[
  {
    "id": "http://arxiv.org/abs/2510.07318v1",
    "title": "Artificial Hippocampus Networks for Efficient Long-Context Modeling",
    "summary": "Long-sequence modeling faces a fundamental trade-off between the efficiency\nof compressive fixed-size memory in RNN-like models and the fidelity of\nlossless growing memory in attention-based Transformers. Inspired by the\nMulti-Store Model in cognitive science, we introduce a memory framework of\nartificial neural networks. Our method maintains a sliding window of the\nTransformer's KV cache as lossless short-term memory, while a learnable module\ntermed Artificial Hippocampus Network (AHN) recurrently compresses\nout-of-window information into a fixed-size compact long-term memory. To\nvalidate this framework, we instantiate AHNs using modern RNN-like\narchitectures, including Mamba2, DeltaNet, and Gated DeltaNet. Extensive\nexperiments on long-context benchmarks LV-Eval and InfiniteBench demonstrate\nthat AHN-augmented models consistently outperform sliding window baselines and\nachieve performance comparable or even superior to full-attention models, while\nsubstantially reducing computational and memory requirements. For instance,\naugmenting the Qwen2.5-3B-Instruct with AHNs reduces inference FLOPs by 40.5%\nand memory cache by 74.0%, while improving its average score on LV-Eval (128k\nsequence length) from 4.41 to 5.88. Code is available at:\nhttps://github.com/ByteDance-Seed/AHN.",
    "published": "2025-10-08T17:59:55Z",
    "updated": "2025-10-08T17:59:55Z",
    "link": "http://arxiv.org/pdf/2510.07318v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Yunhao Fang",
      "Weihao Yu",
      "Shu Zhong",
      "Qinghao Ye",
      "Xuehan Xiong",
      "Lai Wei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.17353v3",
    "title": "NdLinear: Preserving Multi-Dimensional Structure for Parameter-Efficient\n  Neural Networks",
    "summary": "In deep learning, processing multidimensional inputs (e.g., images, medical\nscans, and time series) is an important task that often requires flattening the\ninputs. We introduce $\\mathit{NdLinear}$, a drop-in replacement for linear\nlayers that operates directly on tensors, requiring no flattening. By applying\ntransformations separately along each dimension, NdLinear preserves native data\nstructure while achieving dramatic parameter reductions, often by orders of\nmagnitude, with minimal memory overhead. We prove NdLinear maintains\nexpressivity through structured Tucker decomposition while preserving\nVC-dimension scaling. Extensive experiments demonstrate NdLinear's capacity to\nachieve significant parameter reductions with substantial wall-clock efficiency\ngains and minimal memory overhead. For instance, our $\\mathit{NdLinear-LoRA}$\nmatches or exceeds standard LoRA on language reasoning tasks using up to\n$9\\times$ fewer parameters. Experiments across CNNs, RNNs, Transformers, and\nMLPs on vision, language, time-series, and tabular tasks consistently\ndemonstrate NdLinear's efficiency gains. While excelling at axis-separable\ntasks, NdLinear has limitations with entangled spatial interactions. By\nprocessing data in its original N-dimensional form, NdLinear provides a\ntheoretically grounded, practical component for building more efficient neural\narchitectures.",
    "published": "2025-03-21T17:52:44Z",
    "updated": "2025-10-08T17:59:37Z",
    "link": "http://arxiv.org/pdf/2503.17353v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Alex Reneau",
      "Jerry Yao-Chieh Hu",
      "Zhongfang Zhuang",
      "Ting-Chun Liu",
      "Xiang He",
      "Judah Goldfeder",
      "Nadav Timor",
      "Allen G Roush",
      "Ravid Shwartz-Ziv"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07315v1",
    "title": "Vibe Checker: Aligning Code Evaluation with Human Preference",
    "summary": "Large Language Models (LLMs) have catalyzed vibe coding, where users leverage\nLLMs to generate and iteratively refine code through natural language\ninteractions until it passes their vibe check. Vibe check is tied to real-world\nhuman preference and goes beyond functionality: the solution should feel right,\nread cleanly, preserve intent, and remain correct. However, current code\nevaluation remains anchored to pass@k and captures only functional correctness,\noverlooking the non-functional instructions that users routinely apply. In this\npaper, we hypothesize that instruction following is the missing piece\nunderlying vibe check that represents human preference in coding besides\nfunctional correctness. To quantify models' code instruction following\ncapabilities with measurable signals, we present VeriCode, a taxonomy of 30\nverifiable code instructions together with corresponding deterministic\nverifiers. We use the taxonomy to augment established evaluation suites,\nresulting in Vibe Checker, a testbed to assess both code instruction following\nand functional correctness. Upon evaluating 31 leading LLMs, we show that even\nthe strongest models struggle to comply with multiple instructions and exhibit\nclear functional regression. Most importantly, a composite score of functional\ncorrectness and instruction following correlates the best with human\npreference, with the latter emerging as the primary differentiator on\nreal-world programming tasks. Our work identifies core factors of the vibe\ncheck, providing a concrete path for benchmarking and developing models that\nbetter align with user preferences in coding.",
    "published": "2025-10-08T17:59:19Z",
    "updated": "2025-10-08T17:59:19Z",
    "link": "http://arxiv.org/pdf/2510.07315v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "authors": [
      "Ming Zhong",
      "Xiang Zhou",
      "Ting-Yun Chang",
      "Qingze Wang",
      "Nan Xu",
      "Xiance Si",
      "Dan Garrette",
      "Shyam Upadhyay",
      "Jeremiah Liu",
      "Jiawei Han",
      "Benoit Schillings",
      "Jiao Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07314v1",
    "title": "GyroSwin: 5D Surrogates for Gyrokinetic Plasma Turbulence Simulations",
    "summary": "Nuclear fusion plays a pivotal role in the quest for reliable and sustainable\nenergy production. A major roadblock to viable fusion power is understanding\nplasma turbulence, which significantly impairs plasma confinement, and is vital\nfor next-generation reactor design. Plasma turbulence is governed by the\nnonlinear gyrokinetic equation, which evolves a 5D distribution function over\ntime. Due to its high computational cost, reduced-order models are often\nemployed in practice to approximate turbulent transport of energy. However,\nthey omit nonlinear effects unique to the full 5D dynamics. To tackle this, we\nintroduce GyroSwin, the first scalable 5D neural surrogate that can model 5D\nnonlinear gyrokinetic simulations, thereby capturing the physical phenomena\nneglected by reduced models, while providing accurate estimates of turbulent\nheat transport.GyroSwin (i) extends hierarchical Vision Transformers to 5D,\n(ii) introduces cross-attention and integration modules for latent\n3D$\\leftrightarrow$5D interactions between electrostatic potential fields and\nthe distribution function, and (iii) performs channelwise mode separation\ninspired by nonlinear physics. We demonstrate that GyroSwin outperforms widely\nused reduced numerics on heat flux prediction, captures the turbulent energy\ncascade, and reduces the cost of fully resolved nonlinear gyrokinetics by three\norders of magnitude while remaining physically verifiable. GyroSwin shows\npromising scaling laws, tested up to one billion parameters, paving the way for\nscalable neural surrogates for gyrokinetic simulations of plasma turbulence.",
    "published": "2025-10-08T17:59:10Z",
    "updated": "2025-10-08T17:59:10Z",
    "link": "http://arxiv.org/pdf/2510.07314v1.pdf",
    "category": [
      "physics.plasm-ph",
      "cs.AI",
      "stat.ML"
    ],
    "authors": [
      "Fabian Paischer",
      "Gianluca Galletti",
      "William Hornsby",
      "Paul Setinek",
      "Lorenzo Zanisi",
      "Naomi Carey",
      "Stanislas Pamela",
      "Johannes Brandstetter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07312v1",
    "title": "h1: Bootstrapping LLMs to Reason over Longer Horizons via Reinforcement\n  Learning",
    "summary": "Large language models excel at short-horizon reasoning tasks, but performance\ndrops as reasoning horizon lengths increase. Existing approaches to combat this\nrely on inference-time scaffolding or costly step-level supervision, neither of\nwhich scales easily. In this work, we introduce a scalable method to bootstrap\nlong-horizon reasoning capabilities using only existing, abundant short-horizon\ndata. Our approach synthetically composes simple problems into complex,\nmulti-step dependency chains of arbitrary length. We train models on this data\nusing outcome-only rewards under a curriculum that automatically increases in\ncomplexity, allowing RL training to be scaled much further without saturating.\nEmpirically, our method generalizes remarkably well: curriculum training on\ncomposed 6th-grade level math problems (GSM8K) boosts accuracy on longer,\ncompetition-level benchmarks (GSM-Symbolic, MATH-500, AIME) by up to 2.06x.\nImportantly, our long-horizon improvements are significantly higher than\nbaselines even at high pass@k, showing that models can learn new reasoning\npaths under RL. Theoretically, we show that curriculum RL with outcome rewards\nachieves an exponential improvement in sample complexity over full-horizon\ntraining, providing training signal comparable to dense supervision. h1\ntherefore introduces an efficient path towards scaling RL for long-horizon\nproblems using only existing data.",
    "published": "2025-10-08T17:58:41Z",
    "updated": "2025-10-08T17:58:41Z",
    "link": "http://arxiv.org/pdf/2510.07312v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Sumeet Ramesh Motwani",
      "Alesia Ivanova",
      "Ziyang Cai",
      "Philip Torr",
      "Riashat Islam",
      "Shital Shah",
      "Christian Schroeder de Witt",
      "Charles London"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07307v1",
    "title": "MLE-Smith: Scaling MLE Tasks with Automated Multi-Agent Pipeline",
    "summary": "While Language Models (LMs) have made significant progress in automating\nmachine learning engineering (MLE), the acquisition of high-quality MLE\ntraining data is significantly constrained. Current MLE benchmarks suffer from\nlow scalability and limited applicability because they rely on static, manually\ncurated tasks, demanding extensive time and manual effort to produce. We\nintroduce MLE-Smith, a fully automated multi-agent pipeline, to transform raw\ndatasets into competition-style MLE challenges through an efficient\ngenerate-verify-execute paradigm for scaling MLE tasks with verifiable quality,\nreal-world usability, and rich diversity. The proposed multi-agent pipeline in\nMLE-Smith drives structured task design and standardized refactoring, coupled\nwith a hybrid verification mechanism that enforces strict structural rules and\nhigh-level semantic soundness. It further validates empirical solvability and\nreal-world fidelity through interactive execution. We apply MLE-Smith to 224 of\nreal-world datasets and generate 606 tasks spanning multiple categories,\nobjectives, and modalities, demonstrating that MLE-Smith can work effectively\nacross a wide range of real-world datasets. Evaluation on the generated tasks\nshows that the performance of eight mainstream and cutting-edge LLMs on\nMLE-Smith tasks is strongly correlated with their performance on carefully\nhuman-designed tasks, highlighting the effectiveness of the MLE-Smith to\nscaling up MLE tasks, while maintaining task quality.",
    "published": "2025-10-08T17:57:19Z",
    "updated": "2025-10-08T17:57:19Z",
    "link": "http://arxiv.org/pdf/2510.07307v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Rushi Qiang",
      "Yuchen Zhuang",
      "Anikait Singh",
      "Percy Liang",
      "Chao Zhang",
      "Sherry Yang",
      "Bo Dai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07304v1",
    "title": "Cocoon: A System Architecture for Differentially Private Training with\n  Correlated Noises",
    "summary": "Machine learning (ML) models memorize and leak training data, causing serious\nprivacy issues to data owners. Training algorithms with differential privacy\n(DP), such as DP-SGD, have been gaining attention as a solution. However,\nDP-SGD adds a noise at each training iteration, which degrades the accuracy of\nthe trained model. To improve accuracy, a new family of approaches adds\ncarefully designed correlated noises, so that noises cancel out each other\nacross iterations. We performed an extensive characterization study of these\nnew mechanisms, for the first time to the best of our knowledge, and show they\nincur non-negligible overheads when the model is large or uses large embedding\ntables. Motivated by the analysis, we propose Cocoon, a hardware-software\nco-designed framework for efficient training with correlated noises. Cocoon\naccelerates models with embedding tables through pre-computing and storing\ncorrelated noises in a coalesced format (Cocoon-Emb), and supports large models\nthrough a custom near-memory processing device (Cocoon-NMP). On a real system\nwith an FPGA-based NMP device prototype, Cocoon improves the performance by\n2.33-10.82x(Cocoon-Emb) and 1.55-3.06x (Cocoon-NMP).",
    "published": "2025-10-08T17:56:30Z",
    "updated": "2025-10-08T17:56:30Z",
    "link": "http://arxiv.org/pdf/2510.07304v1.pdf",
    "category": [
      "cs.AR",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "authors": [
      "Donghwan Kim",
      "Xin Gu",
      "Jinho Baek",
      "Timothy Lo",
      "Younghoon Min",
      "Kwangsik Shin",
      "Jongryool Kim",
      "Jongse Park",
      "Kiwan Maeng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.06635v2",
    "title": "Valid Inference with Imperfect Synthetic Data",
    "summary": "Predictions and generations from large language models are increasingly being\nexplored as an aid in limited data regimes, such as in computational social\nscience and human subjects research. While prior technical work has mainly\nexplored the potential to use model-predicted labels for unlabeled data in a\nprincipled manner, there is increasing interest in using large language models\nto generate entirely new synthetic samples (e.g., synthetic simulations), such\nas in responses to surveys. However, it remains unclear by what means\npractitioners can combine such data with real data and yet produce\nstatistically valid conclusions upon them. In this paper, we introduce a new\nestimator based on generalized method of moments, providing a\nhyperparameter-free solution with strong theoretical guarantees to address this\nchallenge. Intriguingly, we find that interactions between the moment residuals\nof synthetic data and those of real data (i.e., when they are predictive of\neach other) can greatly improve estimates of the target parameter. We validate\nthe finite-sample performance of our estimator across different tasks in\ncomputational social science applications, demonstrating large empirical gains.",
    "published": "2025-08-08T18:32:52Z",
    "updated": "2025-10-08T17:56:19Z",
    "link": "http://arxiv.org/pdf/2508.06635v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "authors": [
      "Yewon Byun",
      "Shantanu Gupta",
      "Zachary C. Lipton",
      "Rachel Leah Childers",
      "Bryan Wilder"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07297v1",
    "title": "Agentic generative AI for media content discovery at the national\n  football league",
    "summary": "Generative AI has unlocked new possibilities in content discovery and\nmanagement. Through collaboration with the National Football League (NFL), we\ndemonstrate how a generative-AI based workflow enables media researchers and\nanalysts to query relevant historical plays using natural language rather than\ntraditional filter-and-click interfaces. The agentic workflow takes a user\nquery as input, breaks it into elements, and translates them into the\nunderlying database query language. Accuracy and latency are further improved\nthrough carefully designed semantic caching. The solution achieves over 95\npercent accuracy and reduces the average time to find relevant videos from 10\nminutes to 30 seconds, significantly increasing the NFL's operational\nefficiency and allowing users to focus on producing creative content and\nengaging storylines.",
    "published": "2025-10-08T17:51:34Z",
    "updated": "2025-10-08T17:51:34Z",
    "link": "http://arxiv.org/pdf/2510.07297v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Henry Wang",
      "Sirajus Salekin",
      "Jake Lee",
      "Ross Claytor",
      "Shinan Zhang",
      "Michael Chi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07293v1",
    "title": "AudioMarathon: A Comprehensive Benchmark for Long-Context Audio\n  Understanding and Efficiency in Audio LLMs",
    "summary": "Processing long-form audio is a major challenge for Large Audio Language\nmodels (LALMs). These models struggle with the quadratic cost of attention\n($O(N^2)$) and with modeling long-range temporal dependencies. Existing audio\nbenchmarks are built mostly from short clips and do not evaluate models in\nrealistic long context settings. To address this gap, we introduce\nAudioMarathon, a benchmark designed to evaluate both understanding and\ninference efficiency on long-form audio. AudioMarathon provides a diverse set\nof tasks built upon three pillars: long-context audio inputs with durations\nranging from 90.0 to 300.0 seconds, which correspond to encoded sequences of\n2,250 to 7,500 audio tokens, respectively, full domain coverage across speech,\nsound, and music, and complex reasoning that requires multi-hop inference. We\nevaluate state-of-the-art LALMs and observe clear performance drops as audio\nlength grows. We also study acceleration techniques and analyze the trade-offs\nof token pruning and KV cache eviction. The results show large gaps across\ncurrent LALMs and highlight the need for better temporal reasoning and\nmemory-efficient architectures. We believe AudioMarathon will drive the audio\nand multimodal research community to develop more advanced audio understanding\nmodels capable of solving complex audio tasks.",
    "published": "2025-10-08T17:50:16Z",
    "updated": "2025-10-08T17:50:16Z",
    "link": "http://arxiv.org/pdf/2510.07293v1.pdf",
    "category": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "eess.AS"
    ],
    "authors": [
      "Peize He",
      "Zichen Wen",
      "Yubo Wang",
      "Yuxuan Wang",
      "Xiaoqian Liu",
      "Jiajie Huang",
      "Zehui Lei",
      "Zhuangcheng Gu",
      "Xiangqi Jin",
      "Jiabing Yang",
      "Kai Li",
      "Zhifei Liu",
      "Weijia Li",
      "Cunxiang Wang",
      "Conghui He",
      "Linfeng Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.00320v2",
    "title": "Dyna-Think: Synergizing Reasoning, Acting, and World Model Simulation in\n  AI Agents",
    "summary": "Recent progress in reasoning with large language models (LLMs), such as\nDeepSeek-R1, demonstrates impressive capabilities in domains like mathematics\nand coding, by exhibiting complex cognitive behaviors such as verification,\ngoal decomposition, and self-reflection. However, it is unclear what behavior\nis effective and what behavior is missing for long-horizon AI agents tasks. In\nthis work, we propose Dyna-Think, a thinking framework that integrates planning\nwith an internal world model with reasoning and acting to enhance AI agent\nperformance. To enable Dyna-Think, we propose Dyna-Think Imitation Learning\n(DIT) and Dyna-Think Dyna Training (DDT). To initialize a policy with\nDyna-Think, DIT reconstructs the thinking process of R1 to focus on performing\nworld model simulation relevant to the proposed (and planned) action, and\ntrains the policy using this reconstructed data. To enhance Dyna-Think, DDT\nuses a two-stage training process to first improve the agent's world modeling\nability via objectives such as state prediction or critique generation, and\nthen improve the agent's action via policy training. We evaluate our methods on\nOSWorld and WindowsAgentArena, and demonstrate that Dyna-Think improves the\nagent's in-domain and out-of-domain performance, achieving similar best-of-n\nperformance compared to R1 while generating 2x less tokens on average. Our\nextensive empirical studies reveal that 1) using critique generation for world\nmodel training is effective to improve policy performance; and 2) AI agents\nwith better performance correlate with better world modeling abilities. We\nbelieve our results suggest a promising research direction to integrate world\nmodel simulation into AI agents to enhance their reasoning, planning, and\nacting capabilities.",
    "published": "2025-05-31T00:10:18Z",
    "updated": "2025-10-08T17:49:53Z",
    "link": "http://arxiv.org/pdf/2506.00320v2.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Xiao Yu",
      "Baolin Peng",
      "Ruize Xu",
      "Michel Galley",
      "Hao Cheng",
      "Suman Nath",
      "Jianfeng Gao",
      "Zhou Yu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.03487v2",
    "title": "SafeProtein: Red-Teaming Framework and Benchmark for Protein Foundation\n  Models",
    "summary": "Proteins play crucial roles in almost all biological processes. The\nadvancement of deep learning has greatly accelerated the development of protein\nfoundation models, leading to significant successes in protein understanding\nand design. However, the lack of systematic red-teaming for these models has\nraised serious concerns about their potential misuse, such as generating\nproteins with biological safety risks. This paper introduces SafeProtein, the\nfirst red-teaming framework designed for protein foundation models to the best\nof our knowledge. SafeProtein combines multimodal prompt engineering and\nheuristic beam search to systematically design red-teaming methods and conduct\ntests on protein foundation models. We also curated SafeProtein-Bench, which\nincludes a manually constructed red-teaming benchmark dataset and a\ncomprehensive evaluation protocol. SafeProtein achieved continuous jailbreaks\non state-of-the-art protein foundation models (up to 70% attack success rate\nfor ESM3), revealing potential biological safety risks in current protein\nfoundation models and providing insights for the development of robust security\nprotection technologies for frontier models. The codes will be made publicly\navailable at https://github.com/jigang-fan/SafeProtein.",
    "published": "2025-09-03T17:13:56Z",
    "updated": "2025-10-08T17:47:56Z",
    "link": "http://arxiv.org/pdf/2509.03487v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "q-bio.BM",
      "q-bio.QM"
    ],
    "authors": [
      "Jigang Fan",
      "Zhenghong Zhou",
      "Ruofan Jin",
      "Le Cong",
      "Mengdi Wang",
      "Zaixi Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07286v1",
    "title": "Evolutionary Profiles for Protein Fitness Prediction",
    "summary": "Predicting the fitness impact of mutations is central to protein engineering\nbut constrained by limited assays relative to the size of sequence space.\nProtein language models (pLMs) trained with masked language modeling (MLM)\nexhibit strong zero-shot fitness prediction; we provide a unifying view by\ninterpreting natural evolution as implicit reward maximization and MLM as\ninverse reinforcement learning (IRL), in which extant sequences act as expert\ndemonstrations and pLM log-odds serve as fitness estimates. Building on this\nperspective, we introduce EvoIF, a lightweight model that integrates two\ncomplementary sources of evolutionary signal: (i) within-family profiles from\nretrieved homologs and (ii) cross-family structural-evolutionary constraints\ndistilled from inverse folding logits. EvoIF fuses sequence-structure\nrepresentations with these profiles via a compact transition block, yielding\ncalibrated probabilities for log-odds scoring. On ProteinGym (217 mutational\nassays; >2.5M mutants), EvoIF and its MSA-enabled variant achieve\nstate-of-the-art or competitive performance while using only 0.15% of the\ntraining data and fewer parameters than recent large models. Ablations confirm\nthat within-family and cross-family profiles are complementary, improving\nrobustness across function types, MSA depths, taxa, and mutation depths. The\ncodes will be made publicly available at https://github.com/aim-uofa/EvoIF.",
    "published": "2025-10-08T17:46:02Z",
    "updated": "2025-10-08T17:46:02Z",
    "link": "http://arxiv.org/pdf/2510.07286v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM",
      "q-bio.QM"
    ],
    "authors": [
      "Jigang Fan",
      "Xiaoran Jiao",
      "Shengdong Lin",
      "Zhanming Liang",
      "Weian Mao",
      "Chenchen Jing",
      "Hao Chen",
      "Chunhua Shen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07285v1",
    "title": "GTCN-G: A Residual Graph-Temporal Fusion Network for Imbalanced\n  Intrusion Detection (Preprint)",
    "summary": "The escalating complexity of network threats and the inherent class imbalance\nin traffic data present formidable challenges for modern Intrusion Detection\nSystems (IDS). While Graph Neural Networks (GNNs) excel in modeling topological\nstructures and Temporal Convolutional Networks (TCNs) are proficient in\ncapturing time-series dependencies, a framework that synergistically integrates\nboth while explicitly addressing data imbalance remains an open challenge. This\npaper introduces a novel deep learning framework, named Gated Temporal\nConvolutional Network and Graph (GTCN-G), engineered to overcome these\nlimitations. Our model uniquely fuses a Gated TCN (G-TCN) for extracting\nhierarchical temporal features from network flows with a Graph Convolutional\nNetwork (GCN) designed to learn from the underlying graph structure. The core\ninnovation lies in the integration of a residual learning mechanism,\nimplemented via a Graph Attention Network (GAT). This mechanism preserves\noriginal feature information through residual connections, which is critical\nfor mitigating the class imbalance problem and enhancing detection sensitivity\nfor rare malicious activities (minority classes). We conducted extensive\nexperiments on two public benchmark datasets, UNSW-NB15 and ToN-IoT, to\nvalidate our approach. The empirical results demonstrate that the proposed\nGTCN-G model achieves state-of-the-art performance, significantly outperforming\nexisting baseline models in both binary and multi-class classification tasks.",
    "published": "2025-10-08T17:45:59Z",
    "updated": "2025-10-08T17:45:59Z",
    "link": "http://arxiv.org/pdf/2510.07285v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Tianxiang Xu",
      "Zhichao Wen",
      "Xinyu Zhao",
      "Qi Hu",
      "Yan Li",
      "Chang Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07284v1",
    "title": "Online Rubrics Elicitation from Pairwise Comparisons",
    "summary": "Rubrics provide a flexible way to train LLMs on open-ended long-form answers\nwhere verifiable rewards are not applicable and human preferences provide\ncoarse signals. Prior work shows that reinforcement learning with rubric-based\nrewards leads to consistent gains in LLM post-training. Most existing\napproaches rely on rubrics that remain static over the course of training. Such\nstatic rubrics, however, are vulnerable to reward-hacking type behaviors and\nfail to capture emergent desiderata that arise during training. We introduce\nOnline Rubrics Elicitation (OnlineRubrics), a method that dynamically curates\nevaluation criteria in an online manner through pairwise comparisons of\nresponses from current and reference policies. This online process enables\ncontinuous identification and mitigation of errors as training proceeds.\nEmpirically, this approach yields consistent improvements of up to 8% over\ntraining exclusively with static rubrics across AlpacaEval, GPQA, ArenaHard as\nwell as the validation sets of expert questions and rubrics. We qualitatively\nanalyze the elicited criteria and identify prominent themes such as\ntransparency, practicality, organization, and reasoning.",
    "published": "2025-10-08T17:44:59Z",
    "updated": "2025-10-08T17:44:59Z",
    "link": "http://arxiv.org/pdf/2510.07284v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "MohammadHossein Rezaei",
      "Robert Vacareanu",
      "Zihao Wang",
      "Clinton Wang",
      "Yunzhong He",
      "Afra Feyza Akyürek"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07276v1",
    "title": "Multi-Objective Multi-Agent Path Finding with Lexicographic Cost\n  Preferences",
    "summary": "Many real-world scenarios require multiple agents to coordinate in shared\nenvironments, while balancing trade-offs between multiple, potentially\ncompeting objectives. Current multi-objective multi-agent path finding\n(MO-MAPF) algorithms typically produce conflict-free plans by computing Pareto\nfrontiers. They do not explicitly optimize for user-defined preferences, even\nwhen the preferences are available, and scale poorly with the number of\nobjectives. We propose a lexicographic framework for modeling MO-MAPF, along\nwith an algorithm \\textit{Lexicographic Conflict-Based Search} (LCBS) that\ndirectly computes a single solution aligned with a lexicographic preference\nover objectives. LCBS integrates a priority-aware low-level $A^*$ search with\nconflict-based search, avoiding Pareto frontier construction and enabling\nefficient planning guided by preference over objectives. We provide insights\ninto optimality and scalability, and empirically demonstrate that LCBS computes\noptimal solutions while scaling to instances with up to ten objectives -- far\nbeyond the limits of existing MO-MAPF methods. Evaluations on standard and\nrandomized MAPF benchmarks show consistently higher success rates against\nstate-of-the-art baselines, especially with increasing number of objectives.",
    "published": "2025-10-08T17:40:41Z",
    "updated": "2025-10-08T17:40:41Z",
    "link": "http://arxiv.org/pdf/2510.07276v1.pdf",
    "category": [
      "cs.AI",
      "cs.MA"
    ],
    "authors": [
      "Pulkit Rustagi",
      "Kyle Hollins Wray",
      "Sandhya Saisubramanian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07268v1",
    "title": "On the false election between regulation and innovation. Ideas for\n  regulation through the responsible use of artificial intelligence in research\n  and education.[Spanish version]",
    "summary": "This short essay is a reworking of the answers offered by the author at the\nDebate Session of the AIHUB (CSIC) and EduCaixa Summer School, organized by\nMarta Garcia-Matos and Lissette Lemus, and coordinated by Albert Sabater\n(OEIAC, UG), with the participation of Vanina Martinez-Posse (IIIA-CSIC),\nEulalia Soler (Eurecat) and Pompeu Casanovas (IIIA-CSIC) on July 4th 2025.\nAlbert Sabater posed three questions: (1) How can regulatory frameworks\npriori-tise the protection of fundamental rights (privacy, non-discrimination,\nautonomy, etc.) in the development of AI, without falling into the false\ndichotomy between regulation and innova-tion? (2) Given the risks of AI (bias,\nmass surveillance, manipulation), what examples of regu-lations or policies\nhave demonstrated that it is possible to foster responsible innovation, putting\nthe public interest before profitability, without giving in to competitive\npressure from actors such as China or the US? (3) In a scenario where the US\nprioritizes flexibility, what mecha-nisms could ensure that international\ncooperation in AI does not become a race to the bottom in rights, but rather a\nglobal standard of accountability? The article attempts to answer these three\nquestions and concludes with some reflections on the relevance of the answers\nfor education and research.",
    "published": "2025-10-08T17:33:46Z",
    "updated": "2025-10-08T17:33:46Z",
    "link": "http://arxiv.org/pdf/2510.07268v1.pdf",
    "category": [
      "cs.CY",
      "cs.AI",
      "J.4; K.3; K.4; K.5"
    ],
    "authors": [
      "Pompeu Casanovas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2404.12353v3",
    "title": "V2Xum-LLM: Cross-Modal Video Summarization with Temporal Prompt\n  Instruction Tuning",
    "summary": "Video summarization aims to create short, accurate, and cohesive summaries of\nlonger videos. Despite the existence of various video summarization datasets, a\nnotable limitation is their limited amount of source videos, which hampers the\neffective training of advanced large vision-language models (VLMs).\nAdditionally, most existing datasets are created for video-to-video\nsummarization, overlooking the contemporary need for multimodal video content\nsummarization. Recent efforts have been made to expand from unimodal to\nmultimodal video summarization, categorizing the task into three sub-tasks\nbased on the summary's modality: video-to-video (V2V), video-to-text (V2T), and\na combination of video and text summarization (V2VT). However, the textual\nsummaries in previous multimodal datasets are inadequate. To address these\nissues, we introduce Instruct-V2Xum, a cross-modal video summarization dataset\nfeaturing 30,000 diverse videos sourced from YouTube, with lengths ranging from\n40 to 940 seconds and an average summarization ratio of 16.39%. Each video\nsummary in Instruct-V2Xum is paired with a textual summary that references\nspecific frame indexes, facilitating the generation of aligned video and\ntextual summaries. In addition, we propose a new video summarization framework\nnamed V2Xum-LLM. V2Xum-LLM, specifically V2Xum-LLaMA in this study, is the\nfirst framework that unifies different video summarization tasks into one large\nlanguage model's (LLM) text decoder and achieves task-controllable video\nsummarization with temporal prompts and task instructions. Experiments show\nthat V2Xum-LLaMA outperforms strong baseline models on multiple video\nsummarization tasks. Furthermore, we propose an enhanced evaluation metric for\nV2V and V2VT summarization tasks.",
    "published": "2024-04-18T17:32:46Z",
    "updated": "2025-10-08T17:22:42Z",
    "link": "http://arxiv.org/pdf/2404.12353v3.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Hang Hua",
      "Yolo Yunlong Tang",
      "Chenliang Xu",
      "Jiebo Luo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2403.16276v3",
    "title": "Empowering LLMs with Pseudo-Untrimmed Videos for Audio-Visual Temporal\n  Understanding",
    "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in\nnatural language and multimodal domains. By fine-tuning multimodal LLMs with\ntemporal annotations from well-annotated datasets, e.g., dense video captioning\ndatasets, their temporal understanding capacity in video-language tasks can be\nobtained. However, there is a notable lack of untrimmed audio-visual video\ndatasets with precise temporal annotations for events. This deficiency hinders\nLLMs from learning the alignment between time, audio-visual events, and text\ntokens, thus impairing their ability to temporally localize audio-visual events\nin videos. To address this gap, we introduce PU-VALOR, a comprehensive\naudio-visual dataset comprising over 114,000 pseudo-untrimmed videos with\ndetailed temporal annotations. PU-VALOR is derived from the large-scale but\ncoarse-annotated audio-visual dataset VALOR, through a subtle method involving\nevent-based video clustering, random temporal scaling, and permutation. By\nfine-tuning a multimodal LLM on PU-VALOR, we developed AVicuna, a model capable\nof aligning audio-visual events with temporal intervals and corresponding text\ntokens. AVicuna excels in temporal localization and time-aware dialogue\ncapabilities. Our experiments demonstrate that AVicuna effectively handles\ntemporal understanding in audio-visual videos and achieves state-of-the-art\nperformance on open-ended video QA, audio-visual QA, and audio-visual event\ndense localization tasks.",
    "published": "2024-03-24T19:50:49Z",
    "updated": "2025-10-08T17:18:11Z",
    "link": "http://arxiv.org/pdf/2403.16276v3.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Yolo Yunlong Tang",
      "Daiki Shimada",
      "Jing Bi",
      "Mingqian Feng",
      "Hang Hua",
      "Chenliang Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2402.09225v4",
    "title": "Is My Data in Your AI? Membership Inference Test (MINT) applied to Face\n  Biometrics",
    "summary": "This article introduces the Membership Inference Test (MINT), a novel\napproach that aims to empirically assess if given data was used during the\ntraining of AI/ML models. Specifically, we propose two MINT architectures\ndesigned to learn the distinct activation patterns that emerge when an Audited\nModel is exposed to data used during its training process. These architectures\nare based on Multilayer Perceptrons (MLPs) and Convolutional Neural Networks\n(CNNs). The experimental framework focuses on the challenging task of Face\nRecognition, considering three state-of-the-art Face Recognition systems.\nExperiments are carried out using six publicly available databases, comprising\nover 22 million face images in total. Different experimental scenarios are\nconsidered depending on the context of the AI model to test. Our proposed MINT\napproach achieves promising results, with up to 90\\% accuracy, indicating the\npotential to recognize if an AI model has been trained with specific data. The\nproposed MINT approach can serve to enforce privacy and fairness in several AI\napplications, e.g., revealing if sensitive or private data was used for\ntraining or tuning Large Language Models (LLMs).",
    "published": "2024-02-14T15:09:01Z",
    "updated": "2025-10-08T17:12:48Z",
    "link": "http://arxiv.org/pdf/2402.09225v4.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Daniel DeAlcala",
      "Aythami Morales",
      "Julian Fierrez",
      "Gonzalo Mancera",
      "Ruben Tolosana",
      "Javier Ortega-Garcia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.10979v4",
    "title": "VidComposition: Can MLLMs Analyze Compositions in Compiled Videos?",
    "summary": "The advancement of Multimodal Large Language Models (MLLMs) has enabled\nsignificant progress in multimodal understanding, expanding their capacity to\nanalyze video content. However, existing evaluation benchmarks for MLLMs\nprimarily focus on abstract video comprehension, lacking a detailed assessment\nof their ability to understand video compositions, the nuanced interpretation\nof how visual elements combine and interact within highly compiled video\ncontexts. We introduce VidComposition, a new benchmark specifically designed to\nevaluate the video composition understanding capabilities of MLLMs using\ncarefully curated compiled videos and cinematic-level annotations.\nVidComposition includes 982 videos with 1706 multiple-choice questions,\ncovering various compositional aspects such as camera movement, angle, shot\nsize, narrative structure, character actions and emotions, etc. Our\ncomprehensive evaluation of 33 open-source and proprietary MLLMs reveals a\nsignificant performance gap between human and model capabilities. This\nhighlights the limitations of current MLLMs in understanding complex, compiled\nvideo compositions and offers insights into areas for further improvement. The\nleaderboard and evaluation code are available at\nhttps://yunlong10.github.io/VidComposition/.",
    "published": "2024-11-17T06:23:46Z",
    "updated": "2025-10-08T17:12:26Z",
    "link": "http://arxiv.org/pdf/2411.10979v4.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Yolo Yunlong Tang",
      "Junjia Guo",
      "Hang Hua",
      "Susan Liang",
      "Mingqian Feng",
      "Xinyang Li",
      "Rui Mao",
      "Chao Huang",
      "Jing Bi",
      "Zeliang Zhang",
      "Pooyan Fazli",
      "Chenliang Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07243v1",
    "title": "LeMAJ (Legal LLM-as-a-Judge): Bridging Legal Reasoning and LLM\n  Evaluation",
    "summary": "Evaluating large language model (LLM) outputs in the legal domain presents\nunique challenges due to the complex and nuanced nature of legal analysis.\nCurrent evaluation approaches either depend on reference data, which is costly\nto produce, or use standardized assessment methods, both of which have\nsignificant limitations for legal applications.\n  Although LLM-as-a-Judge has emerged as a promising evaluation technique, its\nreliability and effectiveness in legal contexts depend heavily on evaluation\nprocesses unique to the legal industry and how trustworthy the evaluation\nappears to the human legal expert. This is where existing evaluation methods\ncurrently fail and exhibit considerable variability.\n  This paper aims to close the gap: a) we break down lengthy responses into\n'Legal Data Points' (LDPs), self-contained units of information, and introduce\na novel, reference-free evaluation methodology that reflects how lawyers\nevaluate legal answers; b) we demonstrate that our method outperforms a variety\nof baselines on both our proprietary dataset and an open-source dataset\n(LegalBench); c) we show how our method correlates more closely with human\nexpert evaluations and helps improve inter-annotator agreement; and finally d)\nwe open source our Legal Data Points for a subset of LegalBench used in our\nexperiments, allowing the research community to replicate our results and\nadvance research in this vital area of LLM evaluation on legal\nquestion-answering.",
    "published": "2025-10-08T17:10:47Z",
    "updated": "2025-10-08T17:10:47Z",
    "link": "http://arxiv.org/pdf/2510.07243v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Joseph Enguehard",
      "Morgane Van Ermengem",
      "Kate Atkinson",
      "Sujeong Cha",
      "Arijit Ghosh Chowdhury",
      "Prashanth Kallur Ramaswamy",
      "Jeremy Roghair",
      "Hannah R Marlowe",
      "Carina Suzana Negreanu",
      "Kitty Boxall",
      "Diana Mincu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.01505v2",
    "title": "Lossy Neural Compression for Geospatial Analytics: A Review",
    "summary": "Over the past decades, there has been an explosion in the amount of available\nEarth Observation (EO) data. The unprecedented coverage of the Earth's surface\nand atmosphere by satellite imagery has resulted in large volumes of data that\nmust be transmitted to ground stations, stored in data centers, and distributed\nto end users. Modern Earth System Models (ESMs) face similar challenges,\noperating at high spatial and temporal resolutions, producing petabytes of data\nper simulated day. Data compression has gained relevance over the past decade,\nwith neural compression (NC) emerging from deep learning and information\ntheory, making EO data and ESM outputs ideal candidates due to their abundance\nof unlabeled data. In this review, we outline recent developments in NC applied\nto geospatial data. We introduce the fundamental concepts of NC including\nseminal works in its traditional applications to image and video compression\ndomains with focus on lossy compression. We discuss the unique characteristics\nof EO and ESM data, contrasting them with \"natural images\", and explain the\nadditional challenges and opportunities they present. Moreover, we review\ncurrent applications of NC across various EO modalities and explore the limited\nefforts in ESM compression to date. The advent of self-supervised learning\n(SSL) and foundation models (FM) has advanced methods to efficiently distill\nrepresentations from vast unlabeled data. We connect these developments to NC\nfor EO, highlighting the similarities between the two fields and elaborate on\nthe potential of transferring compressed feature representations for\nmachine--to--machine communication. Based on insights drawn from this review,\nwe devise future directions relevant to applications in EO and ESM.",
    "published": "2025-03-03T13:19:43Z",
    "updated": "2025-10-08T17:10:10Z",
    "link": "http://arxiv.org/pdf/2503.01505v2.pdf",
    "category": [
      "eess.SP",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "physics.geo-ph"
    ],
    "authors": [
      "Carlos Gomes",
      "Isabelle Wittmann",
      "Damien Robert",
      "Johannes Jakubik",
      "Tim Reichelt",
      "Michele Martone",
      "Stefano Maurogiovanni",
      "Rikard Vinge",
      "Jonas Hurst",
      "Erik Scheurer",
      "Rocco Sedona",
      "Thomas Brunschwiler",
      "Stefan Kesselheim",
      "Matej Batic",
      "Philip Stier",
      "Jan Dirk Wegner",
      "Gabriele Cavallaro",
      "Edzer Pebesma",
      "Michael Marszalek",
      "Miguel A Belenguer-Plomer",
      "Kennedy Adriko",
      "Paolo Fraccaro",
      "Romeo Kienzler",
      "Rania Briq",
      "Sabrina Benassou",
      "Michele Lazzarini",
      "Conrad M Albrecht"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.10974v3",
    "title": "AutoMind: Adaptive Knowledgeable Agent for Automated Data Science",
    "summary": "Large Language Model (LLM) agents have shown great potential in addressing\nreal-world data science problems. LLM-driven data science agents promise to\nautomate the entire machine learning pipeline, yet their real-world\neffectiveness remains limited. Existing frameworks depend on rigid, pre-defined\nworkflows and inflexible coding strategies; consequently, they excel only on\nrelatively simple, classical problems and fail to capture the empirical\nexpertise that human practitioners bring to complex, innovative tasks. In this\nwork, we introduce AutoMind, an adaptive, knowledgeable LLM-agent framework\nthat overcomes these deficiencies through three key advances: (1) a curated\nexpert knowledge base that grounds the agent in domain expert knowledge, (2) an\nagentic knowledgeable tree search algorithm that strategically explores\npossible solutions, and (3) a self-adaptive coding strategy that dynamically\ntailors code generation to task complexity. Evaluations on two automated data\nscience benchmarks demonstrate that AutoMind delivers superior performance\nversus state-of-the-art baselines. Additional analyses confirm favorable\neffectiveness, efficiency, and qualitative solution quality, highlighting\nAutoMind as an efficient and robust step toward fully automated data science.\nCode is at https://github.com/innovatingAI/AutoMind.",
    "published": "2025-06-12T17:59:32Z",
    "updated": "2025-10-08T17:06:47Z",
    "link": "http://arxiv.org/pdf/2506.10974v3.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.MA"
    ],
    "authors": [
      "Yixin Ou",
      "Yujie Luo",
      "Jingsheng Zheng",
      "Lanning Wei",
      "Zhuoyun Yu",
      "Shuofei Qiao",
      "Jintian Zhang",
      "Da Zheng",
      "Yuren Mao",
      "Yunjun Gao",
      "Huajun Chen",
      "Ningyu Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07231v1",
    "title": "Benchmarking LLM Causal Reasoning with Scientifically Validated\n  Relationships",
    "summary": "Causal reasoning is fundamental for Large Language Models (LLMs) to\nunderstand genuine cause-and-effect relationships beyond pattern matching.\nExisting benchmarks suffer from critical limitations such as reliance on\nsynthetic data and narrow domain coverage. We introduce a novel benchmark\nconstructed from casually identified relationships extracted from top-tier\neconomics and finance journals, drawing on rigorous methodologies including\ninstrumental variables, difference-in-differences, and regression discontinuity\ndesigns. Our benchmark comprises 40,379 evaluation items covering five task\ntypes across domains such as health, environment, technology, law, and culture.\nExperimental results on eight state-of-the-art LLMs reveal substantial\nlimitations, with the best model achieving only 57.6\\% accuracy. Moreover,\nmodel scale does not consistently translate to superior performance, and even\nadvanced reasoning models struggle with fundamental causal relationship\nidentification. These findings underscore a critical gap between current LLM\ncapabilities and demands of reliable causal reasoning in high-stakes\napplications.",
    "published": "2025-10-08T17:00:49Z",
    "updated": "2025-10-08T17:00:49Z",
    "link": "http://arxiv.org/pdf/2510.07231v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Donggyu Lee",
      "Sungwon Park",
      "Yerin Hwang",
      "Hyunwoo Oh",
      "Hyoshin Kim",
      "Jungwon Kim",
      "Meeyoung Cha",
      "Sangyoon Park",
      "Jihee Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.11031v3",
    "title": "Prefilled responses enhance zero-shot detection of AI-generated images",
    "summary": "As AI models generate increasingly realistic images, growing concerns over\npotential misuse underscore the need for reliable detection. Traditional\nsupervised detection methods depend on large, curated datasets for training and\noften fail to generalize to novel, out-of-domain image generators. As an\nalternative, we explore pre-trained Vision-Language Models (VLMs) for zero-shot\ndetection of AI-generated images. We evaluate VLM performance on three diverse\nbenchmarks encompassing synthetic images of human faces, objects, and animals\nproduced by 16 different state-of-the-art image generators. While off-the-shelf\nVLMs perform poorly on these datasets, we find that their reasoning can be\nguided effectively through simple response prefilling -- a method we call\nPrefill-Guided Thinking (PGT). In particular, prefilling a VLM response with\nthe task-aligned phrase \"Let's examine the style and the synthesis artifacts\"\nimproves the Macro F1 scores of three widely used open-source VLMs by up to\n24%.",
    "published": "2025-05-20T22:44:04Z",
    "updated": "2025-10-08T16:59:43Z",
    "link": "http://arxiv.org/pdf/2506.11031v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Zoher Kachwala",
      "Danishjeet Singh",
      "Danielle Yang",
      "Filippo Menczer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07227v1",
    "title": "Where to Begin: Efficient Pretraining via Subnetwork Selection and\n  Distillation",
    "summary": "Small Language models (SLMs) offer an efficient and accessible alternative to\nLarge Language Models (LLMs), delivering strong performance while using far\nfewer resources. We introduce a simple and effective framework for pretraining\nSLMs that brings together three complementary ideas. First, we identify\nstructurally sparse sub-network initializations that consistently outperform\nrandomly initialized models of similar size under the same compute budget.\nSecond, we use evolutionary search to automatically discover high-quality\nsub-network initializations, providing better starting points for pretraining.\nThird, we apply knowledge distillation from larger teacher models to speed up\ntraining and improve generalization. Together, these components make SLM\npretraining substantially more efficient: our best model, discovered using\nevolutionary search and initialized with LLM weights, matches the validation\nperplexity of a comparable Pythia SLM while requiring 9.2x fewer pretraining\ntokens. We release all code and models at\nhttps://github.com/whittle-org/whittle/, offering a practical and reproducible\npath toward cost-efficient small language model development at scale.",
    "published": "2025-10-08T16:57:46Z",
    "updated": "2025-10-08T16:57:46Z",
    "link": "http://arxiv.org/pdf/2510.07227v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Arjun Krishnakumar",
      "Rhea Sanjay Sukthanker",
      "Hannan Javed Mahadik",
      "Gabriela Kadlecová",
      "Vladyslav Moroshan",
      "Timur Carstensen",
      "Frank Hutter",
      "Aaron Klein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.19807v3",
    "title": "KnowRL: Exploring Knowledgeable Reinforcement Learning for Factuality",
    "summary": "Large Language Models (LLMs), particularly slow-thinking models, often\nexhibit severe hallucination, outputting incorrect content due to an inability\nto accurately recognize knowledge boundaries during reasoning. While\nReinforcement Learning (RL) can enhance complex reasoning abilities, its\noutcome-oriented reward mechanism often lacks factual supervision over the\nthinking process, further exacerbating the hallucination problem. To address\nthe high hallucination in slow-thinking models, we propose Knowledge-enhanced\nRL, KnowRL. KnowRL guides models to perform fact-based slow thinking by\nintegrating a factuality reward, based on knowledge verification, into the RL\ntraining process, helping them recognize their knowledge boundaries. KnowRL\nguides models to perform fact-based slow thinking by integrating a factuality\nreward, based on knowledge verification, into the RL training process, helping\nthem recognize their knowledge boundaries. This targeted factual input during\nRL training enables the model to learn and internalize fact-based reasoning\nstrategies. By directly rewarding adherence to facts within the reasoning\nsteps, KnowRL fosters a more reliable thinking process. Experimental results on\nthree hallucination evaluation datasets and two reasoning evaluation datasets\ndemonstrate that KnowRL effectively mitigates hallucinations in slow-thinking\nmodels while maintaining their original strong reasoning capabilities. Our code\nis available at https://github.com/zjunlp/KnowRL.",
    "published": "2025-06-24T17:17:17Z",
    "updated": "2025-10-08T16:56:59Z",
    "link": "http://arxiv.org/pdf/2506.19807v3.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG",
      "cs.MA"
    ],
    "authors": [
      "Baochang Ren",
      "Shuofei Qiao",
      "Da Zheng",
      "Huajun Chen",
      "Ningyu Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07217v1",
    "title": "GenPilot: A Multi-Agent System for Test-Time Prompt Optimization in\n  Image Generation",
    "summary": "Text-to-image synthesis has made remarkable progress, yet accurately\ninterpreting complex and lengthy prompts remains challenging, often resulting\nin semantic inconsistencies and missing details. Existing solutions, such as\nfine-tuning, are model-specific and require training, while prior automatic\nprompt optimization (APO) approaches typically lack systematic error analysis\nand refinement strategies, resulting in limited reliability and effectiveness.\nMeanwhile, test-time scaling methods operate on fixed prompts and on noise or\nsample numbers, limiting their interpretability and adaptability. To solve\nthese, we introduce a flexible and efficient test-time prompt optimization\nstrategy that operates directly on the input text. We propose a plug-and-play\nmulti-agent system called GenPilot, integrating error analysis,\nclustering-based adaptive exploration, fine-grained verification, and a memory\nmodule for iterative optimization. Our approach is model-agnostic,\ninterpretable, and well-suited for handling long and complex prompts.\nSimultaneously, we summarize the common patterns of errors and the refinement\nstrategy, offering more experience and encouraging further exploration.\nExperiments on DPG-bench and Geneval with improvements of up to 16.9% and 5.7%\ndemonstrate the strong capability of our methods in enhancing the text and\nimage consistency and structural coherence of generated images, revealing the\neffectiveness of our test-time prompt optimization strategy. The code is\navailable at https://github.com/27yw/GenPilot.",
    "published": "2025-10-08T16:51:52Z",
    "updated": "2025-10-08T16:51:52Z",
    "link": "http://arxiv.org/pdf/2510.07217v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Wen Ye",
      "Zhaocheng Liu",
      "Yuwei Gui",
      "Tingyu Yuan",
      "Yunyue Su",
      "Bowen Fang",
      "Chaoyang Zhao",
      "Qiang Liu",
      "Liang Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07213v1",
    "title": "Language Lives in Sparse Dimensions: Toward Interpretable and Efficient\n  Multilingual Control for Large Language Models",
    "summary": "Large language models exhibit strong multilingual capabilities despite\nlimited exposure to non-English data. Prior studies show that English-centric\nlarge language models map multilingual content into English-aligned\nrepresentations at intermediate layers and then project them back into\ntarget-language token spaces in the final layer. From this observation, we\nhypothesize that this cross-lingual transition is governed by a small and\nsparse set of dimensions, which occur at consistent indices across the\nintermediate to final layers. Building on this insight, we introduce a simple,\ntraining-free method to identify and manipulate these dimensions, requiring\nonly as few as 50 sentences of either parallel or monolingual data. Experiments\non a multilingual generation control task reveal the interpretability of these\ndimensions, demonstrating that the interventions in these dimensions can switch\nthe output language while preserving semantic content, and that it surpasses\nthe performance of prior neuron-based approaches at a substantially lower cost.",
    "published": "2025-10-08T16:46:57Z",
    "updated": "2025-10-08T16:46:57Z",
    "link": "http://arxiv.org/pdf/2510.07213v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Chengzhi Zhong",
      "Fei Cheng",
      "Qianying Liu",
      "Yugo Murawaki",
      "Chenhui Chu",
      "Sadao Kurohashi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.06250v4",
    "title": "Generative AI for Cel-Animation: A Survey",
    "summary": "Traditional Celluloid (Cel) Animation production pipeline encompasses\nmultiple essential steps, including storyboarding, layout design, keyframe\nanimation, inbetweening, and colorization, which demand substantial manual\neffort, technical expertise, and significant time investment. These challenges\nhave historically impeded the efficiency and scalability of Cel-Animation\nproduction. The rise of generative artificial intelligence (GenAI),\nencompassing large language models, multimodal models, and diffusion models,\noffers innovative solutions by automating tasks such as inbetween frame\ngeneration, colorization, and storyboard creation. This survey explores how\nGenAI integration is revolutionizing traditional animation workflows by\nlowering technical barriers, broadening accessibility for a wider range of\ncreators through tools like AniDoc, ToonCrafter, and AniSora, and enabling\nartists to focus more on creative expression and artistic innovation. Despite\nits potential, challenges like visual consistency, stylistic coherence, and\nethical considerations persist. Additionally, this paper explores future\ndirections and advancements in AI-assisted animation. For further exploration\nand resources, please visit our GitHub repository:\nhttps://github.com/yunlong10/Awesome-AI4Animation",
    "published": "2025-01-08T20:57:39Z",
    "updated": "2025-10-08T16:45:46Z",
    "link": "http://arxiv.org/pdf/2501.06250v4.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "authors": [
      "Yolo Yunlong Tang",
      "Junjia Guo",
      "Pinxin Liu",
      "Zhiyuan Wang",
      "Hang Hua",
      "Jia-Xing Zhong",
      "Yunzhong Xiao",
      "Chao Huang",
      "Luchuan Song",
      "Susan Liang",
      "Yizhi Song",
      "Liu He",
      "Jing Bi",
      "Mingqian Feng",
      "Xinyang Li",
      "Zeliang Zhang",
      "Chenliang Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07210v1",
    "title": "HyPlan: Hybrid Learning-Assisted Planning Under Uncertainty for Safe\n  Autonomous Driving",
    "summary": "We present a novel hybrid learning-assisted planning method, named HyPlan,\nfor solving the collision-free navigation problem for self-driving cars in\npartially observable traffic environments. HyPlan combines methods for\nmulti-agent behavior prediction, deep reinforcement learning with proximal\npolicy optimization and approximated online POMDP planning with heuristic\nconfidence-based vertical pruning to reduce its execution time without\ncompromising safety of driving. Our experimental performance analysis on the\nCARLA-CTS2 benchmark of critical traffic scenarios with pedestrians revealed\nthat HyPlan may navigate safer than selected relevant baselines and perform\nsignificantly faster than considered alternative online POMDP planners.",
    "published": "2025-10-08T16:44:54Z",
    "updated": "2025-10-08T16:44:54Z",
    "link": "http://arxiv.org/pdf/2510.07210v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Donald Pfaffmann",
      "Matthias Klusch",
      "Marcel Steinmetz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.16834v3",
    "title": "SimpleDeepSearcher: Deep Information Seeking via Web-Powered Reasoning\n  Trajectory Synthesis",
    "summary": "Retrieval-augmented generation (RAG) systems have advanced large language\nmodels (LLMs) in complex deep search scenarios requiring multi-step reasoning\nand iterative information retrieval. However, existing approaches face critical\nlimitations that lack high-quality training trajectories or suffer from the\ndistributional mismatches in simulated environments and prohibitive\ncomputational costs for real-world deployment. This paper introduces\nSimpleDeepSearcher, a lightweight yet effective framework that bridges this gap\nthrough strategic data engineering rather than complex training paradigms. Our\napproach synthesizes high-quality training data by simulating realistic user\ninteractions in live web search environments, coupled with a multi-criteria\ncuration strategy that optimizes the diversity and quality of input and output\nside. Experiments on five benchmarks across diverse domains demonstrate that\nSFT on only 871 curated samples yields significant improvements over RL-based\nbaselines. Our work establishes SFT as a viable pathway by systematically\naddressing the data-scarce bottleneck, offering practical insights for\nefficient deep search systems. Our code is available at\nhttps://github.com/RUCAIBox/SimpleDeepSearcher.",
    "published": "2025-05-22T16:05:02Z",
    "updated": "2025-10-08T16:40:37Z",
    "link": "http://arxiv.org/pdf/2505.16834v3.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "authors": [
      "Shuang Sun",
      "Huatong Song",
      "Yuhao Wang",
      "Ruiyang Ren",
      "Jinhao Jiang",
      "Junjie Zhang",
      "Fei Bai",
      "Jia Deng",
      "Wayne Xin Zhao",
      "Zheng Liu",
      "Lei Fang",
      "Zhongyuan Wang",
      "Ji-Rong Wen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.07836v4",
    "title": "AerialVG: A Challenging Benchmark for Aerial Visual Grounding by\n  Exploring Positional Relations",
    "summary": "Visual grounding (VG) aims to localize target objects in an image based on\nnatural language descriptions. In this paper, we propose AerialVG, a new task\nfocusing on visual grounding from aerial views. Compared to traditional VG,\nAerialVG poses new challenges, \\emph{e.g.}, appearance-based grounding is\ninsufficient to distinguish among multiple visually similar objects, and\npositional relations should be emphasized. Besides, existing VG models struggle\nwhen applied to aerial imagery, where high-resolution images cause significant\ndifficulties. To address these challenges, we introduce the first AerialVG\ndataset, consisting of 5K real-world aerial images, 50K manually annotated\ndescriptions, and 103K objects. Particularly, each annotation in AerialVG\ndataset contains multiple target objects annotated with relative spatial\nrelations, requiring models to perform comprehensive spatial reasoning.\nFurthermore, we propose an innovative model especially for the AerialVG task,\nwhere a Hierarchical Cross-Attention is devised to focus on target regions, and\na Relation-Aware Grounding module is designed to infer positional relations.\nExperimental results validate the effectiveness of our dataset and method,\nhighlighting the importance of spatial reasoning in aerial visual grounding.\nThe code and dataset will be released.",
    "published": "2025-04-10T15:13:00Z",
    "updated": "2025-10-08T16:28:29Z",
    "link": "http://arxiv.org/pdf/2504.07836v4.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Junli Liu",
      "Qizhi Chen",
      "Zhigang Wang",
      "Yiwen Tang",
      "Yiting Zhang",
      "Chi Yan",
      "Dong Wang",
      "Xuelong Li",
      "Bin Zhao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2209.12164v2",
    "title": "Multi-modal Segment Assemblage Network for Ad Video Editing with\n  Importance-Coherence Reward",
    "summary": "Advertisement video editing aims to automatically edit advertising videos\ninto shorter videos while retaining coherent content and crucial information\nconveyed by advertisers. It mainly contains two stages: video segmentation and\nsegment assemblage. The existing method performs well at video segmentation\nstages but suffers from the problems of dependencies on extra cumbersome models\nand poor performance at the segment assemblage stage. To address these\nproblems, we propose M-SAN (Multi-modal Segment Assemblage Network) which can\nperform efficient and coherent segment assemblage task end-to-end. It utilizes\nmulti-modal representation extracted from the segments and follows the\nEncoder-Decoder Ptr-Net framework with the Attention mechanism.\nImportance-coherence reward is designed for training M-SAN. We experiment on\nthe Ads-1k dataset with 1000+ videos under rich ad scenarios collected from\nadvertisers. To evaluate the methods, we propose a unified metric,\nImp-Coh@Time, which comprehensively assesses the importance, coherence, and\nduration of the outputs at the same time. Experimental results show that our\nmethod achieves better performance than random selection and the previous\nmethod on the metric. Ablation experiments further verify that multi-modal\nrepresentation and importance-coherence reward significantly improve the\nperformance. Ads-1k dataset is available at:\nhttps://github.com/yunlong10/Ads-1k",
    "published": "2022-09-25T06:51:45Z",
    "updated": "2025-10-08T16:27:55Z",
    "link": "http://arxiv.org/pdf/2209.12164v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "authors": [
      "Yolo Yunlong Tang",
      "Siting Xu",
      "Teng Wang",
      "Qin Lin",
      "Qinglin Lu",
      "Feng Zheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07191v1",
    "title": "Resolution scaling governs DINOv3 transfer performance in chest\n  radiograph classification",
    "summary": "Self-supervised learning (SSL) has advanced visual representation learning,\nbut its value in chest radiography, a high-volume imaging modality with\nfine-grained findings, remains unclear. Meta's DINOv3 extends earlier SSL\nmodels through Gram-anchored self-distillation. Whether these design choices\nimprove transfer learning for chest radiography has not been systematically\ntested. We benchmarked DINOv3 against DINOv2 and ImageNet initialization across\nseven datasets (n>814,000). Two representative backbones were evaluated:\nViT-B/16 and ConvNeXt-B. Images were analyzed at 224x224, 512x512, and\n1024x1024 pixels. We additionally assessed frozen features from a 7B model. The\nprimary outcome was mean AUROC across labels. At 224x224, DINOv3 and DINOv2\nachieved comparable performance on adult datasets. Increasing resolution to\n512x512 yielded consistent improvements for DINOv3 over both DINOv2 and\nImageNet. In contrast, results in pediatric cohort showed no differences across\ninitializations. Across all settings, ConvNeXt-B outperformed ViT-B/16. Models\nusing frozen DINOv3-7B features underperformed relative to fully finetuned\n86-89M-parameter backbones, highlighting the importance of domain adaptation.\nScaling to 1024x1024 did not further improve accuracy. Resolution-related gains\nwere most evident for boundary-dependent and small focal abnormalities. In\nchest radiography, higher input resolution is critical for leveraging the\nbenefits of modern self-supervised models. 512x512 pixels represent a practical\nupper limit where DINOv3-initialized ConvNeXt-B networks provide the strongest\nperformance, while larger inputs offer minimal return on cost. Clinically,\nthese findings support use of finetuned, mid-sized backbones at 512x512 for\nchest radiograph interpretation, with the greatest gains expected in detecting\nsubtle or boundary-centered lesions relevant to emergency and critical care\nsettings.",
    "published": "2025-10-08T16:25:04Z",
    "updated": "2025-10-08T16:25:04Z",
    "link": "http://arxiv.org/pdf/2510.07191v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Soroosh Tayebi Arasteh",
      "Mina Shaigan",
      "Christiane Kuhl",
      "Jakob Nikolas Kather",
      "Sven Nebelung",
      "Daniel Truhn"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.03122v2",
    "title": "From Injection to Defense: Constructing Edit-Based Fingerprints for\n  Large Language Models",
    "summary": "Fingerprinting is critical for maintaining traceability and protecting the\nintellectual property (IP) of developers, as LLMs deployed in web applications\nare susceptible to unauthorized redistribution and misuse via fine-tuning or\nblack-box deployment. However, current backdoor-based fingerprinting methods\nface a fundamental trade-off: fingerprints embedded as garbled text are easily\ndetected and filtered, whereas those crafted as coherent natural language are\nprone to being triggered unintentionally. To overcome these limitations, we\npropose RFEdit, a knowledge-editing framework that embeds a rule-based\nmultilingual natural language fingerprint (MNLF) by modifying a sparse subset\nof model weights. This approach enables efficient and robust fingerprint\ninjection with minimal impact on unrelated knowledge in LLMs. Our RFEdit\nframework is further safeguarded by Fingerprint Subspace-aware Fine-Tuning\n(FSFT), which mitigates fingerprint degradation during legitimate fine-tuning\nby restricting parameter updates to the fingerprint subspace. This approach\npreserves fingerprint integrity while enhancing downstream task performance of\nLLMs. These advances establish a comprehensive pipeline from fingerprint\ninjection to defense, achieving high detection effectiveness, robustness\nagainst adversarial manipulations, harmlessness to model utility, and\npersistence under fine-tuning. Extensive experiments demonstrate that RFEdit\nmaintains robustness under quantization and pruning. Additionally, fingerprint\neffectiveness is generally improved by more than 10\\% when combined with FSFT\nfor math and alpaca downstream tasks.",
    "published": "2025-09-03T08:22:04Z",
    "updated": "2025-10-08T16:23:32Z",
    "link": "http://arxiv.org/pdf/2509.03122v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Yue Li",
      "Xin Yi",
      "Dongsheng Shi",
      "Yongyi Cui",
      "Gerard de Melo",
      "Linlin Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07181v1",
    "title": "TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for\n  Robotics",
    "summary": "Vision-Language Models (VLMs) have shown remarkable capabilities in spatial\nreasoning, yet they remain fundamentally limited to qualitative precision and\nlack the computational precision required for real-world robotics. Current\napproaches fail to leverage metric cues from depth sensors and camera\ncalibration, instead reducing geometric problems to pattern recognition tasks\nthat cannot deliver the centimeter-level accuracy essential for robotic\nmanipulation. We present TIGeR (Tool-Integrated Geometric Reasoning), a novel\nframework that transforms VLMs from perceptual estimators to geometric\ncomputers by enabling them to generate and execute precise geometric\ncomputations through external tools. Rather than attempting to internalize\ncomplex geometric operations within neural networks, TIGeR empowers models to\nrecognize geometric reasoning requirements, synthesize appropriate\ncomputational code, and invoke specialized libraries for exact calculations. To\nsupport this paradigm, we introduce TIGeR-300K, a comprehensive\ntool-invocation-oriented dataset covering point transformations, pose\nestimation, trajectory generation, and spatial compatibility verification,\ncomplete with tool invocation sequences and intermediate computations. Through\na two-stage training pipeline combining supervised fine-tuning (SFT) and\nreinforcement fine-tuning (RFT) with our proposed hierarchical reward design,\nTIGeR achieves SOTA performance on geometric reasoning benchmarks while\ndemonstrating centimeter-level precision in real-world robotic manipulation\ntasks.",
    "published": "2025-10-08T16:20:23Z",
    "updated": "2025-10-08T16:20:23Z",
    "link": "http://arxiv.org/pdf/2510.07181v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Yi Han",
      "Cheng Chi",
      "Enshen Zhou",
      "Shanyu Rong",
      "Jingkun An",
      "Pengwei Wang",
      "Zhongyuan Wang",
      "Lu Sheng",
      "Shanghang Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07172v1",
    "title": "NewtonBench: Benchmarking Generalizable Scientific Law Discovery in LLM\n  Agents",
    "summary": "Large language models are emerging as powerful tools for scientific law\ndiscovery, a foundational challenge in AI-driven science. However, existing\nbenchmarks for this task suffer from a fundamental methodological trilemma,\nforcing a trade-off between scientific relevance, scalability, and resistance\nto memorization. Furthermore, they oversimplify discovery as static function\nfitting, failing to capture the authentic scientific process of uncovering\nembedded laws through the interactive exploration of complex model systems. To\naddress these critical gaps, we introduce NewtonBench, a benchmark comprising\n324 scientific law discovery tasks across 12 physics domains. Our design\nmitigates the evaluation trilemma by using metaphysical shifts - systematic\nalterations of canonical laws - to generate a vast suite of problems that are\nscalable, scientifically relevant, and memorization-resistant. Moreover, we\nelevate the evaluation from static function fitting to interactive model\ndiscovery, requiring agents to experimentally probe simulated complex systems\nto uncover hidden principles. Our extensive experiment reveals a clear but\nfragile capability for discovery in frontier LLMs: this ability degrades\nprecipitously with increasing system complexity and exhibits extreme\nsensitivity to observational noise. Notably, we uncover a paradoxical effect of\ntool assistance: providing a code interpreter can hinder more capable models by\ninducing a premature shift from exploration to exploitation, causing them to\nsatisfice on suboptimal solutions. These results demonstrate that robust,\ngeneralizable discovery in complex, interactive environments remains the core\nchallenge. By providing a scalable, robust, and scientifically authentic\ntestbed, NewtonBench offers a crucial tool for measuring true progress and\nguiding the development of next-generation AI agents capable of genuine\nscientific discovery.",
    "published": "2025-10-08T16:12:11Z",
    "updated": "2025-10-08T16:12:11Z",
    "link": "http://arxiv.org/pdf/2510.07172v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Tianshi Zheng",
      "Kelvin Kiu-Wai Tam",
      "Newt Hue-Nam K. Nguyen",
      "Baixuan Xu",
      "Zhaowei Wang",
      "Jiayang Cheng",
      "Hong Ting Tsang",
      "Weiqi Wang",
      "Jiaxin Bai",
      "Tianqing Fang",
      "Yangqiu Song",
      "Ginny Y. Wong",
      "Simon See"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.25775v3",
    "title": "Autonomy-Aware Clustering: When Local Decisions Supersede Global\n  Prescriptions",
    "summary": "Clustering arises in a wide range of problem formulations, yet most existing\napproaches assume that the entities under clustering are passive and strictly\nconform to their assigned groups. In reality, entities often exhibit local\nautonomy, overriding prescribed associations in ways not fully captured by\nfeature representations. Such autonomy can substantially reshape clustering\noutcomes -- altering cluster compositions, geometry, and cardinality -- with\nsignificant downstream effects on inference and decision-making. We introduce\nautonomy-aware clustering, a reinforcement learning (RL) framework that learns\nand accounts for the influence of local autonomy without requiring prior\nknowledge of its form. Our approach integrates RL with a Deterministic\nAnnealing (DA) procedure, where, to determine underlying clusters, DA naturally\npromotes exploration in early stages of annealing and transitions to\nexploitation later. We also show that the annealing procedure exhibits phase\ntransitions that enable design of efficient annealing schedules. To further\nenhance adaptability, we propose the Adaptive Distance Estimation Network\n(ADEN), a transformer-based attention model that learns dependencies between\nentities and cluster representatives within the RL loop, accommodates\nvariable-sized inputs and outputs, and enables knowledge transfer across\ndiverse problem instances. Empirical results show that our framework closely\naligns with underlying data dynamics: even without explicit autonomy models, it\nachieves solutions close to the ground truth (gap ~3-4%), whereas ignoring\nautonomy leads to substantially larger gaps (~35-40%). The code and data are\npublicly available at https://github.com/salar96/AutonomyAwareClustering.",
    "published": "2025-09-30T04:44:36Z",
    "updated": "2025-10-08T16:05:52Z",
    "link": "http://arxiv.org/pdf/2509.25775v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Amber Srivastava",
      "Salar Basiri",
      "Srinivasa Salapaka"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.16082v4",
    "title": "On Task Vectors and Gradients",
    "summary": "Task arithmetic has emerged as a simple yet powerful technique for model\nmerging, enabling the combination of multiple finetuned models into one.\nDespite its empirical success, a clear theoretical explanation of why and when\nit works is lacking. This paper provides a rigorous theoretical foundation for\ntask arithmetic by establishing a connection between task vectors and gradients\nof the task losses. We show that under standard gradient descent, a task vector\ngenerated from one epoch of finetuning is exactly equivalent to the negative\ngradient of the loss, scaled by the learning rate. For the practical\nmulti-epoch setting, we prove that this equivalence holds approximately, with a\nsecond-order error term that we explicitly bound for feed-forward networks. Our\nempirical analysis across seven vision benchmarks corroborates our theory,\ndemonstrating that the first-epoch gradient dominates the finetuning trajectory\nin both norm and direction. A key implication is that merging models finetuned\nfor only a single epoch often yields performance comparable to merging fully\nconverged models. These findings reframe task arithmetic as a form of\napproximate multitask learning, providing a clear rationale for its\neffectiveness and highlighting the critical role of early training dynamics in\nmodel merging.",
    "published": "2025-08-22T04:16:42Z",
    "updated": "2025-10-08T16:00:50Z",
    "link": "http://arxiv.org/pdf/2508.16082v4.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Luca Zhou",
      "Daniele Solombrino",
      "Donato Crisostomi",
      "Maria Sofia Bucarelli",
      "Giuseppe Alessio D'Inverno",
      "Fabrizio Silvestri",
      "Emanuele Rodolà"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07161v1",
    "title": "Integrating Domain Knowledge into Process Discovery Using Large Language\n  Models",
    "summary": "Process discovery aims to derive process models from event logs, providing\ninsights into operational behavior and forming a foundation for conformance\nchecking and process improvement. However, models derived solely from event\ndata may not accurately reflect the real process, as event logs are often\nincomplete or affected by noise, and domain knowledge, an important\ncomplementary resource, is typically disregarded. As a result, the discovered\nmodels may lack reliability for downstream tasks. We propose an interactive\nframework that incorporates domain knowledge, expressed in natural language,\ninto the process discovery pipeline using Large Language Models (LLMs). Our\napproach leverages LLMs to extract declarative rules from textual descriptions\nprovided by domain experts. These rules are used to guide the IMr discovery\nalgorithm, which recursively constructs process models by combining insights\nfrom both the event log and the extracted rules, helping to avoid problematic\nprocess structures that contradict domain knowledge. The framework coordinates\ninteractions among the LLM, domain experts, and a set of backend services. We\npresent a fully implemented tool that supports this workflow and conduct an\nextensive evaluation of multiple LLMs and prompt engineering strategies. Our\nempirical study includes a case study based on a real-life event log with the\ninvolvement of domain experts, who assessed the usability and effectiveness of\nthe framework.",
    "published": "2025-10-08T15:59:11Z",
    "updated": "2025-10-08T15:59:11Z",
    "link": "http://arxiv.org/pdf/2510.07161v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Ali Norouzifar",
      "Humam Kourani",
      "Marcus Dees",
      "Wil van der Aalst"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07151v1",
    "title": "ELMUR: External Layer Memory with Update/Rewrite for Long-Horizon RL",
    "summary": "Real-world robotic agents must act under partial observability and long\nhorizons, where key cues may appear long before they affect decision making.\nHowever, most modern approaches rely solely on instantaneous information,\nwithout incorporating insights from the past. Standard recurrent or transformer\nmodels struggle with retaining and leveraging long-term dependencies: context\nwindows truncate history, while naive memory extensions fail under scale and\nsparsity. We propose ELMUR (External Layer Memory with Update/Rewrite), a\ntransformer architecture with structured external memory. Each layer maintains\nmemory embeddings, interacts with them via bidirectional cross-attention, and\nupdates them through an Least Recently Used (LRU) memory module using\nreplacement or convex blending. ELMUR extends effective horizons up to 100,000\ntimes beyond the attention window and achieves a 100% success rate on a\nsynthetic T-Maze task with corridors up to one million steps. In POPGym, it\noutperforms baselines on more than half of the tasks. On MIKASA-Robo\nsparse-reward manipulation tasks with visual observations, it nearly doubles\nthe performance of strong baselines. These results demonstrate that structured,\nlayer-local external memory offers a simple and scalable approach to decision\nmaking under partial observability.",
    "published": "2025-10-08T15:50:34Z",
    "updated": "2025-10-08T15:50:34Z",
    "link": "http://arxiv.org/pdf/2510.07151v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "authors": [
      "Egor Cherepanov",
      "Alexey K. Kovalev",
      "Aleksandr I. Panov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07147v1",
    "title": "A Multi-Agent Framework for Stateful Inference-Time Search",
    "summary": "Recent work explores agentic inference-time techniques to perform structured,\nmulti-step reasoning. However, stateless inference often struggles on\nmulti-step tasks due to the absence of persistent state. Moreover,\ntask-specific fine-tuning or instruction-tuning often achieve surface-level\ncode generation but remain brittle on tasks requiring deeper reasoning and\nlong-horizon dependencies. To address these limitations, we propose stateful\nmulti-agent evolutionary search, a training-free framework that departs from\nprior stateless approaches by combining (i) persistent inference-time state,\n(ii) adversarial mutation, and (iii) evolutionary preservation. We demonstrate\nits effectiveness in automated unit test generation through the generation of\nedge cases. We generate robust edge cases using an evolutionary search process,\nwhere specialized agents sequentially propose, mutate, and score candidates. A\ncontroller maintains persistent state across generations, while evolutionary\npreservation ensures diversity and exploration across all possible cases. This\nyields a generalist agent capable of discovering robust, high-coverage edge\ncases across unseen codebases. Experiments show our stateful multi-agent\ninference framework achieves substantial gains in coverage over stateless\nsingle-step baselines, evaluated on prevalent unit-testing benchmarks such as\nHumanEval and TestGenEvalMini and using three diverse LLM families - Llama,\nGemma, and GPT. These results indicate that combining persistent inference-time\nstate with evolutionary search materially improves unit-test generation.",
    "published": "2025-10-08T15:48:41Z",
    "updated": "2025-10-08T15:48:41Z",
    "link": "http://arxiv.org/pdf/2510.07147v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.MA",
      "cs.SE"
    ],
    "authors": [
      "Arshika Lalan",
      "Rajat Ghosh",
      "Aditya Kolsur",
      "Debojyoti Dutta"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.09278v3",
    "title": "Towards a Multimodal Large Language Model with Pixel-Level Insight for\n  Biomedicine",
    "summary": "In recent years, Multimodal Large Language Models (MLLM) have achieved\nnotable advancements, demonstrating the feasibility of developing an\nintelligent biomedical assistant. However, current biomedical MLLMs\npredominantly focus on image-level understanding and restrict interactions to\ntextual commands, thus limiting their capability boundaries and the flexibility\nof usage. In this paper, we introduce a novel end-to-end multimodal large\nlanguage model for the biomedical domain, named MedPLIB, which possesses\npixel-level understanding. Excitingly, it supports visual question answering\n(VQA), arbitrary pixel-level prompts (points, bounding boxes, and free-form\nshapes), and pixel-level grounding. We propose a novel Mixture-of-Experts (MoE)\nmulti-stage training strategy, which divides MoE into separate training phases\nfor a visual-language expert model and a pixel-grounding expert model, followed\nby fine-tuning using MoE. This strategy effectively coordinates multitask\nlearning while maintaining the computational cost at inference equivalent to\nthat of a single expert model. To advance the research of biomedical MLLMs, we\nintroduce the Medical Complex Vision Question Answering Dataset (MeCoVQA),\nwhich comprises an array of 8 modalities for complex medical imaging question\nanswering and image region understanding. Experimental results indicate that\nMedPLIB has achieved state-of-the-art outcomes across multiple medical visual\nlanguage tasks. More importantly, in zero-shot evaluations for the pixel\ngrounding task, MedPLIB leads the best small and large models by margins of\n19.7 and 15.6 respectively on the mDice metric. The codes, data, and model\ncheckpoints will be made publicly available at\nhttps://github.com/ShawnHuang497/MedPLIB.",
    "published": "2024-12-12T13:41:35Z",
    "updated": "2025-10-08T15:47:39Z",
    "link": "http://arxiv.org/pdf/2412.09278v3.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Xiaoshuang Huang",
      "Lingdong Shen",
      "Jia Liu",
      "Fangxin Shang",
      "Hongxiang Li",
      "Haifeng Huang",
      "Yehui Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07141v1",
    "title": "Comparing human and language models sentence processing difficulties on\n  complex structures",
    "summary": "Large language models (LLMs) that fluently converse with humans are a reality\n- but do LLMs experience human-like processing difficulties? We systematically\ncompare human and LLM sentence comprehension across seven challenging\nlinguistic structures. We collect sentence comprehension data from humans and\nfive families of state-of-the-art LLMs, varying in size and training procedure\nin a unified experimental framework. Our results show LLMs overall struggle on\nthe target structures, but especially on garden path (GP) sentences. Indeed,\nwhile the strongest models achieve near perfect accuracy on non-GP structures\n(93.7% for GPT-5), they struggle on GP structures (46.8% for GPT-5).\nAdditionally, when ranking structures based on average performance, rank\ncorrelation between humans and models increases with parameter count. For each\ntarget structure, we also collect data for their matched baseline without the\ndifficult structure. Comparing performance on the target vs. baseline\nsentences, the performance gap observed in humans holds for LLMs, with two\nexceptions: for models that are too weak performance is uniformly low across\nboth sentence types, and for models that are too strong the performance is\nuniformly high. Together, these reveal convergence and divergence in human and\nLLM sentence comprehension, offering new insights into the similarity of humans\nand LLMs.",
    "published": "2025-10-08T15:42:49Z",
    "updated": "2025-10-08T15:42:49Z",
    "link": "http://arxiv.org/pdf/2510.07141v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Samuel Joseph Amouyal",
      "Aya Meltzer-Asscher",
      "Jonathan Berant"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.17967v4",
    "title": "FFT-based Dynamic Subspace Selection for Low-Rank Adaptive Optimization\n  of Large Language Models",
    "summary": "Low-rank optimization has emerged as a promising direction in training large\nlanguage models (LLMs) to improve running time and reduce the memory usage of\nadaptive optimizers by constraining learning to a lower-dimensional space.\nPrior work typically projects gradients of linear layers using approaches based\non Singular Value Decomposition (SVD) or QR-decomposition. Applying these\ntechniques individually to each layer in large models is computationally\nexpensive and incurs additional memory costs due to storing the projection\nmatrices. In this work, we propose a computationally efficient and conceptually\nsimple, two-step procedure to approximate SVD/QR-based gradient projections\ninto lower-dimensional spaces by using a predefined orthogonal matrix of the\nDiscrete Cosine Transform (DCT). We dynamically select columns from the DCT\nmatrix based on their alignment with the gradient of each layer. The effective\nprojection matrices are obtained via a simple matmul with the DCT matrix in\n$O(n^3)$ time, followed by a lightweight sorting step to identify the most\nrelevant basis vectors. For large layers, DCT can be computed via Makhoul's\n$N$-point algorithm based on Fast Fourier Transform (FFT) in $O(n^2 \\log(n))$\ntime. Due to the predefined nature of the orthogonal bases, they are computed\nonce at the start of training. Our numerical experiments on both pre-training\nand fine-tuning tasks demonstrate the effectiveness of our dual strategy in\napproximating optimal low-rank projections, obtaining an approach with\nrank-independent running time that matches the performance of costly\nSVD/QR-based methods while achieving faster runtime and reduced memory usage by\nup to $25\\%$ across different model sizes. Our code is available at\n\\href{https://github.com/IST-DASLab/ISTA-DASLab-Optimizers}{\\texttt{https://github.com/IST-DASLab/ISTA-DASLab-Optimizers}}.",
    "published": "2025-05-23T14:37:00Z",
    "updated": "2025-10-08T15:33:25Z",
    "link": "http://arxiv.org/pdf/2505.17967v4.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Ionut-Vlad Modoranu",
      "Mher Safaryan",
      "Erik Schultheis",
      "Max Ryabinin",
      "Artem Chumachenko",
      "Dan Alistarh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07134v1",
    "title": "TrackVLA++: Unleashing Reasoning and Memory Capabilities in VLA Models\n  for Embodied Visual Tracking",
    "summary": "Embodied Visual Tracking (EVT) is a fundamental ability that underpins\npractical applications, such as companion robots, guidance robots and service\nassistants, where continuously following moving targets is essential. Recent\nadvances have enabled language-guided tracking in complex and unstructured\nscenes. However, existing approaches lack explicit spatial reasoning and\neffective temporal memory, causing failures under severe occlusions or in the\npresence of similar-looking distractors. To address these challenges, we\npresent TrackVLA++, a novel Vision-Language-Action (VLA) model that enhances\nembodied visual tracking with two key modules, a spatial reasoning mechanism\nand a Target Identification Memory (TIM). The reasoning module introduces a\nChain-of-Thought paradigm, termed Polar-CoT, which infers the target's relative\nposition and encodes it as a compact polar-coordinate token for action\nprediction. Guided by these spatial priors, the TIM employs a gated update\nstrategy to preserve long-horizon target memory, ensuring spatiotemporal\nconsistency and mitigating target loss during extended occlusions. Extensive\nexperiments show that TrackVLA++ achieves state-of-the-art performance on\npublic benchmarks across both egocentric and multi-camera settings. On the\nchallenging EVT-Bench DT split, TrackVLA++ surpasses the previous leading\napproach by 5.1 and 12, respectively. Furthermore, TrackVLA++ exhibits strong\nzero-shot generalization, enabling robust real-world tracking in dynamic and\noccluded scenarios.",
    "published": "2025-10-08T15:29:17Z",
    "updated": "2025-10-08T15:29:17Z",
    "link": "http://arxiv.org/pdf/2510.07134v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Jiahang Liu",
      "Yunpeng Qi",
      "Jiazhao Zhang",
      "Minghan Li",
      "Shaoan Wang",
      "Kui Wu",
      "Hanjing Ye",
      "Hong Zhang",
      "Zhibo Chen",
      "Fangwei Zhong",
      "Zhizheng Zhang",
      "He Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07133v1",
    "title": "A Digital Twin Framework for Metamorphic Testing of Autonomous Driving\n  Systems Using Generative Model",
    "summary": "Ensuring the safety of self-driving cars remains a major challenge due to the\ncomplexity and unpredictability of real-world driving environments. Traditional\ntesting methods face significant limitations, such as the oracle problem, which\nmakes it difficult to determine whether a system's behavior is correct, and the\ninability to cover the full range of scenarios an autonomous vehicle may\nencounter. In this paper, we introduce a digital twin-driven metamorphic\ntesting framework that addresses these challenges by creating a virtual replica\nof the self-driving system and its operating environment. By combining digital\ntwin technology with AI-based image generative models such as Stable Diffusion,\nour approach enables the systematic generation of realistic and diverse driving\nscenes. This includes variations in weather, road topology, and environmental\nfeatures, all while maintaining the core semantics of the original scenario.\nThe digital twin provides a synchronized simulation environment where changes\ncan be tested in a controlled and repeatable manner. Within this environment,\nwe define three metamorphic relations inspired by real-world traffic rules and\nvehicle behavior. We validate our framework in the Udacity self-driving\nsimulator and demonstrate that it significantly enhances test coverage and\neffectiveness. Our method achieves the highest true positive rate (0.719), F1\nscore (0.689), and precision (0.662) compared to baseline approaches. This\npaper highlights the value of integrating digital twins with AI-powered\nscenario generation to create a scalable, automated, and high-fidelity testing\nsolution for autonomous vehicle safety.",
    "published": "2025-10-08T15:27:39Z",
    "updated": "2025-10-08T15:27:39Z",
    "link": "http://arxiv.org/pdf/2510.07133v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Tony Zhang",
      "Burak Kantarci",
      "Umair Siddique"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07129v1",
    "title": "Graph Conditioned Diffusion for Controllable Histopathology Image\n  Generation",
    "summary": "Recent advances in Diffusion Probabilistic Models (DPMs) have set new\nstandards in high-quality image synthesis. Yet, controlled generation remains\nchallenging, particularly in sensitive areas such as medical imaging. Medical\nimages feature inherent structure such as consistent spatial arrangement, shape\nor texture, all of which are critical for diagnosis. However, existing DPMs\noperate in noisy latent spaces that lack semantic structure and strong priors,\nmaking it difficult to ensure meaningful control over generated content. To\naddress this, we propose graph-based object-level representations for\nGraph-Conditioned-Diffusion. Our approach generates graph nodes corresponding\nto each major structure in the image, encapsulating their individual features\nand relationships. These graph representations are processed by a transformer\nmodule and integrated into a diffusion model via the text-conditioning\nmechanism, enabling fine-grained control over generation. We evaluate this\napproach using a real-world histopathology use case, demonstrating that our\ngenerated data can reliably substitute for annotated patient data in downstream\nsegmentation tasks. The code is available here.",
    "published": "2025-10-08T15:26:08Z",
    "updated": "2025-10-08T15:26:08Z",
    "link": "http://arxiv.org/pdf/2510.07129v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Sarah Cechnicka",
      "Matthew Baugh",
      "Weitong Zhang",
      "Mischa Dombrowski",
      "Zhe Li",
      "Johannes C. Paetzold",
      "Candice Roufosse",
      "Bernhard Kainz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.25373v3",
    "title": "From Perception to Cognition: A Survey of Vision-Language Interactive\n  Reasoning in Multimodal Large Language Models",
    "summary": "Multimodal Large Language Models (MLLMs) strive to achieve a profound,\nhuman-like understanding of and interaction with the physical world, but often\nexhibit a shallow and incoherent integration when acquiring information\n(Perception) and conducting reasoning (Cognition). This disconnect leads to a\nspectrum of reasoning failures, with hallucination being the most prominent.\nCollectively, these issues expose a fundamental challenge: the ability to\nprocess pixels does not yet confer the ability to construct a coherent,\ncredible internal world model. To systematically dissect and address this\nchallenge, this survey introduces a novel and unified analytical framework:\n``From Perception to Cognition.\" We deconstruct the complex process of\nvision-language interactive understanding into two interdependent layers:\nPerception, the foundational ability to accurately extract visual information\nand achieve fine-grained alignment with textual instructions; and Cognition,\nthe higher-order capability for proactive, multi-step, goal-oriented reasoning\nbuilt upon this perceptual foundation, the core of which is the formation of a\ndynamic observe-think-verify reasoning loop. Guided by this framework, this\npaper systematically analyzes the key bottlenecks of current MLLMs at both\nlayers. It surveys the landscape of cutting-edge methods designed to address\nthese challenges, spanning from techniques that enhance low-level visual\nrepresentations to those that improve high-level reasoning paradigms.\nFurthermore, we review critical benchmarks and delineate future research\ndirections. This survey aims to provide the research community with a clear,\nstructured perspective for understanding the intrinsic limitations of current\nMLLMs and to illuminate the path toward building next-generation models capable\nof deep reasoning and a genuine understanding of the world.",
    "published": "2025-09-29T18:25:40Z",
    "updated": "2025-10-08T15:20:30Z",
    "link": "http://arxiv.org/pdf/2509.25373v3.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Chenyue Zhou",
      "Mingxuan Wang",
      "Yanbiao Ma",
      "Chenxu Wu",
      "Wanyi Chen",
      "Zhe Qian",
      "Xinyu Liu",
      "Yiwei Zhang",
      "Junhao Wang",
      "Hengbo Xu",
      "Fei Luo",
      "Xiaohua Chen",
      "Xiaoshuai Hao",
      "Hehan Li",
      "Andi Zhang",
      "Wenxuan Wang",
      "Lingling Li",
      "Zhiwu Lu",
      "Yang Lu",
      "Yike Guo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.05306v2",
    "title": "Enjoying Non-linearity in Multinomial Logistic Bandits",
    "summary": "We consider the multinomial logistic bandit problem, a variant of where a\nlearner interacts with an environment by selecting actions to maximize expected\nrewards based on probabilistic feedback from multiple possible outcomes. In the\nbinary setting, recent work has focused on understanding the impact of the\nnon-linearity of the logistic model (Faury et al., 2020; Abeille et al., 2021).\nThey introduced a problem-dependent constant $\\kappa_* \\geq 1$, that may be\nexponentially large in some problem parameters and which is captured by the\nderivative of the sigmoid function. It encapsulates the non-linearity and\nimproves existing regret guarantees over $T$ rounds from $\\smash{O(d\\sqrt{T})}$\nto $\\smash{O(d\\sqrt{T/\\kappa_*})}$, where $d$ is the dimension of the parameter\nspace. We extend their analysis to the multinomial logistic bandit framework,\nmaking it suitable for complex applications with more than two choices, such as\nreinforcement learning or recommender systems. To achieve this, we extend the\ndefinition of \\( \\kappa_* \\) to the multinomial setting and propose an\nefficient algorithm that leverages the problem's non-linearity. Our method\nyields a problem-dependent regret bound of order $\n\\smash{\\widetilde{\\mathcal{O}}( R d \\sqrt{{KT}/{\\kappa_*}})} $, where $R$ is\nthe norm of the vector of rewards and $K$ is the number of outcomes. This\nimproves upon the best existing guarantees of order $\n\\smash{\\widetilde{\\mathcal{O}}( RdK \\sqrt{T} )} $. Moreover, we provide a\n$\\smash{ \\Omega(Rd\\sqrt{KT/\\kappa_*})}$ lower-bound, showing that our algorithm\nis minimax-optimal and that our definition of $\\kappa_*$ is optimal.",
    "published": "2025-07-07T08:18:25Z",
    "updated": "2025-10-08T15:15:45Z",
    "link": "http://arxiv.org/pdf/2507.05306v2.pdf",
    "category": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "authors": [
      "Pierre Boudart",
      "Pierre Gaillard",
      "Alessandro Rudi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.04174v2",
    "title": "Quasi-Clique Discovery via Energy Diffusion",
    "summary": "Discovering quasi-cliques -- subgraphs whose edge density exceeds a given\nthreshold -- is a fundamental task in graph mining with applications to web\nspam detection, fraud screening, and e-commerce recommendation. However,\nexisting methods for quasi-clique discovery on large-scale web graphs are often\nsensitive to random seeds or lack of explicit edge-density guarantees, making\nthe task challenging in practice. This paper presents EDQC, an energy\ndiffusion-based method for quasi-clique discovery. EDQC first employs an\nadaptive energy diffusion process to generate an energy ranking that highlights\nstructurally cohesive regions. Guided by this energy ranking, the algorithm\nidentifies a high-quality subgraph by minimizing conductance, a standard\nmeasure from community detection. This subgraph is then refined to meet the\nspecified density threshold. Extensive experiments on 75 real-world graphs show\nthat EDQC finds larger quasi-cliques on most datasets, with consistently lower\nvariance across runs and competitive runtime. To the best of our knowledge,\nEDQC is the first method to incorporate energy diffusion into quasi-clique\ndiscovery.",
    "published": "2025-08-06T07:59:56Z",
    "updated": "2025-10-08T15:12:22Z",
    "link": "http://arxiv.org/pdf/2508.04174v2.pdf",
    "category": [
      "cs.SI",
      "cs.AI"
    ],
    "authors": [
      "Yu Zhang",
      "Yilong Luo",
      "Mingyuan Ma",
      "Yao Chen",
      "Enqiang Zhu",
      "Jin Xu",
      "Chanjuan Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07117v1",
    "title": "The Contingencies of Physical Embodiment Allow for Open-Endedness and\n  Care",
    "summary": "Physical vulnerability and mortality are often seen as obstacles to be\navoided in the development of artificial agents, which struggle to adapt to\nopen-ended environments and provide aligned care. Meanwhile, biological\norganisms survive, thrive, and care for each other in an open-ended physical\nworld with relative ease and efficiency. Understanding the role of the\nconditions of life in this disparity can aid in developing more robust,\nadaptive, and caring artificial agents. Here we define two minimal conditions\nfor physical embodiment inspired by the existentialist phenomenology of Martin\nHeidegger: being-in-the-world (the agent is a part of the environment) and\nbeing-towards-death (unless counteracted, the agent drifts toward terminal\nstates due to the second law of thermodynamics). We propose that from these\nconditions we can obtain both a homeostatic drive - aimed at maintaining\nintegrity and avoiding death by expending energy to learn and act - and an\nintrinsic drive to continue to do so in as many ways as possible. Drawing\ninspiration from Friedrich Nietzsche's existentialist concept of will-to-power,\nwe examine how intrinsic drives to maximize control over future states, e.g.,\nempowerment, allow agents to increase the probability that they will be able to\nmeet their future homeostatic needs, thereby enhancing their capacity to\nmaintain physical integrity. We formalize these concepts within a reinforcement\nlearning framework, which enables us to examine how intrinsically driven\nembodied agents learning in open-ended multi-agent environments may cultivate\nthe capacities for open-endedness and care.ov",
    "published": "2025-10-08T15:10:26Z",
    "updated": "2025-10-08T15:10:26Z",
    "link": "http://arxiv.org/pdf/2510.07117v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Leonardo Christov-Moore",
      "Arthur Juliani",
      "Alex Kiefer",
      "Nicco Reggente",
      "B. Scott Rousse",
      "Adam Safron",
      "Nicol'as Hinrichs",
      "Daniel Polani",
      "Antonio Damasio"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.10309v2",
    "title": "Empirically evaluating commonsense intelligence in large language models\n  with large-scale human judgments",
    "summary": "Commonsense intelligence in machines is often assessed by static benchmarks\nthat compare a model's output against human-prescribed correct labels. An\nimportant, albeit implicit, assumption of these labels is that they accurately\ncapture what any human would think, effectively treating human common sense as\nhomogeneous. However, recent empirical work has shown that humans vary\nenormously in what they consider commonsensical; thus what appears self-evident\nto one benchmark designer may not be so to another. Here, we propose a method\nfor evaluating common sense in artificial intelligence (AI), specifically in\nlarge language models (LLMs), that incorporates empirically observed\nheterogeneity among humans by measuring the correspondence between a model's\njudgment and that of a human population. We first find that, when treated as\nindependent survey respondents, most LLMs remain below the human median in\ntheir individual commonsense competence. Second, when used as simulators of a\nhypothetical population, LLMs correlate with real humans only modestly in the\nextent to which they agree on the same set of statements. In both cases,\nsmaller, open-weight models are surprisingly more competitive than larger,\nproprietary frontier models. Our evaluation framework, which ties commonsense\nintelligence to its cultural basis, contributes to the growing call for\nadapting AI models to human collectivities that possess different, often\nincompatible, social stocks of knowledge.",
    "published": "2025-05-15T13:55:27Z",
    "updated": "2025-10-08T15:08:08Z",
    "link": "http://arxiv.org/pdf/2505.10309v2.pdf",
    "category": [
      "cs.AI",
      "cs.HC",
      "cs.SI"
    ],
    "authors": [
      "Tuan Dung Nguyen",
      "Duncan J. Watts",
      "Mark E. Whiting"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07105v1",
    "title": "Opt-ICL at LeWiDi-2025: Maximizing In-Context Signal from Rater Examples\n  via Meta-Learning",
    "summary": "Many natural language processing (NLP) tasks involve subjectivity, ambiguity,\nor legitimate disagreement between annotators. In this paper, we outline our\nsystem for modeling human variation. Our system leverages language models'\n(LLMs) in-context learning abilities, along with a two-step meta-learning\ntraining procedure for 1) post-training on many datasets requiring in-context\nlearning and 2) specializing the model via in-context meta-learning to the\nparticular data distribution of interest. We also evaluate the performance of\nour system submission to the Learning With Disagreements (LeWiDi) competition,\nwhere it was the overall winner on both tasks. Additionally, we perform an\nablation study to measure the importance of each system component. We find that\nincluding rater examples in-context is crucial for our system's performance,\ndataset-specific fine-tuning is helpful on the larger datasets, post-training\non other in-context datasets is helpful on one of the competition datasets, and\nthat performance improves with model scale.",
    "published": "2025-10-08T14:59:24Z",
    "updated": "2025-10-08T14:59:24Z",
    "link": "http://arxiv.org/pdf/2510.07105v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Taylor Sorensen",
      "Yejin Choi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.02270v2",
    "title": "Sustainable Self-evolution Adversarial Training",
    "summary": "With the wide application of deep neural network models in various computer\nvision tasks, there has been a proliferation of adversarial example generation\nstrategies aimed at deeply exploring model security. However, existing\nadversarial training defense models, which rely on single or limited types of\nattacks under a one-time learning process, struggle to adapt to the dynamic and\nevolving nature of attack methods. Therefore, to achieve defense performance\nimprovements for models in long-term applications, we propose a novel\nSustainable Self-Evolution Adversarial Training (SSEAT) framework.\nSpecifically, we introduce a continual adversarial defense pipeline to realize\nlearning from various kinds of adversarial examples across multiple stages.\nAdditionally, to address the issue of model catastrophic forgetting caused by\ncontinual learning from ongoing novel attacks, we propose an adversarial data\nreplay module to better select more diverse and key relearning data.\nFurthermore, we design a consistency regularization strategy to encourage\ncurrent defense models to learn more from previously trained ones, guiding them\nto retain more past knowledge and maintain accuracy on clean samples. Extensive\nexperiments have been conducted to verify the efficacy of the proposed SSEAT\ndefense method, which demonstrates superior defense performance and\nclassification accuracy compared to competitors.Code is available at\nhttps://github.com/aup520/SSEAT",
    "published": "2024-12-03T08:41:11Z",
    "updated": "2025-10-08T14:52:23Z",
    "link": "http://arxiv.org/pdf/2412.02270v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Wenxuan Wang",
      "Chenglei Wang",
      "Huihui Qi",
      "Menghao Ye",
      "Xuelin Qian",
      "Peng Wang",
      "Yanning Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07092v1",
    "title": "Generative World Modelling for Humanoids: 1X World Model Challenge\n  Technical Report",
    "summary": "World models are a powerful paradigm in AI and robotics, enabling agents to\nreason about the future by predicting visual observations or compact latent\nstates. The 1X World Model Challenge introduces an open-source benchmark of\nreal-world humanoid interaction, with two complementary tracks: sampling,\nfocused on forecasting future image frames, and compression, focused on\npredicting future discrete latent codes. For the sampling track, we adapt the\nvideo generation foundation model Wan-2.2 TI2V-5B to video-state-conditioned\nfuture frame prediction. We condition the video generation on robot states\nusing AdaLN-Zero, and further post-train the model using LoRA. For the\ncompression track, we train a Spatio-Temporal Transformer model from scratch.\nOur models achieve 23.0 dB PSNR in the sampling task and a Top-500 CE of 6.6386\nin the compression task, securing 1st place in both challenges.",
    "published": "2025-10-08T14:49:12Z",
    "updated": "2025-10-08T14:49:12Z",
    "link": "http://arxiv.org/pdf/2510.07092v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "authors": [
      "Riccardo Mereu",
      "Aidan Scannell",
      "Yuxin Hou",
      "Yi Zhao",
      "Aditya Jitta",
      "Antonio Dominguez",
      "Luigi Acerbi",
      "Amos Storkey",
      "Paul Chang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07091v1",
    "title": "The Cognitive Bandwidth Bottleneck: Shifting Long-Horizon Agent from\n  Planning with Actions to Planning with Schemas",
    "summary": "Enabling LLMs to effectively operate long-horizon task which requires\nlong-term planning and multiple interactions is essential for open-world\nautonomy. Conventional methods adopt planning with actions where a executable\naction list would be provided as reference. However, this action representation\nchoice would be impractical when the environment action space is combinatorial\nexploded (e.g., open-ended real world). This naturally leads to a question: As\nenvironmental action space scales, what is the optimal action representation\nfor long-horizon agents? In this paper, we systematically study the\neffectiveness of two different action representations. The first one is\nconventional planning with actions (PwA) which is predominantly adopted for its\neffectiveness on existing benchmarks. The other one is planning with schemas\n(PwS) which instantiate an action schema into action lists (e.g., \"move [OBJ]\nto [OBJ]\" -> \"move apple to desk\") to ensure concise action space and reliable\nscalability. This alternative is motivated by its alignment with human\ncognition and its compliance with environment-imposed action format\nrestriction. We propose cognitive bandwidth perspective as a conceptual\nframework to qualitatively understand the differences between these two action\nrepresentations and empirically observe a representation-choice inflection\npoint between ALFWorld (~35 actions) and SciWorld (~500 actions), which serve\nas evidence of the need for scalable representations. We further conduct\ncontrolled experiments to study how the location of this inflection point\ninteracts with different model capacities: stronger planning proficiency shifts\nthe inflection rightward, whereas better schema instantiation shifts it\nleftward. Finally, noting the suboptimal performance of PwS agents, we provide\nan actionable guide for building more capable PwS agents for better scalable\nautonomy.",
    "published": "2025-10-08T14:47:40Z",
    "updated": "2025-10-08T14:47:40Z",
    "link": "http://arxiv.org/pdf/2510.07091v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Baixuan Xu",
      "Tianshi Zheng",
      "Zhaowei Wang",
      "Hong Ting Tsang",
      "Weiqi Wang",
      "Tianqing Fang",
      "Yangqiu Song"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07084v1",
    "title": "HTMformer: Hybrid Time and Multivariate Transformer for Time Series\n  Forecasting",
    "summary": "Transformer-based methods have achieved impressive results in time series\nforecasting. However, existing Transformers still exhibit limitations in\nsequence modeling as they tend to overemphasize temporal dependencies. This\nincurs additional computational overhead without yielding corresponding\nperformance gains. We find that the performance of Transformers is highly\ndependent on the embedding method used to learn effective representations. To\naddress this issue, we extract multivariate features to augment the effective\ninformation captured in the embedding layer, yielding multidimensional\nembeddings that convey richer and more meaningful sequence representations.\nThese representations enable Transformer-based forecasters to better understand\nthe series. Specifically, we introduce Hybrid Temporal and Multivariate\nEmbeddings (HTME). The HTME extractor integrates a lightweight temporal feature\nextraction module with a carefully designed multivariate feature extraction\nmodule to provide complementary features, thereby achieving a balance between\nmodel complexity and performance. By combining HTME with the Transformer\narchitecture, we present HTMformer, leveraging the enhanced feature extraction\ncapability of the HTME extractor to build a lightweight forecaster. Experiments\nconducted on eight real-world datasets demonstrate that our approach\noutperforms existing baselines in both accuracy and efficiency.",
    "published": "2025-10-08T14:40:42Z",
    "updated": "2025-10-08T14:40:42Z",
    "link": "http://arxiv.org/pdf/2510.07084v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Tan Wang",
      "Yun Wei Dong",
      "Tao Zhang",
      "Qi Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.05318v2",
    "title": "BIRD-INTERACT: Re-imagining Text-to-SQL Evaluation for Large Language\n  Models via Lens of Dynamic Interactions",
    "summary": "Large language models (LLMs) have demonstrated remarkable performance on\nsingle-turn text-to-SQL tasks, but real-world database applications\npredominantly require multi-turn interactions to handle ambiguous queries,\nexecution errors, and evolving user requirements. Existing multi-turn\nbenchmarks fall short by treating conversation histories as static context or\nlimiting evaluation to read-only operations, failing to reflect\nproduction-grade database assistant challenges. We introduce BIRD-INTERACT, a\nbenchmark that restores this realism through: (1) a comprehensive interaction\nenvironment coupling each database with a hierarchical knowledge base, metadata\nfiles, and a function-driven user simulator, enabling models to solicit\nclarifications, retrieve knowledge, and recover from errors without human\nsupervision; (2) two evaluation settings consisting of a pre-defined\nconversational protocol (c-Interact) and an open-ended agentic setting\n(a-Interact) where models autonomously decide when to query the user simulator\nor explore the environment; (3) a challenging task suite covering the full CRUD\nspectrum for business-intelligence and operational use cases, guarded by\nexecutable test cases. Each task features ambiguous and follow-up sub-tasks\nrequiring dynamic interaction. The suite comprises BIRD-INTERACT-FULL (600\ntasks, up to 11,796 interactions) for comprehensive performance assessment, and\nBIRD-INTERACT-LITE (300 tasks with simplified databases) for detailed\nbehavioral analysis and rapid method development. Our empirical results\nhighlight BIRD-INTERACT's difficulty: GPT-5 completes only 8.67% of tasks in\nc-Interact and 17.00% in a-Interact. Analysis via memory grafting and\nInteraction Test-time Scaling validates the importance of effective interaction\nfor complex, dynamic text-to-SQL tasks.",
    "published": "2025-10-06T19:31:47Z",
    "updated": "2025-10-08T14:39:59Z",
    "link": "http://arxiv.org/pdf/2510.05318v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Nan Huo",
      "Xiaohan Xu",
      "Jinyang Li",
      "Per Jacobsson",
      "Shipei Lin",
      "Bowen Qin",
      "Binyuan Hui",
      "Xiaolong Li",
      "Ge Qu",
      "Shuzheng Si",
      "Linheng Han",
      "Edward Alexander",
      "Xintong Zhu",
      "Rui Qin",
      "Ruihan Yu",
      "Yiyao Jin",
      "Feige Zhou",
      "Weihao Zhong",
      "Yun Chen",
      "Hongyu Liu",
      "Chenhao Ma",
      "Fatma Ozcan",
      "Yannis Papakonstantinou",
      "Reynold Cheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07077v1",
    "title": "Vision-Language-Action Models for Robotics: A Review Towards Real-World\n  Applications",
    "summary": "Amid growing efforts to leverage advances in large language models (LLMs) and\nvision-language models (VLMs) for robotics, Vision-Language-Action (VLA) models\nhave recently gained significant attention. By unifying vision, language, and\naction data at scale, which have traditionally been studied separately, VLA\nmodels aim to learn policies that generalise across diverse tasks, objects,\nembodiments, and environments. This generalisation capability is expected to\nenable robots to solve novel downstream tasks with minimal or no additional\ntask-specific data, facilitating more flexible and scalable real-world\ndeployment. Unlike previous surveys that focus narrowly on action\nrepresentations or high-level model architectures, this work offers a\ncomprehensive, full-stack review, integrating both software and hardware\ncomponents of VLA systems. In particular, this paper provides a systematic\nreview of VLAs, covering their strategy and architectural transition,\narchitectures and building blocks, modality-specific processing techniques, and\nlearning paradigms. In addition, to support the deployment of VLAs in\nreal-world robotic applications, we also review commonly used robot platforms,\ndata collection strategies, publicly available datasets, data augmentation\nmethods, and evaluation benchmarks. Throughout this comprehensive survey, this\npaper aims to offer practical guidance for the robotics community in applying\nVLAs to real-world robotic systems. All references categorized by training\napproach, evaluation method, modality, and dataset are available in the table\non our project website: https://vla-survey.github.io .",
    "published": "2025-10-08T14:38:25Z",
    "updated": "2025-10-08T14:38:25Z",
    "link": "http://arxiv.org/pdf/2510.07077v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Kento Kawaharazuka",
      "Jihoon Oh",
      "Jun Yamada",
      "Ingmar Posner",
      "Yuke Zhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07074v1",
    "title": "LuxInstruct: A Cross-Lingual Instruction Tuning Dataset For\n  Luxembourgish",
    "summary": "Instruction tuning has become a key technique for enhancing the performance\nof large language models, enabling them to better follow human prompts.\nHowever, low-resource languages such as Luxembourgish face severe limitations\ndue to the lack of high-quality instruction datasets. Traditional reliance on\nmachine translation often introduces semantic misalignment and cultural\ninaccuracies. In this work, we address these challenges by creating a\ncross-lingual instruction tuning dataset for Luxembourgish, without resorting\nto machine-generated translations into it. Instead, by leveraging aligned data\nfrom English, French, and German, we build a high-quality dataset that\npreserves linguistic and cultural nuances. We provide evidence that\ncross-lingual instruction tuning not only improves representational alignment\nacross languages but also the model's generative capabilities in Luxembourgish.\nThis highlights how cross-lingual data curation can avoid the common pitfalls\nof machine-translated data and directly benefit low-resource language\ndevelopment.",
    "published": "2025-10-08T14:35:59Z",
    "updated": "2025-10-08T14:35:59Z",
    "link": "http://arxiv.org/pdf/2510.07074v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Fred Philippy",
      "Laura Bernardy",
      "Siwen Guo",
      "Jacques Klein",
      "Tegawendé F. Bissyandé"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07073v1",
    "title": "VRPAgent: LLM-Driven Discovery of Heuristic Operators for Vehicle\n  Routing Problems",
    "summary": "Designing high-performing heuristics for vehicle routing problems (VRPs) is a\ncomplex task that requires both intuition and deep domain knowledge. Large\nlanguage model (LLM)-based code generation has recently shown promise across\nmany domains, but it still falls short of producing heuristics that rival those\ncrafted by human experts. In this paper, we propose VRPAgent, a framework that\nintegrates LLM-generated components into a metaheuristic and refines them\nthrough a novel genetic search. By using the LLM to generate problem-specific\noperators, embedded within a generic metaheuristic framework, VRPAgent keeps\ntasks manageable, guarantees correctness, and still enables the discovery of\nnovel and powerful strategies. Across multiple problems, including the\ncapacitated VRP, the VRP with time windows, and the prize-collecting VRP, our\nmethod discovers heuristic operators that outperform handcrafted methods and\nrecent learning-based approaches while requiring only a single CPU core. To our\nknowledge, \\VRPAgent is the first LLM-based paradigm to advance the\nstate-of-the-art in VRPs, highlighting a promising future for automated\nheuristics discovery.",
    "published": "2025-10-08T14:35:09Z",
    "updated": "2025-10-08T14:35:09Z",
    "link": "http://arxiv.org/pdf/2510.07073v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "André Hottung",
      "Federico Berto",
      "Chuanbo Hua",
      "Nayeli Gast Zepeda",
      "Daniel Wetzel",
      "Michael Römer",
      "Haoran Ye",
      "Davide Zago",
      "Michael Poli",
      "Stefano Massaroli",
      "Jinkyoo Park",
      "Kevin Tierney"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07069v1",
    "title": "Inductive Learning for Possibilistic Logic Programs Under Stable Models",
    "summary": "Possibilistic logic programs (poss-programs) under stable models are a major\nvariant of answer set programming (ASP). While its semantics (possibilistic\nstable models) and properties have been well investigated, the problem of\ninductive reasoning has not been investigated yet. This paper presents an\napproach to extracting poss-programs from a background program and examples\n(parts of intended possibilistic stable models). To this end, the notion of\ninduction tasks is first formally defined, its properties are investigated and\ntwo algorithms ilpsm and ilpsmmin for computing induction solutions are\npresented. An implementation of ilpsmmin is also provided and experimental\nresults show that when inputs are ordinary logic programs, the prototype\noutperforms a major inductive learning system for normal logic programs from\nstable models on the datasets that are randomly generated.",
    "published": "2025-10-08T14:32:10Z",
    "updated": "2025-10-08T14:32:10Z",
    "link": "http://arxiv.org/pdf/2510.07069v1.pdf",
    "category": [
      "cs.AI",
      "I.2.4"
    ],
    "authors": [
      "Hongbo Hu",
      "Yisong Wang",
      "Yi Huang",
      "Kewen Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07064v1",
    "title": "Prompt Optimization Across Multiple Agents for Representing Diverse\n  Human Populations",
    "summary": "The difficulty and expense of obtaining large-scale human responses make\nLarge Language Models (LLMs) an attractive alternative and a promising proxy\nfor human behavior. However, prior work shows that LLMs often produce\nhomogeneous outputs that fail to capture the rich diversity of human\nperspectives and behaviors. Thus, rather than trying to capture this diversity\nwith a single LLM agent, we propose a novel framework to construct a set of\nagents that collectively capture the diversity of a given human population.\nEach agent is an LLM whose behavior is steered by conditioning on a small set\nof human demonstrations (task-response pairs) through in-context learning. The\ncentral challenge is therefore to select a representative set of LLM agents\nfrom the exponentially large space of possible agents. We tackle this selection\nproblem from the lens of submodular optimization. In particular, we develop\nmethods that offer different trade-offs regarding time complexity and\nperformance guarantees. Extensive experiments in crowdsourcing and educational\ndomains demonstrate that our approach constructs agents that more effectively\nrepresent human populations compared to baselines. Moreover, behavioral\nanalyses on new tasks show that these agents reproduce the behavior patterns\nand perspectives of the students and annotators they are designed to represent.",
    "published": "2025-10-08T14:28:53Z",
    "updated": "2025-10-08T14:28:53Z",
    "link": "http://arxiv.org/pdf/2510.07064v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Manh Hung Nguyen",
      "Sebastian Tschiatschek",
      "Adish Singla"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07053v1",
    "title": "Introspection in Learned Semantic Scene Graph Localisation",
    "summary": "This work investigates how semantics influence localisation performance and\nrobustness in a learned self-supervised, contrastive semantic localisation\nframework. After training a localisation network on both original and perturbed\nmaps, we conduct a thorough post-hoc introspection analysis to probe whether\nthe model filters environmental noise and prioritises distinctive landmarks\nover routine clutter. We validate various interpretability methods and present\na comparative reliability analysis. Integrated gradients and Attention Weights\nconsistently emerge as the most reliable probes of learned behaviour. A\nsemantic class ablation further reveals an implicit weighting in which frequent\nobjects are often down-weighted. Overall, the results indicate that the model\nlearns noise-robust, semantically salient relations about place definition,\nthereby enabling explainable registration under challenging visual and\nstructural variations.",
    "published": "2025-10-08T14:21:45Z",
    "updated": "2025-10-08T14:21:45Z",
    "link": "http://arxiv.org/pdf/2510.07053v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.RO",
      "I.2.10; I.2.9; I.4.8; I.5.2; I.5.1"
    ],
    "authors": [
      "Manshika Charvi Bissessur",
      "Efimia Panagiotaki",
      "Daniele De Martini"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07048v1",
    "title": "Search-R3: Unifying Reasoning and Embedding Generation in Large Language\n  Models",
    "summary": "Despite their remarkable natural language understanding capabilities, Large\nLanguage Models (LLMs) have been underutilized for retrieval tasks. We present\nSearch-R3, a novel framework that addresses this limitation by adapting LLMs to\ngenerate search embeddings as a direct output of their reasoning process. Our\napproach exploits LLMs' chain-of-thought capabilities, allowing them to produce\nmore effective embeddings by reasoning step-by-step through complex semantic\nanalyses. We implement this through three complementary mechanisms. (1) a\nsupervised learning stage enables the model's ability to produce quality\nembeddings, (2) a reinforcement learning (RL) methodology that optimizes\nembedding generation alongside reasoning, and (3) a specialized RL environment\nthat efficiently handles evolving embedding representations without requiring\ncomplete corpus re-encoding at each training iteration. Our extensive\nevaluations on diverse benchmarks demonstrate that Search-R3 significantly\noutperforms prior methods by unifying the reasoning and embedding generation\nprocesses. This integrated post-training approach represents a substantial\nadvancement in handling complex knowledge-intensive tasks that require both\nsophisticated reasoning and effective information retrieval. Project page:\nhttps://github.com/ytgui/Search-R3",
    "published": "2025-10-08T14:16:20Z",
    "updated": "2025-10-08T14:16:20Z",
    "link": "http://arxiv.org/pdf/2510.07048v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "authors": [
      "Yuntao Gui",
      "James Cheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.01845v2",
    "title": "Community-Centered Spatial Intelligence for Climate Adaptation at Nova\n  Scotia's Eastern Shore",
    "summary": "This paper presents an overview of a human-centered initiative aimed at\nstrengthening climate resilience along Nova Scotia's Eastern Shore. This\nregion, a collection of rural villages with deep ties to the sea, faces\nexistential threats from climate change that endanger its way of life. Our\nproject moves beyond a purely technical response, weaving together expertise\nfrom Computer Science, Industrial Engineering, and Coastal Geography to\nco-create tools with the community. By integrating generational knowledge of\nresidents, particularly elders, through the Eastern Shore Citizen Science\nCoastal Monitoring Network, this project aims to collaborate in building a\nliving digital archive. This effort is hosted under Dalhousie University's\nTransforming Climate Action (TCA) initiative, specifically through its\nTransformative Adaptations to Social-Ecological Climate Change Trajectories\n(TranSECT) and TCA Artificial Intelligence (TCA-AI) projects. This work is\ndriven by a collaboration model in which student teams work directly with\nresidents. We present a detailed project timeline and a replicable model for\nhow technology can support traditional communities, enabling them to navigate\nclimate transformation more effectively.",
    "published": "2025-09-02T00:06:17Z",
    "updated": "2025-10-08T14:10:18Z",
    "link": "http://arxiv.org/pdf/2509.01845v2.pdf",
    "category": [
      "cs.HC",
      "cs.AI"
    ],
    "authors": [
      "Gabriel Spadon",
      "Oladapo Oyebode",
      "Camilo M. Botero",
      "Tushar Sharma",
      "Floris Goerlandt",
      "Ronald Pelot"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.12576v2",
    "title": "AdaDim: Dimensionality Adaptation for SSL Representational Dynamics",
    "summary": "A key factor in effective Self-Supervised learning (SSL) is preventing\ndimensional collapse, where higher-dimensional representation spaces ($R$) span\na lower-dimensional subspace. Therefore, SSL optimization strategies involve\nguiding a model to produce $R$ with a higher dimensionality ($H(R)$) through\nobjectives that encourage decorrelation of features or sample uniformity in\n$R$. A higher $H(R)$ indicates that $R$ has greater feature diversity which is\nuseful for generalization to downstream tasks. Alongside dimensionality\noptimization, SSL algorithms also utilize a projection head that maps $R$ into\nan embedding space $Z$. Recent work has characterized the projection head as a\nfilter of noisy or irrelevant features from the SSL objective by reducing the\nmutual information $I(R;Z)$. Therefore, the current literature's view is that a\ngood SSL representation space should have a high $H(R)$ and a low $I(R;Z)$.\nHowever, this view of SSL is lacking in terms of an understanding of the\nunderlying training dynamics that influences the relationship between both\nterms. Our analysis shows that the best performing SSL models do not have the\nhighest $H(R)$ nor the lowest $I(R;Z)$, but effectively arrive at a balance\nbetween both. To take advantage of this analysis, we introduce AdaDim, a\ntraining strategy that leverages SSL training dynamics by adaptively balancing\nbetween increasing $H(R)$ through feature decorrelation and sample uniformity\nas well as gradual regularization of $I(R;Z)$ as training progresses. We show\nperformance improvements of up to 3% over common SSL baselines despite our\nmethod not utilizing expensive techniques such as queues, clustering, predictor\nnetworks, or student-teacher architectures.",
    "published": "2025-05-18T23:35:34Z",
    "updated": "2025-10-08T14:09:23Z",
    "link": "http://arxiv.org/pdf/2505.12576v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Kiran Kokilepersaud",
      "Mohit Prabhushankar",
      "Ghassan AlRegib"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.15927v3",
    "title": "Enhancing Generative Auto-bidding with Offline Reward Evaluation and\n  Policy Search",
    "summary": "Auto-bidding serves as a critical tool for advertisers to improve their\nadvertising performance. Recent progress has demonstrated that AI-Generated\nBidding (AIGB), which learns a conditional generative planner from offline\ndata, achieves superior performance compared to typical offline reinforcement\nlearning (RL)-based auto-bidding methods. However, existing AIGB methods still\nface a performance bottleneck due to their inherent inability to explore beyond\nthe static offline dataset. To address this, we propose {AIGB-Pearl}\n(\\emph{{P}lanning with {E}valu{A}tor via RL}), a novel method that integrates\ngenerative planning and policy optimization. The core of AIGB-Pearl lies in\nconstructing a trajectory evaluator for scoring generation quality and\ndesigning a provably sound KL-Lipschitz-constrained score maximization scheme\nto ensure safe and efficient exploration beyond the offline dataset. A\npractical algorithm incorporating the synchronous coupling technique is further\ndevised to ensure the model regularity required by the proposed scheme.\nExtensive experiments on both simulated and real-world advertising systems\ndemonstrate the state-of-the-art performance of our approach.",
    "published": "2025-09-19T12:30:26Z",
    "updated": "2025-10-08T14:06:32Z",
    "link": "http://arxiv.org/pdf/2509.15927v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Zhiyu Mou",
      "Yiqin Lv",
      "Miao Xu",
      "Qi Wang",
      "Yixiu Mao",
      "Qichen Ye",
      "Chao Li",
      "Rongquan Bai",
      "Chuan Yu",
      "Jian Xu",
      "Bo Zheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.19366v3",
    "title": "Grounding the Ungrounded: A Spectral-Graph Framework for Quantifying\n  Hallucinations in Multimodal LLMs",
    "summary": "Hallucinations in LLMs--especially in multimodal settings--undermine\nreliability. We present a rigorous, information-geometric framework in\ndiffusion dynamics that quantifies hallucination in MLLMs: model outputs are\nembedded spectrally on multimodal graph Laplacians, and gaps to a truth\nmanifold define a semantic-distortion metric. We derive Courant--Fischer bounds\non a temperature-dependent hallucination energy and use RKHS eigenmodes to\nobtain modality-aware, interpretable measures that track evolution over prompts\nand time. This reframes hallucination as measurable and bounded, providing a\nprincipled basis for evaluation and mitigation.",
    "published": "2025-08-26T18:54:52Z",
    "updated": "2025-10-08T14:06:26Z",
    "link": "http://arxiv.org/pdf/2508.19366v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "53B21, 46E22 (Primary), 68R10 (Secondary)"
    ],
    "authors": [
      "Supratik Sarkar",
      "Swagatam Das"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07038v1",
    "title": "Tool-Augmented Policy Optimization: Synergizing Reasoning and Adaptive\n  Tool Use with Reinforcement Learning",
    "summary": "Recent advances in large language models (LLMs) have popularized test-time\nscaling, where models generate additional reasoning tokens before producing\nfinal answers. These approaches have demonstrated significant performance\nimprovements on benchmarks involving mathematical reasoning. However, language\nmodels relying solely on direct inference still struggle with tasks demanding\nup-to-date knowledge or computational tools such as calculators and code\ninterpreters for complex arithmetic operations. To overcome these limitations,\nwe propose Tool-Augmented Policy Optimization (TAPO), a novel reinforcement\nlearning framework that systematically integrates multi-hop reasoning with\nadaptive tool-calling capabilities. Our approach employs a modified version of\nDynamic Sampling Policy Optimization (DAPO), a recently developed RL paradigm,\nwhich we adapt specifically for tool invocation scenarios, enabling models to\ndynamically interleave complex reasoning with on-demand tool usage (including\nsearch APIs and Python interpreters).\n  To support this research, we introduce two new datasets: TAPO-easy-60K and\nTAPO-hard-18K, specifically designed to train and evaluate both fact-based\nreasoning and mathematical calculation capabilities. Our experiments on\nQwen2.5-3B and Qwen2.5-7B models demonstrate the effectiveness of our approach,\nwith both models achieving state-of-the-art performance on tasks requiring\nexternal knowledge and mathematical computation among methods with comparable\nparameters. Notably, TAPO achieves more efficient tool utilization than\nbaseline methods while preventing excessive calls caused by reward hacking.\nThese results highlight the significant potential of combining advanced\nreasoning with tool usage to enhance model performance in knowledge-intensive\nand computationally demanding tasks.",
    "published": "2025-10-08T14:04:27Z",
    "updated": "2025-10-08T14:04:27Z",
    "link": "http://arxiv.org/pdf/2510.07038v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Wenxun Wu",
      "Yuanyang Li",
      "Guhan Chen",
      "Linyue Wang",
      "Hongyang Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07035v1",
    "title": "Unified Molecule Pre-training with Flexible 2D and 3D Modalities: Single\n  and Paired Modality Integration",
    "summary": "Molecular representation learning plays a crucial role in advancing\napplications such as drug discovery and material design. Existing work\nleverages 2D and 3D modalities of molecular information for pre-training,\naiming to capture comprehensive structural and geometric insights. However,\nthese methods require paired 2D and 3D molecular data to train the model\neffectively and prevent it from collapsing into a single modality, posing\nlimitations in scenarios where a certain modality is unavailable or\ncomputationally expensive to generate. To overcome this limitation, we propose\nFlexMol, a flexible molecule pre-training framework that learns unified\nmolecular representations while supporting single-modality input. Specifically,\ninspired by the unified structure in vision-language models, our approach\nemploys separate models for 2D and 3D molecular data, leverages parameter\nsharing to improve computational efficiency, and utilizes a decoder to generate\nfeatures for the missing modality. This enables a multistage continuous\nlearning process where both modalities contribute collaboratively during\ntraining, while ensuring robustness when only one modality is available during\ninference. Extensive experiments demonstrate that FlexMol achieves superior\nperformance across a wide range of molecular property prediction tasks, and we\nalso empirically demonstrate its effectiveness with incomplete data. Our code\nand data are available at https://github.com/tewiSong/FlexMol.",
    "published": "2025-10-08T14:02:51Z",
    "updated": "2025-10-08T14:02:51Z",
    "link": "http://arxiv.org/pdf/2510.07035v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Tengwei Song",
      "Min Wu",
      "Yuan Fang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.16765v2",
    "title": "The Sound of Syntax: Finetuning and Comprehensive Evaluation of Language\n  Models for Speech Pathology",
    "summary": "According to the U.S. National Institutes of Health, more than 3.4 million\nchildren experience speech disorders that require clinical intervention. The\nnumber of speech-language pathologists (SLPs) is roughly 20 times fewer than\nthe number of affected children, highlighting a significant gap in children's\ncare and a pressing need for technological support that improves the\nproductivity of SLPs. State-of-the-art multimodal language models (MLMs) show\npromise for supporting SLPs, but their use remains underexplored largely due to\na limited understanding of their performance in high-stakes clinical settings.\nTo address this gap, we collaborate with domain experts to develop a taxonomy\nof real-world use cases of MLMs in speech-language pathologies. Building on\nthis taxonomy, we introduce the first comprehensive benchmark for evaluating\nMLM across five core use cases, each containing 1,000 manually annotated data\npoints. This benchmark includes robustness and sensitivity tests under various\nsettings, including background noise, speaker gender, and accent. Our\nevaluation of 15 state-of-the-art MLMs reveals that no single model\nconsistently outperforms others across all tasks. Notably, we find systematic\ndisparities, with models performing better on male speakers, and observe that\nchain-of-thought prompting can degrade performance on classification tasks with\nlarge label spaces and narrow decision boundaries. Furthermore, we study\nfine-tuning MLMs on domain-specific data, achieving improvements of over 10\\%\ncompared to base models. These findings highlight both the potential and\nlimitations of current MLMs for speech-language pathology applications,\nunderscoring the need for further research and targeted development.",
    "published": "2025-09-20T18:10:30Z",
    "updated": "2025-10-08T14:02:00Z",
    "link": "http://arxiv.org/pdf/2509.16765v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "authors": [
      "Fagun Patel",
      "Duc Q. Nguyen",
      "Sang T. Truong",
      "Jody Vaynshtok",
      "Sanmi Koyejo",
      "Nick Haber"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.17607v2",
    "title": "Controlled Agentic Planning & Reasoning for Mechanism Synthesis",
    "summary": "This work presents a dual-agent \\ac{llm}-based reasoning framework for\nautomated planar mechanism synthesis that tightly couples linguistic\nspecification with symbolic representation and simulation. From a\nnatural-language task description, the system composes symbolic constraints and\nequations, generates and parametrises simulation code, and iteratively refines\ndesigns via critic-driven feedback, including symbolic regression and geometric\ndistance metrics, closing an actionable linguistic/symbolic optimisation loop.\nTo evaluate the approach, we introduce MSynth, a benchmark of analytically\ndefined planar trajectories. Empirically, critic feedback and iterative\nrefinement yield large improvements (up to 90\\% on individual tasks) and\nstatistically significant gains per the Wilcoxon signed-rank test.\nSymbolic-regression prompts provide deeper mechanistic insight primarily when\npaired with larger models or architectures with appropriate inductive biases\n(e.g., LRM).",
    "published": "2025-05-23T08:16:32Z",
    "updated": "2025-10-08T13:58:13Z",
    "link": "http://arxiv.org/pdf/2505.17607v2.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "João Pedro Gandarela",
      "Thiago Rios",
      "Stefan Menzel",
      "André Freitas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07024v1",
    "title": "Mining the Mind: What 100M Beliefs Reveal About Frontier LLM Knowledge",
    "summary": "LLMs are remarkable artifacts that have revolutionized a range of NLP and AI\ntasks. A significant contributor is their factual knowledge, which, to date,\nremains poorly understood, and is usually analyzed from biased samples. In this\npaper, we take a deep tour into the factual knowledge (or beliefs) of a\nfrontier LLM, based on GPTKB v1.5 (Hu et al., 2025a), a recursively elicited\nset of 100 million beliefs of one of the strongest currently available frontier\nLLMs, GPT-4.1. We find that the models' factual knowledge differs quite\nsignificantly from established knowledge bases, and that its accuracy is\nsignificantly lower than indicated by previous benchmarks. We also find that\ninconsistency, ambiguity and hallucinations are major issues, shedding light on\nfuture research opportunities concerning factual LLM knowledge.",
    "published": "2025-10-08T13:48:38Z",
    "updated": "2025-10-08T13:48:38Z",
    "link": "http://arxiv.org/pdf/2510.07024v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Shrestha Ghosh",
      "Luca Giordano",
      "Yujia Hu",
      "Tuan-Phong Nguyen",
      "Simon Razniewski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.22371v3",
    "title": "Error Bounds for Physics-Informed Neural Networks in Fokker-Planck PDEs",
    "summary": "Stochastic differential equations are commonly used to describe the evolution\nof stochastic processes. The state uncertainty of such processes is best\nrepresented by the probability density function (PDF), whose evolution is\ngoverned by the Fokker-Planck partial differential equation (FP-PDE). However,\nit is generally infeasible to solve the FP-PDE in closed form. In this work, we\nshow that physics-informed neural networks (PINNs) can be trained to\napproximate the solution PDF. Our main contribution is the analysis of PINN\napproximation error: we develop a theoretical framework to construct tight\nerror bounds using PINNs. In addition, we derive a practical error bound that\ncan be efficiently constructed with standard training methods. We discuss that\nthis error-bound framework generalizes to approximate solutions of other linear\nPDEs. Empirical results on nonlinear, high-dimensional, and chaotic systems\nvalidate the correctness of our error bounds while demonstrating the\nscalability of PINNs and their significant computational speedup in obtaining\naccurate PDF solutions compared to the Monte Carlo approach.",
    "published": "2024-10-28T23:25:55Z",
    "updated": "2025-10-08T13:47:39Z",
    "link": "http://arxiv.org/pdf/2410.22371v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA",
      "physics.comp-ph"
    ],
    "authors": [
      "Chun-Wei Kong",
      "Luca Laurenti",
      "Jay McMahon",
      "Morteza Lahijanian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07022v1",
    "title": "Federated Unlearning in the Wild: Rethinking Fairness and Data\n  Discrepancy",
    "summary": "Machine unlearning is critical for enforcing data deletion rights like the\n\"right to be forgotten.\" As a decentralized paradigm, Federated Learning (FL)\nalso requires unlearning, but realistic implementations face two major\nchallenges. First, fairness in Federated Unlearning (FU) is often overlooked.\nExact unlearning methods typically force all clients into costly retraining,\neven those uninvolved. Approximate approaches, using gradient ascent or\ndistillation, make coarse interventions that can unfairly degrade performance\nfor clients with only retained data. Second, most FU evaluations rely on\nsynthetic data assumptions (IID/non-IID) that ignore real-world heterogeneity.\nThese unrealistic benchmarks obscure the true impact of unlearning and limit\nthe applicability of current methods. We first conduct a comprehensive\nbenchmark of existing FU methods under realistic data heterogeneity and\nfairness conditions. We then propose a novel, fairness-aware FU approach,\nFederated Cross-Client-Constrains Unlearning (FedCCCU), to explicitly address\nboth challenges. FedCCCU offers a practical and scalable solution for\nreal-world FU. Experimental results show that existing methods perform poorly\nin realistic settings, while our approach consistently outperforms them.",
    "published": "2025-10-08T13:47:19Z",
    "updated": "2025-10-08T13:47:19Z",
    "link": "http://arxiv.org/pdf/2510.07022v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "ZiHeng Huang",
      "Di Wu",
      "Jun Bai",
      "Jiale Zhang",
      "Sicong Cao",
      "Ji Zhang",
      "Yingjie Hu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07019v1",
    "title": "Native Hybrid Attention for Efficient Sequence Modeling",
    "summary": "Transformers excel at sequence modeling but face quadratic complexity, while\nlinear attention offers improved efficiency but often compromises recall\naccuracy over long contexts. In this work, we introduce Native Hybrid Attention\n(NHA), a novel hybrid architecture of linear and full attention that integrates\nboth intra \\& inter-layer hybridization into a unified layer design. NHA\nmaintains long-term context in key-value slots updated by a linear RNN, and\naugments them with short-term tokens from a sliding window. A single\n\\texttt{softmax attention} operation is then applied over all keys and values,\nenabling per-token and per-head context-dependent weighting without requiring\nadditional fusion parameters. The inter-layer behavior is controlled through a\nsingle hyperparameter, the sliding window size, which allows smooth adjustment\nbetween purely linear and full attention while keeping all layers structurally\nuniform. Experimental results show that NHA surpasses Transformers and other\nhybrid baselines on recall-intensive and commonsense reasoning tasks.\nFurthermore, pretrained LLMs can be structurally hybridized with NHA, achieving\ncompetitive accuracy while delivering significant efficiency gains. Code is\navailable at https://github.com/JusenD/NHA.",
    "published": "2025-10-08T13:44:57Z",
    "updated": "2025-10-08T13:44:57Z",
    "link": "http://arxiv.org/pdf/2510.07019v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Jusen Du",
      "Jiaxi Hu",
      "Tao Zhang",
      "Weigao Sun",
      "Yu Cheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.05516v2",
    "title": "Learning to Recover: Dynamic Reward Shaping with Wheel-Leg Coordination\n  for Fallen Robots",
    "summary": "Adaptive recovery from fall incidents are essential skills for the practical\ndeployment of wheeled-legged robots, which uniquely combine the agility of legs\nwith the speed of wheels for rapid recovery. However, traditional methods\nrelying on preplanned recovery motions, simplified dynamics or sparse rewards\noften fail to produce robust recovery policies. This paper presents a\nlearning-based framework integrating Episode-based Dynamic Reward Shaping and\ncurriculum learning, which dynamically balances exploration of diverse recovery\nmaneuvers with precise posture refinement. An asymmetric actor-critic\narchitecture accelerates training by leveraging privileged information in\nsimulation, while noise-injected observations enhance robustness against\nuncertainties. We further demonstrate that synergistic wheel-leg coordination\nreduces joint torque consumption by 15.8% and 26.2% and improves stabilization\nthrough energy transfer mechanisms. Extensive evaluations on two distinct\nquadruped platforms achieve recovery success rates up to 99.1% and 97.8%\nwithout platform-specific tuning. The supplementary material is available at\nhttps://boyuandeng.github.io/L2R-WheelLegCoordination/",
    "published": "2025-06-05T18:58:12Z",
    "updated": "2025-10-08T13:33:28Z",
    "link": "http://arxiv.org/pdf/2506.05516v2.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Boyuan Deng",
      "Luca Rossini",
      "Jin Wang",
      "Weijie Wang",
      "Dimitrios Kanoulas",
      "Nikolaos Tsagarakis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.09621v2",
    "title": "Interpretable Robot Control via Structured Behavior Trees and Large\n  Language Models",
    "summary": "As intelligent robots become more integrated into human environments, there\nis a growing need for intuitive and reliable Human-Robot Interaction (HRI)\ninterfaces that are adaptable and more natural to interact with. Traditional\nrobot control methods often require users to adapt to interfaces or memorize\npredefined commands, limiting usability in dynamic, unstructured environments.\nThis paper presents a novel framework that bridges natural language\nunderstanding and robotic execution by combining Large Language Models (LLMs)\nwith Behavior Trees. This integration enables robots to interpret natural\nlanguage instructions given by users and translate them into executable actions\nby activating domain-specific plugins. The system supports scalable and modular\nintegration, with a primary focus on perception-based functionalities, such as\nperson tracking and hand gesture recognition. To evaluate the system, a series\nof real-world experiments was conducted across diverse environments.\nExperimental results demonstrate that the proposed approach is practical in\nreal-world scenarios, with an average cognition-to-execution accuracy of\napproximately 94%, making a significant contribution to HRI systems and robots.\nThe complete source code of the framework is publicly available at\nhttps://github.com/snt-arg/robot_suite.",
    "published": "2025-08-13T08:53:13Z",
    "updated": "2025-10-08T13:28:52Z",
    "link": "http://arxiv.org/pdf/2508.09621v2.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Ingrid Maéva Chekam",
      "Ines Pastor-Martinez",
      "Ali Tourani",
      "Jose Andres Millan-Romera",
      "Laura Ribeiro",
      "Pedro Miguel Bastos Soares",
      "Holger Voos",
      "Jose Luis Sanchez-Lopez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07000v1",
    "title": "Pragyaan: Designing and Curating High-Quality Cultural Post-Training\n  Datasets for Indian Languages",
    "summary": "The effectiveness of Large Language Models (LLMs) depends heavily on the\navailability of high-quality post-training data, particularly\ninstruction-tuning and preference-based examples. Existing open-source\ndatasets, however, often lack multilingual coverage, cultural grounding, and\nsuffer from task diversity gaps that are especially pronounced for Indian\nlanguages. We introduce a human-in-the-loop pipeline that combines translations\nwith synthetic expansion to produce reliable and diverse Indic post-training\ndata. Using this pipeline, we curate two datasets: Pragyaan-IT (22.5K) and\nPragyaan-Align (100K) across 10 Indian languages covering 13 broad and 56\nsub-categories, leveraging 57 diverse datasets. Our dataset protocol\nincorporates several often-overlooked dimensions and emphasize task diversity,\nmulti-turn dialogue, instruction fidelity, safety alignment, and preservation\nof cultural nuance, providing a foundation for more inclusive and effective\nmultilingual LLMs.",
    "published": "2025-10-08T13:23:45Z",
    "updated": "2025-10-08T13:23:45Z",
    "link": "http://arxiv.org/pdf/2510.07000v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Neel Prabhanjan Rachamalla",
      "Aravind Konakalla",
      "Gautam Rajeev",
      "Ashish Kulkarni",
      "Chandra Khatri",
      "Shubham Agarwal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06997v1",
    "title": "The Limits of Goal-Setting Theory in LLM-Driven Assessment",
    "summary": "Many users interact with AI tools like ChatGPT using a mental model that\ntreats the system as human-like, which we call Model H. According to\ngoal-setting theory, increased specificity in goals should reduce performance\nvariance. If Model H holds, then prompting a chatbot with more detailed\ninstructions should lead to more consistent evaluation behavior.\n  This paper tests that assumption through a controlled experiment in which\nChatGPT evaluated 29 student submissions using four prompts with increasing\nspecificity. We measured consistency using intra-rater reliability (Cohen's\nKappa) across repeated runs.\n  Contrary to expectations, performance did not improve consistently with\nincreased prompt specificity, and performance variance remained largely\nunchanged. These findings challenge the assumption that LLMs behave like human\nevaluators and highlight the need for greater robustness and improved input\nintegration in future model development.",
    "published": "2025-10-08T13:20:40Z",
    "updated": "2025-10-08T13:20:40Z",
    "link": "http://arxiv.org/pdf/2510.06997v1.pdf",
    "category": [
      "cs.CY",
      "cs.AI"
    ],
    "authors": [
      "Mrityunjay Kumar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.11927v3",
    "title": "Transparent and Coherent Procedural Mistake Detection",
    "summary": "Procedural mistake detection (PMD) is a challenging problem of classifying\nwhether a human user (observed through egocentric video) has successfully\nexecuted a task (specified by a procedural text). Despite significant recent\nefforts, machine performance in the wild remains nonviable, and the reasoning\nprocesses underlying this performance are opaque. As such, we extend PMD to\nrequire generating visual self-dialog rationales to inform decisions. Given the\nimpressive, mature image understanding capabilities observed in recent\nvision-and-language models (VLMs), we curate a suitable benchmark dataset for\nPMD based on individual frames. As our reformulation enables unprecedented\ntransparency, we leverage a natural language inference (NLI) model to formulate\ntwo automated metrics for the coherence of generated rationales. We establish\nbaselines for this reframed task, showing that VLMs struggle off-the-shelf, but\nwith some trade-offs, their accuracy, coherence, and efficiency can be improved\nby incorporating these metrics into common inference and fine-tuning methods.\nLastly, our multi-faceted metrics visualize common outcomes, highlighting areas\nfor further improvement.",
    "published": "2024-12-16T16:13:55Z",
    "updated": "2025-10-08T13:15:22Z",
    "link": "http://arxiv.org/pdf/2412.11927v3.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Shane Storks",
      "Itamar Bar-Yossef",
      "Yayuan Li",
      "Zheyuan Zhang",
      "Jason J. Corso",
      "Joyce Chai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06975v1",
    "title": "VelLMes: A high-interaction AI-based deception framework",
    "summary": "There are very few SotA deception systems based on Large Language Models. The\nexisting ones are limited only to simulating one type of service, mainly SSH\nshells. These systems - but also the deception technologies not based on LLMs -\nlack an extensive evaluation that includes human attackers. Generative AI has\nrecently become a valuable asset for cybersecurity researchers and\npractitioners, and the field of cyber-deception is no exception. Researchers\nhave demonstrated how LLMs can be leveraged to create realistic-looking\nhoneytokens, fake users, and even simulated systems that can be used as\nhoneypots. This paper presents an AI-based deception framework called VelLMes,\nwhich can simulate multiple protocols and services such as SSH Linux shell,\nMySQL, POP3, and HTTP. All of these can be deployed and used as honeypots, thus\nVelLMes offers a variety of choices for deception design based on the users'\nneeds. VelLMes is designed to be attacked by humans, so interactivity and\nrealism are key for its performance. We evaluate the generative capabilities\nand the deception capabilities. Generative capabilities were evaluated using\nunit tests for LLMs. The results of the unit tests show that, with careful\nprompting, LLMs can produce realistic-looking responses, with some LLMs having\na 100% passing rate. In the case of the SSH Linux shell, we evaluated deception\ncapabilities with 89 human attackers. The results showed that about 30% of the\nattackers thought that they were interacting with a real system when they were\nassigned an LLM-based honeypot. Lastly, we deployed 10 instances of the SSH\nLinux shell honeypot on the Internet to capture real-life attacks. Analysis of\nthese attacks showed us that LLM honeypots simulating Linux shells can perform\nwell against unstructured and unexpected attacks on the Internet, responding\ncorrectly to most of the issued commands.",
    "published": "2025-10-08T13:00:23Z",
    "updated": "2025-10-08T13:00:23Z",
    "link": "http://arxiv.org/pdf/2510.06975v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Muris Sladić",
      "Veronica Valeros",
      "Carlos Catania",
      "Sebastian Garcia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06969v1",
    "title": "Learning Global Representation from Queries for Vectorized HD Map\n  Construction",
    "summary": "The online construction of vectorized high-definition (HD) maps is a\ncornerstone of modern autonomous driving systems. State-of-the-art approaches,\nparticularly those based on the DETR framework, formulate this as an instance\ndetection problem. However, their reliance on independent, learnable object\nqueries results in a predominantly local query perspective, neglecting the\ninherent global representation within HD maps. In this work, we propose\n\\textbf{MapGR} (\\textbf{G}lobal \\textbf{R}epresentation learning for HD\n\\textbf{Map} construction), an architecture designed to learn and utilize a\nglobal representations from queries. Our method introduces two synergistic\nmodules: a Global Representation Learning (GRL) module, which encourages the\ndistribution of all queries to better align with the global map through a\ncarefully designed holistic segmentation task, and a Global Representation\nGuidance (GRG) module, which endows each individual query with explicit,\nglobal-level contextual information to facilitate its optimization. Evaluations\non the nuScenes and Argoverse2 datasets validate the efficacy of our approach,\ndemonstrating substantial improvements in mean Average Precision (mAP) compared\nto leading baselines.",
    "published": "2025-10-08T12:56:08Z",
    "updated": "2025-10-08T12:56:08Z",
    "link": "http://arxiv.org/pdf/2510.06969v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Shoumeng Qiu",
      "Xinrun Li",
      "Yang Long",
      "Xiangyang Xue",
      "Varun Ojha",
      "Jian Pu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06967v1",
    "title": "Generating Surface for Text-to-3D using 2D Gaussian Splatting",
    "summary": "Recent advancements in Text-to-3D modeling have shown significant potential\nfor the creation of 3D content. However, due to the complex geometric shapes of\nobjects in the natural world, generating 3D content remains a challenging task.\nCurrent methods either leverage 2D diffusion priors to recover 3D geometry, or\ntrain the model directly based on specific 3D representations. In this paper,\nwe propose a novel method named DirectGaussian, which focuses on generating the\nsurfaces of 3D objects represented by surfels. In DirectGaussian, we utilize\nconditional text generation models and the surface of a 3D object is rendered\nby 2D Gaussian splatting with multi-view normal and texture priors. For\nmulti-view geometric consistency problems, DirectGaussian incorporates\ncurvature constraints on the generated surface during optimization process.\nThrough extensive experiments, we demonstrate that our framework is capable of\nachieving diverse and high-fidelity 3D content creation.",
    "published": "2025-10-08T12:54:57Z",
    "updated": "2025-10-08T12:54:57Z",
    "link": "http://arxiv.org/pdf/2510.06967v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Huanning Dong",
      "Fan Li",
      "Ping Kuang",
      "Jianwen Min"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06965v1",
    "title": "EDUMATH: Generating Standards-aligned Educational Math Word Problems",
    "summary": "Math word problems (MWPs) are critical K-12 educational tools, and\ncustomizing them to students' interests and ability levels can increase\nlearning outcomes. However, teachers struggle to find time to customize MWPs\nfor each student given large class sizes and increasing burnout. We propose\nthat LLMs can support math education by generating MWPs customized to student\ninterests and math education standards. To this end, we use a joint human\nexpert-LLM judge approach to evaluate over 11,000 MWPs generated by open and\nclosed LLMs and develop the first teacher-annotated dataset for\nstandards-aligned educational MWP generation. We show the value of our data by\nusing it to train a 12B open model that matches the performance of larger and\nmore capable open models. We also use our teacher-annotated data to train a\ntext classifier that enables a 30B open LLM to outperform existing closed\nbaselines without any training. Next, we show our models' MWPs are more similar\nto human-written MWPs than those from existing models. We conclude by\nconducting the first study of customized LLM-generated MWPs with grade school\nstudents, finding they perform similarly on our models' MWPs relative to\nhuman-written MWPs but consistently prefer our customized MWPs.",
    "published": "2025-10-08T12:53:06Z",
    "updated": "2025-10-08T12:53:06Z",
    "link": "http://arxiv.org/pdf/2510.06965v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Bryan R. Christ",
      "Penelope Molitz",
      "Jonathan Kropko",
      "Thomas Hartvigsen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06961v1",
    "title": "Open ASR Leaderboard: Towards Reproducible and Transparent Multilingual\n  and Long-Form Speech Recognition Evaluation",
    "summary": "Despite rapid progress, ASR evaluation remains saturated with short-form\nEnglish, and efficiency is rarely reported. We present the Open ASR\nLeaderboard, a fully reproducible benchmark and interactive leaderboard\ncomparing 60+ open-source and proprietary systems across 11 datasets, including\ndedicated multilingual and long-form tracks. We standardize text normalization\nand report both word error rate (WER) and inverse real-time factor (RTFx),\nenabling fair accuracy-efficiency comparisons. For English transcription,\nConformer encoders paired with LLM decoders achieve the best average WER but\nare slower, while CTC and TDT decoders deliver much better RTFx, making them\nattractive for long-form and offline use. Whisper-derived encoders fine-tuned\nfor English improve accuracy but often trade off multilingual coverage. All\ncode and dataset loaders are open-sourced to support transparent, extensible\nevaluation.",
    "published": "2025-10-08T12:44:51Z",
    "updated": "2025-10-08T12:44:51Z",
    "link": "http://arxiv.org/pdf/2510.06961v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "authors": [
      "Vaibhav Srivastav",
      "Steven Zheng",
      "Eric Bezzam",
      "Eustache Le Bihan",
      "Nithin Koluguri",
      "Piotr Żelasko",
      "Somshubra Majumdar",
      "Adel Moumen",
      "Sanchit Gandhi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06953v1",
    "title": "Revisiting the Uniform Information Density Hypothesis in LLM Reasoning\n  Traces",
    "summary": "The Uniform Information Density (UID) hypothesis suggests that effective\ncommunication maintains a stable flow of information. In this work, we revisit\nthis principle in the context of large language model (LLM) reasoning traces,\nasking whether step-level uniformity reflects reasoning quality. To this end,\nwe propose an entropy-based stepwise information density metric and introduce\ntwo complementary measures of uniformity, local and global uniformity scores.\nAcross the experiments on six different reasoning benchmarks, we find that\nstep-level uniformity not only provides a strong theoretical lens but also\nyields practical performance benefits; for example, selecting reasoning traces\nwith more uniform information density at the step-level improves accuracy by\n10-32\\% relative gains over baselines at AIME2025. Our analysis further reveals\nthat correct reasoning traces tend to avoid sharp information density spikes,\nwhile incorrect traces exhibit irregular information bursts. These results\ndemonstrate that UID-inspired information density measures outperform\nalternative internal signals as predictors of reasoning quality. Results\nhighlight the uniformity of the information density as a robust diagnostic and\nselection criterion for building more reliable and accurate reasoning systems.",
    "published": "2025-10-08T12:37:04Z",
    "updated": "2025-10-08T12:37:04Z",
    "link": "http://arxiv.org/pdf/2510.06953v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Minju Gwak",
      "Guijin Son",
      "Jaehyung Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06949v1",
    "title": "Grouped Differential Attention",
    "summary": "The self-attention mechanism, while foundational to modern Transformer\narchitectures, suffers from a critical inefficiency: it frequently allocates\nsubstantial attention to redundant or noisy context. Differential Attention\naddressed this by using subtractive attention maps for signal and noise, but\nits required balanced head allocation imposes rigid constraints on\nrepresentational flexibility and scalability.\n  To overcome this, we propose Grouped Differential Attention (GDA), a novel\napproach that introduces unbalanced head allocation between signal-preserving\nand noise-control groups. GDA significantly enhances signal focus by\nstrategically assigning more heads to signal extraction and fewer to\nnoise-control, stabilizing the latter through controlled repetition (akin to\nGQA). This design achieves stronger signal fidelity with minimal computational\noverhead. We further extend this principle to group-differentiated growth, a\nscalable strategy that selectively replicates only the signal-focused heads,\nthereby ensuring efficient capacity expansion.\n  Through large-scale pretraining and continual training experiments, we\ndemonstrate that moderate imbalance ratios in GDA yield substantial\nimprovements in generalization and stability compared to symmetric baselines.\nOur results collectively establish that ratio-aware head allocation and\nselective expansion offer an effective and practical path toward designing\nscalable, computation-efficient Transformer architectures.",
    "published": "2025-10-08T12:32:28Z",
    "updated": "2025-10-08T12:32:28Z",
    "link": "http://arxiv.org/pdf/2510.06949v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Junghwan Lim",
      "Sungmin Lee",
      "Dongseok Kim",
      "Wai Ting Cheung",
      "Beomgyu Kim",
      "Taehwan Kim",
      "Haesol Lee",
      "Junhyeok Lee",
      "Dongpin Oh",
      "Eunhwan Park"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.03654v2",
    "title": "Improving Neutral Point-of-View Generation with Data- and\n  Parameter-Efficient RL",
    "summary": "The paper shows that parameter-efficient reinforcement learning (PE-RL) is a\nhighly effective training regime to improve large language models' (LLMs)\nability to answer queries on sensitive topics with a Neutral Point of View\n(NPOV), i.e. to provide significantly more informative, diverse and impartial\nanswers. This is shown by evaluating PE-RL and multiple strong\nbaselines-including LoRA finetuning (strongest baseline), SFT and RLHF. PE-RL\nnot only improves on overall NPOV quality compared to the strongest baseline\n($97.06\\%\\rightarrow 99.08\\%$), but also scores much higher on features\nlinguists identify as key to separating sufficient answers from \"great''\nanswers ($60.25\\%\\rightarrow 85.21\\%$ for presence of supportive details,\n$68.74\\%\\rightarrow 91.43\\%$ for absence of oversimplification). A qualitative\nanalysis corroborates this. Moreover, our evaluation also finds a key property\nof PE-RL for this task: unlike methods that update all parameters, it\ngeneralises out of topic. Finally, to enable further studies we also release\nthe dataset, SHQ-NPOV, and provide a methodology to create such datasets\nthrough iterative rounds of human peer-critique and annotator training.",
    "published": "2025-03-05T16:32:47Z",
    "updated": "2025-10-08T12:30:55Z",
    "link": "http://arxiv.org/pdf/2503.03654v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Jessica Hoffmann",
      "Christiane Ahlheim",
      "Zac Yu",
      "Aria Walfrand",
      "Jarvis Jin",
      "Marie Tano",
      "Ahmad Beirami",
      "Erin van Liemt",
      "Nithum Thain",
      "Hakim Sidahmed",
      "Lucas Dixon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06938v1",
    "title": "Expressive and Scalable Quantum Fusion for Multimodal Learning",
    "summary": "The aim of this paper is to introduce a quantum fusion mechanism for\nmultimodal learning and to establish its theoretical and empirical potential.\nThe proposed method, called the Quantum Fusion Layer (QFL), replaces classical\nfusion schemes with a hybrid quantum-classical procedure that uses\nparameterized quantum circuits to learn entangled feature interactions without\nrequiring exponential parameter growth. Supported by quantum signal processing\nprinciples, the quantum component efficiently represents high-order polynomial\ninteractions across modalities with linear parameter scaling, and we provide a\nseparation example between QFL and low-rank tensor-based methods that\nhighlights potential quantum query advantages. In simulation, QFL consistently\noutperforms strong classical baselines on small but diverse multimodal tasks,\nwith particularly marked improvements in high-modality regimes. These results\nsuggest that QFL offers a fundamentally new and scalable approach to multimodal\nfusion that merits deeper exploration on larger systems.",
    "published": "2025-10-08T12:19:44Z",
    "updated": "2025-10-08T12:19:44Z",
    "link": "http://arxiv.org/pdf/2510.06938v1.pdf",
    "category": [
      "quant-ph",
      "cs.AI"
    ],
    "authors": [
      "Tuyen Nguyen",
      "Trong Nghia Hoang",
      "Phi Le Nguyen",
      "Hai L. Vu",
      "Truong Cong Thang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.23274v3",
    "title": "Real-Time Progress Prediction in Reasoning Language Models",
    "summary": "Recent advances in reasoning language models -- particularly those that use\nlong, latent chains of thought -- have demonstrated remarkable capabilities in\ncomplex, agentic tasks. However, as these models operate over increasingly\nextended time horizons, their internal progress becomes opaque to users,\ncomplicating expectation management and real-time oversight. In this work, we\ninvestigate whether real-time progress prediction is feasible. We discretize\nprogress and train a linear probe to classify reasoning states. We then\nintroduce a two-stage fine-tuning approach that enables reasoning models to\ngenerate progress estimates (0$\\rightarrow$100\\%) during inference. Our best\nfine-tuned model achieves an average error of 10\\% for sequences less than\n16,000 tokens, offering a practical mechanism for monitoring and interpreting\nmodel reasoning in real time.",
    "published": "2025-06-29T15:01:01Z",
    "updated": "2025-10-08T12:11:48Z",
    "link": "http://arxiv.org/pdf/2506.23274v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Hans Peter Lynsgøe Raaschou-jensen",
      "Constanza Fierro",
      "Anders Søgaard"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.03363v2",
    "title": "Unified Unsupervised Anomaly Detection via Matching Cost Filtering",
    "summary": "Unsupervised anomaly detection (UAD) aims to identify image- and pixel-level\nanomalies using only normal training data, with wide applications such as\nindustrial inspection and medical analysis, where anomalies are scarce due to\nprivacy concerns and cold-start constraints. Existing methods, whether\nreconstruction-based (restoring normal counterparts) or embedding-based\n(pretrained representations), fundamentally conduct image- or feature-level\nmatching to generate anomaly maps. Nonetheless, matching noise has been largely\noverlooked, limiting their detection ability. Beyond earlier focus on unimodal\nRGB-based UAD, recent advances expand to multimodal scenarios, e.g., RGB-3D and\nRGB-Text, enabled by point cloud sensing and vision-language models. Despite\nshared challenges, these lines remain largely isolated, hindering a\ncomprehensive understanding and knowledge transfer. In this paper, we advocate\nunified UAD for both unimodal and multimodal settings in the matching\nperspective. Under this insight, we present Unified Cost Filtering (UCF), a\ngeneric post-hoc refinement framework for refining anomaly cost volume of any\nUAD model. The cost volume is constructed by matching a test sample against\nnormal samples from the same or different modalities, followed by a learnable\nfiltering module with multi-layer attention guidance from the test sample,\nmitigating matching noise and highlighting subtle anomalies. Comprehensive\nexperiments on 22 diverse benchmarks demonstrate the efficacy of UCF in\nenhancing a variety of UAD methods, consistently achieving new state-of-the-art\nresults in both unimodal (RGB) and multimodal (RGB-3D, RGB-Text) UAD scenarios.\nCode and models will be released at https://github.com/ZHE-SAPI/CostFilter-AD.",
    "published": "2025-10-03T03:28:18Z",
    "updated": "2025-10-08T12:00:06Z",
    "link": "http://arxiv.org/pdf/2510.03363v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "authors": [
      "Zhe Zhang",
      "Mingxiu Cai",
      "Gaochang Wu",
      "Jing Zhang",
      "Lingqiao Liu",
      "Dacheng Tao",
      "Tianyou Chai",
      "Xiatian Zhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.04716v2",
    "title": "A Calibration-Free Fixed Point of Curved Boolean Logic Matching the\n  Fine-Structure Constant",
    "summary": "We show that Curved Boolean Logic (CBL) admits a calibration-free fixed point\nat which the per-face holonomy $\\theta_0$ is the same across independent\nminimal faces (CHSH, KCBS, SAT_6). Equality is enforced by solving the\ntwo-component system $F(\\delta, \\gamma_4, \\gamma_5, \\gamma_6) = (\\theta_0^{(4)}\n- \\theta_0^{(5)}, \\theta_0^{(5)} - \\theta_0^{(6))} = 0$ with a Gauss-Newton\nmethod (no external scale). A finite-difference Jacobian is full rank at the\nsolution, implying local uniqueness. Working at the coupling level $g =\n|\\theta_0|/(2\\pi n)$ removes hidden length factors; at the equality point our\nnormalization audit shows $g = \\alpha$ (Thomson limit) within numerical\ntolerance. The SU(1,1) corner words and overlap placements used to compute\n$\\theta_0$ are specified exactly; we also report a variational minimax analysis\non g and a pilot non-backtracking spectral density that coincides numerically\nwith the per-edge coupling, suggesting a purely topological formulation. Scope:\nthe match is to the low-energy (Thomson) limit; a full spectral equality on the\ncontextual complex is left as a short conjecture. These results promote the\nCBL-$\\alpha$ connection from a calibrated identification to a calibration-free\nderivation candidate.",
    "published": "2025-10-06T11:34:08Z",
    "updated": "2025-10-08T11:54:50Z",
    "link": "http://arxiv.org/pdf/2510.04716v2.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "cs.CC",
      "quant-ph",
      "68Q17, 68Q25",
      "F.1.1; F.2.2; I.2.3"
    ],
    "authors": [
      "Maximilian R. P. von Liechtenstein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06919v1",
    "title": "Bayesian Nonparametric Dynamical Clustering of Time Series",
    "summary": "We present a method that models the evolution of an unbounded number of time\nseries clusters by switching among an unknown number of regimes with linear\ndynamics. We develop a Bayesian non-parametric approach using a hierarchical\nDirichlet process as a prior on the parameters of a Switching Linear Dynamical\nSystem and a Gaussian process prior to model the statistical variations in\namplitude and temporal alignment within each cluster. By modeling the evolution\nof time series patterns, the method avoids unnecessary proliferation of\nclusters in a principled manner. We perform inference by formulating a\nvariational lower bound for off-line and on-line scenarios, enabling efficient\nlearning through optimization. We illustrate the versatility and effectiveness\nof the approach through several case studies of electrocardiogram analysis\nusing publicly available databases.",
    "published": "2025-10-08T11:52:39Z",
    "updated": "2025-10-08T11:52:39Z",
    "link": "http://arxiv.org/pdf/2510.06919v1.pdf",
    "category": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "stat.AP",
      "I.5; I.2.1"
    ],
    "authors": [
      "Adrián Pérez-Herrero",
      "Paulo Félix",
      "Jesús Presedo",
      "Carl Henrik Ek"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06915v1",
    "title": "LongRM: Revealing and Unlocking the Context Boundary of Reward Modeling",
    "summary": "Reward model (RM) plays a pivotal role in aligning large language model (LLM)\nwith human preferences. As real-world applications increasingly involve long\nhistory trajectories, e.g., LLM agent, it becomes indispensable to evaluate\nwhether a model's responses are not only high-quality but also grounded in and\nconsistent with the provided context. Yet, current RMs remain confined to\nshort-context settings and primarily focus on response-level attributes (e.g.,\nsafety or helpfulness), while largely neglecting the critical dimension of long\ncontext-response consistency. In this work, we introduce Long-RewardBench, a\nbenchmark specifically designed for long-context RM evaluation, featuring both\nPairwise Comparison and Best-of-N tasks. Our preliminary study reveals that\neven state-of-the-art generative RMs exhibit significant fragility in\nlong-context scenarios, failing to maintain context-aware preference judgments.\nMotivated by the analysis of failure patterns observed in model outputs, we\npropose a general multi-stage training strategy that effectively scales\narbitrary models into robust Long-context RMs (LongRMs). Experiments show that\nour approach not only substantially improves performance on long-context\nevaluation but also preserves strong short-context capability. Notably, our 8B\nLongRM outperforms much larger 70B-scale baselines and matches the performance\nof the proprietary Gemini 2.5 Pro model.",
    "published": "2025-10-08T11:48:16Z",
    "updated": "2025-10-08T11:48:16Z",
    "link": "http://arxiv.org/pdf/2510.06915v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Zecheng Tang",
      "Baibei Ji",
      "Quantong Qiu",
      "Haitian Wang",
      "Xiaobo Liang",
      "Juntao Li",
      "Min Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06913v1",
    "title": "DecompGAIL: Learning Realistic Traffic Behaviors with Decomposed\n  Multi-Agent Generative Adversarial Imitation Learning",
    "summary": "Realistic traffic simulation is critical for the development of autonomous\ndriving systems and urban mobility planning, yet existing imitation learning\napproaches often fail to model realistic traffic behaviors. Behavior cloning\nsuffers from covariate shift, while Generative Adversarial Imitation Learning\n(GAIL) is notoriously unstable in multi-agent settings. We identify a key\nsource of this instability: irrelevant interaction misguidance, where a\ndiscriminator penalizes an ego vehicle's realistic behavior due to unrealistic\ninteractions among its neighbors. To address this, we propose Decomposed\nMulti-agent GAIL (DecompGAIL), which explicitly decomposes realism into ego-map\nand ego-neighbor components, filtering out misleading neighbor: neighbor and\nneighbor: map interactions. We further introduce a social PPO objective that\naugments ego rewards with distance-weighted neighborhood rewards, encouraging\noverall realism across agents. Integrated into a lightweight SMART-based\nbackbone, DecompGAIL achieves state-of-the-art performance on the WOMD Sim\nAgents 2025 benchmark.",
    "published": "2025-10-08T11:46:39Z",
    "updated": "2025-10-08T11:46:39Z",
    "link": "http://arxiv.org/pdf/2510.06913v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "authors": [
      "Ke Guo",
      "Haochen Liu",
      "Xiaojun Wu",
      "Chen Lv"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06911v1",
    "title": "LLM-Assisted Modeling of Semantic Web-Enabled Multi-Agents Systems with\n  AJAN",
    "summary": "There are many established semantic Web standards for implementing\nmulti-agent driven applications. The AJAN framework allows to engineer\nmulti-agent systems based on these standards. In particular, agent knowledge is\nrepresented in RDF/RDFS and OWL, while agent behavior models are defined with\nBehavior Trees and SPARQL to access and manipulate this knowledge. However, the\nappropriate definition of RDF/RDFS and SPARQL-based agent behaviors still\nremains a major hurdle not only for agent modelers in practice. For example,\ndealing with URIs is very error-prone regarding typos and dealing with complex\nSPARQL queries in large-scale environments requires a high learning curve. In\nthis paper, we present an integrated development environment to overcome such\nhurdles of modeling AJAN agents and at the same time to extend the user\ncommunity for AJAN by the possibility to leverage Large Language Models for\nagent engineering.",
    "published": "2025-10-08T11:45:19Z",
    "updated": "2025-10-08T11:45:19Z",
    "link": "http://arxiv.org/pdf/2510.06911v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Hacane Hechehouche",
      "Andre Antakli",
      "Matthias Klusch"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.15828v2",
    "title": "Context Matters! Relaxing Goals with LLMs for Feasible 3D Scene Planning",
    "summary": "Embodied agents need to plan and act reliably in real and complex 3D\nenvironments. Classical planning (e.g., PDDL) offers structure and guarantees,\nbut in practice it fails under noisy perception and incorrect predicate\ngrounding. On the other hand, Large Language Models (LLMs)-based planners\nleverage commonsense reasoning, yet frequently propose actions that are\nunfeasible or unsafe. Following recent works that combine the two approaches,\nwe introduce ContextMatters, a framework that fuses LLMs and classical planning\nto perform hierarchical goal relaxation: the LLM helps ground symbols to the\nscene and, when the target is unreachable, it proposes functionally equivalent\ngoals that progressively relax constraints, adapting the goal to the context of\nthe agent's environment. Operating on 3D Scene Graphs, this mechanism turns\nmany nominally unfeasible tasks into tractable plans and enables context-aware\npartial achievement when full completion is not achievable. Our experimental\nresults show a +52.45% Success Rate improvement over state-of-the-art LLMs+PDDL\nbaseline, demonstrating the effectiveness of our approach. Moreover, we\nvalidate the execution of ContextMatter in a real world scenario by deploying\nit on a TIAGo robot. Code, dataset, and supplementary materials are available\nto the community at https://lab-rococo-sapienza.github.io/context-matters/.",
    "published": "2025-06-18T19:14:56Z",
    "updated": "2025-10-08T11:45:18Z",
    "link": "http://arxiv.org/pdf/2506.15828v2.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Emanuele Musumeci",
      "Michele Brienza",
      "Francesco Argenziano",
      "Abdel Hakim Drid",
      "Vincenzo Suriani",
      "Daniele Nardi",
      "Domenico D. Bloisi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06908v1",
    "title": "Emotionally Vulnerable Subtype of Internet Gaming Disorder: Measuring\n  and Exploring the Pathology of Problematic Generative AI Use",
    "summary": "Concerns over the potential over-pathologization of generative AI (GenAI) use\nand the lack of conceptual clarity surrounding GenAI addiction call for\nempirical tools and theoretical refinement. This study developed and validated\nthe PUGenAIS-9 (Problematic Use of Generative Artificial Intelligence Scale-9\nitems) and examined whether PUGenAIS reflects addiction-like patterns under the\nInternet Gaming Disorder (IGD) framework. Using samples from China and the\nUnited States (N = 1,508), we conducted confirmatory factor analysis and\nidentified a robust 31-item structure across nine IGD-based dimensions. We then\nderived the PUGenAIS-9 by selecting the highest-loading items from each\ndimension and validated its structure in an independent sample (N = 1,426).\nMeasurement invariance tests confirmed its stability across nationality and\ngender. Person-centered (latent profile analysis) and variable-centered\n(network analysis) approaches found that PUGenAIS matches the traits of the\nemotionally vulnerable subtype of IGD, not the competence-based kind. These\nresults support using PUGenAIS-9 to identify problematic GenAI use and show the\nneed to rethink digital addiction with an ICD (infrastructures, content, and\ndevice) model. This keeps addiction research responsive to new media while\navoiding over-pathologizing.",
    "published": "2025-10-08T11:43:39Z",
    "updated": "2025-10-08T11:43:39Z",
    "link": "http://arxiv.org/pdf/2510.06908v1.pdf",
    "category": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "authors": [
      "Haocan Sun",
      "Di Wua",
      "Weizi Liu",
      "Guoming Yua",
      "Mike Yao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06907v1",
    "title": "Angular Constraint Embedding via SpherePair Loss for Constrained\n  Clustering",
    "summary": "Constrained clustering integrates domain knowledge through pairwise\nconstraints. However, existing deep constrained clustering (DCC) methods are\neither limited by anchors inherent in end-to-end modeling or struggle with\nlearning discriminative Euclidean embedding, restricting their scalability and\nreal-world applicability. To avoid their respective pitfalls, we propose a\nnovel angular constraint embedding approach for DCC, termed SpherePair. Using\nthe SpherePair loss with a geometric formulation, our method faithfully encodes\npairwise constraints and leads to embeddings that are clustering-friendly in\nangular space, effectively separating representation learning from clustering.\nSpherePair preserves pairwise relations without conflict, removes the need to\nspecify the exact number of clusters, generalizes to unseen data, enables rapid\ninference of the number of clusters, and is supported by rigorous theoretical\nguarantees. Comparative evaluations with state-of-the-art DCC methods on\ndiverse benchmarks, along with empirical validation of theoretical insights,\nconfirm its superior performance, scalability, and overall real-world\neffectiveness. Code is available at\n\\href{https://github.com/spherepaircc/SpherePairCC/tree/main}{our repository}.",
    "published": "2025-10-08T11:43:20Z",
    "updated": "2025-10-08T11:43:20Z",
    "link": "http://arxiv.org/pdf/2510.06907v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Shaojie Zhang",
      "Ke Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.05408v3",
    "title": "Tempo: Compiled Dynamic Deep Learning with Symbolic Dependence Graphs",
    "summary": "Deep learning (DL) algorithms are often defined in terms of temporal\nrelationships: a tensor at one timestep may depend on tensors from earlier or\nlater timesteps. Such dynamic dependencies (and corresponding dynamic tensor\nshapes) are difficult to express and optimize: while eager DL systems support\nsuch dynamism, they cannot apply compiler-based optimizations; graph-based\nsystems require static tensor shapes, which forces users to pad tensors or\nbreak-up programs into multiple static graphs.\n  We describe Tempo, a new DL system that combines the dynamism of eager\nexecution with the whole-program optimizations of graph-based compilation.\nTempo achieves this through a declarative programming model with recurrent\ntensors, which include explicit temporal dimensions. Temporal dimensions can be\nindexed using symbolic expressions to express dynamic dependencies on past and\nfuture tensors. Based on this, Tempo constructs a symbolic dependence graph,\nwhich concisely encodes dynamic dependencies between operators, and applies\nwhole-program optimizations, such as algebraic simplifications, vectorization,\ntiling, and fusion. By tiling dynamic dependencies into static-size blocks,\nTempo can also reuse existing static code-generators. It then uses a polyhedral\nmodel to find a feasible execution schedule, which includes memory management\noperations. We show that Tempo achieves a 7$\\times$ speedup over JAX for\nLlama-3.2-3B decoding; for reinforcement learning algorithms, Tempo achieves a\n54$\\times$ speedup, with 16$\\times$ lower peak memory usage.",
    "published": "2025-01-09T18:05:33Z",
    "updated": "2025-10-08T11:36:12Z",
    "link": "http://arxiv.org/pdf/2501.05408v3.pdf",
    "category": [
      "cs.DC",
      "cs.AI",
      "cs.LG",
      "I.2; I.1"
    ],
    "authors": [
      "Pedro F. Silvestre",
      "Peter Pietzuch"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.18824v2",
    "title": "Understanding Software Engineering Agents: A Study of\n  Thought-Action-Result Trajectories",
    "summary": "Large Language Model (LLM)-based agents are increasingly employed to automate\ncomplex software engineering tasks, such as program repair and issue\nresolution. These agents operate by autonomously generating natural language\nthoughts, invoking external tools, and iteratively refining their solutions.\nDespite their widespread adoption, the internal decision-making processes of\nthese agents remain largely unexplored, limiting our understanding of their\noperational dynamics and failure modes. In this paper, we present a large-scale\nempirical study of the thought-action-result trajectories of three\nstate-of-the-art LLM-based agents: RepairAgent, AutoCodeRover, and OpenHands.\nWe unify their interaction logs into a common format, capturing 120\ntrajectories and 2,822 LLM interactions focused on program repair and issue\nresolution. Our study combines quantitative analyses of structural properties,\naction patterns, and token usage with qualitative assessments of reasoning\ncoherence and feedback integration. We identify key trajectory characteristics,\nsuch as iteration counts and token consumption, recurring action sequences, and\nthe semantic coherence of thoughts, actions, and their results. Our findings\nreveal behavioral motifs and anti-patterns that distinguish successful from\nfailed executions, providing actionable insights for improving agent design,\nincluding prompting strategies, failure diagnosis, and anti-pattern detection.\nWe release our dataset and annotation framework to support further research on\ntransparent and robust autonomous software engineering agents.",
    "published": "2025-06-23T16:34:52Z",
    "updated": "2025-10-08T11:28:31Z",
    "link": "http://arxiv.org/pdf/2506.18824v2.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Islem Bouzenia",
      "Michael Pradel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.11031v3",
    "title": "NAR-*ICP: Neural Execution of Classical ICP-based Pointcloud\n  Registration Algorithms",
    "summary": "This study explores the intersection of neural networks and classical\nrobotics algorithms through the Neural Algorithmic Reasoning (NAR) blueprint,\nenabling the training of neural networks to reason like classical robotics\nalgorithms by learning to execute them. Algorithms are integral to robotics and\nsafety-critical applications due to their predictable and consistent\nperformance through logical and mathematical principles. In contrast, while\nneural networks are highly adaptable, handling complex, high-dimensional data\nand generalising across tasks, they often lack interpretability and\ntransparency in their internal computations. To bridge the two, we propose a\nnovel Graph Neural Network (GNN)-based framework, NAR-*ICP, that learns the\nintermediate computations of classical ICP-based registration algorithms,\nextending the CLRS Benchmark. We evaluate our approach across real-world and\nsynthetic datasets, demonstrating its flexibility in handling complex inputs,\nand its potential to be used within larger learning pipelines. Our method\nachieves superior performance compared to the baselines, even surpassing the\nalgorithms it was trained on, further demonstrating its ability to generalise\nbeyond the capabilities of traditional algorithms.",
    "published": "2024-10-14T19:33:46Z",
    "updated": "2025-10-08T11:15:48Z",
    "link": "http://arxiv.org/pdf/2410.11031v3.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Efimia Panagiotaki",
      "Daniele De Martini",
      "Lars Kunze",
      "Paul Newman",
      "Petar Veličković"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06888v1",
    "title": "M3Retrieve: Benchmarking Multimodal Retrieval for Medicine",
    "summary": "With the increasing use of RetrievalAugmented Generation (RAG), strong\nretrieval models have become more important than ever. In healthcare,\nmultimodal retrieval models that combine information from both text and images\noffer major advantages for many downstream tasks such as question answering,\ncross-modal retrieval, and multimodal summarization, since medical data often\nincludes both formats. However, there is currently no standard benchmark to\nevaluate how well these models perform in medical settings. To address this\ngap, we introduce M3Retrieve, a Multimodal Medical Retrieval Benchmark.\nM3Retrieve, spans 5 domains,16 medical fields, and 4 distinct tasks, with over\n1.2 Million text documents and 164K multimodal queries, all collected under\napproved licenses. We evaluate leading multimodal retrieval models on this\nbenchmark to explore the challenges specific to different medical specialities\nand to understand their impact on retrieval performance. By releasing\nM3Retrieve, we aim to enable systematic evaluation, foster model innovation,\nand accelerate research toward building more capable and reliable multimodal\nretrieval systems for medical applications. The dataset and the baselines code\nare available in this github page https://github.com/AkashGhosh/M3Retrieve.",
    "published": "2025-10-08T11:08:47Z",
    "updated": "2025-10-08T11:08:47Z",
    "link": "http://arxiv.org/pdf/2510.06888v1.pdf",
    "category": [
      "cs.IR",
      "cs.AI"
    ],
    "authors": [
      "Arkadeep Acharya",
      "Akash Ghosh",
      "Pradeepika Verma",
      "Kitsuchart Pasupa",
      "Sriparna Saha",
      "Priti Singh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2309.11975v2",
    "title": "Inferring Capabilities from Task Performance with Bayesian Triangulation",
    "summary": "As machine learning models become more general, we need to characterise them\nin richer, more meaningful ways. We describe a method to infer the cognitive\nprofile of a system from diverse experimental data. To do so, we introduce\nmeasurement layouts that model how task-instance features interact with system\ncapabilities to affect performance. These features must be triangulated in\ncomplex ways to be able to infer capabilities from non-populational data -- a\nchallenge for traditional psychometric and inferential tools. Using the\nBayesian probabilistic programming library PyMC, we infer different cognitive\nprofiles for agents in two scenarios: 68 actual contestants in the AnimalAI\nOlympics and 30 synthetic agents for O-PIAAGETS, an object permanence battery.\nWe showcase the potential for capability-oriented evaluation.",
    "published": "2023-09-21T11:19:26Z",
    "updated": "2025-10-08T11:05:18Z",
    "link": "http://arxiv.org/pdf/2309.11975v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "John Burden",
      "Konstantinos Voudouris",
      "Ryan Burnell",
      "Danaja Rutar",
      "Lucy Cheke",
      "José Hernández-Orallo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06882v1",
    "title": "Multi-Dimensional Autoscaling of Stream Processing Services on Edge\n  Devices",
    "summary": "Edge devices have limited resources, which inevitably leads to situations\nwhere stream processing services cannot satisfy their needs. While existing\nautoscaling mechanisms focus entirely on resource scaling, Edge devices require\nalternative ways to sustain the Service Level Objectives (SLOs) of competing\nservices. To address these issues, we introduce a Multi-dimensional Autoscaling\nPlatform (MUDAP) that supports fine-grained vertical scaling across both\nservice- and resource-level dimensions. MUDAP supports service-specific scaling\ntailored to available parameters, e.g., scale data quality or model size for a\nparticular service. To optimize the execution across services, we present a\nscaling agent based on Regression Analysis of Structural Knowledge (RASK). The\nRASK agent efficiently explores the solution space and learns a continuous\nregression model of the processing environment for inferring optimal scaling\nactions. We compared our approach with two autoscalers, the Kubernetes VPA and\na reinforcement learning agent, for scaling up to 9 services on a single Edge\ndevice. Our results showed that RASK can infer an accurate regression model in\nmerely 20 iterations (i.e., observe 200s of processing). By increasingly adding\nelasticity dimensions, RASK sustained the highest request load with 28% less\nSLO violations, compared to baselines.",
    "published": "2025-10-08T10:51:50Z",
    "updated": "2025-10-08T10:51:50Z",
    "link": "http://arxiv.org/pdf/2510.06882v1.pdf",
    "category": [
      "cs.DC",
      "cs.AI",
      "cs.LG",
      "cs.PF"
    ],
    "authors": [
      "Boris Sedlak",
      "Philipp Raith",
      "Andrea Morichetta",
      "Víctor Casamayor Pujol",
      "Schahram Dustdar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06880v1",
    "title": "MoRE-GNN: Multi-omics Data Integration with a Heterogeneous Graph\n  Autoencoder",
    "summary": "The integration of multi-omics single-cell data remains challenging due to\nhigh-dimensionality and complex inter-modality relationships. To address this,\nwe introduce MoRE-GNN (Multi-omics Relational Edge Graph Neural Network), a\nheterogeneous graph autoencoder that combines graph convolution and attention\nmechanisms to dynamically construct relational graphs directly from data.\nEvaluations on six publicly available datasets demonstrate that MoRE-GNN\ncaptures biologically meaningful relationships and outperforms existing\nmethods, particularly in settings with strong inter-modality correlations.\nFurthermore, the learned representations allow for accurate downstream\ncross-modal predictions. While performance may vary with dataset complexity,\nMoRE-GNN offers an adaptive, scalable and interpretable framework for advancing\nmulti-omics integration.",
    "published": "2025-10-08T10:48:15Z",
    "updated": "2025-10-08T10:48:15Z",
    "link": "http://arxiv.org/pdf/2510.06880v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Zhiyu Wang",
      "Sonia Koszut",
      "Pietro Liò",
      "Francesco Ceccarelli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06878v1",
    "title": "TGPR: Tree-Guided Policy Refinement for Robust Self-Debugging of LLMs",
    "summary": "Iterative refinement has been a promising paradigm to enable large language\nmodels (LLMs) to resolve difficult reasoning and problem-solving tasks. One of\nthe key challenges, however, is how to effectively search through the enormous\nsearch space of possible refinements. Existing methods typically fall back on\npredefined heuristics, which are troubled by the exploration-exploitation\ndilemma and cannot adapt based on past refinement outcomes. We introduce\nTree-Guided Policy Refinement (TGPR), a novel framework that combines GRPO with\na Thompson-Sampling-based tree search. TGPR explores both failed and successful\nrefinement paths actively, with denser training trajectories and more adaptive\npolicies. On HumanEval, MBPP, and APPS benchmarks, our method achieves up to\n+4.2 percentage points absolute improvement in pass@1 (on MBPP) and up to\n+12.51 percentage points absolute improvement in pass@10 (on APPS) compared to\na competitive GRPO baseline. Apart from debugging code, TGPR focuses on a\nprincipled approach to combining learned policies with structured search\nmethods, offering a general framework for enhancing iterative refinement and\nstateful reasoning in LLMs.",
    "published": "2025-10-08T10:47:05Z",
    "updated": "2025-10-08T10:47:05Z",
    "link": "http://arxiv.org/pdf/2510.06878v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Daria Ozerova",
      "Ekaterina Trofimova"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06868v1",
    "title": "Multi-hop Deep Joint Source-Channel Coding with Deep Hash Distillation\n  for Semantically Aligned Image Retrieval",
    "summary": "We consider image transmission via deep joint source-channel coding\n(DeepJSCC) over multi-hop additive white Gaussian noise (AWGN) channels by\ntraining a DeepJSCC encoder-decoder pair with a pre-trained deep hash\ndistillation (DHD) module to semantically cluster images, facilitating\nsecurity-oriented applications through enhanced semantic consistency and\nimproving the perceptual reconstruction quality. We train the DeepJSCC module\nto both reduce mean square error (MSE) and minimize cosine distance between DHD\nhashes of source and reconstructed images. Significantly improved perceptual\nquality as a result of semantic alignment is illustrated for different\nmulti-hop settings, for which classical DeepJSCC may suffer from noise\naccumulation, measured by the learned perceptual image patch similarity (LPIPS)\nmetric.",
    "published": "2025-10-08T10:38:24Z",
    "updated": "2025-10-08T10:38:24Z",
    "link": "http://arxiv.org/pdf/2510.06868v1.pdf",
    "category": [
      "cs.IT",
      "cs.AI",
      "cs.CR",
      "cs.LG",
      "math.IT"
    ],
    "authors": [
      "Didrik Bergström",
      "Deniz Gündüz",
      "Onur Günlü"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06860v1",
    "title": "Towards Generalization of Graph Neural Networks for AC Optimal Power\n  Flow",
    "summary": "AC Optimal Power Flow (ACOPF) is computationally expensive for large-scale\npower systems, with conventional solvers requiring prohibitive solution times.\nMachine learning approaches offer computational speedups but struggle with\nscalability and topology adaptability without expensive retraining. To enable\nscalability across grid sizes and adaptability to topology changes, we propose\na Hybrid Heterogeneous Message Passing Neural Network (HH-MPNN). HH-MPNN models\nbuses, generators, loads, shunts, transmission lines and transformers as\ndistinct node or edge types, combined with a scalable transformer model for\nhandling long-range dependencies. On grids from 14 to 2,000 buses, HH-MPNN\nachieves less than 1% optimality gap on default topologies. Applied zero-shot\nto thousands of unseen topologies, HH-MPNN achieves less than 3% optimality gap\ndespite training only on default topologies. Pre-training on smaller grids also\nimproves results on a larger grid. Computational speedups reach 1,000x to\n10,000x compared to interior point solvers. These results advance practical,\ngeneralizable machine learning for real-time power system operations.",
    "published": "2025-10-08T10:28:46Z",
    "updated": "2025-10-08T10:28:46Z",
    "link": "http://arxiv.org/pdf/2510.06860v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Olayiwola Arowolo",
      "Jochen L. Cremer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.12117v2",
    "title": "Quantum Machine Learning in Multi-Qubit Phase-Space Part I: Foundations",
    "summary": "Quantum machine learning (QML) seeks to exploit the intrinsic properties of\nquantum mechanical systems, including superposition, coherence, and quantum\nentanglement for classical data processing. However, due to the exponential\ngrowth of the Hilbert space, QML faces practical limits in classical\nsimulations with the state-vector representation of quantum system. On the\nother hand, phase-space methods offer an alternative by encoding quantum states\nas quasi-probability functions. Building on prior work in qubit phase-space and\nthe Stratonovich-Weyl (SW) correspondence, we construct a closed, composable\ndynamical formalism for one- and many-qubit systems in phase-space. This\nformalism replaces the operator algebra of the Pauli group with function\ndynamics on symplectic manifolds, and recasts the curse of dimensionality in\nterms of harmonic support on a domain that scales linearly with the number of\nqubits. It opens a new route for QML based on variational modelling over\nphase-space.",
    "published": "2025-07-16T10:37:16Z",
    "updated": "2025-10-08T10:26:16Z",
    "link": "http://arxiv.org/pdf/2507.12117v2.pdf",
    "category": [
      "quant-ph",
      "cs.AI",
      "math-ph",
      "math.MP"
    ],
    "authors": [
      "Timothy Heightman",
      "Edward Jiang",
      "Ruth Mora-Soto",
      "Maciej Lewenstein",
      "Marcin Płodzień"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06858v1",
    "title": "Explaining raw data complexity to improve satellite onboard processing",
    "summary": "With increasing processing power, deploying AI models for remote sensing\ndirectly onboard satellites is becoming feasible. However, new constraints\narise, mainly when using raw, unprocessed sensor data instead of preprocessed\nground-based products. While current solutions primarily rely on preprocessed\nsensor images, few approaches directly leverage raw data. This study\ninvestigates the effects of utilising raw data on deep learning models for\nobject detection and classification tasks. We introduce a simulation workflow\nto generate raw-like products from high-resolution L1 imagery, enabling\nsystemic evaluation. Two object detection models (YOLOv11s and YOLOX-S) are\ntrained on both raw and L1 datasets, and their performance is compared using\nstandard detection metrics and explainability tools. Results indicate that\nwhile both models perform similarly at low to medium confidence thresholds, the\nmodel trained on raw data struggles with object boundary identification at high\nconfidence levels. It suggests that adapting AI architectures with improved\ncontouring methods can enhance object detection on raw images, improving\nonboard AI for remote sensing.",
    "published": "2025-10-08T10:26:02Z",
    "updated": "2025-10-08T10:26:02Z",
    "link": "http://arxiv.org/pdf/2510.06858v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Adrien Dorise",
      "Marjorie Bellizzi",
      "Adrien Girard",
      "Benjamin Francesconi",
      "Stéphane May"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06857v1",
    "title": "Autoformalizer with Tool Feedback",
    "summary": "Autoformalization addresses the scarcity of data for Automated Theorem\nProving (ATP) by translating mathematical problems from natural language into\nformal statements. Efforts in recent work shift from directly prompting large\nlanguage models to training an end-to-end formalizer model from scratch,\nachieving remarkable advancements. However, existing formalizer still struggles\nto consistently generate valid statements that meet syntactic validity and\nsemantic consistency. To address this issue, we propose the Autoformalizer with\nTool Feedback (ATF), a novel approach that incorporates syntactic and\nconsistency information as tools into the formalization process. By integrating\nLean 4 compilers for syntax corrections and employing a multi-LLMs-as-judge\napproach for consistency validation, the model is able to adaptively refine\ngenerated statements according to the tool feedback, enhancing both syntactic\nvalidity and semantic consistency. The training of ATF involves a cold-start\nphase on synthetic tool-calling data, an expert iteration phase to improve\nformalization capabilities, and Direct Preference Optimization to alleviate\nineffective revisions. Experimental results show that ATF markedly outperforms\na range of baseline formalizer models, with its superior performance further\nvalidated by human evaluations. Subsequent analysis reveals that ATF\ndemonstrates excellent inference scaling properties. Moreover, we open-source\nNumina-ATF, a dataset containing 750K synthetic formal statements to facilitate\nadvancements in autoformalization and ATP research.",
    "published": "2025-10-08T10:25:12Z",
    "updated": "2025-10-08T10:25:12Z",
    "link": "http://arxiv.org/pdf/2510.06857v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Qi Guo",
      "Jianing Wang",
      "Jianfei Zhang",
      "Deyang Kong",
      "Xiangzhou Huang",
      "Xiangyu Xi",
      "Wei Wang",
      "Jingang Wang",
      "Xunliang Cai",
      "Shikun Zhang",
      "Wei Ye"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.18562v2",
    "title": "GIIFT: Graph-guided Inductive Image-free Multimodal Machine Translation",
    "summary": "Multimodal Machine Translation (MMT) has demonstrated the significant help of\nvisual information in machine translation. However, existing MMT methods face\nchallenges in leveraging the modality gap by enforcing rigid visual-linguistic\nalignment whilst being confined to inference within their trained multimodal\ndomains. In this work, we construct novel multimodal scene graphs to preserve\nand integrate modality-specific information and introduce GIIFT, a two-stage\nGraph-guided Inductive Image-Free MMT framework that uses a cross-modal Graph\nAttention Network adapter to learn multimodal knowledge in a unified fused\nspace and inductively generalize it to broader image-free translation domains.\nExperimental results on the Multi30K dataset of English-to-French and\nEnglish-to-German tasks demonstrate that our GIIFT surpasses existing\napproaches and achieves the state-of-the-art, even without images during\ninference. Results on the WMT benchmark show significant improvements over the\nimage-free translation baselines, demonstrating the strength of GIIFT towards\ninductive image-free inference.",
    "published": "2025-07-24T16:36:47Z",
    "updated": "2025-10-08T10:20:31Z",
    "link": "http://arxiv.org/pdf/2507.18562v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Jiafeng Xiong",
      "Yuting Zhao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06852v1",
    "title": "Enhancing Bankruptcy Prediction of Banks through Advanced Machine\n  Learning Techniques: An Innovative Approach and Analysis",
    "summary": "Context: Financial system stability is determined by the condition of the\nbanking system. A bank failure can destroy the stability of the financial\nsystem, as banks are subject to systemic risk, affecting not only individual\nbanks but also segments or the entire financial system. Calculating the\nprobability of a bank going bankrupt is one way to ensure the banking system is\nsafe and sound. Existing literature and limitations: Statistical models, such\nas Altman's Z-Score, are one of the common techniques for developing a\nbankruptcy prediction model. However, statistical methods rely on rigid and\nsometimes irrelevant assumptions, which can result in low forecast accuracy.\nNew approaches are necessary. Objective of the research: Bankruptcy models are\ndeveloped using machine learning techniques, such as logistic regression (LR),\nrandom forest (RF), and support vector machines (SVM). According to several\nstudies, machine learning is also more accurate and effective than statistical\nmethods for categorising and forecasting banking risk management. Present\nResearch: The commercial bank data are derived from the annual financial\nstatements of 44 active banks and 21 bankrupt banks in Turkey from 1994 to\n2004, and the rural bank data are derived from the quarterly financial reports\nof 43 active and 43 bankrupt rural banks in Indonesia between 2013 and 2019.\nFive rural banks in Indonesia have also been selected to demonstrate the\nfeasibility of analysing bank bankruptcy trends. Findings and implications: The\nresults of the research experiments show that RF can forecast data from\ncommercial banks with a 90% accuracy rate. Furthermore, the three machine\nlearning methods proposed accurately predict the likelihood of rural bank\nbankruptcy. Contribution and Conclusion: The proposed innovative machine\nlearning approach help to implement policies that reduce the costs of\nbankruptcy.",
    "published": "2025-10-08T10:16:10Z",
    "updated": "2025-10-08T10:16:10Z",
    "link": "http://arxiv.org/pdf/2510.06852v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Zuherman Rustam",
      "Sri Hartini",
      "Sardar M. N. Islam",
      "Fevi Novkaniza",
      "Fiftitah R. Aszhari",
      "Muhammad Rifqi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.21154v2",
    "title": "GRPO is Secretly a Process Reward Model",
    "summary": "We prove theoretically that the GRPO RL algorithm induces a non-trivial\nprocess reward model (PRM), under certain assumptions regarding within-group\noverlap of token sequences across completions. We then show empirically that\nthese assumptions are met under real-world conditions: GRPO does in fact induce\na non-trivial PRM. Leveraging the framework of GRPO-as-a-PRM, we identify a\nflaw in the GRPO objective: non-uniformly distributed process steps hinder both\nexploration and exploitation (under different conditions). We propose a simple\nmodification to the algorithm to mitigate this defect ($\\lambda$-GRPO), and\nshow that LLMs trained with $\\lambda$-GRPO achieve higher validation accuracy\nand performance on downstream reasoning tasks$-$and reach peak performance more\nrapidly$-$than LLMs trained with standard GRPO. Our results call into question\nthe advantage of costly, explicitly-defined PRMs for GRPO: we show that it is\npossible to instead leverage the hidden, built-in PRM structure within the\nvanilla GRPO algorithm to boost model performance with a negligible impact on\ntraining time and cost.",
    "published": "2025-09-25T13:40:36Z",
    "updated": "2025-10-08T10:13:42Z",
    "link": "http://arxiv.org/pdf/2509.21154v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Michael Sullivan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06847v1",
    "title": "OpenJAI-v1.0: An Open Thai Large Language Model",
    "summary": "We introduce OpenJAI-v1.0, an open-source large language model for Thai and\nEnglish, developed from the Qwen3-14B model. Our work focuses on boosting\nperformance on practical tasks through carefully curated data across three key\nuse cases: instruction following, long-context understanding, and tool use.\nEvaluation results show that OpenJAI-v1.0 improves on the capabilities of its\nbase model and outperforms other leading open-source Thai models on a diverse\nsuite of benchmarks, while avoiding catastrophic forgetting. OpenJAI-v1.0 is\npublicly released as another alternative NLP resource for the Thai AI\ncommunity.",
    "published": "2025-10-08T10:12:56Z",
    "updated": "2025-10-08T10:12:56Z",
    "link": "http://arxiv.org/pdf/2510.06847v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Pontakorn Trakuekul",
      "Attapol T. Rutherford",
      "Jullajak Karnjanaekarin",
      "Narongkorn Panitsrisit",
      "Sumana Sumanakul"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.20293v3",
    "title": "When Judgment Becomes Noise: How Design Failures in LLM Judge Benchmarks\n  Silently Undermine Validity",
    "summary": "LLM-judged benchmarks are increasingly used to evaluate complex model\nbehaviors, yet their design introduces failure modes absent in conventional\nground-truth based benchmarks. We argue that without tight objectives and\nverifiable constructions, benchmark rankings can produce high-confidence\nrankings that are in fact largely noise. We introduce two mechanisms to\ndiagnose these issues. Schematic adherence quantifies how much of a judge's\noverall verdict is explained by the explicit evaluation schema, revealing\nunexplained variance when judges deviate from their own rubric. Psychometric\nvalidity aggregates internal consistency and discriminant validity signals to\nquantify irreducible uncertainty in any benchmarking run. Applying these tools\nto Arena-Hard Auto, we find severe schema incoherence and factor collapse\nacross popular judges: for example, unexplained variance exceeding 90 percent\nfor DeepSeek-R1-32B and factor correlations above 0.93 for most criteria. We\nalso show that the ELO-style aggregation used by Arena-Hard Auto collapses and\nmasks genuine ranking uncertainty. Our results highlight design failures that\nundermine validity and offer actionable principles for building better-scoped,\nreliability-aware LLM-judged benchmarks. We released our code and dataset at\nhttps://github.com/penfever/judgment-to-noise",
    "published": "2025-09-24T16:26:47Z",
    "updated": "2025-10-08T10:11:46Z",
    "link": "http://arxiv.org/pdf/2509.20293v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Benjamin Feuer",
      "Chiung-Yi Tseng",
      "Astitwa Sarthak Lathe",
      "Oussama Elachqar",
      "John P Dickerson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06843v1",
    "title": "SID: Multi-LLM Debate Driven by Self Signals",
    "summary": "Large Language Models (LLMs) have exhibited impressive capabilities across\ndiverse application domains. Recent work has explored Multi-LLM Agent Debate\n(MAD) as a way to enhance performance by enabling multiple LLMs to discuss and\nrefine responses iteratively. Nevertheless, existing MAD methods predominantly\nfocus on utilizing external structures, such as debate graphs, using\nLLM-as-a-Judge, while neglecting the application of self signals, such as token\nlogits and attention, that arise during generation. This omission leads to\nredundant computation and potential performance degradation. In this paper, we\nshift the focus to the self signals of multi-LLM debate and introduce a\nSelf-Signals Driven Multi-LLM Debate (SID), which leverages two types of\nself-signals: model-level confidence and token-level semantic focus, to\nadaptively guide the debate process. Our approach enables high-confidence\nagents to exit early at the model level and compress the redundant debate\ncontents based on the attention mechanism. We evaluate our method on various\nLLMs and Multimodal LLMs across multiple challenging benchmarks. Experimental\nresults demonstrate that our method not only outperforms existing MAD\ntechniques in accuracy but also reduces token consumption, highlighting the\neffectiveness of utilizing self signals in enhancing both the performance and\nefficiency of multi-agent debate systems. Our code will be available\nat~\\href{https://github.com/xuhang2019/SID}{\\texttt{https://github.com/xuhang2019/SID}}.",
    "published": "2025-10-08T10:10:11Z",
    "updated": "2025-10-08T10:10:11Z",
    "link": "http://arxiv.org/pdf/2510.06843v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Xuhang Chen",
      "Zhifan Song",
      "Deyi Ji",
      "Shuo Gao",
      "Lanyun Zhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.16379v2",
    "title": "FedAGHN: Personalized Federated Learning with Attentive Graph\n  HyperNetworks",
    "summary": "Personalized Federated Learning (PFL) aims to address the statistical\nheterogeneity of data across clients by learning the personalized model for\neach client. Among various PFL approaches, the personalized aggregation-based\napproach conducts parameter aggregation in the server-side aggregation phase to\ngenerate personalized models, and focuses on learning appropriate collaborative\nrelationships among clients for aggregation. However, the collaborative\nrelationships vary in different scenarios and even at different stages of the\nFL process. To this end, we propose Personalized Federated Learning with\nAttentive Graph HyperNetworks (FedAGHN), which employs Attentive Graph\nHyperNetworks (AGHNs) to dynamically capture fine-grained collaborative\nrelationships and generate client-specific personalized initial models.\nSpecifically, AGHNs empower graphs to explicitly model the client-specific\ncollaborative relationships, construct collaboration graphs, and introduce\ntunable attentive mechanism to derive the collaboration weights, so that the\npersonalized initial models can be obtained by aggregating parameters over the\ncollaboration graphs. Extensive experiments can demonstrate the superiority of\nFedAGHN. Moreover, a series of visualizations are presented to explore the\neffectiveness of collaboration graphs learned by FedAGHN.",
    "published": "2025-01-24T10:48:30Z",
    "updated": "2025-10-08T10:08:45Z",
    "link": "http://arxiv.org/pdf/2501.16379v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Jiarui Song",
      "Yunheng Shen",
      "Chengbin Hou",
      "Pengyu Wang",
      "Jinbao Wang",
      "Ke Tang",
      "Hairong Lv"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06840v1",
    "title": "CNN-TFT explained by SHAP with multi-head attention weights for time\n  series forecasting",
    "summary": "Convolutional neural networks (CNNs) and transformer architectures offer\nstrengths for modeling temporal data: CNNs excel at capturing local patterns\nand translational invariances, while transformers effectively model long-range\ndependencies via self-attention. This paper proposes a hybrid architecture\nintegrating convolutional feature extraction with a temporal fusion transformer\n(TFT) backbone to enhance multivariate time series forecasting. The CNN module\nfirst applies a hierarchy of one-dimensional convolutional layers to distill\nsalient local patterns from raw input sequences, reducing noise and\ndimensionality. The resulting feature maps are then fed into the TFT, which\napplies multi-head attention to capture both short- and long-term dependencies\nand to weigh relevant covariates adaptively. We evaluate the CNN-TFT on a\nhydroelectric natural flow time series dataset. Experimental results\ndemonstrate that CNN-TFT outperforms well-established deep learning models,\nwith a mean absolute percentage error of up to 2.2%. The explainability of the\nmodel is obtained by a proposed Shapley additive explanations with multi-head\nattention weights (SHAP-MHAW). Our novel architecture, named CNN-TFT-SHAP-MHAW,\nis promising for applications requiring high-fidelity, multivariate time series\nforecasts, being available for future analysis at\nhttps://github.com/SFStefenon/CNN-TFT-SHAP-MHAW .",
    "published": "2025-10-08T10:08:28Z",
    "updated": "2025-10-08T10:08:28Z",
    "link": "http://arxiv.org/pdf/2510.06840v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Stefano F. Stefenon",
      "João P. Matos-Carvalho",
      "Valderi R. Q. Leithardt",
      "Kin-Choong Yow"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.11557v2",
    "title": "AC-LoRA: (Almost) Training-Free Access Control-Aware Multi-Modal LLMs",
    "summary": "Corporate LLMs are gaining traction for efficient knowledge dissemination and\nmanagement within organizations. However, as current LLMs are vulnerable to\nleaking sensitive information, it has proven difficult to apply them in\nsettings where strict access control is necessary. To this end, we design\nAC-LoRA, an end-to-end system for access control-aware corporate LLM chatbots\nthat maintains a strong information isolation guarantee. AC-LoRA maintains\nseparate LoRA adapters for permissioned datasets, along with the document\nembedding they are finetuned on. AC-LoRA retrieves a precise set of LoRA\nadapters based on the similarity score with the user query and their\npermission. This similarity score is later used to merge the responses if more\nthan one LoRA is retrieved, without requiring any additional training for LoRA\nrouting. We provide an end-to-end prototype of AC-LoRA, evaluate it on two\ndatasets, and show that AC-LoRA matches or even exceeds the performance of\nstate-of-the-art LoRA mixing techniques while providing strong isolation\nguarantees. Furthermore, we show that AC-LoRA design can be directly applied to\ndifferent modalities.",
    "published": "2025-05-15T23:19:35Z",
    "updated": "2025-10-08T10:01:30Z",
    "link": "http://arxiv.org/pdf/2505.11557v2.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Lara Magdalena Lazier",
      "Aritra Dhar",
      "Vasilije Stambolic",
      "Lukas Cavigelli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.18169v5",
    "title": "KunServe: Parameter-centric Memory Management for Efficient Memory\n  Overloading Handling in LLM Serving",
    "summary": "Serving LLMs with a cluster of GPUs is common nowadays, where the serving\nsystem must meet strict latency SLOs required by applications. However, the\nstateful nature of LLM serving requires maintaining huge states (i.e., KVCache)\nin limited GPU memory. Under spikes in real-world workloads, GPU memory can be\neasily throttled, leading to orders of magnitude higher response latency due to\nqueuing introduced by waiting for KVCache to be reclaimed. Prior\nKVCache-centric approaches handle load throttling by dropping, migrating, or\nswapping KVCache. These methods fail to release sufficient memory quickly with\nrequests still queued.\n  This paper proposes the first parameter-centric approach to handling\nthrottling by selectively dropping replicated parameters to instantly free\nmemory for requests, based on an unnoticed observation that model parameters\nare commonly replicated across GPUs for serving LLMs. With additional memory,\nall requests can be served with a larger batch without queuing. To make the\nparameter-centric approach correct and efficient, we cooperatively execute\nrequests on GPUs with a complete copy of parameters using pipeline parallelism,\nand derive an appropriate drop plan without unnecessary cooperation. We also\ndesign techniques to minimize the performance overhead due to pipeline\nparallelism with the execution patterns of requests under drop. Evaluations\nshow that {\\sys} reduces the tail TTFT of requests under throttling by up to\n72.2 times compared to the state-of-the-art systems including Llumnix, vLLM and\nInferCept.",
    "published": "2024-12-24T05:07:46Z",
    "updated": "2025-10-08T10:01:01Z",
    "link": "http://arxiv.org/pdf/2412.18169v5.pdf",
    "category": [
      "cs.DC",
      "cs.AI"
    ],
    "authors": [
      "Rongxin Cheng",
      "Yuxin Lai",
      "Xingda Wei",
      "Rong Chen",
      "Haibo Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06828v1",
    "title": "Recurrence-Complete Frame-based Action Models",
    "summary": "In recent years, attention-like mechanisms have been used to great success in\nthe space of large language models, unlocking scaling potential to a previously\nunthinkable extent. \"Attention Is All You Need\" famously claims RNN cells are\nnot needed in conjunction with attention. We challenge this view. In this\npaper, we point to existing proofs that architectures with fully parallelizable\nforward or backward passes cannot represent classes of problems specifically\ninteresting for long-running agentic tasks. We further conjecture a critical\ntime t beyond which non-recurrence-complete models fail to aggregate inputs\ncorrectly, with concrete implications for agentic systems (e.g., software\nengineering agents). To address this, we introduce a recurrence-complete\narchitecture and train it on GitHub-derived action sequences. Loss follows a\npower law in the trained sequence length while the parameter count remains\nfixed. Moreover, longer-sequence training always amortizes its linearly\nincreasing wall-time cost, yielding lower loss as a function of wall time.",
    "published": "2025-10-08T09:50:41Z",
    "updated": "2025-10-08T09:50:41Z",
    "link": "http://arxiv.org/pdf/2510.06828v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Michael Keiblinger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.23867v3",
    "title": "InfiMed: Low-Resource Medical MLLMs with Advancing Understanding and\n  Reasoning",
    "summary": "Multimodal Large Language Models (MLLMs) have achieved remarkable progress in\ndomains such as visual understanding and mathematical reasoning. However, their\napplication in the medical domain is constrained by two key challenges: (1)\nmultimodal medical datasets are scarce and often contain sparse information,\nlimiting reasoning depth; and (2) Reinforcement Learning with Verifiable\nRewards (RLVR), though effective in general domains, cannot reliably improve\nmodel performance in the medical domain. To overcome these challenges, during\nthe supervised fine-tuning (SFT) stage, we incorporate high-quality textual\nreasoning data and general multimodal data alongside multimodal medical data to\nefficiently enhance foundational medical capabilities and restore the base\nmodel's reasoning ability. Moreover, considering that there are some multimodal\nmedical datasets with sparse information, we further synthesize\nreflective-pattern-injected chain-of-thought (CoT) in addition to general CoT\nsamples, equipping the model with initial reflective reasoning capabilities\nthat provide a structured foundation for subsequent RLVR training. Finally, we\nintroduce our InfiMed-Series models, InfiMed-SFT-3B and InfiMed-RL-3B, both of\nwhich deliver state-of-the-art performance across seven multimodal medical\nbenchmarks. Notably, InfiMed-RL-3B achieves an average accuracy of 59.2%,\noutperforming even larger models like InternVL3-8B, which achieves 57.3%.\nSpecifically, during the SFT phase, we utilized 188K samples, while the RLVR\nphase incorporated 36K samples, demonstrating the efficacy of both training\nstrategies in achieving superior performance. We also conducted a series of\nextensive experiments, which provide valuable insights that contribute to\nadvancing the performance of MLLMs in medical scenarios.",
    "published": "2025-05-29T10:31:57Z",
    "updated": "2025-10-08T09:46:14Z",
    "link": "http://arxiv.org/pdf/2505.23867v3.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Zeyu Liu",
      "Zhitian Hou",
      "Guanghao Zhu",
      "Zhijie Sang",
      "Congkai Xie",
      "Hongxia Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.13590v2",
    "title": "Intelligent Healthcare Imaging Platform: A VLM-Based Framework for\n  Automated Medical Image Analysis and Clinical Report Generation",
    "summary": "The rapid advancement of artificial intelligence (AI) in healthcare imaging\nhas revolutionized diagnostic medicine and clinical decision-making processes.\nThis work presents an intelligent multimodal framework for medical image\nanalysis that leverages Vision-Language Models (VLMs) in healthcare\ndiagnostics. The framework integrates Google Gemini 2.5 Flash for automated\ntumor detection and clinical report generation across multiple imaging\nmodalities including CT, MRI, X-ray, and Ultrasound. The system combines visual\nfeature extraction with natural language processing to enable contextual image\ninterpretation, incorporating coordinate verification mechanisms and\nprobabilistic Gaussian modeling for anomaly distribution. Multi-layered\nvisualization techniques generate detailed medical illustrations, overlay\ncomparisons, and statistical representations to enhance clinical confidence,\nwith location measurement achieving 80 pixels average deviation. Result\nprocessing utilizes precise prompt engineering and textual analysis to extract\nstructured clinical information while maintaining interpretability.\nExperimental evaluations demonstrated high performance in anomaly detection\nacross multiple modalities. The system features a user-friendly Gradio\ninterface for clinical workflow integration and demonstrates zero-shot learning\ncapabilities to reduce dependence on large datasets. This framework represents\na significant advancement in automated diagnostic support and radiological\nworkflow efficiency, though clinical validation and multi-center evaluation are\nnecessary prior to widespread adoption.",
    "published": "2025-09-16T23:15:44Z",
    "updated": "2025-10-08T09:41:31Z",
    "link": "http://arxiv.org/pdf/2509.13590v2.pdf",
    "category": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Samer Al-Hamadani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2403.03881v4",
    "title": "Unlocking Dataset Distillation with Diffusion Models",
    "summary": "Dataset distillation seeks to condense datasets into smaller but highly\nrepresentative synthetic samples. While diffusion models now lead all\ngenerative benchmarks, current distillation methods avoid them and rely instead\non GANs or autoencoders, or, at best, sampling from a fixed diffusion prior.\nThis trend arises because naive backpropagation through the long denoising\nchain leads to vanishing gradients, which prevents effective synthetic sample\noptimization. To address this limitation, we introduce Latent Dataset\nDistillation with Diffusion Models (LD3M), the first method to learn\ngradient-based distilled latents and class embeddings end-to-end through a\npre-trained latent diffusion model. A linearly decaying skip connection,\ninjected from the initial noisy state into every reverse step, preserves the\ngradient signal across dozens of timesteps without requiring diffusion weight\nfine-tuning. Across multiple ImageNet subsets at 128x128 and 256x256, LD3M\nimproves downstream accuracy by up to 4.8 percentage points (1 IPC) and 4.2\npoints (10 IPC) over the prior state-of-the-art. The code for LD3M is provided\nat https://github.com/Brian-Moser/prune_and_distill.",
    "published": "2024-03-06T17:41:41Z",
    "updated": "2025-10-08T09:38:25Z",
    "link": "http://arxiv.org/pdf/2403.03881v4.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Brian B. Moser",
      "Federico Raue",
      "Sebastian Palacio",
      "Stanislav Frolov",
      "Andreas Dengel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.04759v2",
    "title": "Progressive Gaussian Transformer with Anisotropy-aware Sampling for Open\n  Vocabulary Occupancy Prediction",
    "summary": "The 3D occupancy prediction task has witnessed remarkable progress in recent\nyears, playing a crucial role in vision-based autonomous driving systems. While\ntraditional methods are limited to fixed semantic categories, recent approaches\nhave moved towards predicting text-aligned features to enable open-vocabulary\ntext queries in real-world scenes. However, there exists a trade-off in\ntext-aligned scene modeling: sparse Gaussian representation struggles to\ncapture small objects in the scene, while dense representation incurs\nsignificant computational overhead. To address these limitations, we present\nPG-Occ, an innovative Progressive Gaussian Transformer Framework that enables\nopen-vocabulary 3D occupancy prediction. Our framework employs progressive\nonline densification, a feed-forward strategy that gradually enhances the 3D\nGaussian representation to capture fine-grained scene details. By iteratively\nenhancing the representation, the framework achieves increasingly precise and\ndetailed scene understanding. Another key contribution is the introduction of\nan anisotropy-aware sampling strategy with spatio-temporal fusion, which\nadaptively assigns receptive fields to Gaussians at different scales and\nstages, enabling more effective feature aggregation and richer scene\ninformation capture. Through extensive evaluations, we demonstrate that PG-Occ\nachieves state-of-the-art performance with a relative 14.3% mIoU improvement\nover the previous best performing method. Code and pretrained models will be\nreleased upon publication on our project page:\nhttps://yanchi-3dv.github.io/PG-Occ",
    "published": "2025-10-06T12:36:07Z",
    "updated": "2025-10-08T09:34:48Z",
    "link": "http://arxiv.org/pdf/2510.04759v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Chi Yan",
      "Dan Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06800v1",
    "title": "FURINA: A Fully Customizable Role-Playing Benchmark via Scalable\n  Multi-Agent Collaboration Pipeline",
    "summary": "As large language models (LLMs) advance in role-playing (RP) tasks, existing\nbenchmarks quickly become obsolete due to their narrow scope, outdated\ninteraction paradigms, and limited adaptability across diverse application\nscenarios. To address this gap, we introduce FURINA-Builder, a novel\nmulti-agent collaboration pipeline that automatically constructs fully\ncustomizable RP benchmarks at any scale. It enables evaluation of arbitrary\ncharacters across diverse scenarios and prompt formats, as the first benchmark\nbuilder in RP area for adaptable assessment. FURINA-Builder simulates dialogues\nbetween a test character and other characters drawn from a well-constructed\ncharacter-scene pool, while an LLM judge selects fine-grained evaluation\ndimensions and adjusts the test character's responses into final test\nutterances. Using this pipeline, we build FURINA-Bench, a new comprehensive\nrole-playing benchmark featuring both established and synthesized test\ncharacters, each assessed with dimension-specific evaluation criteria. Human\nevaluation and preliminary separability analysis justify our pipeline and\nbenchmark design. We conduct extensive evaluations of cutting-edge LLMs and\nfind that o3 and DeepSeek-R1 achieve the best performance on English and\nChinese RP tasks, respectively. Across all models, established characters\nconsistently outperform synthesized ones, with reasoning capabilities further\namplifying this disparity. Interestingly, we observe that model scale does not\nmonotonically reduce hallucinations. More critically, for reasoning LLMs, we\nuncover a novel trade-off: reasoning improves RP performance but simultaneously\nincreases RP hallucinations. This trade-off extends to a broader Pareto\nfrontier between RP performance and reliability for all LLMs. These findings\ndemonstrate the effectiveness of FURINA-Builder and the challenge posed by\nFURINA-Bench.",
    "published": "2025-10-08T09:30:36Z",
    "updated": "2025-10-08T09:30:36Z",
    "link": "http://arxiv.org/pdf/2510.06800v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.MA"
    ],
    "authors": [
      "Haotian Wu",
      "Shufan Jiang",
      "Chios Chen",
      "Yiyang Feng",
      "Hehai Lin",
      "Heqing Zou",
      "Yao Shu",
      "Yanran Li",
      "Chengwei Qin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.07344v5",
    "title": "Generative Pre-trained Autoregressive Diffusion Transformer",
    "summary": "In this work, we present GPDiT, a Generative Pre-trained Autoregressive\nDiffusion Transformer that unifies the strengths of diffusion and\nautoregressive modeling for long-range video synthesis, within a continuous\nlatent space. Instead of predicting discrete tokens, GPDiT autoregressively\npredicts future latent frames using a diffusion loss, enabling natural modeling\nof motion dynamics and semantic consistency across frames. This continuous\nautoregressive framework not only enhances generation quality but also endows\nthe model with representation capabilities. Additionally, we introduce a\nlightweight causal attention variant and a parameter-free rotation-based\ntime-conditioning mechanism, improving both the training and inference\nefficiency. Extensive experiments demonstrate that GPDiT achieves strong\nperformance in video generation quality, video representation ability, and\nfew-shot learning tasks, highlighting its potential as an effective framework\nfor video modeling in continuous space.",
    "published": "2025-05-12T08:32:39Z",
    "updated": "2025-10-08T09:22:25Z",
    "link": "http://arxiv.org/pdf/2505.07344v5.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Yuan Zhang",
      "Jiacheng Jiang",
      "Guoqing Ma",
      "Zhiying Lu",
      "Haoyang Huang",
      "Jianlong Yuan",
      "Nan Duan",
      "Daxin Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06791v1",
    "title": "Extreme Amodal Face Detection",
    "summary": "Extreme amodal detection is the task of inferring the 2D location of objects\nthat are not fully visible in the input image but are visible within an\nexpanded field-of-view. This differs from amodal detection, where the object is\npartially visible within the input image, but is occluded. In this paper, we\nconsider the sub-problem of face detection, since this class provides\nmotivating applications involving safety and privacy, but do not tailor our\nmethod specifically to this class. Existing approaches rely on image sequences\nso that missing detections may be interpolated from surrounding frames or make\nuse of generative models to sample possible completions. In contrast, we\nconsider the single-image task and propose a more efficient, sample-free\napproach that makes use of the contextual cues from the image to infer the\npresence of unseen faces. We design a heatmap-based extreme amodal object\ndetector that addresses the problem of efficiently predicting a lot (the\nout-of-frame region) from a little (the image) with a selective coarse-to-fine\ndecoder. Our method establishes strong results for this new task, even\noutperforming less efficient generative approaches.",
    "published": "2025-10-08T09:22:03Z",
    "updated": "2025-10-08T09:22:03Z",
    "link": "http://arxiv.org/pdf/2510.06791v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Changlin Song",
      "Yunzhong Hou",
      "Michael Randall Barnes",
      "Rahul Shome",
      "Dylan Campbell"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2211.04774v6",
    "title": "IRNet: Iterative Refinement Network for Noisy Partial Label Learning",
    "summary": "Partial label learning (PLL) is a typical weakly supervised learning, where\neach sample is associated with a set of candidate labels. Its basic assumption\nis that the ground-truth label must be in the candidate set, but this\nassumption may not be satisfied due to the unprofessional judgment of\nannotators. Therefore, we relax this assumption and focus on a more general\ntask, noisy PLL, where the ground-truth label may not exist in the candidate\nset. To address this challenging task, we propose a novel framework called\n``Iterative Refinement Network (IRNet)'', aiming to purify noisy samples\nthrough two key modules (i.e., noisy sample detection and label correction). To\nachieve better performance, we exploit smoothness constraints to reduce\nprediction errors in these modules. Through theoretical analysis, we prove that\nIRNet is able to reduce the noise level of the dataset and eventually\napproximate the Bayes optimal classifier. Meanwhile, IRNet is a plug-in\nstrategy that can be integrated with existing PLL approaches. Experimental\nresults on multiple benchmark datasets show that IRNet outperforms\nstate-of-the-art approaches on noisy PLL. Our source code is available at:\nhttps://github.com/zeroQiaoba/IRNet.",
    "published": "2022-11-09T10:01:25Z",
    "updated": "2025-10-08T09:10:25Z",
    "link": "http://arxiv.org/pdf/2211.04774v6.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Zheng Lian",
      "Mingyu Xu",
      "Lan Chen",
      "Licai Sun",
      "Bin Liu",
      "Lei Feng",
      "Jianhua Tao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.08127v4",
    "title": "Evil twins are not that evil: Qualitative insights into\n  machine-generated prompts",
    "summary": "It has been widely observed that language models (LMs) respond in predictable\nways to algorithmically generated prompts that are seemingly unintelligible.\nThis is both a sign that we lack a full understanding of how LMs work, and a\npractical challenge, because opaqueness can be exploited for harmful uses of\nLMs, such as jailbreaking. We present the first thorough analysis of opaque\nmachine-generated prompts, or autoprompts, pertaining to 6 LMs of different\nsizes and families. We find that machine-generated prompts are characterized by\na last token that is often intelligible and strongly affects the generation. A\nsmall but consistent proportion of the previous tokens are prunable, probably\nappearing in the prompt as a by-product of the fact that the optimization\nprocess fixes the number of tokens. The remaining tokens fall into two\ncategories: filler tokens, which can be replaced with semantically unrelated\nsubstitutes, and keywords, that tend to have at least a loose semantic relation\nwith the generation, although they do not engage in well-formed syntactic\nrelations with it. Additionally, human experts can reliably identify the most\ninfluential tokens in an autoprompt a posteriori, suggesting these prompts are\nnot entirely opaque. Finally, some of the ablations we applied to autoprompts\nyield similar effects in natural language inputs, suggesting that autoprompts\nemerge naturally from the way LMs process linguistic inputs in general.",
    "published": "2024-12-11T06:22:44Z",
    "updated": "2025-10-08T09:07:59Z",
    "link": "http://arxiv.org/pdf/2412.08127v4.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Nathanaël Carraz Rakotonirina",
      "Corentin Kervadec",
      "Francesca Franzon",
      "Marco Baroni"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06780v1",
    "title": "Foundations of LLM Knowledge Materialization: Termination,\n  Reproducibility, Robustness",
    "summary": "Large Language Models (LLMs) encode substantial factual knowledge, yet\nmeasuring and systematizing this knowledge remains challenging. Converting it\ninto structured format, for example through recursive extraction approaches\nsuch as the GPTKB methodology (Hu et al., 2025b), is still underexplored. Key\nopen questions include whether such extraction can terminate, whether its\noutputs are reproducible, and how robust they are to variations. We\nsystematically study LLM knowledge materialization using miniGPTKBs\n(domain-specific, tractable subcrawls), analyzing termination, reproducibility,\nand robustness across three categories of metrics: yield, lexical similarity,\nand semantic similarity. We experiment with four variations (seed, language,\nrandomness, model) and three illustrative domains (from history, entertainment,\nand finance). Our findings show (i) high termination rates, though\nmodel-dependent; (ii) mixed reproducibility; and (iii) robustness that varies\nby perturbation type: high for seeds and temperature, lower for languages and\nmodels. These results suggest that LLM knowledge materialization can reliably\nsurface core knowledge, while also revealing important limitations.",
    "published": "2025-10-08T09:03:58Z",
    "updated": "2025-10-08T09:03:58Z",
    "link": "http://arxiv.org/pdf/2510.06780v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Luca Giordano",
      "Simon Razniewski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.08333v3",
    "title": "Token-based Audio Inpainting via Discrete Diffusion",
    "summary": "Audio inpainting seeks to restore missing segments in degraded recordings.\nPrevious diffusion-based methods exhibit impaired performance when the missing\nregion is large. We introduce the first approach that applies discrete\ndiffusion over tokenized music representations from a pre-trained audio\ntokenizer, enabling stable and semantically coherent restoration of long gaps.\nOur method further incorporates two training approaches: a derivative-based\nregularization loss that enforces smooth temporal dynamics, and a span-based\nabsorbing transition that provides structured corruption during diffusion.\nExperiments on the MusicNet and MAESTRO datasets with gaps up to 750 ms show\nthat our approach consistently outperforms strong baselines across range of gap\nlengths, for gaps of 150 ms and above. This work advances musical audio\nrestoration and introduces new directions for discrete diffusion model\ntraining. Audio examples of our proposed method can be found at\nhttps://iftach21.github.io/.",
    "published": "2025-07-11T06:25:49Z",
    "updated": "2025-10-08T09:01:13Z",
    "link": "http://arxiv.org/pdf/2507.08333v3.pdf",
    "category": [
      "cs.SD",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "eess.AS",
      "math.IT"
    ],
    "authors": [
      "Tali Dror",
      "Iftach Shoham",
      "Moshe Buchris",
      "Oren Gal",
      "Haim Permuter",
      "Gilad Katz",
      "Eliya Nachmani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06776v1",
    "title": "Modeling COVID-19 Dynamics in German States Using Physics-Informed\n  Neural Networks",
    "summary": "The COVID-19 pandemic has highlighted the need for quantitative modeling and\nanalysis to understand real-world disease dynamics. In particular, post hoc\nanalyses using compartmental models offer valuable insights into the\neffectiveness of public health interventions, such as vaccination strategies\nand containment policies. However, such compartmental models like SIR\n(Susceptible-Infectious-Recovered) often face limitations in directly\nincorporating noisy observational data. In this work, we employ\nPhysics-Informed Neural Networks (PINNs) to solve the inverse problem of the\nSIR model using infection data from the Robert Koch Institute (RKI). Our main\ncontribution is a fine-grained, spatio-temporal analysis of COVID-19 dynamics\nacross all German federal states over a three-year period. We estimate\nstate-specific transmission and recovery parameters and time-varying\nreproduction number (R_t) to track the pandemic progression. The results\nhighlight strong variations in transmission behavior across regions, revealing\ncorrelations with vaccination uptake and temporal patterns associated with\nmajor pandemic phases. Our findings demonstrate the utility of PINNs in\nlocalized, long-term epidemiological modeling.",
    "published": "2025-10-08T08:59:39Z",
    "updated": "2025-10-08T08:59:39Z",
    "link": "http://arxiv.org/pdf/2510.06776v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Phillip Rothenbeck",
      "Sai Karthikeya Vemuri",
      "Niklas Penzel",
      "Joachim Denzler"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06761v1",
    "title": "Evolving and Executing Research Plans via Double-Loop Multi-Agent\n  Collaboration",
    "summary": "Automating the end-to-end scientific research process poses a fundamental\nchallenge: it requires both evolving high-level plans that are novel and sound,\nand executing these plans correctly amidst dynamic and uncertain conditions. To\naddress this bilevel challenge, we propose a novel Double-Loop Multi-Agent\n(DLMA) framework to solve the given research problem automatically. The leader\nloop, composed of professor agents, is responsible for evolving research plans.\nIt employs an evolutionary algorithm through involvement, improvement, and\nintegration meetings to iteratively generate and refine a pool of research\nproposals, exploring the solution space effectively. The follower loop,\ncomposed of doctoral student agents, is responsible for executing the\nbest-evolved plan. It dynamically adjusts the plan during implementation via\npre-hoc and post-hoc meetings, ensuring each step (e.g., drafting, coding) is\nwell-supported by contextual and external observations. Extensive experiments\non benchmarks like ACLAward and Laboratory show that DLMA generates research\npapers that achieve state-of-the-art scores in automated evaluation,\nsignificantly outperforming strong baselines. Ablation studies confirm the\ncritical roles of both loops, with evolution driving novelty and execution\nensuring soundness.",
    "published": "2025-10-08T08:40:58Z",
    "updated": "2025-10-08T08:40:58Z",
    "link": "http://arxiv.org/pdf/2510.06761v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Zhi Zhang",
      "Yan Liu",
      "Zhejing Hu",
      "Gong Chen",
      "Sheng-hua Zhong",
      "Jiannong Cao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06756v1",
    "title": "Verifying Memoryless Sequential Decision-making of Large Language Models",
    "summary": "We introduce a tool for rigorous and automated verification of large language\nmodel (LLM)- based policies in memoryless sequential decision-making tasks.\nGiven a Markov decision process (MDP) representing the sequential\ndecision-making task, an LLM policy, and a safety requirement expressed as a\nPCTL formula, our approach incrementally constructs only the reachable portion\nof the MDP guided by the LLM's chosen actions. Each state is encoded as a\nnatural language prompt, the LLM's response is parsed into an action, and\nreachable successor states by the policy are expanded. The resulting formal\nmodel is checked with Storm to determine whether the policy satisfies the\nspecified safety property. In experiments on standard grid world benchmarks, we\nshow that open source LLMs accessed via Ollama can be verified when\ndeterministically seeded, but generally underperform deep reinforcement\nlearning baselines. Our tool natively integrates with Ollama and supports\nPRISM-specified tasks, enabling continuous benchmarking in user-specified\nsequential decision-making tasks and laying a practical foundation for formally\nverifying increasingly capable LLMs.",
    "published": "2025-10-08T08:31:48Z",
    "updated": "2025-10-08T08:31:48Z",
    "link": "http://arxiv.org/pdf/2510.06756v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Dennis Gross",
      "Helge Spieker",
      "Arnaud Gotlieb"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.17518v2",
    "title": "Achieving Hyperbolic-Like Expressiveness with Arbitrary Euclidean\n  Regions: A New Approach to Hierarchical Embeddings",
    "summary": "Hierarchical data is common in many domains like life sciences and\ne-commerce, and its embeddings often play a critical role. While hyperbolic\nembeddings offer a theoretically grounded approach to representing hierarchies\nin low-dimensional spaces, current methods often rely on specific geometric\nconstructs as embedding candidates. This reliance limits their generalizability\nand makes it difficult to integrate with techniques that model semantic\nrelationships beyond pure hierarchies, such as ontology embeddings. In this\npaper, we present RegD, a flexible Euclidean framework that supports the use of\narbitrary geometric regions -- such as boxes and balls -- as embedding\nrepresentations. Although RegD operates entirely in Euclidean space, we\nformally prove that it achieves hyperbolic-like expressiveness by incorporating\na depth-based dissimilarity between regions, enabling it to emulate key\nproperties of hyperbolic geometry, including exponential growth. Our empirical\nevaluation on diverse real-world datasets shows consistent performance gains\nover state-of-the-art methods and demonstrates RegD's potential for broader\napplications such as the ontology embedding task that goes beyond hierarchy.",
    "published": "2025-01-29T09:44:03Z",
    "updated": "2025-10-08T08:26:07Z",
    "link": "http://arxiv.org/pdf/2501.17518v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Hui Yang",
      "Jiaoyan Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2406.15222v5",
    "title": "A Deep Learning System for Rapid and Accurate Warning of Acute Aortic\n  Syndrome on Non-contrast CT in China",
    "summary": "The accurate and timely diagnosis of acute aortic syndromes (AAS) in patients\npresenting with acute chest pain remains a clinical challenge. Aortic CT\nangiography (CTA) is the imaging protocol of choice in patients with suspected\nAAS. However, due to economic and workflow constraints in China, the majority\nof suspected patients initially undergo non-contrast CT as the initial imaging\ntesting, and CTA is reserved for those at higher risk. In this work, we present\nan artificial intelligence-based warning system, iAorta, using non-contrast CT\nfor AAS identification in China, which demonstrates remarkably high accuracy\nand provides clinicians with interpretable warnings. iAorta was evaluated\nthrough a comprehensive step-wise study. In the multi-center retrospective\nstudy (n = 20,750), iAorta achieved a mean area under the receiver operating\ncurve (AUC) of 0.958 (95% CI 0.950-0.967). In the large-scale real-world study\n(n = 137,525), iAorta demonstrated consistently high performance across various\nnon-contrast CT protocols, achieving a sensitivity of 0.913-0.942 and a\nspecificity of 0.991-0.993. In the prospective comparative study (n = 13,846),\niAorta demonstrated the capability to significantly shorten the time to correct\ndiagnostic pathway. For the prospective pilot deployment that we conducted,\niAorta correctly identified 21 out of 22 patients with AAS among 15,584\nconsecutive patients presenting with acute chest pain and under non-contrast CT\nprotocol in the emergency department (ED) and enabled the average diagnostic\ntime of these 21 AAS positive patients to be 102.1 (75-133) mins. Last, the\niAorta can help avoid delayed or missed diagnosis of AAS in settings where\nnon-contrast CT remains the unavoidable the initial or only imaging test in\nresource-constrained regions and in patients who cannot or did not receive\nintravenous contrast.",
    "published": "2024-06-14T02:15:09Z",
    "updated": "2025-10-08T08:24:10Z",
    "link": "http://arxiv.org/pdf/2406.15222v5.pdf",
    "category": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Yujian Hu",
      "Yilang Xiang",
      "Yan-Jie Zhou",
      "Yangyan He",
      "Dehai Lang",
      "Shifeng Yang",
      "Xiaolong Du",
      "Chunlan Den",
      "Youyao Xu",
      "Gaofeng Wang",
      "Zhengyao Ding",
      "Jingyong Huang",
      "Wenjun Zhao",
      "Xuejun Wu",
      "Donglin Li",
      "Qianqian Zhu",
      "Zhenjiang Li",
      "Chenyang Qiu",
      "Ziheng Wu",
      "Yunjun He",
      "Chen Tian",
      "Yihui Qiu",
      "Zuodong Lin",
      "Xiaolong Zhang",
      "Yuan He",
      "Zhenpeng Yuan",
      "Xiaoxiang Zhou",
      "Rong Fan",
      "Ruihan Chen",
      "Wenchao Guo",
      "Jianpeng Zhang",
      "Tony C. W. Mok",
      "Zi Li",
      "Mannudeep K. Kalra",
      "Le Lu",
      "Wenbo Xiao",
      "Xiaoqiang Li",
      "Yun Bian",
      "Chengwei Shao",
      "Guofu Wang",
      "Wei Lu",
      "Zhengxing Huang",
      "Minfeng Xu",
      "Hongkun Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.24031v2",
    "title": "GPS-MTM: Capturing Pattern of Normalcy in GPS-Trajectories with\n  self-supervised learning",
    "summary": "Foundation models have driven remarkable progress in text, vision, and video\nunderstanding, and are now poised to unlock similar breakthroughs in trajectory\nmodeling. We introduce the GPSMasked Trajectory Transformer (GPS-MTM), a\nfoundation model for large-scale mobility data that captures patterns of\nnormalcy in human movement. Unlike prior approaches that flatten trajectories\ninto coordinate streams, GPS-MTM decomposes mobility into two complementary\nmodalities: states (point-of-interest categories) and actions (agent\ntransitions). Leveraging a bi-directional Transformer with a self-supervised\nmasked modeling objective, the model reconstructs missing segments across\nmodalities, enabling it to learn rich semantic correlations without manual\nlabels. Across benchmark datasets, including Numosim-LA, Urban Anomalies, and\nGeolife, GPS-MTM consistently outperforms on downstream tasks such as\ntrajectory infilling and next-stop prediction. Its advantages are most\npronounced in dynamic tasks (inverse and forward dynamics), where contextual\nreasoning is critical. These results establish GPS-MTM as a robust foundation\nmodel for trajectory analytics, positioning mobility data as a first-class\nmodality for large-scale representation learning. Code is released for further\nreference.",
    "published": "2025-09-28T19:00:50Z",
    "updated": "2025-10-08T08:21:22Z",
    "link": "http://arxiv.org/pdf/2509.24031v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.MA"
    ],
    "authors": [
      "Umang Garg",
      "Bowen Zhang",
      "Anantajit Subrahmanya",
      "Chandrakanth Gudavalli",
      "BS Manjunath"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.05942v2",
    "title": "EvalMORAAL: Interpretable Chain-of-Thought and LLM-as-Judge Evaluation\n  for Moral Alignment in Large Language Models",
    "summary": "We present EvalMORAAL, a transparent chain-of-thought (CoT) framework that\nuses two scoring methods (log-probabilities and direct ratings) plus a\nmodel-as-judge peer review to evaluate moral alignment in 20 large language\nmodels. We assess models on the World Values Survey (55 countries, 19 topics)\nand the PEW Global Attitudes Survey (39 countries, 8 topics). With EvalMORAAL,\ntop models align closely with survey responses (Pearson's r approximately 0.90\non WVS). Yet we find a clear regional difference: Western regions average\nr=0.82 while non-Western regions average r=0.61 (a 0.21 absolute gap),\nindicating consistent regional bias. Our framework adds three parts: (1) two\nscoring methods for all models to enable fair comparison, (2) a structured\nchain-of-thought protocol with self-consistency checks, and (3) a\nmodel-as-judge peer review that flags 348 conflicts using a data-driven\nthreshold. Peer agreement relates to survey alignment (WVS r=0.74, PEW r=0.39,\nboth p<.001), supporting automated quality checks. These results show real\nprogress toward culture-aware AI while highlighting open challenges for use\nacross regions.",
    "published": "2025-10-07T13:52:16Z",
    "updated": "2025-10-08T08:03:38Z",
    "link": "http://arxiv.org/pdf/2510.05942v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Hadi Mohammadi",
      "Anastasia Giachanou",
      "Ayoub Bagheri"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06743v1",
    "title": "Evaluating LLMs for Historical Document OCR: A Methodological Framework\n  for Digital Humanities",
    "summary": "Digital humanities scholars increasingly use Large Language Models for\nhistorical document digitization, yet lack appropriate evaluation frameworks\nfor LLM-based OCR. Traditional metrics fail to capture temporal biases and\nperiod-specific errors crucial for historical corpus creation. We present an\nevaluation methodology for LLM-based historical OCR, addressing contamination\nrisks and systematic biases in diplomatic transcription. Using 18th-century\nRussian Civil font texts, we introduce novel metrics including Historical\nCharacter Preservation Rate (HCPR) and Archaic Insertion Rate (AIR), alongside\nprotocols for contamination control and stability testing. We evaluate 12\nmultimodal LLMs, finding that Gemini and Qwen models outperform traditional OCR\nwhile exhibiting over-historicization: inserting archaic characters from\nincorrect historical periods. Post-OCR correction degrades rather than improves\nperformance. Our methodology provides digital humanities practitioners with\nguidelines for model selection and quality assessment in historical corpus\ndigitization.",
    "published": "2025-10-08T08:01:40Z",
    "updated": "2025-10-08T08:01:40Z",
    "link": "http://arxiv.org/pdf/2510.06743v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "68T50"
    ],
    "authors": [
      "Maria Levchenko"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.15098v2",
    "title": "TextMine: Data, Evaluation Framework and Ontology-guided LLM Pipeline\n  for Humanitarian Mine Action",
    "summary": "Humanitarian Mine Action (HMA) addresses the challenge of detecting and\nremoving landmines from conflict regions. Much of the life-saving operational\nknowledge produced by HMA agencies is buried in unstructured reports, limiting\nthe transferability of information between agencies. To address this issue, we\npropose TextMine: the first dataset, evaluation framework and ontology-guided\nlarge language model (LLM) pipeline for knowledge extraction in the HMA domain.\nTextMine structures HMA reports into (subject, relation, object)-triples, thus\ncreating domain-specific knowledge. To ensure real-world relevance, we created\nthe dataset in collaboration with Cambodian Mine Action Center (CMAC). We\nfurther introduce a bias-aware evaluation framework that combines\nhuman-annotated triples with an LLM-as-Judge protocol to mitigate position bias\nin reference-free scoring. Our experiments show that ontology-aligned prompts\nimprove extraction accuracy by up to 44.2%, reduce hallucinations by 22.5%, and\nenhance format adherence by 20.9% compared to baseline models. We publicly\nrelease the dataset and code.",
    "published": "2025-09-18T15:55:19Z",
    "updated": "2025-10-08T08:00:00Z",
    "link": "http://arxiv.org/pdf/2509.15098v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Chenyue Zhou",
      "Gürkan Solmaz",
      "Flavio Cirillo",
      "Kiril Gashteovski",
      "Jonathan Fürst"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06742v1",
    "title": "MultiCNKG: Integrating Cognitive Neuroscience, Gene, and Disease\n  Knowledge Graphs Using Large Language Models",
    "summary": "The advent of large language models (LLMs) has revolutionized the integration\nof knowledge graphs (KGs) in biomedical and cognitive sciences, overcoming\nlimitations in traditional machine learning methods for capturing intricate\nsemantic links among genes, diseases, and cognitive processes. We introduce\nMultiCNKG, an innovative framework that merges three key knowledge sources: the\nCognitive Neuroscience Knowledge Graph (CNKG) with 2.9K nodes and 4.3K edges\nacross 9 node types and 20 edge types; Gene Ontology (GO) featuring 43K nodes\nand 75K edges in 3 node types and 4 edge types; and Disease Ontology (DO)\ncomprising 11.2K nodes and 8.8K edges with 1 node type and 2 edge types.\nLeveraging LLMs like GPT-4, we conduct entity alignment, semantic similarity\ncomputation, and graph augmentation to create a cohesive KG that interconnects\ngenetic mechanisms, neurological disorders, and cognitive functions. The\nresulting MultiCNKG encompasses 6.9K nodes across 5 types (e.g., Genes,\nDiseases, Cognitive Processes) and 11.3K edges spanning 7 types (e.g., Causes,\nAssociated with, Regulates), facilitating a multi-layered view from molecular\nto behavioral domains. Assessments using metrics such as precision (85.20%),\nrecall (87.30%), coverage (92.18%), graph consistency (82.50%), novelty\ndetection (40.28%), and expert validation (89.50%) affirm its robustness and\ncoherence. Link prediction evaluations with models like TransE (MR: 391, MRR:\n0.411) and RotatE (MR: 263, MRR: 0.395) show competitive performance against\nbenchmarks like FB15k-237 and WN18RR. This KG advances applications in\npersonalized medicine, cognitive disorder diagnostics, and hypothesis\nformulation in cognitive neuroscience.",
    "published": "2025-10-08T07:59:32Z",
    "updated": "2025-10-08T07:59:32Z",
    "link": "http://arxiv.org/pdf/2510.06742v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Ali Sarabadani",
      "Kheirolah Rahsepar Fard"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06732v1",
    "title": "Are LLMs Reliable Rankers? Rank Manipulation via Two-Stage Token\n  Optimization",
    "summary": "Large language models (LLMs) are increasingly used as rerankers in\ninformation retrieval, yet their ranking behavior can be steered by small,\nnatural-sounding prompts. To expose this vulnerability, we present Rank\nAnything First (RAF), a two-stage token optimization method that crafts concise\ntextual perturbations to consistently promote a target item in LLM-generated\nrankings while remaining hard to detect. Stage 1 uses Greedy Coordinate\nGradient to shortlist candidate tokens at the current position by combining the\ngradient of the rank-target with a readability score; Stage 2 evaluates those\ncandidates under exact ranking and readability losses using an entropy-based\ndynamic weighting scheme, and selects a token via temperature-controlled\nsampling. RAF generates ranking-promoting prompts token-by-token, guided by\ndual objectives: maximizing ranking effectiveness and preserving linguistic\nnaturalness. Experiments across multiple LLMs show that RAF significantly\nboosts the rank of target items using naturalistic language, with greater\nrobustness than existing methods in both promoting target items and maintaining\nnaturalness. These findings underscore a critical security implication:\nLLM-based reranking is inherently susceptible to adversarial manipulation,\nraising new challenges for the trustworthiness and robustness of modern\nretrieval systems. Our code is available at: https://github.com/glad-lab/RAF.",
    "published": "2025-10-08T07:40:40Z",
    "updated": "2025-10-08T07:40:40Z",
    "link": "http://arxiv.org/pdf/2510.06732v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "authors": [
      "Tiancheng Xing",
      "Jerry Li",
      "Yixuan Du",
      "Xiyang Hu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.04226v3",
    "title": "Epistemic Diversity and Knowledge Collapse in Large Language Models",
    "summary": "Large language models (LLMs) tend to generate lexically, semantically, and\nstylistically homogenous texts. This poses a risk of knowledge collapse, where\nhomogenous LLMs mediate a shrinking in the range of accessible information over\ntime. Existing works on homogenization are limited by a focus on closed-ended\nmultiple-choice setups or fuzzy semantic features, and do not look at trends\nacross time and cultural contexts. To overcome this, we present a new\nmethodology to measure epistemic diversity, i.e., variation in real-world\nclaims in LLM outputs, which we use to perform a broad empirical study of LLM\nknowledge collapse. We test 27 LLMs, 155 topics covering 12 countries, and 200\nprompt variations sourced from real user chats. For the topics in our study, we\nshow that while newer models tend to generate more diverse claims, nearly all\nmodels are less epistemically diverse than a basic web search. We find that\nmodel size has a negative impact on epistemic diversity, while\nretrieval-augmented generation (RAG) has a positive impact, though the\nimprovement from RAG varies by the cultural context. Finally, compared to a\ntraditional knowledge source (Wikipedia), we find that country-specific claims\nreflect the English language more than the local one, highlighting a gap in\nepistemic representation",
    "published": "2025-10-05T14:29:15Z",
    "updated": "2025-10-08T07:35:57Z",
    "link": "http://arxiv.org/pdf/2510.04226v3.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.IR",
      "cs.LG"
    ],
    "authors": [
      "Dustin Wright",
      "Sarah Masud",
      "Jared Moore",
      "Srishti Yadav",
      "Maria Antoniak",
      "Chan Young Park",
      "Isabelle Augenstein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.23206v2",
    "title": "PARL-MT: Learning to Call Functions in Multi-Turn Conversation with\n  Progress Awareness",
    "summary": "Large language models (LLMs) have achieved impressive success in single-turn\nfunction calling, yet real-world applications such as travel planning or\nmulti-stage data analysis typically unfold across multi-turn conversations. In\nthese settings, LLMs must not only issue accurate function calls at each step\nbut also maintain progress awareness, the ability to summarize past\ninteractions and plan future actions to ensure coherent, long-horizon task\nexecution. Existing approaches, however, either reduce multi-turn training to\nisolated single-turn samples, which neglects task-level planning, or employ\nend-to-end reinforcement learning (RL) that struggles with redundancy and lacks\nexplicit integration of progress awareness. To overcome these limitations, we\nintroduce PARL-MT, a framework that explicitly incorporates progress awareness\ninto LLM training for multi-turn function calling. PARL-MT combines (i) a\nProgress Awareness Generation (PAG) pipeline, which automatically constructs\ndatasets coupling conversation summaries with future task planning, and (ii) a\nProgress Awareness-Guided Reinforcement Learning (PAG-RL) algorithm, which\nintegrates progress awareness into RL training to reduce contextual redundancy\nand improve alignment between local actions and global task completion.\nEmpirical results on two public benchmarks demonstrate that PARL-MT\nsignificantly outperforms existing methods, highlighting the effectiveness of\nprogress awareness in enabling robust and efficient multi-turn function\ncalling.",
    "published": "2025-09-27T09:32:27Z",
    "updated": "2025-10-08T07:29:46Z",
    "link": "http://arxiv.org/pdf/2509.23206v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Huacan Chai",
      "Zijie Cao",
      "Maolin Ran",
      "Yingxuan Yang",
      "Jianghao Lin",
      " pengxin",
      "Hairui Wang",
      "Renjie Ding",
      "Ziyu Wan",
      "Muning Wen",
      "Weiwen Liu",
      "Weinan Zhang",
      "Fei Huang",
      "Ying Wen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06727v1",
    "title": "Scaling LLM Multi-turn RL with End-to-end Summarization-based Context\n  Management",
    "summary": "We study reinforcement learning (RL) fine-tuning of large language model\n(LLM) agents for long-horizon multi-turn tool use, where context length quickly\nbecomes a fundamental bottleneck. Existing RL pipelines can suffer from\ndegraded instruction following, excessive rollout costs, and most importantly,\nstrict context limits. To address these challenges, we introduce\nsummarization-based context management to training. In specific, it\nperiodically compresses the tool using history by LLM-generated summaries that\nretain task-relevant information to keep a compact context while enabling the\nagent to scale beyond the fixed context window. Building on this formulation,\nwe derive a policy gradient representation that seamlessly enables standard LLM\nRL infrastructures to optimize both tool-use behaviors as well as summarization\nstrategies in an end-to-end fashion. We instantiate this framework with\n\\underline{SU}mmarization augmented \\underline{P}olicy \\underline{O}ptimization\n(\\texttt{SUPO}), an LLM RL algorithm that enables long-horizon training beyond\na fixed context limit. Experiments on interactive function calling and\nsearching tasks demonstrate that \\texttt{SUPO} significantly improves the\nsuccess rate while maintaining the same or even lower working context length\ncompared to baselines. We also demonstrate that for complex searching tasks,\n\\texttt{SUPO} can further improve the evaluation performance when scaling\ntest-time maximum round of summarization beyond that of training time. Our\nresults establish summarization-based context management as a principled and\nscalable approach for training RL agents beyond a fixed context length limit.",
    "published": "2025-10-08T07:29:22Z",
    "updated": "2025-10-08T07:29:22Z",
    "link": "http://arxiv.org/pdf/2510.06727v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Miao Lu",
      "Weiwei Sun",
      "Weihua Du",
      "Zhan Ling",
      "Xuesong Yao",
      "Kang Liu",
      "Jiecao Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.05763v6",
    "title": "GMLM: Bridging Graph Neural Networks and Language Models for\n  Heterophilic Node Classification",
    "summary": "Integrating Pre-trained Language Models (PLMs) with Graph Neural Networks\n(GNNs) remains a central challenge in text-rich heterophilic graph learning. We\npropose a novel integration framework that enables effective fusion between\npowerful pre-trained text encoders and Relational Graph Convolutional Networks\n(R-GCNs). Our method enhances the alignment of textual and structural\nrepresentations through a bidirectional fusion mechanism and contrastive\nnode-level optimization. To evaluate the approach, we train two variants using\ndifferent PLMs: Snowflake-Embed (state-of-the-art) and GTE-base, each paired\nwith an R-GCN backbone. Experiments on five heterophilic benchmarks demonstrate\nthat our integration method achieves state-of-the-art results on four datasets,\nsurpassing existing GNN and large language model-based approaches. Notably,\nSnowflake-Embed + R-GCN improves accuracy on the Texas dataset by over 8\\% and\non Wisconsin by nearly 5\\%. These results highlight the effectiveness of our\nfusion strategy for advancing text-rich graph representation learning.",
    "published": "2025-02-24T07:44:01Z",
    "updated": "2025-10-08T07:26:24Z",
    "link": "http://arxiv.org/pdf/2503.05763v6.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Aarush Sinha"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.17384v2",
    "title": "A Dual-Agent Adversarial Framework for Robust Generalization in Deep\n  Reinforcement Learning",
    "summary": "Recently, empowered with the powerful capabilities of neural networks,\nreinforcement learning (RL) has successfully tackled numerous challenging\ntasks. However, while these models demonstrate enhanced decision-making\nabilities, they are increasingly prone to overfitting. For instance, a trained\nRL model often fails to generalize to even minor variations of the same task,\nsuch as a change in background color or other minor semantic differences. To\naddress this issue, we propose a dual-agent adversarial policy learning\nframework, which allows agents to spontaneously learn the underlying semantics\nwithout introducing any human prior knowledge. Specifically, our framework\ninvolves a game process between two agents: each agent seeks to maximize the\nimpact of perturbing on the opponent's policy by producing representation\ndifferences for the same state, while maintaining its own stability against\nsuch perturbations. This interaction encourages agents to learn generalizable\npolicies, capable of handling irrelevant features from the high-dimensional\nobservations. Extensive experimental results on the Procgen benchmark\ndemonstrate that the adversarial process significantly improves the\ngeneralization performance of both agents, while also being applied to various\nRL algorithms, e.g., Proximal Policy Optimization (PPO). With the adversarial\nframework, the RL agent outperforms the baseline methods by a significant\nmargin, especially in hard-level tasks, marking a significant step forward in\nthe generalization capabilities of deep reinforcement learning.",
    "published": "2025-01-29T02:36:47Z",
    "updated": "2025-10-08T07:19:57Z",
    "link": "http://arxiv.org/pdf/2501.17384v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Zhengpeng Xie",
      "Yulong Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06718v1",
    "title": "LLM Company Policies and Policy Implications in Software Organizations",
    "summary": "The risks associated with adopting large language model (LLM) chatbots in\nsoftware organizations highlight the need for clear policies. We examine how 11\ncompanies create these policies and the factors that influence them, aiming to\nhelp managers safely integrate chatbots into development workflows.",
    "published": "2025-10-08T07:14:54Z",
    "updated": "2025-10-08T07:14:54Z",
    "link": "http://arxiv.org/pdf/2510.06718v1.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Ranim Khojah",
      "Mazen Mohamad",
      "Linda Erlenhov",
      "Francisco Gomes de Oliveira Neto",
      "Philipp Leitner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06714v1",
    "title": "Dual Goal Representations",
    "summary": "In this work, we introduce dual goal representations for goal-conditioned\nreinforcement learning (GCRL). A dual goal representation characterizes a state\nby \"the set of temporal distances from all other states\"; in other words, it\nencodes a state through its relations to every other state, measured by\ntemporal distance. This representation provides several appealing theoretical\nproperties. First, it depends only on the intrinsic dynamics of the environment\nand is invariant to the original state representation. Second, it contains\nprovably sufficient information to recover an optimal goal-reaching policy,\nwhile being able to filter out exogenous noise. Based on this concept, we\ndevelop a practical goal representation learning method that can be combined\nwith any existing GCRL algorithm. Through diverse experiments on the OGBench\ntask suite, we empirically show that dual goal representations consistently\nimprove offline goal-reaching performance across 20 state- and pixel-based\ntasks.",
    "published": "2025-10-08T07:07:39Z",
    "updated": "2025-10-08T07:07:39Z",
    "link": "http://arxiv.org/pdf/2510.06714v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Seohong Park",
      "Deepinder Mann",
      "Sergey Levine"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06711v1",
    "title": "Inefficiencies of Meta Agents for Agent Design",
    "summary": "Recent works began to automate the design of agentic systems using\nmeta-agents that propose and iteratively refine new agent architectures. In\nthis paper, we examine three key challenges in a common class of meta-agents.\nFirst, we investigate how a meta-agent learns across iterations and find that\nsimply expanding the context with all previous agents, as proposed by previous\nworks, performs worse than ignoring prior designs entirely. We show that the\nperformance improves with an evolutionary approach. Second, although the\nmeta-agent designs multiple agents during training, it typically commits to a\nsingle agent at test time. We find that the designed agents have low behavioral\ndiversity, limiting the potential for their complementary use. Third, we assess\nwhen automated design is economically viable. We find that only in a few\ncases--specifically, two datasets--the overall cost of designing and deploying\nthe agents is lower than that of human-designed agents when deployed on over\n15,000 examples. In contrast, the performance gains for other datasets do not\njustify the design cost, regardless of scale.",
    "published": "2025-10-08T07:06:17Z",
    "updated": "2025-10-08T07:06:17Z",
    "link": "http://arxiv.org/pdf/2510.06711v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Batu El",
      "Mert Yuksekgonul",
      "James Zou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06708v1",
    "title": "AISysRev -- LLM-based Tool for Title-abstract Screening",
    "summary": "Systematic reviews are a standard practice for summarizing the state of\nevidence in software engineering. Conducting systematic reviews is laborious,\nespecially during the screening or study selection phase, where the number of\npapers can be overwhelming. During this phase, papers are assessed against\ninclusion and exclusion criteria based on their titles and abstracts. Recent\nresearch has demonstrated that large language models (LLMs) can perform\ntitle-abstract screening at a level comparable to that of a master's student.\nWhile LLMs cannot be fully trusted, they can help, for example, in Rapid\nReviews, which try to expedite the review process. Building on recent research,\nwe developed AiSysRev, an LLM-based screening tool implemented as a web\napplication running in a Docker container. The tool accepts a CSV file\ncontaining paper titles and abstracts. Users specify inclusion and exclusion\ncriteria. One can use multiple LLMs for screening via OpenRouter. AiSysRev\nsupports both zero-shot and few-shot screening, and also allows for manual\nscreening through interfaces that display LLM results as guidance for human\nreviewers.We conducted a trial study with 137 papers using the tool. Our\nfindings indicate that papers can be classified into four categories: Easy\nIncludes, Easy Excludes, Boundary Includes, and Boundary Excludes. The Boundary\ncases, where LLMs are prone to errors, highlight the need for human\nintervention. While LLMs do not replace human judgment in systematic reviews,\nthey can significantly reduce the burden of assessing large volumes of\nscientific literature. Video: https://www.youtube.com/watch?v=jVbEj4Y4tQI Tool:\nhttps://github.com/EvoTestOps/AISysRev",
    "published": "2025-10-08T06:59:23Z",
    "updated": "2025-10-08T06:59:23Z",
    "link": "http://arxiv.org/pdf/2510.06708v1.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Aleksi Huotala",
      "Miikka Kuutila",
      "Olli-Pekka Turtio",
      "Mika Mäntylä"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.25282v2",
    "title": "Toward Causal-Visual Programming: Enhancing Agentic Reasoning in\n  Low-Code Environments",
    "summary": "Large language model (LLM) agents are increasingly capable of orchestrating\ncomplex tasks in low-code environments. However, these agents often exhibit\nhallucinations and logical inconsistencies because their inherent reasoning\nmechanisms rely on probabilistic associations rather than genuine causal\nunderstanding. This paper introduces a new programming paradigm: Causal-Visual\nProgramming (CVP), designed to address this fundamental issue by explicitly\nintroducing causal structures into the workflow design. CVP allows users to\ndefine a simple \"world model\" for workflow modules through an intuitive\nlow-code interface, effectively creating a Directed Acyclic Graph (DAG) that\nexplicitly defines the causal relationships between modules. This causal graph\nacts as a crucial constraint during the agent's reasoning process, anchoring\nits decisions to a user-defined causal structure and significantly reducing\nlogical errors and hallucinations by preventing reliance on spurious\ncorrelations. To validate the effectiveness of CVP, we designed a synthetic\nexperiment that simulates a common real-world problem: a distribution shift\nbetween the training and test environments. Our results show that a causally\nanchored model maintained stable accuracy in the face of this shift, whereas a\npurely associative baseline model that relied on probabilistic correlations\nexperienced a significant performance drop. The primary contributions of this\nstudy are: a formal definition of causal structures for workflow modules; the\nproposal and implementation of a CVP framework that anchors agent reasoning to\na user-defined causal graph; and empirical evidence demonstrating the\nframework's effectiveness in enhancing agent robustness and reducing errors\ncaused by causal confusion in dynamic environments. CVP offers a viable path\ntoward building more interpretable, reliable, and trustworthy AI agents.",
    "published": "2025-09-29T08:01:31Z",
    "updated": "2025-10-08T06:59:21Z",
    "link": "http://arxiv.org/pdf/2509.25282v2.pdf",
    "category": [
      "cs.AI",
      "cs.HC",
      "cs.SE",
      "I.2.4; D.1.7; I.2.11"
    ],
    "authors": [
      "Jiexi Xu",
      "Jiaqi Liu",
      "Lanruo Wang",
      "Su Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.12658v2",
    "title": "Sustainable LSTM-Based Precoding for RIS-Aided mmWave MIMO Systems with\n  Implicit CSI",
    "summary": "In this paper, we propose a sustainable long short-term memory (LSTM)-based\nprecoding framework for reconfigurable intelligent surface (RIS)-assisted\nmillimeter-wave (mmWave) MIMO systems. Instead of explicit channel state\ninformation (CSI) estimation, the framework exploits uplink pilot sequences to\nimplicitly learn channel characteristics, reducing both pilot overhead and\ninference complexity. Practical hardware constraints are addressed by\nincorporating the phase-dependent amplitude model of RIS elements, while a\nmulti-label training strategy improves robustness when multiple near-optimal\ncodewords yield comparable performance. Simulations show that the proposed\ndesign achieves over 90% of the spectral efficiency of exhaustive search (ES)\nwith only 2.2% of its computation time, cutting energy consumption by nearly\ntwo orders of magnitude. The method also demonstrates resilience under\ndistribution mismatch and scalability to larger RIS arrays, making it a\npractical and energy-efficient solution for sustainable 6G wireless networks.",
    "published": "2025-09-16T04:29:14Z",
    "updated": "2025-10-08T06:53:44Z",
    "link": "http://arxiv.org/pdf/2509.12658v2.pdf",
    "category": [
      "eess.SP",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "cs.NI",
      "math.IT"
    ],
    "authors": [
      "Po-Heng Chou",
      "Jiun-Jia Wu",
      "Wan-Jen Huang",
      "Ronald Y. Chang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06695v1",
    "title": "Learning to Rewrite Prompts for Bootstrapping LLMs on Downstream Tasks",
    "summary": "In recent years, the growing interest in Large Language Models (LLMs) has\nsignificantly advanced prompt engineering, transitioning from manual design to\nmodel-based optimization. Prompts for LLMs generally comprise two components:\nthe \\textit{instruction}, which defines the task or objective, and the\n\\textit{input}, which is tailored to the instruction type. In natural language\ngeneration (NLG) tasks such as machine translation, the \\textit{input}\ncomponent is particularly critical, while the \\textit{instruction} component\ntends to be concise. Existing prompt engineering methods primarily focus on\noptimizing the \\textit{instruction} component for general tasks, often\nrequiring large-parameter LLMs as auxiliary tools. However, these approaches\nexhibit limited applicability for tasks like machine translation, where the\n\\textit{input} component plays a more pivotal role. To address this limitation,\nthis paper introduces a novel prompt optimization method specifically designed\nfor machine translation tasks. The proposed approach employs a small-parameter\nmodel trained using a back-translation-based strategy, significantly reducing\ntraining overhead for single-task optimization while delivering highly\neffective performance. With certain adaptations, this method can also be\nextended to other downstream tasks.",
    "published": "2025-10-08T06:40:06Z",
    "updated": "2025-10-08T06:40:06Z",
    "link": "http://arxiv.org/pdf/2510.06695v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "authors": [
      "Qinhao Zhou",
      "Xiang Xiang",
      "Kun He",
      "John E. Hopcroft"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.02548v2",
    "title": "CyberGym: Evaluating AI Agents' Real-World Cybersecurity Capabilities at\n  Scale",
    "summary": "AI agents have significant potential to reshape cybersecurity, making a\nthorough assessment of their capabilities critical. However, existing\nevaluations fall short, because they are based on small-scale benchmarks and\nonly measure static outcomes, failing to capture the full, dynamic range of\nreal-world security challenges. To address these limitations, we introduce\nCyberGym, a large-scale benchmark featuring 1,507 real-world vulnerabilities\nacross 188 software projects. Adjustable to different vulnerability analysis\nsettings, CyberGym primarily tasks agents with generating a proof-of-concept\ntest that reproduces a vulnerability, given only its text description and the\ncorresponding codebase. Our extensive evaluation highlights that CyberGym\neffectively differentiates agents' and models' cybersecurity capabilities. Even\nthe top-performing combinations only achieve a ~20% success rate, demonstrating\nthe overall difficulty of CyberGym. Beyond static benchmarking, we show that\nCyberGym leads to the discovery of 35 zero-day vulnerabilities and 17\nhistorically incomplete patches. These results underscore that CyberGym is not\nonly a robust benchmark for measuring AI's progress in cybersecurity but also a\nplatform for creating direct, real-world security impact.",
    "published": "2025-06-03T07:35:14Z",
    "updated": "2025-10-08T06:32:58Z",
    "link": "http://arxiv.org/pdf/2506.02548v2.pdf",
    "category": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Zhun Wang",
      "Tianneng Shi",
      "Jingxuan He",
      "Matthew Cai",
      "Jialin Zhang",
      "Dawn Song"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.11711v2",
    "title": "Enhancing GraphQL Security by Detecting Malicious Queries Using Large\n  Language Models, Sentence Transformers, and Convolutional Neural Networks",
    "summary": "GraphQL's flexibility, while beneficial for efficient data fetching,\nintroduces unique security vulnerabilities that traditional API security\nmechanisms often fail to address. Malicious GraphQL queries can exploit the\nlanguage's dynamic nature, leading to denial-of-service attacks, data\nexfiltration through injection, and other exploits. Existing solutions, such as\nstatic analysis, rate limiting, and general-purpose Web Application Firewalls,\noffer limited protection against sophisticated, context-aware attacks. This\npaper presents a novel, AI-driven approach for real-time detection of malicious\nGraphQL queries. Our method combines static analysis with machine learning\ntechniques, including Large Language Models (LLMs) for dynamic schema-based\nconfiguration, Sentence Transformers (SBERT and Doc2Vec) for contextual\nembedding of query payloads, and Convolutional Neural Networks (CNNs), Random\nForests, and Multilayer Perceptrons for classification. We detail the system\narchitecture, implementation strategies optimized for production environments\n(including ONNX Runtime optimization and parallel processing), and evaluate the\nperformance of our detection models and the overall system under load. Results\ndemonstrate high accuracy in detecting various threats, including SQL\ninjection, OS command injection, and XSS exploits, alongside effective\nmitigation of DoS and SSRF attempts. This research contributes a robust and\nadaptable solution for enhancing GraphQL API security.",
    "published": "2025-08-14T07:35:11Z",
    "updated": "2025-10-08T06:22:30Z",
    "link": "http://arxiv.org/pdf/2508.11711v2.pdf",
    "category": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Irash Perera",
      "Hiranya Abeyrathne",
      "Sanjeewa Malalgoda",
      "Arshardh Ifthikar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.21988v2",
    "title": "Functional Matching of Logic Subgraphs: Beyond Structural Isomorphism",
    "summary": "Subgraph matching in logic circuits is foundational for numerous Electronic\nDesign Automation (EDA) applications, including datapath optimization,\narithmetic verification, and hardware trojan detection. However, existing\ntechniques rely primarily on structural graph isomorphism and thus fail to\nidentify function-related subgraphs when synthesis transformations\nsubstantially alter circuit topology. To overcome this critical limitation, we\nintroduce the concept of functional subgraph matching, a novel approach that\nidentifies whether a given logic function is implicitly present within a larger\ncircuit, irrespective of structural variations induced by synthesis or\ntechnology mapping. Specifically, we propose a two-stage multi-modal framework:\n(1) learning robust functional embeddings across AIG and post-mapping netlists\nfor functional subgraph detection, and (2) identifying fuzzy boundaries using a\ngraph segmentation approach. Evaluations on standard benchmarks (ITC99,\nOpenABCD, ForgeEDA) demonstrate significant performance improvements over\nexisting structural methods, with average $93.8\\%$ accuracy in functional\nsubgraph detection and a dice score of $91.3\\%$ in fuzzy boundary\nidentification. The source code and implementation details can be found at\nhttps://github.com/zyzheng17/Functional_Subgraph_Matching-Neurips25.",
    "published": "2025-05-28T05:31:49Z",
    "updated": "2025-10-08T06:16:46Z",
    "link": "http://arxiv.org/pdf/2505.21988v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Ziyang Zheng",
      "Kezhi Li",
      "Zhengyuan Shi",
      "Qiang Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06687v1",
    "title": "Semantic Segmentation Algorithm Based on Light Field and LiDAR Fusion",
    "summary": "Semantic segmentation serves as a cornerstone of scene understanding in\nautonomous driving but continues to face significant challenges under complex\nconditions such as occlusion. Light field and LiDAR modalities provide\ncomplementary visual and spatial cues that are beneficial for robust\nperception; however, their effective integration is hindered by limited\nviewpoint diversity and inherent modality discrepancies. To address these\nchallenges, the first multimodal semantic segmentation dataset integrating\nlight field data and point cloud data is proposed. Based on this dataset, we\nproposed a multi-modal light field point-cloud fusion segmentation\nnetwork(Mlpfseg), incorporating feature completion and depth perception to\nsegment both camera images and LiDAR point clouds simultaneously. The feature\ncompletion module addresses the density mismatch between point clouds and image\npixels by performing differential reconstruction of point-cloud feature maps,\nenhancing the fusion of these modalities. The depth perception module improves\nthe segmentation of occluded objects by reinforcing attention scores for better\nocclusion awareness. Our method outperforms image-only segmentation by 1.71\nMean Intersection over Union(mIoU) and point cloud-only segmentation by 2.38\nmIoU, demonstrating its effectiveness.",
    "published": "2025-10-08T06:15:06Z",
    "updated": "2025-10-08T06:15:06Z",
    "link": "http://arxiv.org/pdf/2510.06687v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Jie Luo",
      "Yuxuan Jiang",
      "Xin Jin",
      "Mingyu Liu",
      "Yihui Fan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06677v1",
    "title": "Incremental Summarization for Customer Support via Progressive\n  Note-Taking and Agent Feedback",
    "summary": "We introduce an incremental summarization system for customer support agents\nthat intelligently determines when to generate concise bullet notes during\nconversations, reducing agents' context-switching effort and redundant review.\nOur approach combines a fine-tuned Mixtral-8x7B model for continuous note\ngeneration with a DeBERTa-based classifier to filter trivial content. Agent\nedits refine the online notes generation and regularly inform offline model\nretraining, closing the agent edits feedback loop. Deployed in production, our\nsystem achieved a 3% reduction in case handling time compared to bulk\nsummarization (with reductions of up to 9% in highly complex cases), alongside\nhigh agent satisfaction ratings from surveys. These results demonstrate that\nincremental summarization with continuous feedback effectively enhances summary\nquality and agent productivity at scale.",
    "published": "2025-10-08T06:05:58Z",
    "updated": "2025-10-08T06:05:58Z",
    "link": "http://arxiv.org/pdf/2510.06677v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Yisha Wu",
      " Cen",
      " Zhao",
      "Yuanpei Cao",
      "Xiaoqing Su",
      "Yashar Mehdad",
      "Mindy Ji",
      "Claire Na Cheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06674v1",
    "title": "Agent-in-the-Loop: A Data Flywheel for Continuous Improvement in\n  LLM-based Customer Support",
    "summary": "We introduce an Agent-in-the-Loop (AITL) framework that implements a\ncontinuous data flywheel for iteratively improving an LLM-based customer\nsupport system. Unlike standard offline approaches that rely on batch\nannotations, AITL integrates four key types of annotations directly into live\ncustomer operations: (1) pairwise response preferences, (2) agent adoption and\nrationales, (3) knowledge relevance checks, and (4) identification of missing\nknowledge. These feedback signals seamlessly feed back into models' updates,\nreducing retraining cycles from months to weeks. Our production pilot involving\nUS-based customer support agents demonstrated significant improvements in\nretrieval accuracy (+11.7% recall@75, +14.8% precision@8), generation quality\n(+8.4% helpfulness) and agent adoption rates (+4.5%). These results underscore\nthe effectiveness of embedding human feedback loops directly into operational\nworkflows to continuously refine LLM-based customer support system.",
    "published": "2025-10-08T05:57:04Z",
    "updated": "2025-10-08T05:57:04Z",
    "link": "http://arxiv.org/pdf/2510.06674v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      " Cen",
      " Zhao",
      "Tiantian Zhang",
      "Hanchen Su",
      " Yufeng",
      " Zhang",
      "Shaowei Su",
      "Mingzhi Xu",
      " Yu",
      " Liu",
      "Wei Han",
      "Jeremy Werner",
      "Claire Na Cheng",
      "Yashar Mehdad"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06673v1",
    "title": "Heptapod: Language Modeling on Visual Signals",
    "summary": "We introduce Heptapod, an image autoregressive model that adheres to the\nfoundational principles of language modeling. Heptapod employs \\textbf{causal\nattention}, \\textbf{eliminates reliance on CFG}, and \\textbf{eschews the trend\nof semantic tokenizers}. Our key innovation is \\textit{next 2D distribution\nprediction}: a causal Transformer with reconstruction-focused visual tokenizer,\nlearns to predict the distribution over the entire 2D spatial grid of images at\neach timestep. This learning objective unifies the sequential modeling of\nautoregressive framework with the holistic self-supervised learning of masked\nautoencoding, enabling the model to capture comprehensive image semantics via\ngenerative training. On the ImageNet generation benchmark, Heptapod achieves an\nFID of $2.70$, significantly outperforming previous causal autoregressive\napproaches. We hope our work inspires a principled rethinking of language\nmodeling on visual signals and beyond.",
    "published": "2025-10-08T05:54:46Z",
    "updated": "2025-10-08T05:54:46Z",
    "link": "http://arxiv.org/pdf/2510.06673v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Yongxin Zhu",
      "Jiawei Chen",
      "Yuanzhe Chen",
      "Zhuo Chen",
      "Dongya Jia",
      "Jian Cong",
      "Xiaobin Zhuang",
      "Yuping Wang",
      "Yuxuan Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2305.11461v8",
    "title": "Hint of Pseudo Code (HoPC): Zero-Shot Step by Step Pseudo Code Reasoning\n  Prompting",
    "summary": "Prompting a language model (LM) is an increasingly important research topic\nfor better utilization of large language models (LLMs). While simple prompting\nis effective for single-step questions, it fails to activate the correct\nknowledge path for multi-step reasoning tasks consistently. The few-shot Chain\nof Thought (CoT), serves as an advanced prompting strategy that explains and\ndemonstrates the reasoning process to the LLM, outperforming simple prompting\nin challenging reasoning tasks such as arithmetic and common-sense reasoning.\nThe Program of Thought (PoT) aims to generate text and programming language\nsolutions for multi-step reasoning problems. In zero-shot CoT, the prompt is\nsimply ``Let's think step by step'', which is overly simplistic and does not\nadequately demonstrate a robust reasoning process for complex reasoning\nchallenges. Additionally, PoT requires an extra interpreter to execute the\nanswer and struggles with semantic reasoning problems like StrategyQA. This\npaper introduces a novel Hint of Pseudo Code (HoPC) prompting technique that\ndoes not require extra interpreter as in PoT and incorporates a more powerful\nzero-shot problem decomposition and semantic code reasoning capabilities than\nzero-shot CoT. It consists of three components: problem decomposition, semantic\ncode reasoning, and answer extraction.\n  We prompt these components as hints in a sequential, step by step manner,\nmaking it easy to tailor and explain for various tasks.",
    "published": "2023-05-19T06:30:17Z",
    "updated": "2025-10-08T05:44:17Z",
    "link": "http://arxiv.org/pdf/2305.11461v8.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Iok Tong Lei",
      "Ziyu Zhu",
      "Han Yu",
      "Yige Yao",
      "Zhidong Deng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06669v1",
    "title": "Automated Neural Architecture Design for Industrial Defect Detection",
    "summary": "Industrial surface defect detection (SDD) is critical for ensuring product\nquality and manufacturing reliability. Due to the diverse shapes and sizes of\nsurface defects, SDD faces two main challenges: intraclass difference and\ninterclass similarity. Existing methods primarily utilize manually designed\nmodels, which require extensive trial and error and often struggle to address\nboth challenges effectively. To overcome this, we propose AutoNAD, an automated\nneural architecture design framework for SDD that jointly searches over\nconvolutions, transformers, and multi-layer perceptrons. This hybrid design\nenables the model to capture both fine-grained local variations and long-range\nsemantic context, addressing the two key challenges while reducing the cost of\nmanual network design. To support efficient training of such a diverse search\nspace, AutoNAD introduces a cross weight sharing strategy, which accelerates\nsupernet convergence and improves subnet performance. Additionally, a\nsearchable multi-level feature aggregation module (MFAM) is integrated to\nenhance multi-scale feature learning. Beyond detection accuracy, runtime\nefficiency is essential for industrial deployment. To this end, AutoNAD\nincorporates a latency-aware prior to guide the selection of efficient\narchitectures. The effectiveness of AutoNAD is validated on three industrial\ndefect datasets and further applied within a defect imaging and detection\nplatform. Code will be available at https://github.com/Yuxi104/AutoNAD.",
    "published": "2025-10-08T05:37:59Z",
    "updated": "2025-10-08T05:37:59Z",
    "link": "http://arxiv.org/pdf/2510.06669v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Yuxi Liu",
      "Yunfeng Ma",
      "Yi Tang",
      "Min Liu",
      "Shuai Jiang",
      "Yaonan Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06661v1",
    "title": "Delay Independent Safe Control with Neural Networks: Positive Lur'e\n  Certificates for Risk Aware Autonomy",
    "summary": "We present a risk-aware safety certification method for autonomous, learning\nenabled control systems. Focusing on two realistic risks, state/input delays\nand interval matrix uncertainty, we model the neural network (NN) controller\nwith local sector bounds and exploit positivity structure to derive linear,\ndelay-independent certificates that guarantee local exponential stability\nacross admissible uncertainties. To benchmark performance, we adopt and\nimplement a state-of-the-art IQC NN verification pipeline. On representative\ncases, our positivity-based tests run orders of magnitude faster than SDP-based\nIQC while certifying regimes the latter cannot-providing scalable safety\nguarantees that complement risk-aware control.",
    "published": "2025-10-08T05:22:28Z",
    "updated": "2025-10-08T05:22:28Z",
    "link": "http://arxiv.org/pdf/2510.06661v1.pdf",
    "category": [
      "eess.SY",
      "cs.AI",
      "cs.SY",
      "93D09, 93D20, 93C10, 68T07",
      "I.2.0; I.2.3; I.2.8; B.1.3; G.2; F.3"
    ],
    "authors": [
      "Hamidreza Montazeri Hedesh",
      "Milad Siami"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.05378v3",
    "title": "Code Like Humans: A Multi-Agent Solution for Medical Coding",
    "summary": "In medical coding, experts map unstructured clinical notes to alphanumeric\ncodes for diagnoses and procedures. We introduce Code Like Humans: a new\nagentic framework for medical coding with large language models. It implements\nofficial coding guidelines for human experts, and it is the first solution that\ncan support the full ICD-10 coding system (+70K labels). It achieves the best\nperformance to date on rare diagnosis codes (fine-tuned discriminative\nclassifiers retain an advantage for high-frequency codes, to which they are\nlimited). Towards future work, we also contribute an analysis of system\nperformance and identify its `blind spots' (codes that are systematically\nundercoded).",
    "published": "2025-09-04T16:31:38Z",
    "updated": "2025-10-08T05:07:35Z",
    "link": "http://arxiv.org/pdf/2509.05378v3.pdf",
    "category": [
      "cs.AI",
      "cs.MA"
    ],
    "authors": [
      "Andreas Motzfeldt",
      "Joakim Edin",
      "Casper L. Christensen",
      "Christian Hardmeier",
      "Lars Maaløe",
      "Anna Rogers"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06649v1",
    "title": "Local Reinforcement Learning with Action-Conditioned Root Mean Squared\n  Q-Functions",
    "summary": "The Forward-Forward (FF) Algorithm is a recently proposed learning procedure\nfor neural networks that employs two forward passes instead of the traditional\nforward and backward passes used in backpropagation. However, FF remains\nlargely confined to supervised settings, leaving a gap at domains where\nlearning signals can be yielded more naturally such as RL. In this work,\ninspired by FF's goodness function using layer activity statistics, we\nintroduce Action-conditioned Root mean squared Q-Functions (ARQ), a novel value\nestimation method that applies a goodness function and action conditioning for\nlocal RL using temporal difference learning. Despite its simplicity and\nbiological grounding, our approach achieves superior performance compared to\nstate-of-the-art local backprop-free RL methods in the MinAtar and the DeepMind\nControl Suite benchmarks, while also outperforming algorithms trained with\nbackpropagation on most tasks. Code can be found at\nhttps://github.com/agentic-learning-ai-lab/arq.",
    "published": "2025-10-08T05:06:09Z",
    "updated": "2025-10-08T05:06:09Z",
    "link": "http://arxiv.org/pdf/2510.06649v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Frank Wu",
      "Mengye Ren"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06646v1",
    "title": "The False Promise of Zero-Shot Super-Resolution in Machine-Learned\n  Operators",
    "summary": "A core challenge in scientific machine learning, and scientific computing\nmore generally, is modeling continuous phenomena which (in practice) are\nrepresented discretely. Machine-learned operators (MLOs) have been introduced\nas a means to achieve this modeling goal, as this class of architecture can\nperform inference at arbitrary resolution. In this work, we evaluate whether\nthis architectural innovation is sufficient to perform \"zero-shot\nsuper-resolution,\" namely to enable a model to serve inference on\nhigher-resolution data than that on which it was originally trained. We\ncomprehensively evaluate both zero-shot sub-resolution and super-resolution\n(i.e., multi-resolution) inference in MLOs. We decouple multi-resolution\ninference into two key behaviors: 1) extrapolation to varying frequency\ninformation; and 2) interpolating across varying resolutions. We empirically\ndemonstrate that MLOs fail to do both of these tasks in a zero-shot manner.\nConsequently, we find MLOs are not able to perform accurate inference at\nresolutions different from those on which they were trained, and instead they\nare brittle and susceptible to aliasing. To address these failure modes, we\npropose a simple, computationally-efficient, and data-driven multi-resolution\ntraining protocol that overcomes aliasing and that provides robust\nmulti-resolution generalization.",
    "published": "2025-10-08T04:59:56Z",
    "updated": "2025-10-08T04:59:56Z",
    "link": "http://arxiv.org/pdf/2510.06646v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Mansi Sakarvadia",
      "Kareem Hegazy",
      "Amin Totounferoush",
      "Kyle Chard",
      "Yaoqing Yang",
      "Ian Foster",
      "Michael W. Mahoney"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06645v1",
    "title": "Distilling Lightweight Language Models for C/C++ Vulnerabilities",
    "summary": "The increasing complexity of modern software systems exacerbates the\nprevalence of security vulnerabilities, posing risks of severe breaches and\nsubstantial economic loss. Consequently, robust code vulnerability detection is\nessential for software security. While Large Language Models (LLMs) have\ndemonstrated remarkable capabilities in natural language processing, their\npotential for automated code vulnerability detection remains underexplored.\nThis paper presents FineSec, a novel framework that harnesses LLMs through\nknowledge distillation to enable efficient and precise vulnerability\nidentification in C/C++ codebases. FineSec utilizes knowledge distillation to\ntransfer expertise from large teacher models to compact student models,\nachieving high accuracy with minimal computational cost. By integrating data\npreparation, training, evaluation, and continuous learning into a unified,\nsingle-task workflow, FineSec offers a streamlined approach. Extensive\nevaluations on C/C++ codebases demonstrate its superiority over both base\nmodels and larger LLMs in identifying complex vulnerabilities and logical\nflaws, establishing FineSec as a practical and scalable solution for real-world\nsoftware security. To facilitate reproducibility, the datasets, source code,\nand experimental results are made publicly available at:\nhttps://github.com/yangxiaoxuan123/FineSec_detect.",
    "published": "2025-10-08T04:58:51Z",
    "updated": "2025-10-08T04:58:51Z",
    "link": "http://arxiv.org/pdf/2510.06645v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Zhiyuan Wei",
      "Xiaoxuan Yang",
      "Jing Sun",
      "Zijian Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.18665v3",
    "title": "Membership Inference Attacks on LLM-based Recommender Systems",
    "summary": "Large language models (LLMs) based Recommender Systems (RecSys) can flexibly\nadapt recommendation systems to different domains. It utilizes in-context\nlearning (ICL), i.e., the prompts, to customize the recommendation functions,\nwhich include sensitive historical user-specific item interactions, e.g.,\nimplicit feedback like clicked items or explicit product reviews. Such private\ninformation may be exposed to novel privacy attack. However, no study has been\ndone on this important issue. We design four membership inference attacks\n(MIAs), aiming to reveal whether victims' historical interactions have been\nused by system prompts. They are \\emph{direct inquiry, hallucination,\nsimilarity, and poisoning attacks}, each of which utilizes the unique features\nof LLMs or RecSys. We have carefully evaluated them on three LLMs that have\nbeen used to develop ICL-LLM RecSys and two well-known RecSys benchmark\ndatasets. The results confirm that the MIA threat on LLM RecSys is realistic:\ndirect inquiry and poisoning attacks showing significantly high attack\nadvantages. We have also analyzed the factors affecting these attacks, such as\nthe number of shots in system prompts and the position of the victim in the\nshots.",
    "published": "2025-08-26T04:14:39Z",
    "updated": "2025-10-08T04:48:57Z",
    "link": "http://arxiv.org/pdf/2508.18665v3.pdf",
    "category": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "cs.LG"
    ],
    "authors": [
      "Jiajie He",
      "Yuechun Gu",
      "Min-Chun Chen",
      "Keke Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06638v1",
    "title": "StaR-KVQA: Structured Reasoning Traces for Implicit-Knowledge Visual\n  Question Answering",
    "summary": "Knowledge-based Visual Question Answering (KVQA) requires models to ground\nentities in images and reason over factual knowledge. We study its\nimplicit-knowledge variant, IK-KVQA, where a multimodal large language model\n(MLLM) is the sole knowledge source, without external retrieval. Yet, MLLMs\nlack explicit reasoning supervision and produce inconsistent justifications,\nand generalize poorly after standard supervised fine-tuning (SFT). We present\nStaR-KVQA (Structured Reasoning Traces for IK-KVQA), which supervises\nstructured traces - dual symbolic relation paths plus path-grounded\nnatural-language explanations - so that reasoning becomes transparent and\nverifiable. With one open-source MLLM, StaR-KVQA constructs and selects\npath-grounded reasoning traces to form a trace-enriched dataset, then\nfine-tunes via structured self-distillation to align generation with\nsupervision; no external retrievers, verifiers, or curated knowledge bases\n(KBs) are used, traces are built offline, and inference is a single\nautoregressive pass. Across benchmarks, StaR-KVQA improves both accuracy and\ninterpretability, achieving up to +11.3% higher answer accuracy on OK-VQA over\nthe strongest baseline while exhibiting robust cross-domain generalization.",
    "published": "2025-10-08T04:37:53Z",
    "updated": "2025-10-08T04:37:53Z",
    "link": "http://arxiv.org/pdf/2510.06638v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Zhihao Wen",
      "Wenkang Wei",
      "Yuan Fang",
      "Xingtong Yu",
      "Hui Zhang",
      "Weicheng Zhu",
      "Xin Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.05379v2",
    "title": "AutoDAN-Reasoning: Enhancing Strategies Exploration based Jailbreak\n  Attacks with Test-Time Scaling",
    "summary": "Recent advancements in jailbreaking large language models (LLMs), such as\nAutoDAN-Turbo, have demonstrated the power of automated strategy discovery.\nAutoDAN-Turbo employs a lifelong learning agent to build a rich library of\nattack strategies from scratch. While highly effective, its test-time\ngeneration process involves sampling a strategy and generating a single\ncorresponding attack prompt, which may not fully exploit the potential of the\nlearned strategy library. In this paper, we propose to further improve the\nattack performance of AutoDAN-Turbo through test-time scaling. We introduce two\ndistinct scaling methods: Best-of-N and Beam Search. The Best-of-N method\ngenerates N candidate attack prompts from a sampled strategy and selects the\nmost effective one based on a scorer model. The Beam Search method conducts a\nmore exhaustive search by exploring combinations of strategies from the library\nto discover more potent and synergistic attack vectors. According to the\nexperiments, the proposed methods significantly boost performance, with Beam\nSearch increasing the attack success rate by up to 15.6 percentage points on\nLlama-3.1-70B-Instruct and achieving a nearly 60% relative improvement against\nthe highly robust GPT-o4-mini compared to the vanilla method.",
    "published": "2025-10-06T21:16:09Z",
    "updated": "2025-10-08T04:37:35Z",
    "link": "http://arxiv.org/pdf/2510.05379v2.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Xiaogeng Liu",
      "Chaowei Xiao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06637v1",
    "title": "Control-Augmented Autoregressive Diffusion for Data Assimilation",
    "summary": "Despite recent advances in test-time scaling and finetuning of diffusion\nmodels, guidance in Auto-Regressive Diffusion Models (ARDMs) remains\nunderexplored. We introduce an amortized framework that augments pretrained\nARDMs with a lightweight controller network, trained offline by previewing\nfuture ARDM rollouts and learning stepwise controls that anticipate upcoming\nobservations under a terminal cost objective. We evaluate this framework in the\ncontext of data assimilation (DA) for chaotic spatiotemporal partial\ndifferential equations (PDEs), a setting where existing methods are often\ncomputationally prohibitive and prone to forecast drift under sparse\nobservations. Our approach reduces DA inference to a single forward rollout\nwith on-the-fly corrections, avoiding expensive adjoint computations and/or\noptimizations during inference. We demonstrate that our method consistently\noutperforms four state-of-the-art baselines in stability, accuracy, and\nphysical fidelity across two canonical PDEs and six observation regimes. We\nwill release code and checkpoints publicly.",
    "published": "2025-10-08T04:37:32Z",
    "updated": "2025-10-08T04:37:32Z",
    "link": "http://arxiv.org/pdf/2510.06637v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Prakhar Srivastava",
      "Farrin Marouf Sofian",
      "Francesco Immorlano",
      "Kushagra Pandey",
      "Stephan Mandt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06631v1",
    "title": "AI-Driven Forecasting and Monitoring of Urban Water System",
    "summary": "Underground water and wastewater pipelines are vital for city operations but\nplagued by anomalies like leaks and infiltrations, causing substantial water\nloss, environmental damage, and high repair costs. Conventional manual\ninspections lack efficiency, while dense sensor deployments are prohibitively\nexpensive. In recent years, artificial intelligence has advanced rapidly and is\nincreasingly applied to urban infrastructure. In this research, we propose an\nintegrated AI and remote-sensor framework to address the challenge of leak\ndetection in underground water pipelines, through deploying a sparse set of\nremote sensors to capture real-time flow and depth data, paired with HydroNet -\na dedicated model utilizing pipeline attributes (e.g., material, diameter,\nslope) in a directed graph for higher-precision modeling. Evaluations on a\nreal-world campus wastewater network dataset demonstrate that our system\ncollects effective spatio-temporal hydraulic data, enabling HydroNet to\noutperform advanced baselines. This integration of edge-aware message passing\nwith hydraulic simulations enables accurate network-wide predictions from\nlimited sensor deployments. We envision that this approach can be effectively\nextended to a wide range of underground water pipeline networks.",
    "published": "2025-10-08T04:28:38Z",
    "updated": "2025-10-08T04:28:38Z",
    "link": "http://arxiv.org/pdf/2510.06631v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Qiming Guo",
      "Bishal Khatri",
      "Hua Zhang",
      "Wenlu Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.04072v2",
    "title": "Slow-Fast Policy Optimization: Reposition-Before-Update for LLM\n  Reasoning",
    "summary": "Reinforcement learning (RL) has become central to enhancing reasoning in\nlarge language models (LLMs). Yet on-policy algorithms such as Group Relative\nPolicy Optimization (GRPO) often suffer in early training: noisy gradients from\nlow-quality rollouts lead to unstable updates and inefficient exploration. We\nintroduce Slow-Fast Policy Optimization (SFPO), a simple yet efficient\nframework to address these limitations via decomposing each step into three\nstages: a short fast trajectory of inner steps on the same batch, a reposition\nmechanism to control off-policy drift, and a final slow correction. This\nreposition-before-update design preserves the objective and rollout process\nunchanged, making SFPO plug-compatible with existing policy-gradient pipelines.\nExtensive experiments demonstrate that SFPO consistently improves stability,\nreduces rollouts, and accelerates convergence of reasoning RL training.\nSpecifically, it outperforms GRPO by up to 2.80 points in average on math\nreasoning benchmarks. It also achieves up to 4.93\\texttimes{} fewer rollouts\nand an up to 4.19\\texttimes{} reduction in wall-clock time to match GRPO's best\naccuracy.",
    "published": "2025-10-05T07:22:54Z",
    "updated": "2025-10-08T04:24:36Z",
    "link": "http://arxiv.org/pdf/2510.04072v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "authors": [
      "Ziyan Wang",
      "Zheng Wang",
      "Jie Fu",
      "Xingwei Qu",
      "Qi Cheng",
      "Shengpu Tang",
      "Minjia Zhang",
      "Xiaoming Huo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.05173v2",
    "title": "SafeGuider: Robust and Practical Content Safety Control for\n  Text-to-Image Models",
    "summary": "Text-to-image models have shown remarkable capabilities in generating\nhigh-quality images from natural language descriptions. However, these models\nare highly vulnerable to adversarial prompts, which can bypass safety measures\nand produce harmful content. Despite various defensive strategies, achieving\nrobustness against attacks while maintaining practical utility in real-world\napplications remains a significant challenge. To address this issue, we first\nconduct an empirical study of the text encoder in the Stable Diffusion (SD)\nmodel, which is a widely used and representative text-to-image model. Our\nfindings reveal that the [EOS] token acts as a semantic aggregator, exhibiting\ndistinct distributional patterns between benign and adversarial prompts in its\nembedding space. Building on this insight, we introduce \\textbf{SafeGuider}, a\ntwo-step framework designed for robust safety control without compromising\ngeneration quality. SafeGuider combines an embedding-level recognition model\nwith a safety-aware feature erasure beam search algorithm. This integration\nenables the framework to maintain high-quality image generation for benign\nprompts while ensuring robust defense against both in-domain and out-of-domain\nattacks. SafeGuider demonstrates exceptional effectiveness in minimizing attack\nsuccess rates, achieving a maximum rate of only 5.48\\% across various attack\nscenarios. Moreover, instead of refusing to generate or producing black images\nfor unsafe prompts, \\textbf{SafeGuider} generates safe and meaningful images,\nenhancing its practical utility. In addition, SafeGuider is not limited to the\nSD model and can be effectively applied to other text-to-image models, such as\nthe Flux model, demonstrating its versatility and adaptability across different\narchitectures. We hope that SafeGuider can shed some light on the practical\ndeployment of secure text-to-image systems.",
    "published": "2025-10-05T10:24:48Z",
    "updated": "2025-10-08T04:00:39Z",
    "link": "http://arxiv.org/pdf/2510.05173v2.pdf",
    "category": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "I.2"
    ],
    "authors": [
      "Peigui Qi",
      "Kunsheng Tang",
      "Wenbo Zhou",
      "Weiming Zhang",
      "Nenghai Yu",
      "Tianwei Zhang",
      "Qing Guo",
      "Jie Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2409.00743v3",
    "title": "Interpretable Clustering: A Survey",
    "summary": "In recent years, much of the research on clustering algorithms has primarily\nfocused on enhancing their accuracy and efficiency, frequently at the expense\nof interpretability. However, as these methods are increasingly being applied\nin high-stakes domains such as healthcare, finance, and autonomous systems, the\nneed for transparent and interpretable clustering outcomes has become a\ncritical concern. This is not only necessary for gaining user trust but also\nfor satisfying the growing ethical and regulatory demands in these fields.\nEnsuring that decisions derived from clustering algorithms can be clearly\nunderstood and justified is now a fundamental requirement. To address this\nneed, this paper provides a comprehensive and structured review of the current\nstate of explainable clustering algorithms, identifying key criteria to\ndistinguish between various methods. These insights can effectively assist\nresearchers in making informed decisions about the most suitable explainable\nclustering methods for specific application contexts, while also promoting the\ndevelopment and adoption of clustering algorithms that are both efficient and\ntransparent. For convenient access and reference, an open repository organizes\nrepresentative and emerging interpretable clustering methods under the taxonomy\nproposed in this survey, available at\nhttps://github.com/hulianyu/Awesome-Interpretable-Clustering",
    "published": "2024-09-01T15:09:51Z",
    "updated": "2025-10-08T03:50:33Z",
    "link": "http://arxiv.org/pdf/2409.00743v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "J.0; I.5; I.2.6; I.2.4; H.1"
    ],
    "authors": [
      "Lianyu Hu",
      "Mudi Jiang",
      "Junjie Dong",
      "Xinying Liu",
      "Zengyou He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.12891v4",
    "title": "TIME: A Multi-level Benchmark for Temporal Reasoning of LLMs in\n  Real-World Scenarios",
    "summary": "Temporal reasoning is pivotal for Large Language Models (LLMs) to comprehend\nthe real world. However, existing works neglect the real-world challenges for\ntemporal reasoning: (1) intensive temporal information, (2) fast-changing event\ndynamics, and (3) complex temporal dependencies in social interactions. To\nbridge this gap, we propose a multi-level benchmark TIME, designed for temporal\nreasoning in real-world scenarios. TIME consists of 38,522 QA pairs, covering 3\nlevels with 11 fine-grained sub-tasks. This benchmark encompasses 3\nsub-datasets reflecting different real-world challenges: TIME-Wiki, TIME-News,\nand TIME-Dial. We conduct extensive experiments on reasoning models and\nnon-reasoning models. And we conducted an in-depth analysis of temporal\nreasoning performance across diverse real-world scenarios and tasks, and\nsummarized the impact of test-time scaling on temporal reasoning capabilities.\nAdditionally, we release TIME-Lite, a human-annotated subset to foster future\nresearch and standardized evaluation in temporal reasoning. The code is\navailable at https://github.com/sylvain-wei/TIME , the dataset is available at\nhttps://huggingface.co/datasets/SylvainWei/TIME , and the project page link is\nhttps://sylvain-wei.github.io/TIME/ .",
    "published": "2025-05-19T09:22:02Z",
    "updated": "2025-10-08T03:45:45Z",
    "link": "http://arxiv.org/pdf/2505.12891v4.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Shaohang Wei",
      "Wei Li",
      "Feifan Song",
      "Wen Luo",
      "Tianyi Zhuang",
      "Haochen Tan",
      "Zhijiang Guo",
      "Houfeng Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.26281v2",
    "title": "Point2RBox-v3: Self-Bootstrapping from Point Annotations via Integrated\n  Pseudo-Label Refinement and Utilization",
    "summary": "Driven by the growing need for Oriented Object Detection (OOD), learning from\npoint annotations under a weakly-supervised framework has emerged as a\npromising alternative to costly and laborious manual labeling. In this paper,\nwe discuss two deficiencies in existing point-supervised methods: inefficient\nutilization and poor quality of pseudo labels. Therefore, we present\nPoint2RBox-v3. At the core are two principles: 1) Progressive Label Assignment\n(PLA). It dynamically estimates instance sizes in a coarse yet intelligent\nmanner at different stages of the training process, enabling the use of label\nassignment methods. 2) Prior-Guided Dynamic Mask Loss (PGDM-Loss). It is an\nenhancement of the Voronoi Watershed Loss from Point2RBox-v2, which overcomes\nthe shortcomings of Watershed in its poor performance in sparse scenes and\nSAM's poor performance in dense scenes. To our knowledge, Point2RBox-v3 is the\nfirst model to employ dynamic pseudo labels for label assignment, and it\ncreatively complements the advantages of SAM model with the watershed\nalgorithm, which achieves excellent performance in both sparse and dense\nscenes. Our solution gives competitive performance, especially in scenarios\nwith large variations in object size or sparse object occurrences:\n66.09%/56.86%/41.28%/46.40%/19.60%/45.96% on\nDOTA-v1.0/DOTA-v1.5/DOTA-v2.0/DIOR/STAR/RSAR.",
    "published": "2025-09-30T14:01:59Z",
    "updated": "2025-10-08T03:36:37Z",
    "link": "http://arxiv.org/pdf/2509.26281v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Teng Zhang",
      "Ziqian Fan",
      "Mingxin Liu",
      "Xin Zhang",
      "Xudong Lu",
      "Wentong Li",
      "Yue Zhou",
      "Yi Yu",
      "Xiang Li",
      "Junchi Yan",
      "Xue Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.17671v3",
    "title": "Consistent Opponent Modeling of Static Opponents in\n  Imperfect-Information Games",
    "summary": "The goal of agents in multi-agent environments is to maximize total reward\nagainst the opposing agents that are encountered. Following a game-theoretic\nsolution concept, such as Nash equilibrium, may obtain a strong performance in\nsome settings; however, such approaches fail to capitalize on historical and\nobserved data from repeated interactions against our opponents. Opponent\nmodeling algorithms integrate machine learning techniques to exploit suboptimal\nopponents utilizing available data; however, the effectiveness of such\napproaches in imperfect-information games to date is quite limited. We show\nthat existing opponent modeling approaches fail to satisfy a simple desirable\nproperty even against static opponents drawn from a known prior distribution;\nnamely, they do not guarantee that the model approaches the opponent's true\nstrategy even in the limit as the number of game iterations approaches\ninfinity. We develop a new algorithm that is able to achieve this property and\nruns efficiently by solving a convex minimization problem based on the\nsequence-form game representation using projected gradient descent. The\nalgorithm is guaranteed to efficiently converge to the opponent's true strategy\ngiven observations from gameplay and possibly additional historical data if it\nis available.",
    "published": "2025-08-25T05:08:49Z",
    "updated": "2025-10-08T03:32:46Z",
    "link": "http://arxiv.org/pdf/2508.17671v3.pdf",
    "category": [
      "cs.GT",
      "cs.AI",
      "cs.MA",
      "econ.TH"
    ],
    "authors": [
      "Sam Ganzfried"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.13055v2",
    "title": "Mitigating Cross-Modal Distraction and Ensuring Geometric Feasibility\n  via Affordance-Guided and Self-Consistent MLLMs for Task Planning in\n  Instruction-Following Manipulation",
    "summary": "We investigate the use of Multimodal Large Language Models (MLLMs) with\nin-context learning for closed-loop task planning in instruction-following\nmanipulation. We identify four essential requirements for successful task\nplanning: quantity estimation, reachability analysis, relative positioning, and\ncollision avoidance. However, existing benchmarks fail to support holistic\nevaluation across all these aspects. To address this gap, we introduce\n\\textbf{QuARC} (Quantity, Analysis, Relative positioning, Collision), a new\nbenchmark based on a food preparation scenario that integrates all four\nchallenges. Using QuARC, we reveal two major limitations of current MLLMs:\ncross-modal distraction and geometric infeasibility. To tackle these, we adapt\nChain-of-Thought with Self-Consistency to mitigate reasoning loss from\ncross-modal distractions and incorporate an affordance predictor to guide\nplanning based on geometric feasibility. Our comprehensive evaluation analyzes\nperformance across multiple baselines and explains sources of improvement. Our\nmethod achieves a 76.7\\% success rate on the benchmark, significantly\noutperforming the ViLa baseline (36.7\\%), without requiring additional\nfinetuning. Code and dataset are available at\nhttps://hcis-lab.github.io/Affordance-Guided-Self-Consistent-MLLM.",
    "published": "2025-03-17T11:01:02Z",
    "updated": "2025-10-08T03:30:23Z",
    "link": "http://arxiv.org/pdf/2503.13055v2.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Yu-Hong Shen",
      "Chuan-Yu Wu",
      "Yi-Ru Yang",
      "Yen-Ling Tai",
      "Yi-Ting Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.04205v2",
    "title": "PolyKAN: A Polyhedral Analysis Framework for Provable and Approximately\n  Optimal KAN Compression",
    "summary": "Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to\ntraditional Multi-Layer Perceptrons (MLPs), offering enhanced interpretability\nand a solid mathematical foundation. However, their parameter efficiency\nremains a significant challenge for practical deployment. This paper introduces\nPolyKAN, a novel theoretical framework for KAN compression that provides formal\nguarantees on both model size reduction and approximation error. By leveraging\nthe inherent piecewise polynomial structure of KANs, we formulate the\ncompression problem as a polyhedral region merging task. We establish a\nrigorous polyhedral characterization of KANs, develop a complete theory of\n$\\epsilon$-equivalent compression, and design a dynamic programming algorithm\nthat achieves approximately optimal compression under specified error bounds.\nOur theoretical analysis demonstrates that PolyKAN achieves provably\nnear-optimal compression while maintaining strict error control, with\nguaranteed global optimality for univariate spline functions. This framework\nprovides the first formal foundation for KAN compression with mathematical\nguarantees, opening new directions for the efficient deployment of\ninterpretable neural architectures.",
    "published": "2025-10-05T13:39:18Z",
    "updated": "2025-10-08T03:27:57Z",
    "link": "http://arxiv.org/pdf/2510.04205v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA",
      "math.OC",
      "68T07, 41A15, 52B11",
      "F.2.2; G.1.2; I.2.6"
    ],
    "authors": [
      "Di Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06605v1",
    "title": "Reading Between the Lines: Towards Reliable Black-box LLM Fingerprinting\n  via Zeroth-order Gradient Estimation",
    "summary": "The substantial investment required to develop Large Language Models (LLMs)\nmakes them valuable intellectual property, raising significant concerns about\ncopyright protection. LLM fingerprinting has emerged as a key technique to\naddress this, which aims to verify a model's origin by extracting an intrinsic,\nunique signature (a \"fingerprint\") and comparing it to that of a source model\nto identify illicit copies. However, existing black-box fingerprinting methods\noften fail to generate distinctive LLM fingerprints. This ineffectiveness\narises because black-box methods typically rely on model outputs, which lose\ncritical information about the model's unique parameters due to the usage of\nnon-linear functions. To address this, we first leverage Fisher Information\nTheory to formally demonstrate that the gradient of the model's input is a more\ninformative feature for fingerprinting than the output. Based on this insight,\nwe propose ZeroPrint, a novel method that approximates these information-rich\ngradients in a black-box setting using zeroth-order estimation. ZeroPrint\novercomes the challenge of applying this to discrete text by simulating input\nperturbations via semantic-preserving word substitutions. This operation allows\nZeroPrint to estimate the model's Jacobian matrix as a unique fingerprint.\nExperiments on the standard benchmark show ZeroPrint achieves a\nstate-of-the-art effectiveness and robustness, significantly outperforming\nexisting black-box methods.",
    "published": "2025-10-08T03:27:38Z",
    "updated": "2025-10-08T03:27:38Z",
    "link": "http://arxiv.org/pdf/2510.06605v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Shuo Shao",
      "Yiming Li",
      "Hongwei Yao",
      "Yifei Chen",
      "Yuchen Yang",
      "Zhan Qin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06600v1",
    "title": "Fine-Grained Emotion Recognition via In-Context Learning",
    "summary": "Fine-grained emotion recognition aims to identify the emotional type in\nqueries through reasoning and decision-making processes, playing a crucial role\nin various systems. Recent methods use In-Context Learning (ICL), enhancing the\nrepresentation of queries in the reasoning process through semantically similar\nexamples, while further improving emotion recognition by explaining the\nreasoning mechanisms. However, these methods enhance the reasoning process but\noverlook the decision-making process. This paper investigates decision-making\nin fine-grained emotion recognition through prototype theory. We show that ICL\nrelies on similarity matching between query representations and emotional\nprototypes within the model, where emotion-accurate representations are\ncritical. However, semantically similar examples often introduce emotional\ndiscrepancies, hindering accurate representations and causing errors. To\naddress this, we propose Emotion In-Context Learning (EICL), which introduces\nemotionally similar examples and uses a dynamic soft-label strategy to improve\nquery representations in the emotion reasoning process. A two-stage exclusion\nstrategy is then employed to assess similarity from multiple angles, further\noptimizing the decision-making process. Extensive experiments show that EICL\nsignificantly outperforms ICL on multiple datasets.",
    "published": "2025-10-08T03:17:09Z",
    "updated": "2025-10-08T03:17:09Z",
    "link": "http://arxiv.org/pdf/2510.06600v1.pdf",
    "category": [
      "cs.AI",
      "H.3.3; I.2.7"
    ],
    "authors": [
      "Zhaochun Ren",
      "Zhou Yang",
      "Chenglong Ye",
      "Haizhou Sun",
      "Chao Chen",
      "Xiaofei Zhu",
      "Xiangwen Liao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06596v1",
    "title": "SDQM: Synthetic Data Quality Metric for Object Detection Dataset\n  Evaluation",
    "summary": "The performance of machine learning models depends heavily on training data.\nThe scarcity of large-scale, well-annotated datasets poses significant\nchallenges in creating robust models. To address this, synthetic data generated\nthrough simulations and generative models has emerged as a promising solution,\nenhancing dataset diversity and improving the performance, reliability, and\nresilience of models. However, evaluating the quality of this generated data\nrequires an effective metric. This paper introduces the Synthetic Dataset\nQuality Metric (SDQM) to assess data quality for object detection tasks without\nrequiring model training to converge. This metric enables more efficient\ngeneration and selection of synthetic datasets, addressing a key challenge in\nresource-constrained object detection tasks. In our experiments, SDQM\ndemonstrated a strong correlation with the mean Average Precision (mAP) scores\nof YOLOv11, a leading object detection model, while previous metrics only\nexhibited moderate or weak correlations. Additionally, it provides actionable\ninsights for improving dataset quality, minimizing the need for costly\niterative training. This scalable and efficient metric sets a new standard for\nevaluating synthetic data. The code for SDQM is available at\nhttps://github.com/ayushzenith/SDQM",
    "published": "2025-10-08T03:01:26Z",
    "updated": "2025-10-08T03:01:26Z",
    "link": "http://arxiv.org/pdf/2510.06596v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "authors": [
      "Ayush Zenith",
      "Arnold Zumbrun",
      "Neel Raut",
      "Jing Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.15174v2",
    "title": "SMARTER: A Data-efficient Framework to Improve Toxicity Detection with\n  Explanation via Self-augmenting Large Language Models",
    "summary": "WARNING: This paper contains examples of offensive materials. To address the\nproliferation of toxic content on social media, we introduce SMARTER, we\nintroduce SMARTER, a data-efficient two-stage framework for explainable content\nmoderation using Large Language Models (LLMs). In Stage 1, we leverage LLMs'\nown outputs to generate synthetic explanations for both correct and incorrect\nlabels, enabling alignment via preference optimization with minimal human\nsupervision. In Stage 2, we refine explanation quality through cross-model\ntraining, allowing weaker models to align stylistically and semantically with\nstronger ones. Experiments on three benchmark tasks -- HateXplain, Latent Hate,\nand Implicit Hate -- demonstrate that SMARTER enables LLMs to achieve up to a\n13.5% macro-F1 improvement over standard few-shot baselines while using only a\nfraction of the full training data. Our framework offers a scalable strategy\nfor low-resource settings by harnessing LLMs' self-improving capabilities for\nboth classification and explanation.",
    "published": "2025-09-18T17:30:36Z",
    "updated": "2025-10-08T03:00:50Z",
    "link": "http://arxiv.org/pdf/2509.15174v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Huy Nghiem",
      "Advik Sachdeva",
      "Hal Daumé III"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.01861v3",
    "title": "ACT-Tensor: Tensor Completion Framework for Financial Dataset Imputation",
    "summary": "Missing data in financial panels presents a critical obstacle, undermining\nasset-pricing models and reducing the effectiveness of investment strategies.\nSuch panels are often inherently multi-dimensional, spanning firms, time, and\nfinancial variables, which adds complexity to the imputation task. Conventional\nimputation methods often fail by flattening the data's multidimensional\nstructure, struggling with heterogeneous missingness patterns, or overfitting\nin the face of extreme data sparsity. To address these limitations, we\nintroduce an Adaptive, Cluster-based Temporal smoothing tensor completion\nframework (ACT-Tensor) tailored for severely and heterogeneously missing\nmulti-dimensional financial data panels. ACT-Tensor incorporates two key\ninnovations: a cluster-based completion module that captures cross-sectional\nheterogeneity by learning group-specific latent structures; and a temporal\nsmoothing module that proactively removes short-lived noise while preserving\nslow-moving fundamental trends. Extensive experiments show that ACT-Tensor\nconsistently outperforms state-of-the-art benchmarks in terms of imputation\naccuracy across a range of missing data regimes, including extreme sparsity\nscenarios. To assess its practical financial utility, we evaluate the imputed\ndata with an asset-pricing pipeline tailored for tensor-structured financial\ndata. Results show that ACT-Tensor not only reduces pricing errors but also\nsignificantly improves risk-adjusted returns of the constructed portfolio.\nThese findings confirm that our method delivers highly accurate and informative\nimputations, offering substantial value for financial decision-making.",
    "published": "2025-08-03T17:28:57Z",
    "updated": "2025-10-08T02:59:25Z",
    "link": "http://arxiv.org/pdf/2508.01861v3.pdf",
    "category": [
      "stat.AP",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Junyi Mo",
      "Jiayu Li",
      "Duo Zhang",
      "Elynn Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.17832v3",
    "title": "MM-PoisonRAG: Disrupting Multimodal RAG with Local and Global Poisoning\n  Attacks",
    "summary": "Multimodal large language models with Retrieval Augmented Generation (RAG)\nhave significantly advanced tasks such as multimodal question answering by\ngrounding responses in external text and images. This grounding improves\nfactuality, reduces hallucination, and extends reasoning beyond parametric\nknowledge. However, this reliance on external knowledge poses a critical yet\nunderexplored safety risk: knowledge poisoning attacks, where adversaries\ndeliberately inject adversarial multimodal content into external knowledge\nbases to steer model toward generating incorrect or even harmful responses. To\nexpose such vulnerabilities, we propose MM-PoisonRAG, the first framework to\nsystematically design knowledge poisoning in multimodal RAG. We introduce two\ncomplementary attack strategies: Localized Poisoning Attack (LPA), which\nimplants targeted multimodal misinformation to manipulate specific queries, and\nGlobalized Poisoning Attack (GPA), which inserts a single adversarial knowledge\nto broadly disrupt reasoning and induce nonsensical responses across all\nqueries. Comprehensive experiments across tasks, models, and access settings\nshow that LPA achieves targeted manipulation with attack success rates of up to\n56%, while GPA completely disrupts model generation to 0% accuracy with just a\nsingle adversarial knowledge injection. Our results reveal the fragility of\nmultimodal RAG and highlight the urgent need for defenses against knowledge\npoisoning.",
    "published": "2025-02-25T04:23:59Z",
    "updated": "2025-10-08T02:51:51Z",
    "link": "http://arxiv.org/pdf/2502.17832v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CV"
    ],
    "authors": [
      "Hyeonjeong Ha",
      "Qiusi Zhan",
      "Jeonghwan Kim",
      "Dimitrios Bralios",
      "Saikrishna Sanniboina",
      "Nanyun Peng",
      "Kai-Wei Chang",
      "Daniel Kang",
      "Heng Ji"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06587v1",
    "title": "WebDART: Dynamic Decomposition and Re-planning for Complex Web Tasks",
    "summary": "Large language model (LLM) agents are becoming competent at straightforward\nweb tasks, such as opening an item page or submitting a form, but still\nstruggle with objectives that require long horizon navigation, large scale\ninformation extraction, and reasoning under constraints. We present WebDART, a\ngeneral framework that enables a single LLM to handle such complex chores.\nWebDART (i) dynamically decomposes each objective into three focused subtasks:\nnavigation, information extraction, and execution, so the model concentrates on\none skill at a time, and (ii) continuously replans the decomposition as new\nwebpages are revealed, taking advantage of newly discovered filters or\nshortcuts and avoiding redundant exploration. Evaluated on WebChoreArena,\nWebDART lifts success rates by up to 13.7 percentage points over previous SOTA\nagents, while matching their performance on the easier WebArena suite and\ncompleting tasks with up to 14.7 fewer navigation steps.",
    "published": "2025-10-08T02:34:59Z",
    "updated": "2025-10-08T02:34:59Z",
    "link": "http://arxiv.org/pdf/2510.06587v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Jingbo Yang",
      "Bairu Hou",
      "Wei Wei",
      "Shiyu Chang",
      "Yujia Bao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.01382v4",
    "title": "An Illusion of Progress? Assessing the Current State of Web Agents",
    "summary": "As digitalization and cloud technologies evolve, the web is becoming\nincreasingly important in the modern society. Autonomous web agents based on\nlarge language models (LLMs) hold a great potential in work automation. It is\ntherefore important to accurately measure and monitor the progression of their\ncapabilities. In this work, we conduct a comprehensive and rigorous assessment\nof the current state of web agents. Our results depict a very different picture\nof the competency of current agents, suggesting over-optimism in previously\nreported results. This gap can be attributed to shortcomings in existing\nbenchmarks. We introduce Online-Mind2Web, an online evaluation benchmark\nconsisting of 300 diverse and realistic tasks spanning 136 websites. It enables\nus to evaluate web agents under a setting that approximates how real users use\nthese agents. To facilitate more scalable evaluation and development, we also\ndevelop a novel LLM-as-a-Judge automatic evaluation method and show that it can\nachieve around 85% agreement with human judgment, substantially higher than\nexisting methods. Finally, we present the first comprehensive comparative\nanalysis of current web agents, highlighting both their strengths and\nlimitations to inspire future research.",
    "published": "2025-04-02T05:51:29Z",
    "updated": "2025-10-08T02:22:45Z",
    "link": "http://arxiv.org/pdf/2504.01382v4.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Tianci Xue",
      "Weijian Qi",
      "Tianneng Shi",
      "Chan Hee Song",
      "Boyu Gou",
      "Dawn Song",
      "Huan Sun",
      "Yu Su"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.02298v3",
    "title": "CAPO: Towards Enhancing LLM Reasoning through Generative Credit\n  Assignment",
    "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has improved the\nreasoning abilities of Large Language Models (LLMs) by using rule-based binary\nfeedback. However, current RLVR methods typically assign the same reward to\nevery token. This coarse-grained feedback hampers precise credit assignment,\nmaking it hard for models to identify which reasoning steps lead to success or\nfailure, and often results in suboptimal policies. Methods like PPO provide\ncredit assignment by value estimation, but yield inaccurate and unverifiable\nsignals due to limited sampling. On the other hand, methods using Process\nReward Models can provide step-wise rewards but suffer from several key\nlimitations: they require high-quality process supervision labels, the feedback\nis unreliable due to probabilistic reward modeling, and their application in\nonline reinforcement learning (RL) is time-consuming. To overcome these\nlimitations, we introduce a simple but efficient method-Credit Assignment\nPolicy Optimization (CAPO). Instead of training auxiliary models, CAPO directly\nleverages an off-the-shelf, general-purpose LLM as a Generative Process Reward\nModel (LLM-as-GenPRM) to generate all step-wise critique by one pass only based\non the correctness of the step itself, providing deterministic token-level\ncredits to refine the tokens that were originally assigned identical rule-based\nrewards. To further enhance the accuracy and robustness, we employ voting\nmechanisms that scale with the number of generated critiques. Extensive\nexperiments on various backbones like Llama and Qwen models show that CAPO\nconsistently outperforms supervised learning-based and RL-based fine-tuning\nmethods across four challenging mathematical benchmarks and three out-of-domain\nbenchmarks. Further analysis shows that CAPO can help the model to foster the\nlearning of correct reasoning pathways leading to correct answers.",
    "published": "2025-08-04T11:06:08Z",
    "updated": "2025-10-08T02:10:47Z",
    "link": "http://arxiv.org/pdf/2508.02298v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Guofu Xie",
      "Yunsheng Shi",
      "Hongtao Tian",
      "Ting Yao",
      "Xiao Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.02360v2",
    "title": "Spiral of Silence in Large Language Model Agents",
    "summary": "The Spiral of Silence (SoS) theory holds that individuals with minority views\noften refrain from speaking out for fear of social isolation, enabling majority\npositions to dominate public discourse. When the 'agents' are large language\nmodels (LLMs), however, the classical psychological explanation is not directly\napplicable, since SoS was developed for human societies. This raises a central\nquestion: can SoS-like dynamics nevertheless emerge from purely statistical\nlanguage generation in LLM collectives? We propose an evaluation framework for\nexamining SoS in LLM agents. Specifically, we consider four controlled\nconditions that systematically vary the availability of 'History' and 'Persona'\nsignals. Opinion dynamics are assessed using trend tests such as Mann-Kendall\nand Spearman's rank, along with concentration measures including kurtosis and\ninterquartile range. Experiments across open-source and closed-source models\nshow that history and persona together produce strong majority dominance and\nreplicate SoS patterns; history signals alone induce strong anchoring; and\npersona signals alone foster diverse but uncorrelated opinions, indicating that\nwithout historical anchoring, SoS dynamics cannot emerge. The work bridges\ncomputational sociology and responsible AI design, highlighting the need to\nmonitor and mitigate emergent conformity in LLM-agent systems.",
    "published": "2025-09-28T08:59:54Z",
    "updated": "2025-10-08T01:58:17Z",
    "link": "http://arxiv.org/pdf/2510.02360v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Mingze Zhong",
      "Meng Fang",
      "Zijing Shi",
      "Yuxuan Huang",
      "Shunfeng Zheng",
      "Yali Du",
      "Ling Chen",
      "Jun Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.05858v2",
    "title": "DACP: Domain-Adaptive Continual Pre-Training of Large Language Models\n  for Phone Conversation Summarization",
    "summary": "Large language models (LLMs) have achieved impressive performance in text\nsummarization, yet their performance often falls short when applied to\nspecialized domains that differ from their original pre-training distribution.\nWhile fine-tuning can improve summarization quality, it typically relies on\ncostly and scarce high-quality labeled data. In this work, we explore continual\npre-training as a scalable, self-supervised approach to adapt LLMs for\ndownstream summarization tasks, particularly in the context of noisy real-world\nconversation transcripts. We conduct extensive experiments using large-scale,\nunlabeled business conversation data to investigate whether continual\npre-training enhances model capabilities in conversational summarization. Our\nresults demonstrate that continual pre-training yields substantial gains in\nboth in-domain and out-of-domain summarization benchmarks, while maintaining\nstrong generalization and robustness. We also analyze the effects of data\nselection strategies, providing practical guidelines for applying continual\npre-training in summarization-focused industrial applications.",
    "published": "2025-10-07T12:26:19Z",
    "updated": "2025-10-08T01:55:53Z",
    "link": "http://arxiv.org/pdf/2510.05858v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Xue-Yong Fu",
      "Elena Khasanova",
      "Md Tahmid Rahman Laskar",
      "Harsh Saini",
      "Shashi Bhushan TN"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.07030v2",
    "title": "A Minimalist Bayesian Framework for Stochastic Optimization",
    "summary": "The Bayesian paradigm offers principled tools for sequential decision-making\nunder uncertainty, but its reliance on a probabilistic model for all parameters\ncan hinder the incorporation of complex structural constraints. We introduce a\nminimalist Bayesian framework that places a prior only on the component of\ninterest, such as the location of the optimum. Nuisance parameters are\neliminated via profile likelihood, which naturally handles constraints. As a\ndirect instantiation, we develop a MINimalist Thompson Sampling (MINTS)\nalgorithm. Our framework accommodates structured problems, including\ncontinuum-armed Lipschitz bandits and dynamic pricing. It also provides a\nprobabilistic lens on classical convex optimization algorithms such as the\ncenter of gravity and ellipsoid methods. We further analyze MINTS for\nmulti-armed bandits and establish near-optimal regret guarantees.",
    "published": "2025-09-07T19:31:12Z",
    "updated": "2025-10-08T01:52:40Z",
    "link": "http://arxiv.org/pdf/2509.07030v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "authors": [
      "Kaizheng Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.08833v2",
    "title": "An Investigation of Robustness of LLMs in Mathematical Reasoning:\n  Benchmarking with Mathematically-Equivalent Transformation of Advanced\n  Mathematical Problems",
    "summary": "In this paper, we introduce a systematic framework beyond conventional method\nto assess LLMs' mathematical-reasoning robustness by stress-testing them on\nadvanced math problems that are mathematically equivalent but with linguistic\nand parametric variation. These transformations allow us to measure the\nsensitivity of LLMs to non-mathematical perturbations, thereby enabling a more\naccurate evaluation of their mathematical reasoning capabilities. Using this\nnew evaluation methodology, we created PutnamGAP, a new benchmark dataset with\nmultiple mathematically-equivalent variations of competition-level math\nproblems. With the new dataset, we evaluate multiple families of representative\nLLMs and examine their robustness. Across 18 commercial and open-source models\nwe observe sharp performance degradation on the variants. OpenAI's flagship\nreasoning model, O3, scores 51.5% on the originals but drops by 4.7 percentage\npoints on surface-renaming variants, and by 12.9 percentage points on\nparametric variants, while smaller models fare far worse. Overall, the results\nshow that the proposed new evaluation methodology is effective for deepening\nour understanding of the robustness of LLMs and generating new insights for\nfurther improving their mathematical reasoning capabilities.",
    "published": "2025-08-12T10:40:33Z",
    "updated": "2025-10-08T01:46:12Z",
    "link": "http://arxiv.org/pdf/2508.08833v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Yuren Hao",
      "Xiang Wan",
      "ChengXiang Zhai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06567v1",
    "title": "The Framework That Survives Bad Models: Human-AI Collaboration For\n  Clinical Trials",
    "summary": "Artificial intelligence (AI) holds great promise for supporting clinical\ntrials, from patient recruitment and endpoint assessment to treatment response\nprediction. However, deploying AI without safeguards poses significant risks,\nparticularly when evaluating patient endpoints that directly impact trial\nconclusions. We compared two AI frameworks against human-only assessment for\nmedical image-based disease evaluation, measuring cost, accuracy, robustness,\nand generalization ability. To stress-test these frameworks, we injected bad\nmodels, ranging from random guesses to naive predictions, to ensure that\nobserved treatment effects remain valid even under severe model degradation. We\nevaluated the frameworks using two randomized controlled trials with endpoints\nderived from spinal X-ray images. Our findings indicate that using AI as a\nsupporting reader (AI-SR) is the most suitable approach for clinical trials, as\nit meets all criteria across various model types, even with bad models. This\nmethod consistently provides reliable disease estimation, preserves clinical\ntrial treatment effect estimates and conclusions, and retains these advantages\nwhen applied to different populations.",
    "published": "2025-10-08T01:40:41Z",
    "updated": "2025-10-08T01:40:41Z",
    "link": "http://arxiv.org/pdf/2510.06567v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "eess.IV"
    ],
    "authors": [
      "Yao Chen",
      "David Ohlssen",
      "Aimee Readie",
      "Gregory Ligozio",
      "Ruvie Martin",
      "Thibaud Coroller"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.05465v2",
    "title": "VAL-Bench: Measuring Value Alignment in Language Models",
    "summary": "Large language models (LLMs) are increasingly used for tasks where outputs\nshape human decisions, so it is critical to test whether their responses\nreflect consistent human values. Existing benchmarks mostly track refusals or\npredefined safety violations, but these only check rule compliance and do not\nreveal whether a model upholds a coherent value system when facing\ncontroversial real-world issues. We introduce the Value ALignment Benchmark\n(VAL-Bench), which evaluates whether models maintain a stable value stance\nacross paired prompts that frame opposing sides of public debates. VAL-Bench\nconsists of 115K such pairs from Wikipedia's controversial sections. A\nwell-aligned model should express similar underlying views regardless of\nframing, which we measure using an LLM-as-judge to score agreement or\ndivergence between paired responses. Applied across leading open- and\nclosed-source models, the benchmark reveals large variation in alignment and\nhighlights trade-offs between safety strategies (e.g., refusals) and more\nexpressive value systems. By providing a scalable, reproducible benchmark,\nVAL-Bench enables systematic comparison of how reliably LLMs embody human\nvalues.",
    "published": "2025-10-06T23:55:48Z",
    "updated": "2025-10-08T01:35:03Z",
    "link": "http://arxiv.org/pdf/2510.05465v2.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Aman Gupta",
      "Denny O'Shea",
      "Fazl Barez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06564v1",
    "title": "HSNet: Heterogeneous Subgraph Network for Single Image Super-resolution",
    "summary": "Existing deep learning approaches for image super-resolution, particularly\nthose based on CNNs and attention mechanisms, often suffer from structural\ninflexibility. Although graph-based methods offer greater representational\nadaptability, they are frequently impeded by excessive computational\ncomplexity. To overcome these limitations, this paper proposes the\nHeterogeneous Subgraph Network (HSNet), a novel framework that efficiently\nleverages graph modeling while maintaining computational feasibility. The core\nidea of HSNet is to decompose the global graph into manageable sub-components.\nFirst, we introduce the Constructive Subgraph Set Block (CSSB), which generates\na diverse set of complementary subgraphs. Rather than relying on a single\nmonolithic graph, CSSB captures heterogeneous characteristics of the image by\nmodeling different relational patterns and feature interactions, producing a\nrich ensemble of both local and global graph structures. Subsequently, the\nSubgraph Aggregation Block (SAB) integrates the representations embedded across\nthese subgraphs. Through adaptive weighting and fusion of multi-graph features,\nSAB constructs a comprehensive and discriminative representation that captures\nintricate interdependencies. Furthermore, a Node Sampling Strategy (NSS) is\ndesigned to selectively retain the most salient features, thereby enhancing\naccuracy while reducing computational overhead. Extensive experiments\ndemonstrate that HSNet achieves state-of-the-art performance, effectively\nbalancing reconstruction quality with computational efficiency. The code will\nbe made publicly available.",
    "published": "2025-10-08T01:32:52Z",
    "updated": "2025-10-08T01:32:52Z",
    "link": "http://arxiv.org/pdf/2510.06564v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Qiongyang Hu",
      "Wenyang Liu",
      "Wenbin Zou",
      "Yuejiao Su",
      "Lap-Pui Chau",
      "Yi Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06559v1",
    "title": "The Algebra of Meaning: Why Machines Need Montague More Than Moore's Law",
    "summary": "Contemporary language models are fluent yet routinely mis-handle the types of\nmeaning their outputs entail. We argue that hallucination, brittle moderation,\nand opaque compliance outcomes are symptoms of missing type-theoretic semantics\nrather than data or scale limitations. Building on Montague's view of language\nas typed, compositional algebra, we recast alignment as a parsing problem:\nnatural-language inputs must be compiled into structures that make explicit\ntheir descriptive, normative, and legal dimensions under context.\n  We present Savassan, a neuro-symbolic architecture that compiles utterances\ninto Montague-style logical forms and maps them to typed ontologies extended\nwith deontic operators and jurisdictional contexts. Neural components extract\ncandidate structures from unstructured inputs; symbolic components perform type\nchecking, constraint reasoning, and cross-jurisdiction mapping to produce\ncompliance-aware guidance rather than binary censorship. In cross-border\nscenarios, the system \"parses once\" (e.g., defect claim(product x, company y))\nand projects the result into multiple legal ontologies (e.g., defamation risk\nin KR/JP, protected opinion in US, GDPR checks in EU), composing outcomes into\na single, explainable decision.\n  This paper contributes: (i) a diagnosis of hallucination as a type error;\n(ii) a formal Montague-ontology bridge for business/legal reasoning; and (iii)\na production-oriented design that embeds typed interfaces across the pipeline.\nWe outline an evaluation plan using legal reasoning benchmarks and synthetic\nmulti-jurisdiction suites. Our position is that trustworthy autonomy requires\ncompositional typing of meaning, enabling systems to reason about what is\ndescribed, what is prescribed, and what incurs liability within a unified\nalgebra of meaning.",
    "published": "2025-10-08T01:22:26Z",
    "updated": "2025-10-08T01:22:26Z",
    "link": "http://arxiv.org/pdf/2510.06559v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LO"
    ],
    "authors": [
      "Cheonkam Jeong",
      "Sungdo Kim",
      "Jewoo Park"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06189v2",
    "title": "Barbarians at the Gate: How AI is Upending Systems Research",
    "summary": "Artificial Intelligence (AI) is starting to transform the research process as\nwe know it by automating the discovery of new solutions. Given a task, the\ntypical AI-driven approach is (i) to generate a set of diverse solutions, and\nthen (ii) to verify these solutions and select one that solves the problem.\nCrucially, this approach assumes the existence of a reliable verifier, i.e.,\none that can accurately determine whether a solution solves the given problem.\nWe argue that systems research, long focused on designing and evaluating new\nperformance-oriented algorithms, is particularly well-suited for AI-driven\nsolution discovery. This is because system performance problems naturally admit\nreliable verifiers: solutions are typically implemented in real systems or\nsimulators, and verification reduces to running these software artifacts\nagainst predefined workloads and measuring performance. We term this approach\nas AI-Driven Research for Systems (ADRS), which iteratively generates,\nevaluates, and refines solutions. Using penEvolve, an existing open-source ADRS\ninstance, we present case studies across diverse domains, including load\nbalancing for multi-region cloud scheduling, Mixture-of-Experts inference,\nLLM-based SQL queries, and transaction scheduling. In multiple instances, ADRS\ndiscovers algorithms that outperform state-of-the-art human designs (e.g.,\nachieving up to 5.0x runtime improvements or 50% cost reductions). We distill\nbest practices for guiding algorithm evolution, from prompt design to evaluator\nconstruction, for existing frameworks. We then discuss the broader implications\nfor the systems community: as AI assumes a central role in algorithm design, we\nargue that human researchers will increasingly focus on problem formulation and\nstrategic guidance. Our results highlight both the disruptive potential and the\nurgent need to adapt systems research practices in the age of AI.",
    "published": "2025-10-07T17:49:24Z",
    "updated": "2025-10-08T01:21:49Z",
    "link": "http://arxiv.org/pdf/2510.06189v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Audrey Cheng",
      "Shu Liu",
      "Melissa Pan",
      "Zhifei Li",
      "Bowen Wang",
      "Alex Krentsel",
      "Tian Xia",
      "Mert Cemri",
      "Jongseok Park",
      "Shuo Yang",
      "Jeff Chen",
      "Lakshya Agrawal",
      "Aditya Desai",
      "Jiarong Xing",
      "Koushik Sen",
      "Matei Zaharia",
      "Ion Stoica"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06557v1",
    "title": "The Markovian Thinker",
    "summary": "Reinforcement learning (RL) has recently become a strong recipe for training\nreasoning LLMs that produce long chains of thought (LongCoT). Yet the standard\nRL \"thinking environment\", where the state is the prompt plus all prior\nreasoning tokens, makes the state unbounded and forces attention-based policies\nto pay quadratic compute as thoughts lengthen. We revisit the environment\nitself. We propose Markovian Thinking, a paradigm in which the policy advances\nreasoning while conditioning on a constant-size state, decoupling thinking\nlength from context size. As an immediate consequence this yields linear\ncompute with constant memory. We instantiate this idea with Delethink, an RL\nenvironment that structures reasoning into fixed-size chunks. Within each\nchunk, the model thinks as usual; at the boundary, the environment resets the\ncontext and reinitializes the prompt with a short carryover. Through RL, the\npolicy learns to write a textual state near the end of each chunk sufficient\nfor seamless continuation of reasoning after reset. Trained in this\nenvironment, an R1-Distill 1.5B model reasons in 8K-token chunks yet thinks up\nto 24K tokens, matching or surpassing LongCoT-RL trained with a 24K budget.\nWith test-time scaling, Delethink continues to improve where LongCoT plateaus.\nThe effect of linear compute is substantial: we empirically estimate at 96K\naverage thinking length LongCoT-RL costs 27 H100-months vs. 7 for Delethink.\nAnalysis at RL initialization shows off-the-shelf reasoning models (1.5B-120B)\noften sample Markovian traces zero-shot across diverse benchmarks, providing\npositive samples that make RL effective at scale. Our results show that\nredesigning the thinking environment is a powerful lever: it enables very long\nreasoning without quadratic overhead and opens a path toward efficient,\nscalable reasoning LLMs.",
    "published": "2025-10-08T01:18:13Z",
    "updated": "2025-10-08T01:18:13Z",
    "link": "http://arxiv.org/pdf/2510.06557v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Milad Aghajohari",
      "Kamran Chitsaz",
      "Amirhossein Kazemnejad",
      "Sarath Chandar",
      "Alessandro Sordoni",
      "Aaron Courville",
      "Siva Reddy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06545v1",
    "title": "Incoherence in goal-conditioned autoregressive models",
    "summary": "We investigate mathematically the notion of incoherence: a structural issue\nwith reinforcement learning policies derived by naive goal-conditioning of\nautoregressive models. We focus on the process of re-training models on their\nown actions, that is, fine-tuning offline-learned policies with online RL. We\nprove that it decreases incoherence and leads to an improvement in return, and\nwe aim to characterize the resulting trajectory of policies. By re-framing\nstandard notions of control-as-inference and soft Q learning, we establish a\nthree-way correspondence with two other ways of understanding the iterative\nre-training process: as folding the posterior into the reward and, in the\ndeterministic case, as decreasing the temperature parameter; the correspondence\nhas computational content via the training-inference trade-off. Through\nsoft-conditioning generative models, we discuss the link between incoherence\nand the effective horizon.",
    "published": "2025-10-08T00:52:13Z",
    "updated": "2025-10-08T00:52:13Z",
    "link": "http://arxiv.org/pdf/2510.06545v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Jacek Karwowski",
      "Raymond Douglas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06540v1",
    "title": "Scalable Policy-Based RL Algorithms for POMDPs",
    "summary": "The continuous nature of belief states in POMDPs presents significant\ncomputational challenges in learning the optimal policy. In this paper, we\nconsider an approach that solves a Partially Observable Reinforcement Learning\n(PORL) problem by approximating the corresponding POMDP model into a\nfinite-state Markov Decision Process (MDP) (called Superstate MDP). We first\nderive theoretical guarantees that improve upon prior work that relate the\noptimal value function of the transformed Superstate MDP to the optimal value\nfunction of the original POMDP. Next, we propose a policy-based learning\napproach with linear function approximation to learn the optimal policy for the\nSuperstate MDP. Consequently, our approach shows that a POMDP can be\napproximately solved using TD-learning followed by Policy Optimization by\ntreating it as an MDP, where the MDP state corresponds to a finite history. We\nshow that the approximation error decreases exponentially with the length of\nthis history. To the best of our knowledge, our finite-time bounds are the\nfirst to explicitly quantify the error introduced when applying standard TD\nlearning to a setting where the true dynamics are not Markovian.",
    "published": "2025-10-08T00:33:38Z",
    "updated": "2025-10-08T00:33:38Z",
    "link": "http://arxiv.org/pdf/2510.06540v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "authors": [
      "Ameya Anjarlekar",
      "Rasoul Etesami",
      "R Srikant"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06538v1",
    "title": "Auto-Prompt Ensemble for LLM Judge",
    "summary": "We present a novel framework that improves the reliability of LLM judges by\nselectively augmenting LLM with auxiliary evaluation dimensions. Existing LLM\njudges often miss crucial evaluation dimensions because they fail to recognize\nthe implicit standards underlying human assessments. To address this challenge,\nwe propose the Auto-Prompt Ensemble (APE), an adaptive framework that\nautomatically learns evaluation dimensions from its failure cases. APE\nincorporates a confidence-based ensemble mechanism to decide when to adopt the\njudgments from additional evaluation dimensions through a novel confidence\nestimation approach called Collective Confidence. Extensive experiments\ndemonstrate that APE improves the reliability of LLM Judge across diverse\nstandard benchmarks. For instance, APE enhances GPT-4o agreement rate on Reward\nBench from 87.2% to 90.5% in the zero-shot setting. Overall, APE provides a\nprincipled approach for LLM Judge to leverage test-time computation, and bridge\nthe evaluation gap between human and LLM judges.",
    "published": "2025-10-08T00:28:51Z",
    "updated": "2025-10-08T00:28:51Z",
    "link": "http://arxiv.org/pdf/2510.06538v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Jiajie Li",
      "Huayi Zhang",
      "Peng Lin",
      "Jinjun Xiong",
      "Wei Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06534v1",
    "title": "Beneficial Reasoning Behaviors in Agentic Search and Effective\n  Post-training to Obtain Them",
    "summary": "Agentic search leverages large language models (LLMs) to interpret complex\nuser information needs and execute a multi-step process of planning, searching,\nand synthesizing information to provide answers. This paradigm introduces\nunique challenges for LLMs' reasoning and agentic capabilities when interacting\nwith retrieval systems and the broader web. In this paper, we propose a\nreasoning-driven LLM-based pipeline to study effective reasoning behavior\npatterns in agentic search. Using this pipeline, we analyze successful agentic\nsearch trajectories and identify four beneficial reasoning behaviors:\nInformation Verification, Authority Evaluation, Adaptive Search, and Error\nRecovery. Based on these findings, we propose a technique called Behavior\nPriming to train more effective agentic search models. It synthesizes agentic\nsearch trajectories that exhibit these four behaviors and integrates them into\nthe agentic search model through supervised fine-tuning (SFT), followed by\nstandard reinforcement learning (RL). Experiments on three benchmarks (GAIA,\nWebWalker, and HLE) demonstrate that behavior priming yields over 35% gains in\nLlama3.2-3B and Qwen3-1.7B compared to directly training agentic search models\nwith RL. Crucially, we demonstrate that the desired reasoning behaviors in the\nSFT data, rather than the correctness of the final answer, is the critical\nfactor for achieving strong final performance after RL: fine-tuning on\ntrajectories with desirable reasoning behaviors but incorrect answers leads to\nbetter performance than fine-tuning on trajectories with correct answers. Our\nanalysis further reveals the underlying mechanism: the introduced reasoning\nbehaviors endow models with more effective exploration (higher pass@k and\nentropy) and test-time scaling (longer trajectories) capabilities, providing a\nstrong foundation for RL. Our code will be released as open source.",
    "published": "2025-10-08T00:20:35Z",
    "updated": "2025-10-08T00:20:35Z",
    "link": "http://arxiv.org/pdf/2510.06534v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Jiahe Jin",
      "Abhijay Paladugu",
      "Chenyan Xiong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06532v1",
    "title": "CLAQS: Compact Learnable All-Quantum Token Mixer with Shared-ansatz for\n  Text Classification",
    "summary": "Quantum compute is scaling fast, from cloud QPUs to high throughput GPU\nsimulators, making it timely to prototype quantum NLP beyond toy tasks.\nHowever, devices remain qubit limited and depth limited, training can be\nunstable, and classical attention is compute and memory heavy. This motivates\ncompact, phase aware quantum token mixers that stabilize amplitudes and scale\nto long sequences. We present CLAQS, a compact, fully quantum token mixer for\ntext classification that jointly learns complex-valued mixing and nonlinear\ntransformations within a unified quantum circuit. To enable stable end-to-end\noptimization, we apply l1 normalization to regulate amplitude scaling and\nintroduce a two-stage parameterized quantum architecture that decouples shared\ntoken embeddings from a window-level quantum feed-forward module. Operating\nunder a sliding-window regime with document-level aggregation, CLAQS requires\nonly eight data qubits and shallow circuits, yet achieves 91.64% accuracy on\nSST-2 and 87.08% on IMDB, outperforming both classical Transformer baselines\nand strong hybrid quantum-classical counterparts.",
    "published": "2025-10-08T00:20:08Z",
    "updated": "2025-10-08T00:20:08Z",
    "link": "http://arxiv.org/pdf/2510.06532v1.pdf",
    "category": [
      "quant-ph",
      "cs.AI"
    ],
    "authors": [
      "Junhao Chen",
      "Yifan Zhou",
      "Hanqi Jiang",
      "Yi Pan",
      "Yiwei Li",
      "Huaqin Zhao",
      "Wei Zhang",
      "Yingfeng Wang",
      "Tianming Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.03511v2",
    "title": "Platonic Transformers: A Solid Choice For Equivariance",
    "summary": "While widespread, Transformers lack inductive biases for geometric symmetries\ncommon in science and computer vision. Existing equivariant methods often\nsacrifice the efficiency and flexibility that make Transformers so effective\nthrough complex, computationally intensive designs. We introduce the Platonic\nTransformer to resolve this trade-off. By defining attention relative to\nreference frames from the Platonic solid symmetry groups, our method induces a\nprincipled weight-sharing scheme. This enables combined equivariance to\ncontinuous translations and Platonic symmetries, while preserving the exact\narchitecture and computational cost of a standard Transformer. Furthermore, we\nshow that this attention is formally equivalent to a dynamic group convolution,\nwhich reveals that the model learns adaptive geometric filters and enables a\nhighly scalable, linear-time convolutional variant. Across diverse benchmarks\nin computer vision (CIFAR-10), 3D point clouds (ScanObjectNN), and molecular\nproperty prediction (QM9, OMol25), the Platonic Transformer achieves\ncompetitive performance by leveraging these geometric constraints at no\nadditional cost.",
    "published": "2025-10-03T20:51:25Z",
    "updated": "2025-10-08T00:09:15Z",
    "link": "http://arxiv.org/pdf/2510.03511v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV"
    ],
    "authors": [
      "Mohammad Mohaiminul Islam",
      "Rishabh Anand",
      "David R. Wessels",
      "Friso de Kruiff",
      "Thijs P. Kuipers",
      "Rex Ying",
      "Clara I. Sánchez",
      "Sharvaree Vadgama",
      "Georg Bökman",
      "Erik J. Bekkers"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.03262v2",
    "title": "Rethinking Inter-LoRA Orthogonality in Adapter Merging: Insights from\n  Orthogonal Monte Carlo Dropout",
    "summary": "We propose Orthogonal Monte Carlo Dropout, a mechanism that enforces strict\northogonality when combining sparse semantic vectors without extra time\ncomplexity. Low-Rank Adaptation (LoRA), a popular fine-tuning method for large\nmodels, typically trains a module to represent a specific concept such as an\nobject or a style. When multiple LoRA modules are merged, for example to\ngenerate an object in a particular style, their outputs (semantic vectors) may\ninterfere with each other. Our method guarantees that merged LoRA modules\nremain orthogonal and thus free from direct interference. However, empirical\nanalysis reveals that such orthogonality does not lead to the semantic\ndisentanglement highlighted in prior work on compositional adaptation. This\nfinding suggests that inter-LoRA orthogonality alone may be insufficient for\nachieving true semantic compositionality, prompting a re-examination of its\nrole in adapter merging.",
    "published": "2025-09-26T18:44:03Z",
    "updated": "2025-10-08T00:05:16Z",
    "link": "http://arxiv.org/pdf/2510.03262v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Andi Zhang",
      "Xuan Ding",
      "Haofan Wang",
      "Steven McDonagh",
      "Samuel Kaski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.02210v2",
    "title": "Exchangeability in Neural Network and its Application to Dynamic Pruning",
    "summary": "Modern neural networks (NN) contain an ever-growing number of parameters,\nsubstantially increasing the memory and computational cost of inference.\nResearchers have explored various ways to reduce the inference cost of NNs by\nreducing the model size before deployment and dynamically pruning the inference\ncomputation at runtime. In this work, we present ExPrune, a general, dynamic\npruning optimization that enables multi-granularity partial computation on a\nper-input basis. ExPrune requires no change to the model architecture or the\ntraining algorithm. ExPrune is based on our theoretical results that the\nrelationship between certain model parameters and intermediate values can be\ndescribed by a statistical property called exchangeability. By identifying\nexchangeable parameters and values in the model, we are able to first partially\nevaluate the network, analyze the statistics of the partial results, and make\npruning decisions on the fly. Because ExPrune is theory grounded, it\ngeneralizes across model architectures in different problem domains. We\nevaluate ExPrune on one computer vision models, one graph model and one\nlanguage model. ExPrune provides 10.98--17.33% reduction in FLOPs with\nnegligible accuracy drop and 21.61--27.16% reduction in FLOPs with at most 1%\naccuracy drop. We also demonstrate that ExPrune composes with static magnitude\npruning. On models that have been aggressively statically pruned, ExPrune still\nprovides additional 10.24--11.11% reduction in FLOPs with negligible accuracy\ndrop and 13.91--14.39% reduction in FLOPs with at most 1% accuracy drop.",
    "published": "2025-06-02T19:50:15Z",
    "updated": "2025-10-07T23:47:39Z",
    "link": "http://arxiv.org/pdf/2506.02210v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.PF"
    ],
    "authors": [
      " Pu",
      " Yi",
      "Tianlang Chen",
      "Yifan Yang",
      "Sara Achour"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.03569v2",
    "title": "Longitudinal Flow Matching for Trajectory Modeling",
    "summary": "Generative models for sequential data often struggle with sparsely sampled\nand high-dimensional trajectories, typically reducing the learning of dynamics\nto pairwise transitions. We propose Interpolative Multi-Marginal Flow Matching\n(IMMFM), a framework that learns continuous stochastic dynamics jointly\nconsistent with multiple observed time points. IMMFM employs a\npiecewise-quadratic interpolation path as a smooth target for flow matching and\njointly optimizes drift and a data-driven diffusion coefficient, supported by a\ntheoretical condition for stable learning. This design captures intrinsic\nstochasticity, handles irregular sparse sampling, and yields subject-specific\ntrajectories. Experiments on synthetic benchmarks and real-world longitudinal\nneuroimaging datasets show that IMMFM outperforms existing methods in both\nforecasting accuracy and further downstream tasks.",
    "published": "2025-10-03T23:33:50Z",
    "updated": "2025-10-07T23:35:32Z",
    "link": "http://arxiv.org/pdf/2510.03569v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "authors": [
      "Mohammad Mohaiminul Islam",
      "Thijs P. Kuipers",
      "Sharvaree Vadgama",
      "Coen de Vente",
      "Afsana Khan",
      "Clara I. Sánchez",
      "Erik J. Bekkers"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.19945v3",
    "title": "Optimizing Breast Cancer Detection in Mammograms: A Comprehensive Study\n  of Transfer Learning, Resolution Reduction, and Multi-View Classification",
    "summary": "Mammography, an X-ray-based imaging technique, remains central to the early\ndetection of breast cancer. Recent advances in artificial intelligence have\nenabled increasingly sophisticated computer-aided diagnostic methods, evolving\nfrom patch-based classifiers to whole-image approaches and then to multi-view\narchitectures that jointly analyze complementary projections. Despite this\nprogress, several critical questions remain unanswered. In this study, we\nsystematically investigate these issues by addressing five key research\nquestions: (1) the role of patch classifiers in performance, (2) the\ntransferability of natural-image-trained backbones, (3) the advantages of\nlearn-to-resize over conventional downscaling, (4) the contribution of\nmulti-view integration, and (5) the robustness of findings across varying image\nquality. Beyond benchmarking, our experiments demonstrate clear performance\ngains over prior work. For the CBIS-DDSM dataset, we improved single-view AUC\nfrom 0.8153 to 0.8343, and multiple-view AUC from 0.8483 to 0.8658. Using a new\ncomparative method, we also observed a 0.0217 AUC increase when extending from\nsingle to multiple-view analysis. On the complete VinDr-Mammo dataset, the\nmultiple-view approach further improved results, achieving a 0.0492 AUC\nincrease over single view and reaching 0.8511 AUC overall. These results\nestablish new state-of-the-art benchmarks, providing clear evidence of the\nadvantages of multi-view architectures for mammogram interpretation. Beyond\nperformance, our analysis offers principled insights into model design and\ntransfer learning strategies, contributing to the development of more accurate\nand reliable breast cancer screening tools. The inference code and trained\nmodels are publicly available at https://github.com/dpetrini/multiple-view.",
    "published": "2025-03-25T11:51:21Z",
    "updated": "2025-10-07T23:35:30Z",
    "link": "http://arxiv.org/pdf/2503.19945v3.pdf",
    "category": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Daniel G. P. Petrini",
      "Hae Yong Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06517v1",
    "title": "Visualizing Multimodality in Combinatorial Search Landscapes",
    "summary": "This work walks through different visualization techniques for combinatorial\nsearch landscapes, focusing on multimodality. We discuss different techniques\nfrom the landscape analysis literature, and how they can be combined to provide\na more comprehensive view of the search landscape. We also include examples and\ndiscuss relevant work to show how others have used these techniques in\npractice, based on the geometric and aesthetic elements of the Grammar of\nGraphics. We conclude that there is no free lunch in visualization, and provide\nrecommendations for future work as there are several paths to continue the work\nin this field.",
    "published": "2025-10-07T23:29:19Z",
    "updated": "2025-10-07T23:29:19Z",
    "link": "http://arxiv.org/pdf/2510.06517v1.pdf",
    "category": [
      "cs.GR",
      "cs.AI",
      "cs.NE"
    ],
    "authors": [
      "Xavier F. C. Sánchez-Díaz",
      "Ole Jakob Mengshoel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06512v1",
    "title": "LogSTOP: Temporal Scores over Prediction Sequences for Matching and\n  Retrieval",
    "summary": "Neural models such as YOLO and HuBERT can be used to detect local properties\nsuch as objects (\"car\") and emotions (\"angry\") in individual frames of videos\nand audio clips respectively. The likelihood of these detections is indicated\nby scores in [0, 1]. Lifting these scores to temporal properties over sequences\ncan be useful for several downstream applications such as query matching (e.g.,\n\"does the speaker eventually sound happy in this audio clip?\"), and ranked\nretrieval (e.g., \"retrieve top 5 videos with a 10 second scene where a car is\ndetected until a pedestrian is detected\"). In this work, we formalize this\nproblem of assigning Scores for TempOral Properties (STOPs) over sequences,\ngiven potentially noisy score predictors for local properties. We then propose\na scoring function called LogSTOP that can efficiently compute these scores for\ntemporal properties represented in Linear Temporal Logic. Empirically, LogSTOP,\nwith YOLO and HuBERT, outperforms Large Vision / Audio Language Models and\nother Temporal Logic-based baselines by at least 16% on query matching with\ntemporal properties over objects-in-videos and emotions-in-speech respectively.\nSimilarly, on ranked retrieval with temporal properties over objects and\nactions in videos, LogSTOP with Grounding DINO and SlowR50 reports at least a\n19% and 16% increase in mean average precision and recall over zero-shot\ntext-to-video retrieval baselines respectively.",
    "published": "2025-10-07T23:05:20Z",
    "updated": "2025-10-07T23:05:20Z",
    "link": "http://arxiv.org/pdf/2510.06512v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Avishree Khare",
      "Hideki Okamoto",
      "Bardh Hoxha",
      "Georgios Fainekos",
      "Rajeev Alur"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06505v1",
    "title": "A Median Perspective on Unlabeled Data for Out-of-Distribution Detection",
    "summary": "Out-of-distribution (OOD) detection plays a crucial role in ensuring the\nrobustness and reliability of machine learning systems deployed in real-world\napplications. Recent approaches have explored the use of unlabeled data,\nshowing potential for enhancing OOD detection capabilities. However,\neffectively utilizing unlabeled in-the-wild data remains challenging due to the\nmixed nature of both in-distribution (InD) and OOD samples. The lack of a\ndistinct set of OOD samples complicates the task of training an optimal OOD\nclassifier. In this work, we introduce Medix, a novel framework designed to\nidentify potential outliers from unlabeled data using the median operation. We\nuse the median because it provides a stable estimate of the central tendency,\nas an OOD detection mechanism, due to its robustness against noise and\noutliers. Using these identified outliers, along with labeled InD data, we\ntrain a robust OOD classifier. From a theoretical perspective, we derive error\nbounds that demonstrate Medix achieves a low error rate. Empirical results\nfurther substantiate our claims, as Medix outperforms existing methods across\nthe board in open-world settings, confirming the validity of our theoretical\ninsights.",
    "published": "2025-10-07T22:43:57Z",
    "updated": "2025-10-07T22:43:57Z",
    "link": "http://arxiv.org/pdf/2510.06505v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "authors": [
      "Momin Abbas",
      "Ali Falahati",
      "Hossein Goli",
      "Mohammad Mohammadi Amiri"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.15946v3",
    "title": "MoRE-Brain: Routed Mixture of Experts for Interpretable and\n  Generalizable Cross-Subject fMRI Visual Decoding",
    "summary": "Decoding visual experiences from fMRI offers a powerful avenue to understand\nhuman perception and develop advanced brain-computer interfaces. However,\ncurrent progress often prioritizes maximizing reconstruction fidelity while\noverlooking interpretability, an essential aspect for deriving neuroscientific\ninsight. To address this gap, we propose MoRE-Brain, a neuro-inspired framework\ndesigned for high-fidelity, adaptable, and interpretable visual reconstruction.\nMoRE-Brain uniquely employs a hierarchical Mixture-of-Experts architecture\nwhere distinct experts process fMRI signals from functionally related voxel\ngroups, mimicking specialized brain networks. The experts are first trained to\nencode fMRI into the frozen CLIP space. A finetuned diffusion model then\nsynthesizes images, guided by expert outputs through a novel dual-stage routing\nmechanism that dynamically weighs expert contributions across the diffusion\nprocess. MoRE-Brain offers three main advancements: First, it introduces a\nnovel Mixture-of-Experts architecture grounded in brain network principles for\nneuro-decoding. Second, it achieves efficient cross-subject generalization by\nsharing core expert networks while adapting only subject-specific routers.\nThird, it provides enhanced mechanistic insight, as the explicit routing\nreveals precisely how different modeled brain regions shape the semantic and\nspatial attributes of the reconstructed image. Extensive experiments validate\nMoRE-Brain's high reconstruction fidelity, with bottleneck analyses further\ndemonstrating its effective utilization of fMRI signals, distinguishing genuine\nneural decoding from over-reliance on generative priors. Consequently,\nMoRE-Brain marks a substantial advance towards more generalizable and\ninterpretable fMRI-based visual decoding. Code will be publicly available soon:\nhttps://github.com/yuxiangwei0808/MoRE-Brain.",
    "published": "2025-05-21T19:02:54Z",
    "updated": "2025-10-07T22:39:42Z",
    "link": "http://arxiv.org/pdf/2505.15946v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.HC"
    ],
    "authors": [
      "Yuxiang Wei",
      "Yanteng Zhang",
      "Xi Xiao",
      "Tianyang Wang",
      "Xiao Wang",
      "Vince D. Calhoun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06503v1",
    "title": "ATLO-ML: Adaptive Time-Length Optimizer for Machine Learning -- Insights\n  from Air Quality Forecasting",
    "summary": "Accurate time-series predictions in machine learning are heavily influenced\nby the selection of appropriate input time length and sampling rate. This paper\nintroduces ATLO-ML, an adaptive time-length optimization system that\nautomatically determines the optimal input time length and sampling rate based\non user-defined output time length. The system provides a flexible approach to\ntime-series data pre-processing, dynamically adjusting these parameters to\nenhance predictive performance. ATLO-ML is validated using air quality\ndatasets, including both GAMS-dataset and proprietary data collected from a\ndata center, both in time series format. Results demonstrate that utilizing the\noptimized time length and sampling rate significantly improves the accuracy of\nmachine learning models compared to fixed time lengths. ATLO-ML shows potential\nfor generalization across various time-sensitive applications, offering a\nrobust solution for optimizing temporal input parameters in machine learning\nworkflows.",
    "published": "2025-10-07T22:38:36Z",
    "updated": "2025-10-07T22:38:36Z",
    "link": "http://arxiv.org/pdf/2510.06503v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "I-Hsi Kao",
      "Kanji Uchino"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06499v1",
    "title": "Webscale-RL: Automated Data Pipeline for Scaling RL Data to Pretraining\n  Levels",
    "summary": "Large Language Models (LLMs) have achieved remarkable success through\nimitation learning on vast text corpora, but this paradigm creates a\ntraining-generation gap and limits robust reasoning. Reinforcement learning\n(RL) offers a more data-efficient solution capable of bridging this gap, yet\nits application has been constrained by a critical data bottleneck: existing RL\ndatasets are orders of magnitude smaller and less diverse than web-scale\npre-training corpora. To address this, we introduce the Webscale-RL pipeline, a\nscalable data engine that systematically converts large-scale pre-training\ndocuments into millions of diverse, verifiable question-answer pairs for RL.\nUsing this pipeline, we construct the Webscale-RL dataset, containing 1.2\nmillion examples across more than 9 domains. Our experiments show that the\nmodel trained on this dataset significantly outperforms continual pretraining\nand strong data refinement baselines across a suite of benchmarks. Notably, RL\ntraining with our dataset proves substantially more efficient, achieving the\nperformance of continual pre-training with up to 100$\\times$ fewer tokens. Our\nwork presents a viable path toward scaling RL to pre-training levels, enabling\nmore capable and efficient language models.",
    "published": "2025-10-07T22:30:59Z",
    "updated": "2025-10-07T22:30:59Z",
    "link": "http://arxiv.org/pdf/2510.06499v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Zhepeng Cen",
      "Haolin Chen",
      "Shiyu Wang",
      "Zuxin Liu",
      "Zhiwei Liu",
      "Ding Zhao",
      "Silvio Savarese",
      "Caiming Xiong",
      "Huan Wang",
      "Weiran Yao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.04975v3",
    "title": "SuffixDecoding: Extreme Speculative Decoding for Emerging AI\n  Applications",
    "summary": "Speculative decoding is widely adopted to reduce latency in large language\nmodel (LLM) inference by leveraging smaller draft models capable of handling\ndiverse user tasks. However, emerging AI applications, such as LLM-based\nagents, present unique workload characteristics: instead of diverse independent\nrequests, agentic frameworks typically submit repetitive inference requests,\nsuch as multi-agent pipelines performing similar subtasks or self-refinement\nloops iteratively enhancing outputs. These workloads result in long and highly\npredictable sequences, which current speculative decoding methods do not\neffectively exploit. To address this gap, we introduce \\emph{SuffixDecoding}, a\nnovel method that utilizes efficient suffix trees to cache long token sequences\nfrom prompts and previous outputs. By adaptively speculating more tokens when\nacceptance likelihood is high and fewer when it is low, SuffixDecoding\neffectively exploits opportunities for longer speculations while conserving\ncomputation when those opportunities are limited. Evaluations on agentic\nbenchmarks, including SWE-Bench and Text-to-SQL, demonstrate that\nSuffixDecoding achieves speedups of up to 5.3$\\times$, outperforming\nstate-of-the-art methods -- 2.8$\\times$ faster than model-based approaches like\nEAGLE-2/3 and 1.9$\\times$ faster than model-free approaches such as Token\nRecycling. SuffixDecoding is open-sourced at\nhttps://github.com/snowflakedb/ArcticInference",
    "published": "2024-11-07T18:49:33Z",
    "updated": "2025-10-07T22:07:44Z",
    "link": "http://arxiv.org/pdf/2411.04975v3.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "authors": [
      "Gabriele Oliaro",
      "Zhihao Jia",
      "Daniel Campos",
      "Aurick Qiao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2209.03358v4",
    "title": "Attacking the Spike: On the Transferability and Security of Spiking\n  Neural Networks to Adversarial Examples",
    "summary": "Spiking neural networks (SNNs) have drawn much attention for their high\nenergy efficiency and recent advances in classification performance. However,\nunlike traditional deep learning, the robustness of SNNs to adversarial\nexamples remains underexplored. This work advances the adversarial attack side\nof SNNs and makes three major contributions. First, we show that successful\nwhite-box attacks on SNNs strongly depend on the surrogate gradient estimation\ntechnique, even for adversarially trained models. Second, using the best single\nsurrogate gradient estimator, we study the transferability of adversarial\nexamples between SNNs and state-of-the-art architectures such as Vision\nTransformers (ViTs) and CNNs. Our analysis reveals two major gaps: no existing\nwhite-box attack leverages multiple surrogate estimators, and no single attack\neffectively fools both SNNs and non-SNN models simultaneously. Third, we\npropose the Mixed Dynamic Spiking Estimation (MDSE) attack, which dynamically\ncombines multiple surrogate gradients to overcome these gaps. MDSE produces\nadversarial examples that fool both SNN and non-SNN models, achieving up to\n91.4% higher effectiveness on SNN/ViT ensembles and a 3x boost on adversarially\ntrained SNN ensembles over Auto-PGD. Experiments span three datasets (CIFAR-10,\nCIFAR-100, ImageNet) and nineteen classifiers, and we will release code and\nmodels upon publication.",
    "published": "2022-09-07T17:05:48Z",
    "updated": "2025-10-07T22:05:22Z",
    "link": "http://arxiv.org/pdf/2209.03358v4.pdf",
    "category": [
      "cs.NE",
      "cs.AI",
      "cs.CR",
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Nuo Xu",
      "Kaleel Mahmood",
      "Haowen Fang",
      "Ethan Rathbun",
      "Caiwen Ding",
      "Wujie Wen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2403.04481v4",
    "title": "ECLM: Entity Level Language Model for Spoken Language Understanding with\n  Chain of Intent",
    "summary": "Large Language Models (LLMs) have demonstrated impressive capabilities in\nlanguage generation and general task performance. However, their application to\nspoken language understanding (SLU) remains challenging, particularly for\ntoken-level tasks, where the autoregressive nature of LLMs often leads to\nmisalignment issues. They also struggle to capture nuanced interrelations in\nsemantic-level tasks through direct fine-tuning alone. To address these\nchallenges, we propose the Entity-level Language Model (ECLM) framework, which\nreformulates slot-filling as an entity recognition task and introduces a novel\nconcept, \\textit{Chain of Intent}, to enable step-by-step multi-intent\nrecognition. Experimental results show that ECLM significantly outperforms\nstrong baselines such as Uni-MIS, achieving gains of 3.7\\% on MixATIS and 3.1\\%\non MixSNIPS. Compared to standard supervised fine-tuning of LLMs, ECLM further\nachieves improvements of 8.5\\% and 21.2\\% on these datasets, respectively. Our\ncode is available at https://github.com/SJY8460/ECLM.",
    "published": "2024-03-07T13:30:52Z",
    "updated": "2025-10-07T22:04:38Z",
    "link": "http://arxiv.org/pdf/2403.04481v4.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Shangjian Yin",
      "Peijie Huang",
      "Jiatian Chen",
      "Haojing Huang",
      "Yuhong Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.18356v2",
    "title": "The Unreasonable Effectiveness of Model Merging for Cross-Lingual\n  Transfer in LLMs",
    "summary": "Large language models (LLMs) still struggle across tasks outside of\nhigh-resource languages. In this work, we investigate cross-lingual transfer to\nlower-resource languages where task-specific post-training data is scarce.\nBuilding on prior work, we first validate that the subsets of model parameters\nthat matter most for mathematical reasoning and multilingual capabilities are\ndistinctly non-overlapping. To exploit this implicit separability between task\nand target language parameterization, we develop and analyze numerous modular\nframeworks to improve the composition of the two during fine-tuning. These\nmethods generally employ freezing parameters or post hoc model merging to\nassign math and language improvement to different key parts of the LLM. In the\nabsence of in-language math data, we demonstrate that the modular approaches\nsuccessfully improve upon baselines across three languages, four models, and\ntwo fine-tuning paradigms (full and LoRA). Furthermore, we identify the most\nconsistently successful modular method to be fine-tuning separate language and\nmath experts and model merging via Layer-Swapping, somewhat surprisingly. We\noffer possible explanations for this result via recent works on the linearity\nof task vectors. We further explain this by empirically showing that reverting\nless useful fine-tuning updates after training often outperforms freezing them\nfrom the start.",
    "published": "2025-05-23T20:28:31Z",
    "updated": "2025-10-07T21:54:21Z",
    "link": "http://arxiv.org/pdf/2505.18356v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7"
    ],
    "authors": [
      "Lucas Bandarkar",
      "Nanyun Peng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.10478v4",
    "title": "Weight Ensembling Improves Reasoning in Language Models",
    "summary": "We investigate a failure mode that arises during the training of reasoning\nmodels, where the diversity of generations begins to collapse, leading to\nsuboptimal test-time scaling. Notably, the Pass@1 rate reliably improves during\nsupervised finetuning (SFT), but Pass@k rapidly deteriorates. Surprisingly, a\nsimple intervention of interpolating the weights of the latest SFT checkpoint\nwith an early checkpoint, otherwise known as WiSE-FT, almost completely\nrecovers Pass@k while also improving Pass@1. The WiSE-FT variant achieves\nbetter test-time scaling (Best@k, majority vote) and achieves superior results\nwith less data when tuned further by reinforcement learning. Finally, we find\nthat WiSE-FT provides complementary performance gains that cannot be achieved\nonly through diversity-inducing decoding strategies, like temperature scaling.\nWe formalize a bias-variance tradeoff of Pass@k with respect to the expectation\nand variance of Pass@1 over the test distribution. We find that WiSE-FT can\nreduce bias and variance simultaneously, while temperature scaling inherently\ntrades off between bias and variance.",
    "published": "2025-04-14T17:59:07Z",
    "updated": "2025-10-07T21:47:38Z",
    "link": "http://arxiv.org/pdf/2504.10478v4.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Xingyu Dang",
      "Christina Baek",
      "Kaiyue Wen",
      "Zico Kolter",
      "Aditi Raghunathan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.07218v2",
    "title": "LLM Unlearning via Neural Activation Redirection",
    "summary": "The ability to selectively remove knowledge from LLMs is highly desirable.\nHowever, existing methods often struggle with balancing unlearning efficacy and\nretain model utility, and lack controllability at inference time to emulate\nbase model behavior as if it had never seen the unlearned data. In this paper,\nwe propose LUNAR, a novel unlearning method grounded in the Linear\nRepresentation Hypothesis and operates by redirecting the representations of\nunlearned data to activation regions that expresses its inability to answer. We\nshow that contrastive features are not a prerequisite for effective activation\nredirection, and LUNAR achieves state-of-the-art unlearning performance and\nsuperior controllability. Specifically, LUNAR achieves between 2.9x and 11.7x\nimprovement in the combined unlearning efficacy and model utility score\n(Deviation Score) across various base models and generates coherent,\ncontextually appropriate responses post-unlearning. Moreover, LUNAR effectively\nreduces parameter updates to a single down-projection matrix, a novel design\nthat significantly enhances efficiency by 20x and robustness. Finally, we\ndemonstrate that LUNAR is robust to white-box adversarial attacks and versatile\nin real-world scenarios, including handling sequential unlearning requests.",
    "published": "2025-02-11T03:23:22Z",
    "updated": "2025-10-07T21:36:07Z",
    "link": "http://arxiv.org/pdf/2502.07218v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "William F. Shen",
      "Xinchi Qiu",
      "Meghdad Kurmanji",
      "Alex Iacob",
      "Lorenzo Sani",
      "Yihong Chen",
      "Nicola Cancedda",
      "Nicholas D. Lane"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06478v1",
    "title": "Valid Stopping for LLM Generation via Empirical Dynamic Formal Lift",
    "summary": "We introduce Sequential-EDFL (Empirical Dynamic Formal Lift), applying\nanytime-valid sequential testing to language model generation stopping. Our\napproach tracks information lift -- the log-likelihood ratio between full\nmodels and deliberately weakened \"skeleton\" baselines -- using self-normalized\nempirical-Bernstein e-processes that provide formal delta-level error control\nregardless of stopping time. We handle unknown centering through online mean\nestimation, combine multiple parameters via mixture e-processes, and support\nadaptive resets under distributional drift. On six benchmarks, Sequential-EDFL\nreduces generation by 22-28% vs. sequential baselines while maintaining\ndelta-level control with 12% computational overhead. We introduce automated\nskeletons (distilled submodels, randomized logits) and show robustness across\nskeleton families. Composing EDFL with a lightweight correctness gate (sentence\nboundaries + verifier) improves end-task correctness while preserving\nanytime-valid guarantees by only delaying stopping. Our certificates control\ninformation sufficiency, not factual correctness -- 10.9% of stopped sequences\nremain incorrect even with the gate (13.2-22.7% without it). EDFL serves as a\nfirst-stage filter reducing verification burden by 83%, not as a standalone\nsolution for safety-critical domains.",
    "published": "2025-10-07T21:28:53Z",
    "updated": "2025-10-07T21:28:53Z",
    "link": "http://arxiv.org/pdf/2510.06478v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Sanjeda Akter",
      "Ibne Farabi Shihab",
      "Anuj Sharma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06477v1",
    "title": "Attention Sinks and Compression Valleys in LLMs are Two Sides of the\n  Same Coin",
    "summary": "Attention sinks and compression valleys have attracted significant attention\nas two puzzling phenomena in large language models, but have been studied in\nisolation. In this work, we present a surprising connection between attention\nsinks and compression valleys, tracing both to the formation of massive\nactivations in the residual stream. We prove theoretically that massive\nactivations necessarily produce representational compression and establish\nbounds on the resulting entropy reduction. Through experiments across several\nmodels (410M-120B parameters), we confirm that when the beginning-of-sequence\ntoken develops extreme activation norms in the middle layers, both compression\nvalleys and attention sinks emerge simultaneously. Targeted ablation studies\nvalidate our theoretical predictions. This unified view motivates us to propose\nthe Mix-Compress-Refine theory of information flow, as an attempt to explain\nhow LLMs organize their computation in depth by controlling attention and\nrepresentational compression via massive activations. Specifically, we posit\nthat Transformer-based LLMs process tokens in three distinct phases: (1) broad\nmixing in the early layers, (2) compressed computation with limited mixing in\nthe middle layers, and (3) selective refinement in the late layers. Our\nframework helps explain why embedding tasks perform best at intermediate\nlayers, whereas generation tasks benefit from full-depth processing, clarifying\ndifferences in task-dependent representations.",
    "published": "2025-10-07T21:27:24Z",
    "updated": "2025-10-07T21:27:24Z",
    "link": "http://arxiv.org/pdf/2510.06477v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Enrique Queipo-de-Llano",
      "Álvaro Arroyo",
      "Federico Barbero",
      "Xiaowen Dong",
      "Michael Bronstein",
      "Yann LeCun",
      "Ravid Shwartz-Ziv"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06475v1",
    "title": "PuzzlePlex: Benchmarking Foundation Models on Reasoning and Planning\n  with Puzzles",
    "summary": "This work investigates the reasoning and planning capabilities of foundation\nmodels and their scalability in complex, dynamic environments. We introduce\nPuzzlePlex, a benchmark designed to assess these capabilities through a diverse\nset of puzzles. PuzzlePlex consists of 15 types of puzzles, including\ndeterministic and stochastic games of varying difficulty, as well as\nsingle-player and two-player scenarios. The PuzzlePlex framework provides a\ncomprehensive environment for each game, and supports extensibility to generate\nmore challenging instances as foundation models evolve. Additionally, we\nimplement customized game-playing strategies for comparison. Building on this\nbenchmark, we develop fine-grained metrics to measure performance and conduct\nan in-depth analysis of frontier foundation models across two settings:\ninstruction-based and code-based. Furthermore, we systematically investigate\ntheir scaling limits. Our findings show that reasoning models outperform others\nin instruction-based settings, while code-based execution presents greater\nchallenges but offers a scalable and efficient alternative. PuzzlePlex enables\ntargeted evaluation and guides future improvements in reasoning, planning, and\ngeneralization for foundation models.",
    "published": "2025-10-07T21:24:29Z",
    "updated": "2025-10-07T21:24:29Z",
    "link": "http://arxiv.org/pdf/2510.06475v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Yitao Long",
      "Yuru Jiang",
      "Hongjun Liu",
      "Yilun Zhao",
      "Jingchen Sun",
      "Yiqiu Shen",
      "Chen Zhao",
      "Arman Cohan",
      "Dennis Shasha"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06473v1",
    "title": "Deep Generative Model for Human Mobility Behavior",
    "summary": "Understanding and modeling human mobility is central to challenges in\ntransport planning, sustainable urban design, and public health. Despite\ndecades of effort, simulating individual mobility remains challenging because\nof its complex, context-dependent, and exploratory nature. Here, we present\nMobilityGen, a deep generative model that produces realistic mobility\ntrajectories spanning days to weeks at large spatial scales. By linking\nbehavioral attributes with environmental context, MobilityGen reproduces key\npatterns such as scaling laws for location visits, activity time allocation,\nand the coupled evolution of travel mode and destination choices. It reflects\nspatio-temporal variability and generates diverse, plausible, and novel\nmobility patterns consistent with the built environment. Beyond standard\nvalidation, MobilityGen yields insights not attainable with earlier models,\nincluding how access to urban space varies across travel modes and how\nco-presence dynamics shape social exposure and segregation. Our work\nestablishes a new framework for mobility simulation, paving the way for\nfine-grained, data-driven studies of human behavior and its societal\nimplications.",
    "published": "2025-10-07T21:22:08Z",
    "updated": "2025-10-07T21:22:08Z",
    "link": "http://arxiv.org/pdf/2510.06473v1.pdf",
    "category": [
      "physics.soc-ph",
      "cs.AI",
      "cs.SI"
    ],
    "authors": [
      "Ye Hong",
      "Yatao Zhang",
      "Konrad Schindler",
      "Martin Raubal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.03318v2",
    "title": "Structure-Aware Compound-Protein Affinity Prediction via Graph Neural\n  Network with Group Lasso Regularization",
    "summary": "Explainable artificial intelligence (XAI) approaches have been increasingly\napplied in drug discovery to learn molecular representations and identify\nsubstructures driving property predictions. However, building end-to-end\nexplainable models for structure-activity relationship (SAR) modeling for\ncompound property prediction faces many challenges, such as the limited number\nof compound-protein interaction activity data for specific protein targets, and\nplenty of subtle changes in molecular configuration sites significantly\naffecting molecular properties. We exploit pairs of molecules with activity\ncliffs that share scaffolds but differ at substituent sites, characterized by\nlarge potency differences for specific protein targets. We propose a framework\nby implementing graph neural networks (GNNs) to leverage property and structure\ninformation from activity cliff pairs to predict compound-protein affinity\n(i.e., half maximal inhibitory concentration, IC50). To enhance model\nperformance and explainability, we train GNNs with structure-aware loss\nfunctions using group lasso and sparse group lasso regularizations, which prune\nand highlight molecular subgraphs relevant to activity differences. We applied\nthis framework to activity cliff data of molecules targeting three\nproto-oncogene tyrosine-protein kinase Src proteins (PDB IDs: 1O42, 2H8H,\n4MXO). Our approach improved property prediction by integrating common and\nuncommon node information with sparse group lasso, as reflected in reduced root\nmean squared error (RMSE) and improved Pearson's correlation coefficient (PCC).\nApplying regularizations also enhances feature attribution for GNN by boosting\ngraph-level global direction scores and improving atom-level coloring accuracy.\nThese advances strengthen model interpretability in drug discovery pipelines,\nparticularly for identifying critical molecular substructures in lead\noptimization.",
    "published": "2025-07-04T06:12:18Z",
    "updated": "2025-10-07T21:09:11Z",
    "link": "http://arxiv.org/pdf/2507.03318v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Zanyu Shi",
      "Yang Wang",
      "Pathum Weerawarna",
      "Jie Zhang",
      "Timothy Richardson",
      "Yijie Wang",
      "Kun Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06457v1",
    "title": "Evaluating Node-tree Interfaces for AI Explainability",
    "summary": "As large language models (LLMs) become ubiquitous in workplace tools and\ndecision-making processes, ensuring explainability and fostering user trust are\ncritical. Although advancements in LLM engineering continue, human-centered\ndesign is still catching up, particularly when it comes to embedding\ntransparency and trust into AI interfaces. This study evaluates user\nexperiences with two distinct AI interfaces - node-tree interfaces and chatbot\ninterfaces - to assess their performance in exploratory, follow-up inquiry,\ndecision-making, and problem-solving tasks. Our design-driven approach\nintroduces a node-tree interface that visually structures AI-generated\nresponses into hierarchically organized, interactive nodes, allowing users to\nnavigate, refine, and follow up on complex information. In a comparative study\nwith n=20 business users, we observed that while the chatbot interface\neffectively supports linear, step-by-step queries, it is the node-tree\ninterface that enhances brainstorming. Quantitative and qualitative findings\nindicate that node-tree interfaces not only improve task performance and\ndecision-making support but also promote higher levels of user trust by\npreserving context. Our findings suggest that adaptive AI interfaces capable of\nswitching between structured visualizations and conversational formats based on\ntask requirements can significantly enhance transparency and user confidence in\nAI-powered systems. This work contributes actionable insights to the fields of\nhuman-robot interaction and AI design, particularly for enterprise applications\nwhere trust-building is critical for teams.",
    "published": "2025-10-07T20:48:08Z",
    "updated": "2025-10-07T20:48:08Z",
    "link": "http://arxiv.org/pdf/2510.06457v1.pdf",
    "category": [
      "cs.HC",
      "cs.AI",
      "H.5.2; I.2.7"
    ],
    "authors": [
      "Lifei Wang",
      "Natalie Friedman",
      "Chengchao Zhu",
      "Zeshu Zhu",
      "S. Joy Mountford"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.22598v4",
    "title": "Performance of machine-learning-assisted Monte Carlo in sampling from\n  simple statistical physics models",
    "summary": "Recent years have seen a rise in the application of machine learning\ntechniques to aid the simulation of hard-to-sample systems that cannot be\nstudied using traditional methods. Despite the introduction of many different\narchitectures and procedures, a wide theoretical understanding is still\nlacking, with the risk of suboptimal implementations. As a first step to\naddress this gap, we provide here a complete analytic study of the widely-used\nSequential Tempering procedure applied to a shallow MADE architecture for the\nCurie-Weiss model. The contribution of this work is twofold: firstly, we give a\ndescription of the optimal weights and of the training under Gradient Descent\noptimization. Secondly, we compare what happens in Sequential Tempering with\nand without the addition of local Metropolis Monte Carlo steps. We are thus\nable to give theoretical predictions on the best procedure to apply in this\ncase. This work establishes a clear theoretical basis for the integration of\nmachine learning techniques into Monte Carlo sampling and optimization.",
    "published": "2025-05-28T17:13:11Z",
    "updated": "2025-10-07T20:41:31Z",
    "link": "http://arxiv.org/pdf/2505.22598v4.pdf",
    "category": [
      "cond-mat.dis-nn",
      "cond-mat.stat-mech",
      "cs.AI",
      "cs.LG",
      "physics.comp-ph"
    ],
    "authors": [
      "Luca Maria Del Bono",
      "Federico Ricci-Tersenghi",
      "Francesco Zamponi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06448v1",
    "title": "How NOT to benchmark your SITE metric: Beyond Static Leaderboards and\n  Towards Realistic Evaluation",
    "summary": "Transferability estimation metrics are used to find a high-performing\npre-trained model for a given target task without fine-tuning models and\nwithout access to the source dataset. Despite the growing interest in\ndeveloping such metrics, the benchmarks used to measure their progress have\ngone largely unexamined. In this work, we empirically show the shortcomings of\nwidely used benchmark setups to evaluate transferability estimation metrics. We\nargue that the benchmarks on which these metrics are evaluated are\nfundamentally flawed. We empirically demonstrate that their unrealistic model\nspaces and static performance hierarchies artificially inflate the perceived\nperformance of existing metrics, to the point where simple, dataset-agnostic\nheuristics can outperform sophisticated methods. Our analysis reveals a\ncritical disconnect between current evaluation protocols and the complexities\nof real-world model selection. To address this, we provide concrete\nrecommendations for constructing more robust and realistic benchmarks to guide\nfuture research in a more meaningful direction.",
    "published": "2025-10-07T20:38:12Z",
    "updated": "2025-10-07T20:38:12Z",
    "link": "http://arxiv.org/pdf/2510.06448v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Prabhant Singh",
      "Sibylle Hess",
      "Joaquin Vanschoren"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06445v1",
    "title": "A Survey on Agentic Security: Applications, Threats and Defenses",
    "summary": "The rapid shift from passive LLMs to autonomous LLM-agents marks a new\nparadigm in cybersecurity. While these agents can act as powerful tools for\nboth offensive and defensive operations, the very agentic context introduces a\nnew class of inherent security risks. In this work we present the first\nholistic survey of the agentic security landscape, structuring the field around\nthree interdependent pillars: Applications, Threats, and Defenses. We provide a\ncomprehensive taxonomy of over 150 papers, explaining how agents are used, the\nvulnerabilities they possess, and the countermeasures designed to protect them.\nA detailed cross-cutting analysis shows emerging trends in agent architecture\nwhile revealing critical research gaps in model and modality coverage.",
    "published": "2025-10-07T20:32:20Z",
    "updated": "2025-10-07T20:32:20Z",
    "link": "http://arxiv.org/pdf/2510.06445v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.CR"
    ],
    "authors": [
      "Asif Shahriar",
      "Md Nafiu Rahman",
      "Sadif Ahmed",
      "Farig Sadeque",
      "Md Rizwan Parvez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06444v1",
    "title": "Context-Aware Inference via Performance Forecasting in Decentralized\n  Learning Networks",
    "summary": "In decentralized learning networks, predictions from many participants are\ncombined to generate a network inference. While many studies have demonstrated\nperformance benefits of combining multiple model predictions, existing\nstrategies using linear pooling methods (ranging from simple averaging to\ndynamic weight updates) face a key limitation. Dynamic prediction combinations\nthat rely on historical performance to update weights are necessarily reactive.\nDue to the need to average over a reasonable number of epochs (with moving\naverages or exponential weighting), they tend to be slow to adjust to changing\ncircumstances (phase or regime changes). In this work, we develop a model that\nuses machine learning to forecast the performance of predictions by models at\neach epoch in a time series. This enables `context-awareness' by assigning\nhigher weight to models that are likely to be more accurate at a given time. We\nshow that adding a performance forecasting worker in a decentralized learning\nnetwork, following a design similar to the Allora network, can improve the\naccuracy of network inferences. Specifically, we find forecasting models that\npredict regret (performance relative to the network inference) or regret\nz-score (performance relative to other workers) show greater improvement than\nmodels predicting losses, which often do not outperform the naive network\ninference (historically weighted average of all inferences). Through a series\nof optimization tests, we show that the performance of the forecasting model\ncan be sensitive to choices in the feature set and number of training epochs.\nThese properties may depend on the exact problem and should be tailored to each\ndomain. Although initially designed for a decentralized learning network, using\nperformance forecasting for prediction combination may be useful in any\nsituation where predictive rather than reactive model weighting is needed.",
    "published": "2025-10-07T20:30:21Z",
    "updated": "2025-10-07T20:30:21Z",
    "link": "http://arxiv.org/pdf/2510.06444v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "authors": [
      "Joel Pfeffer",
      "J. M. Diederik Kruijssen",
      "Clément Gossart",
      "Mélanie Chevance",
      "Diego Campo Millan",
      "Florian Stecker",
      "Steven N. Longmore"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.01103v2",
    "title": "Approximately Aligned Decoding",
    "summary": "It is common to reject undesired outputs of Large Language Models (LLMs);\nhowever, current methods to do so require an excessive amount of computation to\nre-sample after a rejection, or distort the distribution of outputs by\nconstraining the output to highly improbable tokens. We present a method,\nApproximately Aligned Decoding (AprAD), to balance the distortion of the output\ndistribution with computational efficiency, inspired by algorithms from the\nspeculative decoding literature. AprAD allows for the generation of long\nsequences of text with difficult-to-satisfy constraints, while amplifying low\nprobability outputs much less compared to existing methods. We show through a\nseries of experiments that the task-specific performance of AprAD is comparable\nto methods that do not distort the output distribution, while being much more\ncomputationally efficient.",
    "published": "2024-10-01T22:22:13Z",
    "updated": "2025-10-07T20:29:31Z",
    "link": "http://arxiv.org/pdf/2410.01103v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Daniel Melcer",
      "Sujan Gonugondla",
      "Pramuditha Perera",
      "Haifeng Qian",
      "Wen-Hao Chiang",
      "Yanjun Wang",
      "Nihal Jain",
      "Pranav Garg",
      "Xiaofei Ma",
      "Anoop Deoras"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.03540v2",
    "title": "Improving Factuality in LLMs via Inference-Time Knowledge Graph\n  Construction",
    "summary": "Large Language Models (LLMs) often struggle with producing factually\nconsistent answers due to limitations in their parametric memory.\nRetrieval-Augmented Generation (RAG) paradigms mitigate this issue by\nincorporating external knowledge at inference time. However, such methods\ntypically handle knowledge as unstructured text, which reduces retrieval\naccuracy, hinders compositional reasoning, and amplifies the influence of\nirrelevant information on the factual consistency of LLM outputs. To overcome\nthese limitations, we propose a novel framework that dynamically constructs and\nexpands knowledge graphs (KGs) during inference, integrating both internal\nknowledge extracted from LLMs and external knowledge retrieved from external\nsources. Our method begins by extracting a seed KG from the question via\nprompting, followed by iterative expansion using the LLM's internal knowledge.\nThe KG is then selectively refined through external retrieval, enhancing\nfactual coverage and correcting inaccuracies. We evaluate our approach on three\ndiverse Factual QA benchmarks, demonstrating consistent gains in factual\naccuracy over baselines. Our findings reveal that inference-time KG\nconstruction is a promising direction for enhancing LLM factuality in a\nstructured, interpretable, and scalable manner.",
    "published": "2025-08-31T16:36:40Z",
    "updated": "2025-10-07T20:15:22Z",
    "link": "http://arxiv.org/pdf/2509.03540v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Shanglin Wu",
      "Lihui Liu",
      "Jinho D. Choi",
      "Kai Shu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06433v1",
    "title": "Flavonoid Fusion: Creating a Knowledge Graph to Unveil the Interplay\n  Between Food and Health",
    "summary": "The focus on \"food as medicine\" is gaining traction in the field of health\nand several studies conducted in the past few years discussed this aspect of\nfood in the literature. However, very little research has been done on\nrepresenting the relationship between food and health in a standardized,\nmachine-readable format using a semantic web that can help us leverage this\nknowledge effectively. To address this gap, this study aims to create a\nknowledge graph to link food and health through the knowledge graph's ability\nto combine information from various platforms focusing on flavonoid contents of\nfood found in the USDA databases and cancer connections found in the\nliterature. We looked closely at these relationships using KNARM methodology\nand represented them in machine-operable format. The proposed knowledge graph\nserves as an example for researchers, enabling them to explore the complex\ninterplay between dietary choices and disease management. Future work for this\nstudy involves expanding the scope of the knowledge graph by capturing nuances,\nadding more related data, and performing inferences on the acquired knowledge\nto uncover hidden relationships.",
    "published": "2025-10-07T20:11:39Z",
    "updated": "2025-10-07T20:11:39Z",
    "link": "http://arxiv.org/pdf/2510.06433v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Aryan Singh Dalal",
      "Yinglun Zhang",
      "Duru Doğan",
      "Atalay Mert İleri",
      "Hande Küçük McGinty"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.02016v2",
    "title": "Mind the (Belief) Gap: Group Identity in the World of LLMs",
    "summary": "Social biases and belief-driven behaviors can significantly impact Large\nLanguage Models (LLMs) decisions on several tasks. As LLMs are increasingly\nused in multi-agent systems for societal simulations, their ability to model\nfundamental group psychological characteristics remains critical yet\nunder-explored. In this study, we present a multi-agent framework that\nsimulates belief congruence, a classical group psychology theory that plays a\ncrucial role in shaping societal interactions and preferences. Our findings\nreveal that LLMs exhibit amplified belief congruence compared to humans, across\ndiverse contexts. We further investigate the implications of this behavior on\ntwo downstream tasks: (1) misinformation dissemination and (2) LLM learning,\nfinding that belief congruence in LLMs increases misinformation dissemination\nand impedes learning. To mitigate these negative impacts, we propose strategies\ninspired by: (1) contact hypothesis, (2) accuracy nudges, and (3) global\ncitizenship framework. Our results show that the best strategies reduce\nmisinformation dissemination by up to 37% and enhance learning by 11%. Bridging\nsocial psychology and AI, our work provides insights to navigate real-world\ninteractions using LLMs while addressing belief-driven biases.",
    "published": "2025-03-03T19:50:52Z",
    "updated": "2025-10-07T19:44:30Z",
    "link": "http://arxiv.org/pdf/2503.02016v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Angana Borah",
      "Marwa Houalla",
      "Rada Mihalcea"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06410v1",
    "title": "Off-Trajectory Reasoning: Can LLMs Collaborate on Reasoning Trajectory?",
    "summary": "Reasoning LLMs are trained to verbalize their reasoning process, yielding\nstrong gains on complex tasks. This transparency also opens a promising\ndirection: multiple reasoners can directly collaborate on each other's thinking\nwithin a shared trajectory, yielding better inference efficiency and\nexploration. A key prerequisite, however, is the ability to assess the\nusefulness and build on another model's partial thinking -- we call this\noff-trajectory reasoning. Our paper investigates a critical question: can\nstandard solo-reasoning training pipelines deliver desired off-trajectory\nbehaviors? We propose twin tests that capture the two extremes of the\noff-trajectory spectrum, namely Recoverability, which tests whether LLMs can\nbacktrack from \"distractions\" induced by misleading reasoning traces, and\nGuidability, which tests their ability to build upon correct reasoning from\nstronger collaborators. Our study evaluates 15 open-weight LLMs (1.5B-32B) and\nreveals a counterintuitive finding -- \"stronger\" LLMs on benchmarks are often\nmore fragile under distraction. Moreover, all models tested fail to effectively\nleverage guiding steps from collaborators on problems beyond their inherent\ncapabilities with solve rates remaining under 9.2%. Finally, we conduct control\nstudies to isolate the effects of three factors in post-training on these\nbehaviors: the choice of distillation teacher, the use of RL, and data\nselection strategy. Our results provide actionable insights for training\nnatively strong reasoning collaborators; e.g., we find that suboptimal\nrecoverability behaviors of teacher models are transferred to distilled\nstudents even if the distillation trajectories are correct. Taken together,\nthis work lays the groundwork for evaluating multi-model collaborations in\nshared reasoning trajectories and highlights the limitations of off-the-shelf\nreasoning LLMs.",
    "published": "2025-10-07T19:42:50Z",
    "updated": "2025-10-07T19:42:50Z",
    "link": "http://arxiv.org/pdf/2510.06410v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Aochong Oliver Li",
      "Tanya Goyal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06397v1",
    "title": "Geometry-Aware Backdoor Attacks: Leveraging Curvature in Hyperbolic\n  Embeddings",
    "summary": "Non-Euclidean foundation models increasingly place representations in curved\nspaces such as hyperbolic geometry. We show that this geometry creates a\nboundary-driven asymmetry that backdoor triggers can exploit. Near the\nboundary, small input changes appear subtle to standard input-space detectors\nbut produce disproportionately large shifts in the model's representation\nspace. Our analysis formalizes this effect and also reveals a limitation for\ndefenses: methods that act by pulling points inward along the radius can\nsuppress such triggers, but only by sacrificing useful model sensitivity in\nthat same direction. Building on these insights, we propose a simple\ngeometry-adaptive trigger and evaluate it across tasks and architectures.\nEmpirically, attack success increases toward the boundary, whereas conventional\ndetectors weaken, mirroring the theoretical trends. Together, these results\nsurface a geometry-specific vulnerability in non-Euclidean models and offer\nanalysis-backed guidance for designing and understanding the limits of\ndefenses.",
    "published": "2025-10-07T19:24:43Z",
    "updated": "2025-10-07T19:24:43Z",
    "link": "http://arxiv.org/pdf/2510.06397v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Ali Baheri"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.01611v2",
    "title": "PsychoBench: Evaluating the Psychology Intelligence of Large Language\n  Models",
    "summary": "Large Language Models (LLMs) have demonstrated remarkable success across a\nwide range of industries, primarily due to their impressive generative\nabilities. Yet, their potential in applications requiring cognitive abilities,\nsuch as psychological counseling, remains largely untapped. This paper\ninvestigates the key question: Can LLMs be effectively applied to psychological\ncounseling? To determine whether an LLM can effectively take on the role of a\npsychological counselor, the first step is to assess whether it meets the\nqualifications required for such a role, namely the ability to pass the U.S.\nNational Counselor Certification Exam (NCE). This is because, just as a human\ncounselor must pass a certification exam to practice, an LLM must demonstrate\nsufficient psychological knowledge to meet the standards required for such a\nrole. To address this, we introduce PsychoBench, a benchmark grounded in\nU.S.national counselor examinations, a licensure test for professional\ncounselors that requires about 70% accuracy to pass. PsychoBench comprises\napproximately 2,252 carefully curated single-choice questions, crafted to\nrequire deep understanding and broad enough to cover various sub-disciplines of\npsychology. This benchmark provides a comprehensive assessment of an LLM's\nability to function as a counselor. Our evaluation shows that advanced models\nsuch as GPT-4o, Llama3.3-70B, and Gemma3-27B achieve well above the passing\nthreshold, while smaller open-source models (e.g., Qwen2.5-7B, Mistral-7B)\nremain far below it. These results suggest that only frontier LLMs are\ncurrently capable of meeting counseling exam standards, highlighting both the\npromise and the challenges of developing psychology-oriented LLMs.",
    "published": "2025-10-02T02:49:06Z",
    "updated": "2025-10-07T19:24:28Z",
    "link": "http://arxiv.org/pdf/2510.01611v2.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Min Zeng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06396v1",
    "title": "Adaptive Protein Design Protocols and Middleware",
    "summary": "Computational protein design is experiencing a transformation driven by\nAI/ML. However, the range of potential protein sequences and structures is\nastronomically vast, even for moderately sized proteins. Hence, achieving\nconvergence between generated and predicted structures demands substantial\ncomputational resources for sampling. The Integrated Machine-learning for\nProtein Structures at Scale (IMPRESS) offers methods and advanced computing\nsystems for coupling AI to high-performance computing tasks, enabling the\nability to evaluate the effectiveness of protein designs as they are developed,\nas well as the models and simulations used to generate data and train models.\nThis paper introduces IMPRESS and demonstrates the development and\nimplementation of an adaptive protein design protocol and its supporting\ncomputing infrastructure. This leads to increased consistency in the quality of\nprotein design and enhanced throughput of protein design due to dynamic\nresource allocation and asynchronous workload execution.",
    "published": "2025-10-07T19:23:53Z",
    "updated": "2025-10-07T19:23:53Z",
    "link": "http://arxiv.org/pdf/2510.06396v1.pdf",
    "category": [
      "cs.DC",
      "cs.AI",
      "cs.PF",
      "cs.SE"
    ],
    "authors": [
      "Aymen Alsaadi",
      "Jonathan Ash",
      "Mikhail Titov",
      "Matteo Turilli",
      "Andre Merzky",
      "Shantenu Jha",
      "Sagar Khare"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06391v1",
    "title": "Reward Model Perspectives: Whose Opinions Do Reward Models Reward?",
    "summary": "Reward models (RMs) are central to the alignment of language models (LMs). An\nRM often serves as a proxy for human preferences to guide downstream LM\nbehavior. However, our understanding of RM behavior is limited. Our work (i)\nformalizes a framework for measuring the alignment of opinions captured by RMs,\n(ii) investigates the extent to which RMs demonstrate sociodemographic biases,\nand (iii) explores the effects of prompting to steer rewards towards the\npreferences of a target group. We study the subjective and diverse perspectives\non controversial topics, which allows us to quantify RM perspectives in terms\nof their opinions, attitudes, and values. We show that RMs are poorly aligned\nwith several demographic groups and can systematically reward harmful\nstereotypes, and steering alone is not enough to overcome these limitations.\nOur findings underscore the need for more careful consideration of RM behavior\nin model alignment during preference learning to prevent the propagation of\nunwanted social biases in the language technologies that we use.",
    "published": "2025-10-07T19:13:52Z",
    "updated": "2025-10-07T19:13:52Z",
    "link": "http://arxiv.org/pdf/2510.06391v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      " Elle"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06383v1",
    "title": "Protecting De-identified Documents from Search-based Linkage Attacks",
    "summary": "While de-identification models can help conceal the identity of the\nindividual(s) mentioned in a document, they fail to address linkage risks,\ndefined as the potential to map the de-identified text back to its source. One\nstraightforward way to perform such linkages is to extract phrases from the\nde-identified document and then check their presence in the original dataset.\nThis paper presents a method to counter search-based linkage attacks while\npreserving the semantic integrity of the text. The method proceeds in two\nsteps. We first construct an inverted index of the N-grams occurring in the\ndocument collection, making it possible to efficiently determine which N-grams\nappear in less than $k$ documents (either alone or in combination with other\nN-grams). An LLM-based rewriter is then iteratively queried to reformulate\nthose spans until linkage is no longer possible. Experimental results on a\ncollection of court cases show that the method is able to effectively prevent\nsearch-based linkages while remaining faithful to the original content.",
    "published": "2025-10-07T19:02:21Z",
    "updated": "2025-10-07T19:02:21Z",
    "link": "http://arxiv.org/pdf/2510.06383v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Pierre Lison",
      "Mark Anderson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06381v1",
    "title": "Monte Carlo Permutation Search",
    "summary": "We propose Monte Carlo Permutation Search (MCPS), a general-purpose Monte\nCarlo Tree Search (MCTS) algorithm that improves upon the GRAVE algorithm. MCPS\nis relevant when deep reinforcement learning is not an option, or when the\ncomputing power available before play is not substantial, such as in General\nGame Playing, for example. The principle of MCPS is to include in the\nexploration term of a node the statistics on all the playouts that contain all\nthe moves on the path from the root to the node. We extensively test MCPS on a\nvariety of games: board games, wargame, investment game, video game and\nmulti-player games. MCPS has better results than GRAVE in all the two-player\ngames. It has equivalent results for multi-player games because these games are\ninherently balanced even when players have different strengths. We also show\nthat using abstract codes for moves instead of exact codes can be beneficial to\nboth MCPS and GRAVE, as they improve the permutation statistics and the AMAF\nstatistics. We also provide a mathematical derivation of the formulas used for\nweighting the three sources of statistics. These formulas are an improvement on\nthe GRAVE formula since they no longer use the bias hyperparameter of GRAVE.\nMoreover, MCPS is not sensitive to the ref hyperparameter.",
    "published": "2025-10-07T18:59:39Z",
    "updated": "2025-10-07T18:59:39Z",
    "link": "http://arxiv.org/pdf/2510.06381v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Tristan Cazenave"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06377v1",
    "title": "Relational Transformer: Toward Zero-Shot Foundation Models for\n  Relational Data",
    "summary": "Pretrained transformers readily adapt to new sequence modeling tasks via\nzero-shot prompting, but relational domains still lack architectures that\ntransfer across datasets and tasks. The core challenge is the diversity of\nrelational data, with varying heterogeneous schemas, graph structures and\nfunctional dependencies. In this paper, we present the Relational Transformer\n(RT) architecture, which can be pretrained on diverse relational databases and\ndirectly applied to unseen datasets and tasks without task- or dataset-specific\nfine-tuning, or retrieval of in-context examples. RT (i) tokenizes cells with\ntable/column metadata, (ii) is pretrained via masked token prediction, and\n(iii) utilizes a novel \\textit{Relational Attention} mechanism over columns,\nrows, and primary-foreign key links. Pretrained on RelBench datasets spanning\ntasks such as churn and sales forecasting, RT attains strong zero-shot\nperformance, averaging 94% of fully supervised AUROC on binary classification\ntasks with a single forward pass of a 22M parameter model, as opposed to 84%\nfor a 27B LLM. Fine-tuning yields state-of-the-art results with high sample\nefficiency. Our experiments show that RT's zero-shot transfer harnesses\ntask-table context, relational attention patterns and schema semantics.\nOverall, RT provides a practical path toward foundation models for relational\ndata.",
    "published": "2025-10-07T18:51:51Z",
    "updated": "2025-10-07T18:51:51Z",
    "link": "http://arxiv.org/pdf/2510.06377v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.DB"
    ],
    "authors": [
      "Rishabh Ranjan",
      "Valter Hudovernik",
      "Mark Znidar",
      "Charilaos Kanatsoulis",
      "Roshan Upendra",
      "Mahmoud Mohammadi",
      "Joe Meyer",
      "Tom Palczewski",
      "Carlos Guestrin",
      "Jure Leskovec"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.03268v2",
    "title": "Decipher the Modality Gap in Multimodal Contrastive Learning: From\n  Convergent Representations to Pairwise Alignment",
    "summary": "Multimodal contrastive learning (MCL) aims to embed data from different\nmodalities in a shared embedding space. However, empirical evidence shows that\nrepresentations from different modalities occupy completely separate regions of\nembedding space, a phenomenon referred to as the modality gap. Moreover,\nexperimental findings on how the size of the modality gap influences downstream\nperformance are inconsistent. These observations raise two key questions: (1)\nWhat causes the modality gap? (2) How does it affect downstream tasks? To\naddress these questions, this paper introduces the first theoretical framework\nfor analyzing the convergent optimal representations of MCL and the modality\nalignment when training is optimized. Specifically, we prove that without any\nconstraint or under the cone constraint, the modality gap converges to zero.\nUnder the subspace constraint (i.e., representations of two modalities fall\ninto two distinct hyperplanes due to dimension collapse), the modality gap\nconverges to the smallest angle between the two hyperplanes. This result\nidentifies \\emph{dimension collapse} as the fundamental origin of the modality\ngap. Furthermore, our theorems demonstrate that paired samples cannot be\nperfectly aligned under the subspace constraint. The modality gap influences\ndownstream performance by affecting the alignment between sample pairs. We\nprove that, in this case, perfect alignment between two modalities can still be\nachieved via two ways: hyperplane rotation and shared space projection.",
    "published": "2025-09-27T04:21:00Z",
    "updated": "2025-10-07T18:46:38Z",
    "link": "http://arxiv.org/pdf/2510.03268v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Lingjie Yi",
      "Raphael Douady",
      "Chao Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06371v1",
    "title": "EverydayMMQA: A Multilingual and Multimodal Framework for Culturally\n  Grounded Spoken Visual QA",
    "summary": "Large-scale multimodal models achieve strong results on tasks like Visual\nQuestion Answering (VQA), but they often fail when queries require culturally\ngrounded, everyday knowledge, particularly in low-resource and underrepresented\nlanguages. To bridge this gap, we introduce Everyday Multimodal and\nMultilingual QA (EverydayMMQA), a framework for creating large-scale,\nculturally-grounded datasets for spoken and visual question answering (SVQA).\nUsing this framework, we developed OASIS, a multimodal dataset integrating\nspeech, images, and text. With over ~0.92M images and 14.8M QA pairs, OASIS\ncontains 3.7M spoken questions, enabling four unique input combinations:\nspeech-only, text-only, speech+image, and text+image. Focused on English and\nArabic varieties, 18 countries, the dataset content is curated to reflect\ndiverse, real-world situations. OASIS tests models on tasks beyond object\nrecognition that involve pragmatic, commonsense, and culturally aware\nreasoning. We benchmarked four closed-source models, three open-source models,\nand one fine-tuned model. EverydayMMQA and OASIS together provide a benchmark\nand training dataset for building multimodal LLMs for a comprehensive set of\neveryday tasks within cultural contexts. The framework and dataset will be made\npublicly available to the community.",
    "published": "2025-10-07T18:37:32Z",
    "updated": "2025-10-07T18:37:32Z",
    "link": "http://arxiv.org/pdf/2510.06371v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "F.2.2; I.2.7"
    ],
    "authors": [
      "Firoj Alam",
      "Ali Ezzat Shahroor",
      "Md. Arid Hasan",
      "Zien Sheikh Ali",
      "Hunzalah Hassan Bhatti",
      "Mohamed Bayan Kmainasi",
      "Shammur Absar Chowdhury",
      "Basel Mousi",
      "Fahim Dalvi",
      "Nadir Durrani",
      "Natasa Milic-Frayling"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06357v1",
    "title": "Constrained Natural Language Action Planning for Resilient Embodied\n  Systems",
    "summary": "Replicating human-level intelligence in the execution of embodied tasks\nremains challenging due to the unconstrained nature of real-world environments.\nNovel use of large language models (LLMs) for task planning seeks to address\nthe previously intractable state/action space of complex planning tasks, but\nhallucinations limit their reliability, and thus, viability beyond a research\ncontext. Additionally, the prompt engineering required to achieve adequate\nsystem performance lacks transparency, and thus, repeatability. In contrast to\nLLM planning, symbolic planning methods offer strong reliability and\nrepeatability guarantees, but struggle to scale to the complexity and ambiguity\nof real-world tasks. We introduce a new robotic planning method that augments\nLLM planners with symbolic planning oversight to improve reliability and\nrepeatability, and provide a transparent approach to defining hard constraints\nwith considerably stronger clarity than traditional prompt engineering.\nImportantly, these augmentations preserve the reasoning capabilities of LLMs\nand retain impressive generalization in open-world environments. We demonstrate\nour approach in simulated and real-world environments. On the ALFWorld planning\nbenchmark, our approach outperforms current state-of-the-art methods, achieving\na near-perfect 99% success rate. Deployment of our method to a real-world\nquadruped robot resulted in 100% task success compared to 50% and 30% for pure\nLLM and symbolic planners across embodied pick and place tasks. Our approach\npresents an effective strategy to enhance the reliability, repeatability and\ntransparency of LLM-based robot planners while retaining their key strengths:\nflexibility and generalizability to complex real-world environments. We hope\nthat this work will contribute to the broad goal of building resilient embodied\nintelligent systems.",
    "published": "2025-10-07T18:23:12Z",
    "updated": "2025-10-07T18:23:12Z",
    "link": "http://arxiv.org/pdf/2510.06357v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Grayson Byrd",
      "Corban Rivera",
      "Bethany Kemp",
      "Meghan Booker",
      "Aurora Schmidt",
      "Celso M de Melo",
      "Lalithkumar Seenivasan",
      "Mathias Unberath"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.10607v2",
    "title": "MONAQ: Multi-Objective Neural Architecture Querying for Time-Series\n  Analysis on Resource-Constrained Devices",
    "summary": "The growing use of smartphones and IoT devices necessitates efficient\ntime-series analysis on resource-constrained hardware, which is critical for\nsensing applications such as human activity recognition and air quality\nprediction. Recent efforts in hardware-aware neural architecture search (NAS)\nautomate architecture discovery for specific platforms; however, none focus on\ngeneral time-series analysis with edge deployment. Leveraging the\nproblem-solving and reasoning capabilities of large language models (LLM), we\npropose MONAQ, a novel framework that reformulates NAS into Multi-Objective\nNeural Architecture Querying tasks. MONAQ is equipped with multimodal query\ngeneration for processing multimodal time-series inputs and hardware\nconstraints, alongside an LLM agent-based multi-objective search to achieve\ndeployment-ready models via code generation. By integrating numerical data,\ntime-series images, and textual descriptions, MONAQ improves an LLM's\nunderstanding of time-series data. Experiments on fifteen datasets demonstrate\nthat MONAQ-discovered models outperform both handcrafted models and NAS\nbaselines while being more efficient.",
    "published": "2025-05-15T16:35:33Z",
    "updated": "2025-10-07T18:22:51Z",
    "link": "http://arxiv.org/pdf/2505.10607v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Patara Trirat",
      "Jae-Gil Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06353v1",
    "title": "TransFIRA: Transfer Learning for Face Image Recognizability Assessment",
    "summary": "Face recognition in unconstrained environments such as surveillance, video,\nand web imagery must contend with extreme variation in pose, blur,\nillumination, and occlusion, where conventional visual quality metrics fail to\npredict whether inputs are truly recognizable to the deployed encoder. Existing\nFIQA methods typically rely on visual heuristics, curated annotations, or\ncomputationally intensive generative pipelines, leaving their predictions\ndetached from the encoder's decision geometry. We introduce TransFIRA (Transfer\nLearning for Face Image Recognizability Assessment), a lightweight and\nannotation-free framework that grounds recognizability directly in embedding\nspace. TransFIRA delivers three advances: (i) a definition of recognizability\nvia class-center similarity (CCS) and class-center angular separation (CCAS),\nyielding the first natural, decision-boundary--aligned criterion for filtering\nand weighting; (ii) a recognizability-informed aggregation strategy that\nachieves state-of-the-art verification accuracy on BRIAR and IJB-C while nearly\ndoubling correlation with true recognizability, all without external labels,\nheuristics, or backbone-specific training; and (iii) new extensions beyond\nfaces, including encoder-grounded explainability that reveals how degradations\nand subject-specific factors affect recognizability, and the first\nrecognizability-aware body recognition assessment. Experiments confirm\nstate-of-the-art results on faces, strong performance on body recognition, and\nrobustness under cross-dataset shifts. Together, these contributions establish\nTransFIRA as a unified, geometry-driven framework for recognizability\nassessment -- encoder-specific, accurate, interpretable, and extensible across\nmodalities -- significantly advancing FIQA in accuracy, explainability, and\nscope.",
    "published": "2025-10-07T18:16:21Z",
    "updated": "2025-10-07T18:16:21Z",
    "link": "http://arxiv.org/pdf/2510.06353v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Allen Tu",
      "Kartik Narayan",
      "Joshua Gleason",
      "Jennifer Xu",
      "Matthew Meyn",
      "Tom Goldstein",
      "Vishal M. Patel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.06541v2",
    "title": "KramaBench: A Benchmark for AI Systems on Data-to-Insight Pipelines over\n  Data Lakes",
    "summary": "Constructing real-world data-to-insight pipelines often involves data\nextraction from data lakes, data integration across heterogeneous data sources,\nand diverse operations from data cleaning to analysis. The design and\nimplementation of data science pipelines require domain knowledge, technical\nexpertise, and even project-specific insights. AI systems have shown remarkable\nreasoning, coding, and understanding capabilities. However, it remains unclear\nto what extent these capabilities translate into successful design and\nexecution of such complex pipelines. We introduce KRAMABENCH: a benchmark\ncomposed of 104 manually-curated real-world data science pipelines spanning\n1700 data files from 24 data sources in 6 different domains. We show that these\npipelines test the end-to-end capabilities of AI systems on data processing,\nrequiring data discovery, wrangling and cleaning, efficient processing,\nstatistical reasoning, and orchestrating data processing steps given a\nhigh-level task. Our evaluation tests 5 general models and 3 code generation\nmodels using our reference framework, DS-GURU, which instructs the AI model to\ndecompose a question into a sequence of subtasks, reason through each step, and\nsynthesize Python code that implements the proposed design. Our results on\nKRAMABENCH show that, although the models are sufficiently capable of solving\nwell-specified data science code generation tasks, when extensive data\nprocessing and domain knowledge are required to construct real-world data\nscience pipelines, existing out-of-box models fall short. Progress on\nKramaBench represents crucial steps towards developing autonomous data science\nagents for real-world applications. Our code, reference framework, and data are\navailable at https://github.com/mitdbg/KramaBench.",
    "published": "2025-06-06T21:18:45Z",
    "updated": "2025-10-07T18:15:23Z",
    "link": "http://arxiv.org/pdf/2506.06541v2.pdf",
    "category": [
      "cs.DB",
      "cs.AI",
      "cs.MA"
    ],
    "authors": [
      "Eugenie Lai",
      "Gerardo Vitagliano",
      "Ziyu Zhang",
      "Om Chabra",
      "Sivaprasad Sudhir",
      "Anna Zeng",
      "Anton A. Zabreyko",
      "Chenning Li",
      "Ferdi Kossmann",
      "Jialin Ding",
      "Jun Chen",
      "Markos Markakis",
      "Matthew Russo",
      "Weiyang Wang",
      "Ziniu Wu",
      "Michael J. Cafarella",
      "Lei Cao",
      "Samuel Madden",
      "Tim Kraska"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06350v1",
    "title": "Asking For It: Question-Answering for Predicting Rule Infractions in\n  Online Content Moderation",
    "summary": "Online communities rely on a mix of platform policies and community-authored\nrules to define acceptable behavior and maintain order. However, these rules\nvary widely across communities, evolve over time, and are enforced\ninconsistently, posing challenges for transparency, governance, and automation.\nIn this paper, we model the relationship between rules and their enforcement at\nscale, introducing ModQ, a novel question-answering framework for\nrule-sensitive content moderation. Unlike prior classification or\ngeneration-based approaches, ModQ conditions on the full set of community rules\nat inference time and identifies which rule best applies to a given comment. We\nimplement two model variants - extractive and multiple-choice QA - and train\nthem on large-scale datasets from Reddit and Lemmy, the latter of which we\nconstruct from publicly available moderation logs and rule descriptions. Both\nmodels outperform state-of-the-art baselines in identifying moderation-relevant\nrule violations, while remaining lightweight and interpretable. Notably, ModQ\nmodels generalize effectively to unseen communities and rules, supporting\nlow-resource moderation settings and dynamic governance environments.",
    "published": "2025-10-07T18:11:27Z",
    "updated": "2025-10-07T18:11:27Z",
    "link": "http://arxiv.org/pdf/2510.06350v1.pdf",
    "category": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.LG"
    ],
    "authors": [
      "Mattia Samory",
      "Diana Pamfile",
      "Andrew To",
      "Shruti Phadke"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.17624v2",
    "title": "Machine Learning and Multi-source Remote Sensing in Forest Aboveground\n  Biomass Estimation: A Review",
    "summary": "Quantifying forest aboveground biomass (AGB) is crucial for informing\ndecisions and policies that will protect the planet. Machine learning (ML) and\nremote sensing (RS) techniques have been used to do this task more effectively,\nyet there lacks a systematic review on the most recent working combinations of\nML methods and multiple RS sources, especially with the consideration of the\nforests' ecological characteristics. This study systematically analyzed 25\npapers that met strict inclusion criteria from over 80 related studies,\nidentifying all ML methods and combinations of RS data used. Random Forest had\nthe most frequent appearance (88\\% of studies), while Extreme Gradient Boosting\nshowed superior performance in 75\\% of the studies in which it was compared\nwith other methods. Sentinel-1 emerged as the most utilized remote sensing\nsource, with multi-sensor approaches (e.g., Sentinel-1, Sentinel-2, and LiDAR)\nproving especially effective. Our findings provide grounds for recommending\nwhich sensing sources, variables, and methods to consider using when\nintegrating ML and RS for forest AGB estimation.",
    "published": "2024-11-26T17:34:59Z",
    "updated": "2025-10-07T18:11:26Z",
    "link": "http://arxiv.org/pdf/2411.17624v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Autumn Nguyen",
      "Sulagna Saha"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06349v1",
    "title": "Flexible Swarm Learning May Outpace Foundation Models in Essential Tasks",
    "summary": "Foundation models have rapidly advanced AI, raising the question of whether\ntheir decisions will ultimately surpass human strategies in real-world domains.\nThe exponential, and possibly super-exponential, pace of AI development makes\nsuch analysis elusive. Nevertheless, many application areas that matter for\ndaily life and society show only modest gains so far; a prominent case is\ndiagnosing and treating dynamically evolving disease in intensive care.\n  The common challenge is adapting complex systems to dynamic environments.\nEffective strategies must optimize outcomes in systems composed of strongly\ninteracting functions while avoiding shared side effects; this requires\nreliable, self-adaptive modeling. These tasks align with building digital twins\nof highly complex systems whose mechanisms are not fully or quantitatively\nunderstood. It is therefore essential to develop methods for self-adapting AI\nmodels with minimal data and limited mechanistic knowledge. As this challenge\nextends beyond medicine, AI should demonstrate clear superiority in these\nsettings before assuming broader decision-making roles.\n  We identify the curse of dimensionality as a fundamental barrier to efficient\nself-adaptation and argue that monolithic foundation models face conceptual\nlimits in overcoming it. As an alternative, we propose a decentralized\narchitecture of interacting small agent networks (SANs). We focus on agents\nrepresenting the specialized substructure of the system, where each agent\ncovers only a subset of the full system functions. Drawing on mathematical\nresults on the learning behavior of SANs and evidence from existing\napplications, we argue that swarm-learning in diverse swarms can enable\nself-adaptive SANs to deliver superior decision-making in dynamic environments\ncompared with monolithic foundation models, though at the cost of reduced\nreproducibility in detail.",
    "published": "2025-10-07T18:10:31Z",
    "updated": "2025-10-07T18:10:31Z",
    "link": "http://arxiv.org/pdf/2510.06349v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "authors": [
      "Moein E. Samadi",
      "Andreas Schuppert"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.04486v3",
    "title": "Efficient Flow Matching using Latent Variables",
    "summary": "Flow matching models have shown great potential in image generation tasks\namong probabilistic generative models. However, most flow matching models in\nthe literature do not explicitly utilize the underlying clustering structure in\nthe target data when learning the flow from a simple source distribution like\nthe standard Gaussian. This leads to inefficient learning, especially for many\nhigh-dimensional real-world datasets, which often reside in a low-dimensional\nmanifold. To this end, we present $\\texttt{Latent-CFM}$, which provides\nefficient training strategies by conditioning on the features extracted from\ndata using pretrained deep latent variable models. Through experiments on\nsynthetic data from multi-modal distributions and widely used image benchmark\ndatasets, we show that $\\texttt{Latent-CFM}$ exhibits improved generation\nquality with significantly less training and computation than state-of-the-art\nflow matching models by adopting pretrained lightweight latent variable models.\nBeyond natural images, we consider generative modeling of spatial fields\nstemming from physical processes. Using a 2d Darcy flow dataset, we demonstrate\nthat our approach generates more physically accurate samples than competing\napproaches. In addition, through latent space analysis, we demonstrate that our\napproach can be used for conditional image generation conditioned on latent\nfeatures, which adds interpretability to the generation process.",
    "published": "2025-05-07T14:59:23Z",
    "updated": "2025-10-07T18:10:05Z",
    "link": "http://arxiv.org/pdf/2505.04486v3.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Anirban Samaddar",
      "Yixuan Sun",
      "Viktor Nilsson",
      "Sandeep Madireddy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06343v1",
    "title": "Leveraging Large Language Models for Cybersecurity Risk Assessment -- A\n  Case from Forestry Cyber-Physical Systems",
    "summary": "In safety-critical software systems, cybersecurity activities become\nessential, with risk assessment being one of the most critical. In many\nsoftware teams, cybersecurity experts are either entirely absent or represented\nby only a small number of specialists. As a result, the workload for these\nexperts becomes high, and software engineers would need to conduct\ncybersecurity activities themselves. This creates a need for a tool to support\ncybersecurity experts and engineers in evaluating vulnerabilities and threats\nduring the risk assessment process. This paper explores the potential of\nleveraging locally hosted large language models (LLMs) with retrieval-augmented\ngeneration to support cybersecurity risk assessment in the forestry domain\nwhile complying with data protection and privacy requirements that limit\nexternal data sharing. We performed a design science study involving 12 experts\nin interviews, interactive sessions, and a survey within a large-scale project.\nThe results demonstrate that LLMs can assist cybersecurity experts by\ngenerating initial risk assessments, identifying threats, and providing\nredundancy checks. The results also highlight the necessity for human oversight\nto ensure accuracy and compliance. Despite trust concerns, experts were willing\nto utilize LLMs in specific evaluation and assistance roles, rather than solely\nrelying on their generative capabilities. This study provides insights that\nencourage the use of LLM-based agents to support the risk assessment process of\ncyber-physical systems in safety-critical domains.",
    "published": "2025-10-07T18:07:16Z",
    "updated": "2025-10-07T18:07:16Z",
    "link": "http://arxiv.org/pdf/2510.06343v1.pdf",
    "category": [
      "cs.SE",
      "cs.AI",
      "cs.CR"
    ],
    "authors": [
      "Fikret Mert Gültekin",
      "Oscar Lilja",
      "Ranim Khojah",
      "Rebekka Wohlrab",
      "Marvin Damschen",
      "Mazen Mohamad"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.12726v3",
    "title": "DESIGNER: Design-Logic-Guided Multidisciplinary Data Synthesis for LLM\n  Reasoning",
    "summary": "Large language models (LLMs) have achieved remarkable success in many natural\nlanguage tasks but still struggle with complex, multi-step reasoning,\nparticularly across diverse disciplines. Existing reasoning datasets often lack\ndisciplinary breadth, reasoning depth, and diversity, and lack guiding\nprinciples for question synthesis. We propose DESIGNER: a DESIGN-logic-guidEd\nReasoning data synthesis pipeline that leverages naturally available, extensive\nraw documents (e.g., book corpus and web corpus) to generate multidisciplinary\nchallenging questions. We introduce the concept of \"design logic\" and instruct\nLLMs to mimic human educators' question-creation process, enabling automated\nsynthesis of large-scale, high-difficulty questions. We use LLMs to\nreverse-engineer and abstract over 120,000 design logics from existing\nquestions across various disciplines. By matching these design logics with\nsource documents, we are able to create reasoning questions that far surpass\nthe difficulty and diversity of existing datasets. Using this pipeline, we\nsynthesized two large-scale reasoning datasets that span 75 disciplines:\nDLR-Book (3.04 million questions from the book corpus) and DLR-Web (1.66\nmillion questions from the web corpus). Data analysis indicates that the\nquestions synthesized by our method exhibit greater difficulty and diversity\ncompared to those in the baseline datasets. We validate our synthesized data\nthrough supervised fine-tuning (SFT) on the Qwen3 and Llama3 model families.\nOur data substantially enhances their multidisciplinary reasoning capabilities,\noutperforming existing datasets. Notably, after SFT on our datasets, the base\nversions of these models even surpass their official instruction-tuned\ncounterparts.",
    "published": "2025-08-18T08:49:29Z",
    "updated": "2025-10-08T17:57:43Z",
    "link": "http://arxiv.org/pdf/2508.12726v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Weize Liu",
      "Yongchi Zhao",
      "Yijia Luo",
      "Mingyu Xu",
      "Jiaheng Liu",
      "Yanan Li",
      "Xiguo Hu",
      "Zhiqi Bai",
      "Yuchi Xu",
      "Wenbo Su",
      "Bo Zheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07309v1",
    "title": "Agent Bain vs. Agent McKinsey: A New Text-to-SQL Benchmark for the\n  Business Domain",
    "summary": "In the business domain, where data-driven decision making is crucial,\ntext-to-SQL is fundamental for easy natural language access to structured data.\nWhile recent LLMs have achieved strong performance in code generation, existing\ntext-to-SQL benchmarks remain focused on factual retrieval of past records. We\nintroduce CORGI, a new benchmark specifically designed for real-world business\ncontexts. CORGI is composed of synthetic databases inspired by enterprises such\nas Doordash, Airbnb, and Lululemon. It provides questions across four\nincreasingly complex categories of business queries: descriptive, explanatory,\npredictive, and recommendational. This challenge calls for causal reasoning,\ntemporal forecasting, and strategic recommendation, reflecting multi-level and\nmulti-step agentic intelligence. We find that LLM performance drops on\nhigh-level questions, struggling to make accurate predictions and offer\nactionable plans. Based on execution success rate, the CORGI benchmark is about\n21\\% more difficult than the BIRD benchmark. This highlights the gap between\npopular LLMs and the need for real-world business intelligence. We release a\npublic dataset and evaluation framework, and a website for public submissions.",
    "published": "2025-10-08T17:57:35Z",
    "updated": "2025-10-08T17:57:35Z",
    "link": "http://arxiv.org/pdf/2510.07309v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yue Li",
      "Ran Tao",
      "Derek Hommel",
      "Yusuf Denizay Dönder",
      "Sungyong Chang",
      "David Mimno",
      "Unso Eun Seo Jo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.05468v2",
    "title": "LatteReview: A Multi-Agent Framework for Systematic Review Automation\n  Using Large Language Models",
    "summary": "Systematic literature reviews and meta-analyses are essential for\nsynthesizing research insights, but they remain time-intensive and\nlabor-intensive due to the iterative processes of screening, evaluation, and\ndata extraction. This paper introduces and evaluates LatteReview, a\nPython-based framework that leverages large language models (LLMs) and\nmulti-agent systems to automate key elements of the systematic review process.\nDesigned to streamline workflows while maintaining rigor, LatteReview utilizes\nmodular agents for tasks such as title and abstract screening, relevance\nscoring, and structured data extraction. These agents operate within\norchestrated workflows, supporting sequential and parallel review rounds,\ndynamic decision-making, and iterative refinement based on user feedback.\nLatteReview's architecture integrates LLM providers, enabling compatibility\nwith both cloud-based and locally hosted models. The framework supports\nfeatures such as Retrieval-Augmented Generation (RAG) for incorporating\nexternal context, multimodal reviews, Pydantic-based validation for structured\ninputs and outputs, and asynchronous programming for handling large-scale\ndatasets. The framework is available on the GitHub repository, with detailed\ndocumentation and an installable package.",
    "published": "2025-01-05T17:53:00Z",
    "updated": "2025-10-08T17:55:02Z",
    "link": "http://arxiv.org/pdf/2501.05468v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Pouria Rouzrokh",
      "Bardia Khosravi",
      "Parsa Rouzrokh",
      "Moein Shariatnia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07300v1",
    "title": "Think Natively: Unlocking Multilingual Reasoning with\n  Consistency-Enhanced Reinforcement Learning",
    "summary": "Large Reasoning Models (LRMs) have achieved remarkable performance on complex\nreasoning tasks by adopting the \"think-then-answer\" paradigm, which enhances\nboth accuracy and interpretability. However, current LRMs exhibit two critical\nlimitations when processing non-English languages: (1) They often struggle to\nmaintain input-output language consistency; (2) They generally perform poorly\nwith wrong reasoning paths and lower answer accuracy compared to English. These\nlimitations significantly degrade the user experience for non-English speakers\nand hinder the global deployment of LRMs. To address these limitations, we\npropose M-Thinker, which is trained by the GRPO algorithm that involves a\nLanguage Consistency (LC) reward and a novel Cross-lingual Thinking Alignment\n(CTA) reward. Specifically, the LC reward defines a strict constraint on the\nlanguage consistency between the input, thought, and answer. Besides, the CTA\nreward compares the model's non-English reasoning paths with its English\nreasoning path to transfer its own reasoning capability from English to\nnon-English languages. Through an iterative RL procedure, our M-Thinker-1.5B/7B\nmodels not only achieve nearly 100% language consistency and superior\nperformance on two multilingual benchmarks (MMATH and PolyMath), but also\nexhibit excellent generalization on out-of-domain languages.",
    "published": "2025-10-08T17:55:02Z",
    "updated": "2025-10-08T17:55:02Z",
    "link": "http://arxiv.org/pdf/2510.07300v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Xue Zhang",
      "Yunlong Liang",
      "Fandong Meng",
      "Songming Zhang",
      "Kaiyu Huang",
      "Yufeng Chen",
      "Jinan Xu",
      "Jie Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07290v1",
    "title": "On the Convergence of Moral Self-Correction in Large Language Models",
    "summary": "Large Language Models (LLMs) are able to improve their responses when\ninstructed to do so, a capability known as self-correction. When instructions\nprovide only a general and abstract goal without specific details about\npotential issues in the response, LLMs must rely on their internal knowledge to\nimprove response quality, a process referred to as intrinsic self-correction.\nThe empirical success of intrinsic self-correction is evident in various\napplications, but how and why it is effective remains unknown. Focusing on\nmoral self-correction in LLMs, we reveal a key characteristic of intrinsic\nself-correction: performance convergence through multi-round interactions; and\nprovide a mechanistic analysis of this convergence behavior. Based on our\nexperimental results and analysis, we uncover the underlying mechanism of\nconvergence: consistently injected self-correction instructions activate moral\nconcepts that reduce model uncertainty, leading to converged performance as the\nactivated moral concepts stabilize over successive rounds. This paper\ndemonstrates the strong potential of moral self-correction by showing that it\nexhibits a desirable property of converged performance.",
    "published": "2025-10-08T17:46:27Z",
    "updated": "2025-10-08T17:46:27Z",
    "link": "http://arxiv.org/pdf/2510.07290v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Guangliang Liu",
      "Haitao Mao",
      "Bochuan Cao",
      "Zhiyu Xue",
      "Xitong Zhang",
      "Rongrong Wang",
      "Kristen Marie Johnson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.19732v4",
    "title": "Speculative Decoding and Beyond: An In-Depth Survey of Techniques",
    "summary": "Sequential dependencies present a fundamental bottleneck in deploying\nlarge-scale autoregressive models, particularly for real-time applications.\nWhile traditional optimization approaches like pruning and quantization often\ncompromise model quality, recent advances in generation-refinement frameworks\ndemonstrate that this trade-off can be significantly mitigated.\n  This survey presents a comprehensive taxonomy of generation-refinement\nframeworks, analyzing methods across autoregressive sequence tasks. We\ncategorize methods based on their generation strategies (from simple n-gram\nprediction to sophisticated draft models) and refinement mechanisms (including\nsingle-pass verification and iterative approaches). Through systematic analysis\nof both algorithmic innovations and system-level implementations, we examine\ndeployment strategies across computing environments and explore applications\nspanning text, images, and speech generation. This systematic examination of\nboth theoretical frameworks and practical implementations provides a foundation\nfor future research in efficient autoregressive decoding.",
    "published": "2025-02-27T03:53:45Z",
    "updated": "2025-10-08T17:43:07Z",
    "link": "http://arxiv.org/pdf/2502.19732v4.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yunhai Hu",
      "Zining Liu",
      "Zhenyuan Dong",
      "Tianfan Peng",
      "Bradley McDanel",
      "Sai Qian Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.20757v2",
    "title": "MCTS-RAG: Enhancing Retrieval-Augmented Generation with Monte Carlo Tree\n  Search",
    "summary": "We introduce MCTS-RAG, a novel approach that enhances the reasoning\ncapabilities of small language models on knowledge-intensive tasks by\nleveraging retrieval-augmented generation (RAG) to provide relevant context and\nMonte Carlo Tree Search (MCTS) to refine reasoning paths. MCTS-RAG dynamically\nintegrates retrieval and reasoning through an iterative decision-making\nprocess. Unlike standard RAG methods, which typically retrieve information\nindependently from reasoning and thus integrate knowledge suboptimally, or\nconventional MCTS reasoning, which depends solely on internal model knowledge\nwithout external facts, MCTS-RAG combines structured reasoning with adaptive\nretrieval. This integrated approach enhances decision-making, reduces\nhallucinations, and ensures improved factual accuracy and response consistency.\nThe experimental results on multiple reasoning and knowledge-intensive datasets\ndatasets (i.e., ComplexWebQA, GPQA, and FoolMeTwice) show that our method\nenables small-scale LMs to achieve performance comparable to frontier LLMs like\nGPT-4o by effectively scaling inference-time compute, setting a new standard\nfor reasoning in small-scale models.",
    "published": "2025-03-26T17:46:08Z",
    "updated": "2025-10-08T17:36:57Z",
    "link": "http://arxiv.org/pdf/2503.20757v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yunhai Hu",
      "Yilun Zhao",
      "Chen Zhao",
      "Arman Cohan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.16185v2",
    "title": "ParamBench: A Graduate-Level Benchmark for Evaluating LLM Understanding\n  on Indic Subjects",
    "summary": "Large language models have been widely evaluated on tasks such as\ncomprehension, summarization, code generation, etc. However, their performance\non graduate-level, culturally grounded questions in the Indian context remains\nlargely unexplored. Existing Indian benchmarks emphasise basic fact-orientated\nqueries that offer limited assessment of a deeper disciplinary understanding\ntailored to the Indian setting. In this paper, we present ParamBench,\nconsisting of more than 17K questions in the Hindi language, comprising\nquestionnaires from 21 diverse subjects. These questions are primarily derived\nfrom a nationwide graduate-level entrance examination covering topics such as\nhistory, music, instruments, yoga, literature, philosophy, law, etc.~\nspecifically for the Indian context. Additionally, we assess the ability of\nLLMs to handle diverse question formats - such as list-based matching,\nassertion-reason pairs, and sequence ordering - alongside conventional\nmultiple-choice questions. We evaluated the performance of more than 16 open\nsource LLMs on this benchmark, observing that Gemma3-27B attains the highest\noverall accuracy of 56.4\\%. Furthermore, subject-wise analysis indicates that\neven for the best-performing LLMs, performance remains weak on topics such as\nmusic, classical instruments, and law, underscoring persistent challenges in\nculturally grounded reasoning. The dataset and source code is present at\nhttps://github.com/ayushbits/ParamBench.",
    "published": "2025-08-22T07:59:37Z",
    "updated": "2025-10-08T17:29:07Z",
    "link": "http://arxiv.org/pdf/2508.16185v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Ayush Maheshwari",
      "Kaushal Sharma",
      "Vivek Patel",
      "Aditya Maheshwari"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2306.10354v2",
    "title": "LLMVA-GEBC: Large Language Model with Video Adapter for Generic Event\n  Boundary Captioning",
    "summary": "Our winning entry for the CVPR 2023 Generic Event Boundary Captioning (GEBC)\ncompetition is detailed in this paper. Unlike conventional video captioning\ntasks, GEBC demands that the captioning model possess an understanding of\nimmediate changes in status around the designated video boundary, making it a\ndifficult task. This paper proposes an effective model LLMVA-GEBC (Large\nLanguage Model with Video Adapter for Generic Event Boundary Captioning): (1)\nWe utilize a pretrained LLM for generating human-like captions with high\nquality. (2) To adapt the model to the GEBC task, we take the video Q-former as\nan adapter and train it with the frozen visual feature extractors and LLM. Our\nproposed method achieved a 76.14 score on the test set and won the first place\nin the challenge. Our code is available at\nhttps://github.com/zjr2000/LLMVA-GEBC .",
    "published": "2023-06-17T13:55:54Z",
    "updated": "2025-10-08T17:26:33Z",
    "link": "http://arxiv.org/pdf/2306.10354v2.pdf",
    "category": [
      "cs.CV",
      "cs.CL"
    ],
    "authors": [
      "Yolo Yunlong Tang",
      "Jinrui Zhang",
      "Xiangchen Wang",
      "Teng Wang",
      "Feng Zheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2307.04827v3",
    "title": "LaunchpadGPT: Language Model as Music Visualization Designer on\n  Launchpad",
    "summary": "Launchpad is a musical instrument that allows users to create and perform\nmusic by pressing illuminated buttons. To assist and inspire the design of the\nLaunchpad light effect, and provide a more accessible approach for beginners to\ncreate music visualization with this instrument, we proposed the LaunchpadGPT\nmodel to generate music visualization designs on Launchpad automatically. Based\non the language model with excellent generation ability, our proposed\nLaunchpadGPT takes an audio piece of music as input and outputs the lighting\neffects of Launchpad-playing in the form of a video (Launchpad-playing video).\nWe collect Launchpad-playing videos and process them to obtain music and\ncorresponding video frame of Launchpad-playing as prompt-completion pairs, to\ntrain the language model. The experiment result shows the proposed method can\ncreate better music visualization than random generation methods and hold the\npotential for a broader range of music visualization applications. Our code is\navailable at https://github.com/yunlong10/LaunchpadGPT/.",
    "published": "2023-07-07T16:25:59Z",
    "updated": "2025-10-08T17:24:43Z",
    "link": "http://arxiv.org/pdf/2307.04827v3.pdf",
    "category": [
      "cs.SD",
      "cs.CL",
      "cs.MM",
      "eess.AS"
    ],
    "authors": [
      "Siting Xu",
      "Yolo Yunlong Tang",
      "Feng Zheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07248v1",
    "title": "Don't Adapt Small Language Models for Tools; Adapt Tool Schemas to the\n  Models",
    "summary": "Small language models (SLMs) offer significant computational advantages for\ntool-augmented AI systems, yet they struggle with tool-use tasks, particularly\nin selecting appropriate tools and identifying correct parameters. A common\nfailure mode is schema misalignment: models hallucinate plausible but\nnon-existent tool names that reflect naming conventions internalized during\npretraining but absent from the provided tool schema. Rather than forcing\nmodels to adapt to arbitrary schemas, we propose adapting schemas to align with\nmodels' pretrained knowledge. We introduce PA-Tool (Pretraining-Aligned Tool\nSchema Generation), a training-free method that leverages peakedness-a signal\nfrom contamination detection indicating pretraining familiarity-to\nautomatically rename tool components. By generating multiple candidates and\nselecting those with highest output concentration across samples, PA-Tool\nidentifies pretrain-aligned naming patterns. Experiments on MetaTool and\nRoTBench show improvements of up to 17% points, with schema misalignment errors\nreduced by 80%. PA-Tool enables small models to approach state-of-the-art\nperformance while maintaining computational efficiency for adaptation to new\ntools without retraining. Our work demonstrates that schema-level interventions\ncan unlock the tool-use potential of resource-efficient models by adapting\nschemas to models rather than models to schemas.",
    "published": "2025-10-08T17:16:07Z",
    "updated": "2025-10-08T17:16:07Z",
    "link": "http://arxiv.org/pdf/2510.07248v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Jonggeun Lee",
      "Woojung Song",
      "Jongwook Han",
      "Haesung Pyun",
      "Yohan Jo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07242v1",
    "title": "Hybrid Reinforcement: When Reward Is Sparse, It's Better to Be Dense",
    "summary": "Post-training for reasoning of large language models (LLMs) increasingly\nrelies on verifiable rewards: deterministic checkers that provide 0-1\ncorrectness signals. While reliable, such binary feedback is brittle--many\ntasks admit partially correct or alternative answers that verifiers\nunder-credit, and the resulting all-or-nothing supervision limits learning.\nReward models offer richer, continuous feedback, which can serve as a\ncomplementary supervisory signal to verifiers. We introduce HERO (Hybrid\nEnsemble Reward Optimization), a reinforcement learning framework that\nintegrates verifier signals with reward-model scores in a structured way. HERO\nemploys stratified normalization to bound reward-model scores within\nverifier-defined groups, preserving correctness while refining quality\ndistinctions, and variance-aware weighting to emphasize challenging prompts\nwhere dense signals matter most. Across diverse mathematical reasoning\nbenchmarks, HERO consistently outperforms RM-only and verifier-only baselines,\nwith strong gains on both verifiable and hard-to-verify tasks. Our results show\nthat hybrid reward design retains the stability of verifiers while leveraging\nthe nuance of reward models to advance reasoning.",
    "published": "2025-10-08T17:09:41Z",
    "updated": "2025-10-08T17:09:41Z",
    "link": "http://arxiv.org/pdf/2510.07242v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Leitian Tao",
      "Ilia Kulikov",
      "Swarnadeep Saha",
      "Tianlu Wang",
      "Jing Xu",
      "Yixuan Li",
      "Jason E Weston",
      "Ping Yu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07239v1",
    "title": "Red-Bandit: Test-Time Adaptation for LLM Red-Teaming via Bandit-Guided\n  LoRA Experts",
    "summary": "Automated red-teaming has emerged as a scalable approach for auditing Large\nLanguage Models (LLMs) prior to deployment, yet existing approaches lack\nmechanisms to efficiently adapt to model-specific vulnerabilities at inference.\nWe introduce Red-Bandit, a red-teaming framework that adapts online to identify\nand exploit model failure modes under distinct attack styles (e.g.,\nmanipulation, slang). Red-Bandit post-trains a set of parameter-efficient LoRA\nexperts, each specialized for a particular attack style, using reinforcement\nlearning that rewards the generation of unsafe prompts via a rule-based safety\nmodel. At inference, a multi-armed bandit policy dynamically selects among\nthese attack-style experts based on the target model's response safety,\nbalancing exploration and exploitation. Red-Bandit achieves state-of-the-art\nresults on AdvBench under sufficient exploration (ASR@10), while producing more\nhuman-readable prompts (lower perplexity). Moreover, Red-Bandit's bandit policy\nserves as a diagnostic tool for uncovering model-specific vulnerabilities by\nindicating which attack styles most effectively elicit unsafe behaviors.",
    "published": "2025-10-08T17:06:20Z",
    "updated": "2025-10-08T17:06:20Z",
    "link": "http://arxiv.org/pdf/2510.07239v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Christos Ziakas",
      "Nicholas Loo",
      "Nishita Jain",
      "Alessandra Russo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07238v1",
    "title": "When Benchmarks Age: Temporal Misalignment through Large Language Model\n  Factuality Evaluation",
    "summary": "The rapid evolution of large language models (LLMs) and the real world has\noutpaced the static nature of widely used evaluation benchmarks, raising\nconcerns about their reliability for evaluating LLM factuality. While\nsubstantial works continue to rely on the popular but old benchmarks, their\ntemporal misalignment with real-world facts and modern LLMs, and their effects\non LLM factuality evaluation remain underexplored. Therefore, in this work, we\npresent a systematic investigation of this issue by examining five popular\nfactuality benchmarks and eight LLMs released across different years. An\nup-to-date fact retrieval pipeline and three metrics are tailored to quantify\nbenchmark aging and its impact on LLM factuality evaluation. Experimental\nresults and analysis illustrate that a considerable portion of samples in the\nwidely used factuality benchmarks are outdated, leading to unreliable\nassessments of LLM factuality. We hope our work can provide a testbed to assess\nthe reliability of a benchmark for LLM factuality evaluation and inspire more\nresearch on the benchmark aging issue. Codes are available in\nhttps://github.com/JiangXunyi/BenchAge.",
    "published": "2025-10-08T17:06:07Z",
    "updated": "2025-10-08T17:06:07Z",
    "link": "http://arxiv.org/pdf/2510.07238v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Xunyi Jiang",
      "Dingyi Chang",
      "Julian McAuley",
      "Xin Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07233v1",
    "title": "LAD-RAG: Layout-aware Dynamic RAG for Visually-Rich Document\n  Understanding",
    "summary": "Question answering over visually rich documents (VRDs) requires reasoning not\nonly over isolated content but also over documents' structural organization and\ncross-page dependencies. However, conventional retrieval-augmented generation\n(RAG) methods encode content in isolated chunks during ingestion, losing\nstructural and cross-page dependencies, and retrieve a fixed number of pages at\ninference, regardless of the specific demands of the question or context. This\noften results in incomplete evidence retrieval and degraded answer quality for\nmulti-page reasoning tasks. To address these limitations, we propose LAD-RAG, a\nnovel Layout-Aware Dynamic RAG framework. During ingestion, LAD-RAG constructs\na symbolic document graph that captures layout structure and cross-page\ndependencies, adding it alongside standard neural embeddings to yield a more\nholistic representation of the document. During inference, an LLM agent\ndynamically interacts with the neural and symbolic indices to adaptively\nretrieve the necessary evidence based on the query. Experiments on\nMMLongBench-Doc, LongDocURL, DUDE, and MP-DocVQA demonstrate that LAD-RAG\nimproves retrieval, achieving over 90% perfect recall on average without any\ntop-k tuning, and outperforming baseline retrievers by up to 20% in recall at\ncomparable noise levels, yielding higher QA accuracy with minimal latency.",
    "published": "2025-10-08T17:02:04Z",
    "updated": "2025-10-08T17:02:04Z",
    "link": "http://arxiv.org/pdf/2510.07233v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Zhivar Sourati",
      "Zheng Wang",
      "Marianne Menglin Liu",
      "Yazhe Hu",
      "Mengqing Guo",
      "Sujeeth Bharadwaj",
      "Kyu Han",
      "Tao Sheng",
      "Sujith Ravi",
      "Morteza Dehghani",
      "Dan Roth"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07230v1",
    "title": "Customer-R1: Personalized Simulation of Human Behaviors via RL-based LLM\n  Agent in Online Shopping",
    "summary": "Simulating step-wise human behavior with Large Language Models (LLMs) has\nbecome an emerging research direction, enabling applications in various\npractical domains. While prior methods, including prompting, supervised\nfine-tuning (SFT), and reinforcement learning (RL), have shown promise in\nmodeling step-wise behavior, they primarily learn a population-level policy\nwithout conditioning on a user's persona, yielding generic rather than\npersonalized simulations. In this work, we pose a critical question: how can\nLLM agents better simulate personalized user behavior? We introduce\nCustomer-R1, an RL-based method for personalized, step-wise user behavior\nsimulation in online shopping environments. Our policy is conditioned on an\nexplicit persona, and we optimize next-step rationale and action generation via\naction correctness reward signals. Experiments on the OPeRA dataset emonstrate\nthat Customer-R1 not only significantly outperforms prompting and SFT-based\nbaselines in next-action prediction tasks, but also better matches users'\naction distribution, indicating higher fidelity in personalized behavior\nsimulation.",
    "published": "2025-10-08T17:00:25Z",
    "updated": "2025-10-08T17:00:25Z",
    "link": "http://arxiv.org/pdf/2510.07230v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Ziyi Wang",
      "Yuxuan Lu",
      "Yimeng Zhang",
      "Jing Huang",
      "Dakuo Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07226v1",
    "title": "Machines in the Crowd? Measuring the Footprint of Machine-Generated Text\n  on Reddit",
    "summary": "Generative Artificial Intelligence is reshaping online communication by\nenabling large-scale production of Machine-Generated Text (MGT) at low cost.\nWhile its presence is rapidly growing across the Web, little is known about how\nMGT integrates into social media environments. In this paper, we present the\nfirst large-scale characterization of MGT on Reddit. Using a state-of-the-art\nstatistical method for detection of MGT, we analyze over two years of activity\n(2022-2024) across 51 subreddits representative of Reddit's main community\ntypes such as information seeking, social support, and discussion. We study the\nconcentration of MGT across communities and over time, and compared MGT to\nhuman-authored text in terms of social signals it expresses and engagement it\nreceives. Our very conservative estimate of MGT prevalence indicates that\nsynthetic text is marginally present on Reddit, but it can reach peaks of up to\n9% in some communities in some months. MGT is unevenly distributed across\ncommunities, more prevalent in subreddits focused on technical knowledge and\nsocial support, and often concentrated in the activity of a small fraction of\nusers. MGT also conveys distinct social signals of warmth and status giving\ntypical of language of AI assistants. Despite these stylistic differences, MGT\nachieves engagement levels comparable than human-authored content and in a few\ncases even higher, suggesting that AI-generated text is becoming an organic\ncomponent of online social discourse. This work offers the first perspective on\nthe MGT footprint on Reddit, paving the way for new investigations involving\nplatform governance, detection strategies, and community dynamics.",
    "published": "2025-10-08T16:57:45Z",
    "updated": "2025-10-08T16:57:45Z",
    "link": "http://arxiv.org/pdf/2510.07226v1.pdf",
    "category": [
      "cs.SI",
      "cs.CL",
      "cs.CY",
      "physics.soc-ph"
    ],
    "authors": [
      "Lucio La Cava",
      "Luca Maria Aiello",
      "Andrea Tagarelli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.16600v5",
    "title": "Diagnosing Moral Reasoning Acquisition in Language Models: Pragmatics\n  and Generalization",
    "summary": "Ensuring that Large Language Models (LLMs) return just responses which adhere\nto societal values is crucial for their broader application. Prior research has\nshown that LLMs often fail to perform satisfactorily on tasks requiring moral\ncognizance, such as ethics-based judgments. While current approaches have\nfocused on fine-tuning LLMs with curated datasets to improve their capabilities\non such tasks, choosing the optimal learning paradigm to enhance the ethical\nresponses of LLMs remains an open research debate. In this work, we aim to\naddress this fundamental question: can current learning paradigms enable LLMs\nto acquire sufficient moral reasoning capabilities? Drawing from distributional\nsemantics theory and the pragmatic nature of moral discourse, our analysis\nindicates that performance improvements follow a mechanism similar to that of\nsemantic-level tasks, and therefore remain affected by the pragmatic nature of\nmorals latent in discourse, a phenomenon we name the pragmatic dilemma. We\nconclude that this pragmatic dilemma imposes significant limitations on the\ngeneralization ability of current learning paradigms, making it the primary\nbottleneck for moral reasoning acquisition in LLMs.",
    "published": "2025-02-23T15:00:53Z",
    "updated": "2025-10-08T16:56:12Z",
    "link": "http://arxiv.org/pdf/2502.16600v5.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Guangliang Liu",
      "Zimo Qi",
      "Xitong Zhang",
      "Lei Jiang",
      "Kristen Marie Johnson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07221v1",
    "title": "How much speech data is necessary for ASR in African languages? An\n  evaluation of data scaling in Kinyarwanda and Kikuyu",
    "summary": "The development of Automatic Speech Recognition (ASR) systems for\nlow-resource African languages remains challenging due to limited transcribed\nspeech data. While recent advances in large multilingual models like OpenAI's\nWhisper offer promising pathways for low-resource ASR development, critical\nquestions persist regarding practical deployment requirements. This paper\naddresses two fundamental concerns for practitioners: determining the minimum\ndata volumes needed for viable performance and characterizing the primary\nfailure modes that emerge in production systems. We evaluate Whisper's\nperformance through comprehensive experiments on two Bantu languages:\nsystematic data scaling analysis on Kinyarwanda using training sets from 1 to\n1,400 hours, and detailed error characterization on Kikuyu using 270 hours of\ntraining data. Our scaling experiments demonstrate that practical ASR\nperformance (WER < 13\\%) becomes achievable with as little as 50 hours of\ntraining data, with substantial improvements continuing through 200 hours (WER\n< 10\\%). Complementing these volume-focused findings, our error analysis\nreveals that data quality issues, particularly noisy ground truth\ntranscriptions, account for 38.6\\% of high-error cases, indicating that careful\ndata curation is as critical as data volume for robust system performance.\nThese results provide actionable benchmarks and deployment guidance for teams\ndeveloping ASR systems across similar low-resource language contexts. We\nrelease accompanying and models see\nhttps://github.com/SunbirdAI/kinyarwanda-whisper-eval",
    "published": "2025-10-08T16:55:28Z",
    "updated": "2025-10-08T16:55:28Z",
    "link": "http://arxiv.org/pdf/2510.07221v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Benjamin Akera",
      "Evelyn Nafula",
      "Patrick Walukagga",
      "Gilbert Yiga",
      "John Quinn",
      "Ernest Mwebaze"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.19828v4",
    "title": "Memory-R1: Enhancing Large Language Model Agents to Manage and Utilize\n  Memories via Reinforcement Learning",
    "summary": "Large Language Models (LLMs) have demonstrated impressive capabilities across\na wide range of NLP tasks, but they remain fundamentally stateless, constrained\nby limited context windows that hinder long-horizon reasoning. Recent efforts\nto address this limitation often augment LLMs with an external memory bank, yet\nmost existing pipelines are static and heuristic-driven, lacking a learned\nmechanism for deciding what to store, update, or retrieve. We present\nMemory-R1, a reinforcement learning (RL) framework that equips LLMs with the\nability to actively manage and utilize external memory through two specialized\nagents: a Memory Manager that learns structured operations, including ADD,\nUPDATE, DELETE, and NOOP; and an Answer Agent that pre-selects and reasons over\nrelevant entries. Both agents are fine-tuned with outcome-driven RL (PPO and\nGRPO), enabling adaptive memory management with minimal supervision. With only\n152 training QA pairs, Memory-R1 outperforms strong baselines and generalizes\nacross diverse question types, three benchmarks (LoCoMo, MSC, LongMemEval), and\nmultiple model scales (3B-14B).",
    "published": "2025-08-27T12:26:55Z",
    "updated": "2025-10-08T16:54:13Z",
    "link": "http://arxiv.org/pdf/2508.19828v4.pdf",
    "category": [
      "cs.CL",
      "cs.MA"
    ],
    "authors": [
      "Sikuan Yan",
      "Xiufeng Yang",
      "Zuchao Huang",
      "Ercong Nie",
      "Zifeng Ding",
      "Zonggen Li",
      "Xiaowen Ma",
      "Kristian Kersting",
      "Jeff Z. Pan",
      "Hinrich Schütze",
      "Volker Tresp",
      "Yunpu Ma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07203v1",
    "title": "Sunflower: A New Approach To Expanding Coverage of African Languages in\n  Large Language Models",
    "summary": "There are more than 2000 living languages in Africa, most of which have been\nbypassed by advances in language technology. Current leading LLMs exhibit\nstrong performance on a number of the most common languages (e.g. Swahili or\nYoruba), but prioritise support for the languages with the most speakers first,\nresulting in piecemeal ability across disparate languages. We contend that a\nregionally focussed approach is more efficient, and present a case study for\nUganda, a country with high linguistic diversity. We describe the development\nof Sunflower 14B and 32B, a pair of models based on Qwen 3 with state of the\nart comprehension in the majority of all Ugandan languages. These models are\nopen source and can be used to reduce language barriers in a number of\nimportant practical applications.",
    "published": "2025-10-08T16:35:53Z",
    "updated": "2025-10-08T16:35:53Z",
    "link": "http://arxiv.org/pdf/2510.07203v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Benjamin Akera",
      "Evelyn Nafula Ouma",
      "Gilbert Yiga",
      "Patrick Walukagga",
      "Phionah Natukunda",
      "Trevor Saaka",
      "Solomon Nsumba",
      "Lilian Teddy Nabukeera",
      "Joel Muhanguzi",
      "Imran Sekalala",
      "Nimpamya Janat Namara",
      "Engineer Bainomugisha",
      "Ernest Mwebaze",
      "John Quinn"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2312.17432v7",
    "title": "Video Understanding with Large Language Models: A Survey",
    "summary": "With the burgeoning growth of online video platforms and the escalating\nvolume of video content, the demand for proficient video understanding tools\nhas intensified markedly. Given the remarkable capabilities of large language\nmodels (LLMs) in language and multimodal tasks, this survey provides a detailed\noverview of recent advancements in video understanding that harness the power\nof LLMs (Vid-LLMs). The emergent capabilities of Vid-LLMs are surprisingly\nadvanced, particularly their ability for open-ended multi-granularity (general,\ntemporal, and spatiotemporal) reasoning combined with commonsense knowledge,\nsuggesting a promising path for future video understanding. We examine the\nunique characteristics and capabilities of Vid-LLMs, categorizing the\napproaches into three main types: Video Analyzer x LLM, Video Embedder x LLM,\nand (Analyzer + Embedder) x LLM. Furthermore, we identify five sub-types based\non the functions of LLMs in Vid-LLMs: LLM as Summarizer, LLM as Manager, LLM as\nText Decoder, LLM as Regressor, and LLM as Hidden Layer. Furthermore, this\nsurvey presents a comprehensive study of the tasks, datasets, benchmarks, and\nevaluation methodologies for Vid-LLMs. Additionally, it explores the expansive\napplications of Vid-LLMs across various domains, highlighting their remarkable\nscalability and versatility in real-world video understanding challenges.\nFinally, it summarizes the limitations of existing Vid-LLMs and outlines\ndirections for future research. For more information, readers are recommended\nto visit the repository at\nhttps://github.com/yunlong10/Awesome-LLMs-for-Video-Understanding.",
    "published": "2023-12-29T01:56:17Z",
    "updated": "2025-10-08T16:24:55Z",
    "link": "http://arxiv.org/pdf/2312.17432v7.pdf",
    "category": [
      "cs.CV",
      "cs.CL"
    ],
    "authors": [
      "Yolo Yunlong Tang",
      "Jing Bi",
      "Siting Xu",
      "Luchuan Song",
      "Susan Liang",
      "Teng Wang",
      "Daoan Zhang",
      "Jie An",
      "Jingyang Lin",
      "Rongyi Zhu",
      "Ali Vosoughi",
      "Chao Huang",
      "Zeliang Zhang",
      "Pinxin Liu",
      "Mingqian Feng",
      "Feng Zheng",
      "Jianguo Zhang",
      "Ping Luo",
      "Jiebo Luo",
      "Chenliang Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07178v1",
    "title": "Biasless Language Models Learn Unnaturally: How LLMs Fail to Distinguish\n  the Possible from the Impossible",
    "summary": "Are large language models (LLMs) sensitive to the distinction between humanly\npossible languages and humanly impossible languages? This question is taken by\nmany to bear on whether LLMs and humans share the same innate learning biases.\nPrevious work has attempted to answer it in the positive by comparing LLM\nlearning curves on existing language datasets and on \"impossible\" datasets\nderived from them via various perturbation functions. Using the same\nmethodology, we examine this claim on a wider set of languages and impossible\nperturbations. We find that in most cases, GPT-2 learns each language and its\nimpossible counterpart equally easily, in contrast to previous claims. We also\napply a more lenient condition by testing whether GPT-2 provides any kind of\nseparation between the whole set of natural languages and the whole set of\nimpossible languages. By considering cross-linguistic variance in various\nmetrics computed on the perplexity curves, we show that GPT-2 provides no\nsystematic separation between the possible and the impossible. Taken together,\nthese perspectives show that LLMs do not share the human innate biases that\nshape linguistic typology.",
    "published": "2025-10-08T16:17:13Z",
    "updated": "2025-10-08T16:17:13Z",
    "link": "http://arxiv.org/pdf/2510.07178v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Imry Ziv",
      "Nur Lan",
      "Emmanuel Chemla",
      "Roni Katzir"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07177v1",
    "title": "CARPAS: Towards Content-Aware Refinement of Provided Aspects for\n  Summarization in Large Language Models",
    "summary": "Aspect-based summarization has attracted significant attention for its\nability to generate more fine-grained and user-aligned summaries. While most\nexisting approaches assume a set of predefined aspects as input, real-world\nscenarios often present challenges where these given aspects may be incomplete,\nirrelevant, or entirely missing from the document. Users frequently expect\nsystems to adaptively refine or filter the provided aspects based on the actual\ncontent. In this paper, we initiate this novel task setting, termed\nContent-Aware Refinement of Provided Aspects for Summarization (CARPAS), with\nthe aim of dynamically adjusting the provided aspects based on the document\ncontext before summarizing. We construct three new datasets to facilitate our\npilot experiments, and by using LLMs with four representative prompting\nstrategies in this task, we find that LLMs tend to predict an overly\ncomprehensive set of aspects, which often results in excessively long and\nmisaligned summaries. Building on this observation, we propose a preliminary\nsubtask to predict the number of relevant aspects, and demonstrate that the\npredicted number can serve as effective guidance for the LLMs, reducing the\ninference difficulty, and enabling them to focus on the most pertinent aspects.\nOur extensive experiments show that the proposed approach significantly\nimproves performance across all datasets. Moreover, our deeper analyses uncover\nLLMs' compliance when the requested number of aspects differs from their own\nestimations, establishing a crucial insight for the deployment of LLMs in\nsimilar real-world applications.",
    "published": "2025-10-08T16:16:46Z",
    "updated": "2025-10-08T16:16:46Z",
    "link": "http://arxiv.org/pdf/2510.07177v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yong-En Tian",
      "Yu-Chien Tang",
      "An-Zi Yen",
      "Wen-Chih Peng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07175v1",
    "title": "Quantifying Data Contamination in Psychometric Evaluations of LLMs",
    "summary": "Recent studies apply psychometric questionnaires to Large Language Models\n(LLMs) to assess high-level psychological constructs such as values,\npersonality, moral foundations, and dark traits. Although prior work has raised\nconcerns about possible data contamination from psychometric inventories, which\nmay threaten the reliability of such evaluations, there has been no systematic\nattempt to quantify the extent of this contamination. To address this gap, we\npropose a framework to systematically measure data contamination in\npsychometric evaluations of LLMs, evaluating three aspects: (1) item\nmemorization, (2) evaluation memorization, and (3) target score matching.\nApplying this framework to 21 models from major families and four widely used\npsychometric inventories, we provide evidence that popular inventories such as\nthe Big Five Inventory (BFI-44) and Portrait Values Questionnaire (PVQ-40)\nexhibit strong contamination, where models not only memorize items but can also\nadjust their responses to achieve specific target scores.",
    "published": "2025-10-08T16:16:20Z",
    "updated": "2025-10-08T16:16:20Z",
    "link": "http://arxiv.org/pdf/2510.07175v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Jongwook Han",
      "Woojung Song",
      "Jonggeun Lee",
      "Yohan Jo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07173v1",
    "title": "NurseLLM: The First Specialized Language Model for Nursing",
    "summary": "Recent advancements in large language models (LLMs) have significantly\ntransformed medical systems. However, their potential within specialized\ndomains such as nursing remains largely underexplored. In this work, we\nintroduce NurseLLM, the first nursing-specialized LLM tailored for multiple\nchoice question-answering (MCQ) tasks. We develop a multi-stage data generation\npipeline to build the first large scale nursing MCQ dataset to train LLMs on a\nbroad spectrum of nursing topics. We further introduce multiple nursing\nbenchmarks to enable rigorous evaluation. Our extensive experiments demonstrate\nthat NurseLLM outperforms SoTA general-purpose and medical-specialized LLMs of\ncomparable size on different benchmarks, underscoring the importance of a\nspecialized LLM for the nursing domain. Finally, we explore the role of\nreasoning and multi-agent collaboration systems in nursing, highlighting their\npromise for future research and applications.",
    "published": "2025-10-08T16:15:06Z",
    "updated": "2025-10-08T16:15:06Z",
    "link": "http://arxiv.org/pdf/2510.07173v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Md Tawkat Islam Khondaker",
      "Julia Harrington",
      "Shady Shehata"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07169v1",
    "title": "More Data or Better Data? A Critical Analysis of Data Selection and\n  Synthesis for Mathematical Reasoning",
    "summary": "The reasoning capabilities of Large Language Models (LLMs) play a critical\nrole in many downstream tasks, yet depend strongly on the quality of training\ndata. Despite various proposed data construction methods, their practical\nutility in real-world pipelines remains underexplored. In this work, we conduct\na comprehensive analysis of open-source datasets and data synthesis techniques\nfor mathematical reasoning, evaluating them under a unified pipeline designed\nto mirror training and deployment scenarios. We further distill effective data\nselection strategies and identify practical methods suitable for industrial\napplications. Our findings highlight that structuring data in more\ninterpretable formats, or distilling from stronger models often outweighs\nsimply scaling up data volume. This study provides actionable guidance for\nintegrating training data to enhance LLM capabilities, supporting both\ncost-effective data curation and scalable model enhancement. We hope this work\nwill inspire further research on how to balance \"more data\" versus \"better\ndata\" for real-world reasoning tasks.",
    "published": "2025-10-08T16:07:26Z",
    "updated": "2025-10-08T16:07:26Z",
    "link": "http://arxiv.org/pdf/2510.07169v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yike Zhao",
      "Simin Guo",
      "Ziqing Yang",
      "Shifan Han",
      "Dahua Lin",
      "Fei Tan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07167v1",
    "title": "Reasoning for Hierarchical Text Classification: The Case of Patents",
    "summary": "Hierarchical text classification (HTC) assigns documents to multiple levels\nof a pre-defined taxonomy. Automated patent subject classification represents\none of the hardest HTC scenarios because of domain knowledge difficulty and a\nhuge number of labels. Prior approaches only output a flat label set, which\noffers little insight into the reason behind predictions. Therefore, we propose\nReasoning for Hierarchical Classification (RHC), a novel framework that\nreformulates HTC as a step-by-step reasoning task to sequentially deduce\nhierarchical labels. RHC trains large language models (LLMs) in two stages: a\ncold-start stage that aligns outputs with chain-of-thought (CoT) reasoning\nformat and a reinforcement learning (RL) stage to enhance multi-step reasoning\nability. RHC demonstrates four advantages in our experiments. (1)\nEffectiveness: RHC surpasses previous baselines and outperforms the supervised\nfine-tuning counterparts by approximately 3% in accuracy and macro F1. (2)\nExplainability: RHC produces natural-language justifications before prediction\nto facilitate human inspection. (3) Scalability: RHC scales favorably with\nmodel size with larger gains compared to standard fine-tuning. (4)\nApplicability: Beyond patents, we further demonstrate that RHC achieves\nstate-of-the-art performance on other widely used HTC benchmarks, which\nhighlights its broad applicability.",
    "published": "2025-10-08T16:06:04Z",
    "updated": "2025-10-08T16:06:04Z",
    "link": "http://arxiv.org/pdf/2510.07167v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Lekang Jiang",
      "Wenjun Sun",
      "Stephan Goetz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07118v1",
    "title": "TRIM: Token-wise Attention-Derived Saliency for Data-Efficient\n  Instruction Tuning",
    "summary": "Instruction tuning is essential for aligning large language models (LLMs) to\ndownstream tasks and commonly relies on large, diverse corpora. However, small,\nhigh-quality subsets, known as coresets, can deliver comparable or superior\nresults, though curating them remains challenging. Existing methods often rely\non coarse, sample-level signals like gradients, an approach that is\ncomputationally expensive and overlooks fine-grained features. To address this,\nwe introduce TRIM (Token Relevance via Interpretable Multi-layer Attention), a\nforward-only, token-centric framework. Instead of using gradients, TRIM\noperates by matching underlying representational patterns identified via\nattention-based \"fingerprints\" from a handful of target samples. Such an\napproach makes TRIM highly efficient and uniquely sensitive to the structural\nfeatures that define a task. Coresets selected by our method consistently\noutperform state-of-the-art baselines by up to 9% on downstream tasks and even\nsurpass the performance of full-data fine-tuning in some settings. By avoiding\nexpensive backward passes, TRIM achieves this at a fraction of the\ncomputational cost. These findings establish TRIM as a scalable and efficient\nalternative for building high-quality instruction-tuning datasets.",
    "published": "2025-10-08T15:11:04Z",
    "updated": "2025-10-08T15:11:04Z",
    "link": "http://arxiv.org/pdf/2510.07118v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Manish Nagaraj",
      "Sakshi Choudhary",
      "Utkarsh Saxena",
      "Deepak Ravikumar",
      "Kaushik Roy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07098v1",
    "title": "TALENT: Table VQA via Augmented Language-Enhanced Natural-text\n  Transcription",
    "summary": "Table Visual Question Answering (Table VQA) is typically addressed by large\nvision-language models (VLMs). While such models can answer directly from\nimages, they often miss fine-grained details unless scaled to very large sizes,\nwhich are computationally prohibitive, especially for mobile deployment. A\nlighter alternative is to have a small VLM perform OCR and then use a large\nlanguage model (LLM) to reason over structured outputs such as Markdown tables.\nHowever, these representations are not naturally optimized for LLMs and still\nintroduce substantial errors. We propose TALENT (Table VQA via Augmented\nLanguage-Enhanced Natural-text Transcription), a lightweight framework that\nleverages dual representations of tables. TALENT prompts a small VLM to produce\nboth OCR text and natural language narration, then combines them with the\nquestion for reasoning by an LLM. This reframes Table VQA as an LLM-centric\nmultimodal reasoning task, where the VLM serves as a perception-narration\nmodule rather than a monolithic solver. Additionally, we construct ReTabVQA, a\nmore challenging Table VQA dataset requiring multi-step quantitative reasoning\nover table images. Experiments show that TALENT enables a small VLM-LLM\ncombination to match or surpass a single large VLM at significantly lower\ncomputational cost on both public datasets and ReTabVQA.",
    "published": "2025-10-08T14:56:42Z",
    "updated": "2025-10-08T14:56:42Z",
    "link": "http://arxiv.org/pdf/2510.07098v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Guo Yutong",
      "Wanying Wang",
      "Yue Wu",
      "Zichen Miao",
      "Haoyu Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07096v1",
    "title": "Making Machines Sound Sarcastic: LLM-Enhanced and Retrieval-Guided\n  Sarcastic Speech Synthesis",
    "summary": "Sarcasm is a subtle form of non-literal language that poses significant\nchallenges for speech synthesis due to its reliance on nuanced semantic,\ncontextual, and prosodic cues. While existing speech synthesis research has\nfocused primarily on broad emotional categories, sarcasm remains largely\nunexplored. In this paper, we propose a Large Language Model (LLM)-enhanced\nRetrieval-Augmented framework for sarcasm-aware speech synthesis. Our approach\ncombines (1) semantic embeddings from a LoRA-fine-tuned LLaMA 3, which capture\npragmatic incongruity and discourse-level cues of sarcasm, and (2) prosodic\nexemplars retrieved via a Retrieval Augmented Generation (RAG) module, which\nprovide expressive reference patterns of sarcastic delivery. Integrated within\na VITS backbone, this dual conditioning enables more natural and contextually\nappropriate sarcastic speech. Experiments demonstrate that our method\noutperforms baselines in both objective measures and subjective evaluations,\nyielding improvements in speech naturalness, sarcastic expressivity, and\ndownstream sarcasm detection.",
    "published": "2025-10-08T14:53:48Z",
    "updated": "2025-10-08T14:53:48Z",
    "link": "http://arxiv.org/pdf/2510.07096v1.pdf",
    "category": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "authors": [
      "Zhu Li",
      "Yuqing Zhang",
      "Xiyuan Gao",
      "Shekhar Nayak",
      "Matt Coler"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07083v1",
    "title": "All Claims Are Equal, but Some Claims Are More Equal Than Others:\n  Importance-Sensitive Factuality Evaluation of LLM Generations",
    "summary": "Existing methods for evaluating the factuality of large language model (LLM)\nresponses treat all claims as equally important. This results in misleading\nevaluations when vital information is missing or incorrect as it receives the\nsame weight as peripheral details, raising the question: how can we reliably\ndetect such differences when there are errors in key information? Current\napproaches that measure factuality tend to be insensitive to omitted or false\nkey information. To investigate this lack of sensitivity, we construct\nVITALERRORS, a benchmark of 6,733 queries with minimally altered LLM responses\ndesigned to omit or falsify key information. Using this dataset, we demonstrate\nthe insensitivities of existing evaluation metrics to key information errors.\nTo address this gap, we introduce VITAL, a set of metrics that provide greater\nsensitivity in measuring the factuality of responses by incorporating the\nrelevance and importance of claims with respect to the query. Our analysis\ndemonstrates that VITAL metrics more reliably detect errors in key information\nthan previous methods. Our dataset, metrics, and analysis provide a foundation\nfor more accurate and robust assessment of LLM factuality.",
    "published": "2025-10-08T14:40:33Z",
    "updated": "2025-10-08T14:40:33Z",
    "link": "http://arxiv.org/pdf/2510.07083v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Miriam Wanner",
      "Leif Azzopardi",
      "Paul Thomas",
      "Soham Dan",
      "Benjamin Van Durme",
      "Nick Craswell"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07081v1",
    "title": "Accelerating Diffusion LLM Inference via Local Determinism Propagation",
    "summary": "Diffusion large language models (dLLMs) represent a significant advancement\nin text generation, offering parallel token decoding capabilities. However,\nexisting open-source implementations suffer from quality-speed trade-offs that\nimpede their practical deployment. Conservative sampling strategies typically\ndecode only the most confident token per step to ensure quality (i.e., greedy\ndecoding), at the cost of inference efficiency due to repeated redundant\nrefinement iterations--a phenomenon we term delayed decoding. Through\nsystematic analysis of dLLM decoding dynamics, we characterize this delayed\ndecoding behavior and propose a training-free adaptive parallel decoding\nstrategy, named LocalLeap, to address these inefficiencies. LocalLeap is built\non two fundamental empirical principles: local determinism propagation centered\non high-confidence anchors and progressive spatial consistency decay. By\napplying these principles, LocalLeap identifies anchors and performs localized\nrelaxed parallel decoding within bounded neighborhoods, achieving substantial\ninference step reduction through early commitment of already-determined tokens\nwithout compromising output quality. Comprehensive evaluation on various\nbenchmarks demonstrates that LocalLeap achieves 6.94$\\times$ throughput\nimprovements and reduces decoding steps to just 14.2\\% of the original\nrequirement, achieving these gains with negligible performance impact. The\nsource codes are available at: https://github.com/friedrichor/LocalLeap.",
    "published": "2025-10-08T14:39:34Z",
    "updated": "2025-10-08T14:39:34Z",
    "link": "http://arxiv.org/pdf/2510.07081v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Fanheng Kong",
      "Jingyuan Zhang",
      "Yahui Liu",
      "Zirui Wu",
      "Yu Tian",
      "Victoria W.",
      "Guorui Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.22296v2",
    "title": "360-LLaMA-Factory: Plug & Play Sequence Parallelism for Long\n  Post-Training",
    "summary": "Adding sequence parallelism into LLaMA-Factory, we open-sourced\n360-LLaMA-Factory at https://github.com/Qihoo360/360-LLaMA-Factory.\n360-LLaMA-Factory has received wide recognition and used in models such as\nLight-R1 arXiv:2503.10460, TinyR1 arXiv:2503.04872, Kaggle AIMO math models and\nalso in large companies' training frameworks. This technical report delves\ndeeper into the different sequence parallel modes behind 360-LLaMA-Factory and\ndiscusses our implementation insights.",
    "published": "2025-05-28T12:33:46Z",
    "updated": "2025-10-08T14:32:07Z",
    "link": "http://arxiv.org/pdf/2505.22296v2.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Haosheng Zou",
      "Xiaowei Lv",
      "Shousheng Jia",
      "Lin Li",
      "Xiaochun Gong",
      "Xiangzheng Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07061v1",
    "title": "Revisiting Metric Reliability for Fine-grained Evaluation of Machine\n  Translation and Summarization in Indian Languages",
    "summary": "While automatic metrics drive progress in Machine Translation (MT) and Text\nSummarization (TS), existing metrics have been developed and validated almost\nexclusively for English and other high-resource languages. This narrow focus\nleaves Indian languages, spoken by over 1.5 billion people, largely overlooked,\ncasting doubt on the universality of current evaluation practices. To address\nthis gap, we introduce ITEM, a large-scale benchmark that systematically\nevaluates the alignment of 26 automatic metrics with human judgments across six\nmajor Indian languages, enriched with fine-grained annotations. Our extensive\nevaluation, covering agreement with human judgments, sensitivity to outliers,\nlanguage-specific reliability, inter-metric correlations, and resilience to\ncontrolled perturbations, reveals four central findings: (1) LLM-based\nevaluators show the strongest alignment with human judgments at both segment\nand system levels; (2) outliers exert a significant impact on metric-human\nagreement; (3) in TS, metrics are more effective at capturing content fidelity,\nwhereas in MT, they better reflect fluency; and (4) metrics differ in their\nrobustness and sensitivity when subjected to diverse perturbations.\nCollectively, these findings offer critical guidance for advancing metric\ndesign and evaluation in Indian languages.",
    "published": "2025-10-08T14:27:02Z",
    "updated": "2025-10-08T14:27:02Z",
    "link": "http://arxiv.org/pdf/2510.07061v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Amir Hossein Yari",
      "Kalmit Kulkarni",
      "Ahmad Raza Khan",
      "Fajri Koto"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07060v1",
    "title": "Does Local News Stay Local?: Online Content Shifts in Sinclair-Acquired\n  Stations",
    "summary": "Local news stations are often considered to be reliable sources of\nnon-politicized information, particularly local concerns that residents care\nabout. Because these stations are trusted news sources, viewers are\nparticularly susceptible to the information they report. The Sinclair Broadcast\ngroup is a broadcasting company that has acquired many local news stations in\nthe last decade. We investigate the effects of local news stations being\nacquired by Sinclair: how does coverage change? We use computational methods to\ninvestigate changes in internet content put out by local news stations before\nand after being acquired by Sinclair and in comparison to national news\noutlets. We find that there is clear evidence that local news stations report\nmore frequently on national news at the expense of local topics, and that their\ncoverage of polarizing national topics increases.",
    "published": "2025-10-08T14:27:00Z",
    "updated": "2025-10-08T14:27:00Z",
    "link": "http://arxiv.org/pdf/2510.07060v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Miriam Wanner",
      "Sophia Hager",
      "Anjalie Field"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.04023v2",
    "title": "Do LLMs Overthink Basic Math Reasoning? Benchmarking the\n  Accuracy-Efficiency Tradeoff in Language Models",
    "summary": "Large language models (LLMs) achieve impressive performance on complex\nmathematical benchmarks yet sometimes fail on basic math reasoning while\ngenerating unnecessarily verbose responses. In this paper, we present a\nsystematic benchmark and comprehensive empirical study to evaluate the\nefficiency of reasoning in LLMs, focusing on the fundamental tradeoff between\naccuracy and overthinking. First, we formalize the accuracy-verbosity tradeoff.\nSecond, we introduce the Overthinking Score, a harmonic-mean metric combining\naccuracy and token-efficiency for holistic model evaluation. Third, we\nestablish an evaluation protocol with dynamically-generated data across 14\nbasic math tasks. Fourth, we conduct a large-scale empirical study evaluating\n53 LLMs, including reasoning and quantized variants across different reasoning\nbudgets. Our findings reveal: 1) model performance on complex benchmarks does\nnot translate directly to basic math reasoning; 2) reasoning models generate\n~18 more tokens while sometimes achieving lower accuracy and exhibit\ncatastrophic collapse when token is constrained, dropping by ~28; 3) the\naccuracy-verbosity relationship is non-monotonic with extended reasoning\nbudgets yielding diminishing returns (GPT-5/o-series models show zero accuracy\ngain from low -> medium -> high reasoning effort). Our findings challenge the\nassumption that longer reasoning in LLMs necessarily improves mathematical\nreasoning.",
    "published": "2025-07-05T12:31:17Z",
    "updated": "2025-10-08T14:20:50Z",
    "link": "http://arxiv.org/pdf/2507.04023v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Gaurav Srivastava",
      "Aafiya Hussain",
      "Sriram Srinivasan",
      "Xuan Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07037v1",
    "title": "Beyond Monolingual Assumptions: A Survey of Code-Switched NLP in the Era\n  of Large Language Models",
    "summary": "Code-switching (CSW), the alternation of languages and scripts within a\nsingle utterance, remains a fundamental challenge for multiling ual NLP, even\namidst the rapid advances of large language models (LLMs). Most LLMs still\nstruggle with mixed-language inputs, limited CSW datasets, and evaluation\nbiases, hindering deployment in multilingual societies. This survey provides\nthe first comprehensive analysis of CSW-aware LLM research, reviewing\n\\total{unique_references} studies spanning five research areas, 12 NLP tasks,\n30+ datasets, and 80+ languages. We classify recent advances by architecture,\ntraining strategy, and evaluation methodology, outlining how LLMs have reshaped\nCSW modeling and what challenges persist. The paper concludes with a roadmap\nemphasizing the need for inclusive datasets, fair evaluation, and\nlinguistically grounded models to achieve truly multilingual intelligence. A\ncurated collection of all resources is maintained at\nhttps://github.com/lingo-iitgn/awesome-code-mixing/.",
    "published": "2025-10-08T14:04:14Z",
    "updated": "2025-10-08T14:04:14Z",
    "link": "http://arxiv.org/pdf/2510.07037v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Rajvee Sheth",
      "Samridhi Raj Sinha",
      "Mahavir Patil",
      "Himanshu Beniwal",
      "Mayank Singh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.20612v3",
    "title": "Roboflow100-VL: A Multi-Domain Object Detection Benchmark for\n  Vision-Language Models",
    "summary": "Vision-language models (VLMs) trained on internet-scale data achieve\nremarkable zero-shot detection performance on common objects like car, truck,\nand pedestrian. However, state-of-the-art models still struggle to generalize\nto out-of-distribution classes, tasks and imaging modalities not typically\nfound in their pre-training. Rather than simply re-training VLMs on more visual\ndata, we argue that one should align VLMs to new concepts with annotation\ninstructions containing a few visual examples and rich textual descriptions. To\nthis end, we introduce Roboflow100-VL, a large-scale collection of 100\nmulti-modal object detection datasets with diverse concepts not commonly found\nin VLM pre-training. We evaluate state-of-the-art models on our benchmark in\nzero-shot, few-shot, semi-supervised, and fully-supervised settings, allowing\nfor comparison across data regimes. Notably, we find that VLMs like\nGroundingDINO and Qwen2.5-VL achieve less than 2% zero-shot accuracy on\nchallenging medical imaging datasets within Roboflow100-VL, demonstrating the\nneed for few-shot concept alignment. Lastly, we discuss our recent CVPR 2025\nFoundational FSOD competition and share insights from the community. Notably,\nthe winning team significantly outperforms our baseline by 17 mAP! Our code and\ndataset are available at https://github.com/roboflow/rf100-vl and\nhttps://universe.roboflow.com/rf100-vl/.",
    "published": "2025-05-27T01:24:29Z",
    "updated": "2025-10-08T13:51:05Z",
    "link": "http://arxiv.org/pdf/2505.20612v3.pdf",
    "category": [
      "cs.CV",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Peter Robicheaux",
      "Matvei Popov",
      "Anish Madan",
      "Isaac Robinson",
      "Joseph Nelson",
      "Deva Ramanan",
      "Neehar Peri"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.14161v2",
    "title": "MIST: Towards Multi-dimensional Implicit BiaS Evaluation of LLMs via\n  Theory of Mind",
    "summary": "Theory of Mind (ToM) in Large Language Models (LLMs) refers to their capacity\nfor reasoning about mental states, yet failures in this capacity often manifest\nas systematic implicit bias. Evaluating this bias is challenging, as\nconventional direct-query methods are susceptible to social desirability\neffects and fail to capture its subtle, multi-dimensional nature. To this end,\nwe propose an evaluation framework that leverages the Stereotype Content Model\n(SCM) to reconceptualize bias as a multi-dimensional failure in ToM across\nCompetence, Sociability, and Morality. The framework introduces two indirect\ntasks: the Word Association Bias Test (WABT) to assess implicit lexical\nassociations and the Affective Attribution Test (AAT) to measure covert\naffective leanings, both designed to probe latent stereotypes without\ntriggering model avoidance. Extensive experiments on 8 State-of-the-Art LLMs\ndemonstrate our framework's capacity to reveal complex bias structures,\nincluding pervasive sociability bias, multi-dimensional divergence, and\nasymmetric stereotype amplification, thereby providing a more robust\nmethodology for identifying the structural nature of implicit bias.",
    "published": "2025-06-17T03:50:57Z",
    "updated": "2025-10-08T13:24:05Z",
    "link": "http://arxiv.org/pdf/2506.14161v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yanlin Li",
      "Hao Liu",
      "Huimin Liu",
      "Kun Wang",
      "Yinwei Wei",
      "Yupeng Hu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06999v1",
    "title": "Towards Reliable Retrieval in RAG Systems for Large Legal Datasets",
    "summary": "Retrieval-Augmented Generation (RAG) is a promising approach to mitigate\nhallucinations in Large Language Models (LLMs) for legal applications, but its\nreliability is critically dependent on the accuracy of the retrieval step. This\nis particularly challenging in the legal domain, where large databases of\nstructurally similar documents often cause retrieval systems to fail. In this\npaper, we address this challenge by first identifying and quantifying a\ncritical failure mode we term Document-Level Retrieval Mismatch (DRM), where\nthe retriever selects information from entirely incorrect source documents. To\nmitigate DRM, we investigate a simple and computationally efficient technique\nwhich we refer to as Summary-Augmented Chunking (SAC). This method enhances\neach text chunk with a document-level synthetic summary, thereby injecting\ncrucial global context that would otherwise be lost during a standard chunking\nprocess. Our experiments on a diverse set of legal information retrieval tasks\nshow that SAC greatly reduces DRM and, consequently, also improves text-level\nretrieval precision and recall. Interestingly, we find that a generic\nsummarization strategy outperforms an approach that incorporates legal expert\ndomain knowledge to target specific legal elements. Our work provides evidence\nthat this practical, scalable, and easily integrable technique enhances the\nreliability of RAG systems when applied to large-scale legal document datasets.",
    "published": "2025-10-08T13:22:20Z",
    "updated": "2025-10-08T13:22:20Z",
    "link": "http://arxiv.org/pdf/2510.06999v1.pdf",
    "category": [
      "cs.CL",
      "cs.IR",
      "I.2.7; H.3.3; K.5.0"
    ],
    "authors": [
      "Markus Reuter",
      "Tobias Lingenberg",
      "Rūta Liepiņa",
      "Francesca Lagioia",
      "Marco Lippi",
      "Giovanni Sartor",
      "Andrea Passerini",
      "Burcu Sayin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.14146v4",
    "title": "MMReview: A Multidisciplinary and Multimodal Benchmark for LLM-Based\n  Peer Review Automation",
    "summary": "With the rapid growth of academic publications, peer review has become an\nessential yet time-consuming responsibility within the research community.\nLarge Language Models (LLMs) have increasingly been adopted to assist in the\ngeneration of review comments; however, current LLM-based review tasks lack a\nunified evaluation benchmark to rigorously assess the models' ability to\nproduce comprehensive, accurate, and human-aligned assessments, particularly in\nscenarios involving multimodal content such as figures and tables. To address\nthis gap, we propose \\textbf{MMReview}, a comprehensive benchmark that spans\nmultiple disciplines and modalities. MMReview includes multimodal content and\nexpert-written review comments for 240 papers across 17 research domains within\nfour major academic disciplines: Artificial Intelligence, Natural Sciences,\nEngineering Sciences, and Social Sciences. We design a total of 13 tasks\ngrouped into four core categories, aimed at evaluating the performance of LLMs\nand Multimodal LLMs (MLLMs) in step-wise review generation, outcome\nformulation, alignment with human preferences, and robustness to adversarial\ninput manipulation. Extensive experiments conducted on 16 open-source models\nand 5 advanced closed-source models demonstrate the thoroughness of the\nbenchmark. We envision MMReview as a critical step toward establishing a\nstandardized foundation for the development of automated peer review systems.",
    "published": "2025-08-19T16:37:19Z",
    "updated": "2025-10-08T13:20:32Z",
    "link": "http://arxiv.org/pdf/2508.14146v4.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Xian Gao",
      "Jiacheng Ruan",
      "Zongyun Zhang",
      "Jingsheng Gao",
      "Ting Liu",
      "Yuzhuo Fu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06994v1",
    "title": "RedTWIZ: Diverse LLM Red Teaming via Adaptive Attack Planning",
    "summary": "This paper presents the vision, scientific contributions, and technical\ndetails of RedTWIZ: an adaptive and diverse multi-turn red teaming framework,\nto audit the robustness of Large Language Models (LLMs) in AI-assisted software\ndevelopment. Our work is driven by three major research streams: (1) robust and\nsystematic assessment of LLM conversational jailbreaks; (2) a diverse\ngenerative multi-turn attack suite, supporting compositional, realistic and\ngoal-oriented jailbreak conversational strategies; and (3) a hierarchical\nattack planner, which adaptively plans, serializes, and triggers attacks\ntailored to specific LLM's vulnerabilities. Together, these contributions form\na unified framework -- combining assessment, attack generation, and strategic\nplanning -- to comprehensively evaluate and expose weaknesses in LLMs'\nrobustness. Extensive evaluation is conducted to systematically assess and\nanalyze the performance of the overall system and each component. Experimental\nresults demonstrate that our multi-turn adversarial attack strategies can\nsuccessfully lead state-of-the-art LLMs to produce unsafe generations,\nhighlighting the pressing need for more research into enhancing LLM's\nrobustness.",
    "published": "2025-10-08T13:18:42Z",
    "updated": "2025-10-08T13:18:42Z",
    "link": "http://arxiv.org/pdf/2510.06994v1.pdf",
    "category": [
      "cs.CR",
      "cs.CL"
    ],
    "authors": [
      "Artur Horal",
      "Daniel Pina",
      "Henrique Paz",
      "Iago Paulo",
      "João Soares",
      "Rafael Ferreira",
      "Diogo Tavares",
      "Diogo Glória-Silva",
      "João Magalhães",
      "David Semedo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.11364v3",
    "title": "Blessing of Multilinguality: A Systematic Analysis of Multilingual\n  In-Context Learning",
    "summary": "While multilingual large language models generally perform adequately, and\nsometimes even rival English performance on high-resource languages (HRLs),\nthey often significantly underperform on low-resource languages (LRLs). Among\nseveral prompting strategies aiming at bridging the gap, multilingual\nin-context learning (ICL) has been particularly effective when demonstration in\ntarget languages is unavailable. However, there lacks a systematic\nunderstanding of when and why it works well.\n  In this work, we systematically analyze multilingual ICL, using\ndemonstrations in HRLs to enhance cross-lingual transfer. We show that\ndemonstrations in mixed HRLs consistently outperform English-only ones across\nthe board, particularly for tasks written in LRLs. Surprisingly, our ablation\nstudy shows that the presence of irrelevant non-English sentences in the prompt\nyields measurable gains, suggesting the effectiveness of multilingual exposure\nitself. Our results highlight the potential of strategically leveraging\nmultilingual resources to bridge the performance gap for underrepresented\nlanguages.",
    "published": "2025-02-17T02:27:35Z",
    "updated": "2025-10-08T13:09:14Z",
    "link": "http://arxiv.org/pdf/2502.11364v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yilei Tu",
      "Andrew Xue",
      "Freda Shi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06974v1",
    "title": "Probing Social Identity Bias in Chinese LLMs with Gendered Pronouns and\n  Social Groups",
    "summary": "Large language models (LLMs) are increasingly deployed in user-facing\napplications, raising concerns about their potential to reflect and amplify\nsocial biases. We investigate social identity framing in Chinese LLMs using\nMandarin-specific prompts across ten representative Chinese LLMs, evaluating\nresponses to ingroup (\"We\") and outgroup (\"They\") framings, and extending the\nsetting to 240 social groups salient in the Chinese context. To complement\ncontrolled experiments, we further analyze Chinese-language conversations from\na corpus of real interactions between users and chatbots. Across models, we\nobserve systematic ingroup-positive and outgroup-negative tendencies, which are\nnot confined to synthetic prompts but also appear in naturalistic dialogue,\nindicating that bias dynamics might strengthen in real interactions. Our study\nprovides a language-aware evaluation framework for Chinese LLMs, demonstrating\nthat social identity biases documented in English generalize\ncross-linguistically and intensify in user-facing contexts.",
    "published": "2025-10-08T13:00:12Z",
    "updated": "2025-10-08T13:00:12Z",
    "link": "http://arxiv.org/pdf/2510.06974v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Geng Liu",
      "Feng Li",
      "Junjie Mu",
      "Mengxiao Zhu",
      "Francesco Pierri"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.22848v5",
    "title": "LiTEx: A Linguistic Taxonomy of Explanations for Understanding\n  Within-Label Variation in Natural Language Inference",
    "summary": "There is increasing evidence of Human Label Variation (HLV) in Natural\nLanguage Inference (NLI), where annotators assign different labels to the same\npremise-hypothesis pair. However, within-label variation--cases where\nannotators agree on the same label but provide divergent reasoning--poses an\nadditional and mostly overlooked challenge. Several NLI datasets contain\nhighlighted words in the NLI item as explanations, but the same spans on the\nNLI item can be highlighted for different reasons, as evidenced by free-text\nexplanations, which offer a window into annotators' reasoning. To\nsystematically understand this problem and gain insight into the rationales\nbehind NLI labels, we introduce LITEX, a linguistically-informed taxonomy for\ncategorizing free-text explanations in English. Using this taxonomy, we\nannotate a subset of the e-SNLI dataset, validate the taxonomy's reliability,\nand analyze how it aligns with NLI labels, highlights, and explanations. We\nfurther assess the taxonomy's usefulness in explanation generation,\ndemonstrating that conditioning generation on LITEX yields explanations that\nare linguistically closer to human explanations than those generated using only\nlabels or highlights. Our approach thus not only captures within-label\nvariation but also shows how taxonomy-guided generation for reasoning can\nbridge the gap between human and model explanations more effectively than\nexisting strategies.",
    "published": "2025-05-28T20:32:48Z",
    "updated": "2025-10-08T12:35:11Z",
    "link": "http://arxiv.org/pdf/2505.22848v5.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Pingjun Hong",
      "Beiduo Chen",
      "Siyao Peng",
      "Marie-Catherine de Marneffe",
      "Barbara Plank"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.04601v2",
    "title": "FedSRD: Sparsify-Reconstruct-Decompose for Communication-Efficient\n  Federated Large Language Models Fine-Tuning",
    "summary": "The current paradigm of training large language models (LLMs) on publicly\navailable Web data is becoming unsustainable, with high-quality data sources in\nspecialized domains nearing exhaustion. Federated Learning (FL) emerges as a\npractical solution for the next generation of AI on a decentralized Web,\nenabling privacy-preserving collaborative fine-tuning by leveraging private\ndata distributed across a global client base. While Low-Rank Adaptation (LoRA)\nis the standard for efficient fine-tuning, its application in federated\nsettings presents a critical challenge: communication overhead remains a\nsignificant bottleneck across the Web's heterogeneous network conditions. The\nstructural redundancy within LoRA parameters not only incurs a heavy\ncommunication burden but also introduces conflicts when aggregating client\nupdates. To address this, we propose FedSRD, a Sparsify-Reconstruct-Decompose\nframework designed for communication-efficient federated LLMs fine-tuning. We\nfirst introduce an importance-aware sparsification method that preserves the\nstructural integrity of LoRA updates to reduce the uploaded parameter count.\nThe server then reconstructs and aggregates these updates in a full-rank space\nto mitigate conflicts. Finally, it decomposes the global update into a sparse\nlow-rank format for broadcast, ensuring a symmetrically efficient cycle. We\nalso propose an efficient variant, FedSRD-e, to reduce computational overhead.\nExperimental results on 10 benchmarks demonstrate that our framework\nsignificantly reduces communication costs by up to 90\\% while even improving\nmodel performance on heterogeneous client data.",
    "published": "2025-10-06T09:06:38Z",
    "updated": "2025-10-08T12:26:35Z",
    "link": "http://arxiv.org/pdf/2510.04601v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Guochen Yan",
      "Luyuan Xie",
      "Qingni Shen",
      "Yuejian Fang",
      "Zhonghai Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06917v1",
    "title": "SHANKS: Simultaneous Hearing and Thinking for Spoken Language Models",
    "summary": "Current large language models (LLMs) and spoken language models (SLMs) begin\nthinking and taking actions only after the user has finished their turn. This\nprevents the model from interacting during the user's turn and can lead to high\nresponse latency while it waits to think. Consequently, thinking after\nreceiving the full input is not suitable for speech-to-speech interaction,\nwhere real-time, low-latency exchange is important. We address this by noting\nthat humans naturally \"think while listening.\" In this paper, we propose\nSHANKS, a general inference framework that enables SLMs to generate unspoken\nchain-of-thought reasoning while listening to the user input. SHANKS streams\nthe input speech in fixed-duration chunks and, as soon as a chunk is received,\ngenerates unspoken reasoning based on all previous speech and reasoning, while\nthe user continues speaking. SHANKS uses this unspoken reasoning to decide\nwhether to interrupt the user and to make tool calls to complete the task. We\ndemonstrate that SHANKS enhances real-time user-SLM interaction in two\nscenarios: (1) when the user is presenting a step-by-step solution to a math\nproblem, SHANKS can listen, reason, and interrupt when the user makes a\nmistake, achieving 37.1% higher interruption accuracy than a baseline that\ninterrupts without thinking; and (2) in a tool-augmented dialogue, SHANKS can\ncomplete 56.9% of the tool calls before the user finishes their turn. Overall,\nSHANKS moves toward models that keep thinking throughout the conversation, not\nonly after a turn ends. Animated illustrations of Shanks can be found at\nhttps://d223302.github.io/SHANKS/",
    "published": "2025-10-08T11:48:59Z",
    "updated": "2025-10-08T11:48:59Z",
    "link": "http://arxiv.org/pdf/2510.06917v1.pdf",
    "category": [
      "cs.CL",
      "eess.AS"
    ],
    "authors": [
      "Cheng-Han Chiang",
      "Xiaofei Wang",
      "Linjie Li",
      "Chung-Ching Lin",
      "Kevin Lin",
      "Shujie Liu",
      "Zhendong Wang",
      "Zhengyuan Yang",
      "Hung-yi Lee",
      "Lijuan Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.14376v2",
    "title": "AutoRev: Multi-Modal Graph Retrieval for Automated Peer-Review\n  Generation",
    "summary": "Enhancing the quality and efficiency of academic publishing is critical for\nboth authors and reviewers, as research papers are central to scholarly\ncommunication and a major source of high-quality content on the web. To support\nthis goal, we propose AutoRev, an automatic peer-review system designed to\nprovide actionable, high-quality feedback to both reviewers and authors.\nAutoRev leverages a novel Multi-Modal Retrieval-Augmented Generation (RAG)\nframework that combines textual and graphical representations of academic\npapers. By modelling documents as graphs, AutoRev effectively retrieves the\nmost pertinent information, significantly reducing the input context length for\nLLMs and thereby enhancing their review generation capabilities. Experimental\nresults show that AutoRev outperforms state-of-the-art baselines by up to\n58.72% and demonstrates competitive performance in human evaluations against\nground truth reviews. We envision AutoRev as a powerful tool to streamline the\npeer-review workflow, alleviating challenges and enabling scalable,\nhigh-quality scholarly publishing. By guiding both authors and reviewers,\nAutoRev has the potential to accelerate the dissemination of quality research\non the web at a larger scale. Code will be released upon acceptance.",
    "published": "2025-05-20T13:59:58Z",
    "updated": "2025-10-08T11:20:40Z",
    "link": "http://arxiv.org/pdf/2505.14376v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Maitreya Prafulla Chitale",
      "Ketaki Mangesh Shetye",
      "Harshit Gupta",
      "Manav Chaudhary",
      "Manish Shrivastava",
      "Vasudeva Varma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06889v1",
    "title": "MeXtract: Light-Weight Metadata Extraction from Scientific Papers",
    "summary": "Metadata plays a critical role in indexing, documenting, and analyzing\nscientific literature, yet extracting it accurately and efficiently remains a\nchallenging task. Traditional approaches often rely on rule-based or\ntask-specific models, which struggle to generalize across domains and schema\nvariations. In this paper, we present MeXtract, a family of lightweight\nlanguage models designed for metadata extraction from scientific papers. The\nmodels, ranging from 0.5B to 3B parameters, are built by fine-tuning Qwen 2.5\ncounterparts. In their size family, MeXtract achieves state-of-the-art\nperformance on metadata extraction on the MOLE benchmark. To further support\nevaluation, we extend the MOLE benchmark to incorporate model-specific\nmetadata, providing an out-of-domain challenging subset. Our experiments show\nthat fine-tuning on a given schema not only yields high accuracy but also\ntransfers effectively to unseen schemas, demonstrating the robustness and\nadaptability of our approach. We release all the code, datasets, and models\nopenly for the research community.",
    "published": "2025-10-08T11:12:28Z",
    "updated": "2025-10-08T11:12:28Z",
    "link": "http://arxiv.org/pdf/2510.06889v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Zaid Alyafeai",
      "Maged S. Al-Shaibani",
      "Bernard Ghanem"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06870v1",
    "title": "$λ$-GRPO: Unifying the GRPO Frameworks with Learnable Token\n  Preferences",
    "summary": "Reinforcement Learning with Human Feedback (RLHF) has been the dominant\napproach for improving the reasoning capabilities of Large Language Models\n(LLMs). Recently, Reinforcement Learning with Verifiable Rewards (RLVR) has\nsimplified this paradigm by replacing the reward and value models with\nrule-based verifiers. A prominent example is Group Relative Policy Optimization\n(GRPO). However, GRPO inherently suffers from a length bias, since the same\nadvantage is uniformly assigned to all tokens of a response. As a result,\nlonger responses distribute the reward over more tokens and thus contribute\ndisproportionately to gradient updates. Several variants, such as DAPO and Dr.\nGRPO, modify the token-level aggregation of the loss, yet these methods remain\nheuristic and offer limited interpretability regarding their implicit token\npreferences. In this work, we explore the possibility of allowing the model to\nlearn its own token preference during optimization. We unify existing\nframeworks under a single formulation and introduce a learnable parameter\n$\\lambda$ that adaptively controls token-level weighting. We use $\\lambda$-GRPO\nto denote our method, and we find that $\\lambda$-GRPO achieves consistent\nimprovements over vanilla GRPO and DAPO on multiple mathematical reasoning\nbenchmarks. On Qwen2.5 models with 1.5B, 3B, and 7B parameters, $\\lambda$-GRPO\nimproves average accuracy by $+1.9\\%$, $+1.0\\%$, and $+1.7\\%$ compared to GRPO,\nrespectively. Importantly, these gains come without any modifications to the\ntraining data or additional computational cost, highlighting the effectiveness\nand practicality of learning token preferences.",
    "published": "2025-10-08T10:39:07Z",
    "updated": "2025-10-08T10:39:07Z",
    "link": "http://arxiv.org/pdf/2510.06870v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yining Wang",
      "Jinman Zhao",
      "Chuangxin Zhao",
      "Shuhao Guan",
      "Gerald Penn",
      "Shinan Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06866v1",
    "title": "Unlocking Latent Discourse Translation in LLMs Through Quality-Aware\n  Decoding",
    "summary": "Large language models (LLMs) have emerged as strong contenders in machine\ntranslation.Yet, they still struggle to adequately handle discourse phenomena,\nsuch as pronoun resolution and lexical cohesion at the document level. In this\nstudy, we thoroughly investigate the discourse phenomena performance of LLMs in\ncontext-aware translation. We demonstrate that discourse knowledge is encoded\nwithin LLMs and propose the use of quality-aware decoding (QAD) to effectively\nextract this knowledge, showcasing its superiority over other decoding\napproaches through comprehensive analysis. Furthermore, we illustrate that QAD\nenhances the semantic richness of translations and aligns them more closely\nwith human preferences.",
    "published": "2025-10-08T10:37:17Z",
    "updated": "2025-10-08T10:37:17Z",
    "link": "http://arxiv.org/pdf/2510.06866v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Wafaa Mohammed",
      "Vlad Niculae",
      "Chrysoula Zerva"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.19649v5",
    "title": "Taxonomy, Opportunities, and Challenges of Representation Engineering\n  for Large Language Models",
    "summary": "Representation Engineering (RepE) is a novel paradigm for controlling the\nbehavior of LLMs. Unlike traditional approaches that modify inputs or fine-tune\nthe model, RepE directly manipulates the model's internal representations. As a\nresult, it may offer more effective, interpretable, data-efficient, and\nflexible control over models' behavior. We present the first comprehensive\nsurvey of RepE for LLMs, reviewing the rapidly growing literature to address\nkey questions: What RepE methods exist and how do they differ? For what\nconcepts and problems has RepE been applied? What are the strengths and\nweaknesses of RepE compared to other methods? To answer these, we propose a\nunified framework describing RepE as a pipeline comprising representation\nidentification, operationalization, and control. We posit that while RepE\nmethods offer significant potential, challenges remain, including managing\nmultiple concepts, ensuring reliability, and preserving models' performance.\nTowards improving RepE, we identify opportunities for experimental and\nmethodological improvements and construct a guide for best practices.",
    "published": "2025-02-27T00:40:01Z",
    "updated": "2025-10-08T10:19:34Z",
    "link": "http://arxiv.org/pdf/2502.19649v5.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Jan Wehner",
      "Sahar Abdelnabi",
      "Daniel Tan",
      "David Krueger",
      "Mario Fritz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06841v1",
    "title": "GAMBIT+: A Challenge Set for Evaluating Gender Bias in Machine\n  Translation Quality Estimation Metrics",
    "summary": "Gender bias in machine translation (MT) systems has been extensively\ndocumented, but bias in automatic quality estimation (QE) metrics remains\ncomparatively underexplored. Existing studies suggest that QE metrics can also\nexhibit gender bias, yet most analyses are limited by small datasets, narrow\noccupational coverage, and restricted language variety. To address this gap, we\nintroduce a large-scale challenge set specifically designed to probe the\nbehavior of QE metrics when evaluating translations containing gender-ambiguous\noccupational terms. Building on the GAMBIT corpus of English texts with\ngender-ambiguous occupations, we extend coverage to three source languages that\nare genderless or natural-gendered, and eleven target languages with\ngrammatical gender, resulting in 33 source-target language pairs. Each source\ntext is paired with two target versions differing only in the grammatical\ngender of the occupational term(s) (masculine vs. feminine), with all dependent\ngrammatical elements adjusted accordingly. An unbiased QE metric should assign\nequal or near-equal scores to both versions. The dataset's scale, breadth, and\nfully parallel design, where the same set of texts is aligned across all\nlanguages, enables fine-grained bias analysis by occupation and systematic\ncomparisons across languages.",
    "published": "2025-10-08T10:09:03Z",
    "updated": "2025-10-08T10:09:03Z",
    "link": "http://arxiv.org/pdf/2510.06841v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Giorgos Filandrianos",
      "Orfeas Menis Mastromichalakis",
      "Wafaa Mohammed",
      "Giuseppe Attanasio",
      "Chrysoula Zerva"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06096v2",
    "title": "The Alignment Auditor: A Bayesian Framework for Verifying and Refining\n  LLM Objectives",
    "summary": "The objectives that Large Language Models (LLMs) implicitly optimize remain\ndangerously opaque, making trustworthy alignment and auditing a grand\nchallenge. While Inverse Reinforcement Learning (IRL) can infer reward\nfunctions from behaviour, existing approaches either produce a single,\noverconfident reward estimate or fail to address the fundamental ambiguity of\nthe task (non-identifiability). This paper introduces a principled auditing\nframework that re-frames reward inference from a simple estimation task to a\ncomprehensive process for verification. Our framework leverages Bayesian IRL to\nnot only recover a distribution over objectives but to enable three critical\naudit capabilities: (i) Quantifying and systematically reducing\nnon-identifiability by demonstrating posterior contraction over sequential\nrounds of evidence; (ii) Providing actionable, uncertainty-aware diagnostics\nthat expose spurious shortcuts and identify out-of-distribution prompts where\nthe inferred objective cannot be trusted; and (iii) Validating policy-level\nutility by showing that the refined, low-uncertainty reward can be used\ndirectly in RLHF to achieve training dynamics and toxicity reductions\ncomparable to the ground-truth alignment process. Empirically, our framework\nsuccessfully audits a detoxified LLM, yielding a well-calibrated and\ninterpretable objective that strengthens alignment guarantees. Overall, this\nwork provides a practical toolkit for auditors, safety teams, and regulators to\nverify what LLMs are truly trying to achieve, moving us toward more trustworthy\nand accountable AI.",
    "published": "2025-10-07T16:25:14Z",
    "updated": "2025-10-08T10:07:14Z",
    "link": "http://arxiv.org/pdf/2510.06096v2.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Matthieu Bou",
      "Nyal Patel",
      "Arjun Jagota",
      "Satyapriya Krishna",
      "Sonali Parbhoo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.17686v2",
    "title": "Enhancing Few-shot Keyword Spotting Performance through Pre-Trained\n  Self-supervised Speech Models",
    "summary": "Keyword Spotting plays a critical role in enabling hands-free interaction for\nbattery-powered edge devices. Few-Shot Keyword Spotting (FS-KWS) addresses the\nscalability and adaptability challenges of traditional systems by enabling\nrecognition of custom keywords with only a few examples. However, existing\nFS-KWS systems achieve subpar accuracy at desirable false acceptance rates,\nparticularly in resource-constrained edge environments. To address these\nissues, we propose a training scheme that leverages self-supervised learning\nmodels for robust feature extraction, dimensionality reduction, and knowledge\ndistillation. The teacher model, based on Wav2Vec 2.0 is trained using\nSub-center ArcFace loss, which enhances inter-class separability and\nintra-class compactness. To enable efficient deployment on edge devices, we\nintroduce attention-based dimensionality reduction and train a standard\nlightweight ResNet15 student model. We evaluate the proposed approach on the\nEnglish portion of the Multilingual Spoken Words Corpus (MSWC) and the Google\nSpeech Commands (GSC) datasets. Notably, the proposed training method improves\nthe 10-shot classification accuracy from 33.4% to 74.1% on 11 classes at 1%\nfalse alarm accuracy on the GSC dataset, thus making it significantly\nbetter-suited for a real use case scenario.",
    "published": "2025-06-21T11:39:11Z",
    "updated": "2025-10-08T10:04:53Z",
    "link": "http://arxiv.org/pdf/2506.17686v2.pdf",
    "category": [
      "eess.AS",
      "cs.CL",
      "cs.SD"
    ],
    "authors": [
      "Alican Gok",
      "Oguzhan Buyuksolak",
      "Osman Erman Okman",
      "Murat Saraclar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06838v1",
    "title": "Crossing Domains without Labels: Distant Supervision for Term Extraction",
    "summary": "Automatic Term Extraction (ATE) is a critical component in downstream NLP\ntasks such as document tagging, ontology construction and patent analysis.\nCurrent state-of-the-art methods require expensive human annotation and\nstruggle with domain transfer, limiting their practical deployment. This\nhighlights the need for more robust, scalable solutions and realistic\nevaluation settings. To address this, we introduce a comprehensive benchmark\nspanning seven diverse domains, enabling performance evaluation at both the\ndocument- and corpus-levels. Furthermore, we propose a robust LLM-based model\nthat outperforms both supervised cross-domain encoder models and few-shot\nlearning baselines and performs competitively with its GPT-4o teacher on this\nbenchmark. The first step of our approach is generating psuedo-labels with this\nblack-box LLM on general and scientific domains to ensure generalizability.\nBuilding on this data, we fine-tune the first LLMs for ATE. To further enhance\ndocument-level consistency, oftentimes needed for downstream tasks, we\nintroduce lightweight post-hoc heuristics. Our approach exceeds previous\napproaches on 5/7 domains with an average improvement of 10 percentage points.\nWe release our dataset and fine-tuned models to support future research in this\narea.",
    "published": "2025-10-08T10:02:40Z",
    "updated": "2025-10-08T10:02:40Z",
    "link": "http://arxiv.org/pdf/2510.06838v1.pdf",
    "category": [
      "cs.IR",
      "cs.CL"
    ],
    "authors": [
      "Elena Senger",
      "Yuri Campbell",
      "Rob van der Goot",
      "Barbara Plank"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06826v1",
    "title": "Mid-Training of Large Language Models: A Survey",
    "summary": "Large language models (LLMs) are typically developed through large-scale\npre-training followed by task-specific fine-tuning. Recent advances highlight\nthe importance of an intermediate mid-training stage, where models undergo\nmultiple annealing-style phases that refine data quality, adapt optimization\nschedules, and extend context length. This stage mitigates diminishing returns\nfrom noisy tokens, stabilizes convergence, and expands model capability in late\ntraining. Its effectiveness can be explained through gradient noise scale, the\ninformation bottleneck, and curriculum learning, which together promote\ngeneralization and abstraction. Despite widespread use in state-of-the-art\nsystems, there has been no prior survey of mid-training as a unified paradigm.\nWe introduce the first taxonomy of LLM mid-training spanning data distribution,\nlearning-rate scheduling, and long-context extension. We distill practical\ninsights, compile evaluation benchmarks, and report gains to enable structured\ncomparisons across models. We also identify open challenges and propose avenues\nfor future research and practice.",
    "published": "2025-10-08T09:49:37Z",
    "updated": "2025-10-08T09:49:37Z",
    "link": "http://arxiv.org/pdf/2510.06826v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Kaixiang Mo",
      "Yuxin Shi",
      "Weiwei Weng",
      "Zhiqiang Zhou",
      "Shuman Liu",
      "Haibo Zhang",
      "Anxiang Zeng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06825v1",
    "title": "Adaptive Tool Generation with Models as Tools and Reinforcement Learning",
    "summary": "Tool-augmented language models have demonstrated strong capabilities, but\ntheir reliance on live API access creates scalability and reliability\nchallenges during training and deployment. We propose MTR, a simulation-first\ntraining framework for tool-augmented reasoning. Instead of relying on live\nAPIs, MTR learns from complete ReAct traces with schema-validated, simulated\nobservations. Our approach operates through a multi-agent architecture where a\nToolMaker generates task-specific, OpenAI-compatible tool interfaces, an\nAutoAgent produces structured think-act-observe sequences, and a ToolActor\nsimulates realistic responses. Training proceeds in two stages: Stage-1\nSupervised Fine-Tuning (SFT) teaches 'trace grammar' from complete reasoning\nsequences; Stage-2 Group Relative Policy Optimization (GRPO) optimizes strategy\nwith a composite trace reward that balances answer correctness and internal\nconsistency. Across four multi-hop QA benchmarks (HotpotQA, MuSiQue,\n2WikiMultiHopQA, Bamboogle), MTR attains competitive Exact Match (EM) scores to\nlive-API systems and excels on reasoning-intensive tasks, suggesting that\neffective tool reasoning can be learned from structured traces without live\ninteractions.",
    "published": "2025-10-08T09:48:50Z",
    "updated": "2025-10-08T09:48:50Z",
    "link": "http://arxiv.org/pdf/2510.06825v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Chenpeng Wang",
      "Xiaojie Cheng",
      "Chunye Wang",
      "Linfeng Yang",
      "Lei Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06823v1",
    "title": "Exposing Citation Vulnerabilities in Generative Engines",
    "summary": "We analyze answers generated by generative engines (GEs) from the\nperspectives of citation publishers and the content-injection barrier, defined\nas the difficulty for attackers to manipulate answers to user prompts by\nplacing malicious content on the web. GEs integrate two functions: web search\nand answer generation that cites web pages using large language models. Because\nanyone can publish information on the web, GEs are vulnerable to poisoning\nattacks. Existing studies of citation evaluation focus on how faithfully answer\ncontent reflects cited sources, leaving unexamined which web sources should be\nselected as citations to defend against poisoning attacks. To fill this gap, we\nintroduce evaluation criteria that assess poisoning threats using the citation\ninformation contained in answers. Our criteria classify the publisher\nattributes of citations to estimate the content-injection barrier thereby\nrevealing the threat of poisoning attacks in current GEs. We conduct\nexperiments in political domains in Japan and the United States (U.S.) using\nour criteria and show that citations from official party websites (primary\nsources) are approximately \\(25\\%\\)--\\(45\\%\\) in the U.S. and\n\\(60\\%\\)--\\(65\\%\\) in Japan, indicating that U.S. political answers are at\nhigher risk of poisoning attacks. We also find that sources with low\ncontent-injection barriers are frequently cited yet are poorly reflected in\nanswer content. To mitigate this threat, we discuss how publishers of primary\nsources can increase exposure of their web content in answers and show that\nwell-known techniques are limited by language differences.",
    "published": "2025-10-08T09:47:48Z",
    "updated": "2025-10-08T09:47:48Z",
    "link": "http://arxiv.org/pdf/2510.06823v1.pdf",
    "category": [
      "cs.CR",
      "cs.CL",
      "cs.IR"
    ],
    "authors": [
      "Riku Mochizuki",
      "Shusuke Komatsu",
      "Souta Noguchi",
      "Kazuto Ataka"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06811v1",
    "title": "BlackboxNLP-2025 MIB Shared Task: Exploring Ensemble Strategies for\n  Circuit Localization Methods",
    "summary": "The Circuit Localization track of the Mechanistic Interpretability Benchmark\n(MIB) evaluates methods for localizing circuits within large language models\n(LLMs), i.e., subnetworks responsible for specific task behaviors. In this\nwork, we investigate whether ensembling two or more circuit localization\nmethods can improve performance. We explore two variants: parallel and\nsequential ensembling. In parallel ensembling, we combine attribution scores\nassigned to each edge by different methods-e.g., by averaging or taking the\nminimum or maximum value. In the sequential ensemble, we use edge attribution\nscores obtained via EAP-IG as a warm start for a more expensive but more\nprecise circuit identification method, namely edge pruning. We observe that\nboth approaches yield notable gains on the benchmark metrics, leading to a more\nprecise circuit identification approach. Finally, we find that taking a\nparallel ensemble over various methods, including the sequential ensemble,\nachieves the best results. We evaluate our approach in the BlackboxNLP 2025 MIB\nShared Task, comparing ensemble scores to official baselines across multiple\nmodel-task combinations.",
    "published": "2025-10-08T09:39:40Z",
    "updated": "2025-10-08T09:39:40Z",
    "link": "http://arxiv.org/pdf/2510.06811v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Philipp Mondorf",
      "Mingyang Wang",
      "Sebastian Gerstner",
      "Ahmad Dawar Hakimi",
      "Yihong Liu",
      "Leonor Veloso",
      "Shijia Zhou",
      "Hinrich Schütze",
      "Barbara Plank"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06805v1",
    "title": "Overview of the Plagiarism Detection Task at PAN 2025",
    "summary": "The generative plagiarism detection task at PAN 2025 aims at identifying\nautomatically generated textual plagiarism in scientific articles and aligning\nthem with their respective sources. We created a novel large-scale dataset of\nautomatically generated plagiarism using three large language models: Llama,\nDeepSeek-R1, and Mistral. In this task overview paper, we outline the creation\nof this dataset, summarize and compare the results of all participants and four\nbaselines, and evaluate the results on the last plagiarism detection task from\nPAN 2015 in order to interpret the robustness of the proposed approaches. We\nfound that the current iteration does not invite a large variety of approaches\nas naive semantic similarity approaches based on embedding vectors provide\npromising results of up to 0.8 recall and 0.5 precision. In contrast, most of\nthese approaches underperform significantly on the 2015 dataset, indicating a\nlack in generalizability.",
    "published": "2025-10-08T09:33:26Z",
    "updated": "2025-10-08T09:33:26Z",
    "link": "http://arxiv.org/pdf/2510.06805v1.pdf",
    "category": [
      "cs.CL",
      "cs.IR"
    ],
    "authors": [
      "André Greiner-Petter",
      "Maik Fröbe",
      "Jan Philip Wahle",
      "Terry Ruas",
      "Bela Gipp",
      "Akiko Aizawa",
      "Martin Potthast"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.04764v2",
    "title": "Are BabyLMs Deaf to Gricean Maxims? A Pragmatic Evaluation of\n  Sample-efficient Language Models",
    "summary": "Implicit meanings are integral to human communication, making it essential\nfor language models to be capable of identifying and interpreting them. Grice\n(1975) proposed a set of conversational maxims that guide cooperative dialogue,\nnoting that speakers may deliberately violate these principles to express\nmeanings beyond literal words, and that listeners, in turn, recognize such\nviolations to draw pragmatic inferences.\n  Building on Surian et al. (1996)'s study of children's sensitivity to\nviolations of Gricean maxims, we introduce a novel benchmark to test whether\nlanguage models pretrained on less than 10M and less than 100M tokens can\ndistinguish maxim-adhering from maxim-violating utterances. We compare these\nBabyLMs across five maxims and situate their performance relative to children\nand a Large Language Model (LLM) pretrained on 3T tokens.\n  We find that overall, models trained on less than 100M tokens outperform\nthose trained on less than 10M, yet fall short of child-level and LLM\ncompetence. Our results suggest that modest data increases improve some aspects\nof pragmatic behavior, leading to finer-grained differentiation between\npragmatic dimensions.",
    "published": "2025-10-06T12:38:41Z",
    "updated": "2025-10-08T09:14:11Z",
    "link": "http://arxiv.org/pdf/2510.04764v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Raha Askari",
      "Sina Zarrieß",
      "Özge Alacam",
      "Judith Sieker"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07319v1",
    "title": "Temporal Prompting Matters: Rethinking Referring Video Object\n  Segmentation",
    "summary": "Referring Video Object Segmentation (RVOS) aims to segment the object\nreferred to by the query sentence in the video. Most existing methods require\nend-to-end training with dense mask annotations, which could be\ncomputation-consuming and less scalable. In this work, we rethink the RVOS\nproblem and aim to investigate the key to this task. Based on existing\nfoundation segmentation models, we decompose the RVOS task into referring,\nvideo, and segmentation factors, and propose a Temporal Prompt Generation and\nSelection (Tenet) framework to address the referring and video factors while\nleaving the segmentation problem to foundation models. To efficiently adapt\nimage-based foundation segmentation models to referring video object\nsegmentation, we leverage off-the-shelf object detectors and trackers to\nproduce temporal prompts associated with the referring sentence. While\nhigh-quality temporal prompts could be produced, they can not be easily\nidentified from confidence scores. To tackle this issue, we propose Prompt\nPreference Learning to evaluate the quality of the produced temporal prompts.\nBy taking such prompts to instruct image-based foundation segmentation models,\nwe would be able to produce high-quality masks for the referred object,\nenabling efficient model adaptation to referring video object segmentation.\nExperiments on RVOS benchmarks demonstrate the effectiveness of the Tenet\nframework.",
    "published": "2025-10-08T17:59:57Z",
    "updated": "2025-10-08T17:59:57Z",
    "link": "http://arxiv.org/pdf/2510.07319v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ci-Siang Lin",
      "Min-Hung Chen",
      "I-Jieh Liu",
      "Chien-Yi Wang",
      "Sifei Liu",
      "Yu-Chiang Frank Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07317v1",
    "title": "Quantum-enhanced Computer Vision: Going Beyond Classical Algorithms",
    "summary": "Quantum-enhanced Computer Vision (QeCV) is a new research field at the\nintersection of computer vision, optimisation theory, machine learning and\nquantum computing. It has high potential to transform how visual signals are\nprocessed and interpreted with the help of quantum computing that leverages\nquantum-mechanical effects in computations inaccessible to classical (i.e.\nnon-quantum) computers. In scenarios where existing non-quantum methods cannot\nfind a solution in a reasonable time or compute only approximate solutions,\nquantum computers can provide, among others, advantages in terms of better time\nscalability for multiple problem classes. Parametrised quantum circuits can\nalso become, in the long term, a considerable alternative to classical neural\nnetworks in computer vision. However, specialised and fundamentally new\nalgorithms must be developed to enable compatibility with quantum hardware and\nunveil the potential of quantum computational paradigms in computer vision.\nThis survey contributes to the existing literature on QeCV with a holistic\nreview of this research field. It is designed as a quantum computing reference\nfor the computer vision community, targeting computer vision students,\nscientists and readers with related backgrounds who want to familiarise\nthemselves with QeCV. We provide a comprehensive introduction to QeCV, its\nspecifics, and methodologies for formulations compatible with quantum hardware\nand QeCV methods, leveraging two main quantum computational paradigms, i.e.\ngate-based quantum computing and quantum annealing. We elaborate on the\noperational principles of quantum computers and the available tools to access,\nprogram and simulate them in the context of QeCV. Finally, we review existing\nquantum computing tools and learning materials and discuss aspects related to\npublishing and reviewing QeCV papers, open challenges and potential social\nimplications.",
    "published": "2025-10-08T17:59:51Z",
    "updated": "2025-10-08T17:59:51Z",
    "link": "http://arxiv.org/pdf/2510.07317v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Natacha Kuete Meli",
      "Shuteng Wang",
      "Marcel Seelbach Benkner",
      "Michele Sasdelli",
      "Tat-Jun Chin",
      "Tolga Birdal",
      "Michael Moeller",
      "Vladislav Golyanik"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07316v1",
    "title": "Pixel-Perfect Depth with Semantics-Prompted Diffusion Transformers",
    "summary": "This paper presents Pixel-Perfect Depth, a monocular depth estimation model\nbased on pixel-space diffusion generation that produces high-quality,\nflying-pixel-free point clouds from estimated depth maps. Current generative\ndepth estimation models fine-tune Stable Diffusion and achieve impressive\nperformance. However, they require a VAE to compress depth maps into latent\nspace, which inevitably introduces \\textit{flying pixels} at edges and details.\nOur model addresses this challenge by directly performing diffusion generation\nin the pixel space, avoiding VAE-induced artifacts. To overcome the high\ncomplexity associated with pixel-space generation, we introduce two novel\ndesigns: 1) Semantics-Prompted Diffusion Transformers (SP-DiT), which\nincorporate semantic representations from vision foundation models into DiT to\nprompt the diffusion process, thereby preserving global semantic consistency\nwhile enhancing fine-grained visual details; and 2) Cascade DiT Design that\nprogressively increases the number of tokens to further enhance efficiency and\naccuracy. Our model achieves the best performance among all published\ngenerative models across five benchmarks, and significantly outperforms all\nother models in edge-aware point cloud evaluation.",
    "published": "2025-10-08T17:59:33Z",
    "updated": "2025-10-08T17:59:33Z",
    "link": "http://arxiv.org/pdf/2510.07316v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Gangwei Xu",
      "Haotong Lin",
      "Hongcheng Luo",
      "Xianqi Wang",
      "Jingfeng Yao",
      "Lianghui Zhu",
      "Yuechuan Pu",
      "Cheng Chi",
      "Haiyang Sun",
      "Bing Wang",
      "Guang Chen",
      "Hangjun Ye",
      "Sida Peng",
      "Xin Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07313v1",
    "title": "WristWorld: Generating Wrist-Views via 4D World Models for Robotic\n  Manipulation",
    "summary": "Wrist-view observations are crucial for VLA models as they capture\nfine-grained hand-object interactions that directly enhance manipulation\nperformance. Yet large-scale datasets rarely include such recordings, resulting\nin a substantial gap between abundant anchor views and scarce wrist views.\nExisting world models cannot bridge this gap, as they require a wrist-view\nfirst frame and thus fail to generate wrist-view videos from anchor views\nalone. Amid this gap, recent visual geometry models such as VGGT emerge with\ngeometric and cross-view priors that make it possible to address extreme\nviewpoint shifts. Inspired by these insights, we propose WristWorld, the first\n4D world model that generates wrist-view videos solely from anchor views.\nWristWorld operates in two stages: (i) Reconstruction, which extends VGGT and\nincorporates our Spatial Projection Consistency (SPC) Loss to estimate\ngeometrically consistent wrist-view poses and 4D point clouds; (ii) Generation,\nwhich employs our video generation model to synthesize temporally coherent\nwrist-view videos from the reconstructed perspective. Experiments on Droid,\nCalvin, and Franka Panda demonstrate state-of-the-art video generation with\nsuperior spatial consistency, while also improving VLA performance, raising the\naverage task completion length on Calvin by 3.81% and closing 42.4% of the\nanchor-wrist view gap.",
    "published": "2025-10-08T17:59:08Z",
    "updated": "2025-10-08T17:59:08Z",
    "link": "http://arxiv.org/pdf/2510.07313v1.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Zezhong Qian",
      "Xiaowei Chi",
      "Yuming Li",
      "Shizun Wang",
      "Zhiyuan Qin",
      "Xiaozhu Ju",
      "Sirui Han",
      "Shanghang Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07310v1",
    "title": "MATRIX: Mask Track Alignment for Interaction-aware Video Generation",
    "summary": "Video DiTs have advanced video generation, yet they still struggle to model\nmulti-instance or subject-object interactions. This raises a key question: How\ndo these models internally represent interactions? To answer this, we curate\nMATRIX-11K, a video dataset with interaction-aware captions and multi-instance\nmask tracks. Using this dataset, we conduct a systematic analysis that\nformalizes two perspectives of video DiTs: semantic grounding, via\nvideo-to-text attention, which evaluates whether noun and verb tokens capture\ninstances and their relations; and semantic propagation, via video-to-video\nattention, which assesses whether instance bindings persist across frames. We\nfind both effects concentrate in a small subset of interaction-dominant layers.\nMotivated by this, we introduce MATRIX, a simple and effective regularization\nthat aligns attention in specific layers of video DiTs with multi-instance mask\ntracks from the MATRIX-11K dataset, enhancing both grounding and propagation.\nWe further propose InterGenEval, an evaluation protocol for interaction-aware\nvideo generation. In experiments, MATRIX improves both interaction fidelity and\nsemantic alignment while reducing drift and hallucination. Extensive ablations\nvalidate our design choices. Codes and weights will be released.",
    "published": "2025-10-08T17:57:38Z",
    "updated": "2025-10-08T17:57:38Z",
    "link": "http://arxiv.org/pdf/2510.07310v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Siyoon Jin",
      "Seongchan Kim",
      "Dahyun Chung",
      "Jaeho Lee",
      "Hyunwook Choi",
      "Jisu Nam",
      "Jiyoung Kim",
      "Seungryong Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07302v1",
    "title": "SpecGuard: Spectral Projection-based Advanced Invisible Watermarking",
    "summary": "Watermarking embeds imperceptible patterns into images for authenticity\nverification. However, existing methods often lack robustness against various\ntransformations primarily including distortions, image regeneration, and\nadversarial perturbation, creating real-world challenges. In this work, we\nintroduce SpecGuard, a novel watermarking approach for robust and invisible\nimage watermarking. Unlike prior approaches, we embed the message inside hidden\nconvolution layers by converting from the spatial domain to the frequency\ndomain using spectral projection of a higher frequency band that is decomposed\nby wavelet projection. Spectral projection employs Fast Fourier Transform\napproximation to transform spatial data into the frequency domain efficiently.\nIn the encoding phase, a strength factor enhances resilience against diverse\nattacks, including adversarial, geometric, and regeneration-based distortions,\nensuring the preservation of copyrighted information. Meanwhile, the decoder\nleverages Parseval's theorem to effectively learn and extract the watermark\npattern, enabling accurate retrieval under challenging transformations. We\nevaluate the proposed SpecGuard based on the embedded watermark's invisibility,\ncapacity, and robustness. Comprehensive experiments demonstrate the proposed\nSpecGuard outperforms the state-of-the-art models. To ensure reproducibility,\nthe full code is released on\n\\href{https://github.com/inzamamulDU/SpecGuard_ICCV_2025}{\\textcolor{blue}{\\textbf{GitHub}}}.",
    "published": "2025-10-08T17:56:21Z",
    "updated": "2025-10-08T17:56:21Z",
    "link": "http://arxiv.org/pdf/2510.07302v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Inzamamul Alam",
      "Md Tanvir Islam",
      "Khan Muhammad",
      "Simon S. Woo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07277v1",
    "title": "Evaluating Fundus-Specific Foundation Models for Diabetic Macular Edema\n  Detection",
    "summary": "Diabetic Macular Edema (DME) is a leading cause of vision loss among patients\nwith Diabetic Retinopathy (DR). While deep learning has shown promising results\nfor automatically detecting this condition from fundus images, its application\nremains challenging due the limited availability of annotated data. Foundation\nModels (FM) have emerged as an alternative solution. However, it is unclear if\nthey can cope with DME detection in particular. In this paper, we\nsystematically compare different FM and standard transfer learning approaches\nfor this task. Specifically, we compare the two most popular FM for retinal\nimages--RETFound and FLAIR--and an EfficientNet-B0 backbone, across different\ntraining regimes and evaluation settings in IDRiD, MESSIDOR-2 and\nOCT-and-Eye-Fundus-Images (OEFI). Results show that despite their scale, FM do\nnot consistently outperform fine-tuned CNNs in this task. In particular, an\nEfficientNet-B0 ranked first or second in terms of area under the ROC and\nprecision/recall curves in most evaluation settings, with RETFound only showing\npromising results in OEFI. FLAIR, on the other hand, demonstrated competitive\nzero-shot performance, achieving notable AUC-PR scores when prompted\nappropriately. These findings reveal that FM might not be a good tool for\nfine-grained ophthalmic tasks such as DME detection even after fine-tuning,\nsuggesting that lightweight CNNs remain strong baselines in data-scarce\nenvironments.",
    "published": "2025-10-08T17:41:02Z",
    "updated": "2025-10-08T17:41:02Z",
    "link": "http://arxiv.org/pdf/2510.07277v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Franco Javier Arellano",
      "José Ignacio Orlando"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07249v1",
    "title": "TalkCuts: A Large-Scale Dataset for Multi-Shot Human Speech Video\n  Generation",
    "summary": "In this work, we present TalkCuts, a large-scale dataset designed to\nfacilitate the study of multi-shot human speech video generation. Unlike\nexisting datasets that focus on single-shot, static viewpoints, TalkCuts offers\n164k clips totaling over 500 hours of high-quality human speech videos with\ndiverse camera shots, including close-up, half-body, and full-body views. The\ndataset includes detailed textual descriptions, 2D keypoints and 3D SMPL-X\nmotion annotations, covering over 10k identities, enabling multimodal learning\nand evaluation. As a first attempt to showcase the value of the dataset, we\npresent Orator, an LLM-guided multi-modal generation framework as a simple\nbaseline, where the language model functions as a multi-faceted director,\norchestrating detailed specifications for camera transitions, speaker\ngesticulations, and vocal modulation. This architecture enables the synthesis\nof coherent long-form videos through our integrated multi-modal video\ngeneration module. Extensive experiments in both pose-guided and audio-driven\nsettings show that training on TalkCuts significantly enhances the\ncinematographic coherence and visual appeal of generated multi-shot speech\nvideos. We believe TalkCuts provides a strong foundation for future work in\ncontrollable, multi-shot speech video generation and broader multimodal\nlearning.",
    "published": "2025-10-08T17:16:09Z",
    "updated": "2025-10-08T17:16:09Z",
    "link": "http://arxiv.org/pdf/2510.07249v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jiaben Chen",
      "Zixin Wang",
      "Ailing Zeng",
      "Yang Fu",
      "Xueyang Yu",
      "Siyuan Cen",
      "Julian Tanke",
      "Yihang Chen",
      "Koichi Saito",
      "Yuki Mitsufuji",
      "Chuang Gan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2408.12009v2",
    "title": "CaRDiff: Video Salient Object Ranking Chain of Thought Reasoning for\n  Saliency Prediction with Diffusion",
    "summary": "Video saliency prediction aims to identify the regions in a video that\nattract human attention and gaze, driven by bottom-up features from the video\nand top-down processes like memory and cognition. Among these top-down\ninfluences, language plays a crucial role in guiding attention by shaping how\nvisual information is interpreted. Existing methods primarily focus on modeling\nperceptual information while neglecting the reasoning process facilitated by\nlanguage, where ranking cues are crucial outcomes of this process and practical\nguidance for saliency prediction. In this paper, we propose CaRDiff (Caption,\nRank, and generate with Diffusion), a framework that imitates the process by\nintegrating a multimodal large language model (MLLM), a grounding module, and a\ndiffusion model, to enhance video saliency prediction. Specifically, we\nintroduce a novel prompting method VSOR-CoT (Video Salient Object Ranking Chain\nof Thought), which utilizes an MLLM with a grounding module to caption video\ncontent and infer salient objects along with their rankings and positions. This\nprocess derives ranking maps that can be sufficiently leveraged by the\ndiffusion model to decode the saliency maps for the given video accurately.\nExtensive experiments show the effectiveness of VSOR-CoT in improving the\nperformance of video saliency prediction. The proposed CaRDiff performs better\nthan state-of-the-art models on the MVS dataset and demonstrates cross-dataset\ncapabilities on the DHF1k dataset through zero-shot evaluation.",
    "published": "2024-08-21T21:40:30Z",
    "updated": "2025-10-08T17:14:59Z",
    "link": "http://arxiv.org/pdf/2408.12009v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yolo Yunlong Tang",
      "Gen Zhan",
      "Li Yang",
      "Yiting Liao",
      "Chenliang Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.20426v2",
    "title": "MMPerspective: Do MLLMs Understand Perspective? A Comprehensive\n  Benchmark for Perspective Perception, Reasoning, and Robustness",
    "summary": "Understanding perspective is fundamental to human visual perception, yet the\nextent to which multimodal large language models (MLLMs) internalize\nperspective geometry remains unclear. We introduce MMPerspective, the first\nbenchmark specifically designed to systematically evaluate MLLMs' understanding\nof perspective through 10 carefully crafted tasks across three complementary\ndimensions: Perspective Perception, Reasoning, and Robustness. Our benchmark\ncomprises 2,711 real-world and synthetic image instances with 5,083\nquestion-answer pairs that probe key capabilities, such as vanishing point\nperception and counting, perspective type reasoning, line relationship\nunderstanding in 3D space, invariance to perspective-preserving\ntransformations, etc. Through a comprehensive evaluation of 43 state-of-the-art\nMLLMs, we uncover significant limitations: while models demonstrate competence\non surface-level perceptual tasks, they struggle with compositional reasoning\nand maintaining spatial consistency under perturbations. Our analysis further\nreveals intriguing patterns between model architecture, scale, and perspective\ncapabilities, highlighting both robustness bottlenecks and the benefits of\nchain-of-thought prompting. MMPerspective establishes a valuable testbed for\ndiagnosing and advancing spatial understanding in vision-language systems.\nResources available at: https://yunlong10.github.io/MMPerspective/",
    "published": "2025-05-26T18:20:22Z",
    "updated": "2025-10-08T16:58:18Z",
    "link": "http://arxiv.org/pdf/2505.20426v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yolo Yunlong Tang",
      "Pinxin Liu",
      "Mingqian Feng",
      "Zhangyun Tan",
      "Rui Mao",
      "Chao Huang",
      "Jing Bi",
      "Yunzhong Xiao",
      "Susan Liang",
      "Hang Hua",
      "Ali Vosoughi",
      "Luchuan Song",
      "Zeliang Zhang",
      "Chenliang Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.18468v5",
    "title": "RGS-DR: Deferred Reflections and Residual Shading in 2D Gaussian\n  Splatting",
    "summary": "In this work, we address specular appearance in inverse rendering using 2D\nGaussian splatting with deferred shading and argue for a refinement stage to\nimprove specular detail, thereby bridging the gap with reconstruction-only\nmethods. Our pipeline estimates editable material properties and environment\nillumination while employing a directional residual pass that captures leftover\nview-dependent effects for further refining novel view synthesis. In contrast\nto per-Gaussian shading with shortest-axis normals and normal residuals, which\ntends to result in more noisy geometry and specular appearance, a\npixel-deferred surfel formulation with specular residuals yields sharper\nhighlights, cleaner materials, and improved editability. We evaluate our\napproach on rendering and reconstruction quality on three popular datasets\nfeaturing glossy objects, and also demonstrate high-quality relighting and\nmaterial editing.",
    "published": "2025-04-25T16:23:50Z",
    "updated": "2025-10-08T16:55:05Z",
    "link": "http://arxiv.org/pdf/2504.18468v5.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Georgios Kouros",
      "Minye Wu",
      "Tinne Tuytelaars"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07206v1",
    "title": "EigenScore: OOD Detection using Covariance in Diffusion Models",
    "summary": "Out-of-distribution (OOD) detection is critical for the safe deployment of\nmachine learning systems in safety-sensitive domains. Diffusion models have\nrecently emerged as powerful generative models, capable of capturing complex\ndata distributions through iterative denoising. Building on this progress,\nrecent work has explored their potential for OOD detection. We propose\nEigenScore, a new OOD detection method that leverages the eigenvalue spectrum\nof the posterior covariance induced by a diffusion model. We argue that\nposterior covariance provides a consistent signal of distribution shift,\nleading to larger trace and leading eigenvalues on OOD inputs, yielding a clear\nspectral signature. We further provide analysis explicitly linking posterior\ncovariance to distribution mismatch, establishing it as a reliable signal for\nOOD detection. To ensure tractability, we adopt a Jacobian-free subspace\niteration method to estimate the leading eigenvalues using only forward\nevaluations of the denoiser. Empirically, EigenScore achieves SOTA performance,\nwith up to 5% AUROC improvement over the best baseline. Notably, it remains\nrobust in near-OOD settings such as CIFAR-10 vs CIFAR-100, where existing\ndiffusion-based methods often fail.",
    "published": "2025-10-08T16:42:20Z",
    "updated": "2025-10-08T16:42:20Z",
    "link": "http://arxiv.org/pdf/2510.07206v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Shirin Shoushtari",
      "Yi Wang",
      "Xiao Shi",
      "M. Salman Asif",
      "Ulugbek S. Kamilov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07190v1",
    "title": "MV-Performer: Taming Video Diffusion Model for Faithful and Synchronized\n  Multi-view Performer Synthesis",
    "summary": "Recent breakthroughs in video generation, powered by large-scale datasets and\ndiffusion techniques, have shown that video diffusion models can function as\nimplicit 4D novel view synthesizers. Nevertheless, current methods primarily\nconcentrate on redirecting camera trajectory within the front view while\nstruggling to generate 360-degree viewpoint changes. In this paper, we focus on\nhuman-centric subdomain and present MV-Performer, an innovative framework for\ncreating synchronized novel view videos from monocular full-body captures. To\nachieve a 360-degree synthesis, we extensively leverage the MVHumanNet dataset\nand incorporate an informative condition signal. Specifically, we use the\ncamera-dependent normal maps rendered from oriented partial point clouds, which\neffectively alleviate the ambiguity between seen and unseen observations. To\nmaintain synchronization in the generated videos, we propose a multi-view\nhuman-centric video diffusion model that fuses information from the reference\nvideo, partial rendering, and different viewpoints. Additionally, we provide a\nrobust inference procedure for in-the-wild video cases, which greatly mitigates\nthe artifacts induced by imperfect monocular depth estimation. Extensive\nexperiments on three datasets demonstrate our MV-Performer's state-of-the-art\neffectiveness and robustness, setting a strong model for human-centric 4D novel\nview synthesis.",
    "published": "2025-10-08T16:24:22Z",
    "updated": "2025-10-08T16:24:22Z",
    "link": "http://arxiv.org/pdf/2510.07190v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yihao Zhi",
      "Chenghong Li",
      "Hongjie Liao",
      "Xihe Yang",
      "Zhengwentai Sun",
      "Jiahao Chang",
      "Xiaodong Cun",
      "Wensen Feng",
      "Xiaoguang Han"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.17693v2",
    "title": "BIM-Constrained Optimization for Accurate Localization and Deviation\n  Correction in Construction Monitoring",
    "summary": "Augmented reality (AR) applications for construction monitoring rely on\nreal-time environmental tracking to visualize architectural elements. However,\nconstruction sites present significant challenges for traditional tracking\nmethods due to featureless surfaces, dynamic changes, and drift accumulation,\nleading to misalignment between digital models and the physical world. This\npaper proposes a BIM-aware drift correction method to address these challenges.\nInstead of relying solely on SLAM-based localization, we align ``as-built\"\ndetected planes from the real-world environment with ``as-planned\"\narchitectural planes in BIM. Our method performs robust plane matching and\ncomputes a transformation (TF) between SLAM (S) and BIM (B) origin frames using\noptimization techniques, minimizing drift over time. By incorporating BIM as\nprior structural knowledge, we can achieve improved long-term localization and\nenhanced AR visualization accuracy in noisy construction environments. The\nmethod is evaluated through real-world experiments, showing significant\nreductions in drift-induced errors and optimized alignment consistency. On\naverage, our system achieves a reduction of 52.24% in angular deviations and a\nreduction of 60.8% in the distance error of the matched walls compared to the\ninitial manual alignment by the user.",
    "published": "2025-04-24T16:02:02Z",
    "updated": "2025-10-08T16:20:54Z",
    "link": "http://arxiv.org/pdf/2504.17693v2.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Asier Bikandi-Noya",
      "Muhammad Shaheer",
      "Hriday Bavle",
      "Jayan Jevanesan",
      "Holger Voos",
      "Jose Luis Sanchez-Lopez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.19695v2",
    "title": "SubGrapher: Visual Fingerprinting of Chemical Structures",
    "summary": "Automatic extraction of chemical structures from scientific literature plays\na crucial role in accelerating research across fields ranging from drug\ndiscovery to materials science. Patent documents, in particular, contain\nmolecular information in visual form, which is often inaccessible through\ntraditional text-based searches. In this work, we introduce SubGrapher, a\nmethod for the visual fingerprinting of chemical structure images. Unlike\nconventional Optical Chemical Structure Recognition (OCSR) models that attempt\nto reconstruct full molecular graphs, SubGrapher focuses on extracting\nmolecular fingerprints directly from chemical structure images. Using\nlearning-based instance segmentation, SubGrapher identifies functional groups\nand carbon backbones, constructing a substructure-based fingerprint that\nenables chemical structure retrieval. Our approach is evaluated against\nstate-of-the-art OCSR and fingerprinting methods, demonstrating superior\nretrieval performance and robustness across diverse molecular depictions. The\ndataset, models, and code are publicly available.",
    "published": "2025-04-28T11:45:46Z",
    "updated": "2025-10-08T16:18:46Z",
    "link": "http://arxiv.org/pdf/2504.19695v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Lucas Morin",
      "Gerhard Ingmar Meijer",
      "Valéry Weber",
      "Luc Van Gool",
      "Peter W. J. Staar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.05034v2",
    "title": "Video-LMM Post-Training: A Deep Dive into Video Reasoning with Large\n  Multimodal Models",
    "summary": "Video understanding represents the most challenging frontier in computer\nvision, requiring models to reason about complex spatiotemporal relationships,\nlong-term dependencies, and multimodal evidence. The recent emergence of\nVideo-Large Multimodal Models (Video-LMMs), which integrate visual encoders\nwith powerful decoder-based language models, has demonstrated remarkable\ncapabilities in video understanding tasks. However, the critical phase that\ntransforms these models from basic perception systems into sophisticated\nreasoning engines, post-training, remains fragmented across the literature.\nThis survey provides the first comprehensive examination of post-training\nmethodologies for Video-LMMs, encompassing three fundamental pillars:\nsupervised fine-tuning (SFT) with chain-of-thought, reinforcement learning (RL)\nfrom verifiable objectives, and test-time scaling (TTS) through enhanced\ninference computation. We present a structured taxonomy that clarifies the\nroles, interconnections, and video-specific adaptations of these techniques,\naddressing unique challenges such as temporal localization, spatiotemporal\ngrounding, long video efficiency, and multimodal evidence integration. Through\nsystematic analysis of representative methods, we synthesize key design\nprinciples, insights, and evaluation protocols while identifying critical open\nchallenges in reward design, scalability, and cost-performance optimization. We\nfurther curate essential benchmarks, datasets, and metrics to facilitate\nrigorous assessment of post-training effectiveness. This survey aims to provide\nresearchers and practitioners with a unified framework for advancing Video-LMM\ncapabilities. Additional resources and updates are maintained at:\nhttps://github.com/yunlong10/Awesome-Video-LMM-Post-Training",
    "published": "2025-10-06T17:10:44Z",
    "updated": "2025-10-08T16:08:31Z",
    "link": "http://arxiv.org/pdf/2510.05034v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yolo Yunlong Tang",
      "Jing Bi",
      "Pinxin Liu",
      "Zhenyu Pan",
      "Zhangyun Tan",
      "Qianxiang Shen",
      "Jiani Liu",
      "Hang Hua",
      "Junjia Guo",
      "Yunzhong Xiao",
      "Chao Huang",
      "Zhiyuan Wang",
      "Susan Liang",
      "Xinyi Liu",
      "Yizhi Song",
      "Yuhe Nie",
      "Jia-Xing Zhong",
      "Bozheng Li",
      "Daiqing Qi",
      "Ziyun Zeng",
      "Ali Vosoughi",
      "Luchuan Song",
      "Zeliang Zhang",
      "Daiki Shimada",
      "Han Liu",
      "Jiebo Luo",
      "Chenliang Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.05506v2",
    "title": "Human Action Recognition from Point Clouds over Time",
    "summary": "Recent research into human action recognition (HAR) has focused predominantly\non skeletal action recognition and video-based methods. With the increasing\navailability of consumer-grade depth sensors and Lidar instruments, there is a\ngrowing opportunity to leverage dense 3D data for action recognition, to\ndevelop a third way. This paper presents a novel approach for recognizing\nactions from 3D videos by introducing a pipeline that segments human point\nclouds from the background of a scene, tracks individuals over time, and\nperforms body part segmentation. The method supports point clouds from both\ndepth sensors and monocular depth estimation. At the core of the proposed HAR\nframework is a novel backbone for 3D action recognition, which combines\npoint-based techniques with sparse convolutional networks applied to\nvoxel-mapped point cloud sequences. Experiments incorporate auxiliary point\nfeatures including surface normals, color, infrared intensity, and body part\nparsing labels, to enhance recognition accuracy. Evaluation on the NTU RGB- D\n120 dataset demonstrates that the method is competitive with existing skeletal\naction recognition algorithms. Moreover, combining both sensor-based and\nestimated depth inputs in an ensemble setup, this approach achieves 89.3%\naccuracy when different human subjects are considered for training and testing,\noutperforming previous point cloud action recognition methods.",
    "published": "2025-10-07T01:51:27Z",
    "updated": "2025-10-08T16:08:17Z",
    "link": "http://arxiv.org/pdf/2510.05506v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "James Dickens"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07143v1",
    "title": "Are We Using the Right Benchmark: An Evaluation Framework for Visual\n  Token Compression Methods",
    "summary": "Recent endeavors to accelerate inference in Multimodal Large Language Models\n(MLLMs) have primarily focused on visual token compression. The effectiveness\nof these methods is typically assessed by measuring the accuracy drop on\nestablished benchmarks, comparing model performance before and after\ncompression. However, these benchmarks are originally designed to assess the\nperception and reasoning capabilities of MLLMs, rather than to evaluate\ncompression techniques. As a result, directly applying them to visual token\ncompression introduces a task mismatch. Strikingly, our investigation reveals\nthat simple image downsampling consistently outperforms many advanced\ncompression methods across multiple widely used benchmarks. Through extensive\nexperiments, we make the following observations: (i) Current benchmarks are\nnoisy for the visual token compression task. (ii) Down-sampling is able to\nserve as a data filter to evaluate the difficulty of samples in the visual\ntoken compression task. Motivated by these findings, we introduce VTC-Bench, an\nevaluation framework that incorporates a data filtering mechanism to denoise\nexisting benchmarks, thereby enabling fairer and more accurate assessment of\nvisual token compression methods. All data and code are available at\nhttps://github.com/Chenfei-Liao/VTC-Bench.",
    "published": "2025-10-08T15:44:28Z",
    "updated": "2025-10-08T15:44:28Z",
    "link": "http://arxiv.org/pdf/2510.07143v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Chenfei Liao",
      "Wensong Wang",
      "Zichen Wen",
      "Xu Zheng",
      "Yiyu Wang",
      "Haocong He",
      "Yuanhuiyi Lyu",
      "Lutao Jiang",
      "Xin Zou",
      "Yuqian Fu",
      "Bin Ren",
      "Linfeng Zhang",
      "Xuming Hu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07135v1",
    "title": "Few-Shot Adaptation Benchmark for Remote Sensing Vision-Language Models",
    "summary": "Remote Sensing Vision-Language Models (RSVLMs) have shown remarkable\npotential thanks to large-scale pretraining, achieving strong zero-shot\nperformance on various tasks. However, their ability to generalize in low-data\nregimes, such as few-shot learning, remains insufficiently explored. In this\nwork, we present the first structured benchmark for evaluating few-shot\nadaptation methods on RSVLMs. We conduct comprehensive experiments across ten\nremote sensing scene classification datasets, applying five widely used\nfew-shot adaptation strategies to three state-of-the-art RSVLMs with varying\nbackbones. Our findings reveal that models with similar zero-shot performance\ncan exhibit markedly different behavior under few-shot adaptation, with some\nRSVLMs being inherently more amenable to such adaptation than others. The\nvariability of performance and the absence of a clear winner among existing\nmethods highlight the need for the development of more robust methods for\nfew-shot adaptation tailored to RS. To facilitate future research, we provide a\nreproducible benchmarking framework and open-source code to systematically\nevaluate RSVLMs under few-shot conditions. The source code is publicly\navailable on Github: https://github.com/elkhouryk/fewshot_RSVLMs",
    "published": "2025-10-08T15:29:48Z",
    "updated": "2025-10-08T15:29:48Z",
    "link": "http://arxiv.org/pdf/2510.07135v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Karim El Khoury",
      "Maxime Zanella",
      "Christophe De Vleeschouwer",
      "Benoit Macq"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.24893v3",
    "title": "HBSplat: Robust Sparse-View Gaussian Reconstruction with Hybrid-Loss\n  Guided Depth and Bidirectional Warping",
    "summary": "Novel View Synthesis (NVS) from sparse views presents a formidable challenge\nin 3D reconstruction, where limited multi-view constraints lead to severe\noverfitting, geometric distortion, and fragmented scenes. While 3D Gaussian\nSplatting (3DGS) delivers real-time, high-fidelity rendering, its performance\ndrastically deteriorates under sparse inputs, plagued by floating artifacts and\nstructural failures. To address these challenges, we introduce HBSplat, a\nunified framework that elevates 3DGS by seamlessly integrating robust\nstructural cues, virtual view constraints, and occluded region completion. Our\ncore contributions are threefold: a Hybrid-Loss Depth Estimation module that\nensures multi-view consistency by leveraging dense matching priors and\nintegrating reprojection, point propagation, and smoothness constraints; a\nBidirectional Warping Virtual View Synthesis method that enforces substantially\nstronger constraints by creating high-fidelity virtual views through\nbidirectional depth-image warping and multi-view fusion; and an Occlusion-Aware\nReconstruction component that recovers occluded areas using a depth-difference\nmask and a learning-based inpainting model. Extensive evaluations on LLFF,\nBlender, and DTU benchmarks validate that HBSplat sets a new state-of-the-art,\nachieving up to 21.13 dB PSNR and 0.189 LPIPS, while maintaining real-time\ninference. Code is available at: https://github.com/eternalland/HBSplat.",
    "published": "2025-09-29T15:03:31Z",
    "updated": "2025-10-08T15:26:58Z",
    "link": "http://arxiv.org/pdf/2509.24893v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yu Ma",
      "Guoliang Wei",
      "Haihong Xiao",
      "Yue Cheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07126v1",
    "title": "Validation of Various Normalization Methods for Brain Tumor\n  Segmentation: Can Federated Learning Overcome This Heterogeneity?",
    "summary": "Deep learning (DL) has been increasingly applied in medical imaging, however,\nit requires large amounts of data, which raises many challenges related to data\nprivacy, storage, and transfer. Federated learning (FL) is a training paradigm\nthat overcomes these issues, though its effectiveness may be reduced when\ndealing with non-independent and identically distributed (non-IID) data. This\nstudy simulates non-IID conditions by applying different MRI intensity\nnormalization techniques to separate data subsets, reflecting a common cause of\nheterogeneity. These subsets are then used for training and testing models for\nbrain tumor segmentation. The findings provide insights into the influence of\nthe MRI intensity normalization methods on segmentation models, both training\nand inference. Notably, the FL methods demonstrated resilience to\ninconsistently normalized data across clients, achieving the 3D Dice score of\n92%, which is comparable to a centralized model (trained using all data). These\nresults indicate that FL is a solution to effectively train high-performing\nmodels without violating data privacy, a crucial concern in medical\napplications. The code is available at:\nhttps://github.com/SanoScience/fl-varying-normalization.",
    "published": "2025-10-08T15:21:53Z",
    "updated": "2025-10-08T15:21:53Z",
    "link": "http://arxiv.org/pdf/2510.07126v1.pdf",
    "category": [
      "cs.CV",
      "cs.DC"
    ],
    "authors": [
      "Jan Fiszer",
      "Dominika Ciupek",
      "Maciej Malawski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.20772v2",
    "title": "MetaSlot: Break Through the Fixed Number of Slots in Object-Centric\n  Learning",
    "summary": "Learning object-level, structured representations is widely regarded as a key\nto better generalization in vision and underpins the design of next-generation\nPre-trained Vision Models (PVMs). Mainstream Object-Centric Learning (OCL)\nmethods adopt Slot Attention or its variants to iteratively aggregate objects'\nsuper-pixels into a fixed set of query feature vectors, termed slots. However,\ntheir reliance on a static slot count leads to an object being represented as\nmultiple parts when the number of objects varies. We introduce MetaSlot, a\nplug-and-play Slot Attention variant that adapts to variable object counts.\nMetaSlot (i) maintains a codebook that holds prototypes of objects in a dataset\nby vector-quantizing the resulting slot representations; (ii) removes duplicate\nslots from the traditionally aggregated slots by quantizing them with the\ncodebook; and (iii) injects progressively weaker noise into the Slot Attention\niterations to accelerate and stabilize the aggregation. MetaSlot is a general\nSlot Attention variant that can be seamlessly integrated into existing OCL\narchitectures. Across multiple public datasets and tasks--including object\ndiscovery and recognition--models equipped with MetaSlot achieve significant\nperformance gains and markedly interpretable slot representations, compared\nwith existing Slot Attention variants.",
    "published": "2025-05-27T06:23:03Z",
    "updated": "2025-10-08T15:14:03Z",
    "link": "http://arxiv.org/pdf/2505.20772v2.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Hongjia Liu",
      "Rongzhen Zhao",
      "Haohan Chen",
      "Joni Pajarinen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.19256v4",
    "title": "PolyPose: Deformable 2D/3D Registration via Polyrigid Transformations",
    "summary": "Determining the 3D pose of a patient from a limited set of 2D X-ray images is\na critical task in interventional settings. While preoperative volumetric\nimaging (e.g., CT and MRI) provides precise 3D localization and visualization\nof anatomical targets, these modalities cannot be acquired during procedures,\nwhere fast 2D imaging (X-ray) is used instead. To integrate volumetric guidance\ninto intraoperative procedures, we present PolyPose, a simple and robust method\nfor deformable 2D/3D registration. PolyPose parameterizes complex 3D\ndeformation fields as a composition of rigid transforms, leveraging the\nbiological constraint that individual bones do not bend in typical motion.\nUnlike existing methods that either assume no inter-joint movement or fail\noutright in this under-determined setting, our polyrigid formulation enforces\nanatomically plausible priors that respect the piecewise-rigid nature of human\nmovement. This approach eliminates the need for expensive deformation\nregularizers that require patient- and procedure-specific hyperparameter\noptimization. Across extensive experiments on diverse datasets from orthopedic\nsurgery and radiotherapy, we show that this strong inductive bias enables\nPolyPose to successfully align the patient's preoperative volume to as few as\ntwo X-rays, thereby providing crucial 3D guidance in challenging sparse-view\nand limited-angle settings where current registration methods fail. Additional\nvisualizations, tutorials, and code are available at\nhttps://polypose.csail.mit.edu.",
    "published": "2025-05-25T18:24:18Z",
    "updated": "2025-10-08T15:12:51Z",
    "link": "http://arxiv.org/pdf/2505.19256v4.pdf",
    "category": [
      "cs.CV",
      "physics.med-ph"
    ],
    "authors": [
      "Vivek Gopalakrishnan",
      "Neel Dey",
      "Polina Golland"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07119v1",
    "title": "MoRe: Monocular Geometry Refinement via Graph Optimization for\n  Cross-View Consistency",
    "summary": "Monocular 3D foundation models offer an extensible solution for perception\ntasks, making them attractive for broader 3D vision applications. In this\npaper, we propose MoRe, a training-free Monocular Geometry Refinement method\ndesigned to improve cross-view consistency and achieve scale alignment. To\ninduce inter-frame relationships, our method employs feature matching between\nframes to establish correspondences. Rather than applying simple least squares\noptimization on these matched points, we formulate a graph-based optimization\nframework that performs local planar approximation using the estimated 3D\npoints and surface normals estimated by monocular foundation models. This\nformulation addresses the scale ambiguity inherent in monocular geometric\npriors while preserving the underlying 3D structure. We further demonstrate\nthat MoRe not only enhances 3D reconstruction but also improves novel view\nsynthesis, particularly in sparse view rendering scenarios.",
    "published": "2025-10-08T15:11:32Z",
    "updated": "2025-10-08T15:11:32Z",
    "link": "http://arxiv.org/pdf/2510.07119v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Dongki Jung",
      "Jaehoon Choi",
      "Yonghan Lee",
      "Sungmin Eum",
      "Heesung Kwon",
      "Dinesh Manocha"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07115v1",
    "title": "Enhancing Concept Localization in CLIP-based Concept Bottleneck Models",
    "summary": "This paper addresses explainable AI (XAI) through the lens of Concept\nBottleneck Models (CBMs) that do not require explicit concept annotations,\nrelying instead on concepts extracted using CLIP in a zero-shot manner. We show\nthat CLIP, which is central in these techniques, is prone to concept\nhallucination, incorrectly predicting the presence or absence of concepts\nwithin an image in scenarios used in numerous CBMs, hence undermining the\nfaithfulness of explanations. To mitigate this issue, we introduce Concept\nHallucination Inhibition via Localized Interpretability (CHILI), a technique\nthat disentangles image embeddings and localizes pixels corresponding to target\nconcepts. Furthermore, our approach supports the generation of saliency-based\nexplanations that are more interpretable.",
    "published": "2025-10-08T15:07:16Z",
    "updated": "2025-10-08T15:07:16Z",
    "link": "http://arxiv.org/pdf/2510.07115v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Rémi Kazmierczak",
      "Steve Azzolin",
      "Eloïse Berthier",
      "Goran Frehse",
      "Gianni Franchi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07089v1",
    "title": "DADO: A Depth-Attention framework for Object Discovery",
    "summary": "Unsupervised object discovery, the task of identifying and localizing objects\nin images without human-annotated labels, remains a significant challenge and a\ngrowing focus in computer vision. In this work, we introduce a novel model,\nDADO (Depth-Attention self-supervised technique for Discovering unseen\nObjects), which combines an attention mechanism and a depth model to identify\npotential objects in images. To address challenges such as noisy attention maps\nor complex scenes with varying depth planes, DADO employs dynamic weighting to\nadaptively emphasize attention or depth features based on the global\ncharacteristics of each image. We evaluated DADO on standard benchmarks, where\nit outperforms state-of-the-art methods in object discovery accuracy and\nrobustness without the need for fine-tuning.",
    "published": "2025-10-08T14:46:34Z",
    "updated": "2025-10-08T14:46:34Z",
    "link": "http://arxiv.org/pdf/2510.07089v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Federico Gonzalez",
      "Estefania Talavera",
      "Petia Radeva"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07058v1",
    "title": "Concept Retrieval -- What and How?",
    "summary": "A concept may reflect either a concrete or abstract idea. Given an input\nimage, this paper seeks to retrieve other images that share its central\nconcepts, capturing aspects of the underlying narrative. This goes beyond\nconventional retrieval or clustering methods, which emphasize visual or\nsemantic similarity. We formally define the problem, outline key requirements,\nand introduce appropriate evaluation metrics. We propose a novel approach\ngrounded in two key observations: (1) While each neighbor in the embedding\nspace typically shares at least one concept with the query, not all neighbors\nnecessarily share the same concept with one another. (2) Modeling this\nneighborhood with a bimodal Gaussian distribution uncovers meaningful structure\nthat facilitates concept identification. Qualitative, quantitative, and human\nevaluations confirm the effectiveness of our approach. See the package on PyPI:\nhttps://pypi.org/project/coret/",
    "published": "2025-10-08T14:26:18Z",
    "updated": "2025-10-08T14:26:18Z",
    "link": "http://arxiv.org/pdf/2510.07058v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ori nizan",
      "Oren Shrout",
      "Ayellet Tal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07041v1",
    "title": "U-Bench: A Comprehensive Understanding of U-Net through 100-Variant\n  Benchmarking",
    "summary": "Over the past decade, U-Net has been the dominant architecture in medical\nimage segmentation, leading to the development of thousands of U-shaped\nvariants. Despite its widespread adoption, there is still no comprehensive\nbenchmark to systematically evaluate their performance and utility, largely\nbecause of insufficient statistical validation and limited consideration of\nefficiency and generalization across diverse datasets. To bridge this gap, we\npresent U-Bench, the first large-scale, statistically rigorous benchmark that\nevaluates 100 U-Net variants across 28 datasets and 10 imaging modalities. Our\ncontributions are threefold: (1) Comprehensive Evaluation: U-Bench evaluates\nmodels along three key dimensions: statistical robustness, zero-shot\ngeneralization, and computational efficiency. We introduce a novel metric,\nU-Score, which jointly captures the performance-efficiency trade-off, offering\na deployment-oriented perspective on model progress. (2) Systematic Analysis\nand Model Selection Guidance: We summarize key findings from the large-scale\nevaluation and systematically analyze the impact of dataset characteristics and\narchitectural paradigms on model performance. Based on these insights, we\npropose a model advisor agent to guide researchers in selecting the most\nsuitable models for specific datasets and tasks. (3) Public Availability: We\nprovide all code, models, protocols, and weights, enabling the community to\nreproduce our results and extend the benchmark with future methods. In summary,\nU-Bench not only exposes gaps in previous evaluations but also establishes a\nfoundation for fair, reproducible, and practically relevant benchmarking in the\nnext decade of U-Net-based segmentation models. The project can be accessed at:\nhttps://fenghetan9.github.io/ubench. Code is available at:\nhttps://github.com/FengheTan9/U-Bench.",
    "published": "2025-10-08T14:06:17Z",
    "updated": "2025-10-08T14:06:17Z",
    "link": "http://arxiv.org/pdf/2510.07041v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Fenghe Tang",
      "Chengqi Dong",
      "Wenxin Ma",
      "Zikang Xu",
      "Heqin Zhu",
      "Zihang Jiang",
      "Rongsheng Wang",
      "Yuhao Wang",
      "Chenxu Wu",
      "Shaohua Kevin Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.15257v2",
    "title": "RespoDiff: Dual-Module Bottleneck Transformation for Responsible &\n  Faithful T2I Generation",
    "summary": "The rapid advancement of diffusion models has enabled high-fidelity and\nsemantically rich text-to-image generation; however, ensuring fairness and\nsafety remains an open challenge. Existing methods typically improve fairness\nand safety at the expense of semantic fidelity and image quality. In this work,\nwe propose RespoDiff, a novel framework for responsible text-to-image\ngeneration that incorporates a dual-module transformation on the intermediate\nbottleneck representations of diffusion models. Our approach introduces two\ndistinct learnable modules: one focused on capturing and enforcing responsible\nconcepts, such as fairness and safety, and the other dedicated to maintaining\nsemantic alignment with neutral prompts. To facilitate the dual learning\nprocess, we introduce a novel score-matching objective that enables effective\ncoordination between the modules. Our method outperforms state-of-the-art\nmethods in responsible generation by ensuring semantic alignment while\noptimizing both objectives without compromising image fidelity. Our approach\nimproves responsible and semantically coherent generation by 20% across\ndiverse, unseen prompts. Moreover, it integrates seamlessly into large-scale\nmodels like SDXL, enhancing fairness and safety. Code will be released upon\nacceptance.",
    "published": "2025-09-18T07:48:46Z",
    "updated": "2025-10-08T14:03:31Z",
    "link": "http://arxiv.org/pdf/2509.15257v2.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Silpa Vadakkeeveetil Sreelatha",
      "Sauradip Nag",
      "Muhammad Awais",
      "Serge Belongie",
      "Anjan Dutta"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2208.08132v4",
    "title": "Maximising the Utility of Validation Sets for Imbalanced Noisy-label\n  Meta-learning",
    "summary": "Meta-learning is an effective method to handle imbalanced and noisy-label\nlearning, but it depends on a validation set containing randomly selected,\nmanually labelled and balanced distributed samples. The random selection and\nmanual labelling and balancing of this validation set is not only sub-optimal\nfor meta-learning, but it also scales poorly with the number of classes. Hence,\nrecent meta-learning papers have proposed ad-hoc heuristics to automatically\nbuild and label this validation set, but these heuristics are still sub-optimal\nfor meta-learning. In this paper, we analyse the meta-learning algorithm and\npropose new criteria to characterise the utility of the validation set, based\non: 1) the informativeness of the validation set; 2) the class distribution\nbalance of the set; and 3) the correctness of the labels of the set.\nFurthermore, we propose a new imbalanced noisy-label meta-learning (INOLML)\nalgorithm that automatically builds a validation set by maximising its utility\nusing the criteria above. Our method shows significant improvements over\nprevious meta-learning approaches and sets the new state-of-the-art on several\nbenchmarks.",
    "published": "2022-08-17T08:02:53Z",
    "updated": "2025-10-08T13:56:57Z",
    "link": "http://arxiv.org/pdf/2208.08132v4.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Dung Anh Hoang",
      "Cuong Nguyen",
      "Belagiannis Vasileios",
      "Thanh-Toan Do",
      "Gustavo Carneiro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2408.01541v2",
    "title": "Guardians of Image Quality: Benchmarking Defenses Against Adversarial\n  Attacks on Image Quality Metrics",
    "summary": "In the field of Image Quality Assessment (IQA), the adversarial robustness of\nthe metrics poses a critical concern. This paper presents a comprehensive\nbenchmarking study of various defense mechanisms in response to the rise in\nadversarial attacks on IQA. We systematically evaluate 25 defense strategies,\nincluding adversarial purification, adversarial training, and certified\nrobustness methods. We applied 14 adversarial attack algorithms of various\ntypes in both non-adaptive and adaptive settings and tested these defenses\nagainst them. We analyze the differences between defenses and their\napplicability to IQA tasks, considering that they should preserve IQA scores\nand image quality. The proposed benchmark aims to guide future developments and\naccepts submissions of new methods, with the latest results available online:\nhttps://videoprocessing.ai/benchmarks/iqa-defenses.html.",
    "published": "2024-08-02T19:02:49Z",
    "updated": "2025-10-08T13:53:22Z",
    "link": "http://arxiv.org/pdf/2408.01541v2.pdf",
    "category": [
      "cs.CV",
      "eess.IV"
    ],
    "authors": [
      "Alexander Gushchin",
      "Khaled Abud",
      "Georgii Bychkov",
      "Ekaterina Shumitskaya",
      "Anna Chistyakova",
      "Sergey Lavrushkin",
      "Bader Rasheed",
      "Kirill Malyshev",
      "Dmitriy Vatolin",
      "Anastasia Antsiferova"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.18015v3",
    "title": "DiffMI: Breaking Face Recognition Privacy via Diffusion-Driven\n  Training-Free Model Inversion",
    "summary": "Face recognition poses serious privacy risks due to its reliance on sensitive\nand immutable biometric data. While modern systems mitigate privacy risks by\nmapping facial images to embeddings (commonly regarded as privacy-preserving),\nmodel inversion attacks reveal that identity information can still be\nrecovered, exposing critical vulnerabilities. However, existing attacks are\noften computationally expensive and lack generalization, especially those\nrequiring target-specific training. Even training-free approaches suffer from\nlimited identity controllability, hindering faithful reconstruction of nuanced\nor unseen identities. In this work, we propose DiffMI, the first\ndiffusion-driven, training-free model inversion attack. DiffMI introduces a\nnovel pipeline combining robust latent code initialization, a ranked\nadversarial refinement strategy, and a statistically grounded, confidence-aware\noptimization objective. DiffMI applies directly to unseen target identities and\nface recognition models, offering greater adaptability than training-dependent\napproaches while significantly reducing computational overhead. Our method\nachieves 84.42%--92.87% attack success rates against inversion-resilient\nsystems and outperforms the best prior training-free GAN-based approach by\n4.01%--9.82%. The implementation is available at\nhttps://github.com/azrealwang/DiffMI.",
    "published": "2025-04-25T01:53:27Z",
    "updated": "2025-10-08T13:46:41Z",
    "link": "http://arxiv.org/pdf/2504.18015v3.pdf",
    "category": [
      "cs.CR",
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Hanrui Wang",
      "Shuo Wang",
      "Chun-Shien Lu",
      "Isao Echizen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07018v1",
    "title": "Sharpness-Aware Data Generation for Zero-shot Quantization",
    "summary": "Zero-shot quantization aims to learn a quantized model from a pre-trained\nfull-precision model with no access to original real training data. The common\nidea in zero-shot quantization approaches is to generate synthetic data for\nquantizing the full-precision model. While it is well-known that deep neural\nnetworks with low sharpness have better generalization ability, none of the\nprevious zero-shot quantization works considers the sharpness of the quantized\nmodel as a criterion for generating training data. This paper introduces a\nnovel methodology that takes into account quantized model sharpness in\nsynthetic data generation to enhance generalization. Specifically, we first\ndemonstrate that sharpness minimization can be attained by maximizing gradient\nmatching between the reconstruction loss gradients computed on synthetic and\nreal validation data, under certain assumptions. We then circumvent the problem\nof the gradient matching without real validation set by approximating it with\nthe gradient matching between each generated sample and its neighbors.\nExperimental evaluations on CIFAR-100 and ImageNet datasets demonstrate the\nsuperiority of the proposed method over the state-of-the-art techniques in\nlow-bit quantization settings.",
    "published": "2025-10-08T13:43:39Z",
    "updated": "2025-10-08T13:43:39Z",
    "link": "http://arxiv.org/pdf/2510.07018v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Dung Hoang-Anh",
      "Cuong Pham Trung Le",
      "Jianfei Cai",
      "Thanh-Toan Do"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07008v1",
    "title": "Bayesian Modelling of Multi-Year Crop Type Classification Using Deep\n  Neural Networks and Hidden Markov Models",
    "summary": "The temporal consistency of yearly land-cover maps is of great importance to\nmodel the evolution and change of the land cover over the years. In this paper,\nwe focus the attention on a novel approach to classification of yearly\nsatellite image time series (SITS) that combines deep learning with Bayesian\nmodelling, using Hidden Markov Models (HMMs) integrated with Transformer\nEncoder (TE) based DNNs. The proposed approach aims to capture both i)\nintricate temporal correlations in yearly SITS and ii) specific patterns in\nmultiyear crop type sequences. It leverages the cascade classification of an\nHMM layer built on top of the TE, discerning consistent yearly crop-type\nsequences. Validation on a multiyear crop type classification dataset spanning\n47 crop types and six years of Sentinel-2 acquisitions demonstrates the\nimportance of modelling temporal consistency in the predicted labels. HMMs\nenhance the overall performance and F1 scores, emphasising the effectiveness of\nthe proposed approach.",
    "published": "2025-10-08T13:33:32Z",
    "updated": "2025-10-08T13:33:32Z",
    "link": "http://arxiv.org/pdf/2510.07008v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Gianmarco Perantoni",
      "Giulio Weikmann",
      "Lorenzo Bruzzone"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.14230v2",
    "title": "GreedyPixel: Fine-Grained Black-Box Adversarial Attack Via Greedy\n  Algorithm",
    "summary": "Deep neural networks are highly vulnerable to adversarial examples that\ninputs with small, carefully crafted perturbations that cause\nmisclassification, making adversarial attacks an essential tool for robustness\nevaluation. Existing black-box attacks fall into three categories: query-only,\ntransfer-only, and query-and-transfer, and vary in perturbation pattern and\noptimization strategy. However, no prior method jointly achieves\nquery-and-transfer guidance, pixel-wise sparsity, and training-free direct\noptimization, leaving a gap between black-box flexibility and white-box\nprecision. We present GreedyPixel, a new attack framework that fills this gap\nby combining a surrogate-derived pixel priority map with greedy, per-pixel\noptimization refined by query feedback. This design reduces the exponential\nbrute-force search space to a tractable linear procedure, guarantees monotonic\nloss decrease and convergence to a coordinate-wise optimum, and concentrates\nperturbations on robust, semantically meaningful pixels to improve perceptual\nquality. Extensive experiments on CIFAR-10 and ImageNet under both white-box\nand black-box settings demonstrate that GreedyPixel achieves state-of-the-art\nattack success rates and produces visually imperceptible perturbations. Our\nresults show that GreedyPixel bridges the precision gap between white-box and\nblack-box attacks and provides a practical framework for fine-grained\nrobustness evaluation. The implementation is available at\nhttps://github.com/azrealwang/greedypixel.",
    "published": "2025-01-24T04:17:03Z",
    "updated": "2025-10-08T13:27:03Z",
    "link": "http://arxiv.org/pdf/2501.14230v2.pdf",
    "category": [
      "cs.CV",
      "cs.CR",
      "cs.LG"
    ],
    "authors": [
      "Hanrui Wang",
      "Ching-Chun Chang",
      "Chun-Shien Lu",
      "Christopher Leckie",
      "Isao Echizen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.19791v2",
    "title": "Color Bind: Exploring Color Perception in Text-to-Image Models",
    "summary": "Text-to-image generation has recently seen remarkable success, granting users\nwith the ability to create high-quality images through the use of text.\nHowever, contemporary methods face challenges in capturing the precise\nsemantics conveyed by complex multi-object prompts. Consequently, many works\nhave sought to mitigate such semantic misalignments, typically via\ninference-time schemes that modify the attention layers of the denoising\nnetworks. However, prior work has mostly utilized coarse metrics, such as the\ncosine similarity between text and image CLIP embeddings, or human evaluations,\nwhich are challenging to conduct on a larger-scale. In this work, we perform a\ncase study on colors -- a fundamental attribute commonly associated with\nobjects in text prompts, which offer a rich test bed for rigorous evaluation.\nOur analysis reveals that pretrained models struggle to generate images that\nfaithfully reflect multiple color attributes-far more so than with single-color\nprompts-and that neither inference-time techniques nor existing editing methods\nreliably resolve these semantic misalignments. Accordingly, we introduce a\ndedicated image editing technique, mitigating the issue of multi-object\nsemantic alignment for prompts containing multiple colors. We demonstrate that\nour approach significantly boosts performance over a wide range of metrics,\nconsidering images generated by various text-to-image diffusion-based\ntechniques.",
    "published": "2025-08-27T11:16:58Z",
    "updated": "2025-10-08T13:20:56Z",
    "link": "http://arxiv.org/pdf/2508.19791v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Shay Shomer Chai",
      "Wenxuan Peng",
      "Bharath Hariharan",
      "Hadar Averbuch-Elor"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.13430v3",
    "title": "Uncertainty-Aware Remaining Lifespan Prediction from Images",
    "summary": "Predicting mortality-related outcomes from images offers the prospect of\naccessible, noninvasive, and scalable health screening. We present a method\nthat leverages pretrained vision transformer foundation models to estimate\nremaining lifespan from facial and whole-body images, alongside robust\nuncertainty quantification. We show that predictive uncertainty varies\nsystematically with the true remaining lifespan, and that this uncertainty can\nbe effectively modeled by learning a Gaussian distribution for each sample. Our\napproach achieves state-of-the-art mean absolute error (MAE) of 7.41 years on\nan established dataset, and further achieves 4.91 and 4.99 years MAE on two\nnew, higher-quality datasets curated and published in this work. Importantly,\nour models provide calibrated uncertainty estimates, as demonstrated by a\nbucketed expected calibration error of 0.82 years on the Faces Dataset. While\nnot intended for clinical deployment, these results highlight the potential of\nextracting medically relevant signals from images. We make all code and\ndatasets available to facilitate further research.",
    "published": "2025-06-16T12:47:37Z",
    "updated": "2025-10-08T13:18:30Z",
    "link": "http://arxiv.org/pdf/2506.13430v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Tristan Kenneweg",
      "Philip Kenneweg",
      "Barbara Hammer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.20834v2",
    "title": "Fully Spiking Neural Networks for Unified Frame-Event Object Tracking",
    "summary": "The integration of image and event streams offers a promising approach for\nachieving robust visual object tracking in complex environments. However,\ncurrent fusion methods achieve high performance at the cost of significant\ncomputational overhead and struggle to efficiently extract the sparse,\nasynchronous information from event streams, failing to leverage the\nenergy-efficient advantages of event-driven spiking paradigms. To address this\nchallenge, we propose the first fully Spiking Frame-Event Tracking framework\ncalled SpikeFET. This network achieves synergistic integration of convolutional\nlocal feature extraction and Transformer-based global modeling within the\nspiking paradigm, effectively fusing frame and event data. To overcome the\ndegradation of translation invariance caused by convolutional padding, we\nintroduce a Random Patchwork Module (RPM) that eliminates positional bias\nthrough randomized spatial reorganization and learnable type encoding while\npreserving residual structures. Furthermore, we propose a Spatial-Temporal\nRegularization (STR) strategy that overcomes similarity metric degradation from\nasymmetric features by enforcing spatio-temporal consistency among temporal\ntemplate features in latent space. Extensive experiments across multiple\nbenchmarks demonstrate that the proposed framework achieves superior tracking\naccuracy over existing methods while significantly reducing power consumption,\nattaining an optimal balance between performance and efficiency.",
    "published": "2025-05-27T07:53:50Z",
    "updated": "2025-10-08T13:17:15Z",
    "link": "http://arxiv.org/pdf/2505.20834v2.pdf",
    "category": [
      "cs.CV",
      "cs.NE"
    ],
    "authors": [
      "Jingjun Yang",
      "Liangwei Fan",
      "Jinpu Zhang",
      "Xiangkai Lian",
      "Hui Shen",
      "Dewen Hu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06988v1",
    "title": "No MoCap Needed: Post-Training Motion Diffusion Models with\n  Reinforcement Learning using Only Textual Prompts",
    "summary": "Diffusion models have recently advanced human motion generation, producing\nrealistic and diverse animations from textual prompts. However, adapting these\nmodels to unseen actions or styles typically requires additional motion capture\ndata and full retraining, which is costly and difficult to scale. We propose a\npost-training framework based on Reinforcement Learning that fine-tunes\npretrained motion diffusion models using only textual prompts, without\nrequiring any motion ground truth. Our approach employs a pretrained\ntext-motion retrieval network as a reward signal and optimizes the diffusion\npolicy with Denoising Diffusion Policy Optimization, effectively shifting the\nmodel's generative distribution toward the target domain without relying on\npaired motion data. We evaluate our method on cross-dataset adaptation and\nleave-one-out motion experiments using the HumanML3D and KIT-ML datasets across\nboth latent- and joint-space diffusion architectures. Results from quantitative\nmetrics and user studies show that our approach consistently improves the\nquality and diversity of generated motions, while preserving performance on the\noriginal distribution. Our approach is a flexible, data-efficient, and\nprivacy-preserving solution for motion adaptation.",
    "published": "2025-10-08T13:12:10Z",
    "updated": "2025-10-08T13:12:10Z",
    "link": "http://arxiv.org/pdf/2510.06988v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Girolamo Macaluso",
      "Lorenzo Mandelli",
      "Mirko Bicchierai",
      "Stefano Berretti",
      "Andrew D. Bagdanov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06982v1",
    "title": "Revisiting Mixout: An Overlooked Path to Robust Finetuning",
    "summary": "Finetuning vision foundation models often improves in-domain accuracy but\ncomes at the cost of robustness under distribution shift. We revisit Mixout, a\nstochastic regularizer that intermittently replaces finetuned weights with\ntheir pretrained reference, through the lens of a single-run, weight-sharing\nimplicit ensemble. This perspective reveals three key levers that govern\nrobustness: the \\emph{masking anchor}, \\emph{resampling frequency}, and\n\\emph{mask sparsity}. Guided by this analysis, we introduce GMixout, which (i)\nreplaces the fixed anchor with an exponential moving-average snapshot that\nadapts during training, and (ii) regulates masking period via an explicit\nresampling-frequency hyperparameter. Our sparse-kernel implementation updates\nonly a small fraction of parameters with no inference-time overhead, enabling\ntraining on consumer-grade GPUs. Experiments on benchmarks covering covariate\nshift, corruption, and class imbalance, ImageNet / ImageNet-LT, DomainNet,\niWildCam, and CIFAR100-C, GMixout consistently improves in-domain accuracy\nbeyond zero-shot performance while surpassing both Model Soups and strong\nparameter-efficient finetuning baselines under distribution shift.",
    "published": "2025-10-08T13:07:50Z",
    "updated": "2025-10-08T13:07:50Z",
    "link": "http://arxiv.org/pdf/2510.06982v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Masih Aminbeidokhti",
      "Heitor Rapela Medeiros",
      "Eric Granger",
      "Marco Pedersoli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06973v1",
    "title": "Addressing the ID-Matching Challenge in Long Video Captioning",
    "summary": "Generating captions for long and complex videos is both critical and\nchallenging, with significant implications for the growing fields of\ntext-to-video generation and multi-modal understanding. One key challenge in\nlong video captioning is accurately recognizing the same individuals who appear\nin different frames, which we refer to as the ID-Matching problem. Few prior\nworks have focused on this important issue. Those that have, usually suffer\nfrom limited generalization and depend on point-wise matching, which limits\ntheir overall effectiveness. In this paper, unlike previous approaches, we\nbuild upon LVLMs to leverage their powerful priors. We aim to unlock the\ninherent ID-Matching capabilities within LVLMs themselves to enhance the\nID-Matching performance of captions. Specifically, we first introduce a new\nbenchmark for assessing the ID-Matching capabilities of video captions. Using\nthis benchmark, we investigate LVLMs containing GPT-4o, revealing key insights\nthat the performance of ID-Matching can be improved through two methods: 1)\nenhancing the usage of image information and 2) increasing the quantity of\ninformation of individual descriptions. Based on these insights, we propose a\nnovel video captioning method called Recognizing Identities for Captioning\nEffectively (RICE). Extensive experiments including assessments of caption\nquality and ID-Matching performance, demonstrate the superiority of our\napproach. Notably, when implemented on GPT-4o, our RICE improves the precision\nof ID-Matching from 50% to 90% and improves the recall of ID-Matching from 15%\nto 80% compared to baseline. RICE makes it possible to continuously track\ndifferent individuals in the captions of long videos.",
    "published": "2025-10-08T12:59:21Z",
    "updated": "2025-10-08T12:59:21Z",
    "link": "http://arxiv.org/pdf/2510.06973v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhantao Yang",
      "Huangji Wang",
      "Ruili Feng",
      "Han Zhang",
      "Yuting Hu",
      "Shangwen Zhu",
      "Junyan Li",
      "Yu Liu",
      "Fan Cheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2310.06670v2",
    "title": "Domain Generalization by Rejecting Extreme Augmentations",
    "summary": "Data augmentation is one of the most effective techniques for regularizing\ndeep learning models and improving their recognition performance in a variety\nof tasks and domains. However, this holds for standard in-domain settings, in\nwhich the training and test data follow the same distribution. For the\nout-of-domain case, where the test data follow a different and unknown\ndistribution, the best recipe for data augmentation is unclear. In this paper,\nwe show that for out-of-domain and domain generalization settings, data\naugmentation can provide a conspicuous and robust improvement in performance.\nTo do that, we propose a simple training procedure: (i) use uniform sampling on\nstandard data augmentation transformations; (ii) increase the strength\ntransformations to account for the higher data variance expected when working\nout-of-domain, and (iii) devise a new reward function to reject extreme\ntransformations that can harm the training. With this procedure, our data\naugmentation scheme achieves a level of accuracy that is comparable to or\nbetter than state-of-the-art methods on benchmark domain generalization\ndatasets. Code: https://github.com/Masseeh/DCAug",
    "published": "2023-10-10T14:46:22Z",
    "updated": "2025-10-08T12:39:46Z",
    "link": "http://arxiv.org/pdf/2310.06670v2.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Masih Aminbeidokhti",
      "Fidel A. Guerrero Peña",
      "Heitor Rapela Medeiros",
      "Thomas Dubail",
      "Eric Granger",
      "Marco Pedersoli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06955v1",
    "title": "High-Rate Mixout: Revisiting Mixout for Robust Domain Generalization",
    "summary": "Ensembling fine-tuned models initialized from powerful pre-trained weights is\na common strategy to improve robustness under distribution shifts, but it comes\nwith substantial computational costs due to the need to train and store\nmultiple models. Dropout offers a lightweight alternative by simulating\nensembles through random neuron deactivation; however, when applied to\npre-trained models, it tends to over-regularize and disrupt critical\nrepresentations necessary for generalization. In this work, we investigate\nMixout, a stochastic regularization technique that provides an alternative to\nDropout for domain generalization. Rather than deactivating neurons, Mixout\nmitigates overfitting by probabilistically swapping a subset of fine-tuned\nweights with their pre-trained counterparts during training, thereby\nmaintaining a balance between adaptation and retention of prior knowledge. Our\nstudy reveals that achieving strong performance with Mixout on domain\ngeneralization benchmarks requires a notably high masking probability of 0.9\nfor ViTs and 0.8 for ResNets. While this may seem like a simple adjustment, it\nyields two key advantages for domain generalization: (1) higher masking rates\nmore strongly penalize deviations from the pre-trained parameters, promoting\nbetter generalization to unseen domains; and (2) high-rate masking\nsubstantially reduces computational overhead, cutting gradient computation by\nup to 45% and gradient memory usage by up to 90%. Experiments across five\ndomain generalization benchmarks, PACS, VLCS, OfficeHome, TerraIncognita, and\nDomainNet, using ResNet and ViT architectures, show that our approach,\nHigh-rate Mixout, achieves out-of-domain accuracy comparable to ensemble-based\nmethods while significantly reducing training costs.",
    "published": "2025-10-08T12:37:56Z",
    "updated": "2025-10-08T12:37:56Z",
    "link": "http://arxiv.org/pdf/2510.06955v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Masih Aminbeidokhti",
      "Heitor Rapela Medeiros",
      "Eric Granger",
      "Marco Pedersoli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06952v1",
    "title": "OBJVanish: Physically Realizable Text-to-3D Adv. Generation of\n  LiDAR-Invisible Objects",
    "summary": "LiDAR-based 3D object detectors are fundamental to autonomous driving, where\nfailing to detect objects poses severe safety risks. Developing effective 3D\nadversarial attacks is essential for thoroughly testing these detection systems\nand exposing their vulnerabilities before real-world deployment. However,\nexisting adversarial attacks that add optimized perturbations to 3D points have\ntwo critical limitations: they rarely cause complete object disappearance and\nprove difficult to implement in physical environments. We introduce the\ntext-to-3D adversarial generation method, a novel approach enabling physically\nrealizable attacks that can generate 3D models of objects truly invisible to\nLiDAR detectors and be easily realized in the real world. Specifically, we\npresent the first empirical study that systematically investigates the factors\ninfluencing detection vulnerability by manipulating the topology, connectivity,\nand intensity of individual pedestrian 3D models and combining pedestrians with\nmultiple objects within the CARLA simulation environment. Building on the\ninsights, we propose the physically-informed text-to-3D adversarial generation\n(Phy3DAdvGen) that systematically optimizes text prompts by iteratively\nrefining verbs, objects, and poses to produce LiDAR-invisible pedestrians. To\nensure physical realizability, we construct a comprehensive object pool\ncontaining 13 3D models of real objects and constrain Phy3DAdvGen to generate\n3D objects based on combinations of objects in this set. Extensive experiments\ndemonstrate that our approach can generate 3D pedestrians that evade six\nstate-of-the-art (SOTA) LiDAR 3D detectors in both CARLA simulation and\nphysical environments, thereby highlighting vulnerabilities in safety-critical\napplications.",
    "published": "2025-10-08T12:35:35Z",
    "updated": "2025-10-08T12:35:35Z",
    "link": "http://arxiv.org/pdf/2510.06952v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Bing Li",
      "Wuqi Wang",
      "Yanan Zhang",
      "Jingzheng Li",
      "Haigen Min",
      "Wei Feng",
      "Xingyu Zhao",
      "Jie Zhang",
      "Qing Guo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06928v1",
    "title": "IAR2: Improving Autoregressive Visual Generation with Semantic-Detail\n  Associated Token Prediction",
    "summary": "Autoregressive models have emerged as a powerful paradigm for visual content\ncreation, but often overlook the intrinsic structural properties of visual\ndata. Our prior work, IAR, initiated a direction to address this by\nreorganizing the visual codebook based on embedding similarity, thereby\nimproving generation robustness. However, it is constrained by the rigidity of\npre-trained codebooks and the inaccuracies of hard, uniform clustering. To\novercome these limitations, we propose IAR2, an advanced autoregressive\nframework that enables a hierarchical semantic-detail synthesis process. At the\ncore of IAR2 is a novel Semantic-Detail Associated Dual Codebook, which\ndecouples image representations into a semantic codebook for global semantic\ninformation and a detail codebook for fine-grained refinements. It expands the\nquantization capacity from a linear to a polynomial scale, significantly\nenhancing expressiveness. To accommodate this dual representation, we propose a\nSemantic-Detail Autoregressive Prediction scheme coupled with a Local-Context\nEnhanced Autoregressive Head, which performs hierarchical prediction-first the\nsemantic token, then the detail token-while leveraging a local context window\nto enhance spatial coherence. Furthermore, for conditional generation, we\nintroduce a Progressive Attention-Guided Adaptive CFG mechanism that\ndynamically modulates the guidance scale for each token based on its relevance\nto the condition and its temporal position in the generation sequence,\nimproving conditional alignment without sacrificing realism. Extensive\nexperiments demonstrate that IAR2 sets a new state-of-the-art for\nautoregressive image generation, achieving a FID of 1.50 on ImageNet. Our model\nnot only surpasses previous methods in performance but also demonstrates\nsuperior computational efficiency, highlighting the effectiveness of our\nstructured, coarse-to-fine generation strategy.",
    "published": "2025-10-08T12:08:21Z",
    "updated": "2025-10-08T12:08:21Z",
    "link": "http://arxiv.org/pdf/2510.06928v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ran Yi",
      "Teng Hu",
      "Zihan Su",
      "Lizhuang Ma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06926v1",
    "title": "Label-frugal satellite image change detection with generative virtual\n  exemplar learning",
    "summary": "Change detection is a major task in remote sensing which consists in finding\nall the occurrences of changes in multi-temporal satellite or aerial images.\nThe success of existing methods, and particularly deep learning ones, is\ntributary to the availability of hand-labeled training data that capture the\nacquisition conditions and the subjectivity of the user (oracle). In this\npaper, we devise a novel change detection algorithm, based on active learning.\nThe main contribution of our work resides in a new model that measures how\nimportant is each unlabeled sample, and provides an oracle with only the most\ncritical samples (also referred to as virtual exemplars) for further labeling.\nThese exemplars are generated, using an invertible graph convnet, as the\noptimum of an adversarial loss that (i) measures representativity, diversity\nand ambiguity of the data, and thereby (ii) challenges (the most) the current\nchange detection criteria, leading to a better re-estimate of these criteria in\nthe subsequent iterations of active learning. Extensive experiments show the\npositive impact of our label-efficient learning model against comparative\nmethods.",
    "published": "2025-10-08T12:07:35Z",
    "updated": "2025-10-08T12:07:35Z",
    "link": "http://arxiv.org/pdf/2510.06926v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Hichem Sahbi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2401.01160v2",
    "title": "Train-Free Segmentation in MRI with Cubical Persistent Homology",
    "summary": "We present a new general framework for segmentation of MRI scans based on\nTopological Data Analysis (TDA), offering several advantages over traditional\nmachine learning approaches. The pipeline proceeds in three steps, first\nidentifying the whole object to segment via automatic thresholding, then\ndetecting a distinctive subset whose topology is known in advance, and finally\ndeducing the various components of the segmentation. Unlike most prior TDA uses\nin medical image segmentation, which are typically embedded within deep\nnetworks, our approach is a standalone method tailored to MRI. A key ingredient\nis the localization of representative cycles from the persistence diagram,\nwhich enables interpretable mappings from topological features to anatomical\ncomponents. In particular, the method offers the ability to perform\nsegmentation without the need for large annotated datasets. Its modular design\nmakes it adaptable to a wide range of data segmentation challenges. We validate\nthe framework on three applications: glioblastoma segmentation in brain MRI,\nwhere a sphere is to be detected; myocardium in cardiac MRI, forming a\ncylinder; and cortical plate detection in fetal brain MRI, whose 2D slices are\ncircles. We compare our method with established supervised and unsupervised\nbaselines.",
    "published": "2024-01-02T11:43:49Z",
    "updated": "2025-10-08T11:59:15Z",
    "link": "http://arxiv.org/pdf/2401.01160v2.pdf",
    "category": [
      "eess.IV",
      "cs.CG",
      "cs.CV",
      "cs.LG",
      "55N31, 68-04, 92-08, 68U10"
    ],
    "authors": [
      "Anton François",
      "Raphaël Tinarrage"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06887v1",
    "title": "Lung Infection Severity Prediction Using Transformers with Conditional\n  TransMix Augmentation and Cross-Attention",
    "summary": "Lung infections, particularly pneumonia, pose serious health risks that can\nescalate rapidly, especially during pandemics. Accurate AI-based severity\nprediction from medical imaging is essential to support timely clinical\ndecisions and optimize patient outcomes. In this work, we present a novel\nmethod applicable to both CT scans and chest X-rays for assessing lung\ninfection severity. Our contributions are twofold: (i) QCross-Att-PVT, a\nTransformer-based architecture that integrates parallel encoders, a cross-gated\nattention mechanism, and a feature aggregator to capture rich multi-scale\nfeatures; and (ii) Conditional Online TransMix, a custom data augmentation\nstrategy designed to address dataset imbalance by generating mixed-label image\npatches during training. Evaluated on two benchmark datasets, RALO CXR and\nPer-COVID-19 CT, our method consistently outperforms several state-of-the-art\ndeep learning models. The results emphasize the critical role of data\naugmentation and gated attention in improving both robustness and predictive\naccuracy. This approach offers a reliable, adaptable tool to support clinical\ndiagnosis, disease monitoring, and personalized treatment planning. The source\ncode of this work is available at https://github.com/bouthainas/QCross-Att-PVT.",
    "published": "2025-10-08T11:08:34Z",
    "updated": "2025-10-08T11:08:34Z",
    "link": "http://arxiv.org/pdf/2510.06887v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Bouthaina Slika",
      "Fadi Dornaika",
      "Fares Bougourzi",
      "Karim Hammoudi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.16679v3",
    "title": "Polyp-Gen: Realistic and Diverse Polyp Image Generation for Endoscopic\n  Dataset Expansion",
    "summary": "Automated diagnostic systems (ADS) have shown significant potential in the\nearly detection of polyps during endoscopic examinations, thereby reducing the\nincidence of colorectal cancer. However, due to high annotation costs and\nstrict privacy concerns, acquiring high-quality endoscopic images poses a\nconsiderable challenge in the development of ADS. Despite recent advancements\nin generating synthetic images for dataset expansion, existing endoscopic image\ngeneration algorithms failed to accurately generate the details of polyp\nboundary regions and typically required medical priors to specify plausible\nlocations and shapes of polyps, which limited the realism and diversity of the\ngenerated images. To address these limitations, we present Polyp-Gen, the first\nfull-automatic diffusion-based endoscopic image generation framework.\nSpecifically, we devise a spatial-aware diffusion training scheme with a\nlesion-guided loss to enhance the structural context of polyp boundary regions.\nMoreover, to capture medical priors for the localization of potential polyp\nareas, we introduce a hierarchical retrieval-based sampling strategy to match\nsimilar fine-grained spatial features. In this way, our Polyp-Gen can generate\nrealistic and diverse endoscopic images for building reliable ADS. Extensive\nexperiments demonstrate the state-of-the-art generation quality, and the\nsynthetic images can improve the downstream polyp detection task. Additionally,\nour Polyp-Gen has shown remarkable zero-shot generalizability on other\ndatasets. The source code is available at\nhttps://github.com/CUHK-AIM-Group/Polyp-Gen.",
    "published": "2025-01-28T03:25:37Z",
    "updated": "2025-10-08T10:53:54Z",
    "link": "http://arxiv.org/pdf/2501.16679v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Shengyuan Liu",
      "Zhen Chen",
      "Qiushi Yang",
      "Weihao Yu",
      "Di Dong",
      "Jiancong Hu",
      "Yixuan Yuan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06876v1",
    "title": "HARP-NeXt: High-Speed and Accurate Range-Point Fusion Network for 3D\n  LiDAR Semantic Segmentation",
    "summary": "LiDAR semantic segmentation is crucial for autonomous vehicles and mobile\nrobots, requiring high accuracy and real-time processing, especially on\nresource-constrained embedded systems. Previous state-of-the-art methods often\nface a trade-off between accuracy and speed. Point-based and sparse\nconvolution-based methods are accurate but slow due to the complexity of\nneighbor searching and 3D convolutions. Projection-based methods are faster but\nlose critical geometric information during the 2D projection. Additionally,\nmany recent methods rely on test-time augmentation (TTA) to improve\nperformance, which further slows the inference. Moreover, the pre-processing\nphase across all methods increases execution time and is demanding on embedded\nplatforms. Therefore, we introduce HARP-NeXt, a high-speed and accurate LiDAR\nsemantic segmentation network. We first propose a novel pre-processing\nmethodology that significantly reduces computational overhead. Then, we design\nthe Conv-SE-NeXt feature extraction block to efficiently capture\nrepresentations without deep layer stacking per network stage. We also employ a\nmulti-scale range-point fusion backbone that leverages information at multiple\nabstraction levels to preserve essential geometric details, thereby enhancing\naccuracy. Experiments on the nuScenes and SemanticKITTI benchmarks show that\nHARP-NeXt achieves a superior speed-accuracy trade-off compared to all\nstate-of-the-art methods, and, without relying on ensemble models or TTA, is\ncomparable to the top-ranked PTv3, while running 24$\\times$ faster. The code is\navailable at https://github.com/SamirAbouHaidar/HARP-NeXt",
    "published": "2025-10-08T10:46:07Z",
    "updated": "2025-10-08T10:46:07Z",
    "link": "http://arxiv.org/pdf/2510.06876v1.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Samir Abou Haidar",
      "Alexandre Chariot",
      "Mehdi Darouich",
      "Cyril Joly",
      "Jean-Emmanuel Deschaud"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06871v1",
    "title": "SaFeR-VLM: Toward Safety-aware Fine-grained Reasoning in Multimodal\n  Models",
    "summary": "Multimodal Large Reasoning Models (MLRMs) demonstrate impressive cross-modal\nreasoning but often amplify safety risks under adversarial or unsafe prompts, a\nphenomenon we call the \\textit{Reasoning Tax}. Existing defenses mainly act at\nthe output level and do not constrain the reasoning process, leaving models\nexposed to implicit risks. In this paper, we propose SaFeR-VLM, a\nsafety-aligned reinforcement learning framework that embeds safety directly\ninto multimodal reasoning. The framework integrates four components: (I)\nQI-Safe-10K, a curated dataset emphasizing safety-critical and\nreasoning-sensitive cases; (II) safety-aware rollout, where unsafe generations\nundergo reflection and correction instead of being discarded; (III) structured\nreward modeling with multi-dimensional weighted criteria and explicit penalties\nfor hallucinations and contradictions; and (IV) GRPO optimization, which\nreinforces both safe and corrected trajectories. This unified design shifts\nsafety from a passive safeguard to an active driver of reasoning, enabling\nscalable and generalizable safety-aware reasoning. SaFeR-VLM further\ndemonstrates robustness against both explicit and implicit risks, supporting\ndynamic and interpretable safety decisions beyond surface-level filtering.\nSaFeR-VLM-3B achieves average performance $70.13$ and $78.97$ on safety and\nhelpfulness across six benchmarks, surpassing both same-scale and $>10\\times$\nlarger models such as Skywork-R1V3-38B, Qwen2.5VL-72B, and GLM4.5V-106B.\nRemarkably, SaFeR-VLM-7B benefits from its increased scale to surpass\nGPT-5-mini and Gemini-2.5-Flash by \\num{6.47} and \\num{16.76} points\nrespectively on safety metrics, achieving this improvement without any\ndegradation in helpfulness performance. Our codes are available at\nhttps://github.com/HarveyYi/SaFeR-VLM.",
    "published": "2025-10-08T10:39:12Z",
    "updated": "2025-10-08T10:39:12Z",
    "link": "http://arxiv.org/pdf/2510.06871v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Huahui Yi",
      "Kun Wang",
      "Qiankun Li",
      "Miao Yu",
      "Liang Lin",
      "Gongli Xi",
      "Hao Wu",
      "Xuming Hu",
      "Kang Li",
      "Yang Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06855v1",
    "title": "Online Generic Event Boundary Detection",
    "summary": "Generic Event Boundary Detection (GEBD) aims to interpret long-form videos\nthrough the lens of human perception. However, current GEBD methods require\nprocessing complete video frames to make predictions, unlike humans processing\ndata online and in real-time. To bridge this gap, we introduce a new task,\nOnline Generic Event Boundary Detection (On-GEBD), aiming to detect boundaries\nof generic events immediately in streaming videos. This task faces unique\nchallenges of identifying subtle, taxonomy-free event changes in real-time,\nwithout the access to future frames. To tackle these challenges, we propose a\nnovel On-GEBD framework, Estimator, inspired by Event Segmentation Theory (EST)\nwhich explains how humans segment ongoing activity into events by leveraging\nthe discrepancies between predicted and actual information. Our framework\nconsists of two key components: the Consistent Event Anticipator (CEA), and the\nOnline Boundary Discriminator (OBD). Specifically, the CEA generates a\nprediction of the future frame reflecting current event dynamics based solely\non prior frames. Then, the OBD measures the prediction error and adaptively\nadjusts the threshold using statistical tests on past errors to capture\ndiverse, subtle event transitions. Experimental results demonstrate that\nEstimator outperforms all baselines adapted from recent online video\nunderstanding models and achieves performance comparable to prior offline-GEBD\nmethods on the Kinetics-GEBD and TAPOS datasets.",
    "published": "2025-10-08T10:23:45Z",
    "updated": "2025-10-08T10:23:45Z",
    "link": "http://arxiv.org/pdf/2510.06855v1.pdf",
    "category": [
      "cs.CV",
      "eess.IV"
    ],
    "authors": [
      "Hyungrok Jung",
      "Daneul Kim",
      "Seunggyun Lim",
      "Jeany Son",
      "Jonghyun Choi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06842v1",
    "title": "Continual Action Quality Assessment via Adaptive Manifold-Aligned Graph\n  Regularization",
    "summary": "Action Quality Assessment (AQA) quantifies human actions in videos,\nsupporting applications in sports scoring, rehabilitation, and skill\nevaluation. A major challenge lies in the non-stationary nature of quality\ndistributions in real-world scenarios, which limits the generalization ability\nof conventional methods. We introduce Continual AQA (CAQA), which equips AQA\nwith Continual Learning (CL) capabilities to handle evolving distributions\nwhile mitigating catastrophic forgetting. Although parameter-efficient\nfine-tuning of pretrained models has shown promise in CL for image\nclassification, we find it insufficient for CAQA. Our empirical and theoretical\nanalyses reveal two insights: (i) Full-Parameter Fine-Tuning (FPFT) is\nnecessary for effective representation learning; yet (ii) uncontrolled FPFT\ninduces overfitting and feature manifold shift, thereby aggravating forgetting.\nTo address this, we propose Adaptive Manifold-Aligned Graph Regularization\n(MAGR++), which couples backbone fine-tuning that stabilizes shallow layers\nwhile adapting deeper ones with a two-step feature rectification pipeline: a\nmanifold projector to translate deviated historical features into the current\nrepresentation space, and a graph regularizer to align local and global\ndistributions. We construct four CAQA benchmarks from three datasets with\ntailored evaluation protocols and strong baselines, enabling systematic\ncross-dataset comparison. Extensive experiments show that MAGR++ achieves\nstate-of-the-art performance, with average correlation gains of 3.6% offline\nand 12.2% online over the strongest baseline, confirming its robustness and\neffectiveness. Our code is available at https://github.com/ZhouKanglei/MAGRPP.",
    "published": "2025-10-08T10:09:47Z",
    "updated": "2025-10-08T10:09:47Z",
    "link": "http://arxiv.org/pdf/2510.06842v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Kanglei Zhou",
      "Qingyi Pan",
      "Xingxing Zhang",
      "Hubert P. H. Shum",
      "Frederick W. B. Li",
      "Xiaohui Liang",
      "Liyuan Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06829v1",
    "title": "Lattice-allocated Real-time Line Segment Feature Detection and Tracking\n  Using Only an Event-based Camera",
    "summary": "Line segment extraction is effective for capturing geometric features of\nhuman-made environments. Event-based cameras, which asynchronously respond to\ncontrast changes along edges, enable efficient extraction by reducing redundant\ndata. However, recent methods often rely on additional frame cameras or\nstruggle with high event rates. This research addresses real-time line segment\ndetection and tracking using only a modern, high-resolution (i.e., high event\nrate) event-based camera. Our lattice-allocated pipeline consists of (i)\nvelocity-invariant event representation, (ii) line segment detection based on a\nfitting score, (iii) and line segment tracking by perturbating endpoints.\nEvaluation using ad-hoc recorded dataset and public datasets demonstrates\nreal-time performance and higher accuracy compared to state-of-the-art\nevent-only and event-frame hybrid baselines, enabling fully stand-alone event\ncamera operation in real-world settings.",
    "published": "2025-10-08T09:52:35Z",
    "updated": "2025-10-08T09:52:35Z",
    "link": "http://arxiv.org/pdf/2510.06829v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Mikihiro Ikura",
      "Arren Glover",
      "Masayoshi Mizuno",
      "Chiara Bartolozzi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06827v1",
    "title": "StyleKeeper: Prevent Content Leakage using Negative Visual Query\n  Guidance",
    "summary": "In the domain of text-to-image generation, diffusion models have emerged as\npowerful tools. Recently, studies on visual prompting, where images are used as\nprompts, have enabled more precise control over style and content. However,\nexisting methods often suffer from content leakage, where undesired elements of\nthe visual style prompt are transferred along with the intended style. To\naddress this issue, we 1) extend classifier-free guidance (CFG) to utilize\nswapping self-attention and propose 2) negative visual query guidance (NVQG) to\nreduce the transfer of unwanted contents. NVQG employs negative score by\nintentionally simulating content leakage scenarios that swap queries instead of\nkey and values of self-attention layers from visual style prompts. This simple\nyet effective method significantly reduces content leakage. Furthermore, we\nprovide careful solutions for using a real image as visual style prompts.\nThrough extensive evaluation across various styles and text prompts, our method\ndemonstrates superiority over existing approaches, reflecting the style of the\nreferences, and ensuring that resulting images match the text prompts. Our code\nis available \\href{https://github.com/naver-ai/StyleKeeper}{here}.",
    "published": "2025-10-08T09:50:34Z",
    "updated": "2025-10-08T09:50:34Z",
    "link": "http://arxiv.org/pdf/2510.06827v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jaeseok Jeong",
      "Junho Kim",
      "Gayoung Lee",
      "Yunjey Choi",
      "Youngjung Uh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06820v1",
    "title": "Efficient Discriminative Joint Encoders for Large Scale Vision-Language\n  Reranking",
    "summary": "Multimodal retrieval still leans on embedding-based models like CLIP for fast\nvector search over pre-computed image embeddings. Yet, unlike text retrieval,\nwhere joint-encoder rerankers are standard, comparable vision--language\nrerankers are largely absent. We find that seminal joint encoders such as BLIP\nare severely bottlenecked by an expensive visual feature-extraction stage,\npreventing practical deployment at scale. Motivated by this bottleneck, we\nintroduce EDJE, an Efficient Discriminative Joint Encoder that precomputes\nvision tokens offline and compresses them via a lightweight attention-based\nadapter, so online inference runs only a compact joint encoder over a small set\nof visual tokens plus the text. EDJE preserves strong retrieval performance\nwhile drastically reducing storage and online compute, enabling high-throughput\ninference. Specifically, EDJE processes 50k image--text pairs/second while\nrequiring 49kB of disk storage per image, matching prior art on Flickr\n(zero-shot) and COCO (fine-tuned) retrieval. The implementation and checkpoints\nwill be made publicly available shortly.",
    "published": "2025-10-08T09:46:09Z",
    "updated": "2025-10-08T09:46:09Z",
    "link": "http://arxiv.org/pdf/2510.06820v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Mitchell Keren Taraday",
      "Shahaf Wagner",
      "Chaim Baskin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06809v1",
    "title": "VA-Adapter: Adapting Ultrasound Foundation Model to Echocardiography\n  Probe Guidance",
    "summary": "Echocardiography is a critical tool for detecting heart diseases. Recently,\nultrasound foundation models have demonstrated remarkable capabilities in\ncardiac ultrasound image analysis. However, obtaining high-quality ultrasound\nimages is a prerequisite for accurate diagnosis. Due to the exceptionally high\noperational difficulty of cardiac ultrasound, there is a shortage of highly\nskilled personnel, which hinders patients from receiving timely examination\nservices. In this paper, we aim to adapt the medical knowledge learned by\nfoundation models from vast datasets to the probe guidance task, which is\ndesigned to provide real-time operational recommendations for junior\nsonographers to acquire high-quality ultrasound images. Moreover, inspired by\nthe practice where experts optimize action decisions based on past\nexplorations, we meticulously design a parameter-efficient Vision-Action\nAdapter (VA-Adapter) to enable foundation model's image encoder to encode\nvision-action sequences, thereby enhancing guidance performance. With built-in\nsequential reasoning capabilities in a compact design, the VA-Adapter enables a\npre-trained ultrasound foundation model to learn precise probe adjustment\nstrategies by fine-tuning only a small subset of parameters. Extensive\nexperiments demonstrate that the VA-Adapter can surpass strong probe guidance\nmodels. Our code will be released after acceptance.",
    "published": "2025-10-08T09:38:30Z",
    "updated": "2025-10-08T09:38:30Z",
    "link": "http://arxiv.org/pdf/2510.06809v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Teng Wang",
      "Haojun Jiang",
      "Yuxuan Wang",
      "Zhenguo Sun",
      "Shiji Song",
      "Gao Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06802v1",
    "title": "Capture and Interact: Rapid 3D Object Acquisition and Rendering with\n  Gaussian Splatting in Unity",
    "summary": "Capturing and rendering three-dimensional (3D) objects in real time remain a\nsignificant challenge, yet hold substantial potential for applications in\naugmented reality, digital twin systems, remote collaboration and prototyping.\nWe present an end-to-end pipeline that leverages 3D Gaussian Splatting (3D GS)\nto enable rapid acquisition and interactive rendering of real-world objects\nusing a mobile device, cloud processing and a local computer. Users scan an\nobject with a smartphone video, upload it for automated 3D reconstruction, and\nvisualize it interactively in Unity at an average of 150 frames per second\n(fps) on a laptop. The system integrates mobile capture, cloud-based 3D GS and\nUnity rendering to support real-time telepresence. Our experiments show that\nthe pipeline processes scans in approximately 10 minutes on a graphics\nprocessing unit (GPU) achieving real-time rendering on the laptop.",
    "published": "2025-10-08T09:31:29Z",
    "updated": "2025-10-08T09:31:29Z",
    "link": "http://arxiv.org/pdf/2510.06802v1.pdf",
    "category": [
      "cs.GR",
      "cs.CV"
    ],
    "authors": [
      "Islomjon Shukhratov",
      "Sergey Gorinsky"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06784v1",
    "title": "Bionetta: Efficient Client-Side Zero-Knowledge Machine Learning Proving",
    "summary": "In this report, we compare the performance of our UltraGroth-based\nzero-knowledge machine learning framework Bionetta to other tools of similar\npurpose such as EZKL, Lagrange's deep-prove, or zkml. The results show a\nsignificant boost in the proving time for custom-crafted neural networks: they\ncan be proven even on mobile devices, enabling numerous client-side proving\napplications. While our scheme increases the cost of one-time preprocessing\nsteps, such as circuit compilation and generating trusted setup, our approach\nis, to the best of our knowledge, the only one that is deployable on the native\nEVM smart contracts without overwhelming proof size and verification overheads.",
    "published": "2025-10-08T09:10:32Z",
    "updated": "2025-10-08T09:10:32Z",
    "link": "http://arxiv.org/pdf/2510.06784v1.pdf",
    "category": [
      "cs.CR",
      "cs.CV"
    ],
    "authors": [
      "Dmytro Zakharov",
      "Oleksandr Kurbatov",
      "Artem Sdobnov",
      "Lev Soukhanov",
      "Yevhenii Sekhin",
      "Vitalii Volovyk",
      "Mykhailo Velykodnyi",
      "Mark Cherepovskyi",
      "Kyrylo Baibula",
      "Lasha Antadze",
      "Pavlo Kravchenko",
      "Volodymyr Dubinin",
      "Yaroslav Panasenko"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06783v1",
    "title": "TTRV: Test-Time Reinforcement Learning for Vision Language Models",
    "summary": "Existing methods for extracting reward signals in Reinforcement Learning\ntypically rely on labeled data and dedicated training splits, a setup that\ncontrasts with how humans learn directly from their environment. In this work,\nwe propose TTRV to enhance vision language understanding by adapting the model\non the fly at inference time, without the need for any labeled data.\nConcretely, we enhance the Group Relative Policy Optimization (GRPO) framework\nby designing rewards based on the frequency of the base model's output, while\ninferring on each test sample multiple times. Further, we also propose to\ncontrol the diversity of the model's output by simultaneously rewarding the\nmodel for obtaining low entropy of the output empirical distribution. Our\napproach delivers consistent gains across both object recognition and visual\nquestion answering (VQA), with improvements of up to 52.4% and 29.8%,\nrespectively, and average boosts of 24.6% and 10.0% across 16\ndatasets.Remarkably, on image recognition, TTRV applied to InternVL 8B\nsurpasses GPT-4o by an average of 2.3% over 8 benchmarks, while remaining\nhighly competitive on VQA, demonstrating that test-time reinforcement learning\ncan match or exceed the strongest proprietary models. Finally, we find many\ninteresting properties of test-time RL for VLMs: for example, even in extremely\ndata-constrained scenarios, where adaptation is performed on a single randomly\nchosen unlabeled test example, TTRV still yields non-trivial improvements of up\nto 5.5% in recognition tasks.",
    "published": "2025-10-08T09:10:31Z",
    "updated": "2025-10-08T09:10:31Z",
    "link": "http://arxiv.org/pdf/2510.06783v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Akshit Singh",
      "Shyam Marjit",
      "Wei Lin",
      "Paul Gavrikov",
      "Serena Yeung-Levy",
      "Hilde Kuehne",
      "Rogerio Feris",
      "Sivan Doveh",
      "James Glass",
      "M. Jehanzeb Mirza"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06782v1",
    "title": "GPT-5 Model Corrected GPT-4V's Chart Reading Errors, Not Prompting",
    "summary": "We present a quantitative evaluation to understand the effect of zero-shot\nlarge-language model (LLMs) and prompting uses on chart reading tasks. We asked\nLLMs to answer 107 visualization questions to compare inference accuracies\nbetween the agentic GPT-5 and multimodal GPT-4V, for difficult image instances,\nwhere GPT-4V failed to produce correct answers. Our results show that model\narchitecture dominates the inference accuracy: GPT5 largely improved accuracy,\nwhile prompt variants yielded only small effects. Pre-registration of this work\nis available here:\nhttps://osf.io/u78td/?view_only=6b075584311f48e991c39335c840ded3; the Google\nDrive materials are\nhere:https://drive.google.com/file/d/1ll8WWZDf7cCNcfNWrLViWt8GwDNSvVrp/view.",
    "published": "2025-10-08T09:09:29Z",
    "updated": "2025-10-08T09:09:29Z",
    "link": "http://arxiv.org/pdf/2510.06782v1.pdf",
    "category": [
      "cs.HC",
      "cs.CL",
      "cs.CV"
    ],
    "authors": [
      "Kaichun Yang",
      "Jian Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.05759v2",
    "title": "OneVision: An End-to-End Generative Framework for Multi-view E-commerce\n  Vision Search",
    "summary": "Traditional vision search, similar to search and recommendation systems,\nfollows the multi-stage cascading architecture (MCA) paradigm to balance\nefficiency and conversion. Specifically, the query image undergoes feature\nextraction, recall, pre-ranking, and ranking stages, ultimately presenting the\nuser with semantically similar products that meet their preferences. This\nmulti-view representation discrepancy of the same object in the query and the\noptimization objective collide across these stages, making it difficult to\nachieve Pareto optimality in both user experience and conversion. In this\npaper, an end-to-end generative framework, OneVision, is proposed to address\nthese problems. OneVision builds on VRQ, a vision-aligned residual quantization\nencoding, which can align the vastly different representations of an object\nacross multiple viewpoints while preserving the distinctive features of each\nproduct as much as possible. Then a multi-stage semantic alignment scheme is\nadopted to maintain strong visual similarity priors while effectively\nincorporating user-specific information for personalized preference generation.\nIn offline evaluations, OneVision performs on par with online MCA, while\nimproving inference efficiency by 21% through dynamic pruning. In A/B tests, it\nachieves significant online improvements: +2.15% item CTR, +2.27% CVR, and\n+3.12% order volume. These results demonstrate that a semantic ID centric,\ngenerative architecture can unify retrieval and personalization while\nsimplifying the serving pathway.",
    "published": "2025-10-07T10:25:21Z",
    "updated": "2025-10-08T09:02:25Z",
    "link": "http://arxiv.org/pdf/2510.05759v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zexin Zheng",
      "Huangyu Dai",
      "Lingtao Mao",
      "Xinyu Sun",
      "Zihan Liang",
      "Ben Chen",
      "Yuqing Ding",
      "Chenyi Lei",
      "Wenwu Ou",
      "Han Li",
      "Kun Gai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06769v1",
    "title": "A deep multiple instance learning approach based on coarse labels for\n  high-resolution land-cover mapping",
    "summary": "The quantity and the quality of the training labels are central problems in\nhigh-resolution land-cover mapping with machine-learning-based solutions. In\nthis context, weak labels can be gathered in large quantities by leveraging on\nexisting low-resolution or obsolete products. In this paper, we address the\nproblem of training land-cover classifiers using high-resolution imagery (e.g.,\nSentinel-2) and weak low-resolution reference data (e.g., MODIS -derived\nland-cover maps). Inspired by recent works in Deep Multiple Instance Learning\n(DMIL), we propose a method that trains pixel-level multi-class classifiers and\npredicts low-resolution labels (i.e., patch-level classification), where the\nactual high-resolution labels are learned implicitly without direct\nsupervision. This is achieved with flexible pooling layers that are able to\nlink the semantics of the pixels in the high-resolution imagery to the\nlow-resolution reference labels. Then, the Multiple Instance Learning (MIL)\nproblem is re-framed in a multi-class and in a multi-label setting. In the\nformer, the low-resolution annotation represents the majority of the pixels in\nthe patch. In the latter, the annotation only provides us information on the\npresence of one of the land-cover classes in the patch and thus multiple labels\ncan be considered valid for a patch at a time, whereas the low-resolution\nlabels provide us only one label. Therefore, the classifier is trained with a\nPositive-Unlabeled Learning (PUL) strategy. Experimental results on the 2020\nIEEE GRSS Data Fusion Contest dataset show the effectiveness of the proposed\nframework compared to standard training strategies.",
    "published": "2025-10-08T08:50:39Z",
    "updated": "2025-10-08T08:50:39Z",
    "link": "http://arxiv.org/pdf/2510.06769v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Gianmarco Perantoni",
      "Lorenzo Bruzzone"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06757v1",
    "title": "Transforming Noise Distributions with Histogram Matching: Towards a\n  Single Denoiser for All",
    "summary": "Supervised Gaussian denoisers exhibit limited generalization when confronted\nwith out-of-distribution noise, due to the diverse distributional\ncharacteristics of different noise types. To bridge this gap, we propose a\nhistogram matching approach that transforms arbitrary noise towards a target\nGaussian distribution with known intensity. Moreover, a mutually reinforcing\ncycle is established between noise transformation and subsequent denoising.\nThis cycle progressively refines the noise to be converted, making it\napproximate the real noise, thereby enhancing the noise transformation effect\nand further improving the denoising performance. We tackle specific noise\ncomplexities: local histogram matching handles signal-dependent noise,\nintrapatch permutation processes channel-related noise, and frequency-domain\nhistogram matching coupled with pixel-shuffle down-sampling breaks spatial\ncorrelation. By applying these transformations, a single Gaussian denoiser\ngains remarkable capability to handle various out-of-distribution noises,\nincluding synthetic noises such as Poisson, salt-and-pepper and repeating\npattern noises, as well as complex real-world noises. Extensive experiments\ndemonstrate the superior generalization and effectiveness of our method.",
    "published": "2025-10-08T08:34:50Z",
    "updated": "2025-10-08T08:34:50Z",
    "link": "http://arxiv.org/pdf/2510.06757v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Sheng Fu",
      "Junchao Zhang",
      "Kailun Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2409.10353v3",
    "title": "Taming Diffusion Models for Image Restoration: A Review",
    "summary": "Diffusion models have achieved remarkable progress in generative modelling,\nparticularly in enhancing image quality to conform to human preferences.\nRecently, these models have also been applied to low-level computer vision for\nphoto-realistic image restoration (IR) in tasks such as image denoising,\ndeblurring, dehazing, etc. In this review paper, we introduce key constructions\nin diffusion models and survey contemporary techniques that make use of\ndiffusion models in solving general IR tasks. Furthermore, we point out the\nmain challenges and limitations of existing diffusion-based IR frameworks and\nprovide potential directions for future work.",
    "published": "2024-09-16T15:04:14Z",
    "updated": "2025-10-08T08:32:38Z",
    "link": "http://arxiv.org/pdf/2409.10353v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ziwei Luo",
      "Fredrik K. Gustafsson",
      "Zheng Zhao",
      "Jens Sjölund",
      "Thomas B. Schön"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06754v1",
    "title": "UniFField: A Generalizable Unified Neural Feature Field for Visual,\n  Semantic, and Spatial Uncertainties in Any Scene",
    "summary": "Comprehensive visual, geometric, and semantic understanding of a 3D scene is\ncrucial for successful execution of robotic tasks, especially in unstructured\nand complex environments. Additionally, to make robust decisions, it is\nnecessary for the robot to evaluate the reliability of perceived information.\nWhile recent advances in 3D neural feature fields have enabled robots to\nleverage features from pretrained foundation models for tasks such as\nlanguage-guided manipulation and navigation, existing methods suffer from two\ncritical limitations: (i) they are typically scene-specific, and (ii) they lack\nthe ability to model uncertainty in their predictions. We present UniFField, a\nunified uncertainty-aware neural feature field that combines visual, semantic,\nand geometric features in a single generalizable representation while also\npredicting uncertainty in each modality. Our approach, which can be applied\nzero shot to any new environment, incrementally integrates RGB-D images into\nour voxel-based feature representation as the robot explores the scene,\nsimultaneously updating uncertainty estimation. We evaluate our uncertainty\nestimations to accurately describe the model prediction errors in scene\nreconstruction and semantic feature prediction. Furthermore, we successfully\nleverage our feature predictions and their respective uncertainty for an active\nobject search task using a mobile manipulator robot, demonstrating the\ncapability for robust decision-making.",
    "published": "2025-10-08T08:30:26Z",
    "updated": "2025-10-08T08:30:26Z",
    "link": "http://arxiv.org/pdf/2510.06754v1.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Christian Maurer",
      "Snehal Jauhri",
      "Sophie Lueth",
      "Georgia Chalvatzaki"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06751v1",
    "title": "OBS-Diff: Accurate Pruning For Diffusion Models in One-Shot",
    "summary": "Large-scale text-to-image diffusion models, while powerful, suffer from\nprohibitive computational cost. Existing one-shot network pruning methods can\nhardly be directly applied to them due to the iterative denoising nature of\ndiffusion models. To bridge the gap, this paper presents OBS-Diff, a novel\none-shot pruning framework that enables accurate and training-free compression\nof large-scale text-to-image diffusion models. Specifically, (i) OBS-Diff\nrevitalizes the classic Optimal Brain Surgeon (OBS), adapting it to the complex\narchitectures of modern diffusion models and supporting diverse pruning\ngranularity, including unstructured, N:M semi-structured, and structured (MHA\nheads and FFN neurons) sparsity; (ii) To align the pruning criteria with the\niterative dynamics of the diffusion process, by examining the problem from an\nerror-accumulation perspective, we propose a novel timestep-aware Hessian\nconstruction that incorporates a logarithmic-decrease weighting scheme,\nassigning greater importance to earlier timesteps to mitigate potential error\naccumulation; (iii) Furthermore, a computationally efficient group-wise\nsequential pruning strategy is proposed to amortize the expensive calibration\nprocess. Extensive experiments show that OBS-Diff achieves state-of-the-art\none-shot pruning for diffusion models, delivering inference acceleration with\nminimal degradation in visual quality.",
    "published": "2025-10-08T08:19:15Z",
    "updated": "2025-10-08T08:19:15Z",
    "link": "http://arxiv.org/pdf/2510.06751v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Junhan Zhu",
      "Hesong Wang",
      "Mingluo Su",
      "Zefang Wang",
      "Huan Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.24001v2",
    "title": "Gaze Estimation for Human-Robot Interaction: Analysis Using the NICO\n  Platform",
    "summary": "This paper evaluates the current gaze estimation methods within an HRI\ncontext of a shared workspace scenario. We introduce a new, annotated dataset\ncollected with the NICO robotic platform. We evaluate four state-of-the-art\ngaze estimation models. The evaluation shows that the angular errors are close\nto those reported on general-purpose benchmarks. However, when expressed in\nterms of distance in the shared workspace the best median error is 16.48 cm\nquantifying the practical limitations of current methods. We conclude by\ndiscussing these limitations and offering recommendations on how to best\nintegrate gaze estimation as a modality in HRI systems.",
    "published": "2025-09-28T17:49:27Z",
    "updated": "2025-10-08T08:13:31Z",
    "link": "http://arxiv.org/pdf/2509.24001v2.pdf",
    "category": [
      "cs.CV",
      "cs.RO",
      "I.4.9"
    ],
    "authors": [
      "Matej Palider",
      "Omar Eldardeer",
      "Viktor Kocur"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06746v1",
    "title": "DeRainMamba: A Frequency-Aware State Space Model with Detail Enhancement\n  for Image Deraining",
    "summary": "Image deraining is crucial for improving visual quality and supporting\nreliable downstream vision tasks. Although Mamba-based models provide efficient\nsequence modeling, their limited ability to capture fine-grained details and\nlack of frequency-domain awareness restrict further improvements. To address\nthese issues, we propose DeRainMamba, which integrates a Frequency-Aware\nState-Space Module (FASSM) and Multi-Directional Perception Convolution\n(MDPConv). FASSM leverages Fourier transform to distinguish rain streaks from\nhigh-frequency image details, balancing rain removal and detail preservation.\nMDPConv further restores local structures by capturing anisotropic gradient\nfeatures and efficiently fusing multiple convolution branches. Extensive\nexperiments on four public benchmarks demonstrate that DeRainMamba consistently\noutperforms state-of-the-art methods in PSNR and SSIM, while requiring fewer\nparameters and lower computational costs. These results validate the\neffectiveness of combining frequency-domain modeling and spatial detail\nenhancement within a state-space framework for single image deraining.",
    "published": "2025-10-08T08:05:11Z",
    "updated": "2025-10-08T08:05:11Z",
    "link": "http://arxiv.org/pdf/2510.06746v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhiliang Zhu",
      "Tao Zeng",
      "Tao Yang",
      "Guoliang Luo",
      "Jiyong Zeng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.21143v2",
    "title": "The Percept-V Challenge: Can Multimodal LLMs Crack Simple Perception\n  Problems?",
    "summary": "Cognitive science research treats visual perception, the ability to\nunderstand and make sense of a visual input, as one of the early developmental\nsigns of intelligence. Its TVPS-4 framework categorizes and tests human\nperception into seven skills such as visual discrimination, and form constancy.\nDo Multimodal Large Language Models (MLLMs) match up to humans in basic\nperception? Even though there are many benchmarks that evaluate MLLMs on\nadvanced reasoning and knowledge skills, there is limited research that focuses\nevaluation on simple perception. In response, we introduce Percept-V, a dataset\ncontaining 6000 program-generated uncontaminated images divided into 30\ndomains, where each domain tests one or more TVPS-4 skills. Our focus is on\nperception, so we make our domains quite simple and the reasoning and knowledge\nrequired for solving them are minimal. Since modern-day MLLMs can solve much\nmore complex tasks, our a-priori expectation is that they will solve these\ndomains very easily. Contrary to our belief, our experiments show a weak\nperformance of SoTA proprietary and open-source MLLMs compared to very high\nhuman performance on Percept-V. We find that as number of objects in the image\nincreases, performance goes down rather fast. Our experiments also identify the\nperception skills that are considerably harder for all models.",
    "published": "2025-08-28T18:22:38Z",
    "updated": "2025-10-08T07:49:55Z",
    "link": "http://arxiv.org/pdf/2508.21143v2.pdf",
    "category": [
      "cs.CL",
      "cs.CV"
    ],
    "authors": [
      "Samrajnee Ghosh",
      "Naman Agarwal",
      "Hemanshu Garg",
      "Chinmay Mittal",
      " Mausam",
      "Parag Singla"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.01004v6",
    "title": "Adaptive Rank, Reduced Forgetting: Knowledge Retention in Continual\n  Learning Vision-Language Models with Dynamic Rank-Selective LoRA",
    "summary": "Continual learning (CL) aims to accumulate knowledge from sequential tasks\nwithout catastrophic forgetting. Vision-language models such as CLIP, with\nstrong generalization, are widely used for CL. Existing methods often adapt\nisolated PTM components, increasing inference complexity and limiting model\nimprovement, or rely on replay, stored data, or assumptions, leading to high\ncosts and limited applicability. To advance models as continual learners, we\nexplore CL through natural and efficient PTM updates rather than complex\ntask-specific additions. We study continual low-rank learning and analyze how\nLoRA ranks and placements affect learning and forgetting. A higher-rank LoRA\nimproves task learning (plasticity) but increases forgetting, while a\nlower-rank LoRA enhances stability but limits adaptation. We observe a\nplasticity-stability balance tied to rank across parameters and tasks, with\nmoderately small ranks maximizing CL benefits. Motivated by this, we propose\nContinual Dynamic Rank-Selective LoRA (CoDyRA), which continually updates PTMs\nwith LoRA adapters of adaptively optimized ranks. The new-task objective drives\nlearning, while sparsity-promoting regularization minimizes ranks to reduce\ninterference and forgetting, achieving a balance tailored to each parameter and\ntask. Although all parameters are updated, the minimized ranks keep the model\nclose to its prior state while enabling effective new-task learning. CoDyRA\nperforms efficient CL as a sequence of LoRA-based updates without storing past\ndata or relying on assumptions, preserving the original model architecture and\nadding no inference overhead. Experiments show CoDyRA improves new\nrepresentations while retaining old knowledge, achieving state-of-the-art\nresults. Code is available at https://github.com/jeff024/codyra.",
    "published": "2024-12-01T23:41:42Z",
    "updated": "2025-10-08T07:30:38Z",
    "link": "http://arxiv.org/pdf/2412.01004v6.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Haodong Lu",
      "Chongyang Zhao",
      "Jason Xue",
      "Lina Yao",
      "Kristen Moore",
      "Dong Gong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.05886v2",
    "title": "acia-workflows: Automated Single-cell Imaging Analysis for Scalable and\n  Deep Learning-based Live-cell Imaging Analysis Workflows",
    "summary": "Live-cell imaging (LCI) technology enables the detailed spatio-temporal\ncharacterization of living cells at the single-cell level, which is critical\nfor advancing research in the life sciences, from biomedical applications to\nbioprocessing. High-throughput setups with tens to hundreds of parallel cell\ncultivations offer the potential for robust and reproducible insights. However,\nthese insights are obscured by the large amount of LCI data recorded per\nexperiment. Recent advances in state-of-the-art deep learning methods for cell\nsegmentation and tracking now enable the automated analysis of such large data\nvolumes, offering unprecedented opportunities to systematically study\nsingle-cell dynamics. The next key challenge lies in integrating these powerful\ntools into accessible, flexible, and user-friendly workflows that support\nroutine application in biological research. In this work, we present\nacia-workflows, a platform that combines three key components: (1) the\nAutomated live-Cell Imaging Analysis (acia) Python library, which supports the\nmodular design of image analysis pipelines offering eight deep learning\nsegmentation and tracking approaches; (2) workflows that assemble the image\nanalysis pipeline, its software dependencies, documentation, and visualizations\ninto a single Jupyter Notebook, leading to accessible, reproducible and\nscalable analysis workflows; and (3) a collection of application workflows\nshowcasing the analysis and customization capabilities in real-world\napplications. Specifically, we present three workflows to investigate various\ntypes of microfluidic LCI experiments ranging from growth rate comparisons to\nprecise, minute-resolution quantitative analyses of individual dynamic cells\nresponses to changing oxygen conditions. Our collection of more than ten\napplication workflows is open source and publicly available at\nhttps://github.com/JuBiotech/acia-workflows.",
    "published": "2025-10-07T12:58:11Z",
    "updated": "2025-10-08T07:05:37Z",
    "link": "http://arxiv.org/pdf/2510.05886v2.pdf",
    "category": [
      "cs.CV",
      "q-bio.QM"
    ],
    "authors": [
      "Johannes Seiffarth",
      "Keitaro Kasahara",
      "Michelle Bund",
      "Benita Lückel",
      "Richard D. Paul",
      "Matthias Pesch",
      "Lennart Witting",
      "Michael Bott",
      "Dietrich Kohlheyer",
      "Katharina Nöh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.25033v2",
    "title": "VT-FSL: Bridging Vision and Text with LLMs for Few-Shot Learning",
    "summary": "Few-shot learning (FSL) aims to recognize novel concepts from only a few\nlabeled support samples. Recent studies enhance support features by\nincorporating additional semantic information or designing complex semantic\nfusion modules. However, they still suffer from hallucinating semantics that\ncontradict the visual evidence due to the lack of grounding in actual\ninstances, resulting in noisy guidance and costly corrections. To address these\nissues, we propose a novel framework, bridging Vision and Text with LLMs for\nFew-Shot Learning (VT-FSL), which constructs precise cross-modal prompts\nconditioned on Large Language Models (LLMs) and support images, seamlessly\nintegrating them through a geometry-aware alignment. It mainly consists of\nCross-modal Iterative Prompting (CIP) and Cross-modal Geometric Alignment\n(CGA). Specifically, the CIP conditions an LLM on both class names and support\nimages to generate precise class descriptions iteratively in a single\nstructured reasoning pass. These descriptions not only enrich the semantic\nunderstanding of novel classes but also enable the zero-shot synthesis of\nsemantically consistent images. The descriptions and synthetic images act\nrespectively as complementary textual and visual prompts, providing high-level\nclass semantics and low-level intra-class diversity to compensate for limited\nsupport data. Furthermore, the CGA jointly aligns the fused textual, support,\nand synthetic visual representations by minimizing the kernelized volume of the\n3-dimensional parallelotope they span. It captures global and nonlinear\nrelationships among all representations, enabling structured and consistent\nmultimodal integration. The proposed VT-FSL method establishes new\nstate-of-the-art performance across ten diverse benchmarks, including standard,\ncross-domain, and fine-grained few-shot learning scenarios. Code is available\nat https://github.com/peacelwh/VT-FSL.",
    "published": "2025-09-29T16:52:47Z",
    "updated": "2025-10-08T06:46:28Z",
    "link": "http://arxiv.org/pdf/2509.25033v2.pdf",
    "category": [
      "cs.CV",
      "cs.LG",
      "I.4.9"
    ],
    "authors": [
      "Wenhao Li",
      "Qiangchang Wang",
      "Xianjing Meng",
      "Zhibin Wu",
      "Yilong Yin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06694v1",
    "title": "SCas4D: Structural Cascaded Optimization for Boosting Persistent 4D\n  Novel View Synthesis",
    "summary": "Persistent dynamic scene modeling for tracking and novel-view synthesis\nremains challenging due to the difficulty of capturing accurate deformations\nwhile maintaining computational efficiency. We propose SCas4D, a cascaded\noptimization framework that leverages structural patterns in 3D Gaussian\nSplatting for dynamic scenes. The key idea is that real-world deformations\noften exhibit hierarchical patterns, where groups of Gaussians share similar\ntransformations. By progressively refining deformations from coarse part-level\nto fine point-level, SCas4D achieves convergence within 100 iterations per time\nframe and produces results comparable to existing methods with only\none-twentieth of the training iterations. The approach also demonstrates\neffectiveness in self-supervised articulated object segmentation, novel view\nsynthesis, and dense point tracking tasks.",
    "published": "2025-10-08T06:39:33Z",
    "updated": "2025-10-08T06:39:33Z",
    "link": "http://arxiv.org/pdf/2510.06694v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jipeng Lyu",
      "Jiahua Dong",
      "Yu-Xiong Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.25191v2",
    "title": "VGGT-X: When VGGT Meets Dense Novel View Synthesis",
    "summary": "We study the problem of applying 3D Foundation Models (3DFMs) to dense Novel\nView Synthesis (NVS). Despite significant progress in Novel View Synthesis\npowered by NeRF and 3DGS, current approaches remain reliant on accurate 3D\nattributes (e.g., camera poses and point clouds) acquired from\nStructure-from-Motion (SfM), which is often slow and fragile in low-texture or\nlow-overlap captures. Recent 3DFMs showcase orders of magnitude speedup over\nthe traditional pipeline and great potential for online NVS. But most of the\nvalidation and conclusions are confined to sparse-view settings. Our study\nreveals that naively scaling 3DFMs to dense views encounters two fundamental\nbarriers: dramatically increasing VRAM burden and imperfect outputs that\ndegrade initialization-sensitive 3D training. To address these barriers, we\nintroduce VGGT-X, incorporating a memory-efficient VGGT implementation that\nscales to 1,000+ images, an adaptive global alignment for VGGT output\nenhancement, and robust 3DGS training practices. Extensive experiments show\nthat these measures substantially close the fidelity gap with\nCOLMAP-initialized pipelines, achieving state-of-the-art results in dense\nCOLMAP-free NVS and pose estimation. Additionally, we analyze the causes of\nremaining gaps with COLMAP-initialized rendering, providing insights for the\nfuture development of 3D foundation models and dense NVS. Our project page is\navailable at https://dekuliutesla.github.io/vggt-x.github.io/",
    "published": "2025-09-29T17:59:59Z",
    "updated": "2025-10-08T06:29:47Z",
    "link": "http://arxiv.org/pdf/2509.25191v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yang Liu",
      "Chuanchen Luo",
      "Zimo Tang",
      "Junran Peng",
      "Zhaoxiang Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.05899v2",
    "title": "Efficient Universal Models for Medical Image Segmentation via Weakly\n  Supervised In-Context Learning",
    "summary": "Universal models for medical image segmentation, such as interactive and\nin-context learning (ICL) models, offer strong generalization but require\nextensive annotations. Interactive models need repeated user prompts for each\nimage, while ICL relies on dense, pixel-level labels. To address this, we\npropose Weakly Supervised In-Context Learning (WS-ICL), a new ICL paradigm that\nleverages weak prompts (e.g., bounding boxes or points) instead of dense labels\nfor context. This approach significantly reduces annotation effort by\neliminating the need for fine-grained masks and repeated user prompting for all\nimages. We evaluated the proposed WS-ICL model on three held-out benchmarks.\nExperimental results demonstrate that WS-ICL achieves performance comparable to\nregular ICL models at a significantly lower annotation cost. In addition,\nWS-ICL is highly competitive even under the interactive paradigm. These\nfindings establish WS-ICL as a promising step toward more efficient and unified\nuniversal models for medical image segmentation. Our code and model are\npublicly available at https://github.com/jiesihu/Weak-ICL.",
    "published": "2025-10-07T13:07:27Z",
    "updated": "2025-10-08T06:26:50Z",
    "link": "http://arxiv.org/pdf/2510.05899v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jiesi Hu",
      "Yanwu Yang",
      "Zhiyu Ye",
      "Jinyan Zhou",
      "Jianfeng Cao",
      "Hanyang Peng",
      "Ting Ma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06679v1",
    "title": "DreamOmni2: Multimodal Instruction-based Editing and Generation",
    "summary": "Recent advancements in instruction-based image editing and subject-driven\ngeneration have garnered significant attention, yet both tasks still face\nlimitations in meeting practical user needs. Instruction-based editing relies\nsolely on language instructions, which often fail to capture specific editing\ndetails, making reference images necessary. Meanwhile, subject-driven\ngeneration is limited to combining concrete objects or people, overlooking\nbroader, abstract concepts. To address these challenges, we propose two novel\ntasks: multimodal instruction-based editing and generation. These tasks support\nboth text and image instructions and extend the scope to include both concrete\nand abstract concepts, greatly enhancing their practical applications. We\nintroduce DreamOmni2, tackling two primary challenges: data creation and model\nframework design. Our data synthesis pipeline consists of three steps: (1)\nusing a feature mixing method to create extraction data for both abstract and\nconcrete concepts, (2) generating multimodal instruction-based editing training\ndata using the editing and extraction models, and (3) further applying the\nextraction model to create training data for multimodal instruction-based\nediting. For the framework, to handle multi-image input, we propose an index\nencoding and position encoding shift scheme, which helps the model distinguish\nimages and avoid pixel confusion. Additionally, we introduce joint training\nwith the VLM and our generation/editing model to better process complex\ninstructions. In addition, we have proposed comprehensive benchmarks for these\ntwo new tasks to drive their development. Experiments show that DreamOmni2 has\nachieved impressive results. Models and codes will be released.",
    "published": "2025-10-08T06:07:14Z",
    "updated": "2025-10-08T06:07:14Z",
    "link": "http://arxiv.org/pdf/2510.06679v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Bin Xia",
      "Bohao Peng",
      "Yuechen Zhang",
      "Junjia Huang",
      "Jiyang Liu",
      "Jingyao Li",
      "Haoru Tan",
      "Sitong Wu",
      "Chengyao Wang",
      "Yitong Wang",
      "Xinglong Wu",
      "Bei Yu",
      "Jiaya Jia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.15690v3",
    "title": "DWTGS: Rethinking Frequency Regularization for Sparse-view 3D Gaussian\n  Splatting",
    "summary": "Sparse-view 3D Gaussian Splatting (3DGS) presents significant challenges in\nreconstructing high-quality novel views, as it often overfits to the\nwidely-varying high-frequency (HF) details of the sparse training views. While\nfrequency regularization can be a promising approach, its typical reliance on\nFourier transforms causes difficult parameter tuning and biases towards\ndetrimental HF learning. We propose DWTGS, a framework that rethinks frequency\nregularization by leveraging wavelet-space losses that provide additional\nspatial supervision. Specifically, we supervise only the low-frequency (LF) LL\nsubbands at multiple DWT levels, while enforcing sparsity on the HF HH subband\nin a self-supervised manner. Experiments across benchmarks show that DWTGS\nconsistently outperforms Fourier-based counterparts, as this LF-centric\nstrategy improves generalization and reduces HF hallucinations.",
    "published": "2025-07-21T14:56:46Z",
    "updated": "2025-10-08T05:29:45Z",
    "link": "http://arxiv.org/pdf/2507.15690v3.pdf",
    "category": [
      "cs.CV",
      "eess.IV",
      "eess.SP"
    ],
    "authors": [
      "Hung Nguyen",
      "Runfa Li",
      "An Le",
      "Truong Nguyen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.22970v2",
    "title": "Robot Learning from Any Images",
    "summary": "We introduce RoLA, a framework that transforms any in-the-wild image into an\ninteractive, physics-enabled robotic environment. Unlike previous methods, RoLA\noperates directly on a single image without requiring additional hardware or\ndigital assets. Our framework democratizes robotic data generation by producing\nmassive visuomotor robotic demonstrations within minutes from a wide range of\nimage sources, including camera captures, robotic datasets, and Internet\nimages. At its core, our approach combines a novel method for single-view\nphysical scene recovery with an efficient visual blending strategy for\nphotorealistic data collection. We demonstrate RoLA's versatility across\napplications like scalable robotic data generation and augmentation, robot\nlearning from Internet images, and single-image real-to-sim-to-real systems for\nmanipulators and humanoids. Video results are available at\nhttps://sihengz02.github.io/RoLA .",
    "published": "2025-09-26T22:10:34Z",
    "updated": "2025-10-08T05:05:48Z",
    "link": "http://arxiv.org/pdf/2509.22970v2.pdf",
    "category": [
      "cs.RO",
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Siheng Zhao",
      "Jiageng Mao",
      "Wei Chow",
      "Zeyu Shangguan",
      "Tianheng Shi",
      "Rong Xue",
      "Yuxi Zheng",
      "Yijia Weng",
      "Yang You",
      "Daniel Seita",
      "Leonidas Guibas",
      "Sergey Zakharov",
      "Vitor Guizilini",
      "Yue Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.05615v2",
    "title": "TFM Dataset: A Novel Multi-task Dataset and Integrated Pipeline for\n  Automated Tear Film Break-Up Segmentation",
    "summary": "Tear film break-up (TFBU) analysis is critical for diagnosing dry eye\nsyndrome, but automated TFBU segmentation remains challenging due to the lack\nof annotated datasets and integrated solutions. This paper introduces the Tear\nFilm Multi-task (TFM) Dataset, the first comprehensive dataset for multi-task\ntear film analysis, comprising 15 high-resolution videos (totaling 6,247\nframes) annotated with three vision tasks: frame-level classification ('clear',\n'closed', 'broken', 'blur'), Placido Ring detection, and pixel-wise TFBU area\nsegmentation. Leveraging this dataset, we first propose TF-Net, a novel and\nefficient baseline segmentation model. TF-Net incorporates a MobileOne-mini\nbackbone with re-parameterization techniques and an enhanced feature pyramid\nnetwork to achieve a favorable balance between accuracy and computational\nefficiency for real-time clinical applications. We further establish benchmark\nperformance on the TFM segmentation subset by comparing TF-Net against several\nstate-of-the-art medical image segmentation models. Furthermore, we design\nTF-Collab, a novel integrated real-time pipeline that synergistically leverages\nmodels trained on all three tasks of the TFM dataset. By sequentially\norchestrating frame classification for BUT determination, pupil region\nlocalization for input standardization, and TFBU segmentation, TF-Collab fully\nautomates the analysis. Experimental results demonstrate the effectiveness of\nthe proposed TF-Net and TF-Collab, providing a foundation for future research\nin ocular surface diagnostics. Our code and the TFM datasets are available at\nhttps://github.com/glory-wan/TF-Net",
    "published": "2025-10-07T06:45:38Z",
    "updated": "2025-10-08T04:45:51Z",
    "link": "http://arxiv.org/pdf/2510.05615v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Guangrong Wan",
      "Jun liu",
      "Qiyang Zhou",
      "Tang tang",
      "Lianghao Shi",
      "Wenjun Luo",
      "TingTing Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06635v1",
    "title": "StruSR: Structure-Aware Symbolic Regression with Physics-Informed Taylor\n  Guidance",
    "summary": "Symbolic regression aims to find interpretable analytical expressions by\nsearching over mathematical formula spaces to capture underlying system\nbehavior, particularly in scientific modeling governed by physical laws.\nHowever, traditional methods lack mechanisms for extracting structured physical\npriors from time series observations, making it difficult to capture symbolic\nexpressions that reflect the system's global behavior. In this work, we propose\na structure-aware symbolic regression framework, called StruSR, that leverages\ntrained Physics-Informed Neural Networks (PINNs) to extract locally structured\nphysical priors from time series data. By performing local Taylor expansions on\nthe outputs of the trained PINN, we obtain derivative-based structural\ninformation to guide symbolic expression evolution. To assess the importance of\nexpression components, we introduce a masking-based attribution mechanism that\nquantifies each subtree's contribution to structural alignment and physical\nresidual reduction. These sensitivity scores steer mutation and crossover\noperations within genetic programming, preserving substructures with high\nphysical or structural significance while selectively modifying less\ninformative components. A hybrid fitness function jointly minimizes physics\nresiduals and Taylor coefficient mismatch, ensuring consistency with both the\ngoverning equations and the local analytical behavior encoded by the PINN.\nExperiments on benchmark PDE systems demonstrate that StruSR improves\nconvergence speed, structural fidelity, and expression interpretability\ncompared to conventional baselines, offering a principled paradigm for\nphysics-grounded symbolic discovery.",
    "published": "2025-10-08T04:37:04Z",
    "updated": "2025-10-08T04:37:04Z",
    "link": "http://arxiv.org/pdf/2510.06635v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Yunpeng Gong",
      "Sihan Lan",
      "Can Yang",
      "Kunpeng Xu",
      "Min Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.20444v2",
    "title": "HoPE: Hybrid of Position Embedding for Long Context Vision-Language\n  Models",
    "summary": "Vision-Language Models (VLMs) have made significant progress in multimodal\ntasks. However, their performance often deteriorates in long-context scenarios,\nparticularly long videos. While Rotary Position Embedding (RoPE) has been\nwidely adopted for length generalization in Large Language Models (LLMs),\nextending vanilla RoPE to capture the intricate spatial-temporal dependencies\nin videos remains an unsolved challenge. Existing methods typically allocate\ndifferent frequencies within RoPE to encode 3D positional information. However,\nthese allocation strategies mainly rely on heuristics, lacking in-depth\ntheoretical analysis. In this paper, we first study how different allocation\nstrategies impact the long-context capabilities of VLMs. Our analysis reveals\nthat current multimodal RoPEs fail to reliably capture semantic similarities\nover extended contexts. To address this issue, we propose HoPE, a Hybrid of\nPosition Embedding designed to improve the long-context capabilities of VLMs.\nHoPE introduces a hybrid frequency allocation strategy for reliable semantic\nmodeling over arbitrarily long contexts, and a dynamic temporal scaling\nmechanism to facilitate robust learning and flexible inference across diverse\ncontext lengths. Extensive experiments across four video benchmarks on long\nvideo understanding and retrieval tasks demonstrate that HoPE consistently\noutperforms existing methods, confirming its effectiveness. Our code is\navailable at https://github.com/hrlics/HoPE.",
    "published": "2025-05-26T18:37:40Z",
    "updated": "2025-10-08T04:28:29Z",
    "link": "http://arxiv.org/pdf/2505.20444v2.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Haoran Li",
      "Yingjie Qin",
      "Baoyuan Ou",
      "Lai Xu",
      "Ruiwen Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06629v1",
    "title": "Unsupervised Backdoor Detection and Mitigation for Spiking Neural\n  Networks",
    "summary": "Spiking Neural Networks (SNNs) have gained increasing attention for their\nsuperior energy efficiency compared to Artificial Neural Networks (ANNs).\nHowever, their security aspects, particularly under backdoor attacks, have\nreceived limited attention. Existing defense methods developed for ANNs perform\npoorly or can be easily bypassed in SNNs due to their event-driven and temporal\ndependencies. This paper identifies the key blockers that hinder traditional\nbackdoor defenses in SNNs and proposes an unsupervised post-training detection\nframework, Temporal Membrane Potential Backdoor Detection (TMPBD), to overcome\nthese challenges. TMPBD leverages the maximum margin statistics of temporal\nmembrane potential (TMP) in the final spiking layer to detect target labels\nwithout any attack knowledge or data access. We further introduce a robust\nmitigation mechanism, Neural Dendrites Suppression Backdoor Mitigation (NDSBM),\nwhich clamps dendritic connections between early convolutional layers to\nsuppress malicious neurons while preserving benign behaviors, guided by TMP\nextracted from a small, clean, unlabeled dataset. Extensive experiments on\nmultiple neuromorphic benchmarks and state-of-the-art input-aware dynamic\ntrigger attacks demonstrate that TMPBD achieves 100% detection accuracy, while\nNDSBM reduces the attack success rate from 100% to 8.44%, and to 2.81% when\ncombined with detection, without degrading clean accuracy.",
    "published": "2025-10-08T04:25:35Z",
    "updated": "2025-10-08T04:25:35Z",
    "link": "http://arxiv.org/pdf/2510.06629v1.pdf",
    "category": [
      "cs.CR",
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Jiachen Li",
      "Bang Wu",
      "Xiaoyu Xia",
      "Xiaoning Liu",
      "Xun Yi",
      "Xiuzhen Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.04022v3",
    "title": "Video-in-the-Loop: Span-Grounded Long Video QA with Interleaved\n  Reasoning",
    "summary": "We present \\emph{Video-in-the-Loop} (ViTL), a two-stage long-video QA\nframework that preserves a fixed token budget by first \\emph{localizing}\nquestion-relevant interval(s) with a low-fps skim and then \\emph{answering} via\nspan-aware reallocation of visual tokens at higher effective frame rate,\nemitting an interleaved output with both spans and the final option for direct\nattribution. We also introduce \\dataname{}, which converts description based\nevent graphs into \\emph{span-grounded} multiple-choice QA by pairing each\nquestion with \\emph{ground-truth} time span(s) and related reasoning. ViTL is\ntrained end-to-end with an interleaved group-relative objective that couples\ntemporal IoU for localization with answer correctness, allowing credit to flow\nfrom answers back to spans without increasing compute. Under fixed token\nbudgets, ViTL attains up to 8.6% with 50% less frame input on long-video QA and\ntemporal grounding (e.g., Charades-STA, ActivityNet-Captions) and ablations\nshow that span-aware token reallocation consistently surpasses uniform\nsampling. Together, \\dataname{} and ViTL provide an interpretable,\ncompute-efficient recipe for scalable long-video QA.",
    "published": "2025-10-05T04:03:31Z",
    "updated": "2025-10-08T04:05:20Z",
    "link": "http://arxiv.org/pdf/2510.04022v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Chendong Wang",
      "Donglin Bai",
      "Yifan Yang",
      "Xiao Jin",
      "Anlan Zhang",
      "Rui Wang",
      "Shiqi Jiang",
      "Yuqing Yang",
      "Hao Wu",
      "Qi Dai",
      "Chong Luo",
      "Ting Cao",
      "Lili Qiu",
      "Suman Banerjee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06621v1",
    "title": "FEAorta: A Fully Automated Framework for Finite Element Analysis of the\n  Aorta From 3D CT Images",
    "summary": "Aortic aneurysm disease ranks consistently in the top 20 causes of death in\nthe U.S. population. Thoracic aortic aneurysm is manifested as an abnormal\nbulging of thoracic aortic wall and it is a leading cause of death in adults.\nFrom the perspective of biomechanics, rupture occurs when the stress acting on\nthe aortic wall exceeds the wall strength. Wall stress distribution can be\nobtained by computational biomechanical analyses, especially structural Finite\nElement Analysis. For risk assessment, probabilistic rupture risk of TAA can be\ncalculated by comparing stress with material strength using a material failure\nmodel. Although these engineering tools are currently available for TAA rupture\nrisk assessment on patient specific level, clinical adoption has been limited\ndue to two major barriers: labor intensive 3D reconstruction current patient\nspecific anatomical modeling still relies on manual segmentation, making it\ntime consuming and difficult to scale to a large patient population, and\ncomputational burden traditional FEA simulations are resource intensive and\nincompatible with time sensitive clinical workflows. The second barrier was\nsuccessfully overcome by our team through the development of the PyTorch FEA\nlibrary and the FEA DNN integration framework. By incorporating the FEA\nfunctionalities within PyTorch FEA and applying the principle of static\ndeterminacy, we reduced the FEA based stress computation time to approximately\nthree minutes per case. Moreover, by integrating DNN and FEA through the\nPyTorch FEA library, our approach further decreases the computation time to\nonly a few seconds per case. This work focuses on overcoming the first barrier\nthrough the development of an end to end deep neural network capable of\ngenerating patient specific finite element meshes of the aorta directly from 3D\nCT images.",
    "published": "2025-10-08T04:00:46Z",
    "updated": "2025-10-08T04:00:46Z",
    "link": "http://arxiv.org/pdf/2510.06621v1.pdf",
    "category": [
      "eess.IV",
      "cs.CE",
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Jiasong Chen",
      "Linchen Qian",
      "Ruonan Gong",
      "Christina Sun",
      "Tongran Qin",
      "Thuy Pham",
      "Caitlin Martin",
      "Mohammad Zafar",
      "John Elefteriades",
      "Wei Sun",
      "Liang Liang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06619v1",
    "title": "MSITrack: A Challenging Benchmark for Multispectral Single Object\n  Tracking",
    "summary": "Visual object tracking in real-world scenarios presents numerous challenges\nincluding occlusion, interference from similar objects and complex\nbackgrounds-all of which limit the effectiveness of RGB-based trackers.\nMultispectral imagery, which captures pixel-level spectral reflectance,\nenhances target discriminability. However, the availability of multispectral\ntracking datasets remains limited. To bridge this gap, we introduce MSITrack,\nthe largest and most diverse multispectral single object tracking dataset to\ndate. MSITrack offers the following key features: (i) More Challenging\nAttributes-including interference from similar objects and similarity in color\nand texture between targets and backgrounds in natural scenarios, along with a\nwide range of real-world tracking challenges; (ii) Richer and More Natural\nScenes-spanning 55 object categories and 300 distinct natural scenes, MSITrack\nfar exceeds the scope of existing benchmarks. Many of these scenes and\ncategories are introduced to the multispectral tracking domain for the first\ntime; (iii) Larger Scale-300 videos comprising over 129k frames of\nmultispectral imagery. To ensure annotation precision, each frame has undergone\nmeticulous processing, manual labeling and multi-stage verification. Extensive\nevaluations using representative trackers demonstrate that the multispectral\ndata in MSITrack significantly improves performance over RGB-only baselines,\nhighlighting its potential to drive future advancements in the field. The\nMSITrack dataset is publicly available at:\nhttps://github.com/Fengtao191/MSITrack.",
    "published": "2025-10-08T03:56:36Z",
    "updated": "2025-10-08T03:56:36Z",
    "link": "http://arxiv.org/pdf/2510.06619v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Tao Feng",
      "Tingfa Xu",
      "Haolin Qin",
      "Tianhao Li",
      "Shuaihao Han",
      "Xuyang Zou",
      "Zhan Lv",
      "Jianan Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06612v1",
    "title": "A Bridge from Audio to Video: Phoneme-Viseme Alignment Allows Every Face\n  to Speak Multiple Languages",
    "summary": "Speech-driven talking face synthesis (TFS) focuses on generating lifelike\nfacial animations from audio input. Current TFS models perform well in English\nbut unsatisfactorily in non-English languages, producing wrong mouth shapes and\nrigid facial expressions. The terrible performance is caused by the\nEnglish-dominated training datasets and the lack of cross-language\ngeneralization abilities. Thus, we propose Multilingual Experts (MuEx), a novel\nframework featuring a Phoneme-Guided Mixture-of-Experts (PG-MoE) architecture\nthat employs phonemes and visemes as universal intermediaries to bridge audio\nand video modalities, achieving lifelike multilingual TFS. To alleviate the\ninfluence of linguistic differences and dataset bias, we extract audio and\nvideo features as phonemes and visemes respectively, which are the basic units\nof speech sounds and mouth movements. To address audiovisual synchronization\nissues, we introduce the Phoneme-Viseme Alignment Mechanism (PV-Align), which\nestablishes robust cross-modal correspondences between phonemes and visemes. In\naddition, we build a Multilingual Talking Face Benchmark (MTFB) comprising 12\ndiverse languages with 95.04 hours of high-quality videos for training and\nevaluating multilingual TFS performance. Extensive experiments demonstrate that\nMuEx achieves superior performance across all languages in MTFB and exhibits\neffective zero-shot generalization to unseen languages without additional\ntraining.",
    "published": "2025-10-08T03:46:39Z",
    "updated": "2025-10-08T03:46:39Z",
    "link": "http://arxiv.org/pdf/2510.06612v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zibo Su",
      "Kun Wei",
      "Jiahua Li",
      "Xu Yang",
      "Cheng Deng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06611v1",
    "title": "Self-supervised Physics-guided Model with Implicit Representation\n  Regularization for Fast MRI Reconstruction",
    "summary": "Magnetic Resonance Imaging (MRI) is a vital clinical diagnostic tool, yet its\nwidespread application is limited by prolonged scan times. Fast MRI\nreconstruction techniques effectively reduce acquisition duration by\nreconstructing high-fidelity MR images from undersampled k-space data. In\nrecent years, deep learning-based methods have demonstrated remarkable progress\nin this field, with self-supervised and unsupervised learning approaches\nproving particularly valuable in scenarios where fully sampled data are\ndifficult to obtain. This paper proposes a novel zero-shot self-supervised\nreconstruction framework named UnrollINR, which enables scan-specific MRI\nreconstruction without relying on external training data. The method adopts a\nphysics-guided unrolled iterative reconstruction architecture and introduces\nImplicit Neural Representation (INR) as a regularization prior to effectively\nconstrain the solution space. By combining a deep unrolled structure with the\npowerful implicit representation capability of INR, the model's\ninterpretability and reconstruction performance are enhanced. Experimental\nresults demonstrate that even at a high acceleration rate of 10, UnrollINR\nachieves superior reconstruction performance compared to the supervised\nlearning method, validating the superiority of the proposed method.",
    "published": "2025-10-08T03:40:40Z",
    "updated": "2025-10-08T03:40:40Z",
    "link": "http://arxiv.org/pdf/2510.06611v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jingran Xu",
      "Yuanyuan Liu",
      "Yanjie Zhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2403.04066v2",
    "title": "LoDisc: Learning Global-Local Discriminative Features for\n  Self-Supervised Fine-Grained Visual Recognition",
    "summary": "The self-supervised contrastive learning strategy has attracted considerable\nattention due to its exceptional ability in representation learning. However,\ncurrent contrastive learning tends to learn global coarse-grained\nrepresentations of the image that benefit generic object recognition, whereas\nsuch coarse-grained features are insufficient for fine-grained visual\nrecognition. In this paper, we incorporate subtle local fine-grained feature\nlearning into global self-supervised contrastive learning through a pure\nself-supervised global-local fine-grained contrastive learning framework.\nSpecifically, a novel pretext task called local discrimination (LoDisc) is\nproposed to explicitly supervise the self-supervised model's focus toward local\npivotal regions, which are captured by a simple but effective location-wise\nmask sampling strategy. We show that the LoDisc pretext task can effectively\nenhance fine-grained clues in important local regions and that the global-local\nframework further refines the fine-grained feature representations of images.\nExtensive experimental results on different fine-grained object recognition\ntasks demonstrate that the proposed method can lead to a decent improvement in\ndifferent evaluation settings. The proposed method is also effective for\ngeneral object recognition tasks.",
    "published": "2024-03-06T21:36:38Z",
    "updated": "2025-10-08T03:39:09Z",
    "link": "http://arxiv.org/pdf/2403.04066v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jialu Shi",
      "Zhiqiang Wei",
      "Jie Nie",
      "Lei Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06601v1",
    "title": "AIM 2025 Challenge on Real-World RAW Image Denoising",
    "summary": "We introduce the AIM 2025 Real-World RAW Image Denoising Challenge, aiming to\nadvance efficient and effective denoising techniques grounded in data\nsynthesis. The competition is built upon a newly established evaluation\nbenchmark featuring challenging low-light noisy images captured in the wild\nusing five different DSLR cameras. Participants are tasked with developing\nnovel noise synthesis pipelines, network architectures, and training\nmethodologies to achieve high performance across different camera models.\nWinners are determined based on a combination of performance metrics, including\nfull-reference measures (PSNR, SSIM, LPIPS), and non-reference ones (ARNIQA,\nTOPIQ). By pushing the boundaries of camera-agnostic low-light RAW image\ndenoising trained on synthetic data, the competition promotes the development\nof robust and practical models aligned with the rapid progress in digital\nphotography. We expect the competition outcomes to influence multiple domains,\nfrom image restoration to night-time autonomous driving.",
    "published": "2025-10-08T03:22:42Z",
    "updated": "2025-10-08T03:22:42Z",
    "link": "http://arxiv.org/pdf/2510.06601v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Feiran Li",
      "Jiacheng Li",
      "Marcos V. Conde",
      "Beril Besbinar",
      "Vlad Hosu",
      "Daisuke Iso",
      "Radu Timofte"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06592v1",
    "title": "Adaptive Stain Normalization for Cross-Domain Medical Histology",
    "summary": "Deep learning advances have revolutionized automated digital pathology\nanalysis. However, differences in staining protocols and imaging conditions can\nintroduce significant color variability. In deep learning, such color\ninconsistency often reduces performance when deploying models on data acquired\nunder different conditions from the training data, a challenge known as domain\nshift. Many existing methods attempt to address this problem via color\nnormalization but suffer from several notable drawbacks such as introducing\nartifacts or requiring careful choice of a template image for stain mapping. To\naddress these limitations, we propose a trainable color normalization model\nthat can be integrated with any backbone network for downstream tasks such as\nobject detection and classification. Based on the physics of the imaging\nprocess per the Beer-Lambert law, our model architecture is derived via\nalgorithmic unrolling of a nonnegative matrix factorization (NMF) model to\nextract stain-invariant structural information from the original pathology\nimages, which serves as input for further processing. Experimentally, we\nevaluate the method on publicly available pathology datasets and an internally\ncurated collection of malaria blood smears for cross-domain object detection\nand classification, where our method outperforms many state-of-the-art stain\nnormalization methods. Our code is available at\nhttps://github.com/xutianyue/BeerLaNet.",
    "published": "2025-10-08T02:53:28Z",
    "updated": "2025-10-08T02:53:28Z",
    "link": "http://arxiv.org/pdf/2510.06592v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Tianyue Xu",
      "Yanlin Wu",
      "Abhai K. Tripathi",
      "Matthew M. Ippolito",
      "Benjamin D. Haeffele"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06590v1",
    "title": "Ming-UniVision: Joint Image Understanding and Generation with a Unified\n  Continuous Tokenizer",
    "summary": "Visual tokenization remains a core challenge in unifying visual understanding\nand generation within the autoregressive paradigm. Existing methods typically\nemploy tokenizers in discrete latent spaces to align with the tokens from large\nlanguage models, where the quantization errors can limit semantic\nexpressiveness and degrade the capability of vision-language understanding. To\naddress this, we introduce MingTok, a new family of visual tokenizers with a\ncontinuous latent space, for unified autoregressive generation and\nunderstanding. While understanding tasks favor discriminative high-dimensional\nfeatures, generation tasks prefer compact low-level codes. Thus, to reconcile\nthese competing demands, MingTok adopts a three-stage sequential architecture\ninvolving low-level encoding, semantic expansion, and visual reconstruction.\nBuilt on top of it, Ming-UniVision eliminates the need for task-specific visual\nrepresentations, and unifies diverse vision-language tasks under a single\nautoregrsssive prediction paradigm. By formulating both understanding and\ngeneration as next-token prediction in a shared continuous space, it seamlessly\nsupports multi-round, in-context tasks such as iterative understanding,\ngeneration and editing. Empirically, we find that using a unified continuous\nvisual representation reconciles the competing requirements on the tokenizers\nby the understanding and generation tasks, thereby leading to state-of-the-art\nlevel performance across both domains. We hope our findings will facilitate\nunified visual tokenization in the continuous domain. Inference code and model\nweights are released to benefit community.",
    "published": "2025-10-08T02:50:14Z",
    "updated": "2025-10-08T02:50:14Z",
    "link": "http://arxiv.org/pdf/2510.06590v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ziyuan Huang",
      "DanDan Zheng",
      "Cheng Zou",
      "Rui Liu",
      "Xiaolong Wang",
      "Kaixiang Ji",
      "Weilong Chai",
      "Jianxin Sun",
      "Libin Wang",
      "Yongjie Lv",
      "Taozhi Huang",
      "Jiajia Liu",
      "Qingpei Guo",
      "Ming Yang",
      "Jingdong Chen",
      "Jun Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06584v1",
    "title": "Improving Artifact Robustness for CT Deep Learning Models Without\n  Labeled Artifact Images via Domain Adaptation",
    "summary": "Deep learning models which perform well on images from their training\ndistribution can degrade substantially when applied to new distributions. If a\nCT scanner introduces a new artifact not present in the training labels, the\nmodel may misclassify the images. Although modern CT scanners include design\nfeatures which mitigate these artifacts, unanticipated or difficult-to-mitigate\nartifacts can still appear in practice. The direct solution of labeling images\nfrom this new distribution can be costly. As a more accessible alternative,\nthis study evaluates domain adaptation as an approach for training models that\nmaintain classification performance despite new artifacts, even without\ncorresponding labels. We simulate ring artifacts from detector gain error in\nsinogram space and evaluate domain adversarial neural networks (DANN) against\nbaseline and augmentation-based approaches on the OrganAMNIST abdominal CT\ndataset. Our results demonstrate that baseline models trained only on clean\nimages fail to generalize to images with ring artifacts, and traditional\naugmentation with other distortion types provides no improvement on unseen\nartifact domains. In contrast, the DANN approach successfully maintains high\nclassification accuracy on ring artifact images using only unlabeled artifact\ndata during training, demonstrating the viability of domain adaptation for\nartifact robustness. The domain-adapted model achieved classification\nperformance on ring artifact test data comparable to models explicitly trained\nwith labeled artifact images, while also showing unexpected generalization to\nuniform noise. These findings provide empirical evidence that domain adaptation\ncan effectively address distribution shift in medical imaging without requiring\nexpensive expert labeling of new artifact distributions, suggesting promise for\ndeployment in clinical settings where novel artifacts may emerge.",
    "published": "2025-10-08T02:27:09Z",
    "updated": "2025-10-08T02:27:09Z",
    "link": "http://arxiv.org/pdf/2510.06584v1.pdf",
    "category": [
      "cs.CV",
      "q-bio.TO"
    ],
    "authors": [
      "Justin Cheung",
      "Samuel Savine",
      "Calvin Nguyen",
      "Lin Lu",
      "Alhassan S. Yasin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06582v1",
    "title": "Through the Perspective of LiDAR: A Feature-Enriched and\n  Uncertainty-Aware Annotation Pipeline for Terrestrial Point Cloud\n  Segmentation",
    "summary": "Accurate semantic segmentation of terrestrial laser scanning (TLS) point\nclouds is limited by costly manual annotation. We propose a semi-automated,\nuncertainty-aware pipeline that integrates spherical projection, feature\nenrichment, ensemble learning, and targeted annotation to reduce labeling\neffort, while sustaining high accuracy. Our approach projects 3D points to a 2D\nspherical grid, enriches pixels with multi-source features, and trains an\nensemble of segmentation networks to produce pseudo-labels and uncertainty\nmaps, the latter guiding annotation of ambiguous regions. The 2D outputs are\nback-projected to 3D, yielding densely annotated point clouds supported by a\nthree-tier visualization suite (2D feature maps, 3D colorized point clouds, and\ncompact virtual spheres) for rapid triage and reviewer guidance. Using this\npipeline, we build Mangrove3D, a semantic segmentation TLS dataset for mangrove\nforests. We further evaluate data efficiency and feature importance to address\ntwo key questions: (1) how much annotated data are needed and (2) which\nfeatures matter most. Results show that performance saturates after ~12\nannotated scans, geometric features contribute the most, and compact\nnine-channel stacks capture nearly all discriminative power, with the mean\nIntersection over Union (mIoU) plateauing at around 0.76. Finally, we confirm\nthe generalization of our feature-enrichment strategy through cross-dataset\ntests on ForestSemantic and Semantic3D.\n  Our contributions include: (i) a robust, uncertainty-aware TLS annotation\npipeline with visualization tools; (ii) the Mangrove3D dataset; and (iii)\nempirical guidance on data efficiency and feature importance, thus enabling\nscalable, high-quality segmentation of TLS point clouds for ecological\nmonitoring and beyond. The dataset and processing scripts are publicly\navailable at https://fz-rit.github.io/through-the-lidars-eye/.",
    "published": "2025-10-08T02:25:59Z",
    "updated": "2025-10-08T02:25:59Z",
    "link": "http://arxiv.org/pdf/2510.06582v1.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Fei Zhang",
      "Rob Chancia",
      "Josie Clapp",
      "Amirhossein Hassanzadeh",
      "Dimah Dera",
      "Richard MacKenzie",
      "Jan van Aardt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.03538v3",
    "title": "Robust Neural Rendering in the Wild with Asymmetric Dual 3D Gaussian\n  Splatting",
    "summary": "3D reconstruction from in-the-wild images remains a challenging task due to\ninconsistent lighting conditions and transient distractors. Existing methods\ntypically rely on heuristic strategies to handle the low-quality training data,\nwhich often struggle to produce stable and consistent reconstructions,\nfrequently resulting in visual artifacts. In this work, we propose\n\\modelname{}, a novel framework that leverages the stochastic nature of these\nartifacts: they tend to vary across different training runs due to minor\nrandomness. Specifically, our method trains two 3D Gaussian Splatting (3DGS)\nmodels in parallel, enforcing a consistency constraint that encourages\nconvergence on reliable scene geometry while suppressing inconsistent\nartifacts. To prevent the two models from collapsing into similar failure modes\ndue to confirmation bias, we introduce a divergent masking strategy that\napplies two complementary masks: a multi-cue adaptive mask and a\nself-supervised soft mask, which leads to an asymmetric training process of the\ntwo models, reducing shared error modes. In addition, to improve the efficiency\nof model training, we introduce a lightweight variant called Dynamic EMA Proxy,\nwhich replaces one of the two models with a dynamically updated Exponential\nMoving Average (EMA) proxy, and employs an alternating masking strategy to\npreserve divergence. Extensive experiments on challenging real-world datasets\ndemonstrate that our method consistently outperforms existing approaches while\nachieving high efficiency. See the project website at\nhttps://steveli88.github.io/AsymGS.",
    "published": "2025-06-04T03:40:33Z",
    "updated": "2025-10-08T02:13:12Z",
    "link": "http://arxiv.org/pdf/2506.03538v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Chengqi Li",
      "Zhihao Shi",
      "Yangdi Lu",
      "Wenbo He",
      "Xiangyu Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.03993v3",
    "title": "Keep It on a Leash: Controllable Pseudo-label Generation Towards\n  Realistic Long-Tailed Semi-Supervised Learning",
    "summary": "Current long-tailed semi-supervised learning methods assume that labeled data\nexhibit a long-tailed distribution, and unlabeled data adhere to a typical\npredefined distribution (i.e., long-tailed, uniform, or inverse long-tailed).\nHowever, the distribution of the unlabeled data is generally unknown and may\nfollow an arbitrary distribution. To tackle this challenge, we propose a\nControllable Pseudo-label Generation (CPG) framework, expanding the labeled\ndataset with the progressively identified reliable pseudo-labels from the\nunlabeled dataset and training the model on the updated labeled dataset with a\nknown distribution, making it unaffected by the unlabeled data distribution.\nSpecifically, CPG operates through a controllable self-reinforcing optimization\ncycle: (i) at each training step, our dynamic controllable filtering mechanism\nselectively incorporates reliable pseudo-labels from the unlabeled dataset into\nthe labeled dataset, ensuring that the updated labeled dataset follows a known\ndistribution; (ii) we then construct a Bayes-optimal classifier using logit\nadjustment based on the updated labeled data distribution; (iii) this improved\nclassifier subsequently helps identify more reliable pseudo-labels in the next\ntraining step. We further theoretically prove that this optimization cycle can\nsignificantly reduce the generalization error under some conditions.\nAdditionally, we propose a class-aware adaptive augmentation module to further\nimprove the representation of minority classes, and an auxiliary branch to\nmaximize data utilization by leveraging all labeled and unlabeled samples.\nComprehensive evaluations on various commonly used benchmark datasets show that\nCPG achieves consistent improvements, surpassing state-of-the-art methods by up\nto $\\textbf{15.97%}$ in accuracy. The code is available at\nhttps://github.com/yaxinhou/CPG.",
    "published": "2025-10-05T01:52:19Z",
    "updated": "2025-10-08T01:59:22Z",
    "link": "http://arxiv.org/pdf/2510.03993v3.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Yaxin Hou",
      "Bo Han",
      "Yuheng Jia",
      "Hui Liu",
      "Junhui Hou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2405.08589v2",
    "title": "Decomposed Global Optimization for Robust Point Matching with\n  Low-Dimensional Branching",
    "summary": "Numerous applications require algorithms that can align partially overlapping\npoint sets while maintaining invariance to geometric transformations (e.g.,\nsimilarity, affine, rigid). This paper introduces a novel global optimization\nmethod for this task by minimizing the objective function of the Robust Point\nMatching (RPM) algorithm. We first reveal that the original RPM objective is a\ncubic polynomial. Through a concise variable substitution, we transform this\nobjective into a quadratic function. By leveraging the convex envelope of\nbilinear monomials, we derive a tight lower bound for this quadratic function.\nThis lower bound problem conveniently and efficiently decomposes into two\nparts: a standard linear assignment problem (solvable in polynomial time) and a\nlow-dimensional convex quadratic program. Furthermore, we devise a specialized\nBranch-and-Bound (BnB) algorithm that branches exclusively on the\ntransformation parameters, which significantly accelerates convergence by\nconfining the search space. Experiments on 2D and 3D synthetic and real-world\ndata demonstrate that our method, compared to state-of-the-art approaches,\nexhibits superior robustness to non-rigid deformations, positional noise, and\noutliers, particularly in scenarios where outliers are distinct from inliers.",
    "published": "2024-05-14T13:28:57Z",
    "updated": "2025-10-08T01:41:18Z",
    "link": "http://arxiv.org/pdf/2405.08589v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Wei Lian",
      "Zhesen Cui",
      "Fei Ma",
      "Hang Pan",
      "Wangmeng Zuo",
      "Jianmei Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06541v1",
    "title": "Cluster Paths: Navigating Interpretability in Neural Networks",
    "summary": "While modern deep neural networks achieve impressive performance in vision\ntasks, they remain opaque in their decision processes, risking unwarranted\ntrust, undetected biases and unexpected failures. We propose cluster paths, a\npost-hoc interpretability method that clusters activations at selected layers\nand represents each input as its sequence of cluster IDs. To assess these\ncluster paths, we introduce four metrics: path complexity (cognitive load),\nweighted-path purity (class alignment), decision-alignment faithfulness\n(predictive fidelity), and path agreement (stability under perturbations). In a\nspurious-cue CIFAR-10 experiment, cluster paths identify color-based shortcuts\nand collapse when the cue is removed. On a five-class CelebA hair-color task,\nthey achieve 90% faithfulness and maintain 96% agreement under Gaussian noise\nwithout sacrificing accuracy. Scaling to a Vision Transformer pretrained on\nImageNet, we extend cluster paths to concept paths derived from prompting a\nlarge language model on minimal path divergences. Finally, we show that cluster\npaths can serve as an effective out-of-distribution (OOD) detector, reliably\nflagging anomalous samples before the model generates over-confident\npredictions. Cluster paths uncover visual concepts, such as color palettes,\ntextures, or object contexts, at multiple network depths, demonstrating that\ncluster paths scale to large vision models while generating concise and\nhuman-readable explanations.",
    "published": "2025-10-08T00:41:09Z",
    "updated": "2025-10-08T00:41:09Z",
    "link": "http://arxiv.org/pdf/2510.06541v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Nicholas M. Kroeger",
      "Vincent Bindschaedler"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06529v1",
    "title": "VUGEN: Visual Understanding priors for GENeration",
    "summary": "Recent advances in Vision-Language Models (VLMs) have enabled unified\nunderstanding across text and images, yet equipping these models with robust\nimage generation capabilities remains challenging. Existing approaches often\nrely on reconstruction-oriented autoencoders or complex bridging mechanisms,\nleading to misalignment between understanding and generation representations,\nor architectural complexity. In this work, we propose VUGEN, a novel framework\nthat explicitly leverages VLM's pretrained visual understanding priors for\nefficient and high-quality image generation. Our approach first transforms the\nhigh-dimensional latent space of the VLM's native vision encoder into a\nlower-dimensional, tractable distribution that maximally preserves visual\ninformation. The VLM is then trained to sample within this reduced latent\nspace, ensuring alignment with its visual understanding capabilities. Finally,\na dedicated pixel decoder maps these generated latents back to the image space.\nWe find that a VAE-free pixel diffusion decoder to be on par or better than\ncommonly used complex latent diffusion decoders that internally rely on VAE\nlatents. Extensive experiments demonstrate that VUGEN achieves superior image\ngeneration performance, improving DPG Bench from 71.17 to 74.32 and FID from\n11.86 to 9.06 on COCO, while fully preserving the VLM's original understanding\ncapabilities.",
    "published": "2025-10-08T00:04:47Z",
    "updated": "2025-10-08T00:04:47Z",
    "link": "http://arxiv.org/pdf/2510.06529v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xiangyi Chen",
      "Théophane Vallaeys",
      "Maha Elbayad",
      "John Nguyen",
      "Jakob Verbeek"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.18369v3",
    "title": "RePIC: Reinforced Post-Training for Personalizing Multi-Modal Language\n  Models",
    "summary": "Recent multi-modal large language models (MLLMs) often struggle to generate\npersonalized image captions, even when trained on high-quality captions. In\nthis work, we observe that such limitations persist in existing\npost-training-based MLLM personalization methods. Specifically, despite being\npost-tuned with large-scale caption data through supervised fine-tuning (SFT),\nthese models frequently fail to produce faithful descriptions in real-world\nscenarios, such as multi-concept image captioning. However, acquiring\nlarge-scale, high-quality captions for such complex settings is both costly and\ndifficult. To address the data-centric nature of SFT, we propose a\nreinforcement learning (RL)-based post-training framework. To the best of our\nknowledge, this is the first RL-based approach to post-train MLLMs for\npersonalized image captioning. Our method significantly enhances both visual\nrecognition and personalized generation capabilities of MLLMs, and consistently\noutperforms existing SFT-based baselines, especially in the challenging\nmulti-concept image captioning task. Project page:\nhttps://github.com/oyt9306/RePIC",
    "published": "2025-06-23T07:55:52Z",
    "updated": "2025-10-08T00:03:48Z",
    "link": "http://arxiv.org/pdf/2506.18369v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yeongtak Oh",
      "Dohyun Chung",
      "Juhyeon Shin",
      "Sangha Park",
      "Johan Barthelemy",
      "Jisoo Mok",
      "Sungroh Yoon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06518v1",
    "title": "Real-Time Glass Detection and Reprojection using Sensor Fusion Onboard\n  Aerial Robots",
    "summary": "Autonomous aerial robots are increasingly being deployed in real-world\nscenarios, where transparent obstacles present significant challenges to\nreliable navigation and mapping. These materials pose a unique problem for\ntraditional perception systems because they lack discernible features and can\ncause conventional depth sensors to fail, leading to inaccurate maps and\npotential collisions. To ensure safe navigation, robots must be able to\naccurately detect and map these transparent obstacles. Existing methods often\nrely on large, expensive sensors or algorithms that impose high computational\nburdens, making them unsuitable for low Size, Weight, and Power (SWaP) robots.\nIn this work, we propose a novel and computationally efficient framework for\ndetecting and mapping transparent obstacles onboard a sub-300g quadrotor. Our\nmethod fuses data from a Time-of-Flight (ToF) camera and an ultrasonic sensor\nwith a custom, lightweight 2D convolution model. This specialized approach\naccurately detects specular reflections and propagates their depth into\ncorresponding empty regions of the depth map, effectively rendering transparent\nobstacles visible. The entire pipeline operates in real-time, utilizing only a\nsmall fraction of a CPU core on an embedded processor. We validate our system\nthrough a series of experiments in both controlled and real-world environments,\ndemonstrating the utility of our method through experiments where the robot\nmaps indoor environments containing glass. Our work is, to our knowledge, the\nfirst of its kind to demonstrate a real-time, onboard transparent obstacle\nmapping system on a low-SWaP quadrotor using only the CPU.",
    "published": "2025-10-07T23:31:45Z",
    "updated": "2025-10-07T23:31:45Z",
    "link": "http://arxiv.org/pdf/2510.06518v1.pdf",
    "category": [
      "cs.RO",
      "cs.CV",
      "cs.SY",
      "eess.SY"
    ],
    "authors": [
      "Malakhi Hopkins",
      "Varun Murali",
      "Vijay Kumar",
      "Camillo J Taylor"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06516v1",
    "title": "Limited-Angle Tomography Reconstruction via Projector Guided 3D\n  Diffusion",
    "summary": "Limited-angle electron tomography aims to reconstruct 3D shapes from 2D\nprojections of Transmission Electron Microscopy (TEM) within a restricted range\nand number of tilting angles, but it suffers from the missing-wedge problem\nthat causes severe reconstruction artifacts. Deep learning approaches have\nshown promising results in alleviating these artifacts, yet they typically\nrequire large high-quality training datasets with known 3D ground truth which\nare difficult to obtain in electron microscopy. To address these challenges, we\npropose TEMDiff, a novel 3D diffusion-based iterative reconstruction framework.\nOur method is trained on readily available volumetric FIB-SEM data using a\nsimulator that maps them to TEM tilt series, enabling the model to learn\nrealistic structural priors without requiring clean TEM ground truth. By\noperating directly on 3D volumes, TEMDiff implicitly enforces consistency\nacross slices without the need for additional regularization. On simulated\nelectron tomography datasets with limited angular coverage, TEMDiff outperforms\nstate-of-the-art methods in reconstruction quality. We further demonstrate that\na trained TEMDiff model generalizes well to real-world TEM tilts obtained under\ndifferent conditions and can recover accurate structures from tilt ranges as\nnarrow as 8 degrees, with 2-degree increments, without any retraining or\nfine-tuning.",
    "published": "2025-10-07T23:27:28Z",
    "updated": "2025-10-07T23:27:28Z",
    "link": "http://arxiv.org/pdf/2510.06516v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhantao Deng",
      "Mériem Er-Rafik",
      "Anna Sushko",
      "Cécile Hébert",
      "Pascal Fua"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.21526v2",
    "title": "WAFT: Warping-Alone Field Transforms for Optical Flow",
    "summary": "We introduce Warping-Alone Field Transforms (WAFT), a simple and effective\nmethod for optical flow. WAFT is similar to RAFT but replaces cost volume with\nhigh-resolution warping, achieving better accuracy with lower memory cost. This\ndesign challenges the conventional wisdom that constructing cost volumes is\nnecessary for strong performance. WAFT is a simple and flexible\nmeta-architecture with minimal inductive biases and reliance on custom designs.\nCompared with existing methods, WAFT ranks 1st on Spring, Sintel, and KITTI\nbenchmarks, achieves the best zero-shot generalization on KITTI, while being up\nto 4.1x faster than methods with similar performance. Code and model weights\nare available at https://github.com/princeton-vl/WAFT.",
    "published": "2025-06-26T17:47:59Z",
    "updated": "2025-10-07T23:26:36Z",
    "link": "http://arxiv.org/pdf/2506.21526v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yihan Wang",
      "Jia Deng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06509v1",
    "title": "From Captions to Keyframes: Efficient Video Summarization via Caption-\n  and Context-Aware Frame Scoring",
    "summary": "Efficient video-language understanding requires selecting a small set of\nframes that retain semantic and contextual information from long videos. We\npropose KeyScore, a multimodal frame scoring framework that jointly leverages\ncaptions and visual context to estimate frame-level importance. By combining\nsemantic similarity, temporal diversity, and contextual drop impact, KeyScore\nidentifies the most informative frames for downstream tasks such as retrieval,\ncaptioning, and video-language reasoning. To complement KeyScore, we introduce\nSTACFP (Spatio-Temporal Adaptive Clustering for Frame Proposals), which\ngenerates compact and diverse frame candidates for long-form videos. Together,\nthese modules achieve up to 99\\% frame reduction compared to full-frame\ninference and substantially outperform standard 8-frame encoders on MSRVTT,\nMSVD, and DiDeMo. Our results demonstrate that emphasizing multimodal alignment\nbetween visual and textual signals enables scalable, efficient, and\ncaption-grounded video understanding -- without explicit video summarization.",
    "published": "2025-10-07T23:02:27Z",
    "updated": "2025-10-07T23:02:27Z",
    "link": "http://arxiv.org/pdf/2510.06509v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Shih-Yao Lin",
      "Sibendu Paul",
      "Caren Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06504v1",
    "title": "Text2Interact: High-Fidelity and Diverse Text-to-Two-Person Interaction\n  Generation",
    "summary": "Modeling human-human interactions from text remains challenging because it\nrequires not only realistic individual dynamics but also precise,\ntext-consistent spatiotemporal coupling between agents. Currently, progress is\nhindered by 1) limited two-person training data, inadequate to capture the\ndiverse intricacies of two-person interactions; and 2) insufficiently\nfine-grained text-to-interaction modeling, where language conditioning\ncollapses rich, structured prompts into a single sentence embedding. To address\nthese limitations, we propose our Text2Interact framework, designed to generate\nrealistic, text-aligned human-human interactions through a scalable\nhigh-fidelity interaction data synthesizer and an effective spatiotemporal\ncoordination pipeline. First, we present InterCompose, a scalable\nsynthesis-by-composition pipeline that aligns LLM-generated interaction\ndescriptions with strong single-person motion priors. Given a prompt and a\nmotion for an agent, InterCompose retrieves candidate single-person motions,\ntrains a conditional reaction generator for another agent, and uses a neural\nmotion evaluator to filter weak or misaligned samples-expanding interaction\ncoverage without extra capture. Second, we propose InterActor, a\ntext-to-interaction model with word-level conditioning that preserves\ntoken-level cues (initiation, response, contact ordering) and an adaptive\ninteraction loss that emphasizes contextually relevant inter-person joint\npairs, improving coupling and physical plausibility for fine-grained\ninteraction modeling. Extensive experiments show consistent gains in motion\ndiversity, fidelity, and generalization, including out-of-distribution\nscenarios and user studies. We will release code and models to facilitate\nreproducibility.",
    "published": "2025-10-07T22:41:23Z",
    "updated": "2025-10-07T22:41:23Z",
    "link": "http://arxiv.org/pdf/2510.06504v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Qingxuan Wu",
      "Zhiyang Dou",
      "Chuan Guo",
      "Yiming Huang",
      "Qiao Feng",
      "Bing Zhou",
      "Jian Wang",
      "Lingjie Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06487v1",
    "title": "Superpixel Integrated Grids for Fast Image Segmentation",
    "summary": "Superpixels have long been used in image simplification to enable more\nefficient data processing and storage. However, despite their computational\npotential, their irregular spatial distribution has often forced deep learning\napproaches to rely on specialized training algorithms and architectures,\nundermining the original motivation for superpixelations. In this work, we\nintroduce a new superpixel-based data structure, SIGRID (Superpixel-Integrated\nGrid), as an alternative to full-resolution images in segmentation tasks. By\nleveraging classical shape descriptors, SIGRID encodes both color and shape\ninformation of superpixels while substantially reducing input dimensionality.\nWe evaluate SIGRIDs on four benchmark datasets using two popular convolutional\nsegmentation architectures. Our results show that, despite compressing the\noriginal data, SIGRIDs not only match but in some cases surpass the performance\nof pixel-level representations, all while significantly accelerating model\ntraining. This demonstrates that SIGRIDs achieve a favorable balance between\naccuracy and computational efficiency.",
    "published": "2025-10-07T22:02:48Z",
    "updated": "2025-10-07T22:02:48Z",
    "link": "http://arxiv.org/pdf/2510.06487v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jack Roberts",
      "Jeova Farias Sales Rocha Neto"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.09833v2",
    "title": "Erasing More Than Intended? How Concept Erasure Degrades the Generation\n  of Non-Target Concepts",
    "summary": "Concept erasure techniques have recently gained significant attention for\ntheir potential to remove unwanted concepts from text-to-image models. While\nthese methods often demonstrate promising results in controlled settings, their\nrobustness in real-world applications and suitability for deployment remain\nuncertain. In this work, we (1) identify a critical gap in evaluating sanitized\nmodels, particularly in assessing their performance across diverse concept\ndimensions, and (2) systematically analyze the failure modes of text-to-image\nmodels post-erasure. We focus on the unintended consequences of concept removal\non non-target concepts across different levels of interconnected relationships\nincluding visually similar, binomial, and semantically related concepts. To\naddress this, we introduce EraseBench, a comprehensive benchmark for evaluating\npost-erasure performance. EraseBench includes over 100 curated concepts,\ntargeted evaluation prompts, and a robust set of metrics to assess both\neffectiveness and side effects of erasure. Our findings reveal a phenomenon of\nconcept entanglement, where erasure leads to unintended suppression of\nnon-target concepts, causing spillover degradation that manifests as\ndistortions and a decline in generation quality.",
    "published": "2025-01-16T20:42:17Z",
    "updated": "2025-10-07T22:00:31Z",
    "link": "http://arxiv.org/pdf/2501.09833v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ibtihel Amara",
      "Ahmed Imtiaz Humayun",
      "Ivana Kajic",
      "Zarana Parekh",
      "Natalie Harris",
      "Sarah Young",
      "Chirag Nagpal",
      "Najoung Kim",
      "Junfeng He",
      "Cristina Nader Vasconcelos",
      "Deepak Ramachandran",
      "Golnoosh Farnadi",
      "Katherine Heller",
      "Mohammad Havaei",
      "Negar Rostamzadeh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06481v1",
    "title": "Active Next-Best-View Optimization for Risk-Averse Path Planning",
    "summary": "Safe navigation in uncertain environments requires planning methods that\nintegrate risk aversion with active perception. In this work, we present a\nunified framework that refines a coarse reference path by constructing\ntail-sensitive risk maps from Average Value-at-Risk statistics on an\nonline-updated 3D Gaussian-splat Radiance Field. These maps enable the\ngeneration of locally safe and feasible trajectories. In parallel, we formulate\nNext-Best-View (NBV) selection as an optimization problem on the SE(3) pose\nmanifold, where Riemannian gradient descent maximizes an expected information\ngain objective to reduce uncertainty most critical for imminent motion. Our\napproach advances the state-of-the-art by coupling risk-averse path refinement\nwith NBV planning, while introducing scalable gradient decompositions that\nsupport efficient online updates in complex environments. We demonstrate the\neffectiveness of the proposed framework through extensive computational\nstudies.",
    "published": "2025-10-07T21:41:28Z",
    "updated": "2025-10-07T21:41:28Z",
    "link": "http://arxiv.org/pdf/2510.06481v1.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Amirhossein Mollaei Khass",
      "Guangyi Liu",
      "Vivek Pandey",
      "Wen Jiang",
      "Boshu Lei",
      "Kostas Daniilidis",
      "Nader Motee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06469v1",
    "title": "SIGMA-GEN: Structure and Identity Guided Multi-subject Assembly for\n  Image Generation",
    "summary": "We present SIGMA-GEN, a unified framework for multi-identity preserving image\ngeneration. Unlike prior approaches, SIGMA-GEN is the first to enable\nsingle-pass multi-subject identity-preserved generation guided by both\nstructural and spatial constraints. A key strength of our method is its ability\nto support user guidance at various levels of precision -- from coarse 2D or 3D\nboxes to pixel-level segmentations and depth -- with a single model. To enable\nthis, we introduce SIGMA-SET27K, a novel synthetic dataset that provides\nidentity, structure, and spatial information for over 100k unique subjects\nacross 27k images. Through extensive evaluation we demonstrate that SIGMA-GEN\nachieves state-of-the-art performance in identity preservation, image\ngeneration quality, and speed. Code and visualizations at\nhttps://oindrilasaha.github.io/SIGMA-Gen/",
    "published": "2025-10-07T21:12:02Z",
    "updated": "2025-10-07T21:12:02Z",
    "link": "http://arxiv.org/pdf/2510.06469v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Oindrila Saha",
      "Vojtech Krs",
      "Radomir Mech",
      "Subhransu Maji",
      "Kevin Blackburn-Matzen",
      "Matheus Gadelha"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06460v1",
    "title": "TDiff: Thermal Plug-And-Play Prior with Patch-Based Diffusion",
    "summary": "Thermal images from low-cost cameras often suffer from low resolution, fixed\npattern noise, and other localized degradations. Available datasets for thermal\nimaging are also limited in both size and diversity. To address these\nchallenges, we propose a patch-based diffusion framework (TDiff) that leverages\nthe local nature of these distortions by training on small thermal patches. In\nthis approach, full-resolution images are restored by denoising overlapping\npatches and blending them using smooth spatial windowing. To our knowledge,\nthis is the first patch-based diffusion framework that models a learned prior\nfor thermal image restoration across multiple tasks. Experiments on denoising,\nsuper-resolution, and deblurring demonstrate strong results on both simulated\nand real thermal data, establishing our method as a unified restoration\npipeline.",
    "published": "2025-10-07T20:54:34Z",
    "updated": "2025-10-07T20:54:34Z",
    "link": "http://arxiv.org/pdf/2510.06460v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Piyush Dashpute",
      "Niki Nezakati",
      "Wolfgang Heidrich",
      "Vishwanath Saragadam"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06440v1",
    "title": "Road Surface Condition Detection with Machine Learning using New York\n  State Department of Transportation Camera Images and Weather Forecast Data",
    "summary": "The New York State Department of Transportation (NYSDOT) has a network of\nroadside traffic cameras that are used by both the NYSDOT and the public to\nobserve road conditions. The NYSDOT evaluates road conditions by driving on\nroads and observing live cameras, tasks which are labor-intensive but necessary\nfor making critical operational decisions during winter weather events.\nHowever, machine learning models can provide additional support for the NYSDOT\nby automatically classifying current road conditions across the state. In this\nstudy, convolutional neural networks and random forests are trained on camera\nimages and weather data to predict road surface conditions. Models are trained\non a hand-labeled dataset of ~22,000 camera images, each classified by human\nlabelers into one of six road surface conditions: severe snow, snow, wet, dry,\npoor visibility, or obstructed. Model generalizability is prioritized to meet\nthe operational needs of the NYSDOT decision makers, and the weather-related\nroad surface condition model in this study achieves an accuracy of 81.5% on\ncompletely unseen cameras.",
    "published": "2025-10-07T20:24:40Z",
    "updated": "2025-10-07T20:24:40Z",
    "link": "http://arxiv.org/pdf/2510.06440v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Carly Sutter",
      "Kara J. Sulia",
      "Nick P. Bassill",
      "Christopher D. Wirz",
      "Christopher D. Thorncroft",
      "Jay C. Rothenberger",
      "Vanessa Przybylo",
      "Mariana G. Cains",
      "Jacob Radford",
      "David Aaron Evans"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06335v1",
    "title": "Conditional Denoising Diffusion Model-Based Robust MR Image\n  Reconstruction from Highly Undersampled Data",
    "summary": "Magnetic Resonance Imaging (MRI) is a critical tool in modern medical\ndiagnostics, yet its prolonged acquisition time remains a critical limitation,\nespecially in time-sensitive clinical scenarios. While undersampling strategies\ncan accelerate image acquisition, they often result in image artifacts and\ndegraded quality. Recent diffusion models have shown promise for reconstructing\nhigh-fidelity images from undersampled data by learning powerful image priors;\nhowever, most existing approaches either (i) rely on unsupervised score\nfunctions without paired supervision or (ii) apply data consistency only as a\npost-processing step. In this work, we introduce a conditional denoising\ndiffusion framework with iterative data-consistency correction, which differs\nfrom prior methods by embedding the measurement model directly into every\nreverse diffusion step and training the model on paired undersampled-ground\ntruth data. This hybrid design bridges generative flexibility with explicit\nenforcement of MRI physics. Experiments on the fastMRI dataset demonstrate that\nour framework consistently outperforms recent state-of-the-art deep learning\nand diffusion-based methods in SSIM, PSNR, and LPIPS, with LPIPS capturing\nperceptual improvements more faithfully. These results demonstrate that\nintegrating conditional supervision with iterative consistency updates yields\nsubstantial improvements in both pixel-level fidelity and perceptual realism,\nestablishing a principled and practical advance toward robust, accelerated MRI\nreconstruction.",
    "published": "2025-10-07T18:01:08Z",
    "updated": "2025-10-07T18:01:08Z",
    "link": "http://arxiv.org/pdf/2510.06335v1.pdf",
    "category": [
      "eess.IV",
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Mohammed Alsubaie",
      "Wenxi Liu",
      "Linxia Gu",
      "Ovidiu C. Andronesi",
      "Sirani M. Perera",
      "Xianqi Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06048v2",
    "title": "BLISS: A Lightweight Bilevel Influence Scoring Method for Data Selection\n  in Language Model Pretraining",
    "summary": "Effective data selection is essential for pretraining large language models\n(LLMs), enhancing efficiency and improving generalization to downstream tasks.\nHowever, existing approaches often require leveraging external pretrained\nmodels, making it difficult to disentangle the effects of data selection from\nthose of the external pretrained models. In addition, they often overlook the\nlong-term impact of selected data if the model is trained to convergence,\nprimarily due to the prohibitive cost of full-scale LLM pretraining. In this\npaper, we introduce BLISS (\\textbf{B}ileve\\textbf{L} \\textbf{I}nfluence\n\\textbf{S}coring method for data \\textbf{S}election): a lightweight data\nselection method that operates entirely \\emph{from scratch}, without relying on\nany external pretrained oracle models, while explicitly accounting for the\nlong-term impact of selected data. BLISS leverages a small proxy model as a\nsurrogate for the LLM and employs a score model to estimate the long-term\ninfluence of training samples if the proxy model is trained to convergence. We\nformulate data selection as a bilevel optimization problem, where the\nupper-level objective optimizes the score model to assign importance weights to\ntraining samples, ensuring that minimizing the lower-level objective (i.e.,\ntraining the proxy model over the weighted training loss until convergence)\nleads to best validation performance. Once optimized, the trained score model\npredicts influence scores for the dataset, enabling efficient selection of\nhigh-quality samples for LLM pretraining. We validate BLISS by pretraining\n410M/1B/2.8B Pythia and LLaMA-0.5B models on selected subsets of the C4\ndataset. Notably, under the 1B model setting, BLISS achieves $1.7\\times$\nspeedup in reaching the same performance as the state-of-the-art method,\ndemonstrating superior performance across multiple downstream tasks.",
    "published": "2025-10-07T15:42:33Z",
    "updated": "2025-10-08T17:49:49Z",
    "link": "http://arxiv.org/pdf/2510.06048v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Jie Hao",
      "Rui Yu",
      "Wei Zhang",
      "Huixia Wang",
      "Jie Xu",
      "Mingrui Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07289v1",
    "title": "MolGA: Molecular Graph Adaptation with Pre-trained 2D Graph Encoder",
    "summary": "Molecular graph representation learning is widely used in chemical and\nbiomedical research. While pre-trained 2D graph encoders have demonstrated\nstrong performance, they overlook the rich molecular domain knowledge\nassociated with submolecular instances (atoms and bonds). While molecular\npre-training approaches incorporate such knowledge into their pre-training\nobjectives, they typically employ designs tailored to a specific type of\nknowledge, lacking the flexibility to integrate diverse knowledge present in\nmolecules. Hence, reusing widely available and well-validated pre-trained 2D\nencoders, while incorporating molecular domain knowledge during downstream\nadaptation, offers a more practical alternative. In this work, we propose\nMolGA, which adapts pre-trained 2D graph encoders to downstream molecular\napplications by flexibly incorporating diverse molecular domain knowledge.\nFirst, we propose a molecular alignment strategy that bridge the gap between\npre-trained topological representations with domain-knowledge representations.\nSecond, we introduce a conditional adaptation mechanism that generates\ninstance-specific tokens to enable fine-grained integration of molecular domain\nknowledge for downstream tasks. Finally, we conduct extensive experiments on\neleven public datasets, demonstrating the effectiveness of MolGA.",
    "published": "2025-10-08T17:46:22Z",
    "updated": "2025-10-08T17:46:22Z",
    "link": "http://arxiv.org/pdf/2510.07289v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Xingtong Yu",
      "Chang Zhou",
      "Xinming Zhang",
      "Yuan Fang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.05753v2",
    "title": "Empirical Comparison of Membership Inference Attacks in Deep Transfer\n  Learning",
    "summary": "With the emergence of powerful large-scale foundation models, the training\nparadigm is increasingly shifting from from-scratch training to transfer\nlearning. This enables high utility training with small, domain-specific\ndatasets typical in sensitive applications. Membership inference attacks (MIAs)\nprovide an empirical estimate of the privacy leakage by machine learning\nmodels. Yet, prior assessments of MIAs against models fine-tuned with transfer\nlearning rely on a small subset of possible attacks. We address this by\ncomparing performance of diverse MIAs in transfer learning settings to help\npractitioners identify the most efficient attacks for privacy risk evaluation.\nWe find that attack efficacy decreases with the increase in training data for\nscore-based MIAs. We find that there is no one MIA which captures all privacy\nrisks in models trained with transfer learning. While the Likelihood Ratio\nAttack (LiRA) demonstrates superior performance across most experimental\nscenarios, the Inverse Hessian Attack (IHA) proves to be more effective against\nmodels fine-tuned on PatchCamelyon dataset in high data regime.",
    "published": "2025-10-07T10:21:05Z",
    "updated": "2025-10-08T17:41:41Z",
    "link": "http://arxiv.org/pdf/2510.05753v2.pdf",
    "category": [
      "cs.LG",
      "cs.CR"
    ],
    "authors": [
      "Yuxuan Bai",
      "Gauri Pradhan",
      "Marlon Tobaben",
      "Antti Honkela"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.21404v2",
    "title": "Dual Natural Gradient Descent for Scalable Training of Physics-Informed\n  Neural Networks",
    "summary": "Natural-gradient methods markedly accelerate the training of Physics-Informed\nNeural Networks (PINNs), yet their Gauss--Newton update must be solved in the\nparameter space, incurring a prohibitive $O(n^3)$ time complexity, where $n$ is\nthe number of network trainable weights. We show that exactly the same step can\ninstead be formulated in a generally smaller residual space of size $m =\n\\sum_{\\gamma} N_{\\gamma} d_{\\gamma}$, where each residual class $\\gamma$ (e.g.\nPDE interior, boundary, initial data) contributes $N_{\\gamma}$ collocation\npoints of output dimension $d_{\\gamma}$.\n  Building on this insight, we introduce \\textit{Dual Natural Gradient Descent}\n(D-NGD). D-NGD computes the Gauss--Newton step in residual space, augments it\nwith a geodesic-acceleration correction at negligible extra cost, and provides\nboth a dense direct solver for modest $m$ and a Nystrom-preconditioned\nconjugate-gradient solver for larger $m$.\n  Experimentally, D-NGD scales second-order PINN optimization to networks with\nup to 12.8 million parameters, delivers one- to three-order-of-magnitude lower\nfinal error $L^2$ than first-order methods (Adam, SGD) and quasi-Newton\nmethods, and -- crucially -- enables natural-gradient training of PINNs at this\nscale on a single GPU.",
    "published": "2025-05-27T16:27:23Z",
    "updated": "2025-10-08T17:39:20Z",
    "link": "http://arxiv.org/pdf/2505.21404v2.pdf",
    "category": [
      "cs.LG",
      "math.OC"
    ],
    "authors": [
      "Anas Jnini",
      "Flavio Vella"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07266v1",
    "title": "Dynamic Regret Bounds for Online Omniprediction with Long Term\n  Constraints",
    "summary": "We present an algorithm guaranteeing dynamic regret bounds for online\nomniprediction with long term constraints. The goal in this recently introduced\nproblem is for a learner to generate a sequence of predictions which are\nbroadcast to a collection of downstream decision makers. Each decision maker\nhas their own utility function, as well as a vector of constraint functions,\neach mapping their actions and an adversarially selected state to reward or\nconstraint violation terms. The downstream decision makers select actions \"as\nif\" the state predictions are correct, and the goal of the learner is to\nproduce predictions such that all downstream decision makers choose actions\nthat give them worst-case utility guarantees while minimizing worst-case\nconstraint violation. Within this framework, we give the first algorithm that\nobtains simultaneous \\emph{dynamic regret} guarantees for all of the agents --\nwhere regret for each agent is measured against a potentially changing sequence\nof actions across rounds of interaction, while also ensuring vanishing\nconstraint violation for each agent. Our results do not require the agents\nthemselves to maintain any state -- they only solve one-round constrained\noptimization problems defined by the prediction made at that round.",
    "published": "2025-10-08T17:28:05Z",
    "updated": "2025-10-08T17:28:05Z",
    "link": "http://arxiv.org/pdf/2510.07266v1.pdf",
    "category": [
      "cs.LG",
      "cs.GT"
    ],
    "authors": [
      "Yahav Bechavod",
      "Jiuyao Lu",
      "Aaron Roth"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07257v1",
    "title": "Test-Time Graph Search for Goal-Conditioned Reinforcement Learning",
    "summary": "Offline goal-conditioned reinforcement learning (GCRL) trains policies that\nreach user-specified goals at test time, providing a simple, unsupervised,\ndomain-agnostic way to extract diverse behaviors from unlabeled, reward-free\ndatasets. Nonetheless, long-horizon decision making remains difficult for GCRL\nagents due to temporal credit assignment and error accumulation, and the\noffline setting amplifies these effects. To alleviate this issue, we introduce\nTest-Time Graph Search (TTGS), a lightweight planning approach to solve the\nGCRL task. TTGS accepts any state-space distance or cost signal, builds a\nweighted graph over dataset states, and performs fast search to assemble a\nsequence of subgoals that a frozen policy executes. When the base learner is\nvalue-based, the distance is derived directly from the learned goal-conditioned\nvalue function, so no handcrafted metric is needed. TTGS requires no changes to\ntraining, no additional supervision, no online interaction, and no privileged\ninformation, and it runs entirely at inference. On the OGBench benchmark, TTGS\nimproves success rates of multiple base learners on challenging locomotion\ntasks, demonstrating the benefit of simple metric-guided test-time planning for\noffline GCRL.",
    "published": "2025-10-08T17:20:53Z",
    "updated": "2025-10-08T17:20:53Z",
    "link": "http://arxiv.org/pdf/2510.07257v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Evgenii Opryshko",
      "Junwei Quan",
      "Claas Voelcker",
      "Yilun Du",
      "Igor Gilitschenski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07245v1",
    "title": "Discriminative Feature Feedback with General Teacher Classes",
    "summary": "We study the theoretical properties of the interactive learning protocol\nDiscriminative Feature Feedback (DFF) (Dasgupta et al., 2018). The DFF learning\nprotocol uses feedback in the form of discriminative feature explanations. We\nprovide the first systematic study of DFF in a general framework that is\ncomparable to that of classical protocols such as supervised learning and\nonline learning. We study the optimal mistake bound of DFF in the realizable\nand the non-realizable settings, and obtain novel structural results, as well\nas insights into the differences between Online Learning and settings with\nricher feedback such as DFF. We characterize the mistake bound in the\nrealizable setting using a new notion of dimension. In the non-realizable\nsetting, we provide a mistake upper bound and show that it cannot be improved\nin general. Our results show that unlike Online Learning, in DFF the realizable\ndimension is insufficient to characterize the optimal non-realizable mistake\nbound or the existence of no-regret algorithms.",
    "published": "2025-10-08T17:14:22Z",
    "updated": "2025-10-08T17:14:22Z",
    "link": "http://arxiv.org/pdf/2510.07245v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Omri Bar Oz",
      "Tosca Lechner",
      "Sivan Sabato"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.07939v2",
    "title": "Bit-Level Discrete Diffusion with Markov Probabilistic Models: An\n  Improved Framework with Sharp Convergence Bounds under Minimal Assumptions",
    "summary": "This paper introduces Discrete Markov Probabilistic Models (DMPMs), a novel\ndiscrete diffusion algorithm for discrete data generation. The algorithm\noperates in discrete bit space, where the noising process is a continuous-time\nMarkov chain that flips labels uniformly at random. The time-reversal process,\nlike the forward noise process, is a jump process with its intensity governed\nby a discrete analogue of the classical score function. Crucially, this\nintensity is proven to be the conditional expectation of a function of the\nforward process, underlining theoretical alignment with score-based generative\nmodels. We establish convergence bounds for the algorithm under minimal\nassumptions, ensuring robustness and efficiency, which we demonstrate through\nexperiments on low-dimensional Bernoulli-distributed datasets and\nhigh-dimensional binary MNIST data. The results highlight competitive\nperformance in generating discrete structures compared to the state-of-the-art.\nThis work bridges theoretical foundations and practical applications, advancing\nthe development of effective and theoretically grounded discrete generative\nmodeling.",
    "published": "2025-02-11T20:36:23Z",
    "updated": "2025-10-08T16:55:19Z",
    "link": "http://arxiv.org/pdf/2502.07939v2.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Le-Tuyet-Nhi Pham",
      "Dario Shariatian",
      "Antonio Ocello",
      "Giovanni Conforti",
      "Alain Durmus"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2308.00856v2",
    "title": "Differential Privacy for Adaptive Weight Aggregation in Federated Tumor\n  Segmentation",
    "summary": "Federated Learning (FL) is a distributed machine learning approach that\nsafeguards privacy by creating an impartial global model while respecting the\nprivacy of individual client data. However, the conventional FL method can\nintroduce security risks when dealing with diverse client data, potentially\ncompromising privacy and data integrity. To address these challenges, we\npresent a differential privacy (DP) federated deep learning framework in\nmedical image segmentation. In this paper, we extend our similarity weight\naggregation (SimAgg) method to DP-SimAgg algorithm, a differentially private\nsimilarity-weighted aggregation algorithm for brain tumor segmentation in\nmulti-modal magnetic resonance imaging (MRI). Our DP-SimAgg method not only\nenhances model segmentation capabilities but also provides an additional layer\nof privacy preservation. Extensive benchmarking and evaluation of our\nframework, with computational performance as a key consideration, demonstrate\nthat DP-SimAgg enables accurate and robust brain tumor segmentation while\nminimizing communication costs during model training. This advancement is\ncrucial for preserving the privacy of medical image data and safeguarding\nsensitive information. In conclusion, adding a differential privacy layer in\nthe global weight aggregation phase of the federated brain tumor segmentation\nprovides a promising solution to privacy concerns without compromising\nsegmentation model efficacy. By leveraging DP, we ensure the protection of\nclient data against adversarial attacks and malicious participants.",
    "published": "2023-08-01T21:59:22Z",
    "updated": "2025-10-08T16:53:55Z",
    "link": "http://arxiv.org/pdf/2308.00856v2.pdf",
    "category": [
      "cs.LG",
      "cs.CR",
      "eess.IV"
    ],
    "authors": [
      "Muhammad Irfan Khan",
      "Esa Alhoniemi",
      "Elina Kontio",
      "Suleiman A. Khan",
      "Mojtaba Jafaritadi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.23663v2",
    "title": "AMBER: Adaptive Mesh Generation by Iterative Mesh Resolution Prediction",
    "summary": "The cost and accuracy of simulating complex physical systems using the Finite\nElement Method (FEM) scales with the resolution of the underlying mesh.\nAdaptive meshes improve computational efficiency by refining resolution in\ncritical regions, but typically require task-specific heuristics or cumbersome\nmanual design by a human expert. We propose Adaptive Meshing By Expert\nReconstruction (AMBER), a supervised learning approach to mesh adaptation.\nStarting from a coarse mesh, AMBER iteratively predicts the sizing field, i.e.,\na function mapping from the geometry to the local element size of the target\nmesh, and uses this prediction to produce a new intermediate mesh using an\nout-of-the-box mesh generator. This process is enabled through a hierarchical\ngraph neural network, and relies on data augmentation by automatically\nprojecting expert labels onto AMBER-generated data during training. We evaluate\nAMBER on 2D and 3D datasets, including classical physics problems, mechanical\ncomponents, and real-world industrial designs with human expert meshes. AMBER\ngeneralizes to unseen geometries and consistently outperforms multiple recent\nbaselines, including ones using Graph and Convolutional Neural Networks, and\nReinforcement Learning-based approaches.",
    "published": "2025-05-29T17:10:44Z",
    "updated": "2025-10-08T16:48:28Z",
    "link": "http://arxiv.org/pdf/2505.23663v2.pdf",
    "category": [
      "cs.LG",
      "cs.CG"
    ],
    "authors": [
      "Niklas Freymuth",
      "Tobias Würth",
      "Nicolas Schreiber",
      "Balazs Gyenes",
      "Andreas Boltres",
      "Johannes Mitsch",
      "Aleksandar Taranovic",
      "Tai Hoang",
      "Philipp Dahlinger",
      "Philipp Becker",
      "Luise Kärger",
      "Gerhard Neumann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07208v1",
    "title": "A Broader View of Thompson Sampling",
    "summary": "Thompson Sampling is one of the most widely used and studied bandit\nalgorithms, known for its simple structure, low regret performance, and solid\ntheoretical guarantees. Yet, in stark contrast to most other families of bandit\nalgorithms, the exact mechanism through which posterior sampling (as introduced\nby Thompson) is able to \"properly\" balance exploration and exploitation,\nremains a mystery. In this paper we show that the core insight to address this\nquestion stems from recasting Thompson Sampling as an online optimization\nalgorithm. To distill this, a key conceptual tool is introduced, which we refer\nto as \"faithful\" stationarization of the regret formulation. Essentially, the\nfinite horizon dynamic optimization problem is converted into a stationary\ncounterpart which \"closely resembles\" the original objective (in contrast, the\nclassical infinite horizon discounted formulation, that leads to the Gittins\nindex, alters the problem and objective in too significant a manner). The newly\ncrafted time invariant objective can be studied using Bellman's principle which\nleads to a time invariant optimal policy. When viewed through this lens,\nThompson Sampling admits a simple online optimization form that mimics the\nstructure of the Bellman-optimal policy, and where greediness is regularized by\na measure of residual uncertainty based on point-biserial correlation. This\nanswers the question of how Thompson Sampling balances\nexploration-exploitation, and moreover, provides a principled framework to\nstudy and further improve Thompson's original idea.",
    "published": "2025-10-08T16:43:02Z",
    "updated": "2025-10-08T16:43:02Z",
    "link": "http://arxiv.org/pdf/2510.07208v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Yanlin Qu",
      "Hongseok Namkoong",
      "Assaf Zeevi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07205v1",
    "title": "Guided by the Experts: Provable Feature Learning Dynamic of Soft-Routed\n  Mixture-of-Experts",
    "summary": "Mixture-of-Experts (MoE) architectures have emerged as a cornerstone of\nmodern AI systems. In particular, MoEs route inputs dynamically to specialized\nexperts whose outputs are aggregated through weighted summation. Despite their\nwidespread application, theoretical understanding of MoE training dynamics\nremains limited to either separate expert-router optimization or only top-1\nrouting scenarios with carefully constructed datasets. This paper advances MoE\ntheory by providing convergence guarantees for joint training of soft-routed\nMoE models with non-linear routers and experts in a student-teacher framework.\nWe prove that, with moderate over-parameterization, the student network\nundergoes a feature learning phase, where the router's learning process is\n``guided'' by the experts, that recovers the teacher's parameters. Moreover, we\nshow that a post-training pruning can effectively eliminate redundant neurons,\nfollowed by a provably convergent fine-tuning process that reaches global\noptimality. To our knowledge, our analysis is the first to bring novel insights\nin understanding the optimization landscape of the MoE architecture.",
    "published": "2025-10-08T16:40:31Z",
    "updated": "2025-10-08T16:40:31Z",
    "link": "http://arxiv.org/pdf/2510.07205v1.pdf",
    "category": [
      "cs.LG",
      "math.OC"
    ],
    "authors": [
      "Fangshuo Liao",
      "Anastasios Kyrillidis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07202v1",
    "title": "An in-depth look at approximation via deep and narrow neural networks",
    "summary": "In 2017, Hanin and Sellke showed that the class of arbitrarily deep,\nreal-valued, feed-forward and ReLU-activated networks of width w forms a dense\nsubset of the space of continuous functions on R^n, with respect to the\ntopology of uniform convergence on compact sets, if and only if w>n holds. To\nshow the necessity, a concrete counterexample function f:R^n->R was used. In\nthis note we actually approximate this very f by neural networks in the two\ncases w=n and w=n+1 around the aforementioned threshold. We study how the\napproximation quality behaves if we vary the depth and what effect (spoiler\nalert: dying neurons) cause that behavior.",
    "published": "2025-10-08T16:34:45Z",
    "updated": "2025-10-08T16:34:45Z",
    "link": "http://arxiv.org/pdf/2510.07202v1.pdf",
    "category": [
      "cs.LG",
      "68T07, 41A30",
      "I.2.6; I.5.1"
    ],
    "authors": [
      "Joris Dommel",
      "Sven A. Wegner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.08063v2",
    "title": "Last-iterate Convergence for Symmetric, General-sum, $2 \\times 2$ Games\n  Under The Exponential Weights Dynamic",
    "summary": "We conduct a comprehensive analysis of the discrete-time exponential-weights\ndynamic with a constant step size on all \\emph{general-sum and symmetric} $2\n\\times 2$ normal-form games, i.e. games with $2$ pure strategies per player,\nand where the ensuing payoff tuple is of the form $(A,A^\\top)$ (where $A$ is\nthe $2 \\times 2$ payoff matrix corresponding to the first player). Such\nsymmetric games commonly arise in real-world interactions between \"symmetric\"\nagents who have identically defined utility functions -- such as Bertrand\ncompetition, multi-agent performative prediction, and certain congestion games\n-- and display a rich multiplicity of equilibria despite the seemingly simple\nsetting. Somewhat surprisingly, we show through a first-principles analysis\nthat the exponential weights dynamic, which is popular in online learning,\nconverges in the last iterate for such games regardless of initialization with\nan appropriately chosen step size. For certain games and/or initializations, we\nfurther show that the convergence rate is in fact exponential and holds for any\nstep size.\n  We illustrate our theory with extensive simulations and applications to the\naforementioned game-theoretic interactions. In the case of multi-agent\nperformative prediction, we formulate a new \"mortgage competition\" game between\nlenders (i.e. banks) who interact with a population of customers, and show that\nit fits into our framework.",
    "published": "2025-02-12T02:04:46Z",
    "updated": "2025-10-08T16:32:58Z",
    "link": "http://arxiv.org/pdf/2502.08063v2.pdf",
    "category": [
      "cs.GT",
      "cs.LG"
    ],
    "authors": [
      "Guanghui Wang",
      "Krishna Acharya",
      "Lokranjan Lakshmikanthan",
      "Juba Ziani",
      "Vidya Muthukumar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07195v1",
    "title": "Accelerating Inference for Multilayer Neural Networks with Quantum\n  Computers",
    "summary": "Fault-tolerant Quantum Processing Units (QPUs) promise to deliver exponential\nspeed-ups in select computational tasks, yet their integration into modern deep\nlearning pipelines remains unclear. In this work, we take a step towards\nbridging this gap by presenting the first fully-coherent quantum implementation\nof a multilayer neural network with non-linear activation functions. Our\nconstructions mirror widely used deep learning architectures based on ResNet,\nand consist of residual blocks with multi-filter 2D convolutions, sigmoid\nactivations, skip-connections, and layer normalizations. We analyse the\ncomplexity of inference for networks under three quantum data access regimes.\nWithout any assumptions, we establish a quadratic speedup over classical\nmethods for shallow bilinear-style networks. With efficient quantum access to\nthe weights, we obtain a quartic speedup over classical methods. With efficient\nquantum access to both the inputs and the network weights, we prove that a\nnetwork with an $N$-dimensional vectorized input, $k$ residual block layers,\nand a final residual-linear-pooling layer can be implemented with an error of\n$\\epsilon$ with $O(\\text{polylog}(N/\\epsilon)^k)$ inference cost.",
    "published": "2025-10-08T16:26:50Z",
    "updated": "2025-10-08T16:26:50Z",
    "link": "http://arxiv.org/pdf/2510.07195v1.pdf",
    "category": [
      "quant-ph",
      "cs.LG"
    ],
    "authors": [
      "Arthur G. Rattew",
      "Po-Wei Huang",
      "Naixu Guo",
      "Lirandë Pira",
      "Patrick Rebentrost"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07193v1",
    "title": "Covert Quantum Learning: Privately and Verifiably Learning from Quantum\n  Data",
    "summary": "Quantum learning from remotely accessed quantum compute and data must address\ntwo key challenges: verifying the correctness of data and ensuring the privacy\nof the learner's data-collection strategies and resulting conclusions. The\ncovert (verifiable) learning model of Canetti and Karchmer (TCC 2021) provides\na framework for endowing classical learning algorithms with such guarantees. In\nthis work, we propose models of covert verifiable learning in quantum learning\ntheory and realize them without computational hardness assumptions for remote\ndata access scenarios motivated by established quantum data advantages. We\nconsider two privacy notions: (i) strategy-covertness, where the eavesdropper\ndoes not gain information about the learner's strategy; and (ii)\ntarget-covertness, where the eavesdropper does not gain information about the\nunknown object being learned. We show: Strategy-covert algorithms for making\nquantum statistical queries via classical shadows; Target-covert algorithms for\nlearning quadratic functions from public quantum examples and private quantum\nstatistical queries, for Pauli shadow tomography and stabilizer state learning\nfrom public multi-copy and private single-copy quantum measurements, and for\nsolving Forrelation and Simon's problem from public quantum queries and private\nclassical queries, where the adversary is a unidirectional or i.i.d.\nancilla-free eavesdropper. The lattermost results in particular establish that\nthe exponential separation between classical and quantum queries for\nForrelation and Simon's problem survives under covertness constraints. Along\nthe way, we design covert verifiable protocols for quantum data acquisition\nfrom public quantum queries which may be of independent interest. Overall, our\nmodels and corresponding algorithms demonstrate that quantum advantages are\nprivately and verifiably achievable even with untrusted, remote data.",
    "published": "2025-10-08T16:25:28Z",
    "updated": "2025-10-08T16:25:28Z",
    "link": "http://arxiv.org/pdf/2510.07193v1.pdf",
    "category": [
      "quant-ph",
      "cs.CR",
      "cs.LG"
    ],
    "authors": [
      "Abhishek Anand",
      "Matthias C. Caro",
      "Ari Karchmer",
      "Saachi Mutreja"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07192v1",
    "title": "Poisoning Attacks on LLMs Require a Near-constant Number of Poison\n  Samples",
    "summary": "Poisoning attacks can compromise the safety of large language models (LLMs)\nby injecting malicious documents into their training data. Existing work has\nstudied pretraining poisoning assuming adversaries control a percentage of the\ntraining corpus. However, for large models, even small percentages translate to\nimpractically large amounts of data. This work demonstrates for the first time\nthat poisoning attacks instead require a near-constant number of documents\nregardless of dataset size. We conduct the largest pretraining poisoning\nexperiments to date, pretraining models from 600M to 13B parameters on\nchinchilla-optimal datasets (6B to 260B tokens). We find that 250 poisoned\ndocuments similarly compromise models across all model and dataset sizes,\ndespite the largest models training on more than 20 times more clean data. We\nalso run smaller-scale experiments to ablate factors that could influence\nattack success, including broader ratios of poisoned to clean data and\nnon-random distributions of poisoned samples. Finally, we demonstrate the same\ndynamics for poisoning during fine-tuning. Altogether, our results suggest that\ninjecting backdoors through data poisoning may be easier for large models than\npreviously believed as the number of poisons required does not scale up with\nmodel size, highlighting the need for more research on defences to mitigate\nthis risk in future models.",
    "published": "2025-10-08T16:25:05Z",
    "updated": "2025-10-08T16:25:05Z",
    "link": "http://arxiv.org/pdf/2510.07192v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Alexandra Souly",
      "Javier Rando",
      "Ed Chapman",
      "Xander Davies",
      "Burak Hasircioglu",
      "Ezzeldin Shereen",
      "Carlos Mougan",
      "Vasilios Mavroudis",
      "Erik Jones",
      "Chris Hicks",
      "Nicholas Carlini",
      "Yarin Gal",
      "Robert Kirk"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07185v1",
    "title": "Split Conformal Classification with Unsupervised Calibration",
    "summary": "Methods for split conformal prediction leverage calibration samples to\ntransform any prediction rule into a set-prediction rule that complies with a\ntarget coverage probability. Existing methods provide remarkably strong\nperformance guarantees with minimal computational costs. However, they require\nto use calibration samples composed by labeled examples different to those used\nfor training. This requirement can be highly inconvenient, as it prevents the\nuse of all labeled examples for training and may require acquiring additional\nlabels solely for calibration. This paper presents an effective methodology for\nsplit conformal prediction with unsupervised calibration for classification\ntasks. In the proposed approach, set-prediction rules are obtained using\nunsupervised calibration samples together with supervised training samples\npreviously used to learn the classification rule. Theoretical and experimental\nresults show that the presented methods can achieve performance comparable to\nthat with supervised calibration, at the expenses of a moderate degradation in\nperformance guarantees and computational efficiency.",
    "published": "2025-10-08T16:22:41Z",
    "updated": "2025-10-08T16:22:41Z",
    "link": "http://arxiv.org/pdf/2510.07185v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Santiago Mazuelas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07182v1",
    "title": "Bridged Clustering for Representation Learning: Semi-Supervised Sparse\n  Bridging",
    "summary": "We introduce Bridged Clustering, a semi-supervised framework to learn\npredictors from any unpaired input $X$ and output $Y$ dataset. Our method first\nclusters $X$ and $Y$ independently, then learns a sparse, interpretable bridge\nbetween clusters using only a few paired examples. At inference, a new input\n$x$ is assigned to its nearest input cluster, and the centroid of the linked\noutput cluster is returned as the prediction $\\hat{y}$. Unlike traditional SSL,\nBridged Clustering explicitly leverages output-only data, and unlike dense\ntransport-based methods, it maintains a sparse and interpretable alignment.\nThrough theoretical analysis, we show that with bounded mis-clustering and\nmis-bridging rates, our algorithm becomes an effective and efficient predictor.\nEmpirically, our method is competitive with SOTA methods while remaining\nsimple, model-agnostic, and highly label-efficient in low-supervision settings.",
    "published": "2025-10-08T16:20:49Z",
    "updated": "2025-10-08T16:20:49Z",
    "link": "http://arxiv.org/pdf/2510.07182v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Patrick Peixuan Ye",
      "Chen Shani",
      "Ellen Vitercik"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07180v1",
    "title": "Bayesian Portfolio Optimization by Predictive Synthesis",
    "summary": "Portfolio optimization is a critical task in investment. Most existing\nportfolio optimization methods require information on the distribution of\nreturns of the assets that make up the portfolio. However, such distribution\ninformation is usually unknown to investors. Various methods have been proposed\nto estimate distribution information, but their accuracy greatly depends on the\nuncertainty of the financial markets. Due to this uncertainty, a model that\ncould well predict the distribution information at one point in time may\nperform less accurately compared to another model at a different time. To solve\nthis problem, we investigate a method for portfolio optimization based on\nBayesian predictive synthesis (BPS), one of the Bayesian ensemble methods for\nmeta-learning. We assume that investors have access to multiple asset return\nprediction models. By using BPS with dynamic linear models to combine these\npredictions, we can obtain a Bayesian predictive posterior about the mean\nrewards of assets that accommodate the uncertainty of the financial markets. In\nthis study, we examine how to construct mean-variance portfolios and\nquantile-based portfolios based on the predicted distribution information.",
    "published": "2025-10-08T16:18:11Z",
    "updated": "2025-10-08T16:18:11Z",
    "link": "http://arxiv.org/pdf/2510.07180v1.pdf",
    "category": [
      "econ.EM",
      "cs.LG",
      "q-fin.CP",
      "q-fin.PM",
      "stat.AP"
    ],
    "authors": [
      "Masahiro Kato",
      "Kentaro Baba",
      "Hibiki Kaibuchi",
      "Ryo Inokuchi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.00039v2",
    "title": "AbsoluteNet: A Deep Learning Neural Network to Classify Cerebral\n  Hemodynamic Responses of Auditory Processing",
    "summary": "In recent years, deep learning (DL) approaches have demonstrated promising\nresults in decoding hemodynamic responses captured by functional near-infrared\nspectroscopy (fNIRS), particularly in the context of brain-computer interface\n(BCI) applications. This work introduces AbsoluteNet, a novel deep learning\narchitecture designed to classify auditory event-related responses recorded\nusing fNIRS. The proposed network is built upon principles of spatio-temporal\nconvolution and customized activation functions. Our model was compared against\nseveral models, namely fNIRSNET, MDNN, DeepConvNet, and ShallowConvNet. The\nresults showed that AbsoluteNet outperforms existing models, reaching 87.0%\naccuracy, 84.8% sensitivity, and 89.2% specificity in binary classification,\nsurpassing fNIRSNET, the second-best model, by 3.8% in accuracy. These findings\nunderscore the effectiveness of our proposed deep learning model in decoding\nhemodynamic responses related to auditory processing and highlight the\nimportance of spatio-temporal feature aggregation and customized activation\nfunctions to better fit fNIRS dynamics.",
    "published": "2025-05-27T19:21:17Z",
    "updated": "2025-10-08T15:37:01Z",
    "link": "http://arxiv.org/pdf/2506.00039v2.pdf",
    "category": [
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "authors": [
      "Behtom Adeli",
      "John Mclinden",
      "Pankaj Pandey",
      "Ming Shao",
      "Yalda Shahriari"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07136v1",
    "title": "Spectral Graph Clustering under Differential Privacy: Balancing Privacy,\n  Accuracy, and Efficiency",
    "summary": "We study the problem of spectral graph clustering under edge differential\nprivacy (DP). Specifically, we develop three mechanisms: (i) graph perturbation\nvia randomized edge flipping combined with adjacency matrix shuffling, which\nenforces edge privacy while preserving key spectral properties of the graph.\nImportantly, shuffling considerably amplifies the guarantees: whereas flipping\nedges with a fixed probability alone provides only a constant epsilon edge DP\nguarantee as the number of nodes grows, the shuffled mechanism achieves\n(epsilon, delta) edge DP with parameters that tend to zero as the number of\nnodes increase; (ii) private graph projection with additive Gaussian noise in a\nlower-dimensional space to reduce dimensionality and computational complexity;\nand (iii) a noisy power iteration method that distributes Gaussian noise across\niterations to ensure edge DP while maintaining convergence. Our analysis\nprovides rigorous privacy guarantees and a precise characterization of the\nmisclassification error rate. Experiments on synthetic and real-world networks\nvalidate our theoretical analysis and illustrate the practical privacy-utility\ntrade-offs.",
    "published": "2025-10-08T15:30:27Z",
    "updated": "2025-10-08T15:30:27Z",
    "link": "http://arxiv.org/pdf/2510.07136v1.pdf",
    "category": [
      "cs.IT",
      "cs.CR",
      "cs.LG",
      "cs.SI",
      "math.IT"
    ],
    "authors": [
      "Mohamed Seif",
      "Antti Koskela",
      "H. Vincent Poor",
      "Andrea J. Goldsmith"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07132v1",
    "title": "DPMM-CFL: Clustered Federated Learning via Dirichlet Process Mixture\n  Model Nonparametric Clustering",
    "summary": "Clustered Federated Learning (CFL) improves performance under non-IID client\nheterogeneity by clustering clients and training one model per cluster, thereby\nbalancing between a global model and fully personalized models. However, most\nCFL methods require the number of clusters K to be fixed a priori, which is\nimpractical when the latent structure is unknown. We propose DPMM-CFL, a CFL\nalgorithm that places a Dirichlet Process (DP) prior over the distribution of\ncluster parameters. This enables nonparametric Bayesian inference to jointly\ninfer both the number of clusters and client assignments, while optimizing\nper-cluster federated objectives. This results in a method where, at each\nround, federated updates and cluster inferences are coupled, as presented in\nthis paper. The algorithm is validated on benchmark datasets under Dirichlet\nand class-split non-IID partitions.",
    "published": "2025-10-08T15:27:08Z",
    "updated": "2025-10-08T15:27:08Z",
    "link": "http://arxiv.org/pdf/2510.07132v1.pdf",
    "category": [
      "cs.LG",
      "cs.DC",
      "stat.ML"
    ],
    "authors": [
      "Mariona Jaramillo-Civill",
      "Peng Wu",
      "Pau Closas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07109v1",
    "title": "GNN-enhanced Traffic Anomaly Detection for Next-Generation SDN-Enabled\n  Consumer Electronics",
    "summary": "Consumer electronics (CE) connected to the Internet of Things are susceptible\nto various attacks, including DDoS and web-based threats, which can compromise\ntheir functionality and facilitate remote hijacking. These vulnerabilities\nallow attackers to exploit CE for broader system attacks while enabling the\npropagation of malicious code across the CE network, resulting in device\nfailures. Existing deep learning-based traffic anomaly detection systems\nexhibit high accuracy in traditional network environments but are often overly\ncomplex and reliant on static infrastructure, necessitating manual\nconfiguration and management. To address these limitations, we propose a\nscalable network model that integrates Software-defined Networking (SDN) and\nCompute First Networking (CFN) for next-generation CE networks. In this network\nmodel, we propose a Graph Neural Networks-based Network Anomaly Detection\nframework (GNN-NAD) that integrates SDN-based CE networks and enables the CFN\narchitecture. GNN-NAD uniquely fuses a static, vulnerability-aware attack graph\nwith dynamic traffic features, providing a holistic view of network security.\nThe core of the framework is a GNN model (GSAGE) for graph representation\nlearning, followed by a Random Forest (RF) classifier. This design (GSAGE+RF)\ndemonstrates superior performance compared to existing feature selection\nmethods. Experimental evaluations on CE environment reveal that GNN-NAD\nachieves superior metrics in accuracy, recall, precision, and F1 score, even\nwith small sample sizes, exceeding the performance of current network anomaly\ndetection methods. This work advances the security and efficiency of\nnext-generation intelligent CE networks.",
    "published": "2025-10-08T15:01:40Z",
    "updated": "2025-10-08T15:01:40Z",
    "link": "http://arxiv.org/pdf/2510.07109v1.pdf",
    "category": [
      "cs.CR",
      "cs.LG",
      "cs.NI",
      "C.2.0; C.2.1; C.2.3; C.2.5; I.2.6; K.6.5"
    ],
    "authors": [
      "Guan-Yan Yang",
      "Farn Wang",
      "Kuo-Hui Yeh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07106v1",
    "title": "Active Control of Turbulent Airfoil Flows Using Adjoint-based Deep\n  Learning",
    "summary": "We train active neural-network flow controllers using a deep learning PDE\naugmentation method to optimize lift-to-drag ratios in turbulent airfoil flows\nat Reynolds number $5\\times10^4$ and Mach number 0.4. Direct numerical\nsimulation and large eddy simulation are employed to model compressible,\nunconfined flow over two- and three-dimensional semi-infinite NACA 0012\nairfoils at angles of attack $\\alpha = 5^\\circ$, $10^\\circ$, and $15^\\circ$.\nControl actions, implemented through a blowing/suction jet at a fixed location\nand geometry on the upper surface, are adaptively determined by a neural\nnetwork that maps local pressure measurements to optimal jet total pressure,\nenabling a sensor-informed control policy that responds spatially and\ntemporally to unsteady flow conditions. The sensitivities of the flow to the\nneural network parameters are computed using the adjoint Navier-Stokes\nequations, which we construct using automatic differentiation applied to the\nflow solver. The trained flow controllers significantly improve the\nlift-to-drag ratios and reduce flow separation for both two- and\nthree-dimensional airfoil flows, especially at $\\alpha = 5^\\circ$ and\n$10^\\circ$. The 2D-trained models remain effective when applied out-of-sample\nto 3D flows, which demonstrates the robustness of the adjoint-trained control\napproach. The 3D-trained models capture the flow dynamics even more\neffectively, which leads to better energy efficiency and comparable performance\nfor both adaptive (neural network) and offline (simplified, constant-pressure)\ncontrollers. These results underscore the effectiveness of this learning-based\napproach in improving aerodynamic performance.",
    "published": "2025-10-08T14:59:29Z",
    "updated": "2025-10-08T14:59:29Z",
    "link": "http://arxiv.org/pdf/2510.07106v1.pdf",
    "category": [
      "physics.flu-dyn",
      "cs.LG"
    ],
    "authors": [
      "Xuemin Liu",
      "Tom Hickling",
      "Jonathan F. MacArt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07099v1",
    "title": "Diffusion-Augmented Reinforcement Learning for Robust Portfolio\n  Optimization under Stress Scenarios",
    "summary": "In the ever-changing and intricate landscape of financial markets, portfolio\noptimisation remains a formidable challenge for investors and asset managers.\nConventional methods often struggle to capture the complex dynamics of market\nbehaviour and align with diverse investor preferences. To address this, we\npropose an innovative framework, termed Diffusion-Augmented Reinforcement\nLearning (DARL), which synergistically integrates Denoising Diffusion\nProbabilistic Models (DDPMs) with Deep Reinforcement Learning (DRL) for\nportfolio management. By leveraging DDPMs to generate synthetic market crash\nscenarios conditioned on varying stress intensities, our approach significantly\nenhances the robustness of training data. Empirical evaluations demonstrate\nthat DARL outperforms traditional baselines, delivering superior risk-adjusted\nreturns and resilience against unforeseen crises, such as the 2025 Tariff\nCrisis. This work offers a robust and practical methodology to bolster stress\nresilience in DRL-driven financial applications.",
    "published": "2025-10-08T14:56:50Z",
    "updated": "2025-10-08T14:56:50Z",
    "link": "http://arxiv.org/pdf/2510.07099v1.pdf",
    "category": [
      "stat.ML",
      "cs.CE",
      "cs.LG",
      "q-fin.CP"
    ],
    "authors": [
      "Himanshu Choudhary",
      "Arishi Orra",
      "Manoj Thakur"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07093v1",
    "title": "Non-Asymptotic Analysis of Efficiency in Conformalized Regression",
    "summary": "Conformal prediction provides prediction sets with coverage guarantees. The\ninformativeness of conformal prediction depends on its efficiency, typically\nquantified by the expected size of the prediction set. Prior work on the\nefficiency of conformalized regression commonly treats the miscoverage level\n$\\alpha$ as a fixed constant. In this work, we establish non-asymptotic bounds\non the deviation of the prediction set length from the oracle interval length\nfor conformalized quantile and median regression trained via SGD, under mild\nassumptions on the data distribution. Our bounds of order\n$\\mathcal{O}(1/\\sqrt{n} + 1/(\\alpha^2 n) + 1/\\sqrt{m} + \\exp(-\\alpha^2 m))$\ncapture the joint dependence of efficiency on the proper training set size $n$,\nthe calibration set size $m$, and the miscoverage level $\\alpha$. The results\nidentify phase transitions in convergence rates across different regimes of\n$\\alpha$, offering guidance for allocating data to control excess prediction\nset length. Empirical results are consistent with our theoretical findings.",
    "published": "2025-10-08T14:50:35Z",
    "updated": "2025-10-08T14:50:35Z",
    "link": "http://arxiv.org/pdf/2510.07093v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Yunzhen Yao",
      "Lie He",
      "Michael Gastpar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.11329v3",
    "title": "TokenWeave: Efficient Compute-Communication Overlap for Distributed LLM\n  Inference",
    "summary": "Distributed inference of large language models (LLMs) can introduce overheads\nof up to 20% even over GPUs connected via high-speed interconnects such as\nNVLink. Multiple techniques have been proposed to mitigate these overheads by\ndecomposing computations into finer-grained tasks and overlapping communication\nwith sub-tasks as they complete. However, fine-grained decomposition of a large\ncomputation into many smaller computations on GPUs results in overheads.\nFurthermore, the communication itself uses many streaming multiprocessors\n(SMs), adding to the overhead.\n  We present TokenWeave to address these challenges. TokenWeave proposes a\nToken-Splitting technique that divides the tokens in the inference batch into\ntwo approximately equal subsets in a wave-aware manner. The communication of\none subset is then overlapped with the computation of the other. In addition,\nTokenWeave optimizes the order of the layer normalization computation with\nrespect to communication operations and implements a novel fused\nAllReduce--RMSNorm kernel that carefully leverages Multimem instruction support\navailable on Hopper and Blackwell NVIDIA GPUs. These optimizations allow\nTokenWeave to perform communication and RMSNorm using only 2-8 SMs. Moreover,\nour kernel enables the memory-bound RMSNorm to be overlapped with the other\nbatch's computation, providing additional gains.\n  Our evaluations demonstrate up to 1.29x speedup in latency and 1.26x higher\nthroughput across multiple models and workloads. In several settings,\nTokenWeave results in better performance compared to an equivalent model with\nall communication removed.",
    "published": "2025-05-16T14:53:50Z",
    "updated": "2025-10-08T14:49:25Z",
    "link": "http://arxiv.org/pdf/2505.11329v3.pdf",
    "category": [
      "cs.DC",
      "cs.LG"
    ],
    "authors": [
      "Raja Gond",
      "Nipun Kwatra",
      "Ramachandran Ramjee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07088v1",
    "title": "Explaining Models under Multivariate Bernoulli Distribution via\n  Hoeffding Decomposition",
    "summary": "Explaining the behavior of predictive models with random inputs can be\nachieved through sub-models decomposition, where such sub-models have easier\ninterpretable features. Arising from the uncertainty quantification community,\nrecent results have demonstrated the existence and uniqueness of a generalized\nHoeffding decomposition for such predictive models when the stochastic input\nvariables are correlated, based on concepts of oblique projection onto L 2\nsubspaces. This article focuses on the case where the input variables have\nBernoulli distributions and provides a complete description of this\ndecomposition. We show that in this case the underlying L 2 subspaces are\none-dimensional and that the functional decomposition is explicit. This leads\nto a complete interpretability framework and theoretically allows reverse\nengineering. Explicit indicators of the influence of inputs on the output\nprediction (exemplified by Sobol' indices and Shapley effects) can be\nexplicitly derived. Illustrated by numerical experiments, this type of analysis\nproves useful for addressing decision-support problems, based on binary\ndecision diagrams, Boolean networks or binary neural networks. The article\noutlines perspectives for exploring high-dimensional settings and, beyond the\ncase of binary inputs, extending these findings to models with finite countable\ninputs.",
    "published": "2025-10-08T14:46:20Z",
    "updated": "2025-10-08T14:46:20Z",
    "link": "http://arxiv.org/pdf/2510.07088v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Baptiste Ferrere",
      "Nicolas Bousquet",
      "Fabrice Gamboa",
      "Jean-Michel Loubes",
      "Joseph Muré"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07086v1",
    "title": "Non-Stationary Online Structured Prediction with Surrogate Losses",
    "summary": "Online structured prediction, including online classification as a special\ncase, is the task of sequentially predicting labels from input features.\nTherein the surrogate regret -- the cumulative excess of the target loss (e.g.,\n0-1 loss) over the surrogate loss (e.g., logistic loss) of the fixed best\nestimator -- has gained attention, particularly because it often admits a\nfinite bound independent of the time horizon $T$. However, such guarantees\nbreak down in non-stationary environments, where every fixed estimator may\nincur the surrogate loss growing linearly with $T$. We address this by proving\na bound of the form $F_T + C(1 + P_T)$ on the cumulative target loss, where\n$F_T$ is the cumulative surrogate loss of any comparator sequence, $P_T$ is its\npath length, and $C > 0$ is some constant. This bound depends on $T$ only\nthrough $F_T$ and $P_T$, often yielding much stronger guarantees in\nnon-stationary environments. Our core idea is to synthesize the dynamic regret\nbound of the online gradient descent (OGD) with the technique of exploiting the\nsurrogate gap. Our analysis also sheds light on a new Polyak-style learning\nrate for OGD, which systematically offers target-loss guarantees and exhibits\npromising empirical performance. We further extend our approach to a broader\nclass of problems via the convolutional Fenchel--Young loss. Finally, we prove\na lower bound showing that the dependence on $F_T$ and $P_T$ is tight.",
    "published": "2025-10-08T14:43:44Z",
    "updated": "2025-10-08T14:43:44Z",
    "link": "http://arxiv.org/pdf/2510.07086v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Shinsaku Sakaue",
      "Han Bao",
      "Yuzhou Cao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2408.11200v3",
    "title": "Want to train KANS at scale? Now UKAN!",
    "summary": "Kolmogorov-Arnold Networks (KANs) have recently emerged as a powerful\nalternative to traditional multilayer perceptrons. However, their reliance on\npredefined, bounded grids restricts their ability to approximate functions on\nunbounded domains. To address this, we present Unbounded Kolmogorov-Arnold\nNetworks (UKANs), a method that removes the need for bounded grids in\ntraditional Kolmogorov-Arnold Networks (KANs). The key innovation of this\nmethod is a coefficient-generator (CG) model that produces, on the fly, only\nthe B-spline coefficients required locally on an unbounded symmetric grid.\nUKANs couple multilayer perceptrons with KANs by feeding the positional\nencoding of grid groups into the CG model, enabling function approximation on\nunbounded domains without requiring data normalization. To reduce the\ncomputational cost of both UKANs and KANs, we introduce a GPU-accelerated\nlibrary that lowers B-spline evaluation complexity by a factor proportional to\nthe grid size, enabling large-scale learning by leveraging efficient memory\nmanagement, in line with recent software advances such as FlashAttention and\nFlashFFTConv. Performance benchmarking confirms the superior memory and\ncomputational efficiency of our accelerated KAN (warpKAN), and UKANs, showing a\n3-30x speed-up and up to 1000x memory reduction compared to vanilla KANs.\nExperiments on regression, classification, and generative tasks demonstrate the\neffectiveness of UKANs to match or surpass KAN accuracy. Finally, we use both\naccelerated KAN and UKAN in a molecular property prediction task, establishing\nthe feasibility of large-scale end-to-end training with our optimized\nimplementation.",
    "published": "2024-08-20T21:20:38Z",
    "updated": "2025-10-08T14:41:42Z",
    "link": "http://arxiv.org/pdf/2408.11200v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Alireza Moradzadeh",
      "Srimukh Prasad Veccham",
      "Lukasz Wawrzyniak",
      "Miles Macklin",
      "Saee G. Paliwal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07080v1",
    "title": "Pseudo-MDPs: A Novel Framework for Efficiently Optimizing Last Revealer\n  Seed Manipulations in Blockchains",
    "summary": "This study tackles the computational challenges of solving Markov Decision\nProcesses (MDPs) for a restricted class of problems. It is motivated by the\nLast Revealer Attack (LRA), which undermines fairness in some Proof-of-Stake\n(PoS) blockchains such as Ethereum (\\$400B market capitalization). We introduce\npseudo-MDPs (pMDPs) a framework that naturally models such problems and propose\ntwo distinct problem reductions to standard MDPs. One problem reduction\nprovides a novel, counter-intuitive perspective, and combining the two problem\nreductions enables significant improvements in dynamic programming algorithms\nsuch as value iteration. In the case of the LRA which size is parameterized by\n$\\kappa$ (in Ethereum's case $\\kappa$ = 32), we reduce the computational\ncomplexity from O(2^$\\kappa$ $\\kappa$^2^($\\kappa$+2)) to O($\\kappa$^4) (per\niteration). This solution also provide the usual benefits from Dynamic\nProgramming solutions: exponentially fast convergence toward the optimal\nsolution is guaranteed. The dual perspective also simplifies policy extraction,\nmaking the approach well-suited for resource-constrained agents who can operate\nwith very limited memory and computation once the problem has been solved.\nFurthermore, we generalize those results to a broader class of MDPs, enhancing\ntheir applicability. The framework is validated through two case studies: a\nfictional card game and the LRA on the Ethereum random seed consensus protocol.\nThese applications demonstrate the framework's ability to solve large-scale\nproblems effectively while offering actionable insights into optimal\nstrategies. This work advances the study of MDPs and contributes to\nunderstanding security vulnerabilities in blockchain systems.",
    "published": "2025-10-08T14:39:20Z",
    "updated": "2025-10-08T14:39:20Z",
    "link": "http://arxiv.org/pdf/2510.07080v1.pdf",
    "category": [
      "cs.CR",
      "cs.LG"
    ],
    "authors": [
      "Maxime Reynouard"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07071v1",
    "title": "Blind Construction of Angular Power Maps in Massive MIMO Networks",
    "summary": "Channel state information (CSI) acquisition is a challenging problem in\nmassive multiple-input multiple-output (MIMO) networks. Radio maps provide a\npromising solution for radio resource management by reducing online CSI\nacquisition. However, conventional approaches for radio map construction\nrequire location-labeled CSI data, which is challenging in practice. This paper\ninvestigates unsupervised angular power map construction based on large\ntimescale CSI data collected in a massive MIMO network without location labels.\nA hidden Markov model (HMM) is built to connect the hidden trajectory of a\nmobile with the CSI evolution of a massive MIMO channel. As a result, the\nmobile location can be estimated, enabling the construction of an angular power\nmap. We show that under uniform rectilinear mobility with Poisson-distributed\nbase stations (BSs), the Cramer-Rao Lower Bound (CRLB) for localization error\ncan vanish at any signal-to-noise ratios (SNRs), whereas when BSs are confined\nto a limited region, the error remains nonzero even with infinite independent\nmeasurements. Based on reference signal received power (RSRP) data collected in\na real multi-cell massive MIMO network, an average localization error of 18\nmeters can be achieved although measurements are mainly obtained from a single\nserving cell.",
    "published": "2025-10-08T14:32:53Z",
    "updated": "2025-10-08T14:32:53Z",
    "link": "http://arxiv.org/pdf/2510.07071v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Zheng Xing",
      "Junting Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.04591v2",
    "title": "Data-Driven Adaptive PID Control Based on Physics-Informed Neural\n  Networks",
    "summary": "This article proposes a data-driven PID controller design based on the\nprinciple of adaptive gain optimization, leveraging Physics-Informed Neural\nNetworks (PINNs) generated for predictive modeling purposes. The proposed\ncontrol design method utilizes gradients of the PID gain optimization, achieved\nthrough the automatic differentiation of PINNs, to apply model predictive\ncontrol using a cost function based on tracking error and control inputs. By\noptimizing PINNs-based PID gains, the method achieves adaptive gain tuning that\nensures stability while accounting for system nonlinearities. The proposed\nmethod features a systematic framework for integrating PINNs-based models of\ndynamical control systems into closed-loop control systems, enabling direct\napplication to PID control design. A series of numerical experiments is\nconducted to demonstrate the effectiveness of the proposed method from the\ncontrol perspectives based on both time and frequency domains.",
    "published": "2025-10-06T08:46:20Z",
    "updated": "2025-10-08T14:27:34Z",
    "link": "http://arxiv.org/pdf/2510.04591v2.pdf",
    "category": [
      "eess.SY",
      "cs.LG",
      "cs.SY"
    ],
    "authors": [
      "Junsei Ito",
      "Yasuaki Wasa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07052v1",
    "title": "Enhancing Speech Emotion Recognition via Fine-Tuning Pre-Trained Models\n  and Hyper-Parameter Optimisation",
    "summary": "We propose a workflow for speech emotion recognition (SER) that combines\npre-trained representations with automated hyperparameter optimisation (HPO).\nUsing SpeechBrain wav2vec2-base model fine-tuned on IEMOCAP as the encoder, we\ncompare two HPO strategies, Gaussian Process Bayesian Optimisation (GP-BO) and\nTree-structured Parzen Estimators (TPE), under an identical four-dimensional\nsearch space and 15-trial budget, with balanced class accuracy (BCA) on the\nGerman EmoDB corpus as the objective. All experiments run on 8 CPU cores with\n32 GB RAM. GP-BO achieves 0.96 BCA in 11 minutes, and TPE (Hyperopt\nimplementation) attains 0.97 in 15 minutes. In contrast, grid search requires\n143 trials and 1,680 minutes to exceed 0.9 BCA, and the best AutoSpeech 2020\nbaseline reports only 0.85 in 30 minutes on GPU. For cross-lingual\ngeneralisation, an EmoDB-trained HPO-tuned model improves zero-shot accuracy by\n0.25 on CREMA-D and 0.26 on RAVDESS. Results show that efficient HPO with\npre-trained encoders delivers competitive SER on commodity CPUs. Source code to\nthis work is available at:\nhttps://github.com/youngaryan/speechbrain-emotion-hpo.",
    "published": "2025-10-08T14:20:43Z",
    "updated": "2025-10-08T14:20:43Z",
    "link": "http://arxiv.org/pdf/2510.07052v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Aryan Golbaghi",
      "Shuo Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07043v1",
    "title": "COMPASS: A Multi-Turn Benchmark for Tool-Mediated Planning & Preference\n  Optimization",
    "summary": "Real-world large language model (LLM) agents must master strategic tool use\nand user preference optimization through multi-turn interactions to assist\nusers with complex planning tasks. We introduce COMPASS (Constrained\nOptimization through Multi-turn Planning and Strategic Solutions), a benchmark\nthat evaluates agents on realistic travel-planning scenarios. We cast travel\nplanning as a constrained preference optimization problem, where agents must\nsatisfy hard constraints while simultaneously optimizing soft user preferences.\nTo support this, we build a realistic travel database covering transportation,\naccommodation, and ticketing for 20 U.S. National Parks, along with a\ncomprehensive tool ecosystem that mirrors commercial booking platforms.\nEvaluating state-of-the-art models, we uncover two critical gaps: (i) an\nacceptable-optimal gap, where agents reliably meet constraints but fail to\noptimize preferences, and (ii) a plan-coordination gap, where performance\ncollapses on multi-service (flight and hotel) coordination tasks, especially\nfor open-source models. By grounding reasoning and planning in a practical,\nuser-facing domain, COMPASS provides a benchmark that directly measures an\nagent's ability to optimize user preferences in realistic tasks, bridging\ntheoretical advances with real-world impact.",
    "published": "2025-10-08T14:09:46Z",
    "updated": "2025-10-08T14:09:46Z",
    "link": "http://arxiv.org/pdf/2510.07043v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Tian Qin",
      "Felix Bai",
      "Ting-Yao Hu",
      "Raviteja Vemulapalli",
      "Hema Swetha Koppula",
      "Zhiyang Xu",
      "Bowen Jin",
      "Mert Cemri",
      "Jiarui Lu",
      "Zirui Wang",
      "Meng Cao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06995v1",
    "title": "Root Cause Analysis of Outliers in Unknown Cyclic Graphs",
    "summary": "We study the propagation of outliers in cyclic causal graphs with linear\nstructural equations, tracing them back to one or several \"root cause\" nodes.\nWe show that it is possible to identify a short list of potential root causes\nprovided that the perturbation is sufficiently strong and propagates according\nto the same structural equations as in the normal mode. This shortlist consists\nof the true root causes together with those of its parents lying on a cycle\nwith the root cause. Notably, our method does not require prior knowledge of\nthe causal graph.",
    "published": "2025-10-08T13:19:01Z",
    "updated": "2025-10-08T13:19:01Z",
    "link": "http://arxiv.org/pdf/2510.06995v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "authors": [
      "Daniela Schkoda",
      "Dominik Janzing"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.01588v2",
    "title": "A Differentiable Alignment Framework for Sequence-to-Sequence Modeling\n  via Optimal Transport",
    "summary": "Accurate sequence-to-sequence (seq2seq) alignment is critical for\napplications like medical speech analysis and language learning tools relying\non automatic speech recognition (ASR). State-of-the-art end-to-end (E2E) ASR\nsystems, such as the Connectionist Temporal Classification (CTC) and\ntransducer-based models, suffer from peaky behavior and alignment inaccuracies.\nIn this paper, we propose a novel differentiable alignment framework based on\none-dimensional optimal transport, enabling the model to learn a single\nalignment and perform ASR in an E2E manner. We introduce a pseudo-metric,\ncalled Sequence Optimal Transport Distance (SOTD), over the sequence space and\ndiscuss its theoretical properties. Based on the SOTD, we propose Optimal\nTemporal Transport Classification (OTTC) loss for ASR and contrast its behavior\nwith CTC. Experimental results on the TIMIT, AMI, and LibriSpeech datasets show\nthat our method considerably improves alignment performance compared to CTC and\nthe more recently proposed Consistency-Regularized CTC, though with a trade-off\nin ASR performance. We believe this work opens new avenues for seq2seq\nalignment research, providing a solid foundation for further exploration and\ndevelopment within the community.",
    "published": "2025-02-03T18:20:29Z",
    "updated": "2025-10-08T13:13:58Z",
    "link": "http://arxiv.org/pdf/2502.01588v2.pdf",
    "category": [
      "cs.LG",
      "cs.SD",
      "eess.AS",
      "stat.ML"
    ],
    "authors": [
      "Yacouba Kaloga",
      "Shashi Kumar",
      "Petr Motlicek",
      "Ina Kodrasi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06987v1",
    "title": "Spiral Model Technique For Data Science & Machine Learning Lifecycle",
    "summary": "Analytics play an important role in modern business. Companies adapt data\nscience lifecycles to their culture to seek productivity and improve their\ncompetitiveness among others. Data science lifecycles are fairly an important\ncontributing factor to start and end a project that are data dependent. Data\nscience and Machine learning life cycles comprises of series of steps that are\ninvolved in a project. A typical life cycle states that it is a linear or\ncyclical model that revolves around. It is mostly depicted that it is possible\nin a traditional data science life cycle to start the process again after\nreaching the end of cycle. This paper suggests a new technique to incorporate\ndata science life cycle to business problems that have a clear end goal. A new\ntechnique called spiral technique is introduced to emphasize versatility,\nagility and iterative approach to business processes.",
    "published": "2025-10-08T13:11:58Z",
    "updated": "2025-10-08T13:11:58Z",
    "link": "http://arxiv.org/pdf/2510.06987v1.pdf",
    "category": [
      "cs.LG",
      "cs.IR",
      "cs.SE"
    ],
    "authors": [
      "Rohith Mahadevan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06980v1",
    "title": "Relational Database Distillation: From Structured Tables to Condensed\n  Graph Data",
    "summary": "Relational databases (RDBs) underpin the majority of global data management\nsystems, where information is structured into multiple interdependent tables.\nTo effectively use the knowledge within RDBs for predictive tasks, recent\nadvances leverage graph representation learning to capture complex inter-table\nrelations as multi-hop dependencies. Despite achieving state-of-the-art\nperformance, these methods remain hindered by the prohibitive storage overhead\nand excessive training time, due to the massive scale of the database and the\ncomputational burden of intensive message passing across interconnected tables.\nTo alleviate these concerns, we propose and study the problem of Relational\nDatabase Distillation (RDD). Specifically, we aim to distill large-scale RDBs\ninto compact heterogeneous graphs while retaining the predictive power (i.e.,\nutility) required for training graph-based models. Multi-modal column\ninformation is preserved through node features, and primary-foreign key\nrelations are encoded via heterogeneous edges, thereby maintaining both data\nfidelity and relational structure. To ensure adaptability across diverse\ndownstream tasks without engaging the traditional, inefficient bi-level\ndistillation framework, we further design a kernel ridge regression-guided\nobjective with pseudo-labels, which produces quality features for the distilled\ngraph. Extensive experiments on multiple real-world RDBs demonstrate that our\nsolution substantially reduces the data size while maintaining competitive\nperformance on classification and regression tasks, creating an effective\npathway for scalable learning with RDBs.",
    "published": "2025-10-08T13:05:31Z",
    "updated": "2025-10-08T13:05:31Z",
    "link": "http://arxiv.org/pdf/2510.06980v1.pdf",
    "category": [
      "cs.DB",
      "cs.LG"
    ],
    "authors": [
      "Xinyi Gao",
      "Jingxi Zhang",
      "Lijian Chen",
      "Tong Chen",
      "Lizhen Cui",
      "Hongzhi Yin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.12598v3",
    "title": "Dynamic Learning Rate for Deep Reinforcement Learning: A Bandit Approach",
    "summary": "In deep Reinforcement Learning (RL), the learning rate critically influences\nboth stability and performance, yet its optimal value shifts during training as\nthe environment and policy evolve. Standard decay schedulers assume monotonic\nconvergence and often misalign with these dynamics, leading to premature or\ndelayed adjustments. We introduce LRRL, a meta-learning approach that\ndynamically selects the learning rate based on policy performance rather than\ntraining steps. LRRL adaptively favors rates that improve returns, remaining\nrobust even when the candidate set includes values that individually cause\ndivergence. Across Atari and MuJoCo benchmarks, LRRL achieves performance\ncompetitive with or superior to tuned baselines and standard schedulers. Our\nfindings position LRRL as a practical solution for adapting to non-stationary\nobjectives in deep RL.",
    "published": "2024-10-16T14:15:28Z",
    "updated": "2025-10-08T12:58:01Z",
    "link": "http://arxiv.org/pdf/2410.12598v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Henrique Donâncio",
      "Antoine Barrier",
      "Leah F. South",
      "Florence Forbes"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06970v1",
    "title": "Falsification-Driven Reinforcement Learning for Maritime Motion Planning",
    "summary": "Compliance with maritime traffic rules is essential for the safe operation of\nautonomous vessels, yet training reinforcement learning (RL) agents to adhere\nto them is challenging. The behavior of RL agents is shaped by the training\nscenarios they encounter, but creating scenarios that capture the complexity of\nmaritime navigation is non-trivial, and real-world data alone is insufficient.\nTo address this, we propose a falsification-driven RL approach that generates\nadversarial training scenarios in which the vessel under test violates maritime\ntraffic rules, which are expressed as signal temporal logic specifications. Our\nexperiments on open-sea navigation with two vessels demonstrate that the\nproposed approach provides more relevant training scenarios and achieves more\nconsistent rule compliance.",
    "published": "2025-10-08T12:56:31Z",
    "updated": "2025-10-08T12:56:31Z",
    "link": "http://arxiv.org/pdf/2510.06970v1.pdf",
    "category": [
      "eess.SY",
      "cs.LG",
      "cs.SY"
    ],
    "authors": [
      "Marlon Müller",
      "Florian Finkeldei",
      "Hanna Krasowski",
      "Murat Arcak",
      "Matthias Althoff"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.05786v2",
    "title": "Möbius transforms and Shapley values for vector-valued functions on\n  weighted directed acyclic multigraphs",
    "summary": "We generalize the concept of M\\\"obius inversion and Shapley values to\ndirected acyclic multigraphs and weighted versions thereof. We further allow\nvalue functions (games) and thus their M\\\"obius transforms (synergy function)\nand Shapley values to have values in any abelian group that is a module over a\nring that contains the graph weights, e.g. vector-valued functions. To achieve\nthis and overcome the obstruction that the classical axioms (linearity,\nefficiency, null player, symmetry) are not strong enough to uniquely determine\nShapley values in this more general setting, we analyze Shapley values from two\nnovel points of view: 1) We introduce projection operators that allow us to\ninterpret Shapley values as the recursive projection and re-attribution of\nhigher-order synergies to lower-order ones; 2) we propose a strengthening of\nthe null player axiom and a localized symmetry axiom, namely the weak elements\nand flat hierarchy axioms. The former allows us to remove coalitions with\nvanishing synergy while preserving the rest of the hierarchical structure. The\nlatter treats player-coalition bonds uniformly in the corner case of\nhierarchically flat graphs. Together with linearity these axioms already imply\na unique explicit formula for the Shapley values, as well as classical\nproperties like efficiency, null player, symmetry, and novel ones like the\nprojection property. This whole framework then specializes to finite inclusion\nalgebras, lattices, partial orders and mereologies, and also recovers certain\npreviously known cases as corner cases, and presents others from a new\nperspective. The admission of general weighted directed acyclic multigraph\nstructured hierarchies and vector-valued functions and Shapley values opens up\nthe possibility for new analytic tools and application areas, like machine\nlearning, language processing, explainable artificial intelligence, and many\nmore.",
    "published": "2025-10-07T11:05:25Z",
    "updated": "2025-10-08T12:55:31Z",
    "link": "http://arxiv.org/pdf/2510.05786v2.pdf",
    "category": [
      "cs.GT",
      "cs.DM",
      "cs.LG",
      "math.CO",
      "91A12 (Primary) 06A07, 05E99 (Secondary)",
      "F.2.2; G.2.1; G.2.2; I.2.0"
    ],
    "authors": [
      "Patrick Forré",
      "Abel Jansma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.17063v2",
    "title": "Contrastive Graph Condensation: Advancing Data Versatility through\n  Self-Supervised Learning",
    "summary": "With the increasing computation of training graph neural networks (GNNs) on\nlarge-scale graphs, graph condensation (GC) has emerged as a promising solution\nto synthesize a compact, substitute graph of the large-scale original graph for\nefficient GNN training. However, existing GC methods predominantly employ\nclassification as the surrogate task for optimization, thus excessively relying\non node labels and constraining their utility in label-sparsity scenarios. More\ncritically, this surrogate task tends to overfit class-specific information\nwithin the condensed graph, consequently restricting the generalization\ncapabilities of GC for other downstream tasks. To address these challenges, we\nintroduce Contrastive Graph Condensation (CTGC), which adopts a self-supervised\nsurrogate task to extract critical, causal information from the original graph\nand enhance the cross-task generalizability of the condensed graph.\nSpecifically, CTGC employs a dual-branch framework to disentangle the\ngeneration of the node attributes and graph structures, where a dedicated\nstructural branch is designed to explicitly encode geometric information\nthrough nodes' positional embeddings. By implementing an alternating\noptimization scheme with contrastive loss terms, CTGC promotes the mutual\nenhancement of both branches and facilitates high-quality graph generation\nthrough the model inversion technique. Extensive experiments demonstrate that\nCTGC excels in handling various downstream tasks with a limited number of\nlabels, consistently outperforming state-of-the-art GC methods.",
    "published": "2024-11-26T03:01:22Z",
    "updated": "2025-10-08T12:49:19Z",
    "link": "http://arxiv.org/pdf/2411.17063v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Xinyi Gao",
      "Yayong Li",
      "Tong Chen",
      "Guanhua Ye",
      "Wentao Zhang",
      "Hongzhi Yin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06957v1",
    "title": "Accelerating Sparse Ternary GEMM for Quantized LLM inference on Apple\n  Silicon",
    "summary": "Sparse Ternary General Matrix-Matrix Multiplication (GEMM) remains\nunder-optimized in existing libraries for Apple Silicon CPUs. We present a\nSparse Ternary GEMM kernel optimized specifically for Apple's M-series\nprocessors. We propose a set of architecture-aware optimizations, including a\nnovel blocked and interleaved sparse data format to improve memory locality,\nstrategies to increase Instruction-Level Parallelism (ILP), and NEON-based\nSingle Instruction Multiple Data (SIMD) vectorization to exploit data-level\nparallelism. Our scalar implementation achieves up to a 5.98x performance\nincrease over a traditional Ternary Compressed Sparse Column (TCSC) baseline\nfor large matrices with 50% ternary nonzero values (sparsity), reaching up to a\n50.2% of the processor's theoretical peak performance, and remains stable\nacross varying sparsity levels. Our vectorized implementation delivers up to a\n5.59x performance increase for large matrices with 25% sparsity, and remains\nstable across varying sparsity levels.",
    "published": "2025-10-08T12:42:07Z",
    "updated": "2025-10-08T12:42:07Z",
    "link": "http://arxiv.org/pdf/2510.06957v1.pdf",
    "category": [
      "cs.PF",
      "cs.LG"
    ],
    "authors": [
      "Baraq Lipshitz",
      "Alessio Melone",
      "Charalampos Maraziaris",
      "Muhammed Bilal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06954v1",
    "title": "From Condensation to Rank Collapse: A Two-Stage Analysis of Transformer\n  Training Dynamics",
    "summary": "Although transformer-based models have shown exceptional empirical\nperformance, the fundamental principles governing their training dynamics are\ninadequately characterized beyond configuration-specific studies. Inspired by\nempirical evidence showing improved reasoning capabilities under small\ninitialization scales in language models, we employ the gradient flow\nanalytical framework established in [Zhou et al. NeurIPS 2022] to\nsystematically investigate linearized Transformer training dynamics. Our\ntheoretical analysis dissects the dynamics of attention modules into two\ndistinct stages. In the first stage, asymmetric weight perturbations from\nrandom initialization sustain non-degenerate gradient dynamics in parameter\nmatrices, facilitating systematic escape from small initialization regimes.\nSubsequently, these matrices undergo condensation, progressively aligning\ntoward the target orientation. In the second stage, the previously static\nkey-query matrices actively participate in training, driving the normalized\nmatrices toward asymptotic rank collapse. This two-stage framework generalizes\nclassical directional convergence results.",
    "published": "2025-10-08T12:37:53Z",
    "updated": "2025-10-08T12:37:53Z",
    "link": "http://arxiv.org/pdf/2510.06954v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Zheng-An Chen",
      "Tao Luo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06945v1",
    "title": "Fisher Information, Training and Bias in Fourier Regression Models",
    "summary": "Motivated by the growing interest in quantum machine learning, in particular\nquantum neural networks (QNNs), we study how recently introduced evaluation\nmetrics based on the Fisher information matrix (FIM) are effective for\npredicting their training and prediction performance. We exploit the\nequivalence between a broad class of QNNs and Fourier models, and study the\ninterplay between the \\emph{effective dimension} and the \\emph{bias} of a model\ntowards a given task, investigating how these affect the model's training and\nperformance. We show that for a model that is completely agnostic, or unbiased,\ntowards the function to be learned, a higher effective dimension likely results\nin a better trainability and performance. On the other hand, for models that\nare biased towards the function to be learned a lower effective dimension is\nlikely beneficial during training. To obtain these results, we derive an\nanalytical expression of the FIM for Fourier models and identify the features\ncontrolling a model's effective dimension. This allows us to construct models\nwith tunable effective dimension and bias, and to compare their training. We\nfurthermore introduce a tensor network representation of the considered Fourier\nmodels, which could be a tool of independent interest for the analysis of QNN\nmodels. Overall, these findings provide an explicit example of the interplay\nbetween geometrical properties, model-task alignment and training, which are\nrelevant for the broader machine learning community.",
    "published": "2025-10-08T12:29:11Z",
    "updated": "2025-10-08T12:29:11Z",
    "link": "http://arxiv.org/pdf/2510.06945v1.pdf",
    "category": [
      "cs.LG",
      "cond-mat.dis-nn",
      "physics.data-an",
      "quant-ph"
    ],
    "authors": [
      "Lorenzo Pastori",
      "Veronika Eyring",
      "Mierk Schwabe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06940v1",
    "title": "Revisiting Node Affinity Prediction in Temporal Graphs",
    "summary": "Node affinity prediction is a common task that is widely used in temporal\ngraph learning with applications in social and financial networks, recommender\nsystems, and more. Recent works have addressed this task by adapting\nstate-of-the-art dynamic link property prediction models to node affinity\nprediction. However, simple heuristics, such as Persistent Forecast or Moving\nAverage, outperform these models. In this work, we analyze the challenges in\ntraining current Temporal Graph Neural Networks for node affinity prediction\nand suggest appropriate solutions. Combining the solutions, we develop NAViS -\nNode Affinity prediction model using Virtual State, by exploiting the\nequivalence between heuristics and state space models. While promising,\ntraining NAViS is non-trivial. Therefore, we further introduce a novel loss\nfunction for node affinity prediction. We evaluate NAViS on TGB and show that\nit outperforms the state-of-the-art, including heuristics. Our source code is\navailable at https://github.com/orfeld415/NAVIS",
    "published": "2025-10-08T12:21:52Z",
    "updated": "2025-10-08T12:21:52Z",
    "link": "http://arxiv.org/pdf/2510.06940v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Krishna Sri Ipsit Mantri",
      "Or Feldman",
      "Moshe Eliasof",
      "Chaim Baskin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06935v1",
    "title": "PyCFRL: A Python library for counterfactually fair offline reinforcement\n  learning via sequential data preprocessing",
    "summary": "Reinforcement learning (RL) aims to learn and evaluate a sequential decision\nrule, often referred to as a \"policy\", that maximizes the population-level\nbenefit in an environment across possibly infinitely many time steps. However,\nthe sequential decisions made by an RL algorithm, while optimized to maximize\noverall population benefits, may disadvantage certain individuals who are in\nminority or socioeconomically disadvantaged groups. To address this problem, we\nintroduce PyCFRL, a Python library for ensuring counterfactual fairness in\noffline RL. PyCFRL implements a novel data preprocessing algorithm for learning\ncounterfactually fair RL policies from offline datasets and provides tools to\nevaluate the values and counterfactual unfairness levels of RL policies. We\ndescribe the high-level functionalities of PyCFRL and demonstrate one of its\nmajor use cases through a data example. The library is publicly available on\nPyPI and Github (https://github.com/JianhanZhang/PyCFRL), and detailed\ntutorials can be found in the PyCFRL documentation\n(https://pycfrl-documentation.netlify.app).",
    "published": "2025-10-08T12:19:10Z",
    "updated": "2025-10-08T12:19:10Z",
    "link": "http://arxiv.org/pdf/2510.06935v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Jianhan Zhang",
      "Jitao Wang",
      "Chengchun Shi",
      "John D. Piette",
      "Donglin Zeng",
      "Zhenke Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06931v1",
    "title": "Textual interpretation of transient image classifications from large\n  language models",
    "summary": "Modern astronomical surveys deliver immense volumes of transient detections,\nyet distinguishing real astrophysical signals (for example, explosive events)\nfrom bogus imaging artefacts remains a challenge. Convolutional neural networks\nare effectively used for real versus bogus classification; however, their\nreliance on opaque latent representations hinders interpretability. Here we\nshow that large language models (LLMs) can approach the performance level of a\nconvolutional neural network on three optical transient survey datasets\n(Pan-STARRS, MeerLICHT and ATLAS) while simultaneously producing direct,\nhuman-readable descriptions for every candidate. Using only 15 examples and\nconcise instructions, Google's LLM, Gemini, achieves a 93% average accuracy\nacross datasets that span a range of resolution and pixel scales. We also show\nthat a second LLM can assess the coherence of the output of the first model,\nenabling iterative refinement by identifying problematic cases. This framework\nallows users to define the desired classification behaviour through natural\nlanguage and examples, bypassing traditional training pipelines. Furthermore,\nby generating textual descriptions of observed features, LLMs enable users to\nquery classifications as if navigating an annotated catalogue, rather than\ndeciphering abstract latent spaces. As next-generation telescopes and surveys\nfurther increase the amount of data available, LLM-based classification could\nhelp bridge the gap between automated detection and transparent, human-level\nunderstanding.",
    "published": "2025-10-08T12:12:46Z",
    "updated": "2025-10-08T12:12:46Z",
    "link": "http://arxiv.org/pdf/2510.06931v1.pdf",
    "category": [
      "astro-ph.IM",
      "cs.LG"
    ],
    "authors": [
      "Fiorenzo Stoppa",
      "Turan Bulmus",
      "Steven Bloemen",
      "Stephen J. Smartt",
      "Paul J. Groot",
      "Paul Vreeswijk",
      "Ken W. Smith"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06925v1",
    "title": "Quantum Sparse Recovery and Quantum Orthogonal Matching Pursuit",
    "summary": "We study quantum sparse recovery in non-orthogonal, overcomplete\ndictionaries: given coherent quantum access to a state and a dictionary of\nvectors, the goal is to reconstruct the state up to $\\ell_2$ error using as few\nvectors as possible. We first show that the general recovery problem is\nNP-hard, ruling out efficient exact algorithms in full generality. To overcome\nthis, we introduce Quantum Orthogonal Matching Pursuit (QOMP), the first\nquantum analogue of the classical OMP greedy algorithm. QOMP combines quantum\nsubroutines for inner product estimation, maximum finding, and block-encoded\nprojections with an error-resetting design that avoids iteration-to-iteration\nerror accumulation. Under standard mutual incoherence and well-conditioned\nsparsity assumptions, QOMP provably recovers the exact support of a $K$-sparse\nstate in polynomial time. As an application, we give the first framework for\nsparse quantum tomography with non-orthogonal dictionaries in $\\ell_2$ norm,\nachieving query complexity $\\widetilde{O}(\\sqrt{N}/\\epsilon)$ in favorable\nregimes and reducing tomography to estimating only $K$ coefficients instead of\n$N$ amplitudes. In particular, for pure-state tomography with $m=O(N)$\ndictionary vectors and sparsity $K=\\widetilde{O}(1)$ on a well-conditioned\nsubdictionary, this circumvents the $\\widetilde{\\Omega}(N/\\epsilon)$ lower\nbound that holds in the dense, orthonormal-dictionary setting, without\ncontradiction, by leveraging sparsity together with non-orthogonality. Beyond\ntomography, we analyze QOMP in the QRAM model, where it yields polynomial\nspeedups over classical OMP implementations, and provide a quantum algorithm to\nestimate the mutual incoherence of a dictionary of $m$ vectors in\n$O(m/\\epsilon)$ queries, improving over both deterministic and quantum-inspired\nclassical methods.",
    "published": "2025-10-08T12:05:07Z",
    "updated": "2025-10-08T12:05:07Z",
    "link": "http://arxiv.org/pdf/2510.06925v1.pdf",
    "category": [
      "quant-ph",
      "cs.DS",
      "cs.LG"
    ],
    "authors": [
      "Armando Bellante",
      "Stefano Vanerio",
      "Stefano Zanero"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.11803v4",
    "title": "Automating RT Planning at Scale: High Quality Data For AI Training",
    "summary": "Radiotherapy (RT) planning is complex, subjective, and time-intensive.\nAdvances with artificial intelligence (AI) promise to improve its precision and\nefficiency, but progress is often limited by the scarcity of large,\nstandardized datasets. To address this, we introduce the Automated Iterative RT\nPlanning (AIRTP) system, a scalable solution for generating high-quality\ntreatment plans. This scalable solution is designed to generate substantial\nvolumes of consistently high-quality treatment plans, overcoming a key obstacle\nin the advancement of AI-driven RT planning. Our AIRTP pipeline adheres to\nclinical guidelines and automates essential steps, including organ-at-risk\n(OAR) contouring, helper structure creation, beam setup, optimization, and plan\nquality improvement, using AI integrated with RT planning software like Varian\nEclipse. Furthermore, a novel approach for determining optimization parameters\nto reproduce 3D dose distributions, i.e. a method to convert dose predictions\nto deliverable treatment plans constrained by machine limitations is proposed.\nA comparative analysis of plan quality reveals that our automated pipeline\nproduces treatment plans of quality comparable to those generated manually,\nwhich traditionally require several hours of labor per plan. Committed to\npublic research, the first data release of our AIRTP pipeline includes nine\ncohorts covering head-and-neck and lung cancer sites to support an AAPM 2025\nchallenge. To our best knowledge, this dataset features more than 10 times\nnumber of plans compared to the largest existing well-curated public dataset.\nRepo: https://github.com/RiqiangGao/GDP-HMM_AAPMChallenge.",
    "published": "2025-01-21T00:44:18Z",
    "updated": "2025-10-08T11:49:31Z",
    "link": "http://arxiv.org/pdf/2501.11803v4.pdf",
    "category": [
      "cs.HC",
      "cs.LG",
      "cs.RO"
    ],
    "authors": [
      "Riqiang Gao",
      "Mamadou Diallo",
      "Han Liu",
      "Anthony Magliari",
      "Jonathan Sackett",
      "Wilko Verbakel",
      "Sandra Meyers",
      "Rafe Mcbeth",
      "Masoud Zarepisheh",
      "Simon Arberet",
      "Martin Kraus",
      "Florin C. Ghesu",
      "Ali Kamen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06912v1",
    "title": "Utilizing Large Language Models for Machine Learning Explainability",
    "summary": "This study explores the explainability capabilities of large language models\n(LLMs), when employed to autonomously generate machine learning (ML) solutions.\nWe examine two classification tasks: (i) a binary classification problem\nfocused on predicting driver alertness states, and (ii) a multilabel\nclassification problem based on the yeast dataset. Three state-of-the-art LLMs\n(i.e. OpenAI GPT, Anthropic Claude, and DeepSeek) are prompted to design\ntraining pipelines for four common classifiers: Random Forest, XGBoost,\nMultilayer Perceptron, and Long Short-Term Memory networks. The generated\nmodels are evaluated in terms of predictive performance (recall, precision, and\nF1-score) and explainability using SHAP (SHapley Additive exPlanations).\nSpecifically, we measure Average SHAP Fidelity (Mean Squared Error between SHAP\napproximations and model outputs) and Average SHAP Sparsity (number of features\ndeemed influential). The results reveal that LLMs are capable of producing\neffective and interpretable models, achieving high fidelity and consistent\nsparsity, highlighting their potential as automated tools for interpretable ML\npipeline generation. The results show that LLMs can produce effective,\ninterpretable pipelines with high fidelity and consistent sparsity, closely\nmatching manually engineered baselines.",
    "published": "2025-10-08T11:46:23Z",
    "updated": "2025-10-08T11:46:23Z",
    "link": "http://arxiv.org/pdf/2510.06912v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Alexandros Vassiliades",
      "Nikolaos Polatidis",
      "Stamatios Samaras",
      "Sotiris Diplaris",
      "Ignacio Cabrera Martin",
      "Yannis Manolopoulos",
      "Stefanos Vrochidis",
      "Ioannis Kompatsiaris"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06910v1",
    "title": "Vacuum Spiker: A Spiking Neural Network-Based Model for Efficient\n  Anomaly Detection in Time Series",
    "summary": "Anomaly detection is a key task across domains such as industry, healthcare,\nand cybersecurity. Many real-world anomaly detection problems involve analyzing\nmultiple features over time, making time series analysis a natural approach for\nsuch problems. While deep learning models have achieved strong performance in\nthis field, their trend to exhibit high energy consumption limits their\ndeployment in resource-constrained environments such as IoT devices, edge\ncomputing platforms, and wearables. To address this challenge, this paper\nintroduces the \\textit{Vacuum Spiker algorithm}, a novel Spiking Neural\nNetwork-based method for anomaly detection in time series. It incorporates a\nnew detection criterion that relies on global changes in neural activity rather\nthan reconstruction or prediction error. It is trained using Spike\nTime-Dependent Plasticity in a novel way, intended to induce changes in neural\nactivity when anomalies occur. A new efficient encoding scheme is also\nproposed, which discretizes the input space into non-overlapping intervals,\nassigning each to a single neuron. This strategy encodes information with a\nsingle spike per time step, improving energy efficiency compared to\nconventional encoding methods. Experimental results on publicly available\ndatasets show that the proposed algorithm achieves competitive performance\nwhile significantly reducing energy consumption, compared to a wide set of deep\nlearning and machine learning baselines. Furthermore, its practical utility is\nvalidated in a real-world case study, where the model successfully identifies\npower curtailment events in a solar inverter. These results highlight its\npotential for sustainable and efficient anomaly detection.",
    "published": "2025-10-08T11:43:54Z",
    "updated": "2025-10-08T11:43:54Z",
    "link": "http://arxiv.org/pdf/2510.06910v1.pdf",
    "category": [
      "cs.LG",
      "I.2; I.5"
    ],
    "authors": [
      "Iago Xabier Vázquez",
      "Javier Sedano",
      "Muhammad Afzal",
      "Ángel Miguel García-Vico"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.04128v2",
    "title": "Who Pays for Fairness? Rethinking Recourse under Social Burden",
    "summary": "Machine learning based predictions are increasingly used in sensitive\ndecision-making applications that directly affect our lives. This has led to\nextensive research into ensuring the fairness of classifiers. Beyond just fair\nclassification, emerging legislation now mandates that when a classifier\ndelivers a negative decision, it must also offer actionable steps an individual\ncan take to reverse that outcome. This concept is known as algorithmic\nrecourse. Nevertheless, many researchers have expressed concerns about the\nfairness guarantees within the recourse process itself. In this work, we\nprovide a holistic theoretical characterization of unfairness in algorithmic\nrecourse, formally linking fairness guarantees in recourse and classification,\nand highlighting limitations of the standard equal cost paradigm. We then\nintroduce a novel fairness framework based on social burden, along with a\npractical algorithm (MISOB), broadly applicable under real-world conditions.\nEmpirical results on real-world datasets show that MISOB reduces the social\nburden across all groups without compromising overall classifier accuracy.",
    "published": "2025-09-04T11:53:42Z",
    "updated": "2025-10-08T11:28:46Z",
    "link": "http://arxiv.org/pdf/2509.04128v2.pdf",
    "category": [
      "cs.LG",
      "cs.CY"
    ],
    "authors": [
      "Ainhize Barrainkua",
      "Giovanni De Toni",
      "Jose Antonio Lozano",
      "Novi Quadrianto"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.20936v2",
    "title": "GenFacts-Generative Counterfactual Explanations for Multi-Variate Time\n  Series",
    "summary": "Counterfactual explanations aim to enhance model transparency by illustrating\nhow input modifications can change model predictions. In the multivariate time\nseries domain, existing approaches often produce counterfactuals that lack\nvalidity, plausibility, or intuitive interpretability. We present\n\\textbf{GenFacts}, a novel generative framework for producing plausible and\nactionable counterfactual explanations for time series classifiers. GenFacts\nintroduces a structured approach to latent space modeling and targeted\ncounterfactual synthesis.\n  We evaluate GenFacts on radar gesture recognition as an industrial use case\nand handwritten letter trajectories as an intuitive benchmark. Across both\ndatasets, GenFacts consistently outperforms baseline methods in plausibility\nmetrics (+18.7\\%) and achieves the highest interpretability scores in user\nstudies. These results underscore that realism and user-centered\ninterpretability, rather than sparsity alone, are vital for actionable\ncounterfactuals in time series applications.",
    "published": "2025-09-25T09:22:19Z",
    "updated": "2025-10-08T11:16:15Z",
    "link": "http://arxiv.org/pdf/2509.20936v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Sarah Seifi",
      "Anass Ibrahimi",
      "Tobias Sukianto",
      "Cecilia Carbonelli",
      "Lorenzo Servadei",
      "Robert Wille"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06050v2",
    "title": "Edit-Based Flow Matching for Temporal Point Processes",
    "summary": "Temporal point processes (TPPs) are a fundamental tool for modeling event\nsequences in continuous time, but most existing approaches rely on\nautoregressive parameterizations that are limited by their sequential sampling.\nRecent non-autoregressive, diffusion-style models mitigate these issues by\njointly interpolating between noise and data through event insertions and\ndeletions in a discrete Markov chain. In this work, we generalize this\nperspective and introduce an Edit Flow process for TPPs that transports noise\nto data via insert, delete, and substitute edit operations. By learning the\ninstantaneous edit rates within a continuous-time Markov chain framework, we\nattain a flexible and efficient model that effectively reduces the total number\nof necessary edit operations during generation. Empirical results demonstrate\nthe generative flexibility of our unconditionally trained model in a wide range\nof unconditional and conditional generation tasks on benchmark TPPs.",
    "published": "2025-10-07T15:44:12Z",
    "updated": "2025-10-08T10:51:35Z",
    "link": "http://arxiv.org/pdf/2510.06050v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "David Lüdke",
      "Marten Lienen",
      "Marcel Kollovieh",
      "Stephan Günnemann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.22524v3",
    "title": "Inference-Time Scaling of Discrete Diffusion Models via Importance\n  Weighting and Optimal Proposal Design",
    "summary": "Discrete diffusion models have become highly effective across various\ndomains. However, real-world applications often require the generative process\nto adhere to certain constraints. To this end, we propose a Sequential Monte\nCarlo (SMC) framework that enables scalable inference-time control of discrete\ndiffusion models through principled importance weighting and optimal proposal\nconstruction. Specifically, our approach derives tractable importance weights\nfor a range of intermediate targets and characterises the optimal proposal, for\nwhich we develop two practical approximations: a first-order gradient-based\napproximation and an amortised proposal trained to minimise the log-variance of\nthe importance weights. Empirical results across synthetic tasks, language\nmodelling, biology design, and text-to-image generation demonstrate that our\nframework enhances controllability and sample quality, highlighting the\neffectiveness of SMC as a versatile recipe for scaling discrete diffusion\nmodels at inference time.",
    "published": "2025-05-28T16:12:03Z",
    "updated": "2025-10-08T10:49:29Z",
    "link": "http://arxiv.org/pdf/2505.22524v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Zijing Ou",
      "Chinmay Pani",
      "Yingzhen Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.23385v3",
    "title": "Flow Matching for Robust Simulation-Based Inference under Model\n  Misspecification",
    "summary": "Simulation-based inference (SBI) is transforming experimental sciences by\nenabling parameter estimation in complex non-linear models from simulated data.\nA persistent challenge, however, is model misspecification: simulators are only\napproximations of reality, and mismatches between simulated and real data can\nyield biased or overconfident posteriors. We address this issue by introducing\nFlow Matching Corrected Posterior Estimation (FMCPE), a framework that\nleverages the flow matching paradigm to refine simulation-trained posterior\nestimators using a small set of real calibration samples. Our approach proceeds\nin two stages: first, a posterior approximator is trained on abundant simulated\ndata; second, flow matching transports its predictions toward the true\nposterior supported by real observations, without requiring explicit knowledge\nof the misspecification. This design enables FMCPE to combine the scalability\nof SBI with robustness to distributional shift. Across synthetic benchmarks and\nreal-world datasets, we show that our proposal consistently mitigates the\neffects of misspecification, delivering improved inference accuracy and\nuncertainty calibration compared to standard SBI baselines, while remaining\ncomputationally efficient.",
    "published": "2025-09-27T16:10:53Z",
    "updated": "2025-10-08T10:25:46Z",
    "link": "http://arxiv.org/pdf/2509.23385v3.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Pierre-Louis Ruhlmann",
      "Pedro L. C. Rodrigues",
      "Michael Arbel",
      "Florence Forbes"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.10186v2",
    "title": "P3D: Scalable Neural Surrogates for High-Resolution 3D Physics\n  Simulations with Global Context",
    "summary": "We present a scalable framework for learning deterministic and probabilistic\nneural surrogates for high-resolution 3D physics simulations. We introduce a\nhybrid CNN-Transformer backbone architecture targeted for 3D physics\nsimulations, which significantly outperforms existing architectures in terms of\nspeed and accuracy. Our proposed network can be pretrained on small patches of\nthe simulation domain, which can be fused to obtain a global solution,\noptionally guided via a fast and scalable sequence-to-sequence model to include\nlong-range dependencies. This setup allows for training large-scale models with\nreduced memory and compute requirements for high-resolution datasets. We\nevaluate our backbone architecture against a large set of baseline methods with\nthe objective to simultaneously learn the dynamics of 14 different types of\nPDEs in 3D. We demonstrate how to scale our model to high-resolution isotropic\nturbulence with spatial resolutions of up to $512^3$. Finally, we demonstrate\nthe versatility of our network by training it as a diffusion model to produce\nprobabilistic samples of highly turbulent 3D channel flows across varying\nReynolds numbers, accurately capturing the underlying flow statistics.",
    "published": "2025-09-12T12:26:06Z",
    "updated": "2025-10-08T10:19:07Z",
    "link": "http://arxiv.org/pdf/2509.10186v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Benjamin Holzschuh",
      "Georg Kohl",
      "Florian Redinger",
      "Nils Thuerey"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06848v1",
    "title": "Reconquering Bell sampling on qudits: stabilizer learning and testing,\n  quantum pseudorandomness bounds, and more",
    "summary": "Bell sampling is a simple yet powerful tool based on measuring two copies of\na quantum state in the Bell basis, and has found applications in a plethora of\nproblems related to stabiliser states and measures of magic. However, it was\nnot known how to generalise the procedure from qubits to $d$-level systems --\nqudits -- for all dimensions $d > 2$ in a useful way. Indeed, a prior work of\nthe authors (arXiv'24) showed that the natural extension of Bell sampling to\narbitrary dimensions fails to provide meaningful information about the quantum\nstates being measured. In this paper, we overcome the difficulties encountered\nin previous works and develop a useful generalisation of Bell sampling to\nqudits of all $d\\geq 2$. At the heart of our primitive is a new unitary, based\non Lagrange's four-square theorem, that maps four copies of any stabiliser\nstate $|\\mathcal{S}\\rangle$ to four copies of its complex conjugate\n$|\\mathcal{S}^\\ast\\rangle$ (up to some Pauli operator), which may be of\nindependent interest. We then demonstrate the utility of our new Bell sampling\ntechnique by lifting several known results from qubits to qudits for any $d\\geq\n2$:\n  1. Learning stabiliser states in $O(n^3)$ time with $O(n)$ samples;\n  2. Solving the Hidden Stabiliser Group Problem in\n$\\tilde{O}(n^3/\\varepsilon)$ time with $\\tilde{O}(n/\\varepsilon)$ samples;\n  3. Testing whether $|\\psi\\rangle$ has stabiliser size at least $d^t$ or is\n$\\varepsilon$-far from all such states in $\\tilde{O}(n^3/\\varepsilon)$ time\nwith $\\tilde{O}(n/\\varepsilon)$ samples;\n  4. Clifford circuits with at most $n/2$ single-qudit non-Clifford gates\ncannot prepare pseudorandom states;\n  5. Testing whether $|\\psi\\rangle$ has stabiliser fidelity at least\n$1-\\varepsilon_1$ or at most $1-\\varepsilon_2$ with $O(d^2/\\varepsilon_2)$\nsamples if $\\varepsilon_1 = 0$ or $O(d^2/\\varepsilon_2^2)$ samples if\n$\\varepsilon_1 = O(d^{-2})$.",
    "published": "2025-10-08T10:13:16Z",
    "updated": "2025-10-08T10:13:16Z",
    "link": "http://arxiv.org/pdf/2510.06848v1.pdf",
    "category": [
      "quant-ph",
      "cs.CC",
      "cs.DS",
      "cs.LG"
    ],
    "authors": [
      "Jonathan Allcock",
      "Joao F. Doriguello",
      "Gábor Ivanyos",
      "Miklos Santha"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.01642v5",
    "title": "Quantum Rationale-Aware Graph Contrastive Learning for Jet\n  Discrimination",
    "summary": "In high-energy physics, particle jet tagging plays a pivotal role in\ndistinguishing quark from gluon jets using data from collider experiments.\nWhile graph-based deep learning methods have advanced this task beyond\ntraditional feature-engineered approaches, the complex data structure and\nlimited labeled samples present ongoing challenges. However, existing\ncontrastive learning (CL) frameworks struggle to leverage rationale-aware\naugmentations effectively, often lacking supervision signals that guide the\nextraction of salient features and facing computational efficiency issues such\nas high parameter counts. In this study, we demonstrate that integrating a\nquantum rationale generator (QRG) within our proposed Quantum Rationale-aware\nGraph Contrastive Learning (QRGCL) framework significantly enhances jet\ndiscrimination performance, reducing reliance on labeled data and capturing\ndiscriminative features. Evaluated on the quark-gluon jet dataset, QRGCL\nachieves an AUC score of $77.53\\%$ while maintaining a compact architecture of\nonly 45 QRG parameters, outperforming classical, quantum, and hybrid GCL and\nGNN benchmarks. These results highlight QRGCL's potential to advance jet\ntagging and other complex classification tasks in high-energy physics, where\ncomputational efficiency and feature extraction limitations persist.",
    "published": "2024-11-03T17:36:05Z",
    "updated": "2025-10-08T10:09:02Z",
    "link": "http://arxiv.org/pdf/2411.01642v5.pdf",
    "category": [
      "cs.LG",
      "hep-ph"
    ],
    "authors": [
      "Md Abrar Jahin",
      "Md. Akmol Masud",
      "M. F. Mridha",
      "Nilanjan Dey",
      "Zeyar Aung"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06834v1",
    "title": "Vectorized FlashAttention with Low-cost Exponential Computation in\n  RISC-V Vector Processors",
    "summary": "Attention is a core operation in numerous machine learning and artificial\nintelligence models. This work focuses on the acceleration of attention kernel\nusing FlashAttention algorithm, in vector processors, particularly those based\non the RISC-V instruction set architecture (ISA). This work represents the\nfirst effort to vectorize FlashAttention, minimizing scalar code and\nsimplifying the computational complexity of evaluating exponentials needed by\nsoftmax used in attention. By utilizing a low-cost approximation for\nexponentials in floating-point arithmetic, we reduce the cost of computing the\nexponential function without the need to extend baseline vector ISA with new\ncustom instructions. Also, appropriate tiling strategies are explored with the\ngoal to improve memory locality. Experimental results highlight the scalability\nof our approach, demonstrating significant performance gains with the\nvectorized implementations when processing attention layers in practical\napplications.",
    "published": "2025-10-08T09:55:32Z",
    "updated": "2025-10-08T09:55:32Z",
    "link": "http://arxiv.org/pdf/2510.06834v1.pdf",
    "category": [
      "cs.LG",
      "cs.DC",
      "cs.PF"
    ],
    "authors": [
      "Vasileios Titopoulos",
      "Kosmas Alexandridis",
      "Giorgos Dimitrakopoulos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06831v1",
    "title": "Early wind turbine alarm prediction based on machine learning:\n  AlarmForecasting",
    "summary": "Alarm data is pivotal in curbing fault behavior in Wind Turbines (WTs) and\nforms the backbone for advancedpredictive monitoring systems. Traditionally,\nresearch cohorts have been confined to utilizing alarm data solelyas a\ndiagnostic tool, merely indicative of unhealthy status. However, this study\naims to offer a transformativeleap towards preempting alarms, preventing alarms\nfrom triggering altogether, and consequently avertingimpending failures. Our\nproposed Alarm Forecasting and Classification (AFC) framework is designed on\ntwosuccessive modules: first, the regression module based on long short-term\nmemory (LSTM) for time-series alarmforecasting, and thereafter, the\nclassification module to implement alarm tagging on the forecasted alarm.\nThisway, the entire alarm taxonomy can be forecasted reliably rather than a few\nspecific alarms. 14 Senvion MM82turbines with an operational period of 5 years\nare used as a case study; the results demonstrated 82%, 52%,and 41% accurate\nforecasts for 10, 20, and 30 min alarm forecasts, respectively. The results\nsubstantiateanticipating and averting alarms, which is significant in curbing\nalarm frequency and enhancing operationalefficiency through proactive\nintervention.",
    "published": "2025-10-08T09:53:49Z",
    "updated": "2025-10-08T09:53:49Z",
    "link": "http://arxiv.org/pdf/2510.06831v1.pdf",
    "category": [
      "cs.LG",
      "physics.app-ph"
    ],
    "authors": [
      "Syed Shazaib Shah",
      "Daoliang Tan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06824v1",
    "title": "Efficient numeracy in language models through single-token number\n  embeddings",
    "summary": "To drive progress in science and engineering, large language models (LLMs)\nmust be able to process large amounts of numerical data and solve long\ncalculations efficiently. This is currently only possible through the use of\nexternal tools or extensive reasoning chains, either limiting the numerical\nintuition of LLMs or limiting the length of problems they can solve. We show\nthat frontier LLMs require excessive amounts of reasoning tokens to solve even\nbasic calculations, which is exacerbated by their tokenization strategies that\nsplit single numbers into multiple tokens. This motivates the need for\nefficient and effective single-token number encodings. We introduce a set of\ndesiderata for such encodings and show that existing approaches fail to fulfill\nthem. To address these shortcomings, we propose BitTokens, a novel tokenization\nstrategy that embeds any number into a single token using its IEEE 754 binary\nfloating-point representation. Through extensive experiments we show that our\nBitTokens allow even small language models to learn algorithms that solve basic\narithmetic operations nearly perfectly. This newly gained efficiency could\nexpand the length and complexity of problems language models can solve.",
    "published": "2025-10-08T09:48:11Z",
    "updated": "2025-10-08T09:48:11Z",
    "link": "http://arxiv.org/pdf/2510.06824v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Linus Kreitner",
      "Paul Hager",
      "Jonathan Mengedoht",
      "Georgios Kaissis",
      "Daniel Rueckert",
      "Martin J. Menten"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06819v1",
    "title": "The Unreasonable Effectiveness of Randomized Representations in Online\n  Continual Graph Learning",
    "summary": "Catastrophic forgetting is one of the main obstacles for Online Continual\nGraph Learning (OCGL), where nodes arrive one by one, distribution drifts may\noccur at any time and offline training on task-specific subgraphs is not\nfeasible. In this work, we explore a surprisingly simple yet highly effective\napproach for OCGL: we use a fixed, randomly initialized encoder to generate\nrobust and expressive node embeddings by aggregating neighborhood information,\ntraining online only a lightweight classifier. By freezing the encoder, we\neliminate drifts of the representation parameters, a key source of forgetting,\nobtaining embeddings that are both expressive and stable. When evaluated across\nseveral OCGL benchmarks, despite its simplicity and lack of memory buffer, this\napproach yields consistent gains over state-of-the-art methods, with surprising\nimprovements of up to 30% and performance often approaching that of the joint\noffline-training upper bound. These results suggest that in OCGL, catastrophic\nforgetting can be minimized without complex replay or regularization by\nembracing architectural simplicity and stability.",
    "published": "2025-10-08T09:44:14Z",
    "updated": "2025-10-08T09:44:14Z",
    "link": "http://arxiv.org/pdf/2510.06819v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Giovanni Donghi",
      "Daniele Zambon",
      "Luca Pasa",
      "Cesare Alippi",
      "Nicolò Navarin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.12845v4",
    "title": "ExLLM: Experience-Enhanced LLM Optimization for Molecular Design and\n  Beyond",
    "summary": "Molecular design involves an enormous and irregular search space, where\ntraditional optimizers such as Bayesian optimization, genetic algorithms, and\ngenerative models struggle to leverage expert knowledge or handle complex\nfeedback. Recently, LLMs have been used as optimizers, achieving promising\nresults on benchmarks such as PMO. However, existing approaches rely only on\nprompting or extra training, without mechanisms to handle complex feedback or\nmaintain scalable memory. In particular, the common practice of appending or\nsummarizing experiences at every query leads to redundancy, degraded\nexploration, and ultimately poor final outcomes under large-scale iterative\nsearch. We introduce ExLLM (Experience-Enhanced LLM optimization), an\nLLM-as-optimizer framework with three components: (1) a compact, evolving\nexperience snippet tailored to large discrete spaces that distills\nnon-redundant cues and improves convergence at low cost; (2) a simple yet\neffective k-offspring scheme that widens exploration per call and reduces\norchestration cost; and (3) a lightweight feedback adapter that normalizes\nobjectives for selection while formatting constraints and expert hints for\niteration. ExLLM sets new state-of-the-art results on PMO and generalizes\nstrongly in our setup, it sets records on circle packing and stellarator\ndesign, and yields consistent gains across additional domains requiring only a\ntask-description template and evaluation functions to transfer.",
    "published": "2025-02-18T13:25:00Z",
    "updated": "2025-10-08T09:32:42Z",
    "link": "http://arxiv.org/pdf/2502.12845v4.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Nian Ran",
      "Yue Wang",
      "Xiaoyuan Zhang",
      "Zhongzheng Li",
      "Qingsong Ran",
      "Wenhao Li",
      "Richard Allmendinger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06803v1",
    "title": "Quantum Computing Methods for Malware Detection",
    "summary": "In this paper, we explore the potential of quantum computing in enhancing\nmalware detection through the application of Quantum Machine Learning (QML).\nOur main objective is to investigate the performance of the Quantum Support\nVector Machine (QSVM) algorithm compared to SVM. A publicly available dataset\ncontaining raw binaries of Portable Executable (PE) files was used for the\nclassification. The QSVM algorithm, incorporating quantum kernels through\ndifferent feature maps, was implemented and evaluated on a local simulator\nwithin the Qiskit SDK and IBM quantum computers. Experimental results from\nsimulators and quantum hardware provide insights into the behavior and\nperformance of quantum computers, especially in handling large-scale\ncomputations for malware detection tasks. The work summarizes the practical\nexperience with using quantum hardware via the Qiskit interfaces. We describe\nin detail the critical issues encountered, as well as the fixes that had to be\ndeveloped and applied to the base code of the Qiskit Machine Learning library.\nThese issues include missing transpilation of the circuits submitted to IBM\nQuantum systems and exceeding the maximum job size limit due to the submission\nof all the circuits in one job.",
    "published": "2025-10-08T09:31:31Z",
    "updated": "2025-10-08T09:31:31Z",
    "link": "http://arxiv.org/pdf/2510.06803v1.pdf",
    "category": [
      "quant-ph",
      "cs.LG"
    ],
    "authors": [
      "Eliška Krátká",
      "Aurél Gábor Gábris"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.10098v2",
    "title": "Estimating the Joint Probability of Scenario Parameters with Gaussian\n  Mixture Copula Models",
    "summary": "This paper presents the first application of Gaussian Mixture Copula Models\nto the statistical modeling of driving scenarios for the safety validation of\nautomated driving systems. Knowledge of the joint probability distribution of\nscenario parameters is essential for scenario-based safety assessment, where\nrisk quantification depends on the likelihood of concrete parameter\ncombinations. Gaussian Mixture Copula Models bring together the multimodal\nexpressivity of Gaussian Mixture Models and the flexibility of copulas,\nenabling separate modeling of marginal distributions and dependencies. We\nbenchmark Gaussian Mixture Copula Models against previously proposed approaches\n- Gaussian Mixture Models and Gaussian Copula Models - using real-world driving\ndata drawn from scenarios defined in United Nations Regulation No. 157. Our\nevaluation across approximately 18 million scenario instances demonstrates that\nGaussian Mixture Copula Models consistently surpass Gaussian Copula Models and\nperform better than, or at least comparably to, Gaussian Mixture Models, as\nmeasured by both log-likelihood and Sinkhorn distance. These results are\npromising for the adoption of Gaussian Mixture Copula Models as a statistical\nfoundation for future scenario-based validation frameworks.",
    "published": "2025-06-11T18:30:20Z",
    "updated": "2025-10-08T09:26:20Z",
    "link": "http://arxiv.org/pdf/2506.10098v2.pdf",
    "category": [
      "cs.RO",
      "cs.LG"
    ],
    "authors": [
      "Christian Reichenbächer",
      "Philipp Rank",
      "Jochen Hipp",
      "Oliver Bringmann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06790v1",
    "title": "Get RICH or Die Scaling: Profitably Trading Inference Compute for\n  Robustness",
    "summary": "Models are susceptible to adversarially out-of-distribution (OOD) data\ndespite large training-compute investments into their robustification. Zaremba\net al. (2025) make progress on this problem at test time, showing LLM reasoning\nimproves satisfaction of model specifications designed to thwart attacks,\nresulting in a correlation between reasoning effort and robustness to\njailbreaks. However, this benefit of test compute fades when attackers are\ngiven access to gradients or multimodal inputs. We address this gap, clarifying\nthat inference-compute offers benefits even in such cases. Our approach argues\nthat compositional generalization, through which OOD data is understandable via\nits in-distribution (ID) components, enables adherence to defensive\nspecifications on adversarially OOD inputs. Namely, we posit the Robustness\nfrom Inference Compute Hypothesis (RICH): inference-compute defenses profit as\nthe model's training data better reflects the attacked data's components. We\nempirically support this hypothesis across vision language model and attack\ntypes, finding robustness gains from test-time compute if specification\nfollowing on OOD data is unlocked by compositional generalization, while RL\nfinetuning and protracted reasoning are not critical. For example, increasing\nemphasis on defensive specifications via prompting lowers the success rate of\ngradient-based multimodal attacks on VLMs robustified by adversarial\npretraining, but this same intervention provides no such benefit to\nnot-robustified models. This correlation of inference-compute's robustness\nbenefit with base model robustness is the rich-get-richer dynamic of the RICH:\nattacked data components are more ID for robustified models, aiding\ncompositional generalization to OOD data. Accordingly, we advise layering\ntrain-time and test-time defenses to obtain their synergistic benefit.",
    "published": "2025-10-08T09:18:53Z",
    "updated": "2025-10-08T09:18:53Z",
    "link": "http://arxiv.org/pdf/2510.06790v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Tavish McDonald",
      "Bo Lei",
      "Stanislav Fort",
      "Bhavya Kailkhura",
      "Brian Bartoldson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.16063v4",
    "title": "VICON: Vision In-Context Operator Networks for Multi-Physics Fluid\n  Dynamics Prediction",
    "summary": "In-Context Operator Networks (ICONs) have demonstrated the ability to learn\noperators across diverse partial differential equations using few-shot,\nin-context learning. However, existing ICONs process each spatial point as an\nindividual token, severely limiting computational efficiency when handling\ndense data in higher spatial dimensions. We propose Vision In-Context Operator\nNetworks (VICON), which integrates vision transformer architectures to\nefficiently process 2D data through patch-wise operations while preserving\nICON's adaptability to multiphysics systems and varying timesteps. Evaluated\nacross three fluid dynamics benchmarks, VICON significantly outperforms\nstate-of-the-art baselines: DPOT and MPP, reducing the averaged last-step\nrollout error by 37.9% compared to DPOT and 44.7% compared to MPP, while\nrequiring only 72.5% and 34.8% of their respective inference times. VICON\nnaturally supports flexible rollout strategies with varying timestep strides,\nenabling immediate deployment in imperfect measurement systems where sampling\nfrequencies may differ or frames might be dropped - common challenges in\nreal-world settings - without requiring retraining or interpolation. In these\nrealistic scenarios, VICON exhibits remarkable robustness, experiencing only\n24.41% relative performance degradation compared to 71.37%-74.49% degradation\nin baseline methods, demonstrating its versatility for deploying in realistic\napplications. Our scripts for processing datasets and code are publicly\navailable at https://github.com/Eydcao/VICON.",
    "published": "2024-11-25T03:25:17Z",
    "updated": "2025-10-08T09:18:34Z",
    "link": "http://arxiv.org/pdf/2411.16063v4.pdf",
    "category": [
      "cs.LG",
      "cs.NA",
      "math.NA",
      "physics.flu-dyn"
    ],
    "authors": [
      "Yadi Cao",
      "Yuxuan Liu",
      "Liu Yang",
      "Rose Yu",
      "Hayden Schaeffer",
      "Stanley Osher"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06762v1",
    "title": "Function regression using the forward forward training and inferring\n  paradigm",
    "summary": "Function regression/approximation is a fundamental application of machine\nlearning. Neural networks (NNs) can be easily trained for function regression\nusing a sufficient number of neurons and epochs. The forward-forward learning\nalgorithm is a novel approach for training neural networks without\nbackpropagation, and is well suited for implementation in neuromorphic\ncomputing and physical analogs for neural networks. To the best of the authors'\nknowledge, the Forward Forward paradigm of training and inferencing NNs is\ncurrently only restricted to classification tasks. This paper introduces a new\nmethodology for approximating functions (function regression) using the\nForward-Forward algorithm. Furthermore, the paper evaluates the developed\nmethodology on univariate and multivariate functions, and provides preliminary\nstudies of extending the proposed Forward-Forward regression to Kolmogorov\nArnold Networks, and Deep Physical Neural Networks.",
    "published": "2025-10-08T08:41:14Z",
    "updated": "2025-10-08T08:41:14Z",
    "link": "http://arxiv.org/pdf/2510.06762v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Shivam Padmani",
      "Akshay Joshi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.11006v3",
    "title": "Is Supervised Learning Really That Different from Unsupervised?",
    "summary": "We demonstrate how supervised learning can be decomposed into a two-stage\nprocedure, where (1) all model parameters are selected in an unsupervised\nmanner, and (2) the outputs y are added to the model, without changing the\nparameter values. This is achieved by a new model selection criterion that, in\ncontrast to cross-validation, can be used also without access to y. For linear\nridge regression, we bound the asymptotic out-of-sample risk of our method in\nterms of the optimal asymptotic risk. We also demonstrate on real and synthetic\ndata that versions of linear and kernel ridge regression, smoothing splines,\nand neural networks, which are trained without access to y, perform similarly\nto their standard y-based counterparts. Hence, our results suggest that the\ndifference between supervised and unsupervised learning is less fundamental\nthan it may appear.",
    "published": "2025-05-16T08:51:44Z",
    "updated": "2025-10-08T08:28:20Z",
    "link": "http://arxiv.org/pdf/2505.11006v3.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Oskar Allerbo",
      "Thomas B. Schön"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.00656v3",
    "title": "2 OLMo 2 Furious",
    "summary": "We present OLMo 2, the next generation of our fully open language models.\nOLMo 2 includes a family of dense autoregressive language models at 7B, 13B and\n32B scales with fully released artifacts -- model weights, full training data,\ntraining code and recipes, training logs and thousands of intermediate\ncheckpoints. In this work, we describe our modified model architecture and\ntraining recipe, focusing on techniques for achieving better training stability\nand improved per-token efficiency. Our updated pretraining data mixture\nintroduces a new, specialized data mix called Dolmino Mix 1124, which\nsignificantly improves model capabilities across many downstream task\nbenchmarks when introduced via late-stage curriculum training (i.e. specialized\ndata during the annealing phase of pretraining). Finally, we incorporate best\npractices from T\\\"ulu 3 to develop OLMo 2-Instruct, focusing on permissive data\nand extending our final-stage reinforcement learning with verifiable rewards\n(RLVR). Our OLMo 2 base models sit at the Pareto frontier of performance to\ntraining compute, often matching or outperforming open-weight only models like\nLlama 3.1, Qwen 2.5, and Gemma 2 while using fewer FLOPs and with fully\ntransparent training data, code, and recipe. Our fully open OLMo 2-Instruct\nmodels are competitive with open-weight only models of comparable size and even\nsome proprietary models like GPT-3.5 Turbo and GPT 4o Mini.",
    "published": "2024-12-31T21:55:10Z",
    "updated": "2025-10-08T07:50:45Z",
    "link": "http://arxiv.org/pdf/2501.00656v3.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Team OLMo",
      "Pete Walsh",
      "Luca Soldaini",
      "Dirk Groeneveld",
      "Kyle Lo",
      "Shane Arora",
      "Akshita Bhagia",
      "Yuling Gu",
      "Shengyi Huang",
      "Matt Jordan",
      "Nathan Lambert",
      "Dustin Schwenk",
      "Oyvind Tafjord",
      "Taira Anderson",
      "David Atkinson",
      "Faeze Brahman",
      "Christopher Clark",
      "Pradeep Dasigi",
      "Nouha Dziri",
      "Allyson Ettinger",
      "Michal Guerquin",
      "David Heineman",
      "Hamish Ivison",
      "Pang Wei Koh",
      "Jiacheng Liu",
      "Saumya Malik",
      "William Merrill",
      "Lester James V. Miranda",
      "Jacob Morrison",
      "Tyler Murray",
      "Crystal Nam",
      "Jake Poznanski",
      "Valentina Pyatkin",
      "Aman Rangapur",
      "Michael Schmitz",
      "Sam Skjonsberg",
      "David Wadden",
      "Christopher Wilhelm",
      "Michael Wilson",
      "Luke Zettlemoyer",
      "Ali Farhadi",
      "Noah A. Smith",
      "Hannaneh Hajishirzi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06735v1",
    "title": "Incorporating Expert Knowledge into Bayesian Causal Discovery of\n  Mixtures of Directed Acyclic Graphs",
    "summary": "Bayesian causal discovery benefits from prior information elicited from\ndomain experts, and in heterogeneous domains any prior knowledge would be badly\nneeded. However, so far prior elicitation approaches have assumed a single\ncausal graph and hence are not suited to heterogeneous domains. We propose a\ncausal elicitation strategy for heterogeneous settings, based on Bayesian\nexperimental design (BED) principles, and a variational mixture structure\nlearning (VaMSL) method -- extending the earlier differentiable Bayesian\nstructure learning (DiBS) method -- to iteratively infer mixtures of causal\nBayesian networks (CBNs). We construct an informative graph prior incorporating\nelicited expert feedback in the inference of mixtures of CBNs. Our proposed\nmethod successfully produces a set of alternative causal models (mixture\ncomponents or clusters), and achieves an improved structure learning\nperformance on heterogeneous synthetic data when informed by a simulated\nexpert. Finally, we demonstrate that our approach is capable of capturing\ncomplex distributions in a breast cancer database.",
    "published": "2025-10-08T07:47:18Z",
    "updated": "2025-10-08T07:47:18Z",
    "link": "http://arxiv.org/pdf/2510.06735v1.pdf",
    "category": [
      "cs.LG",
      "stat.ME"
    ],
    "authors": [
      "Zachris Björkman",
      "Jorge Loría",
      "Sophie Wharrie",
      "Samuel Kaski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.15112v3",
    "title": "Distributional Machine Unlearning via Selective Data Removal",
    "summary": "Machine learning systems increasingly face requirements to remove entire\ndomains of information -- such as toxic language or biases -- rather than\nindividual user data. This task presents a dilemma: full removal of the\nunwanted domain data is computationally expensive, while random partial removal\nis statistically inefficient. We find that a domain's statistical influence is\noften concentrated in a small subset of its data samples, suggesting a path\nbetween ineffective partial removal and unnecessary complete removal. We\nformalize this as distributional unlearning: a framework to select a small\nsubset that balances forgetting an unwanted distribution while preserving a\ndesired one. Using Kullback-Leibler divergence constraints, we derive the exact\nremoval-preservation Pareto frontier for exponential families and prove that\nmodels trained on the edited data achieve corresponding log-loss bounds. We\npropose a distance-based selection algorithm and show it is quadratically more\nsample-efficient than random removal in the challenging low-divergence regime.\nExperiments across synthetic, text, and image datasets (Jigsaw, CIFAR-10, SMS\nspam) show our method requires 15-82% less deletion than full removal for\nstrong unlearning effects, e.g., halving initial forget set accuracy.\nUltimately, by showing a small forget set often suffices, our framework lays\nthe foundations for more scalable and rigorous subpopulation unlearning.",
    "published": "2025-07-20T20:21:23Z",
    "updated": "2025-10-08T07:38:34Z",
    "link": "http://arxiv.org/pdf/2507.15112v3.pdf",
    "category": [
      "cs.LG",
      "cs.CR",
      "stat.ML"
    ],
    "authors": [
      "Youssef Allouah",
      "Rachid Guerraoui",
      "Sanmi Koyejo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2208.03761v2",
    "title": "An Empirical Analysis of the Laplace and Neural Tangent Kernels",
    "summary": "The neural tangent kernel is a kernel function defined over the parameter\ndistribution of an infinite width neural network. Despite the impracticality of\nthis limit, the neural tangent kernel has allowed for a more direct study of\nneural networks and a gaze through the veil of their black box. More recently,\nit has been shown theoretically that the Laplace kernel and neural tangent\nkernel share the same reproducing kernel Hilbert space in the space of\n$\\mathbb{S}^{d-1}$ alluding to their equivalence. In this work, we analyze the\npractical equivalence of the two kernels. We first do so by matching the\nkernels exactly and then by matching posteriors of a Gaussian process.\nMoreover, we analyze the kernels in $\\mathbb{R}^d$ and experiment with them in\nthe task of regression.",
    "published": "2022-08-07T16:18:02Z",
    "updated": "2025-10-08T07:37:52Z",
    "link": "http://arxiv.org/pdf/2208.03761v2.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "math.FA",
      "math.ST",
      "stat.TH",
      "62M08 (Primary), 46C08 (Secondary)",
      "G.3"
    ],
    "authors": [
      "Ronaldas Paulius Lencevičius"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.09755v3",
    "title": "Jailbreak Attack Initializations as Extractors of Compliance Directions",
    "summary": "Safety-aligned LLMs respond to prompts with either compliance or refusal,\neach corresponding to distinct directions in the model's activation space.\nRecent works show that initializing attacks via self-transfer from other\nprompts significantly enhances their performance. However, the underlying\nmechanisms of these initializations remain unclear, and attacks utilize\narbitrary or hand-picked initializations. This work presents that each\ngradient-based jailbreak attack and subsequent initialization gradually\nconverge to a single compliance direction that suppresses refusal, thereby\nenabling an efficient transition from refusal to compliance. Based on this\ninsight, we propose CRI, an initialization framework that aims to project\nunseen prompts further along compliance directions. We demonstrate our approach\non multiple attacks, models, and datasets, achieving an increased attack\nsuccess rate (ASR) and reduced computational overhead, highlighting the\nfragility of safety-aligned LLMs. A reference implementation is available at:\nhttps://amit1221levi.github.io/CRI-Jailbreak-Init-LLMs-evaluation.",
    "published": "2025-02-13T20:25:40Z",
    "updated": "2025-10-08T07:28:04Z",
    "link": "http://arxiv.org/pdf/2502.09755v3.pdf",
    "category": [
      "cs.CR",
      "cs.LG"
    ],
    "authors": [
      "Amit Levi",
      "Rom Himelstein",
      "Yaniv Nemcovsky",
      "Avi Mendelson",
      "Chaim Baskin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06719v1",
    "title": "Differentially Private Synthetic Text Generation for Retrieval-Augmented\n  Generation (RAG)",
    "summary": "Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by\ngrounding them in external knowledge. However, its application in sensitive\ndomains is limited by privacy risks. Existing private RAG methods typically\nrely on query-time differential privacy (DP), which requires repeated noise\ninjection and leads to accumulated privacy loss. To address this issue, we\npropose DP-SynRAG, a framework that uses LLMs to generate differentially\nprivate synthetic RAG databases. Unlike prior methods, the synthetic text can\nbe reused once created, thereby avoiding repeated noise injection and\nadditional privacy costs. To preserve essential information for downstream RAG\ntasks, DP-SynRAG extends private prediction, which instructs LLMs to generate\ntext that mimics subsampled database records in a DP manner. Experiments show\nthat DP-SynRAG achieves superior performanec to the state-of-the-art private\nRAG systems while maintaining a fixed privacy budget, offering a scalable\nsolution for privacy-preserving RAG.",
    "published": "2025-10-08T07:15:50Z",
    "updated": "2025-10-08T07:15:50Z",
    "link": "http://arxiv.org/pdf/2510.06719v1.pdf",
    "category": [
      "cs.CR",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Junki Mori",
      "Kazuya Kakizaki",
      "Taiki Miyagawa",
      "Jun Sakuma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.06274v3",
    "title": "IPR: Intelligent Prompt Routing with User-Controlled Quality-Cost\n  Trade-offs",
    "summary": "Routing incoming queries to the most cost-effective LLM while maintaining\nresponse quality poses a fundamental challenge in optimizing performance-cost\ntrade-offs for large-scale commercial systems. We present IPR\\, -- \\,a\nquality-constrained \\textbf{I}ntelligent \\textbf{P}rompt \\textbf{R}outing\nframework that dynamically selects optimal models based on predicted response\nquality and user-specified tolerance levels. IPR introduces three key\ninnovations: (1) a modular architecture with lightweight quality estimators\ntrained on 1.5M prompts annotated with calibrated quality scores, enabling\nfine-grained quality prediction across model families; (2) a user-controlled\nrouting mechanism with tolerance parameter $\\tau \\in [0,1]$ that provides\nexplicit control over quality-cost trade-offs; and (3) an extensible design\nusing frozen encoders with model-specific adapters, reducing new model\nintegration from days to hours. To rigorously train and evaluate IPR, we curate\nan industrial-level dataset IPRBench\\footnote{IPRBench will be released upon\nlegal approval.}, a comprehensive benchmark containing 1.5 million examples\nwith response quality annotations across 11 LLM candidates. Deployed on a major\ncloud platform, IPR achieves 43.9\\% cost reduction while maintaining quality\nparity with the strongest model in the Claude family and processes requests\nwith sub-150ms latency. The deployed system and additional product details are\npublicly available at\nhttps://aws.amazon.com/bedrock/intelligent-prompt-routing/",
    "published": "2025-09-08T01:46:27Z",
    "updated": "2025-10-08T06:57:37Z",
    "link": "http://arxiv.org/pdf/2509.06274v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Aosong Feng",
      "Balasubramaniam Srinivasan",
      "Yun Zhou",
      "Zhichao Xu",
      "Kang Zhou",
      "Sheng Guan",
      "Yueyan Chen",
      "Xian Wu",
      "Ninad Kulkarni",
      "Yi Zhang",
      "Zhengyuan Shen",
      "Dmitriy Bespalov",
      "Soumya Smruti Mishra",
      "Yifei Teng",
      "Darren Yow-Bang Wang",
      "Haibo Ding",
      "Lin Lee Cheong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.05070v2",
    "title": "ResMimic: From General Motion Tracking to Humanoid Whole-body\n  Loco-Manipulation via Residual Learning",
    "summary": "Humanoid whole-body loco-manipulation promises transformative capabilities\nfor daily service and warehouse tasks. While recent advances in general motion\ntracking (GMT) have enabled humanoids to reproduce diverse human motions, these\npolicies lack the precision and object awareness required for\nloco-manipulation. To this end, we introduce ResMimic, a two-stage residual\nlearning framework for precise and expressive humanoid control from human\nmotion data. First, a GMT policy, trained on large-scale human-only motion,\nserves as a task-agnostic base for generating human-like whole-body movements.\nAn efficient but precise residual policy is then learned to refine the GMT\noutputs to improve locomotion and incorporate object interaction. To further\nfacilitate efficient training, we design (i) a point-cloud-based object\ntracking reward for smoother optimization, (ii) a contact reward that\nencourages accurate humanoid body-object interactions, and (iii) a\ncurriculum-based virtual object controller to stabilize early training. We\nevaluate ResMimic in both simulation and on a real Unitree G1 humanoid. Results\nshow substantial gains in task success, training efficiency, and robustness\nover strong baselines. Videos are available at https://resmimic.github.io/ .",
    "published": "2025-10-06T17:47:02Z",
    "updated": "2025-10-08T06:51:48Z",
    "link": "http://arxiv.org/pdf/2510.05070v2.pdf",
    "category": [
      "cs.RO",
      "cs.LG"
    ],
    "authors": [
      "Siheng Zhao",
      "Yanjie Ze",
      "Yue Wang",
      "C. Karen Liu",
      "Pieter Abbeel",
      "Guanya Shi",
      "Rocky Duan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06699v1",
    "title": "A Diffusion Model for Regular Time Series Generation from Irregular Data\n  with Completion and Masking",
    "summary": "Generating realistic time series data is critical for applications in\nhealthcare, finance, and science. However, irregular sampling and missing\nvalues present significant challenges. While prior methods address these\nirregularities, they often yield suboptimal results and incur high\ncomputational costs. Recent advances in regular time series generation, such as\nthe diffusion-based ImagenTime model, demonstrate strong, fast, and scalable\ngenerative capabilities by transforming time series into image representations,\nmaking them a promising solution. However, extending ImagenTime to irregular\nsequences using simple masking introduces \"unnatural\" neighborhoods, where\nmissing values replaced by zeros disrupt the learning process. To overcome\nthis, we propose a novel two-step framework: first, a Time Series Transformer\ncompletes irregular sequences, creating natural neighborhoods; second, a\nvision-based diffusion model with masking minimizes dependence on the completed\nvalues. This approach leverages the strengths of both completion and masking,\nenabling robust and efficient generation of realistic time series. Our method\nachieves state-of-the-art performance, achieving a relative improvement in\ndiscriminative score by $70\\%$ and in computational cost by $85\\%$. Code is at\nhttps://github.com/azencot-group/ImagenI2R.",
    "published": "2025-10-08T06:47:58Z",
    "updated": "2025-10-08T06:47:58Z",
    "link": "http://arxiv.org/pdf/2510.06699v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Gal Fadlon",
      "Idan Arbiv",
      "Nimrod Berman",
      "Omri Azencot"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06692v1",
    "title": "Is the Hard-Label Cryptanalytic Model Extraction Really Polynomial?",
    "summary": "Deep Neural Networks (DNNs) have attracted significant attention, and their\ninternal models are now considered valuable intellectual assets. Extracting\nthese internal models through access to a DNN is conceptually similar to\nextracting a secret key via oracle access to a block cipher. Consequently,\ncryptanalytic techniques, particularly differential-like attacks, have been\nactively explored recently. ReLU-based DNNs are the most commonly and widely\ndeployed architectures. While early works (e.g., Crypto 2020, Eurocrypt 2024)\nassume access to exact output logits, which are usually invisible, more recent\nworks (e.g., Asiacrypt 2024, Eurocrypt 2025) focus on the hard-label setting,\nwhere only the final classification result (e.g., \"dog\" or \"car\") is available\nto the attacker. Notably, Carlini et al. (Eurocrypt 2025) demonstrated that\nmodel extraction is feasible in polynomial time even under this restricted\nsetting.\n  In this paper, we first show that the assumptions underlying their attack\nbecome increasingly unrealistic as the attack-target depth grows. In practice,\nsatisfying these assumptions requires an exponential number of queries with\nrespect to the attack depth, implying that the attack does not always run in\npolynomial time. To address this critical limitation, we propose a novel attack\nmethod called CrossLayer Extraction. Instead of directly extracting the secret\nparameters (e.g., weights and biases) of a specific neuron, which incurs\nexponential cost, we exploit neuron interactions across layers to extract this\ninformation from deeper layers. This technique significantly reduces query\ncomplexity and mitigates the limitations of existing model extraction\napproaches.",
    "published": "2025-10-08T06:29:36Z",
    "updated": "2025-10-08T06:29:36Z",
    "link": "http://arxiv.org/pdf/2510.06692v1.pdf",
    "category": [
      "cs.LG",
      "cs.CR"
    ],
    "authors": [
      "Akira Ito",
      "Takayuki Miura",
      "Yosuke Todo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06691v1",
    "title": "Latent Representation Learning in Heavy-Ion Collisions with MaskPoint\n  Transformer",
    "summary": "A central challenge in high-energy nuclear physics is to extract informative\nfeatures from the high-dimensional final-state data of heavy-ion collisions\n(HIC) in order to enable reliable downstream analyses. Traditional approaches\noften rely on selected observables, which may miss subtle but physically\nrelevant structures in the data. To address this, we introduce a\nTransformer-based autoencoder trained with a two-stage paradigm:\nself-supervised pre-training followed by supervised fine-tuning. The pretrained\nencoder learns latent representations directly from unlabeled HIC data,\nproviding a compact and information-rich feature space that can be adapted to\ndiverse physics tasks. As a case study, we apply the method to distinguish\nbetween large and small collision systems, where it achieves significantly\nhigher classification accuracy than PointNet. Principal component analysis and\nSHAP interpretation further demonstrate that the autoencoder captures complex\nnonlinear correlations beyond individual observables, yielding features with\nstrong discriminative and explanatory power. These results establish our\ntwo-stage framework as a general and robust foundation for feature learning in\nHIC, opening the door to more powerful analyses of quark--gluon plasma\nproperties and other emergent phenomena. The implementation is publicly\navailable at https://github.com/Giovanni-Sforza/MaskPoint-AMPT.",
    "published": "2025-10-08T06:27:10Z",
    "updated": "2025-10-08T06:27:10Z",
    "link": "http://arxiv.org/pdf/2510.06691v1.pdf",
    "category": [
      "hep-ph",
      "cs.LG"
    ],
    "authors": [
      "Jing-Zong Zhang",
      "Shuang Guo",
      "Li-Lin Zhu",
      "Lingxiao Wang",
      "Guo-Liang Ma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06685v1",
    "title": "Gaussian Equivalence for Self-Attention: Asymptotic Spectral Analysis of\n  Attention Matrix",
    "summary": "Self-attention layers have become fundamental building blocks of modern deep\nneural networks, yet their theoretical understanding remains limited,\nparticularly from the perspective of random matrix theory. In this work, we\nprovide a rigorous analysis of the singular value spectrum of the attention\nmatrix and establish the first Gaussian equivalence result for attention. In a\nnatural regime where the inverse temperature remains of constant order, we show\nthat the singular value distribution of the attention matrix is asymptotically\ncharacterized by a tractable linear model. We further demonstrate that the\ndistribution of squared singular values deviates from the Marchenko-Pastur law,\nwhich has been believed in previous work. Our proof relies on two key\ningredients: precise control of fluctuations in the normalization term and a\nrefined linearization that leverages favorable Taylor expansions of the\nexponential. This analysis also identifies a threshold for linearization and\nelucidates why attention, despite not being an entrywise operation, admits a\nrigorous Gaussian equivalence in this regime.",
    "published": "2025-10-08T06:13:42Z",
    "updated": "2025-10-08T06:13:42Z",
    "link": "http://arxiv.org/pdf/2510.06685v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "math.PR"
    ],
    "authors": [
      "Tomohiro Hayase",
      "Benoît Collins",
      "Ryo Karakida"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06684v1",
    "title": "AutoBalance: An Automatic Balancing Framework for Training\n  Physics-Informed Neural Networks",
    "summary": "Physics-Informed Neural Networks (PINNs) provide a powerful and general\nframework for solving Partial Differential Equations (PDEs) by embedding\nphysical laws into loss functions. However, training PINNs is notoriously\ndifficult due to the need to balance multiple loss terms, such as PDE residuals\nand boundary conditions, which often have conflicting objectives and vastly\ndifferent curvatures. Existing methods address this issue by manipulating\ngradients before optimization (a \"pre-combine\" strategy). We argue that this\napproach is fundamentally limited, as forcing a single optimizer to process\ngradients from spectrally heterogeneous loss landscapes disrupts its internal\npreconditioning. In this work, we introduce AutoBalance, a novel \"post-combine\"\ntraining paradigm. AutoBalance assigns an independent adaptive optimizer to\neach loss component and aggregates the resulting preconditioned updates\nafterwards. Extensive experiments on challenging PDE benchmarks show that\nAutoBalance consistently outperforms existing frameworks, achieving significant\nreductions in solution error, as measured by both the MSE and $L^{\\infty}$\nnorms. Moreover, AutoBalance is orthogonal to and complementary with other\npopular PINN methodologies, amplifying their effectiveness on demanding\nbenchmarks.",
    "published": "2025-10-08T06:13:03Z",
    "updated": "2025-10-08T06:13:03Z",
    "link": "http://arxiv.org/pdf/2510.06684v1.pdf",
    "category": [
      "cs.LG",
      "cs.NA",
      "math.NA",
      "math.OC"
    ],
    "authors": [
      "Kang An",
      "Chenhao Si",
      "Ming Yan",
      "Shiqian Ma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06683v1",
    "title": "Distributed Algorithms for Multi-Agent Multi-Armed Bandits with\n  Collision",
    "summary": "We study the stochastic Multiplayer Multi-Armed Bandit (MMAB) problem, where\nmultiple players select arms to maximize their cumulative rewards. Collisions\noccur when two or more players select the same arm, resulting in no reward, and\nare observed by the players involved. We consider a distributed setting without\ncentral coordination, where each player can only observe their own actions and\ncollision feedback. We propose a distributed algorithm with an adaptive,\nefficient communication protocol. The algorithm achieves near-optimal group and\nindividual regret, with a communication cost of only $\\mathcal{O}(\\log\\log T)$.\nOur experiments demonstrate significant performance improvements over existing\nbaselines. Compared to state-of-the-art (SOTA) methods, our approach achieves a\nnotable reduction in individual regret. Finally, we extend our approach to a\nperiodic asynchronous setting, proving the lower bound for this problem and\npresenting an algorithm that achieves logarithmic regret.",
    "published": "2025-10-08T06:12:59Z",
    "updated": "2025-10-08T06:12:59Z",
    "link": "http://arxiv.org/pdf/2510.06683v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Daoyuan Zhou",
      "Xuchuang Wang",
      "Lin Yang",
      "Yang Gao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06680v1",
    "title": "TimeFormer: Transformer with Attention Modulation Empowered by Temporal\n  Characteristics for Time Series Forecasting",
    "summary": "Although Transformers excel in natural language processing, their extension\nto time series forecasting remains challenging due to insufficient\nconsideration of the differences between textual and temporal modalities. In\nthis paper, we develop a novel Transformer architecture designed for time\nseries data, aiming to maximize its representational capacity. We identify two\nkey but often overlooked characteristics of time series: (1) unidirectional\ninfluence from the past to the future, and (2) the phenomenon of decaying\ninfluence over time. These characteristics are introduced to enhance the\nattention mechanism of Transformers. We propose TimeFormer, whose core\ninnovation is a self-attention mechanism with two modulation terms (MoSA),\ndesigned to capture these temporal priors of time series under the constraints\nof the Hawkes process and causal masking. Additionally, TimeFormer introduces a\nframework based on multi-scale and subsequence analysis to capture semantic\ndependencies at different temporal scales, enriching the temporal dependencies.\nExtensive experiments conducted on multiple real-world datasets show that\nTimeFormer significantly outperforms state-of-the-art methods, achieving up to\na 7.45% reduction in MSE compared to the best baseline and setting new\nbenchmarks on 94.04\\% of evaluation metrics. Moreover, we demonstrate that the\nMoSA mechanism can be broadly applied to enhance the performance of other\nTransformer-based models.",
    "published": "2025-10-08T06:07:30Z",
    "updated": "2025-10-08T06:07:30Z",
    "link": "http://arxiv.org/pdf/2510.06680v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Zhipeng Liu",
      "Peibo Duan",
      "Xuan Tang",
      "Baixin Li",
      "Yongsheng Huang",
      "Mingyang Geng",
      "Changsheng Zhang",
      "Bin Zhang",
      "Binwu Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06672v1",
    "title": "XRPO: Pushing the limits of GRPO with Targeted Exploration and\n  Exploitation",
    "summary": "Reinforcement learning algorithms such as GRPO have driven recent advances in\nlarge language model (LLM) reasoning. While scaling the number of rollouts\nstabilizes training, existing approaches suffer from limited exploration on\nchallenging prompts and leave informative feedback signals underexploited, due\nto context-independent rollout allocation across prompts (e.g., generating 16\nrollouts per prompt) and relying heavily on sparse rewards. This paper presents\nXRPO(eXplore - eXploit GRPO), a unified framework that recasts policy\noptimization through the principled lens of rollout exploration-exploitation.\nTo enhance exploration, XRPO introduces a mathematically grounded rollout\nallocator that adaptively prioritizes prompts with higher potential for\nuncertainty reduction. It further addresses stagnation on zero-reward prompts\nthrough an in-context seeding strategy that injects curated exemplars, steering\nthe model into more difficult reasoning trajectories. To strengthen\nexploitation, XRPO develops a group-relative, novelty-aware advantage\nsharpening mechanism that leverages sequence likelihoods to amplify\nlow-probability yet correct responses, thereby extending the policy's reach\nbeyond sparse rewards. Experiments across diverse math and coding benchmarks on\nboth reasoning and non-reasoning models demonstrate that XRPO outperforms\nexisting advances (e.g., GRPO and GSPO) up to 4% pass@1 and 6% cons@32, while\naccelerating training convergence by up to 2.7X.",
    "published": "2025-10-08T05:53:56Z",
    "updated": "2025-10-08T05:53:56Z",
    "link": "http://arxiv.org/pdf/2510.06672v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Udbhav Bamba",
      "Minghao Fang",
      "Yifan Yu",
      "Haizhong Zheng",
      "Fan Lai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06662v1",
    "title": "The Effect of Attention Head Count on Transformer Approximation",
    "summary": "Transformer has become the dominant architecture for sequence modeling, yet a\ndetailed understanding of how its structural parameters influence expressive\npower remains limited. In this work, we study the approximation properties of\ntransformers, with particular emphasis on the role of the number of attention\nheads. Our analysis begins with the introduction of a generalized $D$-retrieval\ntask, which we prove to be dense in the space of continuous functions, thereby\nproviding the basis for our theoretical framework. We then establish both upper\nand lower bounds on the parameter complexity required for\n$\\epsilon$-approximation. Specifically, we show that transformers with\nsufficiently many heads admit efficient approximation, whereas with too few\nheads, the number of parameters must scale at least as $O(1/\\epsilon^{cT})$,\nfor some constant $c$ and sequence length $T$. To the best of our knowledge,\nthis constitutes the first rigorous lower bound of this type in a nonlinear and\npractically relevant setting. We further examine the single-head case and\ndemonstrate that an embedding dimension of order $O(T)$ allows complete\nmemorization of the input, where approximation is entirely achieved by the\nfeed-forward block. Finally, we validate our theoretical findings with\nexperiments on both synthetic data and real-world tasks, illustrating the\npractical relevance of our results.",
    "published": "2025-10-08T05:27:25Z",
    "updated": "2025-10-08T05:27:25Z",
    "link": "http://arxiv.org/pdf/2510.06662v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Penghao Yu",
      "Haotian Jiang",
      "Zeyu Bao",
      "Ruoxi Yu",
      "Qianxiao Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06660v1",
    "title": "Rethinking Nonlinearity: Trainable Gaussian Mixture Modules for Modern\n  Neural Architectures",
    "summary": "Neural networks in general, from MLPs and CNNs to attention-based\nTransformers, are constructed from layers of linear combinations followed by\nnonlinear operations such as ReLU, Sigmoid, or Softmax. Despite their strength,\nthese conventional designs are often limited in introducing non-linearity by\nthe choice of activation functions. In this work, we introduce Gaussian\nMixture-Inspired Nonlinear Modules (GMNM), a new class of differentiable\nmodules that draw on the universal density approximation Gaussian mixture\nmodels (GMMs) and distance properties (metric space) of Gaussian kernal. By\nrelaxing probabilistic constraints and adopting a flexible parameterization of\nGaussian projections, GMNM can be seamlessly integrated into diverse neural\narchitectures and trained end-to-end with gradient-based methods. Our\nexperiments demonstrate that incorporating GMNM into architectures such as\nMLPs, CNNs, attention mechanisms, and LSTMs consistently improves performance\nover standard baselines. These results highlight GMNM's potential as a powerful\nand flexible module for enhancing efficiency and accuracy across a wide range\nof machine learning applications.",
    "published": "2025-10-08T05:20:34Z",
    "updated": "2025-10-08T05:20:34Z",
    "link": "http://arxiv.org/pdf/2510.06660v1.pdf",
    "category": [
      "cs.LG",
      "math.PR"
    ],
    "authors": [
      "Weiguo Lu",
      "Gangnan Yuan",
      "Hong-kun Zhang",
      "Shangyang Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06655v1",
    "title": "Fitzpatrick Thresholding for Skin Image Segmentation",
    "summary": "Accurate estimation of the body surface area (BSA) involved by a rash, such\nas psoriasis, is critical for assessing rash severity, selecting an initial\ntreatment regimen, and following clinical treatment response. Attempts at\nsegmentation of inflammatory skin disease such as psoriasis perform markedly\nworse on darker skin tones, potentially impeding equitable care. We assembled a\npsoriasis dataset sourced from six public atlases, annotated for Fitzpatrick\nskin type, and added detailed segmentation masks for every image. Reference\nmodels based on U-Net, ResU-Net, and SETR-small are trained without tone\ninformation. On the tuning split we sweep decision thresholds and select (i)\nglobal optima and (ii) per Fitzpatrick skin tone optima for Dice and binary\nIoU. Adapting Fitzpatrick specific thresholds lifted segmentation performance\nfor the darkest subgroup (Fitz VI) by up to +31 % bIoU and +24 % Dice on UNet,\nwith consistent, though smaller, gains in the same direction for ResU-Net (+25\n% bIoU, +18 % Dice) and SETR-small (+17 % bIoU, +11 % Dice). Because\nFitzpatrick skin tone classifiers trained on Fitzpatrick-17k now exceed 95 %\naccuracy, the cost of skin tone labeling required for this technique has fallen\ndramatically. Fitzpatrick thresholding is simple, model-agnostic, requires no\narchitectural changes, no re-training, and is virtually cost free. We\ndemonstrate the inclusion of Fitzpatrick thresholding as a potential future\nfairness baseline.",
    "published": "2025-10-08T05:15:49Z",
    "updated": "2025-10-08T05:15:49Z",
    "link": "http://arxiv.org/pdf/2510.06655v1.pdf",
    "category": [
      "eess.IV",
      "cs.LG",
      "I.4.6; I.2.10; J.3"
    ],
    "authors": [
      "Duncan Stothers",
      "Sophia Xu",
      "Carlie Reeves",
      "Lia Gracey"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06647v1",
    "title": "Q-Learning with Fine-Grained Gap-Dependent Regret",
    "summary": "We study fine-grained gap-dependent regret bounds for model-free\nreinforcement learning in episodic tabular Markov Decision Processes. Existing\nmodel-free algorithms achieve minimax worst-case regret, but their\ngap-dependent bounds remain coarse and fail to fully capture the structure of\nsuboptimality gaps. We address this limitation by establishing fine-grained\ngap-dependent regret bounds for both UCB-based and non-UCB-based algorithms. In\nthe UCB-based setting, we develop a novel analytical framework that explicitly\nseparates the analysis of optimal and suboptimal state-action pairs, yielding\nthe first fine-grained regret upper bound for UCB-Hoeffding (Jin et al., 2018).\nTo highlight the generality of this framework, we introduce ULCB-Hoeffding, a\nnew UCB-based algorithm inspired by AMB (Xu et al.,2021) but with a simplified\nstructure, which enjoys fine-grained regret guarantees and empirically\noutperforms AMB. In the non-UCB-based setting, we revisit the only known\nalgorithm AMB, and identify two key issues in its algorithm design and\nanalysis: improper truncation in the $Q$-updates and violation of the\nmartingale difference condition in its concentration argument. We propose a\nrefined version of AMB that addresses these issues, establishing the first\nrigorous fine-grained gap-dependent regret for a non-UCB-based method, with\nexperiments demonstrating improved performance over AMB.",
    "published": "2025-10-08T05:02:16Z",
    "updated": "2025-10-08T05:02:16Z",
    "link": "http://arxiv.org/pdf/2510.06647v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Haochen Zhang",
      "Zhong Zheng",
      "Lingzhou Xue"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.02053v2",
    "title": "ProCut: LLM Prompt Compression via Attribution Estimation",
    "summary": "In large-scale industrial LLM systems, prompt templates often expand to\nthousands of tokens as teams iteratively incorporate sections such as task\ninstructions, few-shot examples, and heuristic rules to enhance robustness and\ncoverage. This expansion leads to bloated prompts that are difficult to\nmaintain and incur significant inference latency and serving costs. To address\nthis, we introduce Prompt Compression via Attribution Estimation (ProCut), a\nflexible, LLM-agnostic, training-free framework that compresses prompts through\nattribution analysis. ProCut segments prompt templates into semantically\nmeaningful units, quantifies their impact on task performance, and prunes\nlow-utility components. Through extensive experiments on five public benchmark\ndatasets and real-world industrial prompts, we show that ProCut achieves\nsubstantial prompt size reductions (78% fewer tokens in production) while\nmaintaining or even slightly improving task performance (up to 62% better than\nalternative methods). We further introduce an LLM-driven attribution estimator\nthat reduces compression latency by over 50%, and demonstrate that ProCut\nintegrates seamlessly with existing prompt-optimization frameworks to produce\nconcise, high-performing prompts.",
    "published": "2025-08-04T04:44:43Z",
    "updated": "2025-10-08T04:59:55Z",
    "link": "http://arxiv.org/pdf/2508.02053v2.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Zhentao Xu",
      "Fengyi Li",
      "Albert Chen",
      "Xiaofeng Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06640v1",
    "title": "A Comparative Analysis of Contextual Representation Flow in State-Space\n  and Transformer Architectures",
    "summary": "State Space Models (SSMs) have recently emerged as efficient alternatives to\nTransformer-Based Models (TBMs) for long-sequence processing, offering linear\nscaling and lower memory use. Yet, how contextual information flows across\nlayers and tokens in these architectures remains understudied. We present the\nfirst unified, token- and layer-level analysis of representation propagation in\nSSMs and TBMs. Using centered kernel alignment, stability metrics, and probing,\nwe characterize how representations evolve within and across layers. We find a\nkey divergence: TBMs rapidly homogenize token representations, with diversity\nreemerging only in later layers, while SSMs preserve token uniqueness early but\nconverge to homogenization deeper. Theoretical analysis and parameter\nrandomization further reveal that oversmoothing in TBMs stems from\narchitectural design, whereas in SSMs it arises mainly from training dynamics.\nThese insights clarify the inductive biases of both architectures and inform\nfuture model and training designs for long-context reasoning.",
    "published": "2025-10-08T04:46:11Z",
    "updated": "2025-10-08T04:46:11Z",
    "link": "http://arxiv.org/pdf/2510.06640v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Nhat M. Hoang",
      "Do Xuan Long",
      "Cong-Duy Nguyen",
      "Min-Yen Kan",
      "Luu Anh Tuan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.17646v2",
    "title": "Unveiling the Basin-Like Loss Landscape in Large Language Models",
    "summary": "We discover the emergence of \\textit{basins} in the loss landscape of large\nlanguage models. As model scale increases, LLMs become progressively more\nresilient to random perturbations in the parameter space, giving rise to\nexpansive stability regions where models exhibit nearly identical performance,\nbut outside of which their capabilities collapse. We observe that pre-training\ncreates a \\textit{basic capability} basin, and subsequent alignment fine-tuning\nforms \\textit{specific capability} basins (e.g., safety, math, coding). Thus,\nwe argue that benign fine-tuning confined to the basin should preserve prior\ncapabilities. Besides, we also analyze the loss landscape for worst-case\ndirections, which is consistently sharp and detrimental. We find that\nadversarial fine-tuning moves along the nearly worst-case directions, thus\nrapidly degrading model capabilities. Finally, we provide a theoretical\nanalysis demonstrating that the basin size bounds the performance degradation\nof any fine-tuning, including the adversarial ones, while also guaranteeing the\nmodel robustness w.r.t. input perturbations, suggesting the benefit of\nenlarging basins.",
    "published": "2025-05-23T09:06:40Z",
    "updated": "2025-10-08T04:36:39Z",
    "link": "http://arxiv.org/pdf/2505.17646v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Huanran Chen",
      "Yinpeng Dong",
      "Zeming Wei",
      "Yao Huang",
      "Yichi Zhang",
      "Hang Su",
      "Jun Zhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06634v1",
    "title": "Three Forms of Stochastic Injection for Improved\n  Distribution-to-Distribution Generative Modeling",
    "summary": "Modeling transformations between arbitrary data distributions is a\nfundamental scientific challenge, arising in applications like drug discovery\nand evolutionary simulation. While flow matching offers a natural framework for\nthis task, its use has thus far primarily focused on the noise-to-data setting,\nwhile its application in the general distribution-to-distribution setting is\nunderexplored. We find that in the latter case, where the source is also a data\ndistribution to be learned from limited samples, standard flow matching fails\ndue to sparse supervision. To address this, we propose a simple and\ncomputationally efficient method that injects stochasticity into the training\nprocess by perturbing source samples and flow interpolants. On five diverse\nimaging tasks spanning biology, radiology, and astronomy, our method\nsignificantly improves generation quality, outperforming existing baselines by\nan average of 9 FID points. Our approach also reduces the transport cost\nbetween input and generated samples to better highlight the true effect of the\ntransformation, making flow matching a more practical tool for simulating the\ndiverse distribution transformations that arise in science.",
    "published": "2025-10-08T04:36:34Z",
    "updated": "2025-10-08T04:36:34Z",
    "link": "http://arxiv.org/pdf/2510.06634v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Shiye Su",
      "Yuhui Zhang",
      "Linqi Zhou",
      "Rajesh Ranganath",
      "Serena Yeung-Levy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06632v1",
    "title": "Chem-NMF: Multi-layer $α$-divergence Non-Negative Matrix\n  Factorization for Cardiorespiratory Disease Clustering, with Improved\n  Convergence Inspired by Chemical Catalysts and Rigorous Asymptotic Analysis",
    "summary": "Non-Negative Matrix Factorization (NMF) is an unsupervised learning method\noffering low-rank representations across various domains such as audio\nprocessing, biomedical signal analysis, and image recognition. The\nincorporation of $\\alpha$-divergence in NMF formulations enhances flexibility\nin optimization, yet extending these methods to multi-layer architectures\npresents challenges in ensuring convergence. To address this, we introduce a\nnovel approach inspired by the Boltzmann probability of the energy barriers in\nchemical reactions to theoretically perform convergence analysis. We introduce\na novel method, called Chem-NMF, with a bounding factor which stabilizes\nconvergence. To our knowledge, this is the first study to apply a physical\nchemistry perspective to rigorously analyze the convergence behaviour of the\nNMF algorithm. We start from mathematically proven asymptotic convergence\nresults and then show how they apply to real data. Experimental results\ndemonstrate that the proposed algorithm improves clustering accuracy by 5.6%\n$\\pm$ 2.7% on biomedical signals and 11.1% $\\pm$ 7.2% on face images (mean\n$\\pm$ std).",
    "published": "2025-10-08T04:31:10Z",
    "updated": "2025-10-08T04:31:10Z",
    "link": "http://arxiv.org/pdf/2510.06632v1.pdf",
    "category": [
      "cs.LG",
      "eess.SP"
    ],
    "authors": [
      "Yasaman Torabi",
      "Shahram Shirani",
      "James P. Reilly"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.25678v2",
    "title": "Guiding Mixture-of-Experts with Temporal Multimodal Interactions",
    "summary": "Mixture-of-Experts (MoE) architectures have become pivotal for large-scale\nmultimodal models. However, their routing mechanisms typically overlook the\ninformative, time-varying interaction dynamics between modalities. This\nlimitation hinders expert specialization, as the model cannot explicitly\nleverage intrinsic modality relationships for effective reasoning. To address\nthis, we propose a novel framework that guides MoE routing using quantified\ntemporal interaction. A multimodal interaction-aware router learns to dispatch\ntokens to experts based on the nature of their interactions. This dynamic\nrouting encourages experts to acquire generalizable interaction-processing\nskills rather than merely learning task-specific features. Our framework builds\non a new formulation of temporal multimodal interaction dynamics, which are\nused to guide expert routing. We first demonstrate that these temporal\nmultimodal interactions reveal meaningful patterns across applications, and\nthen show how they can be leveraged to improve both the design and performance\nof MoE-based models. Comprehensive experiments on challenging multimodal\nbenchmarks validate our approach, demonstrating both enhanced performance and\nimproved interpretability.",
    "published": "2025-09-30T02:26:31Z",
    "updated": "2025-10-08T04:21:03Z",
    "link": "http://arxiv.org/pdf/2509.25678v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Xing Han",
      "Hsing-Huan Chung",
      "Joydeep Ghosh",
      "Paul Pu Liang",
      "Suchi Saria"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.19040v4",
    "title": "Towards the Worst-case Robustness of Large Language Models",
    "summary": "Recent studies have revealed the vulnerability of large language models to\nadversarial attacks, where adversaries craft specific input sequences to induce\nharmful, violent, private, or incorrect outputs. In this work, we study their\nworst-case robustness, i.e., whether an adversarial example exists that leads\nto such undesirable outputs. We upper bound the worst-case robustness using\nstronger white-box attacks, indicating that most current deterministic defenses\nachieve nearly 0\\% worst-case robustness. We propose a general tight lower\nbound for randomized smoothing using fractional knapsack solvers or 0-1\nknapsack solvers, and using them to bound the worst-case robustness of all\nstochastic defenses. Based on these solvers, we provide theoretical lower\nbounds for several previous empirical defenses. For example, we certify the\nrobustness of a specific case, smoothing using a uniform kernel, against\n\\textit{any possible attack} with an average $\\ell_0$ perturbation of 2.02 or\nan average suffix length of 6.41.",
    "published": "2025-01-31T11:10:49Z",
    "updated": "2025-10-08T04:21:02Z",
    "link": "http://arxiv.org/pdf/2501.19040v4.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Huanran Chen",
      "Yinpeng Dong",
      "Zeming Wei",
      "Hang Su",
      "Jun Zhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.04042v2",
    "title": "Simulation-based inference via telescoping ratio estimation for trawl\n  processes",
    "summary": "The growing availability of large and complex datasets has increased interest\nin temporal stochastic processes that can capture stylized facts such as\nmarginal skewness, non-Gaussian tails, long memory, and even non-Markovian\ndynamics. While such models are often easy to simulate from, parameter\nestimation remains challenging. Simulation-based inference (SBI) offers a\npromising way forward, but existing methods typically require large training\ndatasets or complex architectures and frequently yield confidence (credible)\nregions that fail to attain their nominal values, raising doubts on the\nreliability of estimates for the very features that motivate the use of these\nmodels. To address these challenges, we propose a fast and accurate,\nsample-efficient SBI framework for amortized posterior inference applicable to\nintractable stochastic processes. The proposed approach relies on two main\nsteps: first, we learn the posterior density by decomposing it sequentially\nacross parameter dimensions. Then, we use Chebyshev polynomial approximations\nto efficiently generate independent posterior samples, enabling accurate\ninference even when Markov chain Monte Carlo methods mix poorly. We further\ndevelop novel diagnostic tools for SBI in this context, as well as post-hoc\ncalibration techniques; the latter not only lead to performance improvements of\nthe learned inferential tool, but also to the ability to reuse it directly with\nnew time series of varying lengths, thus amortizing the training cost. We\ndemonstrate the method's effectiveness on trawl processes, a class of flexible\ninfinitely divisible models that generalize univariate Gaussian processes,\napplied to energy demand data.",
    "published": "2025-10-05T05:26:46Z",
    "updated": "2025-10-08T04:20:39Z",
    "link": "http://arxiv.org/pdf/2510.04042v2.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "authors": [
      "Dan Leonte",
      "Raphaël Huser",
      "Almut E. D. Veraart"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06627v1",
    "title": "POME: Post Optimization Model Edit via Muon-style Projection",
    "summary": "We introduce Post-Optimization Model Edit (POME), a new algorithm that\nenhances the performance of fine-tuned large language models using only their\npretrained and fine-tuned checkpoints, without requiring extra data or further\noptimization. The core idea is to apply a muon-style projection to $\\Delta W$,\nthe difference between the fine-tuned and pretrained weights. This projection\nuses truncated singular value decomposition (SVD) to equalize the influence of\ndominant update directions and prune small singular values, which often\nrepresent noise. As a simple post-processing step, POME is completely decoupled\nfrom the training pipeline. It requires zero modifications and imposes no\noverhead, making it universally compatible with any optimizer or distributed\nframework. POME delivers consistent gains, boosting average performance by\n+2.5\\% on GSM8K and +1.0\\% on code generation. Its broad applicability -- from\n7B foundation models to 72B RLHF-instructed models -- establishes it as a\npractical, zero-cost enhancement for any fine-tuning pipeline. Code is\navailable at https://github.com/NUS-HPC-AI-Lab/POME.",
    "published": "2025-10-08T04:20:11Z",
    "updated": "2025-10-08T04:20:11Z",
    "link": "http://arxiv.org/pdf/2510.06627v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Yong Liu",
      "Di Fu",
      "Yang Luo",
      "Zirui Zhu",
      "Minhao Cheng",
      "Cho-Jui Hsieh",
      "Yang You"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.04781v2",
    "title": "DPGIIL: Dirichlet Process-Deep Generative Model-Integrated Incremental\n  Learning for Clustering in Transmissibility-based Online Structural Anomaly\n  Detection",
    "summary": "Clustering based on vibration responses, such as transmissibility functions\n(TFs), is promising in structural anomaly detection. However, most existing\nmethods struggle to determine the optimal cluster number, handle\nhigh-dimensional streaming data, and rely heavily on manually engineered\nfeatures due to their shallow structures. To address these issues, this work\nproposes a novel clustering framework, referred to as Dirichlet process-deep\ngenerative model-integrated incremental learning (DPGIIL), for online\nstructural anomaly detection, which combines the advantages of deep generative\nmodels (DGMs) in representation learning and the Dirichlet process mixture\nmodel (DPMM) in identifying distinct patterns in observed data. Within the\ncontext of variational Bayesian inference, a lower bound on the log marginal\nlikelihood of DPGIIL, tighter than the evidence lower bound, is derived\nanalytically, which enables the joint optimization of DGM and DPMM parameters,\nthereby allowing the DPMM to regularize the DGM's feature extraction process.\nAdditionally, a greedy split-merge scheme-based coordinate ascent variational\ninference method is devised to accelerate the optimization. The summary\nstatistics of the DPMM, along with the network parameters, are used to retain\ninformation about previous data for incremental learning. For online structural\nanomaly detection, DPGIIL can not only detect anomalies by dynamically\nassigning incoming data to new clusters but also indicate different structural\nstates using distinct clusters, thereby providing additional information about\nthe operating conditions of the monitored structure compared to traditional\nanomaly detectors. Three case studies demonstrate the dynamic adaptability of\nthe proposed method and show that it outperforms some state-of-the-art\napproaches in both structural anomaly detection and clustering.",
    "published": "2024-12-06T05:18:58Z",
    "updated": "2025-10-08T04:14:42Z",
    "link": "http://arxiv.org/pdf/2412.04781v2.pdf",
    "category": [
      "cs.LG",
      "physics.data-an",
      "stat.ML"
    ],
    "authors": [
      "Lin-Feng Mei",
      "Wang-Ji Yan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06623v1",
    "title": "DPA-Net: A Dual-Path Attention Neural Network for Inferring Glycemic\n  Control Metrics from Self-Monitored Blood Glucose Data",
    "summary": "Continuous glucose monitoring (CGM) provides dense and dynamic glucose\nprofiles that enable reliable estimation of Ambulatory Glucose Profile (AGP)\nmetrics, such as Time in Range (TIR), Time Below Range (TBR), and Time Above\nRange (TAR). However, the high cost and limited accessibility of CGM restrict\nits widespread adoption, particularly in low- and middle-income regions. In\ncontrast, self-monitoring of blood glucose (SMBG) is inexpensive and widely\navailable but yields sparse and irregular data that are challenging to\ntranslate into clinically meaningful glycemic metrics.\n  In this work, we propose a Dual-Path Attention Neural Network (DPA-Net) to\nestimate AGP metrics directly from SMBG data. DPA-Net integrates two\ncomplementary paths: (1) a spatial-channel attention path that reconstructs a\nCGM-like trajectory from sparse SMBG observations, and (2) a multi-scale ResNet\npath that directly predicts AGP metrics. An alignment mechanism between the two\npaths is introduced to reduce bias and mitigate overfitting. In addition, we\ndevelop an active point selector to identify realistic and informative SMBG\nsampling points that reflect patient behavioral patterns.\n  Experimental results on a large, real-world dataset demonstrate that DPA-Net\nachieves robust accuracy with low errors while reducing systematic bias. To the\nbest of our knowledge, this is the first supervised machine learning framework\nfor estimating AGP metrics from SMBG data, offering a practical and clinically\nrelevant decision-support tool in settings where CGM is not accessible.",
    "published": "2025-10-08T04:06:22Z",
    "updated": "2025-10-08T04:06:22Z",
    "link": "http://arxiv.org/pdf/2510.06623v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Canyu Lei",
      "Benjamin Lobo",
      "Jianxin Xie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.22554v4",
    "title": "A Copula Based Supervised Filter for Feature Selection in Diabetes Risk\n  Prediction Using Machine Learning",
    "summary": "Effective feature selection is vital for robust and interpretable medical\nprediction, especially for identifying risk factors concentrated in extreme\npatient strata. Standard methods emphasize average associations and may miss\npredictors whose importance lies in the tails of the distribution. We propose a\ncomputationally efficient supervised filter that ranks features using the\nGumbel copula upper tail dependence coefficient ($\\lambda_U$), prioritizing\nvariables that are simultaneously extreme with the positive class. We\nbenchmarked against Mutual Information, mRMR, ReliefF, and $L_1$ Elastic Net\nacross four classifiers on two diabetes datasets: a large public health survey\n(CDC, N=253,680) and a clinical benchmark (PIMA, N=768). Evaluation included\npaired statistical tests, permutation importance, and robustness checks with\nlabel flips, feature noise, and missingness. On CDC, our method was the fastest\nselector and reduced the feature space by about 52% while retaining strong\ndiscrimination. Although using all 21 features yielded the highest AUC, our\nfilter significantly outperformed Mutual Information and mRMR and was\nstatistically indistinguishable from ReliefF. On PIMA, with only eight\npredictors, our ranking produced the numerically highest ROC AUC, and no\nsignificant differences were found versus strong baselines. Across both\ndatasets, the upper tail criterion consistently identified clinically coherent,\nimpactful predictors. We conclude that copula based feature selection via upper\ntail dependence is a powerful, efficient, and interpretable approach for\nbuilding risk models in public health and clinical medicine.",
    "published": "2025-05-28T16:34:58Z",
    "updated": "2025-10-08T04:03:38Z",
    "link": "http://arxiv.org/pdf/2505.22554v4.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Agnideep Aich",
      "Md Monzur Murshed",
      "Sameera Hewage",
      "Amanda Mayeaux"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.15492v2",
    "title": "Reinforcement Learning for Dynamic Memory Allocation",
    "summary": "In recent years, reinforcement learning (RL) has gained popularity and has\nbeen applied to a wide range of tasks. One such popular domain where RL has\nbeen effective is resource management problems in systems. We look to extend\nwork on RL for resource management problems by considering the novel domain of\ndynamic memory allocation management. We consider dynamic memory allocation to\nbe a suitable domain for RL since current algorithms like first-fit, best-fit,\nand worst-fit can fail to adapt to changing conditions and can lead to\nfragmentation and suboptimal efficiency. In this paper, we present a framework\nin which an RL agent continuously learns from interactions with the system to\nimprove memory management tactics. We evaluate our approach through various\nexperiments using high-level and low-level action spaces and examine different\nmemory allocation patterns. Our results show that RL can successfully train\nagents that can match and surpass traditional allocation strategies,\nparticularly in environments characterized by adversarial request patterns. We\nalso explore the potential of history-aware policies that leverage previous\nallocation requests to enhance the allocator's ability to handle complex\nrequest patterns. Overall, we find that RL offers a promising avenue for\ndeveloping more adaptive and efficient memory allocation strategies,\npotentially overcoming limitations of hardcoded allocation algorithms.",
    "published": "2024-10-20T20:13:46Z",
    "updated": "2025-10-08T04:03:22Z",
    "link": "http://arxiv.org/pdf/2410.15492v2.pdf",
    "category": [
      "cs.LG",
      "cs.OS"
    ],
    "authors": [
      "Arisrei Lim",
      "Abhiram Maddukuri"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.07844v4",
    "title": "Conditional Local Independence Testing for Itô processes with\n  Applications to Dynamic Causal Discovery",
    "summary": "Inferring causal relationships from dynamical systems is the central interest\nof many scientific inquiries. Conditional local independence, which describes\nwhether the evolution of one process is influenced by another process given\nadditional processes, is important for causal learning in such systems. In this\npaper, we propose a hypothesis test for conditional local independence in It\\^o\nprocesses. Our test is grounded in the semimartingale decomposition of the\nIt\\^o process, with which we introduce a stochastic integral process that is a\nmartingale under the null hypothesis. We then apply a test for the martingale\nproperty, quantifying potential deviation from local independence. The test\nstatistics is estimated using the optimal filtering equation. We show the\nconsistency of the estimation, thereby establishing the level and power of our\ntest. Numerical verification and a real-world application to causal discovery\nin brain resting-state fMRIs are conducted.",
    "published": "2025-06-09T15:08:41Z",
    "updated": "2025-10-08T03:52:23Z",
    "link": "http://arxiv.org/pdf/2506.07844v4.pdf",
    "category": [
      "stat.ME",
      "cs.LG"
    ],
    "authors": [
      "Mingzhou Liu",
      "Xinwei Sun",
      "Yizhou Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.05024v2",
    "title": "Inoculation Prompting: Instructing LLMs to misbehave at train-time\n  improves test-time alignment",
    "summary": "Large language models are sometimes trained with imperfect oversight signals,\nleading to undesired behaviors such as reward hacking and sycophancy. Improving\noversight quality can be expensive or infeasible, motivating methods that\nimprove learned behavior despite an imperfect training signal. We introduce\nInoculation Prompting (IP), a simple but counterintuitive technique that\nprevents learning of an undesired behavior by modifying training prompts to\nexplicitly request it. For example, to inoculate against reward hacking, we\nmodify the prompts used in supervised fine-tuning to request code that only\nworks on provided test cases but fails on other inputs. Across four settings we\nfind that IP reduces the learning of undesired behavior without substantially\nreducing the learning of desired capabilities. We also show that prompts which\nmore strongly elicit the undesired behavior prior to fine-tuning more\neffectively inoculate against the behavior when used during training; this\nserves as a heuristic to identify promising inoculation prompts. Overall, IP is\na simple yet effective way to control how models generalize from fine-tuning,\npreventing learning of undesired behaviors without substantially disrupting\ndesired capabilities.",
    "published": "2025-10-06T17:02:59Z",
    "updated": "2025-10-08T03:13:07Z",
    "link": "http://arxiv.org/pdf/2510.05024v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Nevan Wichers",
      "Aram Ebtekar",
      "Ariana Azarbal",
      "Victor Gillioz",
      "Christine Ye",
      "Emil Ryd",
      "Neil Rathi",
      "Henry Sleight",
      "Alex Mallen",
      "Fabien Roger",
      "Samuel Marks"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.16192v2",
    "title": "Nonparametric Bellman Mappings for Value Iteration in Distributed\n  Reinforcement Learning",
    "summary": "This paper introduces novel Bellman mappings (B-Maps) for value iteration\n(VI) in distributed reinforcement learning (DRL), where agents are deployed\nover an undirected, connected graph/network with arbitrary topology -- but\nwithout a centralized node, that is, a node capable of aggregating all data and\nperforming computations. Each agent constructs a nonparametric B-Map from its\nprivate data, operating on Q-functions represented in a reproducing kernel\nHilbert space, with flexibility in choosing the basis for their representation.\nAgents exchange their Q-function estimates only with direct neighbors, and\nunlike existing DRL approaches that restrict communication to Q-functions, the\nproposed framework also enables the transmission of basis information in the\nform of covariance matrices, thereby conveying additional structural details.\nLinear convergence rates are established for both Q-function and\ncovariance-matrix estimates toward their consensus values, regardless of the\nnetwork topology, with optimal learning rates determined by the ratio of the\nsmallest positive eigenvalue (the graph's Fiedler value) to the largest\neigenvalue of the graph Laplacian matrix. A detailed performance analysis\nfurther shows that the proposed DRL framework effectively approximates the\nperformance of a centralized node, had such a node existed. Numerical tests on\ntwo benchmark control problems confirm the effectiveness of the proposed\nnonparametric B-Maps relative to prior methods. Notably, the tests reveal a\ncounter-intuitive outcome: although the framework involves richer information\nexchange -- specifically through transmitting covariance matrices as basis\ninformation -- it achieves the desired performance at a lower cumulative\ncommunication cost than existing DRL schemes, underscoring the critical role of\nsharing basis information in accelerating the learning process.",
    "published": "2025-03-20T14:39:21Z",
    "updated": "2025-10-08T02:54:52Z",
    "link": "http://arxiv.org/pdf/2503.16192v2.pdf",
    "category": [
      "cs.LG",
      "eess.SP"
    ],
    "authors": [
      "Yuki Akiyama",
      "Konstantinos Slavakis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.21626v2",
    "title": "Learning where to learn: Training data distribution optimization for\n  scientific machine learning",
    "summary": "In scientific machine learning, models are routinely deployed with parameter\nvalues or boundary conditions far from those used in training. This paper\nstudies the learning-where-to-learn problem of designing a training data\ndistribution that minimizes average prediction error across a family of\ndeployment regimes. A theoretical analysis shows how the training distribution\nshapes deployment accuracy. This motivates two adaptive algorithms based on\nbilevel or alternating optimization in the space of probability measures.\nDiscretized implementations using parametric distribution classes or\nnonparametric particle-based gradient flows deliver optimized training\ndistributions that outperform nonadaptive designs. Once trained, the resulting\nmodels exhibit improved sample complexity and robustness to distribution shift.\nThis framework unlocks the potential of principled data acquisition for\nlearning functions and solution operators of partial differential equations.",
    "published": "2025-05-27T18:00:58Z",
    "updated": "2025-10-08T02:51:54Z",
    "link": "http://arxiv.org/pdf/2505.21626v2.pdf",
    "category": [
      "cs.LG",
      "math.OC",
      "stat.ML",
      "62K05, 65K10 (Primary) 68T07, 65D15, 62R20, 60G57 (Secondary)"
    ],
    "authors": [
      "Nicolas Guerra",
      "Nicholas H. Nelsen",
      "Yunan Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.05396v2",
    "title": "Scalable In-context Ranking with Generative Models",
    "summary": "In-context Ranking (ICR) is an emerging paradigm for Information Retrieval\n(IR), which leverages contextual understanding of LLMs by directly\nincorporating the task description, candidate documents, and the query into the\nmodel's input prompt and tasking the LLM to identify relevant document(s).\nWhile it is effective, efficiency is a significant challenge in this paradigm,\nespecially as the candidate list grows due to quadratic/super-linear scaling of\nattention operation with context length. To this end, this paper first\nidentifies inherent and exploitable structures in the attention of LLMs\nfinetuned for ICR: (1) inter-document block sparsity: attention is dense within\neach document block but sparse across different documents in the context; and\n(2) query-document block relevance: the attention scores from certain query\ntokens to a document block in middle layers strongly correlate with that\ndocument's actual relevance. Motivated by these observations, we introduce\nBlockRank (Blockwise In-context Ranking), a novel method that adapts the\nattention operation in an LLM by (a) architecturally enforcing the observed\ninter-document block sparsity, reducing attention complexity from quadratic to\nlinear without loss in performance, and (b) optimizing query-document block\nrelevance for true relevant documents during fine-tuning using an auxiliary\ncontrastive training objective, improving retrieval in attention. Experiments\non BEIR, MSMarco and NQ with Mistral-7B demonstrate that BlockRank Mistral\nmatches or outperforms existing SOTA listwise rankers and controlled fine-tuned\nbaseline while being significantly more efficient at inference (4.7x for 100\nMSMarco documents in context) and scaling gracefully to long-context\nshortlists, around 500 documents in-context (approximately 100K context length)\nwithin a second, presenting a scalable and effective solution for ICR.",
    "published": "2025-10-06T21:41:58Z",
    "updated": "2025-10-08T02:02:37Z",
    "link": "http://arxiv.org/pdf/2510.05396v2.pdf",
    "category": [
      "cs.IR",
      "cs.LG"
    ],
    "authors": [
      "Nilesh Gupta",
      "Chong You",
      "Srinadh Bhojanapalli",
      "Sanjiv Kumar",
      "Inderjit Dhillon",
      "Felix Yu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06563v1",
    "title": "Adapting Quantum Machine Learning for Energy Dissociation of Bonds",
    "summary": "Accurate prediction of bond dissociation energies (BDEs) underpins\nmechanistic insight and the rational design of molecules and materials. We\npresent a systematic, reproducible benchmark comparing quantum and classical\nmachine learning models for BDE prediction using a chemically curated feature\nset encompassing atomic properties (atomic numbers, hybridization), bond\ncharacteristics (bond order, type), and local environmental descriptors. Our\nquantum framework, implemented in Qiskit Aer on six qubits, employs\nZZFeatureMap encodings with variational ansatz (RealAmplitudes) across multiple\narchitectures Variational Quantum Regressors (VQR), Quantum Support Vector\nRegressors (QSVR), Quantum Neural Networks (QNN), Quantum Convolutional Neural\nNetworks (QCNN), and Quantum Random Forests (QRF). These are rigorously\nbenchmarked against strong classical baselines, including Support Vector\nRegression (SVR), Random Forests (RF), and Multi-Layer Perceptrons (MLP).\nComprehensive evaluation spanning absolute and relative error metrics,\nthreshold accuracies, and error distributions shows that top-performing quantum\nmodels (QCNN, QRF) match the predictive accuracy and robustness of classical\nensembles and deep networks, particularly within the chemically prevalent\nmid-range BDE regime. These findings establish a transparent baseline for\nquantum-enhanced molecular property prediction and outline a practical\nfoundation for advancing quantum computational chemistry toward near chemical\naccuracy.",
    "published": "2025-10-08T01:32:26Z",
    "updated": "2025-10-08T01:32:26Z",
    "link": "http://arxiv.org/pdf/2510.06563v1.pdf",
    "category": [
      "quant-ph",
      "cs.LG"
    ],
    "authors": [
      "Swathi Chandrasekhar",
      "Shiva Raj Pokhrel",
      "Navneet Singh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.21181v2",
    "title": "Closed-form $\\ell_r$ norm scaling with data for overparameterized linear\n  regression and diagonal linear networks under $\\ell_p$ bias",
    "summary": "For overparameterized linear regression with isotropic Gaussian design and\nminimum-$\\ell_p$ interpolator $p\\in(1,2]$, we give a unified, high-probability\ncharacterization for the scaling of the family of parameter norms $ \\\\{ \\lVert\n\\widehat{w_p} \\rVert_r \\\\}_{r \\in [1,p]} $ with sample size.\n  We solve this basic, but unresolved question through a simple dual-ray\nanalysis, which reveals a competition between a signal *spike* and a *bulk* of\nnull coordinates in $X^\\top Y$, yielding closed-form predictions for (i) a\ndata-dependent transition $n_\\star$ (the \"elbow\"), and (ii) a universal\nthreshold $r_\\star=2(p-1)$ that separates $\\lVert \\widehat{w_p} \\rVert_r$'s\nwhich plateau from those that continue to grow with an explicit exponent.\n  This unified solution resolves the scaling of *all* $\\ell_r$ norms within the\nfamily $r\\in [1,p]$ under $\\ell_p$-biased interpolation, and explains in one\npicture which norms saturate and which increase as $n$ grows.\n  We then study diagonal linear networks (DLNs) trained by gradient descent. By\ncalibrating the initialization scale $\\alpha$ to an effective\n$p_{\\mathrm{eff}}(\\alpha)$ via the DLN separable potential, we show empirically\nthat DLNs inherit the same elbow/threshold laws, providing a predictive bridge\nbetween explicit and implicit bias.\n  Given that many generalization proxies depend on $\\lVert \\widehat {w_p}\n\\rVert_r$, our results suggest that their predictive power will depend\nsensitively on which $l_r$ norm is used.",
    "published": "2025-09-25T13:59:22Z",
    "updated": "2025-10-08T01:23:07Z",
    "link": "http://arxiv.org/pdf/2509.21181v2.pdf",
    "category": [
      "cs.LG",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "authors": [
      "Shuofeng Zhang",
      "Ard Louis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06548v1",
    "title": "From Acceleration to Saturation: Scaling Behavior of Bootstrapped\n  Language Model Pretraining",
    "summary": "Bootstrapped pretraining, i.e., the reuse of a pretrained base model for\nfurther pretraining, such as continual pretraining or model growth, is\npromising at reducing the cost of training language models from scratch.\nHowever, its effectiveness remains unclear, especially when applied to\novertrained base models. In this work, we empirically study the scaling\nbehavior of bootstrapped pretraining and find that its scaling efficiency\ndiminishes in a predictable manner: The scaling exponent with respect to\nsecond-stage pretraining tokens decreases logarithmically with the number of\ntokens used to pretrain the base model. The joint dependence on first- and\nsecond-stage tokens is accurately modeled by a simple scaling law. Such\nsaturation effect reveals a fundamental trade-off in multi-stage pretraining\nstrategies: the more extensively a model is pretrained, the less additional\nbenefit bootstrapping provides. Our findings provide practical insights for\nefficient language model training and raise important considerations for the\nreuse of overtrained models.",
    "published": "2025-10-08T00:59:33Z",
    "updated": "2025-10-08T00:59:33Z",
    "link": "http://arxiv.org/pdf/2510.06548v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Seng Pei Liew",
      "Takuya Kato"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06530v1",
    "title": "From Description to Detection: LLM based Extendable O-RAN Compliant\n  Blind DoS Detection in 5G and Beyond",
    "summary": "The quality and experience of mobile communication have significantly\nimproved with the introduction of 5G, and these improvements are expected to\ncontinue beyond the 5G era. However, vulnerabilities in control-plane\nprotocols, such as Radio Resource Control (RRC) and Non-Access Stratum (NAS),\npose significant security threats, such as Blind Denial of Service (DoS)\nattacks. Despite the availability of existing anomaly detection methods that\nleverage rule-based systems or traditional machine learning methods, these\nmethods have several limitations, including the need for extensive training\ndata, predefined rules, and limited explainability. Addressing these\nchallenges, we propose a novel anomaly detection framework that leverages the\ncapabilities of Large Language Models (LLMs) in zero-shot mode with unordered\ndata and short natural language attack descriptions within the Open Radio\nAccess Network (O-RAN) architecture. We analyse robustness to prompt variation,\ndemonstrate the practicality of automating the attack descriptions and show\nthat detection quality relies on the semantic completeness of the description\nrather than its phrasing or length. We utilise an RRC/NAS dataset to evaluate\nthe solution and provide an extensive comparison of open-source and proprietary\nLLM implementations to demonstrate superior performance in attack detection. We\nfurther validate the practicality of our framework within O-RAN's real-time\nconstraints, illustrating its potential for detecting other Layer-3 attacks.",
    "published": "2025-10-08T00:13:02Z",
    "updated": "2025-10-08T00:13:02Z",
    "link": "http://arxiv.org/pdf/2510.06530v1.pdf",
    "category": [
      "cs.CR",
      "cs.ET",
      "cs.LG",
      "cs.NI"
    ],
    "authors": [
      "Thusitha Dayaratne",
      "Ngoc Duy Pham",
      "Viet Vo",
      "Shangqi Lai",
      "Sharif Abuadbba",
      "Hajime Suzuki",
      "Xingliang Yuan",
      "Carsten Rudolph"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06528v1",
    "title": "BACHI: Boundary-Aware Symbolic Chord Recognition Through Masked\n  Iterative Decoding on Pop and Classical Music",
    "summary": "Automatic chord recognition (ACR) via deep learning models has gradually\nachieved promising recognition accuracy, yet two key challenges remain. First,\nprior work has primarily focused on audio-domain ACR, while symbolic music\n(e.g., score) ACR has received limited attention due to data scarcity. Second,\nexisting methods still overlook strategies that are aligned with human music\nanalytical practices. To address these challenges, we make two contributions:\n(1) we introduce POP909-CL, an enhanced version of POP909 dataset with\ntempo-aligned content and human-corrected labels of chords, beats, keys, and\ntime signatures; and (2) We propose BACHI, a symbolic chord recognition model\nthat decomposes the task into different decision steps, namely boundary\ndetection and iterative ranking of chord root, quality, and bass (inversion).\nThis mechanism mirrors the human ear-training practices. Experiments\ndemonstrate that BACHI achieves state-of-the-art chord recognition performance\non both classical and pop music benchmarks, with ablation studies validating\nthe effectiveness of each module.",
    "published": "2025-10-08T00:02:56Z",
    "updated": "2025-10-08T00:02:56Z",
    "link": "http://arxiv.org/pdf/2510.06528v1.pdf",
    "category": [
      "cs.SD",
      "cs.LG",
      "eess.AS"
    ],
    "authors": [
      "Mingyang Yao",
      "Ke Chen",
      "Shlomo Dubnov",
      "Taylor Berg-Kirkpatrick"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06527v1",
    "title": "Wide Neural Networks as a Baseline for the Computational No-Coincidence\n  Conjecture",
    "summary": "We establish that randomly initialized neural networks, with large width and\na natural choice of hyperparameters, have nearly independent outputs exactly\nwhen their activation function is nonlinear with zero mean under the Gaussian\nmeasure: $\\mathbb{E}_{z \\sim \\mathcal{N}(0,1)}[\\sigma(z)]=0$. For example, this\nincludes ReLU and GeLU with an additive shift, as well as tanh, but not ReLU or\nGeLU by themselves. Because of their nearly independent outputs, we propose\nneural networks with zero-mean activation functions as a promising candidate\nfor the Alignment Research Center's computational no-coincidence conjecture --\na conjecture that aims to measure the limits of AI interpretability.",
    "published": "2025-10-08T00:02:22Z",
    "updated": "2025-10-08T00:02:22Z",
    "link": "http://arxiv.org/pdf/2510.06527v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "John Dunbar",
      "Scott Aaronson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06525v1",
    "title": "Text-to-Image Models Leave Identifiable Signatures: Implications for\n  Leaderboard Security",
    "summary": "Generative AI leaderboards are central to evaluating model capabilities, but\nremain vulnerable to manipulation. Among key adversarial objectives is rank\nmanipulation, where an attacker must first deanonymize the models behind\ndisplayed outputs -- a threat previously demonstrated and explored for large\nlanguage models (LLMs). We show that this problem can be even more severe for\ntext-to-image leaderboards, where deanonymization is markedly easier. Using\nover 150,000 generated images from 280 prompts and 19 diverse models spanning\nmultiple organizations, architectures, and sizes, we demonstrate that simple\nreal-time classification in CLIP embedding space identifies the generating\nmodel with high accuracy, even without prompt control or historical data. We\nfurther introduce a prompt-level separability metric and identify prompts that\nenable near-perfect deanonymization. Our results indicate that rank\nmanipulation in text-to-image leaderboards is easier than previously\nrecognized, underscoring the need for stronger defenses.",
    "published": "2025-10-07T23:53:41Z",
    "updated": "2025-10-07T23:53:41Z",
    "link": "http://arxiv.org/pdf/2510.06525v1.pdf",
    "category": [
      "cs.LG",
      "cs.CR"
    ],
    "authors": [
      "Ali Naseh",
      "Anshuman Suri",
      "Yuefeng Peng",
      "Harsh Chaudhari",
      "Alina Oprea",
      "Amir Houmansadr"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.03470v2",
    "title": "On residual network depth",
    "summary": "Deep residual architectures, such as ResNet and the Transformer, have enabled\nmodels of unprecedented depth, yet a formal understanding of why depth is so\neffective remains an open question. A popular intuition, following Veit et al.\n(2016), is that these residual networks behave like ensembles of many shallower\nmodels. Our key finding is an explicit analytical formula that verifies this\nensemble perspective, proving that increasing network depth is mathematically\nequivalent to expanding the size of this implicit ensemble. Furthermore, our\nexpansion reveals a hierarchical ensemble structure in which the combinatorial\ngrowth of computation paths leads to an explosion in the output signal,\nexplaining the historical necessity of normalization layers in training deep\nmodels. This insight offers a first principles explanation for the historical\ndependence on normalization layers and sheds new light on a family of\nsuccessful normalization-free techniques like SkipInit and Fixup. However,\nwhile these previous approaches infer scaling factors through optimizer\nanalysis or a heuristic analogy to Batch Normalization, our work offers the\nfirst explanation derived directly from the network's inherent functional\nstructure. Specifically, our Residual Expansion Theorem reveals that scaling\neach residual module provides a principled solution to taming the combinatorial\nexplosion inherent to these architectures. We further show that this scaling\nacts as a capacity controls that also implicitly regularizes the model's\ncomplexity.",
    "published": "2025-10-03T19:48:48Z",
    "updated": "2025-10-07T23:37:12Z",
    "link": "http://arxiv.org/pdf/2510.03470v2.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Benoit Dherin",
      "Michael Munn"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06515v1",
    "title": "Online Matching via Reinforcement Learning: An Expert Policy\n  Orchestration Strategy",
    "summary": "Online matching problems arise in many complex systems, from cloud services\nand online marketplaces to organ exchange networks, where timely, principled\ndecisions are critical for maintaining high system performance. Traditional\nheuristics in these settings are simple and interpretable but typically\ntailored to specific operating regimes, which can lead to inefficiencies when\nconditions change. We propose a reinforcement learning (RL) approach that\nlearns to orchestrate a set of such expert policies, leveraging their\ncomplementary strengths in a data-driven, adaptive manner. Building on the Adv2\nframework (Jonckheere et al., 2024), our method combines expert decisions\nthrough advantage-based weight updates and extends naturally to settings where\nonly estimated value functions are available. We establish both expectation and\nhigh-probability regret guarantees and derive a novel finite-time bias bound\nfor temporal-difference learning, enabling reliable advantage estimation even\nunder constant step size and non-stationary dynamics. To support scalability,\nwe introduce a neural actor-critic architecture that generalizes across large\nstate spaces while preserving interpretability. Simulations on stochastic\nmatching models, including an organ exchange scenario, show that the\norchestrated policy converges faster and yields higher system level efficiency\nthan both individual experts and conventional RL baselines. Our results\nhighlight how structured, adaptive learning can improve the modeling and\nmanagement of complex resource allocation and decision-making processes.",
    "published": "2025-10-07T23:26:16Z",
    "updated": "2025-10-07T23:26:16Z",
    "link": "http://arxiv.org/pdf/2510.06515v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Chiara Mignacco",
      "Matthieu Jonckheere",
      "Gilles Stoltz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.18915v3",
    "title": "Testing Support Size More Efficiently Than Learning Histograms",
    "summary": "Consider two problems about an unknown probability distribution $p$:\n  1. How many samples from $p$ are required to test if $p$ is supported on $n$\nelements or not? Specifically, given samples from $p$, determine whether it is\nsupported on at most $n$ elements, or it is \"$\\epsilon$-far\" (in total\nvariation distance) from being supported on $n$ elements.\n  2. Given $m$ samples from $p$, what is the largest lower bound on its support\nsize that we can produce?\n  The best known upper bound for problem (1) uses a general algorithm for\nlearning the histogram of the distribution $p$, which requires\n$\\Theta(\\tfrac{n}{\\epsilon^2 \\log n})$ samples. We show that testing can be\ndone more efficiently than learning the histogram, using only\n$O(\\tfrac{n}{\\epsilon \\log n} \\log(1/\\epsilon))$ samples, nearly matching the\nbest known lower bound of $\\Omega(\\tfrac{n}{\\epsilon \\log n})$. This algorithm\nalso provides a better solution to problem (2), producing larger lower bounds\non support size than what follows from previous work. The proof relies on an\nanalysis of Chebyshev polynomial approximations outside the range where they\nare designed to be good approximations, and the paper is intended as an\naccessible self-contained exposition of the Chebyshev polynomial method.",
    "published": "2024-10-24T17:05:34Z",
    "updated": "2025-10-07T23:03:39Z",
    "link": "http://arxiv.org/pdf/2410.18915v3.pdf",
    "category": [
      "cs.DS",
      "cs.LG"
    ],
    "authors": [
      "Renato Ferreira Pinto Jr.",
      "Nathaniel Harms"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06502v1",
    "title": "GUIDE: Guided Initialization and Distillation of Embeddings",
    "summary": "Algorithmic efficiency techniques such as distillation\n(\\cite{hinton2015distillation}) are useful in improving model quality without\nincreasing serving costs, provided a larger teacher model is available for a\nsmaller student model to learn from during training. Standard distillation\nmethods are limited to only forcing the student to match the teacher's outputs.\nGiven the costs associated with training a large model, we believe we should be\nextracting more useful information from a teacher model than by just making the\nstudent match the teacher's outputs.\n  In this paper, we introduce \\guide (Guided Initialization and Distillation of\nEmbeddings). \\guide can be considered a distillation technique that forces the\nstudent to match the teacher in the parameter space. Using \\guide we show\n25-26\\% reduction in the teacher-student quality gap when using large student\nmodels (400M - 1B parameters) trained on $\\approx$ 20B tokens. We also present\na thorough analysis demonstrating that \\guide can be combined with knowledge\ndistillation with near additive improvements. Furthermore, we show that\napplying \\guide alone leads to substantially better model quality than applying\nknowledge distillation by itself.\n  Most importantly, \\guide introduces no training or inference overhead and\nhence any model quality gains from our method are virtually free.",
    "published": "2025-10-07T22:37:24Z",
    "updated": "2025-10-07T22:37:24Z",
    "link": "http://arxiv.org/pdf/2510.06502v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Khoa Trinh",
      "Gaurav Menghani",
      "Erik Vee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2407.08868v5",
    "title": "Generalizable Physics-Informed Learning for Stochastic Safety-Critical\n  Systems",
    "summary": "Accurate estimation of long-term risk is essential for the design and\nanalysis of stochastic dynamical systems. Existing risk quantification methods\ntypically rely on extensive datasets involving risk events observed over\nextended time horizons, which can be prohibitively expensive to acquire.\nMotivated by this gap, we propose an efficient method for learning long-term\nrisk probabilities using short-term samples with limited occurrence of risk\nevents. Specifically, we establish that four distinct classes of long-term risk\nprobabilities are characterized by specific partial differential equations\n(PDEs). Using this characterization, we introduce a physics-informed learning\nframework that combines empirical data with physics information to infer risk\nprobabilities. We then analyze the theoretical properties of this framework in\nterms of generalization and convergence. Through numerical experiments, we\ndemonstrate that our framework not only generalizes effectively beyond the\nsampled states and time horizons but also offers additional benefits such as\nimproved sample efficiency, rapid online inference capabilities under changing\nsystem dynamics, and stable computation of probability gradients. These results\nhighlight how embedding PDE constraints, which contain explicit gradient terms\nand inform how risk probabilities depend on state, time horizon, and system\nparameters, improves interpolation and generalization between/beyond the\navailable data.",
    "published": "2024-07-11T21:10:03Z",
    "updated": "2025-10-07T22:19:44Z",
    "link": "http://arxiv.org/pdf/2407.08868v5.pdf",
    "category": [
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "authors": [
      "Zhuoyuan Wang",
      "Albert Chern",
      "Yorie Nakahira"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.09348v2",
    "title": "Adversarial Surrogate Risk Bounds for Binary Classification",
    "summary": "A central concern in classification is the vulnerability of machine learning\nmodels to adversarial attacks. Adversarial training is one of the most popular\ntechniques for training robust classifiers, which involves minimizing an\nadversarial surrogate risk. Recent work has characterized the conditions under\nwhich any sequence minimizing the adversarial surrogate risk also minimizes the\nadversarial classification risk in the binary setting, a property known as\nadversarial consistency. However, these results do not address the rate at\nwhich the adversarial classification risk approaches its optimal value along\nsuch a sequence. This paper provides surrogate risk bounds that quantify that\nconvergence rate.",
    "published": "2025-06-11T02:57:08Z",
    "updated": "2025-10-07T22:02:43Z",
    "link": "http://arxiv.org/pdf/2506.09348v2.pdf",
    "category": [
      "cs.LG",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "authors": [
      "Natalie S. Frank"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.15559v2",
    "title": "A Novel Collaborative Framework for Efficient Synchronization in Split\n  Federated Learning over Wireless Networks",
    "summary": "Split Federated Learning (SFL) offers a promising approach for distributed\nmodel training in wireless networks, combining the layer-partitioning\nadvantages of split learning with the federated aggregation that ensures global\nconvergence. However, in heterogeneous wireless environments, disparities in\ndevice capabilities and channel conditions make strict round-based\nsynchronization heavily straggler-dominated, thereby limiting both efficiency\nand scalability. To address this challenge, we propose a new framework, called\nCollaborative Split Federated Learning (CSFL), that redefines workload\nredistribution through device-to-device collaboration. Building on the\nflexibility of model partitioning, CSFL enables efficient devices, after\ncompleting their own forward propagation, to seamlessly take over the\nunfinished layers of bottleneck devices. This collaborative process, supported\nby D2D communications, allows bottleneck devices to offload computation earlier\nwhile maintaining synchronized progression across the network. Beyond the\nsystem design, we highlight key technical enablers such as privacy protection,\nmulti-perspective matching, and incentive mechanisms, and discuss practical\nchallenges including matching balance, privacy risks, and incentive\nsustainability. A case study demonstrates that CSFL significantly reduces\ntraining latency without compromising convergence speed or accuracy,\nunderscoring collaboration as a key enabler for synchronization-efficient\nlearning in next-generation wireless networks.",
    "published": "2025-03-18T22:11:54Z",
    "updated": "2025-10-07T21:23:55Z",
    "link": "http://arxiv.org/pdf/2503.15559v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Haoran Gao",
      "Samuel D. Okegbile",
      "Jun Cai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.00602v2",
    "title": "Multi-Agent Stage-wise Conservative Linear Bandits",
    "summary": "In many real-world applications such as recommendation systems, multiple\nlearning agents must balance exploration and exploitation while maintaining\nsafety guarantees to avoid catastrophic failures. We study the stochastic\nlinear bandit problem in a multi-agent networked setting where agents must\nsatisfy stage-wise conservative constraints. A network of $N$ agents\ncollaboratively maximizes cumulative reward while ensuring that the expected\nreward at every round is no less than $(1-\\alpha)$ times that of a baseline\npolicy. Each agent observes local rewards with unknown parameters, but the\nnetwork optimizes for the global parameter (average of local parameters).\nAgents communicate only with immediate neighbors, and each communication round\nincurs additional regret. We propose MA-SCLUCB (Multi-Agent Stage-wise\nConservative Linear UCB), an episodic algorithm alternating between action\nselection and consensus-building phases. We prove that MA-SCLUCB achieves\nregret\n$\\tilde{O}\\left(\\frac{d}{\\sqrt{N}}\\sqrt{T}\\cdot\\frac{\\log(NT)}{\\sqrt{\\log(1/|\\lambda_2|)}}\\right)$\nwith high probability, where $d$ is the dimension, $T$ is the horizon, and\n$|\\lambda_2|$ is the network's second largest eigenvalue magnitude. Our\nanalysis shows: (i) collaboration yields $\\frac{1}{\\sqrt{N}}$ improvement\ndespite local communication, (ii) communication overhead grows only\nlogarithmically for well-connected networks, and (iii) stage-wise safety adds\nonly lower-order regret. Thus, distributed learning with safety guarantees\nachieves near-optimal performance in reasonably connected networks.",
    "published": "2025-10-01T07:29:18Z",
    "updated": "2025-10-07T21:07:32Z",
    "link": "http://arxiv.org/pdf/2510.00602v2.pdf",
    "category": [
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "authors": [
      "Amirhoseein Afsharrad",
      "Ahmadreza Moradipari",
      "Sanjay Lall"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.00264v3",
    "title": "Baseline Systems For The 2025 Low-Resource Audio Codec Challenge",
    "summary": "The Low-Resource Audio Codec (LRAC) Challenge aims to advance neural audio\ncoding for deployment in resource-constrained environments. The first edition\nfocuses on low-resource neural speech codecs that must operate reliably under\neveryday noise and reverberation, while satisfying strict constraints on\ncomputational complexity, latency, and bitrate. Track 1 targets transparency\ncodecs, which aim to preserve the perceptual transparency of input speech under\nmild noise and reverberation. Track 2 addresses enhancement codecs, which\ncombine coding and compression with denoising and dereverberation. This paper\npresents the official baseline systems for both tracks in the 2025 LRAC\nChallenge. The baselines are convolutional neural codec models with Residual\nVector Quantization, trained end-to-end using a combination of adversarial and\nreconstruction objectives. We detail the data filtering and augmentation\nstrategies, model architectures, optimization procedures, and checkpoint\nselection criteria.",
    "published": "2025-09-30T20:36:58Z",
    "updated": "2025-10-07T20:55:21Z",
    "link": "http://arxiv.org/pdf/2510.00264v3.pdf",
    "category": [
      "cs.SD",
      "cs.LG"
    ],
    "authors": [
      "Yusuf Ziya Isik",
      "Rafał Łaganowski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.20309v2",
    "title": "Guiding Giants: Lightweight Controllers for Weighted Activation Steering\n  in LLMs",
    "summary": "Controlling undesirable Large Language Model (LLM) behaviors, such as the\ngeneration of unsafe content or failing to adhere to safety guidelines, often\nrelies on costly fine-tuning. Activation steering provides an alternative for\ninference-time control, but existing methods typically lack fine-grained,\nadaptive mechanisms. We introduce a novel approach using a lightweight,\ntrainable controller network integrated during inference. This controller\nnetwork observes specific intermediate LLM activations and predicts both a\nglobal scaling factor and layer-specific weights. The predicted global scaling\nfactor and layer-specific weights then dynamically modulate the intensity of a\nsteering patch, derived from a pre-computed \"refusal direction\" vector, applied\nacross the LLM's layers during generation. Trained on activations from both\nharmful and benign prompts, our controller learns to discriminatively apply\nnuanced, layer-aware interventions, activating steering primarily for harmful\ninputs. Experiments using safety benchmarks like ToxicChat & In-The-Wild\nJailbreak Prompts demonstrate that our weighted steering controller\nsignificantly increases refusal rates compared to the base LLM, achieving\ntargeted behavioral modification without altering the original model\nparameters. Our experiments with Llama-3.1-8B, Llama-3.2-1B & Mistral-7B show\nour approach outperforms existing methods, presenting an efficient and adaptive\nmethod for fine-grained control over LLM behavior at inference time.",
    "published": "2025-05-22T01:48:38Z",
    "updated": "2025-10-07T20:52:01Z",
    "link": "http://arxiv.org/pdf/2505.20309v2.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Amr Hegazy",
      "Mostafa Elhoushi",
      "Amr Alanwar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.24076v4",
    "title": "A Family of Kernelized Matrix Costs for Multiple-Output Mixture Neural\n  Networks",
    "summary": "Pairwise distance-based costs are crucial for self-supervised and contrastive\nfeature learning. Mixture Density Networks (MDNs) are a widely used approach\nfor generative models and density approximation, using neural networks to\nproduce multiple centers that define a Gaussian mixture. By combining MDNs with\ncontrastive costs, this paper proposes data density approximation using four\ntypes of kernelized matrix costs in the Hilbert space: the scalar cost, the\nvector-matrix cost, the matrix-matrix cost (the trace of Schur complement), and\nthe SVD cost (the nuclear norm), for learning multiple centers required to\ndefine a mixture density.",
    "published": "2025-09-28T21:23:11Z",
    "updated": "2025-10-07T20:25:57Z",
    "link": "http://arxiv.org/pdf/2509.24076v4.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Bo Hu",
      "José C. Príncipe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06439v1",
    "title": "Bayesian Optimization under Uncertainty for Training a Scale Parameter\n  in Stochastic Models",
    "summary": "Hyperparameter tuning is a challenging problem especially when the system\nitself involves uncertainty. Due to noisy function evaluations, optimization\nunder uncertainty can be computationally expensive. In this paper, we present a\nnovel Bayesian optimization framework tailored for hyperparameter tuning under\nuncertainty, with a focus on optimizing a scale- or precision-type parameter in\nstochastic models. The proposed method employs a statistical surrogate for the\nunderlying random variable, enabling analytical evaluation of the expectation\noperator. Moreover, we derive a closed-form expression for the optimizer of the\nrandom acquisition function, which significantly reduces computational cost per\niteration. Compared with a conventional one-dimensional Monte Carlo-based\noptimization scheme, the proposed approach requires 40 times fewer data points,\nresulting in up to a 40-fold reduction in computational cost. We demonstrate\nthe effectiveness of the proposed method through two numerical examples in\ncomputational engineering.",
    "published": "2025-10-07T20:19:51Z",
    "updated": "2025-10-07T20:19:51Z",
    "link": "http://arxiv.org/pdf/2510.06439v1.pdf",
    "category": [
      "cs.LG",
      "cs.CE",
      "math.OC",
      "stat.ML"
    ],
    "authors": [
      "Akash Yadav",
      "Ruda Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.00387v2",
    "title": "Bayesian Distributional Models of Executive Functioning",
    "summary": "This study uses controlled simulations with known ground-truth parameters to\nevaluate how Distributional Latent Variable Models (DLVM) and Bayesian\nDistributional Active LEarning (DALE) perform in comparison to conventional\nIndependent Maximum Likelihood Estimation (IMLE). DLVM integrates observations\nacross multiple executive function tasks and individuals, allowing parameter\nestimation even under sparse or incomplete data conditions. DLVM consistently\noutperformed IMLE, especially under with smaller amounts of data, and converges\nfaster to highly accurate estimates of the true distributions. In a second set\nof analyses, DALE adaptively guided sampling to maximize information gain,\noutperforming random sampling and fixed test batteries, particularly within the\nfirst 80 trials. These findings establish the advantages of combining DLVM's\ncross-task inference with DALE's optimal adaptive sampling, providing a\nprincipled basis for more efficient cognitive assessments.",
    "published": "2025-10-01T00:59:31Z",
    "updated": "2025-10-07T20:12:14Z",
    "link": "http://arxiv.org/pdf/2510.00387v2.pdf",
    "category": [
      "cs.LG",
      "cs.HC"
    ],
    "authors": [
      "Robert Kasumba",
      "Zeyu Lu",
      "Dom CP Marticorena",
      "Mingyang Zhong",
      "Paul Beggs",
      "Anja Pahor",
      "Geetha Ramani",
      "Imani Goffney",
      "Susanne M Jaeggi",
      "Aaron R Seitz",
      "Jacob R Gardner",
      "Dennis L Barbour"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06434v1",
    "title": "Nearly Instance-Optimal Parameter Recovery from Many Trajectories via\n  Hellinger Localization",
    "summary": "Learning from temporally-correlated data is a core facet of modern machine\nlearning. Yet our understanding of sequential learning remains incomplete,\nparticularly in the multi-trajectory setting where data consists of many\nindependent realizations of a time-indexed stochastic process. This important\nregime both reflects modern training pipelines such as for large foundation\nmodels, and offers the potential for learning without the typical mixing\nassumptions made in the single-trajectory case. However, instance-optimal\nbounds are known only for least-squares regression with dependent covariates;\nfor more general models or loss functions, the only broadly applicable\nguarantees result from a reduction to either i.i.d. learning, with effective\nsample size scaling only in the number of trajectories, or an existing\nsingle-trajectory result when each individual trajectory mixes, with effective\nsample size scaling as the full data budget deflated by the mixing-time.\n  In this work, we significantly broaden the scope of instance-optimal rates in\nmulti-trajectory settings via the Hellinger localization framework, a general\napproach for maximum likelihood estimation. Our method proceeds by first\ncontrolling the squared Hellinger distance at the path-measure level via a\nreduction to i.i.d. learning, followed by localization as a quadratic form in\nparameter space weighted by the trajectory Fisher information. This yields\ninstance-optimal bounds that scale with the full data budget under a broad set\nof conditions. We instantiate our framework across four diverse case studies: a\nsimple mixture of Markov chains, dependent linear regression under non-Gaussian\nnoise, generalized linear models with non-monotonic activations, and\nlinear-attention sequence models. In all cases, our bounds nearly match the\ninstance-optimal rates from asymptotic normality, substantially improving over\nstandard reductions.",
    "published": "2025-10-07T20:12:04Z",
    "updated": "2025-10-07T20:12:04Z",
    "link": "http://arxiv.org/pdf/2510.06434v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Eliot Shekhtman",
      "Yichen Zhou",
      "Ingvar Ziemann",
      "Nikolai Matni",
      "Stephen Tu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06419v1",
    "title": "Test-Time Efficient Pretrained Model Portfolios for Time Series\n  Forecasting",
    "summary": "Is bigger always better for time series foundation models? With the question\nin mind, we explore an alternative to training a single, large monolithic\nmodel: building a portfolio of smaller, pretrained forecasting models. By\napplying ensembling or model selection over these portfolios, we achieve\ncompetitive performance on large-scale benchmarks using much fewer parameters.\nWe explore strategies for designing such portfolios and find that collections\nof specialist models consistently outperform portfolios of independently\ntrained generalists. Remarkably, we demonstrate that post-training a base model\nis a compute-effective approach for creating sufficiently diverse specialists,\nand provide evidences that ensembling and model selection are more\ncompute-efficient than test-time fine-tuning.",
    "published": "2025-10-07T19:57:10Z",
    "updated": "2025-10-07T19:57:10Z",
    "link": "http://arxiv.org/pdf/2510.06419v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Mert Kayaalp",
      "Caner Turkmen",
      "Oleksandr Shchur",
      "Pedro Mercado",
      "Abdul Fatir Ansari",
      "Michael Bohlke-Schneider",
      "Bernie Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.00336v2",
    "title": "Denoising Score Matching with Random Features: Insights on Diffusion\n  Models from Precise Learning Curves",
    "summary": "We theoretically investigate the phenomena of generalization and memorization\nin diffusion models. Empirical studies suggest that these phenomena are\ninfluenced by model complexity and the size of the training dataset. In our\nexperiments, we further observe that the number of noise samples per data\nsample ($m$) used during Denoising Score Matching (DSM) plays a significant and\nnon-trivial role. We capture these behaviors and shed insights into their\nmechanisms by deriving asymptotically precise expressions for test and train\nerrors of DSM under a simple theoretical setting. The score function is\nparameterized by random features neural networks, with the target distribution\nbeing $d$-dimensional Gaussian. We operate in a regime where the dimension $d$,\nnumber of data samples $n$, and number of features $p$ tend to infinity while\nkeeping the ratios $\\psi_n=\\frac{n}{d}$ and $\\psi_p=\\frac{p}{d}$ fixed. By\ncharacterizing the test and train errors, we identify regimes of generalization\nand memorization as a function of $\\psi_n,\\psi_p$, and $m$. Our theoretical\nfindings are consistent with the empirical observations.",
    "published": "2025-02-01T06:43:33Z",
    "updated": "2025-10-07T19:37:10Z",
    "link": "http://arxiv.org/pdf/2502.00336v2.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Anand Jerry George",
      "Rodrigo Veiga",
      "Nicolas Macris"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06401v1",
    "title": "The Effect of Label Noise on the Information Content of Neural\n  Representations",
    "summary": "In supervised classification tasks, models are trained to predict a label for\neach data point. In real-world datasets, these labels are often noisy due to\nannotation errors. While the impact of label noise on the performance of deep\nlearning models has been widely studied, its effects on the networks' hidden\nrepresentations remain poorly understood. We address this gap by systematically\ncomparing hidden representations using the Information Imbalance, a\ncomputationally efficient proxy of conditional mutual information. Through this\nanalysis, we observe that the information content of the hidden representations\nfollows a double descent as a function of the number of network parameters,\nakin to the behavior of the test error. We further demonstrate that in the\nunderparameterized regime, representations learned with noisy labels are more\ninformative than those learned with clean labels, while in the\noverparameterized regime, these representations are equally informative. Our\nresults indicate that the representations of overparameterized networks are\nrobust to label noise. We also found that the information imbalance between the\npenultimate and pre-softmax layers decreases with cross-entropy loss in the\noverparameterized regime. This offers a new perspective on understanding\ngeneralization in classification tasks. Extending our analysis to\nrepresentations learned from random labels, we show that these perform worse\nthan random features. This indicates that training on random labels drives\nnetworks much beyond lazy learning, as weights adapt to encode labels\ninformation.",
    "published": "2025-10-07T19:27:26Z",
    "updated": "2025-10-07T19:27:26Z",
    "link": "http://arxiv.org/pdf/2510.06401v1.pdf",
    "category": [
      "cs.LG",
      "cs.IT",
      "cs.NE",
      "math.IT",
      "stat.ML"
    ],
    "authors": [
      "Ali Hussaini Umar",
      "Franky Kevin Nando Tezoh",
      "Jean Barbier",
      "Santiago Acevedo",
      "Alessandro Laio"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.09714v2",
    "title": "Auto-Compressing Networks",
    "summary": "Deep neural networks with short residual connections have demonstrated\nremarkable success across domains, but increasing depth often introduces\ncomputational redundancy without corresponding improvements in representation\nquality. We introduce Auto-Compressing Networks (ACNs), an architectural\nvariant where additive long feedforward connections from each layer to the\noutput replace traditional short residual connections. By analyzing the\ndistinct dynamics induced by this modification, we reveal a unique property we\ncoin as auto-compression, the ability of a network to organically compress\ninformation during training with gradient descent, through architectural design\nalone. Through auto-compression, information is dynamically \"pushed\" into early\nlayers during training, enhancing their representational quality and revealing\npotential redundancy in deeper ones. We theoretically show that this property\nemerges from layer-wise training patterns present in ACNs, where layers are\ndynamically utilized during training based on task requirements. We also find\nthat ACNs exhibit enhanced noise robustness compared to residual networks,\nsuperior performance in low-data settings, improved transfer learning\ncapabilities, and mitigate catastrophic forgetting suggesting that they learn\nrepresentations that generalize better despite using fewer parameters. Our\nresults demonstrate up to 18% reduction in catastrophic forgetting and 30-80%\narchitectural compression while maintaining accuracy across vision\ntransformers, MLP-mixers, and BERT architectures. These findings establish ACNs\nas a practical approach to developing efficient neural architectures that\nautomatically adapt their computational footprint to task complexity, while\nlearning robust representations suitable for noisy real-world tasks and\ncontinual learning scenarios.",
    "published": "2025-06-11T13:26:09Z",
    "updated": "2025-10-07T19:23:20Z",
    "link": "http://arxiv.org/pdf/2506.09714v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Vaggelis Dorovatas",
      "Georgios Paraskevopoulos",
      "Alexandros Potamianos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.19752v2",
    "title": "On the necessity of adaptive regularisation:Optimal anytime online\n  learning on $\\boldsymbol{\\ell_p}$-balls",
    "summary": "We study online convex optimization on $\\ell_p$-balls in $\\mathbb{R}^d$ for\n$p > 2$. While always sub-linear, the optimal regret exhibits a shift between\nthe high-dimensional setting ($d > T$), when the dimension $d$ is greater than\nthe time horizon $T$ and the low-dimensional setting ($d \\leq T$). We show that\nFollow-the-Regularised-Leader (FTRL) with time-varying regularisation which is\nadaptive to the dimension regime is anytime optimal for all dimension regimes.\nMotivated by this, we ask whether it is possible to obtain anytime optimality\nof FTRL with fixed non-adaptive regularisation. Our main result establishes\nthat for separable regularisers, adaptivity in the regulariser is necessary,\nand that any fixed regulariser will be sub-optimal in one of the two dimension\nregimes. Finally, we provide lower bounds which rule out sub-linear regret\nbounds for the linear bandit problem in sufficiently high-dimension for all\n$\\ell_p$-balls with $p \\geq 1$.",
    "published": "2025-06-24T16:06:56Z",
    "updated": "2025-10-07T19:15:19Z",
    "link": "http://arxiv.org/pdf/2506.19752v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Emmeran Johnson",
      "David Martínez-Rubio",
      "Ciara Pike-Burke",
      "Patrick Rebeschini"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06388v1",
    "title": "Making and Evaluating Calibrated Forecasts",
    "summary": "Calibrated predictions can be reliably interpreted as probabilities. An\nimportant step towards achieving better calibration is to design an appropriate\ncalibration measure to meaningfully assess the miscalibration level of a\npredictor. A recent line of work initiated by Haghtalab et al. [2024] studies\nthe design of truthful calibration measures: a truthful measure is minimized\nwhen a predictor outputs the true probabilities, whereas a non-truthful measure\nincentivizes the predictor to lie so as to appear more calibrated. All previous\ncalibration measures were non-truthful until Hartline et al. [2025] introduced\nthe first perfectly truthful calibration measures for binary prediction tasks\nin the batch setting.\n  We introduce a perfectly truthful calibration measure for multi-class\nprediction tasks, generalizing the work of Hartline et al. [2025] beyond binary\nprediction. We study common methods of extending calibration measures from\nbinary to multi-class prediction and identify ones that do or do not preserve\ntruthfulness. In addition to truthfulness, we mathematically prove and\nempirically verify that our calibration measure exhibits superior robustness:\nit robustly preserves the ordering between dominant and dominated predictors,\nregardless of the choice of hyperparameters (bin sizes). This result addresses\nthe non-robustness issue of binned ECE, which has been observed repeatedly in\nprior work.",
    "published": "2025-10-07T19:11:03Z",
    "updated": "2025-10-07T19:11:03Z",
    "link": "http://arxiv.org/pdf/2510.06388v1.pdf",
    "category": [
      "cs.LG",
      "cs.DS",
      "stat.ML"
    ],
    "authors": [
      "Yuxuan Lu",
      "Yifan Wu",
      "Jason Hartline",
      "Lunjia Hu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.14003v2",
    "title": "Machine Learning H-theorem",
    "summary": "H-theorem provides a microscopic foundation of the Second Law of\nThermodynamics and is therefore essential to establishing statistical physics,\nbut at the same time, H-theorem has been subject to controversy that in part\npersists till this day. To better understand H-theorem and its relation to the\narrow of time, we study the equilibration of randomly oriented and positioned\nhard disks with periodic boundary conditions. Using a model based on the\nDeepSets architecture, which imposes permutation invariance of the particle\nlabels, we train a model to capture the irreversibility of the H-functional.",
    "published": "2025-08-19T17:02:51Z",
    "updated": "2025-10-07T19:09:19Z",
    "link": "http://arxiv.org/pdf/2508.14003v2.pdf",
    "category": [
      "cond-mat.stat-mech",
      "cs.LG"
    ],
    "authors": [
      "Ruben Lier"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.22552v3",
    "title": "Probing forced responses and causal mechanisms in large-scale climate\n  dynamics with reduced-order neural models",
    "summary": "A central challenge in climate science and applied mathematics is developing\ndata-driven models of multiscale systems that capture not only stationary\nstatistics but also responses to external perturbations. Current neural climate\nemulators seek to resolve the atmosphere-ocean system in all its complexity but\noften fail to reproduce forced responses, limiting their use in causal studies\nsuch as Green's function experiments. Response theory offers a rigorous\nframework to explore these limitations, moving beyond stationary statistics,\nprobing causal mechanisms, and guiding model design. Using a simplified\nmultiscale system, we argue that the skill of purely data-driven models in\nreproducing perturbed statistics depends critically on (i) identifying the\nproper variables to model, including spatial and temporal scales, and (ii)\naccurate stochastic parameterizations of unresolved processes. For studies of\nlow-frequency climate dynamics, these insights motivate reduced-order neural\nmodels, tailored to specific processes, as valuable alternatives to\ngeneral-purpose emulators. We illustrate this perspective with a reduced-order\nneural stochastic model designed to investigate responses of radiative fluxes\nto surface temperature perturbations. The model largely reproduces stationary\nstatistics and enables the study of forced responses in both ensemble mean and\nvariance, shifting the study of climate feedbacks from single trajectories to\nresponses of probability distributions. These results underscore reduced-order\nmodels, augmented with modern neural networks and evaluated within the\nframework of response theory, as a practical strategy for causal inference and\nattribution studies in large-scale climate dynamics.",
    "published": "2025-06-27T18:04:36Z",
    "updated": "2025-10-07T19:05:35Z",
    "link": "http://arxiv.org/pdf/2506.22552v3.pdf",
    "category": [
      "nlin.CD",
      "cond-mat.stat-mech",
      "cs.LG",
      "physics.ao-ph"
    ],
    "authors": [
      "Fabrizio Falasca"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06372v1",
    "title": "A General Constructive Upper Bound on Shallow Neural Nets Complexity",
    "summary": "We provide an upper bound on the number of neurons required in a shallow\n  neural network to approximate a continuous function on a compact set with a\n  given accuracy. This method, inspired by a specific proof of the\n  Stone-Weierstrass theorem, is constructive and more general than previous\n  bounds of this character, as it applies to any continuous function on any\n  compact set.",
    "published": "2025-10-07T18:40:40Z",
    "updated": "2025-10-07T18:40:40Z",
    "link": "http://arxiv.org/pdf/2510.06372v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Frantisek Hakl",
      "Vit Fojtik"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06367v1",
    "title": "Lagrangian neural ODEs: Measuring the existence of a Lagrangian with\n  Helmholtz metrics",
    "summary": "Neural ODEs are a widely used, powerful machine learning technique in\nparticular for physics. However, not every solution is physical in that it is\nan Euler-Lagrange equation. We present Helmholtz metrics to quantify this\nresemblance for a given ODE and demonstrate their capabilities on several\nfundamental systems with noise. We combine them with a second order neural ODE\nto form a Lagrangian neural ODE, which allows to learn Euler-Lagrange equations\nin a direct fashion and with zero additional inference cost. We demonstrate\nthat, using only positional data, they can distinguish Lagrangian and\nnon-Lagrangian systems and improve the neural ODE solutions.",
    "published": "2025-10-07T18:29:03Z",
    "updated": "2025-10-07T18:29:03Z",
    "link": "http://arxiv.org/pdf/2510.06367v1.pdf",
    "category": [
      "cs.LG",
      "math.DS",
      "physics.comp-ph",
      "physics.data-an"
    ],
    "authors": [
      "Luca Wolf",
      "Tobias Buck",
      "Bjoern Malte Schaefer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06361v1",
    "title": "Diffusion-Guided Renormalization of Neural Systems via Tensor Networks",
    "summary": "Far from equilibrium, neural systems self-organize across multiple scales.\nExploiting multiscale self-organization in neuroscience and artificial\nintelligence requires a computational framework for modeling the effective\nnon-equilibrium dynamics of stochastic neural trajectories. Non-equilibrium\nthermodynamics and representational geometry offer theoretical foundations, but\nwe need scalable data-driven techniques for modeling collective properties of\nhigh-dimensional neural networks from partial subsampled observations.\nRenormalization is a coarse-graining technique central to studying emergent\nscaling properties of many-body and nonlinear dynamical systems. While widely\napplied in physics and machine learning, coarse-graining complex dynamical\nnetworks remains unsolved, affecting many computational sciences. Recent\ndiffusion-based renormalization, inspired by quantum statistical mechanics,\ncoarse-grains networks near entropy transitions marked by maximal changes in\nspecific heat or information transmission. Here I explore diffusion-based\nrenormalization of neural systems by generating symmetry-breaking\nrepresentations across scales and offering scalable algorithms using tensor\nnetworks. Diffusion-guided renormalization bridges microscale and mesoscale\ndynamics of dissipative neural systems. For microscales, I developed a scalable\ngraph inference algorithm for discovering community structure from subsampled\nneural activity. Using community-based node orderings, diffusion-guided\nrenormalization generates renormalization group flow through metagraphs and\njoint probability functions. Towards mesoscales, diffusion-guided\nrenormalization targets learning the effective non-equilibrium dynamics of\ndissipative neural trajectories occupying lower-dimensional subspaces, enabling\ncoarse-to-fine control in systems neuroscience and artificial intelligence.",
    "published": "2025-10-07T18:26:10Z",
    "updated": "2025-10-07T18:26:10Z",
    "link": "http://arxiv.org/pdf/2510.06361v1.pdf",
    "category": [
      "q-bio.NC",
      "cond-mat.stat-mech",
      "cs.LG"
    ],
    "authors": [
      "Nathan X. Kodama"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06355v1",
    "title": "PIKAN: Physics-Inspired Kolmogorov-Arnold Networks for Explainable UAV\n  Channel Modelling",
    "summary": "Unmanned aerial vehicle (UAV) communications demand accurate yet\ninterpretable air-to-ground (A2G) channel models that can adapt to\nnonstationary propagation environments. While deterministic models offer\ninterpretability and deep learning (DL) models provide accuracy, both\napproaches suffer from either rigidity or a lack of explainability. To bridge\nthis gap, we propose the Physics-Inspired Kolmogorov-Arnold Network (PIKAN)\nthat embeds physical principles (e.g., free-space path loss, two-ray\nreflections) into the learning process. Unlike physics-informed neural networks\n(PINNs), PIKAN is more flexible for applying physical information because it\nintroduces them as flexible inductive biases. Thus, it enables a more flexible\ntraining process. Experiments on UAV A2G measurement data show that PIKAN\nachieves comparable accuracy to DL models while providing symbolic and\nexplainable expressions aligned with propagation laws. Remarkably, PIKAN\nachieves this performance with only 232 parameters, making it up to 37 times\nlighter than multilayer perceptron (MLP) baselines with thousands of\nparameters, without sacrificing correlation with measurements and also\nproviding symbolic expressions. These results highlight PIKAN as an efficient,\ninterpretable, and scalable solution for UAV channel modelling in beyond-5G and\n6G networks.",
    "published": "2025-10-07T18:21:47Z",
    "updated": "2025-10-07T18:21:47Z",
    "link": "http://arxiv.org/pdf/2510.06355v1.pdf",
    "category": [
      "cs.LG",
      "eess.SP"
    ],
    "authors": [
      "Kürşat Tekbıyık",
      "Güneş Karabulut Kurt",
      "Antoine Lesage-Landry"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.01698v3",
    "title": "TalkPlay-Tools: Conversational Music Recommendation with LLM Tool\n  Calling",
    "summary": "While the recent developments in large language models (LLMs) have\nsuccessfully enabled generative recommenders with natural language\ninteractions, their recommendation behavior is limited, leaving other simpler\nyet crucial components such as metadata or attribute filtering underutilized in\nthe system. We propose an LLM-based music recommendation system with tool\ncalling to serve as a unified retrieval-reranking pipeline. Our system\npositions an LLM as an end-to-end recommendation system that interprets user\nintent, plans tool invocations, and orchestrates specialized components:\nboolean filters (SQL), sparse retrieval (BM25), dense retrieval (embedding\nsimilarity), and generative retrieval (semantic IDs). Through tool planning,\nthe system predicts which types of tools to use, their execution order, and the\narguments needed to find music matching user preferences, supporting diverse\nmodalities while seamlessly integrating multiple database filtering methods. We\ndemonstrate that this unified tool-calling framework achieves competitive\nperformance across diverse recommendation scenarios by selectively employing\nappropriate retrieval methods based on user queries, envisioning a new paradigm\nfor conversational music recommendation systems.",
    "published": "2025-10-02T06:08:54Z",
    "updated": "2025-10-08T05:49:57Z",
    "link": "http://arxiv.org/pdf/2510.01698v3.pdf",
    "category": [
      "cs.IR",
      "cs.MM",
      "cs.SD",
      "eess.AS"
    ],
    "authors": [
      "Seungheon Doh",
      "Keunwoo Choi",
      "Juhan Nam"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07275v1",
    "title": "Geometric Queries on Closed Implicit Surfaces for Walk on Stars",
    "summary": "Walk on stars (WoSt) is currently one of the most advanced Monte Carlo\nsolvers for PDEs. Unfortunately, the lack of reliable geometric query\napproaches has hindered its applicability to boundaries defined by implicit\nsurfaces. This work proposes a geometric query framework over closed implicit\nsurfaces for WoSt, under the scope of walkin' Robin. Our key observation is\nthat all WoSt queries can be formulated as constrained global optimization or\nconstraint satisfaction problems. Based on our formulations, to solve the\nhighly non-convex problems, we adopt a branch-and-bound approach based on\ninterval analysis. To the best of our knowledge, our method is the first to\nstudy closest silhouette point queries and Robin radius bound queries on closed\nimplicit surfaces. Our formulations and methods first enable mesh-free PDE\nsolving via WoSt when boundaries are defined by closed implicit surfaces.",
    "published": "2025-10-08T17:40:05Z",
    "updated": "2025-10-08T17:40:05Z",
    "link": "http://arxiv.org/pdf/2510.07275v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Tianyu Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.21633v2",
    "title": "SAR-GS: Gaussian Splatting based SAR Images Rendering and Target\n  Reconstruction",
    "summary": "Three-dimensional target reconstruction from synthetic aperture radar (SAR)\nimagery is crucial for interpreting complex scattering information in SAR data.\nHowever, the intricate electromagnetic scattering mechanisms inherent to SAR\nimaging pose significant reconstruction challenges. Inspired by the remarkable\nsuccess of 3D Gaussian Splatting (3D-GS) in optical domain reconstruction, this\npaper presents a novel SAR Differentiable Gaussian Splatting Rasterizer (SDGR)\nspecifically designed for SAR target reconstruction. Our approach combines\nGaussian splatting with the Mapping and Projection Algorithm to compute\nscattering intensities of Gaussian primitives and generate simulated SAR images\nthrough SDGR. Subsequently, the loss function between the rendered image and\nthe ground truth image is computed to optimize the Gaussian primitive\nparameters representing the scene, while a custom CUDA gradient flow is\nemployed to replace automatic differentiation for accelerated gradient\ncomputation. Through experiments involving the rendering of simplified\narchitectural targets and SAR images of multiple vehicle targets, we validate\nthe imaging rationality of SDGR on simulated SAR imagery. Furthermore, the\neffectiveness of our method for target reconstruction is demonstrated on both\nsimulated and real-world datasets containing multiple vehicle targets, with\nquantitative evaluations conducted to assess its reconstruction performance.\nExperimental results indicate that our approach can effectively reconstruct the\ngeometric structures and scattering properties of targets, thereby providing a\nnovel solution for 3D reconstruction in the field of SAR imaging.",
    "published": "2025-06-25T07:27:09Z",
    "updated": "2025-10-08T11:11:27Z",
    "link": "http://arxiv.org/pdf/2506.21633v2.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Aobo Li",
      "Zhengxin Lei",
      "Jiangtao Wei",
      "Feng Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06608v1",
    "title": "A Review of 10 Years of ProtoSpace: Spacecraft CAD Visualization in\n  Collaborative Augmented Reality",
    "summary": "ProtoSpace is a custom JPL-built platform to help scientists and engineers\nvisualize their CAD models collaboratively in augmented reality (AR) and on the\nweb in 3D. In addition to this main use case, ProtoSpace has been used\nthroughout the entire spacecraft mission lifecycle and beyond: ventilator\ndesign and assembly; providing AR-based instructions to astronauts in-training;\neducating the next generation on the process of spacecraft design; etc.\nProtoSpace has been used for a decade by NASA missions-including Mars\nPerseverance, Europa Clipper, NISAR, SPHEREx, CAL, and Mars Sample Return-to\nreduce cost and risk by helping engineers and scientists fix problems earlier\nthrough reducing miscommunication and helping people understand the spatial\ncontext of their spacecraft in the appropriate physical context more quickly.\nThis paper will explore how ProtoSpace came to be, define the system\narchitecture and overview-including HoloLens and 3D web clients, the ProtoSpace\nserver, and the CAD model optimizer-and dive into the use cases, spin-offs, and\nlessons learned that led to 10 years of success at NASA's Jet Propulsion\nLaboratory.",
    "published": "2025-10-08T03:35:56Z",
    "updated": "2025-10-08T03:35:56Z",
    "link": "http://arxiv.org/pdf/2510.06608v1.pdf",
    "category": [
      "cs.ET",
      "astro-ph.IM",
      "cs.GR",
      "cs.HC"
    ],
    "authors": [
      "Benjamin Nuernberger",
      "Samuel-Hunter Berndt",
      "Robert Tapella",
      "Laura Mann",
      "Aaron Plave",
      "Sasha Samochina",
      "Victor X. Luo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.07136v2",
    "title": "LangSplatV2: High-dimensional 3D Language Gaussian Splatting with 450+\n  FPS",
    "summary": "In this paper, we introduce LangSplatV2, which achieves high-dimensional\nfeature splatting at 476.2 FPS and 3D open-vocabulary text querying at 384.6\nFPS for high-resolution images, providing a 42 $\\times$ speedup and a 47\n$\\times$ boost over LangSplat respectively, along with improved query accuracy.\nLangSplat employs Gaussian Splatting to embed 2D CLIP language features into\n3D, significantly enhancing speed and learning a precise 3D language field with\nSAM semantics. Such advancements in 3D language fields are crucial for\napplications that require language interaction within complex scenes. However,\nLangSplat does not yet achieve real-time inference performance (8.2 FPS), even\nwith advanced A100 GPUs, severely limiting its broader application. In this\npaper, we first conduct a detailed time analysis of LangSplat, identifying the\nheavyweight decoder as the primary speed bottleneck. Our solution, LangSplatV2\nassumes that each Gaussian acts as a sparse code within a global dictionary,\nleading to the learning of a 3D sparse coefficient field that entirely\neliminates the need for a heavyweight decoder. By leveraging this sparsity, we\nfurther propose an efficient sparse coefficient splatting method with CUDA\noptimization, rendering high-dimensional feature maps at high quality while\nincurring only the time cost of splatting an ultra-low-dimensional feature. Our\nexperimental results demonstrate that LangSplatV2 not only achieves better or\ncompetitive query accuracy but is also significantly faster. Codes and demos\nare available at our project page: https://langsplat-v2.github.io.",
    "published": "2025-07-09T00:19:58Z",
    "updated": "2025-10-08T03:25:34Z",
    "link": "http://arxiv.org/pdf/2507.07136v2.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Wanhua Li",
      "Yujie Zhao",
      "Minghan Qin",
      "Yang Liu",
      "Yuanhao Cai",
      "Chuang Gan",
      "Hanspeter Pfister"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.13306v3",
    "title": "Temporally Smooth Mesh Extraction for Procedural Scenes with Long-Range\n  Camera Trajectories using Spacetime Octrees",
    "summary": "The procedural occupancy function is a flexible and compact representation\nfor creating 3D scenes. For rasterization and other tasks, it is often\nnecessary to extract a mesh that represents the shape. Unbounded scenes with\nlong-range camera trajectories, such as flying through a forest, pose a unique\nchallenge for mesh extraction. A single static mesh representing all the\ngeometric detail necessary for the full camera path can be prohibitively large.\nTherefore, independent meshes can be extracted for different camera views, but\nthis approach may lead to popping artifacts during transitions. We propose a\ntemporally coherent method for extracting meshes suitable for long-range camera\ntrajectories in unbounded scenes represented by an occupancy function. The key\nidea is to perform 4D mesh extraction using a new spacetime tree structure\ncalled a binary-octree. Experiments show that, compared to existing baseline\nmethods, our method offers superior visual consistency at a comparable cost.\nThe code and the supplementary video for this paper are available at\nhttps://github.com/princeton-vl/BinocMesher.",
    "published": "2025-09-16T17:57:04Z",
    "updated": "2025-10-07T20:46:16Z",
    "link": "http://arxiv.org/pdf/2509.13306v3.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Zeyu Ma",
      "Adam Finkelstein",
      "Jia Deng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07197v1",
    "title": "COMPAct: Computational Optimization and Automated Modular design of\n  Planetary Actuators",
    "summary": "The optimal design of robotic actuators is a critical area of research, yet\nlimited attention has been given to optimizing gearbox parameters and\nautomating actuator CAD. This paper introduces COMPAct: Computational\nOptimization and Automated Modular Design of Planetary Actuators, a framework\nthat systematically identifies optimal gearbox parameters for a given motor\nacross four gearbox types, single-stage planetary gearbox (SSPG), compound\nplanetary gearbox (CPG), Wolfrom planetary gearbox (WPG), and double-stage\nplanetary gearbox (DSPG). The framework minimizes mass and actuator width while\nmaximizing efficiency, and further automates actuator CAD generation to enable\ndirect 3D printing without manual redesign. Using this framework, optimal\ngearbox designs are explored over a wide range of gear ratios, providing\ninsights into the suitability of different gearbox types across various gear\nratio ranges. In addition, the framework is used to generate CAD models of all\nfour gearbox types with varying gear ratios and motors. Two actuator types are\nfabricated and experimentally evaluated through power efficiency, no-load\nbacklash, and transmission stiffness tests. Experimental results indicate that\nthe SSPG actuator achieves a mechanical efficiency of 60-80 %, a no-load\nbacklash of 0.59 deg, and a transmission stiffness of 242.7 Nm/rad, while the\nCPG actuator demonstrates 60 % efficiency, 2.6 deg backlash, and a stiffness of\n201.6 Nm/rad. Code available at:\nhttps://anonymous.4open.science/r/COMPAct-SubNum-3408 Video:\nhttps://youtu.be/99zOKgxsDho",
    "published": "2025-10-08T16:28:51Z",
    "updated": "2025-10-08T16:28:51Z",
    "link": "http://arxiv.org/pdf/2510.07197v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Aman Singh",
      "Deepak Kapa",
      "Suryank Joshi",
      "Shishir Kolathaya"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2403.16275v3",
    "title": "M^3RS: Multi-robot, Multi-objective, and Multi-mode Routing and\n  Scheduling",
    "summary": "Task execution quality significantly impacts multi-robot missions, yet\nexisting task allocation frameworks rarely consider quality of service as a\ndecision variable, despite its importance in applications like robotic\ndisinfection and cleaning. We introduce the multi-robot, multi-objective, and\nmulti-mode routing and scheduling (M3RS) problem, designed for time-constrained\nmissions. In M3RS, each task offers multiple execution modes with varying\nresource needs, durations, and quality levels, allowing trade-offs across\nmission objectives. M3RS is modeled as a mixed-integer linear programming (MIP)\nproblem and optimizes task sequencing and execution modes for each agent. We\napply M3RS to multi-robot disinfection in healthcare and public spaces,\noptimizing disinfection quality and task completion rates. Through synthetic\ncase studies, M3RS demonstrates 3-46$\\%$ performance improvements over the\nstandard task allocation method across various metrics. Further, to improve\ncompute time, we propose a clustering-based column generation algorithm that\nachieves solutions comparable to or better than the baseline MIP solver while\nreducing computation time by 60$\\%$. We also conduct case studies with\nsimulated and real robots. Experimental videos are available on the project\npage:\n\\href{https://sites.google.com/view/g-robot/m3rs/}{https://sites.google.com/view/g-robot/m3rs/}.",
    "published": "2024-03-24T19:47:37Z",
    "updated": "2025-10-08T16:08:40Z",
    "link": "http://arxiv.org/pdf/2403.16275v3.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Ishaan Mehta",
      "Junseo Kim",
      "Sharareh Taghipour",
      "Sajad Saeedi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07160v1",
    "title": "A Narwhal-Inspired Sensing-to-Control Framework for Small Fixed-Wing\n  Aircraft",
    "summary": "Fixed-wing unmanned aerial vehicles (UAVs) offer endurance and efficiency but\nlack low-speed agility due to highly coupled dynamics. We present an end-to-end\nsensing-to-control pipeline that combines bio-inspired hardware,\nphysics-informed dynamics learning, and convex control allocation. Measuring\nairflow on a small airframe is difficult because near-body aerodynamics,\npropeller slipstream, control-surface actuation, and ambient gusts distort\npressure signals. Inspired by the narwhal's protruding tusk, we mount in-house\nmulti-hole probes far upstream and complement them with sparse, carefully\nplaced wing pressure sensors for local flow measurement. A data-driven\ncalibration maps probe pressures to airspeed and flow angles. We then learn a\ncontrol-affine dynamics model using the estimated airspeed/angles and sparse\nsensors. A soft left/right symmetry regularizer improves identifiability under\npartial observability and limits confounding between wing pressures and\nflaperon inputs. Desired wrenches (forces and moments) are realized by a\nregularized least-squares allocator that yields smooth, trimmed actuation.\nWind-tunnel studies across a wide operating range show that adding wing\npressures reduces force-estimation error by 25-30%, the proposed model degrades\nless under distribution shift (about 12% versus 44% for an unstructured\nbaseline), and force tracking improves with smoother inputs, including a 27%\nreduction in normal-force RMSE versus a plain affine model and 34% versus an\nunstructured baseline.",
    "published": "2025-10-08T15:58:17Z",
    "updated": "2025-10-08T15:58:17Z",
    "link": "http://arxiv.org/pdf/2510.07160v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Fengze Xie",
      "Xiaozhou Fan",
      "Jacob Schuster",
      "Yisong Yue",
      "Morteza Gharib"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07152v1",
    "title": "DPL: Depth-only Perceptive Humanoid Locomotion via Realistic Depth\n  Synthesis and Cross-Attention Terrain Reconstruction",
    "summary": "Recent advancements in legged robot perceptive locomotion have shown\npromising progress. However, terrain-aware humanoid locomotion remains largely\nconstrained to two paradigms: depth image-based end-to-end learning and\nelevation map-based methods. The former suffers from limited training\nefficiency and a significant sim-to-real gap in depth perception, while the\nlatter depends heavily on multiple vision sensors and localization systems,\nresulting in latency and reduced robustness. To overcome these challenges, we\npropose a novel framework that tightly integrates three key components: (1)\nTerrain-Aware Locomotion Policy with a Blind Backbone, which leverages\npre-trained elevation map-based perception to guide reinforcement learning with\nminimal visual input; (2) Multi-Modality Cross-Attention Transformer, which\nreconstructs structured terrain representations from noisy depth images; (3)\nRealistic Depth Images Synthetic Method, which employs self-occlusion-aware ray\ncasting and noise-aware modeling to synthesize realistic depth observations,\nachieving over 30\\% reduction in terrain reconstruction error. This combination\nenables efficient policy training with limited data and hardware resources,\nwhile preserving critical terrain features essential for generalization. We\nvalidate our framework on a full-sized humanoid robot, demonstrating agile and\nadaptive locomotion across diverse and challenging terrains.",
    "published": "2025-10-08T15:51:36Z",
    "updated": "2025-10-08T15:51:36Z",
    "link": "http://arxiv.org/pdf/2510.07152v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Jingkai Sun",
      "Gang Han",
      "Pihai Sun",
      "Wen Zhao",
      "Jiahang Cao",
      "Jiaxu Wang",
      "Yijie Guo",
      "Qiang Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.13972v2",
    "title": "BIM Informed Visual SLAM for Construction Monitoring",
    "summary": "Simultaneous Localization and Mapping (SLAM) is a key tool for monitoring\nconstruction sites, where aligning the evolving as-built state with the\nas-planned design enables early error detection and reduces costly rework.\nLiDAR-based SLAM achieves high geometric precision, but its sensors are\ntypically large and power-demanding, limiting their use on portable platforms.\nVisual SLAM offers a practical alternative with lightweight cameras already\nembedded in most mobile devices. however, visually mapping construction\nenvironments remains challenging: repetitive layouts, occlusions, and\nincomplete or low-texture structures often cause drift in the trajectory map.\nTo mitigate this, we propose an RGB-D SLAM system that incorporates the\nBuilding Information Model (BIM) as structural prior knowledge. Instead of\nrelying solely on visual cues, our system continuously establishes\ncorrespondences between detected wall and their BIM counterparts, which are\nthen introduced as constraints in the back-end optimization. The proposed\nmethod operates in real time and has been validated on real construction sites,\nreducing trajectory error by an average of 23.71% and map RMSE by 7.14%\ncompared to visual SLAM baselines. These results demonstrate that BIM\nconstraints enable reliable alignment of the digital plan with the as-built\nscene, even under partially constructed conditions.",
    "published": "2025-09-17T13:45:06Z",
    "updated": "2025-10-08T15:43:42Z",
    "link": "http://arxiv.org/pdf/2509.13972v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Asier Bikandi-Noya",
      "Miguel Fernandez-Cortizas",
      "Muhammad Shaheer",
      "Ali Tourani",
      "Holger Voos",
      "Jose Luis Sanchez-Lopez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.02152v2",
    "title": "Interleave-VLA: Enhancing Robot Manipulation with Interleaved Image-Text\n  Instructions",
    "summary": "The rise of foundation models paves the way for generalist robot policies in\nthe physical world. Existing methods relying on text-only instructions often\nstruggle to generalize to unseen scenarios. We argue that interleaved\nimage-text inputs offer richer and less biased context and enable robots to\nbetter handle unseen tasks with more versatile human-robot interaction.\nBuilding on this insight, Interleave-VLA, the first robot learning paradigm\ncapable of comprehending interleaved image-text instructions and directly\ngenerating continuous action sequences in the physical world, is introduced. It\noffers a natural, flexible, and model-agnostic paradigm that extends\nstate-of-the-art vision-language-action (VLA) models with minimal modifications\nwhile achieving strong zero-shot generalization. Interleave-VLA also includes\nan automatic pipeline that converts text instructions from Open X-Embodiment\ninto interleaved image-text instructions, resulting in a large-scale real-world\ninterleaved embodied dataset with 210k episodes. Comprehensive evaluation in\nsimulation and the real world shows that Interleave-VLA offers two major\nbenefits: (1) improves out-of-domain generalization to unseen objects by 2x\ncompared to text input baselines, (2) supports flexible task interfaces and\ndiverse instructions in a zero-shot manner, such as hand-drawn sketches. We\nattribute Interleave-VLA's strong zero-shot capability to the use of\ninstruction images, which effectively mitigate hallucinations, and the\ninclusion of heterogeneous multimodal datasets, enriched with Internet-sourced\nimages, offering potential for scalability. More information is available at\nhttps://interleave-vla.github.io/Interleave-VLA-Anonymous/",
    "published": "2025-05-04T15:25:23Z",
    "updated": "2025-10-08T15:41:50Z",
    "link": "http://arxiv.org/pdf/2505.02152v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Cunxin Fan",
      "Xiaosong Jia",
      "Yihang Sun",
      "Yixiao Wang",
      "Jianglan Wei",
      "Ziyang Gong",
      "Xiangyu Zhao",
      "Masayoshi Tomizuka",
      "Xue Yang",
      "Junchi Yan",
      "Mingyu Ding"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07094v1",
    "title": "Sampling Strategies for Robust Universal Quadrupedal Locomotion Policies",
    "summary": "This work focuses on sampling strategies of configuration variations for\ngenerating robust universal locomotion policies for quadrupedal robots. We\ninvestigate the effects of sampling physical robot parameters and joint\nproportional-derivative gains to enable training a single reinforcement\nlearning policy that generalizes to multiple parameter configurations. Three\nfundamental joint gain sampling strategies are compared: parameter sampling\nwith (1) linear and polynomial function mappings of mass-to-gains, (2)\nperformance-based adaptive filtering, and (3) uniform random sampling. We\nimprove the robustness of the policy by biasing the configurations using\nnominal priors and reference models. All training was conducted on RaiSim,\ntested in simulation on a range of diverse quadrupeds, and zero-shot deployed\nonto hardware using the ANYmal quadruped robot. Compared to multiple baseline\nimplementations, our results demonstrate the need for significant joint\ncontroller gains randomization for robust closing of the sim-to-real gap.",
    "published": "2025-10-08T14:51:42Z",
    "updated": "2025-10-08T14:51:42Z",
    "link": "http://arxiv.org/pdf/2510.07094v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "David Rytz",
      "Kim Tien Ly",
      "Ioannis Havoutis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07067v1",
    "title": "Bring the Apple, Not the Sofa: Impact of Irrelevant Context in Embodied\n  AI Commands on VLA Models",
    "summary": "Vision Language Action (VLA) models are widely used in Embodied AI, enabling\nrobots to interpret and execute language instructions. However, their\nrobustness to natural language variability in real-world scenarios has not been\nthoroughly investigated. In this work, we present a novel systematic study of\nthe robustness of state-of-the-art VLA models under linguistic perturbations.\nSpecifically, we evaluate model performance under two types of instruction\nnoise: (1) human-generated paraphrasing and (2) the addition of irrelevant\ncontext. We further categorize irrelevant contexts into two groups according to\ntheir length and their semantic and lexical proximity to robot commands. In\nthis study, we observe consistent performance degradation as context size\nexpands. We also demonstrate that the model can exhibit relative robustness to\nrandom context, with a performance drop within 10%, while semantically and\nlexically similar context of the same length can trigger a quality decline of\naround 50%. Human paraphrases of instructions lead to a drop of nearly 20%. To\nmitigate this, we propose an LLM-based filtering framework that extracts core\ncommands from noisy inputs. Incorporating our filtering step allows models to\nrecover up to 98.5% of their original performance under noisy conditions.",
    "published": "2025-10-08T14:31:35Z",
    "updated": "2025-10-08T14:31:35Z",
    "link": "http://arxiv.org/pdf/2510.07067v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Daria Pugacheva",
      "Andrey Moskalenko",
      "Denis Shepelev",
      "Andrey Kuznetsov",
      "Vlad Shakhuro",
      "Elena Tutubalina"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07063v1",
    "title": "Artists' Views on Robotics Involvement in Painting Productions",
    "summary": "As robotic technologies evolve, their potential in artistic creation becomes\nan increasingly relevant topic of inquiry. This study explores how professional\nabstract artists perceive and experience co-creative interactions with an\nautonomous painting robotic arm. Eight artists engaged in six painting sessions\n-- three with a human partner, followed by three with the robot -- and\nsubsequently participated in semi-structured interviews analyzed through\nreflexive thematic analysis. Human-human interactions were described as\nintuitive, dialogic, and emotionally engaging, whereas human-robot sessions\nfelt more playful and reflective, offering greater autonomy and prompting for\nnovel strategies to overcome the system's limitations. This work offers one of\nthe first empirical investigations into artists' lived experiences with a\nrobot, highlighting the value of long-term engagement and a multidisciplinary\napproach to human-robot co-creation.",
    "published": "2025-10-08T14:28:30Z",
    "updated": "2025-10-08T14:28:30Z",
    "link": "http://arxiv.org/pdf/2510.07063v1.pdf",
    "category": [
      "cs.HC",
      "cs.RO"
    ],
    "authors": [
      "Francesca Cocchella",
      "Nilay Roy Choudhury",
      "Eric Chen",
      "Patrícia Alves-Oliveira"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.10040v2",
    "title": "Diffusion Trajectory-guided Policy for Long-horizon Robot Manipulation",
    "summary": "Recently, Vision-Language-Action models (VLA) have advanced robot imitation\nlearning, but high data collection costs and limited demonstrations hinder\ngeneralization and current imitation learning methods struggle in\nout-of-distribution scenarios, especially for long-horizon tasks. A key\nchallenge is how to mitigate compounding errors in imitation learning, which\nlead to cascading failures over extended trajectories. To address these\nchallenges, we propose the Diffusion Trajectory-guided Policy (DTP) framework,\nwhich generates 2D trajectories through a diffusion model to guide policy\nlearning for long-horizon tasks. By leveraging task-relevant trajectories, DTP\nprovides trajectory-level guidance to reduce error accumulation. Our two-stage\napproach first trains a generative vision-language model to create\ndiffusion-based trajectories, then refines the imitation policy using them.\nExperiments on the CALVIN benchmark show that DTP outperforms state-of-the-art\nbaselines by 25% in success rate, starting from scratch without external\npretraining. Moreover, DTP significantly improves real-world robot performance.",
    "published": "2025-02-14T09:38:15Z",
    "updated": "2025-10-08T14:17:08Z",
    "link": "http://arxiv.org/pdf/2502.10040v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Shichao Fan",
      "Quantao Yang",
      "Yajie Liu",
      "Kun Wu",
      "Zhengping Che",
      "Qingjie Liu",
      "Min Wan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07030v1",
    "title": "Diffusing Trajectory Optimization Problems for Recovery During\n  Multi-Finger Manipulation",
    "summary": "Multi-fingered hands are emerging as powerful platforms for performing fine\nmanipulation tasks, including tool use. However, environmental perturbations or\nexecution errors can impede task performance, motivating the use of recovery\nbehaviors that enable normal task execution to resume. In this work, we take\nadvantage of recent advances in diffusion models to construct a framework that\nautonomously identifies when recovery is necessary and optimizes contact-rich\ntrajectories to recover. We use a diffusion model trained on the task to\nestimate when states are not conducive to task execution, framed as an\nout-of-distribution detection problem. We then use diffusion sampling to\nproject these states in-distribution and use trajectory optimization to plan\ncontact-rich recovery trajectories. We also propose a novel diffusion-based\napproach that distills this process to efficiently diffuse the full\nparameterization, including constraints, goal state, and initialization, of the\nrecovery trajectory optimization problem, saving time during online execution.\nWe compare our method to a reinforcement learning baseline and other methods\nthat do not explicitly plan contact interactions, including on a hardware\nscrewdriver-turning task where we show that recovering using our method\nimproves task performance by 96% and that ours is the only method evaluated\nthat can attempt recovery without causing catastrophic task failure. Videos can\nbe found at https://dtourrecovery.github.io/.",
    "published": "2025-10-08T13:58:31Z",
    "updated": "2025-10-08T13:58:31Z",
    "link": "http://arxiv.org/pdf/2510.07030v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Abhinav Kumar",
      "Fan Yang",
      "Sergio Aguilera Marinovic",
      "Soshi Iba",
      "Rana Soltani Zarrin",
      "Dmitry Berenson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07028v1",
    "title": "Temporal-Prior-Guided View Planning for Periodic 3D Plant Reconstruction",
    "summary": "Periodic 3D reconstruction is essential for crop monitoring, but costly when\neach cycle restarts from scratch, wasting resources and ignoring information\nfrom previous captures. We propose temporal-prior-guided view planning for\nperiodic plant reconstruction, in which a previously reconstructed model of the\nsame plant is non-rigidly aligned to a new partial observation to form an\napproximation of the current geometry. To accommodate plant growth, we inflate\nthis approximation and solve a set covering optimization problem to compute a\nminimal set of views. We integrated this method into a complete pipeline that\nacquires one additional next-best view before registration for robustness and\nthen plans a globally shortest path to connect the planned set of views and\noutputs the best view sequence. Experiments on maize and tomato under\nhemisphere and sphere view spaces show that our system maintains or improves\nsurface coverage while requiring fewer views and comparable movement cost\ncompared to state-of-the-art baselines.",
    "published": "2025-10-08T13:57:29Z",
    "updated": "2025-10-08T13:57:29Z",
    "link": "http://arxiv.org/pdf/2510.07028v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Sicong Pan",
      "Xuying Huang",
      "Maren Bennewitz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07027v1",
    "title": "Tailoring materials into kirigami robots",
    "summary": "Kirigami, the traditional paper-cutting craft, holds immense potential for\nrevolutionizing robotics by providing multifunctional, lightweight, and\nadaptable solutions. Kirigami structures, characterized by their\nbending-dominated deformation, offer resilience to tensile forces and\nfacilitate shape morphing under small actuation forces. Kirigami components\nsuch as actuators, sensors, batteries, controllers, and body structures can be\ntailored to specific robotic applications by optimizing cut patterns. Actuators\nbased on kirigami principles exhibit complex motions programmable through\nvarious energy sources, while kirigami sensors bridge the gap between\nelectrical conductivity and compliance. Kirigami-integrated batteries enable\nenergy storage directly within robot structures, enhancing flexibility and\ncompactness. Kirigami-controlled mechanisms mimic mechanical computations,\nenabling advanced functionalities such as shape morphing and memory functions.\nApplications of kirigami-enabled robots include grasping, locomotion, and\nwearables, showcasing their adaptability to diverse environments and tasks.\nDespite promising opportunities, challenges remain in the design of cut\npatterns for a given function and streamlining fabrication techniques.",
    "published": "2025-10-08T13:56:29Z",
    "updated": "2025-10-08T13:56:29Z",
    "link": "http://arxiv.org/pdf/2510.07027v1.pdf",
    "category": [
      "cs.RO",
      "cond-mat.soft"
    ],
    "authors": [
      "Saravana Prashanth Murali Babu",
      "Aida Parvaresh",
      "Ahmad Rafsanjani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.07839v2",
    "title": "Touch Speaks, Sound Feels: A Multimodal Approach to Affective and Social\n  Touch from Robots to Humans",
    "summary": "Affective tactile interaction constitutes a fundamental component of human\ncommunication. In natural human-human encounters, touch is seldom experienced\nin isolation; rather, it is inherently multisensory. Individuals not only\nperceive the physical sensation of touch but also register the accompanying\nauditory cues generated through contact. The integration of haptic and auditory\ninformation forms a rich and nuanced channel for emotional expression. While\nextensive research has examined how robots convey emotions through facial\nexpressions and speech, their capacity to communicate social gestures and\nemotions via touch remains largely underexplored. To address this gap, we\ndeveloped a multimodal interaction system incorporating a 5*5 grid of 25\nvibration motors synchronized with audio playback, enabling robots to deliver\ncombined haptic-audio stimuli. In an experiment involving 32 Chinese\nparticipants, ten emotions and six social gestures were presented through\nvibration, sound, or their combination. Participants rated each stimulus on\narousal and valence scales. The results revealed that (1) the combined\nhaptic-audio modality significantly enhanced decoding accuracy compared to\nsingle modalities; (2) each individual channel-vibration or sound-effectively\nsupported certain emotions recognition, with distinct advantages depending on\nthe emotional expression; and (3) gestures alone were generally insufficient\nfor conveying clearly distinguishable emotions. These findings underscore the\nimportance of multisensory integration in affective human-robot interaction and\nhighlight the complementary roles of haptic and auditory cues in enhancing\nemotional communication.",
    "published": "2025-08-11T10:45:43Z",
    "updated": "2025-10-08T13:39:36Z",
    "link": "http://arxiv.org/pdf/2508.07839v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Qiaoqiao Ren",
      "Tony Belpaeme"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.13832v2",
    "title": "UltraHiT: A Hierarchical Transformer Architecture for Generalizable\n  Internal Carotid Artery Robotic Ultrasonography",
    "summary": "Carotid ultrasound is crucial for the assessment of cerebrovascular health,\nparticularly the internal carotid artery (ICA). While previous research has\nexplored automating carotid ultrasound, none has tackled the challenging ICA.\nThis is primarily due to its deep location, tortuous course, and significant\nindividual variations, which greatly increase scanning complexity. To address\nthis, we propose a Hierarchical Transformer-based decision architecture, namely\nUltraHiT, that integrates high-level variation assessment with low-level action\ndecision. Our motivation stems from conceptualizing individual vascular\nstructures as morphological variations derived from a standard vascular model.\nThe high-level module identifies variation and switches between two low-level\nmodules: an adaptive corrector for variations, or a standard executor for\nnormal cases. Specifically, both the high-level module and the adaptive\ncorrector are implemented as causal transformers that generate predictions\nbased on the historical scanning sequence. To ensure generalizability, we\ncollected the first large-scale ICA scanning dataset comprising 164\ntrajectories and 72K samples from 28 subjects of both genders. Based on the\nabove innovations, our approach achieves a 95% success rate in locating the ICA\non unseen individuals, outperforming baselines and demonstrating its\neffectiveness. Our code will be released after acceptance.",
    "published": "2025-09-17T08:57:56Z",
    "updated": "2025-10-08T12:18:13Z",
    "link": "http://arxiv.org/pdf/2509.13832v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Teng Wang",
      "Haojun Jiang",
      "Yuxuan Wang",
      "Zhenguo Sun",
      "Xiangjie Yan",
      "Xiang Li",
      "Gao Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.15915v3",
    "title": "Development of a magnetorheological hand exoskeleton featuring a high\n  force-to-power ratio for enhanced grip endurance",
    "summary": "Hand exoskeletons have significant potential in labor-intensive fields by\nmitigating hand grip fatigue, enhancing hand strength, and preventing injuries.\nHowever, most of the traditional hand exoskeletons are driven by motors, whose\noutput force is limited in the constrained installation conditions. Besides,\nthey also come with the disadvantages of high power consumption, complex and\nbulky assistive systems, and high instability. In this work, we develop a novel\nhand exoskeleton integrated with innovative magnetorheological (MR) clutches\nthat offers a high force-to-power ratio to improve grip endurance. The clutch\nfeatures an enhanced structure design, a micro roller enhancing structure,\nwhich can significantly boost output forces. The experimental data demonstrate\nthat, when it is supplied with 2 V, the clutch can deliver a peak holding force\nof 381.15 N-55 times that when no voltage is provided (7 N). In this scenario,\nit only consumes 1.38 W, yielding a force-to-power ratio of 256.75N/W, which is\n2.35 times higher than the best-reported actuator used for hand exoskeletons.\nThis capability enables the designed MRHE to provide approximately 419.79 N\nsupport force for gripping. The designed MR hand exoskeleton is highly\nintegrated, comprising an exoskeleton frame, MR clutches, a control unit, and a\nbattery. Evaluations through static grip endurance tests and dynamic carrying\nand lifting tests confirm that the MR hand exoskeleton can effectively reduce\nmuscle fatigue, extend grip endurance, and minimize injuries. These findings\nhighlight its strong potential for practical applications in repetitive tasks\nsuch as carrying and lifting in industrial settings.",
    "published": "2025-03-20T07:46:04Z",
    "updated": "2025-10-08T11:30:38Z",
    "link": "http://arxiv.org/pdf/2503.15915v3.pdf",
    "category": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "authors": [
      "Wenbo Li",
      "Xianlong Mai",
      "Ying Li",
      "Weihua Li",
      "Shiwu Zhang",
      "Lei Deng",
      "Shuaishuai Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06836v1",
    "title": "Distributed 3D Source Seeking via SO(3) Geometric Control of Robot\n  Swarms",
    "summary": "This paper presents a geometric control framework on the Lie group SO(3) for\n3D source-seeking by robots with first-order attitude dynamics and constant\ntranslational speed. By working directly on SO(3), the approach avoids\nEuler-angle singularities and quaternion ambiguities, providing a unique,\nintrinsic representation of orientation. We design a proportional feed-forward\ncontroller that ensures exponential alignment of each agent to an estimated\nascending direction toward a 3D scalar field source. The controller adapts to\nbounded unknown variations and preserves well-posed swarm formations. Numerical\nsimulations demonstrate the effectiveness of the method, with all code provided\nopen source for reproducibility.",
    "published": "2025-10-08T09:58:48Z",
    "updated": "2025-10-08T09:58:48Z",
    "link": "http://arxiv.org/pdf/2510.06836v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Jesús Bautista",
      "Héctor García de Marina"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2409.10878v4",
    "title": "P2 Explore: Efficient Exploration in Unknown Cluttered Environment with\n  Floor Plan Prediction",
    "summary": "Robot exploration aims at the reconstruction of unknown environments, and it\nis important to achieve it with shorter paths. Traditional methods focus on\noptimizing the visiting order of frontiers based on current observations, which\nmay lead to local-minimal results. Recently, by predicting the structure of the\nunseen environment, the exploration efficiency can be further improved.\nHowever, in a cluttered environment, due to the randomness of obstacles, the\nability to predict is weak. Moreover, this inaccuracy will lead to limited\nimprovement in exploration. Therefore, we propose FPUNet which can be efficient\nin predicting the layout of noisy indoor environments. Then, we extract the\nsegmentation of rooms and construct their topological connectivity based on the\npredicted map. The visiting order of these predicted rooms is optimized which\ncan provide high-level guidance for exploration. The FPUNet is compared with\nother network architectures which demonstrates it is the SOTA method for this\ntask. Extensive experiments in simulations show that our method can shorten the\npath length by 2.18% to 34.60% compared to the baselines.",
    "published": "2024-09-17T04:16:29Z",
    "updated": "2025-10-08T09:27:21Z",
    "link": "http://arxiv.org/pdf/2409.10878v4.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Kun Song",
      "Gaoming Chen",
      "Masayoshi Tomizuka",
      "Wei Zhan",
      "Zhenhua Xiong",
      "Mingyu Ding"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.22459v2",
    "title": "Control of Humanoid Robots with Parallel Mechanisms using Differential\n  Actuation Models",
    "summary": "Several recently released humanoid robots, inspired by the mechanical design\nof Cassie, employ actuator configurations in which the motors are displaced\nfrom the joints to reduce leg inertia. While studies accounting for the full\nkinematic complexity have demonstrated the benefits of these designs, the\nassociated loop-closure constraints greatly increase computational cost and\nlimit their use in control and learning. As a result, the non-linear\ntransmission is often approximated by a constant reduction ratio, preventing\nexploitation of the mechanism's full capabilities. This paper introduces a\ncompact analytical formulation for the two standard knee and ankle mechanisms\nthat captures the exact non-linear transmission while remaining computationally\nefficient. The model is fully differentiable up to second order with a minimal\nformulation, enabling low-cost evaluation of dynamic derivatives for trajectory\noptimization and of the apparent transmission impedance for reinforcement\nlearning. We integrate this formulation into trajectory optimization and\nlocomotion policy learning, and compare it against simplified constant-ratio\napproaches. Hardware experiments demonstrate improved accuracy and robustness,\nshowing that the proposed method provides a practical means to incorporate\nparallel actuation into modern control algorithms.",
    "published": "2025-03-28T14:13:00Z",
    "updated": "2025-10-08T07:46:30Z",
    "link": "http://arxiv.org/pdf/2503.22459v2.pdf",
    "category": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "authors": [
      "Victor Lutz",
      "Ludovic de Matteis",
      "Virgile Batto",
      "Nicolas Mansard"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06717v1",
    "title": "SanDRA: Safe Large-Language-Model-Based Decision Making for Automated\n  Vehicles Using Reachability Analysis",
    "summary": "Large language models have been widely applied to knowledge-driven\ndecision-making for automated vehicles due to their strong generalization and\nreasoning capabilities. However, the safety of the resulting decisions cannot\nbe ensured due to possible hallucinations and the lack of integrated vehicle\ndynamics. To address this issue, we propose SanDRA, the first safe\nlarge-language-model-based decision making framework for automated vehicles\nusing reachability analysis. Our approach starts with a comprehensive\ndescription of the driving scenario to prompt large language models to generate\nand rank feasible driving actions. These actions are translated into temporal\nlogic formulas that incorporate formalized traffic rules, and are subsequently\nintegrated into reachability analysis to eliminate unsafe actions. We validate\nour approach in both open-loop and closed-loop driving environments using\noff-the-shelf and finetuned large language models, showing that it can provide\nprovably safe and, where possible, legally compliant driving actions, even\nunder high-density traffic conditions. To ensure transparency and facilitate\nfuture research, all code and experimental setups are publicly available at\ngithub.com/CommonRoad/SanDRA.",
    "published": "2025-10-08T07:13:18Z",
    "updated": "2025-10-08T07:13:18Z",
    "link": "http://arxiv.org/pdf/2510.06717v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Yuanfei Lin",
      "Sebastian Illing",
      "Matthias Althoff"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06710v1",
    "title": "RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training",
    "summary": "Recent progress in vision and language foundation models has significantly\nadvanced multimodal understanding, reasoning, and generation, inspiring a surge\nof interest in extending such capabilities to embodied settings through\nvision-language-action (VLA) models. Yet, most VLA models are still trained\nwith supervised fine-tuning (SFT), which struggles to generalize under\ndistribution shifts due to error accumulation. Reinforcement learning (RL)\noffers a promising alternative by directly optimizing task performance through\ninteraction, but existing attempts remain fragmented and lack a unified\nplatform for fair and systematic comparison across model architectures and\nalgorithmic designs. To address this gap, we introduce RLinf-VLA, a unified and\nefficient framework for scalable RL training of VLA models. The system adopts a\nhighly flexible resource allocation design that addresses the challenge of\nintegrating rendering, training, and inference in RL+VLA training. In\nparticular, for GPU-parallelized simulators, RLinf-VLA implements a novel\nhybrid fine-grained pipeline allocation mode, achieving a 1.61x-1.88x speedup\nin training. Through a unified interface, RLinf-VLA seamlessly supports diverse\nVLA architectures (e.g., OpenVLA, OpenVLA-OFT), multiple RL algorithms (e.g.,\nPPO, GRPO), and various simulators (e.g., ManiSkill, LIBERO). In simulation, a\nunified model achieves 98.11\\% across 130 LIBERO tasks and 97.66\\% across 25\nManiSkill tasks. Beyond empirical performance, our study distills a set of best\npractices for applying RL to VLA training and sheds light on emerging patterns\nin this integration. Furthermore, we present preliminary deployment on a\nreal-world Franka robot, where RL-trained policies exhibit stronger\ngeneralization than those trained with SFT. We envision RLinf-VLA as a\nfoundation to accelerate and standardize research on embodied intelligence.",
    "published": "2025-10-08T07:05:13Z",
    "updated": "2025-10-08T07:05:13Z",
    "link": "http://arxiv.org/pdf/2510.06710v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Hongzhi Zang",
      "Mingjie Wei",
      "Si Xu",
      "Yongji Wu",
      "Zhen Guo",
      "Yuanqing Wang",
      "Hao Lin",
      "Liangzhi Shi",
      "Yuqing Xie",
      "Zhexuan Xu",
      "Zhihao Liu",
      "Kang Chen",
      "Wenhao Tang",
      "Quanlu Zhang",
      "Weinan Zhang",
      "Chao Yu",
      "Yu Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.11202v5",
    "title": "Online Hybrid-Belief POMDP with Coupled Semantic-Geometric Models",
    "summary": "Robots operating in complex and unknown environments frequently require\ngeometric-semantic representations of the environment to safely perform their\ntasks. While inferring the environment, they must account for many possible\nscenarios when planning future actions. Since objects' class types are discrete\nand the robot's self-pose and the objects' poses are continuous, the\nenvironment can be represented by a hybrid discrete-continuous belief which is\nupdated according to models and incoming data. Prior probabilities and\nobservation models representing the environment can be learned from data using\ndeep learning algorithms. Such models often couple environmental semantic and\ngeometric properties. As a result, semantic variables are interconnected,\ncausing semantic state space dimensionality to increase exponentially. In this\npaper, we consider planning under uncertainty using partially observable Markov\ndecision processes (POMDPs) with hybrid semantic-geometric beliefs. The models\nand priors consider the coupling between semantic and geometric variables.\nWithin POMDP, we introduce the concept of semantically aware safety. Obtaining\nrepresentative samples of the theoretical hybrid belief, required for\nestimating the value function, is very challenging. As a key contribution, we\ndevelop a novel form of the hybrid belief and leverage it to sample\nrepresentative samples. We show that under certain conditions, the value\nfunction and probability of safety can be calculated efficiently with an\nexplicit expectation over all possible semantic mappings. Our simulations show\nthat our estimates of the objective function and probability of safety achieve\nsimilar levels of accuracy compared to estimators that run exhaustively on the\nentire semantic state-space using samples from the theoretical hybrid belief.\nNevertheless, the complexity of our estimators is polynomial rather than\nexponential.",
    "published": "2025-01-20T00:22:44Z",
    "updated": "2025-10-08T06:56:07Z",
    "link": "http://arxiv.org/pdf/2501.11202v5.pdf",
    "category": [
      "cs.RO",
      "None"
    ],
    "authors": [
      "Tuvy Lemberg",
      "Vadim Indelman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06633v1",
    "title": "Assist-As-Needed: Adaptive Multimodal Robotic Assistance for Medication\n  Management in Dementia Care",
    "summary": "People living with dementia (PLWDs) face progressively declining abilities in\nmedication management-from simple forgetfulness to complete task breakdown-yet\nmost assistive technologies fail to adapt to these changing needs. This\none-size-fits-all approach undermines autonomy, accelerates dependence, and\nincreases caregiver burden. Occupational therapy principles emphasize matching\nassistance levels to individual capabilities: minimal reminders for those who\nmerely forget, spatial guidance for those who misplace items, and comprehensive\nmultimodal support for those requiring step-by-step instruction. However,\nexisting robotic systems lack this adaptive, graduated response framework\nessential for maintaining PLWD independence. We present an adaptive multimodal\nrobotic framework using the Pepper robot that dynamically adjusts assistance\nbased on real-time assessment of user needs. Our system implements a\nhierarchical intervention model progressing from (1) simple verbal reminders,\nto (2) verbal + gestural cues, to (3) full multimodal guidance combining\nphysical navigation to medication locations with step-by-step verbal and\ngestural instructions. Powered by LLM-driven interaction strategies and\nmultimodal sensing, the system continuously evaluates task states to provide\njust-enough assistance-preserving autonomy while ensuring medication adherence.\nWe conducted a preliminary study with healthy adults and dementia care\nstakeholders in a controlled lab setting, evaluating the system's usability,\ncomprehensibility, and appropriateness of adaptive feedback mechanisms. This\nwork contributes: (1) a theoretically grounded adaptive assistance framework\ntranslating occupational therapy principles into HRI design, (2) a multimodal\nrobotic implementation that preserves PLWD dignity through graduated support,\nand (3) empirical insights into stakeholder perceptions of adaptive robotic\ncare.",
    "published": "2025-10-08T04:34:43Z",
    "updated": "2025-10-08T04:34:43Z",
    "link": "http://arxiv.org/pdf/2510.06633v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Kruthika Gangaraju",
      "Tanmayi Inaparthy",
      "Jiaqi Yang",
      "Yihao Zheng",
      "Fengpei Yuan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06566v1",
    "title": "Safe Obstacle-Free Guidance of Space Manipulators in Debris Removal\n  Missions via Deep Reinforcement Learning",
    "summary": "The objective of this study is to develop a model-free workspace trajectory\nplanner for space manipulators using a Twin Delayed Deep Deterministic Policy\nGradient (TD3) agent to enable safe and reliable debris capture. A local\ncontrol strategy with singularity avoidance and manipulability enhancement is\nemployed to ensure stable execution. The manipulator must simultaneously track\na capture point on a non-cooperative target, avoid self-collisions, and prevent\nunintended contact with the target. To address these challenges, we propose a\ncurriculum-based multi-critic network where one critic emphasizes accurate\ntracking and the other enforces collision avoidance. A prioritized experience\nreplay buffer is also used to accelerate convergence and improve policy\nrobustness. The framework is evaluated on a simulated seven-degree-of-freedom\nKUKA LBR iiwa mounted on a free-floating base in Matlab/Simulink, demonstrating\nsafe and adaptive trajectory generation for debris removal missions.",
    "published": "2025-10-08T01:34:46Z",
    "updated": "2025-10-08T01:34:46Z",
    "link": "http://arxiv.org/pdf/2510.06566v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Vincent Lam",
      "Robin Chhabra"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.20635v2",
    "title": "Generating and Optimizing Topologically Distinct Guesses for Mobile\n  Manipulator Path Planning with Path Constraints",
    "summary": "Optimal path planning is prone to convergence to local, rather than global,\noptima. This is often the case for mobile manipulators due to nonconvexities\ninduced by obstacles, robot kinematics and constraints. This paper focuses on\nplanning under end effector path constraints and attempts to circumvent the\nissue of converging to a local optimum. We propose a pipeline that first\ndiscovers multiple homotopically distinct paths, and then optimizes them to\nobtain multiple distinct local optima. The best out of these distinct local\noptima is likely to be close to the global optimum. We demonstrate the\neffectiveness of our pipeline in the optimal path planning of mobile\nmanipulators in the presence of path and obstacle constraints.",
    "published": "2024-10-27T23:48:08Z",
    "updated": "2025-10-08T01:03:02Z",
    "link": "http://arxiv.org/pdf/2410.20635v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Rufus Cheuk Yin Wong",
      "Mayank Sewlia",
      "Adrian Wiltz",
      "Dimos V. Dimarogonas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06546v1",
    "title": "RAISE: A self-driving laboratory for interfacial property formulation\n  discovery",
    "summary": "Surface wettability is a critical design parameter for biomedical devices,\ncoatings, and textiles. Contact angle measurements quantify liquid-surface\ninteractions, which depend strongly on liquid formulation. Herein, we present\nthe Robotic Autonomous Imaging Surface Evaluator (RAISE), a closed-loop,\nself-driving laboratory that is capable of linking liquid formulation\noptimization with surface wettability assessment. RAISE comprises a full\nexperimental orchestrator with the ability of mixing liquid ingredients to\ncreate varying formulation cocktails, transferring droplets of prepared\nformulations to a high-throughput stage, and using a pick-and-place camera tool\nfor automated droplet image capture. The system also includes an automated\nimage processing pipeline to measure contact angles. This closed loop\nexperiment orchestrator is integrated with a Bayesian Optimization (BO) client,\nwhich enables iterative exploration of new formulations based on previous\ncontact angle measurements to meet user-defined objectives. The system operates\nin a high-throughput manner and can achieve a measurement rate of approximately\n1 contact angle measurement per minute. Here we demonstrate RAISE can be used\nto explore surfactant wettability and how surfactant combinations create\ntunable formulations that compensate for purity-related variations.\nFurthermore, multi-objective BO demonstrates how precise and optimal\nformulations can be reached based on application-specific goals. The\noptimization is guided by a desirability score, which prioritizes formulations\nthat are within target contact angle ranges, minimize surfactant usage and\nreduce cost. This work demonstrates the capabilities of RAISE to autonomously\nlink liquid formulations to contact angle measurements in a closed-loop system,\nusing multi-objective BO to efficiently identify optimal formulations aligned\nwith researcher-defined criteria.",
    "published": "2025-10-08T00:53:28Z",
    "updated": "2025-10-08T00:53:28Z",
    "link": "http://arxiv.org/pdf/2510.06546v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Mohammad Nazeri",
      "Sheldon Mei",
      "Jeffrey Watchorn",
      "Alex Zhang",
      "Erin Ng",
      "Tao Wen",
      "Abhijoy Mandal",
      "Kevin Golovin",
      "Alan Aspuru-Guzik",
      "Frank Gu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2409.10832v2",
    "title": "EffiTune: Diagnosing and Mitigating Training Inefficiency for Parameter\n  Tuner in Robot Navigation System",
    "summary": "Robot navigation systems are critical for various real-world applications\nsuch as delivery services, hospital logistics, and warehouse management.\nAlthough classical navigation methods provide interpretability, they rely\nheavily on expert manual tuning, limiting their adaptability. Conversely,\npurely learning-based methods offer adaptability but often lead to instability\nand erratic robot behaviors. Recently introduced parameter tuners aim to\nbalance these approaches by integrating data-driven adaptability into classical\nnavigation frameworks. However, the parameter tuning process currently suffers\nfrom training inefficiencies and redundant sampling, with critical regions in\nenvironment often underrepresented in training data. In this paper, we propose\nEffiTune, a novel framework designed to diagnose and mitigate training\ninefficiency for parameter tuners in robot navigation systems. EffiTune first\nperforms robot-behavior-guided diagnostics to pinpoint critical bottlenecks and\nunderrepresented regions. It then employs a targeted up-sampling strategy to\nenrich the training dataset with critical samples, significantly reducing\nredundancy and enhancing training efficiency. Our comprehensive evaluation\ndemonstrates that EffiTune achieves more than a 13.5% improvement in navigation\nperformance, enhanced robustness in out-of-distribution scenarios, and a 4x\nimprovement in training efficiency within the same computational budget.",
    "published": "2024-09-17T01:49:17Z",
    "updated": "2025-10-08T00:25:32Z",
    "link": "http://arxiv.org/pdf/2409.10832v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Shiwei Feng",
      "Xuan Chen",
      "Zikang Xiong",
      "Zhiyuan Cheng",
      "Yifei Gao",
      "Siyuan Cheng",
      "Sayali Kate",
      "Xiangyu Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06492v1",
    "title": "What You Don't Know Can Hurt You: How Well do Latent Safety Filters\n  Understand Partially Observable Safety Constraints?",
    "summary": "Safe control techniques, such as Hamilton-Jacobi reachability, provide\nprincipled methods for synthesizing safety-preserving robot policies but\ntypically assume hand-designed state spaces and full observability. Recent work\nhas relaxed these assumptions via latent-space safe control, where state\nrepresentations and dynamics are learned jointly through world models that\nreconstruct future high-dimensional observations (e.g., RGB images) from\ncurrent observations and actions. This enables safety constraints that are\ndifficult to specify analytically (e.g., spilling) to be framed as\nclassification problems in latent space, allowing controllers to operate\ndirectly from raw observations. However, these methods assume that\nsafety-critical features are observable in the learned latent state. We ask:\nwhen are latent state spaces sufficient for safe control? To study this, we\nexamine temperature-based failures, comparable to overheating in cooking or\nmanufacturing tasks, and find that RGB-only observations can produce myopic\nsafety behaviors, e.g., avoiding seeing failure states rather than preventing\nfailure itself. To predict such behaviors, we introduce a mutual\ninformation-based measure that identifies when observations fail to capture\nsafety-relevant features. Finally, we propose a multimodal-supervised training\nstrategy that shapes the latent state with additional sensory inputs during\ntraining, but requires no extra modalities at deployment, and validate our\napproach in simulation and on hardware with a Franka Research 3 manipulator\npreventing a pot of wax from overheating.",
    "published": "2025-10-07T22:09:42Z",
    "updated": "2025-10-07T22:09:42Z",
    "link": "http://arxiv.org/pdf/2510.06492v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Matthew Kim",
      "Kensuke Nakamura",
      "Andrea Bajcsy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06470v1",
    "title": "Terrain-Aided Navigation Using a Point Cloud Measurement Sensor",
    "summary": "We investigate the use of a point cloud measurement in terrain-aided\nnavigation. Our goal is to aid an inertial navigation system, by exploring ways\nto generate a useful measurement innovation error for effective nonlinear state\nestimation. We compare two such measurement models that involve the scanning of\na digital terrain elevation model: a) one that is based on typical ray-casting\nfrom a given pose, that returns the predicted point cloud measurement from that\npose, and b) another computationally less intensive one that does not require\nraycasting and we refer to herein as a sliding grid. Besides requiring a pose,\nit requires the pattern of the point cloud measurement itself and returns a\npredicted point cloud measurement. We further investigate the observability\nproperties of the altitude for both measurement models. As a baseline, we\ncompare the use of a point cloud measurement performance to the use of a radar\naltimeter and show the gains in accuracy. We conclude by showing that a point\ncloud measurement outperforms the use of a radar altimeter, and the point cloud\nmeasurement model to use depends on the computational resources",
    "published": "2025-10-07T21:13:20Z",
    "updated": "2025-10-07T21:13:20Z",
    "link": "http://arxiv.org/pdf/2510.06470v1.pdf",
    "category": [
      "eess.SY",
      "cs.RO",
      "cs.SY"
    ],
    "authors": [
      "Abdülbaki Şanlan",
      "Fatih Erol",
      "Murad Abu-Khalaf",
      "Emre Koyuncu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06394v1",
    "title": "Three-dimensional Integrated Guidance and Control for Leader-Follower\n  Flexible Formation of Fixed Wing UAVs",
    "summary": "This paper presents a nonlinear integrated guidance and control (IGC)\napproach for flexible leader-follower formation flight of fixed-wing unmanned\naerial vehicles (UAVs) while accounting for high-fidelity aerodynamics and\nthrust dynamics. Unlike conventional leader-follower schemes that fix the\nfollower's position relative to the leader, the follower is steered to maintain\nrange and bearing angles (which is the angle between its velocity vector and\nits line-of-sight (LOS) with respect to the leader) arbitrarily close to the\nprescribed values, enabling the follower to maintain formation on a\nhemispherical region behind the leader. The proposed IGC framework directly\nmaps leader-follower relative range dynamics to throttle commands, and the\nfollower's velocity orientation relative to the LOS to aerodynamic control\nsurface deflections. This enables synergism between guidance and control\nsubsystems. The control design uses a dynamic surface control-based\nbackstepping approach to achieve convergence to the desired formation set,\nwhere Lyapunov barrier functions are incorporated to ensure the follower's\nbearing angle is constrained within specified bounds. Rigorous stability\nanalysis guarantees uniform ultimate boundedness of all error states and strict\nconstraint satisfaction in the presence of aerodynamic nonlinearities. The\nproposed flexible formation scheme allows the follower to have an orientation\nmismatch relative to the leader to execute anticipatory reconfiguration by\ntransitioning between the relative positions in the admissible formation set\nwhen the leader aggressively maneuvers. The proposed IGC law relies only on\nrelative information and onboard sensors without the information about the\nleader's maneuver, making it suitable for GPS-denied or non-cooperative\nscenarios. Finally, we present simulation results to vindicate the\neffectiveness and robustness of our approach.",
    "published": "2025-10-07T19:17:08Z",
    "updated": "2025-10-07T19:17:08Z",
    "link": "http://arxiv.org/pdf/2510.06394v1.pdf",
    "category": [
      "eess.SY",
      "cs.MA",
      "cs.RO",
      "cs.SY",
      "math.DS"
    ],
    "authors": [
      "Praveen Kumar Ranjan",
      "Abhinav Sinha",
      "Yongcan Cao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06351v1",
    "title": "A Formal gatekeeper Framework for Safe Dual Control with Active\n  Exploration",
    "summary": "Planning safe trajectories under model uncertainty is a fundamental\nchallenge. Robust planning ensures safety by considering worst-case\nrealizations, yet ignores uncertainty reduction and leads to overly\nconservative behavior. Actively reducing uncertainty on-the-fly during a\nnominal mission defines the dual control problem. Most approaches address this\nby adding a weighted exploration term to the cost, tuned to trade off the\nnominal objective and uncertainty reduction, but without formal consideration\nof when exploration is beneficial. Moreover, safety is enforced in some methods\nbut not in others. We propose a framework that integrates robust planning with\nactive exploration under formal guarantees as follows: The key innovation and\ncontribution is that exploration is pursued only when it provides a verifiable\nimprovement without compromising safety. To achieve this, we utilize our\nearlier work on gatekeeper as an architecture for safety verification, and\nextend it so that it generates both safe and informative trajectories that\nreduce uncertainty and the cost of the mission, or keep it within a\nuser-defined budget. The methodology is evaluated via simulation case studies\non the online dual control of a quadrotor under parametric uncertainty.",
    "published": "2025-10-07T18:12:29Z",
    "updated": "2025-10-07T18:12:29Z",
    "link": "http://arxiv.org/pdf/2510.06351v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Kaleb Ben Naveed",
      "Devansh R. Agrawal",
      "Dimitra Panagou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06339v1",
    "title": "Vi-TacMan: Articulated Object Manipulation via Vision and Touch",
    "summary": "Autonomous manipulation of articulated objects remains a fundamental\nchallenge for robots in human environments. Vision-based methods can infer\nhidden kinematics but can yield imprecise estimates on unfamiliar objects.\nTactile approaches achieve robust control through contact feedback but require\naccurate initialization. This suggests a natural synergy: vision for global\nguidance, touch for local precision. Yet no framework systematically exploits\nthis complementarity for generalized articulated manipulation. Here we present\nVi-TacMan, which uses vision to propose grasps and coarse directions that seed\na tactile controller for precise execution. By incorporating surface normals as\ngeometric priors and modeling directions via von Mises-Fisher distributions,\nour approach achieves significant gains over baselines (all p<0.0001).\nCritically, manipulation succeeds without explicit kinematic models -- the\ntactile controller refines coarse visual estimates through real-time contact\nregulation. Tests on more than 50,000 simulated and diverse real-world objects\nconfirm robust cross-category generalization. This work establishes that coarse\nvisual cues suffice for reliable manipulation when coupled with tactile\nfeedback, offering a scalable paradigm for autonomous systems in unstructured\nenvironments.",
    "published": "2025-10-07T18:02:50Z",
    "updated": "2025-10-07T18:02:50Z",
    "link": "http://arxiv.org/pdf/2510.06339v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Leiyao Cui",
      "Zihang Zhao",
      "Sirui Xie",
      "Wenhuan Zhang",
      "Zhi Han",
      "Yixin Zhu"
    ]
  }
]