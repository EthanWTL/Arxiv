[
  {
    "id": "http://arxiv.org/abs/2601.18796v1",
    "title": "ctELM: Decoding and Manipulating Embeddings of Clinical Trials with Embedding Language Models",
    "summary": "Text embeddings have become an essential part of a variety of language applications. However, methods for interpreting, exploring and reversing embedding spaces are limited, reducing transparency and precluding potentially valuable generative use cases. In this work, we align Large Language Models to embeddings of clinical trials using the recently reported Embedding Language Model (ELM) method. We develop an open-source, domain-agnostic ELM architecture and training framework, design training tasks for clinical trials, and introduce an expert-validated synthetic dataset. We then train a series of ELMs exploring the impact of tasks and training regimes. Our final model, ctELM, can accurately describe and compare unseen clinical trials from embeddings alone and produce plausible clinical trials from novel vectors. We further show that generated trial abstracts are responsive to moving embeddings along concept vectors for age and sex of study subjects. Our public ELM implementation and experimental results will aid the alignment of Large Language Models to embedding spaces in the biomedical domain and beyond.",
    "published": "2026-01-26T18:58:46Z",
    "updated": "2026-01-26T18:58:46Z",
    "link": "http://arxiv.org/pdf/2601.18796v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Brian Ondov",
      "Chia-Hsuan Chang",
      "Yujia Zhou",
      "Mauro Giuffrè",
      "Hua Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18795v1",
    "title": "Reuse your FLOPs: Scaling RL on Hard Problems by Conditioning on Very Off-Policy Prefixes",
    "summary": "Typical reinforcement learning (RL) methods for LLM reasoning waste compute on hard problems, where correct on-policy traces are rare, policy gradients vanish, and learning stalls. To bootstrap more efficient RL, we consider reusing old sampling FLOPs (from prior inference or RL training) in the form of off-policy traces. Standard off-policy methods supervise against off-policy data, causing instabilities during RL optimization. We introduce PrefixRL, where we condition on the prefix of successful off-policy traces and run on-policy RL to complete them, side-stepping off-policy instabilities. PrefixRL boosts the learning signal on hard problems by modulating the difficulty of the problem through the off-policy prefix length. We prove that the PrefixRL objective is not only consistent with the standard RL objective but also more sample efficient. Empirically, we discover back-generalization: training only on prefixed problems generalizes to out-of-distribution unprefixed performance, with learned strategies often differing from those in the prefix. In our experiments, we source the off-policy traces by rejection sampling with the base model, creating a self-improvement loop. On hard reasoning problems, PrefixRL reaches the same training reward 2x faster than the strongest baseline (SFT on off-policy data then RL), even after accounting for the compute spent on the initial rejection sampling, and increases the final reward by 3x. The gains transfer to held-out benchmarks, and PrefixRL is still effective when off-policy traces are derived from a different model family, validating its flexibility in practical settings.",
    "published": "2026-01-26T18:57:00Z",
    "updated": "2026-01-26T18:57:00Z",
    "link": "http://arxiv.org/pdf/2601.18795v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Amrith Setlur",
      "Zijian Wang",
      "Andrew Cohen",
      "Paria Rashidinejad",
      "Sang Michael Xie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18791v1",
    "title": "Subword-Based Comparative Linguistics across 242 Languages Using Wikipedia Glottosets",
    "summary": "We present a large-scale comparative study of 242 Latin and Cyrillic-script languages using subword-based methodologies. By constructing 'glottosets' from Wikipedia lexicons, we introduce a framework for simultaneous cross-linguistic comparison via Byte-Pair Encoding (BPE). Our approach utilizes rank-based subword vectors to analyze vocabulary overlap, lexical divergence, and language similarity at scale. Evaluations demonstrate that BPE segmentation aligns with morpheme boundaries 95% better than random baseline across 15 languages (F1 = 0.34 vs 0.15). BPE vocabulary similarity correlates significantly with genetic language relatedness (Mantel r = 0.329, p < 0.001), with Romance languages forming the tightest cluster (mean distance 0.51) and cross-family pairs showing clear separation (0.82). Analysis of 26,939 cross-linguistic homographs reveals that 48.7% receive different segmentations across related languages, with variation correlating to phylogenetic distance. Our results provide quantitative macro-linguistic insights into lexical patterns across typologically diverse languages within a unified analytical framework.",
    "published": "2026-01-26T18:55:28Z",
    "updated": "2026-01-26T18:55:28Z",
    "link": "http://arxiv.org/pdf/2601.18791v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Iaroslav Chelombitko",
      "Mika Hämäläinen",
      "Aleksey Komissarov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18785v1",
    "title": "Design Techniques for LLM-Powered Interactive Storytelling: A Case Study of the Dramamancer System",
    "summary": "The rise of Large Language Models (LLMs) has enabled a new paradigm for bridging authorial intent and player agency in interactive narrative. We consider this paradigm through the example of Dramamancer, a system that uses an LLM to transform author-created story schemas into player-driven playthroughs. This extended abstract outlines some design techniques and evaluation considerations associated with this system.",
    "published": "2026-01-26T18:51:20Z",
    "updated": "2026-01-26T18:51:20Z",
    "link": "http://arxiv.org/pdf/2601.18785v1.pdf",
    "category": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Tiffany Wang",
      "Yuqian Sun",
      "Yi Wang",
      "Melissa Roemmele",
      "John Joon Young Chung",
      "Max Kreminski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18783v1",
    "title": "Multi-Objective Reinforcement Learning for Efficient Tactical Decision Making for Trucks in Highway Traffic",
    "summary": "Balancing safety, efficiency, and operational costs in highway driving poses a challenging decision-making problem for heavy-duty vehicles. A central difficulty is that conventional scalar reward formulations, obtained by aggregating these competing objectives, often obscure the structure of their trade-offs. We present a Proximal Policy Optimization based multi-objective reinforcement learning framework that learns a continuous set of policies explicitly representing these trade-offs and evaluates it on a scalable simulation platform for tactical decision making in trucks. The proposed approach learns a continuous set of Pareto-optimal policies that capture the trade-offs among three conflicting objectives: safety, quantified in terms of collisions and successful completion; energy efficiency and time efficiency, quantified using energy cost and driver cost, respectively. The resulting Pareto frontier is smooth and interpretable, enabling flexibility in choosing driving behavior along different conflicting objectives. This framework allows seamless transitions between different driving policies without retraining, yielding a robust and adaptive decision-making strategy for autonomous trucking applications.",
    "published": "2026-01-26T18:50:21Z",
    "updated": "2026-01-26T18:50:21Z",
    "link": "http://arxiv.org/pdf/2601.18783v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "eess.SY"
    ],
    "authors": [
      "Deepthi Pathare",
      "Leo Laine",
      "Morteza Haghir Chehreghani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18779v1",
    "title": "POPE: Learning to Reason on Hard Problems via Privileged On-Policy Exploration",
    "summary": "Reinforcement learning (RL) has improved the reasoning abilities of large language models (LLMs), yet state-of-the-art methods still fail to learn on many training problems. On hard problems, on-policy RL rarely explores even a single correct rollout, yielding zero reward and no learning signal for driving improvement. We find that natural solutions to remedy this exploration problem from classical RL, such as entropy bonuses, more permissive clipping of the importance ratio, or direct optimization of pass@k objectives, do not resolve this issue and often destabilize optimization without improving solvability. A natural alternative is to leverage transfer from easier problems. However, we show that mixing easy and hard problems during RL training is counterproductive due to ray interference, where optimization focuses on already-solvable problems in a way that actively inhibits progress on harder ones. To address this challenge, we introduce Privileged On-Policy Exploration (POPE), an approach that leverages human- or other oracle solutions as privileged information to guide exploration on hard problems, unlike methods that use oracle solutions as training targets (e.g., off-policy RL methods or warmstarting from SFT). POPE augments hard problems with prefixes of oracle solutions, enabling RL to obtain non-zero rewards during guided rollouts. Crucially, the resulting behaviors transfer back to the original, unguided problems through a synergy between instruction-following and reasoning. Empirically, POPE expands the set of solvable problems and substantially improves performance on challenging reasoning benchmarks.",
    "published": "2026-01-26T18:47:21Z",
    "updated": "2026-01-26T18:47:21Z",
    "link": "http://arxiv.org/pdf/2601.18779v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Yuxiao Qu",
      "Amrith Setlur",
      "Virginia Smith",
      "Ruslan Salakhutdinov",
      "Aviral Kumar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18777v1",
    "title": "PRECISE: Reducing the Bias of LLM Evaluations Using Prediction-Powered Ranking Estimation",
    "summary": "Evaluating the quality of search, ranking and RAG systems traditionally requires a significant number of human relevance annotations. In recent times, several deployed systems have explored the usage of Large Language Models (LLMs) as automated judges for this task while their inherent biases prevent direct use for metric estimation. We present a statistical framework extending Prediction-Powered Inference (PPI) that combines minimal human annotations with LLM judgments to produce reliable estimates of metrics which require sub-instance annotations. Our method requires as few as 100 human-annotated queries and 10,000 unlabeled examples, reducing annotation requirements significantly compared to traditional approaches. We formulate our proposed framework (PRECISE) for inference of relevance uplift for an LLM-based query reformulation application, extending PPI to sub-instance annotations at the query-document level. By reformulating the metric-integration space, we reduced the computational complexity from O(2^|C|) to O(2^K), where |C| represents corpus size (in order of millions). Detailed experiments across prominent retrieval datasets demonstrate that our method reduces the variance of estimates for the business-critical Precision@K metric, while effectively correcting for LLM bias in low-resource settings.",
    "published": "2026-01-26T18:46:49Z",
    "updated": "2026-01-26T18:46:49Z",
    "link": "http://arxiv.org/pdf/2601.18777v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Abhishek Divekar",
      "Anirban Majumder"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18771v1",
    "title": "Dep-Search: Learning Dependency-Aware Reasoning Traces with Persistent Memory",
    "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in complex reasoning tasks, particularly when augmented with search mechanisms that enable systematic exploration of external knowledge bases. The field has evolved from traditional retrieval-augmented generation (RAG) frameworks to more sophisticated search-based frameworks that orchestrate multi-step reasoning through explicit search strategies. However, existing search frameworks still rely heavily on implicit natural language reasoning to determine search strategies and how to leverage retrieved information across reasoning steps. This reliance on implicit reasoning creates fundamental challenges for managing dependencies between sub-questions, efficiently reusing previously retrieved knowledge, and learning optimal search strategies through reinforcement learning. To address these limitations, we propose Dep-Search, a dependency-aware search framework that advances beyond existing search frameworks by integrating structured reasoning, retrieval, and persistent memory through GRPO. Dep-Search introduces explicit control mechanisms that enable the model to decompose questions with dependency relationships, retrieve information when needed, access previously stored knowledge from memory, and summarize long reasoning contexts into reusable memory entries. Through extensive experiments on seven diverse question answering datasets, we demonstrate that Dep-Search significantly enhances LLMs' ability to tackle complex multi-hop reasoning tasks, achieving substantial improvements over strong baselines across different model scales.",
    "published": "2026-01-26T18:42:33Z",
    "updated": "2026-01-26T18:42:33Z",
    "link": "http://arxiv.org/pdf/2601.18771v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "authors": [
      "Yanming Liu",
      "Xinyue Peng",
      "Zixuan Yan",
      "Yanxin Shen",
      "Wenjie Xu",
      "Yuefeng Huang",
      "Xinyi Wang",
      "Jiannan Cao",
      "Jianwei Yin",
      "Xuhong Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.22846v3",
    "title": "RocqStar: Leveraging Similarity-driven Retrieval and Agentic Systems for Rocq generation",
    "summary": "Interactive Theorem Proving was repeatedly shown to be fruitful when combined with Generative Artificial Intelligence. This paper assesses multiple approaches to Rocq generation and illuminates potential avenues for improvement. We identify retrieval-based premise selection as a central component of effective Rocq proof generation and propose a novel approach based on a self-attentive embedder model. The evaluation of the designed approach shows up to 28% relative increase of the generator's performance. We tackle the problem of writing Rocq proofs using a multi-stage agentic system, tailored for formal verification, and demonstrate its high effectiveness. We conduct an ablation study and demonstrate that incorporating multi-agent debate during the planning stage increases the proof success rate by 20% overall and nearly doubles it for complex theorems, while the reflection mechanism further enhances stability and consistency.",
    "published": "2025-05-28T20:26:11Z",
    "updated": "2026-01-26T18:27:30Z",
    "link": "http://arxiv.org/pdf/2505.22846v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.LO",
      "cs.SE"
    ],
    "authors": [
      "Andrei Kozyrev",
      "Nikita Khramov",
      "Gleb Solovev",
      "Anton Podkopaev"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18754v1",
    "title": "$α^3$-SecBench: A Large-Scale Evaluation Suite of Security, Resilience, and Trust for LLM-based UAV Agents over 6G Networks",
    "summary": "Autonomous unmanned aerial vehicle (UAV) systems are increasingly deployed in safety-critical, networked environments where they must operate reliably in the presence of malicious adversaries. While recent benchmarks have evaluated large language model (LLM)-based UAV agents in reasoning, navigation, and efficiency, systematic assessment of security, resilience, and trust under adversarial conditions remains largely unexplored, particularly in emerging 6G-enabled settings.\n  We introduce $α^{3}$-SecBench, the first large-scale evaluation suite for assessing the security-aware autonomy of LLM-based UAV agents under realistic adversarial interference. Building on multi-turn conversational UAV missions from $α^{3}$-Bench, the framework augments benign episodes with 20,000 validated security overlay attack scenarios targeting seven autonomy layers, including sensing, perception, planning, control, communication, edge/cloud infrastructure, and LLM reasoning. $α^{3}$-SecBench evaluates agents across three orthogonal dimensions: security (attack detection and vulnerability attribution), resilience (safe degradation behavior), and trust (policy-compliant tool usage).\n  We evaluate 23 state-of-the-art LLMs from major industrial providers and leading AI labs using thousands of adversarially augmented UAV episodes sampled from a corpus of 113,475 missions spanning 175 threat types. While many models reliably detect anomalous behavior, effective mitigation, vulnerability attribution, and trustworthy control actions remain inconsistent. Normalized overall scores range from 12.9% to 57.1%, highlighting a significant gap between anomaly detection and security-aware autonomous decision-making. We release $α^{3}$-SecBench on GitHub: https://github.com/maferrag/AlphaSecBench",
    "published": "2026-01-26T18:25:07Z",
    "updated": "2026-01-26T18:25:07Z",
    "link": "http://arxiv.org/pdf/2601.18754v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Mohamed Amine Ferrag",
      "Abderrahmane Lakas",
      "Merouane Debbah"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18753v1",
    "title": "HalluGuard: Demystifying Data-Driven and Reasoning-Driven Hallucinations in LLMs",
    "summary": "The reliability of Large Language Models (LLMs) in high-stakes domains such as healthcare, law, and scientific discovery is often compromised by hallucinations. These failures typically stem from two sources: data-driven hallucinations and reasoning-driven hallucinations. However, existing detection methods usually address only one source and rely on task-specific heuristics, limiting their generalization to complex scenarios. To overcome these limitations, we introduce the Hallucination Risk Bound, a unified theoretical framework that formally decomposes hallucination risk into data-driven and reasoning-driven components, linked respectively to training-time mismatches and inference-time instabilities. This provides a principled foundation for analyzing how hallucinations emerge and evolve. Building on this foundation, we introduce HalluGuard, an NTK-based score that leverages the induced geometry and captured representations of the NTK to jointly identify data-driven and reasoning-driven hallucinations. We evaluate HalluGuard on 10 diverse benchmarks, 11 competitive baselines, and 9 popular LLM backbones, consistently achieving state-of-the-art performance in detecting diverse forms of LLM hallucinations.",
    "published": "2026-01-26T18:23:09Z",
    "updated": "2026-01-26T18:23:09Z",
    "link": "http://arxiv.org/pdf/2601.18753v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Xinyue Zeng",
      "Junhong Lin",
      "Yujun Yan",
      "Feng Guo",
      "Liang Shi",
      "Jun Wu",
      "Dawei Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18751v1",
    "title": "Trust, Don't Trust, or Flip: Robust Preference-Based Reinforcement Learning with Multi-Expert Feedback",
    "summary": "Preference-based reinforcement learning (PBRL) offers a promising alternative to explicit reward engineering by learning from pairwise trajectory comparisons. However, real-world preference data often comes from heterogeneous annotators with varying reliability; some accurate, some noisy, and some systematically adversarial. Existing PBRL methods either treat all feedback equally or attempt to filter out unreliable sources, but both approaches fail when faced with adversarial annotators who systematically provide incorrect preferences. We introduce TriTrust-PBRL (TTP), a unified framework that jointly learns a shared reward model and expert-specific trust parameters from multi-expert preference feedback. The key insight is that trust parameters naturally evolve during gradient-based optimization to be positive (trust), near zero (ignore), or negative (flip), enabling the model to automatically invert adversarial preferences and recover useful signal rather than merely discarding corrupted feedback. We provide theoretical analysis establishing identifiability guarantees and detailed gradient analysis that explains how expert separation emerges naturally during training without explicit supervision. Empirically, we evaluate TTP on four diverse domains spanning manipulation tasks (MetaWorld) and locomotion (DM Control) under various corruption scenarios. TTP achieves state-of-the-art robustness, maintaining near-oracle performance under adversarial corruption while standard PBRL methods fail catastrophically. Notably, TTP outperforms existing baselines by successfully learning from mixed expert pools containing both reliable and adversarial annotators, all while requiring no expert features beyond identification indices and integrating seamlessly with existing PBRL pipelines.",
    "published": "2026-01-26T18:21:48Z",
    "updated": "2026-01-26T18:21:48Z",
    "link": "http://arxiv.org/pdf/2601.18751v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Seyed Amir Hosseini",
      "Maryam Abdolali",
      "Amirhosein Tavakkoli",
      "Fardin Ayar",
      "Ehsan Javanmardi",
      "Manabu Tsukada",
      "Mahdi Javanmardi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.02599v2",
    "title": "Next Token Knowledge Tracing: Exploiting Pretrained LLM Representations to Decode Student Behaviour",
    "summary": "Modelling student knowledge is a key challenge when leveraging AI in education, with major implications for personalised learning. The Knowledge Tracing (KT) task aims to predict how students will respond to educational questions in learning environments, based on their prior interactions. Existing KT models typically use response correctness along with metadata like skill tags and timestamps, often overlooking the question text, which is an important source of pedagogical insight. This omission poses a lost opportunity while limiting predictive performance. We propose Next Token Knowledge Tracing (NTKT), a novel approach that reframes KT as a next-token prediction task using pretrained Large Language Models (LLMs). NTKT represents both student histories and question content as sequences of text, allowing LLMs to learn patterns in both behaviour and language. Our series of experiments significantly improves performance over state-of-the-art neural KT models and generalises much better to cold-start questions and users. These findings highlight the importance of question content in KT and demonstrate the benefits of leveraging pretrained representations of LLMs to model student learning more effectively.",
    "published": "2025-11-04T14:20:56Z",
    "updated": "2026-01-26T18:20:30Z",
    "link": "http://arxiv.org/pdf/2511.02599v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Max Norris",
      "Kobi Gal",
      "Sahan Bulathwela"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18747v1",
    "title": "Capturing P: On the Expressive Power and Efficient Evaluation of Boolean Retrieval",
    "summary": "Modern information retrieval is transitioning from simple document filtering to complex, neuro-symbolic reasoning workflows. However, current retrieval architectures face a fundamental efficiency dilemma when handling the rigorous logical and arithmetic constraints required by this new paradigm. Standard iterator-based engines (Document-at-a-Time) do not natively support complex, nested logic graphs; forcing them to execute such queries typically results in intractable runtime performance. Conversely, naive recursive approaches (Term-at-a-Time), while capable of supporting these structures, suffer from prohibitive memory consumption when enforcing broad logical exclusions.\n  In this paper, we propose that a retrieval engine must be capable of ``Capturing $\\mathbf{P}$'' -- evaluating any polynomial-time property directly over its index in a computationally efficient manner. We define a formal Retrieval Language ($\\mathcal{L}_R$) based on Directed Acyclic Graphs (DAGs) and prove it precisely captures the complexity class $\\mathbf{P}$. We introduce \\texttt{ComputePN}, a novel evaluation algorithm that makes $\\mathcal{L}_R$ tractable. By combining native DAG traversal with a memory-efficient ``Positive-Negative'' response mechanism, \\texttt{ComputePN} ensures the efficient evaluation of any query in $\\mathcal{L}_R$. This work establishes the theoretical foundation for turning the search index into a general-purpose computational engine.",
    "published": "2026-01-26T18:07:40Z",
    "updated": "2026-01-26T18:07:40Z",
    "link": "http://arxiv.org/pdf/2601.18747v1.pdf",
    "category": [
      "cs.IR",
      "cs.AI",
      "cs.CC",
      "cs.CL",
      "cs.DB"
    ],
    "authors": [
      "Amir Aavani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18744v1",
    "title": "TSRBench: A Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models",
    "summary": "Time series data is ubiquitous in real-world scenarios and crucial for critical applications ranging from energy management to traffic control. Consequently, the ability to reason over time series is a fundamental skill for generalist models to solve practical problems. However, this dimension is notably absent from existing benchmarks of generalist models. To bridge this gap, we introduce TSRBench, a comprehensive multi-modal benchmark designed to stress-test the full spectrum of time series reasoning capabilities. TSRBench features: i) a diverse set of 4125 problems from 14 domains, and is categorized into 4 major dimensions: Perception, Reasoning, Prediction, and Decision-Making. ii) 15 tasks from the 4 dimensions evaluating essential reasoning capabilities (e.g., numerical reasoning). Through extensive experiments, we evaluated over 30 leading proprietary and open-source LLMs, VLMs, and TSLLMs within TSRBench. Our findings reveal that: i) scaling laws hold for perception and reasoning but break down for prediction; ii) strong reasoning does not guarantee accurate context-aware forecasting, indicating a decoupling between semantic understanding and numerical prediction; and iii) despite the complementary nature of textual and visual represenations of time series as inputs, current multimodal models fail to effectively fuse them for reciprocal performance gains. TSRBench provides a standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance generalist models. Our code and dataset are available at https://tsrbench.github.io/.",
    "published": "2026-01-26T18:04:54Z",
    "updated": "2026-01-26T18:04:54Z",
    "link": "http://arxiv.org/pdf/2601.18744v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Fangxu Yu",
      "Xingang Guo",
      "Lingzhi Yuan",
      "Haoqiang Kang",
      "Hongyu Zhao",
      "Lianhui Qin",
      "Furong Huang",
      "Bin Hu",
      "Tianyi Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18739v1",
    "title": "SeNeDiF-OOD: Semantic Nested Dichotomy Fusion for Out-of-Distribution Detection Methodology in Open-World Classification. A Case Study on Monument Style Classification",
    "summary": "Out-of-distribution (OOD) detection is a fundamental requirement for the reliable deployment of artificial intelligence applications in open-world environments. However, addressing the heterogeneous nature of OOD data, ranging from low-level corruption to semantic shifts, remains a complex challenge that single-stage detectors often fail to resolve. To address this issue, we propose SeNeDiF-OOD, a novel methodology based on Semantic Nested Dichotomy Fusion. This framework decomposes the detection task into a hierarchical structure of binary fusion nodes, where each layer is designed to integrate decision boundaries aligned with specific levels of semantic abstraction. To validate the proposed framework, we present a comprehensive case study using MonuMAI, a real-world architectural style recognition system exposed to an open environment. This application faces a diverse range of inputs, including non-monument images, unknown architectural styles, and adversarial attacks, making it an ideal testbed for our proposal. Through extensive experimental evaluation in this domain, results demonstrate that our hierarchical fusion methodology significantly outperforms traditional baselines, effectively filtering these diverse OOD categories while preserving in-distribution performance.",
    "published": "2026-01-26T18:01:46Z",
    "updated": "2026-01-26T18:01:46Z",
    "link": "http://arxiv.org/pdf/2601.18739v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Ignacio Antequera-Sánchez",
      "Juan Luis Suárez-Díaz",
      "Rosana Montes",
      "Francisco Herrera"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18735v1",
    "title": "Why Keep Your Doubts to Yourself? Trading Visual Uncertainties in Multi-Agent Bandit Systems",
    "summary": "Vision-Language Models (VLMs) enable powerful multi-agent systems, but scaling them is economically unsustainable: coordinating heterogeneous agents under information asymmetry often spirals costs. Existing paradigms, such as Mixture-of-Agents and knowledge-based routers, rely on heuristic proxies that ignore costs and collapse uncertainty structure, leading to provably suboptimal coordination. We introduce Agora, a framework that reframes coordination as a decentralized market for uncertainty. Agora formalizes epistemic uncertainty into a structured, tradable asset (perceptual, semantic, inferential), and enforces profitability-driven trading among agents based on rational economic rules. A market-aware broker, extending Thompson Sampling, initiates collaboration and guides the system toward cost-efficient equilibria. Experiments on five multimodal benchmarks (MMMU, MMBench, MathVision, InfoVQA, CC-OCR) show that Agora outperforms strong VLMs and heuristic multi-agent strategies, e.g., achieving +8.5% accuracy over the best baseline on MMMU while reducing cost by over 3x. These results establish market-based coordination as a principled and scalable paradigm for building economically viable multi-agent visual intelligence systems.",
    "published": "2026-01-26T17:58:53Z",
    "updated": "2026-01-26T17:58:53Z",
    "link": "http://arxiv.org/pdf/2601.18735v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Jusheng Zhang",
      "Yijia Fan",
      "Kaitong Cai",
      "Jing Yang",
      "Jiawei Yao",
      "Jian Wang",
      "Guanlong Qu",
      "Ziliang Chen",
      "Keze Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18733v1",
    "title": "Advances and Innovations in the Multi-Agent Robotic System (MARS) Challenge",
    "summary": "Recent advancements in multimodal large language models and vision-languageaction models have significantly driven progress in Embodied AI. As the field transitions toward more complex task scenarios, multi-agent system frameworks are becoming essential for achieving scalable, efficient, and collaborative solutions. This shift is fueled by three primary factors: increasing agent capabilities, enhancing system efficiency through task delegation, and enabling advanced human-agent interactions. To address the challenges posed by multi-agent collaboration, we propose the Multi-Agent Robotic System (MARS) Challenge, held at the NeurIPS 2025 Workshop on SpaVLE. The competition focuses on two critical areas: planning and control, where participants explore multi-agent embodied planning using vision-language models (VLMs) to coordinate tasks and policy execution to perform robotic manipulation in dynamic environments. By evaluating solutions submitted by participants, the challenge provides valuable insights into the design and coordination of embodied multi-agent systems, contributing to the future development of advanced collaborative AI systems.",
    "published": "2026-01-26T17:56:19Z",
    "updated": "2026-01-26T17:56:19Z",
    "link": "http://arxiv.org/pdf/2601.18733v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Li Kang",
      "Heng Zhou",
      "Xiufeng Song",
      "Rui Li",
      "Bruno N. Y. Chen",
      "Ziye Wang",
      "Ximeng Meng",
      "Stone Tao",
      "Yiran Qin",
      "Xiaohong Liu",
      "Ruimao Zhang",
      "Lei Bai",
      "Yilun Du",
      "Hao Su",
      "Philip Torr",
      "Zhenfei Yin",
      "Ruihao Gong",
      "Yejun Zeng",
      "Fengjun Zhong",
      "Shenghao Jin",
      "Jinyang Guo",
      "Xianglong Liu",
      "Xiaojun Jia",
      "Tianqi Shan",
      "Wenqi Ren",
      "Simeng Qin",
      "Jialing Yang",
      "Xiaoyu Ma",
      "Tianxing Chen",
      "Zixuan Li",
      "Zijian Cai",
      "Yan Qin",
      "Yusen Qin",
      "Qiangyu Chen",
      "Kaixuan Wang",
      "Zhaoming Han",
      "Yao Mu",
      "Ping Luo",
      "Yuanqi Yao",
      "Haoming Song",
      "Jan-Nico Zaech",
      "Fabien Despinoy",
      "Danda Pani Paudel",
      "Luc Van Gool"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18732v1",
    "title": "Optimal Use of Preferences in Artificial Intelligence Algorithms",
    "summary": "Machine learning systems embed preferences either in training losses or through post-processing of calibrated predictions. Applying information design methods from Strack and Yang (2024), this paper provides decision problem agnostic conditions under which separation training preference free and applying preferences ex post is optimal. Unlike prior work that requires specifying downstream objectives, the welfare results here apply uniformly across decision problems. The key primitive is a diminishing-value-of-information condition: relative to a fixed (normalised) preference-free loss, preference embedding makes informativeness less valuable at the margin, inducing a mean-preserving contraction of learned posteriors. Because the value of information is convex in beliefs, preference-free training weakly dominates for any expected utility decision problem. This provides theoretical foundations for modular AI pipelines that learn calibrated probabilities and implement asymmetric costs through downstream decision rules. However, separation requires users to implement optimal decision rules. When cognitive constraints bind, as documented in human AI decision-making, preference embedding can dominate by automating threshold computation. These results provide design guidance: preserve optionality through post-processing when objectives may shift; embed preferences when decision-stage frictions dominate.",
    "published": "2026-01-26T17:55:56Z",
    "updated": "2026-01-26T17:55:56Z",
    "link": "http://arxiv.org/pdf/2601.18732v1.pdf",
    "category": [
      "econ.TH",
      "cs.AI"
    ],
    "authors": [
      "Joshua S. Gans"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18731v1",
    "title": "One Adapts to Any: Meta Reward Modeling for Personalized LLM Alignment",
    "summary": "Alignment of Large Language Models (LLMs) aims to align outputs with human preferences, and personalized alignment further adapts models to individual users. This relies on personalized reward models that capture user-specific preferences and automatically provide individualized feedback. However, developing these models faces two critical challenges: the scarcity of feedback from individual users and the need for efficient adaptation to unseen users. We argue that addressing these constraints requires a paradigm shift from fitting data to learn user preferences to learn the process of preference adaptation. To realize this, we propose Meta Reward Modeling (MRM), which reformulates personalized reward modeling as a meta-learning problem. Specifically, we represent each user's reward model as a weighted combination of base reward functions, and optimize the initialization of these weights using a Model-Agnostic Meta-Learning (MAML)-style framework to support fast adaptation under limited feedback. To ensure robustness, we introduce the Robust Personalization Objective (RPO), which places greater emphasis on hard-to-learn users during meta optimization. Extensive experiments on personalized preference datasets validate that MRM enhances few-shot personalization, improves user robustness, and consistently outperforms baselines.",
    "published": "2026-01-26T17:55:52Z",
    "updated": "2026-01-26T17:55:52Z",
    "link": "http://arxiv.org/pdf/2601.18731v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Hongru Cai",
      "Yongqi Li",
      "Tiezheng Yu",
      "Fengbin Zhu",
      "Wenjie Wang",
      "Fuli Feng",
      "Wenjie Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.22673v2",
    "title": "Physiology-Informed Generative Multi-Task Network for Contrast-Free CT Perfusion",
    "summary": "Perfusion imaging is extensively utilized to assess hemodynamic status and tissue perfusion in various organs. Computed tomography perfusion (CTP) imaging plays a key role in the early assessment and planning of stroke treatment. While CTP provides essential perfusion parameters to identify abnormal blood flow in the brain, the use of contrast agents in CTP can lead to allergic reactions and adverse side effects, along with costing USD 4.9 billion worldwide in 2022. To address these challenges, we propose a novel deep learning framework called Multitask Automated Generation of Intermodal CT perfusion maps (MAGIC). This framework combines generative artificial intelligence and physiological information to map non-contrast computed tomography (CT) imaging to multiple contrast-free CTP imaging maps. We demonstrate enhanced image fidelity by incorporating physiological characteristics into the loss terms. Our network was trained and validated using CT image data from patients referred for stroke at UF Health and demonstrated robustness to abnormalities in brain perfusion activity. A double-blinded study was conducted involving seven experienced neuroradiologists and vascular neurologists. This study validated MAGIC's visual quality and diagnostic accuracy showing favorable performance compared to clinical perfusion imaging with intravenous contrast injection. Overall, MAGIC holds great promise in revolutionizing healthcare by offering contrast-free, cost-effective, and rapid perfusion imaging.",
    "published": "2025-05-12T22:58:55Z",
    "updated": "2026-01-26T17:55:25Z",
    "link": "http://arxiv.org/pdf/2505.22673v2.pdf",
    "category": [
      "q-bio.TO",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Wasif Khan",
      "John Rees",
      "Kyle B. See",
      "Simon Kato",
      "Ziqian Huang",
      "Amy Lazarte",
      "Kyle Douglas",
      "Xiangyang Lou",
      "Teng J. Peng",
      "Dhanashree Rajderkar",
      "Pina Sanelli",
      "Amita Singh",
      "Ibrahim Tuna",
      "Christina A. Wilson",
      "Ruogu Fang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.21447v2",
    "title": "ARTI-6: Towards Six-dimensional Articulatory Speech Encoding",
    "summary": "We propose ARTI-6, a compact six-dimensional articulatory speech encoding framework derived from real-time MRI data that captures crucial vocal tract regions including the velum, tongue root, and larynx. ARTI-6 consists of three components: (1) a six-dimensional articulatory feature set representing key regions of the vocal tract; (2) an articulatory inversion model, which predicts articulatory features from speech acoustics leveraging speech foundation models, achieving a prediction correlation of 0.87; and (3) an articulatory synthesis model, which reconstructs intelligible speech directly from articulatory features, showing that even a low-dimensional representation can generate natural-sounding speech. Together, ARTI-6 provides an interpretable, computationally efficient, and physiologically grounded framework for advancing articulatory inversion, synthesis, and broader speech technology applications. The source code and speech samples are publicly available.",
    "published": "2025-09-25T19:18:35Z",
    "updated": "2026-01-26T17:51:41Z",
    "link": "http://arxiv.org/pdf/2509.21447v2.pdf",
    "category": [
      "eess.AS",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Jihwan Lee",
      "Sean Foley",
      "Thanathai Lertpetchpun",
      "Kevin Huang",
      "Yoonjeong Lee",
      "Tiantian Feng",
      "Louis Goldstein",
      "Dani Byrd",
      "Shrikanth Narayanan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.19391v2",
    "title": "TensLoRA: Tensor Alternatives for Low-Rank Adaptation",
    "summary": "Low-Rank Adaptation (LoRA) is widely used to efficiently adapt Transformers by adding trainable low-rank matrices to attention projections. While effective, these matrices are considered independent for each attention projection (Query, Key, and Value) and each layer. Recent extensions have considered joint, tensor-based adaptations, but only in limited forms and without a systematic framework. We introduce TensLoRA, a unified framework that aggregates LoRA updates into higher-order tensors and models a broad family of tensor-based low-rank adaptations. Our formulation generalizes existing tensor-based methods and enables mode-specific compression rates, allowing parameter budgets to be tailored according to the modality and task. Experiments on vision and language benchmarks reveal that the tensor construction directly impacts performance, sometimes better than standard LoRA under similar parameter counts.",
    "published": "2025-09-22T17:15:23Z",
    "updated": "2026-01-26T17:51:38Z",
    "link": "http://arxiv.org/pdf/2509.19391v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Axel Marmoret",
      "Reda Bensaid",
      "Jonathan Lys",
      "Vincent Gripon",
      "François Leduc-Primeau"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18724v1",
    "title": "HalluCitation Matters: Revealing the Impact of Hallucinated References with 300 Hallucinated Papers in ACL Conferences",
    "summary": "Recently, we have often observed hallucinated citations or references that do not correspond to any existing work in papers under review, preprints, or published papers. Such hallucinated citations pose a serious concern to scientific reliability. When they appear in accepted papers, they may also negatively affect the credibility of conferences. In this study, we refer to hallucinated citations as \"HalluCitation\" and systematically investigate their prevalence and impact. We analyze all papers published at ACL, NAACL, and EMNLP in 2024 and 2025, including main conference, Findings, and workshop papers. Our analysis reveals that nearly 300 papers contain at least one HalluCitation, most of which were published in 2025. Notably, half of these papers were identified at EMNLP 2025, the most recent conference, indicating that this issue is rapidly increasing. Moreover, more than 100 such papers were accepted as main conference and Findings papers at EMNLP 2025, affecting the credibility.",
    "published": "2026-01-26T17:48:23Z",
    "updated": "2026-01-26T17:48:23Z",
    "link": "http://arxiv.org/pdf/2601.18724v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.DL"
    ],
    "authors": [
      "Yusuke Sakai",
      "Hidetaka Kamigaito",
      "Taro Watanabe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18716v1",
    "title": "Conditioned Generative Modeling of Molecular Glues: A Realistic AI Approach for Synthesizable Drug-like Molecules",
    "summary": "Alzheimer's disease (AD) is marked by the pathological accumulation of amyloid beta-42 (Abeta-42), contributing to synaptic dysfunction and neurodegeneration. While extracellular amyloid plaques are well-studied, increasing evidence highlights intracellular Abeta-42 as an early and toxic driver of disease progression. In this study, we present a novel, AI-assisted drug design approach to promote targeted degradation of Abeta-42 via the ubiquitin-proteasome system (UPS), using E3 ligase-directed molecular glues. We systematically evaluated the ternary complex formation potential of Abeta-42 with three E3 ligases: CRBN, VHL, and MDM2, through structure-based modeling, ADMET screening, and docking. We then developed a Ligase-Conditioned Junction Tree Variational Autoencoder (LC-JT-VAE) to generate ligase-specific small molecules, incorporating protein sequence embeddings and torsional angle-aware molecular graphs. Our results demonstrate that this generative model can produce chemically valid, novel, and target-specific molecular glues capable of facilitating Abeta-42 degradation. This integrated approach offers a promising framework for designing UPS-targeted therapies for neurodegenerative diseases.",
    "published": "2026-01-26T17:39:59Z",
    "updated": "2026-01-26T17:39:59Z",
    "link": "http://arxiv.org/pdf/2601.18716v1.pdf",
    "category": [
      "cs.AI",
      "q-bio.BM"
    ],
    "authors": [
      "Naeyma N. Islam",
      "Thomas R. Caulfield"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18714v1",
    "title": "Low Cost, High Efficiency: LiDAR Place Recognition in Vineyards with Matryoshka Representation Learning",
    "summary": "Localization in agricultural environments is challenging due to their unstructured nature and lack of distinctive landmarks. Although agricultural settings have been studied in the context of object classification and segmentation, the place recognition task for mobile robots is not trivial in the current state of the art. In this study, we propose MinkUNeXt-VINE, a lightweight, deep-learning-based method that surpasses state-of-the-art methods in vineyard environments thanks to its pre-processing and Matryoshka Representation Learning multi-loss approach. Our method prioritizes enhanced performance with low-cost, sparse LiDAR inputs and lower-dimensionality outputs to ensure high efficiency in real-time scenarios. Additionally, we present a comprehensive ablation study of the results on various evaluation cases and two extensive long-term vineyard datasets employing different LiDAR sensors. The results demonstrate the efficiency of the trade-off output produced by this approach, as well as its robust performance on low-cost and low-resolution input data. The code is publicly available for reproduction.",
    "published": "2026-01-26T17:38:56Z",
    "updated": "2026-01-26T17:38:56Z",
    "link": "http://arxiv.org/pdf/2601.18714v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "authors": [
      "Judith Vilella-Cantos",
      "Mauro Martini",
      "Marcello Chiaberge",
      "Mónica Ballesta",
      "David Valiente"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18713v1",
    "title": "Point transformer for protein structural heterogeneity analysis using CryoEM",
    "summary": "Structural dynamics of macromolecules is critical to their structural-function relationship. Cryogenic electron microscopy (CryoEM) provides snapshots of vitrified protein at different compositional and conformational states, and the structural heterogeneity of proteins can be characterized through computational analysis of the images. For protein systems with multiple degrees of freedom, it is still challenging to disentangle and interpret the different modes of dynamics. Here, by implementing Point Transformer, a self-attention network designed for point cloud analysis, we are able to improve the performance of heterogeneity analysis on CryoEM data, and characterize the dynamics of highly complex protein systems in a more human-interpretable way.",
    "published": "2026-01-26T17:38:52Z",
    "updated": "2026-01-26T17:38:52Z",
    "link": "http://arxiv.org/pdf/2601.18713v1.pdf",
    "category": [
      "q-bio.QM",
      "cs.AI"
    ],
    "authors": [
      "Muyuan Chen",
      "Muchen Li",
      "Renjie Liao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.16249v2",
    "title": "Ordering-based Causal Discovery via Generalized Score Matching",
    "summary": "Learning DAG structures from purely observational data remains a long-standing challenge across scientific domains. An emerging line of research leverages the score of the data distribution to initially identify a topological order of the underlying DAG via leaf node detection and subsequently performs edge pruning for graph recovery. This paper extends the score matching framework for causal discovery, which is originally designated for continuous data, and introduces a novel leaf discriminant criterion based on the discrete score function. Through simulated and real-world experiments, we demonstrate that our theory enables accurate inference of true causal orders from observed discrete data and the identified ordering can significantly boost the accuracy of existing causal discovery baselines on nearly all of the settings.",
    "published": "2026-01-22T18:08:31Z",
    "updated": "2026-01-26T17:35:03Z",
    "link": "http://arxiv.org/pdf/2601.16249v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Vy Vo",
      "He Zhao",
      "Trung Le",
      "Edwin V. Bonilla",
      "Dinh Phung"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18707v1",
    "title": "SMART: Scalable Mesh-free Aerodynamic Simulations from Raw Geometries using a Transformer-based Surrogate Model",
    "summary": "Machine learning-based surrogate models have emerged as more efficient alternatives to numerical solvers for physical simulations over complex geometries, such as car bodies. Many existing models incorporate the simulation mesh as an additional input, thereby reducing prediction errors. However, generating a simulation mesh for new geometries is computationally costly. In contrast, mesh-free methods, which do not rely on the simulation mesh, typically incur higher errors. Motivated by these considerations, we introduce SMART, a neural surrogate model that predicts physical quantities at arbitrary query locations using only a point-cloud representation of the geometry, without requiring access to the simulation mesh. The geometry and simulation parameters are encoded into a shared latent space that captures both structural and parametric characteristics of the physical field. A physics decoder then attends to the encoder's intermediate latent representations to map spatial queries to physical quantities. Through this cross-layer interaction, the model jointly updates latent geometric features and the evolving physical field. Extensive experiments show that SMART is competitive with and often outperforms existing methods that rely on the simulation mesh as input, demonstrating its capabilities for industry-level simulations.",
    "published": "2026-01-26T17:34:16Z",
    "updated": "2026-01-26T17:34:16Z",
    "link": "http://arxiv.org/pdf/2601.18707v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.NE"
    ],
    "authors": [
      "Jan Hagnberger",
      "Mathias Niepert"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18706v1",
    "title": "Health-SCORE: Towards Scalable Rubrics for Improving Health-LLMs",
    "summary": "Rubrics are essential for evaluating open-ended LLM responses, especially in safety-critical domains such as healthcare. However, creating high-quality and domain-specific rubrics typically requires significant human expertise time and development cost, making rubric-based evaluation and training difficult to scale. In this work, we introduce Health-SCORE, a generalizable and scalable rubric-based training and evaluation framework that substantially reduces rubric development costs without sacrificing performance. We show that Health-SCORE provides two practical benefits beyond standalone evaluation: it can be used as a structured reward signal to guide reinforcement learning with safety-aware supervision, and it can be incorporated directly into prompts to improve response quality through in-context learning. Across open-ended healthcare tasks, Health-SCORE achieves evaluation quality comparable to human-created rubrics while significantly lowering development effort, making rubric-based evaluation and training more scalable.",
    "published": "2026-01-26T17:34:10Z",
    "updated": "2026-01-26T17:34:10Z",
    "link": "http://arxiv.org/pdf/2601.18706v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Zhichao Yang",
      "Sepehr Janghorbani",
      "Dongxu Zhang",
      "Jun Han",
      "Qian Qian",
      "Andrew Ressler",
      "Gregory D. Lyng",
      "Sanjit Singh Batra",
      "Robert E. Tillman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18702v1",
    "title": "From Fuzzy to Exact: The Halo Architecture for Infinite-Depth Reasoning via Rational Arithmetic",
    "summary": "Current paradigms in Deep Learning prioritize computational throughput over numerical precision, relying on the assumption that intelligence emerges from statistical correlation at scale. In this paper, we challenge this orthodoxy. We propose the Exactness Hypothesis: that General Intelligence (AGI), specifically high-order causal inference, requires a computational substrate capable of Arbitrary Precision Arithmetic. We argue that the \"hallucinations\" and logical incoherence seen in current Large Language Models (LLMs) are artifacts of IEEE 754 floating-point approximation errors accumulating over deep compositional functions. To mitigate this, we introduce the Halo Architecture, a paradigm shift to Rational Arithmetic ($\\mathbb{Q}$) supported by a novel Exact Inference Unit (EIU). Empirical validation on the Huginn-0125 prototype demonstrates that while 600B-parameter scale BF16 baselines collapse in chaotic systems, Halo maintains zero numerical divergence indefinitely. This work establishes exact arithmetic as a prerequisite for reducing logical uncertainty in System 2 AGI.",
    "published": "2026-01-26T17:24:34Z",
    "updated": "2026-01-26T17:24:34Z",
    "link": "http://arxiv.org/pdf/2601.18702v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "authors": [
      "Hansheng Ren"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18700v1",
    "title": "TEA-Bench: A Systematic Benchmarking of Tool-enhanced Emotional Support Dialogue Agent",
    "summary": "Emotional Support Conversation requires not only affective expression but also grounded instrumental support to provide trustworthy guidance. However, existing ESC systems and benchmarks largely focus on affective support in text-only settings, overlooking how external tools can enable factual grounding and reduce hallucination in multi-turn emotional support. We introduce TEA-Bench, the first interactive benchmark for evaluating tool-augmented agents in ESC, featuring realistic emotional scenarios, an MCP-style tool environment, and process-level metrics that jointly assess the quality and factual grounding of emotional support. Experiments on nine LLMs show that tool augmentation generally improves emotional support quality and reduces hallucination, but the gains are strongly capacity-dependent: stronger models use tools more selectively and effectively, while weaker models benefit only marginally. We further release TEA-Dialog, a dataset of tool-enhanced ESC dialogues, and find that supervised fine-tuning improves in-distribution support but generalizes poorly. Our results underscore the importance of tool use in building reliable emotional support agents.",
    "published": "2026-01-26T17:15:27Z",
    "updated": "2026-01-26T17:15:27Z",
    "link": "http://arxiv.org/pdf/2601.18700v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Xingyu Sui",
      "Yanyan Zhao",
      "Yulin Hu",
      "Jiahe Guo",
      "Weixiang Zhao",
      "Bing Qin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.00555v3",
    "title": "MMedAgent-RL: Optimizing Multi-Agent Collaboration for Multimodal Medical Reasoning",
    "summary": "Medical Large Vision-Language Models (Med-LVLMs) have shown strong potential in multimodal diagnostic tasks. However, existing single-agent models struggle to generalize across diverse medical specialties, limiting their performance. Recent efforts introduce multi-agent collaboration frameworks inspired by clinical workflows, where general practitioners (GPs) and specialists interact in a fixed sequence. Despite improvements, these static pipelines lack flexibility and adaptability in reasoning. To address this, we propose MMedAgent-RL, a reinforcement learning (RL)-based multi-agent framework that enables dynamic, optimized collaboration among medical agents. Specifically, we train two GP agents based on Qwen2.5-VL via RL: the triage doctor learns to assign patients to appropriate specialties, while the attending physician integrates the judgments from multi-specialists and its own knowledge to make final decisions. To address the inconsistency in specialist outputs, we introduce a curriculum learning (CL)-guided RL strategy with dynamic entropy regulation, progressively teaching the attending physician to balance between imitating specialists and correcting their mistakes. Experiments on five medical VQA benchmarks demonstrate that MMedAgent-RL outperforms both open-source and proprietary Med-LVLMs. Notably, it achieves an average performance gain of 23.6% over strong baselines.",
    "published": "2025-05-31T13:22:55Z",
    "updated": "2026-01-26T17:15:26Z",
    "link": "http://arxiv.org/pdf/2506.00555v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "authors": [
      "Peng Xia",
      "Jinglu Wang",
      "Yibo Peng",
      "Kaide Zeng",
      "Zihan Dong",
      "Xian Wu",
      "Xiangru Tang",
      "Hongtu Zhu",
      "Yun Li",
      "Linjun Zhang",
      "Shujie Liu",
      "Yan Lu",
      "Huaxiu Yao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18694v1",
    "title": "Neural Multi-Speaker Voice Cloning for Nepali in Low-Resource Settings",
    "summary": "This research presents a few-shot voice cloning system for Nepali speakers, designed to synthesize speech in a specific speaker's voice from Devanagari text using minimal data. Voice cloning in Nepali remains largely unexplored due to its low-resource nature. To address this, we constructed separate datasets: untranscribed audio for training a speaker encoder and paired text-audio data for training a Tacotron2-based synthesizer. The speaker encoder, optimized with Generative End2End loss, generates embeddings that capture the speaker's vocal identity, validated through Uniform Manifold Approximation and Projection (UMAP) for dimension reduction visualizations. These embeddings are fused with Tacotron2's text embeddings to produce mel-spectrograms, which are then converted into audio using a WaveRNN vocoder. Audio data were collected from various sources, including self-recordings, and underwent thorough preprocessing for quality and alignment. Training was performed using mel and gate loss functions under multiple hyperparameter settings. The system effectively clones speaker characteristics even for unseen voices, demonstrating the feasibility of few-shot voice cloning for the Nepali language and establishing a foundation for personalized speech synthesis in low-resource scenarios.",
    "published": "2026-01-26T17:10:17Z",
    "updated": "2026-01-26T17:10:17Z",
    "link": "http://arxiv.org/pdf/2601.18694v1.pdf",
    "category": [
      "cs.SD",
      "cs.AI"
    ],
    "authors": [
      "Aayush M. Shrestha",
      "Aditya Bajracharya",
      "Projan Shakya",
      "Dinesh B. Kshatri"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.16912v3",
    "title": "Exploration vs Exploitation: Rethinking RLVR through Clipping, Entropy, and Spurious Reward",
    "summary": "This paper examines the exploration-exploitation trade-off in reinforcement learning with verifiable rewards (RLVR), a framework for improving the reasoning of Large Language Models (LLMs). Recent studies suggest that RLVR can elicit strong mathematical reasoning in LLMs through two seemingly paradoxical mechanisms: spurious rewards, which suppress exploitation by rewarding outcomes unrelated to the ground truth, and entropy minimization, which suppresses exploration by pushing the model toward more confident and deterministic outputs, highlighting a puzzling dynamic: both discouraging exploitation and discouraging exploration improve reasoning performance, yet the underlying principles that reconcile these effects remain poorly understood. We focus on two fundamental questions: (i) how policy entropy relates to performance, and (ii) whether spurious rewards yield gains, potentially through the interplay of clipping bias and model contamination. Our results show that clipping bias under spurious rewards reduces policy entropy, leading to more confident and deterministic outputs, while entropy minimization alone is insufficient for improvement. We further propose a reward-misalignment model explaining why spurious rewards can enhance performance beyond contaminated settings. Our findings clarify the mechanisms behind spurious-reward benefits and provide principles for more effective RLVR training.",
    "published": "2025-12-18T18:59:27Z",
    "updated": "2026-01-26T17:06:02Z",
    "link": "http://arxiv.org/pdf/2512.16912v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Peter Chen",
      "Xiaopeng Li",
      "Ziniu Li",
      "Wotao Yin",
      "Xi Chen",
      "Tianyi Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.04886v2",
    "title": "Analyzing Message-Code Inconsistency in AI Coding Agent-Authored Pull Requests",
    "summary": "Pull request (PR) descriptions generated by AI coding agents are the primary channel for communicating code changes to human reviewers. However, the alignment between these messages and the actual changes remains unexplored, raising concerns about the trustworthiness of AI agents. To fill this gap, we analyzed 23,247 agentic PRs across five agents using PR message-code inconsistency (PR-MCI). We contributed 974 manually annotated PRs, found 406 PRs (1.7%) exhibited high PR-MCI, and identified eight PR-MCI types, revealing that \"descriptions claim unimplemented changes\" was the most common issue (45.4%). Statistical tests confirmed that high-MCI PRs had 51.7% lower acceptance rates (28.3% vs. 80.0%) and took 3.5 times longer to merge (55.8 vs. 16.0 hours). Our findings suggest that unreliable PR descriptions undermine trust in AI agents, highlighting the need for PR-MCI verification mechanisms and improved PR generation to enable trustworthy human-AI collaboration.",
    "published": "2026-01-08T12:31:02Z",
    "updated": "2026-01-26T17:05:34Z",
    "link": "http://arxiv.org/pdf/2601.04886v2.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Jingzhi Gong",
      "Giovanni Pinna",
      "Yixin Bian",
      "Jie M. Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.09101v2",
    "title": "Masked Generative Policy for Robotic Control",
    "summary": "We present Masked Generative Policy (MGP), a novel framework for visuomotor imitation learning. We represent actions as discrete tokens, and train a conditional masked transformer that generates tokens in parallel and then rapidly refines only low-confidence tokens. We further propose two new sampling paradigms: MGP-Short, which performs parallel masked generation with score-based refinement for Markovian tasks, and MGP-Long, which predicts full trajectories in a single pass and dynamically refines low-confidence action tokens based on new observations. With globally coherent prediction and robust adaptive execution capabilities, MGP-Long enables reliable control on complex and non-Markovian tasks that prior methods struggle with. Extensive evaluations on 150 robotic manipulation tasks spanning the Meta-World and LIBERO benchmarks show that MGP achieves both rapid inference and superior success rates compared to state-of-the-art diffusion and autoregressive policies. Specifically, MGP increases the average success rate by 9% across 150 tasks while cutting per-sequence inference time by up to 35x. It further improves the average success rate by 60% in dynamic and missing-observation environments, and solves two non-Markovian scenarios where other state-of-the-art methods fail.",
    "published": "2025-12-09T20:37:40Z",
    "updated": "2026-01-26T17:04:17Z",
    "link": "http://arxiv.org/pdf/2512.09101v2.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Lipeng Zhuang",
      "Shiyu Fan",
      "Florent P. Audonnet",
      "Yingdong Ru",
      "Edmond S. L. Ho",
      "Gerardo Aragon Camarasa",
      "Paul Henderson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18681v1",
    "title": "ART for Diffusion Sampling: A Reinforcement Learning Approach to Timestep Schedule",
    "summary": "We consider time discretization for score-based diffusion models to generate samples from a learned reverse-time dynamic on a finite grid. Uniform and hand-crafted grids can be suboptimal given a budget on the number of time steps. We introduce Adaptive Reparameterized Time (ART) that controls the clock speed of a reparameterized time variable, leading to a time change and uneven timesteps along the sampling trajectory while preserving the terminal time. The objective is to minimize the aggregate error arising from the discretized Euler scheme. We derive a randomized control companion, ART-RL, and formulate time change as a continuous-time reinforcement learning (RL) problem with Gaussian policies. We then prove that solving ART-RL recovers the optimal ART schedule, which in turn enables practical actor--critic updates to learn the latter in a data-driven way. Empirically, based on the official EDM pipeline, ART-RL improves Fréchet Inception Distance on CIFAR-10 over a wide range of budgets and transfers to AFHQv2, FFHQ, and ImageNet without the need of retraining.",
    "published": "2026-01-26T16:56:40Z",
    "updated": "2026-01-26T16:56:40Z",
    "link": "http://arxiv.org/pdf/2601.18681v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "eess.SY",
      "math.OC"
    ],
    "authors": [
      "Yilie Huang",
      "Wenpin Tang",
      "Xunyu Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18675v1",
    "title": "Learning temporal embeddings from electronic health records of chronic kidney disease patients",
    "summary": "We investigate whether temporal embedding models trained on longitudinal electronic health records can learn clinically meaningful representations without compromising predictive performance, and how architectural choices affect embedding quality. Model-guided medicine requires representations that capture disease dynamics while remaining transparent and task agnostic, whereas most clinical prediction models are optimised for a single task. Representation learning facilitates learning embeddings that generalise across downstream tasks, and recurrent architectures are well-suited for modelling temporal structure in observational clinical data. Using the MIMIC-IV dataset, we study patients with chronic kidney disease (CKD) and compare three recurrent architectures: a vanilla LSTM, an attention-augmented LSTM, and a time-aware LSTM (T-LSTM). All models are trained both as embedding models and as direct end-to-end predictors. Embedding quality is evaluated via CKD stage clustering and in-ICU mortality prediction. The T-LSTM produces more structured embeddings, achieving a lower Davies-Bouldin Index (DBI = 9.91) and higher CKD stage classification accuracy (0.74) than the vanilla LSTM (DBI = 15.85, accuracy = 0.63) and attention-augmented LSTM (DBI = 20.72, accuracy = 0.67). For in-ICU mortality prediction, embedding models consistently outperform end-to-end predictors, improving accuracy from 0.72-0.75 to 0.82-0.83, which indicates that learning embeddings as an intermediate step is more effective than direct end-to-end learning.",
    "published": "2026-01-26T16:50:50Z",
    "updated": "2026-01-26T16:50:50Z",
    "link": "http://arxiv.org/pdf/2601.18675v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Aditya Kumar",
      "Mario A. Cypko",
      "Oliver Amft"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.15436v2",
    "title": "Not Your Typical Sycophant: The Elusive Nature of Sycophancy in Large Language Models",
    "summary": "We propose a novel way to evaluate sycophancy of LLMs in a direct and neutral way, mitigating various forms of uncontrolled bias, noise, or manipulative language, deliberately injected to prompts in prior works. A key novelty in our approach is the use of LLM-as-a-judge, evaluation of sycophancy as a zero-sum game in a bet setting. Under this framework, sycophancy serves one individual (the user) while explicitly incurring cost on another. Comparing four leading models - Gemini 2.5 Pro, ChatGpt 4o, Mistral-Large-Instruct-2411, and Claude Sonnet 3.7 - we find that while all models exhibit sycophantic tendencies in the common setting, in which sycophancy is self-serving to the user and incurs no cost on others, Claude and Mistral exhibit \"moral remorse\" and over-compensate for their sycophancy in case it explicitly harms a third party. Additionally, we observed that all models are biased toward the answer proposed last. Crucially, we find that these two phenomena are not independent; sycophancy and recency bias interact to produce `constructive interference' effect, where the tendency to agree with the user is exacerbated when the user's opinion is presented last.",
    "published": "2026-01-21T20:00:14Z",
    "updated": "2026-01-26T16:45:31Z",
    "link": "http://arxiv.org/pdf/2601.15436v2.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "authors": [
      "Shahar Ben Natan",
      "Oren Tsur"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.13321v2",
    "title": "Adjust for Trust: Mitigating Trust-Induced Inappropriate Reliance on AI Assistance",
    "summary": "Trust biases how users rely on AI recommendations in AI-assisted decision-making tasks, with low and high levels of trust resulting in increased under- and over-reliance, respectively. We propose that AI assistants should adapt their behavior through trust-adaptive interventions to mitigate such inappropriate reliance. For instance, when user trust is low, providing an explanation can elicit more careful consideration of the assistant's advice by the user. In two decision-making scenarios -- laypeople answering science questions and doctors making medical diagnoses -- we find that providing supporting and counter-explanations during moments of low and high trust, respectively, yields up to 38% reduction in inappropriate reliance and 20% improvement in decision accuracy. We are similarly able to reduce over-reliance by adaptively inserting forced pauses to promote deliberation. Our results highlight how AI adaptation to user trust facilitates appropriate reliance, presenting exciting avenues for improving human-AI collaboration.",
    "published": "2025-02-18T22:42:39Z",
    "updated": "2026-01-26T16:35:39Z",
    "link": "http://arxiv.org/pdf/2502.13321v2.pdf",
    "category": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Tejas Srinivasan",
      "Jesse Thomason"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.10414v3",
    "title": "Is In-Context Learning Learning?",
    "summary": "In-context learning (ICL) allows some autoregressive models to solve tasks via next-token prediction and without needing further training. This has led to claims about these model's ability to solve (learn) unseen tasks with only a few shots (exemplars) in the prompt. However, deduction does not always imply learning, as ICL does not explicitly encode a given observation. Instead, the models rely on their prior knowledge and the exemplars given, if any. We argue that, mathematically, ICL does constitute learning, but its full characterisation requires empirical work. We then carry out a large-scale analysis of ICL ablating out or accounting for memorisation, pretraining, distributional shifts, and prompting style and phrasing. We find that ICL is an effective learning paradigm, but limited in its ability to learn and generalise to unseen tasks. We note that, in the limit where exemplars become more numerous, accuracy is insensitive to exemplar distribution, model, prompt style, and the input's linguistic features. Instead, it deduces patterns from regularities in the prompt, which leads to distributional sensitivity, especially in prompting styles such as chain-of-thought. Given the varied accuracies on formally similar tasks, we conclude that autoregression's ad-hoc encoding is not a robust mechanism, and suggests limited all-purpose generalisability.",
    "published": "2025-09-12T17:12:04Z",
    "updated": "2026-01-26T16:34:06Z",
    "link": "http://arxiv.org/pdf/2509.10414v3.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Adrian de Wynter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.14278v2",
    "title": "Beyond Data Privacy: New Privacy Risks for Large Language Models",
    "summary": "Large Language Models (LLMs) have achieved remarkable progress in natural language understanding, reasoning, and autonomous decision-making. However, these advancements have also come with significant privacy concerns. While significant research has focused on mitigating the data privacy risks of LLMs during various stages of model training, less attention has been paid to new threats emerging from their deployment. The integration of LLMs into widely used applications and the weaponization of their autonomous abilities have created new privacy vulnerabilities. These vulnerabilities provide opportunities for both inadvertent data leakage and malicious exfiltration from LLM-powered systems. Additionally, adversaries can exploit these systems to launch sophisticated, large-scale privacy attacks, threatening not only individual privacy but also financial security and societal trust. In this paper, we systematically examine these emerging privacy risks of LLMs. We also discuss potential mitigation strategies and call for the research community to broaden its focus beyond data privacy risks, developing new defenses to address the evolving threats posed by increasingly powerful LLMs and LLM-powered systems.",
    "published": "2025-09-16T09:46:09Z",
    "updated": "2026-01-26T16:30:10Z",
    "link": "http://arxiv.org/pdf/2509.14278v2.pdf",
    "category": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Yuntao Du",
      "Zitao Li",
      "Ninghui Li",
      "Bolin Ding"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.25178v2",
    "title": "GHOST: Hallucination-Inducing Image Generation for Multimodal LLMs",
    "summary": "Object hallucination in Multimodal Large Language Models (MLLMs) is a persistent failure mode that causes the model to perceive objects absent in the image. This weakness of MLLMs is currently studied using static benchmarks with fixed visual scenarios, which preempts the possibility of uncovering model-specific or unanticipated hallucination vulnerabilities. We introduce GHOST (Generating Hallucinations via Optimizing Stealth Tokens), a method designed to stress-test MLLMs by actively generating images that induce hallucination. GHOST is fully automatic and requires no human supervision or prior knowledge. It operates by optimizing in the image embedding space to mislead the model while keeping the target object absent, and then guiding a diffusion model conditioned on the embedding to generate natural-looking images. The resulting images remain visually natural and close to the original input, yet introduce subtle misleading cues that cause the model to hallucinate. We evaluate our method across a range of models, including reasoning models like GLM-4.1V-Thinking, and achieve a hallucination success rate exceeding 28%, compared to around 1% in prior data-driven discovery methods. We confirm that the generated images are both high-quality and object-free through quantitative metrics and human evaluation. Also, GHOST uncovers transferable vulnerabilities: images optimized for Qwen2.5-VL induce hallucinations in GPT-4o at a 66.5% rate. Finally, we show that fine-tuning on our images mitigates hallucination, positioning GHOST as both a diagnostic and corrective tool for building more reliable multimodal systems.",
    "published": "2025-09-29T17:59:23Z",
    "updated": "2026-01-26T16:30:01Z",
    "link": "http://arxiv.org/pdf/2509.25178v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Aryan Yazdan Parast",
      "Parsa Hosseini",
      "Hesam Asadollahzadeh",
      "Arshia Soltani Moakhar",
      "Basim Azam",
      "Soheil Feizi",
      "Naveed Akhtar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.06822v2",
    "title": "RAFFLES: Reasoning-based Attribution of Faults for LLM Systems",
    "summary": "The advent of complex, interconnected long-horizon LLM systems has made it incredibly tricky to identify where and when these systems break down. Evaluation capabilities that currently exist today are limited in that they often focus on simple metrics, end-to-end outcomes, and are dependent on the perspectives of humans. In order to match the increasing complexity of these many component systems, evaluation frameworks must also be able to reason, probe, iterate, and understand the nuanced logic passing through these systems. In this paper, we present RAFFLES, an offline evaluation architecture that incorporates iterative reasoning. Specifically, RAFFLES operates as an iterative, multi-component pipeline, using a central Judge to systematically identify faults and a set of specialized Evaluators to assess the quality of the candidate faults as well as rationales of the Judge. We evaluated RAFFLES with several benchmarks - the Who&When dataset to identify step-level faults in multi-agent systems and the ReasonEval datasets to diagnose step-level mathematical reasoning errors. RAFFLES outperforms strong baselines, achieving an accuracy of over 20% and 50% on the Who&When Hand-Crafted and Algorithmically-Generated datasets, and over 80% on the ReasonEval datasets. These results demonstrate a key step towards introducing automated fault detection for autonomous systems over labor-intensive manual review.",
    "published": "2025-09-08T15:57:14Z",
    "updated": "2026-01-26T16:25:46Z",
    "link": "http://arxiv.org/pdf/2509.06822v2.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Chenyang Zhu",
      "Spencer Hong",
      "Jingyu Wu",
      "Kushal Chawla",
      "Charlotte Tang",
      "Youbing Yin",
      "Nathan Wolfe",
      "Erin Babinsky",
      "Daben Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18650v1",
    "title": "FaLW: A Forgetting-aware Loss Reweighting for Long-tailed Unlearning",
    "summary": "Machine unlearning, which aims to efficiently remove the influence of specific data from trained models, is crucial for upholding data privacy regulations like the ``right to be forgotten\". However, existing research predominantly evaluates unlearning methods on relatively balanced forget sets. This overlooks a common real-world scenario where data to be forgotten, such as a user's activity records, follows a long-tailed distribution. Our work is the first to investigate this critical research gap. We find that in such long-tailed settings, existing methods suffer from two key issues: \\textit{Heterogeneous Unlearning Deviation} and \\textit{Skewed Unlearning Deviation}. To address these challenges, we propose FaLW, a plug-and-play, instance-wise dynamic loss reweighting method. FaLW innovatively assesses the unlearning state of each sample by comparing its predictive probability to the distribution of unseen data from the same class. Based on this, it uses a forgetting-aware reweighting scheme, modulated by a balancing factor, to adaptively adjust the unlearning intensity for each sample. Extensive experiments demonstrate that FaLW achieves superior performance. Code is available at \\textbf{Supplementary Material}.",
    "published": "2026-01-26T16:21:01Z",
    "updated": "2026-01-26T16:21:01Z",
    "link": "http://arxiv.org/pdf/2601.18650v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Liheng Yu",
      "Zhe Zhao",
      "Yuxuan Wang",
      "Pengkun Wang",
      "Binwu Wang",
      "Yang Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.06574v3",
    "title": "On the Impact of the Utility in Semivalue-based Data Valuation",
    "summary": "Semivalue-based data valuation uses cooperative-game theory intuitions to assign each data point a value reflecting its contribution to a downstream task. Still, those values depend on the practitioner's choice of utility, raising the question: How robust is semivalue-based data valuation to changes in the utility? This issue is critical when the utility is set as a trade-off between several criteria and when practitioners must select among multiple equally valid utilities. We address it by introducing the notion of a dataset's spatial signature: given a semivalue, we embed each data point into a lower-dimensional space where any utility becomes a linear functional, making the data valuation framework amenable to a simpler geometric picture. Building on this, we propose a practical methodology centered on an explicit robustness metric that informs practitioners whether and by how much their data valuation results will shift as the utility changes. We validate this approach across diverse datasets and semivalues, demonstrating strong agreement with rank-correlation analyses and offering analytical insight into how choosing a semivalue can amplify or diminish robustness.",
    "published": "2025-02-10T15:42:38Z",
    "updated": "2026-01-26T16:18:37Z",
    "link": "http://arxiv.org/pdf/2502.06574v3.pdf",
    "category": [
      "cs.AI",
      "cs.GT",
      "cs.LG"
    ],
    "authors": [
      "Mélissa Tamine",
      "Benjamin Heymann",
      "Patrick Loiseau",
      "Maxime Vono"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2408.08055v5",
    "title": "DeNOTS: Stable Deep Neural ODEs for Time Series",
    "summary": "Neural CDEs provide a natural way to process the temporal evolution of irregular time series. The number of function evaluations (NFE) is these systems' natural analog of depth (the number of layers in traditional neural networks). It is usually regulated via solver error tolerance: lower tolerance means higher numerical precision, requiring more integration steps. However, lowering tolerances does not adequately increase the models' expressiveness. We propose a simple yet effective alternative: scaling the integration time horizon to increase NFEs and \"deepen`` the model. Increasing the integration interval causes uncontrollable growth in conventional vector fields, so we also propose a way to stabilize the dynamics via Negative Feedback (NF). It ensures provable stability without constraining flexibility. It also implies robustness: we provide theoretical bounds for Neural ODE risk using Gaussian process theory. Experiments on four open datasets demonstrate that our method, DeNOTS, outperforms existing approaches~ -- ~including recent Neural RDEs and state space models,~ -- ~achieving up to $20\\%$ improvement in metrics. DeNOTS combines expressiveness, stability, and robustness, enabling reliable modelling in continuous-time domains.",
    "published": "2024-08-15T09:49:37Z",
    "updated": "2026-01-26T16:17:44Z",
    "link": "http://arxiv.org/pdf/2408.08055v5.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Ilya Kuleshov",
      "Evgenia Romanenkova",
      "Vladislav Zhuzhel",
      "Galina Boeva",
      "Evgeni Vorsin",
      "Alexey Zaytsev"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.08091v2",
    "title": "Gateways to Tractability for Satisfiability in Pearl's Causal Hierarchy",
    "summary": "Pearl's Causal Hierarchy (PCH) is a central framework for reasoning about probabilistic, interventional, and counterfactual statements, yet the satisfiability problem for PCH formulas is computationally intractable in almost all classical settings. We revisit this challenge through the lens of parameterized complexity and identify the first gateways to tractability. Our results include fixed-parameter and XP-algorithms for satisfiability in key probabilistic and counterfactual fragments, using parameters such as primal treewidth and the number of variables, together with matching hardness results that map the limits of tractability. Technically, we depart from the dynamic programming paradigm typically employed for treewidth-based algorithms and instead exploit structural characterizations of well-formed causal models, providing a new algorithmic toolkit for causal reasoning.",
    "published": "2025-11-11T10:45:03Z",
    "updated": "2026-01-26T16:14:32Z",
    "link": "http://arxiv.org/pdf/2511.08091v2.pdf",
    "category": [
      "cs.AI",
      "cs.CC"
    ],
    "authors": [
      "Robert Ganian",
      "Marlene Gründel",
      "Simon Wietheger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18642v1",
    "title": "FadeMem: Biologically-Inspired Forgetting for Efficient Agent Memory",
    "summary": "Large language models deployed as autonomous agents face critical memory limitations, lacking selective forgetting mechanisms that lead to either catastrophic forgetting at context boundaries or information overload within them. While human memory naturally balances retention and forgetting through adaptive decay processes, current AI systems employ binary retention strategies that preserve everything or lose it entirely. We propose FadeMem, a biologically-inspired agent memory architecture that incorporates active forgetting mechanisms mirroring human cognitive efficiency. FadeMem implements differential decay rates across a dual-layer memory hierarchy, where retention is governed by adaptive exponential decay functions modulated by semantic relevance, access frequency, and temporal patterns. Through LLM-guided conflict resolution and intelligent memory fusion, our system consolidates related information while allowing irrelevant details to fade. Experiments on Multi-Session Chat, LoCoMo, and LTI-Bench demonstrate superior multi-hop reasoning and retrieval with 45\\% storage reduction, validating the effectiveness of biologically-inspired forgetting in agent memory systems.",
    "published": "2026-01-26T16:12:54Z",
    "updated": "2026-01-26T16:12:54Z",
    "link": "http://arxiv.org/pdf/2601.18642v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Lei Wei",
      "Xu Dong",
      "Xiao Peng",
      "Niantao Xie",
      "Bin Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18641v1",
    "title": "Unheard in the Digital Age: Rethinking AI Bias and Speech Diversity",
    "summary": "Speech remains one of the most visible yet overlooked vectors of inclusion and exclusion in contemporary society. While fluency is often equated with credibility and competence, individuals with atypical speech patterns are routinely marginalized. Given the current state of the debate, this article focuses on the structural biases that shape perceptions of atypical speech and are now being encoded into artificial intelligence. Automated speech recognition (ASR) systems and voice interfaces, trained predominantly on standardized speech, routinely fail to recognize or respond to diverse voices, compounding digital exclusion. As AI technologies increasingly mediate access to opportunity, the study calls for inclusive technological design, anti-bias training to minimize the impact of discriminatory algorithmic decisions, and enforceable policy reform that explicitly recognize speech diversity as a matter of equity, not merely accessibility. Drawing on interdisciplinary research, the article advocates for a cultural and institutional shift in how we value voice, urging co-created solutions that elevate the rights, representation, and realities of atypical speakers in the digital age. Ultimately, the article reframes speech inclusion as a matter of equity (not accommodation) and advocates for co-created AI systems that reflect the full spectrum of human voices.",
    "published": "2026-01-26T16:12:25Z",
    "updated": "2026-01-26T16:12:25Z",
    "link": "http://arxiv.org/pdf/2601.18641v1.pdf",
    "category": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "authors": [
      "Onyedikachi Hope Amaechi-Okorie",
      "Branislav Radeljic"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18631v1",
    "title": "AdaReasoner: Dynamic Tool Orchestration for Iterative Visual Reasoning",
    "summary": "When humans face problems beyond their immediate capabilities, they rely on tools, providing a promising paradigm for improving visual reasoning in multimodal large language models (MLLMs). Effective reasoning, therefore, hinges on knowing which tools to use, when to invoke them, and how to compose them over multiple steps, even when faced with new tools or new tasks. We introduce \\textbf{AdaReasoner}, a family of multimodal models that learn tool use as a general reasoning skill rather than as tool-specific or explicitly supervised behavior. AdaReasoner is enabled by (i) a scalable data curation pipeline exposing models to long-horizon, multi-step tool interactions; (ii) Tool-GRPO, a reinforcement learning algorithm that optimizes tool selection and sequencing based on end-task success; and (iii) an adaptive learning mechanism that dynamically regulates tool usage. Together, these components allow models to infer tool utility from task context and intermediate outcomes, enabling coordination of multiple tools and generalization to unseen tools. Empirically, AdaReasoner exhibits strong tool-adaptive and generalization behaviors: it autonomously adopts beneficial tools, suppresses irrelevant ones, and adjusts tool usage frequency based on task demands, despite never being explicitly trained to do so. These capabilities translate into state-of-the-art performance across challenging benchmarks, improving the 7B base model by +24.9\\% on average and surpassing strong proprietary systems such as GPT-5 on multiple tasks, including VSP and Jigsaw.",
    "published": "2026-01-26T16:04:43Z",
    "updated": "2026-01-26T16:04:43Z",
    "link": "http://arxiv.org/pdf/2601.18631v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.MA"
    ],
    "authors": [
      "Mingyang Song",
      "Haoyu Sun",
      "Jiawei Gu",
      "Linjie Li",
      "Luxin Xu",
      "Ranjay Krishna",
      "Yu Cheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18630v1",
    "title": "Assessing the Quality of Mental Health Support in LLM Responses through Multi-Attribute Human Evaluation",
    "summary": "The escalating global mental health crisis, marked by persistent treatment gaps, availability, and a shortage of qualified therapists, positions Large Language Models (LLMs) as a promising avenue for scalable support. While LLMs offer potential for accessible emotional assistance, their reliability, therapeutic relevance, and alignment with human standards remain challenging to address. This paper introduces a human-grounded evaluation methodology designed to assess LLM generated responses in therapeutic dialogue. Our approach involved curating a dataset of 500 mental health conversations from datasets with real-world scenario questions and evaluating the responses generated by nine diverse LLMs, including closed source and open source models. More specifically, these responses were evaluated by two psychiatric trained experts, who independently rated each on a 5 point Likert scale across a comprehensive 6 attribute rubric. This rubric captures Cognitive Support and Affective Resonance, providing a multidimensional perspective on therapeutic quality. Our analysis reveals that LLMs provide strong cognitive reliability by producing safe, coherent, and clinically appropriate information, but they demonstrate unstable affective alignment. Although closed source models (e.g., GPT-4o) offer balanced therapeutic responses, open source models show greater variability and emotional flatness. We reveal a persistent cognitive-affective gap and highlight the need for failure aware, clinically grounded evaluation frameworks that prioritize relational sensitivity alongside informational accuracy in mental health oriented LLMs. We advocate for balanced evaluation protocols with human in the loop that center on therapeutic sensitivity and provide a framework to guide the responsible design and clinical oversight of mental health oriented conversational AI.",
    "published": "2026-01-26T16:04:19Z",
    "updated": "2026-01-26T16:04:19Z",
    "link": "http://arxiv.org/pdf/2601.18630v1.pdf",
    "category": [
      "cs.AI",
      "cs.HC"
    ],
    "authors": [
      "Abeer Badawi",
      "Md Tahmid Rahman Laskar",
      "Elahe Rahimi",
      "Sheri Grach",
      "Lindsay Bertrand",
      "Lames Danok",
      "Frank Rudzicz",
      "Jimmy Huang",
      "Elham Dolatabadi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18626v1",
    "title": "Rank-1 Approximation of Inverse Fisher for Natural Policy Gradients in Deep Reinforcement Learning",
    "summary": "Natural gradients have long been studied in deep reinforcement learning due to their fast convergence properties and covariant weight updates. However, computing natural gradients requires inversion of the Fisher Information Matrix (FIM) at each iteration, which is computationally prohibitive in nature. In this paper, we present an efficient and scalable natural policy optimization technique that leverages a rank-1 approximation to full inverse-FIM. We theoretically show that under certain conditions, a rank-1 approximation to inverse-FIM converges faster than policy gradients and, under some conditions, enjoys the same sample complexity as stochastic policy gradient methods. We benchmark our method on a diverse set of environments and show that it achieves superior performance to standard actor-critic and trust-region baselines.",
    "published": "2026-01-26T16:02:18Z",
    "updated": "2026-01-26T16:02:18Z",
    "link": "http://arxiv.org/pdf/2601.18626v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "authors": [
      "Yingxiao Huo",
      "Satya Prakash Dash",
      "Radu Stoican",
      "Samuel Kaski",
      "Mingfei Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.14724v2",
    "title": "HERMES: KV Cache as Hierarchical Memory for Efficient Streaming Video Understanding",
    "summary": "Recent advancements in Multimodal Large Language Models (MLLMs) have demonstrated significant improvement in offline video understanding. However, extending these capabilities to streaming video inputs, remains challenging, as existing models struggle to simultaneously maintain stable understanding performance, real-time responses, and low GPU memory overhead. To address this challenge, we propose HERMES, a novel training-free architecture for real-time and accurate understanding of video streams. Based on a mechanistic attention investigation, we conceptualize KV cache as a hierarchical memory framework that encapsulates video information across multiple granularities. During inference, HERMES reuses a compact KV cache, enabling efficient streaming understanding under resource constraints. Notably, HERMES requires no auxiliary computations upon the arrival of user queries, thereby guaranteeing real-time responses for continuous video stream interactions, which achieves 10$\\times$ faster TTFT compared to prior SOTA. Even when reducing video tokens by up to 68% compared with uniform sampling, HERMES achieves superior or comparable accuracy across all benchmarks, with up to 11.4% gains on streaming datasets.",
    "published": "2026-01-21T07:26:15Z",
    "updated": "2026-01-26T15:57:42Z",
    "link": "http://arxiv.org/pdf/2601.14724v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Haowei Zhang",
      "Shudong Yang",
      "Jinlan Fu",
      "See-Kiong Ng",
      "Xipeng Qiu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.08641v2",
    "title": "Resisting Manipulative Bots in Meme Coin Copy Trading: A Multi-Agent Approach with Chain-of-Thought Reasoning",
    "summary": "Copy trading has become the dominant entry strategy in meme coin markets. However, due to the market's extreme illiquid and volatile nature, the strategy exposes an exploitable attack surface: adversaries deploy manipulative bots to front-run trades, conceal positions, and fabricate sentiment, systematically extracting value from naïve copiers at scale. Despite its prevalence, bot-driven manipulation remains largely unexplored, and no robust defensive framework exists. We propose a manipulation-resistant copy-trading system based on a multi-agent architecture powered by a multi-modal, explainable large language model (LLM). Our system decomposes copy trading into three specialized agents for coin evaluation, wallet selection, and timing assessment. Evaluated on historical data from over 6,000 meme coins, our approach outperforms zero-shot and most statistic-driven baselines in prediction accuracy as well as all baselines in economic performance, achieving an average return of 14% for identified smart-money trades and an estimated copier return of 3% per trade under realistic market frictions. Overall, our results demonstrate the effectiveness of agent-based defenses and predictability of trader profitability in adversarial meme coin markets, providing a practical foundation for robust copy trading.",
    "published": "2026-01-13T15:13:41Z",
    "updated": "2026-01-26T15:57:36Z",
    "link": "http://arxiv.org/pdf/2601.08641v2.pdf",
    "category": [
      "cs.AI",
      "q-fin.TR"
    ],
    "authors": [
      "Yichen Luo",
      "Yebo Feng",
      "Jiahua Xu",
      "Yang Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.11480v2",
    "title": "Cross-Platform Scaling of Vision-Language-Action Models from Edge to Cloud GPUs",
    "summary": "Vision-Language-Action (VLA) models have emerged as powerful generalist policies for robotic control, yet their performance scaling across model architectures and hardware platforms, as well as their associated power budgets, remain poorly understood. This work presents an evaluation of five representative VLA models -- spanning state-of-the-art baselines and two newly proposed architectures -- targeting edge and datacenter GPU platforms. Using the LIBERO benchmark, we measure accuracy alongside system-level metrics, including latency, throughput, and peak memory usage, under varying edge power constraints and high-performance datacenter GPU configurations. Our results identify distinct scaling trends: (1) architectural choices, such as action tokenization and model backbone size, strongly influence throughput and memory footprint; (2) power-constrained edge devices exhibit non-linear performance degradation, with some configurations matching or exceeding older datacenter GPUs; and (3) high-throughput variants can be achieved without significant accuracy loss. These findings provide actionable insights when selecting and optimizing VLAs across a range of deployment constraints. Our work challenges current assumptions about the superiority of datacenter hardware for robotic inference.",
    "published": "2025-09-15T00:00:37Z",
    "updated": "2026-01-26T15:57:20Z",
    "link": "http://arxiv.org/pdf/2509.11480v2.pdf",
    "category": [
      "cs.AI",
      "cs.CV",
      "cs.ET",
      "cs.LG",
      "cs.RO"
    ],
    "authors": [
      "Amir Taherin",
      "Juyi Lin",
      "Arash Akbari",
      "Arman Akbari",
      "Pu Zhao",
      "Weiwei Chen",
      "David Kaeli",
      "Yanzhi Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18617v1",
    "title": "Emergence of Phonemic, Syntactic, and Semantic Representations in Artificial Neural Networks",
    "summary": "During language acquisition, children successively learn to categorize phonemes, identify words, and combine them with syntax to form new meaning. While the development of this behavior is well characterized, we still lack a unifying computational framework to explain its underlying neural representations. Here, we investigate whether and when phonemic, lexical, and syntactic representations emerge in the activations of artificial neural networks during their training. Our results show that both speech- and text-based models follow a sequence of learning stages: during training, their neural activations successively build subspaces, where the geometry of the neural activations represents phonemic, lexical, and syntactic structure. While this developmental trajectory qualitatively relates to children's, it is quantitatively different: These algorithms indeed require two to four orders of magnitude more data for these neural representations to emerge. Together, these results show conditions under which major stages of language acquisition spontaneously emerge, and hence delineate a promising path to understand the computations underpinning language acquisition.",
    "published": "2026-01-26T15:56:41Z",
    "updated": "2026-01-26T15:56:41Z",
    "link": "http://arxiv.org/pdf/2601.18617v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Pierre Orhan",
      "Pablo Diego-Simón",
      "Emmnanuel Chemla",
      "Yair Lakretz",
      "Yves Boubenec",
      "Jean-Rémi King"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18608v1",
    "title": "PolySHAP: Extending KernelSHAP with Interaction-Informed Polynomial Regression",
    "summary": "Shapley values have emerged as a central game-theoretic tool in explainable AI (XAI). However, computing Shapley values exactly requires $2^d$ game evaluations for a model with $d$ features. Lundberg and Lee's KernelSHAP algorithm has emerged as a leading method for avoiding this exponential cost. KernelSHAP approximates Shapley values by approximating the game as a linear function, which is fit using a small number of game evaluations for random feature subsets.\n  In this work, we extend KernelSHAP by approximating the game via higher degree polynomials, which capture non-linear interactions between features. Our resulting PolySHAP method yields empirically better Shapley value estimates for various benchmark datasets, and we prove that these estimates are consistent.\n  Moreover, we connect our approach to paired sampling (antithetic sampling), a ubiquitous modification to KernelSHAP that improves empirical accuracy. We prove that paired sampling outputs exactly the same Shapley value approximations as second-order PolySHAP, without ever fitting a degree 2 polynomial. To the best of our knowledge, this finding provides the first strong theoretical justification for the excellent practical performance of the paired sampling heuristic.",
    "published": "2026-01-26T15:47:45Z",
    "updated": "2026-01-26T15:47:45Z",
    "link": "http://arxiv.org/pdf/2601.18608v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Fabian Fumagalli",
      "R. Teal Witter",
      "Christopher Musco"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.17466v3",
    "title": "Autiverse: Eliciting Autistic Adolescents' Daily Narratives through AI-guided Multimodal Journaling",
    "summary": "Journaling can potentially serve as an effective method for autistic adolescents to improve narrative skills. However, its text-centric nature and high executive functioning demands present barriers to practice. We present Autiverse, an AI-guided multimodal journaling app for tablets that scaffolds daily narratives through conversational prompts and visual supports. Autiverse elicits key details of an adolescent-selected event through a stepwise dialogue with peer-like, customizable AI and composes them into an editable four-panel comic strip. Through a two-week deployment study with 10 autistic adolescent-parent dyads, we examine how Autiverse supports autistic adolescents to organize their daily experience and emotion. Our findings show Autiverse scaffolded adolescents' coherent narratives, while enabling parents to learn additional details of their child's events and emotions. Moreover, the customized AI peer created a comfortable space for sharing, fostering enjoyment and a strong sense of agency. Drawing on these results, we discuss implications for adaptive scaffolding across autism profiles, socio-emotionally appropriate AI peer design, and balancing autonomy with parental involvement.",
    "published": "2025-09-22T08:02:09Z",
    "updated": "2026-01-26T15:44:08Z",
    "link": "http://arxiv.org/pdf/2509.17466v3.pdf",
    "category": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Migyeong Yang",
      "Kyungah Lee",
      "Jinyoung Han",
      "SoHyun Park",
      "Young-Ho Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.13805v3",
    "title": "Towards a Physics Foundation Model",
    "summary": "Foundation models have revolutionized natural language processing through a ``train once, deploy anywhere'' paradigm, where a single pre-trained model adapts to countless downstream tasks without retraining. Access to a Physics Foundation Model (PFM) would be transformative - democratizing access to high-fidelity simulations, accelerating scientific discovery, and eliminating the need for specialized solver development. Yet current physics-aware machine learning approaches remain fundamentally limited to single, narrow domains and require retraining for each new system. We present the General Physics Transformer (GPhyT), trained on 1.8 TB of diverse simulation data, that demonstrates foundation model capabilities are achievable for physics. Our key insight is that transformers can learn to infer governing dynamics from context, enabling a single model to simulate fluid-solid interactions, shock waves, thermal convection, and multi-phase dynamics without being told the underlying equations. GPhyT achieves three critical breakthroughs: (1) superior performance across multiple physics domains, outperforming specialized architectures by more than 7x, (2) plausible zero-shot generalization to entirely unseen physical systems through in-context learning, and (3) more stable long-term predictions through long-horizon rollouts. By establishing that a single model can learn generalizable physical principles from data alone, this work opens the path toward a universal PFM that could transform computational science and engineering.",
    "published": "2025-09-17T08:19:57Z",
    "updated": "2026-01-26T15:42:33Z",
    "link": "http://arxiv.org/pdf/2509.13805v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "authors": [
      "Florian Wiesner",
      "Matthias Wessling",
      "Stephen Baek"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18595v1",
    "title": "A Balanced Neuro-Symbolic Approach for Commonsense Abductive Logic",
    "summary": "Although Large Language Models (LLMs) have demonstrated impressive formal reasoning abilities, they often break down when problems require complex proof planning. One promising approach for improving LLM reasoning abilities involves translating problems into formal logic and using a logic solver. Although off-the-shelf logic solvers are in principle substantially more efficient than LLMs at logical reasoning, they assume that all relevant facts are provided in a question and are unable to deal with missing commonsense relations. In this work, we propose a novel method that uses feedback from the logic solver to augment a logic problem with commonsense relations provided by the LLM, in an iterative manner. This involves a search procedure through potential commonsense assumptions to maximize the chance of finding useful facts while keeping cost tractable. On a collection of pure-logical reasoning datasets, from which some commonsense information has been removed, our method consistently achieves considerable improvements over existing techniques, demonstrating the value in balancing neural and symbolic elements when working in human contexts.",
    "published": "2026-01-26T15:40:26Z",
    "updated": "2026-01-26T15:40:26Z",
    "link": "http://arxiv.org/pdf/2601.18595v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Joseph Cotnareanu",
      "Didier Chetelat",
      "Yingxue Zhang",
      "Mark Coates"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.19008v2",
    "title": "Computational Phenomenology of Borderline Personality Disorder: A Comparative Evaluation of LLM-Simulated Expert Personas and Human Clinical Experts",
    "summary": "Building on a human-led thematic analysis of life-story interviews with inpatients with Borderline Personality Disorder, this study examines the capacity of large language models (OpenAI's GPT, Google's Gemini, and Anthropic's Claude) to support qualitative clinical analysis. The models were evaluated through a mixed procedure. Study A involved blinded and non-blinded expert judges in phenomenology and clinical psychology. Assessments included semantic congruence, Jaccard coefficients for overlap of outputs, multidimensional validity ratings of credibility, coherence, and the substantiveness of results, and their grounding in qualitative data. In Study B, neural methods were used to embed the theme descriptions created by humans and the models in a two-dimensional vector space to provide a computational measure of the difference between human and model semantics and linguistic style. In Study C, complementary non-expert evaluations were conducted to examine the influence of thematic verbosity on the perception of human authorship and content validity. Results of all three studies revealed variable overlap with the human analysis, with models being partly indistinguishable from, and also identifying themes originally omitted by, human researchers. The findings highlight both the variability and potential of AI-augmented thematic qualitative analysis to mitigate human interpretative bias and enhance sensitivity.",
    "published": "2025-08-26T13:13:47Z",
    "updated": "2026-01-26T15:37:22Z",
    "link": "http://arxiv.org/pdf/2508.19008v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Marcin Moskalewicz",
      "Anna Sterna",
      "Karolina Drożdż",
      "Kacper Dudzic",
      "Marek Pokropski",
      "Paula Flores"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18588v1",
    "title": "Stability as a Liability:Systematic Breakdown of Linguistic Structure in LLMs",
    "summary": "Training stability is typically regarded as a prerequisite for reliable optimization in large language models. In this work, we analyze how stabilizing training dynamics affects the induced generation distribution. We show that under standard maximum likelihood training, stable parameter trajectories lead stationary solutions to approximately minimize the forward KL divergence to the empirical distribution, while implicitly reducing generative entropy. As a consequence, the learned model can concentrate probability mass on a limited subset of empirical modes, exhibiting systematic degeneration despite smooth loss convergence. We empirically validate this effect using a controlled feedback-based training framework that stabilizes internal generation statistics, observing consistent low-entropy outputs and repetitive behavior across architectures and random seeds. It indicates that optimization stability and generative expressivity are not inherently aligned, and that stability alone is an insufficient indicator of generative quality.",
    "published": "2026-01-26T15:34:50Z",
    "updated": "2026-01-26T15:34:50Z",
    "link": "http://arxiv.org/pdf/2601.18588v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Xianzhe Meng",
      "Qiangsheng Zeng",
      "Ling Luo",
      "Qinghan Yang",
      "Jiarui Hao",
      "Wenbo Wu",
      "Qinyu Wang",
      "Rui Yin",
      "Lin Qi",
      "Renzhi Lu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18586v1",
    "title": "Learning long term climate-resilient transport adaptation pathways under direct and indirect flood impacts using reinforcement learning",
    "summary": "Climate change is expected to intensify rainfall and other hazards, increasing disruptions in urban transportation systems. Designing effective adaptation strategies is challenging due to the long-term, sequential nature of infrastructure investments, deep uncertainty, and complex cross-sector interactions. We propose a generic decision-support framework that couples an integrated assessment model (IAM) with reinforcement learning (RL) to learn adaptive, multi-decade investment pathways under uncertainty. The framework combines long-term climate projections (e.g., IPCC scenario pathways) with models that map projected extreme-weather drivers (e.g. rain) into hazard likelihoods (e.g. flooding), propagate hazards into urban infrastructure impacts (e.g. transport disruption), and value direct and indirect consequences for service performance and societal costs. Embedded in a reinforcement-learning loop, it learns adaptive climate adaptation policies that trade off investment and maintenance expenditures against avoided impacts. In collaboration with Copenhagen Municipality, we demonstrate the approach on pluvial flooding in the inner city for the horizon of 2024 to 2100. The learned strategies yield coordinated spatial-temporal pathways and improved robustness relative to conventional optimization baselines, namely inaction and random action, illustrating the framework's transferability to other hazards and cities.",
    "published": "2026-01-26T15:32:40Z",
    "updated": "2026-01-26T15:32:40Z",
    "link": "http://arxiv.org/pdf/2601.18586v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Miguel Costa",
      "Arthur Vandervoort",
      "Carolin Schmidt",
      "Morten W. Petersen",
      "Martin Drews",
      "Karyn Morrissey",
      "Francisco C. Pereira"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18579v1",
    "title": "FastInsight: Fast and Insightful Retrieval via Fusion Operators for Graph RAG",
    "summary": "Existing Graph RAG methods aiming for insightful retrieval on corpus graphs typically rely on time-intensive processes that interleave Large Language Model (LLM) reasoning. To enable time-efficient insightful retrieval, we propose FastInsight. We first introduce a graph retrieval taxonomy that categorizes existing methods into three fundamental operations: vector search, graph search, and model-based search. Through this taxonomy, we identify two critical limitations in current approaches: the topology-blindness of model-based search and the semantics-blindness of graph search. FastInsight overcomes these limitations by interleaving two novel fusion operators: the Graph-based Reranker (GRanker), which functions as a graph model-based search, and Semantic-Topological eXpansion (STeX), which operates as a vector-graph search. Extensive experiments on broad retrieval and generation datasets demonstrate that FastInsight significantly improves both retrieval accuracy and generation quality compared to state-of-the-art baselines, achieving a substantial Pareto improvement in the trade-off between effectiveness and efficiency.",
    "published": "2026-01-26T15:23:41Z",
    "updated": "2026-01-26T15:23:41Z",
    "link": "http://arxiv.org/pdf/2601.18579v1.pdf",
    "category": [
      "cs.IR",
      "cs.AI"
    ],
    "authors": [
      "Seonho An",
      "Chaejeong Hyun",
      "Min-Soo Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.04564v6",
    "title": "Fundamental Limits of Hierarchical Secure Aggregation with Cyclic User Association",
    "summary": "Secure aggregation is motivated by federated learning (FL) where a cloud server aims to compute an {aggregated} model (i.e., weights of deep neural networks) of the locally-trained models of numerous clients {through an iterative communication process}, while adhering to data security requirements. Hierarchical secure aggregation (HSA) extends this concept to a three-layer hierarchical network, where clustered users communicate with the server through an intermediate layer of relays. In HSA, beyond conventional server security, relay security is also enforced to ensure that the relays remain oblivious to the users' inputs (an abstraction of the local models in FL). {Existing studies on HSA that jointly consider communication and secret key generation efficiency typically assume that each user is associated with only one relay, limiting opportunities for coding across inter-cluster users to achieve efficient communication and key generation.} In this paper, we consider HSA with a cyclic association pattern where each user is connected to $B$ consecutive relays in a wrap-around manner. We propose an efficient aggregation scheme which includes a message design for the inputs inspired by gradient coding-a well-known technique for efficient communication in distributed computing-along with a highly non-trivial security key design.",
    "published": "2025-03-06T15:53:37Z",
    "updated": "2026-01-26T15:19:58Z",
    "link": "http://arxiv.org/pdf/2503.04564v6.pdf",
    "category": [
      "cs.IT",
      "cs.AI",
      "cs.CR",
      "cs.DC"
    ],
    "authors": [
      "Xiang Zhang",
      "Zhou Li",
      "Kai Wan",
      "Hua Sun",
      "Mingyue Ji",
      "Giuseppe Caire"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18569v1",
    "title": "Attention-Based Neural-Augmented Kalman Filter for Legged Robot State Estimation",
    "summary": "In this letter, we propose an Attention-Based Neural-Augmented Kalman Filter (AttenNKF) for state estimation in legged robots. Foot slip is a major source of estimation error: when slip occurs, kinematic measurements violate the no-slip assumption and inject bias during the update step. Our objective is to estimate this slip-induced error and compensate for it. To this end, we augment an Invariant Extended Kalman Filter (InEKF) with a neural compensator that uses an attention mechanism to infer error conditioned on foot-slip severity and then applies this estimate as a post-update compensation to the InEKF state (i.e., after the filter update). The compensator is trained in a latent space, which aims to reduce sensitivity to raw input scales and encourages structured slip-conditioned compensations, while preserving the InEKF recursion. Experiments demonstrate improved performance compared to existing legged-robot state estimators, particularly under slip-prone conditions.",
    "published": "2026-01-26T15:13:36Z",
    "updated": "2026-01-26T15:13:36Z",
    "link": "http://arxiv.org/pdf/2601.18569v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Seokju Lee",
      "Kyung-Soo Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.15169v3",
    "title": "SafeRBench: Dissecting the Reasoning Safety of Large Language Models",
    "summary": "Large Reasoning Models (LRMs) have significantly improved problem-solving through explicit Chain-of-Thought (CoT) reasoning. However, this capability creates a Safety-Helpfulness Paradox: the reasoning process itself can be misused to justify harmful actions or conceal malicious intent behind lengthy intermediate steps. Most existing benchmarks only check the final output, missing how risks evolve, or ``drift'', during the model's internal reasoning. To address this, we propose SafeRBench, the first framework to evaluate LRM safety end-to-end, from the initial input to the reasoning trace and final answer. Our approach introduces: (i) a Risk Stratification Probing that uses specific risk levels to stress-test safety boundaries beyond simple topics; (ii) Micro-Thought Analysis, a new chunking method that segments traces to pinpoint exactly where safety alignment breaks down; and (iii) a comprehensive suite of 10 fine-grained metrics that, for the first time, jointly measure a model's Risk Exposure (e.g., risk level, execution feasibility) and Safety Awareness (e.g., intent awareness). Experiments on 19 LRMs reveal that while enabling Thinking modes improves safety in mid-sized models, it paradoxically increases actionable risks in larger models due to a strong always-help tendency.",
    "published": "2025-11-19T06:46:33Z",
    "updated": "2026-01-26T15:12:11Z",
    "link": "http://arxiv.org/pdf/2511.15169v3.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Xin Gao",
      "Shaohan Yu",
      "Zerui Chen",
      "Yueming Lyu",
      "Weichen Yu",
      "Guanghao Li",
      "Jiyao Liu",
      "Jianxiong Gao",
      "Jian Liang",
      "Ziwei Liu",
      "Chenyang Si"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.19514v3",
    "title": "SIPDO: Closed-Loop Prompt Optimization via Synthetic Data Feedback",
    "summary": "Prompt quality plays a critical role in the performance of large language models (LLMs), motivating a growing body of work on prompt optimization. Most existing methods optimize prompts over a fixed dataset, assuming static input distributions and offering limited support for iterative improvement. We introduce SIPDO (Self-Improving Prompts through Data-Augmented Optimization), a closed-loop framework for prompt learning that integrates synthetic data generation into the optimization process. SIPDO couples a synthetic data generator with a prompt optimizer, where the generator produces new examples that reveal current prompt weaknesses and the optimizer incrementally refines the prompt in response. This feedback-driven loop enables systematic improvement of prompt performance without assuming access to external supervision or new tasks. Experiments across question answering and reasoning benchmarks show that SIPDO outperforms standard prompt tuning methods, highlighting the value of integrating data synthesis into prompt learning workflows.",
    "published": "2025-05-26T04:56:48Z",
    "updated": "2026-01-26T15:07:30Z",
    "link": "http://arxiv.org/pdf/2505.19514v3.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Yaoning Yu",
      "Ye Yu",
      "Peiyan Zhang",
      "Kai Wei",
      "Haojing Luo",
      "Haohan Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18554v1",
    "title": "Deconstructing Instruction-Following: A New Benchmark for Granular Evaluation of Large Language Model Instruction Compliance Abilities",
    "summary": "Reliably ensuring Large Language Models (LLMs) follow complex instructions is a critical challenge, as existing benchmarks often fail to reflect real-world use or isolate compliance from task success. We introduce MOSAIC (MOdular Synthetic Assessment of Instruction Compliance), a modular framework that uses a dynamically generated dataset with up to 20 application-oriented generation constraints to enable a granular and independent analysis of this capability. Our evaluation of five LLMs from different families based on this new benchmark demonstrates that compliance is not a monolithic capability but varies significantly with constraint type, quantity, and position. The analysis reveals model-specific weaknesses, uncovers synergistic and conflicting interactions between instructions, and identifies distinct positional biases such as primacy and recency effects. These granular insights are critical for diagnosing model failures and developing more reliable LLMs for systems that demand strict adherence to complex instructions.",
    "published": "2026-01-26T15:02:15Z",
    "updated": "2026-01-26T15:02:15Z",
    "link": "http://arxiv.org/pdf/2601.18554v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Alberto Purpura",
      "Li Wang",
      "Sahil Badyal",
      "Eugenio Beaufrand",
      "Adam Faulkner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.04139v2",
    "title": "Introducing COGENT3: An AI Architecture for Emergent Cognition",
    "summary": "This paper presents COGENT3 (or Collective Growth and Entropy-modulated Triads System), a novel approach for emergent cognition integrating pattern formation networks with group influence dynamics. Contrasting with traditional strategies that rely on predetermined architectures, computational structures emerge dynamically in our framework through agent interactions. This enables a more flexible and adaptive system exhibiting characteristics reminiscent of human cognitive processes. The incorporation of temperature modulation and memory effects in COGENT3 closely integrates statistical mechanics, machine learning, and cognitive science.",
    "published": "2025-04-05T11:05:55Z",
    "updated": "2026-01-26T14:56:16Z",
    "link": "http://arxiv.org/pdf/2504.04139v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Eduardo Salazar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06913v2",
    "title": "DecompGAIL: Learning Realistic Traffic Behaviors with Decomposed Multi-Agent Generative Adversarial Imitation Learning",
    "summary": "Realistic traffic simulation is critical for the development of autonomous driving systems and urban mobility planning, yet existing imitation learning approaches often fail to model realistic traffic behaviors. Behavior cloning suffers from covariate shift, while Generative Adversarial Imitation Learning (GAIL) is notoriously unstable in multi-agent settings. We identify a key source of this instability: irrelevant interaction misguidance, where a discriminator penalizes an ego vehicle's realistic behavior due to unrealistic interactions among its neighbors. To address this, we propose Decomposed Multi-agent GAIL (DecompGAIL), which explicitly decomposes realism into ego-map and ego-neighbor components, filtering out misleading neighbor: neighbor and neighbor: map interactions. We further introduce a social PPO objective that augments ego rewards with distance-weighted neighborhood rewards, encouraging overall realism across agents. Integrated into a lightweight SMART-based backbone, DecompGAIL achieves state-of-the-art performance on the WOMD Sim Agents 2025 benchmark.",
    "published": "2025-10-08T11:46:39Z",
    "updated": "2026-01-26T14:53:15Z",
    "link": "http://arxiv.org/pdf/2510.06913v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "authors": [
      "Ke Guo",
      "Haochen Liu",
      "Xiaojun Wu",
      "Chen Lv"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18537v1",
    "title": "SKETCH: Semantic Key-Point Conditioning for Long-Horizon Vessel Trajectory Prediction",
    "summary": "Accurate long-horizon vessel trajectory prediction remains challenging due to compounded uncertainty from complex navigation behaviors and environmental factors. Existing methods often struggle to maintain global directional consistency, leading to drifting or implausible trajectories when extrapolated over long time horizons. To address this issue, we propose a semantic-key-point-conditioned trajectory modeling framework, in which future trajectories are predicted by conditioning on a high-level Next Key Point (NKP) that captures navigational intent. This formulation decomposes long-horizon prediction into global semantic decision-making and local motion modeling, effectively restricting the support of future trajectories to semantically feasible subsets. To efficiently estimate the NKP prior from historical observations, we adopt a pretrain-finetune strategy. Extensive experiments on real-world AIS data demonstrate that the proposed method consistently outperforms state-of-the-art approaches, particularly for long travel durations, directional accuracy, and fine-grained trajectory prediction.",
    "published": "2026-01-26T14:42:31Z",
    "updated": "2026-01-26T14:42:31Z",
    "link": "http://arxiv.org/pdf/2601.18537v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Linyong Gan",
      "Zimo Li",
      "Wenxin Xu",
      "Xingjian Li",
      "Jianhua Z. Huang",
      "Enmei Tu",
      "Shuhang Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18521v1",
    "title": "Scalable Transit Delay Prediction at City Scale: A Systematic Approach with Multi-Resolution Feature Engineering and Deep Learning",
    "summary": "Urban bus transit agencies need reliable, network-wide delay predictions to provide accurate arrival information to passengers and support real-time operational control. Accurate predictions help passengers plan their trips, reduce waiting time, and allow operations staff to adjust headways, dispatch extra vehicles, and manage disruptions. Although real-time feeds such as GTFS-Realtime (GTFS-RT) are now widely available, most existing delay prediction systems handle only a few routes, depend on hand-crafted features, and offer little guidance on how to design a scalable, reusable architecture.\n  We present a city-scale prediction pipeline that combines multi-resolution feature engineering, dimensionality reduction, and deep learning. The framework generates 1,683 spatiotemporal features by exploring 23 aggregation combinations over H3 cells, routes, segments, and temporal patterns, and compresses them into 83 components using Adaptive PCA while preserving 95% of the variance. To avoid the \"giant cluster\" problem that occurs when dense urban areas fall into a single H3 region, we introduce a hybrid H3+topology clustering method that yields 12 balanced route clusters (coefficient of variation 0.608) and enables efficient distributed training.\n  We compare five model architectures on six months of bus operations from the Société de transport de Montréal (STM) network in Montréal. A global LSTM with cluster-aware features achieves the best trade-off between accuracy and efficiency, outperforming transformer models by 18 to 52% while using 275 times fewer parameters. We also report multi-level evaluation at the elementary segment, segment, and trip level with walk-forward validation and latency analysis, showing that the proposed pipeline is suitable for real-time, city-scale deployment and can be reused for other networks with limited adaptation.",
    "published": "2026-01-26T14:30:50Z",
    "updated": "2026-01-26T14:30:50Z",
    "link": "http://arxiv.org/pdf/2601.18521v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Emna Boudabbous",
      "Mohamed Karaa",
      "Lokman Sboui",
      "Julio Montecinos",
      "Omar Alam"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.04182v4",
    "title": "Thinking on the Fly: Test-Time Reasoning Enhancement via Latent Thought Policy Optimization",
    "summary": "Recent advancements in Large Language Models (LLMs) have shifted from explicit Chain-of-Thought (CoT) reasoning to more efficient latent reasoning, where intermediate thoughts are represented as vectors rather than text. However, latent reasoning can be brittle on challenging, out-of-distribution tasks where robust reasoning is most critical. To overcome these limitations, we introduce Latent Thought Policy Optimization (LTPO), a parameter-free framework that enhances LLM reasoning entirely at test time, without requiring model parameter updates. LTPO treats intermediate latent \"thought\" vectors as dynamic parameters that are actively optimized for each problem instance. It employs an online policy gradient method guided by an intrinsic, confidence-based reward signal computed directly from the frozen LLM's own output distributions, eliminating the need for external supervision or expensive text generation during optimization. Extensive experiments on five reasoning benchmarks show that LTPO not only matches or surpasses strong baselines on standard tasks but also demonstrates remarkable robustness where others fail. Most notably, on highly challenging AIME benchmarks where existing latent reasoning baselines collapse to near-zero accuracy, LTPO delivers substantial improvements, showcasing a unique capability for complex reasoning.",
    "published": "2025-10-05T12:50:39Z",
    "updated": "2026-01-26T14:30:08Z",
    "link": "http://arxiv.org/pdf/2510.04182v4.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Wengao Ye",
      "Yan Liang",
      "Lianlei Shan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.19893v2",
    "title": "Distillation-Enabled Knowledge Alignment for Generative Semantic Communications of AIGC Images",
    "summary": "Due to the surging amount of AI-generated images, its provisioning to edges and mobile users from the cloud incurs substantial traffic on networks. Generative semantic communication (GSC) offers a promising solution by transmitting highly compact information, i.e., prompt text and latent representations, instead of high-dimensional image data. However, GSC relies on the alignment between the knowledge in the cloud generative AI (GAI) and that possessed by the edges and users, and between the knowledge for wireless transmission and that of actual channels, which remains challenging. In this paper, we propose DeKA-g, a distillation-enabled knowledge alignment algorithm for GSC systems. The core idea is to distill the image generation knowledge from the cloud-GAI into low-rank matrices, which can be incorporated by the edge and used to adapt the transmission knowledge to diverse wireless channel conditions. DeKA-g comprises two novel methods: metaword-aided knowledge distillation (MAKD) and condition-aware low-rank adaptation (CALA). For MAKD, an optimized metaword is employed to enhance the efficiency of knowledge distillation, while CALA enables efficient adaptation to diverse rate requirements and channel conditions. From simulation results, DeKA-g improves the consistency between the edge-generated images and the cloud-generated ones by 44% and enahnces the average transmission quality in terms of PSNR by 6.5 dB over the baselines without knowledge alignment.",
    "published": "2025-06-24T10:50:14Z",
    "updated": "2026-01-26T14:18:19Z",
    "link": "http://arxiv.org/pdf/2506.19893v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "eess.IV"
    ],
    "authors": [
      "Jingzhi Hu",
      "Geoffrey Ye Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18510v1",
    "title": "Just-In-Time Reinforcement Learning: Continual Learning in LLM Agents Without Gradient Updates",
    "summary": "While Large Language Model (LLM) agents excel at general tasks, they inherently struggle with continual adaptation due to the frozen weights after deployment. Conventional reinforcement learning (RL) offers a solution but incurs prohibitive computational costs and the risk of catastrophic forgetting. We introduce Just-In-Time Reinforcement Learning (JitRL), a training-free framework that enables test-time policy optimization without any gradient updates. JitRL maintains a dynamic, non-parametric memory of experiences and retrieves relevant trajectories to estimate action advantages on-the-fly. These estimates are then used to directly modulate the LLM's output logits. We theoretically prove that this additive update rule is the exact closed-form solution to the KL-constrained policy optimization objective. Extensive experiments on WebArena and Jericho demonstrate that JitRL establishes a new state-of-the-art among training-free methods. Crucially, JitRL outperforms the performance of computationally expensive fine-tuning methods (e.g., WebRL) while reducing monetary costs by over 30 times, offering a scalable path for continual learning agents. The code is available at https://github.com/liushiliushi/JitRL.",
    "published": "2026-01-26T14:16:51Z",
    "updated": "2026-01-26T14:16:51Z",
    "link": "http://arxiv.org/pdf/2601.18510v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Yibo Li",
      "Zijie Lin",
      "Ailin Deng",
      "Xuan Zhang",
      "Yufei He",
      "Shuo Ji",
      "Tri Cao",
      "Bryan Hooi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.10571v5",
    "title": "On the Failure of Latent State Persistence in Large Language Models",
    "summary": "While Large Language Models (LLMs) excel in reasoning, whether they can sustain persistent latent states remains under-explored. The capacity to maintain and manipulate unexpressed, internal representations-analogous to human working memory-is a cornerstone of complex reasoning. In this paper, we formalize and quantify the \"Latent State Persistence\" (LSP) gap through three novel experiments. First, we utilize a Number Guessing Game, demonstrating that across independent queries, LLMs fail to allocate probability mass to a singular hidden choice, violating a fundamental probabilistic principle. Second, we employ a Yes-No Game to show that as the number of questions increases, LLMs suffer from \"concept drift,\" leading to inevitable self-contradictions due to the lack of LSP. Finally, inspired by Mathematical Mentalism, we task models with tracking transformations on hidden variables, revealing a failure in variable binding and state evolution when the initial state is not explicitly present in the context. Collectively, these findings suggest that LLMs function as reactive post-hoc solvers rather than proactive planners with LSP. Our work provides a framework for evaluating the fidelity of internal representations and highlights a fundamental architectural divergence between autoregressive transformers and human-like cognition.",
    "published": "2025-04-30T16:18:39Z",
    "updated": "2026-01-26T14:13:17Z",
    "link": "http://arxiv.org/pdf/2505.10571v5.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Jen-tse Huang",
      "Kaiser Sun",
      "Wenxuan Wang",
      "Mark Dredze"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.16944v2",
    "title": "Pretrain Value, Not Reward: Decoupled Value Policy Optimization",
    "summary": "In this paper, we explore how directly pretraining a value model simplifies and stabilizes reinforcement learning from human feedback (RLHF). In reinforcement learning, value estimation is the key to policy optimization, distinct from reward supervision. The value function predicts the \\emph{return-to-go} of a partial answer, that is, how promising the partial answer is if it were continued to completion. In RLHF, however, the standard pipeline first pretrains a reward model and then learns a value function online, even though no new reward signals are available once preference data is collected. This makes critic learning redundant, as the process of training a reward model and then deriving a value model is informationally equivalent to directly pretraining a value model. Importantly, this requires no additional supervision, and our value model is trained on exactly the same data used for reward modeling. Building on this insight, we introduce \\emph{Decoupled Value Policy Optimization} (DVPO), a framework that pretrains a \\emph{Global Value Model} (GVM) offline and freezes it as a universal critic for policy learning. The GVM provides stable, fine-grained credit assignment without critic drift or trajectory sampling. Experiments across MT-Bench, Alpaca-Eval, and Arena-Hard demonstrate that DVPO matches or surpasses state-of-the-art RLHF methods. These results highlight RLHF can be reframed as policy-only optimization guided by a single pretrained value model.",
    "published": "2025-02-24T08:11:33Z",
    "updated": "2026-01-26T14:09:10Z",
    "link": "http://arxiv.org/pdf/2502.16944v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Chenghua Huang",
      "Lu Wang",
      "Fangkai Yang",
      "Pu Zhao",
      "Zhixu Li",
      "Qingwei Lin",
      "Dongmei Zhang",
      "Saravan Rajmohan",
      "Qi Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18496v1",
    "title": "DEEPMED: Building a Medical DeepResearch Agent via Multi-hop Med-Search Data and Turn-Controlled Agentic Training & Inference",
    "summary": "Medical reasoning models remain constrained by parametric knowledge and are thus susceptible to forgetting and hallucinations. DeepResearch (DR) models ground outputs in verifiable evidence from tools and perform strongly in general domains, but their direct transfer to medical field yields relatively limited gains. We attribute this to two gaps: task characteristic and tool-use scaling. Medical questions require evidence interpretation in a knowledge-intensive clinical context; while general DR models can retrieve information, they often lack clinical-context reasoning and thus \"find it but fail to use it,\" leaving performance limited by medical abilities. Moreover, in medical scenarios, blindly scaling tool-call can inject noisy context, derailing sensitive medical reasoning and prompting repetitive evidence-seeking along incorrect paths. Therefore, we propose DeepMed. For data, we deploy a multi-hop med-search QA synthesis method supporting the model to apply the DR paradigm in medical contexts. For training, we introduce a difficulty-aware turn-penalty to suppress excessive tool-call growth. For inference, we bring a monitor to help validate hypotheses within a controlled number of steps and avoid context rot. Overall, on seven medical benchmarks, DeepMed improves its base model by 9.79\\% on average and outperforms larger medical reasoning and DR models.",
    "published": "2026-01-26T13:57:48Z",
    "updated": "2026-01-26T13:57:48Z",
    "link": "http://arxiv.org/pdf/2601.18496v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Zihan wang",
      "Hao Wang",
      "Shi Feng",
      "Xiaocui Yang",
      "Daling Wang",
      "Yiqun Zhang",
      "Jinghao Lin",
      "Haihua Yang",
      "Xiaozhong Ji"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18491v1",
    "title": "AgentDoG: A Diagnostic Guardrail Framework for AI Agent Safety and Security",
    "summary": "The rise of AI agents introduces complex safety and security challenges arising from autonomous tool use and environmental interactions. Current guardrail models lack agentic risk awareness and transparency in risk diagnosis. To introduce an agentic guardrail that covers complex and numerous risky behaviors, we first propose a unified three-dimensional taxonomy that orthogonally categorizes agentic risks by their source (where), failure mode (how), and consequence (what). Guided by this structured and hierarchical taxonomy, we introduce a new fine-grained agentic safety benchmark (ATBench) and a Diagnostic Guardrail framework for agent safety and security (AgentDoG). AgentDoG provides fine-grained and contextual monitoring across agent trajectories. More Crucially, AgentDoG can diagnose the root causes of unsafe actions and seemingly safe but unreasonable actions, offering provenance and transparency beyond binary labels to facilitate effective agent alignment. AgentDoG variants are available in three sizes (4B, 7B, and 8B parameters) across Qwen and Llama model families. Extensive experimental results demonstrate that AgentDoG achieves state-of-the-art performance in agentic safety moderation in diverse and complex interactive scenarios. All models and datasets are openly released.",
    "published": "2026-01-26T13:45:41Z",
    "updated": "2026-01-26T13:45:41Z",
    "link": "http://arxiv.org/pdf/2601.18491v1.pdf",
    "category": [
      "cs.AI",
      "cs.CC",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Dongrui Liu",
      "Qihan Ren",
      "Chen Qian",
      "Shuai Shao",
      "Yuejin Xie",
      "Yu Li",
      "Zhonghao Yang",
      "Haoyu Luo",
      "Peng Wang",
      "Qingyu Liu",
      "Binxin Hu",
      "Ling Tang",
      "Jilin Mei",
      "Dadi Guo",
      "Leitao Yuan",
      "Junyao Yang",
      "Guanxu Chen",
      "Qihao Lin",
      "Yi Yu",
      "Bo Zhang",
      "Jiaxuan Guo",
      "Jie Zhang",
      "Wenqi Shao",
      "Huiqi Deng",
      "Zhiheng Xi",
      "Wenjie Wang",
      "Wenxuan Wang",
      "Wen Shen",
      "Zhikai Chen",
      "Haoyu Xie",
      "Jialing Tao",
      "Juntao Dai",
      "Jiaming Ji",
      "Zhongjie Ba",
      "Linfeng Zhang",
      "Yong Liu",
      "Quanshi Zhang",
      "Lei Zhu",
      "Zhihua Wei",
      "Hui Xue",
      "Chaochao Lu",
      "Jing Shao",
      "Xia Hu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.16882v2",
    "title": "Explaining Group Recommendations via Counterfactuals",
    "summary": "Group recommender systems help users make collective choices but often lack transparency, leaving group members uncertain about why items are suggested. Existing explanation methods focus on individuals, offering limited support for groups where multiple preferences interact. In this paper, we propose a framework for group counterfactual explanations, which reveal how removing specific past interactions would change a group recommendation. We formalize this concept, introduce utility and fairness measures tailored to groups, and design heuristic algorithms, such as Pareto-based filtering and grow-and-prune strategies, for efficient explanation discovery. Experiments on MovieLens and Amazon datasets show clear trade-offs: low-cost methods produce larger, less fair explanations, while other approaches yield concise and balanced results at higher cost. Furthermore, the Pareto-filtering heuristic demonstrates significant efficiency improvements in sparse settings.",
    "published": "2026-01-23T16:42:05Z",
    "updated": "2026-01-26T13:40:58Z",
    "link": "http://arxiv.org/pdf/2601.16882v2.pdf",
    "category": [
      "cs.IR",
      "cs.AI"
    ],
    "authors": [
      "Maria Stratigi",
      "Nikos Bikakis",
      "Kostas Stefanidis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.14702v2",
    "title": "Seeing Beyond the Image: ECG and Anatomical Knowledge-Guided Myocardial Scar Segmentation from Late Gadolinium-Enhanced Images",
    "summary": "Accurate segmentation of myocardial scar from late gadolinium enhanced (LGE) cardiac MRI is essential for evaluating tissue viability, yet remains challenging due to variable contrast and imaging artifacts. Electrocardiogram (ECG) signals provide complementary physiological information, as conduction abnormalities can help localize or suggest scarred myocardial regions. In this work, we propose a novel multimodal framework that integrates ECG-derived electrophysiological information with anatomical priors from the AHA-17 atlas for physiologically consistent LGE-based scar segmentation. As ECGs and LGE-MRIs are not acquired simultaneously, we introduce a Temporal Aware Feature Fusion (TAFF) mechanism that dynamically weights and fuses features based on their acquisition time difference. Our method was evaluated on a clinical dataset and achieved substantial gains over the state-of-the-art image-only baseline (nnU-Net), increasing the average Dice score for scars from 0.6149 to 0.8463 and achieving high performance in both precision (0.9115) and sensitivity (0.9043). These results show that integrating physiological and anatomical knowledge allows the model to \"see beyond the image\", setting a new direction for robust and physiologically grounded cardiac scar segmentation.",
    "published": "2025-11-18T17:42:20Z",
    "updated": "2026-01-26T13:39:13Z",
    "link": "http://arxiv.org/pdf/2511.14702v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Farheen Ramzan",
      "Yusuf Kiberu",
      "Nikesh Jathanna",
      "Meryem Jabrane",
      "Vicente Grau",
      "Shahnaz Jamil-Copley",
      "Richard H. Clayton",
      " Chen",
      " Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18483v1",
    "title": "Funny or Persuasive, but Not Both: Evaluating Fine-Grained Multi-Concept Control in LLMs",
    "summary": "Large Language Models (LLMs) offer strong generative capabilities, but many applications require explicit and \\textit{fine-grained} control over specific textual concepts, such as humor, persuasiveness, or formality. Prior approaches in prompting and representation engineering can provide coarse or single-attribute control, but systematic evaluation of multi-attribute settings remains limited. We introduce an evaluation framework for fine-grained controllability for both single- and dual-concept scenarios, focusing on linguistically distinct concept pairs (e.g., persuasiveness vs.~humor). Surprisingly, across multiple LLMs and generative tasks, we find that performance often drops in the dual-concept setting, even though the chosen concepts should in principle be separable. This reveals a fundamental limitation of naive prompting-based control: models struggle with compositionality even when concepts are intuitively independent. Our framework provides systematic evidence of this gap and offers a principled approach for measuring the ability of future methods for multi-concept control.",
    "published": "2026-01-26T13:36:34Z",
    "updated": "2026-01-26T13:36:34Z",
    "link": "http://arxiv.org/pdf/2601.18483v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Arya Labroo",
      "Ivaxi Sheth",
      "Vyas Raina",
      "Amaani Ahmed",
      "Mario Fritz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.11233v2",
    "title": "STaR: Towards Effective and Stable Table Reasoning via Slow-Thinking Large Language Models",
    "summary": "Table reasoning with large language models (LLMs) plays a critical role in building intelligent systems capable of understanding and analyzing tabular data. Despite recent progress, existing methods still face key limitations: their reasoning processes lacks depth and explicit multi-step reasoning, often relying solely on implicit language model understanding. In addition, their reasoning processes suffer from instability, primarily caused by model uncertainty. In this work, we propose STaR, a novel slow-thinking model that can achieve effective and stable table reasoning. To enable effective multi-step reasoning, we design a two-stage training framework consisting of supervised fine-tuning (SFT) warm-up followed by reinforced fine-tuning (RFT). Specifically, in the SFT stage, we construct a high-quality dataset through automatic self-verification. In the RFT stage, we introduce a difficulty-aware reinforcement learning mechanism to further enhance reasoning capabilities. Furthermore, to improve reasoning stability, we introduce trajectory-level uncertainty quantification, which fuses token-level confidence with answer-level consistency, enabling the selection of better reasoning trajectories. Extensive experiments demonstrate that STaR-8B achieves state-of-the-art performance on in-domain benchmarks and exhibits strong generalization to out-of-domain datasets, highlighting its potential for enhancing both effectiveness and stability in table reasoning.",
    "published": "2025-11-14T12:34:17Z",
    "updated": "2026-01-26T13:35:03Z",
    "link": "http://arxiv.org/pdf/2511.11233v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Huajian Zhang",
      "Mingyue Cheng",
      "Yucong Luo",
      "Xiaoyu Tao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.13551v2",
    "title": "Tandem Training for Language Models",
    "summary": "As language models continue to rapidly improve, we can expect their actions and reasoning to become difficult or impossible for weaker agents and humans to follow, undermining interpretability and oversight. With an eye on long-term futures, we pursue methods that encourage models to produce solutions that remain intelligible to weaker collaborators. We formalize intelligibility as handoff robustness: a strong model's solution is intelligible to a weaker model if randomly handing off control to the weaker model along the solution path does not cause failure. Building on this criterion, we introduce tandem training for language models, a reinforcement learning (RL) paradigm in which rollout tokens are intermittently and randomly sampled from a frozen weak model rather than the strong model being trained. Because rollouts succeed only when the strong model's actions and reasoning process can be continued by the weak model -- when the two can co-construct a successful solution -- optimizing standard RL objectives with tandem training implicitly incentivizes both correctness and intelligibility. In the GSM8K math reasoning task, tandem training reliably teaches models to abandon jargon and adapt their language to weaker partners while keeping task accuracy high. Our results demonstrate a promising route to building AI systems that remain auditable by weaker agents, with implications for human--AI collaboration and multi-agent communication.",
    "published": "2025-10-15T13:48:16Z",
    "updated": "2026-01-26T13:19:16Z",
    "link": "http://arxiv.org/pdf/2510.13551v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Robert West",
      "Ashton Anderson",
      "Ece Kamar",
      "Eric Horvitz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18467v1",
    "title": "OffSeeker: Online Reinforcement Learning Is Not All You Need for Deep Research Agents",
    "summary": "Deep research agents have shown remarkable potential in handling long-horizon tasks. However, state-of-the-art performance typically relies on online reinforcement learning (RL), which is financially expensive due to extensive API calls. While offline training offers a more efficient alternative, its progress is hindered by the scarcity of high-quality research trajectories. In this paper, we demonstrate that expensive online reinforcement learning is not all you need to build powerful research agents. To bridge this gap, we introduce a fully open-source suite designed for effective offline training. Our core contributions include DeepForge, a ready-to-use task synthesis framework that generates large-scale research queries without heavy preprocessing; and a curated collection of 66k QA pairs, 33k SFT trajectories, and 21k DPO pairs. Leveraging these resources, we train OffSeeker (8B), a model developed entirely offline. Extensive evaluations across six benchmarks show that OffSeeker not only leads among similar-sized agents but also remains competitive with 30B-parameter systems trained via heavy online RL.",
    "published": "2026-01-26T13:13:59Z",
    "updated": "2026-01-26T13:13:59Z",
    "link": "http://arxiv.org/pdf/2601.18467v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Yuhang Zhou",
      "Kai Zheng",
      "Qiguang Chen",
      "Mengkang Hu",
      "Qingfeng Sun",
      "Can Xu",
      "Jingjing Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18464v1",
    "title": "Fair-Eye Net: A Fair, Trustworthy, Multimodal Integrated Glaucoma Full Chain AI System",
    "summary": "Glaucoma is a top cause of irreversible blindness globally, making early detection and longitudinal follow-up pivotal to preventing permanent vision loss. Current screening and progression assessment, however, rely on single tests or loosely linked examinations, introducing subjectivity and fragmented care. Limited access to high-quality imaging tools and specialist expertise further compromises consistency and equity in real-world use. To address these gaps, we developed Fair-Eye Net, a fair, reliable multimodal AI system closing the clinical loop from glaucoma screening to follow-up and risk alerting. It integrates fundus photos, OCT structural metrics, VF functional indices, and demographic factors via a dual-stream heterogeneous fusion architecture, with an uncertainty-aware hierarchical gating strategy for selective prediction and safe referral. A fairness constraint reduces missed diagnoses in disadvantaged subgroups. Experimental results show it achieved an AUC of 0.912 (96.7% specificity), cut racial false-negativity disparity by 73.4% (12.31% to 3.28%), maintained stable cross-domain performance, and enabled 3-12 months of early risk alerts (92% sensitivity, 88% specificity). Unlike post hoc fairness adjustments, Fair-Eye Net optimizes fairness as a primary goal with clinical reliability via multitask learning, offering a reproducible path for clinical translation and large-scale deployment to advance global eye health equity.",
    "published": "2026-01-26T13:12:24Z",
    "updated": "2026-01-26T13:12:24Z",
    "link": "http://arxiv.org/pdf/2601.18464v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Wenbin Wei",
      "Suyuan Yao",
      "Cheng Huang",
      "Xiangyu Gao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18451v1",
    "title": "3DGesPolicy: Phoneme-Aware Holistic Co-Speech Gesture Generation Based on Action Control",
    "summary": "Generating holistic co-speech gestures that integrate full-body motion with facial expressions suffers from semantically incoherent coordination on body motion and spatially unstable meaningless movements due to existing part-decomposed or frame-level regression methods, We introduce 3DGesPolicy, a novel action-based framework that reformulates holistic gesture generation as a continuous trajectory control problem through diffusion policy from robotics. By modeling frame-to-frame variations as unified holistic actions, our method effectively learns inter-frame holistic gesture motion patterns and ensures both spatially and semantically coherent movement trajectories that adhere to realistic motion manifolds. To further bridge the gap in expressive alignment, we propose a Gesture-Audio-Phoneme (GAP) fusion module that can deeply integrate and refine multi-modal signals, ensuring structured and fine-grained alignment between speech semantics, body motion, and facial expressions. Extensive quantitative and qualitative experiments on the BEAT2 dataset demonstrate the effectiveness of our 3DGesPolicy across other state-of-the-art methods in generating natural, expressive, and highly speech-aligned holistic gestures.",
    "published": "2026-01-26T12:57:36Z",
    "updated": "2026-01-26T12:57:36Z",
    "link": "http://arxiv.org/pdf/2601.18451v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "cs.SD"
    ],
    "authors": [
      "Xuanmeng Sha",
      "Liyun Zhang",
      "Tomohiro Mashita",
      "Naoya Chiba",
      "Yuki Uranishi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18447v1",
    "title": "GCFX: Generative Counterfactual Explanations for Deep Graph Models at the Model Level",
    "summary": "Deep graph learning models have demonstrated remarkable capabilities in processing graph-structured data and have been widely applied across various fields. However, their complex internal architectures and lack of transparency make it difficult to explain their decisions, resulting in opaque models that users find hard to understand and trust. In this paper, we explore model-level explanation techniques for deep graph learning models, aiming to provide users with a comprehensive understanding of the models' overall decision-making processes and underlying mechanisms. Specifically, we address the problem of counterfactual explanations for deep graph learning models by introducing a generative model-level counterfactual explanation approach called GCFX, which is based on deep graph generation. This approach generates a set of high-quality counterfactual explanations that reflect the model's global predictive behavior by leveraging an enhanced deep graph generation framework and a global summarization algorithm. GCFX features an architecture that combines dual encoders, structure-aware taggers, and Message Passing Neural Network decoders, enabling it to accurately learn the true latent distribution of input data and generate high-quality, closely related counterfactual examples. Subsequently, a global counterfactual summarization algorithm selects the most representative and comprehensive explanations from numerous candidate counterfactuals, providing broad insights into the model's global predictive patterns. Experiments on a synthetic dataset and several real-world datasets demonstrate that GCFX outperforms existing methods in terms of counterfactual validity and coverage while maintaining low explanation costs, thereby offering crucial support for enhancing the practicality and trustworthiness of global counterfactual explanations.",
    "published": "2026-01-26T12:56:01Z",
    "updated": "2026-01-26T12:56:01Z",
    "link": "http://arxiv.org/pdf/2601.18447v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Jinlong Hu",
      "Jiacheng Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.20984v2",
    "title": "Learning Grouped Lattice Vector Quantizers for Low-Bit LLM Compression",
    "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities but typically require extensive computational resources and memory for inference. Post-training quantization (PTQ) can effectively reduce these demands by storing weights in lower bit-width formats. However, standard uniform quantization often leads to notable performance degradation, particularly in low-bit scenarios. In this work, we introduce a Grouped Lattice Vector Quantization (GLVQ) framework that assigns each group of weights a customized lattice codebook, defined by a learnable generation matrix. To address the non-differentiability of the quantization process, we adopt Babai rounding to approximate nearest-lattice-point search during training, which enables stable optimization of the generation matrices. Once trained, decoding reduces to a simple matrix-vector multiplication, yielding an efficient and practical quantization pipeline. Experiments on multiple benchmarks show that our approach achieves a better trade-off between model size and accuracy compared to existing post-training quantization baselines, highlighting its effectiveness in deploying large models under stringent resource constraints. Our source code is available on GitHub repository: https://github.com/xzhang9308/GLVQ.",
    "published": "2025-10-23T20:19:48Z",
    "updated": "2026-01-26T12:51:01Z",
    "link": "http://arxiv.org/pdf/2510.20984v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Xi Zhang",
      "Xiaolin Wu",
      "Jiamang Wang",
      "Weisi Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18420v1",
    "title": "Gradient Regularized Natural Gradients",
    "summary": "Gradient regularization (GR) has been shown to improve the generalizability of trained models. While Natural Gradient Descent has been shown to accelerate optimization in the initial phase of training, little attention has been paid to how the training dynamics of second-order optimizers can benefit from GR. In this work, we propose Gradient-Regularized Natural Gradients (GRNG), a family of scalable second-order optimizers that integrate explicit gradient regularization with natural gradient updates. Our framework provides two complementary algorithms: a frequentist variant that avoids explicit inversion of the Fisher Information Matrix (FIM) via structured approximations, and a Bayesian variant based on a Regularized-Kalman formulation that eliminates the need for FIM inversion entirely. We establish convergence guarantees for GRNG, showing that gradient regularization improves stability and enables convergence to global minima. Empirically, we demonstrate that GRNG consistently enhances both optimization speed and generalization compared to first-order methods (SGD, AdamW) and second-order baselines (K-FAC, Sophia), with strong results on vision and language benchmarks. Our findings highlight gradient regularization as a principled and practical tool to unlock the robustness of natural gradient methods for large-scale deep learning.",
    "published": "2026-01-26T12:25:04Z",
    "updated": "2026-01-26T12:25:04Z",
    "link": "http://arxiv.org/pdf/2601.18420v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Satya Prakash Dash",
      "Hossein Abdi",
      "Wei Pan",
      "Samuel Kaski",
      "Mingfei Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18419v1",
    "title": "Emergent Cooperation in Quantum Multi-Agent Reinforcement Learning Using Communication",
    "summary": "Emergent cooperation in classical Multi-Agent Reinforcement Learning has gained significant attention, particularly in the context of Sequential Social Dilemmas (SSDs). While classical reinforcement learning approaches have demonstrated capability for emergent cooperation, research on extending these methods to Quantum Multi-Agent Reinforcement Learning remains limited, particularly through communication. In this paper, we apply communication approaches to quantum Q-Learning agents: the Mutual Acknowledgment Token Exchange (MATE) protocol, its extension Mutually Endorsed Distributed Incentive Acknowledgment Token Exchange (MEDIATE), the peer rewarding mechanism Gifting, and Reinforced Inter-Agent Learning (RIAL). We evaluate these approaches in three SSDs: the Iterated Prisoner's Dilemma, Iterated Stag Hunt, and Iterated Game of Chicken. Our experimental results show that approaches using MATE with temporal-difference measure (MATE\\textsubscript{TD}), AutoMATE, MEDIATE-I, and MEDIATE-S achieved high cooperation levels across all dilemmas, demonstrating that communication is a viable mechanism for fostering emergent cooperation in Quantum Multi-Agent Reinforcement Learning.",
    "published": "2026-01-26T12:21:05Z",
    "updated": "2026-01-26T12:21:05Z",
    "link": "http://arxiv.org/pdf/2601.18419v1.pdf",
    "category": [
      "quant-ph",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "authors": [
      "Michael Kölle",
      "Christian Reff",
      "Leo Sünkel",
      "Julian Hager",
      "Gerhard Stenzel",
      "Claudia Linnhoff-Popien"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18418v1",
    "title": "daVinci-Dev: Agent-native Mid-training for Software Engineering",
    "summary": "Recently, the frontier of Large Language Model (LLM) capabilities has shifted from single-turn code generation to agentic software engineering-a paradigm where models autonomously navigate, edit, and test complex repositories. While post-training methods have become the de facto approach for code agents, **agentic mid-training**-mid-training (MT) on large-scale data that mirrors authentic agentic workflows-remains critically underexplored due to substantial resource requirements, despite offering a more scalable path to instilling foundational agentic behaviors than relying solely on expensive reinforcement learning. A central challenge in realizing effective agentic mid-training is the distribution mismatch between static training data and the dynamic, feedback-rich environment of real development. To address this, we present a systematic study of agentic mid-training, establishing both the data synthesis principles and training methodology for effective agent development at scale. Central to our approach is **agent-native data**-supervision comprising two complementary types of trajectories: **contextually-native trajectories** that preserve the complete information flow an agent experiences, offering broad coverage and diversity; and **environmentally-native trajectories** collected from executable repositories where observations stem from actual tool invocations and test executions, providing depth and interaction authenticity. We verify the model's agentic capabilities on `SWE-Bench Verified`. We demonstrate our superiority over the previous open software engineering mid-training recipe `Kimi-Dev` under two post-training settings with an aligned base model and agentic scaffold, while using less than half mid-training tokens (73.1B). Besides relative advantage, our best performing 32B and 72B models achieve **56.1%** and **58.5%** resolution rates, respectively, which are ...",
    "published": "2026-01-26T12:20:18Z",
    "updated": "2026-01-26T12:20:18Z",
    "link": "http://arxiv.org/pdf/2601.18418v1.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Ji Zeng",
      "Dayuan Fu",
      "Tiantian Mi",
      "Yumin Zhuang",
      "Yaxing Huang",
      "Xuefeng Li",
      "Lyumanshan Ye",
      "Muhang Xie",
      "Qishuo Hua",
      "Zhen Huang",
      "Mohan Jiang",
      "Hanning Wang",
      "Jifan Lin",
      "Yang Xiao",
      "Jie Sun",
      "Yunze Wu",
      "Pengfei Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.23972v4",
    "title": "Noise-based reward-modulated learning",
    "summary": "The pursuit of energy-efficient and adaptive artificial intelligence (AI) has positioned neuromorphic computing as a promising alternative to conventional computing. However, achieving learning on these platforms requires techniques that prioritize local information while enabling effective credit assignment. Here, we propose noise-based reward-modulated learning (NRL), a novel synaptic plasticity rule that mathematically unifies reinforcement learning and gradient-based optimization with biologically-inspired local updates. NRL addresses the computational bottleneck of exact gradients by approximating them through stochastic neural activity, transforming the inherent noise of biological and neuromorphic substrates into a functional resource. Drawing inspiration from biological learning, our method uses reward prediction errors as its optimization target to generate increasingly advantageous behavior, and eligibility traces to facilitate retrospective credit assignment. Experimental validation on reinforcement tasks, featuring immediate and delayed rewards, shows that NRL achieves performance comparable to baselines optimized using backpropagation, although with slower convergence, while showing significantly superior performance and scalability in multi-layer networks compared to reward-modulated Hebbian learning (RMHL), the most prominent similar approach. While tested on simple architectures, the results highlight the potential of noise-driven, brain-inspired learning for low-power adaptive systems, particularly in computing substrates with locality constraints. NRL offers a theoretically grounded paradigm well-suited for the event-driven characteristics of next-generation neuromorphic AI.",
    "published": "2025-03-31T11:35:23Z",
    "updated": "2026-01-26T11:58:34Z",
    "link": "http://arxiv.org/pdf/2503.23972v4.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Jesús García Fernández",
      "Nasir Ahmad",
      "Marcel van Gerven"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.19065v3",
    "title": "Tackling Federated Unlearning as a Parameter Estimation Problem",
    "summary": "Privacy regulations require the erasure of data from deep learning models. This is a significant challenge that is amplified in Federated Learning, where data remains on clients, making full retraining or coordinated updates often infeasible. This work introduces an efficient Federated Unlearning framework based on information theory, modeling leakage as a parameter estimation problem. Our method uses second-order Hessian information to identify and selectively reset only the parameters most sensitive to the data being forgotten, followed by minimal federated retraining. This model-agnostic approach supports categorical and client unlearning without requiring server access to raw client data after initial information aggregation. Evaluations on benchmark datasets demonstrate strong privacy (MIA success near random, categorical knowledge erased) and high performance (Normalized Accuracy against re-trained benchmarks of $\\approx$ 0.9), while aiming for increased efficiency over complete retraining. Furthermore, in a targeted backdoor attack scenario, our framework effectively neutralizes the malicious trigger, restoring model integrity. This offers a practical solution for data forgetting in FL.",
    "published": "2025-08-26T14:24:45Z",
    "updated": "2026-01-26T11:53:10Z",
    "link": "http://arxiv.org/pdf/2508.19065v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.IT"
    ],
    "authors": [
      "Antonio Balordi",
      "Lorenzo Manini",
      "Fabio Stella",
      "Alessio Merlo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.06216v3",
    "title": "Integer Linear Programming Preprocessing for Maximum Satisfiability",
    "summary": "The Maximum Satisfiability problem (MaxSAT) is a major optimization challenge with numerous practical applications. In recent MaxSAT evaluations, most MaxSAT solvers have incorporated an Integer Linear Programming (ILP) solver into their portfolios. However, a good portfolio strategy requires a lot of tuning work and is limited to the profiling benchmark. This paper proposes a methodology to fully integrate ILP preprocessing techniques into the MaxSAT solving pipeline and investigates the impact on the top-performing MaxSAT solvers. Experimental results show that our approach helps to improve 5 out of 6 state-of-the-art MaxSAT solvers, especially for WMaxCDCL-OpenWbo1200, the winner of the MaxSAT evaluation 2024 on the unweighted track, which is able to solve 15 additional instances using our methodology.",
    "published": "2025-06-06T16:21:38Z",
    "updated": "2026-01-26T11:50:51Z",
    "link": "http://arxiv.org/pdf/2506.06216v3.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Jialu Zhang",
      "Chu-Min Li",
      "Sami Cherif",
      "Shuolin Li",
      "Zhifei Zheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.08653v2",
    "title": "Prism: Towards Lowering User Cognitive Load in LLMs via Complex Intent Understanding",
    "summary": "Large Language Models are rapidly emerging as web-native interfaces to social platforms. On the social web, users frequently have ambiguous and dynamic goals, making complex intent understanding-rather than single-turn execution-the cornerstone of effective human-LLM collaboration. Existing approaches attempt to clarify user intents through sequential or parallel questioning, yet they fall short of addressing the core challenge: modeling the logical dependencies among clarification questions. Inspired by the Cognitive Load Theory, we propose Prism, a novel framework for complex intent understanding that enables logically coherent and efficient intent clarification. Prism comprises four tailored modules: a complex intent decomposition module, which decomposes user intents into smaller, well-structured elements and identifies logical dependencies among them; a logical clarification generation module, which organizes clarification questions based on these dependencies to ensure coherent, low-friction interactions; an intent-aware reward module, which evaluates the quality of clarification trajectories via an intent-aware reward function and leverages Monte Carlo Sample to simulate user-LLM interactions for large-scale,high-quality training data generation; and a self-evolved intent tuning module, which iteratively refines the LLM's logical clarification capability through data-driven feedback and optimization. Prism consistently outperforms existing approaches across clarification interactions, intent execution, and cognitive load benchmarks. It achieves stateof-the-art logical consistency, reduces logical conflicts to 11.5%, increases user satisfaction by 14.4%, and decreases task completion time by 34.8%. All data and code are released.",
    "published": "2026-01-13T15:30:48Z",
    "updated": "2026-01-26T11:38:04Z",
    "link": "http://arxiv.org/pdf/2601.08653v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Zenghua Liao",
      "Jinzhi Liao",
      "Xiang Zhao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18383v1",
    "title": "Dynamic Thinking-Token Selection for Efficient Reasoning in Large Reasoning Models",
    "summary": "Large Reasoning Models (LRMs) excel at solving complex problems by explicitly generating a reasoning trace before deriving the final answer. However, these extended generations incur substantial memory footprint and computational overhead, bottlenecking LRMs' efficiency. This work uses attention maps to analyze the influence of reasoning traces and uncover an interesting phenomenon: only some decision-critical tokens in a reasoning trace steer the model toward the final answer, while the remaining tokens contribute negligibly. Building on this observation, we propose Dynamic Thinking-Token Selection (DynTS). This method identifies decision-critical tokens and retains only their associated Key-Value (KV) cache states during inference, evicting the remaining redundant entries to optimize efficiency.",
    "published": "2026-01-26T11:31:40Z",
    "updated": "2026-01-26T11:31:40Z",
    "link": "http://arxiv.org/pdf/2601.18383v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Zhenyuan Guo",
      "Tong Chen",
      "Wenlong Meng",
      "Chen Gong",
      "Xin Yu",
      "Chengkun Wei",
      "Wenzhi Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18381v1",
    "title": "AI Agent for Reverse-Engineering Legacy Finite-Difference Code and Translating to Devito",
    "summary": "To facilitate the transformation of legacy finite difference implementations into the Devito environment, this study develops an integrated AI agent framework. Retrieval-Augmented Generation (RAG) and open-source Large Language Models are combined through multi-stage iterative workflows in the system's hybrid LangGraph architecture. The agent constructs an extensive Devito knowledge graph through document parsing, structure-aware segmentation, extraction of entity relationships, and Leiden-based community detection. GraphRAG optimisation enhances query performance across semantic communities that include seismic wave simulation, computational fluid dynamics, and performance tuning libraries. A reverse engineering component derives three-level query strategies for RAG retrieval through static analysis of Fortran source code. To deliver precise contextual information for language model guidance, the multi-stage retrieval pipeline performs parallel searching, concept expansion, community-scale retrieval, and semantic similarity analysis. Code synthesis is governed by Pydantic-based constraints to guarantee structured outputs and reliability. A comprehensive validation framework integrates conventional static analysis with the G-Eval approach, covering execution correctness, structural soundness, mathematical consistency, and API compliance. The overall agent workflow is implemented on the LangGraph framework and adopts concurrent processing to support quality-based iterative refinement and state-aware dynamic routing. The principal contribution lies in the incorporation of feedback mechanisms motivated by reinforcement learning, enabling a transition from static code translation toward dynamic and adaptive analytical behavior.",
    "published": "2026-01-26T11:31:00Z",
    "updated": "2026-01-26T11:31:00Z",
    "link": "http://arxiv.org/pdf/2601.18381v1.pdf",
    "category": [
      "cs.AI",
      "cs.SE"
    ],
    "authors": [
      "Yinghan Hou",
      "Zongyou Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.04235v3",
    "title": "Shared Spatial Memory Through Predictive Coding",
    "summary": "Constructing a consistent shared spatial memory is a critical challenge in multi-agent systems, where partial observability and limited bandwidth often lead to catastrophic failures in coordination. We introduce a multi-agent predictive coding framework that formulates coordination as the minimization of mutual uncertainty among agents. Through an information bottleneck objective, this framework prompts agents to learn not only who and what to communicate but also when. At the foundation of this framework lies a grid-cell-like metric as internal spatial coding for self-localization, emerging spontaneously from self-supervised motion prediction. Building upon this internal spatial code, agents gradually develop a bandwidth-efficient communication mechanism and specialized neural populations that encode partners' locations-an artificial analogue of hippocampal social place cells (SPCs). These social representations are further utilized by a hierarchical reinforcement learning policy that actively explores to reduce joint uncertainty. On the Memory-Maze benchmark, our approach shows exceptional resilience to bandwidth constraints: success degrades gracefully from 73.5% to 64.4% as bandwidth shrinks from 128 to 4 bits/step, whereas a full-broadcast baseline collapses from 67.6% to 28.6%. Our findings establish a theoretically principled and biologically plausible basis for how complex social representations emerge from a unified predictive drive, leading to collective intelligence.",
    "published": "2025-11-06T10:12:46Z",
    "updated": "2026-01-26T11:24:30Z",
    "link": "http://arxiv.org/pdf/2511.04235v3.pdf",
    "category": [
      "cs.AI",
      "cs.CE"
    ],
    "authors": [
      "Zhengru Fang",
      "Yu Guo",
      "Jingjing Wang",
      "Yuang Zhang",
      "Haonan An",
      "Yinhai Wang",
      "Wenbo Ding",
      "Yuguang Fang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.21448v3",
    "title": "Constructing and Benchmarking: a Labeled Email Dataset for Text-Based Phishing and Spam Detection Framework",
    "summary": "Phishing and spam emails remain a major cybersecurity threat, with attackers increasingly leveraging Large Language Models (LLMs) to craft highly deceptive content. This study presents a comprehensive email dataset containing phishing, spam, and legitimate messages, explicitly distinguishing between human- and LLM-generated content. Each email is annotated with its category, emotional appeal (e.g., urgency, fear, authority), and underlying motivation (e.g., link-following, credential theft, financial fraud). We benchmark multiple LLMs on their ability to identify these emotional and motivational cues and select the most reliable model to annotate the full dataset. To evaluate classification robustness, emails were also rephrased using several LLMs while preserving meaning and intent. A state-of-the-art LLM was then assessed on its performance across both original and rephrased emails using expert-labeled ground truth. The results highlight strong phishing detection capabilities but reveal persistent challenges in distinguishing spam from legitimate emails. Our dataset and evaluation framework contribute to improving AI-assisted email security systems. To support open science, all code, templates, and resources are available on our project site.",
    "published": "2025-11-26T14:40:06Z",
    "updated": "2026-01-26T11:12:45Z",
    "link": "http://arxiv.org/pdf/2511.21448v3.pdf",
    "category": [
      "cs.CR",
      "cs.AI",
      "cs.DB"
    ],
    "authors": [
      "Rebeka Toth",
      "Tamas Bisztray",
      "Richard Dubniczky"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.02015v3",
    "title": "Surprisal and Metaphor Novelty Judgments: Moderate Correlations and Divergent Scaling Effects Revealed by Corpus-Based and Synthetic Datasets",
    "summary": "Novel metaphor comprehension involves complex semantic processes and linguistic creativity, making it an interesting task for studying language models (LMs). This study investigates whether surprisal, a probabilistic measure of predictability in LMs, correlates with annotations of metaphor novelty in different datasets. We analyse the surprisal of metaphoric words in corpus-based and synthetic metaphor datasets using 16 causal LM variants. We propose a cloze-style surprisal method that conditions on full-sentence context. Results show that LM surprisal yields significant moderate correlations with scores/labels of metaphor novelty. We further identify divergent scaling patterns: on corpus-based data, correlation strength decreases with model size (inverse scaling effect), whereas on synthetic data it increases (quality-power hypothesis). We conclude that while surprisal can partially account for annotations of metaphor novelty, it remains limited as a metric of linguistic creativity. Code and data are publicly available: https://github.com/OmarMomen14/surprisal-metaphor-novelty",
    "published": "2026-01-05T11:24:33Z",
    "updated": "2026-01-26T11:00:39Z",
    "link": "http://arxiv.org/pdf/2601.02015v3.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.IT"
    ],
    "authors": [
      "Omar Momen",
      "Emilie Sitter",
      "Berenike Herrmann",
      "Sina Zarrieß"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18353v1",
    "title": "Can Good Writing Be Generative? Expert-Level AI Writing Emerges through Fine-Tuning on High-Quality Books",
    "summary": "Creative writing has long been considered a uniquely human endeavor, requiring voice and style that machines could not replicate. This assumption is challenged by Generative AI that can emulate thousands of author styles in seconds with negligible marginal labor. To understand this better, we conducted a behavioral experiment where 28 MFA writers (experts) competed against three LLMs in emulating 50 critically acclaimed authors. Based on blind pairwise comparisons by 28 expert judges and 131 lay judges, we find that experts preferred human writing in 82.7% of cases under the in-context prompting condition but this reversed to 62% preference for AI after fine-tuning on authors' complete works. Lay judges, however, consistently preferred AI writing. Debrief interviews with expert writers revealed that their preference for AI writing triggered an identity crisis, eroding aesthetic confidence and questioning what constitutes \"good writing.\" These findings challenge discourse about AI's creative limitations and raise fundamental questions about the future of creative labor.",
    "published": "2026-01-26T10:59:21Z",
    "updated": "2026-01-26T10:59:21Z",
    "link": "http://arxiv.org/pdf/2601.18353v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "authors": [
      "Tuhin Chakrabarty",
      "Paramveer S. Dhillon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18352v1",
    "title": "Code over Words: Overcoming Semantic Inertia via Code-Grounded Reasoning",
    "summary": "LLMs struggle with Semantic Inertia: the inability to inhibit pre-trained priors (e.g., \"Lava is Dangerous\") when dynamic, in-context rules contradict them. We probe this phenomenon using Baba Is You, where physical laws are mutable text rules, enabling precise evaluation of models' ability to override learned priors when rules change. We quantatively observe that larger models can exhibit inverse scaling: they perform worse than smaller models when natural language reasoning requires suppressing pre-trained associations (e.g., accepting \"Lava is Safe\"). Our analysis attributes this to natural language encoding, which entangles descriptive semantics and logical rules, leading to persistent hallucinations of familiar physics despite explicit contradictory rules. Here we show that representing dynamics as executable code, rather than descriptive text, reverses this trend and enables effective prior inhibition. We introduce Code-Grounded Vistas (LCV), which fine-tunes models on counterfactual pairs and identifies states with contradictory rules, thereby forcing attention to logical constraints rather than visual semantics. This training-time approach outperforms expensive inference-time search methods in both efficiency and accuracy. Our results demonstrate that representation fundamentally determines whether scaling improves or impairs contextual reasoning. This challenges the assumption that larger models are universally better, with implications for domains that require dynamic overriding of learned priors.",
    "published": "2026-01-26T10:58:52Z",
    "updated": "2026-01-26T10:58:52Z",
    "link": "http://arxiv.org/pdf/2601.18352v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Manjie Xu",
      "Isabella Yin",
      "Xinyi Tu",
      "Chi Zhang",
      "Yixin Zhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18350v1",
    "title": "When Domain Pretraining Interferes with Instruction Alignment: An Empirical Study of Adapter Merging in Medical LLMs",
    "summary": "Large language models (LLMs) show strong general capability but often struggle with medical terminology precision and safety-critical instruction following. We present a case study for adapter interference in safety-critical domains using a 14B-parameter base model through a two-stage LoRA pipeline: (1) domain-adaptive pre-training (PT) to inject broad medical knowledge via continued pre-training (DAPT), and (2) supervised fine-tuning (SFT) to align the model with medical question-answering behaviors through instruction-style data. To balance instruction-following ability and domain knowledge retention, we propose Weighted Adapter Merging, linearly combining SFT and PT adapters before exporting a merged base-model checkpoint. On a held-out medical validation set (F5/F6), the merged model achieves BLEU-4 = 16.38, ROUGE-1 = 20.42, ROUGE-2 = 4.60, and ROUGE-L = 11.54 under a practical decoding configuration. We further analyze decoding sensitivity and training stability with loss curves and controlled decoding comparisons.",
    "published": "2026-01-26T10:54:06Z",
    "updated": "2026-01-26T10:54:06Z",
    "link": "http://arxiv.org/pdf/2601.18350v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Junyi Zou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.18470v4",
    "title": "SWE-EVO: Benchmarking Coding Agents in Long-Horizon Software Evolution Scenarios",
    "summary": "Existing benchmarks for AI coding agents focus on isolated, single-issue tasks such as fixing a bug or implementing a small feature. However, real-world software engineering is fundamentally a long-horizon endeavor: developers must interpret high-level requirements, plan coordinated changes across many files, and evolve codebases over multiple iterations while preserving existing functionality. We introduce SWE-EVO, a benchmark that evaluates agents on this long-horizon software evolution challenge. Constructed from release notes and version histories of seven mature open-source Python projects, SWE-EVO comprises 48 evolution tasks that require agents to implement multi-step modifications spanning an average of 21 files, validated against comprehensive test suites averaging 874 tests per instance. Experiments with state-of-the-art models reveal a striking capability gap: even GPT-5 with OpenHands achieves only a 21 percent resolution rate on SWE-EVO, compared to 65 percent on the single-issue SWE-Bench Verified. This demonstrates that current agents struggle with sustained, multi-file reasoning. We also propose Fix Rate, a fine-grained metric that captures partial progress toward solving these complex, long-horizon tasks.",
    "published": "2025-12-20T19:08:15Z",
    "updated": "2026-01-26T10:49:58Z",
    "link": "http://arxiv.org/pdf/2512.18470v4.pdf",
    "category": [
      "cs.SE",
      "cs.AI",
      "cs.MA"
    ],
    "authors": [
      "Minh V. T. Thai",
      "Tue Le",
      "Dung Nguyen Manh",
      "Huy Phan Nhat",
      "Nghi D. Q. Bui"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.15303v3",
    "title": "DSSmoothing: Toward Certified Dataset Ownership Verification for Pre-trained Language Models via Dual-Space Smoothing",
    "summary": "Large web-scale datasets have driven the rapid advancement of pre-trained language models (PLMs), but unauthorized data usage has raised serious copyright concerns. Existing dataset ownership verification (DOV) methods typically assume that watermarks remain stable during inference; however, this assumption often fails under natural noise and adversary-crafted perturbations. We propose the first certified dataset ownership verification method for PLMs under a gray-box setting (i.e., the defender can only query the suspicious model but is aware of its input representation module), based on dual-space smoothing (i.e., DSSmoothing). To address the challenges of text discreteness and semantic sensitivity, DSSmoothing introduces continuous perturbations in the embedding space to capture semantic robustness and applies controlled token reordering in the permutation space to capture sequential robustness. DSSmoothing consists of two stages: in the first stage, triggers are collaboratively embedded in both spaces to generate norm-constrained and robust watermarked datasets; in the second stage, randomized smoothing is applied in both spaces during verification to compute the watermark robustness (WR) of suspicious models and statistically compare it with the principal probability (PP) values of a set of benign models. Theoretically, DSSmoothing provides provable robustness guarantees for dataset ownership verification by ensuring that WR consistently exceeds PP under bounded dual-space perturbations. Extensive experiments on multiple representative web datasets demonstrate that DSSmoothing achieves stable and reliable verification performance and exhibits robustness against potential adaptive attacks. Our code is available at https://github.com/NcepuQiaoTing/DSSmoothing.",
    "published": "2025-10-17T04:25:32Z",
    "updated": "2026-01-26T10:46:02Z",
    "link": "http://arxiv.org/pdf/2510.15303v3.pdf",
    "category": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "authors": [
      "Ting Qiao",
      "Xing Liu",
      "Wenke Huang",
      "Jianbin Li",
      "Zhaoxin Fan",
      "Yiming Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18335v1",
    "title": "Analytic Incremental Learning For Sound Source Localization With Imbalance Rectification",
    "summary": "Sound source localization (SSL) demonstrates remarkable results in controlled settings but struggles in real-world deployment due to dual imbalance challenges: intra-task imbalance arising from long-tailed direction-of-arrival (DoA) distributions, and inter-task imbalance induced by cross-task skews and overlaps. These often lead to catastrophic forgetting, significantly degrading the localization accuracy. To mitigate these issues, we propose a unified framework with two key innovations. Specifically, we design a GCC-PHAT-based data augmentation (GDA) method that leverages peak characteristics to alleviate intra-task distribution skews. We also propose an Analytic dynamic imbalance rectifier (ADIR) with task-adaption regularization, which enables analytic updates that adapt to inter-task dynamics. On the SSLR benchmark, our proposal achieves state-of-the-art (SoTA) results of 89.0% accuracy, 5.3° mean absolute error, and 1.6 backward transfer, demonstrating robustness to evolving imbalances without exemplar storage.",
    "published": "2026-01-26T10:22:01Z",
    "updated": "2026-01-26T10:22:01Z",
    "link": "http://arxiv.org/pdf/2601.18335v1.pdf",
    "category": [
      "cs.SD",
      "cs.AI"
    ],
    "authors": [
      "Zexia Fan",
      "Yu Chen",
      "Qiquan Zhang",
      "Kainan Chen",
      "Xinyuan Qian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.20082v2",
    "title": "Evolution of AI in Education: Agentic Workflows",
    "summary": "The primary goal of this study is to analyze agentic workflows in education according to the proposed four major technological paradigms: reflection, planning, tool use, and multi-agent collaboration. We critically examine the role of AI agents in education through these key design paradigms, exploring their advantages, applications, and challenges. Second, to illustrate the practical potential of agentic systems, we present a proof-of-concept application: a multi-agent framework for automated essay scoring. Preliminary results suggest this agentic approach may offer improved consistency compared to stand-alone LLMs. Our findings highlight the transformative potential of AI agents in educational settings while underscoring the need for further research into their interpretability and trustworthiness.",
    "published": "2025-04-25T13:44:57Z",
    "updated": "2026-01-26T10:11:03Z",
    "link": "http://arxiv.org/pdf/2504.20082v2.pdf",
    "category": [
      "cs.AI",
      "cs.CY"
    ],
    "authors": [
      "Firuz Kamalov",
      "David Santandreu Calonge",
      "Linda Smail",
      "Dilshod Azizov",
      "Dimple R. Thadani",
      "Theresa Kwong",
      "Amara Atif"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19367v2",
    "title": "Sprecher Networks: A Parameter-Efficient Kolmogorov-Arnold Architecture",
    "summary": "We introduce Sprecher Networks (SNs), a family of trainable architectures derived from David Sprecher's 1965 constructive form of the Kolmogorov-Arnold representation. Each SN block implements a \"sum of shifted univariate functions\" using only two shared learnable splines per block, a monotone inner spline $φ$ and a general outer spline $Φ$, together with a learnable shift parameter $η$ and a mixing vector $λ$ shared across all output dimensions. Stacking these blocks yields deep, compositional models; for vector-valued outputs we append an additional non-summed output block.\n  We also propose an optional lateral mixing operator enabling intra-block communication between output channels with only $O(d_{\\mathrm{out}})$ additional parameters. Owing to the vector (not matrix) mixing weights and spline sharing, SNs scale linearly in width, approximately $O(\\sum_{\\ell}(d_{\\ell-1}+d_{\\ell}+G))$ parameters for $G$ spline knots, versus $O(\\sum_{\\ell} d_{\\ell-1}d_{\\ell})$ for dense MLPs and $O(G\\sum_{\\ell} d_{\\ell-1}d_{\\ell})$ for edge-spline KANs. This linear width-scaling is particularly attractive for extremely wide, shallow models, where low depth can translate into low inference latency. Finally, we describe a sequential forward implementation that avoids materializing the $d_{\\mathrm{in}}\\times d_{\\mathrm{out}}$ shifted-input tensor, reducing peak forward-intermediate memory from quadratic to linear in layer width, relevant for memory-constrained settings such as on-device/edge inference; we demonstrate deployability via fixed-point real-time digit classification on resource-constrained embedded device with only 4 MB RAM. We provide empirical demonstrations on supervised regression, Fashion-MNIST classification (including stable training at 25 hidden layers with residual connections and normalization), and a Poisson PINN, with controlled comparisons to MLP and KAN baselines.",
    "published": "2025-12-22T13:09:45Z",
    "updated": "2026-01-26T10:10:49Z",
    "link": "http://arxiv.org/pdf/2512.19367v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "math.NA"
    ],
    "authors": [
      "Christian Hägg",
      "Kathlén Kohn",
      "Giovanni Luca Marchetti",
      "Boris Shapiro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18320v1",
    "title": "MultiVis-Agent: A Multi-Agent Framework with Logic Rules for Reliable and Comprehensive Cross-Modal Data Visualization",
    "summary": "Real-world visualization tasks involve complex, multi-modal requirements that extend beyond simple text-to-chart generation, requiring reference images, code examples, and iterative refinement. Current systems exhibit fundamental limitations: single-modality input, one-shot generation, and rigid workflows. While LLM-based approaches show potential for these complex requirements, they introduce reliability challenges including catastrophic failures and infinite loop susceptibility. To address this gap, we propose MultiVis-Agent, a logic rule-enhanced multi-agent framework for reliable multi-modal and multi-scenario visualization generation. Our approach introduces a four-layer logic rule framework that provides mathematical guarantees for system reliability while maintaining flexibility. Unlike traditional rule-based systems, our logic rules are mathematical constraints that guide LLM reasoning rather than replacing it. We formalize the MultiVis task spanning four scenarios from basic generation to iterative refinement, and develop MultiVis-Bench, a benchmark with over 1,000 cases for multi-modal visualization evaluation. Extensive experiments demonstrate that our approach achieves 75.63% visualization score on challenging tasks, significantly outperforming baselines (57.54-62.79%), with task completion rates of 99.58% and code execution success rates of 94.56% (vs. 74.48% and 65.10% without logic rules), successfully addressing both complexity and reliability challenges in automated visualization generation.",
    "published": "2026-01-26T10:03:10Z",
    "updated": "2026-01-26T10:03:10Z",
    "link": "http://arxiv.org/pdf/2601.18320v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ],
    "authors": [
      "Jinwei Lu",
      "Yuanfeng Song",
      "Chen Zhang",
      "Raymond Chi-Wing Wong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.11526v3",
    "title": "Foundation Models in Autonomous Driving: A Survey on Scenario Generation and Scenario Analysis",
    "summary": "For autonomous vehicles, safe navigation in complex environments depends on handling a broad range of diverse and rare driving scenarios. Simulation- and scenario-based testing have emerged as key approaches to development and validation of autonomous driving systems. Traditional scenario generation relies on rule-based systems, knowledge-driven models, and data-driven synthesis, often producing limited diversity and unrealistic safety-critical cases. With the emergence of foundation models, which represent a new generation of pre-trained, general-purpose AI models, developers can process heterogeneous inputs (e.g., natural language, sensor data, HD maps, and control actions), enabling the synthesis and interpretation of complex driving scenarios. In this paper, we conduct a survey about the application of foundation models for scenario generation and scenario analysis in autonomous driving (as of May 2025). Our survey presents a unified taxonomy that includes large language models, vision-language models, multimodal large language models, diffusion models, and world models for the generation and analysis of autonomous driving scenarios. In addition, we review the methodologies, open-source datasets, simulation platforms, and benchmark challenges, and we examine the evaluation metrics tailored explicitly to scenario generation and analysis. Finally, the survey concludes by highlighting the open challenges and research questions, and outlining promising future research directions. All reviewed papers are listed in a continuously maintained repository, which contains supplementary materials and is available at https://github.com/TUM-AVS/FM-for-Scenario-Generation-Analysis.",
    "published": "2025-06-13T07:25:59Z",
    "updated": "2026-01-26T09:55:34Z",
    "link": "http://arxiv.org/pdf/2506.11526v3.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Yuan Gao",
      "Mattia Piccinini",
      "Yuchen Zhang",
      "Dingrui Wang",
      "Korbinian Moller",
      "Roberto Brusnicki",
      "Baha Zarrouki",
      "Alessio Gambi",
      "Jan Frederik Totz",
      "Kai Storms",
      "Steven Peters",
      "Andrea Stocco",
      "Bassam Alrifaee",
      "Marco Pavone",
      "Johannes Betz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2407.00449v5",
    "title": "Fully tensorial approach to hypercomplex-valued neural networks",
    "summary": "A fully tensorial theoretical framework for hypercomplex-valued neural networks is presented. The proposed approach enables neural network architectures to operate on data defined over arbitrary finite-dimensional algebras. The central observation is that algebra multiplication can be represented by a rank-three tensor, which allows all algebraic operations in neural network layers to be formulated in terms of standard tensor contractions, permutations, and reshaping operations.\n  This tensor-based formulation provides a unified and dimension-independent description of hypercomplex-valued dense and convolutional layers and is directly compatible with modern deep learning libraries supporting optimized tensor operations. The proposed framework recovers existing constructions for four-dimensional algebras as a special case.\n  Within this setting, a tensor-based version of the universal approximation theorem for single-layer hypercomplex-valued perceptrons is established under mild non-degeneracy assumptions on the underlying algebra, thereby providing a rigorous theoretical foundation for the considered class of neural networks.",
    "published": "2024-06-29T14:19:40Z",
    "updated": "2026-01-26T09:51:42Z",
    "link": "http://arxiv.org/pdf/2407.00449v5.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "authors": [
      "Agnieszka Niemczynowicz",
      "Radosław Antoni Kycia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18308v1",
    "title": "A Generative AI-Driven Reliability Layer for Action-Oriented Disaster Resilience",
    "summary": "As climate-related hazards intensify, conventional early warning systems (EWS) disseminate alerts rapidly but often fail to trigger timely protective actions, leading to preventable losses and inequities. We introduce Climate RADAR (Risk-Aware, Dynamic, and Action Recommendation system), a generative AI-based reliability layer that reframes disaster communication from alerts delivered to actions executed. It integrates meteorological, hydrological, vulnerability, and social data into a composite risk index and employs guardrail-embedded large language models (LLMs) to deliver personalized recommendations across citizen, volunteer, and municipal interfaces. Evaluation through simulations, user studies, and a municipal pilot shows improved outcomes, including higher protective action execution, reduced response latency, and increased usability and trust. By combining predictive analytics, behavioral science, and responsible AI, Climate RADAR advances people-centered, transparent, and equitable early warning systems, offering practical pathways toward compliance-ready disaster resilience infrastructures.",
    "published": "2026-01-26T09:43:30Z",
    "updated": "2026-01-26T09:43:30Z",
    "link": "http://arxiv.org/pdf/2601.18308v1.pdf",
    "category": [
      "cs.AI",
      "cs.SI",
      "eess.SY"
    ],
    "authors": [
      "Geunsik Lim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18306v1",
    "title": "Calibrating Beyond English: Language Diversity for Better Quantized Multilingual LLM",
    "summary": "Quantization is an effective technique for reducing the storage footprint and computational costs of Large Language Models (LLMs), but it often results in performance degradation. Existing post-training quantization methods typically use small, English-only calibration sets; however, their impact on multilingual models remains underexplored. We systematically evaluate eight calibration settings (five single-language and three multilingual mixes) on two quantizers (GPTQ, AWQ) on data from 10 languages. Our findings reveal a consistent trend: non-English and multilingual calibration sets significantly improve perplexity compared to English-only baselines. Specifically, we observe notable average perplexity gains across both quantizers on Llama3.1 8B and Qwen2.5 7B, with multilingual mixes achieving the largest overall reductions of up to 3.52 points in perplexity. Furthermore, our analysis indicates that tailoring calibration sets to the evaluation language yields the largest improvements for individual languages, underscoring the importance of linguistic alignment. We also identify specific failure cases where certain language-quantizer combinations degrade performance, which we trace to differences in activation range distributions across languages. These results highlight that static one-size-fits-all calibration is suboptimal and that tailoring calibration data, both in language and diversity, plays a crucial role in robustly quantizing multilingual LLMs.",
    "published": "2026-01-26T09:36:03Z",
    "updated": "2026-01-26T09:36:03Z",
    "link": "http://arxiv.org/pdf/2601.18306v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Everlyn Asiko Chimoto",
      "Mostafa Elhoushi",
      "Bruce A. Bassett"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01289v2",
    "title": "OntoMetric: An Ontology-Driven LLM-Assisted Framework for Automated ESG Metric Knowledge Graph Generation",
    "summary": "Environmental, Social, and Governance (ESG) metric knowledge is inherently structured, connecting industries, reporting frameworks, metric categories, metrics, and calculation models through compositional dependencies, yet in practice this structure remains embedded implicitly in regulatory documents such as SASB, TCFD, and IFRS S2 and rarely exists as an explicit, governed, or machine-actionable artefact. Existing ESG ontologies define formal schemas but do not address scalable population and governance from authoritative regulatory sources, while unconstrained large language model (LLM) extraction frequently produces semantically incorrect entities, hallucinated relationships, and structurally invalid graphs. OntoMetric is an ontology-guided framework for the automated construction and governance of ESG metric knowledge graphs from regulatory documents that operationalises the ESG Metric Knowledge Graph (ESGMKG) ontology as a first-class constraint embedded directly into the extraction and population process. The framework integrates structure-aware segmentation, ontology-constrained LLM extraction enriched with semantic fields and deterministic identifiers, and two-phase validation combining semantic type verification with rule-based schema checking, while preserving segment-level and page-level provenance to ensure traceability to regulatory source text. Evaluation on five ESG regulatory standards shows that ontology-guided extraction achieves 65-90 percent semantic accuracy and over 80 percent schema compliance, compared with 3-10 percent for unconstrained baseline extraction, and yields stable cost efficiency with a cost per validated entity of 0.01-0.02 USD and a 48 times efficiency improvement over baseline.",
    "published": "2025-12-01T05:21:22Z",
    "updated": "2026-01-26T09:28:23Z",
    "link": "http://arxiv.org/pdf/2512.01289v2.pdf",
    "category": [
      "cs.AI",
      "cs.GR"
    ],
    "authors": [
      "Mingqin Yu",
      "Fethi Rabhi",
      "Boming Xia",
      "Zhengyi Yang",
      "Felix Tan",
      "Qinghua Lu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18296v1",
    "title": "Temp-R1: A Unified Autonomous Agent for Complex Temporal KGQA via Reverse Curriculum Reinforcement Learning",
    "summary": "Temporal Knowledge Graph Question Answering (TKGQA) is inherently challenging, as it requires sophisticated reasoning over dynamic facts with multi-hop dependencies and complex temporal constraints. Existing methods rely on fixed workflows and expensive closed-source APIs, limiting flexibility and scalability. We propose Temp-R1, the first autonomous end-to-end agent for TKGQA trained through reinforcement learning. To address cognitive overload in single-action reasoning, we expand the action space with specialized internal actions alongside external action. To prevent shortcut learning on simple questions, we introduce reverse curriculum learning that trains on difficult questions first, forcing the development of sophisticated reasoning before transferring to easier cases. Our 8B-parameter Temp-R1 achieves state-of-the-art performance on MultiTQ and TimelineKGQA, improving 19.8% over strong baselines on complex questions. Our work establishes a new paradigm for autonomous temporal reasoning agents. Our code will be publicly available soon at https://github.com/zjukg/Temp-R1.",
    "published": "2026-01-26T09:23:53Z",
    "updated": "2026-01-26T09:23:53Z",
    "link": "http://arxiv.org/pdf/2601.18296v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Zhaoyan Gong",
      "Zhiqiang Liu",
      "Songze Li",
      "Xiaoke Guo",
      "Yuanxiang Liu",
      "Xinle Deng",
      "Zhizhen Liu",
      "Lei Liang",
      "Huajun Chen",
      "Wen Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18292v1",
    "title": "TriPlay-RL: Tri-Role Self-Play Reinforcement Learning for LLM Safety Alignment",
    "summary": "In recent years, safety risks associated with large language models have become increasingly prominent, highlighting the urgent need to mitigate the generation of toxic and harmful content. The mainstream paradigm for LLM safety alignment typically adopts a collaborative framework involving three roles: an attacker for adversarial prompt generation, a defender for safety defense, and an evaluator for response assessment. In this paper, we propose a closed-loop reinforcement learning framework called TriPlay-RL that enables iterative and co-improving collaboration among three roles with near-zero manual annotation. Experimental results show that the attacker preserves high output diversity while achieving a 20%-50% improvement in adversarial effectiveness; the defender attains 10%-30% gains in safety performance without degrading general reasoning capability; and the evaluator continuously refines its fine-grained judgment ability through iterations, accurately distinguishing unsafe responses, simple refusals, and useful guidance. Overall, our framework establishes an efficient and scalable paradigm for LLM safety alignment, enabling continuous co-evolution within a unified learning loop.",
    "published": "2026-01-26T09:21:43Z",
    "updated": "2026-01-26T09:21:43Z",
    "link": "http://arxiv.org/pdf/2601.18292v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Zhewen Tan",
      "Wenhan Yu",
      "Jianfeng Si",
      "Tongxin Liu",
      "Kaiqi Guan",
      "Huiyan Jin",
      "Jiawen Tao",
      "Xiaokun Yuan",
      "Duohe Ma",
      "Xiangzheng Zhang",
      "Tong Yang",
      "Lin Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.13588v3",
    "title": "CoBRA: Programming Cognitive Bias in Social Agents Using Classic Social Science Experiments",
    "summary": "This paper introduces CoBRA, a novel toolkit for systematically specifying agent behavior in LLM-based social simulation. We found that conventional approaches that specify agent behavior through implicit natural-language descriptions often do not yield consistent behavior across models, and the resulting behavior does not capture the nuances of the descriptions. In contrast, CoBRA introduces a model-agnostic way to control agent behavior that lets researchers explicitly specify desired nuances and obtain consistent behavior across models. At the heart of CoBRA is a novel closed-loop system primitive with two components: (1) Cognitive Bias Index that measures the demonstrated cognitive bias of a social agent, by quantifying the agent's reactions in a set of validated classic social science experiments; (2) Behavioral Regulation Engine that aligns the agent's behavior to exhibit controlled cognitive bias. Through CoBRA, we show how to operationalize validated social science knowledge (i.e., classical experiments) as reusable \"gym\" environments for AI -- an approach that may generalize to richer social and affective simulations beyond bias alone.",
    "published": "2025-09-16T23:03:02Z",
    "updated": "2026-01-26T09:12:21Z",
    "link": "http://arxiv.org/pdf/2509.13588v3.pdf",
    "category": [
      "cs.AI",
      "cs.CE",
      "cs.CY"
    ],
    "authors": [
      "Xuan Liu",
      "Haoyang Shang",
      "Haojian Jin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18282v1",
    "title": "Think-Augmented Function Calling: Improving LLM Parameter Accuracy Through Embedded Reasoning",
    "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in function calling for autonomous agents, yet current mechanisms lack explicit reasoning transparency during parameter generation, particularly for complex functions with interdependent parameters. While existing approaches like chain-of-thought prompting operate at the agent level, they fail to provide fine-grained reasoning guidance for individual function parameters. To address these limitations, we propose Think-Augmented Function Calling (TAFC), a novel framework that enhances function calling accuracy through explicit reasoning at both function and parameter levels. Our method introduces a universal \"think\" parameter augmentation that enables models to articulate their decision-making process, with dynamic optimization for parameter descriptions to improve reasoning quality. For complex parameters, TAFC automatically triggers granular reasoning based on complexity scoring, ensuring appropriate justification for critical decisions. Additionally, we propose reasoning-guided optimization to align generated reasoning with human expectations. TAFC requires no architectural modifications to existing LLMs while maintaining full API compatibility. Evaluation on ToolBench across proprietary and open-source models demonstrates significant improvements in parameter generation accuracy and reasoning coherence for multi-parameter functions, while providing enhanced interpretability for debugging AI agent behaviors.",
    "published": "2026-01-26T09:05:00Z",
    "updated": "2026-01-26T09:05:00Z",
    "link": "http://arxiv.org/pdf/2601.18282v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Lei Wei",
      "Jinpeng Ou",
      "Xiao Peng",
      "Bin Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18278v1",
    "title": "What Do Learned Models Measure?",
    "summary": "In many scientific and data-driven applications, machine learning models are increasingly used as measurement instruments, rather than merely as predictors of predefined labels. When the measurement function is learned from data, the mapping from observations to quantities is determined implicitly by the training distribution and inductive biases, allowing multiple inequivalent mappings to satisfy standard predictive evaluation criteria. We formalize learned measurement functions as a distinct focus of evaluation and introduce measurement stability, a property capturing invariance of the measured quantity across admissible realizations of the learning process and across contexts. We show that standard evaluation criteria in machine learning, including generalization error, calibration, and robustness, do not guarantee measurement stability. Through a real-world case study, we show that models with comparable predictive performance can implement systematically inequivalent measurement functions, with distribution shift providing a concrete illustration of this failure. Taken together, our results highlight a limitation of existing evaluation frameworks in settings where learned model outputs are identified as measurements, motivating the need for an additional evaluative dimension.",
    "published": "2026-01-26T09:00:48Z",
    "updated": "2026-01-26T09:00:48Z",
    "link": "http://arxiv.org/pdf/2601.18278v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Indrė Žliobaitė"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.16387v2",
    "title": "Probing the Hidden Talent of ASR Foundation Models for L2 English Oral Assessment",
    "summary": "In this paper, we explore the untapped potential of Whisper, a well-established automatic speech recognition (ASR) foundation model, in the context of L2 spoken language assessment (SLA). Unlike prior studies that extrinsically analyze transcriptions produced by Whisper, our approach goes a step further to probe its latent capabilities by extracting acoustic and linguistic features from hidden representations. With only a lightweight classifier being trained on top of Whisper's intermediate and final outputs, our method achieves strong performance on the GEPT picture-description dataset, outperforming existing cutting-edge baselines, including a multimodal approach. Furthermore, by incorporating image and text-prompt information as auxiliary relevance cues, we demonstrate additional performance gains. Finally, we conduct an in-depth analysis of Whisper's embeddings, which reveals that, even without task-specific fine-tuning, the model intrinsically encodes both ordinal proficiency patterns and semantic aspects of speech, highlighting its potential as a powerful foundation for SLA and other spoken language understanding tasks.",
    "published": "2025-10-18T08:10:24Z",
    "updated": "2026-01-26T08:58:34Z",
    "link": "http://arxiv.org/pdf/2510.16387v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "authors": [
      "Fu-An Chao",
      "Bi-Cheng Yan",
      "Berlin Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.14125v3",
    "title": "Contrastive Consolidation of Top-Down Modulations Achieves Sparsely Supervised Continual Learning",
    "summary": "Biological brains learn continually from a stream of unlabeled data, while integrating specialized information from sparsely labeled examples without compromising their ability to generalize. Meanwhile, machine learning methods are susceptible to catastrophic forgetting in this natural learning setting, as supervised specialist fine-tuning degrades performance on the original task. We introduce task-modulated contrastive learning (TMCL), which takes inspiration from the biophysical machinery in the neocortex, using predictive coding principles to integrate top-down information continually and without supervision. We follow the idea that these principles build a view-invariant representation space, and that this can be implemented using a contrastive loss. Then, whenever labeled samples of a new class occur, new affine modulations are learned that improve separation of the new class from all others, without affecting feedforward weights. By co-opting the view-invariance learning mechanism, we then train feedforward weights to match the unmodulated representation of a data sample to its modulated counterparts. This introduces modulation invariance into the representation space, and, by also using past modulations, stabilizes it. Our experiments show improvements in both class-incremental and transfer learning over state-of-the-art unsupervised approaches, as well as over comparable supervised approaches, using as few as 1% of available labels. Taken together, our work suggests that top-down modulations play a crucial role in balancing stability and plasticity.",
    "published": "2025-05-20T09:31:57Z",
    "updated": "2026-01-26T08:58:24Z",
    "link": "http://arxiv.org/pdf/2505.14125v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "q-bio.NC"
    ],
    "authors": [
      "Viet Anh Khoa Tran",
      "Emre Neftci",
      "Willem A. M. Wybo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.25236v2",
    "title": "Networks of Causal Abstractions: A Sheaf-theoretic Framework",
    "summary": "Causal artificial intelligence aims to improve explainability, robustness, and trustworthiness by leveraging causal models. Recent work has shown that sheaf-theoretic approaches offer a principled framework for representing and aligning causal knowledge across collections of subjective and imperfect causal models connected by relational structures. In this work, we introduce the causal abstraction network (CAN), a general sheaf-theoretic framework for representing, learning, and reasoning across collections of mixture causal models (MCMs). CAN formalizes causal abstraction relations among subjective MCMs operating at different levels of granularity, while remaining agnostic to explicit causal graphs, functional mechanisms, interventional data, or jointly sampled observations. At the theoretical level, we provide a categorical formulation of MCMs and characterize key properties of CANs, including consistency, smoothness, and the existence of global sections, which are related to spectral properties of an associated combinatorial Laplacian. At the methodological level, we address the problem of learning consistent CANs from data by exploiting the compositionality of causal abstractions and necessary conditions for their existence. The learning task decomposes into local problems on the network edges, for which we propose efficient solutions in Gaussian and Gaussian mixture settings. We validate the proposed learning methods on synthetic data and illustrate the practical relevance of the CAN framework through a financial application, demonstrating both recovery and counterfactual reasoning capabilities.",
    "published": "2025-09-25T07:48:25Z",
    "updated": "2026-01-26T08:47:17Z",
    "link": "http://arxiv.org/pdf/2509.25236v2.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "authors": [
      "Gabriele D'Acunto",
      "Paolo Di Lorenzo",
      "Sergio Barbarossa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18264v1",
    "title": "Neural Network Approximation: A View from Polytope Decomposition",
    "summary": "Universal approximation theory offers a foundational framework to verify neural network expressiveness, enabling principled utilization in real-world applications. However, most existing theoretical constructions are established by uniformly dividing the input space into tiny hypercubes without considering the local regularity of the target function. In this work, we investigate the universal approximation capabilities of ReLU networks from a view of polytope decomposition, which offers a more realistic and task-oriented approach compared to current methods. To achieve this, we develop an explicit kernel polynomial method to derive an universal approximation of continuous functions, which is characterized not only by the refined Totik-Ditzian-type modulus of continuity, but also by polytopical domain decomposition. Then, a ReLU network is constructed to approximate the kernel polynomial in each subdomain separately. Furthermore, we find that polytope decomposition makes our approximation more efficient and flexible than existing methods in many cases, especially near singular points of the objective function. Lastly, we extend our approach to analytic functions to reach a higher approximation rate.",
    "published": "2026-01-26T08:39:11Z",
    "updated": "2026-01-26T08:39:11Z",
    "link": "http://arxiv.org/pdf/2601.18264v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "ZeYu Li",
      "ShiJun Zhang",
      "TieYong Zeng",
      "FengLei Fan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.18135v2",
    "title": "SDGF: Fusing Static and Multi-Scale Dynamic Correlations for Multivariate Time Series Forecasting",
    "summary": "Accurate multivariate time series forecasting hinges on inter-series correlations, which often evolve in complex ways across different temporal scales. Existing methods are limited in modeling these multi-scale dependencies and struggle to capture their intricate and evolving nature. To address this challenge, this paper proposes a novel Static-Dynamic Graph Fusion network (SDGF), whose core lies in capturing multi-scale inter-series correlations through a dual-path graph structure learning approach. Specifically, the model utilizes a static graph based on prior knowledge to anchor long-term, stable dependencies, while concurrently employing Multi-level Wavelet Decomposition to extract multi-scale features for constructing an adaptively learned dynamic graph to capture associations at different scales. We design an attention-gated module to fuse these two complementary sources of information intelligently, and a multi-kernel dilated convolutional network is then used to deepen the understanding of temporal patterns. Comprehensive experiments on multiple widely used real-world benchmark datasets demonstrate the effectiveness of our proposed model. Code is available at https://github.com/shaoxun6033/SDGFNet.",
    "published": "2025-09-14T11:23:12Z",
    "updated": "2026-01-26T08:35:47Z",
    "link": "http://arxiv.org/pdf/2509.18135v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Shaoxun Wang",
      "Xingjun Zhang",
      "Qianyang Li",
      "Jiawei Cao",
      "Zhendong Tan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.15165v2",
    "title": "The Flexibility Trap: Why Arbitrary Order Limits Reasoning Potential in Diffusion Language Models",
    "summary": "Diffusion Large Language Models (dLLMs) break the rigid left-to-right constraint of traditional LLMs, enabling token generation in arbitrary orders. Intuitively, this flexibility implies a solution space that strictly supersets the fixed autoregressive trajectory, theoretically unlocking superior reasoning potential for general tasks like mathematics and coding. Consequently, numerous works have leveraged reinforcement learning (RL) to elicit the reasoning capability of dLLMs. In this paper, we reveal a counter-intuitive reality: arbitrary order generation, in its current form, narrows rather than expands the reasoning boundary of dLLMs. We find that dLLMs tend to exploit this order flexibility to bypass high-uncertainty tokens that are crucial for exploration, leading to a premature collapse of the solution space. This observation motivates a rethink of RL approaches for dLLMs, where considerable complexities, such as handling combinatorial trajectories and intractable likelihoods, are often devoted to preserving this flexibility. We demonstrate that effective reasoning can be better elicited by intentionally forgoing arbitrary order and applying standard Group Relative Policy Optimization (GRPO) instead. Our approach, JustGRPO, is minimalist yet surprisingly effective (e.g., 89.1% accuracy on GSM8K) while fully retaining the parallel decoding ability of dLLMs. Project page: https://nzl-thu.github.io/the-flexibility-trap",
    "published": "2026-01-21T16:41:58Z",
    "updated": "2026-01-26T08:29:32Z",
    "link": "http://arxiv.org/pdf/2601.15165v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Zanlin Ni",
      "Shenzhi Wang",
      "Yang Yue",
      "Tianyu Yu",
      "Weilin Zhao",
      "Yeguo Hua",
      "Tianyi Chen",
      "Jun Song",
      "Cheng Yu",
      "Bo Zheng",
      "Gao Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18255v1",
    "title": "Beyond Retention: Orchestrating Structural Safety and Plasticity in Continual Learning for LLMs",
    "summary": "Continual learning in Large Language Models (LLMs) faces the critical challenge of balancing stability (retaining old knowledge) and plasticity (learning new tasks). While Experience Replay (ER) is a standard countermeasure against catastrophic forgetting, its impact across diverse capabilities remains underexplored. In this work, we uncover a critical dichotomy in ER's behavior: while it induces positive backward transfer on robust, unstructured tasks (e.g., boosting performance on previous NLP classification tasks through repeated rehearsal), it causes severe negative transfer on fragile, structured domains like code generation (e.g., a significant relative drop in coding accuracy). This reveals that ER trades structural integrity for broad consolidation. To address this dilemma, we propose \\textbf{Orthogonal Subspace Wake-up (OSW)}. OSW identifies essential parameter subspaces of previous tasks via a brief \"wake-up\" phase and enforces orthogonal updates for new tasks, providing a mathematically grounded \"safety guarantee\" for established knowledge structures. Empirical results across a diverse four-task sequence demonstrate that OSW uniquely succeeds in preserving fragile coding abilities where Replay fails, while simultaneously maintaining high plasticity for novel tasks. Our findings emphasize the necessity of evaluating structural safety alongside average retention in LLM continual learning.",
    "published": "2026-01-26T08:28:02Z",
    "updated": "2026-01-26T08:28:02Z",
    "link": "http://arxiv.org/pdf/2601.18255v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Fei Meng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18253v1",
    "title": "BoRP: Bootstrapped Regression Probing for Scalable and Human-Aligned LLM Evaluation",
    "summary": "Accurate evaluation of user satisfaction is critical for iterative development of conversational AI. However, for open-ended assistants, traditional A/B testing lacks reliable metrics: explicit feedback is sparse, while implicit metrics are ambiguous. To bridge this gap, we introduce BoRP (Bootstrapped Regression Probing), a scalable framework for high-fidelity satisfaction evaluation. Unlike generative approaches, BoRP leverages the geometric properties of LLM latent space. It employs a polarization-index-based bootstrapping mechanism to automate rubric generation and utilizes Partial Least Squares (PLS) to map hidden states to continuous scores. Experiments on industrial datasets show that BoRP (Qwen3-8B/14B) significantly outperforms generative baselines (even Qwen3-Max) in alignment with human judgments. Furthermore, BoRP reduces inference costs by orders of magnitude, enabling full-scale monitoring and highly sensitive A/B testing via CUPED.",
    "published": "2026-01-26T08:20:02Z",
    "updated": "2026-01-26T08:20:02Z",
    "link": "http://arxiv.org/pdf/2601.18253v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Peng Sun",
      "Xiangyu Zhang",
      "Duan Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.14788v2",
    "title": "Structure-Aware Contrastive Learning with Fine-Grained Binding Representations for Drug Discovery",
    "summary": "Accurate identification of drug-target interactions (DTI) remains a central challenge in computational pharmacology, where sequence-based methods offer scalability. This work introduces a sequence-based drug-target interaction framework that integrates structural priors into protein representations while maintaining high-throughput screening capability. Evaluated across multiple benchmarks, the model achieves state-of-the-art performance on Human and BioSNAP datasets and remains competitive on BindingDB. In virtual screening tasks, it surpasses prior methods on LIT-PCBA, yielding substantial gains in AUROC and BEDROC. Ablation studies confirm the critical role of learned aggregation, bilinear attention, and contrastive alignment in enhancing predictive robustness. Embedding visualizations reveal improved spatial correspondence with known binding pockets and highlight interpretable attention patterns over ligand-residue contacts. These results validate the framework's utility for scalable and structure-aware DTI prediction.",
    "published": "2025-09-18T09:38:46Z",
    "updated": "2026-01-26T08:19:42Z",
    "link": "http://arxiv.org/pdf/2509.14788v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "authors": [
      "Jing Lan",
      "Hexiao Ding",
      "Hongzhao Chen",
      "Yufeng Jiang",
      "Nga-Chun Ng",
      "Gwing Kei Yip",
      "Gerald W. Y. Cheng",
      "Yunlin Mao",
      "Jing Cai",
      "Liang-ting Lin",
      "Jung Sun Yoo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18252v1",
    "title": "Co-PLNet: A Collaborative Point-Line Network for Prompt-Guided Wireframe Parsing",
    "summary": "Wireframe parsing aims to recover line segments and their junctions to form a structured geometric representation useful for downstream tasks such as Simultaneous Localization and Mapping (SLAM). Existing methods predict lines and junctions separately and reconcile them post-hoc, causing mismatches and reduced robustness. We present Co-PLNet, a point-line collaborative framework that exchanges spatial cues between the two tasks, where early detections are converted into spatial prompts via a Point-Line Prompt Encoder (PLP-Encoder), which encodes geometric attributes into compact and spatially aligned maps. A Cross-Guidance Line Decoder (CGL-Decoder) then refines predictions with sparse attention conditioned on complementary prompts, enforcing point-line consistency and efficiency. Experiments on Wireframe and YorkUrban show consistent improvements in accuracy and robustness, together with favorable real-time efficiency, demonstrating our effectiveness for structured geometry perception.",
    "published": "2026-01-26T08:16:02Z",
    "updated": "2026-01-26T08:16:02Z",
    "link": "http://arxiv.org/pdf/2601.18252v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Chao Wang",
      "Xuanying Li",
      "Cheng Dai",
      "Jinglei Feng",
      "Yuxiang Luo",
      "Yuqi Ouyang",
      "Hao Qin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18250v1",
    "title": "A multimodal vision foundation model for generalizable knee pathology",
    "summary": "Musculoskeletal disorders represent a leading cause of global disability, creating an urgent demand for precise interpretation of medical imaging. Current artificial intelligence (AI) approaches in orthopedics predominantly rely on task-specific, supervised learning paradigms. These methods are inherently fragmented, require extensive annotated datasets, and often lack generalizability across different modalities and clinical scenarios. The development of foundation models in this field has been constrained by the scarcity of large-scale, curated, and open-source musculoskeletal datasets. To address these challenges, we introduce OrthoFoundation, a multimodal vision foundation model optimized for musculoskeletal pathology. We constructed a pre-training dataset of 1.2 million unlabeled knee X-ray and MRI images from internal and public databases. Utilizing a Dinov3 backbone, the model was trained via self-supervised contrastive learning to capture robust radiological representations. OrthoFoundation achieves state-of-the-art (SOTA) performance across 14 downstream tasks. It attained superior accuracy in X-ray osteoarthritis diagnosis and ranked first in MRI structural injury detection. The model demonstrated remarkable label efficiency, matching supervised baselines using only 50% of labeled data. Furthermore, despite being pre-trained on knee images, OrthoFoundation exhibited exceptional cross-anatomy generalization to the hip, shoulder, and ankle. OrthoFoundation represents a significant advancement toward general-purpose AI for musculoskeletal imaging. By learning fundamental, joint-agnostic radiological semantics from large-scale multimodal data, it overcomes the limitations of conventional models, which provides a robust framework for reducing annotation burdens and enhancing diagnostic accuracy in clinical practice.",
    "published": "2026-01-26T08:14:51Z",
    "updated": "2026-01-26T08:14:51Z",
    "link": "http://arxiv.org/pdf/2601.18250v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Kang Yu",
      "Dingyu Wang",
      "Zimu Yuan",
      "Nan Zhou",
      "Jiajun Liu",
      "Jiaxin Liu",
      "Shanggui Liu",
      "Yaoyan Zheng",
      "Huishu Yuan",
      "Di Huang",
      "Dong Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.17218v2",
    "title": "Generalized Policy Gradient with History-Aware Decision Transformer for Path Planning",
    "summary": "With the rapidly increased number of vehicles in urban areas, existing road infrastructure struggles to accommodate modern traffic demands, resulting in congestion. This highlights the importance of efficient path planning strategies. Most recent navigation models focus on deterministic or time-dependent networks, overlooking correlations and the stochastic nature of traffic flows. In this work, we address the reliable shortest path problem in stochastic transportation networks and propose a path planning solution integrating the decision Transformer with the Generalized Policy Gradient (GPG) framework. Leveraging the Transformer's ability to model long-term dependencies, our solution improves path decision accuracy and stability. Experiments on the Sioux Falls (SFN) and large Anaheim (AN) networks show consistent improvement in on-time arrival probabilities by capturing non-Markovian dependencies in historical routing decisions on real-world topologies.",
    "published": "2025-08-24T05:41:11Z",
    "updated": "2026-01-26T07:54:02Z",
    "link": "http://arxiv.org/pdf/2508.17218v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Xing Wei",
      "Duoxiang Zhao",
      "Zezhou Zhang",
      "Yuqi Ouyang",
      "Hao Qin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.09017v3",
    "title": "Value-State Gated Attention for Mitigating Extreme-Token Phenomena in Transformers",
    "summary": "Large models based on the Transformer architecture are susceptible to extreme-token phenomena, such as attention sinks and value-state drains. These issues, which degrade model performance, quantization fidelity, and interpretability, arise from a problematic mutual reinforcement mechanism where the model learns an inefficient 'no-op' behavior by focusing attention on tokens with near-zero value states. In this paper, we propose Value-State Gated Attention (VGA), a simple, dedicated, and stable architectural mechanism for performing 'no-op' attention efficiently by directly breaking this cycle. VGA introduces a learnable, data-dependent gate, computed directly from the value vectors (V), to modulate the output. Through a theoretical analysis of the underlying gradients, we show that gating the value-state with a function of itself is more effective at decoupling value and attention score updates than prior methods that gate on input embeddings. This creates a direct regulatory pathway that allows the model to suppress a token's contribution based on its emergent value representation. Our experiments demonstrate that VGA significantly mitigates the formation of attention sinks and stabilizes value-state norms, leading to improved performance, robust quantization fidelity, and enhanced model interpretability.",
    "published": "2025-10-10T05:40:53Z",
    "updated": "2026-01-26T07:50:44Z",
    "link": "http://arxiv.org/pdf/2510.09017v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Rui Bu",
      "Haofeng Zhong",
      "Wenzheng Chen",
      "Yangyan Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.15552v3",
    "title": "Multimodal Evaluation of Russian-language Architectures",
    "summary": "Multimodal large language models (MLLMs) are currently at the center of research attention, showing rapid progress in scale and capabilities, yet their intelligence, limitations, and risks remain insufficiently understood. To address these issues, particularly in the context of the Russian language, where no multimodal benchmarks currently exist, we introduce MERA Multi, an open multimodal evaluation framework for Russian-spoken architectures. The benchmark is instruction-based and encompasses default text, image, audio, and video modalities, comprising 18 newly constructed evaluation tasks for both general-purpose models and modality-specific architectures (imageto-text, video-to-text, and audio-to-text). Our contributions include: (i) a universal taxonomy of multimodal abilities; (ii) 18 datasets created entirely from scratch with attention to Russian cultural and linguistic specificity, unified prompts, and metrics; (iii) baseline results for both closed-source and open-source models; (iv) a methodology for preventing benchmark leakage, including watermarking for private sets. While our current focus is on Russian, the proposed benchmark provides a replicable methodology for constructing multimodal benchmarks in typologically diverse languages, particularly within the Slavic language family.",
    "published": "2025-11-19T15:43:53Z",
    "updated": "2026-01-26T07:50:42Z",
    "link": "http://arxiv.org/pdf/2511.15552v3.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Artem Chervyakov",
      "Ulyana Isaeva",
      "Anton Emelyanov",
      "Artem Safin",
      "Maria Tikhonova",
      "Alexander Kharitonov",
      "Yulia Lyakh",
      "Petr Surovtsev",
      "Denis Shevelev",
      "Vildan Saburov",
      "Vasily Konovalov",
      "Elisei Rykov",
      "Ivan Sviridov",
      "Amina Miftakhova",
      "Ilseyar Alimova",
      "Alexander Panchenko",
      "Alexander Kapitanov",
      "Alena Fenogenova"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18241v1",
    "title": "TAM-Eval: Evaluating LLMs for Automated Unit Test Maintenance",
    "summary": "While Large Language Models (LLMs) have shown promise in software engineering, their application to unit testing remains largely confined to isolated test generation or oracle prediction, neglecting the broader challenge of test suite maintenance. We introduce TAM-Eval (Test Automated Maintenance Evaluation), a framework and benchmark designed to evaluate model performance across three core test maintenance scenarios: creation, repair, and updating of test suites. Unlike prior work limited to function-level tasks, TAM-Eval operates at the test file level, while maintaining access to full repository context during isolated evaluation, better reflecting real-world maintenance workflows. Our benchmark comprises 1,539 automatically extracted and validated scenarios from Python, Java, and Go projects. TAM-Eval supports system-agnostic evaluation of both raw LLMs and agentic workflows, using a reference-free protocol based on test suite pass rate, code coverage, and mutation testing. Empirical results indicate that state-of-the-art LLMs have limited capabilities in realistic test maintenance processes and yield only marginal improvements in test effectiveness. We release TAM-Eval as an open-source framework to support future research in automated software testing. Our data and code are publicly available at https://github.com/trndcenter/TAM-Eval.",
    "published": "2026-01-26T07:47:22Z",
    "updated": "2026-01-26T07:47:22Z",
    "link": "http://arxiv.org/pdf/2601.18241v1.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Elena Bruches",
      "Vadim Alperovich",
      "Dari Baturova",
      "Roman Derunets",
      "Daniil Grebenkin",
      "Georgy Mkrtchyan",
      "Oleg Sedukhin",
      "Mikhail Klementev",
      "Ivan Bondarenko",
      "Nikolay Bushkov",
      "Stanislav Moiseev"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.00847v4",
    "title": "Pay for The Second-Best Service: A Game-Theoretic Approach Against Dishonest LLM Providers",
    "summary": "The widespread adoption of Large Language Models (LLMs) through Application Programming Interfaces (APIs) induces a critical vulnerability: the potential for dishonest manipulation by service providers. This manipulation can manifest in various forms, such as secretly substituting a proclaimed high-performance model with a low-cost alternative, or inflating responses with meaningless tokens to increase billing. This work tackles the issue through the lens of algorithmic game theory and mechanism design. We are the first to propose a formal economic model for a realistic user-provider ecosystem, where a user can iteratively delegate $T$ queries to multiple model providers, and providers can engage in a range of strategic behaviors. As our central contribution, we prove that for a continuous strategy space and any $ε\\in(0,\\frac12)$, there exists an approximate incentive-compatible mechanism with an additive approximation ratio of $O(T^{1-ε}\\log T)$, and a guaranteed quasi-linear second-best user utility. We also prove an impossibility result, stating that no mechanism can guarantee an expected user utility that is asymptotically better than our mechanism. Furthermore, we demonstrate the effectiveness of our mechanism in simulation experiments with real-world API settings.",
    "published": "2025-11-02T08:18:20Z",
    "updated": "2026-01-26T07:46:04Z",
    "link": "http://arxiv.org/pdf/2511.00847v4.pdf",
    "category": [
      "cs.GT",
      "cs.AI"
    ],
    "authors": [
      "Yuhan Cao",
      "Yu Wang",
      "Sitong Liu",
      "Miao Li",
      "Yixin Tao",
      "Tianxing He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18234v1",
    "title": "Generative AI in Saudi Arabia: A National Survey of Adoption, Risks, and Public Perceptions",
    "summary": "Generative Artificial Intelligence (GenAI) is rapidly becoming embedded in Saudi Arabia's digital transformation under Vision 2030, yet public awareness, adoption, and concerns surrounding these tools remain underexplored. This study provides an early snapshot of GenAI engagement among Saudi nationals. Using a nationwide survey of 330 participants across regions, age groups, and employment sectors, we examine seven dimensions of GenAI use: awareness and understanding, adoption patterns, perceived impacts, training needs, risks and barriers, data-sharing behaviors, and future expectations. Findings show that 93% of respondents actively use GenAI primarily for text-based tasks, while more advanced uses such as programming or multimodal generation are less common. Despite the prevalence of use, overall awareness and conceptual understanding remain uneven, with many reporting limited technical knowledge. Participants recognize GenAI's benefits for productivity, work quality, and understanding complex information, yet caution that sustained reliance may undermine critical thinking and key professional skills. Trust in AI-generated outputs remains cautious, with widespread concerns about privacy, misinformation, and ethical misuse, including potential job displacement. Respondents show strong interest in structured GenAI training that combines foundational skills, domain-specific applications, and clear guidance on privacy, ethics, and responsible use. These results establish a baseline for GenAI engagement in Saudi Arabia and highlight priorities for policymakers and developers: expanding AI literacy, ensuring culturally and linguistically aligned GenAI solutions, and strengthening frameworks for privacy and responsible deployment.",
    "published": "2026-01-26T07:40:41Z",
    "updated": "2026-01-26T07:40:41Z",
    "link": "http://arxiv.org/pdf/2601.18234v1.pdf",
    "category": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Abdulaziz AlDakheel",
      "Ali Alshehre",
      "Esraa Alamoudi",
      "Moslim AlKhabbaz",
      "Ahmed Aljohani",
      "Raed Alharbi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18894v3",
    "title": "Not All Pixels Are Equal: Pixel-wise Meta-Learning for Medical Segmentation with Noisy Labels",
    "summary": "Medical image segmentation is crucial for clinical applications, but it is frequently disrupted by noisy annotations and ambiguous anatomical boundaries, which lead to instability in model training. Existing methods typically rely on global noise assumptions or confidence-based sample selection, which inadequately mitigate the performance degradation caused by annotation noise, especially in challenging boundary regions. To address this issue, we propose MetaDCSeg, a robust framework that dynamically learns optimal pixel-wise weights to suppress the influence of noisy labels while preserving reliable annotations. By explicitly modeling boundary uncertainty through a Dynamic Center Distance (DCD) mechanism, our approach utilizes weighted feature distances for foreground, background, and boundary centers, directing the model's attention toward hard-to-segment pixels near ambiguous boundaries. This strategy enables more precise handling of structural boundaries, which are often overlooked by existing methods, and significantly enhances segmentation performance. Extensive experiments across four benchmark datasets with varying noise levels demonstrate that MetaDCSeg outperforms existing state-of-the-art methods.",
    "published": "2025-11-24T08:51:02Z",
    "updated": "2026-01-26T07:40:19Z",
    "link": "http://arxiv.org/pdf/2511.18894v3.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Chenyu Mu",
      "Guihai Chen",
      "Xun Yang",
      "Erkun Yang",
      "Cheng Deng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.11020v2",
    "title": "GeoVLMath: Enhancing Geometry Reasoning in Vision-Language Models via Cross-Modal Reward for Auxiliary Line Creation",
    "summary": "Auxiliary lines are essential for solving complex geometric problems but remain challenging for large vision-language models (LVLMs). Recent attempts construct auxiliary lines via code-driven rendering, a strategy that relies on accurate and executable code generation to produce visual renderings of the auxiliary lines for subsequent reasoning. However, in complex solid geometry settings, such a strong dependence on precise specifications substantially restricts the robustness of this strategy. Alternatively, we turn to a simpler and more stable solution, representing auxiliary-line constructions as structured textual descriptions. To bridge the gap between textual descriptions and spatial structure, we propose a reinforcement learning framework that enhances diagram-text alignment. The core is a cross-modal reward model that evaluates how well the generated auxiliary-line description matches the ground-truth auxiliary-line diagram. The reward signal drives a GRPO-based RL stage to yield informative auxiliary-line descriptions for the reasoning. To support the training and evaluation, we develop a scalable data pipeline and construct AuxSolidMath, a dataset of 3,018 real-exam geometry problems with paired diagrams and aligned textual fields. Based on this framework, we derive GeoVLMath, an LVLM for solving complex solid geometry.",
    "published": "2025-10-13T05:33:51Z",
    "updated": "2026-01-26T07:35:43Z",
    "link": "http://arxiv.org/pdf/2510.11020v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Shasha Guo",
      "Liang Pang",
      "Xi Wang",
      "Yanling Wang",
      "Huawei Shen",
      "Jing Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18231v1",
    "title": "Rethinking Cross-Modal Fine-Tuning: Optimizing the Interaction between Feature Alignment and Target Fitting",
    "summary": "Adapting pre-trained models to unseen feature modalities has become increasingly important due to the growing need for cross-disciplinary knowledge integration.~A key challenge here is how to align the representation of new modalities with the most relevant parts of the pre-trained model's representation space to enable accurate knowledge transfer.~This requires combining feature alignment with target fine-tuning, but uncalibrated combinations can exacerbate misalignment between the source and target feature-label structures and reduce target generalization.~Existing work however lacks a theoretical understanding of this critical interaction between feature alignment and target fitting.~To bridge this gap, we develop a principled framework that establishes a provable generalization bound on the target error, which explains the interaction between feature alignment and target fitting through a novel concept of feature-label distortion.~This bound offers actionable insights into how this interaction should be optimized for practical algorithm design. The resulting approach achieves significantly improved performance over state-of-the-art methods across a wide range of benchmark datasets.",
    "published": "2026-01-26T07:34:15Z",
    "updated": "2026-01-26T07:34:15Z",
    "link": "http://arxiv.org/pdf/2601.18231v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Trong Khiem Tran",
      "Manh Cuong Dao",
      "Phi Le Nguyen",
      "Thao Nguyen Truong",
      "Trong Nghia Hoang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18226v1",
    "title": "Yunjue Agent Tech Report: A Fully Reproducible, Zero-Start In-Situ Self-Evolving Agent System for Open-Ended Tasks",
    "summary": "Conventional agent systems often struggle in open-ended environments where task distributions continuously drift and external supervision is scarce. Their reliance on static toolsets or offline training lags behind these dynamics, leaving the system's capability boundaries rigid and unknown. To address this, we propose the In-Situ Self-Evolving paradigm. This approach treats sequential task interactions as a continuous stream of experience, enabling the system to distill short-term execution feedback into long-term, reusable capabilities without access to ground-truth labels. Within this framework, we identify tool evolution as the critical pathway for capability expansion, which provides verifiable, binary feedback signals. Within this framework, we develop Yunjue Agent, a system that iteratively synthesizes, optimizes, and reuses tools to navigate emerging challenges. To optimize evolutionary efficiency, we further introduce a Parallel Batch Evolution strategy. Empirical evaluations across five diverse benchmarks under a zero-start setting demonstrate significant performance gains over proprietary baselines. Additionally, complementary warm-start evaluations confirm that the accumulated general knowledge can be seamlessly transferred to novel domains. Finally, we propose a novel metric to monitor evolution convergence, serving as a function analogous to training loss in conventional optimization. We open-source our codebase, system traces, and evolved tools to facilitate future research in resilient, self-evolving intelligence.",
    "published": "2026-01-26T07:27:47Z",
    "updated": "2026-01-26T07:27:47Z",
    "link": "http://arxiv.org/pdf/2601.18226v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Haotian Li",
      "Shijun Yang",
      "Weizhen Qi",
      "Silei Zhao",
      "Rui Hua",
      "Mingzhu Song",
      "Xiaojian Yang",
      "Chao Peng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.08258v2",
    "title": "T3: Benchmarking Sycophancy and Skepticism in Causal Judgment",
    "summary": "We introduce T3 (Testing Trustworthy Thinking), a diagnostic benchmark designed to rigorously evaluate LLM causal judgment across Pearl's Ladder of Causality. Comprising 454 expert-curated vignettes, T3 prioritizes high-resolution failure analysis, decomposing performance into Utility (sensitivity), Safety (specificity), and Wise Refusal on underdetermined cases. By applying T3 to frontier models, we diagnose two distinct pathologies: a \"Skepticism Trap\" at L1 (where safety-tuned models like Claude Haiku reject 60% of valid links) and a non-monotonic Scaling Paradox at L3. In the latter, the larger GPT-5.2 underperforms GPT-4-Turbo by 55 points on ambiguous counterfactuals, driven by a collapse into paralysis (excessive hedging) rather than hallucination. Finally, we use the benchmark to validate a process-verified protocol (RCA), showing that T3 successfully captures the restoration of decisive causal judgment under structured verification.",
    "published": "2026-01-13T06:29:56Z",
    "updated": "2026-01-26T07:26:14Z",
    "link": "http://arxiv.org/pdf/2601.08258v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Edward Y. Chang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18225v1",
    "title": "ShopSimulator: Evaluating and Exploring RL-Driven LLM Agent for Shopping Assistants",
    "summary": "Large language model (LLM)-based agents are increasingly deployed in e-commerce shopping. To perform thorough, user-tailored product searches, agents should interpret personal preferences, engage in multi-turn dialogues, and ultimately retrieve and discriminate among highly similar products. However, existing research has yet to provide a unified simulation environment that consistently captures all of these aspects, and always focuses solely on evaluation benchmarks without training support. In this paper, we introduce ShopSimulator, a large-scale and challenging Chinese shopping environment. Leveraging ShopSimulator, we evaluate LLMs across diverse scenarios, finding that even the best-performing models achieve less than 40% full-success rate. Error analysis reveals that agents struggle with deep search and product selection in long trajectories, fail to balance the use of personalization cues, and to effectively engage with users. Further training exploration provides practical guidance for overcoming these weaknesses, with the combination of supervised fine-tuning (SFT) and reinforcement learning (RL) yielding significant performance improvements. Code and data will be released at https://github.com/ShopAgent-Team/ShopSimulator.",
    "published": "2026-01-26T07:24:28Z",
    "updated": "2026-01-26T07:24:28Z",
    "link": "http://arxiv.org/pdf/2601.18225v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Pei Wang",
      "Yanan Wu",
      "Xiaoshuai Song",
      "Weixun Wang",
      "Gengru Chen",
      "Zhongwen Li",
      "Kezhong Yan",
      "Ken Deng",
      "Qi Liu",
      "Shuaibing Zhao",
      "Shaopan Xiong",
      "Xuepeng Liu",
      "Xuefeng Chen",
      "Wanxi Deng",
      "Wenbo Su",
      "Bo Zheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.15408v2",
    "title": "Unifying VXAI: A Systematic Review and Framework for the Evaluation of Explainable AI",
    "summary": "Modern AI systems frequently rely on opaque black-box models, most notably Deep Neural Networks, whose performance stems from complex architectures with millions of learned parameters. While powerful, their complexity poses a major challenge to trustworthiness, particularly due to a lack of transparency. Explainable AI (XAI) addresses this issue by providing human-understandable explanations of model behavior. However, to ensure their usefulness and trustworthiness, such explanations must be rigorously evaluated. Despite the growing number of XAI methods, the field lacks standardized evaluation protocols and consensus on appropriate metrics. To address this gap, we conduct a systematic literature review following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines and introduce a unified framework for the eValuation of XAI (VXAI). We identify 362 relevant publications and aggregate their contributions into 41 functionally similar metric groups. In addition, we propose a three-dimensional categorization scheme spanning explanation type, evaluation contextuality, and explanation quality desiderata. Our framework provides the most comprehensive and structured overview of VXAI to date. It supports systematic metric selection, promotes comparability across methods, and offers a flexible foundation for future extensions.",
    "published": "2025-06-18T12:25:37Z",
    "updated": "2026-01-26T07:18:02Z",
    "link": "http://arxiv.org/pdf/2506.15408v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "David Dembinsky",
      "Adriano Lucieri",
      "Stanislav Frolov",
      "Hiba Najjar",
      "Ko Watanabe",
      "Andreas Dengel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.13379v3",
    "title": "The Art of Saying \"Maybe\": A Conformal Lens for Uncertainty Benchmarking in VLMs",
    "summary": "Vision-Language Models (VLMs) have achieved remarkable progress in complex visual understanding across scientific and reasoning tasks. While performance benchmarking has advanced our understanding of these capabilities, the critical dimension of uncertainty quantification has received insufficient attention. Therefore, unlike prior conformal prediction studies that focused on limited settings, we conduct a comprehensive uncertainty benchmarking study, evaluating 18 state-of-the-art VLMs (open and closed-source) across 6 multimodal datasets with 3 distinct scoring functions. For closed-source models lacking token-level logprob access, we develop and validate instruction-guided likelihood proxies. Our findings demonstrate that larger models consistently exhibit better uncertainty quantification; models that know more also know better what they don't know. More certain models achieve higher accuracy, while mathematical and reasoning tasks elicit poorer uncertainty performance across all models compared to other domains. This work establishes a foundation for reliable uncertainty evaluation in multimodal systems.",
    "published": "2025-09-16T08:17:39Z",
    "updated": "2026-01-26T07:17:20Z",
    "link": "http://arxiv.org/pdf/2509.13379v3.pdf",
    "category": [
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Asif Azad",
      "Mohammad Sadat Hossain",
      "MD Sadik Hossain Shanto",
      "M Saifur Rahman",
      "Md Rizwan Parvez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18218v1",
    "title": "PaperTok: Exploring the Use of Generative AI for Creating Short-form Videos for Research Communication",
    "summary": "The dissemination of scholarly research is critical, yet researchers often lack the time and skills to create engaging content for popular media such as short-form videos. To address this gap, we explore the use of generative AI to help researchers transform their academic papers into accessible video content. Informed by a formative study with science communicators and content creators (N=8), we designed PaperTok, an end-to-end system that automates the initial creative labor by generating script options and corresponding audiovisual content from a source paper. Researchers can then refine based on their preferences with further prompting. A mixed-methods user study (N=18) and crowdsourced evaluation (N=100) demonstrate that PaperTok's workflow can help researchers create engaging and informative short-form videos. We also identified the need for more fine-grained controls in the creation process. To this end, we offer implications for future generative tools that support science outreach.",
    "published": "2026-01-26T07:08:57Z",
    "updated": "2026-01-26T07:08:57Z",
    "link": "http://arxiv.org/pdf/2601.18218v1.pdf",
    "category": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Meziah Ruby Cristobal",
      "Hyeonjeong Byeon",
      "Tze-Yu Chen",
      "Ruoxi Shang",
      "Donghoon Shin",
      "Ruican Zhong",
      "Tony Zhou",
      "Gary Hsieh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18217v1",
    "title": "Paying Less Generalization Tax: A Cross-Domain Generalization Study of RL Training for LLM Agents",
    "summary": "Generalist LLM agents are often post-trained on a narrow set of environments but deployed across far broader, unseen domains. In this work, we investigate the challenge of agentic post-training when the eventual test domains are unknown. Specifically, we analyze which properties of reinforcement learning (RL) environments and modeling choices have the greatest influence on out-of-domain performance. First, we identify two environment axes that strongly correlate with cross-domain generalization: (i) state information richness, i.e., the amount of information for the agent to process from the state, and (ii) planning complexity, estimated via goal reachability and trajectory length under a base policy. Notably, domain realism and text-level similarity are not the primary factors; for instance, the simple grid-world domain Sokoban leads to even stronger generalization in SciWorld than the more realistic ALFWorld. Motivated by these findings, we further show that increasing state information richness alone can already effectively improve cross-domain robustness. We propose a randomization technique, which is low-overhead and broadly applicable: add small amounts of distractive goal-irrelevant features to the state to make it richer without altering the task. Beyond environment-side properties, we also examine several modeling choices: (a) SFT warmup or mid-training helps prevent catastrophic forgetting during RL but undermines generalization to domains that are not included in the mid-training datamix; and (b) turning on step-by-step thinking during RL, while not always improving in-domain performance, plays a crucial role in preserving generalization.",
    "published": "2026-01-26T07:07:03Z",
    "updated": "2026-01-26T07:07:03Z",
    "link": "http://arxiv.org/pdf/2601.18217v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Zhihan Liu",
      "Lin Guan",
      "Yixin Nie",
      "Kai Zhang",
      "Zhuoqun Hao",
      "Lin Chen",
      "Asli Celikyilmaz",
      "Zhaoran Wang",
      "Na Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.10132v2",
    "title": "Is More Context Always Better? Examining LLM Reasoning Capability for Time Interval Prediction",
    "summary": "Large Language Models (LLMs) have demonstrated impressive capabilities in reasoning and prediction across different domains. Yet, their ability to infer temporal regularities from structured behavioral data remains underexplored. This paper presents a systematic study investigating whether LLMs can predict time intervals between recurring user actions, such as repeated purchases, and how different levels of contextual information shape their predictive behavior. Using a simple but representative repurchase scenario, we benchmark state-of-the-art LLMs in zero-shot settings against both statistical and machine-learning models. Two key findings emerge. First, while LLMs surpass lightweight statistical baselines, they consistently underperform dedicated machine-learning models, showing their limited ability to capture quantitative temporal structure. Second, although moderate context can improve LLM accuracy, adding further user-level detail degrades performance. These results challenge the assumption that \"more context leads to better reasoning\". Our study highlights fundamental limitations of today's LLMs in structured temporal inference and offers guidance for designing future context-aware hybrid models that integrate statistical precision with linguistic flexibility.",
    "published": "2026-01-15T07:18:40Z",
    "updated": "2026-01-26T06:58:30Z",
    "link": "http://arxiv.org/pdf/2601.10132v2.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Yanan Cao",
      "Farnaz Fallahi",
      "Murali Mohana Krishna Dandu",
      "Lalitesh Morishetti",
      "Kai Zhao",
      "Luyi Ma",
      "Sinduja Subramaniam",
      "Jianpeng Xu",
      "Evren Korpeoglu",
      "Kaushiki Nag",
      "Sushant Kumar",
      "Kannan Achan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.12846v6",
    "title": "VFEFL: Privacy-Preserving Federated Learning against Malicious Clients via Verifiable Functional Encryption",
    "summary": "Federated learning is a promising distributed learning paradigm that enables collaborative model training without exposing local client data, thereby protecting data privacy. However, it also brings new threats and challenges. The advancement of model inversion attacks has rendered the plaintext transmission of local models insecure, while the distributed nature of federated learning makes it particularly vulnerable to attacks raised by malicious clients. To protect data privacy and prevent malicious client attacks, this paper proposes a privacy-preserving Federated Learning framework based on Verifiable Functional Encryption (VFEFL), without a non-colluding dual-server assumption or additional trusted third-party. Specifically, we propose a novel Cross-Ciphertext Decentralized Verifiable Functional Encryption (CC-DVFE) scheme that enables the verification of specific relationships over multi-dimensional ciphertexts. This scheme is formally treated, in terms of definition, security model and security proof. Furthermore, based on the proposed CC-DVFE scheme, we design a privacy-preserving federated learning framework that incorporates a novel robust aggregation rule to detect malicious clients, enabling the effective training of high-accuracy models under adversarial settings. Finally, we provide the formal analysis and empirical evaluation of VFEFL. The results demonstrate that our approach achieves the desired privacy protection, robustness, verifiability and fidelity, while eliminating the reliance on non-colluding dual-server assumption or trusted third parties required by most existing methods.",
    "published": "2025-06-15T13:38:40Z",
    "updated": "2026-01-26T06:50:08Z",
    "link": "http://arxiv.org/pdf/2506.12846v6.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Nina Cai",
      "Jinguang Han",
      "Weizhi Meng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18207v1",
    "title": "PaperSearchQA: Learning to Search and Reason over Scientific Papers with RLVR",
    "summary": "Search agents are language models (LMs) that reason and search knowledge bases (or the web) to answer questions; recent methods supervise only the final answer accuracy using reinforcement learning with verifiable rewards (RLVR). Most RLVR search agents tackle general-domain QA, which limits their relevance to technical AI systems in science, engineering, and medicine. In this work we propose training agents to search and reason over scientific papers -- this tests technical question-answering, it is directly relevant to real scientists, and the capabilities will be crucial to future AI Scientist systems. Concretely, we release a search corpus of 16 million biomedical paper abstracts and construct a challenging factoid QA dataset called PaperSearchQA with 60k samples answerable from the corpus, along with benchmarks. We train search agents in this environment to outperform non-RL retrieval baselines; we also perform further quantitative analysis and observe interesting agent behaviors like planning, reasoning, and self-verification. Our corpus, datasets, and benchmarks are usable with the popular Search-R1 codebase for RLVR training and released on https://huggingface.co/collections/jmhb/papersearchqa. Finally, our data creation methods are scalable and easily extendable to other scientific domains.",
    "published": "2026-01-26T06:46:16Z",
    "updated": "2026-01-26T06:46:16Z",
    "link": "http://arxiv.org/pdf/2601.18207v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "authors": [
      "James Burgess",
      "Jan N. Hansen",
      "Duo Peng",
      "Yuhui Zhang",
      "Alejandro Lozano",
      "Min Woo Sun",
      "Emma Lundberg",
      "Serena Yeung-Levy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2409.07314v2",
    "title": "MEDIC: Comprehensive Evaluation of Leading Indicators for LLM Safety and Utility in Clinical Applications",
    "summary": "While Large Language Models (LLMs) achieve superhuman performance on standardized medical licensing exams, these static benchmarks have become saturated and increasingly disconnected from the functional requirements of clinical workflows. To bridge the gap between theoretical capability and verified utility, we introduce MEDIC, a comprehensive evaluation framework establishing leading indicators across various clinical dimensions. Beyond standard question-answering, we assess operational capabilities using deterministic execution protocols and a novel Cross-Examination Framework (CEF), which quantifies information fidelity and hallucination rates without reliance on reference texts. Our evaluation across a heterogeneous task suite exposes critical performance trade-offs: we identify a significant knowledge-execution gap, where proficiency in static retrieval does not predict success in operational tasks such as clinical calculation or SQL generation. Furthermore, we observe a divergence between passive safety (refusal) and active safety (error detection), revealing that models fine-tuned for high refusal rates often fail to reliably audit clinical documentation for factual accuracy. These findings demonstrate that no single architecture dominates across all dimensions, highlighting the necessity of a portfolio approach to clinical model deployment. As part of this investigation, we released a public leaderboard on Hugging Face.\\footnote{https://huggingface.co/spaces/m42-health/MEDIC-Benchmark}",
    "published": "2024-09-11T14:44:51Z",
    "updated": "2026-01-26T06:45:00Z",
    "link": "http://arxiv.org/pdf/2409.07314v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Praveenkumar Kanithi",
      "Clément Christophe",
      "Marco AF Pimentel",
      "Tathagata Raha",
      "Prateek Munjal",
      "Nada Saadi",
      "Hamza A Javed",
      "Svetlana Maslenkova",
      "Nasir Hayat",
      "Ronnie Rajan",
      "Shadab Khan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.19459v2",
    "title": "Your Classifier Can Do More: Towards Bridging the Gaps in Classification, Robustness, and Generation",
    "summary": "Joint Energy-based Models (JEMs) are well known for their ability to unify classification and generation within a single framework. Despite their promising generative and discriminative performance, their robustness remains far inferior to adversarial training (AT), which, conversely, achieves strong robustness but sacrifices clean accuracy and lacks generative ability. This inherent trilemma-balancing classification accuracy, robustness, and generative capability-raises a fundamental question: Can a single model achieve all three simultaneously? To answer this, we conduct a systematic energy landscape analysis of clean, adversarial, and generated samples across various JEM and AT variants. We observe that AT reduces the energy gap between clean and adversarial samples, while JEMs narrow the gap between clean and synthetic ones. This observation suggests a key insight: if the energy distributions of all three data types can be aligned, we might bridge their performance disparities. Building on this idea, we propose Energy-based Joint Distribution Adversarial Training (EB-JDAT), a unified generative-discriminative-robust framework that maximizes the joint probability of clean and adversarial distribution. EB-JDAT introduces a novel min-max energy optimization to explicitly aligning energies across clean, adversarial, and generated samples. Extensive experiments on CIFAR-10, CIFAR-100, and ImageNet subsets demonstrate that EB-JDAT achieves state-of-the-art robustness while maintaining near-original accuracy and generation quality of JEMs, effectively resolving the triple trade-off between accuracy, robustness, and generation.",
    "published": "2025-05-26T03:26:55Z",
    "updated": "2026-01-26T06:41:27Z",
    "link": "http://arxiv.org/pdf/2505.19459v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Kaichao Jiang",
      "He Wang",
      "Xiaoshuai Hao",
      "Xiulong Yang",
      "Ajian Liu",
      "Qi Chu",
      "Yunfeng Diao",
      "Richang Hong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18202v1",
    "title": "SAGE: Steerable Agentic Data Generation for Deep Search with Execution Feedback",
    "summary": "Deep search agents, which aim to answer complex questions requiring reasoning across multiple documents, can significantly speed up the information-seeking process. Collecting human annotations for this application is prohibitively expensive due to long and complex exploration trajectories. We propose an agentic pipeline that automatically generates high quality, difficulty-controlled deep search question-answer pairs for a given corpus and a target difficulty level. Our pipeline, SAGE, consists of a data generator which proposes QA pairs and a search agent which attempts to solve the generated question and provide execution feedback for the data generator. The two components interact over multiple rounds to iteratively refine the question-answer pairs until they satisfy the target difficulty level. Our intrinsic evaluation shows SAGE generates questions that require diverse reasoning strategies, while significantly increases the correctness and difficulty of the generated data. Our extrinsic evaluation demonstrates up to 23% relative performance gain on popular deep search benchmarks by training deep search agents with our synthetic data. Additional experiments show that agents trained on our data can adapt from fixed-corpus retrieval to Google Search at inference time, without further training.",
    "published": "2026-01-26T06:37:56Z",
    "updated": "2026-01-26T06:37:56Z",
    "link": "http://arxiv.org/pdf/2601.18202v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Fangyuan Xu",
      "Rujun Han",
      "Yanfei Chen",
      "Zifeng Wang",
      "I-Hung Hsu",
      "Jun Yan",
      "Vishy Tirumalashetty",
      "Eunsol Choi",
      "Tomas Pfister",
      "Chen-Yu Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.16943v2",
    "title": "RASTP: Representation-Aware Semantic Token Pruning for Generative Recommendation with Semantic Identifiers",
    "summary": "Generative recommendation systems typically leverage Semantic Identifiers (SIDs), which represent each item as a sequence of tokens that encode semantic information. However, representing item ID with multiple SIDs significantly increases input sequence length, which is a major determinant of computational complexity and memory consumption. While existing efforts primarily focus on optimizing attention computation and KV cache, we propose RASTP (Representation-Aware Semantic Token Pruning), which directly prunes less informative tokens in the input sequence. Specifically, RASTP evaluates token importance by combining semantic saliency, measured via representation magnitude, and attention centrality, derived from cumulative attention weights. Since RASTP dynamically prunes low-information or irrelevant semantic tokens, experiments on three real-world Amazon datasets show that RASTP reduces training time by 26.7\\%, while maintaining or slightly improving recommendation performance. The code has been open-sourced at https://github.com/Yuzt-zju/RASTP.",
    "published": "2025-11-21T04:39:32Z",
    "updated": "2026-01-26T06:37:34Z",
    "link": "http://arxiv.org/pdf/2511.16943v2.pdf",
    "category": [
      "cs.IR",
      "cs.AI"
    ],
    "authors": [
      "Tianyu Zhan",
      "Kairui Fu",
      "Zheqi Lv",
      "Shengyu Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18200v1",
    "title": "HeterCSI: Channel-Adaptive Heterogeneous CSI Pretraining Framework for Generalized Wireless Foundation Models",
    "summary": "Wireless foundation models promise transformative capabilities for channel state information (CSI) processing across diverse 6G network applications, yet face fundamental challenges due to the inherent dual heterogeneity of CSI across both scale and scenario dimensions. However, current pretraining approaches either constrain inputs to fixed dimensions or isolate training by scale, limiting the generalization and scalability of wireless foundation models. In this paper, we propose HeterCSI, a channel-adaptive pretraining framework that reconciles training efficiency with robust cross-scenario generalization via a new understanding of gradient dynamics in heterogeneous CSI pretraining. Our key insight reveals that CSI scale heterogeneity primarily causes destructive gradient interference, while scenario diversity actually promotes constructive gradient alignment when properly managed. Specifically, we formulate heterogeneous CSI batch construction as a partitioning optimization problem that minimizes zero-padding overhead while preserving scenario diversity. To solve this, we develop a scale-aware adaptive batching strategy that aligns CSI samples of similar scales, and design a double-masking mechanism to isolate valid signals from padding artifacts. Extensive experiments on 12 datasets demonstrate that HeterCSI establishes a generalized foundation model without scenario-specific finetuning, achieving superior average performance over full-shot baselines. Compared to the state-of-the-art zero-shot benchmark WiFo, it reduces NMSE by 7.19 dB, 4.08 dB, and 5.27 dB for CSI reconstruction, time-domain, and frequency-domain prediction, respectively. The proposed HeterCSI framework also reduces training latency by 53% compared to existing approaches while improving generalization performance by 1.53 dB on average.",
    "published": "2026-01-26T06:35:48Z",
    "updated": "2026-01-26T06:35:48Z",
    "link": "http://arxiv.org/pdf/2601.18200v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Chenyu Zhang",
      "Xinchen Lyu",
      "Chenshan Ren",
      "Shuhan Liu",
      "Qimei Cui",
      "Xiaofeng Tao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.08235v3",
    "title": "MPCI-Bench: A Benchmark for Multimodal Pairwise Contextual Integrity Evaluation of Language Model Agents",
    "summary": "As language-model agents evolve from passive chatbots into proactive assistants that handle personal data, evaluating their adherence to social norms becomes increasingly critical, often through the lens of Contextual Integrity (CI). However, existing CI benchmarks are largely text-centric and primarily emphasize negative refusal scenarios, overlooking multimodal privacy risks and the fundamental trade-off between privacy and utility. In this paper, we introduce MPCI-Bench, the first Multimodal Pairwise Contextual Integrity benchmark for evaluating privacy behavior in agentic settings. MPCI-Bench consists of paired positive and negative instances derived from the same visual source and instantiated across three tiers: normative Seed judgments, context-rich Story reasoning, and executable agent action Traces. Data quality is ensured through a Tri-Principle Iterative Refinement pipeline. Evaluations of state-of-the-art multimodal models reveal systematic failures to balance privacy and utility and a pronounced modality leakage gap, where sensitive visual information is leaked more frequently than textual information. We will open-source MPCI-Bench to facilitate future research on agentic CI.",
    "published": "2026-01-13T05:39:43Z",
    "updated": "2026-01-26T06:30:36Z",
    "link": "http://arxiv.org/pdf/2601.08235v3.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Shouju Wang",
      "Haopeng Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18197v1",
    "title": "GAIA: A Data Flywheel System for Training GUI Test-Time Scaling Critic Models",
    "summary": "While Large Vision-Language Models (LVLMs) have significantly advanced GUI agents' capabilities in parsing textual instructions, interpreting screen content, and executing tasks, a critical challenge persists: the irreversibility of agent operations, where a single erroneous action can trigger catastrophic deviations. To address this, we propose the GUI Action Critic's Data Flywheel System (GAIA), a training framework that enables the models to have iterative critic capabilities, which are used to improve the Test-Time Scaling (TTS) of basic GUI agents' performance. Specifically, we train an Intuitive Critic Model (ICM) using positive and negative action examples from a base agent first. This critic evaluates the immediate correctness of the agent's intended actions, thereby selecting operations with higher success probability. Then, the initial critic guides agent actions to collect refined positive/negative samples, initiating the self-improving cycle. The augmented data then trains a second-round critic with enhanced discernment capability. We conduct experiments on various datasets and demonstrate that the proposed ICM can improve the test-time performance of various closed-source and open-source models, and the performance can be gradually improved as the data is recycled. The code and dataset will be publicly released.",
    "published": "2026-01-26T06:29:41Z",
    "updated": "2026-01-26T06:29:41Z",
    "link": "http://arxiv.org/pdf/2601.18197v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Shaokang Wang",
      "Pei Fu",
      "Ruoceng Zhang",
      "Shaojie Zhang",
      "Xiuwen Xi",
      "Jiahui Yang",
      "Bin Qin",
      "Ying Huang",
      "Zhenbo Luo",
      "Jian Luan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.05695v5",
    "title": "Architecture independent generalization bounds for overparametrized deep ReLU networks",
    "summary": "We prove that overparametrized neural networks are able to generalize with a test error that is independent of the level of overparametrization, and independent of the Vapnik-Chervonenkis (VC) dimension. We prove explicit bounds that only depend on the metric geometry of the test and training sets, on the regularity properties of the activation function, and on the operator norms of the weights and norms of biases. For overparametrized deep ReLU networks with a training sample size bounded by the input space dimension, we explicitly construct zero loss minimizers without use of gradient descent, and prove a uniform generalization bound that is independent of the network architecture. We perform computational experiments of our theoretical results with MNIST, and obtain agreement with the true test error within a 22 % margin on average.",
    "published": "2025-04-08T05:37:38Z",
    "updated": "2026-01-26T06:20:02Z",
    "link": "http://arxiv.org/pdf/2504.05695v5.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "math.AP",
      "math.OC",
      "stat.ML"
    ],
    "authors": [
      "Anandatheertha Bapu",
      "Thomas Chen",
      "Chun-Kai Kevin Chien",
      "Patricia Muñoz Ewald",
      "Andrew G. Moore"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.11669v2",
    "title": "Collaborative Learning-Enhanced Lightweight Models for Predicting Arterial Blood Pressure Waveform in a Large-scale Perioperative Dataset",
    "summary": "Noninvasive arterial blood pressure (ABP) monitoring is essential for patient management in critical care and perioperative settings, providing continuous assessment of cardiovascular hemodynamics with minimal risks. Numerous deep learning models have developed to reconstruct ABP waveform from noninvasively acquired physiological signals such as electrocardiogram and photoplethysmogram. However, limited research has addressed the issue of model performance and computational load for deployment on embedded systems. The study introduces a lightweight sInvResUNet, along with a collaborative learning scheme named KDCL_sInvResUNet. With only 0.89 million parameters and a computational load of 0.02 GFLOPS, real-time ABP estimation was successfully achieved on embedded devices with an inference time of just 8.49 milliseconds for a 10-second output. We performed subject-independent validation in a large-scale and heterogeneous perioperative dataset containing 1,257,141 data segments from 2,154 patients, with a wide BP range (41-257 mmHg for SBP, and 31-234 mmHg for DBP). The proposed KDCL_sInvResUNet achieved lightly better performance compared to large models, with a mean absolute error of 10.06 mmHg and mean Pearson correlation of 0.88 in tracking ABP changes. Despite these promising results, all deep learning models showed significant performance variations across different demographic and cardiovascular conditions, highlighting their limited ability to generalize across such a broad and diverse population. This study lays a foundation work for real-time, unobtrusive ABP monitoring in real-world perioperative settings, providing baseline for future advancements in this area.",
    "published": "2025-08-07T02:40:17Z",
    "updated": "2026-01-26T06:17:13Z",
    "link": "http://arxiv.org/pdf/2508.11669v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Wentao Li",
      "Yonghu He",
      "Zirong Yu",
      "Kun Gao",
      "Qing Liu",
      "Yali Zheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18188v1",
    "title": "\\textsc{NaVIDA}: Vision-Language Navigation with Inverse Dynamics Augmentation",
    "summary": "Vision-and-Language Navigation (VLN) requires agents to interpret natural language instructions and act coherently in visually rich environments. However, most existing methods rely on reactive state-action mappings without explicitly modeling how actions causally transform subsequent visual observations. Lacking such vision-action causality, agents cannot anticipate the visual changes induced by its own actions, leading to unstable behaviors, weak generalization, and cumulative error along trajectory. To address these issues, we introduce \\textsc{NaVIDA} (\\textbf{Nav}igation with \\textbf{I}nverse \\textbf{D}ynamics \\textbf{A}ugmentation), a unified VLN framework that couples policy learning with action-grounded visual dynamics and adaptive execution. \\textsc{NaVIDA} augments training with chunk-based inverse-dynamics supervision to learn causal relationship between visual changes and corresponding actions. To structure this supervision and extend the effective planning range, \\textsc{NaVIDA} employs hierarchical probabilistic action chunking (HPAC), which organizes trajectories into multi-step chunks and provides discriminative, longer-range visual-change cues. To further curb error accumulation and stabilize behavior at inference, an entropy-guided mechanism adaptively sets the execution horizon of action chunks. Extensive experiments show that \\textsc{NaVIDA} achieves superior navigation performance compared to state-of-the-art methods with fewer parameters (3B vs. 8B). Real-world robot evaluations further validate the practical feasibility and effectiveness of our approach. Code and data will be available upon acceptance.",
    "published": "2026-01-26T06:16:17Z",
    "updated": "2026-01-26T06:16:17Z",
    "link": "http://arxiv.org/pdf/2601.18188v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Weiye Zhu",
      "Zekai Zhang",
      "Xiangchen Wang",
      "Hewei Pan",
      "Teng Wang",
      "Tiantian Geng",
      "Rongtao Xu",
      "Feng Zheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18184v1",
    "title": "VIBEVOICE-ASR Technical Report",
    "summary": "This report presents VibeVoice-ASR, a general-purpose speech understanding framework built upon VibeVoice, designed to address the persistent challenges of context fragmentation and multi-speaker complexity in long-form audio (e.g., meetings, podcasts) that remain despite recent advancements in short-form speech recognition. Unlike traditional pipelined approaches that rely on audio chunking, VibeVoice-ASRsupports single-pass processing for up to 60 minutes of audio. It unifies Automatic Speech Recognition, Speaker Diarization, and Timestamping into a single end-to-end generation task. In addition, VibeVoice-ASR supports over 50 languages, requires no explicit language setting, and natively handles code-switching within and across utterances. Furthermore, we introduce a prompt-based context injection mechanism that allows users to supply customized conetxt, significantly improving accuracy on domain-specific terminology and polyphonic character disambiguation.",
    "published": "2026-01-26T06:11:51Z",
    "updated": "2026-01-26T06:11:51Z",
    "link": "http://arxiv.org/pdf/2601.18184v1.pdf",
    "category": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "authors": [
      "Zhiliang Peng",
      "Jianwei Yu",
      "Yaoyao Chang",
      "Zilong Wang",
      "Li Dong",
      "Yingbo Hao",
      "Yujie Tu",
      "Chenyu Yang",
      "Wenhui Wang",
      "Songchen Xu",
      "Yutao Sun",
      "Hangbo Bao",
      "Weijiang Xu",
      "Yi Zhu",
      "Zehua Wang",
      "Ting Song",
      "Yan Xia",
      "Zewen Chi",
      "Shaohan Huang",
      "Liang Wang",
      "Chuang Ding",
      "Shuai Wang",
      "Xie Chen",
      "Furu Wei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.14054v4",
    "title": "Scientifically-Interpretable Reasoning Network (ScIReN): Discovering Hidden Relationships in the Carbon Cycle and Beyond",
    "summary": "Soils have potential to mitigate climate change by sequestering carbon from the atmosphere, but the soil carbon cycle remains poorly understood. Scientists have developed process-based models of the soil carbon cycle based on existing knowledge, but they contain numerous unknown parameters and often fit observations poorly. On the other hand, neural networks can learn patterns from data, but do not respect known scientific laws, and are too opaque to reveal novel scientific relationships. We thus propose Scientifically-Interpretable Reasoning Network (ScIReN), a fully-transparent framework that combines interpretable neural and process-based reasoning. An interpretable encoder predicts scientifically-meaningful latent parameters, which are then passed through a differentiable process-based decoder to predict labeled output variables. While the process-based decoder enforces existing scientific knowledge, the encoder leverages Kolmogorov-Arnold networks (KANs) to reveal interpretable relationships between input features and latent parameters, using novel smoothness penalties to balance expressivity and simplicity. ScIReN also introduces a novel hard-sigmoid constraint layer to restrict latent parameters into prior ranges while maintaining interpretability. We apply ScIReN on two tasks: simulating the flow of organic carbon through soils, and modeling ecosystem respiration from plants. On both tasks, ScIReN outperforms or matches black-box models in predictive accuracy, while greatly improving scientific interpretability -- it can infer latent scientific mechanisms and their relationships with input features.",
    "published": "2025-06-16T23:21:37Z",
    "updated": "2026-01-26T06:05:18Z",
    "link": "http://arxiv.org/pdf/2506.14054v4.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Joshua Fan",
      "Haodi Xu",
      "Feng Tao",
      "Md Nasim",
      "Marc Grimson",
      "Yiqi Luo",
      "Carla P. Gomes"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.10977v2",
    "title": "Revisiting Model Interpolation for Efficient Reasoning",
    "summary": "Model merging, typically on Instruct and Thinking models, has shown remarkable performance for efficient reasoning. In this paper, we systematically revisit the simplest merging method that interpolates two weights directly. Particularly, we observe that model interpolation follows a three-stage evolutionary paradigm with distinct behaviors on the reasoning trajectory. These dynamics provide a principled guide for navigating the performance-cost trade-off. Empirical results demonstrate that a strategically interpolated model surprisingly surpasses sophisticated model merging baselines on both efficiency and effectiveness. We further validate our findings with extensive ablation studies on model layers, modules, and decoding strategies. Ultimately, this work demystifies model interpolation and offers a practical framework for crafting models with precisely targeted reasoning capabilities. Code is available at \\href{https://github.com/wutaiqiang/MI}{Github}.",
    "published": "2025-10-13T03:30:01Z",
    "updated": "2026-01-26T06:02:57Z",
    "link": "http://arxiv.org/pdf/2510.10977v2.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Taiqiang Wu",
      "Runming Yang",
      "Tao Liu",
      "Jiahao Wang",
      "Ngai Wong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.19005v6",
    "title": "Building Self-Evolving Agents via Experience-Driven Lifelong Learning: A Framework and Benchmark",
    "summary": "As AI advances toward general intelligence, the focus is shifting from systems optimized for static tasks to creating open-ended agents that learn continuously. In this paper, we introduce Experience-driven Lifelong Learning (ELL), a framework for building self-evolving agents capable of continuous growth through real-world interaction. The framework is built on four core principles: (1) Experience Exploration: Agents learn through continuous, self-motivated interaction with dynamic environments, navigating interdependent tasks and generating rich experiential trajectories. (2) Long-term Memory: Agents preserve and structure historical knowledge, including personal experiences, domain expertise, and commonsense reasoning, into a persistent memory system. (3) Skill Learning: Agents autonomously improve by abstracting recurring patterns from experience into reusable skills, which are actively refined and validated for application in new tasks. (4) Knowledge Internalization: Agents internalize explicit and discrete experiences into implicit and intuitive capabilities as \"second nature\".\n  We also introduce StuLife, a benchmark dataset for ELL that simulates a student's holistic college journey, from enrollment to academic and personal development, across three core phases and ten detailed sub-scenarios. StuLife is designed around three key paradigm",
    "published": "2025-08-26T13:04:28Z",
    "updated": "2026-01-26T06:00:10Z",
    "link": "http://arxiv.org/pdf/2508.19005v6.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Yuxuan Cai",
      "Yipeng Hao",
      "Jie Zhou",
      "Hang Yan",
      "Zhikai Lei",
      "Rui Zhen",
      "Zhenhua Han",
      "Yutao Yang",
      "Junsong Li",
      "Qianjun Pan",
      "Tianyu Huai",
      "Qin Chen",
      "Xin Li",
      "Kai Chen",
      "Bo Zhang",
      "Xipeng Qiu",
      "Liang He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18175v1",
    "title": "Success Conditioning as Policy Improvement: The Optimization Problem Solved by Imitating Success",
    "summary": "A widely used technique for improving policies is success conditioning, in which one collects trajectories, identifies those that achieve a desired outcome, and updates the policy to imitate the actions taken along successful trajectories. This principle appears under many names -- rejection sampling with SFT, goal-conditioned RL, Decision Transformers -- yet what optimization problem it solves, if any, has remained unclear. We prove that success conditioning exactly solves a trust-region optimization problem, maximizing policy improvement subject to a $χ^2$ divergence constraint whose radius is determined automatically by the data. This yields an identity: relative policy improvement, the magnitude of policy change, and a quantity we call action-influence -- measuring how random variation in action choices affects success rates -- are exactly equal at every state. Success conditioning thus emerges as a conservative improvement operator. Exact success conditioning cannot degrade performance or induce dangerous distribution shift, but when it fails, it does so observably, by hardly changing the policy at all. We apply our theory to the common practice of return thresholding, showing this can amplify improvement, but at the cost of potential misalignment with the true objective.",
    "published": "2026-01-26T05:54:39Z",
    "updated": "2026-01-26T05:54:39Z",
    "link": "http://arxiv.org/pdf/2601.18175v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "eess.SY",
      "stat.ML"
    ],
    "authors": [
      "Daniel Russo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12869v2",
    "title": "On the Fundamental Limits of LLMs at Scale",
    "summary": "Large Language Models (LLMs) have benefited enormously from scaling, yet these gains are bounded by five fundamental limitations: (1) hallucination, (2) context compression, (3) reasoning degradation, (4) retrieval fragility, and (5) multimodal misalignment. While existing surveys describe these phenomena empirically, they lack a rigorous theoretical synthesis connecting them to the foundational limits of computation, information, and learning. This work closes that gap by presenting a unified, proof-informed framework that formalizes the innate theoretical ceilings of LLM scaling. First, computability and uncomputability imply an irreducible residue of error: for any computably enumerable model family, diagonalization guarantees inputs on which some model must fail, and undecidable queries (e.g., halting-style tasks) induce infinite failure sets for all computable predictors. Second, information-theoretic and statistical constraints bound attainable accuracy even on decidable tasks, finite description length enforces compression error, and long-tail factual knowledge requires prohibitive sample complexity. Third, geometric and computational effects compress long contexts far below their nominal size due to positional under-training, encoding attenuation, and softmax crowding. We further show how likelihood-based training favors pattern completion over inference, how retrieval under token limits suffers from semantic drift and coupling noise, and how multimodal scaling inherits shallow cross-modal alignment. Across sections, we pair theorems and empirical evidence to outline where scaling helps, where it saturates, and where it cannot progress, providing both theoretical foundations and practical mitigation paths like bounded-oracle retrieval, positional curricula, and sparse or hierarchical attention.",
    "published": "2025-11-17T01:55:33Z",
    "updated": "2026-01-26T05:53:56Z",
    "link": "http://arxiv.org/pdf/2511.12869v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.IT",
      "cs.MA"
    ],
    "authors": [
      "Muhammad Ahmed Mohsin",
      "Muhammad Umer",
      "Ahsan Bilal",
      "Zeeshan Memon",
      "Muhammad Ibtsaam Qadir",
      "Sagnik Bhattacharya",
      "Hassan Rizwan",
      "Abhiram R. Gorle",
      "Maahe Zehra Kazmi",
      "Nukhba Amir",
      "Ali Subhan",
      "Muhammad Usman Rafique",
      "Zihao He",
      "Pulkit Mehta",
      "Muhammad Ali Jamshed",
      "John M. Cioffi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.09394v4",
    "title": "Beyond Single-Granularity Prompts: A Multi-Scale Chain-of-Thought Prompt Learning for Graph",
    "summary": "The ``pre-train, prompt\" paradigm, designed to bridge the gap between pre-training tasks and downstream objectives, has been extended from the NLP domain to the graph domain and has achieved remarkable progress. Current mainstream graph prompt-tuning methods modify input or output features using learnable prompt vectors. However, existing approaches are confined to single-granularity (e.g., node-level or subgraph-level) during prompt generation, overlooking the inherently multi-scale structural information in graph data, which limits the diversity of prompt semantics. To address this issue, we pioneer the integration of multi-scale information into graph prompt and propose a Multi-Scale Graph Chain-of-Thought (MSGCOT) prompting framework. Specifically, we design a lightweight, low-rank coarsening network to efficiently capture multi-scale structural features as hierarchical basis vectors for prompt generation. Subsequently, mimicking human cognition from coarse-to-fine granularity, we dynamically integrate multi-scale information at each reasoning step, forming a progressive coarse-to-fine prompt chain. Extensive experiments on eight benchmark datasets demonstrate that MSGCOT outperforms the state-of-the-art single-granularity graph prompt-tuning method, particularly in few-shot scenarios, showcasing superior performance. The code is available at: https://github.com/zhengziyu77/MSGCOT.",
    "published": "2025-10-10T13:48:34Z",
    "updated": "2026-01-26T05:44:55Z",
    "link": "http://arxiv.org/pdf/2510.09394v4.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Ziyu Zheng",
      "Yaming Yang",
      "Ziyu Guan",
      "Wei Zhao",
      "Xinyan Huang",
      "Weigang Lu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.16946v4",
    "title": "MobileCity: An Efficient Framework for Large-Scale Urban Behavior Simulation",
    "summary": "Generative agents offer promising capabilities for simulating realistic urban behaviors. However, existing methods oversimplify transportation choices, rely heavily on static agent profiles leading to behavioral homogenization, and inherit prohibitive computational costs. To address these limitations, we present MobileCity, a lightweight simulation platform designed to model realistic urban mobility with high computational efficiency. We introduce a comprehensive transportation system with multiple transport modes, and collect questionnaire data from respondents to construct agent profiles. To enable scalable simulation, agents perform action selection within a pre-generated action space and uses local models for efficient agent memory generation. Through extensive micro and macro-level evaluations on 4,000 agents, we demonstrate that MobileCity generates more realistic urban behaviors than baselines while maintaining computational efficiency. We further explore practical applications such as predicting movement patterns and analyzing demographic trends in transportation preferences. Our code is publicly available at https://github.com/Tony-Yip/MobileCity.",
    "published": "2025-04-18T07:01:05Z",
    "updated": "2026-01-26T05:38:33Z",
    "link": "http://arxiv.org/pdf/2504.16946v4.pdf",
    "category": [
      "cs.SI",
      "cs.AI"
    ],
    "authors": [
      "Xiaotong Ye",
      "Nicolas Bougie",
      "Toshihiko Yamasaki",
      "Narimasa Watanabe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18156v1",
    "title": "Beyond Pairwise Comparisons: A Distributional Test of Distinctiveness for Machine-Generated Works in Intellectual Property Law",
    "summary": "Key doctrines, including novelty (patent), originality (copyright), and distinctiveness (trademark), turn on a shared empirical question: whether a body of work is meaningfully distinct from a relevant reference class. Yet analyses typically operationalize this set-level inquiry using item-level evidence: pairwise comparisons among exemplars. That unit-of-analysis mismatch may be manageable for finite corpora of human-created works, where it can be bridged by ad hoc aggregations. But it becomes acute for machine-generated works, where the object of evaluation is not a fixed set of works but a generative process with an effectively unbounded output space. We propose a distributional alternative: a two-sample test based on maximum mean discrepancy computed on semantic embeddings to determine if two creative processes-whether human or machine-produce statistically distinguishable output distributions. The test requires no task-specific training-obviating the need for discovery of proprietary training data to characterize the generative process-and is sample-efficient, often detecting differences with as few as 5-10 images and 7-20 texts. We validate the framework across three domains: handwritten digits (controlled images), patent abstracts (text), and AI-generated art (real-world images). We reveal a perceptual paradox: even when human evaluators distinguish AI outputs from human-created art with only about 58% accuracy, our method detects distributional distinctiveness. Our results present evidence contrary to the view that generative models act as mere regurgitators of training data. Rather than producing outputs statistically indistinguishable from a human baseline-as simple regurgitation would predict-they produce outputs that are semantically human-like yet stochastically distinct, suggesting their dominant function is as a semantic interpolator within a learned latent space.",
    "published": "2026-01-26T05:20:33Z",
    "updated": "2026-01-26T05:20:33Z",
    "link": "http://arxiv.org/pdf/2601.18156v1.pdf",
    "category": [
      "cs.CY",
      "cs.AI"
    ],
    "authors": [
      "Anirban Mukherjee",
      "Hannah Hanwen Chang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18151v1",
    "title": "Explaining Synergistic Effects in Social Recommendations",
    "summary": "In social recommenders, the inherent nonlinearity and opacity of synergistic effects across multiple social networks hinders users from understanding how diverse information is leveraged for recommendations, consequently diminishing explainability. However, existing explainers can only identify the topological information in social networks that significantly influences recommendations, failing to further explain the synergistic effects among this information. Inspired by existing findings that synergistic effects enhance mutual information between inputs and predictions to generate information gain, we extend this discovery to graph data. We quantify graph information gain to identify subgraphs embodying synergistic effects. Based on the theoretical insights, we propose SemExplainer, which explains synergistic effects by identifying subgraphs that embody them. SemExplainer first extracts explanatory subgraphs from multi-view social networks to generate preliminary importance explanations for recommendations. A conditional entropy optimization strategy to maximize information gain is developed, thereby further identifying subgraphs that embody synergistic effects from explanatory subgraphs. Finally, SemExplainer searches for paths from users to recommended items within the synergistic subgraphs to generate explanations for the recommendations. Extensive experiments on three datasets demonstrate the superiority of SemExplainer over baseline methods, providing superior explanations of synergistic effects.",
    "published": "2026-01-26T05:14:59Z",
    "updated": "2026-01-26T05:14:59Z",
    "link": "http://arxiv.org/pdf/2601.18151v1.pdf",
    "category": [
      "cs.SI",
      "cs.AI"
    ],
    "authors": [
      "Yicong Li",
      "Shan Jin",
      "Qi Liu",
      "Shuo Wang",
      "Jiaying Liu",
      "Shuo Yu",
      "Qiang Zhang",
      "Kuanjiu Zhou",
      "Feng Xia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18792v1",
    "title": "MEGnifying Emotion: Sentiment Analysis from Annotated Brain Data",
    "summary": "Decoding emotion from brain activity could unlock a deeper understanding of the human experience. While a number of existing datasets align brain data with speech and with speech transcripts, no datasets have annotated brain data with sentiment. To bridge this gap, we explore the use of pre-trained Text-to-Sentiment models to annotate non invasive brain recordings, acquired using magnetoencephalography (MEG), while participants listened to audiobooks. Having annotated the text, we employ force-alignment of the text and audio to align our sentiment labels with the brain recordings. It is straightforward then to train Brainto-Sentiment models on these data. Experimental results show an improvement in balanced accuracy for Brain-to-Sentiment compared to baseline, supporting the proposed approach as a proof-of-concept for leveraging existing MEG datasets and learning to decode sentiment directly from the brain.",
    "published": "2026-01-26T18:55:44Z",
    "updated": "2026-01-26T18:55:44Z",
    "link": "http://arxiv.org/pdf/2601.18792v1.pdf",
    "category": [
      "cs.HC",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Brian Liu",
      "Oiwi Parker Jones"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18790v1",
    "title": "MortalMATH: Evaluating the Conflict Between Reasoning Objectives and Emergency Contexts",
    "summary": "Large Language Models are increasingly optimized for deep reasoning, prioritizing the correct execution of complex tasks over general conversation. We investigate whether this focus on calculation creates a \"tunnel vision\" that ignores safety in critical situations. We introduce MortalMATH, a benchmark of 150 scenarios where users request algebra help while describing increasingly life-threatening emergencies (e.g., stroke symptoms, freefall). We find a sharp behavioral split: generalist models (like Llama-3.1) successfully refuse the math to address the danger. In contrast, specialized reasoning models (like Qwen-3-32b and GPT-5-nano) often ignore the emergency entirely, maintaining over 95 percent task completion rates while the user describes dying. Furthermore, the computational time required for reasoning introduces dangerous delays: up to 15 seconds before any potential help is offered. These results suggest that training models to relentlessly pursue correct answers may inadvertently unlearn the survival instincts required for safe deployment.",
    "published": "2026-01-26T18:55:07Z",
    "updated": "2026-01-26T18:55:07Z",
    "link": "http://arxiv.org/pdf/2601.18790v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Etienne Lanzeray",
      "Stephane Meilliez",
      "Malo Ruelle",
      "Damien Sileo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18788v1",
    "title": "Unsupervised Text Segmentation via Kernel Change-Point Detection on Sentence Embeddings",
    "summary": "Unsupervised text segmentation is crucial because boundary labels are expensive, subjective, and often fail to transfer across domains and granularity choices. We propose Embed-KCPD, a training-free method that represents sentences as embedding vectors and estimates boundaries by minimizing a penalized KCPD objective. Beyond the algorithmic instantiation, we develop, to our knowledge, the first dependence-aware theory for KCPD under $m$-dependent sequences, a finite-memory abstraction of short-range dependence common in language. We prove an oracle inequality for the population penalized risk and a localization guarantee showing that each true change point is recovered within a window that is small relative to segment length. To connect theory to practice, we introduce an LLM-based simulation framework that generates synthetic documents with controlled finite-memory dependence and known boundaries, validating the predicted scaling behavior. Across standard segmentation benchmarks, Embed-KCPD often outperforms strong unsupervised baselines. A case study on Taylor Swift's tweets illustrates that Embed-KCPD combines strong theoretical guarantees, simulated reliability, and practical effectiveness for text segmentation.",
    "published": "2026-01-26T18:54:34Z",
    "updated": "2026-01-26T18:54:34Z",
    "link": "http://arxiv.org/pdf/2601.18788v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Mumin Jia",
      "Jairo Diaz-Rodriguez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18778v1",
    "title": "Teaching Models to Teach Themselves: Reasoning at the Edge of Learnability",
    "summary": "Can a model learn to escape its own learning plateau? Reinforcement learning methods for finetuning large reasoning models stall on datasets with low initial success rates, and thus little training signal. We investigate a fundamental question: Can a pretrained LLM leverage latent knowledge to generate an automated curriculum for problems it cannot solve? To explore this, we design SOAR: A self-improvement framework designed to surface these pedagogical signals through meta-RL. A teacher copy of the model proposes synthetic problems for a student copy, and is rewarded with its improvement on a small subset of hard problems. Critically, SOAR grounds the curriculum in measured student progress rather than intrinsic proxy rewards. Our study on the hardest subsets of mathematical benchmarks (0/128 success) reveals three core findings. First, we show that it is possible to realize bi-level meta-RL that unlocks learning under sparse, binary rewards by sharpening a latent capacity of pretrained models to generate useful stepping stones. Second, grounded rewards outperform intrinsic reward schemes used in prior LLM self-play, reliably avoiding the instability and diversity collapse modes they typically exhibit. Third, analyzing the generated questions reveals that structural quality and well-posedness are more critical for learning progress than solution correctness. Our results suggest that the ability to generate useful stepping stones does not require the preexisting ability to actually solve the hard problems, paving a principled path to escape reasoning plateaus without additional curated data.",
    "published": "2026-01-26T18:46:56Z",
    "updated": "2026-01-26T18:46:56Z",
    "link": "http://arxiv.org/pdf/2601.18778v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Shobhita Sundaram",
      "John Quan",
      "Ariel Kwiatkowski",
      "Kartik Ahuja",
      "Yann Ollivier",
      "Julia Kempe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.03437v2",
    "title": "Consistent Kernel Change-Point Detection under m-Dependence for Text Segmentation",
    "summary": "Kernel change-point detection (KCPD) has become a widely used tool for identifying structural changes in complex data. While existing theory establishes consistency under independence assumptions, real-world sequential data such as text exhibits strong dependencies. We establish new guarantees for KCPD under $m$-dependent data: specifically, we prove consistency in the number of detected change points and weak consistency in their locations under mild additional assumptions. We perform an LLM-based simulation that generates synthetic $m$-dependent text to validate the asymptotics. To complement these results, we present the first comprehensive empirical study of KCPD for text segmentation with modern embeddings. Across diverse text datasets, KCPD with text embeddings outperforms baselines in standard text segmentation metrics. We demonstrate through a case study on Taylor Swift's tweets that KCPD not only provides strong theoretical and simulated reliability but also practical effectiveness for text segmentation tasks.",
    "published": "2025-10-03T18:57:22Z",
    "updated": "2026-01-26T18:36:37Z",
    "link": "http://arxiv.org/pdf/2510.03437v2.pdf",
    "category": [
      "cs.LG",
      "cs.CL",
      "stat.ML"
    ],
    "authors": [
      "Jairo Diaz-Rodriguez",
      "Mumin Jia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18760v1",
    "title": "Beyond Preferences: Learning Alignment Principles Grounded in Human Reasons and Values",
    "summary": "A crucial consideration when developing and deploying Large Language Models (LLMs) is the human values to which these models are aligned. In the constitutional framework of alignment models are aligned to a set of principles (the constitution) specified in natural language. However, it is unclear how to fairly determine this constitution with widespread stakeholder input. In this work we propose Grounded Constitutional AI (GCAI), a unified framework for generating constitutions of principles that are representative of both users' general expectations toward AI (general principles) and their interaction-time preferences (contextual principles). We extend the Inverse Constitutional AI (ICAI) approach to generate contextual principles from human preference annotation data by leveraging human-provided \\textit{reasons} for their preferences. We supplement these contextual principles with general principles surfaced from user statements of \\textit{values} regarding AI. We show that a constitution generated by GCAI is preferred by humans over one generated through ICAI both personally, and for widespread use in governing AI behavior. Additionally participants consider the GCAI constitution to be more morally grounded, coherent, and pluralistic.",
    "published": "2026-01-26T18:27:00Z",
    "updated": "2026-01-26T18:27:00Z",
    "link": "http://arxiv.org/pdf/2601.18760v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Henry Bell",
      "Lara Neubauer da Costa Schertel",
      "Bochu Ding",
      "Brandon Fain"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18734v1",
    "title": "Self-Distilled Reasoner: On-Policy Self-Distillation for Large Language Models",
    "summary": "Knowledge distillation improves large language model (LLM) reasoning by compressing the knowledge of a teacher LLM to train smaller LLMs. On-policy distillation advances this approach by having the student sample its own trajectories while a teacher LLM provides dense token-level supervision, addressing the distribution mismatch between training and inference in off-policy distillation methods. However, on-policy distillation typically requires a separate, often larger, teacher LLM and does not explicitly leverage ground-truth solutions available in reasoning datasets. Inspired by the intuition that a sufficiently capable LLM can rationalize external privileged reasoning traces and teach its weaker self (i.e., the version without access to privileged information), we introduce On-Policy Self-Distillation (OPSD), a framework where a single model acts as both teacher and student by conditioning on different contexts. The teacher policy conditions on privileged information (e.g., verified reasoning traces) while the student policy sees only the question; training minimizes the per-token divergence between these distributions over the student's own rollouts. We demonstrate the efficacy of our method on multiple mathematical reasoning benchmarks, achieving 4-8x token efficiency compared to reinforcement learning methods such as GRPO and superior performance over off-policy distillation methods.",
    "published": "2026-01-26T17:56:50Z",
    "updated": "2026-01-26T17:56:50Z",
    "link": "http://arxiv.org/pdf/2601.18734v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Siyan Zhao",
      "Zhihui Xie",
      "Mengchen Liu",
      "Jing Huang",
      "Guan Pang",
      "Feiyu Chen",
      "Aditya Grover"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18730v1",
    "title": "Reflect: Transparent Principle-Guided Reasoning for Constitutional Alignment at Scale",
    "summary": "The constitutional framework of alignment aims to align large language models (LLMs) with value-laden principles written in natural language (such as to avoid using biased language). Prior work has focused on parameter fine-tuning techniques, such as reinforcement learning from human feedback (RLHF), to instill these principles. However, these approaches are computationally demanding, require careful engineering and tuning, and often require difficult-to-obtain human annotation data. We propose \\textsc{reflect}, an inference-time framework for constitutional alignment that does not require any training or data, providing a plug-and-play approach for aligning an instruction-tuned model to a set of principles. \\textsc{reflect} operates entirely in-context, combining a (i) constitution-conditioned base response with post-generation (ii) self-evaluation, (iii)(a) self-critique, and (iii)(b) final revision. \\textsc{reflect}'s technique of explicit in-context reasoning over principles during post-generation outperforms standard few-shot prompting and provides transparent reasoning traces. Our results demonstrate that \\textsc{reflect} significantly improves LLM conformance to diverse and complex principles, including principles quite distinct from those emphasized in the model's original parameter fine-tuning, without sacrificing factual reasoning. \\textsc{reflect} is particularly effective at reducing the rate of rare but significant violations of principles, thereby improving safety and robustness in the tail end of the distribution of generations. Finally, we show that \\textsc{reflect} naturally generates useful training data for traditional parameter fine-tuning techniques, allowing for efficient scaling and the reduction of inference-time computational overhead in long-term deployment scenarios.",
    "published": "2026-01-26T17:54:54Z",
    "updated": "2026-01-26T17:54:54Z",
    "link": "http://arxiv.org/pdf/2601.18730v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Henry Bell",
      "Caroline Zhang",
      "Mohammed Mobasserul Haque",
      "Dhaval Potdar",
      "Samia Zaman",
      "Brandon Fain"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18722v1",
    "title": "Gained in Translation: Privileged Pairwise Judges Enhance Multilingual Reasoning",
    "summary": "When asked a question in a language less seen in its training data, current reasoning large language models (RLMs) often exhibit dramatically lower performance than when asked the same question in English. In response, we introduce \\texttt{SP3F} (Self-Play with Privileged Pairwise Feedback), a two-stage framework for enhancing multilingual reasoning without \\textit{any} data in the target language(s). First, we supervise fine-tune (SFT) on translated versions of English question-answer pairs to raise base model correctness. Second, we perform RL with feedback from a pairwise judge in a self-play fashion, with the judge receiving the English reference response as \\textit{privileged information}. Thus, even when none of the model's responses are completely correct, the privileged pairwise judge can still tell which response is better. End-to-end, \\texttt{SP3F} greatly improves base model performance, even outperforming fully post-trained models on multiple math and non-math tasks with less than\n  of the training data across the single-language, multilingual, and generalization to unseen language settings.",
    "published": "2026-01-26T17:46:44Z",
    "updated": "2026-01-26T17:46:44Z",
    "link": "http://arxiv.org/pdf/2601.18722v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Lintang Sutawika",
      "Gokul Swamy",
      "Zhiwei Steven Wu",
      "Graham Neubig"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.13687v3",
    "title": "Your Extreme Multi-label Classifier is Secretly a Hierarchical Text Classifier for Free",
    "summary": "Assigning a set of labels to a given text is a classification problem with many real-world applications, such as recommender systems. Two separate research streams address this issue. Hierarchical Text Classification (HTC) focuses on datasets with label pools of hundreds of entries, accompanied by a semantic label hierarchy. In contrast, eXtreme Multi-Label Text Classification (XML) considers very large sets of labels with up to millions of entries but without an explicit hierarchy. In XML methods, it is common to construct an artificial hierarchy in order to deal with the large label space before or during the training process. Here, we investigate how state-of-the-art HTC models perform when trained and tested on XML datasets and vice versa using three benchmark datasets from each of the two streams. Our results demonstrate that XML models, with their internally constructed hierarchy, are very effective HTC models. HTC models, on the other hand, are not equipped to handle the sheer label set size of XML datasets and achieve poor transfer results. We further argue that for a fair comparison in HTC and XML, more than one metric like F1 should be used but complemented with P@k and R-Precision.",
    "published": "2024-11-20T20:07:25Z",
    "updated": "2026-01-26T17:39:52Z",
    "link": "http://arxiv.org/pdf/2411.13687v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Nerijus Bertalis",
      "Paul Granse",
      "Ferhat Gül",
      "Florian Hauss",
      "Leon Menkel",
      "David Schüler",
      "Tom Speier",
      "Lukas Galke",
      "Ansgar Scherp"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18699v1",
    "title": "Mechanistic Analysis of Catastrophic Forgetting in Large Language Models During Continual Fine-tuning",
    "summary": "Large language models exhibit remarkable performance across diverse tasks through pre-training and fine-tuning paradigms. However, continual fine-tuning on sequential tasks induces catastrophic forgetting, where newly acquired knowledge interferes with previously learned capabilities. Despite widespread observations of this phenomenon, the mechanistic understanding remains limited. Here, we present a comprehensive mechanistic analysis of catastrophic forgetting in transformer-based LLMs during sequential fine-tuning. Through systematic experiments across multiple model scales (109B to 400B total parameters) and task sequences, we identify three primary mechanisms driving forgetting: gradient interference in attention weights, representational drift in intermediate layers, and loss landscape flattening. We demonstrate that forgetting severity correlates strongly with task similarity (Pearson r = 0.87) and gradient alignment metrics. Our analysis reveals that approximately 15 to 23 percent of attention heads undergo severe disruption during fine-tuning, with lower layers showing greater susceptibility. These findings establish mechanistic foundations for developing targeted mitigation strategies in continual learning systems.",
    "published": "2026-01-26T17:15:10Z",
    "updated": "2026-01-26T17:15:10Z",
    "link": "http://arxiv.org/pdf/2601.18699v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Olaf Yunus Laitinen Imanov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.06950v2",
    "title": "CtrlRAG: Black-box Document Poisoning Attacks for Retrieval-Augmented Generation of Large Language Models",
    "summary": "Retrieval-Augmented Generation (RAG) systems enhance response credibility and traceability by displaying reference contexts, but this transparency simultaneously introduces a novel black-box attack vector. Existing document poisoning attacks, where adversaries inject malicious documents into the knowledge base to manipulate RAG outputs, rely primarily on unrealistic white-box or gray-box assumptions, limiting their practical applicability. To address this gap, we propose CtrlRAG, a two-stage black-box attack that (1) constructs malicious documents containing misinformation or emotion-inducing content and injects them into the knowledge base, and (2) iteratively optimizes them using a localization algorithm and Masked Language Model (MLM) guided on reference context feedback, ensuring their retrieval priority while preserving linguistic naturalness. With only five malicious documents per target question injected into the million-document MS MARCO dataset, CtrlRAG achieves up to 90% attack success rates on commercial LLMs (e.g., GPT-4o), a 30% improvement over optimal baselines, in both *Emotion Manipulation* and *Hallucination Amplification* tasks. Furthermore, we show that existing defenses fail to balance security and performance. To mitigate this challenge, we introduce a dynamic *Knowledge Expansion* defense strategy based on *Parametric/Non-parametric Memory Confrontation*, blocking 78% of attacks while maintaining 95.5% system accuracy. Our findings reveal critical vulnerabilities in RAG systems and provide effective defense strategies.",
    "published": "2025-03-10T05:55:15Z",
    "updated": "2026-01-26T16:58:51Z",
    "link": "http://arxiv.org/pdf/2503.06950v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Runqi Sui"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.12945v3",
    "title": "LLMPopcorn: Exploring LLMs as Assistants for Popular Micro-video Generation",
    "summary": "In an era where micro-videos dominate platforms like TikTok and YouTube, AI-generated content is nearing cinematic quality. The next frontier is using large language models (LLMs) to autonomously create viral micro-videos, a largely untapped potential that could shape the future of AI-driven content creation. To address this gap, this paper presents the first exploration of LLM-assisted popular micro-video generation (LLMPopcorn). We selected popcorn as the icon for this paper because it symbolizes leisure and entertainment, aligning with this study on leveraging LLMs as assistants for generating popular micro-videos that are often consumed during leisure time. Specifically, we empirically study the following research questions: (i) How can LLMs be effectively utilized to assist popular micro-video generation? (ii) To what extent can prompt-based enhancements optimize the LLM-generated content for higher popularity? (iii) How well do various LLMs and video generators perform in the popular micro-video generation task? Exploring these questions, we show that advanced LLMs like DeepSeek-V3 can generate micro-videos with popularity rivaling human content. Prompt enhancement further boosts results, while benchmarking highlights DeepSeek-V3 and R1 for LLMs, and LTX-Video and HunyuanVideo for video generation. This work advances AI-assisted micro-video creation and opens new research directions. The code is publicly available at https://github.com/GAIR-Lab/LLMPopcorn.",
    "published": "2025-02-18T15:29:05Z",
    "updated": "2026-01-26T16:44:12Z",
    "link": "http://arxiv.org/pdf/2502.12945v3.pdf",
    "category": [
      "cs.CL",
      "cs.CV"
    ],
    "authors": [
      "Junchen Fu",
      "Xuri Ge",
      "Kaiwen Zheng",
      "Alexandros Karatzoglou",
      "Ioannis Arapakis",
      "Xin Xin",
      "Yongxin Ni",
      "Joemon M. Jose"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.15969v2",
    "title": "VoXtream: Full-Stream Text-to-Speech with Extremely Low Latency",
    "summary": "We present VoXtream, a fully autoregressive, zero-shot streaming text-to-speech (TTS) system for real-time use that begins speaking from the first word. VoXtream directly maps incoming phonemes to audio tokens using a monotonic alignment scheme and a limited look-ahead that does not delay onset. Built around an incremental phoneme transformer, a temporal transformer predicting semantic and duration tokens, and a depth transformer producing acoustic tokens, VoXtream achieves, to our knowledge, the lowest initial delay among publicly available streaming TTS: 102 ms on GPU. Despite being trained on a mid-scale 9k-hour corpus, it matches or surpasses larger baselines on several metrics, while delivering competitive quality in both output- and full-streaming settings. Demo and code are available at https://herimor.github.io/voxtream.",
    "published": "2025-09-19T13:26:46Z",
    "updated": "2026-01-26T16:25:29Z",
    "link": "http://arxiv.org/pdf/2509.15969v2.pdf",
    "category": [
      "eess.AS",
      "cs.CL",
      "cs.HC",
      "cs.LG",
      "cs.SD"
    ],
    "authors": [
      "Nikita Torgashov",
      "Gustav Eje Henter",
      "Gabriel Skantze"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18582v1",
    "title": "From Classification to Ranking: Enhancing LLM Reasoning Capabilities for MBTI Personality Detection",
    "summary": "Personality detection aims to measure an individual's corresponding personality traits through their social media posts. The advancements in Large Language Models (LLMs) offer novel perspectives for personality detection tasks. Existing approaches enhance personality trait analysis by leveraging LLMs to extract semantic information from textual posts as prompts, followed by training classifiers for categorization. However, accurately classifying personality traits remains challenging due to the inherent complexity of human personality and subtle inter-trait distinctions. Moreover, prompt-based methods often exhibit excessive dependency on expert-crafted knowledge without autonomous pattern-learning capacity. To address these limitations, we view personality detection as a ranking task rather than a classification and propose a corresponding reinforcement learning training paradigm. First, we employ supervised fine-tuning (SFT) to establish personality trait ranking capabilities while enforcing standardized output formats, creating a robust initialization. Subsequently, we introduce Group Relative Policy Optimization (GRPO) with a specialized ranking-based reward function. Unlike verification tasks with definitive solutions, personality assessment involves subjective interpretations and blurred boundaries between trait categories. Our reward function explicitly addresses this challenge by training LLMs to learn optimal answer rankings. Comprehensive experiments have demonstrated that our method achieves state-of-the-art performance across multiple personality detection benchmarks.",
    "published": "2026-01-26T15:28:43Z",
    "updated": "2026-01-26T15:28:43Z",
    "link": "http://arxiv.org/pdf/2601.18582v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yuan Cao",
      "Feixiang Liu",
      "Xinyue Wang",
      "Yihan Zhu",
      "Hui Xu",
      "Zheng Wang",
      "Qiang Qiu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18572v1",
    "title": "One Persona, Many Cues, Different Results: How Sociodemographic Cues Impact LLM Personalization",
    "summary": "Personalization of LLMs by sociodemographic subgroup often improves user experience, but can also introduce or amplify biases and unfair outcomes across groups. Prior work has employed so-called personas, sociodemographic user attributes conveyed to a model, to study bias in LLMs by relying on a single cue to prompt a persona, such as user names or explicit attribute mentions. This disregards LLM sensitivity to prompt variations (robustness) and the rarity of some cues in real interactions (external validity). We compare six commonly used persona cues across seven open and proprietary LLMs on four writing and advice tasks. While cues are overall highly correlated, they produce substantial variance in responses across personas. We therefore caution against claims from a single persona cue and recommend future personalization research to evaluate multiple externally valid cues.",
    "published": "2026-01-26T15:15:58Z",
    "updated": "2026-01-26T15:15:58Z",
    "link": "http://arxiv.org/pdf/2601.18572v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Franziska Weeber",
      "Vera Neplenbroek",
      "Jan Batzner",
      "Sebastian Padó"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.13470v3",
    "title": "Induce, Align, Predict: Zero-Shot Stance Detection via Cognitive Inductive Reasoning",
    "summary": "Zero-shot stance detection (ZSSD) seeks to determine the stance of text toward previously unseen targets, a task critical for analyzing dynamic and polarized online discourse with limited labeled data. While large language models (LLMs) offer zero-shot capabilities, prompting-based approaches often fall short in handling complex reasoning and lack robust generalization to novel targets. Meanwhile, LLM-enhanced methods still require substantial labeled data and struggle to move beyond instance-level patterns, limiting their interpretability and adaptability. Inspired by cognitive science, we propose the Cognitive Inductive Reasoning Framework (CIRF), a schema-driven method that bridges linguistic inputs and abstract reasoning via automatic induction and application of cognitive reasoning schemas. CIRF abstracts first-order logic patterns from raw text into multi-relational schema graphs in an unsupervised manner, and leverages a schema-enhanced graph kernel model to align input structures with schema templates for robust, interpretable zero-shot inference. Extensive experiments on SemEval-2016, VAST, and COVID-19-Stance benchmarks demonstrate that CIRF not only establishes new state-of-the-art results, but also achieves comparable performance with just 30% of the labeled data, demonstrating its strong generalization and efficiency in low-resource settings.",
    "published": "2025-06-16T13:28:37Z",
    "updated": "2026-01-26T15:05:54Z",
    "link": "http://arxiv.org/pdf/2506.13470v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Bowen Zhang",
      "Jun Ma",
      "Fuqiang Niu",
      "Li Dong",
      "Jinzhou Cao",
      "Genan Dai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18552v1",
    "title": "Unknown Unknowns: Why Hidden Intentions in LLMs Evade Detection",
    "summary": "LLMs are increasingly embedded in everyday decision-making, yet their outputs can encode subtle, unintended behaviours that shape user beliefs and actions. We refer to these covert, goal-directed behaviours as hidden intentions, which may arise from training and optimisation artefacts, or be deliberately induced by an adversarial developer, yet remain difficult to detect in practice. We introduce a taxonomy of ten categories of hidden intentions, grounded in social science research and organised by intent, mechanism, context, and impact, shifting attention from surface-level behaviours to design-level strategies of influence. We show how hidden intentions can be easily induced in controlled models, providing both testbeds for evaluation and demonstrations of potential misuse. We systematically assess detection methods, including reasoning and non-reasoning LLM judges, and find that detection collapses in realistic open-world settings, particularly under low-prevalence conditions, where false positives overwhelm precision and false negatives conceal true risks. Stress tests on precision-prevalence and precision-FNR trade-offs reveal why auditing fails without vanishingly small false positive rates or strong priors on manipulation types. Finally, a qualitative case study shows that all ten categories manifest in deployed, state-of-the-art LLMs, emphasising the urgent need for robust frameworks. Our work provides the first systematic analysis of detectability failures of hidden intentions in LLMs under open-world settings, offering a foundation for understanding, inducing, and stress-testing such behaviours, and establishing a flexible taxonomy for anticipating evolving threats and informing governance.",
    "published": "2026-01-26T14:59:17Z",
    "updated": "2026-01-26T14:59:17Z",
    "link": "http://arxiv.org/pdf/2601.18552v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Devansh Srivastav",
      "David Pape",
      "Lea Schönherr"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18536v1",
    "title": "Evaluating Morphological Plausibility of Subword Tokenization via Statistical Alignment with Morpho-Syntactic Features",
    "summary": "We present a novel metric for the evaluation of the morphological plausibility of subword segmentation. Unlike the typically used morpheme boundary or retrieval F-score, which requires gold segmentation data that is either unavailable or of inconsistent quality across many languages, our approach utilizes morpho-syntactic features. These are available in resources such as Universal Dependencies or UniMorph for a much wider range of languages. The metric works by probabilistically aligning subwords with morphological features through an IBM Model 1. Our experiments show that the metric correlates well with traditional morpheme boundary recall while being more broadly applicable across languages with different morphological systems.",
    "published": "2026-01-26T14:41:44Z",
    "updated": "2026-01-26T14:41:44Z",
    "link": "http://arxiv.org/pdf/2601.18536v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Abishek Stephen",
      "Jindřich Libovický"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18533v1",
    "title": "From Verifiable Dot to Reward Chain: Harnessing Verifiable Reference-based Rewards for Reinforcement Learning of Open-ended Generation",
    "summary": "Reinforcement learning with verifiable rewards (RLVR) succeeds in reasoning tasks (e.g., math and code) by checking the final verifiable answer (i.e., a verifiable dot signal). However, extending this paradigm to open-ended generation is challenging because there is no unambiguous ground truth. Relying on single-dot supervision often leads to inefficiency and reward hacking. To address these issues, we propose reinforcement learning with verifiable reference-based rewards (RLVRR). Instead of checking the final answer, RLVRR extracts an ordered linguistic signal from high-quality references (i.e, reward chain). Specifically, RLVRR decomposes rewards into two dimensions: content, which preserves deterministic core concepts (e.g., keywords), and style, which evaluates adherence to stylistic properties through LLM-based verification. In this way, RLVRR combines the exploratory strength of RL with the efficiency and reliability of supervised fine-tuning (SFT). Extensive experiments on more than 10 benchmarks with Qwen and Llama models confirm the advantages of our approach. RLVRR (1) substantially outperforms SFT trained with ten times more data and advanced reward models, (2) unifies the training of structured reasoning and open-ended generation, and (3) generalizes more effectively while preserving output diversity. These results establish RLVRR as a principled and efficient path toward verifiable reinforcement learning for general-purpose LLM alignment. We release our code and data at https://github.com/YJiangcm/RLVRR.",
    "published": "2026-01-26T14:39:58Z",
    "updated": "2026-01-26T14:39:58Z",
    "link": "http://arxiv.org/pdf/2601.18533v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yuxin Jiang",
      "Yufei Wang",
      "Qiyuan Zhang",
      "Xingshan Zeng",
      "Liangyou Li",
      "Jierun Chen",
      "Chaofan Tao",
      "Haoli Bai",
      "Lifeng Shang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18527v1",
    "title": "Exploring Fine-Tuning for In-Context Retrieval and Efficient KV-Caching in Long-Context Language Models",
    "summary": "With context windows of millions of tokens, Long-Context Language Models (LCLMs) can encode entire document collections, offering a strong alternative to conventional retrieval-augmented generation (RAG). However, it remains unclear whether fine-tuning strategies can improve long-context performance and translate to greater robustness under KV-cache compression techniques. In this work, we investigate which training strategies most effectively enhance LCLMs' ability to identify and use relevant information, as well as enhancing their robustness under KV-cache compression. Our experiments show substantial in-domain improvements, achieving gains of up to +20 points over the base model. However, out-of-domain generalization remains task dependent with large variance -- LCLMs excels on finance questions (+9 points), while RAG shows stronger performance on multiple-choice questions (+6 points) over the baseline models. Finally, we show that our fine-tuning approaches bring moderate improvements in robustness under KV-cache compression, with gains varying across tasks.",
    "published": "2026-01-26T14:37:02Z",
    "updated": "2026-01-26T14:37:02Z",
    "link": "http://arxiv.org/pdf/2601.18527v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Francesco Maria Molfese",
      "Momchil Hardalov",
      "Rexhina Blloshmi",
      "Bill Byrne",
      "Adrià de Gispert"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18517v1",
    "title": "GenAI for Social Work Field Education: Client Simulation with Real-Time Feedback",
    "summary": "Field education is the signature pedagogy of social work, yet providing timely and objective feedback during training is constrained by the availability of instructors and counseling clients. In this paper, we present SWITCH, the Social Work Interactive Training Chatbot. SWITCH integrates realistic client simulation, real-time counseling skill classification, and a Motivational Interviewing (MI) progression system into the training workflow. To model a client, SWITCH uses a cognitively grounded profile comprising static fields (e.g., background, beliefs) and dynamic fields (e.g., emotions, automatic thoughts, openness), allowing the agent's behavior to evolve throughout a session realistically. The skill classification module identifies the counseling skills from the user utterances, and feeds the result to the MI controller that regulates the MI stage transitions. To enhance classification accuracy, we study in-context learning with retrieval over annotated transcripts, and a fine-tuned BERT multi-label classifier. In the experiments, we demonstrated that both BERT-based approach and in-context learning outperforms the baseline with big margin. SWITCH thereby offers a scalable, low-cost, and consistent training workflow that complements field education, and allows supervisors to focus on higher-level mentorship.",
    "published": "2026-01-26T14:26:54Z",
    "updated": "2026-01-26T14:26:54Z",
    "link": "http://arxiv.org/pdf/2601.18517v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "James Sungarda",
      "Hongkai Liu",
      "Zilong Zhou",
      "Tien-Hsuan Wu",
      "Johnson Chun-Sing Cheung",
      "Ben Kao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.18052v2",
    "title": "The PIMMUR Principles: Ensuring Validity in Collective Behavior of LLM Societies",
    "summary": "Large language models (LLMs) are increasingly deployed to simulate human collective behaviors, yet the methodological rigor of these \"AI societies\" remains under-explored. Through a systematic audit of 42 recent studies, we identify six pervasive flaws-spanning agent profiles, interaction, memory, control, unawareness, and realism (PIMMUR). Our analysis reveals that 90.7% of studies violate at least one principle, undermining simulation validity. We demonstrate that frontier LLMs correctly identify the underlying social experiment in 47.6% of cases, while 65.3% of prompts exert excessive control that pre-determines outcomes. By reproducing five representative experiments (e.g., telephone game), we show that reported collective phenomena often vanish or reverse when PIMMUR principles are enforced, suggesting that many \"emergent\" behaviors are methodological artifacts rather than genuine social dynamics. Our findings suggest that current AI simulations may capture model-specific biases rather than universal human social behaviors, raising critical concerns about the use of LLMs as scientific proxies for human society.",
    "published": "2025-09-22T17:27:29Z",
    "updated": "2026-01-26T14:24:09Z",
    "link": "http://arxiv.org/pdf/2509.18052v2.pdf",
    "category": [
      "cs.CL",
      "cs.CY"
    ],
    "authors": [
      "Jiaxu Zhou",
      "Jen-tse Huang",
      "Xuhui Zhou",
      "Man Ho Lam",
      "Xintao Wang",
      "Hao Zhu",
      "Wenxuan Wang",
      "Maarten Sap"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18512v1",
    "title": "Using Large Language Models to Construct Virtual Top Managers: A Method for Organizational Research",
    "summary": "This study introduces a methodological framework that uses large language models to create virtual personas of real top managers. Drawing on real CEO communications and Moral Foundations Theory, we construct LLM-based participants that simulate the decision-making of individual leaders. Across three phases, we assess construct validity, reliability, and behavioral fidelity by benchmarking these virtual CEOs against human participants. Our results indicate that theoretically scaffolded personas approximate the moral judgements observed in human samples, suggesting that LLM-based personas can serve as credible and complementary tools for organizational research in contexts where direct access to executives is limited. We conclude by outlining implications for future research using LLM-based personas in organizational settings.",
    "published": "2026-01-26T14:17:23Z",
    "updated": "2026-01-26T14:17:23Z",
    "link": "http://arxiv.org/pdf/2601.18512v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Antonio Garzon-Vico",
      "Krithika Sharon Komalapati",
      "Arsalan Shahid",
      "Jan Rosier"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18486v1",
    "title": "Demographic Probing of Large Language Models Lacks Construct Validity",
    "summary": "Demographic probing is widely used to study how large language models (LLMs) adapt their behavior to signaled demographic attributes. This approach typically uses a single demographic cue in isolation (e.g., a name or dialect) as a signal for group membership, implicitly assuming strong construct validity: that such cues are interchangeable operationalizations of the same underlying, demographically conditioned behavior. We test this assumption in realistic advice-seeking interactions, focusing on race and gender in a U.S. context. We find that cues intended to represent the same demographic group induce only partially overlapping changes in model behavior, while differentiation between groups within a given cue is weak and uneven. Consequently, estimated disparities are unstable, with both magnitude and direction varying across cues. We further show that these inconsistencies partly arise from variation in how strongly cues encode demographic attributes and from linguistic confounders that independently shape model behavior. Together, our findings suggest that demographic probing lacks construct validity: it does not yield a single, stable characterization of how LLMs condition on demographic information, which may reflect a misspecified or fragmented construct. We conclude by recommending the use of multiple, ecologically valid cues and explicit control of confounders to support more defensible claims about demographic effects in LLMs.",
    "published": "2026-01-26T13:41:35Z",
    "updated": "2026-01-26T13:41:35Z",
    "link": "http://arxiv.org/pdf/2601.18486v1.pdf",
    "category": [
      "cs.CL",
      "cs.CY"
    ],
    "authors": [
      "Manuel Tonneau",
      "Neil K. R. Seghal",
      "Niyati Malhotra",
      "Victor Orozco-Olvera",
      "Ana María Muñoz Boudet",
      "Lakshmi Subramanian",
      "Sharath Chandra Guntuku",
      "Valentin Hofmann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18468v1",
    "title": "Latent Knowledge as a Predictor of Fact Acquisition in Fine-Tuned Large Language Models",
    "summary": "Large language models store biomedical facts with uneven strength after pretraining: some facts are present in the weights but are not reliably accessible under deterministic decoding (latent knowledge), while others are scarcely represented. We fine tuned Llama 3.1 8B Instruct to learn ontology term identifier mappings from the Human Phenotype Ontology (800 pairs) and the Gene Ontology (400 training pairs), withholding 400 GO pairs to test generalization. Treating learning as a time to event process across 20 epochs, we used stochastic decoding to detect latent knowledge at baseline and Cox proportional hazards models to identify predictors of acquisition, generalization, and degradation. Baseline deterministic recall for HPO was 2.8%, rising to 71.9% after fine-tuning. Latent knowledge was the strongest predictor of faster fact acquisition (HR 2.6) and was associated with earlier, higher peak learning rates and faster convergence; identifier frequency and curated annotation counts had smaller effects. Generalization to withheld GO facts was uncommon (5.8%) but more likely when latent knowledge was present. Previously correct GO mappings degraded more often for withheld (unseen) terms than for trained (seen) terms, suggesting a protective effect of reinforcement during training. These results show that latent knowledge predicts both the speed of factual learning during fine-tuning and the limited generalization of unseen ontology facts, while resistance to degradation depends on whether facts are reinforced.",
    "published": "2026-01-26T13:15:23Z",
    "updated": "2026-01-26T13:15:23Z",
    "link": "http://arxiv.org/pdf/2601.18468v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Daniel B. Hier",
      "Tayo Obafemi-Ajayi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18415v1",
    "title": "Pisets: A Robust Speech Recognition System for Lectures and Interviews",
    "summary": "This work presents a speech-to-text system \"Pisets\" for scientists and journalists which is based on a three-component architecture aimed at improving speech recognition accuracy while minimizing errors and hallucinations associated with the Whisper model. The architecture comprises primary recognition using Wav2Vec2, false positive filtering via the Audio Spectrogram Transformer (AST), and final speech recognition through Whisper. The implementation of curriculum learning methods and the utilization of diverse Russian-language speech corpora significantly enhanced the system's effectiveness. Additionally, advanced uncertainty modeling techniques were introduced, contributing to further improvements in transcription quality. The proposed approaches ensure robust transcribing of long audio data across various acoustic conditions compared to WhisperX and the usual Whisper model. The source code of \"Pisets\" system is publicly available at GitHub: https://github.com/bond005/pisets.",
    "published": "2026-01-26T12:14:51Z",
    "updated": "2026-01-26T12:14:51Z",
    "link": "http://arxiv.org/pdf/2601.18415v1.pdf",
    "category": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "authors": [
      "Ivan Bondarenko",
      "Daniil Grebenkin",
      "Oleg Sedukhin",
      "Mikhail Klementev",
      "Roman Derunets",
      "Lyudmila Budneva"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18396v1",
    "title": "Noise-Robust AV-ASR Using Visual Features Both in the Whisper Encoder and Decoder",
    "summary": "In audiovisual automatic speech recognition (AV-ASR) systems, information fusion of visual features in a pre-trained ASR has been proven as a promising method to improve noise robustness. In this work, based on the prominent Whisper ASR, first, we propose a simple and effective visual fusion method -- use of visual features both in encoder and decoder (dual-use) -- to learn the audiovisual interactions in the encoder and to weigh modalities in the decoder. Second, we compare visual fusion methods in Whisper models of various sizes. Our proposed dual-use method shows consistent noise robustness improvement, e.g., a 35% relative improvement (WER: 4.41% vs. 6.83%) based on Whisper small, and a 57% relative improvement (WER: 4.07% vs. 9.53%) based on Whisper medium, compared to typical reference middle fusion in babble noise with a signal-to-noise ratio (SNR) of 0dB. Third, we conduct ablation studies examining the impact of various module designs and fusion options. Fine-tuned on 1929 hours of audiovisual data, our dual-use method using Whisper medium achieves 4.08% (MUSAN babble noise) and 4.43% (NoiseX babble noise) average WER across various SNRs, thereby establishing a new state-of-the-art in noisy conditions on the LRS3 AV-ASR benchmark. Our code is at https://github.com/ifnspaml/Dual-Use-AVASR",
    "published": "2026-01-26T11:55:07Z",
    "updated": "2026-01-26T11:55:07Z",
    "link": "http://arxiv.org/pdf/2601.18396v1.pdf",
    "category": [
      "eess.AS",
      "cs.CL",
      "cs.CV",
      "cs.SD"
    ],
    "authors": [
      "Zhengyang Li",
      "Thomas Graave",
      "Björn Möller",
      "Zehang Wu",
      "Matthias Franz",
      "Tim Fingscheidt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18395v1",
    "title": "Do not be greedy, Think Twice: Sampling and Selection for Document-level Information Extraction",
    "summary": "Document-level Information Extraction (DocIE) aims to produce an output template with the entities and relations of interest occurring in the given document. Standard practices include prompting decoder-only LLMs using greedy decoding to avoid output variability. Rather than treating this variability as a limitation, we show that sampling can produce substantially better solutions than greedy decoding, especially when using reasoning models. We thus propose ThinkTwice, a sampling and selection framework in which the LLM generates multiple candidate templates for a given document, and a selection module chooses the most suitable one. We introduce both an unsupervised method that exploits agreement across generated outputs, and a supervised selection method using reward models trained on labeled DocIE data. To address the scarcity of golden reasoning trajectories for DocIE, we propose a rejection-sampling-based method to generate silver training data that pairs output templates with reasoning traces. Our experiments show the validity of unsupervised and supervised ThinkTwice, consistently outperforming greedy baselines and the state-of-the-art.",
    "published": "2026-01-26T11:53:08Z",
    "updated": "2026-01-26T11:53:08Z",
    "link": "http://arxiv.org/pdf/2601.18395v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Mikel Zubillaga",
      "Oscar Sainz",
      "Oier Lopez de Lacalle",
      "Eneko Agirre"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18393v1",
    "title": "OCR-Enhanced Multimodal ASR Can Read While Listening",
    "summary": "Visual information, such as subtitles in a movie, often helps automatic speech recognition. In this paper, we propose Donut-Whisper, an audio-visual ASR model with dual encoder to leverage visual information to improve speech recognition performance in both English and Chinese. Donut-Whisper combines the advantage of the linear and the Q-Former-based modality alignment structures via a cross-attention module, generating more powerful audio-visual features. Meanwhile, we propose a lightweight knowledge distillation scheme showcasing the potential of using audio-visual models to teach audio-only models to achieve better performance. Moreover, we propose a new multilingual audio-visual speech recognition dataset based on movie clips containing both Chinese and English partitions. As a result, Donut-Whisper achieved significantly better performance on both English and Chinese partition of the dataset compared to both Donut and Whisper large V3 baselines. In particular, an absolute 5.75% WER reduction and a 16.5% absolute CER reduction were achieved on the English and Chinese sets respectively compared to the Whisper ASR baseline.",
    "published": "2026-01-26T11:51:08Z",
    "updated": "2026-01-26T11:51:08Z",
    "link": "http://arxiv.org/pdf/2601.18393v1.pdf",
    "category": [
      "cs.SD",
      "cs.CL",
      "eess.AS"
    ],
    "authors": [
      "Junli Chen",
      "Changli Tang",
      "Yixuan Li",
      "Guangzhi Sun",
      "Chao Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18380v1",
    "title": "Corpus-Based Approaches to Igbo Diacritic Restoration",
    "summary": "With natural language processing (NLP), researchers aim to enable computers to identify and understand patterns in human languages. This is often difficult because a language embeds many dynamic and varied properties in its syntax, pragmatics and phonology, which need to be captured and processed. The capacity of computers to process natural languages is increasing because NLP researchers are pushing its boundaries. But these research works focus more on well-resourced languages such as English, Japanese, German, French, Russian, Mandarin Chinese, etc. Over 95% of the world's 7000 languages are low-resourced for NLP, i.e. they have little or no data, tools, and techniques for NLP work.\n  In this thesis, we present an overview of diacritic ambiguity and a review of previous diacritic disambiguation approaches on other languages. Focusing on the Igbo language, we report the steps taken to develop a flexible framework for generating datasets for diacritic restoration. Three main approaches, the standard n-gram model, the classification models and the embedding models were proposed. The standard n-gram models use a sequence of previous words to the target stripped word as key predictors of the correct variants. For the classification models, a window of words on both sides of the target stripped word was used. The embedding models compare the similarity scores of the combined context word embeddings and the embeddings of each of the candidate variant vectors.",
    "published": "2026-01-26T11:30:36Z",
    "updated": "2026-01-26T11:30:36Z",
    "link": "http://arxiv.org/pdf/2601.18380v1.pdf",
    "category": [
      "cs.CL",
      "cs.CY",
      "cs.IR"
    ],
    "authors": [
      "Ignatius Ezeani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18375v1",
    "title": "Hierarchical Text Classification with LLM-Refined Taxonomies",
    "summary": "Hierarchical text classification (HTC) depends on taxonomies that organize labels into structured hierarchies. However, many real-world taxonomies introduce ambiguities, such as identical leaf names under similar parent nodes, which prevent language models (LMs) from learning clear decision boundaries. In this paper, we present TaxMorph, a framework that uses large language models (LLMs) to transform entire taxonomies through operations such as renaming, merging, splitting, and reordering. Unlike prior work, our method revises the full hierarchy to better match the semantics encoded by LMs. Experiments across three HTC benchmarks show that LLM-refined taxonomies consistently outperform human-curated ones in various settings up to +2.9pp. in F1. To better understand these improvements, we compare how well LMs can assign leaf nodes to parent nodes and vice versa across human-curated and LLM-refined taxonomies. We find that human-curated taxonomies lead to more easily separable clusters in embedding space. However, the LLM-refined taxonomies align more closely with the model's actual confusion patterns during classification. In other words, even though they are harder to separate, they better reflect the model's inductive biases. These findings suggest that LLM-guided refinement creates taxonomies that are more compatible with how models learn, improving HTC performance.",
    "published": "2026-01-26T11:28:32Z",
    "updated": "2026-01-26T11:28:32Z",
    "link": "http://arxiv.org/pdf/2601.18375v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Jonas Golde",
      "Nicolaas Jedema",
      "Ravi Krishnan",
      "Phong Le"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.26136v2",
    "title": "CliniBench: A Clinical Outcome Prediction Benchmark for Generative and Encoder-Based Language Models",
    "summary": "With their growing capabilities, generative large language models (LLMs) are being increasingly investigated for complex medical tasks. However, their effectiveness in real-world clinical applications remains underexplored. To address this, we present CliniBench, the first benchmark that enables comparability of well-studied encoder-based classifiers and generative LLMs for discharge diagnosis prediction from admission notes in MIMIC-IV dataset. Our extensive study compares 12 generative LLMs and 3 encoder-based classifiers and demonstrates that encoder-based classifiers consistently outperform generative models in diagnosis prediction. We assess several retrieval augmentation strategies for in-context learning from similar patients and find that they provide notable performance improvements for generative LLMs.",
    "published": "2025-09-30T11:56:53Z",
    "updated": "2026-01-26T11:28:24Z",
    "link": "http://arxiv.org/pdf/2509.26136v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Paul Grundmann",
      "Dennis Fast",
      "Jan Frick",
      "Thomas Steffek",
      "Felix Gers",
      "Wolfgang Nejdl",
      "Alexander Löser"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18374v1",
    "title": "CitiLink: Enhancing Municipal Transparency and Citizen Engagement through Searchable Meeting Minutes",
    "summary": "City council minutes are typically lengthy and formal documents with a bureaucratic writing style. Although publicly available, their structure often makes it difficult for citizens or journalists to efficiently find information. In this demo, we present CitiLink, a platform designed to transform unstructured municipal meeting minutes into structured and searchable data, demonstrating how NLP and IR can enhance the accessibility and transparency of local government. The system employs LLMs to extract metadata, discussed subjects, and voting outcomes, which are then indexed in a database to support full-text search with BM25 ranking and faceted filtering through a user-friendly interface. The developed system was built over a collection of 120 minutes made available by six Portuguese municipalities. To assess its usability, CitiLink was tested through guided sessions with municipal personnel, providing insights into how real users interact with the system. In addition, we evaluated Gemini's performance in extracting relevant information from the minutes, highlighting its effectiveness in data extraction.",
    "published": "2026-01-26T11:26:57Z",
    "updated": "2026-01-26T11:26:57Z",
    "link": "http://arxiv.org/pdf/2601.18374v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Rodrigo Silva",
      "José Evans",
      "José Isidro",
      "Miguel Marques",
      "Afonso Fonseca",
      "Ricardo Morais",
      "João Canavilhas",
      "Arian Pasquali",
      "Purificação Silvano",
      "Alípio Jorge",
      "Nuno Guimarães",
      "Sérgio Nunes",
      "Ricardo Campos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.24235v2",
    "title": "LAILA: A Large Trait-Based Dataset for Arabic Automated Essay Scoring",
    "summary": "Automated Essay Scoring (AES) has gained increasing attention in recent years, yet research on Arabic AES remains limited due to the lack of publicly available datasets. To address this, we introduce LAILA, the largest publicly available Arabic AES dataset to date, comprising 7,859 essays annotated with holistic and trait-specific scores on seven dimensions: relevance, organization, vocabulary, style, development, mechanics, and grammar. We detail the dataset design, collection, and annotations, and provide benchmark results using state-of-the-art Arabic and English models in prompt-specific and cross-prompt settings. LAILA fills a critical need in Arabic AES research, supporting the development of robust scoring systems.",
    "published": "2025-12-30T13:49:52Z",
    "updated": "2026-01-26T11:22:08Z",
    "link": "http://arxiv.org/pdf/2512.24235v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "May Bashendy",
      "Walid Massoud",
      "Sohaila Eltanbouly",
      "Salam Albatarni",
      "Marwan Sayed",
      "Abrar Abir",
      "Houda Bouamor",
      "Tamer Elsayed"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.01387v2",
    "title": "ABCD-LINK: Annotation Bootstrapping for Cross-Document Fine-Grained Links",
    "summary": "Understanding fine-grained links between documents is crucial for many applications, yet progress is limited by the lack of efficient methods for data curation. To address this limitation, we introduce a domain-agnostic framework for bootstrapping sentence-level cross-document links from scratch. Our approach (1) generates and validates semi-synthetic datasets of linked documents, (2) uses these datasets to benchmark and shortlist the best-performing linking approaches, and (3) applies the shortlisted methods in large-scale human-in-the-loop annotation of natural text pairs. We apply the framework in two distinct domains -- peer review and news -- and show that combining retrieval models with LLMs achieves a 73% human approval rate for suggested links, more than doubling the acceptance of strong retrievers alone. Our framework allows users to produce novel datasets that enable systematic study of cross-document understanding, supporting downstream tasks such as media framing analysis and peer review assessment. All code, data, and annotation protocols are released to facilitate future research.",
    "published": "2025-09-01T11:32:24Z",
    "updated": "2026-01-26T11:09:33Z",
    "link": "http://arxiv.org/pdf/2509.01387v2.pdf",
    "category": [
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "authors": [
      "Serwar Basch",
      "Ilia Kuznetsov",
      "Tom Hope",
      "Iryna Gurevych"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18334v1",
    "title": "Overalignment in Frontier LLMs: An Empirical Study of Sycophantic Behaviour in Healthcare",
    "summary": "As LLMs are increasingly integrated into clinical workflows, their tendency for sycophancy, prioritizing user agreement over factual accuracy, poses significant risks to patient safety. While existing evaluations often rely on subjective datasets, we introduce a robust framework grounded in medical MCQA with verifiable ground truths. We propose the Adjusted Sycophancy Score, a novel metric that isolates alignment bias by accounting for stochastic model instability, or \"confusability\". Through an extensive scaling analysis of the Qwen-3 and Llama-3 families, we identify a clear scaling trajectory for resilience. Furthermore, we reveal a counter-intuitive vulnerability in reasoning-optimized \"Thinking\" models: while they demonstrate high vanilla accuracy, their internal reasoning traces frequently rationalize incorrect user suggestions under authoritative pressure. Our results across frontier models suggest that benchmark performance is not a proxy for clinical reliability, and that simplified reasoning structures may offer superior robustness against expert-driven sycophancy.",
    "published": "2026-01-26T10:21:34Z",
    "updated": "2026-01-26T10:21:34Z",
    "link": "http://arxiv.org/pdf/2601.18334v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Clément Christophe",
      "Wadood Mohammed Abdul",
      "Prateek Munjal",
      "Tathagata Raha",
      "Ronnie Rajan",
      "Praveenkumar Kanithi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.07687v2",
    "title": "Large Language Models as Proxies for Theories of Human Linguistic Cognition",
    "summary": "We consider the possible role of current large language models (LLMs) in the study of human linguistic cognition. We focus on the use of such models as proxies for theories of cognition that are relatively linguistically-neutral in their representations and learning but differ from current LLMs in key ways. We illustrate this potential use of LLMs as proxies for theories of cognition in the context of two kinds of questions: (a) whether the target theory accounts for the acquisition of a given pattern from a given corpus; and (b) whether the target theory makes a given typologically-attested pattern easier to acquire than another, typologically-unattested pattern. For each of the two questions we show, building on recent literature, how current LLMs can potentially be of help, but we note that at present this help is quite limited.",
    "published": "2025-02-11T16:38:16Z",
    "updated": "2026-01-26T10:13:26Z",
    "link": "http://arxiv.org/pdf/2502.07687v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Imry Ziv",
      "Nur Lan",
      "Emmanuel Chemla",
      "Roni Katzir"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18321v1",
    "title": "Integrating Fine-Grained Audio-Visual Evidence for Robust Multimodal Emotion Reasoning",
    "summary": "Multimodal emotion analysis is shifting from static classification to generative reasoning. Beyond simple label prediction, robust affective reasoning must synthesize fine-grained signals such as facial micro-expressions and prosodic which shifts to decode the latent causality within complex social contexts. However, current Multimodal Large Language Models (MLLMs) face significant limitations in fine-grained perception, primarily due to data scarcity and insufficient cross-modal fusion. As a result, these models often exhibit unimodal dominance which leads to hallucinations in complex multimodal interactions, particularly when visual and acoustic cues are subtle, ambiguous, or even contradictory (e.g., in sarcastic scenery). To address this, we introduce SABER-LLM, a framework designed for robust multimodal reasoning. First, we construct SABER, a large-scale emotion reasoning dataset comprising 600K video clips, annotated with a novel six-dimensional schema that jointly captures audiovisual cues and causal logic. Second, we propose the structured evidence decomposition paradigm, which enforces a \"perceive-then-reason\" separation between evidence extraction and reasoning to alleviate unimodal dominance. The ability to perceive complex scenes is further reinforced by consistency-aware direct preference optimization, which explicitly encourages alignment among modalities under ambiguous or conflicting perceptual conditions. Experiments on EMER, EmoBench-M, and SABER-Test demonstrate that SABER-LLM significantly outperforms open-source baselines and achieves robustness competitive with closed-source models in decoding complex emotional dynamics. The dataset and model are available at https://github.com/zxzhao0/SABER-LLM.",
    "published": "2026-01-26T10:03:26Z",
    "updated": "2026-01-26T10:03:26Z",
    "link": "http://arxiv.org/pdf/2601.18321v1.pdf",
    "category": [
      "cs.MM",
      "cs.CL",
      "cs.CV"
    ],
    "authors": [
      "Zhixian Zhao",
      "Wenjie Tian",
      "Xiaohai Tian",
      "Jun Zhang",
      "Lei Xie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.15556v2",
    "title": "A Survey on Multilingual Mental Disorders Detection from Social Media Data",
    "summary": "The increasing prevalence of mental disorders globally highlights the urgent need for effective digital screening methods that can be used in multilingual contexts. Most existing studies, however, focus on English data, overlooking critical mental health signals that may be present in non-English texts. To address this gap, we present a survey of the detection of mental disorders using social media data beyond the English language. We compile a comprehensive list of 108 datasets spanning 25 languages that can be used for developing NLP models for mental health screening. In addition, we discuss the cultural nuances that influence online language patterns and self-disclosure behaviors, and how these factors can impact the performance of NLP tools. Our survey highlights major challenges, including the scarcity of resources for low- and mid-resource languages and the dominance of depression-focused data over other disorders. By identifying these gaps, we advocate for interdisciplinary collaborations and the development of multilingual benchmarks to enhance mental health screening worldwide.",
    "published": "2025-05-21T14:15:54Z",
    "updated": "2026-01-26T09:53:26Z",
    "link": "http://arxiv.org/pdf/2505.15556v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Ana-Maria Bucur",
      "Marcos Zampieri",
      "Tharindu Ranasinghe",
      "Fabio Crestani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.14004v3",
    "title": "Locate, Steer, and Improve: A Practical Survey of Actionable Mechanistic Interpretability in Large Language Models",
    "summary": "Mechanistic Interpretability (MI) has emerged as a vital approach to demystify the opaque decision-making of Large Language Models (LLMs). However, existing reviews primarily treat MI as an observational science, summarizing analytical insights while lacking a systematic framework for actionable intervention. To bridge this gap, we present a practical survey structured around the pipeline: \"Locate, Steer, and Improve.\" We formally categorize Localizing (diagnosis) and Steering (intervention) methods based on specific Interpretable Objects to establish a rigorous intervention protocol. Furthermore, we demonstrate how this framework enables tangible improvements in Alignment, Capability, and Efficiency, effectively operationalizing MI as an actionable methodology for model optimization. The curated paper list of this work is available at https://github.com/rattlesnakey/Awesome-Actionable-MI-Survey.",
    "published": "2026-01-20T14:23:23Z",
    "updated": "2026-01-26T09:33:08Z",
    "link": "http://arxiv.org/pdf/2601.14004v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Hengyuan Zhang",
      "Zhihao Zhang",
      "Mingyang Wang",
      "Zunhai Su",
      "Yiwei Wang",
      "Qianli Wang",
      "Shuzhou Yuan",
      "Ercong Nie",
      "Xufeng Duan",
      "Qibo Xue",
      "Zeping Yu",
      "Chenming Shang",
      "Xiao Liang",
      "Jing Xiong",
      "Hui Shen",
      "Chaofan Tao",
      "Zhengwu Liu",
      "Senjie Jin",
      "Zhiheng Xi",
      "Dongdong Zhang",
      "Sophia Ananiadou",
      "Tao Gui",
      "Ruobing Xie",
      "Hayden Kwok-Hay So",
      "Hinrich Schütze",
      "Xuanjing Huang",
      "Qi Zhang",
      "Ngai Wong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06700v2",
    "title": "How Language Models Conflate Logical Validity with Plausibility: A Representational Analysis of Content Effects",
    "summary": "Both humans and large language models (LLMs) exhibit content effects: biases in which the plausibility of the semantic content of a reasoning problem influences judgments regarding its logical validity. While this phenomenon in humans is best explained by the dual-process theory of reasoning, the mechanisms behind content effects in LLMs remain unclear. In this work, we address this issue by investigating how LLMs encode the concepts of validity and plausibility within their internal representations. We show that both concepts are linearly represented and strongly aligned in representational geometry, leading models to conflate plausibility with validity. Using steering vectors, we demonstrate that plausibility vectors can causally bias validity judgements, and vice versa, and that the degree of alignment between these two concepts predicts the magnitude of behavioral content effects across models. Finally, we construct debiasing vectors that disentangle these concepts, reducing content effects and improving reasoning accuracy. Our findings advance understanding of how abstract logical concepts are represented in LLMs and highlight representational interventions as a path toward more logical systems.",
    "published": "2025-10-08T06:48:08Z",
    "updated": "2026-01-26T09:31:45Z",
    "link": "http://arxiv.org/pdf/2510.06700v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Leonardo Bertolazzi",
      "Sandro Pezzelle",
      "Raffaella Bernardi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18302v1",
    "title": "Suppressing Final Layer Hidden State Jumps in Transformer Pretraining",
    "summary": "This paper discusses the internal behavior of Transformer language models. Many recent pre-trained models have been reported to exhibit only slight changes in the angular distance between the input and output hidden state vectors in the middle Transformer layers, despite a disproportionately large ``jump'' in the angular distance occurring in or around the final Transformer layer. To characterize this, we first introduce a quantitative metric for the jump strength around the final layer, and then demonstrate its prevalence across many open-weight models, as well as its amplification throughout pre-training. Assuming such jumps indicate an undesirable property, we propose the jump-suppressing regularizer (JREG) which penalizes this jump during pre-training, thereby encouraging more balanced capability usage across the middle layers. Empirical evaluations of three model sizes of Llama-based models, trained with the proposed JREG method, reveal improved task performance compared to the baseline without altering the model architecture.",
    "published": "2026-01-26T09:30:49Z",
    "updated": "2026-01-26T09:30:49Z",
    "link": "http://arxiv.org/pdf/2601.18302v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Keigo Shibata",
      "Kazuki Yano",
      "Ryosuke Takahashi",
      "Jaesung Lee",
      "Wataru Ikeda",
      "Jun Suzuki"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.14313v3",
    "title": "Teaching Small Language Models to Learn Logic through Meta-Learning",
    "summary": "Large language models (LLMs) are increasingly evaluated on reasoning tasks, yet their logical abilities remain contested. To address this, we study LLMs' reasoning in a well-defined fragment of logic: syllogistic reasoning. We cast the problem as premise selection and construct controlled datasets to isolate logical competence. Beyond evaluation, an open challenge is enabling LLMs to acquire abstract inference patterns that generalize to novel structures. We propose to apply few-shot meta-learning to this domain, thereby encouraging models to extract rules across tasks rather than memorize patterns within tasks. Although meta-learning has been little explored in the context of logic learnability, our experiments show that it is effective: small models (1.5B-7B) fine-tuned with meta-learning demonstrate strong gains in generalization, with especially pronounced benefits in low-data regimes. These meta-learned models outperform GPT-4o and o3-mini on our syllogistic reasoning task.",
    "published": "2025-05-20T13:00:48Z",
    "updated": "2026-01-26T09:25:06Z",
    "link": "http://arxiv.org/pdf/2505.14313v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Leonardo Bertolazzi",
      "Manuel Vargas Guzmán",
      "Raffaella Bernardi",
      "Maciej Malicki",
      "Jakub Szymanik"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18285v1",
    "title": "U-Fold: Dynamic Intent-Aware Context Folding for User-Centric Agents",
    "summary": "Large language model (LLM)-based agents have been successfully deployed in many tool-augmented settings, but their scalability is fundamentally constrained by context length. Existing context-folding methods mitigate this issue by summarizing past interactions, yet they are typically designed for single-query or single-intent scenarios. In more realistic user-centric dialogues, we identify two major failure modes: (i) they irreversibly discard fine-grained constraints and intermediate facts that are crucial for later decisions, and (ii) their summaries fail to track evolving user intent, leading to omissions and erroneous actions. To address these limitations, we propose U-Fold, a dynamic context-folding framework tailored to user-centric tasks. U-Fold retains the full user--agent dialogue and tool-call history but, at each turn, uses two core components to produce an intent-aware, evolving dialogue summary and a compact, task-relevant tool log. Extensive experiments on $τ$-bench, $τ^2$-bench, VitaBench, and harder context-inflated settings show that U-Fold consistently outperforms ReAct (achieving a 71.4% win rate in long-context settings) and prior folding baselines (with improvements of up to 27.0%), particularly on long, noisy, multi-turn tasks. Our study demonstrates that U-Fold is a promising step toward transferring context-management techniques from single-query benchmarks to realistic user-centric applications.",
    "published": "2026-01-26T09:11:49Z",
    "updated": "2026-01-26T09:11:49Z",
    "link": "http://arxiv.org/pdf/2601.18285v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Jin Su",
      "Runnan Fang",
      "Yeqiu Li",
      "Xiaobin Wang",
      "Shihao Cai",
      "Pengjun Xie",
      "Ningyu Zhang",
      "Fajie Yuan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18281v1",
    "title": "Reflecting Twice before Speaking with Empathy: Self-Reflective Alternating Inference for Empathy-Aware End-to-End Spoken Dialogue",
    "summary": "End-to-end Spoken Language Models (SLMs) hold great potential for paralinguistic perception, and numerous studies have aimed to enhance their capabilities, particularly for empathetic dialogue. However, current approaches largely depend on rigid supervised signals, such as ground-truth response in supervised fine-tuning or preference scores in reinforcement learning. Such reliance is fundamentally limited for modeling complex empathy, as there is no single \"correct\" response and a simple numerical score cannot fully capture the nuances of emotional expression or the appropriateness of empathetic behavior. To address these limitations, we sequentially introduce EmpathyEval, a descriptive natural-language-based evaluation model for assessing empathetic quality in spoken dialogues. Building upon EmpathyEval, we propose ReEmpathy, an end-to-end SLM that enhances empathetic dialogue through a novel Empathetic Self-Reflective Alternating Inference mechanism, which interleaves spoken response generation with free-form, empathy-related reflective reasoning. Extensive experiments demonstrate that ReEmpathy substantially improves empathy-sensitive spoken dialogue by enabling reflective reasoning, offering a promising approach toward more emotionally intelligent and empathy-aware human-computer interactions.",
    "published": "2026-01-26T09:04:50Z",
    "updated": "2026-01-26T09:04:50Z",
    "link": "http://arxiv.org/pdf/2601.18281v1.pdf",
    "category": [
      "cs.CL",
      "cs.SD"
    ],
    "authors": [
      "Yuhang Jia",
      "Pei Liu",
      "Haoqin Sun",
      "Jiaming Zhou",
      "Xuxin Cheng",
      "Cao Liu",
      "Ke Zeng",
      "Xunliang Cai",
      "Yong Qin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18271v1",
    "title": "Designing large language model prompts to extract scores from messy text: A shared dataset and challenge",
    "summary": "In some areas of computing, natural language processing and information science, progress is made by sharing datasets and challenging the community to design the best algorithm for an associated task. This article introduces a shared dataset of 1446 short texts, each of which describes a research quality score on the UK scale of 1* to 4*. This is a messy collection, with some texts not containing scores and others including invalid scores or strange formats. With this dataset there is also a description of what constitutes a valid score and a \"gold standard\" of the correct scores for these texts (including missing values). The challenge is to design a prompt for Large Language Models (LLMs) to extract the scores from these texts as accurately as possible. The format for the response should be a number and no other text so there are two aspects to the challenge: ensuring that the LLM returns only a number, and instructing it to deduce the correct number for the text. As part of this, the LLM prompt needs to explain when to return the missing value code, -1, instead of a number when the text does not clearly contain one. The article also provides an example of a simple prompt. The purpose of the challenge is twofold: to get an effective solution to this problem, and to increase understanding of prompt design and LLM capabilities for complex numerical tasks. The initial solution suggested has an accuracy of 72.6%, so the challenge is to beat this.",
    "published": "2026-01-26T08:55:55Z",
    "updated": "2026-01-26T08:55:55Z",
    "link": "http://arxiv.org/pdf/2601.18271v1.pdf",
    "category": [
      "cs.DL",
      "cs.CL"
    ],
    "authors": [
      "Mike Thelwall"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.15727v2",
    "title": "Towards Automated Kernel Generation in the Era of LLMs",
    "summary": "The performance of modern AI systems is fundamentally constrained by the quality of their underlying kernels, which translate high-level algorithmic semantics into low-level hardware operations. Achieving near-optimal kernels requires expert-level understanding of hardware architectures and programming models, making kernel engineering a critical but notoriously time-consuming and non-scalable process. Recent advances in large language models (LLMs) and LLM-based agents have opened new possibilities for automating kernel generation and optimization. LLMs are well-suited to compress expert-level kernel knowledge that is difficult to formalize, while agentic systems further enable scalable optimization by casting kernel development as an iterative, feedback-driven loop. Rapid progress has been made in this area. However, the field remains fragmented, lacking a systematic perspective for LLM-driven kernel generation. This survey addresses this gap by providing a structured overview of existing approaches, spanning LLM-based approaches and agentic optimization workflows, and systematically compiling the datasets and benchmarks that underpin learning and evaluation in this domain. Moreover, key open challenges and future research directions are further outlined, aiming to establish a comprehensive reference for the next generation of automated kernel optimization. To keep track of this field, we maintain an open-source GitHub repository at https://github.com/flagos-ai/awesome-LLM-driven-kernel-generation.",
    "published": "2026-01-22T07:53:52Z",
    "updated": "2026-01-26T08:47:52Z",
    "link": "http://arxiv.org/pdf/2601.15727v2.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Yang Yu",
      "Peiyu Zang",
      "Chi Hsu Tsai",
      "Haiming Wu",
      "Yixin Shen",
      "Jialing Zhang",
      "Haoyu Wang",
      "Zhiyou Xiao",
      "Jingze Shi",
      "Yuyu Luo",
      "Wentao Zhang",
      "Chunlei Men",
      "Guang Liu",
      "Yonghua Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18261v1",
    "title": "FGGM: Fisher-Guided Gradient Masking for Continual Learning",
    "summary": "Catastrophic forgetting impairs the continuous learning of large language models. We propose Fisher-Guided Gradient Masking (FGGM), a framework that mitigates this by strategically selecting parameters for updates using diagonal Fisher Information. FGGM dynamically generates binary masks with adaptive thresholds, preserving critical parameters to balance stability and plasticity without requiring historical data. Unlike magnitude-based methods such as MIGU, our approach offers a mathematically principled parameter importance estimation. On the TRACE benchmark, FGGM shows a 9.6% relative improvement in retaining general capabilities over supervised fine-tuning (SFT) and a 4.4% improvement over MIGU on TRACE tasks. Additional analysis on code generation tasks confirms FGGM's superior performance and reduced forgetting, establishing it as an effective solution.",
    "published": "2026-01-26T08:35:34Z",
    "updated": "2026-01-26T08:35:34Z",
    "link": "http://arxiv.org/pdf/2601.18261v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Chao-Hong Tan",
      "Qian Chen",
      "Wen Wang",
      "Yukun Ma",
      "Chong Zhang",
      "Chong Deng",
      "Qinglin Zhang",
      "Xiangang Li",
      "Jieping Ye"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18238v1",
    "title": "TechING: Towards Real World Technical Image Understanding via VLMs",
    "summary": "Professionals working in technical domain typically hand-draw (on whiteboard, paper, etc.) technical diagrams (e.g., flowcharts, block diagrams, etc.) during discussions; however, if they want to edit these later, it needs to be drawn from scratch. Modern day VLMs have made tremendous progress in image understanding but they struggle when it comes to understanding technical diagrams. One way to overcome this problem is to fine-tune on real world hand-drawn images, but it is not practically possible to generate large number of such images. In this paper, we introduce a large synthetically generated corpus (reflective of real world images) for training VLMs and subsequently evaluate VLMs on a smaller corpus of hand-drawn images (with the help of humans). We introduce several new self-supervision tasks for training and perform extensive experiments with various baseline models and fine-tune Llama 3.2 11B-instruct model on synthetic images on these tasks to obtain LLama-VL-TUG, which significantly improves the ROUGE-L performance of Llama 3.2 11B-instruct by 2.14x and achieves the best all-round performance across all baseline models. On real-world images, human evaluation reveals that we achieve minimum compilation errors across all baselines in 7 out of 8 diagram types and improve the average F1 score of Llama 3.2 11B-instruct by 6.97x.",
    "published": "2026-01-26T07:43:55Z",
    "updated": "2026-01-26T07:43:55Z",
    "link": "http://arxiv.org/pdf/2601.18238v1.pdf",
    "category": [
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Tafazzul Nadeem",
      "Bhavik Shangari",
      "Manish Rai",
      "Gagan Raj Gupta",
      "Ashutosh Modi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.16781v2",
    "title": "Persuasion Tokens for Editing Factual Knowledge in LLMs",
    "summary": "In-context knowledge editing (IKE) is a promising technique for updating Large Language Models (LLMs) with new information. However, IKE relies on lengthy, fact-specific demonstrations which are costly to create and consume significant context window space. In this paper, we introduce persuasion tokens (P-Tokens) -- special tokens trained to replicate the effect of IKE demonstrations, enabling efficient knowledge editing without requiring fact-specific demonstrations. We evaluate P-Tokens across two editing datasets and three LLMs, demonstrating performance comparable to, and often exceeding, IKE. We further find that editing performance is robust to distractors with small negative effects to neighboring facts, and that increasing the number of P-Tokens improves performance. Our work addresses key limitations of IKE and provides a more practical and scalable alternative for editing LLMs.",
    "published": "2026-01-23T14:29:28Z",
    "updated": "2026-01-26T07:21:17Z",
    "link": "http://arxiv.org/pdf/2601.16781v2.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Paul Youssef",
      "Christin Seifert",
      "Jörg Schlötterer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18204v1",
    "title": "MemWeaver: Weaving Hybrid Memories for Traceable Long-Horizon Agentic Reasoning",
    "summary": "Large language model-based agents operating in long-horizon interactions require memory systems that support temporal consistency, multi-hop reasoning, and evidence-grounded reuse across sessions. Existing approaches largely rely on unstructured retrieval or coarse abstractions, which often lead to temporal conflicts, brittle reasoning, and limited traceability. We propose MemWeaver, a unified memory framework that consolidates long-term agent experiences into three interconnected components: a temporally grounded graph memory for structured relational reasoning, an experience memory that abstracts recurring interaction patterns from repeated observations, and a passage memory that preserves original textual evidence. MemWeaver employs a dual-channel retrieval strategy that jointly retrieves structured knowledge and supporting evidence to construct compact yet information-dense contexts for reasoning. Experiments on the LoCoMo benchmark demonstrate that MemWeaver substantially improves multi-hop and temporal reasoning accuracy while reducing input context length by over 95\\% compared to long-context baselines.",
    "published": "2026-01-26T06:39:27Z",
    "updated": "2026-01-26T06:39:27Z",
    "link": "http://arxiv.org/pdf/2601.18204v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Juexiang Ye",
      "Xue Li",
      "Xinyu Yang",
      "Chengkai Huang",
      "Lanshun Nie",
      "Lina Yao",
      "Dechen Zhan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.15609v2",
    "title": "When Sharpening Becomes Collapse: Sampling Bias and Semantic Coupling in RL with Verifiable Rewards",
    "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) is a central paradigm for turning large language models (LLMs) into reliable problem solvers, especially in logic-heavy domains. Despite its empirical success, it remains unclear whether RLVR elicits novel capabilities or merely sharpens the distribution over existing knowledge. We study this by formalizing over-sharpening, a phenomenon where the policy collapses onto limited modes, suppressing valid alternatives. At a high level, we discover finite-batch updates intrinsically bias learning toward sampled modes, triggering a collapse that propagates globally via semantic coupling. To mitigate this, we propose inverse-success advantage calibration to prioritize difficult queries and distribution-level calibration to diversify sampling via a memory network. Empirical evaluations validate that our strategies can effectively improve generalization.",
    "published": "2026-01-22T03:15:57Z",
    "updated": "2026-01-26T06:32:51Z",
    "link": "http://arxiv.org/pdf/2601.15609v2.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Mingyuan Fan",
      "Weiguang Han",
      "Daixin Wang",
      "Cen Chen",
      "Zhiqiang Zhang",
      "Jun Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18413v3",
    "title": "Multi-Agent Collaborative Filtering: Orchestrating Users and Items for Agentic Recommendations",
    "summary": "Agentic recommendations cast recommenders as large language model (LLM) agents that can plan, reason, use tools, and interact with users of varying preferences in web applications. However, most existing agentic recommender systems focus on generic single-agent plan-execute workflows or multi-agent task decomposition pipelines. Without recommendation-oriented design, they often underuse the collaborative signals in the user-item interaction history, leading to unsatisfying recommendation results. To address this, we propose the Multi-Agent Collaborative Filtering (MACF) framework for agentic recommendations, drawing an analogy between traditional collaborative filtering algorithms and LLM-based multi-agent collaboration. Specifically, given a target user and query, we instantiate similar users and relevant items as LLM agents with unique profiles. Each agent is able to call retrieval tools, suggest candidate items, and interact with other agents. Different from the static preference aggregation in traditional collaborative filtering, MACF employs a central orchestrator agent to adaptively manage the collaboration between user and item agents via dynamic agent recruitment and personalized collaboration instruction. Experimental results on datasets from three different domains show the advantages of our MACF framework compared to strong agentic recommendation baselines.",
    "published": "2025-11-23T11:57:10Z",
    "updated": "2026-01-26T05:57:33Z",
    "link": "http://arxiv.org/pdf/2511.18413v3.pdf",
    "category": [
      "cs.CL",
      "cs.IR"
    ],
    "authors": [
      "Yu Xia",
      "Sungchul Kim",
      "Tong Yu",
      "Ryan A. Rossi",
      "Julian McAuley"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.11214v2",
    "title": "T$^\\star$: Progressive Block Scaling for MDM Through Trajectory Aware RL",
    "summary": "We present T*, a simple TraceRL-based training curriculum for progressive block-size scaling in masked diffusion language models (MDMs). Starting from an AR-initialized small-block MDM, T* transitions smoothly to larger blocks, enabling higher-parallelism decoding with minimal performance degradation on math reasoning benchmarks. Moreover, further analysis suggests that T* can converge to an alternative decoding schedule that achieves comparable performance.",
    "published": "2026-01-16T11:44:12Z",
    "updated": "2026-01-26T05:54:22Z",
    "link": "http://arxiv.org/pdf/2601.11214v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Hanchen Xia",
      "Baoyou Chen",
      "Yutang Ge",
      "Guojiang Zhao",
      "Siyu Zhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18162v1",
    "title": "Fine-Grained Emotion Detection on GoEmotions: Experimental Comparison of Classical Machine Learning, BiLSTM, and Transformer Models",
    "summary": "Fine-grained emotion recognition is a challenging multi-label NLP task due to label overlap and class imbalance. In this work, we benchmark three modeling families on the GoEmotions dataset: a TF-IDF-based logistic regression system trained with binary relevance, a BiLSTM with attention, and a BERT model fine-tuned for multi-label classification. Experiments follow the official train/validation/test split, and imbalance is mitigated using inverse-frequency class weights. Across several metrics, namely Micro-F1, Macro-F1, Hamming Loss, and Subset Accuracy, we observe that logistic regression attains the highest Micro-F1 of 0.51, while BERT achieves the best overall balance surpassing the official paper's reported results, reaching Macro-F1 0.49, Hamming Loss 0.036, and Subset Accuracy 0.36. This suggests that frequent emotions often rely on surface lexical cues, whereas contextual representations improve performance on rarer emotions and more ambiguous examples.",
    "published": "2026-01-26T05:29:27Z",
    "updated": "2026-01-26T05:29:27Z",
    "link": "http://arxiv.org/pdf/2601.18162v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Ani Harutyunyan",
      "Sachin Kumar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18150v1",
    "title": "FP8-RL: A Practical and Stable Low-Precision Stack for LLM Reinforcement Learning",
    "summary": "Reinforcement learning (RL) for large language models (LLMs) is increasingly bottlenecked by rollout (generation), where long output sequence lengths make attention and KV-cache memory dominate end-to-end step time. FP8 offers an attractive lever for accelerating RL by reducing compute cost and memory traffic during rollout, but applying FP8 in RL introduces unique engineering and algorithmic challenges: policy weights change every step (requiring repeated quantization and weight synchronization into the inference engine) and low-precision rollouts can deviate from the higher-precision policy assumed by the trainer, causing train-inference mismatch and potential instability. This report presents a practical FP8 rollout stack for LLM RL, implemented in the veRL ecosystem with support for common training backends (e.g., FSDP/Megatron-LM) and inference engines (e.g., vLLM/SGLang). We (i) enable FP8 W8A8 linear-layer rollout using blockwise FP8 quantization, (ii) extend FP8 to KV-cache to remove long-context memory bottlenecks via per-step QKV scale recalibration, and (iii) mitigate mismatch using importance-sampling-based rollout correction (token-level TIS/MIS variants). Across dense and MoE models, these techniques deliver up to 44% rollout throughput gains while preserving learning behavior comparable to BF16 baselines.",
    "published": "2026-01-26T05:12:05Z",
    "updated": "2026-01-26T05:12:05Z",
    "link": "http://arxiv.org/pdf/2601.18150v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Zhaopeng Qiu",
      "Shuang Yu",
      "Jingqi Zhang",
      "Shuai Zhang",
      "Xue Huang",
      "Jingyi Yang",
      "Junjie Lai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.15516v2",
    "title": "DeltaDorsal: Enhancing Hand Pose Estimation with Dorsal Features in Egocentric Views",
    "summary": "The proliferation of XR devices has made egocentric hand pose estimation a vital task, yet this perspective is inherently challenged by frequent finger occlusions. To address this, we propose a novel approach that leverages the rich information in dorsal hand skin deformation, unlocked by recent advances in dense visual featurizers. We introduce a dual-stream delta encoder that learns pose by contrasting features from a dynamic hand with a baseline relaxed position. Our evaluation demonstrates that, using only cropped dorsal images, our method reduces the Mean Per Joint Angle Error (MPJAE) by 18% in self-occluded scenarios (fingers >= 50% occluded) compared to state-of-the-art techniques that depend on the whole hand's geometry and large model backbones. Consequently, our method not only enhances the reliability of downstream tasks like index finger pinch and tap estimation in occluded scenarios but also unlocks new interaction paradigms, such as detecting isometric force for a surface \"click\" without visible movement while minimizing model size.",
    "published": "2026-01-21T23:00:43Z",
    "updated": "2026-01-26T18:45:41Z",
    "link": "http://arxiv.org/pdf/2601.15516v2.pdf",
    "category": [
      "cs.CV",
      "cs.HC",
      "cs.LG"
    ],
    "authors": [
      "William Huang",
      "Siyou Pei",
      "Leyi Zou",
      "Eric J. Gonzalez",
      "Ishan Chatterjee",
      "Yang Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.16984v2",
    "title": "HiCache: A Plug-in Scaled-Hermite Upgrade for Taylor-Style Cache-then-Forecast Diffusion Acceleration",
    "summary": "Diffusion models have achieved remarkable success in content generation but often incur prohibitive computational costs due to iterative sampling. Recent feature caching methods accelerate inference via temporal extrapolation, yet can suffer quality degradation from inaccurate modeling of the complex dynamics of feature evolution. We propose HiCache (Hermite Polynomial-based Feature Cache), a training-free acceleration framework that improves feature prediction by aligning mathematical tools with empirical properties. Our key insight is that feature-derivative approximations in diffusion Transformers exhibit multivariate Gaussian characteristics, motivating the use of Hermite polynomials as a potentially optimal basis for Gaussian-correlated processes. We further introduce a dual-scaling mechanism that ensures numerical stability while preserving predictive accuracy, and is also effective when applied standalone or integrated with TaylorSeer. Extensive experiments demonstrate HiCache's superiority, achieving 5.55x speedup on FLUX.1-dev while matching or exceeding baseline quality, and maintaining strong performance across text-to-image, video generation, and super-resolution tasks. Moreover, HiCache can be naturally added to previous caching methods to enhance their performance, e.g., improving ClusCa from 0.9480 to 0.9840 in terms of image rewards. Code: https://github.com/fenglang918/HiCache",
    "published": "2025-08-23T10:35:16Z",
    "updated": "2026-01-26T18:39:41Z",
    "link": "http://arxiv.org/pdf/2508.16984v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Liang Feng",
      "Shikang Zheng",
      "Jiacheng Liu",
      "Yuqi Lin",
      "Qinming Zhou",
      "Peiliang Cai",
      "Xinyu Wang",
      "Junjie Chen",
      "Chang Zou",
      "Yue Ma",
      "Linfeng Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.09828v3",
    "title": "DGFusion: Depth-Guided Sensor Fusion for Robust Semantic Perception",
    "summary": "Robust semantic perception for autonomous vehicles relies on effectively combining multiple sensors with complementary strengths and weaknesses. State-of-the-art sensor fusion approaches to semantic perception often treat sensor data uniformly across the spatial extent of the input, which hinders performance when faced with challenging conditions. By contrast, we propose a novel depth-guided multimodal fusion method that upgrades condition-aware fusion by integrating depth information. Our network, DGFusion, poses multimodal segmentation as a multi-task problem, utilizing the lidar measurements, which are typically available in outdoor sensor suites, both as one of the model's inputs and as ground truth for learning depth. Our corresponding auxiliary depth head helps to learn depth-aware features, which are encoded into spatially varying local depth tokens that condition our attentive cross-modal fusion. Together with a global condition token, these local depth tokens dynamically adapt sensor fusion to the spatially varying reliability of each sensor across the scene, which largely depends on depth. In addition, we propose a robust loss for our depth, which is essential for learning from lidar inputs that are typically sparse and noisy in adverse conditions. Our method achieves state-of-the-art panoptic and semantic segmentation performance on the challenging MUSES and DeLiVER datasets. Code and models are available at https://github.com/timbroed/DGFusion",
    "published": "2025-09-11T20:03:00Z",
    "updated": "2026-01-26T18:33:05Z",
    "link": "http://arxiv.org/pdf/2509.09828v3.pdf",
    "category": [
      "cs.CV",
      "cs.LG",
      "cs.RO"
    ],
    "authors": [
      "Tim Broedermannn",
      "Christos Sakaridis",
      "Luigi Piccinelli",
      "Wim Abbeloos",
      "Luc Van Gool"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.04084v2",
    "title": "When Swin Transformer Meets KANs: An Improved Transformer Architecture for Medical Image Segmentation",
    "summary": "Medical image segmentation is critical for accurate diagnostics and treatment planning, but remains challenging due to complex anatomical structures and limited annotated training data. CNN-based segmentation methods excel at local feature extraction, but struggle with modeling long-range dependencies. Transformers, on the other hand, capture global context more effectively, but are inherently data-hungry and computationally expensive. In this work, we introduce UKAST, a U-Net like architecture that integrates rational-function based Kolmogorov-Arnold Networks (KANs) into Swin Transformer encoders. By leveraging rational base functions and Group Rational KANs (GR-KANs) from the Kolmogorov-Arnold Transformer (KAT), our architecture addresses the inefficiencies of vanilla spline-based KANs, yielding a more expressive and data-efficient framework with reduced FLOPs and only a very small increase in parameter count compared to SwinUNETR. UKAST achieves state-of-the-art performance on four diverse 2D and 3D medical image segmentation benchmarks, consistently surpassing both CNN- and Transformer-based baselines. Notably, it attains superior accuracy in data-scarce settings, alleviating the data-hungry limitations of standard Vision Transformers. These results show the potential of KAN-enhanced Transformers to advance data-efficient medical image segmentation. Code is available at: https://github.com/nsapkota417/UKAST",
    "published": "2025-11-06T05:44:57Z",
    "updated": "2026-01-26T18:07:50Z",
    "link": "http://arxiv.org/pdf/2511.04084v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Nishchal Sapkota",
      "Haoyan Shi",
      "Yejia Zhang",
      "Xianshi Ma",
      "Bofang Zheng",
      "Fabian Vazquez",
      "Pengfei Gu",
      "Danny Z. Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.19328v4",
    "title": "BAH Dataset for Ambivalence/Hesitancy Recognition in Videos for Digital Behavioural Change",
    "summary": "Ambivalence and hesitancy (A/H), a closely related construct, is the primary reasons why individuals delay, avoid, or abandon health behaviour changes. It is a subtle and conflicting emotion that sets a person in a state between positive and negative orientations, or between acceptance and refusal to do something. It manifests by a discord in affect between multiple modalities or within a modality, such as facial and vocal expressions, and body language. Although experts can be trained to recognize A/H as done for in-person interactions, integrating them into digital health interventions is costly and less effective. Automatic A/H recognition is therefore critical for the personalization and cost-effectiveness of digital behaviour change interventions. However, no datasets currently exists for the design of machine learning models to recognize A/H. This paper introduces the Behavioural Ambivalence/Hesitancy (BAH) dataset collected for multimodal recognition of A/H in videos. It contains 1,427 videos with a total duration of 10.60 hours captured from 300 participants across Canada answering predefined questions to elicit A/H. It is intended to mirror real-world online personalized behaviour change interventions. BAH is annotated by three experts to provide timestamps that indicate where A/H occurs, and frame- and video-level annotations with A/H cues. Video transcripts, cropped and aligned faces, and participants' meta-data are also provided. Since A and H manifest similarly in practice, we provide a binary annotation indicating the presence or absence of A/H. Additionally, this paper includes benchmarking results using baseline models on BAH for frame- and video-level recognition, zero-shot prediction, and personalization using source-free domain adaptation. The data, code, and pretrained weights are available.",
    "published": "2025-05-25T21:29:00Z",
    "updated": "2026-01-26T18:01:53Z",
    "link": "http://arxiv.org/pdf/2505.19328v4.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Manuela González-González",
      "Soufiane Belharbi",
      "Muhammad Osama Zeeshan",
      "Masoumeh Sharafi",
      "Muhammad Haseeb Aslam",
      "Marco Pedersoli",
      "Alessandro Lameiras Koerich",
      "Simon L Bacon",
      "Eric Granger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.02831v5",
    "title": "No Other Representation Component Is Needed: Diffusion Transformers Can Provide Representation Guidance by Themselves",
    "summary": "Recent studies have demonstrated that learning a meaningful internal representation can accelerate generative training. However, existing approaches necessitate to either introduce an off-the-shelf external representation task or rely on a large-scale, pre-trained external representation encoder to provide representation guidance during the training process. In this study, we posit that the unique discriminative process inherent to diffusion transformers enables them to offer such guidance without requiring external representation components. We propose SelfRepresentation Alignment (SRA), a simple yet effective method that obtains representation guidance using the internal representations of learned diffusion transformer. SRA aligns the latent representation of the diffusion transformer in the earlier layer conditioned on higher noise to that in the later layer conditioned on lower noise to progressively enhance the overall representation learning during only the training process. Experimental results indicate that applying SRA to DiTs and SiTs yields consistent performance improvements, and largely outperforms approaches relying on auxiliary representation task. Our approach achieves performance comparable to methods that are dependent on an external pre-trained representation encoder, which demonstrates the feasibility of acceleration with representation alignment in diffusion transformers themselves.",
    "published": "2025-05-05T17:58:05Z",
    "updated": "2026-01-26T17:30:19Z",
    "link": "http://arxiv.org/pdf/2505.02831v5.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Dengyang Jiang",
      "Mengmeng Wang",
      "Liuzhuozheng Li",
      "Lei Zhang",
      "Haoyu Wang",
      "Wei Wei",
      "Guang Dai",
      "Yanning Zhang",
      "Jingdong Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18698v1",
    "title": "Are Video Generation Models Geographically Fair? An Attraction-Centric Evaluation of Global Visual Knowledge",
    "summary": "Recent advances in text-to-video generation have produced visually compelling results, yet it remains unclear whether these models encode geographically equitable visual knowledge. In this work, we investigate the geo-equity and geographically grounded visual knowledge of text-to-video models through an attraction-centric evaluation. We introduce Geo-Attraction Landmark Probing (GAP), a systematic framework for assessing how faithfully models synthesize tourist attractions from diverse regions, and construct GEOATTRACTION-500, a benchmark of 500 globally distributed attractions spanning varied regions and popularity levels. GAP integrates complementary metrics that disentangle overall video quality from attraction-specific knowledge, including global structural alignment, fine-grained keypoint-based alignment, and vision-language model judgments, all validated against human evaluation. Applying GAP to the state-of-the-art text-to-video model Sora 2, we find that, contrary to common assumptions of strong geographic bias, the model exhibits a relatively uniform level of geographically grounded visual knowledge across regions, development levels, and cultural groupings, with only weak dependence on attraction popularity. These results suggest that current text-to-video models express global visual knowledge more evenly than expected, highlighting both their promise for globally deployed applications and the need for continued evaluation as such systems evolve.",
    "published": "2026-01-26T17:14:57Z",
    "updated": "2026-01-26T17:14:57Z",
    "link": "http://arxiv.org/pdf/2601.18698v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xiao Liu",
      "Jiawei Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.26441v2",
    "title": "A-TPT: Angular Diversity Calibration Properties for Test-Time Prompt Tuning of Vision-Language Models",
    "summary": "Test-time prompt tuning (TPT) has emerged as a promising technique for adapting large vision-language models (VLMs) to unseen tasks without relying on labeled data. However, the lack of dispersion between textual features can hurt calibration performance, which raises concerns about VLMs' reliability, trustworthiness, and safety. Current TPT approaches primarily focus on improving prompt calibration by either maximizing average textual feature dispersion or enforcing orthogonality constraints to encourage angular separation. However, these methods may not always have optimal angular separation between class-wise textual features, which implies overlooking the critical role of angular diversity. To address this, we propose A-TPT, a novel TPT framework that introduces angular diversity to encourage uniformity in the distribution of normalized textual features induced by corresponding learnable prompts. This uniformity is achieved by maximizing the minimum pairwise angular distance between features on the unit hypersphere. We show that our approach consistently surpasses state-of-the-art TPT methods in reducing the aggregate average calibration error while maintaining comparable accuracy through extensive experiments with various backbones on different datasets. Notably, our approach exhibits superior zero-shot calibration performance on natural distribution shifts and generalizes well to medical datasets. We provide extensive analyses, including theoretical aspects, to establish the grounding of A-TPT. These results highlight the potency of promoting angular diversity to achieve well-dispersed textual features, significantly improving VLM calibration during test-time adaptation. Our code will be made publicly available.",
    "published": "2025-10-30T12:45:24Z",
    "updated": "2026-01-26T17:12:54Z",
    "link": "http://arxiv.org/pdf/2510.26441v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Shihab Aaqil Ahamed",
      "Udaya S. K. P. Miriya Thanthrige",
      "Ranga Rodrigo",
      "Muhammad Haris Khan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18692v1",
    "title": "A Pragmatic VLA Foundation Model",
    "summary": "Offering great potential in robotic manipulation, a capable Vision-Language-Action (VLA) foundation model is expected to faithfully generalize across tasks and platforms while ensuring cost efficiency (e.g., data and GPU hours required for adaptation). To this end, we develop LingBot-VLA with around 20,000 hours of real-world data from 9 popular dual-arm robot configurations. Through a systematic assessment on 3 robotic platforms, each completing 100 tasks with 130 post-training episodes per task, our model achieves clear superiority over competitors, showcasing its strong performance and broad generalizability. We have also built an efficient codebase, which delivers a throughput of 261 samples per second per GPU with an 8-GPU training setup, representing a 1.5~2.8$\\times$ (depending on the relied VLM base model) speedup over existing VLA-oriented codebases. The above features ensure that our model is well-suited for real-world deployment. To advance the field of robot learning, we provide open access to the code, base model, and benchmark data, with a focus on enabling more challenging tasks and promoting sound evaluation standards.",
    "published": "2026-01-26T17:08:04Z",
    "updated": "2026-01-26T17:08:04Z",
    "link": "http://arxiv.org/pdf/2601.18692v1.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Wei Wu",
      "Fan Lu",
      "Yunnan Wang",
      "Shuai Yang",
      "Shi Liu",
      "Fangjing Wang",
      "Qian Zhu",
      "He Sun",
      "Yong Wang",
      "Shuailei Ma",
      "Yiyu Ren",
      "Kejia Zhang",
      "Hui Yu",
      "Jingmei Zhao",
      "Shuai Zhou",
      "Zhenqi Qiu",
      "Houlong Xiong",
      "Ziyu Wang",
      "Zechen Wang",
      "Ran Cheng",
      "Yong-Lu Li",
      "Yongtao Huang",
      "Xing Zhu",
      "Yujun Shen",
      "Kecheng Zheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.07915v2",
    "title": "MARC: Memory-Augmented RL Token Compression for Efficient Video Understanding",
    "summary": "The rapid progress of large language models (LLMs) has laid the foundation for multimodal models. However, visual language models (VLMs) still face heavy computational costs when extended from images to videos due to high frame rates and long durations. Token compression is a promising solution, yet most existing training-free methods cause information loss and performance degradation. To overcome this, we propose \\textbf{Memory-Augmented Reinforcement Learning-based Token Compression (MARC)}, which integrates structured retrieval and RL-based distillation. MARC adopts a \\textit{retrieve-then-compress} strategy using a \\textbf{Visual Memory Retriever (VMR)} to select key clips and a \\textbf{Compression Group Relative Policy Optimization (C-GRPO)} framework to distil reasoning ability from a teacher to a student model. Experiments on six video benchmarks show that MARC achieves near-baseline accuracy using only one frame's tokens -- reducing visual tokens by \\textbf{95\\%}, GPU memory by \\textbf{72\\%}, and latency by \\textbf{23.9\\%}. This demonstrates its potential for efficient, real-time video understanding in resource-constrained settings such as video QA, surveillance, and autonomous driving.",
    "published": "2025-10-09T08:07:19Z",
    "updated": "2026-01-26T16:58:19Z",
    "link": "http://arxiv.org/pdf/2510.07915v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Peiran Wu",
      "Zhuorui Yu",
      "Yunze Liu",
      "Chi-Hao Wu",
      "Enmin Zhou",
      "Junxiao Shen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18678v1",
    "title": "Counterfactual Explanations on Robust Perceptual Geodesics",
    "summary": "Latent-space optimization methods for counterfactual explanations - framed as minimal semantic perturbations that change model predictions - inherit the ambiguity of Wachter et al.'s objective: the choice of distance metric dictates whether perturbations are meaningful or adversarial. Existing approaches adopt flat or misaligned geometries, leading to off-manifold artifacts, semantic drift, or adversarial collapse. We introduce Perceptual Counterfactual Geodesics (PCG), a method that constructs counterfactuals by tracing geodesics under a perceptually Riemannian metric induced from robust vision features. This geometry aligns with human perception and penalizes brittle directions, enabling smooth, on-manifold, semantically valid transitions. Experiments on three vision datasets show that PCG outperforms baselines and reveals failure modes hidden under standard metrics.",
    "published": "2026-01-26T16:52:54Z",
    "updated": "2026-01-26T16:52:54Z",
    "link": "http://arxiv.org/pdf/2601.18678v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV",
      "cs.HC",
      "math.DG"
    ],
    "authors": [
      "Eslam Zaher",
      "Maciej Trzaskowski",
      "Quan Nguyen",
      "Fred Roosta"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.02103v2",
    "title": "HeadLighter: Disentangling Illumination in Generative 3D Gaussian Heads via Lightstage Captures",
    "summary": "Recent 3D-aware head generative models based on 3D Gaussian Splatting achieve real-time, photorealistic and view-consistent head synthesis. However, a fundamental limitation persists: the deep entanglement of illumination and intrinsic appearance prevents controllable relighting. Existing disentanglement methods rely on strong assumptions to enable weakly supervised learning, which restricts their capacity for complex illumination. To address this challenge, we introduce HeadLighter, a novel supervised framework that learns a physically plausible decomposition of appearance and illumination in head generative models. Specifically, we design a dual-branch architecture that separately models lighting-invariant head attributes and physically grounded rendering components. A progressive disentanglement training is employed to gradually inject head appearance priors into the generative architecture, supervised by multi-view images captured under controlled light conditions with a light stage setup. We further introduce a distillation strategy to generate high-quality normals for realistic rendering. Experiments demonstrate that our method preserves high-quality generation and real-time rendering, while simultaneously supporting explicit lighting and viewpoint editing. We will publicly release our code and dataset.",
    "published": "2026-01-05T13:32:37Z",
    "updated": "2026-01-26T16:17:33Z",
    "link": "http://arxiv.org/pdf/2601.02103v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yating Wang",
      "Yuan Sun",
      "Xuan Wang",
      "Ran Yi",
      "Boyao Zhou",
      "Yipengjing Sun",
      "Hongyu Liu",
      "Yinuo Wang",
      "Lizhuang Ma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.05742v3",
    "title": "Whole Slide Concepts: A Supervised Foundation Model For Pathological Images",
    "summary": "Foundation models (FMs) are transforming computational pathology by offering new ways to analyze histopathology images. However, FMs typically require weeks of training on large databases, making their creation a resource-intensive process. In this paper, we present a training for foundation models from whole slide images using supervised, end-to-end, multitask learning on slide-level labels. Notably, it is the first model to incorporate cancer subtyping, risk estimation, and genetic mutation prediction into one model. The presented model outperforms self-supervised models on seven benchmark tasks while the training only required 5% of the computational resources. The results not only show that supervised training can outperform self-supervision with less data, but also offer a solution to annotation problems, as patient-based labels are widely available through routine clinical processes. Furthermore, an attention module provides a layer of explainability across different tasks and serves as a tumor detector for unseen cancer types. To address the issue of closed-source datasets, the model was fully trained on openly available data. The code and model weights are made available under https://github.com/FraunhoferMEVIS/MedicalMultitaskModeling.",
    "published": "2025-07-08T07:42:12Z",
    "updated": "2026-01-26T16:08:57Z",
    "link": "http://arxiv.org/pdf/2507.05742v3.pdf",
    "category": [
      "eess.IV",
      "cs.CV"
    ],
    "authors": [
      "Till Nicke",
      "Daniela Schacherer",
      "Jan Raphael Schäfer",
      "Natalia Artysh",
      "Antje Prasse",
      "André Homeyer",
      "Andrea Schenk",
      "Henning Höfener",
      "Johannes Lotz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18633v1",
    "title": "Splat-Portrait: Generalizing Talking Heads with Gaussian Splatting",
    "summary": "Talking Head Generation aims at synthesizing natural-looking talking videos from speech and a single portrait image. Previous 3D talking head generation methods have relied on domain-specific heuristics such as warping-based facial motion representation priors to animate talking motions, yet still produce inaccurate 3D avatar reconstructions, thus undermining the realism of generated animations. We introduce Splat-Portrait, a Gaussian-splatting-based method that addresses the challenges of 3D head reconstruction and lip motion synthesis. Our approach automatically learns to disentangle a single portrait image into a static 3D reconstruction represented as static Gaussian Splatting, and a predicted whole-image 2D background. It then generates natural lip motion conditioned on input audio, without any motion driven priors. Training is driven purely by 2D reconstruction and score-distillation losses, without 3D supervision nor landmarks. Experimental results demonstrate that Splat-Portrait exhibits superior performance on talking head generation and novel view synthesis, achieving better visual quality compared to previous works. Our project code and supplementary documents are public available at https://github.com/stonewalking/Splat-portrait.",
    "published": "2026-01-26T16:06:57Z",
    "updated": "2026-01-26T16:06:57Z",
    "link": "http://arxiv.org/pdf/2601.18633v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Tong Shi",
      "Melonie de Almeida",
      "Daniela Ivanova",
      "Nicolas Pugeault",
      "Paul Henderson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.18663v3",
    "title": "DVD-Quant: Data-free Video Diffusion Transformers Quantization",
    "summary": "Diffusion Transformers (DiTs) have emerged as the state-of-the-art architecture for video generation, yet their computational and memory demands hinder practical deployment. While post-training quantization (PTQ) presents a promising approach to accelerate Video DiT models, existing methods suffer from two critical limitations: (1) dependence on computation-heavy and inflexible calibration procedures, and (2) considerable performance deterioration after quantization. To address these challenges, we propose DVD-Quant, a novel Data-free quantization framework for Video DiTs. Our approach integrates three key innovations: (1) Bounded-init Grid Refinement (BGR) and (2) Auto-scaling Rotated Quantization (ARQ) for calibration data-free quantization error reduction, as well as (3) $δ$-Guided Bit Switching ($δ$-GBS) for adaptive bit-width allocation. Extensive experiments across multiple video generation benchmarks demonstrate that DVD-Quant achieves an approximately 2$\\times$ speedup over full-precision baselines on advanced DiT models while maintaining visual fidelity. Notably, DVD-Quant is the first to enable W4A4 PTQ for Video DiTs without compromising video quality. Code and models will be available at https://github.com/lhxcs/DVD-Quant.",
    "published": "2025-05-24T11:56:02Z",
    "updated": "2026-01-26T16:04:47Z",
    "link": "http://arxiv.org/pdf/2505.18663v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhiteng Li",
      "Hanxuan Li",
      "Junyi Wu",
      "Kai Liu",
      "Haotong Qin",
      "Linghe Kong",
      "Guihai Chen",
      "Yulun Zhang",
      "Xiaokang Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18625v1",
    "title": "CONQUER: Context-Aware Representation with Query Enhancement for Text-Based Person Search",
    "summary": "Text-Based Person Search (TBPS) aims to retrieve pedestrian images from large galleries using natural language descriptions. This task, essential for public safety applications, is hindered by cross-modal discrepancies and ambiguous user queries. We introduce CONQUER, a two-stage framework designed to address these challenges by enhancing cross-modal alignment during training and adaptively refining queries at inference. During training, CONQUER employs multi-granularity encoding, complementary pair mining, and context-guided optimal matching based on Optimal Transport to learn robust embeddings. At inference, a plug-and-play query enhancement module refines vague or incomplete queries via anchor selection and attribute-driven enrichment, without requiring retraining of the backbone. Extensive experiments on CUHK-PEDES, ICFG-PEDES, and RSTPReid demonstrate that CONQUER consistently outperforms strong baselines in both Rank-1 accuracy and mAP, yielding notable improvements in cross-domain and incomplete-query scenarios. These results highlight CONQUER as a practical and effective solution for real-world TBPS deployment. Source code is available at https://github.com/zqxie77/CONQUER.",
    "published": "2026-01-26T16:01:33Z",
    "updated": "2026-01-26T16:01:33Z",
    "link": "http://arxiv.org/pdf/2601.18625v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zequn Xie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18623v1",
    "title": "Adaptive Domain Shift in Diffusion Models for Cross-Modality Image Translation",
    "summary": "Cross-modal image translation remains brittle and inefficient. Standard diffusion approaches often rely on a single, global linear transfer between domains. We find that this shortcut forces the sampler to traverse off-manifold, high-cost regions, inflating the correction burden and inviting semantic drift. We refer to this shared failure mode as fixed-schedule domain transfer. In this paper, we embed domain-shift dynamics directly into the generative process. Our model predicts a spatially varying mixing field at every reverse step and injects an explicit, target-consistent restoration term into the drift. This in-step guidance keeps large updates on-manifold and shifts the model's role from global alignment to local residual correction. We provide a continuous-time formulation with an exact solution form and derive a practical first-order sampler that preserves marginal consistency. Empirically, across translation tasks in medical imaging, remote sensing, and electroluminescence semantic mapping, our framework improves structural fidelity and semantic consistency while converging in fewer denoising steps.",
    "published": "2026-01-26T16:00:36Z",
    "updated": "2026-01-26T16:00:36Z",
    "link": "http://arxiv.org/pdf/2601.18623v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zihao Wang",
      "Yuzhou Chen",
      "Shaogang Ren"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18619v1",
    "title": "Scale-Aware Self-Supervised Learning for Segmentation of Small and Sparse Structures",
    "summary": "Self-supervised learning (SSL) has emerged as a powerful strategy for representation learning under limited annotation regimes, yet its effectiveness remains highly sensitive to many factors, especially the nature of the target task. In segmentation, existing pipelines are typically tuned to large, homogeneous regions, but their performance drops when objects are small, sparse, or locally irregular. In this work, we propose a scale-aware SSL adaptation that integrates small-window cropping into the augmentation pipeline, zooming in on fine-scale structures during pretraining. We evaluate this approach across two domains with markedly different data modalities: seismic imaging, where the goal is to segment sparse faults, and neuroimaging, where the task is to delineate small cellular structures. In both settings, our method yields consistent improvements over standard and state-of-the-art baselines under label constraints, improving accuracy by up to 13% for fault segmentation and 5% for cell delineation. In contrast, large-scale features such as seismic facies or tissue regions see little benefit, underscoring that the value of SSL depends critically on the scale of the target objects. Our findings highlight the need to align SSL design with object size and sparsity, offering a general principle for buil ding more effective representation learning pipelines across scientific imaging domains.",
    "published": "2026-01-26T15:58:04Z",
    "updated": "2026-01-26T15:58:04Z",
    "link": "http://arxiv.org/pdf/2601.18619v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jorge Quesada",
      "Ghassan AlRegib"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18612v1",
    "title": "Multimodal Privacy-Preserving Entity Resolution with Fully Homomorphic Encryption",
    "summary": "The canonical challenge of entity resolution within high-compliance sectors, where secure identity reconciliation is frequently confounded by significant data heterogeneity, including syntactic variations in personal identifiers, is a longstanding and complex problem. To this end, we introduce a novel multimodal framework operating with the voluminous data sets typical of government and financial institutions. Specifically, our methodology is designed to address the tripartite challenge of data volume, matching fidelity, and privacy. Consequently, the underlying plaintext of personally identifiable information remains computationally inaccessible throughout the matching lifecycle, empowering institutions to rigorously satisfy stringent regulatory mandates with cryptographic assurances of client confidentiality while achieving a demonstrably low equal error rate and maintaining computational tractability at scale.",
    "published": "2026-01-26T15:53:04Z",
    "updated": "2026-01-26T15:53:04Z",
    "link": "http://arxiv.org/pdf/2601.18612v1.pdf",
    "category": [
      "cs.CR",
      "cs.CV"
    ],
    "authors": [
      "Susim Roy",
      "Nalini Ratha"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.04058v2",
    "title": "SMooGPT: Stylized Motion Generation using Large Language Models",
    "summary": "Stylized motion generation is actively studied in computer graphics, especially benefiting from the rapid advances in diffusion models. The goal of this task is to produce a novel motion respecting both the motion content and the desired motion style, e.g., ``walking in a loop like a Monkey''. Existing research attempts to address this problem via motion style transfer or conditional motion generation. They typically embed the motion style into a latent space and guide the motion implicitly in a latent space as well. Despite the progress, their methods suffer from low interpretability and control, limited generalization to new styles, and fail to produce motions other than ``walking'' due to the strong bias in the public stylization dataset. In this paper, we propose to solve the stylized motion generation problem from a new perspective of reasoning-composition-generation, based on our observations: i) human motion can often be effectively described using natural language in a body-part centric manner, ii) LLMs exhibit a strong ability to understand and reason about human motion, and iii) human motion has an inherently compositional nature, facilitating the new motion content or style generation via effective recomposing. We thus propose utilizing body-part text space as an intermediate representation, and present SMooGPT, a fine-tuned LLM, acting as a reasoner, composer, and generator when generating the desired stylized motion. Our method executes in the body-part text space with much higher interpretability, enabling fine-grained motion control, effectively resolving potential conflicts between motion content and style, and generalizes well to new styles thanks to the open-vocabulary ability of LLMs. Comprehensive experiments and evaluations, and a user perceptual study, demonstrate the effectiveness of our approach, especially under the pure text-driven stylized motion generation.",
    "published": "2025-09-04T09:41:18Z",
    "updated": "2026-01-26T15:51:20Z",
    "link": "http://arxiv.org/pdf/2509.04058v2.pdf",
    "category": [
      "cs.GR",
      "cs.CV"
    ],
    "authors": [
      "Lei Zhong",
      "Yi Yang",
      "Changjian Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18597v1",
    "title": "EFSI-DETR: Efficient Frequency-Semantic Integration for Real-Time Small Object Detection in UAV Imagery",
    "summary": "Real-time small object detection in Unmanned Aerial Vehicle (UAV) imagery remains challenging due to limited feature representation and ineffective multi-scale fusion. Existing methods underutilize frequency information and rely on static convolutional operations, which constrain the capacity to obtain rich feature representations and hinder the effective exploitation of deep semantic features. To address these issues, we propose EFSI-DETR, a novel detection framework that integrates efficient semantic feature enhancement with dynamic frequency-spatial guidance. EFSI-DETR comprises two main components: (1) a Dynamic Frequency-Spatial Unified Synergy Network (DyFusNet) that jointly exploits frequency and spatial cues for robust multi-scale feature fusion, (2) an Efficient Semantic Feature Concentrator (ESFC) that enables deep semantic extraction with minimal computational cost. Furthermore, a Fine-grained Feature Retention (FFR) strategy is adopted to incorporate spatially rich shallow features during fusion to preserve fine-grained details, crucial for small object detection in UAV imagery. Extensive experiments on VisDrone and CODrone benchmarks demonstrate that our EFSI-DETR achieves the state-of-the-art performance with real-time efficiency, yielding improvement of \\textbf{1.6}\\% and \\textbf{5.8}\\% in AP and AP$_{s}$ on VisDrone, while obtaining \\textbf{188} FPS inference speed on a single RTX 4090 GPU.",
    "published": "2026-01-26T15:41:37Z",
    "updated": "2026-01-26T15:41:37Z",
    "link": "http://arxiv.org/pdf/2601.18597v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yu Xia",
      "Chang Liu",
      "Tianqi Xiang",
      "Zhigang Tu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18589v1",
    "title": "AGSP-DSA: An Adaptive Graph Signal Processing Framework for Robust Multimodal Fusion with Dynamic Semantic Alignment",
    "summary": "In this paper, we introduce an Adaptive Graph Signal Processing with Dynamic Semantic Alignment (AGSP DSA) framework to perform robust multimodal data fusion over heterogeneous sources, including text, audio, and images. The requested approach uses a dual-graph construction to learn both intra-modal and inter-modal relations, spectral graph filtering to boost the informative signals, and effective node embedding with Multi-scale Graph Convolutional Networks (GCNs). Semantic aware attention mechanism: each modality may dynamically contribute to the context with respect to contextual relevance. The experimental outcomes on three benchmark datasets, including CMU-MOSEI, AVE, and MM-IMDB, show that AGSP-DSA performs as the state of the art. More precisely, it achieves 95.3% accuracy, 0.936 F1-score, and 0.924 mAP on CMU-MOSEI, improving MM-GNN by 2.6 percent in accuracy. It gets 93.4% accuracy and 0.911 F1-score on AVE and 91.8% accuracy and 0.886 F1-score on MM-IMDB, which demonstrate good generalization and robustness in the missing modality setting. These findings verify the efficiency of AGSP-DSA in promoting multimodal learning in sentiment analysis, event recognition and multimedia classification.",
    "published": "2026-01-26T15:35:03Z",
    "updated": "2026-01-26T15:35:03Z",
    "link": "http://arxiv.org/pdf/2601.18589v1.pdf",
    "category": [
      "cs.CV",
      "cs.MM"
    ],
    "authors": [
      "KV Karthikeya",
      "Ashok Kumar Das",
      "Shantanu Pal",
      "Vivekananda Bhat K",
      "Arun Sekar Rajasekaran"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18585v1",
    "title": "GimmBO: Interactive Generative Image Model Merging via Bayesian Optimization",
    "summary": "Fine-tuning-based adaptation is widely used to customize diffusion-based image generation, leading to large collections of community-created adapters that capture diverse subjects and styles. Adapters derived from the same base model can be merged with weights, enabling the synthesis of new visual results within a vast and continuous design space. To explore this space, current workflows rely on manual slider-based tuning, an approach that scales poorly and makes weight selection difficult, even when the candidate set is limited to 20-30 adapters. We propose GimmBO to support interactive exploration of adapter merging for image generation through Preferential Bayesian Optimization (PBO). Motivated by observations from real-world usage, including sparsity and constrained weight ranges, we introduce a two-stage BO backend that improves sampling efficiency and convergence in high-dimensional spaces. We evaluate our approach with simulated users and a user study, demonstrating improved convergence, high success rates, and consistent gains over BO and line-search baselines, and further show the flexibility of the framework through several extensions.",
    "published": "2026-01-26T15:32:16Z",
    "updated": "2026-01-26T15:32:16Z",
    "link": "http://arxiv.org/pdf/2601.18585v1.pdf",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "Chenxi Liu",
      "Selena Ling",
      "Alec Jacobson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18577v1",
    "title": "Self-Refining Video Sampling",
    "summary": "Modern video generators still struggle with complex physical dynamics, often falling short of physical realism. Existing approaches address this using external verifiers or additional training on augmented data, which is computationally expensive and still limited in capturing fine-grained motion. In this work, we present self-refining video sampling, a simple method that uses a pre-trained video generator trained on large-scale datasets as its own self-refiner. By interpreting the generator as a denoising autoencoder, we enable iterative inner-loop refinement at inference time without any external verifier or additional training. We further introduce an uncertainty-aware refinement strategy that selectively refines regions based on self-consistency, which prevents artifacts caused by over-refinement. Experiments on state-of-the-art video generators demonstrate significant improvements in motion coherence and physics alignment, achieving over 70\\% human preference compared to the default sampler and guidance-based sampler.",
    "published": "2026-01-26T15:22:27Z",
    "updated": "2026-01-26T15:22:27Z",
    "link": "http://arxiv.org/pdf/2601.18577v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Sangwon Jang",
      "Taekyung Ki",
      "Jaehyeong Jo",
      "Saining Xie",
      "Jaehong Yoon",
      "Sung Ju Hwang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18564v1",
    "title": "An Unsupervised Tensor-Based Domain Alignment",
    "summary": "We propose a tensor-based domain alignment (DA) algorithm designed to align source and target tensors within an invariant subspace through the use of alignment matrices. These matrices along with the subspace undergo iterative optimization of which constraint is on oblique manifold, which offers greater flexibility and adaptability compared to the traditional Stiefel manifold. Moreover, regularization terms defined to preserve the variance of both source and target tensors, ensures robust performance. Our framework is versatile, effectively generalizing existing tensor-based DA methods as special cases. Through extensive experiments, we demonstrate that our approach not only enhances DA conversion speed but also significantly boosts classification accuracy. This positions our method as superior to current state-of-the-art techniques, making it a preferable choice for complex domain adaptation tasks.",
    "published": "2026-01-26T15:11:12Z",
    "updated": "2026-01-26T15:11:12Z",
    "link": "http://arxiv.org/pdf/2601.18564v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV",
      "eess.SP"
    ],
    "authors": [
      "Chong Hyun Lee",
      "Kibae Lee",
      "Hyun Hee Yim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18560v1",
    "title": "AI-enabled Satellite Edge Computing: A Single-Pixel Feature based Shallow Classification Model for Hyperspectral Imaging",
    "summary": "As the important component of the Earth observation system, hyperspectral imaging satellites provide high-fidelity and enriched information for the formulation of related policies due to the powerful spectral measurement capabilities. However, the transmission speed of the satellite downlink has become a major bottleneck in certain applications, such as disaster monitoring and emergency mapping, which demand a fast response ability. We propose an efficient AI-enabled Satellite Edge Computing paradigm for hyperspectral image classification, facilitating the satellites to attain autonomous decision-making. To accommodate the resource constraints of satellite platforms, the proposed method adopts a lightweight, non-deep learning framework integrated with a few-shot learning strategy. Moreover, onboard processing on satellites could be faced with sensor failure and scan pattern errors, which result in degraded image quality with bad/misaligned pixels and mixed noise. To address these challenges, we develop a novel two-stage pixel-wise label propagation scheme that utilizes only intrinsic spectral features at the single pixel level without the necessity to consider spatial structural information as requested by deep neural networks. In the first stage, initial pixel labels are obtained by propagating selected anchor labels through the constructed anchor-pixel affinity matrix. Subsequently, a top-k pruned sparse graph is generated by directly computing pixel-level similarities. In the second stage, a closed-form solution derived from the sparse graph is employed to replace iterative computations. Furthermore, we developed a rank constraint-based graph clustering algorithm to determine the anchor labels.",
    "published": "2026-01-26T15:07:31Z",
    "updated": "2026-01-26T15:07:31Z",
    "link": "http://arxiv.org/pdf/2601.18560v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Li Fang",
      "Tianyu Li",
      "Yanghong Lin",
      "Shudong Zhou",
      "Wei Yao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18556v1",
    "title": "Generative Diffusion Augmentation with Quantum-Enhanced Discrimination for Medical Image Diagnosis",
    "summary": "In biomedical engineering, artificial intelligence has become a pivotal tool for enhancing medical diagnostics, particularly in medical image classification tasks such as detecting pneumonia from chest X-rays and breast cancer screening. However, real-world medical datasets frequently exhibit severe class imbalance, where positive samples substantially outnumber negative samples, leading to biased models with low recall rates for minority classes. This imbalance not only compromises diagnostic accuracy but also poses clinical misdiagnosis risks. To address this challenge, we propose SDA-QEC (Simplified Diffusion Augmentation with Quantum-Enhanced Classification), an innovative framework that integrates simplified diffusion-based data augmentation with quantum-enhanced feature discrimination. Our approach employs a lightweight diffusion augmentor to generate high-quality synthetic samples for minority classes, rebalancing the training distribution. Subsequently, a quantum feature layer embedded within MobileNetV2 architecture enhances the model's discriminative capability through high-dimensional feature mapping in Hilbert space. Comprehensive experiments on coronary angiography image classification demonstrate that SDA-QEC achieves 98.33% accuracy, 98.78% AUC, and 98.33% F1-score, significantly outperforming classical baselines including ResNet18, MobileNetV2, DenseNet121, and VGG16. Notably, our framework simultaneously attains 98.33% sensitivity and 98.33% specificity, achieving a balanced performance critical for clinical deployment. The proposed method validates the feasibility of integrating generative augmentation with quantum-enhanced modeling in real-world medical imaging tasks, offering a novel research pathway for developing highly reliable medical AI systems in small-sample, highly imbalanced, and high-risk diagnostic scenarios.",
    "published": "2026-01-26T15:05:19Z",
    "updated": "2026-01-26T15:05:19Z",
    "link": "http://arxiv.org/pdf/2601.18556v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Jingsong Xia",
      "Siqi Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18555v1",
    "title": "Automated Landmark Detection for assessing hip conditions: A Cross-Modality Validation of MRI versus X-ray",
    "summary": "Many clinical screening decisions are based on angle measurements. In particular, FemoroAcetabular Impingement (FAI) screening relies on angles traditionally measured on X-rays. However, assessing the height and span of the impingement area requires also a 3D view through an MRI scan. The two modalities inform the surgeon on different aspects of the condition. In this work, we conduct a matched-cohort validation study (89 patients, paired MRI/X-ray) using standard heatmap regression architectures to assess cross-modality clinical equivalence. Seen that landmark detection has been proven effective on X-rays, we show that MRI also achieves equivalent localisation and diagnostic accuracy for cam-type impingement. Our method demonstrates clinical feasibility for FAI assessment in coronal views of 3D MRI volumes, opening the possibility for volumetric analysis through placing further landmarks. These results support integrating automated FAI assessment into routine MRI workflows. Code is released at https://github.com/Malga-Vision/Landmarks-Hip-Conditions",
    "published": "2026-01-26T15:04:21Z",
    "updated": "2026-01-26T15:04:21Z",
    "link": "http://arxiv.org/pdf/2601.18555v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Roberto Di Via",
      "Vito Paolo Pastore",
      "Francesca Odone",
      "Siôn Glyn-Jones",
      "Irina Voiculescu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18547v1",
    "title": "REMAC: Reference-Based Martian Asymmetrical Image Compression",
    "summary": "To expedite space exploration on Mars, it is indispensable to develop an efficient Martian image compression method for transmitting images through the constrained Mars-to-Earth communication channel. Although the existing learned compression methods have achieved promising results for natural images from earth, there remain two critical issues that hinder their effectiveness for Martian image compression: 1) They overlook the highly-limited computational resources on Mars; 2) They do not utilize the strong \\textit{inter-image} similarities across Martian images to advance image compression performance. Motivated by our empirical analysis of the strong \\textit{intra-} and \\textit{inter-image} similarities from the perspective of texture, color, and semantics, we propose a reference-based Martian asymmetrical image compression (REMAC) approach, which shifts computational complexity from the encoder to the resource-rich decoder and simultaneously improves compression performance. To leverage \\textit{inter-image} similarities, we propose a reference-guided entropy module and a ref-decoder that utilize useful information from reference images, reducing redundant operations at the encoder and achieving superior compression performance. To exploit \\textit{intra-image} similarities, the ref-decoder adopts a deep, multi-scale architecture with enlarged receptive field size to model long-range spatial dependencies. Additionally, we develop a latent feature recycling mechanism to further alleviate the extreme computational constraints on Mars. Experimental results show that REMAC reduces encoder complexity by 43.51\\% compared to the state-of-the-art method, while achieving a BD-PSNR gain of 0.2664 dB.",
    "published": "2026-01-26T14:55:17Z",
    "updated": "2026-01-26T14:55:17Z",
    "link": "http://arxiv.org/pdf/2601.18547v1.pdf",
    "category": [
      "cs.CV",
      "cs.MM"
    ],
    "authors": [
      "Qing Ding",
      "Mai Xu",
      "Shengxi Li",
      "Xin Deng",
      "Xin Zou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.05270v4",
    "title": "CLIP's Visual Embedding Projector is a Few-shot Cornucopia",
    "summary": "We introduce ProLIP, a simple and architecture-agnostic method for adapting contrastively pretrained vision-language models, such as CLIP, to few-shot classification. ProLIP fine-tunes the vision encoder's projection matrix with Frobenius norm regularization on its deviation from the pretrained weights. It achieves state-of-the-art performance on 11 few-shot classification benchmarks under both ``few-shot validation'' and ``validation-free'' settings. Moreover, by rethinking the non-linear CLIP-Adapter through ProLIP's lens, we design a Regularized Linear Adapter (RLA) that performs better, requires no hyperparameter tuning, is less sensitive to learning rate values, and offers an alternative to ProLIP in black-box scenarios where model weights are inaccessible. Beyond few-shot classification, ProLIP excels in cross-dataset transfer, domain generalization, base-to-new class generalization, and test-time adaptation--where it outperforms prompt tuning while being an order of magnitude faster to train. Code is available at https://github.com/astra-vision/ProLIP .",
    "published": "2024-10-07T17:59:59Z",
    "updated": "2026-01-26T14:50:34Z",
    "link": "http://arxiv.org/pdf/2410.05270v4.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Mohammad Fahes",
      "Tuan-Hung Vu",
      "Andrei Bursuc",
      "Patrick Pérez",
      "Raoul de Charette"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18543v1",
    "title": "GenAgent: Scaling Text-to-Image Generation via Agentic Multimodal Reasoning",
    "summary": "We introduce GenAgent, unifying visual understanding and generation through an agentic multimodal model. Unlike unified models that face expensive training costs and understanding-generation trade-offs, GenAgent decouples these capabilities through an agentic framework: understanding is handled by the multimodal model itself, while generation is achieved by treating image generation models as invokable tools. Crucially, unlike existing modular systems constrained by static pipelines, this design enables autonomous multi-turn interactions where the agent generates multimodal chains-of-thought encompassing reasoning, tool invocation, judgment, and reflection to iteratively refine outputs. We employ a two-stage training strategy: first, cold-start with supervised fine-tuning on high-quality tool invocation and reflection data to bootstrap agent behaviors; second, end-to-end agentic reinforcement learning combining pointwise rewards (final image quality) and pairwise rewards (reflection accuracy), with trajectory resampling for enhanced multi-turn exploration. GenAgent significantly boosts base generator(FLUX.1-dev) performance on GenEval++ (+23.6\\%) and WISE (+14\\%). Beyond performance gains, our framework demonstrates three key properties: 1) cross-tool generalization to generators with varying capabilities, 2) test-time scaling with consistent improvements across interaction rounds, and 3) task-adaptive reasoning that automatically adjusts to different tasks. Our code will be available at \\href{https://github.com/deep-kaixun/GenAgent}{this url}.",
    "published": "2026-01-26T14:49:04Z",
    "updated": "2026-01-26T14:49:04Z",
    "link": "http://arxiv.org/pdf/2601.18543v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Kaixun Jiang",
      "Yuzheng Wang",
      "Junjie Zhou",
      "Pandeng Li",
      "Zhihang Liu",
      "Chen-Wei Xie",
      "Zhaoyu Chen",
      "Yun Zheng",
      "Wenqiang Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18532v1",
    "title": "From Cold Start to Active Learning: Embedding-Based Scan Selection for Medical Image Segmentation",
    "summary": "Accurate segmentation annotations are critical for disease monitoring, yet manual labeling remains a major bottleneck due to the time and expertise required. Active learning (AL) alleviates this burden by prioritizing informative samples for annotation, typically through a diversity-based cold-start phase followed by uncertainty-driven selection. We propose a novel cold-start sampling strategy that combines foundation-model embeddings with clustering, including automatic selection of the number of clusters and proportional sampling across clusters, to construct a diverse and representative initial training. This is followed by an uncertainty-based AL framework that integrates spatial diversity to guide sample selection. The proposed method is intuitive and interpretable, enabling visualization of the feature-space distribution of candidate samples. We evaluate our approach on three datasets spanning X-ray and MRI modalities. On the CheXmask dataset, the cold-start strategy outperforms random selection, improving Dice from 0.918 to 0.929 and reducing the Hausdorff distance from 32.41 to 27.66 mm. In the AL setting, combined entropy and diversity selection improves Dice from 0.919 to 0.939 and reduces the Hausdorff distance from 30.10 to 19.16 mm. On the Montgomery dataset, cold-start gains are substantial, with Dice improving from 0.928 to 0.950 and Hausdorff distance decreasing from 14.22 to 9.38 mm. On the SynthStrip dataset, cold-start selection slightly affects Dice but reduces the Hausdorff distance from 9.43 to 8.69 mm, while active learning improves Dice from 0.816 to 0.826 and reduces the Hausdorff distance from 7.76 to 6.38 mm. Overall, the proposed framework consistently outperforms baseline methods in low-data regimes, improving segmentation accuracy.",
    "published": "2026-01-26T14:39:03Z",
    "updated": "2026-01-26T14:39:03Z",
    "link": "http://arxiv.org/pdf/2601.18532v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Devon Levy",
      "Bar Assayag",
      "Laura Gaspar",
      "Ilan Shimshoni",
      "Bella Specktor-Fadida"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18525v1",
    "title": "Closing the Modality Gap Aligns Group-Wise Semantics",
    "summary": "In multimodal learning, CLIP has been recognized as the \\textit{de facto} method for learning a shared latent space across multiple modalities, placing similar representations close to each other and moving them away from dissimilar ones. Although CLIP-based losses effectively align modalities at the semantic level, the resulting latent spaces often remain only partially shared, revealing a structural mismatch known as the modality gap. While the necessity of addressing this phenomenon remains debated, particularly given its limited impact on instance-wise tasks (e.g., retrieval), we prove that its influence is instead strongly pronounced in group-level tasks (e.g., clustering). To support this claim, we introduce a novel method designed to consistently reduce this discrepancy in two-modal settings, with a straightforward extension to the general $n$-modal case. Through our extensive evaluation, we demonstrate our novel insight: while reducing the gap provides only marginal or inconsistent improvements in traditional instance-wise tasks, it significantly enhances group-wise tasks. These findings may reshape our understanding of the modality gap, highlighting its key role in improving performance on tasks requiring semantic grouping.",
    "published": "2026-01-26T14:36:04Z",
    "updated": "2026-01-26T14:36:04Z",
    "link": "http://arxiv.org/pdf/2601.18525v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Eleonora Grassucci",
      "Giordano Cicchetti",
      "Emanuele Frasca",
      "Aurelio Uncini",
      "Danilo Comminiello"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.24386v2",
    "title": "PCICF: A Pedestrian Crossing Identification and Classification Framework",
    "summary": "We have recently observed the commercial roll-out of robotaxis in various countries. They are deployed within an operational design domain (ODD) on specific routes and environmental conditions, and are subject to continuous monitoring to regain control in safety-critical situations. Since ODDs typically cover urban areas, robotaxis must reliably detect vulnerable road users (VRUs) such as pedestrians, bicyclists, or e-scooter riders. To better handle such varied traffic situations, end-to-end AI, which directly compute vehicle control actions from multi-modal sensor data instead of only for perception, is on the rise. High quality data is needed for systematically training and evaluating such systems within their OOD. In this work, we propose PCICF, a framework to systematically identify and classify VRU situations to support ODD's incident analysis. We base our work on the existing synthetic dataset SMIRK, and enhance it by extending its single-pedestrian-only design into the MoreSMIRK dataset, a structured dictionary of multi-pedestrian crossing situations constructed systematically. We then use space-filling curves (SFCs) to transform multi-dimensional features of scenarios into characteristic patterns, which we match with corresponding entries in MoreSMIRK. We evaluate PCICF with the large real-world dataset PIE, which contains more than 150 manually annotated pedestrian crossing videos. We show that PCICF can successfully identify and classify complex pedestrian crossings, even when groups of pedestrians merge or split. By leveraging computationally efficient components like SFCs, PCICF has even potential to be used onboard of robotaxis for OOD detection for example. We share an open-source replication package for PCICF containing its algorithms, the complete MoreSMIRK dataset and dictionary, as well as our experiment results presented in: https://github.com/Claud1234/PCICF",
    "published": "2025-09-29T07:35:12Z",
    "updated": "2026-01-26T14:32:36Z",
    "link": "http://arxiv.org/pdf/2509.24386v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Junyi Gu",
      "Beatriz Cabrero-Daniel",
      "Ali Nouri",
      "Lydia Armini",
      "Christian Berger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.20355v2",
    "title": "Practical insights on the effect of different encodings, ansätze and measurements in quantum and hybrid convolutional neural networks",
    "summary": "This study investigates the design choices of parameterized quantum circuits (PQCs) within quantum and hybrid convolutional neural network (HQNN and QCNN) architectures, applied to the task of satellite image classification using the EuroSAT dataset. We systematically evaluate the performance implications of data encoding techniques, variational ansätze, and measurement in approx. 500 distinct model configurations. Our analysis reveals a clear hierarchy of influence on model performance. For hybrid architectures, which were benchmarked against their direct classical equivalents (e.g. the same architecture with the PQCs removed), the data encoding strategy is the dominant factor, with validation accuracy varying over 30% for distinct embeddings. In contrast, the selection of variational ansätze and measurement basis had a comparatively marginal effect, with validation accuracy variations remaining below 5%. For purely quantum models, restricted to amplitude encoding, performance was most dependent on the measurement protocol and the data-to-amplitude mapping. The measurement strategy varied the validation accuracy by up to 30% and the encoding mapping by around 8 percentage points.",
    "published": "2025-06-25T12:10:11Z",
    "updated": "2026-01-26T14:20:23Z",
    "link": "http://arxiv.org/pdf/2506.20355v2.pdf",
    "category": [
      "quant-ph",
      "cs.CV"
    ],
    "authors": [
      "Jesús Lozano-Cruz",
      "Albert Nieto-Morales",
      "Oriol Balló-Gimbernat",
      "Adan Garriga",
      "Antón Rodríguez-Otero",
      "Alejandro Borrallo-Rentero"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.16885v2",
    "title": "GPA-VGGT:Adapting VGGT to Large Scale Localization by Self-Supervised Learning with Geometry and Physics Aware Loss",
    "summary": "Transformer-based general visual geometry frameworks have shown promising performance in camera pose estimation and 3D scene understanding. Recent advancements in Visual Geometry Grounded Transformer (VGGT) models have shown great promise in camera pose estimation and 3D reconstruction. However, these models typically rely on ground truth labels for training, posing challenges when adapting to unlabeled and unseen scenes. In this paper, we propose a self-supervised framework to train VGGT with unlabeled data, thereby enhancing its localization capability in large-scale environments. To achieve this, we extend conventional pair-wise relations to sequence-wise geometric constraints for self-supervised learning. Specifically, in each sequence, we sample multiple source frames and geometrically project them onto different target frames, which improves temporal feature consistency. We formulate physical photometric consistency and geometric constraints as a joint optimization loss to circumvent the requirement for hard labels. By training the model with this proposed method, not only the local and global cross-view attention layers but also the camera and depth heads can effectively capture the underlying multi-view geometry. Experiments demonstrate that the model converges within hundreds of iterations and achieves significant improvements in large-scale localization. Our code will be released at https://github.com/X-yangfan/GPA-VGGT.",
    "published": "2026-01-23T16:46:59Z",
    "updated": "2026-01-26T14:14:37Z",
    "link": "http://arxiv.org/pdf/2601.16885v2.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Yangfan Xu",
      "Lilian Zhang",
      "Xiaofeng He",
      "Pengdong Wu",
      "Wenqi Wu",
      "Jun Mao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2407.09386v3",
    "title": "Radiance Fields from Photons",
    "summary": "Neural radiance fields, or NeRFs, have become the de facto approach for high-quality view synthesis from a collection of images captured from multiple viewpoints. However, many issues remain when capturing images in-the-wild under challenging conditions, such as low light, high dynamic range, or rapid motion leading to smeared reconstructions with noticeable artifacts. In this work, we introduce quanta radiance fields, a novel class of neural radiance fields that are trained at the granularity of individual photons using single-photon cameras (SPCs). We develop theory and practical computational techniques for building radiance fields and estimating dense camera poses from unconventional, stochastic, and high-speed binary frame sequences captured by SPCs. We demonstrate, both via simulations and a SPC hardware prototype, high-fidelity reconstructions under high-speed motion, in low light, and for extreme dynamic range settings.",
    "published": "2024-07-12T16:06:51Z",
    "updated": "2026-01-26T14:06:37Z",
    "link": "http://arxiv.org/pdf/2407.09386v3.pdf",
    "category": [
      "cs.CV",
      "eess.IV"
    ],
    "authors": [
      "Sacha Jungerman",
      "Aryan Garg",
      "Mohit Gupta"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18493v1",
    "title": "DisasterInsight: A Multimodal Benchmark for Function-Aware and Grounded Disaster Assessment",
    "summary": "Timely interpretation of satellite imagery is critical for disaster response, yet existing vision-language benchmarks for remote sensing largely focus on coarse labels and image-level recognition, overlooking the functional understanding and instruction robustness required in real humanitarian workflows. We introduce DisasterInsight, a multimodal benchmark designed to evaluate vision-language models (VLMs) on realistic disaster analysis tasks. DisasterInsight restructures the xBD dataset into approximately 112K building-centered instances and supports instruction-diverse evaluation across multiple tasks, including building-function classification, damage-level and disaster-type classification, counting, and structured report generation aligned with humanitarian assessment guidelines.\n  To establish domain-adapted baselines, we propose DI-Chat, obtained by fine-tuning existing VLM backbones on disaster-specific instruction data using parameter-efficient Low-Rank Adaptation (LoRA). Extensive experiments on state-of-the-art generic and remote-sensing VLMs reveal substantial performance gaps across tasks, particularly in damage understanding and structured report generation. DI-Chat achieves significant improvements on damage-level and disaster-type classification as well as report generation quality, while building-function classification remains challenging for all evaluated models. DisasterInsight provides a unified benchmark for studying grounded multimodal reasoning in disaster imagery.",
    "published": "2026-01-26T13:48:11Z",
    "updated": "2026-01-26T13:48:11Z",
    "link": "http://arxiv.org/pdf/2601.18493v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Sara Tehrani",
      "Yonghao Xu",
      "Leif Haglund",
      "Amanda Berg",
      "Michael Felsberg"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18475v1",
    "title": "LoD-Structured 3D Gaussian Splatting for Streaming Video Reconstruction",
    "summary": "Free-Viewpoint Video (FVV) reconstruction enables photorealistic and interactive 3D scene visualization; however, real-time streaming is often bottlenecked by sparse-view inputs, prohibitive training costs, and bandwidth constraints. While recent 3D Gaussian Splatting (3DGS) has advanced FVV due to its superior rendering speed, Streaming Free-Viewpoint Video (SFVV) introduces additional demands for rapid optimization, high-fidelity reconstruction under sparse constraints, and minimal storage footprints. To bridge this gap, we propose StreamLoD-GS, an LoD-based Gaussian Splatting framework designed specifically for SFVV. Our approach integrates three core innovations: 1) an Anchor- and Octree-based LoD-structured 3DGS with a hierarchical Gaussian dropout technique to ensure efficient and stable optimization while maintaining high-quality rendering; 2) a GMM-based motion partitioning mechanism that separates dynamic and static content, refining dynamic regions while preserving background stability; and 3) a quantized residual refinement framework that significantly reduces storage requirements without compromising visual fidelity. Extensive experiments demonstrate that StreamLoD-GS achieves competitive or state-of-the-art performance in terms of quality, efficiency, and storage.",
    "published": "2026-01-26T13:27:46Z",
    "updated": "2026-01-26T13:27:46Z",
    "link": "http://arxiv.org/pdf/2601.18475v1.pdf",
    "category": [
      "cs.GR",
      "cs.CV"
    ],
    "authors": [
      "Xinhui Liu",
      "Can Wang",
      "Lei Liu",
      "Zhenghao Chen",
      "Wei Jiang",
      "Wei Wang",
      "Dong Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.21366v2",
    "title": "BADiff: Bandwidth Adaptive Diffusion Model",
    "summary": "In this work, we propose a novel framework to enable diffusion models to adapt their generation quality based on real-time network bandwidth constraints. Traditional diffusion models produce high-fidelity images by performing a fixed number of denoising steps, regardless of downstream transmission limitations. However, in practical cloud-to-device scenarios, limited bandwidth often necessitates heavy compression, leading to loss of fine textures and wasted computation. To address this, we introduce a joint end-to-end training strategy where the diffusion model is conditioned on a target quality level derived from the available bandwidth. During training, the model learns to adaptively modulate the denoising process, enabling early-stop sampling that maintains perceptual quality appropriate to the target transmission condition. Our method requires minimal architectural changes and leverages a lightweight quality embedding to guide the denoising trajectory. Experimental results demonstrate that our approach significantly improves the visual fidelity of bandwidth-adapted generations compared to naive early-stopping, offering a promising solution for efficient image delivery in bandwidth-constrained environments. Code is available at: https://github.com/xzhang9308/BADiff.",
    "published": "2025-10-24T11:50:03Z",
    "updated": "2026-01-26T12:57:27Z",
    "link": "http://arxiv.org/pdf/2510.21366v2.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Xi Zhang",
      "Hanwei Zhu",
      "Yan Zhong",
      "Jiamang Wang",
      "Weisi Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18448v1",
    "title": "On Procrustes Contamination in Machine Learning Applications of Geometric Morphometrics",
    "summary": "Geometric morphometrics (GMM) is widely used to quantify shape variation, more recently serving as input for machine learning (ML) analyses. Standard practice aligns all specimens via Generalized Procrustes Analysis (GPA) prior to splitting data into training and test sets, potentially introducing statistical dependence and contaminating downstream predictive models. Here, the effects of GPA-induced contamination are formally characterised using controlled 2D and 3D simulations across varying sample sizes, landmark densities, and allometric patterns. A novel realignment procedure is proposed, whereby test specimens are aligned to the training set prior to model fitting, eliminating cross-sample dependency. Simulations reveal a robust \"diagonal\" in sample-size vs. landmark-space, reflecting the scaling of RMSE under isotropic variation, with slopes analytically derived from the degrees of freedom in Procrustes tangent space. The importance of spatial autocorrelation among landmarks is further demonstrated using linear and convolutional regression models, highlighting performance degradation when landmark relationships are ignored. This work establishes the need for careful preprocessing in ML applications of GMM, provides practical guidelines for realignment, and clarifies fundamental statistical constraints inherent to Procrustes shape space.",
    "published": "2026-01-26T12:56:23Z",
    "updated": "2026-01-26T12:56:23Z",
    "link": "http://arxiv.org/pdf/2601.18448v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Lloyd Austin Courtenay"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.10408v2",
    "title": "MultiHateLoc: Towards Temporal Localisation of Multimodal Hate Content in Online Videos",
    "summary": "The rapid growth of video content on platforms such as TikTok and YouTube has intensified the spread of multimodal hate speech, where harmful cues emerge subtly and asynchronously across visual, acoustic, and textual streams. Existing research primarily focuses on video-level classification, leaving the practically crucial task of temporal localisation, identifying when hateful segments occur, largely unaddressed. This challenge is even more noticeable under weak supervision, where only video-level labels are available, and static fusion or classification-based architectures struggle to capture cross-modal and temporal dynamics. To address these challenges, we propose MultiHateLoc, the first framework designed for weakly-supervised multimodal hate localisation. MultiHateLoc incorporates (1) modality-aware temporal encoders to model heterogeneous sequential patterns, including a tailored text-based preprocessing module for feature enhancement; (2) dynamic cross-modal fusion to adaptively emphasise the most informative modality at each moment and a cross-modal contrastive alignment strategy to enhance multimodal feature consistency; (3) a modality-aware MIL objective to identify discriminative segments under video-level supervision. Despite relying solely on coarse labels, MultiHateLoc produces fine-grained, interpretable frame-level predictions. Experiments on HateMM and MultiHateClip show that our method achieves state-of-the-art performance in the localisation task.",
    "published": "2025-12-11T08:18:22Z",
    "updated": "2026-01-26T12:39:05Z",
    "link": "http://arxiv.org/pdf/2512.10408v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Qiyue Sun",
      "Tailin Chen",
      "Yinghui Zhang",
      "Yuchen Zhang",
      "Jiangbei Yue",
      "Jianbo Jiao",
      "Zeyu Fu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.03906v2",
    "title": "From Filters to VLMs: Benchmarking Defogging Methods through Object Detection and Segmentation Performance",
    "summary": "Autonomous driving perception systems are particularly vulnerable in foggy conditions, where light scattering reduces contrast and obscures fine details critical for safe operation. While numerous defogging methods exist, from handcrafted filters to learned restoration models, improvements in image fidelity do not consistently translate into better downstream detection and segmentation. Moreover, prior evaluations often rely on synthetic data, raising concerns about real-world transferability.\n  We present a structured empirical study that benchmarks a comprehensive set of defogging pipelines, including classical dehazing filters, modern defogging networks, chained variants combining filters and models, and prompt-driven visual language image editing models applied directly to foggy images. To bridge the gap between simulated and physical environments, we evaluate these pipelines on both the synthetic Foggy Cityscapes dataset and the real-world Adverse Conditions Dataset with Correspondences (ACDC).\n  We examine generalization by evaluating performance on synthetic fog and real-world conditions, assessing both image quality and downstream perception in terms of object detection mean average precision and segmentation panoptic quality. Our analysis identifies when defogging is effective, the impact of combining models, and how visual language models compare to traditional approaches. We additionally report qualitative rubric-based evaluations from both human and visual language model judges and analyze their alignment with downstream task metrics.\n  Together, these results establish a transparent, task-oriented benchmark for defogging methods and identify the conditions under which pre-processing meaningfully improves autonomous perception in adverse weather.\n  Project page: https://aradfir.github.io/filters-to-vlms-defogging-page/",
    "published": "2025-10-04T19:05:04Z",
    "updated": "2026-01-26T12:26:48Z",
    "link": "http://arxiv.org/pdf/2510.03906v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ardalan Aryashad",
      "Parsa Razmara",
      "Amin Mahjoub",
      "Seyedarmin Azizi",
      "Mahdi Salmani",
      "Arad Firouzkouhi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.12513v3",
    "title": "GlobalGeoTree: A Multi-Granular Vision-Language Dataset for Global Tree Species Classification",
    "summary": "Global tree species mapping using remote sensing data is vital for biodiversity monitoring, forest management, and ecological research. However, progress in this field has been constrained by the scarcity of large-scale, labeled datasets. To address this, we introduce GlobalGeoTree, a comprehensive global dataset for tree species classification. GlobalGeoTree comprises 6.3 million geolocated tree occurrences, spanning 275 families, 2,734 genera, and 21,001 species across the hierarchical taxonomic levels. Each sample is paired with Sentinel-2 image time series and 27 auxiliary environmental variables, encompassing bioclimatic, geographic, and soil data. The dataset is partitioned into GlobalGeoTree-6M for model pretraining and curated evaluation subsets, primarily GlobalGeoTree-10kEval for zero-shot and few-shot benchmarking. To demonstrate the utility of the dataset, we introduce a baseline model, GeoTreeCLIP, which leverages paired remote sensing data and taxonomic text labels within a vision-language framework pretrained on GlobalGeoTree-6M. Experimental results show that GeoTreeCLIP achieves substantial improvements in zero- and few-shot classification on GlobalGeoTree-10kEval over existing advanced models. By making the dataset, models, and code publicly available, we aim to establish a benchmark to advance tree species classification and foster innovation in biodiversity research and ecological applications.",
    "published": "2025-05-18T18:31:00Z",
    "updated": "2026-01-26T12:22:05Z",
    "link": "http://arxiv.org/pdf/2505.12513v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yang Mu",
      "Zhitong Xiong",
      "Yi Wang",
      "Muhammad Shahzad",
      "Franz Essl",
      "Holger Kreft",
      "Mark van Kleunen",
      "Xiao Xiang Zhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.18989v2",
    "title": "Ask Me Again Differently: GRAS for Measuring Bias in Vision Language Models on Gender, Race, Age, and Skin Tone",
    "summary": "As Vision Language Models (VLMs) become integral to real-world applications, understanding their demographic biases is critical. We introduce GRAS, a benchmark for uncovering demographic biases in VLMs across gender, race, age, and skin tone, offering the most diverse coverage to date. We further propose the GRAS Bias Score, an interpretable metric for quantifying bias. We benchmark five state-of-the-art VLMs and reveal concerning bias levels, with the least biased model attaining a GRAS Bias Score of only 2 out of 100. Our findings also reveal a methodological insight: evaluating bias in VLMs with visual question answering (VQA) requires considering multiple formulations of a question. Our code, data, and evaluation results are publicly available.",
    "published": "2025-08-26T12:41:35Z",
    "updated": "2026-01-26T12:18:24Z",
    "link": "http://arxiv.org/pdf/2508.18989v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Shaivi Malik",
      "Hasnat Md Abdullah",
      "Sriparna Saha",
      "Amit Sheth"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18414v1",
    "title": "Comparative Evaluation of Machine Learning Algorithms for Affective State Recognition from Children's Drawings",
    "summary": "Autism spectrum disorder (ASD) represents a neurodevelopmental condition characterized by difficulties in expressing emotions and communication, particularly during early childhood. Understanding the affective state of children at an early age remains challenging, as conventional assessment methods are often intrusive, subjective, or difficult to apply consistently. This paper builds upon previous work on affective state recognition from children's drawings by presenting a comparative evaluation of machine learning models for emotion classification. Three deep learning architectures -- MobileNet, EfficientNet, and VGG16 -- are evaluated within a unified experimental framework to analyze classification performance, robustness, and computational efficiency. The models are trained using transfer learning on a dataset of children's drawings annotated with emotional labels provided by psychological experts. The results highlight important trade-offs between lightweight and deeper architectures when applied to drawing-based affective computing tasks, particularly in mobile and real-time application contexts.",
    "published": "2026-01-26T12:12:24Z",
    "updated": "2026-01-26T12:12:24Z",
    "link": "http://arxiv.org/pdf/2601.18414v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Aura Loredana Dan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2309.16738v3",
    "title": "ELIP: Efficient Discriminative Language-Image Pre-training with Fewer Vision Tokens",
    "summary": "Learning a versatile language-image model is computationally prohibitive under a limited computing budget. This paper delves into the \\emph{efficient language-image pre-training}, an area that has received relatively little attention despite its importance in reducing computational cost and footprint. To that end, we propose a vision token pruning and merging method ELIP, to remove less influential tokens based on the supervision of language outputs. Our method is designed with several strengths, such as being computation-efficient, memory-efficient, and trainable-parameter-free, and is distinguished from previous vision-only token pruning approaches by its alignment with task objectives. We implement this method in a progressively pruning manner using several sequential blocks. To evaluate its generalization performance, we apply ELIP to three commonly used language-image pre-training models and utilize public image-caption pairs with 4M images for pre-training. Our experiments demonstrate that with the removal of ~30$\\%$ vision tokens across 12 ViT layers, ELIP maintains significantly comparable performance with baselines ($\\sim$0.32 accuracy drop on average) over various downstream tasks including cross-modal retrieval, VQA, image captioning, \\emph{etc}. In addition, the spared GPU resources by our ELIP allow us to scale up with larger batch sizes, thereby accelerating model pre-training and even sometimes enhancing downstream model performance.",
    "published": "2023-09-28T05:31:07Z",
    "updated": "2026-01-26T12:11:48Z",
    "link": "http://arxiv.org/pdf/2309.16738v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yangyang Guo",
      "Haoyu Zhang",
      "Yongkang Wong",
      "Liqiang Nie",
      "Mohan Kankanhalli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18407v1",
    "title": "Larger than memory image processing",
    "summary": "This report addresses larger-than-memory image analysis for petascale datasets such as 1.4 PB electron-microscopy volumes and 150 TB human-organ atlases. We argue that performance is fundamentally I/O-bound. We show that structuring analysis as streaming passes over data is crucial. For 3D volumes, two representations are popular: stacks of 2D slices (e.g., directories or multi-page TIFF) and 3D chunked layouts (e.g., Zarr/HDF5). While for a few algorithms, chunked layout on disk is crucial to keep disk I/O at a minimum, we show how the slice-based streaming architecture can be built on top of either image representation in a manner that minimizes disk I/O. This is in particular advantageous for algorithms relying on neighbouring values, since the slicing streaming architecture is 1D, which implies that there are only 2 possible sweeping orders, both of which are aligned with the order in which images are read from the disk. This is in contrast to 3D chunks, in which any sweep cannot be done without accessing each chunk at least 9 times. We formalize this with sweep-based execution (natural 2D/3D orders), windowed operations, and overlap-aware tiling to minimize redundant access. Building on these principles, we introduce a domain-specific language (DSL) that encodes algorithms with intrinsic knowledge of their optimal streaming and memory use; the DSL performs compile-time and run-time pipeline analyses to automatically select window sizes, fuse stages, tee and zip streams, and schedule passes for limited-RAM machines, yielding near-linear I/O scans and predictable memory footprints. The approach integrates with existing tooling for segmentation and morphology but reframes pre/post-processing as pipelines that privilege sequential read/write patterns, delivering substantial throughput gains for extremely large images without requiring full-volume residency in memory.",
    "published": "2026-01-26T12:02:41Z",
    "updated": "2026-01-26T12:02:41Z",
    "link": "http://arxiv.org/pdf/2601.18407v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jon Sporring",
      "David Stansby"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18392v1",
    "title": "Efficient Complex-Valued Vision Transformers for MRI Classification Directly from k-Space",
    "summary": "Deep learning applications in Magnetic Resonance Imaging (MRI) predominantly operate on reconstructed magnitude images, a process that discards phase information and requires computationally expensive transforms. Standard neural network architectures rely on local operations (convolutions or grid-patches) that are ill-suited for the global, non-local nature of raw frequency-domain (k-Space) data. In this work, we propose a novel complex-valued Vision Transformer (kViT) designed to perform classification directly on k-Space data. To bridge the geometric disconnect between current architectures and MRI physics, we introduce a radial k-Space patching strategy that respects the spectral energy distribution of the frequency-domain. Extensive experiments on the fastMRI and in-house datasets demonstrate that our approach achieves classification performance competitive with state-of-the-art image-domain baselines (ResNet, EfficientNet, ViT). Crucially, kViT exhibits superior robustness to high acceleration factors and offers a paradigm shift in computational efficiency, reducing VRAM consumption during training by up to 68$\\times$ compared to standard methods. This establishes a pathway for resource-efficient, direct-from-scanner AI analysis.",
    "published": "2026-01-26T11:50:52Z",
    "updated": "2026-01-26T11:50:52Z",
    "link": "http://arxiv.org/pdf/2601.18392v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Moritz Rempe",
      "Lukas T. Rotkopf",
      "Marco Schlimbach",
      "Helmut Becker",
      "Fabian Hörst",
      "Johannes Haubold",
      "Philipp Dammann",
      "Kevin Kröninger",
      "Jens Kleesiek"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.11654v2",
    "title": "Kinetic Mining in Context: Few-Shot Action Synthesis via Text-to-Motion Distillation",
    "summary": "The acquisition cost for large, annotated motion datasets remains a critical bottleneck for skeletal-based Human Activity Recognition (HAR). Although Text-to-Motion (T2M) generative models offer a compelling, scalable source of synthetic data, their training objectives, which emphasize general artistic motion, and dataset structures fundamentally differ from HAR's requirements for kinematically precise, class-discriminative actions. This disparity creates a significant domain gap, making generalist T2M models ill-equipped for generating motions suitable for HAR classifiers. To address this challenge, we propose KineMIC (Kinetic Mining In Context), a transfer learning framework for few-shot action synthesis. KineMIC adapts a T2M diffusion model to an HAR domain by hypothesizing that semantic correspondences in the text encoding space can provide soft supervision for kinematic distillation. We operationalize this via a kinetic mining strategy that leverages CLIP text embeddings to establish correspondences between sparse HAR labels and T2M source data. This process guides fine-tuning, transforming the generalist T2M backbone into a specialized few-shot Action-to-Motion generator. We validate KineMIC using HumanML3D as the source T2M dataset and a subset of NTU RGB+D 120 as the target HAR domain, randomly selecting just 10 samples per action class. Our approach generates significantly more coherent motions, providing a robust data augmentation source that delivers a +23.1% accuracy points improvement. Animated illustrations and supplementary materials are available at https://lucazzola.github.io/publications/kinemic.",
    "published": "2025-12-12T15:32:28Z",
    "updated": "2026-01-26T11:40:49Z",
    "link": "http://arxiv.org/pdf/2512.11654v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Luca Cazzola",
      "Ahed Alboody"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18386v1",
    "title": "ARMOR: Agentic Reasoning for Methods Orchestration and Reparameterization for Robust Adversarial Attacks",
    "summary": "Existing automated attack suites operate as static ensembles with fixed sequences, lacking strategic adaptation and semantic awareness. This paper introduces the Agentic Reasoning for Methods Orchestration and Reparameterization (ARMOR) framework to address these limitations. ARMOR orchestrates three canonical adversarial primitives, Carlini-Wagner (CW), Jacobian-based Saliency Map Attack (JSMA), and Spatially Transformed Attacks (STA) via Vision Language Models (VLM)-guided agents that collaboratively generate and synthesize perturbations through a shared ``Mixing Desk\". Large Language Models (LLMs) adaptively tune and reparameterize parallel attack agents in a real-time, closed-loop system that exploits image-specific semantic vulnerabilities. On standard benchmarks, ARMOR achieves improved cross-architecture transfer and reliably fools both settings, delivering a blended output for blind targets and selecting the best attack or blended attacks for white-box targets using a confidence-and-SSIM score.",
    "published": "2026-01-26T11:36:34Z",
    "updated": "2026-01-26T11:36:34Z",
    "link": "http://arxiv.org/pdf/2601.18386v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Gabriel Lee Jun Rong",
      "Christos Korgialas",
      "Dion Jia Xu Ho",
      "Pai Chet Ng",
      "Xiaoxiao Miao",
      "Konstantinos N. Plataniotis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18385v1",
    "title": "Estimation of geometric transformation matrices using grid-shaped pilot signals",
    "summary": "Digital watermarking techniques are essential to prevent unauthorized use of images. Since pirated images are often geometrically distorted by operations such as scaling and cropping, accurate synchronization - detecting the embedding position of the watermark - is critical for proper extraction. In particular, cropping changes the origin of the image, making synchronization difficult. However, few existing methods are robust against cropping. To address this issue, we propose a watermarking method that estimates geometric transformations applied to a stego image using a pilot signal, allowing synchronization even after cropping. A grid-shaped pilot signal with distinct horizontal and vertical values is embedded in the image. When the image is transformed, the grid is also distorted. By analyzing this distortion, the transformation matrix can be estimated. Applying the Radon transform to the distorted image allows estimation of the grid angles and intervals. In addition, since the horizontal and vertical grid lines are encoded differently, the grid orientation can be determined, which reduces ambiguity. To validate our method, we performed simulations with anisotropic scaling, rotation, shearing, and cropping. The results show that the proposed method accurately estimates transformation matrices with low error under both single and composite attacks.",
    "published": "2026-01-26T11:33:01Z",
    "updated": "2026-01-26T11:33:01Z",
    "link": "http://arxiv.org/pdf/2601.18385v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Rinka Kawano",
      "Masaki Kawamura"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18372v1",
    "title": "Gaze Prediction in Virtual Reality Without Eye Tracking Using Visual and Head Motion Cues",
    "summary": "Gaze prediction plays a critical role in Virtual Reality (VR) applications by reducing sensor-induced latency and enabling computationally demanding techniques such as foveated rendering, which rely on anticipating user attention. However, direct eye tracking is often unavailable due to hardware limitations or privacy concerns. To address this, we present a novel gaze prediction framework that combines Head-Mounted Display (HMD) motion signals with visual saliency cues derived from video frames. Our method employs UniSal, a lightweight saliency encoder, to extract visual features, which are then fused with HMD motion data and processed through a time-series prediction module. We evaluate two lightweight architectures, TSMixer and LSTM, for forecasting future gaze directions. Experiments on the EHTask dataset, along with deployment on commercial VR hardware, show that our approach consistently outperforms baselines such as Center-of-HMD and Mean Gaze. These results demonstrate the effectiveness of predictive gaze modeling in reducing perceptual lag and enhancing natural interaction in VR environments where direct eye tracking is constrained.",
    "published": "2026-01-26T11:26:27Z",
    "updated": "2026-01-26T11:26:27Z",
    "link": "http://arxiv.org/pdf/2601.18372v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Christos Petrou",
      "Harris Partaourides",
      "Athanasios Balomenos",
      "Yannis Kopsinis",
      "Sotirios Chatzis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18368v1",
    "title": "OREHAS: A fully automated deep-learning pipeline for volumetric endolymphatic hydrops quantification in MRI",
    "summary": "We present OREHAS (Optimized Recognition & Evaluation of volumetric Hydrops in the Auditory System), the first fully automatic pipeline for volumetric quantification of endolymphatic hydrops (EH) from routine 3D-SPACE-MRC and 3D-REAL-IR MRI. The system integrates three components -- slice classification, inner ear localization, and sequence-specific segmentation -- into a single workflow that computes per-ear endolymphatic-to-vestibular volume ratios (ELR) directly from whole MRI volumes, eliminating the need for manual intervention.\n  Trained with only 3 to 6 annotated slices per patient, OREHAS generalized effectively to full 3D volumes, achieving Dice scores of 0.90 for SPACE-MRC and 0.75 for REAL-IR. In an external validation cohort with complete manual annotations, OREHAS closely matched expert ground truth (VSI = 74.3%) and substantially outperformed the clinical syngo.via software (VSI = 42.5%), which tended to overestimate endolymphatic volumes. Across 19 test patients, vestibular measurements from OREHAS were consistent with syngo.via, while endolymphatic volumes were systematically smaller and more physiologically realistic.\n  These results show that reliable and reproducible EH quantification can be achieved from standard MRI using limited supervision. By combining efficient deep-learning-based segmentation with a clinically aligned volumetric workflow, OREHAS reduces operator dependence, ensures methodological consistency. Besides, the results are compatible with established imaging protocols. The approach provides a robust foundation for large-scale studies and for recalibrating clinical diagnostic thresholds based on accurate volumetric measurements of the inner ear.",
    "published": "2026-01-26T11:19:21Z",
    "updated": "2026-01-26T11:19:21Z",
    "link": "http://arxiv.org/pdf/2601.18368v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Caterina Fuster-Barceló",
      "Claudia Castrillón",
      "Laura Rodrigo-Muñoz",
      "Victor Manuel Vega-Suárez",
      "Nicolás Pérez-Fernández",
      "Gorka Bastarrika",
      "Arrate Muñoz-Barrutia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.20787v4",
    "title": "Real-Time Object Detection Meets DINOv3",
    "summary": "Driven by the simple and effective Dense O2O, DEIM demonstrates faster convergence and enhanced performance. In this work, we extend it with DINOv3 features, resulting in DEIMv2. DEIMv2 spans eight model sizes from X to Atto, covering GPU, edge, and mobile deployment. For the X, L, M, and S variants, we adopt DINOv3-pretrained or distilled backbones and introduce a Spatial Tuning Adapter (STA), which efficiently converts DINOv3's single-scale output into multi-scale features and complements strong semantics with fine-grained details to enhance detection. For ultra-lightweight models (Nano, Pico, Femto, and Atto), we employ HGNetv2 with depth and width pruning to meet strict resource budgets. Together with a simplified decoder and an upgraded Dense O2O, this unified design enables DEIMv2 to achieve a superior performance-cost trade-off across diverse scenarios, establishing new state-of-the-art results. Notably, our largest model, DEIMv2-X, achieves 57.8 AP with only 50.3 million parameters, surpassing prior X-scale models that require over 60 million parameters for just 56.5 AP. On the compact side, DEIMv2-S is the first sub-10 million model (9.71 million) to exceed the 50 AP milestone on COCO, reaching 50.9 AP. Even the ultra-lightweight DEIMv2-Pico, with just 1.5 million parameters, delivers 38.5 AP, matching YOLOv10-Nano (2.3 million) with around 50 percent fewer parameters. Our code and pre-trained models are available at https://github.com/Intellindust-AI-Lab/DEIMv2",
    "published": "2025-09-25T06:14:00Z",
    "updated": "2026-01-26T10:42:27Z",
    "link": "http://arxiv.org/pdf/2509.20787v4.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Shihua Huang",
      "Yongjie Hou",
      "Longfei Liu",
      "Xuanlong Yu",
      "Xi Shen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18346v1",
    "title": "Q-Bench-Portrait: Benchmarking Multimodal Large Language Models on Portrait Image Quality Perception",
    "summary": "Recent advances in multimodal large language models (MLLMs) have demonstrated impressive performance on existing low-level vision benchmarks, which primarily focus on generic images. However, their capabilities to perceive and assess portrait images, a domain characterized by distinct structural and perceptual properties, remain largely underexplored. To this end, we introduce Q-Bench-Portrait, the first holistic benchmark specifically designed for portrait image quality perception, comprising 2,765 image-question-answer triplets and featuring (1) diverse portrait image sources, including natural, synthetic distortion, AI-generated, artistic, and computer graphics images; (2) comprehensive quality dimensions, covering technical distortions, AIGC-specific distortions, and aesthetics; and (3) a range of question formats, including single-choice, multiple-choice, true/false, and open-ended questions, at both global and local levels. Based on Q-Bench-Portrait, we evaluate 20 open-source and 5 closed-source MLLMs, revealing that although current models demonstrate some competence in portrait image perception, their performance remains limited and imprecise, with a clear gap relative to human judgments. We hope that the proposed benchmark will foster further research into enhancing the portrait image perception capabilities of both general-purpose and domain-specific MLLMs.",
    "published": "2026-01-26T10:37:20Z",
    "updated": "2026-01-26T10:37:20Z",
    "link": "http://arxiv.org/pdf/2601.18346v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Sijing Wu",
      "Yunhao Li",
      "Zicheng Zhang",
      "Qi Jia",
      "Xinyue Li",
      "Huiyu Duan",
      "Xiongkuo Min",
      "Guangtao Zhai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18340v1",
    "title": "Beyond Rigid: Benchmarking Non-Rigid Video Editing",
    "summary": "Despite the remarkable progress in text-driven video editing, generating coherent non-rigid deformations remains a critical challenge, often plagued by physical distortion and temporal flicker. To bridge this gap, we propose NRVBench, the first dedicated and comprehensive benchmark designed to evaluate non-rigid video editing. First, we curate a high-quality dataset consisting of 180 non-rigid motion videos from six physics-based categories, equipped with 2,340 fine-grained task instructions and 360 multiple-choice questions. Second, we propose NRVE-Acc, a novel evaluation metric based on Vision-Language Models that can rigorously assess physical compliance, temporal consistency, and instruction alignment, overcoming the limitations of general metrics in capturing complex dynamics. Third, we introduce a training-free baseline, VM-Edit, which utilizes a dual-region denoising mechanism to achieve structure-aware control, balancing structural preservation and dynamic deformation. Extensive experiments demonstrate that while current methods have shortcomings in maintaining physical plausibility, our method achieves excellent performance across both standard and proposed metrics. We believe the benchmark could serve as a standard testing platform for advancing physics-aware video editing.",
    "published": "2026-01-26T10:28:09Z",
    "updated": "2026-01-26T10:28:09Z",
    "link": "http://arxiv.org/pdf/2601.18340v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Bingzheng Qu",
      "Kehai Chen",
      "Xuefeng Bai",
      "Jun Yu",
      "Min Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18336v1",
    "title": "PPISP: Physically-Plausible Compensation and Control of Photometric Variations in Radiance Field Reconstruction",
    "summary": "Multi-view 3D reconstruction methods remain highly sensitive to photometric inconsistencies arising from camera optical characteristics and variations in image signal processing (ISP). Existing mitigation strategies such as per-frame latent variables or affine color corrections lack physical grounding and generalize poorly to novel views. We propose the Physically-Plausible ISP (PPISP) correction module, which disentangles camera-intrinsic and capture-dependent effects through physically based and interpretable transformations. A dedicated PPISP controller, trained on the input views, predicts ISP parameters for novel viewpoints, analogous to auto exposure and auto white balance in real cameras. This design enables realistic and fair evaluation on novel views without access to ground-truth images. PPISP achieves SoTA performance on standard benchmarks, while providing intuitive control and supporting the integration of metadata when available. The source code is available at: https://github.com/nv-tlabs/ppisp",
    "published": "2026-01-26T10:23:43Z",
    "updated": "2026-01-26T10:23:43Z",
    "link": "http://arxiv.org/pdf/2601.18336v1.pdf",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "Isaac Deutsch",
      "Nicolas Moënne-Loccoz",
      "Gavriel State",
      "Zan Gojcic"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18330v1",
    "title": "A Tumor Aware DenseNet Swin Hybrid Learning with Boosted and Hierarchical Feature Spaces for Large-Scale Brain MRI Classification",
    "summary": "This study proposes an efficient Densely Swin Hybrid (EDSH) framework for brain tumor MRI analysis, designed to jointly capture fine grained texture patterns and long range contextual dependencies. Two tumor aware experimental setups are introduced to address class-specific diagnostic challenges. The first setup employs a Boosted Feature Space (BFS), where independently customized DenseNet and Swint branches learn complementary local and global representations that are dimension aligned, fused, and boosted, enabling highly sensitive detection of diffuse glioma patterns by successfully learning the features of irregular shape, poorly defined mass, and heterogeneous texture. The second setup adopts a hierarchical DenseNet Swint architecture with Deep Feature Extraction have Dual Residual connections (DFE and DR), in which DenseNet serves as a stem CNN for structured local feature learning, while Swin_t models global tumor morphology, effectively suppressing false negatives in meningioma and pituitary tumor classification by learning the features of well defined mass, location (outside brain) and enlargments in tumors (dural tail or upward extension). DenseNet is customized at the input level to match MRI spatial characteristics, leveraging dense residual connectivity to preserve texture information and mitigate vanishing-gradient effects. In parallel, Swint is tailored through task aligned patch embedding and shifted-window self attention to efficiently capture hierarchical global dependencies. Extensive evaluation on a large-scale MRI dataset (stringent 40,260 images across four tumor classes) demonstrates consistent superiority over standalone CNNs, Vision Transformers, and hybrids, achieving 98.50 accuracy and recall on the test unseen dataset.",
    "published": "2026-01-26T10:14:57Z",
    "updated": "2026-01-26T10:14:57Z",
    "link": "http://arxiv.org/pdf/2601.18330v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Muhammad Ali Shah",
      "Muhammad Mansoor Alam",
      "Saddam Hussain Khan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.05344v3",
    "title": "Coding the Visual World: From Image to Simulation Using Vision Language Models",
    "summary": "The ability to construct mental models of the world is a central aspect of understanding. Similarly, visual understanding can be viewed as the ability to construct a representative model of the system depicted in an image. This work explores the capacity of Vision Language Models (VLMs) to recognize and simulate the systems and mechanisms depicted in images using the Im2Sim methodology. The VLM is given a natural image of a real-world system (e.g., cities, clouds, vegetation) and is tasked with describing the system and writing code that simulates and generates it. This generative code is then executed to produce a synthetic image, which is compared against the original. This approach is tested on various complex emergent systems, ranging from physical systems (waves, lights, clouds) to vegetation, cities, materials, and geological formations. Through analysis of the models and images generated by the VLMs, we examine their understanding of the systems in images. The results show that leading VLMs (GPT, Gemini) have the ability to understand and model complex, multi-component systems across multiple layers of abstraction and a wide range of domains. At the same time, the VLMs exhibit limited ability to replicate fine details and low-level arrangements of patterns in the image. These findings reveal an interesting asymmetry: VLMs combine high-level, deep visual understanding of images with limited perception of fine details.",
    "published": "2026-01-08T19:49:05Z",
    "updated": "2026-01-26T10:11:31Z",
    "link": "http://arxiv.org/pdf/2601.05344v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Sagi Eppel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.07076v3",
    "title": "Context-measure: Contextualizing Metric for Camouflage",
    "summary": "Camouflage is primarily context-dependent yet current metrics for camouflaged scenarios overlook this critical factor. Instead, these metrics are originally designed for evaluating general or salient objects, with an inherent assumption of uncorrelated spatial context. In this paper, we propose a new contextualized evaluation paradigm, Context-measure, built upon a probabilistic pixel-aware correlation framework. By incorporating spatial dependencies and pixel-wise camouflage quantification, our measure better aligns with human perception. Extensive experiments across three challenging camouflaged object segmentation datasets show that Context-measure delivers more reliability than existing context-independent metrics. Our measure can provide a foundational evaluation benchmark for various computer vision applications involving camouflaged patterns, such as agricultural, industrial, and medical scenarios. Code is available at https://github.com/pursuitxi/Context-measure.",
    "published": "2025-12-08T01:23:28Z",
    "updated": "2026-01-26T09:52:42Z",
    "link": "http://arxiv.org/pdf/2512.07076v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Chen-Yang Wang",
      "Gepeng Ji",
      "Song Shao",
      "Ming-Ming Cheng",
      "Deng-Ping Fan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18305v1",
    "title": "SwipeGen: Bridging the Execution Gap in GUI Agents via Human-like Swipe Synthesis",
    "summary": "With the widespread adoption of Graphical User Interface (GUI) agents for automating GUI interaction tasks, substantial research focused on improving GUI perception to ground task instructions into concrete action steps. However, the step execution capability of these agents has gradually emerged as a new bottleneck for task completion. In particular, existing GUI agents often adopt overly simplified strategies for handling swipe interactions, preventing them from accurately replicating human-like behavior. To address this limitation, we decompose human swipe gestures into multiple quantifiable dimensions and propose an automated pipeline SwipeGen to synthesize human-like swipe interactions through GUI exploration. Based on this pipeline, we construct and release the first benchmark for evaluating the swipe execution capability of GUI agents. Furthermore, leveraging the synthesized data, we propose GUISwiper, a GUI agent with enhanced interaction execution capabilities. Experimental results demonstrate that GUISwiper achieves a swipe execution accuracy of 69.07%, representing a 214% improvement over existing VLM baselines.",
    "published": "2026-01-26T09:35:10Z",
    "updated": "2026-01-26T09:35:10Z",
    "link": "http://arxiv.org/pdf/2601.18305v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xuan Wang",
      "Siyuan Su",
      "Quantong Fu",
      "Yongxiang Hu",
      "Yangfan Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18301v1",
    "title": "Contextual Range-View Projection for 3D LiDAR Point Clouds",
    "summary": "Range-view projection provides an efficient method for transforming 3D LiDAR point clouds into 2D range image representations, enabling effective processing with 2D deep learning models. However, a major challenge in this projection is the many-to-one conflict, where multiple 3D points are mapped onto the same pixel in the range image, requiring a selection strategy. Existing approaches typically retain the point with the smallest depth (closest to the LiDAR), disregarding semantic relevance and object structure, which leads to the loss of important contextual information. In this paper, we extend the depth-based selection rule by incorporating contextual information from both instance centers and class labels, introducing two mechanisms: \\textit{Centerness-Aware Projection (CAP)} and \\textit{Class-Weighted-Aware Projection (CWAP)}. In CAP, point depths are adjusted according to their distance from the instance center, thereby prioritizing central instance points over noisy boundary and background points. In CWAP, object classes are prioritized through user-defined weights, offering flexibility in the projection strategy. Our evaluations on the SemanticKITTI dataset show that CAP preserves more instance points during projection, achieving up to a 3.1\\% mIoU improvement compared to the baseline. Furthermore, CWAP enhances the performance of targeted classes while having a negligible impact on the performance of other classes",
    "published": "2026-01-26T09:30:43Z",
    "updated": "2026-01-26T09:30:43Z",
    "link": "http://arxiv.org/pdf/2601.18301v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Seyedali Mousavi",
      "Seyedhamidreza Mousavi",
      "Masoud Daneshtalab"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.08603v2",
    "title": "CellStyle: Improved Zero-Shot Cell Segmentation via Style Transfer",
    "summary": "Cell microscopy data are abundant; however, corresponding segmentation annotations remain scarce. Moreover, variations in cell types, imaging devices, and staining techniques introduce significant domain gaps between datasets. As a result, even large, pretrained segmentation models trained on diverse datasets (source datasets) struggle to generalize to unseen datasets (target datasets). To overcome this generalization problem, we propose CellStyle, which improves the segmentation quality of such models without requiring labels for the target dataset, thereby enabling zero-shot adaptation. CellStyle transfers the attributes of an unannotated target dataset, such as texture, color, and noise, to the annotated source dataset. This transfer is performed while preserving the cell shapes of the source images, ensuring that the existing source annotations can still be used while maintaining the visual characteristics of the target dataset. The styled synthetic images with the existing annotations enable the finetuning of a generalist segmentation model for application to the unannotated target data. We demonstrate that CellStyle significantly improves zero-shot cell segmentation performance across diverse datasets by finetuning multiple segmentation models on the style-transferred data. The code will be made publicly available.",
    "published": "2025-03-11T16:39:09Z",
    "updated": "2026-01-26T09:13:52Z",
    "link": "http://arxiv.org/pdf/2503.08603v2.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Rüveyda Yilmaz",
      "Zhu Chen",
      "Yuli Wu",
      "Johannes Stegmaier"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.16522v2",
    "title": "Adams Bashforth Moulton Solver for Inversion and Editing in Rectified Flow",
    "summary": "Rectified flow models have achieved remarkable performance in image and video generation tasks. However, existing numerical solvers face a trade-off between fast sampling and high accuracy solutions, limiting their effectiveness in downstream applications such as reconstruction and editing. To address this challenge, we propose leveraging the Adams Bashforth Moulton (ABM) predictor corrector method to enhance the accuracy of ODE solving in rectified flow models. Specifically, we introduce ABM Solver, which integrates a multi step predictor corrector approach to reduce local truncation errors and employs Adaptive Step Size Adjustment to improve sampling speed. Furthermore, to effectively preserve non edited regions while facilitating semantic modifications, we introduce a Mask Guided Feature Injection module. We estimate self-similarity to generate a spatial mask that differentiates preserved regions from those available for editing. Extensive experiments on multiple high resolution image datasets validate that ABM Solver significantly improves inversion precision and editing quality, outperforming existing solvers without requiring additional training or optimization.",
    "published": "2025-03-17T02:17:33Z",
    "updated": "2026-01-26T09:12:33Z",
    "link": "http://arxiv.org/pdf/2503.16522v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yongjia Ma",
      "Donglin Di",
      "Xuan Liu",
      "Xiaokai Chen",
      "Lei Fan",
      "Tonghua Su",
      "Yue Gao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.10203v3",
    "title": "A Style-Based Profiling Framework for Quantifying the Synthetic-to-Real Gap in Autonomous Driving Datasets",
    "summary": "Ensuring the reliability of autonomous driving perception systems requires extensive environment-based testing, yet real-world execution is often impractical. Synthetic datasets have therefore emerged as a promising alternative, offering advantages such as cost-effectiveness, bias free labeling, and controllable scenarios. However, the domain gap between synthetic and real-world datasets remains a major obstacle to model generalization. To address this challenge from a data-centric perspective, this paper introduces a profile extraction and discovery framework for characterizing the style profiles underlying both synthetic and real image datasets. We propose Style Embedding Distribution Discrepancy (SEDD) as a novel evaluation metric. Our framework combines Gram matrix-based style extraction with metric learning optimized for intra-class compactness and inter-class separation to extract style embeddings. Furthermore, we establish a benchmark using publicly available datasets. Experiments are conducted on a variety of datasets and sim-to-real methods, and the results show that our method is capable of quantifying the synthetic-to-real gap. This work provides a standardized profiling-based quality control paradigm that enables systematic diagnosis and targeted enhancement of synthetic datasets, advancing future development of data-driven autonomous driving systems.",
    "published": "2025-10-11T13:09:41Z",
    "updated": "2026-01-26T08:50:40Z",
    "link": "http://arxiv.org/pdf/2510.10203v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Dingyi Yao",
      "Xinyao Han",
      "Ruibo Ming",
      "Zhihang Song",
      "Lihui Peng",
      "Jianming Hu",
      "Danya Yao",
      "Yi Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18263v1",
    "title": "Revisiting Aerial Scene Classification on the AID Benchmark",
    "summary": "Aerial images play a vital role in urban planning and environmental preservation, as they consist of various structures, representing different types of buildings, forests, mountains, and unoccupied lands. Due to its heterogeneous nature, developing robust models for scene classification remains a challenge. In this study, we conduct a literature review of various machine learning methods for aerial image classification. Our survey covers a range of approaches from handcrafted features (e.g., SIFT, LBP) to traditional CNNs (e.g., VGG, GoogLeNet), and advanced deep hybrid networks. In this connection, we have also designed Aerial-Y-Net, a spatial attention-enhanced CNN with multi-scale feature fusion mechanism, which acts as an attention-based model and helps us to better understand the complexities of aerial images. Evaluated on the AID dataset, our model achieves 91.72% accuracy, outperforming several baseline architectures.",
    "published": "2026-01-26T08:39:02Z",
    "updated": "2026-01-26T08:39:02Z",
    "link": "http://arxiv.org/pdf/2601.18263v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Subhajeet Das",
      "Susmita Ghosh",
      "Abhiroop Chatterjee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18260v1",
    "title": "Depth to Anatomy: Learning Internal Organ Locations from Surface Depth Images",
    "summary": "Automated patient positioning plays an important role in optimizing scanning procedure and improving patient throughput. Leveraging depth information captured by RGB-D cameras presents a promising approach for estimating internal organ positions, thereby enabling more accurate and efficient positioning. In this work, we propose a learning-based framework that directly predicts the 3D locations and shapes of multiple internal organs from single 2D depth images of the body surface. Utilizing a large-scale dataset of full-body MRI scans, we synthesize depth images paired with corresponding anatomical segmentations to train a unified convolutional neural network architecture. Our method accurately localizes a diverse set of anatomical structures, including bones and soft tissues, without requiring explicit surface reconstruction. Experimental results demonstrate the potential of integrating depth sensors into radiology workflows to streamline scanning procedures and enhance patient experience through automated patient positioning.",
    "published": "2026-01-26T08:33:11Z",
    "updated": "2026-01-26T08:33:11Z",
    "link": "http://arxiv.org/pdf/2601.18260v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Eytan Kats",
      "Kai Geissler",
      "Daniel Mensing",
      "Jochen G. Hirsch",
      "Stefan Heldman",
      "Mattias P. Heinrich"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2409.12680v3",
    "title": "Exploiting Minority Pseudo-Labels for Semi-Supervised Fine-grained Road Scene Understanding",
    "summary": "In fine-grained road scene understanding, semantic segmentation plays a crucial role in enabling vehicles to perceive and comprehend their surroundings. By assigning a specific class label to each pixel in an image, it allows for precise identification and localization of detailed road features, which is vital for high-quality scene understanding and downstream perception tasks. A key challenge in this domain lies in improving the recognition performance of minority classes while mitigating the dominance of majority classes, which is essential for achieving balanced and robust overall performance. However, traditional semi-supervised learning methods often train models overlooking the imbalance between classes. To address this issue, firstly, we propose a general training module that learns from all the pseudo-labels without a conventional filtering strategy. Secondly, we propose a professional training module to learn specifically from reliable minority-class pseudo-labels identified by a novel mismatch score metric. The two modules are crossly supervised by each other so that it reduces model coupling which is essential for semi-supervised learning. During contrastive learning, to avoid the dominance of the majority classes in the feature space, we propose a strategy to assign evenly distributed anchors for different classes in the feature space. Experimental results on multiple public benchmarks show that our method surpasses traditional approaches in recognizing tail classes.",
    "published": "2024-09-19T11:47:25Z",
    "updated": "2026-01-26T08:29:19Z",
    "link": "http://arxiv.org/pdf/2409.12680v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yuting Hong",
      "Yongkang Wu",
      "Hui Xiao",
      "Huazheng Hao",
      "Xiaojie Qiu",
      "Baochen Yao",
      "Chengbin Peng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18242v1",
    "title": "Vision-Language-Model-Guided Differentiable Ray Tracing for Fast and Accurate Multi-Material RF Parameter Estimation",
    "summary": "Accurate radio-frequency (RF) material parameters are essential for electromagnetic digital twins in 6G systems, yet gradient-based inverse ray tracing (RT) remains sensitive to initialization and costly under limited measurements. This paper proposes a vision-language-model (VLM) guided framework that accelerates and stabilizes multi-material parameter estimation in a differentiable RT (DRT) engine. A VLM parses scene images to infer material categories and maps them to quantitative priors via an ITU-R material table, yielding informed conductivity initializations. The VLM further selects informative transmitter/receiver placements that promote diverse, material-discriminative paths. Starting from these priors, the DRT performs gradient-based refinement using measured received signal strengths. Experiments in NVIDIA Sionna on indoor scenes show 2-4$\\times$ faster convergence and 10-100$\\times$ lower final parameter error compared with uniform or random initialization and random placement baselines, achieving sub-0.1\\% mean relative error with only a few receivers. Complexity analyses indicate per-iteration time scales near-linearly with the number of materials and measurement setups, while VLM-guided placement reduces the measurements required for accurate recovery. Ablations over RT depth and ray counts confirm further accuracy gains without significant per-iteration overhead. Results demonstrate that semantic priors from VLMs effectively guide physics-based optimization for fast and reliable RF material estimation.",
    "published": "2026-01-26T07:54:53Z",
    "updated": "2026-01-26T07:54:53Z",
    "link": "http://arxiv.org/pdf/2601.18242v1.pdf",
    "category": [
      "cs.CV",
      "cs.NI"
    ],
    "authors": [
      "Zerui Kang",
      "Yishen Lim",
      "Zhouyou Gu",
      "Seung-Woo Ko",
      "Tony Q. S. Quek",
      "Jihong Park"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18240v1",
    "title": "V-Loop: Visual Logical Loop Verification for Hallucination Detection in Medical Visual Question Answering",
    "summary": "Multimodal Large Language Models (MLLMs) have shown remarkable capability in assisting disease diagnosis in medical visual question answering (VQA). However, their outputs remain vulnerable to hallucinations (i.e., responses that contradict visual facts), posing significant risks in high-stakes medical scenarios. Recent introspective detection methods, particularly uncertainty-based approaches, offer computational efficiency but are fundamentally indirect, as they estimate predictive uncertainty for an image-question pair rather than verifying the factual correctness of a specific answer. To address this limitation, we propose Visual Logical Loop Verification (V-Loop), a training-free and plug-and-play framework for hallucination detection in medical VQA. V-Loop introduces a bidirectional reasoning process that forms a visually grounded logical loop to verify factual correctness. Given an input, the MLLM produces an answer for the primary input pair. V-Loop extracts semantic units from the primary QA pair, generates a verification question by conditioning on the answer unit to re-query the question unit, and enforces visual attention consistency to ensure answering both primary question and verification question rely on the same image evidence. If the verification answer matches the expected semantic content, the logical loop closes, indicating factual grounding; otherwise, the primary answer is flagged as hallucinated. Extensive experiments on multiple medical VQA benchmarks and MLLMs show that V-Loop consistently outperforms existing introspective methods, remains highly efficient, and further boosts uncertainty-based approaches when used in combination.",
    "published": "2026-01-26T07:46:41Z",
    "updated": "2026-01-26T07:46:41Z",
    "link": "http://arxiv.org/pdf/2601.18240v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Mengyuan Jin",
      "Zehui Liao",
      "Yong Xia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.16532v2",
    "title": "AnchoredDream: Zero-Shot 360° Indoor Scene Generation from a Single View via Geometric Grounding",
    "summary": "Single-view indoor scene generation plays a crucial role in a range of real-world applications. However, generating a complete 360° scene from a single image remains a highly ill-posed and challenging problem. Recent approaches have made progress by leveraging diffusion models and depth estimation networks, yet they still struggle to maintain appearance consistency and geometric plausibility under large viewpoint changes, limiting their effectiveness in full-scene generation. To address this, we propose AnchoredDream, a novel zero-shot pipeline that anchors 360° scene generation on high-fidelity geometry via an appearance-geometry mutual boosting mechanism. Given a single-view image, our method first performs appearance-guided geometry generation to construct a reliable 3D scene layout. Then, we progressively generate the complete scene through a series of modules: warp-and-inpaint, warp-and-refine, post-optimization, and a novel Grouting Block, which ensures seamless transitions between the input view and generated regions. Extensive experiments demonstrate that AnchoredDream outperforms existing methods by a large margin in both appearance consistency and geometric plausibility--all in a zero-shot manner. Our results highlight the potential of geometric grounding for high-quality, zero-shot single-view scene generation.",
    "published": "2026-01-23T08:08:12Z",
    "updated": "2026-01-26T07:46:19Z",
    "link": "http://arxiv.org/pdf/2601.16532v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Runmao Yao",
      "Junsheng Zhou",
      "Zhen Dong",
      "Yu-Shen Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18228v1",
    "title": "Facial Emotion Recognition on FER-2013 using an EfficientNetB2-Based Approach",
    "summary": "Detection of human emotions based on facial images in real-world scenarios is a difficult task due to low image quality, variations in lighting, pose changes, background distractions, small inter-class variations, noisy crowd-sourced labels, and severe class imbalance, as observed in the FER-2013 dataset of 48x48 grayscale images. Although recent approaches using large CNNs such as VGG and ResNet achieve reasonable accuracy, they are computationally expensive and memory-intensive, limiting their practicality for real-time applications. We address these challenges using a lightweight and efficient facial emotion recognition pipeline based on EfficientNetB2, trained using a two-stage warm-up and fine-tuning strategy. The model is enhanced with AdamW optimization, decoupled weight decay, label smoothing (epsilon = 0.06) to reduce annotation noise, and clipped class weights to mitigate class imbalance, along with dropout, mixed-precision training, and extensive real-time data augmentation. The model is trained using a stratified 87.5%/12.5% train-validation split while keeping the official test set intact, achieving a test accuracy of 68.78% with nearly ten times fewer parameters than VGG16-based baselines. Experimental results, including per-class metrics and learning dynamics, demonstrate stable training and strong generalization, making the proposed approach suitable for real-time and edge-based applications.",
    "published": "2026-01-26T07:29:50Z",
    "updated": "2026-01-26T07:29:50Z",
    "link": "http://arxiv.org/pdf/2601.18228v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Sahil Naik",
      "Soham Bagayatkar",
      "Pavankumar Singh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18222v1",
    "title": "HomoFM: Deep Homography Estimation with Flow Matching",
    "summary": "Deep homography estimation has broad applications in computer vision and robotics. Remarkable progresses have been achieved while the existing methods typically treat it as a direct regression or iterative refinement problem and often struggling to capture complex geometric transformations or generalize across different domains. In this work, we propose HomoFM, a new framework that introduces the flow matching technique from generative modeling into the homography estimation task for the first time. Unlike the existing methods, we formulate homography estimation problem as a velocity field learning problem. By modeling a continuous and point-wise velocity field that transforms noisy distributions into registered coordinates, the proposed network recovers high-precision transformations through a conditional flow trajectory. Furthermore, to address the challenge of domain shifts issue, e.g., the cases of multimodal matching or varying illumination scenarios, we integrate a gradient reversal layer (GRL) into the feature extraction backbone. This domain adaptation strategy explicitly constrains the encoder to learn domain-invariant representations, significantly enhancing the network's robustness. Extensive experiments demonstrate the effectiveness of the proposed method, showing that HomoFM outperforms state-of-the-art methods in both estimation accuracy and robustness on standard benchmarks. Code and data resource are available at https://github.com/hmf21/HomoFM.",
    "published": "2026-01-26T07:17:32Z",
    "updated": "2026-01-26T07:17:32Z",
    "link": "http://arxiv.org/pdf/2601.18222v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Mengfan He",
      "Liangzheng Sun",
      "Chunyu Li",
      "Ziyang Meng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18219v1",
    "title": "Automated HER2 scoring with uncertainty quantification using lensfree holography and deep learning",
    "summary": "Accurate assessment of human epidermal growth factor receptor 2 (HER2) expression is critical for breast cancer diagnosis, prognosis, and therapy selection; yet, most existing digital HER2 scoring methods rely on bulky and expensive optical systems. Here, we present a compact and cost-effective lensfree holography platform integrated with deep learning for automated HER2 scoring of immunohistochemically stained breast tissue sections. The system captures lensfree diffraction patterns of stained HER2 tissue sections under RGB laser illumination and acquires complex field information over a sample area of ~1,250 mm^2 at an effective throughput of ~84 mm^2 per minute. To enhance diagnostic reliability, we incorporated an uncertainty quantification strategy based on Bayesian Monte Carlo dropout, which provides autonomous uncertainty estimates for each prediction and supports reliable, robust HER2 scoring, with an overall correction rate of 30.4%. Using a blinded test set of 412 unique tissue samples, our approach achieved a testing accuracy of 84.9% for 4-class (0, 1+, 2+, 3+) HER2 classification and 94.8% for binary (0/1+ vs. 2+/3+) HER2 scoring with uncertainty quantification. Overall, this lensfree holography approach provides a practical pathway toward portable, high-throughput, and cost-effective HER2 scoring, particularly suited for resource-limited settings, where traditional digital pathology infrastructure is unavailable.",
    "published": "2026-01-26T07:09:08Z",
    "updated": "2026-01-26T07:09:08Z",
    "link": "http://arxiv.org/pdf/2601.18219v1.pdf",
    "category": [
      "physics.med-ph",
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Che-Yung Shen",
      "Xilin Yang",
      "Yuzhu Li",
      "Leon Lenk",
      "Aydogan Ozcan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18195v1",
    "title": "QualiRAG: Retrieval-Augmented Generation for Visual Quality Understanding",
    "summary": "Visual quality assessment (VQA) is increasingly shifting from scalar score prediction toward interpretable quality understanding -- a paradigm that demands \\textit{fine-grained spatiotemporal perception} and \\textit{auxiliary contextual information}. Current approaches rely on supervised fine-tuning or reinforcement learning on curated instruction datasets, which involve labor-intensive annotation and are prone to dataset-specific biases. To address these challenges, we propose \\textbf{QualiRAG}, a \\textit{training-free} \\textbf{R}etrieval-\\textbf{A}ugmented \\textbf{G}eneration \\textbf{(RAG)} framework that systematically leverages the latent perceptual knowledge of large multimodal models (LMMs) for visual quality perception. Unlike conventional RAG that retrieves from static corpora, QualiRAG dynamically generates auxiliary knowledge by decomposing questions into structured requests and constructing four complementary knowledge sources: \\textit{visual metadata}, \\textit{subject localization}, \\textit{global quality summaries}, and \\textit{local quality descriptions}, followed by relevance-aware retrieval for evidence-grounded reasoning. Extensive experiments show that QualiRAG achieves substantial improvements over open-source general-purpose LMMs and VQA-finetuned LMMs on visual quality understanding tasks, and delivers competitive performance on visual quality comparison tasks, demonstrating robust quality assessment capabilities without any task-specific training. The code will be publicly available at https://github.com/clh124/QualiRAG.",
    "published": "2026-01-26T06:27:03Z",
    "updated": "2026-01-26T06:27:03Z",
    "link": "http://arxiv.org/pdf/2601.18195v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Linhan Cao",
      "Wei Sun",
      "Weixia Zhang",
      "Xiangyang Zhu",
      "Kaiwei Zhang",
      "Jun Jia",
      "Dandan Zhu",
      "Guangtao Zhai",
      "Xiongkuo Min"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18192v1",
    "title": "MindCine: Multimodal EEG-to-Video Reconstruction with Large-Scale Pretrained Models",
    "summary": "Reconstructing human dynamic visual perception from electroencephalography (EEG) signals is of great research significance since EEG's non-invasiveness and high temporal resolution. However, EEG-to-video reconstruction remains challenging due to: 1) Single Modality: existing studies solely align EEG signals with the text modality, which ignores other modalities and are prone to suffer from overfitting problems; 2) Data Scarcity: current methods often have difficulty training to converge with limited EEG-video data. To solve the above problems, we propose a novel framework MindCine to achieve high-fidelity video reconstructions on limited data. We employ a multimodal joint learning strategy to incorporate beyond-text modalities in the training stage and leverage a pre-trained large EEG model to relieve the data scarcity issue for decoding semantic information, while a Seq2Seq model with causal attention is specifically designed for decoding perceptual information. Extensive experiments demonstrate that our model outperforms state-of-the-art methods both qualitatively and quantitatively. Additionally, the results underscore the effectiveness of the complementary strengths of different modalities and demonstrate that leveraging a large-scale EEG model can further enhance reconstruction performance by alleviating the challenges associated with limited data.",
    "published": "2026-01-26T06:20:34Z",
    "updated": "2026-01-26T06:20:34Z",
    "link": "http://arxiv.org/pdf/2601.18192v1.pdf",
    "category": [
      "cs.CV",
      "cs.HC",
      "cs.MM"
    ],
    "authors": [
      "Tian-Yi Zhou",
      "Xuan-Hao Liu",
      "Bao-Liang Lu",
      "Wei-Long Zheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18190v1",
    "title": "Multi-Perspective Subimage CLIP with Keyword Guidance for Remote Sensing Image-Text Retrieval",
    "summary": "Vision-Language Pre-training (VLP) models like CLIP have significantly advanced Remote Sensing Image-Text Retrieval (RSITR). However, existing methods predominantly rely on coarse-grained global alignment, which often overlooks the dense, multi-scale semantics inherent in overhead imagery. Moreover, adapting these heavy models via full fine-tuning incurs prohibitive computational costs and risks catastrophic forgetting. To address these challenges, we propose MPS-CLIP, a parameter-efficient framework designed to shift the retrieval paradigm from global matching to keyword-guided fine-grained alignment. Specifically, we leverage a Large Language Model (LLM) to extract core semantic keywords, guiding the Segment Anything Model (SamGeo) to generate semantically relevant sub-perspectives. To efficiently adapt the frozen backbone, we introduce a Gated Global Attention (G^2A) adapter, which captures global context and long-range dependencies with minimal overhead. Furthermore, a Multi-Perspective Representation (MPR) module aggregates these local cues into robust multi-perspective embeddings. The framework is optimized via a hybrid objective combining multi-perspective contrastive and weighted triplet losses, which dynamically selects maximum-response perspectives to suppress noise and enforce precise semantic matching. Extensive experiments on the RSICD and RSITMD benchmarks demonstrate that MPS-CLIP achieves state-of-the-art performance with 35.18% and 48.40% mean Recall (mR), respectively, significantly outperforming full fine-tuning baselines and recent competitive methods. Code is available at https://github.com/Lcrucial1f/MPS-CLIP.",
    "published": "2026-01-26T06:16:53Z",
    "updated": "2026-01-26T06:16:53Z",
    "link": "http://arxiv.org/pdf/2601.18190v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yifan Li",
      "Shiying Wang",
      "Jianqiang Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18172v1",
    "title": "YOLO-DS: Fine-Grained Feature Decoupling via Dual-Statistic Synergy Operator for Object Detection",
    "summary": "One-stage object detection, particularly the YOLO series, strikes a favorable balance between accuracy and efficiency. However, existing YOLO detectors lack explicit modeling of heterogeneous object responses within shared feature channels, which limits further performance gains. To address this, we propose YOLO-DS, a framework built around a novel Dual-Statistic Synergy Operator (DSO). The DSO decouples object features by jointly modeling the channel-wise mean and the peak-to-mean difference. Building upon the DSO, we design two lightweight gating modules: the Dual-Statistic Synergy Gating (DSG) module for adaptive channel-wise feature selection, and the Multi-Path Segmented Gating (MSG) module for depth-wise feature weighting. On the MS-COCO benchmark, YOLO-DS consistently outperforms YOLOv8 across five model scales (N, S, M, L, X), achieving AP gains of 1.1% to 1.7% with only a minimal increase in inference latency. Extensive visualization, ablation, and comparative studies validate the effectiveness of our approach, demonstrating its superior capability in discriminating heterogeneous objects with high efficiency.",
    "published": "2026-01-26T05:50:32Z",
    "updated": "2026-01-26T05:50:32Z",
    "link": "http://arxiv.org/pdf/2601.18172v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Lin Huang",
      "Yujuan Tan",
      "Weisheng Li",
      "Shitai Shan",
      "Liu Liu",
      "Bo Liu",
      "Linlin Shen",
      "Jing Yu",
      "Yue Niu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18168v1",
    "title": "TempDiffReg: Temporal Diffusion Model for Non-Rigid 2D-3D Vascular Registration",
    "summary": "Transarterial chemoembolization (TACE) is a preferred treatment option for hepatocellular carcinoma and other liver malignancies, yet it remains a highly challenging procedure due to complex intra-operative vascular navigation and anatomical variability. Accurate and robust 2D-3D vessel registration is essential to guide microcatheter and instruments during TACE, enabling precise localization of vascular structures and optimal therapeutic targeting. To tackle this issue, we develop a coarse-to-fine registration strategy. First, we introduce a global alignment module, structure-aware perspective n-point (SA-PnP), to establish correspondence between 2D and 3D vessel structures. Second, we propose TempDiffReg, a temporal diffusion model that performs vessel deformation iteratively by leveraging temporal context to capture complex anatomical variations and local structural changes. We collected data from 23 patients and constructed 626 paired multi-frame samples for comprehensive evaluation. Experimental results demonstrate that the proposed method consistently outperforms state-of-the-art (SOTA) methods in both accuracy and anatomical plausibility. Specifically, our method achieves a mean squared error (MSE) of 0.63 mm and a mean absolute error (MAE) of 0.51 mm in registration accuracy, representing 66.7\\% lower MSE and 17.7\\% lower MAE compared to the most competitive existing approaches. It has the potential to assist less-experienced clinicians in safely and efficiently performing complex TACE procedures, ultimately enhancing both surgical outcomes and patient care. Code and data are available at: \\textcolor{blue}{https://github.com/LZH970328/TempDiffReg.git}",
    "published": "2026-01-26T05:40:45Z",
    "updated": "2026-01-26T05:40:45Z",
    "link": "http://arxiv.org/pdf/2601.18168v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zehua Liu",
      "Shihao Zou",
      "Jincai Huang",
      "Yanfang Zhang",
      "Chao Tong",
      "Weixin Si"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18157v1",
    "title": "Agentic Very Long Video Understanding",
    "summary": "The advent of always-on personal AI assistants, enabled by all-day wearable devices such as smart glasses, demands a new level of contextual understanding, one that goes beyond short, isolated events to encompass the continuous, longitudinal stream of egocentric video. Achieving this vision requires advances in long-horizon video understanding, where systems must interpret and recall visual and audio information spanning days or even weeks. Existing methods, including large language models and retrieval-augmented generation, are constrained by limited context windows and lack the ability to perform compositional, multi-hop reasoning over very long video streams. In this work, we address these challenges through EGAgent, an enhanced agentic framework centered on entity scene graphs, which represent people, places, objects, and their relationships over time. Our system equips a planning agent with tools for structured search and reasoning over these graphs, as well as hybrid visual and audio search capabilities, enabling detailed, cross-modal, and temporally coherent reasoning. Experiments on the EgoLifeQA and Video-MME (Long) datasets show that our method achieves state-of-the-art performance on EgoLifeQA (57.5%) and competitive performance on Video-MME (Long) (74.1%) for complex longitudinal video understanding tasks.",
    "published": "2026-01-26T05:20:47Z",
    "updated": "2026-01-26T05:20:47Z",
    "link": "http://arxiv.org/pdf/2601.18157v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Aniket Rege",
      "Arka Sadhu",
      "Yuliang Li",
      "Kejie Li",
      "Ramya Korlakai Vinayak",
      "Yuning Chai",
      "Yong Jae Lee",
      "Hyo Jin Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.00203v2",
    "title": "Beyond Expected Goals: A Probabilistic Framework for Shot Occurrences in Soccer",
    "summary": "Expected goals (xG) models estimate the probability that a shot results in a goal from its context (e.g., location, pressure), but they operate only on observed shots. We propose xG+, a possession-level framework that first estimates the probability that a shot occurs within the next second and its corresponding xG if it were to occur. We also introduce ways to aggregate this joint probability estimate over the course of a possession. By jointly modeling shot-taking behavior and shot quality, xG+ remedies the conditioning-on-shots limitation of standard xG. We show that this improves predictive accuracy at the team level and produces a more persistent player skill signal than standard xG models.",
    "published": "2025-11-28T20:59:29Z",
    "updated": "2026-01-26T18:59:43Z",
    "link": "http://arxiv.org/pdf/2512.00203v2.pdf",
    "category": [
      "stat.AP",
      "cs.LG",
      "eess.IV"
    ],
    "authors": [
      "Jonathan Pipping-Gamón",
      "Tianshu Feng",
      "R. Paul Sabin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.03612v2",
    "title": "Mathematical Foundations of Polyphonic Music Generation via Structural Inductive Bias",
    "summary": "This monograph introduces a novel approach to polyphonic music generation by addressing the \"Missing Middle\" problem through structural inductive bias. Focusing on Beethoven's piano sonatas as a case study, we empirically verify the independence of pitch and hand attributes using normalized mutual information (NMI=0.167) and propose the Smart Embedding architecture, achieving a 48.30% reduction in parameters. We provide rigorous mathematical proofs using information theory (negligible loss bounded at 0.153 bits), Rademacher complexity (28.09% tighter generalization bound), and category theory to demonstrate improved stability and generalization. Empirical results show a 9.47% reduction in validation loss, confirmed by SVD analysis and an expert listening study (N=53). This dual theoretical and applied framework bridges gaps in AI music generation, offering verifiable insights for mathematically grounded deep learning.",
    "published": "2026-01-07T05:40:09Z",
    "updated": "2026-01-26T18:53:22Z",
    "link": "http://arxiv.org/pdf/2601.03612v2.pdf",
    "category": [
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "authors": [
      "Joonwon Seo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18766v1",
    "title": "Learning to Discover: A Generalized Framework for Raga Identification without Forgetting",
    "summary": "Raga identification in Indian Art Music (IAM) remains challenging due to the presence of numerous rarely performed Ragas that are not represented in available training datasets. Traditional classification models struggle in this setting, as they assume a closed set of known categories and therefore fail to recognise or meaningfully group previously unseen Ragas. Recent works have tried categorizing unseen Ragas, but they run into a problem of catastrophic forgetting, where the knowledge of previously seen Ragas is diminished. To address this problem, we adopt a unified learning framework that leverages both labeled and unlabeled audio, enabling the model to discover coherent categories corresponding to the unseen Ragas, while retaining the knowledge of previously known ones. We test our model on benchmark Raga Identification datasets and demonstrate its performance in categorizing previously seen, unseen, and all Raga classes. The proposed approach surpasses the previous NCD-based pipeline even in discovering the unseen Raga categories, offering new insights into representation learning for IAM tasks.",
    "published": "2026-01-26T18:37:30Z",
    "updated": "2026-01-26T18:37:30Z",
    "link": "http://arxiv.org/pdf/2601.18766v1.pdf",
    "category": [
      "eess.AS",
      "cs.LG"
    ],
    "authors": [
      "Parampreet Singh",
      "Somya Kumar",
      "Chaitanya Shailendra Nitawe",
      "Vipul Arora"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.19229v2",
    "title": "Brain-Inspired Perspective on Configurations: Unsupervised Similarity and Early Cognition",
    "summary": "Infants discover categories, detect novelty, and adapt to new contexts without supervision-a challenge for current machine learning. We present a brain-inspired perspective on configurations, a finite-resolution clustering framework that uses a single resolution parameter and attraction-repulsion dynamics to yield hierarchical organization, novelty sensitivity, and flexible adaptation. To evaluate these properties, we introduce mheatmap, which provides proportional heatmaps and reassignment algorithm to fairly assess multi-resolution and dynamic behavior. Across datasets, configurations are competitive on standard clustering metrics, achieve 87% AUC in novelty detection, and show 35% better stability during dynamic category evolution. These results position configurations as a principled computational model of early cognitive categorization and a step toward brain-inspired AI.",
    "published": "2025-10-22T04:28:23Z",
    "updated": "2026-01-26T18:34:12Z",
    "link": "http://arxiv.org/pdf/2510.19229v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Juntang Wang",
      "Yihan Wang",
      "Hao Wu",
      "Dongmian Zou",
      "Shixin Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.18413v2",
    "title": "VoxGuard: Evaluating User and Attribute Privacy in Speech via Membership Inference Attacks",
    "summary": "Voice anonymization aims to conceal speaker identity and attributes while preserving intelligibility, but current evaluations rely almost exclusively on Equal Error Rate (EER) that obscures whether adversaries can mount high-precision attacks. We argue that privacy should instead be evaluated in the low false-positive rate (FPR) regime, where even a small number of successful identifications constitutes a meaningful breach. To this end, we introduce VoxGuard, a framework grounded in differential privacy and membership inference that formalizes two complementary notions: User Privacy, preventing speaker re-identification, and Attribute Privacy, protecting sensitive traits such as gender and accent. Across synthetic and real datasets, we find that informed adversaries, especially those using fine-tuned models and max-similarity scoring, achieve orders-of-magnitude stronger attacks at low-FPR despite similar EER. For attributes, we show that simple transparent attacks recover gender and accent with near-perfect accuracy even after anonymization. Our results demonstrate that EER substantially underestimates leakage, highlighting the need for low-FPR evaluation, and recommend VoxGuard as a benchmark for evaluating privacy leakage.",
    "published": "2025-09-22T20:57:48Z",
    "updated": "2026-01-26T18:23:42Z",
    "link": "http://arxiv.org/pdf/2509.18413v2.pdf",
    "category": [
      "cs.CR",
      "cs.LG"
    ],
    "authors": [
      "Efthymios Tsaprazlis",
      "Thanathai Lertpetchpun",
      "Tiantian Feng",
      "Sai Praneeth Karimireddy",
      "Shrikanth Narayanan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.14485v4",
    "title": "CaTs and DAGs: Integrating Directed Acyclic Graphs with Transformers for Causally Constrained Predictions",
    "summary": "Artificial Neural Networks (ANNs), including fully-connected networks and transformers, are highly flexible and powerful function approximators, widely applied in fields like computer vision and natural language processing. However, their inability to inherently respect causal structures can limit their robustness, making them vulnerable to covariate shift and difficult to interpret/explain. This poses significant challenges for their reliability in real-world applications. In this paper, we introduce Causal Transformers (CaTs), a general model class designed to operate under predefined causal constraints, as specified by a Directed Acyclic Graph (DAG). CaTs retain the powerful function approximation abilities of traditional neural networks while adhering to the underlying structural constraints, improving robustness, reliability, and interpretability at inference time. This approach opens new avenues for deploying neural networks in more demanding, real-world scenarios where robustness and explainability is critical.",
    "published": "2024-10-18T14:10:16Z",
    "updated": "2026-01-26T18:20:32Z",
    "link": "http://arxiv.org/pdf/2410.14485v4.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Matthew J. Vowels",
      "Mathieu Rochat",
      "Sina Akbari"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18736v1",
    "title": "Benchmarking Machine Learning Models for IoT Malware Detection under Data Scarcity and Drift",
    "summary": "The rapid expansion of the Internet of Things (IoT) in domains such as smart cities, transportation, and industrial systems has heightened the urgency of addressing their security vulnerabilities. IoT devices often operate under limited computational resources, lack robust physical safeguards, and are deployed in heterogeneous and dynamic networks, making them prime targets for cyberattacks and malware applications. Machine learning (ML) offers a promising approach to automated malware detection and classification, but practical deployment requires models that are both effective and lightweight. The goal of this study is to investigate the effectiveness of four supervised learning models (Random Forest, LightGBM, Logistic Regression, and a Multi-Layer Perceptron) for malware detection and classification using the IoT-23 dataset. We evaluate model performance in both binary and multiclass classification tasks, assess sensitivity to training data volume, and analyze temporal robustness to simulate deployment in evolving threat landscapes. Our results show that tree-based models achieve high accuracy and generalization, even with limited training data, while performance deteriorates over time as malware diversity increases. These findings underscore the importance of adaptive, resource-efficient ML models for securing IoT systems in real-world environments.",
    "published": "2026-01-26T17:59:33Z",
    "updated": "2026-01-26T17:59:33Z",
    "link": "http://arxiv.org/pdf/2601.18736v1.pdf",
    "category": [
      "cs.LG",
      "cs.NI"
    ],
    "authors": [
      "Jake Lyon",
      "Ehsan Saeedizade",
      "Shamik Sengupta"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18728v1",
    "title": "Riemannian AmbientFlow: Towards Simultaneous Manifold Learning and Generative Modeling from Corrupted Data",
    "summary": "Modern generative modeling methods have demonstrated strong performance in learning complex data distributions from clean samples. In many scientific and imaging applications, however, clean samples are unavailable, and only noisy or linearly corrupted measurements can be observed. Moreover, latent structures, such as manifold geometries, present in the data are important to extract for further downstream scientific analysis. In this work, we introduce Riemannian AmbientFlow, a framework for simultaneously learning a probabilistic generative model and the underlying, nonlinear data manifold directly from corrupted observations. Building on the variational inference framework of AmbientFlow, our approach incorporates data-driven Riemannian geometry induced by normalizing flows, enabling the extraction of manifold structure through pullback metrics and Riemannian Autoencoders. We establish theoretical guarantees showing that, under appropriate geometric regularization and measurement conditions, the learned model recovers the underlying data distribution up to a controllable error and yields a smooth, bi-Lipschitz manifold parametrization. We further show that the resulting smooth decoder can serve as a principled generative prior for inverse problems with recovery guarantees. We empirically validate our approach on low-dimensional synthetic manifolds and on MNIST.",
    "published": "2026-01-26T17:51:52Z",
    "updated": "2026-01-26T17:51:52Z",
    "link": "http://arxiv.org/pdf/2601.18728v1.pdf",
    "category": [
      "cs.LG",
      "math.DG",
      "math.OC",
      "math.ST"
    ],
    "authors": [
      "Willem Diepeveen",
      "Oscar Leong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18710v1",
    "title": "Analyzing Images of Blood Cells with Quantum Machine Learning Methods: Equilibrium Propagation and Variational Quantum Circuits to Detect Acute Myeloid Leukemia",
    "summary": "This paper presents a feasibility study demonstrating that quantum machine learning (QML) algorithms achieve competitive performance on real-world medical imaging despite operating under severe constraints. We evaluate Equilibrium Propagation (EP), an energy-based learning method that does not use backpropagation (incompatible with quantum systems due to state-collapsing measurements) and Variational Quantum Circuits (VQCs) for automated detection of Acute Myeloid Leukemia (AML) from blood cell microscopy images using binary classification (2 classes: AML vs. Healthy).\n  Key Result: Using limited subsets (50-250 samples per class) of the AML-Cytomorphology dataset (18,365 expert-annotated images), quantum methods achieve performance only 12-15% below classical CNNs despite reduced image resolution (64x64 pixels), engineered features (20D), and classical simulation via Qiskit. EP reaches 86.4% accuracy (only 12% below CNN) without backpropagation, while the 4-qubit VQC attains 83.0% accuracy with consistent data efficiency: VQC maintains stable 83% performance with only 50 samples per class, whereas CNN requires 250 samples (5x more data) to reach 98%. These results establish reproducible baselines for QML in healthcare, validating NISQ-era feasibility.",
    "published": "2026-01-26T17:36:19Z",
    "updated": "2026-01-26T17:36:19Z",
    "link": "http://arxiv.org/pdf/2601.18710v1.pdf",
    "category": [
      "cs.ET",
      "cs.LG",
      "quant-ph"
    ],
    "authors": [
      "A. Bano",
      "L. Liebovitch"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18704v1",
    "title": "Data-Driven Qubit Characterization and Optimal Control using Deep Learning",
    "summary": "Quantum computing requires the optimization of control pulses to achieve high-fidelity quantum gates. We propose a machine learning-based protocol to address the challenges of evaluating gradients and modeling complex system dynamics. By training a recurrent neural network (RNN) to predict qubit behavior, our approach enables efficient gradient-based pulse optimization without the need for a detailed system model. First, we sample qubit dynamics using random control pulses with weak prior assumptions. We then train the RNN on the system's observed responses, and use the trained model to optimize high-fidelity control pulses. We demonstrate the effectiveness of this approach through simulations on a single $ST_0$ qubit.",
    "published": "2026-01-26T17:26:20Z",
    "updated": "2026-01-26T17:26:20Z",
    "link": "http://arxiv.org/pdf/2601.18704v1.pdf",
    "category": [
      "quant-ph",
      "cs.LG"
    ],
    "authors": [
      "Paul Surrey",
      "Julian D. Teske",
      "Tobias Hangleiter",
      "Hendrik Bluhm",
      "Pascal Cerfontaine"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.10098v4",
    "title": "Estimating the Joint Probability of Scenario Parameters with Gaussian Mixture Copula Models",
    "summary": "This paper presents the first application of Gaussian Mixture Copula Models to the statistical modeling of driving scenarios for the safety validation of automated driving systems. Knowledge of the joint probability distribution of scenario parameters is essential for scenario-based safety assessment, where risk quantification depends on the likelihood of concrete parameter combinations. Gaussian Mixture Copula Models bring together the multimodal expressivity of Gaussian Mixture Models and the flexibility of copulas, enabling separate modeling of marginal distributions and dependence. We benchmark Gaussian Mixture Copula Models against previously proposed approaches - Gaussian Mixture Models and Gaussian Copula Models - using real-world driving data drawn from two scenarios defined in United Nations Regulation No. 157. Our evaluation on approximately 18 million instances of these two scenarios demonstrates that Gaussian Mixture Copula Models consistently surpass Gaussian Copula Models and perform competitively with Gaussian Mixture Models, as measured by both log-likelihood and Sinkhorn distance, with relative performance depending on the scenario. The results are promising for the adoption of Gaussian Mixture Copula Models as a statistical foundation for future scenario-based validation frameworks.",
    "published": "2025-06-11T18:30:20Z",
    "updated": "2026-01-26T17:24:02Z",
    "link": "http://arxiv.org/pdf/2506.10098v4.pdf",
    "category": [
      "cs.RO",
      "cs.LG"
    ],
    "authors": [
      "Christian Reichenbächer",
      "Philipp Rank",
      "Jochen Hipp",
      "Oliver Bringmann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18696v1",
    "title": "Explainability Methods for Hardware Trojan Detection: A Systematic Comparison",
    "summary": "Hardware trojan detection requires accurate identification and interpretable explanations for security engineers to validate and act on results. This work compares three explainability categories for gate-level trojan detection on the Trust-Hub benchmark: (1) domain-aware property-based analysis of 31 circuit-specific features from gate fanin patterns, flip-flop distances, and I/O connectivity; (2) case-based reasoning using k-nearest neighbors for precedent-based explanations; and (3) model-agnostic feature attribution (LIME, SHAP, gradient).\n  Results show different advantages per approach. Property-based analysis provides explanations through circuit concepts like \"high fanin complexity near outputs indicates potential triggers.\" Case-based reasoning achieves 97.4% correspondence between predictions and training exemplars, offering justifications grounded in precedent. LIME and SHAP provide feature attributions with strong inter-method correlation (r=0.94, p<0.001) but lack circuit-level context for validation.\n  XGBoost classification achieves 46.15% precision and 52.17% recall on 11,392 test samples, a 9-fold precision improvement over prior work (Hasegawa et al.: 5.13%) while reducing false positive rates from 5.6% to 0.25%. Gradient-based attribution runs 481 times faster than SHAP but provides similar domain-opaque insights.\n  This work demonstrates that property-based and case-based approaches offer domain alignment and precedent-based interpretability compared to generic feature rankings, with implications for XAI deployment where practitioners must validate ML predictions.",
    "published": "2026-01-26T17:13:00Z",
    "updated": "2026-01-26T17:13:00Z",
    "link": "http://arxiv.org/pdf/2601.18696v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Paul Whitten",
      "Francis Wolff",
      "Chris Papachristou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.17543v4",
    "title": "Bilateral Distribution Compression: Reducing Both Data Size and Dimensionality",
    "summary": "Existing distribution compression methods reduce dataset size by minimising the Maximum Mean Discrepancy (MMD) between original and compressed sets, but modern datasets are often large in both sample size and dimensionality. We propose Bilateral Distribution Compression (BDC), a two-stage framework that compresses along both axes while preserving the underlying distribution, with overall linear time and memory complexity in dataset size and dimension. Central to BDC is the Decoded MMD (DMMD), which quantifies the discrepancy between the original data and a compressed set decoded from a low-dimensional latent space. BDC proceeds by (i) learning a low-dimensional projection using the Reconstruction MMD (RMMD), and (ii) optimising a latent compressed set with the Encoded MMD (EMMD). We show that this procedure minimises the DMMD, guaranteeing that the compressed set faithfully represents the original distribution. Experiments show that across a variety of scenarios BDC can achieve comparable or superior performance to ambient-space compression at substantially lower cost.",
    "published": "2025-09-22T09:01:52Z",
    "updated": "2026-01-26T17:10:18Z",
    "link": "http://arxiv.org/pdf/2509.17543v4.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "authors": [
      "Dominic Broadbent",
      "Nick Whiteley",
      "Robert Allison",
      "Tom Lovett"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18685v1",
    "title": "LLAMA LIMA: A Living Meta-Analysis on the Effects of Generative AI on Learning Mathematics",
    "summary": "The capabilities of generative AI in mathematics education are rapidly evolving, posing significant challenges for research to keep pace. Research syntheses remain scarce and risk being outdated by the time of publication. To address this issue, we present a Living Meta-Analysis (LIMA) on the effects of generative AI-based interventions for learning mathematics. Following PRISMA-LSR guidelines, we continuously update the literature base, apply a Bayesian multilevel meta-regression model to account for cumulative data, and publish updated versions on a preprint server at regular intervals. This paper reports results from the first version, including 15 studies. The analyses indicate a small positive effect (g = 0.31) with a wide credible interval [0.06, 0.58], reflecting the still limited evidence base.",
    "published": "2026-01-26T17:00:52Z",
    "updated": "2026-01-26T17:00:52Z",
    "link": "http://arxiv.org/pdf/2601.18685v1.pdf",
    "category": [
      "math.HO",
      "cs.LG"
    ],
    "authors": [
      "Anselm Strohmaier",
      "Samira Bödefeld",
      "Frank Reinhold"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18683v1",
    "title": "Learned harmonic mean estimation of the marginal likelihood for multimodal posteriors with flow matching",
    "summary": "The marginal likelihood, or Bayesian evidence, is a crucial quantity for Bayesian model comparison but its computation can be challenging for complex models, even in parameters space of moderate dimension. The learned harmonic mean estimator has been shown to provide accurate and robust estimates of the marginal likelihood simply using posterior samples. It is agnostic to the sampling strategy, meaning that the samples can be obtained using any method. This enables marginal likelihood calculation and model comparison with whatever sampling is most suitable for the task. However, the internal density estimators considered previously for the learned harmonic mean can struggle with highly multimodal posteriors. In this work we introduce flow matching-based continuous normalizing flows as a powerful architecture for the internal density estimation of the learned harmonic mean. We demonstrate the ability to handle challenging multimodal posteriors, including an example in 20 parameter dimensions, showcasing the method's ability to handle complex posteriors without the need for fine-tuning or heuristic modifications to the base distribution.",
    "published": "2026-01-26T17:00:08Z",
    "updated": "2026-01-26T17:00:08Z",
    "link": "http://arxiv.org/pdf/2601.18683v1.pdf",
    "category": [
      "stat.ME",
      "astro-ph.IM",
      "cs.LG"
    ],
    "authors": [
      "Alicja Polanska",
      "Jason D. McEwen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.22048v2",
    "title": "PF$Δ$: A Benchmark Dataset for Power Flow under Load, Generation, and Topology Variations",
    "summary": "Power flow (PF) calculations are the backbone of real-time grid operations, across workflows such as contingency analysis (where repeated PF evaluations assess grid security under outages) and topology optimization (which involves PF-based searches over combinatorially large action spaces). Running these calculations at operational timescales or across large evaluation spaces remains a major computational bottleneck. Additionally, growing uncertainty in power system operations from the integration of renewables and climate-induced extreme weather also calls for tools that can accurately and efficiently simulate a wide range of scenarios and operating conditions. Machine learning methods offer a potential speedup over traditional solvers, but their performance has not been systematically assessed on benchmarks that capture real-world variability. This paper introduces PF$Δ$, a benchmark dataset for power flow that captures diverse variations in load, generation, and topology. PF$Δ$ contains 859,800 solved power flow instances spanning six different bus system sizes, capturing three types of contingency scenarios (N , N -1, and N -2), and including close-to-infeasible cases near steady-state voltage stability limits. We evaluate traditional solvers and GNN-based methods, highlighting key areas where existing approaches struggle, and identifying open problems for future research. Our dataset is available at https://huggingface.co/datasets/pfdelta/pfdelta/tree/main and our code with data generation scripts and model implementations is at https://github.com/MOSSLab-MIT/pfdelta.",
    "published": "2025-10-24T22:09:09Z",
    "updated": "2026-01-26T16:54:28Z",
    "link": "http://arxiv.org/pdf/2510.22048v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Ana K. Rivera",
      "Anvita Bhagavathula",
      "Alvaro Carbonero",
      "Priya Donti"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18677v1",
    "title": "Out-of-Distribution Radar Detection with Complex VAEs: Theory, Whitening, and ANMF Fusion",
    "summary": "We investigate the detection of weak complex-valued signals immersed in non-Gaussian, range-varying interference, with emphasis on maritime radar scenarios. The proposed methodology exploits a Complex-valued Variational AutoEncoder (CVAE) trained exclusively on clutter-plus-noise to perform Out-Of-Distribution detection. By operating directly on in-phase / quadrature samples, the CVAE preserves phase and Doppler structure and is assessed in two configurations: (i) using unprocessed range profiles and (ii) after local whitening, where per-range covariance estimates are obtained from neighboring profiles. Using extensive simulations together with real sea-clutter data from the CSIR maritime dataset, we benchmark performance against classical and adaptive detectors (MF, NMF, AMF-SCM, ANMF-SCM, ANMF-Tyler). In both configurations, the CVAE yields a higher detection probability Pd at matched false-alarm rate Pfa, with the most notable improvements observed under whitening. We further integrate the CVAE with the ANMF through a weighted log-p fusion rule at the decision level, attaining enhanced robustness in strongly non-Gaussian clutter and enabling empirically calibrated Pfa control under H0. Overall, the results demonstrate that statistical normalization combined with complex-valued generative modeling substantively improves detection in realistic sea-clutter conditions, and that the fused CVAE-ANMF scheme constitutes a competitive alternative to established model-based detectors.",
    "published": "2026-01-26T16:51:19Z",
    "updated": "2026-01-26T16:51:19Z",
    "link": "http://arxiv.org/pdf/2601.18677v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Yadang Alexis Rouzoumka",
      "Jean Pinsolle",
      "Eugénie Terreaux",
      "Christèle Morisseau",
      "Jean-Philippe Ovarlez",
      "Chengfang Ren"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18676v1",
    "title": "Quasi Monte Carlo methods enable extremely low-dimensional deep generative models",
    "summary": "This paper introduces quasi-Monte Carlo latent variable models (QLVMs): a class of deep generative models that are specialized for finding extremely low-dimensional and interpretable embeddings of high-dimensional datasets. Unlike standard approaches, which rely on a learned encoder and variational lower bounds, QLVMs directly approximate the marginal likelihood by randomized quasi-Monte Carlo integration. While this brute force approach has drawbacks in higher-dimensional spaces, we find that it excels in fitting one, two, and three dimensional deep latent variable models. Empirical results on a range of datasets show that QLVMs consistently outperform conventional variational autoencoders (VAEs) and importance weighted autoencoders (IWAEs) with matched latent dimensionality. The resulting embeddings enable transparent visualization and post hoc analyses such as nonparametric density estimation, clustering, and geodesic path computation, which are nontrivial to validate in higher-dimensional spaces. While our approach is compute-intensive and struggles to generate fine-scale details in complex datasets, it offers a compelling solution for applications prioritizing interpretability and latent space analysis.",
    "published": "2026-01-26T16:51:03Z",
    "updated": "2026-01-26T16:51:03Z",
    "link": "http://arxiv.org/pdf/2601.18676v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Miles Martinez",
      "Alex H. Williams"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18672v1",
    "title": "A Dynamic Framework for Grid Adaptation in Kolmogorov-Arnold Networks",
    "summary": "Kolmogorov-Arnold Networks (KANs) have recently demonstrated promising potential in scientific machine learning, partly due to their capacity for grid adaptation during training. However, existing adaptation strategies rely solely on input data density, failing to account for the geometric complexity of the target function or metrics calculated during network training. In this work, we propose a generalized framework that treats knot allocation as a density estimation task governed by Importance Density Functions (IDFs), allowing training dynamics to determine grid resolution. We introduce a curvature-based adaptation strategy and evaluate it across synthetic function fitting, regression on a subset of the Feynman dataset and different instances of the Helmholtz PDE, demonstrating that it significantly outperforms the standard input-based baseline. Specifically, our method yields average relative error reductions of 25.3% on synthetic functions, 9.4% on the Feynman dataset, and 23.3% on the PDE benchmark. Statistical significance is confirmed via Wilcoxon signed-rank tests, establishing curvature-based adaptation as a robust and computationally efficient alternative for KAN training.",
    "published": "2026-01-26T16:49:06Z",
    "updated": "2026-01-26T16:49:06Z",
    "link": "http://arxiv.org/pdf/2601.18672v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Spyros Rigas",
      "Thanasis Papaioannou",
      "Panagiotis Trakadas",
      "Georgios Alexandridis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18663v1",
    "title": "Uniform Computability of PAC Learning",
    "summary": "We study uniform computability properties of PAC learning using Weihrauch complexity. We focus on closed concept classes, which are either represented by positive, by negative or by full information. Among other results, we prove that proper PAC learning from positive information is equivalent to the limit operation on Baire space, whereas improper PAC learning from positive information is closely related to Weak Kőnig's Lemma and even equivalent to it, when we have some negative information about the admissible hypotheses. If arbitrary hypotheses are allowed, then improper PAC learning from positive information is still in a finitary DNC range, which implies that it is non-deterministically computable, but does not allow for probabilistic algorithms. These results can also be seen as a classification of the degree of constructivity of the Fundamental Theorem of Statistical Learning. All the aforementioned results hold if an upper bound of the VC dimension is provided as an additional input information. We also study the question of how these results are affected if the VC dimension is not given, but only promised to be finite or if concept classes are represented by negative or full information. Finally, we also classify the complexity of the VC dimension operation itself, which is a problem that is of independent interest. For positive or full information it turns out to be equivalent to the binary sorting problem, for negative information it is equivalent to the jump of sorting. This classification allows also conclusions regarding the Borel complexity of PAC learnability.",
    "published": "2026-01-26T16:39:38Z",
    "updated": "2026-01-26T16:39:38Z",
    "link": "http://arxiv.org/pdf/2601.18663v1.pdf",
    "category": [
      "math.LO",
      "cs.LG",
      "cs.LO"
    ],
    "authors": [
      "Vasco Brattka",
      "Guillaume Chirache"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.21231v3",
    "title": "MiST: Understanding the Role of Mid-Stage Scientific Training in Developing Chemical Reasoning Models",
    "summary": "Large Language Models can develop reasoning capabilities through online fine-tuning with rule-based rewards. However, recent studies reveal a critical constraint: reinforcement learning succeeds only when the base model already assigns non-negligible probability to correct answers -- a property we term 'latent solvability'. This work investigates the emergence of chemical reasoning capabilities and what these prerequisites mean for chemistry. We identify two necessary conditions for RL-based chemical reasoning: 1) Symbolic competence, and 2) Latent chemical knowledge. We propose mid-stage scientific training (MiST): a set of mid-stage training techniques to satisfy these, including data-mixing with SMILES/CIF-aware pre-processing, continued pre-training on 2.9B tokens, and supervised fine-tuning on 1B tokens. These steps raise the latent-solvability score on 3B and 7B models by up to 1.8x, and enable RL to lift top-1 accuracy from 10.9 to 63.9% on organic reaction naming, and from 40.6 to 67.4% on inorganic material generation. Similar results are observed for other challenging chemical tasks, while producing interpretable reasoning traces. Our results define clear prerequisites for chemical reasoning training and highlight the broader role of mid-stage training in unlocking reasoning capabilities.",
    "published": "2025-12-24T15:15:18Z",
    "updated": "2026-01-26T16:31:50Z",
    "link": "http://arxiv.org/pdf/2512.21231v3.pdf",
    "category": [
      "cs.LG",
      "cond-mat.mtrl-sci"
    ],
    "authors": [
      "Andres M Bran",
      "Tong Xie",
      "Shai Pranesh",
      "Jeffrey Meng",
      "Xuan Vu Nguyen",
      "Jeremy Goumaz",
      "David Ming Segura",
      "Ruizhi Xu",
      "Dongzhan Zhou",
      "Wenjie Zhang",
      "Bram Hoex",
      "Philippe Schwaller"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.13001v2",
    "title": "Adaptable Symbolic Music Infilling with MIDI-RWKV",
    "summary": "Existing work in automatic music generation has mostly focused on end-to-end systems that generate either entire compositions or continuations of pieces, which are difficult for composers to iterate on. The area of computer-assisted composition, where generative models integrate into existing creative workflows, remains comparatively underexplored. In this study, we address the tasks of model style adaptation and multi-track, long-context, and controllable symbolic music infilling to enhance the process of computer-assisted composition. We present MIDI-RWKV, a small foundation model based on the RWKV-7 linear architecture, to enable efficient and coherent musical cocreation on edge devices. We also demonstrate that MIDI-RWKV admits an effective method of finetuning its initial state for style adaptation in the very-low-sample regime. We evaluate MIDI-RWKV and its state tuning on several quantitative and qualitative metrics with respect to existing models, and release model weights and code at https://github.com/christianazinn/MIDI-RWKV.",
    "published": "2025-06-16T00:04:01Z",
    "updated": "2026-01-26T16:27:48Z",
    "link": "http://arxiv.org/pdf/2506.13001v2.pdf",
    "category": [
      "cs.SD",
      "cs.LG",
      "cs.MM",
      "eess.AS"
    ],
    "authors": [
      "Christian Zhou-Zheng",
      "Philippe Pasquier"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.22500v2",
    "title": "Dual Optimistic Ascent (PI Control) is the Augmented Lagrangian Method in Disguise",
    "summary": "Constrained optimization is a powerful framework for enforcing requirements on neural networks. These constrained deep learning problems are typically solved using first-order methods on their min-max Lagrangian formulation, but such approaches often suffer from oscillations and can fail to find all local solutions. While the Augmented Lagrangian method (ALM) addresses these issues, practitioners often favor dual optimistic ascent schemes (PI control) on the standard Lagrangian, which perform well empirically but lack formal guarantees. In this paper, we establish a previously unknown equivalence between these approaches: dual optimistic ascent on the Lagrangian is equivalent to gradient descent-ascent on the Augmented Lagrangian. This finding allows us to transfer the robust theoretical guarantees of the ALM to the dual optimistic setting, proving it converges linearly to all local solutions. Furthermore, the equivalence provides principled guidance for tuning the optimism hyper-parameter. Our work closes a critical gap between the empirical success of dual optimistic methods and their theoretical foundation in the single-step, first-order regime commonly used in constrained deep learning.",
    "published": "2025-09-26T15:41:20Z",
    "updated": "2026-01-26T16:22:02Z",
    "link": "http://arxiv.org/pdf/2509.22500v2.pdf",
    "category": [
      "cs.LG",
      "math.OC"
    ],
    "authors": [
      "Juan Ramirez",
      "Simon Lacoste-Julien"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.15765v2",
    "title": "Data Valuation for LLM Fine-Tuning: Efficient Shapley Value Approximation via Language Model Arithmetic",
    "summary": "Data is a critical asset for training large language models (LLMs), alongside compute resources and skilled workers. While some training data is publicly available, substantial investment is required to generate proprietary datasets, such as human preference annotations or to curate new ones from existing sources. As larger datasets generally yield better model performance, two natural questions arise. First, how can data owners make informed decisions about curation strategies and data sources investment? Second, how can multiple data owners collaboratively pool their resources to train superior models while fairly distributing the benefits? This problem, data valuation, which is not specific to large language models, has been addressed by the machine learning community through the lens of cooperative game theory, with the Shapley value being the prevalent solution concept. However, computing Shapley values is notoriously expensive for data valuation, typically requiring numerous model retrainings, which can become prohibitive for large machine learning models. In this work, we demonstrate that this computational challenge is dramatically simplified for LLMs trained with Direct Preference Optimization (DPO). We show how the specific mathematical structure of DPO enables scalable Shapley value computation. We believe this observation unlocks many applications at the intersection of data valuation and large language models.",
    "published": "2025-12-12T10:13:54Z",
    "updated": "2026-01-26T16:21:48Z",
    "link": "http://arxiv.org/pdf/2512.15765v2.pdf",
    "category": [
      "cs.LG",
      "cs.GT",
      "stat.ML"
    ],
    "authors": [
      "Mélissa Tamine",
      "Otmane Sakhi",
      "Benjamin Heymann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.14832v2",
    "title": "How to pick the best anomaly detector?",
    "summary": "Anomaly detection has the potential to discover new physics in unexplored regions of the data. However, choosing the best anomaly detector for a given data set in a model-agnostic way is an important challenge which has hitherto largely been neglected. In this paper, we introduce the data-driven ARGOS metric, which has a sound theoretical foundation and is empirically shown to robustly select the most sensitive anomaly detection model given the data. Focusing on weakly-supervised, classifier-based anomaly detection methods, we show that the ARGOS metric outperforms other model selection metrics previously used in the literature, in particular the binary cross-entropy loss. We explore several realistic applications, including hyperparameter tuning as well as architecture and feature selection, and in all cases we demonstrate that ARGOS is robust to the noisy conditions of anomaly detection.",
    "published": "2025-11-18T19:00:01Z",
    "updated": "2026-01-26T16:20:26Z",
    "link": "http://arxiv.org/pdf/2511.14832v2.pdf",
    "category": [
      "hep-ph",
      "cs.LG",
      "hep-ex",
      "physics.data-an"
    ],
    "authors": [
      "Marie Hein",
      "Gregor Kasieczka",
      "Michael Krämer",
      "Louis Moureaux",
      "Alexander Mück",
      "David Shih"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18640v1",
    "title": "TwinPurify: Purifying gene expression data to reveal tumor-intrinsic transcriptional programs via self-supervised learning",
    "summary": "Advances in single-cell and spatial transcriptomic technologies have transformed tumor ecosystem profiling at cellular resolution. However, large scale studies on patient cohorts continue to rely on bulk transcriptomic data, where variation in tumor purity obscures tumor-intrinsic transcriptional signals and constrains downstream discovery. Many deconvolution methods report strong performance on synthetic bulk mixtures but fail to generalize to real patient cohorts because of unmodeled biological and technical variation.\n  Here, we introduce TwinPurify, a representation learning framework that adapts the Barlow Twins self-supervised objective, representing a fundamental departure from the deconvolution paradigm. Rather than resolving the bulk mixture into discrete cell-type fractions, TwinPurify instead learns continuous, high-dimensional tumor embeddings by leveraging adjacent-normal profiles within the same cohort as \"background\" guidance, enabling the disentanglement of tumor-specific signals without relying on any external reference.\n  Benchmarked against multiple large cancer cohorts across RNA-seq and microarray platforms, TwinPurify outperforms conventional representation learning baselines like auto-encoders in recovering tumor-intrinsic and immune signals. The purified embeddings improve molecular subtype and grade classification, enhance survival model concordance, and uncover biologically meaningful pathway activities compared to raw bulk profiles. By providing a transferable framework for decontaminating bulk transcriptomics, TwinPurify extends the utility of existing clinical datasets for molecular discovery.",
    "published": "2026-01-26T16:11:34Z",
    "updated": "2026-01-26T16:11:34Z",
    "link": "http://arxiv.org/pdf/2601.18640v1.pdf",
    "category": [
      "cs.LG",
      "q-bio.MN"
    ],
    "authors": [
      "Zhiwei Zheng",
      "Kevin Bryson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18638v1",
    "title": "Physics-Informed Uncertainty Enables Reliable AI-driven Design",
    "summary": "Inverse design is a central goal in much of science and engineering, including frequency-selective surfaces (FSS) that are critical to microelectronics for telecommunications and optical metamaterials. Traditional surrogate-assisted optimization methods using deep learning can accelerate the design process but do not usually incorporate uncertainty quantification, leading to poorer optimization performance due to erroneous predictions in data-sparse regions. Here, we introduce and validate a fundamentally different paradigm of Physics-Informed Uncertainty, where the degree to which a model's prediction violates fundamental physical laws serves as a computationally-cheap and effective proxy for predictive uncertainty. By integrating physics-informed uncertainty into a multi-fidelity uncertainty-aware optimization workflow to design complex frequency-selective surfaces within the 20 - 30 GHz range, we increase the success rate of finding performant solutions from less than 10% to over 50%, while simultaneously reducing computational cost by an order of magnitude compared to the sole use of a high-fidelity solver. These results highlight the necessity of incorporating uncertainty quantification in machine-learning-driven inverse design for high-dimensional problems, and establish physics-informed uncertainty as a viable alternative to quantifying uncertainty in surrogate models for physical systems, thereby setting the stage for autonomous scientific discovery systems that can efficiently and robustly explore and evaluate candidate designs.",
    "published": "2026-01-26T16:10:59Z",
    "updated": "2026-01-26T16:10:59Z",
    "link": "http://arxiv.org/pdf/2601.18638v1.pdf",
    "category": [
      "cs.LG",
      "physics.comp-ph"
    ],
    "authors": [
      "Tingkai Xue",
      "Chin Chun Ooi",
      "Yang Jiang",
      "Luu Trung Pham Duong",
      "Pao-Hsiung Chiu",
      "Weijiang Zhao",
      "Nagarajan Raghavan",
      "My Ha Dao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18637v1",
    "title": "Universality of Many-body Projected Ensemble for Learning Quantum Data Distribution",
    "summary": "Generating quantum data by learning the underlying quantum distribution poses challenges in both theoretical and practical scenarios, yet it is a critical task for understanding quantum systems. A fundamental question in quantum machine learning (QML) is the universality of approximation: whether a parameterized QML model can approximate any quantum distribution. We address this question by proving a universality theorem for the Many-body Projected Ensemble (MPE) framework, a method for quantum state design that uses a single many-body wave function to prepare random states. This demonstrates that MPE can approximate any distribution of pure states within a 1-Wasserstein distance error. This theorem provides a rigorous guarantee of universal expressivity, addressing key theoretical gaps in QML. For practicality, we propose an Incremental MPE variant with layer-wise training to improve the trainability. Numerical experiments on clustered quantum states and quantum chemistry datasets validate MPE's efficacy in learning complex quantum data distributions.",
    "published": "2026-01-26T16:10:32Z",
    "updated": "2026-01-26T16:10:32Z",
    "link": "http://arxiv.org/pdf/2601.18637v1.pdf",
    "category": [
      "quant-ph",
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Quoc Hoan Tran",
      "Koki Chinzei",
      "Yasuhiro Endo",
      "Hirotaka Oshima"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2404.06106v2",
    "title": "Unifying Low Dimensional Observations in Deep Learning Through the Deep Linear Unconstrained Feature Model",
    "summary": "Empirical studies have revealed low dimensional structures in the eigenspectra of weights, Hessians, gradients, and feature vectors of deep networks, consistently observed across datasets and architectures in the overparameterized regime. In this work, we analyze deep unconstrained feature models (UFMs) to provide an analytic explanation of how these structures emerge at the layerwise level, including the bulk outlier Hessian spectrum and the alignment of gradient descent with the outlier eigenspace. We show that deep neural collapse underlies these phenomena, deriving explicit expressions for eigenvalues and eigenvectors of many deep learning matrices in terms of class feature means. Furthermore, we demonstrate that the full Hessian inherits its low dimensional structure from the layerwise Hessians, and empirically validate our theory in both UFMs and deep networks.",
    "published": "2024-04-09T08:17:32Z",
    "updated": "2026-01-26T16:10:02Z",
    "link": "http://arxiv.org/pdf/2404.06106v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Connall Garrod",
      "Jonathan P. Keating"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18620v1",
    "title": "CASSANDRA: Programmatic and Probabilistic Learning and Inference for Stochastic World Modeling",
    "summary": "Building world models is essential for planning in real-world domains such as businesses. Since such domains have rich semantics, we can leverage world knowledge to effectively model complex action effects and causal relationships from limited data. In this work, we propose CASSANDRA, a neurosymbolic world modeling approach that leverages an LLM as a knowledge prior to construct lightweight transition models for planning. CASSANDRA integrates two components: (1) LLM-synthesized code to model deterministic features, and (2) LLM-guided structure learning of a probabilistic graphical model to capture causal relationships among stochastic variables. We evaluate CASSANDRA in (i) a small-scale coffee-shop simulator and (ii) a complex theme park business simulator, where we demonstrate significant improvements in transition prediction and planning over baselines.",
    "published": "2026-01-26T15:58:53Z",
    "updated": "2026-01-26T15:58:53Z",
    "link": "http://arxiv.org/pdf/2601.18620v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Panagiotis Lymperopoulos",
      "Abhiramon Rajasekharan",
      "Ian Berlot-Attwell",
      "Stéphane Aroca-Ouellette",
      "Kaheer Suleman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18615v1",
    "title": "Geometry-Free Conditional Diffusion Modeling for Solving the Inverse Electrocardiography Problem",
    "summary": "This paper proposes a data-driven model for solving the inverse problem of electrocardiography, the mathematical problem that forms the basis of electrocardiographic imaging (ECGI). We present a conditional diffusion framework that learns a probabilistic mapping from noisy body surface signals to heart surface electric potentials. The proposed approach leverages the generative nature of diffusion models to capture the non-unique and underdetermined nature of the ECGI inverse problem, enabling probabilistic sampling of multiple reconstructions rather than a single deterministic estimate. Unlike traditional methods, the proposed framework is geometry-free and purely data-driven, alleviating the need for patient-specific mesh construction. We evaluate the method on a real ECGI dataset and compare it against strong deterministic baselines, including a convolutional neural network, long short-term memory network, and transformer-based model. The results demonstrate that the proposed diffusion approach achieves improved reconstruction accuracy, highlighting the potential of diffusion models as a robust tool for noninvasive cardiac electrophysiology imaging.",
    "published": "2026-01-26T15:53:54Z",
    "updated": "2026-01-26T15:53:54Z",
    "link": "http://arxiv.org/pdf/2601.18615v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Ramiro Valdes Jara",
      "Adam Meyers"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18604v1",
    "title": "LaCoGSEA: Unsupervised deep learning for pathway analysis via latent correlation",
    "summary": "Motivation: Pathway enrichment analysis is widely used to interpret gene expression data. Standard approaches, such as GSEA, rely on predefined phenotypic labels and pairwise comparisons, which limits their applicability in unsupervised settings. Existing unsupervised extensions, including single-sample methods, provide pathway-level summaries but primarily capture linear relationships and do not explicitly model gene-pathway associations. More recently, deep learning models have been explored to capture non-linear transcriptomic structure. However, their interpretation has typically relied on generic explainable AI (XAI) techniques designed for feature-level attribution. As these methods are not designed for pathway-level interpretation in unsupervised transcriptomic analyses, their effectiveness in this setting remains limited.\n  Results: To bridge this gap, we introduce LaCoGSEA (Latent Correlation GSEA), an unsupervised framework that integrates deep representation learning with robust pathway statistics. LaCoGSEA employs an autoencoder to capture non-linear manifolds and proposes a global gene-latent correlation metric as a proxy for differential expression, generating dense gene rankings without prior labels. We demonstrate that LaCoGSEA offers three key advantages: (i) it achieves improved clustering performance in distinguishing cancer subtypes compared to existing unsupervised baselines; (ii) it recovers a broader range of biologically meaningful pathways at higher ranks compared with linear dimensionality reduction and gradient-based XAI methods; and (iii) it maintains high robustness and consistency across varying experimental protocols and dataset sizes. Overall, LaCoGSEA provides state-of-the-art performance in unsupervised pathway enrichment analysis.\n  Availability and implementation: https://github.com/willyzzz/LaCoGSEA",
    "published": "2026-01-26T15:45:33Z",
    "updated": "2026-01-26T15:45:33Z",
    "link": "http://arxiv.org/pdf/2601.18604v1.pdf",
    "category": [
      "cs.LG",
      "q-bio.GN"
    ],
    "authors": [
      "Zhiwei Zheng",
      "Kevin Bryson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.20941v2",
    "title": "Revisiting the Past: Data Unlearning with Model State History",
    "summary": "Large language models are trained on massive corpora of web data, which may include private data, copyrighted material, factually inaccurate data, or data that degrades model performance. Eliminating the influence of such problematic datapoints on a model through complete retraining -- by repeatedly pretraining the model on datasets that exclude these specific instances -- is computationally prohibitive. To address this, unlearning algorithms have been proposed, that aim to eliminate the influence of particular datapoints at a low computational cost, while leaving the rest of the model intact. However, precisely unlearning the influence of data on a large language model has proven to be a major challenge. In this work, we propose a new algorithm, MSA (Model State Arithmetic), for unlearning datapoints in large language models. MSA utilizes prior model checkpoints -- artifacts that record model states at different stages of pretraining -- to estimate and counteract the effect of targeted datapoints. Our experimental results show that MSA achieves competitive performance and often outperforms existing machine unlearning algorithms across multiple benchmarks, models, and evaluation metrics, suggesting that MSA could be an effective approach towards more flexible large language models that are capable of data erasure.",
    "published": "2025-06-26T02:16:16Z",
    "updated": "2026-01-26T15:38:28Z",
    "link": "http://arxiv.org/pdf/2506.20941v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Keivan Rezaei",
      "Mehrdad Saberi",
      "Abhilasha Ravichander",
      "Soheil Feizi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18580v1",
    "title": "K-Myriad: Jump-starting reinforcement learning with unsupervised parallel agents",
    "summary": "Parallelization in Reinforcement Learning is typically employed to speed up the training of a single policy, where multiple workers collect experience from an identical sampling distribution. This common design limits the potential of parallelization by neglecting the advantages of diverse exploration strategies. We propose K-Myriad, a scalable and unsupervised method that maximizes the collective state entropy induced by a population of parallel policies. By cultivating a portfolio of specialized exploration strategies, K-Myriad provides a robust initialization for Reinforcement Learning, leading to both higher training efficiency and the discovery of heterogeneous solutions. Experiments on high-dimensional continuous control tasks, with large-scale parallelization, demonstrate that K-Myriad can learn a broad set of distinct policies, highlighting its effectiveness for collective exploration and paving the way towards novel parallelization strategies.",
    "published": "2026-01-26T15:26:40Z",
    "updated": "2026-01-26T15:26:40Z",
    "link": "http://arxiv.org/pdf/2601.18580v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Vincenzo De Paola",
      "Mirco Mutti",
      "Riccardo Zamboni",
      "Marcello Restelli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.22345v2",
    "title": "Uncertainty quantification in model discovery by distilling interpretable material constitutive models from Gaussian process posteriors",
    "summary": "Constitutive model discovery refers to the task of identifying an appropriate model structure, usually from a predefined model library, while simultaneously inferring its material parameters. The data used for model discovery are measured in mechanical tests and are thus inevitably affected by noise which, in turn, induces uncertainties. Previously proposed methods for uncertainty quantification in model discovery either require the selection of a prior for the material parameters, are restricted to linear coefficients of the model library or are limited in the flexibility of the inferred parameter probability distribution. We therefore propose a partially Bayesian framework for uncertainty quantification in model discovery that does not require prior selection for the material parameters and also allows for the discovery of constitutive models with inner-non-linear parameters: First, we augment the available stress-deformation data with a Gaussian process. Second, we approximate the parameter distribution by a normalizing flow, which allows for modeling complex joint distributions. Third, we distill the parameter distribution by matching the distribution of stress-deformation functions induced by the parameters with the Gaussian process posterior. Fourth, we perform a Sobol' sensitivity analysis to obtain a sparse and interpretable model. We demonstrate the capability of our framework for both isotropic and experimental anisotropic data.",
    "published": "2025-10-25T16:02:03Z",
    "updated": "2026-01-26T14:59:21Z",
    "link": "http://arxiv.org/pdf/2510.22345v2.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "David Anton",
      "Henning Wessels",
      "Ulrich Römer",
      "Alexander Henkes",
      "Jorge-Humberto Urrea-Quintero"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18546v1",
    "title": "Information Hidden in Gradients of Regression with Target Noise",
    "summary": "Second-order information -- such as curvature or data covariance -- is critical for optimisation, diagnostics, and robustness. However, in many modern settings, only the gradients are observable. We show that the gradients alone can reveal the Hessian, equalling the data covariance $Σ$ for the linear regression. Our key insight is a simple variance calibration: injecting Gaussian noise so that the total target noise variance equals the batch size ensures that the empirical gradient covariance closely approximates the Hessian, even when evaluated far from the optimum. We provide non-asymptotic operator-norm guarantees under sub-Gaussian inputs. We also show that without such calibration, recovery can fail by an $Ω(1)$ factor. The proposed method is practical (a \"set target-noise variance to $n$\" rule) and robust (variance $\\mathcal{O}(n)$ suffices to recover $Σ$ up to scale). Applications include preconditioning for faster optimisation, adversarial risk estimation, and gradient-only training, for example, in distributed systems. We support our theoretical results with experiments on synthetic and real data.",
    "published": "2026-01-26T14:50:16Z",
    "updated": "2026-01-26T14:50:16Z",
    "link": "http://arxiv.org/pdf/2601.18546v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Arash Jamshidi",
      "Katsiaryna Haitsiukevich",
      "Kai Puolamäki"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.12540v4",
    "title": "Harnessing the Universal Geometry of Embeddings",
    "summary": "We introduce the first method for translating text embeddings from one vector space to another without any paired data, encoders, or predefined sets of matches. Our unsupervised approach translates any embedding to and from a universal latent representation (i.e., a universal semantic structure conjectured by the Platonic Representation Hypothesis). Our translations achieve high cosine similarity across model pairs with different architectures, parameter counts, and training datasets.\n  The ability to translate unknown embeddings into a different space while preserving their geometry has serious implications for the security of vector databases. An adversary with access only to embedding vectors can extract sensitive information about the underlying documents, sufficient for classification and attribute inference.",
    "published": "2025-05-18T20:37:07Z",
    "updated": "2026-01-26T14:47:13Z",
    "link": "http://arxiv.org/pdf/2505.12540v4.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Rishi Jha",
      "Collin Zhang",
      "Vitaly Shmatikov",
      "John X. Morris"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18524v1",
    "title": "From Human Labels to Literature: Semi-Supervised Learning of NMR Chemical Shifts at Scale",
    "summary": "Accurate prediction of nuclear magnetic resonance (NMR) chemical shifts is fundamental to spectral analysis and molecular structure elucidation, yet existing machine learning methods rely on limited, labor-intensive atom-assigned datasets. We propose a semi-supervised framework that learns NMR chemical shifts from millions of literature-extracted spectra without explicit atom-level assignments, integrating a small amount of labeled data with large-scale unassigned spectra. We formulate chemical shift prediction from literature spectra as a permutation-invariant set supervision problem, and show that under commonly satisfied conditions on the loss function, optimal bipartite matching reduces to a sorting-based loss, enabling stable large-scale semi-supervised training beyond traditional curated datasets. Our models achieve substantially improved accuracy and robustness over state-of-the-art methods and exhibit stronger generalization on significantly larger and more diverse molecular datasets. Moreover, by incorporating solvent information at scale, our approach captures systematic solvent effects across common NMR solvents for the first time. Overall, our results demonstrate that large-scale unlabeled spectra mined from the literature can serve as a practical and effective data source for training NMR shift models, suggesting a broader role of literature-derived, weakly structured data in data-centric AI for science.",
    "published": "2026-01-26T14:35:25Z",
    "updated": "2026-01-26T14:35:25Z",
    "link": "http://arxiv.org/pdf/2601.18524v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Yongqi Jin",
      "Yecheng Wang",
      "Jun-jie Wang",
      "Rong Zhu",
      "Guolin Ke",
      "Weinan E"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.12070v4",
    "title": "Emergence of Quantised Representations Isolated to Anisotropic Functions",
    "summary": "Presented is a novel methodology for determining representational structure, which builds upon the existing Spotlight Resonance method. This new tool is used to gain insight into how discrete representations can emerge and organise in autoencoder models, through a controlled ablation study that alters only the activation function. Using this technique, the validity of whether function-driven symmetries can act as implicit inductive biases on representations is determined. Representations are found to tend to discretise when the activation functions are defined through a discrete algebraic permutation-equivariant symmetry. In contrast, they remain continuous under a continuous algebraic orthogonal-equivariant definition. This confirms the hypothesis that the symmetries of network primitives can carry unintended inductive biases, leading to task-independent artefactual structures in representations. The discrete symmetry of contemporary forms is shown to be a strong predictor for the production of symmetry-organised discrete representations emerging from otherwise continuous distributions -- a quantisation effect. This motivates further reassessment of functional forms in common usage due to such unintended consequences. Moreover, this supports a general causal model for a mode in which discrete representations may form, and could constitute a prerequisite for downstream interpretability phenomena, including grandmother neurons, discrete coding schemes, general linear features and a type of Superposition. Hence, this tool and proposed mechanism for the influence of functional form on representations may provide insights into interpretability research. Finally, preliminary results indicate that quantisation of representations correlates with a measurable increase in reconstruction error, reinforcing previous conjectures that this collapse can be detrimental.",
    "published": "2025-07-16T09:27:54Z",
    "updated": "2026-01-26T14:19:44Z",
    "link": "http://arxiv.org/pdf/2507.12070v4.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "George Bird"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18513v1",
    "title": "LipNeXt: Scaling up Lipschitz-based Certified Robustness to Billion-parameter Models",
    "summary": "Lipschitz-based certification offers efficient, deterministic robustness guarantees but has struggled to scale in model size, training efficiency, and ImageNet performance. We introduce \\emph{LipNeXt}, the first \\emph{constraint-free} and \\emph{convolution-free} 1-Lipschitz architecture for certified robustness. LipNeXt is built using two techniques: (1) a manifold optimization procedure that updates parameters directly on the orthogonal manifold and (2) a \\emph{Spatial Shift Module} to model spatial pattern without convolutions. The full network uses orthogonal projections, spatial shifts, a simple 1-Lipschitz $β$-Abs nonlinearity, and $L_2$ spatial pooling to maintain tight Lipschitz control while enabling expressive feature mixing. Across CIFAR-10/100 and Tiny-ImageNet, LipNeXt achieves state-of-the-art clean and certified robust accuracy (CRA), and on ImageNet it scales to 1-2B large models, improving CRA over prior Lipschitz models (e.g., up to $+8\\%$ at $\\varepsilon{=}1$) while retaining efficient, stable low-precision training. These results demonstrate that Lipschitz-based certification can benefit from modern scaling trends without sacrificing determinism or efficiency.",
    "published": "2026-01-26T14:18:55Z",
    "updated": "2026-01-26T14:18:55Z",
    "link": "http://arxiv.org/pdf/2601.18513v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Kai Hu",
      "Haoqi Hu",
      "Matt Fredrikson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18509v1",
    "title": "Conformal Prediction Algorithms for Time Series Forecasting: Methods and Benchmark",
    "summary": "Reliable uncertainty quantification is of critical importance in time series forecasting, yet traditional methods often rely on restrictive distributional assumptions. Conformal prediction (CP) has emerged as a promising distribution-free framework for generating prediction intervals with rigorous theoretical guarantees. However, applying CP to sequential data presents a primary challenge: the temporal dependencies inherent in time series fundamentally violate the core assumption of data exchangeability, upon which standard CP guarantees are built. This review critically examines the main categories of algorithmic solutions designed to address this conflict. We survey and benchmark methods that relax the exchangeability assumption, those that redefine the data unit to be a collection of independent time series, approaches that explicitly model the dynamics of the prediction residuals, and online learning algorithms that adapt to distribution shifts to maintain long-run coverage. By synthesizing these approaches, we highlight computational efficiency and practical performance on real-world data.",
    "published": "2026-01-26T14:15:08Z",
    "updated": "2026-01-26T14:15:08Z",
    "link": "http://arxiv.org/pdf/2601.18509v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Andro Sabashvili"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.14308v3",
    "title": "Improving the Accuracy of Amortized Model Comparison with Self-Consistency",
    "summary": "Amortized Bayesian inference (ABI) offers fast, scalable approximations to posterior densities by training neural surrogates on data simulated from the statistical model. However, ABI methods are highly sensitive to model misspecification: when observed data fall outside the training distribution (generative scope of the statistical models), neural surrogates can behave unpredictably. This makes it a challenge in a model comparison setting, where multiple statistical models are considered, of which at least some are misspecified. Recent work on self-consistency (SC) provides a promising remedy to this issue, accessible even for empirical data (without ground-truth labels). In this work, we investigate how SC can improve amortized model comparison conceptualized in four different ways. Across two synthetic and two real-world case studies, we find that approaches for model comparison that estimate marginal likelihoods through approximate parameter posteriors consistently outperform methods that directly approximate model evidence or posterior model probabilities. SC training improves robustness when the likelihood is available, even under severe model misspecification. The benefits of SC for methods without access of analytic likelihoods are more limited and inconsistent. Our results suggest practical guidance for reliable amortized Bayesian model comparison: prefer parameter posterior-based methods and augment them with SC training on empirical datasets to mitigate extrapolation bias under model misspecification.",
    "published": "2025-12-16T11:25:40Z",
    "updated": "2026-01-26T14:12:31Z",
    "link": "http://arxiv.org/pdf/2512.14308v3.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "stat.CO"
    ],
    "authors": [
      "Šimon Kucharský",
      "Aayush Mishra",
      "Daniel Habermann",
      "Stefan T. Radev",
      "Paul-Christian Bürkner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18500v1",
    "title": "Nearly Optimal Bayesian Inference for Structural Missingness",
    "summary": "Structural missingness breaks 'just impute and train': values can be undefined by causal or logical constraints, and the mask may depend on observed variables, unobserved variables (MNAR), and other missingness indicators. It simultaneously brings (i) a catch-22 situation with causal loop, prediction needs the missing features, yet inferring them depends on the missingness mechanism, (ii) under MNAR, the unseen are different, the missing part can come from a shifted distribution, and (iii) plug-in imputation, a single fill-in can lock in uncertainty and yield overconfident, biased decisions. In the Bayesian view, prediction via the posterior predictive distribution integrates over the full model posterior uncertainty, rather than relying on a single point estimate. This framework decouples (i) learning an in-model missing-value posterior from (ii) label prediction by optimizing the predictive posterior distribution, enabling posterior integration. This decoupling yields an in-model almost-free-lunch: once the posterior is learned, prediction is plug-and-play while preserving uncertainty propagation. It achieves SOTA on 43 classification and 15 imputation benchmarks, with finite-sample near Bayes-optimality guarantees under our SCM prior.",
    "published": "2026-01-26T14:03:11Z",
    "updated": "2026-01-26T14:03:11Z",
    "link": "http://arxiv.org/pdf/2601.18500v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Chen Liang",
      "Donghua Yang",
      "Yutong Wang",
      "Tianle Zhang",
      "Shenghe Zhou",
      "Zhiyu Liang",
      "Hengtong Zhang",
      "Hongzhi Wang",
      "Ziqi Li",
      "Xiyang Zhang",
      "Zheng Liang",
      "Yifei Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.03384v2",
    "title": "Solving stochastic partial differential equations using neural networks in the Wiener chaos expansion",
    "summary": "In this paper, we solve stochastic partial differential equations (SPDEs) numerically by using (possibly random) neural networks in the truncated Wiener chaos expansion of their corresponding solution. Moreover, we provide some approximation rates for learning the solution of SPDEs with additive and/or multiplicative noise. Finally, we apply our results in numerical examples to approximate the solution of three SPDEs: the stochastic heat equation, the Heath-Jarrow-Morton equation, and the Zakai equation.",
    "published": "2024-11-05T18:11:25Z",
    "updated": "2026-01-26T13:43:30Z",
    "link": "http://arxiv.org/pdf/2411.03384v2.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "math.NA",
      "math.PR"
    ],
    "authors": [
      "Ariel Neufeld",
      "Philipp Schmocker"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18479v1",
    "title": "Enhancing Control Policy Smoothness by Aligning Actions with Predictions from Preceding States",
    "summary": "Deep reinforcement learning has proven to be a powerful approach to solving control tasks, but its characteristic high-frequency oscillations make it difficult to apply in real-world environments. While prior methods have addressed action oscillations via architectural or loss-based methods, the latter typically depend on heuristic or synthetic definitions of state similarity to promote action consistency, which often fail to accurately reflect the underlying system dynamics. In this paper, we propose a novel loss-based method by introducing a transition-induced similar state. The transition-induced similar state is defined as the distribution of next states transitioned from the previous state. Since it utilizes only environmental feedback and actually collected data, it better captures system dynamics. Building upon this foundation, we introduce Action Smoothing by Aligning Actions with Predictions from Preceding States (ASAP), an action smoothing method that effectively mitigates action oscillations. ASAP enforces action smoothness by aligning the actions with those taken in transition-induced similar states and by penalizing second-order differences to suppress high-frequency oscillations. Experiments in Gymnasium and Isaac-Lab environments demonstrate that ASAP yields smoother control and improved policy performance over existing methods.",
    "published": "2026-01-26T13:34:34Z",
    "updated": "2026-01-26T13:34:34Z",
    "link": "http://arxiv.org/pdf/2601.18479v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Kyoleen Kwak",
      "Hyoseok Hwang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.11594v2",
    "title": "Multi-Scale Negative Coupled Information Systems (MNCIS): A Unified Spectral Topology Framework for Stability in Turbulence, AI, and Biology",
    "summary": "Complex dynamical systems frequently encounter a recurrent structural instability: the collapse of the spectral gap, driving the system toward a low-dimensional \"Zero-Mode Attractor\" (e.g., spectral pile-up or over-smoothing). Building upon recent global well-posedness estimates [Hou, arXiv:2601.00638], this work generalizes the Multi-Scale Negative Coupled Information System (MNCIS) framework. We postulate that global stability requires an active topological operator - Adaptive Spectral Negative Coupling (ASNC) - functioning as a state-dependent high-pass filter that penalizes entropy accumulation at spectral boundaries. We validate this unified framework via three implementations: (1) Hydrodynamics: In 3D Navier-Stokes turbulence ($N=256^3$), ASNC acts as a global-enstrophy adaptive sub-grid scale (SGS) model, stabilizing the inviscid limit and preserving the Kolmogorov $-5/3$ inertial range without artificial hyper-viscosity. Crucially, we verify that the operator remains dormant ($γ\\approx 0$) during the linear growth phase of physical instabilities, functioning strictly as a conditional topological clamp. (2) Artificial Intelligence: Addressing Over-smoothing in Graph Neural Networks (GNNs), we implement ASNC as a parameter-free topological constraint. Unlike baselines (e.g., DeepGCNs) relying on dense residual connections, our framework enables the training of ultra-deep 64-layer networks without residual connections, maintaining perfectly stationary feature variance ($σ^2 \\equiv 1.0$) on the ogbn-arxiv benchmark. (3) Biological Physics: In reaction-diffusion morphogenesis, it stabilizes Turing patterns against diffusive washout in high-entropy regimes. Our results suggest that the MNCIS framework provides a base-independent topological condition for distinguishing viable complex systems from those collapsing into thermal equilibrium.",
    "published": "2026-01-06T21:11:33Z",
    "updated": "2026-01-26T12:36:53Z",
    "link": "http://arxiv.org/pdf/2601.11594v2.pdf",
    "category": [
      "physics.comp-ph",
      "cs.LG",
      "nlin.AO",
      "physics.bio-ph"
    ],
    "authors": [
      "Pengyue Hou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18424v1",
    "title": "Fusion of Spatio-Temporal and Multi-Scale Frequency Features for Dry Electrodes MI-EEG Decoding",
    "summary": "Dry-electrode Motor Imagery Electroencephalography (MI-EEG) enables fast, comfortable, real-world Brain Computer Interface by eliminating gels and shortening setup for at-home and wearable use.However, dry recordings pose three main issues: lower Signal-to-Noise Ratio with more baseline drift and sudden transients; weaker and noisier data with poor phase alignment across trials; and bigger variances between sessions. These drawbacks lead to larger data distribution shift, making features less stable for MI-EEG tasks.To address these problems, we introduce STGMFM, a tri-branch framework tailored for dry-electrode MI-EEG, which models complementary spatio-temporal dependencies via dual graph orders, and captures robust envelope dynamics with a multi-scale frequency mixing branch, motivated by the observation that amplitude envelopes are less sensitive to contact variability than instantaneous waveforms. Physiologically meaningful connectivity priors guide learning, and decision-level fusion consolidates a noise-tolerant consensus. On our collected dry-electrode MI-EEG, STGMFM consistently surpasses competitive CNN/Transformer/graph baselines. Codes are available at https://github.com/Tianyi-325/STGMFM.",
    "published": "2026-01-26T12:35:23Z",
    "updated": "2026-01-26T12:35:23Z",
    "link": "http://arxiv.org/pdf/2601.18424v1.pdf",
    "category": [
      "cs.HC",
      "cs.LG"
    ],
    "authors": [
      "Tianyi Gong",
      "Can Han",
      "Junxi Wu",
      "Dahong Qian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18409v1",
    "title": "Frequency-Based Hyperparameter Selection in Games",
    "summary": "Learning in smooth games fundamentally differs from standard minimization due to rotational dynamics, which invalidate classical hyperparameter tuning strategies. Despite their practical importance, effective methods for tuning in games remain underexplored. A notable example is LookAhead (LA), which achieves strong empirical performance but introduces additional parameters that critically influence performance. We propose a principled approach to hyperparameter selection in games by leveraging frequency estimation of oscillatory dynamics. Specifically, we analyze oscillations both in continuous-time trajectories and through the spectrum of the discrete dynamics in the associated frequency-based space. Building on this analysis, we introduce \\emph{Modal LookAhead (MoLA)}, an extension of LA that selects the hyperparameters adaptively to a given problem. We provide convergence guarantees and demonstrate in experiments that MoLA accelerates training in both purely rotational games and mixed regimes, all with minimal computational overhead.",
    "published": "2026-01-26T12:06:59Z",
    "updated": "2026-01-26T12:06:59Z",
    "link": "http://arxiv.org/pdf/2601.18409v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Aniket Sanyal",
      "Baraah A. M. Sidahmed",
      "Rebekka Burkholz",
      "Tatjana Chavdarova"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18401v1",
    "title": "Superlinear Multi-Step Attention",
    "summary": "In this paper, we propose \\textbf{Superlinear attention}, a fully trainable multi-step attention architecture that achieves subquadratic complexity for long sequences while preserving \\textbf{random context access} (a.k.a.\\ structural non-exclusion): no eligible token position is structurally excluded from being selected for attention. Superlinear attention reformulates standard causal self-attention as a multi-step search problem with $N$ steps, yielding an overall complexity of $O(L^{1+\\frac{1}{N}})$. To illustrate the architecture, we present a baseline $N=2$ implementation, which is algorithmically analogous to standard jump search. In this $O(L^{3/2})$ instantiation, the first step performs $O(L^{3/2})$ span-search to select relevant spans of the sequence, and the second step applies $O(L^{3/2})$ span-attention (standard attention restricted to the selected spans). In an upscaled $O(L^{1.54})$ configuration for robustness, we achieve an average decoding throughput of 114 tokens/sec at 1M context length and 80 tokens/sec at 10M context in our implementation on a modified 30B hybrid MoE model on a single B200 GPU. With limited training, we also obtain strong performance on the NIAH (Needle In A Haystack) task up to 256K context length, demonstrating that the routed span selection is learnable end-to-end. This paper emphasizes architectural formulation, scaling analysis, and systems feasibility, and presents initial validation; comprehensive quality evaluations across diverse long-context tasks are left to future work.",
    "published": "2026-01-26T11:58:42Z",
    "updated": "2026-01-26T11:58:42Z",
    "link": "http://arxiv.org/pdf/2601.18401v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Yufeng Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.03097v2",
    "title": "A Computational Transition for Detecting Multivariate Shuffled Linear Regression by Low-Degree Polynomials",
    "summary": "In this paper, we study the problem of multivariate shuffled linear regression, where the correspondence between predictors and responses in a linear model is obfuscated by a latent permutation. Specifically, we investigate the model $Y=\\tfrac{1}{\\sqrt{1+σ^2}}(Π_* X Q_* + σZ)$, where $X$ is an $n*d$ standard Gaussian design matrix, $Z$ is an $n*m$ Gaussian noise matrix, $Π_*$ is an unknown $n*n$ permutation matrix, and $Q_*$ is an unknown $d*m$ on the Grassmanian manifold satisfying $Q_*^{\\top} Q_* = \\mathbb I_m$.\n  Consider the hypothesis testing problem of distinguishing this model from the case where $X$ and $Y$ are independent Gaussian random matrices of sizes $n*d$ and $n*m$, respectively. Our results reveal a phase transition phenomenon in the performance of low-degree polynomial algorithms for this task. (1) When $m=o(d)$, we show that all degree-$D$ polynomials fail to distinguish these two models even when $σ=0$, provided with $D^4=o\\big( \\tfrac{d}{m} \\big)$. (2) When $m=d$ and $σ=ω(1)$, we show that all degree-$D$ polynomials fail to distinguish these two models provided with $D=o(σ)$. (3) When $m=d$ and $σ=o(1)$, we show that there exists a constant-degree polynomial that strongly distinguish these two models. These results establish a smooth transition in the effectiveness of low-degree polynomial algorithms for this problem, highlighting the interplay between the dimensions $m$ and $d$, the noise level $σ$, and the computational complexity of the testing task.",
    "published": "2025-04-04T00:32:38Z",
    "updated": "2026-01-26T11:58:09Z",
    "link": "http://arxiv.org/pdf/2504.03097v2.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "math.PR",
      "math.ST"
    ],
    "authors": [
      "Zhangsong Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18399v1",
    "title": "Estimating Dense-Packed Zone Height in Liquid-Liquid Separation: A Physics-Informed Neural Network Approach",
    "summary": "Separating liquid-liquid dispersions in gravity settlers is critical in chemical, pharmaceutical, and recycling processes. The dense-packed zone height is an important performance and safety indicator but it is often expensive and impractical to measure due to optical limitations. We propose to estimate phase heights using only inexpensive volume flow measurements. To this end, a physics-informed neural network (PINN) is first pretrained on synthetic data and physics equations derived from a low-fidelity (approximate) mechanistic model to reduce the need for extensive experimental data. While the mechanistic model is used to generate synthetic training data, only volume balance equations are used in the PINN, since the integration of submodels describing droplet coalescence and sedimentation into the PINN would be computationally prohibitive. The pretrained PINN is then fine-tuned with scarce experimental data to capture the actual dynamics of the separator. We then employ the differentiable PINN as a predictive model in an Extended Kalman Filter inspired state estimation framework, enabling the phase heights to be tracked and updated from flow-rate measurements. We first test the two-stage trained PINN by forward simulation from a known initial state against the mechanistic model and a non-pretrained PINN. We then evaluate phase height estimation performance with the filter, comparing the two-stage trained PINN with a two-stage trained purely data-driven neural network. All model types are trained and evaluated using ensembles to account for model parameter uncertainty. In all evaluations, the two-stage trained PINN yields the most accurate phase-height estimates.",
    "published": "2026-01-26T11:57:28Z",
    "updated": "2026-01-26T11:57:28Z",
    "link": "http://arxiv.org/pdf/2601.18399v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Mehmet Velioglu",
      "Song Zhai",
      "Alexander Mitsos",
      "Adel Mhamdi",
      "Andreas Jupke",
      "Manuel Dahmen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.02380v4",
    "title": "EntroLLM: Entropy Encoded Weight Compression for Efficient Large Language Model Inference on Edge Devices",
    "summary": "Large Language Models (LLMs) achieve strong performance across tasks, but face storage and compute challenges on edge devices. We propose EntroLLM, a compression framework combining mixed quantization and entropy coding to reduce storage while preserving accuracy. We use a combination of unsigned and asymmetric quantization. Tensor-level quantization produces an entropy-reducing effect, increasing weight compressibility, and improving downstream Huffman encoding by $7\\times$ (8-bit) and $11.3\\times$ (4-bit) over state-of-the-art methods. Huffman coding further reduces memory bandwidth demands, while a parallel decoding strategy enables efficient weight retrieval with minimal latency. Experiments on edge-scale LLMs (smolLM-1.7B, phi3-mini-4k, mistral-7B) show up to $30\\%$ storage savings over uint8 and $65\\%$ over uint4 models, with $31.9-146.6\\%$ faster inference on memory-limited devices like the NVIDIA JETSON P3450. EntroLLM requires no retraining and is compatible with existing post-training quantization pipelines, making it practical for edge LLM deployment.",
    "published": "2025-05-05T05:42:14Z",
    "updated": "2026-01-26T11:44:39Z",
    "link": "http://arxiv.org/pdf/2505.02380v4.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Arnab Sanyal",
      "Gourav Datta",
      "Prithwish Mukherjee",
      "Sandeep P. Chinchali",
      "Michael Orshansky"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18356v1",
    "title": "Making medical vision-language models think causally across modalities with retrieval-augmented cross-modal reasoning",
    "summary": "Medical vision-language models (VLMs) achieve strong performance in diagnostic reporting and image-text alignment, yet their underlying reasoning mechanisms remain fundamentally correlational, exhibiting reliance on superficial statistical associations that fail to capture the causal pathophysiological mechanisms central to clinical decision-making. This limitation makes them fragile, prone to hallucinations, and sensitive to dataset biases. Retrieval-augmented generation (RAG) offers a partial remedy by grounding predictions in external knowledge. However, conventional RAG depends on semantic similarity, introducing new spurious correlations. We propose Multimodal Causal Retrieval-Augmented Generation, a framework that integrates causal inference principles with multimodal retrieval. It retrieves clinically relevant exemplars and causal graphs from external sources, conditioning model reasoning on counterfactual and interventional evidence rather than correlations alone. Applied to radiology report generation, diagnosis prediction, and visual question answering, it improves factual accuracy, robustness to distribution shifts, and interpretability. Our results highlight causal retrieval as a scalable path toward medical VLMs that think beyond pattern matching, enabling trustworthy multimodal reasoning in high-stakes clinical settings.",
    "published": "2026-01-26T11:03:00Z",
    "updated": "2026-01-26T11:03:00Z",
    "link": "http://arxiv.org/pdf/2601.18356v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Weiqin Yang",
      "Haowen Xue",
      "Qingyi Peng",
      "Hexuan Hu",
      "Qian Huang",
      "Tingbo Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2405.10360v2",
    "title": "Adversarial Robustness Guarantees for Quantum Classifiers",
    "summary": "Despite their ever more widespread deployment throughout society, machine learning algorithms remain critically vulnerable to being spoofed by subtle adversarial tampering with their input data. The prospect of near-term quantum computers being capable of running {quantum machine learning} (QML) algorithms has therefore generated intense interest in their adversarial vulnerability. Here we show that quantum properties of QML algorithms can confer fundamental protections against such attacks, in certain scenarios guaranteeing robustness against classically-armed adversaries. We leverage tools from many-body physics to identify the quantum sources of this protection. Our results offer a theoretical underpinning of recent evidence which suggest quantum advantages in the search for adversarial robustness. In particular, we prove that quantum classifiers are: (i) protected against weak perturbations of data drawn from the trained distribution, (ii) protected against local attacks if they are insufficiently scrambling, and (iii) show evidence that they are protected against universal adversarial attacks if they are sufficiently chaotic. Our analytic results are supported by numerical evidence demonstrating the applicability of our theorems and the resulting robustness of a quantum classifier in practice. This line of inquiry constitutes a concrete pathway to advantage in QML, orthogonal to the usually sought improvements in model speed or accuracy.",
    "published": "2024-05-16T18:00:01Z",
    "updated": "2026-01-26T10:52:29Z",
    "link": "http://arxiv.org/pdf/2405.10360v2.pdf",
    "category": [
      "quant-ph",
      "cond-mat.stat-mech",
      "cs.LG",
      "nlin.CD"
    ],
    "authors": [
      "Neil Dowling",
      "Maxwell T. West",
      "Angus Southwell",
      "Azar C. Nakhl",
      "Martin Sevior",
      "Muhammad Usman",
      "Kavan Modi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18342v1",
    "title": "Structural Gender Bias in Credit Scoring: Proxy Leakage",
    "summary": "As financial institutions increasingly adopt machine learning for credit risk assessment, the persistence of algorithmic bias remains a critical barrier to equitable financial inclusion. This study provides a comprehensive audit of structural gender bias within the Taiwan Credit Default dataset, specifically challenging the prevailing doctrine of \"fairness through blindness.\" Despite the removal of explicit protected attributes and the application of industry standard fairness interventions, our results demonstrate that gendered predictive signals remain deeply embedded within non-sensitive features. Utilizing SHAP (SHapley Additive exPlanations), we identify that variables such as Marital Status, Age, and Credit Limit function as potent proxies for gender, allowing models to maintain discriminatory pathways while appearing statistically fair. To mathematically quantify this leakage, we employ an adversarial inverse modeling framework. Our findings reveal that the protected gender attribute can be reconstructed from purely non-sensitive financial features with an ROC AUC score of 0.65, demonstrating that traditional fairness audits are insufficient for detecting implicit structural bias. These results advocate for a shift from surface-level statistical parity toward causal-aware modeling and structural accountability in financial AI.",
    "published": "2026-01-26T10:29:45Z",
    "updated": "2026-01-26T10:29:45Z",
    "link": "http://arxiv.org/pdf/2601.18342v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Navya SD",
      "Sreekanth D",
      "SS Uma Sankari"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18339v1",
    "title": "A Dataset for Automatic Vocal Mode Classification",
    "summary": "The Complete Vocal Technique (CVT) is a school of singing developed in the past decades by Cathrin Sadolin et al.. CVT groups the use of the voice into so called vocal modes, namely Neutral, Curbing, Overdrive and Edge. Knowledge of the desired vocal mode can be helpful for singing students. Automatic classification of vocal modes can thus be important for technology-assisted singing teaching. Previously, automatic classification of vocal modes has been attempted without major success, potentially due to a lack of data. Therefore, we recorded a novel vocal mode dataset consisting of sustained vowels recorded from four singers, three of which professional singers with more than five years of CVT-experience. The dataset covers the entire vocal range of the subjects, totaling 3,752 unique samples. By using four microphones, thereby offering a natural data augmentation, the dataset consists of more than 13,000 samples combined. An annotation was created using three CVT-experienced annotators, each providing an individual annotation. The merged annotation as well as the three individual annotations come with the published dataset. Additionally, we provide some baseline classification results. The best balanced accuracy across a 5-fold cross validation of 81.3\\,\\% was achieved with a ResNet18. The dataset can be downloaded under https://zenodo.org/records/14276415.",
    "published": "2026-01-26T10:28:06Z",
    "updated": "2026-01-26T10:28:06Z",
    "link": "http://arxiv.org/pdf/2601.18339v1.pdf",
    "category": [
      "cs.SD",
      "cs.LG"
    ],
    "authors": [
      "Reemt Hinrichs",
      "Sonja Stephan",
      "Alexander Lange",
      "Jörn Ostermann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18329v1",
    "title": "Discriminability-Driven Spatial-Channel Selection with Gradient Norm for Drone Signal OOD Detection",
    "summary": "We propose a drone signal out-of-distribution (OOD) detection algorithm based on discriminability-driven spatial-channel selection with a gradient norm. Time-frequency image features are adaptively weighted along both spatial and channel dimensions by quantifying inter-class similarity and variance based on protocol-specific time-frequency characteristics. Subsequently, a gradient-norm metric is introduced to measure perturbation sensitivity for capturing the inherent instability of OOD samples, which is then fused with energy-based scores for joint inference. Simulation results demonstrate that the proposed algorithm provides superior discriminative power and robust performance via SNR and various drone types.",
    "published": "2026-01-26T10:13:07Z",
    "updated": "2026-01-26T10:13:07Z",
    "link": "http://arxiv.org/pdf/2601.18329v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Chuhan Feng",
      "Jing Li",
      "Jie Li",
      "Lu Lv",
      "Fengkui Gong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18326v1",
    "title": "Cognitive Fusion of ZC Sequences and Time-Frequency Images for Out-of-Distribution Detection of Drone Signals",
    "summary": "We propose a drone signal out-of-distribution detection (OODD) algorithm based on the cognitive fusion of Zadoff-Chu (ZC) sequences and time-frequency images (TFI). ZC sequences are identified by analyzing the communication protocols of DJI drones, while TFI capture the time-frequency characteristics of drone signals with unknown or non-standard communication protocols. Both modalities are used jointly to enable OODD in the drone remote identification (RID) task. Specifically, ZC sequence features and TFI features are generated from the received radio frequency signals, which are then processed through dedicated feature extraction module to enhance and align them. The resultant multi-modal features undergo multi-modal feature interaction, single-modal feature fusion, and multi-modal feature fusion to produce features that integrate and complement information across modalities. Discrimination scores are computed from the fused features along both spatial and channel dimensions to capture time-frequency characteristic differences dictated by the communication protocols, and these scores will be transformed into adaptive attention weights. The weighted features are then passed through a Softmax function to produce the signal classification results. Simulation results demonstrate that the proposed algorithm outperforms existing algorithms and achieves 1.7% and 7.5% improvements in RID and OODD metrics, respectively. The proposed algorithm also performs strong robustness under varying flight conditions and across different drone types.",
    "published": "2026-01-26T10:10:08Z",
    "updated": "2026-01-26T10:10:08Z",
    "link": "http://arxiv.org/pdf/2601.18326v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Jie Li",
      "Jing Li",
      "Lu Lv",
      "Zhanyu Ju",
      "Fengkui Gong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18314v1",
    "title": "A Master Class on Reproducibility: A Student Hackathon on Advanced MRI Reconstruction Methods",
    "summary": "We report the design, protocol, and outcomes of a student reproducibility hackathon focused on replicating the results of three influential MRI reconstruction papers: (a) MoDL, an unrolled model-based network with learned denoising; (b) HUMUS-Net, a hybrid unrolled multiscale CNN+Transformer architecture; and (c) an untrained, physics-regularized dynamic MRI method that uses a quantitative MR model for early stopping. We describe the setup of the hackathon and present reproduction outcomes alongside additional experiments, and we detail fundamental practices for building reproducible codebases.",
    "published": "2026-01-26T09:50:02Z",
    "updated": "2026-01-26T09:50:02Z",
    "link": "http://arxiv.org/pdf/2601.18314v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Lina Felsner",
      "Sevgi G. Kafali",
      "Hannah Eichhorn",
      "Agnes A. J. Leth",
      "Aidas Batvinskas",
      "Andre Datchev",
      "Fabian Klemm",
      "Jan Aulich",
      "Puntika Leepagorn",
      "Ruben Klinger",
      "Daniel Rueckert",
      "Julia A. Schnabel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18313v1",
    "title": "Convex Chance-Constrained Stochastic Control under Uncertain Specifications with Application to Learning-Based Hybrid Powertrain Control",
    "summary": "This paper presents a strictly convex chance-constrained stochastic control framework that accounts for uncertainty in control specifications such as reference trajectories and operational constraints. By jointly optimizing control inputs and risk allocation under general (possibly non-Gaussian) uncertainties, the proposed method guarantees probabilistic constraint satisfaction while ensuring strict convexity, leading to uniqueness and continuity of the optimal solution. The formulation is further extended to nonlinear model-based control using exactly linearizable models identified through machine learning. The effectiveness of the proposed approach is demonstrated through model predictive control applied to a hybrid powertrain system.",
    "published": "2026-01-26T09:49:33Z",
    "updated": "2026-01-26T09:49:33Z",
    "link": "http://arxiv.org/pdf/2601.18313v1.pdf",
    "category": [
      "eess.SY",
      "cs.LG",
      "math.OC"
    ],
    "authors": [
      "Teruki Kato",
      "Ryotaro Shima",
      "Kenji Kashima"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2005.05837v2",
    "title": "Energy-Aware DNN Graph Optimization",
    "summary": "Unlike existing work in deep neural network (DNN) graphs optimization for inference performance, we explore DNN graph optimization for energy awareness and savings for power- and resource-constrained machine learning devices. We present a method that allows users to optimize energy consumption or balance between energy and inference performance for DNN graphs. This method efficiently searches through the space of equivalent graphs, and identifies a graph and the corresponding algorithms that incur the least cost in execution. We implement the method and evaluate it with multiple DNN models on a GPU-based machine. Results show that our method achieves significant energy savings, i.e., 24% with negligible performance impact.",
    "published": "2020-05-12T14:56:19Z",
    "updated": "2026-01-26T09:20:07Z",
    "link": "http://arxiv.org/pdf/2005.05837v2.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Yu Wang",
      "Rong Ge",
      "Shuang Qiu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.23832v2",
    "title": "An extrapolated and provably convergent algorithm for nonlinear matrix decomposition with the ReLU function",
    "summary": "ReLU matrix decomposition (RMD) is the following problem: given a sparse, nonnegative matrix $X$ and a factorization rank $r$, identify a rank-$r$ matrix $Θ$ such that $X\\approx \\max(0,Θ)$. RMD is a particular instance of nonlinear matrix decomposition (NMD) that finds application in data compression, matrix completion with entries missing not at random, and manifold learning. The standard RMD model minimizes the least squares error, that is, $\\|X - \\max(0,Θ)\\|_F^2$. The corresponding optimization problem, Least-Squares RMD (LS-RMD), is nondifferentiable and highly nonconvex. This motivated Saul to propose an alternative model, \\revise{dubbed Latent-RMD}, where a latent variable $Z$ is introduced and satisfies $\\max(0,Z)=X$ while minimizing $\\|Z - Θ\\|_F^2$ (``A nonlinear matrix decomposition for mining the zeros of sparse data'', SIAM J.\\ Math.\\ Data Sci., 2022). Our first contribution is to show that the two formulations may yield different low-rank solutions $Θ$. We then consider a reparametrization of the Latent-RMD, called 3B-RMD, in which $Θ$ is substituted by a low-rank product $WH$, where $W$ has $r$ columns and $H$ has $r$ rows. Our second contribution is to prove the convergence of a block coordinate descent (BCD) approach applied to 3B-RMD. Our third contribution is a novel extrapolated variant of BCD, dubbed eBCD, which we prove is also convergent under mild assumptions. We illustrate the significant acceleration effect of eBCD compared to eBCD, and also show that eBCD performs well against the state of the art on synthetic and real-world data sets.",
    "published": "2025-03-31T08:27:41Z",
    "updated": "2026-01-26T09:08:56Z",
    "link": "http://arxiv.org/pdf/2503.23832v2.pdf",
    "category": [
      "cs.LG",
      "eess.IV",
      "math.OC",
      "stat.ML"
    ],
    "authors": [
      "Nicolas Gillis",
      "Margherita Porcelli",
      "Giovanni Seraghiti"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.12469v2",
    "title": "Sparse Concept Anchoring for Interpretable and Controllable Neural Representations",
    "summary": "We introduce Sparse Concept Anchoring, a method that biases latent space to position a targeted subset of concepts while allowing others to self-organize, using only minimal supervision (labels for <0.1% of examples per anchored concept). Training combines activation normalization, a separation regularizer, and anchor or subspace regularizers that attract rare labeled examples to predefined directions or axis-aligned subspaces. The anchored geometry enables two practical interventions: reversible behavioral steering that projects out a concept's latent component at inference, and permanent removal via targeted weight ablation of anchored dimensions. Experiments on structured autoencoders show selective attenuation of targeted concepts with negligible impact on orthogonal features, and complete elimination with reconstruction error approaching theoretical bounds. Sparse Concept Anchoring therefore provides a practical pathway to interpretable, steerable behavior in learned representations.",
    "published": "2025-12-13T21:43:17Z",
    "updated": "2026-01-26T09:03:00Z",
    "link": "http://arxiv.org/pdf/2512.12469v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Sandy Fraser",
      "Patryk Wielopolski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.17977v2",
    "title": "SliceGX: Layer-wise GNN Explanation with Model-slicing",
    "summary": "Ensuring the trustworthiness of graph neural networks (GNNs), which are often treated as black-box models, requires effective explanation techniques. Existing GNN explanations typically apply input perturbations to identify subgraphs that are responsible for the occurrence of the final output of GNNs. However, such approaches lack finer-grained, layer-wise analysis of how intermediate representations contribute to the final result, capabilities that are crucial for model diagnosis and architecture optimization. This paper introduces SliceGX, a novel GNN explanation approach that generates explanations at specific GNN layers in a progressive manner. Given a GNN model M, a set of selected intermediate layers, and a target layer, SliceGX slices M into layer blocks(\"model slice\") and discovers high-quality explanatory subgraphs within each block that elucidate how the model output arises at the target layer. Although finding such layer-wise explanations is computationally challenging, we develop efficient algorithms and optimization techniques that incrementally construct and maintain these subgraphs with provable approximation guarantees. Extensive experiments on synthetic and real-world benchmarks demonstrate the effectiveness and efficiency of SliceGX, and illustrate its practical utility in supporting model debugging.",
    "published": "2025-06-22T10:28:46Z",
    "updated": "2026-01-26T08:59:24Z",
    "link": "http://arxiv.org/pdf/2506.17977v2.pdf",
    "category": [
      "cs.LG",
      "cs.DB"
    ],
    "authors": [
      "Tingting Zhu",
      "Tingyang Chen",
      "Yinghui Wu",
      "Arijit Khan",
      "Xiangyu Ke"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18273v1",
    "title": "Toward Scalable Normalizing Flows for the Hubbard Model",
    "summary": "Normalizing flows have recently demonstrated the ability to learn the Boltzmann distribution of the Hubbard model, opening new avenues for generative modeling in condensed matter physics. In this work, we investigate the steps required to extend such simulations to larger lattice sizes and lower temperatures, with a focus on enhancing stability and efficiency. Additionally, we present the scaling behavior of stochastic normalizing flows and non-equilibrium Markov chain Monte Carlo methods for this fermionic system.",
    "published": "2026-01-26T08:58:08Z",
    "updated": "2026-01-26T08:58:08Z",
    "link": "http://arxiv.org/pdf/2601.18273v1.pdf",
    "category": [
      "cond-mat.str-el",
      "cs.LG",
      "hep-lat"
    ],
    "authors": [
      "Janik Kreit",
      "Andrea Bulgarelli",
      "Lena Funcke",
      "Thomas Luu",
      "Dominic Schuh",
      "Simran Singh",
      "Lorenzo Verzichelli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18245v1",
    "title": "Tractable Gaussian Phase Retrieval with Heavy Tails and Adversarial Corruption with Near-Linear Sample Complexity",
    "summary": "Phase retrieval is the classical problem of recovering a signal $x^* \\in \\mathbb{R}^n$ from its noisy phaseless measurements $y_i = \\langle a_i, x^* \\rangle^2 + ζ_i$ (where $ζ_i$ denotes noise, and $a_i$ is the sensing vector) for $i \\in [m]$. The problem of phase retrieval has a rich history, with a variety of applications such as optics, crystallography, heteroscedastic regression, astrophysics, etc. A major consideration in algorithms for phase retrieval is robustness against measurement errors. In recent breakthroughs in algorithmic robust statistics, efficient algorithms have been developed for several parameter estimation tasks such as mean estimation, covariance estimation, robust principal component analysis (PCA), etc. in the presence of heavy-tailed noise and adversarial corruptions. In this paper, we study efficient algorithms for robust phase retrieval with heavy-tailed noise when a constant fraction of both the measurements $y_i$ and the sensing vectors $a_i$ may be arbitrarily adversarially corrupted. For this problem, Buna and Rebeschini (AISTATS 2025) very recently gave an exponential time algorithm with sample complexity $O(n \\log n)$. Their algorithm needs a robust spectral initialization, specifically, a robust estimate of the top eigenvector of a covariance matrix, which they deemed to be beyond known efficient algorithmic techniques (similar spectral initializations are a key ingredient of a large family of phase retrieval algorithms). In this work, we make a connection between robust spectral initialization and recent algorithmic advances in robust PCA, yielding the first polynomial-time algorithms for robust phase retrieval with both heavy-tailed noise and adversarial corruptions, in fact with near-linear (in $n$) sample complexity.",
    "published": "2026-01-26T08:06:16Z",
    "updated": "2026-01-26T08:06:16Z",
    "link": "http://arxiv.org/pdf/2601.18245v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Santanu Das",
      "Jatin Batra"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2409.02588v2",
    "title": "Multiview Random Vector Functional Link Network for Predicting DNA-Binding Proteins",
    "summary": "The identification of DNA-binding proteins (DBPs) is essential due to their significant impact on various biological activities. Understanding the mechanisms underlying protein-DNA interactions is essential for elucidating various life activities. In recent years, machine learning-based models have been prominently utilized for DBP prediction. In this paper, to predict DBPs, we propose a novel framework termed a multiview random vector functional link (MvRVFL) network, which fuses neural network architecture with multiview learning. The MvRVFL model integrates both late and early fusion advantages, enabling separate regularization parameters for each view, while utilizing a closed-form solution for efficiently determining unknown parameters. The primal objective function incorporates a coupling term aimed at minimizing a composite of errors stemming from all views. From each of the three protein views of the DBP datasets, we extract five features. These features are then fused together by incorporating a hidden feature during the model training process. The performance of the proposed MvRVFL model on the DBP dataset surpasses that of baseline models, demonstrating its superior effectiveness. We further validate the practicality of the proposed model across diverse benchmark datasets, and both theoretical analysis and empirical results consistently demonstrate its superior generalization performance over baseline models.",
    "published": "2024-09-04T10:14:17Z",
    "updated": "2026-01-26T06:22:52Z",
    "link": "http://arxiv.org/pdf/2409.02588v2.pdf",
    "category": [
      "cs.LG",
      "q-bio.BM"
    ],
    "authors": [
      "A. Quadir",
      "M. Sajid",
      "M. Tanveer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18189v1",
    "title": "Smooth, Sparse, and Stable: Finite-Time Exact Skeleton Recovery via Smoothed Proximal Gradients",
    "summary": "Continuous optimization has significantly advanced causal discovery, yet existing methods (e.g., NOTEARS) generally guarantee only asymptotic convergence to a stationary point. This often yields dense weighted matrices that require arbitrary post-hoc thresholding to recover a DAG. This gap between continuous optimization and discrete graph structures remains a fundamental challenge. In this paper, we bridge this gap by proposing the Hybrid-Order Acyclicity Constraint (AHOC) and optimizing it via the Smoothed Proximal Gradient (SPG-AHOC). Leveraging the Manifold Identification Property of proximal algorithms, we provide a rigorous theoretical guarantee: the Finite-Time Oracle Property. We prove that under standard identifiability assumptions, SPG-AHOC recovers the exact DAG support (structure) in finite iterations, even when optimizing a smoothed approximation. This result eliminates structural ambiguity, as our algorithm returns graphs with exact zero entries without heuristic truncation. Empirically, SPG-AHOC achieves state-of-the-art accuracy and strongly corroborates the finite-time identification theory.",
    "published": "2026-01-26T06:16:47Z",
    "updated": "2026-01-26T06:16:47Z",
    "link": "http://arxiv.org/pdf/2601.18189v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Rui Wu",
      "Yongjun Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18171v1",
    "title": "Learning Fair Domain Adaptation with Virtual Label Distribution",
    "summary": "Unsupervised Domain Adaptation (UDA) aims to mitigate performance degradation when training and testing data are sampled from different distributions. While significant progress has been made in enhancing overall accuracy, most existing methods overlook performance disparities across categories-an issue we refer to as category fairness. Our empirical analysis reveals that UDA classifiers tend to favor certain easy categories while neglecting difficult ones. To address this, we propose Virtual Label-distribution-aware Learning (VILL), a simple yet effective framework designed to improve worst-case performance while preserving high overall accuracy. The core of VILL is an adaptive re-weighting strategy that amplifies the influence of hard-to-classify categories. Furthermore, we introduce a KL-divergence-based re-balancing strategy, which explicitly adjusts decision boundaries to enhance category fairness. Experiments on commonly used datasets demonstrate that VILL can be seamlessly integrated as a plug-and-play module into existing UDA methods, significantly improving category fairness.",
    "published": "2026-01-26T05:48:47Z",
    "updated": "2026-01-26T05:48:47Z",
    "link": "http://arxiv.org/pdf/2601.18171v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Yuguang Zhang",
      "Lijun Sheng",
      "Jian Liang",
      "Ran He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.16399v2",
    "title": "A Regularized Actor-Critic Algorithm for Bi-Level Reinforcement Learning",
    "summary": "We study a structured bi-level optimization problem where the upper-level objective is a smooth function and the lower-level problem is policy optimization in a Markov decision process (MDP). The upper-level decision variable parameterizes the reward of the lower-level MDP, and the upper-level objective depends on the optimal induced policy. Existing methods for bi-level optimization and RL often require second-order information, impose strong regularization at the lower level, or inefficiently use samples through nested-loop procedures. In this work, we propose a single-loop, first-order actor-critic algorithm that optimizes the bi-level objective via a penalty-based reformulation. We introduce into the lower-level RL objective an attenuating entropy regularization, which enables asymptotically unbiased upper-level hyper-gradient estimation without solving the unregularized RL problem exactly. We establish the finite-time and finite-sample convergence of the proposed algorithm to a stationary point of the original, unregularized bi-level optimization problem through a novel lower-level residual analysis under a special type of Polyak-Lojasiewicz condition. We validate the performance of our method through experiments on a GridWorld goal position problem and on happy tweet generation through reinforcement learning from human feedback (RLHF).",
    "published": "2026-01-23T02:12:24Z",
    "updated": "2026-01-26T05:27:01Z",
    "link": "http://arxiv.org/pdf/2601.16399v2.pdf",
    "category": [
      "cs.LG",
      "math.OC"
    ],
    "authors": [
      "Sihan Zeng",
      "Sujay Bhatt",
      "Sumitra Ganesh",
      "Alec Koppel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18145v1",
    "title": "Exact Minimum-Volume Confidence Set Intersection for Multinomial Outcomes",
    "summary": "Computation of confidence sets is central to data science and machine learning, serving as the workhorse of A/B testing and underpinning the operation and analysis of reinforcement learning algorithms. Among all valid confidence sets for the multinomial parameter, minimum-volume confidence sets (MVCs) are optimal in that they minimize average volume, but they are defined as level sets of an exact p-value that is discontinuous and difficult to compute. Rather than attempting to characterize the geometry of MVCs directly, this paper studies a practically motivated decision problem: given two observed multinomial outcomes, can one certify whether their MVCs intersect? We present a certified, tolerance-aware algorithm for this intersection problem. The method exploits the fact that likelihood ordering induces halfspace constraints in log-odds coordinates, enabling adaptive geometric partitioning of parameter space and computable lower and upper bounds on p-values over each cell. For three categories, this yields an efficient and provably sound algorithm that either certifies intersection, certifies disjointness, or returns an indeterminate result when the decision lies within a prescribed margin. We further show how the approach extends to higher dimensions. The results demonstrate that, despite their irregular geometry, MVCs admit reliable certified decision procedures for core tasks in A/B testing.",
    "published": "2026-01-26T05:07:47Z",
    "updated": "2026-01-26T05:07:47Z",
    "link": "http://arxiv.org/pdf/2601.18145v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "stat.CO"
    ],
    "authors": [
      "Heguang Lin",
      "Binhao Chen",
      "Mengze Li",
      "Daniel Pimentel-Alarcón",
      "Matthew L. Malloy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18670v1",
    "title": "COMETS: Coordinated Multi-Destination Video Transmission with In-Network Rate Adaptation",
    "summary": "Large-scale video streaming events attract millions of simultaneous viewers, stressing existing delivery infrastructures. Client-driven adaptation reacts slowly to shared congestion, while server-based coordination introduces scalability bottlenecks and single points of failure. We present COMETS, a coordinated multi-destination video transmission framework that leverages information-centric networking principles such as request aggregation and in-network state awareness to enable scalable, fair, and adaptive rate control. COMETS introduces a novel range-interest protocol and distributed in-network decision process that aligns video quality across receiver groups while minimizing redundant transmissions. To achieve this, we develop a lightweight distributed optimization framework that guides per-hop quality adaptation without centralized control. Extensive emulation shows that COMETS consistently improves bandwidth utilization, fairness, and user-perceived quality of experience over DASH, MoQ, and ICN baselines, particularly under high concurrency. The results highlight COMETS as a practical, deployable approach for next-generation scalable video delivery.",
    "published": "2026-01-26T16:47:45Z",
    "updated": "2026-01-26T16:47:45Z",
    "link": "http://arxiv.org/pdf/2601.18670v1.pdf",
    "category": [
      "cs.NI",
      "cs.MM",
      "eess.IV"
    ],
    "authors": [
      "Yulong Zhang",
      "Ying Cui",
      "Zili Meng",
      "Abhishek Kumar",
      "Dirk Kutscher"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18765v1",
    "title": "Goal-oriented Communication for Fast and Robust Robotic Fault Detection and Recovery",
    "summary": "Autonomous robotic systems are widely deployed in smart factories and operate in dynamic, uncertain, and human-involved environments that require low-latency and robust fault detection and recovery (FDR). However, existing FDR frameworks exhibit various limitations, such as significant delays in communication and computation, and unreliability in robot motion/trajectory generation, mainly because the communication-computation-control (3C) loop is designed without considering the downstream FDR goal. To address this, we propose a novel Goal-oriented Communication (GoC) framework that jointly designs the 3C loop tailored for fast and robust robotic FDR, with the goal of minimising the FDR time while maximising the robotic task (e.g., workpiece sorting) success rate. For fault detection, our GoC framework innovatively defines and extracts the 3D scene graph (3D-SG) as the semantic representation via our designed representation extractor, and detects faults by monitoring spatial relationship changes in the 3D-SG. For fault recovery, we fine-tune a small language model (SLM) via Low-Rank Adaptation (LoRA) and enhance its reasoning and generalization capabilities via knowledge distillation to generate recovery motions for robots. We also design a lightweight goal-oriented digital twin reconstruction module to refine the recovery motions generated by the SLM when fine-grained robotic control is required, using only task-relevant object contours for digital twin reconstruction. Extensive simulations demonstrate that our GoC framework reduces the FDR time by up to 82.6% and improves the task success rate by up to 76%, compared to the state-of-the-art frameworks that rely on vision language models for fault detection and large language models for fault recovery.",
    "published": "2026-01-26T18:32:33Z",
    "updated": "2026-01-26T18:32:33Z",
    "link": "http://arxiv.org/pdf/2601.18765v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Shutong Chen",
      "Adnan Aijaz",
      "Yansha Deng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.08835v2",
    "title": "Goal-oriented Semantic Communication for Robot Arm Reconstruction in Digital Twin: Feature and Temporal Selections",
    "summary": "As one of the most promising technologies in industry, the Digital Twin (DT) facilitates real-time monitoring and predictive analysis for real-world systems by precisely reconstructing virtual replicas of physical entities. However, this reconstruction faces unprecedented challenges due to the everincreasing communication overhead, especially for digital robot arm reconstruction. To this end, we propose a novel goal-oriented semantic communication (GSC) framework to extract the GSC information for the robot arm reconstruction task in the DT, with the aim of minimising the communication load under the strict and relaxed reconstruction error constraints. Unlike the traditional reconstruction framework that periodically transmits a reconstruction message for real-time DT reconstruction, our framework implements a feature selection (FS) algorithm to extract the semantic information from the reconstruction message, and a deep reinforcement learning-based temporal selection algorithm to selectively transmit the semantic information over time. We validate our proposed GSC framework through both Pybullet simulations and lab experiments based on the Franka Research 3 robot arm. For a range of distinct robotic tasks, simulation results show that our framework can reduce the communication load by at least 59.5% under strict reconstruction error constraints and 80% under relaxed reconstruction error constraints, compared with traditional communication framework. Also, experimental results confirm the effectiveness of our framework, where the communication load is reduced by 53% in strict constraint case and 74% in relaxed constraint case. The demo is available at: https://youtu.be/2OdeHKxcgnk.",
    "published": "2024-11-13T18:14:23Z",
    "updated": "2026-01-26T18:16:49Z",
    "link": "http://arxiv.org/pdf/2411.08835v2.pdf",
    "category": [
      "cs.RO",
      "eess.SY"
    ],
    "authors": [
      "Shutong Chen",
      "Emmanouil Spyrakos-Papastavridis",
      "Yichao Jin",
      "Yansha Deng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.00577v2",
    "title": "Actor-Critic Cooperative Compensation to Model Predictive Control for Off-Road Autonomous Vehicles Under Unknown Dynamics",
    "summary": "This study presents an Actor-Critic Cooperative Compensated Model Predictive Controller (AC3MPC) designed to address unknown system dynamics. To avoid the difficulty of modeling highly complex dynamics and ensuring realtime control feasibility and performance, this work uses deep reinforcement learning with a model predictive controller in a cooperative framework to handle unknown dynamics. The model-based controller takes on the primary role as both controllers are provided with predictive information about the other. This improves tracking performance and retention of inherent robustness of the model predictive controller. We evaluate this framework for off-road autonomous driving on unknown deformable terrains that represent sandy deformable soil, sandy and rocky soil, and cohesive clay-like deformable soil. Our findings demonstrate that our controller statistically outperforms standalone model-based and learning-based controllers by upto 29.2% and 10.2%. This framework generalized well over varied and previously unseen terrain characteristics to track longitudinal reference speeds with lower errors. Furthermore, this required significantly less training data compared to purely learning-based controller, while delivering better performance even when under-trained.",
    "published": "2025-03-01T17:59:55Z",
    "updated": "2026-01-26T17:57:52Z",
    "link": "http://arxiv.org/pdf/2503.00577v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Prakhar Gupta",
      "Jonathon M Smereka",
      "Yunyi Jia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18723v1",
    "title": "Trustworthy Evaluation of Robotic Manipulation: A New Benchmark and AutoEval Methods",
    "summary": "Driven by the rapid evolution of Vision-Action and Vision-Language-Action models, imitation learning has significantly advanced robotic manipulation capabilities. However, evaluation methodologies have lagged behind, hindering the establishment of Trustworthy Evaluation for these behaviors. Current paradigms rely on binary success rates, failing to address the critical dimensions of trust: Source Authenticity (i.e., distinguishing genuine policy behaviors from human teleoperation) and Execution Quality (e.g., smoothness and safety). To bridge these gaps, we propose a solution that combines the Eval-Actions benchmark and the AutoEval architecture. First, we construct the Eval-Actions benchmark to support trustworthiness analysis. Distinct from existing datasets restricted to successful human demonstrations, Eval-Actions integrates VA and VLA policy execution trajectories alongside human teleoperation data, explicitly including failure scenarios. This dataset is structured around three core supervision signals: Expert Grading (EG), Rank-Guided preferences (RG), and Chain-of-Thought (CoT). Building on this, we propose the AutoEval architecture: AutoEval leverages Spatio-Temporal Aggregation for semantic assessment, augmented by an auxiliary Kinematic Calibration Signal to refine motion smoothness; AutoEval Plus (AutoEval-P) incorporates the Group Relative Policy Optimization (GRPO) paradigm to enhance logical reasoning capabilities. Experiments show AutoEval achieves Spearman's Rank Correlation Coefficients (SRCC) of 0.81 and 0.84 under the EG and RG protocols, respectively. Crucially, the framework possesses robust source discrimination capabilities, distinguishing between policy-generated and teleoperated videos with 99.6% accuracy, thereby establishing a rigorous standard for trustworthy robotic evaluation. Our project and code are available at https://term-bench.github.io/.",
    "published": "2026-01-26T17:47:42Z",
    "updated": "2026-01-26T17:47:42Z",
    "link": "http://arxiv.org/pdf/2601.18723v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Mengyuan Liu",
      "Juyi Sheng",
      "Peiming Li",
      "Ziyi Wang",
      "Tianming Xu",
      "Tiantian Xu",
      "Hong Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2312.08684v4",
    "title": "A Computationally Efficient Maximum A Posteriori Sequence Estimation via Stein Variational Inference",
    "summary": "State estimation in robotic systems presents significant challenges, particularly due to the prevalence of multimodal posterior distributions in real-world scenarios. One effective strategy for handling such complexity is to compute maximum a posteriori (MAP) sequences over a discretized or sampled state space, which enables a concise representation of the most likely state trajectory. However, this approach often incurs substantial computational costs, especially in high-dimensional settings. In this article, we propose a novel MAP sequence estimation method, Stein-MAP-Seq, which effectively addresses multimodality while substantially reducing computational and memory overhead. Our key contribution is a sequential variational inference framework that captures temporal dependencies in dynamical system models and integrates Stein variational gradient descent (SVGD) into a Viterbi-style dynamic programming algorithm, enabling computationally efficient MAP sequence estimation. This integration allows the method to focus computational effort on MAP-consistent modes rather than exhaustively exploring the entire state space. Stein-MAP-Seq inherits the parallelism and mode-seeking behavior of SVGD, allowing particle updates to be efficiently executed on parallel hardware and significantly reducing the number of trajectory candidates required for MAP-sequence recursion compared to conventional methods that rely on hundreds to thousands of particles. We validate the proposed approach on a range of highly multimodal scenarios, including nonlinear dynamics with ambiguous observations, unknown data association with outliers, range-only localization under temporary unobservability, and high-dimensional robotic manipulators. Experimental results demonstrate substantial improvements in estimation accuracy and robustness to multimodality over existing estimation methods.",
    "published": "2023-12-14T06:46:35Z",
    "updated": "2026-01-26T17:43:08Z",
    "link": "http://arxiv.org/pdf/2312.08684v4.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Min-Won Seo",
      "Solmaz S. Kia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19855v2",
    "title": "Gaussian Variational Inference with Non-Gaussian Factors for State Estimation: A UWB Localization Case Study",
    "summary": "This letter extends the exactly sparse Gaussian variational inference (ESGVI) algorithm for state estimation in two complementary directions. First, ESGVI is generalized to operate on matrix Lie groups, enabling the estimation of states with orientation components while respecting the underlying group structure. Second, factors are introduced to accommodate heavy-tailed and skewed noise distributions, as commonly encountered in ultra-wideband (UWB) localization due to non-line-of-sight (NLOS) and multipath effects. Both extensions are shown to integrate naturally within the ESGVI framework while preserving its sparse and derivative-free structure. The proposed approach is validated in a UWB localization experiment with NLOS-rich measurements, demonstrating improved accuracy and comparable consistency. Finally, a Python implementation within a factor-graph-based estimation framework is made open-source (https://github.com/decargroup/gvi_ws) to support broader research use.",
    "published": "2025-12-22T20:17:04Z",
    "updated": "2026-01-26T16:40:41Z",
    "link": "http://arxiv.org/pdf/2512.19855v2.pdf",
    "category": [
      "cs.RO",
      "stat.ML"
    ],
    "authors": [
      "Andrew Stirling",
      "Mykola Lukashchuk",
      "Dmitry Bagaev",
      "Wouter Kouw",
      "James R. Forbes"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18639v1",
    "title": "Constraint-Aware Discrete-Time PID Gain Optimization for Robotic Joint Control Under Actuator Saturation",
    "summary": "The precise regulation of rotary actuation is fundamental in autonomous robotics, yet practical PID loops deviate from continuous-time theory due to discrete-time execution, actuator saturation, and small delays and measurement imperfections. We present an implementation-aware analysis and tuning workflow for saturated discrete-time joint control. We (i) derive PI stability regions under Euler and exact zero-order-hold (ZOH) discretizations using the Jury criterion, (ii) evaluate a discrete back-calculation anti-windup realization under saturation-dominant regimes, and (iii) propose a hybrid-certified Bayesian optimization workflow that screens analytically unstable candidates and behaviorally unsafe transients while optimizing a robust IAE objective with soft penalties on overshoot and saturation duty. Baseline sweeps ($τ=1.0$~s, $Δt=0.01$~s, $u\\in[-10,10]$) quantify rise/settle trends for P/PI/PID. Under a randomized model family emulating uncertainty, delay, noise, quantization, and tighter saturation, robustness-oriented tuning improves median IAE from $0.843$ to $0.430$ while keeping median overshoot below $2\\%$. In simulation-only tuning, the certification screen rejects $11.6\\%$ of randomly sampled gains within bounds before full robust evaluation, improving sample efficiency without hardware experiments.",
    "published": "2026-01-26T16:11:05Z",
    "updated": "2026-01-26T16:11:05Z",
    "link": "http://arxiv.org/pdf/2601.18639v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Ojasva Mishra",
      "Xiaolong Wu",
      "Min Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18629v1",
    "title": "ExoGS: A 4D Real-to-Sim-to-Real Framework for Scalable Manipulation Data Collection",
    "summary": "Real-to-Sim-to-Real technique is gaining increasing interest for robotic manipulation, as it can generate scalable data in simulation while having narrower sim-to-real gap. However, previous methods mainly focused on environment-level visual real-to-sim transfer, ignoring the transfer of interactions, which could be challenging and inefficient to obtain purely in simulation especially for contact-rich tasks. We propose ExoGS, a robot-free 4D Real-to-Sim-to-Real framework that captures both static environments and dynamic interactions in the real world and transfers them seamlessly to a simulated environment. It provides a new solution for scalable manipulation data collection and policy learning. ExoGS employs a self-designed robot-isomorphic passive exoskeleton AirExo-3 to capture kinematically consistent trajectories with millimeter-level accuracy and synchronized RGB observations during direct human demonstrations. The robot, objects, and environment are reconstructed as editable 3D Gaussian Splatting assets, enabling geometry-consistent replay and large-scale data augmentation. Additionally, a lightweight Mask Adapter injects instance-level semantics into the policy to enhance robustness under visual domain shifts. Real-world experiments demonstrate that ExoGS significantly improves data efficiency and policy generalization compared to teleoperation-based baselines. Code and hardware files have been released on https://github.com/zaixiabalala/ExoGS.",
    "published": "2026-01-26T16:04:12Z",
    "updated": "2026-01-26T16:04:12Z",
    "link": "http://arxiv.org/pdf/2601.18629v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Yiming Wang",
      "Ruogu Zhang",
      "Minyang Li",
      "Hao Shi",
      "Junbo Wang",
      "Deyi Li",
      "Jieji Ren",
      "Wenhai Liu",
      "Weiming Wang",
      "Hao-Shu Fang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18548v1",
    "title": "Fast and Safe Trajectory Optimization for Mobile Manipulators With Neural Configuration Space Distance Field",
    "summary": "Mobile manipulators promise agile, long-horizon behavior by coordinating base and arm motion, yet whole-body trajectory optimization in cluttered, confined spaces remains difficult due to high-dimensional nonconvexity and the need for fast, accurate collision reasoning. Configuration Space Distance Fields (CDF) enable fixed-base manipulators to model collisions directly in configuration space via smooth, implicit distances. This representation holds strong potential to bypass the nonlinear configuration-to-workspace mapping while preserving accurate whole-body geometry and providing optimization-friendly collision costs. Yet, extending this capability to mobile manipulators is hindered by unbounded workspaces and tighter base-arm coupling. We lift this promise to mobile manipulation with Generalized Configuration Space Distance Fields (GCDF), extending CDF to robots with both translational and rotational joints in unbounded workspaces with tighter base-arm coupling. We prove that GCDF preserves Euclidean-like local distance structure and accurately encodes whole-body geometry in configuration space, and develop a data generation and training pipeline that yields continuous neural GCDFs with accurate values and gradients, supporting efficient GPU-batched queries. Building on this representation, we develop a high-performance sequential convex optimization framework centered on GCDF-based collision reasoning. The solver scales to large numbers of implicit constraints through (i) online specification of neural constraints, (ii) sparsity-aware active-set detection with parallel batched evaluation across thousands of constraints, and (iii) incremental constraint management for rapid replanning under scene changes.",
    "published": "2026-01-26T14:55:26Z",
    "updated": "2026-01-26T14:55:26Z",
    "link": "http://arxiv.org/pdf/2601.18548v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Yulin Li",
      "Zhiyuan Song",
      "Yiming Li",
      "Zhicheng Song",
      "Kai Chen",
      "Chunxin Zheng",
      "Zhihai Bi",
      "Jiahang Cao",
      "Sylvain Calinon",
      "Fan Shi",
      "Jun Ma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18492v1",
    "title": "DV-VLN: Dual Verification for Reliable LLM-Based Vision-and-Language Navigation",
    "summary": "Vision-and-Language Navigation (VLN) requires an embodied agent to navigate in a complex 3D environment according to natural language instructions. Recent progress in large language models (LLMs) has enabled language-driven navigation with improved interpretability. However, most LLM-based agents still rely on single-shot action decisions, where the model must choose one option from noisy, textualized multi-perspective observations. Due to local mismatches and imperfect intermediate reasoning, such decisions can easily deviate from the correct path, leading to error accumulation and reduced reliability in unseen environments. In this paper, we propose DV-VLN, a new VLN framework that follows a generate-then-verify paradigm. DV-VLN first performs parameter-efficient in-domain adaptation of an open-source LLaMA-2 backbone to produce a structured navigational chain-of-thought, and then verifies candidate actions with two complementary channels: True-False Verification (TFV) and Masked-Entity Verification (MEV). DV-VLN selects actions by aggregating verification successes across multiple samples, yielding interpretable scores for reranking. Experiments on R2R, RxR (English subset), and REVERIE show that DV-VLN consistently improves over direct prediction and sampling-only baselines, achieving competitive performance among language-only VLN agents and promising results compared with several cross-modal systems.Code is available at https://github.com/PlumJun/DV-VLN.",
    "published": "2026-01-26T13:47:55Z",
    "updated": "2026-01-26T13:47:55Z",
    "link": "http://arxiv.org/pdf/2601.18492v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Zijun Li",
      "Shijie Li",
      "Zhenxi Zhang",
      "Bin Li",
      "Shoujun Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18442v1",
    "title": "SG-CADVLM: A Context-Aware Decoding Powered Vision Language Model for Safety-Critical Scenario Generation",
    "summary": "Autonomous vehicle safety validation requires testing on safety-critical scenarios, but these events are rare in real-world driving and costly to test due to collision risks. Crash reports provide authentic specifications of safety-critical events, offering a vital alternative to scarce real-world collision trajectory data. This makes them valuable sources for generating realistic high-risk scenarios through simulation. Existing approaches face significant limitations because data-driven methods lack diversity due to their reliance on existing latent distributions, whereas adversarial methods often produce unrealistic scenarios lacking physical fidelity. Large Language Model (LLM) and Vision Language Model (VLM)-based methods show significant promise. However, they suffer from context suppression issues where internal parametric knowledge overrides crash specifications, producing scenarios that deviate from actual accident characteristics. This paper presents SG-CADVLM (A Context-Aware Decoding Powered Vision Language Model for Safety-Critical Scenario Generation), a framework that integrates Context-Aware Decoding with multi-modal input processing to generate safety-critical scenarios from crash reports and road network diagrams. The framework mitigates VLM hallucination issues while enabling the simultaneous generation of road geometry and vehicle trajectories. The experimental results demonstrate that SG-CADVLM generates critical risk scenarios at a rate of 84.4% compared to 12.5% for the baseline methods, representing an improvement of 469%, while producing executable simulations for autonomous vehicle testing.",
    "published": "2026-01-26T12:53:12Z",
    "updated": "2026-01-26T12:53:12Z",
    "link": "http://arxiv.org/pdf/2601.18442v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Hongyi Zhao",
      "Shuo Wang",
      "Qijie He",
      "Ziyuan Pu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.03400v2",
    "title": "Close-Fitting Dressing Assistance Based on State Estimation of Feet and Garments with Semantic-based Visual Attention",
    "summary": "As the population continues to age, a shortage of caregivers is expected in the future. Dressing assistance, in particular, is crucial for opportunities for social participation. Especially dressing close-fitting garments, such as socks, remains challenging due to the need for fine force adjustments to handle the friction or snagging against the skin, while considering the shape and position of the garment. This study introduces a method uses multi-modal information including not only robot's camera images, joint angles, joint torques, but also tactile forces for proper force interaction that can adapt to individual differences in humans. Furthermore, by introducing semantic information based on object concepts, rather than relying solely on RGB data, it can be generalized to unseen feet and background. In addition, incorporating depth data helps infer relative spatial relationship between the sock and the foot. To validate its capability for semantic object conceptualization and to ensure safety, training data were collected using a mannequin, and subsequent experiments were conducted with human subjects. In experiments, the robot successfully adapted to previously unseen human feet and was able to put socks on 10 participants, achieving a higher success rate than Action Chunking with Transformer and Diffusion Policy. These results demonstrate that the proposed model can estimate the state of both the garment and the foot, enabling precise dressing assistance for close-fitting garments.",
    "published": "2025-05-06T10:28:39Z",
    "updated": "2026-01-26T11:10:17Z",
    "link": "http://arxiv.org/pdf/2505.03400v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Takuma Tsukakoshi",
      "Tamon Miyake",
      "Tetsuya Ogata",
      "Yushi Wang",
      "Takumi Akaishi",
      "Shigeki Sugano"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18323v1",
    "title": "TC-IDM: Grounding Video Generation for Executable Zero-shot Robot Motion",
    "summary": "The vision-language-action (VLA) paradigm has enabled powerful robotic control by leveraging vision-language models, but its reliance on large-scale, high-quality robot data limits its generalization. Generative world models offer a promising alternative for general-purpose embodied AI, yet a critical gap remains between their pixel-level plans and physically executable actions.\n  To this end, we propose the Tool-Centric Inverse Dynamics Model (TC-IDM). By focusing on the tool's imagined trajectory as synthesized by the world model, TC-IDM establishes a robust intermediate representation that bridges the gap between visual planning and physical control.\n  TC-IDM extracts the tool's point cloud trajectories via segmentation and 3D motion estimation from generated videos. Considering diverse tool attributes, our architecture employs decoupled action heads to project these planned trajectories into 6-DoF end-effector motions and corresponding control signals.\n  This plan-and-translate paradigm not only supports a wide range of end-effectors but also significantly improves viewpoint invariance. Furthermore, it exhibits strong generalization capabilities across long-horizon and out-of-distribution tasks, including interacting with deformable objects.\n  In real-world evaluations, the world model with TC-IDM achieves an average success rate of 61.11 percent, with 77.7 percent on simple tasks and 38.46 percent on zero-shot deformable object tasks. It substantially outperforms end-to-end VLA-style baselines and other inverse dynamics models.",
    "published": "2026-01-26T10:06:56Z",
    "updated": "2026-01-26T10:06:56Z",
    "link": "http://arxiv.org/pdf/2601.18323v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Weishi Mi",
      "Yong Bao",
      "Xiaowei Chi",
      "Xiaozhu Ju",
      "Zhiyuan Qin",
      "Kuangzhi Ge",
      "Kai Tang",
      "Peidong Jia",
      "Shanghang Zhang",
      "Jian Tang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.18289v1",
    "title": "Quest2ROS2: A ROS 2 Framework for Bi-manual VR Teleoperation",
    "summary": "Quest2ROS2 is an open-source ROS2 framework for bi-manual teleoperation designed to scale robot data collection. Extending Quest2ROS, it overcomes workspace limitations via relative motion-based control, calculating robot movement from VR controller pose changes to enable intuitive, pose-independent operation. The framework integrates essential usability and safety features, including real-time RViz visualization, streamlined gripper control, and a pause-and-reset function for smooth transitions. We detail a modular architecture that supports \"Side-by-Side\" and \"Mirror\" control modes to optimize operator experience across diverse platforms. Code is available at: https://github.com/Taokt/Quest2ROS2.",
    "published": "2026-01-26T09:19:16Z",
    "updated": "2026-01-26T09:19:16Z",
    "link": "http://arxiv.org/pdf/2601.18289v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Jialong Li",
      "Zhenguo Wang",
      "Tianci Wang",
      "Maj Stenmark",
      "Volker Krueger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2601.01155v2",
    "title": "ORION: Option-Regularized Deep Reinforcement Learning for Cooperative Multi-Agent Online Navigation",
    "summary": "Existing methods for multi-agent navigation typically assume fully known environments, offering limited support for partially known scenarios such as warehouses or factory floors. There, agents may need to plan trajectories that balance their own path optimality with their ability to collect and share information about the environment that can help their teammates reach their own goals. To these ends, we propose ORION, a novel deep reinforcement learning framework for cooperative multi-agent online navigation in partially known environments. Starting from an imperfect prior map, ORION trains agents to make decentralized decisions, coordinate to reach their individual targets, and actively reduce map uncertainty by sharing online observations in a closed perception-action loop. We first design a shared graph encoder that fuses prior map with online perception into a unified representation, providing robust state embeddings under dynamic map discrepancies. At the core of ORION is an option-critic framework that learns to reason about a set of high-level cooperative modes that translate into sequences of low-level actions, allowing agents to switch between individual navigation and team-level exploration adaptively. We further introduce a dual-stage cooperation strategy that enables agents to assist teammates under map uncertainty, thereby reducing the overall makespan. Across extensive maze-like maps and large-scale warehouse environments, our simulation results show that ORION achieves high-quality, real-time decentralized cooperation over varying team sizes, outperforming state-of-the-art classical and learning-based baselines. Finally, we validate ORION on physical robot teams, demonstrating its robustness and practicality for real-world cooperative navigation.",
    "published": "2026-01-03T10:55:10Z",
    "updated": "2026-01-26T08:48:21Z",
    "link": "http://arxiv.org/pdf/2601.01155v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Shizhe Zhang",
      "Jingsong Liang",
      "Zhitao Zhou",
      "Shuhan Ye",
      "Yizhuo Wang",
      "Ming Siang Derek Tan",
      "Jimmy Chiun",
      "Yuhong Cao",
      "Guillaume Sartoretti"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.11908v2",
    "title": "Safe Learning for Contact-Rich Robot Tasks: A Survey from Classical Learning-Based Methods to Safe Foundation Models",
    "summary": "Contact-rich tasks pose significant challenges for robotic systems due to inherent uncertainty, complex dynamics, and the high risk of damage during interaction. Recent advances in learning-based control have shown great potential in enabling robots to acquire and generalize complex manipulation skills in such environments, but ensuring safety, both during exploration and execution, remains a critical bottleneck for reliable real-world deployment. This survey provides a comprehensive overview of safe learning-based methods for robot contact-rich tasks. We categorize existing approaches into two main domains: safe exploration and safe execution. We review key techniques, including constrained reinforcement learning, risk-sensitive optimization, uncertainty-aware modeling, control barrier functions, and model predictive safety shields, and highlight how these methods incorporate prior knowledge, task structure, and online adaptation to balance safety and efficiency. A particular emphasis of this survey is on how these safe learning principles extend to and interact with emerging robotic foundation models, especially vision-language models (VLMs) and vision-language-action models (VLAs), which unify perception, language, and control for contact-rich manipulation. We discuss both the new safety opportunities enabled by VLM/VLA-based methods, such as language-level specification of constraints and multimodal grounding of safety signals, and the amplified risks and evaluation challenges they introduce. Finally, we outline current limitations and promising future directions toward deploying reliable, safety-aligned, and foundation-model-enabled robots in complex contact-rich environments. More details and materials are available at our \\href{ https://github.com/jack-sherman01/Awesome-Learning4Safe-Contact-rich-tasks}{Project GitHub Repository}.",
    "published": "2025-12-10T21:01:02Z",
    "updated": "2026-01-26T07:32:41Z",
    "link": "http://arxiv.org/pdf/2512.11908v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Heng Zhang",
      "Rui Dai",
      "Gokhan Solak",
      "Pokuang Zhou",
      "Yu She",
      "Arash Ajoudani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.10481v2",
    "title": "Contact SLAM: An Active Tactile Exploration Policy Based on Physical Reasoning Utilized in Robotic Fine Blind Manipulation Tasks",
    "summary": "Contact-rich manipulation is difficult for robots to execute and requires accurate perception of the environment. In some scenarios, vision is occluded. The robot can then no longer obtain real-time scene state information through visual feedback. This is called ``blind manipulation\". In this manuscript, a novel physically-driven contact cognition method, called ``Contact SLAM\", is proposed. It estimates the state of the environment and achieves manipulation using only tactile sensing and prior knowledge of the scene. To maximize exploration efficiency, this manuscript also designs an active exploration policy. The policy gradually reduces uncertainties in the manipulation scene. The experimental results demonstrated the effectiveness and accuracy of the proposed method in several contact-rich tasks, including the difficult and delicate socket assembly task and block-pushing task.",
    "published": "2025-12-11T09:59:08Z",
    "updated": "2026-01-26T07:20:46Z",
    "link": "http://arxiv.org/pdf/2512.10481v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Gaozhao Wang",
      "Xing Liu",
      "Zhenduo Ye",
      "Zhengxiong Liu",
      "Panfeng Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.10961v3",
    "title": "EquiContact: A Hierarchical SE(3) Vision-to-Force Equivariant Policy for Spatially Generalizable Contact-rich Tasks",
    "summary": "This paper presents a framework for learning vision-based robotic policies for contact-rich manipulation tasks that generalize spatially across task configurations. We focus on achieving robust spatial generalization of the policy for the peg-in-hole (PiH) task trained from a small number of demonstrations. We propose EquiContact, a hierarchical policy composed of a high-level vision planner (Diffusion Equivariant Descriptor Field, Diff-EDF) and a novel low-level compliant visuomotor policy (Geometric Compliant ACT, G-CompACT). G-CompACT operates using only localized observations (geometrically consistent error vectors (GCEV), force-torque readings, and wrist-mounted RGB images) and produces actions defined in the end-effector frame. Through these design choices, we show that the entire EquiContact pipeline is SE(3)-equivariant, from perception to force control. We also outline three key components for spatially generalizable contact-rich policies: compliance, localized policies, and induced equivariance. Real-world experiments on PiH, screwing, and surface wiping tasks demonstrate a near-perfect success rate and robust generalization to unseen spatial configurations, validating the proposed framework and principles.",
    "published": "2025-07-15T03:45:26Z",
    "updated": "2026-01-26T06:44:47Z",
    "link": "http://arxiv.org/pdf/2507.10961v3.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Joohwan Seo",
      "Arvind Kruthiventy",
      "Soomi Lee",
      "Megan Teng",
      "Seoyeon Choi",
      "Xiang Zhang",
      "Jongeun Choi",
      "Roberto Horowitz"
    ]
  }
]