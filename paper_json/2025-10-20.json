[
  {
    "id": "http://arxiv.org/abs/2510.17802v1",
    "title": "Unbiased Gradient Low-Rank Projection",
    "summary": "Memory-efficient optimization is critical for training increasingly large\nlanguage models (LLMs). A popular strategy involves gradient low-rank\nprojection, storing only the projected optimizer states, with GaLore being a\nrepresentative example. However, a significant drawback of many such methods is\ntheir lack of convergence guarantees, as various low-rank projection approaches\nintroduce inherent biases relative to the original optimization algorithms,\nwhich contribute to performance gaps compared to full-parameter training.\nAiming to tackle this problem, this paper investigates the layerwise sampling\ntechnique for debiasing low-rank projection mechanisms. In particular, an\ninstantiation of the paradigm gives rise to a novel and unbiased low-rank\noptimization method built upon GaLore's mechanism and the Muon algorithm, named\nGaLore Unbiased with Muon (GUM). We theoretically prove our method matches the\nconvergence guarantees of the base Muon algorithm while preserving the memory\nefficiency of low-rank techniques. Empirical experiments on LLM fine-tuning and\npretraining also demonstrate non-trivial improvements over GaLore and even\nbetter performance than full-parameter training. Further investigation shows\nthat the improvement of this technique comes from a more uniform distribution\nof knowledge inside layers, leading to more efficient utilization of the model\nparameter space and better memorization.",
    "published": "2025-10-20T17:59:25Z",
    "updated": "2025-10-20T17:59:25Z",
    "link": "http://arxiv.org/pdf/2510.17802v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "authors": [
      "Rui Pan",
      "Yang Luo",
      "Yuxing Liu",
      "Yang You",
      "Tong Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17797v1",
    "title": "Enterprise Deep Research: Steerable Multi-Agent Deep Research for\n  Enterprise Analytics",
    "summary": "As information grows exponentially, enterprises face increasing pressure to\ntransform unstructured data into coherent, actionable insights. While\nautonomous agents show promise, they often struggle with domain-specific\nnuances, intent alignment, and enterprise integration. We present Enterprise\nDeep Research (EDR), a multi-agent system that integrates (1) a Master Planning\nAgent for adaptive query decomposition, (2) four specialized search agents\n(General, Academic, GitHub, LinkedIn), (3) an extensible MCP-based tool\necosystem supporting NL2SQL, file analysis, and enterprise workflows, (4) a\nVisualization Agent for data-driven insights, and (5) a reflection mechanism\nthat detects knowledge gaps and updates research direction with optional\nhuman-in-the-loop steering guidance. These components enable automated report\ngeneration, real-time streaming, and seamless enterprise deployment, as\nvalidated on internal datasets. On open-ended benchmarks including DeepResearch\nBench and DeepConsult, EDR outperforms state-of-the-art agentic systems without\nany human steering. We release the EDR framework and benchmark trajectories to\nadvance research on multi-agent reasoning applications.\n  Code at https://github.com/SalesforceAIResearch/enterprise-deep-research and\nDataset at https://huggingface.co/datasets/Salesforce/EDR-200",
    "published": "2025-10-20T17:55:11Z",
    "updated": "2025-10-20T17:55:11Z",
    "link": "http://arxiv.org/pdf/2510.17797v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Akshara Prabhakar",
      "Roshan Ram",
      "Zixiang Chen",
      "Silvio Savarese",
      "Frank Wang",
      "Caiming Xiong",
      "Huan Wang",
      "Weiran Yao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17795v1",
    "title": "Executable Knowledge Graphs for Replicating AI Research",
    "summary": "Replicating AI research is a crucial yet challenging task for large language\nmodel (LLM) agents. Existing approaches often struggle to generate executable\ncode, primarily due to insufficient background knowledge and the limitations of\nretrieval-augmented generation (RAG) methods, which fail to capture latent\ntechnical details hidden in referenced papers. Furthermore, previous approaches\ntend to overlook valuable implementation-level code signals and lack structured\nknowledge representations that support multi-granular retrieval and reuse. To\novercome these challenges, we propose Executable Knowledge Graphs (xKG), a\nmodular and pluggable knowledge base that automatically integrates technical\ninsights, code snippets, and domain-specific knowledge extracted from\nscientific literature. When integrated into three agent frameworks with two\ndifferent LLMs, xKG shows substantial performance gains (10.9% with o3-mini) on\nPaperBench, demonstrating its effectiveness as a general and extensible\nsolution for automated AI research replication. Code will released at\nhttps://github.com/zjunlp/xKG.",
    "published": "2025-10-20T17:53:23Z",
    "updated": "2025-10-20T17:53:23Z",
    "link": "http://arxiv.org/pdf/2510.17795v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "cs.SE"
    ],
    "authors": [
      "Yujie Luo",
      "Zhuoyun Yu",
      "Xuehai Wang",
      "Yuqi Zhu",
      "Ningyu Zhang",
      "Lanning Wei",
      "Lun Du",
      "Da Zheng",
      "Huajun Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17793v1",
    "title": "Foundational Automatic Evaluators: Scaling Multi-Task Generative\n  Evaluator Training for Reasoning-Centric Domains",
    "summary": "Finetuning specialized generative evaluators has emerged as a popular\nparadigm to meet the increasing demand for scalable evaluation during both\ntraining and test-time. However, recent work has largely focused on applying\nnew methodology, such as reinforcement learning (RL), to training evaluators,\nshying away from large-scale, data-driven development. In this work, we focus\non data scaling, curating a set of 2.5M samples spanning five unique evaluation\ntasks (pairwise, step-level, reference-free and reference-based verification,\nand single rating) and multiple domains focused on reasoning evaluation. With\nour data, we train Foundational Automatic Reasoning Evaluators (FARE), a family\nof 8B and 20B (with 3.6B active) parameter evaluators, with a simple iterative\nrejection-sampling supervised finetuning (SFT) approach. FARE-8B challenges\nlarger specialized RL-trained evaluators and FARE-20B sets the new standard for\nopen-source evaluators, surpassing specialized 70B+ evaluators. Beyond static\nbenchmarks, we evaluate FARE in real-world tasks: As inference-time rerankers,\nFARE-20B achieves near-oracle performance on MATH. As verifiers in RL training,\nFARE improves the downstream RL-trained model performance by up to 14.1% vs.\nstring-matching verifiers. When initialized from FARE, a continually-finetuned\nFARE-Code outperforms gpt-oss-20B by 65% on evaluating test-case quality.",
    "published": "2025-10-20T17:52:06Z",
    "updated": "2025-10-20T17:52:06Z",
    "link": "http://arxiv.org/pdf/2510.17793v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Austin Xu",
      "Xuan-Phi Nguyen",
      "Yilun Zhou",
      "Chien-Sheng Wu",
      "Caiming Xiong",
      "Shafiq Joty"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.07578v2",
    "title": "Denoising the Future: Top-p Distributions for Moving Through Time",
    "summary": "Inference in dynamic probabilistic models is a complex task involving\nexpensive operations. In particular, for Hidden Markov Models, the whole state\nspace has to be enumerated for advancing in time. Even states with negligible\nprobabilities are considered, resulting in computational inefficiency and\nincreased noise due to the propagation of unlikely probability mass. We propose\nto denoise the future and speed up inference by using only the top-p states,\ni.e., the most probable states with accumulated probability p. We show that the\nerror introduced by using only the top-p states is bound by p and the so-called\nminimal mixing rate of the underlying model. Moreover, in our empirical\nevaluation, we show that we can expect speedups of at least an order of\nmagnitude, while the error in terms of total variation distance is below 0.09.",
    "published": "2025-06-09T09:23:09Z",
    "updated": "2025-10-20T17:51:25Z",
    "link": "http://arxiv.org/pdf/2506.07578v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Florian Andreas Marwitz",
      "Ralf MÃ¶ller",
      "Magnus Bender",
      "Marcel Gehrke"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17792v1",
    "title": "SoftMimic: Learning Compliant Whole-body Control from Examples",
    "summary": "We introduce SoftMimic, a framework for learning compliant whole-body control\npolicies for humanoid robots from example motions. Imitating human motions with\nreinforcement learning allows humanoids to quickly learn new skills, but\nexisting methods incentivize stiff control that aggressively corrects\ndeviations from a reference motion, leading to brittle and unsafe behavior when\nthe robot encounters unexpected contacts. In contrast, SoftMimic enables robots\nto respond compliantly to external forces while maintaining balance and\nposture. Our approach leverages an inverse kinematics solver to generate an\naugmented dataset of feasible compliant motions, which we use to train a\nreinforcement learning policy. By rewarding the policy for matching compliant\nresponses rather than rigidly tracking the reference motion, SoftMimic learns\nto absorb disturbances and generalize to varied tasks from a single motion\nclip. We validate our method through simulations and real-world experiments,\ndemonstrating safe and effective interaction with the environment.",
    "published": "2025-10-20T17:49:27Z",
    "updated": "2025-10-20T17:49:27Z",
    "link": "http://arxiv.org/pdf/2510.17792v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Gabriel B. Margolis",
      "Michelle Wang",
      "Nolan Fey",
      "Pulkit Agrawal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.10815v3",
    "title": "DRIFT: Decompose, Retrieve, Illustrate, then Formalize Theorems",
    "summary": "Automating the formalization of mathematical statements for theorem proving\nremains a major challenge for Large Language Models (LLMs). LLMs struggle to\nidentify and utilize the prerequisite mathematical knowledge and its\ncorresponding formal representation in languages like Lean. Current\nretrieval-augmented autoformalization methods query external libraries using\nthe informal statement directly, but overlook a fundamental limitation:\ninformal mathematical statements are often complex and offer limited context on\nthe underlying math concepts. To address this, we introduce DRIFT, a novel\nframework that enables LLMs to decompose informal mathematical statements into\nsmaller, more tractable ''sub-components''. This facilitates targeted retrieval\nof premises from mathematical libraries such as Mathlib. Additionally, DRIFT\nretrieves illustrative theorems to help models use premises more effectively in\nformalization tasks. We evaluate DRIFT across diverse benchmarks (ProofNet,\nConNF, and MiniF2F-test) and find that it consistently improves premise\nretrieval, nearly doubling the F1 score compared to the DPR baseline on\nProofNet. Notably, DRIFT demonstrates strong performance on the\nout-of-distribution ConNF benchmark, with BEq+@10 improvements of 37.14% and\n42.25% using GPT-4.1 and DeepSeek-V3.1, respectively. Our analysis shows that\nretrieval effectiveness in mathematical autoformalization depends heavily on\nmodel-specific knowledge boundaries, highlighting the need for adaptive\nretrieval strategies aligned with each model's capabilities.",
    "published": "2025-10-12T21:42:04Z",
    "updated": "2025-10-20T17:46:57Z",
    "link": "http://arxiv.org/pdf/2510.10815v3.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.SC"
    ],
    "authors": [
      "Meiru Zhang",
      "Philipp Borchert",
      "Milan Gritta",
      "Gerasimos Lampouras"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17776v1",
    "title": "Mapping Post-Training Forgetting in Language Models at Scale",
    "summary": "Scaled post-training now drives many of the largest capability gains in\nlanguage models (LMs), yet its effect on pretrained knowledge remains poorly\nunderstood. Not all forgetting is equal: Forgetting one fact (e.g., a U.S.\npresident or an API call) does not \"average out\" by recalling another. Hence,\nwe propose a sample-wise paradigm to measure what is forgotten and when\nbackward transfer occurs. Our metric counts 1->0 transitions (correct before\npost-training, incorrect after) to quantify forgetting and 0->1 transitions to\nquantify backward transfer. Traditional task averages conflate these effects\nand obscure large changes. For multiple-choice benchmarks, we add\nchance-adjusted variants that subtract the expected contribution of random\nguessing from pre- and post-training accuracies. We apply this framework across\npost-training stages, model sizes, and data scales. Our large-scale analysis\nshows that: (1) Domain-continual pretraining induces moderate forgetting with\nlow-to-moderate backward transfer; (2) RL/SFT post-training applied to base\nmodels and Instruction tuning yields moderate-to-large backward transfer on\nmath and logic with overall low-to-moderate forgetting; (3) Applying RL/SFT to\ninstruction-tuned models is sensitive on data scale: at small scales, both\nforgetting and backward transfer are small; at larger scales, effects are mixed\nand warrant further study with better controls; (4) Model merging does not\nreliably mitigate forgetting. Overall, our framework offers a practical\nyardstick for mapping how post-training alters pretrained knowledge at scale --\nenabling progress towards generally capable AI systems.",
    "published": "2025-10-20T17:35:47Z",
    "updated": "2025-10-20T17:35:47Z",
    "link": "http://arxiv.org/pdf/2510.17776v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Jackson Harmon",
      "Andreas Hochlehnert",
      "Matthias Bethge",
      "Ameya Prabhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17773v1",
    "title": "Towards Explainable Skin Cancer Classification: A Dual-Network Attention\n  Model with Lesion Segmentation and Clinical Metadata Fusion",
    "summary": "Skin cancer is a life-threatening disease where early detection significantly\nimproves patient outcomes. Automated diagnosis from dermoscopic images is\nchallenging due to high intra-class variability and subtle inter-class\ndifferences. Many deep learning models operate as \"black boxes,\" limiting\nclinical trust. In this work, we propose a dual-encoder attention-based\nframework that leverages both segmented lesions and clinical metadata to\nenhance skin lesion classification in terms of both accuracy and\ninterpretability. A novel Deep-UNet architecture with Dual Attention Gates\n(DAG) and Atrous Spatial Pyramid Pooling (ASPP) is first employed to segment\nlesions. The classification stage uses two DenseNet201 encoders-one on the\noriginal image and another on the segmented lesion whose features are fused via\nmulti-head cross-attention. This dual-input design guides the model to focus on\nsalient pathological regions. In addition, a transformer-based module\nincorporates patient metadata (age, sex, lesion site) into the prediction. We\nevaluate our approach on the HAM10000 dataset and the ISIC 2018 and 2019\nchallenges. The proposed method achieves state-of-the-art segmentation\nperformance and significantly improves classification accuracy and average AUC\ncompared to baseline models. To validate our model's reliability, we use\nGradient-weighted Class Activation Mapping (Grad-CAM) to generate heatmaps.\nThese visualizations confirm that our model's predictions are based on the\nlesion area, unlike models that rely on spurious background features. These\nresults demonstrate that integrating precise lesion segmentation and clinical\ndata with attention-based fusion leads to a more accurate and interpretable\nskin cancer classification model.",
    "published": "2025-10-20T17:33:51Z",
    "updated": "2025-10-20T17:33:51Z",
    "link": "http://arxiv.org/pdf/2510.17773v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Md. Enamul Atiq",
      "Shaikh Anowarul Fattah"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17771v1",
    "title": "Seeing but Not Believing: Probing the Disconnect Between Visual\n  Attention and Answer Correctness in VLMs",
    "summary": "Vision-Language Models (VLMs) achieve strong results on multimodal tasks such\nas visual question answering, yet they can still fail even when the correct\nvisual evidence is present. In this work, we systematically investigate whether\nthese failures arise from not perceiving the evidence or from not leveraging it\neffectively. By examining layer-wise attention dynamics, we find that shallow\nlayers focus primarily on text, while deeper layers sparsely but reliably\nattend to localized evidence regions. Surprisingly, VLMs often perceive the\nvisual evidence when outputting incorrect answers, a phenomenon we term\n``seeing but not believing'' that widely exists in major VLM families. Building\non this, we introduce an inference-time intervention that highlights deep-layer\nevidence regions through selective attention-based masking. It requires no\ntraining and consistently improves accuracy across multiple families, including\nLLaVA, Qwen, Gemma, and InternVL. These results show that VLMs encode reliable\nevidence internally but under-utilize it, making such signals explicit can\nbridge the gap between perception and reasoning, advancing the diagnostic\nunderstanding and reliability of VLMs.",
    "published": "2025-10-20T17:31:09Z",
    "updated": "2025-10-20T17:31:09Z",
    "link": "http://arxiv.org/pdf/2510.17771v1.pdf",
    "category": [
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Zhining Liu",
      "Ziyi Chen",
      "Hui Liu",
      "Chen Luo",
      "Xianfeng Tang",
      "Suhang Wang",
      "Joy Zeng",
      "Zhenwei Dai",
      "Zhan Shi",
      "Tianxin Wei",
      "Benoit Dumoulin",
      "Hanghang Tong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.24760v2",
    "title": "REASONING GYM: Reasoning Environments for Reinforcement Learning with\n  Verifiable Rewards",
    "summary": "We introduce Reasoning Gym (RG), a library of reasoning environments for\nreinforcement learning with verifiable rewards. It provides over 100 data\ngenerators and verifiers spanning multiple domains including algebra,\narithmetic, computation, cognition, geometry, graph theory, logic, and various\ncommon games. Its key innovation is the ability to generate virtually infinite\ntraining data with adjustable complexity, unlike most previous reasoning\ndatasets, which are typically fixed. This procedural generation approach allows\nfor continuous evaluation across varying difficulty levels. Our experimental\nresults demonstrate the efficacy of RG in both evaluating and reinforcement\nlearning of reasoning models.",
    "published": "2025-05-30T16:20:18Z",
    "updated": "2025-10-20T17:28:35Z",
    "link": "http://arxiv.org/pdf/2505.24760v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Zafir Stojanovski",
      "Oliver Stanley",
      "Joe Sharratt",
      "Richard Jones",
      "Abdulhakeem Adefioye",
      "Jean Kaddour",
      "Andreas KÃ¶pf"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.03095v3",
    "title": "Evolution of AI Agent Registry Solutions: Centralized, Enterprise, and\n  Distributed Approaches",
    "summary": "Autonomous AI agents now operate across cloud, enterprise, and decentralized\ndomains, creating demand for registry infrastructures that enable trustworthy\ndiscovery, capability negotiation, and identity assurance. We analyze five\nprominent approaches: (1) MCP Registry (centralized publication of mcp.json\ndescriptors), (2) A2A Agent Cards (decentralized self-describing JSON\ncapability manifests), (3) AGNTCY Agent Directory Service (IPFS Kademlia DHT\ncontent routing extended for semantic taxonomy-based content discovery, OCI\nartifact storage, and Sigstore-backed integrity), (4) Microsoft Entra Agent ID\n(enterprise SaaS directory with policy and zero-trust integration), and (5)\nNANDA Index AgentFacts (cryptographically verifiable, privacy-preserving fact\nmodel with credentialed assertions). Using four evaluation dimensions:\nsecurity, authentication, scalability, and maintainability, we surface\narchitectural trade-offs between centralized control, enterprise governance,\nand distributed resilience. We conclude with design recommendations for an\nemerging Internet of AI Agents requiring verifiable identity, adaptive\ndiscovery flows, and interoperable capability semantics.",
    "published": "2025-08-05T05:17:18Z",
    "updated": "2025-10-20T17:13:35Z",
    "link": "http://arxiv.org/pdf/2508.03095v3.pdf",
    "category": [
      "cs.NI",
      "cs.AI",
      "cs.MA"
    ],
    "authors": [
      "Aditi Singh",
      "Abul Ehtesham",
      "Mahesh Lambe",
      "Jared James Grogan",
      "Abhishek Singh",
      "Saket Kumar",
      "Luca Muscariello",
      "Vijoy Pandey",
      "Guillaume Sauvage De Saint Marc",
      "Pradyumna Chari",
      "Ramesh Raskar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17756v1",
    "title": "Prediction of Sea Ice Velocity and Concentration in the Arctic Ocean\n  using Physics-informed Neural Network",
    "summary": "As an increasing amount of remote sensing data becomes available in the\nArctic Ocean, data-driven machine learning (ML) techniques are becoming widely\nused to predict sea ice velocity (SIV) and sea ice concentration (SIC).\nHowever, fully data-driven ML models have limitations in generalizability and\nphysical consistency due to their excessive reliance on the quantity and\nquality of training data. In particular, as Arctic sea ice entered a new phase\nwith thinner ice and accelerated melting, there is a possibility that an ML\nmodel trained with historical sea ice data cannot fully represent the\ndynamically changing sea ice conditions in the future. In this study, we\ndevelop physics-informed neural network (PINN) strategies to integrate physical\nknowledge of sea ice into the ML model. Based on the Hierarchical\nInformation-sharing U-net (HIS-Unet) architecture, we incorporate the physics\nloss function and the activation function to produce physically plausible SIV\nand SIC outputs. Our PINN model outperforms the fully data-driven model in the\ndaily predictions of SIV and SIC, even when trained with a small number of\nsamples. The PINN approach particularly improves SIC predictions in melting and\nearly freezing seasons and near fast-moving ice regions.",
    "published": "2025-10-20T17:10:01Z",
    "updated": "2025-10-20T17:10:01Z",
    "link": "http://arxiv.org/pdf/2510.17756v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Younghyun Koo",
      "Maryam Rahnemoonfar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17753v1",
    "title": "Human-AI Interactions: Cognitive, Behavioral, and Emotional Impacts",
    "summary": "As stories of human-AI interactions continue to be highlighted in the news\nand research platforms, the challenges are becoming more pronounced, including\npotential risks of overreliance, cognitive offloading, social and emotional\nmanipulation, and the nuanced degradation of human agency and judgment. This\npaper surveys recent research on these issues through the lens of the\npsychological triad: cognition, behavior, and emotion. Observations seem to\nsuggest that while AI can substantially enhance memory, creativity, and\nengagement, it also introduces risks such as diminished critical thinking,\nskill erosion, and increased anxiety. Emotional outcomes are similarly mixed,\nwith AI systems showing promise for support and stress reduction, but raising\nconcerns about dependency, inappropriate attachments, and ethical oversight.\nThis paper aims to underscore the need for responsible and context-aware AI\ndesign, highlighting gaps for longitudinal research and grounded evaluation\nframeworks to balance benefits with emerging human-centric risks.",
    "published": "2025-10-20T17:06:46Z",
    "updated": "2025-10-20T17:06:46Z",
    "link": "http://arxiv.org/pdf/2510.17753v1.pdf",
    "category": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "authors": [
      "Celeste Riley",
      "Omar Al-Refai",
      "Yadira Colunga Reyes",
      "Eman Hammad"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17745v1",
    "title": "A Multi-Threading Kernel for Enabling Neuromorphic Edge Applications",
    "summary": "Spiking Neural Networks (SNNs) have sparse, event driven processing that can\nleverage neuromorphic applications. In this work, we introduce a\nmulti-threading kernel that enables neuromorphic applications running at the\nedge, meaning they process sensory input directly and without any up-link to or\ndependency on a cloud service. The kernel shows speed-up gains over single\nthread processing by a factor of four on moderately sized SNNs and 1.7X on a\nSynfire network. Furthermore, it load-balances all cores available on\nmulti-core processors, such as ARM, which run today's mobile devices and is up\nto 70% more energy efficient compared to statical core assignment. The present\nwork can enable the development of edge applications that have low Size,\nWeight, and Power (SWaP), and can prototype the integration of neuromorphic\nchips.",
    "published": "2025-10-20T17:01:18Z",
    "updated": "2025-10-20T17:01:18Z",
    "link": "http://arxiv.org/pdf/2510.17745v1.pdf",
    "category": [
      "cs.NE",
      "cs.AI"
    ],
    "authors": [
      "Lars Niedermeier",
      "Vyom Shah",
      "Jeffrey L. Krichmar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.14623v2",
    "title": "LeapFactual: Reliable Visual Counterfactual Explanation Using\n  Conditional Flow Matching",
    "summary": "The growing integration of machine learning (ML) and artificial intelligence\n(AI) models into high-stakes domains such as healthcare and scientific research\ncalls for models that are not only accurate but also interpretable. Among the\nexisting explainable methods, counterfactual explanations offer\ninterpretability by identifying minimal changes to inputs that would alter a\nmodel's prediction, thus providing deeper insights. However, current\ncounterfactual generation methods suffer from critical limitations, including\ngradient vanishing, discontinuous latent spaces, and an overreliance on the\nalignment between learned and true decision boundaries. To overcome these\nlimitations, we propose LeapFactual, a novel counterfactual explanation\nalgorithm based on conditional flow matching. LeapFactual generates reliable\nand informative counterfactuals, even when true and learned decision boundaries\ndiverge. Following a model-agnostic approach, LeapFactual is not limited to\nmodels with differentiable loss functions. It can even handle human-in-the-loop\nsystems, expanding the scope of counterfactual explanations to domains that\nrequire the participation of human annotators, such as citizen science. We\nprovide extensive experiments on benchmark and real-world datasets showing that\nLeapFactual generates accurate and in-distribution counterfactual explanations\nthat offer actionable insights. We observe, for instance, that our reliable\ncounterfactual samples with labels aligning to ground truth can be beneficially\nused as new training data to enhance the model. The proposed method is broadly\napplicable and enhances both scientific knowledge discovery and non-expert\ninterpretability.",
    "published": "2025-10-16T12:34:10Z",
    "updated": "2025-10-20T16:46:23Z",
    "link": "http://arxiv.org/pdf/2510.14623v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Zhuo Cao",
      "Xuan Zhao",
      "Lena Krieger",
      "Hanno Scharr",
      "Ira Assent"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17725v1",
    "title": "AcademicEval: Live Long-Context LLM Benchmark",
    "summary": "Large Language Models (LLMs) have recently achieved remarkable performance in\nlong-context understanding. However, current long-context LLM benchmarks are\nlimited by rigid context length, labor-intensive annotation, and the pressing\nchallenge of label leakage issues during LLM training. Therefore, we propose\n\\textsc{AcademicEval}, a live benchmark for evaluating LLMs over long-context\ngeneration tasks. \\textsc{AcademicEval} adopts papers on arXiv to introduce\nseveral academic writing tasks with long-context inputs, \\textit{i.e.},\n\\textsc{Title}, \\textsc{Abstract}, \\textsc{Introduction}, and \\textsc{Related\nWork}, which cover a wide range of abstraction levels and require no manual\nlabeling. Moreover, \\textsc{AcademicEval} integrates high-quality and\nexpert-curated few-shot demonstrations from a collected co-author graph to\nenable flexible context length. Especially, \\textsc{AcademicEval} features an\nefficient live evaluation, ensuring no label leakage. We conduct a holistic\nevaluation on \\textsc{AcademicEval}, and the results illustrate that LLMs\nperform poorly on tasks with hierarchical abstraction levels and tend to\nstruggle with long few-shot demonstrations, highlighting the challenge of our\nbenchmark. Through experimental analysis, we also reveal some insights for\nenhancing LLMs' long-context modeling capabilities. Code is available at\nhttps://github.com/ulab-uiuc/AcademicEval",
    "published": "2025-10-20T16:42:30Z",
    "updated": "2025-10-20T16:42:30Z",
    "link": "http://arxiv.org/pdf/2510.17725v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Haozhen Zhang",
      "Tao Feng",
      "Pengrui Han",
      "Jiaxuan You"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17724v1",
    "title": "Signature Forgery Detection: Improving Cross-Dataset Generalization",
    "summary": "Automated signature verification is a critical biometric technique used in\nbanking, identity authentication, and legal documentation. Despite the notable\nprogress achieved by deep learning methods, most approaches in offline\nsignature verification still struggle to generalize across datasets, as\nvariations in handwriting styles and acquisition protocols often degrade\nperformance. This study investigates feature learning strategies for signature\nforgery detection, focusing on improving cross-dataset generalization -- that\nis, model robustness when trained on one dataset and tested on another. Using\nthree public benchmarks -- CEDAR, ICDAR, and GPDS Synthetic -- two experimental\npipelines were developed: one based on raw signature images and another\nemploying a preprocessing method referred to as shell preprocessing. Several\nbehavioral patterns were identified and analyzed; however, no definitive\nsuperiority between the two approaches was established. The results show that\nthe raw-image model achieved higher performance across benchmarks, while the\nshell-based model demonstrated promising potential for future refinement toward\nrobust, cross-domain signature verification.",
    "published": "2025-10-20T16:42:21Z",
    "updated": "2025-10-20T16:42:21Z",
    "link": "http://arxiv.org/pdf/2510.17724v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Matheus Ramos Parracho"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17722v1",
    "title": "MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating\n  Multimodal LLMs in Multi-Turn Dialogues",
    "summary": "The recent development of Multimodal Large Language Models (MLLMs) has\nsignificantly advanced AI's ability to understand visual modalities. However,\nexisting evaluation benchmarks remain limited to single-turn question\nanswering, overlooking the complexity of multi-turn dialogues in real-world\nscenarios. To bridge this gap, we introduce MT-Video-Bench, a holistic video\nunderstanding benchmark for evaluating MLLMs in multi-turn dialogues.\nSpecifically, our MT-Video-Bench mainly assesses six core competencies that\nfocus on perceptivity and interactivity, encompassing 987 meticulously curated\nmulti-turn dialogues from diverse domains. These capabilities are rigorously\naligned with real-world applications, such as interactive sports analysis and\nmulti-turn video-based intelligent tutoring. With MT-Video-Bench, we\nextensively evaluate various state-of-the-art open-source and closed-source\nMLLMs, revealing their significant performance discrepancies and limitations in\nhandling multi-turn video dialogues. The benchmark will be publicly available\nto foster future research.",
    "published": "2025-10-20T16:38:40Z",
    "updated": "2025-10-20T16:38:40Z",
    "link": "http://arxiv.org/pdf/2510.17722v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Yaning Pan",
      "Zekun Wang",
      "Qianqian Xie",
      "Yongqian Wen",
      "Yuanxing Zhang",
      "Guohui Zhang",
      "Haoxuan Hu",
      "Zhiyu Pan",
      "Yibing Huang",
      "Zhidong Gan",
      "Yonghong Lin",
      "An Ping",
      "Tianhao Peng",
      "Jiaheng Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17720v1",
    "title": "PANER: A Paraphrase-Augmented Framework for Low-Resource Named Entity\n  Recognition",
    "summary": "Named Entity Recognition (NER) is a critical task that requires substantial\nannotated data, making it challenging in low-resource scenarios where label\nacquisition is expensive. While zero-shot and instruction-tuned approaches have\nmade progress, they often fail to generalize to domain-specific entities and do\nnot effectively utilize limited available data. We present a lightweight\nfew-shot NER framework that addresses these challenges through two key\ninnovations: (1) a new instruction tuning template with a simplified output\nformat that combines principles from prior IT approaches to leverage the large\ncontext window of recent state-of-the-art LLMs; (2) introducing a strategic\ndata augmentation technique that preserves entity information while\nparaphrasing the surrounding context, thereby expanding our training data\nwithout compromising semantic relationships. Experiments on benchmark datasets\nshow that our method achieves performance comparable to state-of-the-art models\non few-shot and zero-shot tasks, with our few-shot approach attaining an\naverage F1 score of 80.1 on the CrossNER datasets. Models trained with our\nparaphrasing approach show consistent improvements in F1 scores of up to 17\npoints over baseline versions, offering a promising solution for groups with\nlimited NER training data and compute power.",
    "published": "2025-10-20T16:36:18Z",
    "updated": "2025-10-20T16:36:18Z",
    "link": "http://arxiv.org/pdf/2510.17720v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Nanda Kumar Rengarajan",
      "Jun Yan",
      "Chun Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17709v1",
    "title": "Closing the Sim2Real Performance Gap in RL",
    "summary": "Sim2Real aims at training policies in high-fidelity simulation environments\nand effectively transferring them to the real world. Despite the developments\nof accurate simulators and Sim2Real RL approaches, the policies trained purely\nin simulation often suffer significant performance drops when deployed in real\nenvironments. This drop is referred to as the Sim2Real performance gap. Current\nSim2Real RL methods optimize the simulator accuracy and variability as proxies\nfor real-world performance. However, these metrics do not necessarily correlate\nwith the real-world performance of the policy as established theoretically and\nempirically in the literature. We propose a novel framework to address this\nissue by directly adapting the simulator parameters based on real-world\nperformance. We frame this problem as a bi-level RL framework: the inner-level\nRL trains a policy purely in simulation, and the outer-level RL adapts the\nsimulation model and in-sim reward parameters to maximize real-world\nperformance of the in-sim policy. We derive and validate in simple examples the\nmathematical tools needed to develop bi-level RL algorithms that close the\nSim2Real performance gap.",
    "published": "2025-10-20T16:25:13Z",
    "updated": "2025-10-20T16:25:13Z",
    "link": "http://arxiv.org/pdf/2510.17709v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Akhil S Anand",
      "Shambhuraj Sawant",
      "Jasper Hoffmann",
      "Dirk Reinhardt",
      "Sebastien Gros"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.17451v2",
    "title": "CLIMB: Class-imbalanced Learning Benchmark on Tabular Data",
    "summary": "Class-imbalanced learning (CIL) on tabular data is important in many\nreal-world applications where the minority class holds the critical but rare\noutcomes. In this paper, we present CLIMB, a comprehensive benchmark for\nclass-imbalanced learning on tabular data. CLIMB includes 73 real-world\ndatasets across diverse domains and imbalance levels, along with unified\nimplementations of 29 representative CIL algorithms. Built on a high-quality\nopen-source Python package with unified API designs, detailed documentation,\nand rigorous code quality controls, CLIMB supports easy implementation and\ncomparison between different CIL algorithms. Through extensive experiments, we\nprovide practical insights on method accuracy and efficiency, highlighting the\nlimitations of naive rebalancing, the effectiveness of ensembles, and the\nimportance of data quality. Our code, documentation, and examples are available\nat https://github.com/ZhiningLiu1998/imbalanced-ensemble.",
    "published": "2025-05-23T04:21:03Z",
    "updated": "2025-10-20T16:25:08Z",
    "link": "http://arxiv.org/pdf/2505.17451v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Zhining Liu",
      "Zihao Li",
      "Ze Yang",
      "Tianxin Wei",
      "Jian Kang",
      "Yada Zhu",
      "Hendrik Hamann",
      "Jingrui He",
      "Hanghang Tong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17705v1",
    "title": "Contextual Attention Modulation: Towards Efficient Multi-Task Adaptation\n  in Large Language Models",
    "summary": "Large Language Models (LLMs) possess remarkable generalization capabilities\nbut struggle with multi-task adaptation, particularly in balancing knowledge\nretention with task-specific specialization. Conventional fine-tuning methods\nsuffer from catastrophic forgetting and substantial resource consumption, while\nexisting parameter-efficient methods perform suboptimally in complex multi-task\nscenarios. To address this, we propose Contextual Attention Modulation (CAM), a\nnovel mechanism that dynamically modulates the representations of\nself-attention modules in LLMs. CAM enhances task-specific features while\npreserving general knowledge, thereby facilitating more effective and efficient\nadaptation. For effective multi-task adaptation, CAM is integrated into our\nHybrid Contextual Attention Modulation (HyCAM) framework, which combines a\nshared, full-parameter CAM module with multiple specialized, lightweight CAM\nmodules, enhanced by a dynamic routing strategy for adaptive knowledge fusion.\nExtensive experiments on heterogeneous tasks, including question answering,\ncode generation, and logical reasoning, demonstrate that our approach\nsignificantly outperforms existing approaches, achieving an average performance\nimprovement of 3.65%. The implemented code and data are available to ease\nreproducibility at https://github.com/Applied-Machine-Learning-Lab/HyCAM.",
    "published": "2025-10-20T16:19:27Z",
    "updated": "2025-10-20T16:19:27Z",
    "link": "http://arxiv.org/pdf/2510.17705v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Dayan Pan",
      "Zhaoyang Fu",
      "Jingyuan Wang",
      "Xiao Han",
      "Yue Zhu",
      "Xiangyu Zhao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17703v1",
    "title": "Improving Cross-Patient Generalization in Parkinson's Disease Detection\n  through Chunk-Based Analysis of Hand-Drawn Patterns",
    "summary": "Parkinson's disease (PD) is a neurodegenerative disease affecting about 1% of\npeople over the age of 60, causing motor impairments that impede hand\ncoordination activities such as writing and drawing. Many approaches have tried\nto support early detection of Parkinson's disease based on hand-drawn images;\nhowever, we identified two major limitations in the related works: (1) the lack\nof sufficient datasets, (2) the robustness when dealing with unseen patient\ndata. In this paper, we propose a new approach to detect Parkinson's disease\nthat consists of two stages: The first stage classifies based on their drawing\ntype(circle, meander, spiral), and the second stage extracts the required\nfeatures from the images and detects Parkinson's disease. We overcame the\nprevious two limitations by applying a chunking strategy where we divide each\nimage into 2x2 chunks. Each chunk is processed separately when extracting\nfeatures and recognizing Parkinson's disease indicators. To make the final\nclassification, an ensemble method is used to merge the decisions made from\neach chunk. Our evaluation shows that our proposed approach outperforms the top\nperforming state-of-the-art approaches, in particular on unseen patients. On\nthe NewHandPD dataset our approach, it achieved 97.08% accuracy for seen\npatients and 94.91% for unseen patients, our proposed approach maintained a gap\nof only 2.17 percentage points, compared to the 4.76-point drop observed in\nprior work.",
    "published": "2025-10-20T16:18:36Z",
    "updated": "2025-10-20T16:18:36Z",
    "link": "http://arxiv.org/pdf/2510.17703v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Mhd Adnan Albani",
      "Riad Sonbol"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17697v1",
    "title": "A Principle of Targeted Intervention for Multi-Agent Reinforcement\n  Learning",
    "summary": "Steering cooperative multi-agent reinforcement learning (MARL) towards\ndesired outcomes is challenging, particularly when the global guidance from a\nhuman on the whole multi-agent system is impractical in a large-scale MARL. On\nthe other hand, designing mechanisms to coordinate agents most relies on\nempirical studies, lacking a easy-to-use research tool. In this work, we employ\nmulti-agent influence diagrams (MAIDs) as a graphical framework to address the\nabove issues. First, we introduce interaction paradigms that leverage MAIDs to\nanalyze and visualize existing approaches in MARL. Then, we design a new\ninteraction paradigm based on MAIDs, referred to as targeted intervention that\nis applied to only a single targeted agent, so the problem of global guidance\ncan be mitigated. In our implementation, we introduce a causal inference\ntechnique-referred to as Pre-Strategy Intervention (PSI)-to realize the\ntargeted intervention paradigm. Since MAIDs can be regarded as a special class\nof causal diagrams, a composite desired outcome that integrates the primary\ntask goal and an additional desired outcome can be achieved by maximizing the\ncorresponding causal effect through the PSI. Moreover, the bundled relevance\ngraph analysis of MAIDs provides a tool to identify whether an MARL learning\nparadigm is workable under the design of an interaction paradigm. In\nexperiments, we demonstrate the effectiveness of our proposed targeted\nintervention, and verify the result of relevance graph analysis.",
    "published": "2025-10-20T16:10:56Z",
    "updated": "2025-10-20T16:10:56Z",
    "link": "http://arxiv.org/pdf/2510.17697v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "I.2.11; I.2.6"
    ],
    "authors": [
      "Anjie Liu",
      "Jianhong Wang",
      "Samuel Kaski",
      "Jun Wang",
      "Mengyue Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.03308v2",
    "title": "Creative synthesis of kinematic mechanisms",
    "summary": "In this paper, we formulate the problem of kinematic synthesis for planar\nlinkages as a cross-domain image generation task. We develop a planar linkages\ndataset using RGB image representations, covering a range of mechanisms: from\nsimple types such as crank-rocker and crank-slider to more complex eight-bar\nlinkages like Jansen's mechanism. A shared-latent variational autoencoder (VAE)\nis employed to explore the potential of image generative models for\nsynthesizing unseen motion curves and simulating novel kinematics. By encoding\nthe drawing speed of trajectory points as color gradients, the same\narchitecture also supports kinematic synthesis conditioned on both trajectory\nshape and velocity profiles. We validate our method on three datasets of\nincreasing complexity: a standard four-bar linkage set, a mixed set of four-bar\nand crank-slider mechanisms, and a complex set including multi-loop mechanisms.\nPreliminary results demonstrate the effectiveness of image-based\nrepresentations for generative mechanical design, showing that mechanisms with\nrevolute and prismatic joints, and potentially cams and gears, can be\nrepresented and synthesized within a unified image generation framework.",
    "published": "2025-09-30T19:32:30Z",
    "updated": "2025-10-20T16:07:47Z",
    "link": "http://arxiv.org/pdf/2510.03308v2.pdf",
    "category": [
      "cs.GR",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Jiong Lin",
      "Jialong Ning",
      "Judah Goldfeder",
      "Hod Lipson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17687v1",
    "title": "CrossGuard: Safeguarding MLLMs against Joint-Modal Implicit Malicious\n  Attacks",
    "summary": "Multimodal Large Language Models (MLLMs) achieve strong reasoning and\nperception capabilities but are increasingly vulnerable to jailbreak attacks.\nWhile existing work focuses on explicit attacks, where malicious content\nresides in a single modality, recent studies reveal implicit attacks, in which\nbenign text and image inputs jointly express unsafe intent. Such joint-modal\nthreats are difficult to detect and remain underexplored, largely due to the\nscarcity of high-quality implicit data. We propose ImpForge, an automated\nred-teaming pipeline that leverages reinforcement learning with tailored reward\nmodules to generate diverse implicit samples across 14 domains. Building on\nthis dataset, we further develop CrossGuard, an intent-aware safeguard\nproviding robust and comprehensive defense against both explicit and implicit\nthreats. Extensive experiments across safe and unsafe benchmarks, implicit and\nexplicit attacks, and multiple out-of-domain settings demonstrate that\nCrossGuard significantly outperforms existing defenses, including advanced\nMLLMs and guardrails, achieving stronger security while maintaining high\nutility. This offers a balanced and practical solution for enhancing MLLM\nrobustness against real-world multimodal threats.",
    "published": "2025-10-20T16:02:34Z",
    "updated": "2025-10-20T16:02:34Z",
    "link": "http://arxiv.org/pdf/2510.17687v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Xu Zhang",
      "Hao Li",
      "Zhichao Lu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17685v1",
    "title": "Multilingual Text-to-Image Person Retrieval via Bidirectional Relation\n  Reasoning and Aligning",
    "summary": "Text-to-image person retrieval (TIPR) aims to identify the target person\nusing textual descriptions, facing challenge in modality heterogeneity. Prior\nworks have attempted to address it by developing cross-modal global or local\nalignment strategies. However, global methods typically overlook fine-grained\ncross-modal differences, whereas local methods require prior information to\nexplore explicit part alignments. Additionally, current methods are\nEnglish-centric, restricting their application in multilingual contexts. To\nalleviate these issues, we pioneer a multilingual TIPR task by developing a\nmultilingual TIPR benchmark, for which we leverage large language models for\ninitial translations and refine them by integrating domain-specific knowledge.\nCorrespondingly, we propose Bi-IRRA: a Bidirectional Implicit Relation\nReasoning and Aligning framework to learn alignment across languages and\nmodalities. Within Bi-IRRA, a bidirectional implicit relation reasoning module\nenables bidirectional prediction of masked image and text, implicitly enhancing\nthe modeling of local relations across languages and modalities, a\nmulti-dimensional global alignment module is integrated to bridge the modality\nheterogeneity. The proposed method achieves new state-of-the-art results on all\nmultilingual TIPR datasets. Data and code are presented in\nhttps://github.com/Flame-Chasers/Bi-IRRA.",
    "published": "2025-10-20T16:01:11Z",
    "updated": "2025-10-20T16:01:11Z",
    "link": "http://arxiv.org/pdf/2510.17685v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Min Cao",
      "Xinyu Zhou",
      "Ding Jiang",
      "Bo Du",
      "Mang Ye",
      "Min Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17684v1",
    "title": "Intelligent Communication Mixture-of-Experts Boosted-Medical Image\n  Segmentation Foundation Model",
    "summary": "Foundation models for medical image segmentation have achieved remarkable\nperformance. Adaptive fine-tuning of natural image segmentation foundation\nmodels is crucial for medical image segmentation tasks. However, some\nlimitations exist in existing fine-tuning methods: 1) insufficient\nrepresentation of high-level features and 2) the fine-tuning process disrupts\nthe structural integrity of pretrained weights. Inspired by these critical\nproblems, we propose an intelligent communication mixture-of-experts\nboosted-medical image segmentation foundation model, named IC-MoE, with twofold\nideas: 1) We construct basic experts, semantic experts, and adaptive experts.\nMoreover, we implement a pixel probability adaptive voting strategy, which\nenables expert selection and fusion through label consistency and load\nbalancing. This approach preliminarily enhances the representation capability\nof high-level features while preserving the structural integrity of pretrained\nweights. 2) We propose a semantic-guided contrastive learning method to address\nthe issue of weak supervision in contrastive learning. This method further\nenhances the representation capability of high-level features while preserving\nthe structural integrity of pretrained weights. Extensive experiments across\nthree public medical image segmentation datasets demonstrate that the IC-MoE\noutperforms other SOTA models. Consequently, the proposed IC-MoE effectively\nsupplements foundational medical image segmentation models with high-level\nfeatures and pretrained structural integrity. We also validate the superior\ngeneralizability of the IC-MoE across diverse medical image segmentation\nscenarios.",
    "published": "2025-10-20T16:00:59Z",
    "updated": "2025-10-20T16:00:59Z",
    "link": "http://arxiv.org/pdf/2510.17684v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Xinwei Zhang",
      "Hu Chen",
      "Zhe Yuan",
      "Sukun Tian",
      "Peng Feng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17681v1",
    "title": "PICABench: How Far Are We from Physically Realistic Image Editing?",
    "summary": "Image editing has achieved remarkable progress recently. Modern editing\nmodels could already follow complex instructions to manipulate the original\ncontent. However, beyond completing the editing instructions, the accompanying\nphysical effects are the key to the generation realism. For example, removing\nan object should also remove its shadow, reflections, and interactions with\nnearby objects. Unfortunately, existing models and benchmarks mainly focus on\ninstruction completion but overlook these physical effects. So, at this moment,\nhow far are we from physically realistic image editing? To answer this, we\nintroduce PICABench, which systematically evaluates physical realism across\neight sub-dimension (spanning optics, mechanics, and state transitions) for\nmost of the common editing operations (add, remove, attribute change, etc). We\nfurther propose the PICAEval, a reliable evaluation protocol that uses\nVLM-as-a-judge with per-case, region-level human annotations and questions.\nBeyond benchmarking, we also explore effective solutions by learning physics\nfrom videos and construct a training dataset PICA-100K. After evaluating most\nof the mainstream models, we observe that physical realism remains a\nchallenging problem with large rooms to explore. We hope that our benchmark and\nproposed solutions can serve as a foundation for future work moving from naive\ncontent editing toward physically consistent realism.",
    "published": "2025-10-20T15:53:57Z",
    "updated": "2025-10-20T15:53:57Z",
    "link": "http://arxiv.org/pdf/2510.17681v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Yuandong Pu",
      "Le Zhuo",
      "Songhao Han",
      "Jinbo Xing",
      "Kaiwen Zhu",
      "Shuo Cao",
      "Bin Fu",
      "Si Liu",
      "Hongsheng Li",
      "Yu Qiao",
      "Wenlong Zhang",
      "Xi Chen",
      "Yihao Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17671v1",
    "title": "LILO: Bayesian Optimization with Interactive Natural Language Feedback",
    "summary": "For many real-world applications, feedback is essential in translating\ncomplex, nuanced, or subjective goals into quantifiable optimization\nobjectives. We propose a language-in-the-loop framework that uses a large\nlanguage model (LLM) to convert unstructured feedback in the form of natural\nlanguage into scalar utilities to conduct BO over a numeric search space.\nUnlike preferential BO, which only accepts restricted feedback formats and\nrequires customized models for each domain-specific problem, our approach\nleverages LLMs to turn varied types of textual feedback into consistent utility\nsignals and to easily include flexible user priors without manual kernel\ndesign. At the same time, our method maintains the sample efficiency and\nprincipled uncertainty quantification of BO. We show that this hybrid method\nnot only provides a more natural interface to the decision maker but also\noutperforms conventional BO baselines and LLM-only optimizers, particularly in\nfeedback-limited regimes.",
    "published": "2025-10-20T15:41:56Z",
    "updated": "2025-10-20T15:41:56Z",
    "link": "http://arxiv.org/pdf/2510.17671v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Katarzyna Kobalczyk",
      "Zhiyuan Jerry Lin",
      "Benjamin Letham",
      "Zhuokai Zhao",
      "Maximilian Balandat",
      "Eytan Bakshy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17670v1",
    "title": "On-the-Fly OVD Adaptation with FLAME: Few-shot Localization via Active\n  Marginal-Samples Exploration",
    "summary": "Open-vocabulary object detection (OVD) models offer remarkable flexibility by\ndetecting objects from arbitrary text queries. However, their zero-shot\nperformance in specialized domains like Remote Sensing (RS) is often\ncompromised by the inherent ambiguity of natural language, limiting critical\ndownstream applications. For instance, an OVD model may struggle to distinguish\nbetween fine-grained classes such as \"fishing boat\" and \"yacht\" since their\nembeddings are similar and often inseparable. This can hamper specific user\ngoals, such as monitoring illegal fishing, by producing irrelevant detections.\nTo address this, we propose a cascaded approach that couples the broad\ngeneralization of a large pre-trained OVD model with a lightweight few-shot\nclassifier. Our method first employs the zero-shot model to generate\nhigh-recall object proposals. These proposals are then refined for high\nprecision by a compact classifier trained in real-time on only a handful of\nuser-annotated examples - drastically reducing the high costs of RS imagery\nannotation.The core of our framework is FLAME, a one-step active learning\nstrategy that selects the most informative samples for training. FLAME\nidentifies, on the fly, uncertain marginal candidates near the decision\nboundary using density estimation, followed by clustering to ensure sample\ndiversity. This efficient sampling technique achieves high accuracy without\ncostly full-model fine-tuning and enables instant adaptation, within less then\na minute, which is significantly faster than state-of-the-art alternatives.Our\nmethod consistently surpasses state-of-the-art performance on RS benchmarks,\nestablishing a practical and resource-efficient framework for adapting\nfoundation models to specific user needs.",
    "published": "2025-10-20T15:41:55Z",
    "updated": "2025-10-20T15:41:55Z",
    "link": "http://arxiv.org/pdf/2510.17670v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "authors": [
      "Yehonathan Refael",
      "Amit Aides",
      "Aviad Barzilai",
      "George Leifman",
      "Genady Beryozkin",
      "Vered Silverman",
      "Bolous Jaber",
      "Tomer Shekel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.02456v2",
    "title": "Market-Driven Subset Selection for Budgeted Training",
    "summary": "Training large language models on massive datasets is computationally\nexpensive, yet empirical evidence suggests that substantial portions of\ntraining examples contribute minimally to final performance. Data subset\nselection addresses this inefficiency by identifying small, high-utility\nsubsets under resource constraints. However, example utility is inherently\nmulti-faceted, encompassing uncertainty, distributional rarity, and diversity\nsignals that are heterogeneous and typically combined through ad hoc weighted\nsums lacking theoretical grounding. We propose a market-based framework that\ntreats each training example as a tradeable contract and employs the\nLogarithmic Market Scoring Rule to aggregate multiple utility signals into\ncoherent prices. Heterogeneous signals act as traders, a single liquidity\nparameter controls concentration versus smoothing, and topic-wise normalization\nensures calibrated aggregation. Token budgets are handled explicitly through a\nprice-per-token decision rule with an interpretable length-bias parameter. We\nestablish theoretical connections to maximum-entropy aggregation and provide\nutility recovery guarantees under noisy but monotone signals. On GSM8K\nmathematical reasoning under strict 60k-token budgets, our selector achieves\nparity with strong single-signal baselines while exhibiting lower variance and\nincurring less than 0.1 GPU-hour overhead. On AGNews classification at 5-25\\%\nretention rates, the market formulation delivers competitive accuracy with\nimproved stability. Our framework unifies multi-signal data curation under\nfixed computational budgets for prompt-level reasoning and classification\ntasks.",
    "published": "2025-10-02T18:12:03Z",
    "updated": "2025-10-20T15:38:47Z",
    "link": "http://arxiv.org/pdf/2510.02456v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA"
    ],
    "authors": [
      "Ashish Jha",
      "Valentin Leplat",
      "AH Phan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.17821v2",
    "title": "Limitations of Normalization in Attention Mechanism",
    "summary": "This paper investigates the limitations of the normalization in attention\nmechanisms. We begin with a theoretical framework that enables the\nidentification of the model's selective ability and the geometric separation\ninvolved in token selection. Our analysis includes explicit bounds on distances\nand separation criteria for token vectors under softmax scaling. Through\nexperiments with pre-trained GPT-2 model, we empirically validate our\ntheoretical results and analyze key behaviors of the attention mechanism.\nNotably, we demonstrate that as the number of selected tokens increases, the\nmodel's ability to distinguish informative tokens declines, often converging\ntoward a uniform selection pattern. We also show that gradient sensitivity\nunder softmax normalization presents challenges during training, especially at\nlow temperature settings. These findings advance current understanding of\nsoftmax-based attention mechanism and motivate the need for more robust\nnormalization and selection strategies in future attention architectures.",
    "published": "2025-08-25T09:25:05Z",
    "updated": "2025-10-20T15:30:30Z",
    "link": "http://arxiv.org/pdf/2508.17821v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Timur Mudarisov",
      "Mikhail Burtsev",
      "Tatiana Petrova",
      "Radu State"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17651v1",
    "title": "Frugal Federated Learning for Violence Detection: A Comparison of\n  LoRA-Tuned VLMs and Personalized CNNs",
    "summary": "We examine frugal federated learning approaches to violence detection by\ncomparing two complementary strategies: (i) zero-shot and federated fine-tuning\nof vision-language models (VLMs), and (ii) personalized training of a compact\n3D convolutional neural network (CNN3D). Using LLaVA-7B and a 65.8M parameter\nCNN3D as representative cases, we evaluate accuracy, calibration, and energy\nusage under realistic non-IID settings.\n  Both approaches exceed 90% accuracy. CNN3D slightly outperforms Low-Rank\nAdaptation(LoRA)-tuned VLMs in ROC AUC and log loss, while using less energy.\nVLMs remain favorable for contextual reasoning and multimodal inference. We\nquantify energy and CO$_2$ emissions across training and inference, and analyze\nsustainability trade-offs for deployment.\n  To our knowledge, this is the first comparative study of LoRA-tuned\nvision-language models and personalized CNNs for federated violence detection,\nwith an emphasis on energy efficiency and environmental metrics.\n  These findings support a hybrid model: lightweight CNNs for routine\nclassification, with selective VLM activation for complex or descriptive\nscenarios. The resulting framework offers a reproducible baseline for\nresponsible, resource-aware AI in video surveillance, with extensions toward\nreal-time, multimodal, and lifecycle-aware systems.",
    "published": "2025-10-20T15:26:43Z",
    "updated": "2025-10-20T15:26:43Z",
    "link": "http://arxiv.org/pdf/2510.17651v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "SÃ©bastien Thuau",
      "Siba Haidar",
      "Ayush Bajracharya",
      "Rachid Chelouah"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17640v1",
    "title": "RESample: A Robust Data Augmentation Framework via Exploratory Sampling\n  for Robotic Manipulation",
    "summary": "Vision-Language-Action models (VLAs) have demonstrated remarkable performance\non complex robotic manipulation tasks through imitation learning. However,\nexisting imitation learning datasets contain only successful trajectories and\nlack failure or recovery data, especially for out-of-distribution (OOD) states\nwhere the robot deviates from the main policy due to minor perturbations or\nerrors, leading VLA models to struggle with states deviating from the training\ndistribution. To this end, we propose an automated OOD data augmentation\nframework named RESample through exploratory sampling. Specifically, we first\nleverage offline reinforcement learning to obtain an action-value network that\naccurately identifies sub-optimal actions under the current manipulation\npolicy. We further sample potential OOD states from trajectories via rollout,\nand design an exploratory sampling mechanism that adaptively incorporates these\naction proxies into the training dataset to ensure efficiency. Subsequently,\nour framework explicitly encourages the VLAs to recover from OOD states and\nenhances their robustness against distributional shifts. We conduct extensive\nexperiments on the LIBERO benchmark as well as real-world robotic manipulation\ntasks, demonstrating that RESample consistently improves the stability and\ngeneralization ability of VLA models.",
    "published": "2025-10-20T15:21:12Z",
    "updated": "2025-10-20T15:21:12Z",
    "link": "http://arxiv.org/pdf/2510.17640v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Yuquan Xue",
      "Guanxing Lu",
      "Zhenyu Wu",
      "Chuanrui Zhang",
      "Bofang Jia",
      "Zhengyi Gu",
      "Yansong Tang",
      "Ziwei Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17638v1",
    "title": "LLM-as-a-Prophet: Understanding Predictive Intelligence with Prophet\n  Arena",
    "summary": "Forecasting is not only a fundamental intellectual pursuit but also is of\nsignificant importance to societal systems such as finance and economics. With\nthe rapid advances of large language models (LLMs) trained on Internet-scale\ndata, it raises the promise of employing LLMs to forecast real-world future\nevents, an emerging paradigm we call \"LLM-as-a-Prophet\". This paper\nsystematically investigates such predictive intelligence of LLMs. To this end,\nwe build Prophet Arena, a general evaluation benchmark that continuously\ncollects live forecasting tasks and decomposes each task into distinct pipeline\nstages, in order to support our controlled and large-scale experimentation. Our\ncomprehensive evaluation reveals that many LLMs already exhibit impressive\nforecasting capabilities, reflected in, e.g., their small calibration errors,\nconsistent prediction confidence and promising market returns. However, we also\nuncover key bottlenecks towards achieving superior predictive intelligence via\nLLM-as-a-Prophet, such as LLMs' inaccurate event recalls, misunderstanding of\ndata sources and slower information aggregation compared to markets when\nresolution nears.",
    "published": "2025-10-20T15:20:05Z",
    "updated": "2025-10-20T15:20:05Z",
    "link": "http://arxiv.org/pdf/2510.17638v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Qingchuan Yang",
      "Simon Mahns",
      "Sida Li",
      "Anri Gu",
      "Jibang Wu",
      "Haifeng Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17626v1",
    "title": "CaMiT: A Time-Aware Car Model Dataset for Classification and Generation",
    "summary": "AI systems must adapt to evolving visual environments, especially in domains\nwhere object appearances change over time. We introduce Car Models in Time\n(CaMiT), a fine-grained dataset capturing the temporal evolution of car models,\na representative class of technological artifacts. CaMiT includes 787K labeled\nsamples of 190 car models (2007-2023) and 5.1M unlabeled samples (2005-2023),\nsupporting both supervised and self-supervised learning. Static pretraining on\nin-domain data achieves competitive performance with large-scale generalist\nmodels while being more resource-efficient, yet accuracy declines when models\nare tested across years. To address this, we propose a time-incremental\nclassification setting, a realistic continual learning scenario with emerging,\nevolving, and disappearing classes. We evaluate two strategies:\ntime-incremental pretraining, which updates the backbone, and time-incremental\nclassifier learning, which updates only the final layer, both improving\ntemporal robustness. Finally, we explore time-aware image generation that\nleverages temporal metadata during training, yielding more realistic outputs.\nCaMiT offers a rich benchmark for studying temporal adaptation in fine-grained\nvisual recognition and generation.",
    "published": "2025-10-20T15:11:05Z",
    "updated": "2025-10-20T15:11:05Z",
    "link": "http://arxiv.org/pdf/2510.17626v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "FrÃ©dÃ©ric LIN",
      "Biruk Abere Ambaw",
      "Adrian Popescu",
      "Hejer Ammar",
      "Romaric Audigier",
      "HervÃ© Le Borgne"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.11302v2",
    "title": "When Does Supervised Training Pay Off? The Hidden Economics of Object\n  Detection in the Era of Vision-Language Models",
    "summary": "Object detection traditionally relies on costly manual annotation. We present\nthe first comprehensive cost-effectiveness analysis comparing supervised YOLO\nand zero-shot vision-language models (Gemini Flash 2.5 and GPT-4). Evaluated on\n5,000 stratified COCO images and 500 diverse product images, combined with\nTotal Cost of Ownership modeling, we derive break-even thresholds for\narchitecture selection. Results show supervised YOLO attains 91.2% accuracy\nversus 68.5% for Gemini and 71.3% for GPT-4 on standard categories; the\nannotation expense for a 100-category system is $10,800, and the accuracy\nadvantage only pays off beyond 55 million inferences (151,000 images/day for\none year). On diverse product categories Gemini achieves 52.3% and GPT-4 55.1%,\nwhile supervised YOLO cannot detect untrained classes.\nCost-per-correct-detection favors Gemini ($0.00050) and GPT-4 ($0.00067) over\nYOLO ($0.143) at 100,000 inferences. We provide decision frameworks showing\nthat optimal architecture choice depends on inference volume, category\nstability, budget, and accuracy requirements.",
    "published": "2025-10-13T11:48:48Z",
    "updated": "2025-10-20T15:09:23Z",
    "link": "http://arxiv.org/pdf/2510.11302v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Samer Al-Hamadani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.00583v2",
    "title": "AI-Generated Video Detection via Perceptual Straightening",
    "summary": "The rapid advancement of generative AI enables highly realistic synthetic\nvideos, posing significant challenges for content authentication and raising\nurgent concerns about misuse. Existing detection methods often struggle with\ngeneralization and capturing subtle temporal inconsistencies. We propose\nReStraV(Representation Straightening Video), a novel approach to distinguish\nnatural from AI-generated videos. Inspired by the \"perceptual straightening\"\nhypothesis -- which suggests real-world video trajectories become more straight\nin neural representation domain -- we analyze deviations from this expected\ngeometric property. Using a pre-trained self-supervised vision transformer\n(DINOv2), we quantify the temporal curvature and stepwise distance in the\nmodel's representation domain. We aggregate statistics of these measures for\neach video and train a classifier. Our analysis shows that AI-generated videos\nexhibit significantly different curvature and distance patterns compared to\nreal videos. A lightweight classifier achieves state-of-the-art detection\nperformance (e.g., 97.17% accuracy and 98.63% AUROC on the VidProM benchmark),\nsubstantially outperforming existing image- and video-based methods. ReStraV is\ncomputationally efficient, it is offering a low-cost and effective detection\nsolution. This work provides new insights into using neural representation\ngeometry for AI-generated video detection.",
    "published": "2025-07-01T09:04:21Z",
    "updated": "2025-10-20T15:07:58Z",
    "link": "http://arxiv.org/pdf/2507.00583v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Christian InternÃ²",
      "Robert Geirhos",
      "Markus Olhofer",
      "Sunny Liu",
      "Barbara Hammer",
      "David Klindt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17621v1",
    "title": "GUIDE: Enhancing Gradient Inversion Attacks in Federated Learning with\n  Denoising Models",
    "summary": "Federated Learning (FL) enables collaborative training of Machine Learning\n(ML) models across multiple clients while preserving their privacy. Rather than\nsharing raw data, federated clients transmit locally computed updates to train\nthe global model. Although this paradigm should provide stronger privacy\nguarantees than centralized ML, client updates remain vulnerable to privacy\nleakage. Adversaries can exploit them to infer sensitive properties about the\ntraining data or even to reconstruct the original inputs via Gradient Inversion\nAttacks (GIAs). Under the honest-butcurious threat model, GIAs attempt to\nreconstruct training data by reversing intermediate updates using\noptimizationbased techniques. We observe that these approaches usually\nreconstruct noisy approximations of the original inputs, whose quality can be\nenhanced with specialized denoising models. This paper presents Gradient Update\nInversion with DEnoising (GUIDE), a novel methodology that leverages diffusion\nmodels as denoising tools to improve image reconstruction attacks in FL. GUIDE\ncan be integrated into any GIAs that exploits surrogate datasets, a widely\nadopted assumption in GIAs literature. We comprehensively evaluate our approach\nin two attack scenarios that use different FL algorithms, models, and datasets.\nOur results demonstrate that GUIDE integrates seamlessly with two state-ofthe-\nart GIAs, substantially improving reconstruction quality across multiple\nmetrics. Specifically, GUIDE achieves up to 46% higher perceptual similarity,\nas measured by the DreamSim metric.",
    "published": "2025-10-20T15:04:29Z",
    "updated": "2025-10-20T15:04:29Z",
    "link": "http://arxiv.org/pdf/2510.17621v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Vincenzo Carletti",
      "Pasquale Foggia",
      "Carlo Mazzocca",
      "Giuseppe Parrella",
      "Mario Vento"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.10351v4",
    "title": "PhysioWave: A Multi-Scale Wavelet-Transformer for Physiological Signal\n  Representation",
    "summary": "Physiological signals are often corrupted by motion artifacts, baseline\ndrift, and other low-SNR disturbances, which pose significant challenges for\nanalysis. Additionally, these signals exhibit strong non-stationarity, with\nsharp peaks and abrupt changes that evolve continuously, making them difficult\nto represent using traditional time-domain or filtering methods. To address\nthese issues, a novel wavelet-based approach for physiological signal analysis\nis presented, aiming to capture multi-scale time-frequency features in various\nphysiological signals. Leveraging this technique, two large-scale pretrained\nmodels specific to EMG and ECG are introduced for the first time, achieving\nsuperior performance and setting new baselines in downstream tasks.\nAdditionally, a unified multi-modal framework is constructed by integrating\npretrained EEG model, where each modality is guided through its dedicated\nbranch and fused via learnable weighted fusion. This design effectively\naddresses challenges such as low signal-to-noise ratio, high inter-subject\nvariability, and device mismatch, outperforming existing methods on multi-modal\ntasks. The proposed wavelet-based architecture lays a solid foundation for\nanalysis of diverse physiological signals, while the multi-modal design points\nto next-generation physiological signal processing with potential impact on\nwearable health monitoring, clinical diagnostics, and broader biomedical\napplications. Code and data are available at:\ngithub.com/ForeverBlue816/PhysioWave",
    "published": "2025-06-12T05:11:41Z",
    "updated": "2025-10-20T15:00:40Z",
    "link": "http://arxiv.org/pdf/2506.10351v4.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Yanlong Chen",
      "Mattia Orlandi",
      "Pierangelo Maria Rapa",
      "Simone Benatti",
      "Luca Benini",
      "Yawei Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17614v1",
    "title": "OG-Rank: Learning to Rank Fast and Slow with Uncertainty and\n  Reward-Trend Guided Adaptive Exploration",
    "summary": "Clinicians need ranking systems that work in real time and still justify\ntheir choices. Motivated by the need for a low-latency, decoder-based reranker,\nwe present OG-Rank, a single-decoder approach that pairs a pooled first-token\nscoring signal with an uncertainty-gated explanation step. The model scores all\ncandidates in one pass and generates a brief, structured rationale only when\nthe list is genuinely ambiguous, keeping latency predictable. Trained with a\ncurriculum that concentrates effort on hard cases, OG-Rank delivers strong\neffectiveness on encounter-scoped order selection (fast path: Recall@1~0.45,\nnDCG@20~0.625) and improves further when the gate activates (Recall@1~0.56,\nnDCG@20~0.699 at a 45\\% gate rate), while compact backbones show similar gains\nunder the same policy. Encoder baselines trail in both effectiveness and\nflexibility. The result is a practical recipe: rank fast by default and explain\nwhen it helps, a pattern that applies broadly to decision tasks where selective\ngeneration buys accuracy at acceptable cost. The single-policy design\nsimplifies deployment and budget planning, and the curriculum principle (spend\nmore on the hard cases, less on the easy ones) readily transfers beyond\nclinical order selection.",
    "published": "2025-10-20T15:00:02Z",
    "updated": "2025-10-20T15:00:02Z",
    "link": "http://arxiv.org/pdf/2510.17614v1.pdf",
    "category": [
      "cs.AI",
      "cs.IR"
    ],
    "authors": [
      "Praphul Singh",
      "Corey Barrett",
      "Sumana Srivasta",
      "Irfan Bulu",
      "Sri Gadde",
      "Krishnaram Kenthapadi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.01611v3",
    "title": "PsychCounsel-Bench: Evaluating the Psychology Intelligence of Large\n  Language Models",
    "summary": "Large Language Models (LLMs) have demonstrated remarkable success across a\nwide range of industries, primarily due to their impressive generative\nabilities. Yet, their potential in applications requiring cognitive abilities,\nsuch as psychological counseling, remains largely untapped. This paper\ninvestigates the key question: \\textit{Can LLMs be effectively applied to\npsychological counseling?} To determine whether an LLM can effectively take on\nthe role of a psychological counselor, the first step is to assess whether it\nmeets the qualifications required for such a role, namely the ability to pass\nthe U.S. National Counselor Certification Exam (NCE). This is because, just as\na human counselor must pass a certification exam to practice, an LLM must\ndemonstrate sufficient psychological knowledge to meet the standards required\nfor such a role. To address this, we introduce PsychCounsel-Bench, a benchmark\ngrounded in U.S.national counselor examinations, a licensure test for\nprofessional counselors that requires about 70\\% accuracy to pass.\nPsychCounsel-Bench comprises approximately 2,252 carefully curated\nsingle-choice questions, crafted to require deep understanding and broad enough\nto cover various sub-disciplines of psychology. This benchmark provides a\ncomprehensive assessment of an LLM's ability to function as a counselor. Our\nevaluation shows that advanced models such as GPT-4o, Llama3.3-70B, and\nGemma3-27B achieve well above the passing threshold, while smaller open-source\nmodels (e.g., Qwen2.5-7B, Mistral-7B) remain far below it. These results\nsuggest that only frontier LLMs are currently capable of meeting counseling\nexam standards, highlighting both the promise and the challenges of developing\npsychology-oriented LLMs. We release the proposed dataset for public use:\nhttps://github.com/cloversjtu/PsychCounsel-Bench",
    "published": "2025-10-02T02:49:06Z",
    "updated": "2025-10-20T14:59:12Z",
    "link": "http://arxiv.org/pdf/2510.01611v3.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Min Zeng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.13389v3",
    "title": "From Next Token Prediction to (STRIPS) World Models -- Preliminary\n  Results",
    "summary": "We consider the problem of learning propositional STRIPS world models from\naction traces alone, using a deep learning architecture (transformers) and\ngradient descent. The task is cast as a supervised next token prediction\nproblem where the tokens are the actions, and an action $a$ may follow an\naction sequence if the hidden effects of the previous actions do not make an\naction precondition of $a$ false. We show that a suitable transformer\narchitecture can faithfully represent propositional STRIPS world models, and\nthat the models can be learned from sets of random valid (positive) and invalid\n(negative) action sequences alone. A number of experiments are reported.",
    "published": "2025-09-16T14:03:58Z",
    "updated": "2025-10-20T14:57:16Z",
    "link": "http://arxiv.org/pdf/2509.13389v3.pdf",
    "category": [
      "cs.AI",
      "I.2.4; I.2.6; I.2.8"
    ],
    "authors": [
      "Carlos NÃºÃ±ez-Molina",
      "VicenÃ§ GÃ³mez",
      "Hector Geffner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.12081v2",
    "title": "VimoRAG: Video-based Retrieval-augmented 3D Motion Generation for Motion\n  Language Models",
    "summary": "This paper introduces VimoRAG, a novel video-based retrieval-augmented motion\ngeneration framework for motion large language models (LLMs). As motion LLMs\nface severe out-of-domain/out-of-vocabulary issues due to limited annotated\ndata, VimoRAG leverages large-scale in-the-wild video databases to enhance 3D\nmotion generation by retrieving relevant 2D human motion signals. While\nvideo-based motion RAG is nontrivial, we address two key bottlenecks: (1)\ndeveloping an effective motion-centered video retrieval model that\ndistinguishes human poses and actions, and (2) mitigating the issue of error\npropagation caused by suboptimal retrieval results. We design the Gemini Motion\nVideo Retriever mechanism and the Motion-centric Dual-alignment DPO Trainer,\nenabling effective retrieval and generation processes. Experimental results\nshow that VimoRAG significantly boosts the performance of motion LLMs\nconstrained to text-only input. All the resources are available at\nhttps://walkermitty.github.io/VimoRAG/",
    "published": "2025-08-16T15:31:14Z",
    "updated": "2025-10-20T14:52:28Z",
    "link": "http://arxiv.org/pdf/2508.12081v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Haidong Xu",
      "Guangwei Xu",
      "Zhedong Zheng",
      "Xiatian Zhu",
      "Wei Ji",
      "Xiangtai Li",
      "Ruijie Guo",
      "Meishan Zhang",
      "Min zhang",
      "Hao Fei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.12814v2",
    "title": "PsyMem: Fine-grained psychological alignment and Explicit Memory Control\n  for Advanced Role-Playing LLMs",
    "summary": "Existing LLM-based role-playing methods often rely on superficial textual\ndescriptions or simplistic metrics, inadequately modeling both intrinsic and\nextrinsic character dimensions. Additionally, they typically simulate character\nmemory with implicit model knowledge or basic retrieval augment generation\nwithout explicit memory alignment, compromising memory consistency. The two\nissues weaken reliability of role-playing LLMs in several applications, such as\ntrustworthy social simulation. To address these limitations, we propose PsyMem,\na novel framework integrating fine-grained psychological attributes and\nexplicit memory control for role-playing. PsyMem supplements textual\ndescriptions with 26 psychological indicators to detailed model character.\nAdditionally, PsyMem implements memory alignment training, explicitly trains\nthe model to align character's response with memory, thereby enabling dynamic\nmemory-controlled responding during inference. By training Qwen2.5-7B-Instruct\non our specially designed dataset (including 5,414 characters and 38,962\ndialogues extracted from novels), the resulting model, termed as PsyMem-Qwen,\noutperforms baseline models in role-playing, achieving the best performance in\nhuman-likeness and character fidelity.",
    "published": "2025-05-19T07:45:09Z",
    "updated": "2025-10-20T14:52:07Z",
    "link": "http://arxiv.org/pdf/2505.12814v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Xilong Cheng",
      "Yunxiao Qin",
      "Yuting Tan",
      "Zhengnan Li",
      "Ye Wang",
      "Hongjiang Xiao",
      "Yuan Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.02508v4",
    "title": "When Words Smile: Generating Diverse Emotional Facial Expressions from\n  Text",
    "summary": "Enabling digital humans to express rich emotions has significant applications\nin dialogue systems, gaming, and other interactive scenarios. While recent\nadvances in talking head synthesis have achieved impressive results in lip\nsynchronization, they tend to overlook the rich and dynamic nature of facial\nexpressions. To fill this critical gap, we introduce an end-to-end\ntext-to-expression model that explicitly focuses on emotional dynamics. Our\nmodel learns expressive facial variations in a continuous latent space and\ngenerates expressions that are diverse, fluid, and emotionally coherent. To\nsupport this task, we introduce EmoAva, a large-scale and high-quality dataset\ncontaining 15,000 text-3D expression pairs. Extensive experiments on both\nexisting datasets and EmoAva demonstrate that our method significantly\noutperforms baselines across multiple evaluation metrics, marking a significant\nadvancement in the field.",
    "published": "2024-12-03T15:39:05Z",
    "updated": "2025-10-20T14:51:27Z",
    "link": "http://arxiv.org/pdf/2412.02508v4.pdf",
    "category": [
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Haidong Xu",
      "Meishan Zhang",
      "Hao Ju",
      "Zhedong Zheng",
      "Erik Cambria",
      "Min Zhang",
      "Hao Fei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.00461v2",
    "title": "TimeEmb: A Lightweight Static-Dynamic Disentanglement Framework for Time\n  Series Forecasting",
    "summary": "Temporal non-stationarity, the phenomenon that time series distributions\nchange over time, poses fundamental challenges to reliable time series\nforecasting. Intuitively, the complex time series can be decomposed into two\nfactors, \\ie time-invariant and time-varying components, which indicate static\nand dynamic patterns, respectively. Nonetheless, existing methods often\nconflate the time-varying and time-invariant components, and jointly learn the\ncombined long-term patterns and short-term fluctuations, leading to suboptimal\nperformance facing distribution shifts. To address this issue, we initiatively\npropose a lightweight static-dynamic decomposition framework, TimeEmb, for time\nseries forecasting. TimeEmb innovatively separates time series into two\ncomplementary components: (1) time-invariant component, captured by a novel\nglobal embedding module that learns persistent representations across time\nseries, and (2) time-varying component, processed by an efficient\nfrequency-domain filtering mechanism inspired by full-spectrum analysis in\nsignal processing. Experiments on real-world datasets demonstrate that TimeEmb\noutperforms state-of-the-art baselines and requires fewer computational\nresources. We conduct comprehensive quantitative and qualitative analyses to\nverify the efficacy of static-dynamic disentanglement. This lightweight\nframework can also improve existing time-series forecasting methods with simple\nintegration. To ease reproducibility, the code is available at\nhttps://github.com/showmeon/TimeEmb.",
    "published": "2025-10-01T03:28:49Z",
    "updated": "2025-10-20T14:49:33Z",
    "link": "http://arxiv.org/pdf/2510.00461v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Mingyuan Xia",
      "Chunxu Zhang",
      "Zijian Zhang",
      "Hao Miao",
      "Qidong Liu",
      "Yuanshao Zhu",
      "Bo Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17598v1",
    "title": "Reasoning Distillation and Structural Alignment for Improved Code\n  Generation",
    "summary": "Effective code generation with language models hinges on two critical\nfactors: accurately understanding the intent of the prompt and generating code\nthat applies algorithmic reasoning to produce correct solutions capable of\npassing diverse test cases while adhering to the syntax of the target\nprogramming language. Unlike other language tasks, code generation requires\nmore than accurate token prediction; it demands comprehension of solution-level\nand structural relationships rather than merely generating the most likely\ntokens. very large language model (VLLM) are capable of generating detailed\nsteps toward the correct solution of complex tasks where reasoning is crucial\nin solving the problem. Such reasoning capabilities may be absent in smaller\nlanguage models. Therefore, in this work, we distill the reasoning capabilities\nof a VLLM into a smaller, more efficient model that is faster and cheaper to\ndeploy. Our approach trains the model to emulate the reasoning and\nproblem-solving abilities of the VLLM by learning to identify correct solution\npathways and establishing a structural correspondence between problem\ndefinitions and potential solutions through a novel method of structure-aware\nloss optimization. This enables the model to transcend token-level generation\nand to deeply grasp the overarching structure of solutions for given problems.\nExperimental results show that our fine-tuned model, developed through a cheap\nand simple to implement process, significantly outperforms our baseline model\nin terms of pass@1, average data flow, and average syntax match metrics across\nthe MBPP, MBPP Plus, and HumanEval benchmarks.",
    "published": "2025-10-20T14:47:47Z",
    "updated": "2025-10-20T14:47:47Z",
    "link": "http://arxiv.org/pdf/2510.17598v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Amir Jalilifard",
      "Anderson de Rezende Rocha",
      "Marcos Medeiros Raimundo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17591v1",
    "title": "HGAdapter: Hypergraph-based Adapters in Language Models for Code\n  Summarization and Clone Detection",
    "summary": "Pre-trained language models (PLMs) are increasingly being applied to\ncode-related tasks. Although PLMs have achieved good results, they do not take\ninto account potential high-order data correlations within the code. We propose\nthree types of high-order correlations in code tokens, i.e. abstract syntax\ntree family correlation, lexical correlation, and line correlation. We design a\ntokens and hyperedges generator to capture these high-order data correlations.\nWe improve the architecture of hypergraph neural networks and combine it with\nadapter tuning to propose a novel hypergraph-based adapter (HGAdapter) to\nfine-tune PLMs. HGAdapter can encode high-order data correlations and is\nallowed to be inserted into various PLMs to enhance performance. Experiments\nwere conducted on several public datasets, including six languages of code\nsummarization and code clone detection tasks. Our methods improved the\nperformance of PLMs in datasets to varying degrees. Experimental results\nvalidate the introduction of high-order data correlations that contribute to\nimproved effectiveness.",
    "published": "2025-10-20T14:41:28Z",
    "updated": "2025-10-20T14:41:28Z",
    "link": "http://arxiv.org/pdf/2510.17591v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "authors": [
      "Guang Yang",
      "Yujie Zhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17590v1",
    "title": "MIRAGE: Agentic Framework for Multimodal Misinformation Detection with\n  Web-Grounded Reasoning",
    "summary": "Misinformation spreads across web platforms through billions of daily\nmultimodal posts that combine text and images, overwhelming manual\nfact-checking capacity. Supervised detection models require domain-specific\ntraining data and fail to generalize across diverse manipulation tactics. We\npresent MIRAGE, an inference-time, model-pluggable agentic framework that\ndecomposes multimodal verification into four sequential modules: visual\nveracity assessment detects AI-generated images, cross-modal consistency\nanalysis identifies out-of-context repurposing, retrieval-augmented factual\nchecking grounds claims in web evidence through iterative question generation,\nand a calibrated judgment module integrates all signals. MIRAGE orchestrates\nvision-language model reasoning with targeted web retrieval, outputs structured\nand citation-linked rationales. On MMFakeBench validation set (1,000 samples),\nMIRAGE with GPT-4o-mini achieves 81.65% F1 and 75.1% accuracy, outperforming\nthe strongest zero-shot baseline (GPT-4V with MMD-Agent at 74.0% F1) by 7.65\npoints while maintaining 34.3% false positive rate versus 97.3% for a\njudge-only baseline. Test set results (5,000 samples) confirm generalization\nwith 81.44% F1 and 75.08% accuracy. Ablation studies show visual verification\ncontributes 5.18 F1 points and retrieval-augmented reasoning contributes 2.97\npoints. Our results demonstrate that decomposed agentic reasoning with web\nretrieval can match supervised detector performance without domain-specific\ntraining, enabling misinformation detection across modalities where labeled\ndata remains scarce.",
    "published": "2025-10-20T14:40:26Z",
    "updated": "2025-10-20T14:40:26Z",
    "link": "http://arxiv.org/pdf/2510.17590v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.CY",
      "cs.LG",
      "I.2.7; H.3.3; I.4.9"
    ],
    "authors": [
      "Mir Nafis Sharear Shopnil",
      "Sharad Duwal",
      "Abhishek Tyagi",
      "Adiba Mahbub Proma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17584v1",
    "title": "CEPerFed: Communication-Efficient Personalized Federated Learning for\n  Multi-Pulse MRI Classification",
    "summary": "Multi-pulse magnetic resonance imaging (MRI) is widely utilized for clinical\npractice such as Alzheimer's disease diagnosis. To train a robust model for\nmulti-pulse MRI classification, it requires large and diverse data from various\nmedical institutions while protecting privacy by preventing raw data sharing\nacross institutions. Although federated learning (FL) is a feasible solution to\naddress this issue, it poses challenges of model convergence due to the effect\nof data heterogeneity and substantial communication overhead due to large\nnumbers of parameters transmitted within the model. To address these\nchallenges, we propose CEPerFed, a communication-efficient personalized FL\nmethod. It mitigates the effect of data heterogeneity by incorporating\nclient-side historical risk gradients and historical mean gradients to\ncoordinate local and global optimization. The former is used to weight the\ncontributions from other clients, enhancing the reliability of local updates,\nwhile the latter enforces consistency between local updates and the global\noptimization direction to ensure stable convergence across heterogeneous data\ndistributions. To address the high communication overhead, we propose a\nhierarchical SVD (HSVD) strategy that transmits only the most critical\ninformation required for model updates. Experiments on five classification\ntasks demonstrate the effectiveness of the CEPerFed method. The code will be\nreleased upon acceptance at https://github.com/LD0416/CEPerFed.",
    "published": "2025-10-20T14:34:16Z",
    "updated": "2025-10-20T14:34:16Z",
    "link": "http://arxiv.org/pdf/2510.17584v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Ludi Li",
      "Junbin Mao",
      "Hanhe Lin",
      "Xu Tian",
      "Fang-Xiang Wu",
      "Jin Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.00432v2",
    "title": "Does Math Reasoning Improve General LLM Capabilities? Understanding\n  Transferability of LLM Reasoning",
    "summary": "Math reasoning has become the poster child of progress in large language\nmodels (LLMs), with new models rapidly surpassing human-level performance on\nbenchmarks like MATH and AIME. But as math leaderboards improve week by week,\nit is worth asking: do these gains reflect broader problem-solving ability or\njust narrow overfitting? To answer this question, we evaluate over 20\nopen-weight reasoning-tuned models across a broad suite of tasks, including\nmath, scientific QA, agent planning, coding, and standard\ninstruction-following. We surprisingly find that most models that succeed in\nmath fail to transfer their gains to other domains. To rigorously study this\nphenomenon, we conduct controlled experiments on Qwen3-14B models using\nmath-only data but different tuning methods. We find that reinforcement\nlearning (RL)-tuned models generalize well across domains, while supervised\nfine-tuning (SFT)-tuned models often forget general capabilities. Latent-space\nrepresentation and token-space distribution shift analyses reveal that SFT\ninduces substantial representation and output drift, while RL preserves\ngeneral-domain structure. Our results suggest a need to rethink standard\npost-training recipes, particularly the reliance on SFT-distilled data for\nadvancing reasoning models.",
    "published": "2025-07-01T05:23:05Z",
    "updated": "2025-10-20T14:27:09Z",
    "link": "http://arxiv.org/pdf/2507.00432v2.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Maggie Huan",
      "Yuetai Li",
      "Tuney Zheng",
      "Xiaoyu Xu",
      "Seungone Kim",
      "Minxin Du",
      "Radha Poovendran",
      "Graham Neubig",
      "Xiang Yue"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17576v1",
    "title": "Intent-Driven LLM Ensemble Planning for Flexible Multi-Robot\n  Disassembly: Demonstration on EV Batteries",
    "summary": "This paper addresses the problem of planning complex manipulation tasks, in\nwhich multiple robots with different end-effectors and capabilities, informed\nby computer vision, must plan and execute concatenated sequences of actions on\na variety of objects that can appear in arbitrary positions and configurations\nin unstructured scenes. We propose an intent-driven planning pipeline which can\nrobustly construct such action sequences with varying degrees of supervisory\ninput from a human using simple language instructions. The pipeline integrates:\n(i) perception-to-text scene encoding, (ii) an ensemble of large language\nmodels (LLMs) that generate candidate removal sequences based on the operator's\nintent, (iii) an LLM-based verifier that enforces formatting and precedence\nconstraints, and (iv) a deterministic consistency filter that rejects\nhallucinated objects. The pipeline is evaluated on an example task in which two\nrobot arms work collaboratively to dismantle an Electric Vehicle battery for\nrecycling applications. A variety of components must be grasped and removed in\nspecific sequences, determined by human instructions and/or by task-order\nfeasibility decisions made by the autonomous system. On 200 real scenes with\n600 operator prompts across five component classes, we used metrics of\nfull-sequence correctness and next-task correctness to evaluate and compare\nfive LLM-based planners (including ablation analyses of pipeline components).\nWe also evaluated the LLM-based human interface in terms of time to execution\nand NASA TLX with human participant experiments. Results indicate that our\nensemble-with-verification approach reliably maps operator intent to safe,\nexecutable multi-robot plans while maintaining low user effort.",
    "published": "2025-10-20T14:24:39Z",
    "updated": "2025-10-20T14:24:39Z",
    "link": "http://arxiv.org/pdf/2510.17576v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.HC",
      "cs.MA"
    ],
    "authors": [
      "Cansu Erdogan",
      "Cesar Alan Contreras",
      "Alireza Rastegarpanah",
      "Manolis Chiou",
      "Rustam Stolkin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.12164v2",
    "title": "Diffusion Transformers as Open-World Spatiotemporal Foundation Models",
    "summary": "The urban environment is characterized by complex spatio-temporal dynamics\narising from diverse human activities and interactions. Effectively modeling\nthese dynamics is essential for understanding and optimizing urban systems. In\nthis work, we introduce UrbanDiT, a foundation model for open-world urban\nspatio-temporal learning that successfully scales up diffusion transformers in\nthis field. UrbanDiT pioneers a unified model that integrates diverse data\nsources and types while learning universal spatio-temporal patterns across\ndifferent cities and scenarios. This allows the model to unify both multi-data\nand multi-task learning, and effectively support a wide range of\nspatio-temporal applications. Its key innovation lies in the elaborated prompt\nlearning framework, which adaptively generates both data-driven and\ntask-specific prompts, guiding the model to deliver superior performance across\nvarious urban applications. UrbanDiT offers three advantages: 1) It unifies\ndiverse data types, such as grid-based and graph-based data, into a sequential\nformat; 2) With task-specific prompts, it supports a wide range of tasks,\nincluding bi-directional spatio-temporal prediction, temporal interpolation,\nspatial extrapolation, and spatio-temporal imputation; and 3) It generalizes\neffectively to open-world scenarios, with its powerful zero-shot capabilities\noutperforming nearly all baselines with training data. UrbanDiT sets up a new\nbenchmark for foundation models in the urban spatio-temporal domain. Code and\ndatasets are publicly available at\nhttps://github.com/tsinghua-fib-lab/UrbanDiT.",
    "published": "2024-11-19T02:01:07Z",
    "updated": "2025-10-20T14:24:19Z",
    "link": "http://arxiv.org/pdf/2411.12164v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Yuan Yuan",
      "Chonghua Han",
      "Jingtao Ding",
      "Guozhen Zhang",
      "Depeng Jin",
      "Yong Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.16198v5",
    "title": "RPG: A Repository Planning Graph for Unified and Scalable Codebase\n  Generation",
    "summary": "Large language models excel at generating individual functions or single\nfiles of code, yet generating complete repositories from scratch remains a\nfundamental challenge. This capability is key to building coherent software\nsystems from high-level specifications and realizing the full potential of\nautomated code generation. The process requires planning at two levels:\ndeciding what features and modules to build (proposal stage) and defining their\nimplementation details (implementation stage). Current approaches rely on\nnatural language planning, which often produces unclear specifications,\nmisaligned components, and brittle designs due to its inherent ambiguity and\nlack of structure. To address these limitations, we introduce the Repository\nPlanning Graph (RPG), a structured representation that encodes capabilities,\nfile structures, data flows, and functions in a unified graph. By replacing\nfree-form natural language with an explicit blueprint, RPG enables consistent\nlong-horizon planning for repository generation. Building on RPG, we develop\nZeroRepo, a graph-driven framework that operates in three stages:\nproposal-level planning, implementation-level construction, and graph-guided\ncode generation with test validation. To evaluate, we construct RepoCraft, a\nbenchmark of six real-world projects with 1,052 tasks. On RepoCraft, ZeroRepo\nproduces nearly 36K Code Lines and 445K Code Tokens, on average 3.9$\\times$\nlarger than the strongest baseline (Claude Code), and 68$\\times$ larger than\nother baselines. It achieves 81.5% coverage and 69.7% test accuracy, improving\nover Claude Code by 27.3 and 35.8 points. Further analysis shows that RPG\nmodels complex dependencies, enables more sophisticated planning through\nnear-linear scaling, and improves agent understanding of repositories, thus\naccelerating localization.",
    "published": "2025-09-19T17:58:14Z",
    "updated": "2025-10-20T14:22:14Z",
    "link": "http://arxiv.org/pdf/2509.16198v5.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.SE"
    ],
    "authors": [
      "Jane Luo",
      "Xin Zhang",
      "Steven Liu",
      "Jie Wu",
      "Jianfeng Liu",
      "Yiming Huang",
      "Yangyu Huang",
      "Chengyu Yin",
      "Ying Xin",
      "Yuefeng Zhan",
      "Hao Sun",
      "Qi Chen",
      "Scarlett Li",
      "Mao Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17564v1",
    "title": "An Empirical Study of Lagrangian Methods in Safe Reinforcement Learning",
    "summary": "In safety-critical domains such as robotics, navigation and power systems,\nconstrained optimization problems arise where maximizing performance must be\ncarefully balanced with associated constraints. Safe reinforcement learning\nprovides a framework to address these challenges, with Lagrangian methods being\na popular choice. However, the effectiveness of Lagrangian methods crucially\ndepends on the choice of the Lagrange multiplier $\\lambda$, which governs the\ntrade-off between return and constraint cost. A common approach is to update\nthe multiplier automatically during training. Although this is standard in\npractice, there remains limited empirical evidence on the robustness of an\nautomated update and its influence on overall performance. Therefore, we\nanalyze (i) optimality and (ii) stability of Lagrange multipliers in safe\nreinforcement learning across a range of tasks. We provide $\\lambda$-profiles\nthat give a complete visualization of the trade-off between return and\nconstraint cost of the optimization problem. These profiles show the highly\nsensitive nature of $\\lambda$ and moreover confirm the lack of general\nintuition for choosing the optimal value $\\lambda^*$. Our findings additionally\nshow that automated multiplier updates are able to recover and sometimes even\nexceed the optimal performance found at $\\lambda^*$ due to the vast difference\nin their learning trajectories. Furthermore, we show that automated multiplier\nupdates exhibit oscillatory behavior during training, which can be mitigated\nthrough PID-controlled updates. However, this method requires careful tuning to\nachieve consistently better performance across tasks. This highlights the need\nfor further research on stabilizing Lagrangian methods in safe reinforcement\nlearning. The code used to reproduce our results can be found at\nhttps://github.com/lindsayspoor/Lagrangian_SafeRL.",
    "published": "2025-10-20T14:13:17Z",
    "updated": "2025-10-20T14:13:17Z",
    "link": "http://arxiv.org/pdf/2510.17564v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "authors": [
      "Lindsay Spoor",
      "Ãlvaro Serra-GÃ³mez",
      "Aske Plaat",
      "Thomas Moerland"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.22904v2",
    "title": "SketchMind: A Multi-Agent Cognitive Framework for Assessing\n  Student-Drawn Scientific Sketches",
    "summary": "Scientific sketches (e.g., models) offer a powerful lens into students'\nconceptual understanding, yet AI-powered automated assessment of such\nfree-form, visually diverse artifacts remains a critical challenge. Existing\nsolutions often treat sketch evaluation as either an image classification task\nor monolithic vision-language models, which lack interpretability, pedagogical\nalignment, and adaptability across cognitive levels. To address these\nlimitations, we present SketchMind, a cognitively grounded, multi-agent\nframework for evaluating and improving student-drawn scientific sketches.\nSketchMind comprises modular agents responsible for rubric parsing, sketch\nperception, cognitive alignment, and iterative feedback with sketch\nmodification, enabling personalized and transparent evaluation. We evaluate\nSketchMind on a curated dataset of 3,575 student-generated sketches across six\nscience assessment items with different highest order of Bloom's level that\nrequire students to draw models to explain phenomena. Compared to baseline\nGPT-4o performance without SRG (average accuracy: 55.6%), and with SRG\nintegration achieves 77.1% average accuracy (+21.4% average absolute gain). We\nalso demonstrate that multi-agent orchestration with SRG enhances SketchMind\nperformance, for example, GPT-4.1 gains an average 8.9% increase in sketch\nprediction accuracy, outperforming single-agent pipelines across all items.\nHuman evaluators rated the feedback and co-created sketches generated by\n\\textsc{SketchMind} with GPT-4.1, which achieved an average of 4.1 out of 5,\nsignificantly higher than those of baseline models (e.g., 2.3 for GPT-4o).\nExperts noted the system's potential to meaningfully support conceptual growth\nthrough guided revision. Our code and (pending approval) dataset will be\nreleased to support reproducibility and future research in AI-driven education.",
    "published": "2025-06-29T11:35:10Z",
    "updated": "2025-10-20T13:55:37Z",
    "link": "http://arxiv.org/pdf/2507.22904v2.pdf",
    "category": [
      "cs.HC",
      "cs.AI"
    ],
    "authors": [
      "Ehsan Latif",
      "Zirak Khan",
      "Xiaoming Zhai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.07170v5",
    "title": "Parameter Efficient Fine-tuning via Explained Variance Adaptation",
    "summary": "Foundation models (FMs) are pre-trained on large-scale datasets and then\nfine-tuned for a specific downstream task. The most common fine-tuning method\nis to update pretrained weights via low-rank adaptation (LoRA). Existing\ninitialization strategies for LoRA often rely on singular value decompositions\n(SVD) of gradients or weight matrices. However, they do not provably maximize\nthe expected gradient signal, which is critical for fast adaptation. To this\nend, we introduce Explained Variance Adaptation (EVA), an initialization scheme\nthat uses the directions capturing the most activation variance, provably\nmaximizing the expected gradient signal and accelerating fine-tuning. EVA\nperforms incremental SVD on minibatches of activation vectors and selects the\nright-singular vectors for initialization once they converged. Further, by\nselecting the directions that capture the most activation-variance for a given\nrank budget, EVA accommodates adaptive ranks that reduce the number of\ntrainable parameters. We apply EVA to a variety of fine-tuning tasks as\nlanguage generation and understanding, image classification, and reinforcement\nlearning. EVA exhibits faster convergence than competitors and achieves the\nhighest average score across a multitude of tasks per domain while reducing the\nnumber of trainable parameters through rank redistribution. In summary, EVA\nestablishes a new Pareto frontier compared to existing LoRA initialization\nschemes in both accuracy and efficiency.",
    "published": "2024-10-09T17:59:06Z",
    "updated": "2025-10-20T13:48:17Z",
    "link": "http://arxiv.org/pdf/2410.07170v5.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "authors": [
      "Fabian Paischer",
      "Lukas Hauzenberger",
      "Thomas Schmied",
      "Benedikt Alkin",
      "Marc Peter Deisenroth",
      "Sepp Hochreiter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17529v1",
    "title": "MambaX-Net: Dual-Input Mamba-Enhanced Cross-Attention Network for\n  Longitudinal MRI Segmentation",
    "summary": "Active Surveillance (AS) is a treatment option for managing low and\nintermediate-risk prostate cancer (PCa), aiming to avoid overtreatment while\nmonitoring disease progression through serial MRI and clinical follow-up.\nAccurate prostate segmentation is an important preliminary step for automating\nthis process, enabling automated detection and diagnosis of PCa. However,\nexisting deep-learning segmentation models are often trained on\nsingle-time-point and expertly annotated datasets, making them unsuitable for\nlongitudinal AS analysis, where multiple time points and a scarcity of expert\nlabels hinder their effective fine-tuning. To address these challenges, we\npropose MambaX-Net, a novel semi-supervised, dual-scan 3D segmentation\narchitecture that computes the segmentation for time point t by leveraging the\nMRI and the corresponding segmentation mask from the previous time point. We\nintroduce two new components: (i) a Mamba-enhanced Cross-Attention Module,\nwhich integrates the Mamba block into cross attention to efficiently capture\ntemporal evolution and long-range spatial dependencies, and (ii) a Shape\nExtractor Module that encodes the previous segmentation mask into a latent\nanatomical representation for refined zone delination. Moreover, we introduce a\nsemi-supervised self-training strategy that leverages pseudo-labels generated\nfrom a pre-trained nnU-Net, enabling effective learning without expert\nannotations. MambaX-Net was evaluated on a longitudinal AS dataset, and results\nshowed that it significantly outperforms state-of-the-art U-Net and\nTransformer-based models, achieving superior prostate zone segmentation even\nwhen trained on limited and noisy data.",
    "published": "2025-10-20T13:32:42Z",
    "updated": "2025-10-20T13:32:42Z",
    "link": "http://arxiv.org/pdf/2510.17529v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Yovin Yahathugoda",
      "Davide Prezzi",
      "Piyalitt Ittichaiwong",
      "Vicky Goh",
      "Sebastien Ourselin",
      "Michela Antonelli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17519v1",
    "title": "MUG-V 10B: High-efficiency Training Pipeline for Large Video Generation\n  Models",
    "summary": "In recent years, large-scale generative models for visual content\n(\\textit{e.g.,} images, videos, and 3D objects/scenes) have made remarkable\nprogress. However, training large-scale video generation models remains\nparticularly challenging and resource-intensive due to cross-modal text-video\nalignment, the long sequences involved, and the complex spatiotemporal\ndependencies. To address these challenges, we present a training framework that\noptimizes four pillars: (i) data processing, (ii) model architecture, (iii)\ntraining strategy, and (iv) infrastructure for large-scale video generation\nmodels. These optimizations delivered significant efficiency gains and\nperformance improvements across all stages of data preprocessing, video\ncompression, parameter scaling, curriculum-based pretraining, and\nalignment-focused post-training. Our resulting model, MUG-V 10B, matches recent\nstate-of-the-art video generators overall and, on e-commerce-oriented video\ngeneration tasks, surpasses leading open-source baselines in human evaluations.\nMore importantly, we open-source the complete stack, including model weights,\nMegatron-Core-based large-scale training code, and inference pipelines for\nvideo generation and enhancement. To our knowledge, this is the first public\nrelease of large-scale video generation training code that exploits\nMegatron-Core to achieve high training efficiency and near-linear multi-node\nscaling, details are available in\n\\href{https://github.com/Shopee-MUG/MUG-V}{our webpage}.",
    "published": "2025-10-20T13:20:37Z",
    "updated": "2025-10-20T13:20:37Z",
    "link": "http://arxiv.org/pdf/2510.17519v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Yongshun Zhang",
      "Zhongyi Fan",
      "Yonghang Zhang",
      "Zhangzikang Li",
      "Weifeng Chen",
      "Zhongwei Feng",
      "Chaoyue Wang",
      "Peng Hou",
      "Anxiang Zeng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17516v1",
    "title": "SimBench: Benchmarking the Ability of Large Language Models to Simulate\n  Human Behaviors",
    "summary": "Large language model (LLM) simulations of human behavior have the potential\nto revolutionize the social and behavioral sciences, if and only if they\nfaithfully reflect real human behaviors. Current evaluations are fragmented,\nbased on bespoke tasks and metrics, creating a patchwork of incomparable\nresults. To address this, we introduce SimBench, the first large-scale,\nstandardized benchmark for a robust, reproducible science of LLM simulation. By\nunifying 20 diverse datasets covering tasks from moral decision-making to\neconomic choice across a large global participant pool, SimBench provides the\nnecessary foundation to ask fundamental questions about when, how, and why LLM\nsimulations succeed or fail. We show that, while even the best LLMs today have\nlimited simulation ability (score: 40.80/100), performance scales log-linearly\nwith model size. Simulation performance is not improved by increased\ninference-time compute. We demonstrate an alignment-simulation trade-off:\ninstruction-tuning improves performance on low-entropy (consensus) questions\nbut degrades it on high-entropy (diverse) ones. Models particularly struggle\nwhen simulating specific demographic groups. Finally, we demonstrate that\nsimulation ability correlates most strongly with deep, knowledge-intensive\nreasoning (MMLU-Pro, r=0.939). By making progress measurable, we aim to\naccelerate the development of more faithful LLM simulators.",
    "published": "2025-10-20T13:14:38Z",
    "updated": "2025-10-20T13:14:38Z",
    "link": "http://arxiv.org/pdf/2510.17516v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "authors": [
      "Tiancheng Hu",
      "Joachim Baumann",
      "Lorenzo Lupo",
      "Dirk Hovy",
      "Nigel Collier",
      "Paul RÃ¶ttger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17515v1",
    "title": "The Graphon Limit Hypothesis: Understanding Neural Network Pruning via\n  Infinite Width Analysis",
    "summary": "Sparse neural networks promise efficiency, yet training them effectively\nremains a fundamental challenge. Despite advances in pruning methods that\ncreate sparse architectures, understanding why some sparse structures are\nbetter trainable than others with the same level of sparsity remains poorly\nunderstood. Aiming to develop a systematic approach to this fundamental\nproblem, we propose a novel theoretical framework based on the theory of graph\nlimits, particularly graphons, that characterizes sparse neural networks in the\ninfinite-width regime. Our key insight is that connectivity patterns of sparse\nneural networks induced by pruning methods converge to specific graphons as\nnetworks' width tends to infinity, which encodes implicit structural biases of\ndifferent pruning methods. We postulate the Graphon Limit Hypothesis and\nprovide empirical evidence to support it. Leveraging this graphon\nrepresentation, we derive a Graphon Neural Tangent Kernel (Graphon NTK) to\nstudy the training dynamics of sparse networks in the infinite width limit.\nGraphon NTK provides a general framework for the theoretical analysis of sparse\nnetworks. We empirically show that the spectral analysis of Graphon NTK\ncorrelates with observed training dynamics of sparse networks, explaining the\nvarying convergence behaviours of different pruning methods. Our framework\nprovides theoretical insights into the impact of connectivity patterns on the\ntrainability of various sparse network architectures.",
    "published": "2025-10-20T13:13:35Z",
    "updated": "2025-10-20T13:13:35Z",
    "link": "http://arxiv.org/pdf/2510.17515v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Hoang Pham",
      "The-Anh Ta",
      "Tom Jacobs",
      "Rebekka Burkholz",
      "Long Tran-Thanh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.19850v2",
    "title": "DISCOVER: Automated Curricula for Sparse-Reward Reinforcement Learning",
    "summary": "Sparse-reward reinforcement learning (RL) can model a wide range of highly\ncomplex tasks. Solving sparse-reward tasks is RL's core premise, requiring\nefficient exploration coupled with long-horizon credit assignment, and\novercoming these challenges is key for building self-improving agents with\nsuperhuman ability. Prior work commonly explores with the objective of solving\nmany sparse-reward tasks, making exploration of individual high-dimensional,\nlong-horizon tasks intractable. We argue that solving such challenging tasks\nrequires solving simpler tasks that are relevant to the target task, i.e.,\nwhose achieval will teach the agent skills required for solving the target\ntask. We demonstrate that this sense of direction, necessary for effective\nexploration, can be extracted from existing RL algorithms, without leveraging\nany prior information. To this end, we propose a method for directed\nsparse-reward goal-conditioned very long-horizon RL (DISCOVER), which selects\nexploratory goals in the direction of the target task. We connect DISCOVER to\nprincipled exploration in bandits, formally bounding the time until the target\ntask becomes achievable in terms of the agent's initial distance to the target,\nbut independent of the volume of the space of all tasks. We then perform a\nthorough evaluation in high-dimensional environments. We find that the directed\ngoal selection of DISCOVER solves exploration problems that are beyond the\nreach of prior state-of-the-art exploration methods in RL.",
    "published": "2025-05-26T11:35:07Z",
    "updated": "2025-10-20T12:58:20Z",
    "link": "http://arxiv.org/pdf/2505.19850v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "authors": [
      "Leander Diaz-Bone",
      "Marco Bagatella",
      "Jonas HÃ¼botter",
      "Andreas Krause"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17501v1",
    "title": "Context-Aware Pseudo-Label Scoring for Zero-Shot Video Summarization",
    "summary": "With the rapid proliferation of video content across social media,\nsurveillance, and education platforms, efficiently summarizing long videos into\nconcise yet semantically faithful surrogates has become increasingly vital.\nExisting supervised methods achieve strong in-domain accuracy by learning from\ndense annotations but suffer from high labeling costs and limited cross-dataset\ngeneralization, while unsupervised approaches, though label-free, often fail to\ncapture high-level human semantics and fine-grained narrative cues. More\nrecently, zero-shot prompting pipelines have leveraged large language models\n(LLMs) for training-free video summarization, yet remain highly sensitive to\nhandcrafted prompt templates and dataset-specific score normalization. To\novercome these limitations, we introduce a rubric-guided, pseudo-labeled\nprompting framework that transforms a small subset of ground-truth annotations\ninto high-confidence pseudo labels, which are aggregated into structured,\ndataset-adaptive scoring rubrics guiding interpretable scene evaluation. During\ninference, first and last segments are scored based solely on their\ndescriptions, whereas intermediate ones incorporate brief contextual summaries\nof adjacent scenes to assess narrative progression and redundancy. This\ncontextual prompting enables the LLM to balance local salience and global\ncoherence without parameter tuning. On SumMe and TVSum, our method achieves F1\nscores of \\textbf{57.58} and \\textbf{63.05}, surpassing unsupervised and prior\nzero-shot baselines while approaching supervised performance. The results\ndemonstrate that rubric-guided pseudo labeling effectively stabilizes LLM-based\nscoring and establishes a general, interpretable zero-shot paradigm for video\nsummarization.",
    "published": "2025-10-20T12:54:32Z",
    "updated": "2025-10-20T12:54:32Z",
    "link": "http://arxiv.org/pdf/2510.17501v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Yuanli Wu",
      "Long Zhang",
      "Yue Du",
      "Bin Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17496v1",
    "title": "I-RAVEN-X: Benchmarking Generalization and Robustness of Analogical and\n  Mathematical Reasoning in Large Language and Reasoning Models",
    "summary": "We introduce I-RAVEN-X, a symbolic benchmark designed to evaluate\ngeneralization and robustness in analogical and mathematical reasoning for\nLarge Language Models (LLMs) and Large Reasoning Models (LRMs). I-RAVEN-X\nextends I-RAVEN by increasing operand complexity, attribute range, and\nintroducing perceptual uncertainty. Compared to LLMs, empirical results show\nthat LRMs achieve improved productivity and systematicity on longer reasoning\nrelations and wider attribute ranges, respectively. However, LRMs are still\nsignificantly challenged by reasoning under uncertainty and cannot effectively\nexplore multiple probabilistic outcomes.",
    "published": "2025-10-20T12:51:13Z",
    "updated": "2025-10-20T12:51:13Z",
    "link": "http://arxiv.org/pdf/2510.17496v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Giacomo Camposampiero",
      "Michael Hersche",
      "Roger Wattenhofer",
      "Abu Sebastian",
      "Abbas Rahimi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.00783v2",
    "title": "KG-TRACES: Enhancing Large Language Models with Knowledge\n  Graph-constrained Trajectory Reasoning and Attribution Supervision",
    "summary": "Large language models (LLMs) have made remarkable strides in various natural\nlanguage processing tasks, but their performance on complex reasoning problems\nremains hindered by a lack of explainability and trustworthiness. This issue,\noften manifesting as hallucinations or unattributable reasoning processes,\nlimits their applicability in complex reasoning scenarios. To address this, we\npropose Knowledge Graph-constrained Trajectory Reasoning Attribution and Chain\nExplanation Supervision (KG-TRACES), a novel framework that enhances the\nreasoning ability of LLMs through explicit supervision over reasoning paths and\nprocesses. KG-TRACES jointly supervises the model to: (1) predict symbolic\nrelation paths, (2) predict full triple-level reasoning paths, and (3) generate\nattribution-aware reasoning processes grounded in the reasoning paths. At\ninference phase, the model adapts to both KG-available and KG-unavailable\nscenarios, retrieving reasoning paths from a KG when possible or predicting\nplausible reasoning paths with only intrinsic knowledge when not. This design\nenables the model to reason in an explainable and source-attributable pattern.\nThrough extensive experiments on complex reasoning tasks, we demonstrate that\nKG-TRACES significantly outperforms existing SOTA: it improves Hits@1 by 1.6%\nand F1 by 4.7% on WebQSP, and achieves improvements of 4.8% in Hits@1 and 2.1%\nin F1 on CWQ. Moreover, we show its transferability to specialized domains such\nas medicine. By visualizing the intermediate steps of reasoning processes, we\nfurther show that the explicit supervision introduced by KG-TRACES leads to\nmore stable and goal-directed reasoning processes, aligning closely with\ncorrect answers. Code is available at https://github.com/Edaizi/KG-TRACES.",
    "published": "2025-06-01T02:20:45Z",
    "updated": "2025-10-20T12:31:56Z",
    "link": "http://arxiv.org/pdf/2506.00783v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Rong Wu",
      "Pinlong Cai",
      "Jianbiao Mei",
      "Licheng Wen",
      "Tao Hu",
      "Xuemeng Yang",
      "Daocheng Fu",
      "Botian Shi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.04755v2",
    "title": "A New Digital Divide? Coder Worldviews, the Slop Economy, and Democracy\n  in the Age of AI",
    "summary": "Digital technologies are transforming democratic life in conflicting ways.\nThis article bridges two perspectives to unpack these tensions. First, we\npresent an original survey of software developers in Silicon Valley,\ninterrogating how coder worldviews, ethics, and workplace cultures shape the\ndemocratic potential and social impact of the technologies they build. Results\nindicate that while most developers recognize the power of their products to\ninfluence civil liberties and political discourse, they often face ethical\ndilemmas and top-down pressures that can lead to design choices undermining\ndemocratic ideals. Second, we critically investigate these findings in the\ncontext of an emerging new digital divide, not of internet access but of\ninformation quality. We interrogate the survey findings in the context of the\nSlop Economy, in which billions of users unable to pay for high-quality content\nexperience an internet dominated by low-quality, AI-generated ad-driven\ncontent. We find a reinforcing cycle between tech creator beliefs and the\ndigital ecosystems they spawn. We discuss implications for democratic\ngovernance, arguing for more ethically informed design and policy interventions\nto help bridge the digital divide to ensure that technological innovation\nsupports rather than subverts democratic values in the next chapter of the\ndigital age.",
    "published": "2025-10-06T12:32:37Z",
    "updated": "2025-10-20T12:31:39Z",
    "link": "http://arxiv.org/pdf/2510.04755v2.pdf",
    "category": [
      "cs.CY",
      "cs.AI"
    ],
    "authors": [
      "Jason Miklian",
      "Kristian Hoelscher"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17482v1",
    "title": "SparseWorld: A Flexible, Adaptive, and Efficient 4D Occupancy World\n  Model Powered by Sparse and Dynamic Queries",
    "summary": "Semantic occupancy has emerged as a powerful representation in world models\nfor its ability to capture rich spatial semantics. However, most existing\noccupancy world models rely on static and fixed embeddings or grids, which\ninherently limit the flexibility of perception. Moreover, their ``in-place\nclassification\" over grids exhibits a potential misalignment with the dynamic\nand continuous nature of real scenarios.In this paper, we propose SparseWorld,\na novel 4D occupancy world model that is flexible, adaptive, and efficient,\npowered by sparse and dynamic queries. We propose a Range-Adaptive Perception\nmodule, in which learnable queries are modulated by the ego vehicle states and\nenriched with temporal-spatial associations to enable extended-range\nperception. To effectively capture the dynamics of the scene, we design a\nState-Conditioned Forecasting module, which replaces classification-based\nforecasting with regression-guided formulation, precisely aligning the dynamic\nqueries with the continuity of the 4D environment. In addition, We specifically\ndevise a Temporal-Aware Self-Scheduling training strategy to enable smooth and\nefficient training. Extensive experiments demonstrate that SparseWorld achieves\nstate-of-the-art performance across perception, forecasting, and planning\ntasks. Comprehensive visualizations and ablation studies further validate the\nadvantages of SparseWorld in terms of flexibility, adaptability, and\nefficiency. The code is available at https://github.com/MSunDYY/SparseWorld.",
    "published": "2025-10-20T12:26:25Z",
    "updated": "2025-10-20T12:26:25Z",
    "link": "http://arxiv.org/pdf/2510.17482v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Chenxu Dang",
      "Haiyan Liu",
      "Guangjun Bao",
      "Pei An",
      "Xinyue Tang",
      "Jie Ma",
      "Bingchuan Sun",
      "Yan Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17475v1",
    "title": "DAMSDAN: Distribution-Aware Multi-Source Domain Adaptation Network for\n  Cross-Domain EEG-based Emotion Recognition",
    "summary": "Significant inter-individual variability limits the generalization of\nEEG-based emotion recognition under cross-domain settings. We address two core\nchallenges in multi-source adaptation: (1) dynamically modeling distributional\nheterogeneity across sources and quantifying their relevance to a target to\nreduce negative transfer; and (2) achieving fine-grained semantic consistency\nto strengthen class discrimination. We propose a distribution-aware\nmulti-source domain adaptation network (DAMSDAN). DAMSDAN integrates\nprototype-based constraints with adversarial learning to drive the encoder\ntoward discriminative, domain-invariant emotion representations. A domain-aware\nsource weighting strategy based on maximum mean discrepancy (MMD) dynamically\nestimates inter-domain shifts and reweights source contributions. In addition,\na prototype-guided conditional alignment module with dual pseudo-label\ninteraction enhances pseudo-label reliability and enables category-level,\nfine-grained alignment, mitigating noise propagation and semantic drift.\nExperiments on SEED and SEED-IV show average accuracies of 94.86\\% and 79.78\\%\nfor cross-subject, and 95.12\\% and 83.15\\% for cross-session protocols. On the\nlarge-scale FACED dataset, DAMSDAN achieves 82.88\\% (cross-subject). Extensive\nablations and interpretability analyses corroborate the effectiveness of the\nproposed framework for cross-domain EEG-based emotion recognition.",
    "published": "2025-10-20T12:18:46Z",
    "updated": "2025-10-20T12:18:46Z",
    "link": "http://arxiv.org/pdf/2510.17475v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Fo Hu",
      "Can Wang",
      "Qinxu Zheng",
      "Xusheng Yang",
      "Bin Zhou",
      "Gang Li",
      "Yu Sun",
      "Wen-an Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.01622v5",
    "title": "General agents contain world models",
    "summary": "Are world models a necessary ingredient for flexible, goal-directed\nbehaviour, or is model-free learning sufficient? We provide a formal answer to\nthis question, showing that any agent capable of generalizing to multi-step\ngoal-directed tasks must have learned a predictive model of its environment. We\nshow that this model can be extracted from the agent's policy, and that\nincreasing the agents performance or the complexity of the goals it can achieve\nrequires learning increasingly accurate world models. This has a number of\nconsequences: from developing safe and general agents, to bounding agent\ncapabilities in complex environments, and providing new algorithms for\neliciting world models from agents.",
    "published": "2025-06-02T13:01:13Z",
    "updated": "2025-10-20T12:08:32Z",
    "link": "http://arxiv.org/pdf/2506.01622v5.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "cs.RO",
      "stat.ML"
    ],
    "authors": [
      "Jonathan Richens",
      "David Abel",
      "Alexis Bellot",
      "Tom Everitt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17469v1",
    "title": "Layer Specialization Underlying Compositional Reasoning in Transformers",
    "summary": "Transformers exhibit compositional reasoning on sequences not observed during\ntraining, a capability often attributed to in-context learning (ICL) and skill\ncomposition. We investigate this phenomenon using the Random Hierarchy Model\n(RHM), a probabilistic context-free grammar that generates sequences through\nrecursive rule application. Models are trained on subsets of sequences and\nevaluated across four generalization conditions: memorization, in-distribution\ngeneralization, out-of-distribution generalization with the same rules, and\ncross-layer transfer. Behaviorally, performance improves systematically with\ntask complexity and the number of in-context examples, with out-of-distribution\ntasks requiring substantially more examples than in-distribution scenarios.\nMechanistically, we identify a progressive emergence of layer specialization\nduring training that correlates with generalization performance. Principal\ncomponent analysis and attention pattern clustering reveal that transformers\ndevelop structured, hierarchically organized representations in specialized\nlayers. These results demonstrate that transformers develop modular,\ninterpretable mechanisms supporting compositional reasoning, linking internal\nalgorithmic structure to observed behavioral capabilities.",
    "published": "2025-10-20T12:08:22Z",
    "updated": "2025-10-20T12:08:22Z",
    "link": "http://arxiv.org/pdf/2510.17469v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Jing Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.13472v2",
    "title": "CodeVisionary: An Agent-based Framework for Evaluating Large Language\n  Models in Code Generation",
    "summary": "Large language models (LLMs) have demonstrated strong capabilities in code\ngeneration, underscoring the critical need for rigorous and comprehensive\nevaluation. Existing evaluation approaches fall into three categories,\nincluding human-centered, metric-based, and LLM-based. Considering that\nhuman-centered approaches are labour-intensive and metric-based ones overly\nrely on reference answers, LLM-based approaches are gaining increasing\nattention due to their stronger contextual understanding capabilities. However,\nthey generally evaluate the generated code based on static prompts, and tend to\nfail for complex code scenarios which typically involve multiple requirements\nand require more contextual information. In addition, these approaches lack\nfine-grained evaluation for complex code, resulting in limited explainability.\nTo mitigate the limitations, we propose CodeVisionary, the first agent-based\nevaluation framework for complex code generation. CodeVisionary consists of two\nstages: (1) Requirement-guided multi-dimensional context distillation stage and\n(2) Fine-grained scoring and summarization stage. A comprehensive evaluation\nreport is also generated for enhanced explainability. For validation, we\nconstruct a new benchmark consisting of 363 samples spanning 37 coding\nscenarios and 23 programming languages. Extensive experiments demonstrate that\nCodeVisionary achieves the best performance among three baselines for\nevaluating complex code generation, outperforming the best baseline with\naverage improvements of 0.217, 0.163, and 0.141 in Pearson, Spearman, and\nKendall-Tau coefficients, respectively. The resources of CodeVisionary are\navailable at https://github.com/Eshe0922/CodeVisionary.",
    "published": "2025-04-18T05:26:32Z",
    "updated": "2025-10-20T12:00:10Z",
    "link": "http://arxiv.org/pdf/2504.13472v2.pdf",
    "category": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Xinchen Wang",
      "Pengfei Gao",
      "Chao Peng",
      "Ruida Hu",
      "Cuiyun Gao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17463v1",
    "title": "Label Indeterminacy in AI & Law",
    "summary": "Machine learning is increasingly used in the legal domain, where it typically\noperates retrospectively by treating past case outcomes as ground truth.\nHowever, legal outcomes are often shaped by human interventions that are not\ncaptured in most machine learning approaches. A final decision may result from\na settlement, an appeal, or other procedural actions. This creates label\nindeterminacy: the outcome could have been different if the intervention had or\nhad not taken place. We argue that legal machine learning applications need to\naccount for label indeterminacy. Methods exist that can impute these\nindeterminate labels, but they are all grounded in unverifiable assumptions. In\nthe context of classifying cases from the European Court of Human Rights, we\nshow that the way that labels are constructed during training can significantly\naffect model behaviour. We therefore position label indeterminacy as a relevant\nconcern in AI & Law and demonstrate how it can shape model behaviour.",
    "published": "2025-10-20T11:58:07Z",
    "updated": "2025-10-20T11:58:07Z",
    "link": "http://arxiv.org/pdf/2510.17463v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Cor Steging",
      "Tadeusz ZbiegieÅ"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.15430v2",
    "title": "Learning to Detect Unknown Jailbreak Attacks in Large Vision-Language\n  Models",
    "summary": "Despite extensive alignment efforts, Large Vision-Language Models (LVLMs)\nremain vulnerable to jailbreak attacks, posing serious safety risks. To address\nthis, existing detection methods either learn attack-specific parameters, which\nhinders generalization to unseen attacks, or rely on heuristically sound\nprinciples, which limit accuracy and efficiency. To overcome these limitations,\nwe propose Learning to Detect (LoD), a general framework that accurately\ndetects unknown jailbreak attacks by shifting the focus from attack-specific\nlearning to task-specific learning. This framework includes a Multi-modal\nSafety Concept Activation Vector module for safety-oriented representation\nlearning and a Safety Pattern Auto-Encoder module for unsupervised attack\nclassification. Extensive experiments show that our method achieves\nconsistently higher detection AUROC on diverse unknown attacks while improving\nefficiency. The code is available at\nhttps://anonymous.4open.science/r/Learning-to-Detect-51CB.",
    "published": "2025-10-17T08:37:45Z",
    "updated": "2025-10-20T11:50:13Z",
    "link": "http://arxiv.org/pdf/2510.15430v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Shuang Liang",
      "Zhihao Xu",
      "Jialing Tao",
      "Hui Xue",
      "Xiting Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.16068v3",
    "title": "Communications to Circulations: Real-Time 3D Wind Field Prediction Using\n  5G GNSS Signals and Deep Learning",
    "summary": "Accurate atmospheric wind field information is crucial for various\napplications, including weather forecasting, aviation safety, and disaster risk\nreduction. However, obtaining high spatiotemporal resolution wind data remains\nchallenging due to limitations in traditional in-situ observations and remote\nsensing techniques, as well as the computational expense and biases of\nnumerical weather prediction (NWP) models. This paper introduces G-WindCast, a\nnovel deep learning framework that leverages signal strength variations from 5G\nGlobal Navigation Satellite System (GNSS) signals to forecast three-dimensional\n(3D) atmospheric wind fields. The framework utilizes Forward Neural Networks\n(FNN) and Transformer networks to capture complex, nonlinear, and\nspatiotemporal relationships between GNSS-derived features and wind dynamics.\nOur preliminary results demonstrate promising accuracy in real-time wind\nforecasts (up to 30 minutes lead time). The model exhibits robustness across\nforecast horizons and different pressure levels, and its predictions for wind\nfields show superior agreement with ground-based radar wind profiler compared\nto concurrent European Centre for Medium-Range Weather Forecasts (ECMWF)\nReanalysis v5 (ERA5). Furthermore, we show that the system can maintain\nexcellent performance for localized forecasting even with a significantly\nreduced number of GNSS stations (e.g., around 100), highlighting its\ncost-effectiveness and scalability. This interdisciplinary approach underscores\nthe transformative potential of exploiting non-traditional data sources and\ndeep learning for advanced environmental monitoring and real-time atmospheric\napplications.",
    "published": "2025-09-19T15:17:08Z",
    "updated": "2025-10-20T11:46:22Z",
    "link": "http://arxiv.org/pdf/2509.16068v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "68T07",
      "I.2.1"
    ],
    "authors": [
      "Yuchen Ye",
      "Chaoxia Yuan",
      "Mingyu Li",
      "Aoqi Zhou",
      "Hong Liang",
      "Chunqing Shang",
      "Kezuan Wang",
      "Yifeng Zheng",
      "Cong Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17451v1",
    "title": "The Parameterized Complexity of Computing the VC-Dimension",
    "summary": "The VC-dimension is a fundamental and well-studied measure of the complexity\nof a set system (or hypergraph) that is central to many areas of machine\nlearning. We establish several new results on the complexity of computing the\nVC-dimension. In particular, given a hypergraph\n$\\mathcal{H}=(\\mathcal{V},\\mathcal{E})$, we prove that the naive\n$2^{\\mathcal{O}(|\\mathcal{V}|)}$-time algorithm is asymptotically tight under\nthe Exponential Time Hypothesis (ETH). We then prove that the problem admits a\n1-additive fixed-parameter approximation algorithm when parameterized by the\nmaximum degree of $\\mathcal{H}$ and a fixed-parameter algorithm when\nparameterized by its dimension, and that these are essentially the only such\nexploitable structural parameters. Lastly, we consider a generalization of the\nproblem, formulated using graphs, which captures the VC-dimension of both set\nsystems and graphs. We show that it is fixed-parameter tractable parameterized\nby the treewidth of the graph (which, in the case of set systems, applies to\nthe treewidth of its incidence graph). In contrast with closely related\nproblems whose dependency on the treewidth is necessarily double-exponential\n(assuming the ETH), our algorithm has a relatively low dependency on the\ntreewidth.",
    "published": "2025-10-20T11:36:39Z",
    "updated": "2025-10-20T11:36:39Z",
    "link": "http://arxiv.org/pdf/2510.17451v1.pdf",
    "category": [
      "cs.CC",
      "cs.AI",
      "cs.DM",
      "cs.LG",
      "math.CO"
    ],
    "authors": [
      "Florent Foucaud",
      "Harmender Gahlawat",
      "Fionn Mc Inerney",
      "Prafullkumar Tale"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17450v1",
    "title": "Active Inference for an Intelligent Agent in Autonomous Reconnaissance\n  Missions",
    "summary": "We develop an active inference route-planning method for the autonomous\ncontrol of intelligent agents. The aim is to reconnoiter a geographical area to\nmaintain a common operational picture. To achieve this, we construct an\nevidence map that reflects our current understanding of the situation,\nincorporating both positive and \"negative\" sensor observations of possible\ntarget objects collected over time, and diffusing the evidence across the map\nas time progresses. The generative model of active inference uses\nDempster-Shafer theory and a Gaussian sensor model, which provides input to the\nagent. The generative process employs a Bayesian approach to update a posterior\nprobability distribution. We calculate the variational free energy for all\npositions within the area by assessing the divergence between a pignistic\nprobability distribution of the evidence map and a posterior probability\ndistribution of a target object based on the observations, including the level\nof surprise associated with receiving new observations. Using the free energy,\nwe direct the agents' movements in a simulation by taking an incremental step\ntoward a position that minimizes the free energy. This approach addresses the\nchallenge of exploration and exploitation, allowing agents to balance searching\nextensive areas of the geographical map while tracking identified target\nobjects.",
    "published": "2025-10-20T11:35:46Z",
    "updated": "2025-10-20T11:35:46Z",
    "link": "http://arxiv.org/pdf/2510.17450v1.pdf",
    "category": [
      "cs.AI",
      "H.4.2; I.2.3; I.2.6; I.2.8; I.2.9; J.7"
    ],
    "authors": [
      "Johan Schubert",
      "Farzad Kamrani",
      "Tove Gustavi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.02298v4",
    "title": "CAPO: Towards Enhancing LLM Reasoning through Generative Credit\n  Assignment",
    "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has improved the\nreasoning abilities of Large Language Models (LLMs) by using rule-based binary\nfeedback. However, current RLVR methods typically assign the same reward to\nevery token. This coarse-grained feedback hampers precise credit assignment,\nmaking it hard for models to identify which reasoning steps lead to success or\nfailure, and often results in suboptimal policies. Methods like PPO provide\ncredit assignment by value estimation, but yield inaccurate and unverifiable\nsignals due to limited sampling. On the other hand, methods using Process\nReward Models can provide step-wise rewards but suffer from several key\nlimitations: they require high-quality process supervision labels, the feedback\nis unreliable due to probabilistic reward modeling, and their application in\nonline reinforcement learning (RL) is time-consuming. To overcome these\nlimitations, we introduce a simple but efficient method-Credit Assignment\nPolicy Optimization (CAPO). Instead of training auxiliary models, CAPO directly\nleverages an off-the-shelf, general-purpose LLM as a Generative Process Reward\nModel (LLM-as-GenPRM) to generate all step-wise critique by one pass only based\non the correctness of the step itself, providing deterministic token-level\ncredits to refine the tokens that were originally assigned identical rule-based\nrewards. To further enhance the accuracy and robustness, we employ voting\nmechanisms that scale with the number of generated critiques. Extensive\nexperiments on various backbones like Llama and Qwen models show that CAPO\nconsistently outperforms supervised learning-based and RL-based fine-tuning\nmethods across four challenging mathematical benchmarks and three out-of-domain\nbenchmarks. Further analysis shows that CAPO can help the model to foster the\nlearning of correct reasoning pathways leading to correct answers.",
    "published": "2025-08-04T11:06:08Z",
    "updated": "2025-10-20T11:32:37Z",
    "link": "http://arxiv.org/pdf/2508.02298v4.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Guofu Xie",
      "Yunsheng Shi",
      "Hongtao Tian",
      "Ting Yao",
      "Xiao Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17439v1",
    "title": "From Spatial to Actions: Grounding Vision-Language-Action Model in\n  Spatial Foundation Priors",
    "summary": "Existing vision-language-action (VLA) models act in 3D real-world but are\ntypically built on 2D encoders, leaving a spatial reasoning gap that limits\ngeneralization and adaptability. Recent 3D integration techniques for VLAs\neither require specialized sensors and transfer poorly across modalities, or\ninject weak cues that lack geometry and degrade vision-language alignment. In\nthis work, we introduce FALCON (From Spatial to Action), a novel paradigm that\ninjects rich 3D spatial tokens into the action head. FALCON leverages spatial\nfoundation models to deliver strong geometric priors from RGB alone, and\nincludes an Embodied Spatial Model that can optionally fuse depth, or pose for\nhigher fidelity when available, without retraining or architectural changes. To\npreserve language reasoning, spatial tokens are consumed by a Spatial-Enhanced\nAction Head rather than being concatenated into the vision-language backbone.\nThese designs enable FALCON to address limitations in spatial representation,\nmodality transferability, and alignment. In comprehensive evaluations across\nthree simulation benchmarks and eleven real-world tasks, our proposed FALCON\nachieves state-of-the-art performance, consistently surpasses competitive\nbaselines, and remains robust under clutter, spatial-prompt conditioning, and\nvariations in object scale and height.",
    "published": "2025-10-20T11:26:45Z",
    "updated": "2025-10-20T11:26:45Z",
    "link": "http://arxiv.org/pdf/2510.17439v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Zhengshen Zhang",
      "Hao Li",
      "Yalun Dai",
      "Zhengbang Zhu",
      "Lei Zhou",
      "Chenchen Liu",
      "Dong Wang",
      "Francis E. H. Tay",
      "Sijin Chen",
      "Ziwei Liu",
      "Yuxiao Liu",
      "Xinghang Li",
      "Pan Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17426v1",
    "title": "Navigating the Alignment-Calibration Trade-off: A Pareto-Superior\n  Frontier via Model Merging",
    "summary": "The \"alignment tax\" of post-training is typically framed as a drop in task\naccuracy. We show it also involves a severe loss of calibration, making models\noverconfident, less reliable, and model outputs less diverse. We show that this\ntrade-off can be navigated effectively via a simple post-hoc intervention:\ninterpolating between a model's weights before and after alignment. Crucially,\nthis is not a strict trade-off. We find that the process consistently reveals\nPareto-optimal interpolations - models that improve accuracy beyond both\nparents while substantially recovering the calibration lost during alignment.\nOur work demonstrates that simple model merging provides a computationally\nefficient method for mitigating the full scope of the alignment tax, yielding\nmodels that are more capable and more reliable.",
    "published": "2025-10-20T11:12:41Z",
    "updated": "2025-10-20T11:12:41Z",
    "link": "http://arxiv.org/pdf/2510.17426v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Tiancheng Hu",
      "Benjamin Minixhofer",
      "Nigel Collier"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.03197v2",
    "title": "Infinity Parser: Layout Aware Reinforcement Learning for Scanned\n  Document Parsing",
    "summary": "Automated parsing of scanned documents into richly structured,\nmachine-readable formats remains a critical bottleneck in Document AI, as\ntraditional multi-stage pipelines suffer from error propagation and limited\nadaptability to diverse layouts. We introduce layoutRL, an end-to-end\nreinforcement learning framework that trains models to be explicitly\nlayout-aware by optimizing a composite reward of normalized edit distance,\nparagraph count accuracy, and reading order preservation. Leveraging our newly\nreleased dataset, Infinity-Doc-55K, which combines 55K high-fidelity synthetic\nscanned document parsing data with expert-filtered real-world documents, we\ninstantiate layoutRL in a vision-language-model-based parser called\nInfinity-Parser. Evaluated on English and Chinese benchmarks for OCR, table and\nformula extraction, and reading order detection, Infinity-Parser achieves new\nstate-of-the-art performance in both accuracy and structural fidelity,\noutpacing specialist pipelines and general-purpose vision-language models. We\nwill publicly release our code and dataset to accelerate progress in robust\ndocument understanding.",
    "published": "2025-06-01T15:19:52Z",
    "updated": "2025-10-20T11:09:33Z",
    "link": "http://arxiv.org/pdf/2506.03197v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Baode Wang",
      "Biao Wu",
      "Weizhen Li",
      "Meng Fang",
      "Zuming Huang",
      "Jun Huang",
      "Haozhe Wang",
      "Yanjie Liang",
      "Ling Chen",
      "Wei Chu",
      "Yuan Qi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17418v1",
    "title": "Diverse Planning with Simulators via Linear Temporal Logic",
    "summary": "Autonomous agents rely on automated planning algorithms to achieve their\nobjectives. Simulation-based planning offers a significant advantage over\ndeclarative models in modelling complex environments. However, relying solely\non a planner that produces a single plan may not be practical, as the generated\nplans may not always satisfy the agent's preferences. To address this\nlimitation, we introduce $\\texttt{FBI}_\\texttt{LTL}$, a diverse planner\nexplicitly designed for simulation-based planning problems.\n$\\texttt{FBI}_\\texttt{LTL}$ utilises Linear Temporal Logic (LTL) to define\nsemantic diversity criteria, enabling agents to specify what constitutes\nmeaningfully different plans. By integrating these LTL-based diversity models\ndirectly into the search process, $\\texttt{FBI}_\\texttt{LTL}$ ensures the\ngeneration of semantically diverse plans, addressing a critical limitation of\nexisting diverse planning approaches that may produce syntactically different\nbut semantically identical solutions. Extensive evaluations on various\nbenchmarks consistently demonstrate that $\\texttt{FBI}_\\texttt{LTL}$ generates\nmore diverse plans compared to a baseline approach. This work establishes the\nfeasibility of semantically-guided diverse planning in simulation-based\nenvironments, paving the way for innovative approaches in realistic,\nnon-symbolic domains where traditional model-based approaches fail.",
    "published": "2025-10-20T10:59:09Z",
    "updated": "2025-10-20T10:59:09Z",
    "link": "http://arxiv.org/pdf/2510.17418v1.pdf",
    "category": [
      "cs.AI",
      "cs.MA"
    ],
    "authors": [
      "Mustafa F. Abdelwahed",
      "Alice Toniolo",
      "Joan Espasa",
      "Ian P. Gent"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17415v1",
    "title": "BenCao: An Instruction-Tuned Large Language Model for Traditional\n  Chinese Medicine",
    "summary": "Traditional Chinese Medicine (TCM), with a history spanning over two\nmillennia, plays a role in global healthcare. However, applying large language\nmodels (LLMs) to TCM remains challenging due to its reliance on holistic\nreasoning, implicit logic, and multimodal diagnostic cues. Existing TCM-domain\nLLMs have made progress in text-based understanding but lack multimodal\nintegration, interpretability, and clinical applicability. To address these\nlimitations, we developed BenCao, a ChatGPT-based multimodal assistant for TCM,\nintegrating structured knowledge bases, diagnostic data, and expert feedback\nrefinement. BenCao was trained through natural language instruction tuning\nrather than parameter retraining, aligning with expert-level reasoning and\nethical norms specific to TCM. The system incorporates a comprehensive\nknowledge base of over 1,000 classical and modern texts, a scenario-based\ninstruction framework for diverse interactions, a chain-of-thought simulation\nmechanism for interpretable reasoning, and a feedback refinement process\ninvolving licensed TCM practitioners. BenCao connects to external APIs for\ntongue-image classification and multimodal database retrieval, enabling dynamic\naccess to diagnostic resources. In evaluations across single-choice question\nbenchmarks and multimodal classification tasks, BenCao achieved superior\naccuracy to general-domain and TCM-domain models, particularly in diagnostics,\nherb recognition, and constitution classification. The model was deployed as an\ninteractive application on the OpenAI GPTs Store, accessed by nearly 1,000\nusers globally as of October 2025. This study demonstrates the feasibility of\ndeveloping a TCM-domain LLM through natural language-based instruction tuning\nand multimodal integration, offering a practical framework for aligning\ngenerative AI with traditional medical reasoning and a scalable pathway for\nreal-world deployment.",
    "published": "2025-10-20T10:57:37Z",
    "updated": "2025-10-20T10:57:37Z",
    "link": "http://arxiv.org/pdf/2510.17415v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.MA",
      "cs.MM",
      "cs.SE"
    ],
    "authors": [
      "Jiacheng Xie",
      "Yang Yu",
      "Yibo Chen",
      "Hanyao Zhang",
      "Lening Zhao",
      "Jiaxuan He",
      "Lei Jiang",
      "Xiaoting Tang",
      "Guanghui An",
      "Dong Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17405v1",
    "title": "AFRICAPTION: Establishing a New Paradigm for Image Captioning in African\n  Languages",
    "summary": "Multimodal AI research has overwhelmingly focused on high-resource languages,\nhindering the democratization of advancements in the field. To address this, we\npresent AfriCaption, a comprehensive framework for multilingual image\ncaptioning in 20 African languages and our contributions are threefold: (i) a\ncurated dataset built on Flickr8k, featuring semantically aligned captions\ngenerated via a context-aware selection and translation process; (ii) a\ndynamic, context-preserving pipeline that ensures ongoing quality through model\nensembling and adaptive substitution; and (iii) the AfriCaption model, a 0.5B\nparameter vision-to-text architecture that integrates SigLIP and NLLB200 for\ncaption generation across under-represented languages. This unified framework\nensures ongoing data quality and establishes the first scalable\nimage-captioning resource for under-represented African languages, laying the\ngroundwork for truly inclusive multimodal AI.",
    "published": "2025-10-20T10:44:44Z",
    "updated": "2025-10-20T10:44:44Z",
    "link": "http://arxiv.org/pdf/2510.17405v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Mardiyyah Oduwole",
      "Prince Mireku",
      "Fatimo Adebanjo",
      "Oluwatosin Olajide",
      "Mahi Aminu Aliyu",
      "Jekaterina Novikova"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17402v1",
    "title": "Leveraging Group Relative Policy Optimization to Advance Large Language\n  Models in Traditional Chinese Medicine",
    "summary": "Traditional Chinese Medicine (TCM) presents a rich and structurally unique\nknowledge system that challenges conventional applications of large language\nmodels (LLMs). Although previous TCM-specific LLMs have shown progress through\nsupervised fine-tuning, they often face limitations in alignment, data quality,\nand evaluation consistency. In this study, we introduce Ladder-base, the first\nTCM-focused LLM trained with Group Relative Policy Optimization (GRPO), a\nreinforcement learning method that improves reasoning and factual consistency\nby optimizing response selection based on intra-group comparisons. Ladder-base\nis built upon the Qwen2.5-7B-Instruct foundation model and trained exclusively\non the textual subset of the TCM-Ladder benchmark, using 80 percent of the data\nfor training and the remaining 20 percent split evenly between validation and\ntest sets. Through standardized evaluation, Ladder-base demonstrates superior\nperformance across multiple reasoning metrics when compared to both\nstate-of-the-art general-purpose LLMs such as GPT-4, Gemini 2.5, Claude 3, and\nQwen3 and domain-specific TCM models including BenTsao, HuatuoGPT2, and\nZhongjing. These findings suggest that GRPO provides an effective and efficient\nstrategy for aligning LLMs with expert-level reasoning in traditional medical\ndomains and supports the development of trustworthy and clinically grounded TCM\nartificial intelligence systems.",
    "published": "2025-10-20T10:43:33Z",
    "updated": "2025-10-20T10:43:33Z",
    "link": "http://arxiv.org/pdf/2510.17402v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Jiacheng Xie",
      "Shuai Zeng",
      "Yang Yu",
      "Xiaoting Tang",
      "Guanghui An",
      "Dong Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.17786v3",
    "title": "Accurate and Efficient Low-Rank Model Merging in Core Space",
    "summary": "In this paper, we address the challenges associated with merging low-rank\nadaptations of large neural networks. With the rise of parameter-efficient\nadaptation techniques, such as Low-Rank Adaptation (LoRA), model fine-tuning\nhas become more accessible. While fine-tuning models with LoRA is highly\nefficient, existing merging methods often sacrifice this efficiency by merging\nfully-sized weight matrices. We propose the Core Space merging framework, which\nenables the merging of LoRA-adapted models within a common alignment basis,\nthereby preserving the efficiency of low-rank adaptation while substantially\nimproving accuracy across tasks. We further provide a formal proof that\nprojection into Core Space ensures no loss of information and provide a\ncomplexity analysis showing the efficiency gains. Extensive empirical results\ndemonstrate that Core Space significantly improves existing merging techniques\nand achieves state-of-the-art results on both vision and language tasks while\nutilizing a fraction of the computational resources. Codebase is available at\nhttps://github.com/apanariello4/core-space-merging.",
    "published": "2025-09-22T13:48:15Z",
    "updated": "2025-10-20T10:33:14Z",
    "link": "http://arxiv.org/pdf/2509.17786v3.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Aniello Panariello",
      "Daniel Marczak",
      "Simone Magistri",
      "Angelo Porrello",
      "BartÅomiej Twardowski",
      "Andrew D. Bagdanov",
      "Simone Calderara",
      "Joost van de Weijer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17389v1",
    "title": "EduAdapt: A Question Answer Benchmark Dataset for Evaluating Grade-Level\n  Adaptability in LLMs",
    "summary": "Large language models (LLMs) are transforming education by answering\nquestions, explaining complex concepts, and generating content across a wide\nrange of subjects. Despite strong performance on academic benchmarks, they\noften fail to tailor responses to students' grade levels. This is a critical\nneed in K-12 education, where age-appropriate vocabulary and explanation are\nessential for effective learning. Existing models frequently produce outputs\nthat are too advanced or vague for younger learners, and there are no\nstandardized benchmarks to evaluate their ability to adjust across cognitive\nand developmental stages. To address this gap, we introduce EduAdapt, a\nbenchmark of nearly 48k grade-labeled QA pairs across nine science subjects,\nspanning Grades 1-12 and grouped into four grade levels. We evaluate a diverse\nset of open-source LLMs on EduAdapt and find that while larger models generally\nperform better, they still struggle with generating suitable responses for\nearly-grade students (Grades 1-5). Our work presents the first dataset and\nevaluation framework for assessing grade-level adaptability in LLMs, aiming to\nfoster more developmentally aligned educational AI systems through better\ntraining and prompting strategies. EduAdapt code and datasets are publicly\navailable at https://github.com/NaumanNaeem/EduAdapt.",
    "published": "2025-10-20T10:30:40Z",
    "updated": "2025-10-20T10:30:40Z",
    "link": "http://arxiv.org/pdf/2510.17389v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "authors": [
      "Numaan Naeem",
      "Abdellah El Mekki",
      "Muhammad Abdul-Mageed"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.13477v3",
    "title": "Periodontal Bone Loss Analysis via Keypoint Detection With Heuristic\n  Post-Processing",
    "summary": "This study proposes a deep learning framework and annotation methodology for\nthe automatic detection of periodontal bone loss landmarks, associated\nconditions, and staging. 192 periapical radiographs were collected and\nannotated with a stage agnostic methodology, labelling clinically relevant\nlandmarks regardless of disease presence or extent. We propose a heuristic\npost-processing module that aligns predicted keypoints to tooth boundaries\nusing an auxiliary instance segmentation model. An evaluation metric,\nPercentage of Relative Correct Keypoints (PRCK), is proposed to capture\nkeypoint performance in dental imaging domains. Four donor pose estimation\nmodels were adapted with fine-tuning for our keypoint problem. Post-processing\nimproved fine-grained localisation, raising average PRCK^{0.05} by +0.028, but\nreduced coarse performance for PRCK^{0.25} by -0.0523 and PRCK^{0.5} by\n-0.0345. Orientation estimation shows excellent performance for auxiliary\nsegmentation when filtered with either stage 1 object detection model.\nPeriodontal staging was detected sufficiently, with the best mesial and distal\nDice scores of 0.508 and 0.489, while furcation involvement and widened\nperiodontal ligament space tasks remained challenging due to scarce positive\nsamples. Scalability is implied with similar validation and external set\nperformance. The annotation methodology enables stage agnostic training with\nbalanced representation across disease severities for some detection tasks. The\nPRCK metric provides a domain-specific alternative to generic pose metrics,\nwhile the heuristic post-processing module consistently corrected implausible\npredictions with occasional catastrophic failures. The proposed framework\ndemonstrates the feasibility of clinically interpretable periodontal bone loss\nassessment, with potential to reduce diagnostic variability and clinician\nworkload.",
    "published": "2025-03-05T00:34:29Z",
    "updated": "2025-10-20T10:26:37Z",
    "link": "http://arxiv.org/pdf/2503.13477v3.pdf",
    "category": [
      "q-bio.TO",
      "cs.AI",
      "cs.CV",
      "I.2.1; I.2.10; J.3"
    ],
    "authors": [
      "Ryan Banks",
      "Vishal Thengane",
      "MarÃ­a Eugenia Guerrero",
      "Nelly Maria GarcÃ­a-MadueÃ±o",
      "Yunpeng Li",
      "Hongying Tang",
      "Akhilanand Chaurasia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17386v1",
    "title": "Inference of Deterministic Finite Automata via Q-Learning",
    "summary": "Traditional approaches to inference of deterministic finite-state automata\n(DFA) stem from symbolic AI, including both active learning methods (e.g.,\nAngluin's L* algorithm and its variants) and passive techniques (e.g., Biermann\nand Feldman's method, RPNI). Meanwhile, sub-symbolic AI, particularly machine\nlearning, offers alternative paradigms for learning from data, such as\nsupervised, unsupervised, and reinforcement learning (RL). This paper\ninvestigates the use of Q-learning, a well-known reinforcement learning\nalgorithm, for the passive inference of deterministic finite automata. It\nbuilds on the core insight that the learned Q-function, which maps state-action\npairs to rewards, can be reinterpreted as the transition function of a DFA over\na finite domain. This provides a novel bridge between sub-symbolic learning and\nsymbolic representations. The paper demonstrates how Q-learning can be adapted\nfor automaton inference and provides an evaluation on several examples.",
    "published": "2025-10-20T10:23:36Z",
    "updated": "2025-10-20T10:23:36Z",
    "link": "http://arxiv.org/pdf/2510.17386v1.pdf",
    "category": [
      "cs.FL",
      "cs.AI"
    ],
    "authors": [
      "Elaheh Hosseinkhani",
      "Martin Leucker"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17385v1",
    "title": "TabR1: Taming GRPO for tabular reasoning LLMs",
    "summary": "Tabular prediction has traditionally relied on gradient-boosted decision\ntrees and specialized deep learning models, which excel within tasks but\nprovide limited interpretability and weak transfer across tables. Reasoning\nlarge language models (LLMs) promise cross-task adaptability with trans- parent\nreasoning traces, yet their potential has not been fully realized for tabular\ndata. This paper presents TabR1, the first reasoning LLM for tabular prediction\nwith multi-step reasoning. At its core is Permutation Relative Policy\nOptimization (PRPO), a simple yet efficient reinforcement learning method that\nencodes column-permutation invariance as a structural prior. By construct- ing\nmultiple label-preserving permutations per sample and estimating advantages\nboth within and across permutations, PRPO transforms sparse rewards into dense\nlearning signals and improves generalization. With limited supervision, PRPO\nactivates the reasoning ability of LLMs for tabular prediction, enhancing\nfew-shot and zero-shot performance as well as interpretability. Comprehensive\nexperiments demonstrate that TabR1 achieves performance comparable to strong\nbaselines under full-supervision fine-tuning. In the zero-shot setting, TabR1\napproaches the performance of strong baselines under the 32-shot setting.\nMoreover, TabR1 (8B) substantially outperforms much larger LLMs across various\ntasks, achieving up to 53.17% improvement over DeepSeek-R1 (685B).",
    "published": "2025-10-20T10:22:01Z",
    "updated": "2025-10-20T10:22:01Z",
    "link": "http://arxiv.org/pdf/2510.17385v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Pengxiang Cai",
      "Zihao Gao",
      "Jintai Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17382v1",
    "title": "Graph Attention-Guided Search for Dense Multi-Agent Pathfinding",
    "summary": "Finding near-optimal solutions for dense multi-agent pathfinding (MAPF)\nproblems in real-time remains challenging even for state-of-the-art planners.\nTo this end, we develop a hybrid framework that integrates a learned heuristic\nderived from MAGAT, a neural MAPF policy with a graph attention scheme, into a\nleading search-based algorithm, LaCAM. While prior work has explored\nlearning-guided search in MAPF, such methods have historically underperformed.\nIn contrast, our approach, termed LaGAT, outperforms both purely search-based\nand purely learning-based methods in dense scenarios. This is achieved through\nan enhanced MAGAT architecture, a pre-train-then-fine-tune strategy on maps of\ninterest, and a deadlock detection scheme to account for imperfect neural\nguidance. Our results demonstrate that, when carefully designed, hybrid search\noffers a powerful solution for tightly coupled, challenging multi-agent\ncoordination problems.",
    "published": "2025-10-20T10:19:35Z",
    "updated": "2025-10-20T10:19:35Z",
    "link": "http://arxiv.org/pdf/2510.17382v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "cs.RO"
    ],
    "authors": [
      "Rishabh Jain",
      "Keisuke Okumura",
      "Michael Amir",
      "Amanda Prorok"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.18065v2",
    "title": "Unseen from Seen: Rewriting Observation-Instruction Using Foundation\n  Models for Augmenting Vision-Language Navigation",
    "summary": "Data scarcity is a long-standing challenge in the Vision-Language Navigation\n(VLN) field, which extremely hinders the generalization of agents to unseen\nenvironments. Previous works primarily rely on additional simulator data or\nweb-collected images/videos to improve the generalization. However, the\nsimulator environments still face limited diversity, and the web-collected data\noften requires extensive labor to remove the noise. In this paper, we propose a\nRewriting-driven AugMentation (RAM) paradigm for VLN, which directly creates\nthe unseen observation-instruction pairs via rewriting human-annotated training\ndata. Benefiting from our rewriting mechanism, new observation-instruction\npairs can be obtained in both simulator-free and labor-saving manners to\npromote generalization. Specifically, we first introduce Object-Enriched\nObservation Rewriting, where we combine Vision-Language Models (VLMs) and Large\nLanguage Models (LLMs) to derive rewritten object-enriched scene descriptions,\nenabling observation synthesis with diverse objects and spatial layouts via\nText-to-Image Generation Models (T2IMs). Then, we propose Observation-Contrast\nInstruction Rewriting, which generates observation-aligned rewritten\ninstructions by requiring LLMs to reason the difference between original and\nnew observations. We further develop a mixing-then-focusing training strategy\nwith a random observation cropping scheme, effectively enhancing data\ndistribution diversity while suppressing augmentation data noise during\ntraining. Experiments on both the discrete environments (R2R, REVERIE, and R4R\ndatasets) and continuous environments (R2R-CE dataset) show the superior\nperformance and impressive generalization ability of our method. Code is\navailable at https://github.com/SaDil13/VLN-RAM.",
    "published": "2025-03-23T13:18:17Z",
    "updated": "2025-10-20T10:19:21Z",
    "link": "http://arxiv.org/pdf/2503.18065v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.RO"
    ],
    "authors": [
      "Ziming Wei",
      "Bingqian Lin",
      "Yunshuang Nie",
      "Jiaqi Chen",
      "Shikui Ma",
      "Hang Xu",
      "Xiaodan Liang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17380v1",
    "title": "Optimizing Energy Management of Smart Grid using Reinforcement Learning\n  aided by Surrogate models built using Physics-informed Neural Networks",
    "summary": "Optimizing the energy management within a smart grids scenario presents\nsignificant challenges, primarily due to the complexity of real-world systems\nand the intricate interactions among various components. Reinforcement Learning\n(RL) is gaining prominence as a solution for addressing the challenges of\nOptimal Power Flow in smart grids. However, RL needs to iterate compulsively\nthroughout a given environment to obtain the optimal policy. This means\nobtaining samples from a, most likely, costly simulator, which can lead to a\nsample efficiency problem. In this work, we address this problem by\nsubstituting costly smart grid simulators with surrogate models built using\nPhisics-informed Neural Networks (PINNs), optimizing the RL policy training\nprocess by arriving to convergent results in a fraction of the time employed by\nthe original environment.",
    "published": "2025-10-20T10:17:42Z",
    "updated": "2025-10-20T10:17:42Z",
    "link": "http://arxiv.org/pdf/2510.17380v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Julen Cestero",
      "Carmine Delle Femine",
      "Kenji S. Muro",
      "Marco Quartulli",
      "Marcello Restelli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17369v1",
    "title": "Bridging Embodiment Gaps: Deploying Vision-Language-Action Models on\n  Soft Robots",
    "summary": "Robotic systems are increasingly expected to operate in human-centered,\nunstructured environments where safety, adaptability, and generalization are\nessential. Vision-Language-Action (VLA) models have been proposed as a language\nguided generalized control framework for real robots. However, their deployment\nhas been limited to conventional serial link manipulators. Coupled by their\nrigidity and unpredictability of learning based control, the ability to safely\ninteract with the environment is missing yet critical. In this work, we present\nthe deployment of a VLA model on a soft continuum manipulator to demonstrate\nautonomous safe human-robot interaction. We present a structured finetuning and\ndeployment pipeline evaluating two state-of-the-art VLA models (OpenVLA-OFT and\n$\\pi_0$) across representative manipulation tasks, and show while\nout-of-the-box policies fail due to embodiment mismatch, through targeted\nfinetuning the soft robot performs equally to the rigid counterpart. Our\nfindings highlight the necessity of finetuning for bridging embodiment gaps,\nand demonstrate that coupling VLA models with soft robots enables safe and\nflexible embodied AI in human-shared environments.",
    "published": "2025-10-20T10:06:39Z",
    "updated": "2025-10-20T10:06:39Z",
    "link": "http://arxiv.org/pdf/2510.17369v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Haochen Su",
      "Cristian Meo",
      "Francesco Stella",
      "Andrea Peirone",
      "Kai Junge",
      "Josie Hughes"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17358v1",
    "title": "Localist LLMs with Recruitment Learning",
    "summary": "We present a novel framework for training large language models with\ncontinuously adjustable internal representations that span the full spectrum\nfrom localist (interpretable, rule-based) to distributed (generalizable,\nefficient) encodings. The key innovations are (1) a locality dial, a tunable\nparameter that dynamically controls the degree of localization during both\ntraining and inference without requiring model retraining, (2) an\ninformation-theoretic recruitment mechanism that adaptively allocates semantic\nblocks as needed, eliminating the requirement for complete domain knowledge at\ninitialization, and (3) a hierarchical recruitment framework that extends\ncapacity allocation to entire specialized LLMs, enabling multi-granularity\narchitectural adaptation. This is achieved through group sparsity penalties on\nattention mechanisms, information-theoretic anchor design, dynamic rule\ninjection, and principled recruitment criteria based on penalized likelihood\nwith explicit units. We provide rigorous mathematical results establishing\nexplicit threshold conditions under which attention provably concentrates on\nsemantically relevant blocks at stationary points, with exact bounds on\nattention entropy and pointer fidelity. The hierarchical recruitment mechanism\nprovides convergence guarantees at both the block level (fine-grained,\nwithin-LLM) and the LLM level (coarse-grained, cross-domain), ensuring the\nsystem discovers semantic partitions that balance model complexity against data\nencoding efficiency. This framework enables practitioners to continuously\ninterpolate between interpretable and high-performance modes while adapting\narchitectural capacity at multiple granularities, supporting applications in\nregulated domains requiring both transparency and capability.",
    "published": "2025-10-20T09:58:34Z",
    "updated": "2025-10-20T09:58:34Z",
    "link": "http://arxiv.org/pdf/2510.17358v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Joachim Diederich"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17354v1",
    "title": "Towards Mixed-Modal Retrieval for Universal Retrieval-Augmented\n  Generation",
    "summary": "Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm for\nenhancing large language models (LLMs) by retrieving relevant documents from an\nexternal corpus. However, existing RAG systems primarily focus on unimodal text\ndocuments, and often fall short in real-world scenarios where both queries and\ndocuments may contain mixed modalities (such as text and images). In this\npaper, we address the challenge of Universal Retrieval-Augmented Generation\n(URAG), which involves retrieving and reasoning over mixed-modal information to\nimprove vision-language generation. To this end, we propose Nyx, a unified\nmixed-modal to mixed-modal retriever tailored for URAG scenarios. To mitigate\nthe scarcity of realistic mixed-modal data, we introduce a four-stage automated\npipeline for generation and filtering, leveraging web documents to construct\nNyxQA, a dataset comprising diverse mixed-modal question-answer pairs that\nbetter reflect real-world information needs. Building on this high-quality\ndataset, we adopt a two-stage training framework for Nyx: we first perform\npre-training on NyxQA along with a variety of open-source retrieval datasets,\nfollowed by supervised fine-tuning using feedback from downstream\nvision-language models (VLMs) to align retrieval outputs with generative\npreferences. Experimental results demonstrate that Nyx not only performs\ncompetitively on standard text-only RAG benchmarks, but also excels in the more\ngeneral and realistic URAG setting, significantly improving generation quality\nin vision-language tasks.",
    "published": "2025-10-20T09:56:43Z",
    "updated": "2025-10-20T09:56:43Z",
    "link": "http://arxiv.org/pdf/2510.17354v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "authors": [
      "Chenghao Zhang",
      "Guanting Dong",
      "Xinyu Yang",
      "Zhicheng Dou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.19360v2",
    "title": "Semantic Representation Attack against Aligned Large Language Models",
    "summary": "Large Language Models (LLMs) increasingly employ alignment techniques to\nprevent harmful outputs. Despite these safeguards, attackers can circumvent\nthem by crafting prompts that induce LLMs to generate harmful content.\n  Current methods typically target exact affirmative responses, such as ``Sure,\nhere is...'', suffering from limited convergence, unnatural prompts, and high\ncomputational costs.\n  We introduce Semantic Representation Attack, a novel paradigm that\nfundamentally reconceptualizes adversarial objectives against aligned LLMs.\n  Rather than targeting exact textual patterns, our approach exploits the\nsemantic representation space comprising diverse responses with equivalent\nharmful meanings.\n  This innovation resolves the inherent trade-off between attack efficacy and\nprompt naturalness that plagues existing methods.\n  The Semantic Representation Heuristic Search algorithm is proposed to\nefficiently generate semantically coherent and concise adversarial prompts by\nmaintaining interpretability during incremental expansion.\n  We establish rigorous theoretical guarantees for semantic convergence and\ndemonstrate that our method achieves unprecedented attack success rates\n(89.41\\% averaged across 18 LLMs, including 100\\% on 11 models) while\nmaintaining stealthiness and efficiency.\n  Comprehensive experimental results confirm the overall superiority of our\nSemantic Representation Attack.\n  The code will be publicly available.",
    "published": "2025-09-18T15:06:46Z",
    "updated": "2025-10-20T09:45:40Z",
    "link": "http://arxiv.org/pdf/2509.19360v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Jiawei Lian",
      "Jianhong Pan",
      "Lefan Wang",
      "Yi Wang",
      "Shaohui Mei",
      "Lap-Pui Chau"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17346v1",
    "title": "TopSeg: A Multi-Scale Topological Framework for Data-Efficient Heart\n  Sound Segmentation",
    "summary": "Deep learning approaches for heart-sound (PCG) segmentation built on\ntime--frequency features can be accurate but often rely on large expert-labeled\ndatasets, limiting robustness and deployment. We present TopSeg, a topological\nrepresentation-centric framework that encodes PCG dynamics with multi-scale\ntopological features and decodes them using a lightweight temporal\nconvolutional network (TCN) with an order- and duration-constrained inference\nstep. To evaluate data efficiency and generalization, we train exclusively on\nPhysioNet 2016 dataset with subject-level subsampling and perform external\nvalidation on CirCor dataset. Under matched-capacity decoders, the topological\nfeatures consistently outperform spectrogram and envelope inputs, with the\nlargest margins at low data budgets; as a full system, TopSeg surpasses\nrepresentative end-to-end baselines trained on their native inputs under the\nsame budgets while remaining competitive at full data. Ablations at 10%\ntraining confirm that all scales contribute and that combining H_0 and H_1\nyields more reliable S1/S2 localization and boundary stability. These results\nindicate that topology-aware representations provide a strong inductive bias\nfor data-efficient, cross-dataset PCG segmentation, supporting practical use\nwhen labeled data are limited.",
    "published": "2025-10-20T09:43:39Z",
    "updated": "2025-10-20T09:43:39Z",
    "link": "http://arxiv.org/pdf/2510.17346v1.pdf",
    "category": [
      "cs.SD",
      "cs.AI"
    ],
    "authors": [
      "Peihong Zhang",
      "Zhixin Li",
      "Yuxuan Liu",
      "Rui Sang",
      "Yiqiang Cai",
      "Yizhou Tan",
      "Shengchen Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17345v1",
    "title": "DDSC: Dynamic Dual-Signal Curriculum for Data-Efficient Acoustic Scene\n  Classification under Domain Shift",
    "summary": "Acoustic scene classification (ASC) suffers from device-induced domain shift,\nespecially when labels are limited. Prior work focuses on curriculum-based\ntraining schedules that structure data presentation by ordering or reweighting\ntraining examples from easy-to-hard to facilitate learning; however, existing\ncurricula are static, fixing the ordering or the weights before training and\nignoring that example difficulty and marginal utility evolve with the learned\nrepresentation. To overcome this limitation, we propose the Dynamic Dual-Signal\nCurriculum (DDSC), a training schedule that adapts the curriculum online by\ncombining two signals computed each epoch: a domain-invariance signal and a\nlearning-progress signal. A time-varying scheduler fuses these signals into\nper-example weights that prioritize domain-invariant examples in early epochs\nand progressively emphasize device-specific cases. DDSC is lightweight,\narchitecture-agnostic, and introduces no additional inference overhead. Under\nthe official DCASE 2024 Task~1 protocol, DDSC consistently improves\ncross-device performance across diverse ASC baselines and label budgets, with\nthe largest gains on unseen-device splits.",
    "published": "2025-10-20T09:43:29Z",
    "updated": "2025-10-20T09:43:29Z",
    "link": "http://arxiv.org/pdf/2510.17345v1.pdf",
    "category": [
      "cs.SD",
      "cs.AI"
    ],
    "authors": [
      "Peihong Zhang",
      "Yuxuan Liu",
      "Rui Sang",
      "Zhixin Li",
      "Yiqiang Cai",
      "Yizhou Tan",
      "Shengchen Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.15862v2",
    "title": "PokeeResearch: Effective Deep Research via Reinforcement Learning from\n  AI Feedback and Robust Reasoning Scaffold",
    "summary": "Tool-augmented large language models (LLMs) are emerging as deep research\nagents, systems that decompose complex queries, retrieve external evidence, and\nsynthesize grounded responses. Yet current agents remain limited by shallow\nretrieval, weak alignment metrics, and brittle tool-use behavior. We introduce\nPokeeResearch-7B, a 7B-parameter deep research agent built under a unified\nreinforcement learning framework for robustness, alignment, and scalability.\nPokeeResearch-7B is trained by an annotation-free Reinforcement Learning from\nAI Feedback (RLAIF) framework to optimize policies using LLM-based reward\nsignals that capture factual accuracy, citation faithfulness, and instruction\nadherence. A chain-of-thought-driven multi-call reasoning scaffold further\nenhances robustness through self-verification and adaptive recovery from tool\nfailures. Among 10 popular deep research benchmarks, PokeeResearch-7B achieves\nstate-of-the-art performance among 7B-scale deep research agents. This\nhighlights that careful reinforcement learning and reasoning design can produce\nefficient, resilient, and research-grade AI agents. The model and inference\ncode is open-sourced under MIT license at\nhttps://github.com/Pokee-AI/PokeeResearchOSS.",
    "published": "2025-10-17T17:53:06Z",
    "updated": "2025-10-20T09:43:05Z",
    "link": "http://arxiv.org/pdf/2510.15862v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Yi Wan",
      "Jiuqi Wang",
      "Liam Li",
      "Jinsong Liu",
      "Ruihao Zhu",
      "Zheqing Zhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.04162v4",
    "title": "SRA-CL: Semantic Retrieval Augmented Contrastive Learning for Sequential\n  Recommendation",
    "summary": "Contrastive learning has shown effectiveness in improving sequential\nrecommendation models. However, existing methods still face challenges in\ngenerating high-quality contrastive pairs: they either rely on random\nperturbations that corrupt user preference patterns or depend on sparse\ncollaborative data that generates unreliable contrastive pairs. Furthermore,\nexisting approaches typically require predefined selection rules that impose\nstrong assumptions, limiting the model's ability to autonomously learn optimal\ncontrastive pairs. To address these limitations, we propose a novel approach\nnamed Semantic Retrieval Augmented Contrastive Learning (SRA-CL). SRA-CL\nleverages the semantic understanding and reasoning capabilities of LLMs to\ngenerate expressive embeddings that capture both user preferences and item\ncharacteristics. These semantic embeddings enable the construction of candidate\npools for inter-user and intra-user contrastive learning through semantic-based\nretrieval. To further enhance the quality of the contrastive samples, we\nintroduce a learnable sample synthesizer that optimizes the contrastive sample\ngeneration process during model training. SRA-CL adopts a plug-and-play design,\nenabling seamless integration with existing sequential recommendation\narchitectures. Extensive experiments on four public datasets demonstrate the\neffectiveness and model-agnostic nature of our approach.",
    "published": "2025-03-06T07:25:19Z",
    "updated": "2025-10-20T09:37:16Z",
    "link": "http://arxiv.org/pdf/2503.04162v4.pdf",
    "category": [
      "cs.IR",
      "cs.AI"
    ],
    "authors": [
      "Ziqiang Cui",
      "Yunpeng Weng",
      "Xing Tang",
      "Xiaokun Zhang",
      "Shiwei Li",
      "Peiyang Liu",
      "Bowei He",
      "Dugang Liu",
      "Weihong Luo",
      "Xiuqiang He",
      "Chen Ma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.16293v4",
    "title": "Robust LLM Training Infrastructure at ByteDance",
    "summary": "The training scale of large language models (LLMs) has reached tens of\nthousands of GPUs and is still continuously expanding, enabling faster learning\nof larger models. Accompanying the expansion of the resource scale is the\nprevalence of failures (CUDA error, NaN values, job hang, etc.), which poses\nsignificant challenges to training stability. Any large-scale LLM training\ninfrastructure should strive for minimal training interruption, efficient fault\ndiagnosis, and effective failure tolerance to enable highly efficient\ncontinuous training. This paper presents ByteRobust, a large-scale GPU\ninfrastructure management system tailored for robust and stable training of\nLLMs. It exploits the uniqueness of LLM training process and gives top\npriorities to detecting and recovering failures in a routine manner. Leveraging\nparallelisms and characteristics of LLM training, ByteRobust enables\nhigh-capacity fault tolerance, prompt fault demarcation, and localization with\nan effective data-driven approach, comprehensively ensuring continuous and\nefficient training of LLM tasks. ByteRobust is deployed on a production GPU\nplatform and achieves 97% ETTR for a three-month training job on 9,600 GPUs.",
    "published": "2025-09-19T15:08:33Z",
    "updated": "2025-10-20T09:35:27Z",
    "link": "http://arxiv.org/pdf/2509.16293v4.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "authors": [
      "Borui Wan",
      "Gaohong Liu",
      "Zuquan Song",
      "Jun Wang",
      "Yun Zhang",
      "Guangming Sheng",
      "Shuguang Wang",
      "Houmin Wei",
      "Chenyuan Wang",
      "Weiqiang Lou",
      "Xi Yang",
      "Mofan Zhang",
      "Kaihua Jiang",
      "Cheng Ren",
      "Xiaoyun Zhi",
      "Menghan Yu",
      "Zhe Nan",
      "Zhuolin Zheng",
      "Baoquan Zhong",
      "Qinlong Wang",
      "Huan Yu",
      "Jinxin Chi",
      "Wang Zhang",
      "Yuhan Li",
      "Zixian Du",
      "Sida Zhao",
      "Yongqiang Zhang",
      "Jingzhe Tang",
      "Zherui Liu",
      "Chuan Wu",
      "Yanghua Peng",
      "Haibin Lin",
      "Wencong Xiao",
      "Xin Liu",
      "Liang Xiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.09121v2",
    "title": "MSDM: Generating Task-Specific Pathology Images with a Multimodal\n  Conditioned Diffusion Model for Cell and Nuclei Segmentation",
    "summary": "Scarcity of annotated data, particularly for rare or atypical morphologies,\npresent significant challenges for cell and nuclei segmentation in\ncomputational pathology. While manual annotation is labor-intensive and costly,\nsynthetic data offers a cost-effective alternative. We introduce a Multimodal\nSemantic Diffusion Model (MSDM) for generating realistic pixel-precise\nimage-mask pairs for cell and nuclei segmentation. By conditioning the\ngenerative process with cellular/nuclear morphologies (using horizontal and\nvertical maps), RGB color characteristics, and BERT-encoded assay/indication\nmetadata, MSDM generates datasests with desired morphological properties. These\nheterogeneous modalities are integrated via multi-head cross-attention,\nenabling fine-grained control over the generated images. Quantitative analysis\ndemonstrates that synthetic images closely match real data, with low\nWasserstein distances between embeddings of generated and real images under\nmatching biological conditions. The incorporation of these synthetic samples,\nexemplified by columnar cells, significantly improves segmentation model\naccuracy on columnar cells. This strategy systematically enriches data sets,\ndirectly targeting model deficiencies. We highlight the effectiveness of\nmultimodal diffusion-based augmentation for advancing the robustness and\ngeneralizability of cell and nuclei segmentation models. Thereby, we pave the\nway for broader application of generative models in computational pathology.",
    "published": "2025-10-10T08:23:14Z",
    "updated": "2025-10-20T09:26:24Z",
    "link": "http://arxiv.org/pdf/2510.09121v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Dominik Winter",
      "Mai Bui",
      "Monica Azqueta Gavaldon",
      "Nicolas Triltsch",
      "Marco Rosati",
      "Nicolas Brieu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17330v1",
    "title": "CharDiff: A Diffusion Model with Character-Level Guidance for License\n  Plate Image Restoration",
    "summary": "The significance of license plate image restoration goes beyond the\npreprocessing stage of License Plate Recognition (LPR) systems, as it also\nserves various purposes, including increasing evidential value, enhancing the\nclarity of visual interface, and facilitating further utilization of license\nplate images. We propose a novel diffusion-based framework with character-level\nguidance, CharDiff, which effectively restores and recognizes severely degraded\nlicense plate images captured under realistic conditions. CharDiff leverages\nfine-grained character-level priors extracted through external segmentation and\nOptical Character Recognition (OCR) modules tailored for low-quality license\nplate images. For precise and focused guidance, CharDiff incorporates a novel\nCharacter-guided Attention through Region-wise Masking (CHARM) module, which\nensures that each character's guidance is restricted to its own region, thereby\navoiding interference with other regions. In experiments, CharDiff\nsignificantly outperformed the baseline restoration models in both restoration\nquality and recognition accuracy, achieving a 28% relative reduction in CER on\nthe Roboflow-LP dataset, compared to the best-performing baseline model. These\nresults indicate that the structured character-guided conditioning effectively\nenhances the robustness of diffusion-based license plate restoration and\nrecognition in practical deployment scenarios.",
    "published": "2025-10-20T09:23:29Z",
    "updated": "2025-10-20T09:23:29Z",
    "link": "http://arxiv.org/pdf/2510.17330v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Gyuhwan Park",
      "Kihyun Na",
      "Injung Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.22109v3",
    "title": "The quest for the GRAph Level autoEncoder (GRALE)",
    "summary": "Although graph-based learning has attracted a lot of attention, graph\nrepresentation learning is still a challenging task whose resolution may impact\nkey application fields such as chemistry or biology. To this end, we introduce\nGRALE, a novel graph autoencoder that encodes and decodes graphs of varying\nsizes into a shared embedding space. GRALE is trained using an Optimal\nTransport-inspired loss that compares the original and reconstructed graphs and\nleverages a differentiable node matching module, which is trained jointly with\nthe encoder and decoder. The proposed attention-based architecture relies on\nEvoformer, the core component of AlphaFold, which we extend to support both\ngraph encoding and decoding. We show, in numerical experiments on simulated and\nmolecular data, that GRALE enables a highly general form of pre-training,\napplicable to a wide range of downstream tasks, from classification and\nregression to more complex tasks such as graph interpolation, editing,\nmatching, and prediction.",
    "published": "2025-05-28T08:37:33Z",
    "updated": "2025-10-20T09:22:12Z",
    "link": "http://arxiv.org/pdf/2505.22109v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Paul Krzakala",
      "Gabriel Melo",
      "Charlotte Laclau",
      "Florence d'AlchÃ©-Buc",
      "RÃ©mi Flamary"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.12985v3",
    "title": "PartSDF: Part-Based Implicit Neural Representation for Composite 3D\n  Shape Parametrization and Optimization",
    "summary": "Accurate 3D shape representation is essential in engineering applications\nsuch as design, optimization, and simulation. In practice, engineering\nworkflows require structured, part-based representations, as objects are\ninherently designed as assemblies of distinct components. However, most\nexisting methods either model shapes holistically or decompose them without\npredefined part structures, limiting their applicability in real-world design\ntasks. We propose PartSDF, a supervised implicit representation framework that\nexplicitly models composite shapes with independent, controllable parts while\nmaintaining shape consistency. Thanks to its simple but innovative\narchitecture, PartSDF outperforms both supervised and unsupervised baselines in\nreconstruction and generation tasks. We further demonstrate its effectiveness\nas a structured shape prior for engineering applications, enabling precise\ncontrol over individual components while preserving overall coherence. Code\navailable at https://github.com/cvlab-epfl/PartSDF.",
    "published": "2025-02-18T16:08:47Z",
    "updated": "2025-10-20T09:17:01Z",
    "link": "http://arxiv.org/pdf/2502.12985v3.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Nicolas Talabot",
      "Olivier Clerc",
      "Arda Cinar Demirtas",
      "Alexis Goujon",
      "Hieu Le",
      "Doruk Oner",
      "Pascal Fua"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.20413v2",
    "title": "Client Clustering Meets Knowledge Sharing: Enhancing Privacy and\n  Robustness in Personalized Peer-to-Peer Learning",
    "summary": "The growing adoption of Artificial Intelligence (AI) in Internet of Things\n(IoT) ecosystems has intensified the need for personalized learning methods\nthat can operate efficiently and privately across heterogeneous,\nresource-constrained devices. However, enabling effective personalized learning\nin decentralized settings introduces several challenges, including efficient\nknowledge transfer between clients, protection of data privacy, and resilience\nagainst poisoning attacks. In this paper, we address these challenges by\ndeveloping P4 (Personalized, Private, Peer-to-Peer) -- a method designed to\ndeliver personalized models for resource-constrained IoT devices while ensuring\ndifferential privacy and robustness against poisoning attacks. Our solution\nemploys a lightweight, fully decentralized algorithm to privately detect client\nsimilarity and form collaborative groups. Within each group, clients leverage\ndifferentially private knowledge distillation to co-train their models,\nmaintaining high accuracy while ensuring robustness to the presence of\nmalicious clients. We evaluate P4 on popular benchmark datasets using both\nlinear and CNN-based architectures across various heterogeneity settings and\nattack scenarios. Experimental results show that P4 achieves 5% to 30% higher\naccuracy than leading differentially private peer-to-peer approaches and\nmaintains robustness with up to 30% malicious clients. Additionally, we\ndemonstrate its practicality by deploying it on resource-constrained devices,\nwhere collaborative training between two clients adds only ~7 seconds of\noverhead.",
    "published": "2025-06-25T13:27:36Z",
    "updated": "2025-10-20T09:11:04Z",
    "link": "http://arxiv.org/pdf/2506.20413v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "authors": [
      "Mohammad Mahdi Maheri",
      "Denys Herasymuk",
      "Hamed Haddadi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.05011v3",
    "title": "DARIL: When Imitation Learning outperforms Reinforcement Learning in\n  Surgical Action Planning",
    "summary": "Surgical action planning requires predicting future instrument-verb-target\ntriplets for real-time assistance. While teleoperated robotic surgery provides\nnatural expert demonstrations for imitation learning (IL), reinforcement\nlearning (RL) could potentially discover superior strategies through\nself-exploration. We present the first comprehensive comparison of IL versus RL\nfor surgical action planning on CholecT50. Our Dual-task Autoregressive\nImitation Learning (DARIL) baseline achieves 34.6% action triplet recognition\nmAP and 33.6% next frame prediction mAP with smooth planning degradation to\n29.2% at 10-second horizons. We evaluated three RL variants: world model-based\nRL, direct video RL, and inverse RL enhancement. Surprisingly, all RL\napproaches underperformed DARIL--world model RL dropped to 3.1% mAP at 10s\nwhile direct video RL achieved only 15.9%. Our analysis reveals that\ndistribution matching on expert-annotated test sets systematically favors IL\nover potentially valid RL policies that differ from training demonstrations.\nThis challenges assumptions about RL superiority in sequential decision making\nand provides crucial insights for surgical AI development.",
    "published": "2025-07-07T13:49:57Z",
    "updated": "2025-10-20T09:07:47Z",
    "link": "http://arxiv.org/pdf/2507.05011v3.pdf",
    "category": [
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Maxence Boels",
      "Harry Robertshaw",
      "Thomas C Booth",
      "Prokar Dasgupta",
      "Alejandro Granados",
      "Sebastien Ourselin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.06211v2",
    "title": "Late Fusion and Multi-Level Fission Amplify Cross-Modal Transfer in\n  Text-Speech LMs",
    "summary": "Text-Speech Language Models (TSLMs) -- language models trained to jointly\nprocess and generate text and speech -- are commonly trained through an early\nmodality fusion/fission approach, in which both modalities are fed and\npredicted from a shared backbone via linear layers. We hypothesize that this\napproach limits cross-modal transfer by neglecting feature compositionality --\nspecifically, the finer-grained nature of speech representations compared to\ntext -- preventing the emergence of a shared feature hierarchy within model\nlayers. In this paper, we argue that this limitation can be addressed through\nlate fusion and fission, with a fission process that accesses both high- and\nlow-level features for speech generation. Our models implementing these\nprinciples, SmolTolk, rival or surpass state-of-the-art TSLMs trained with\norders of magnitude more compute, and achieve significantly improved\ncross-modal performance relative to early fusion/fission baselines.\nRepresentation analyses further suggest that our method enhances the model's\nability to abstract higher-level, more semantic features from speech, and leads\nto increasingly shared representation spaces across layers.",
    "published": "2025-03-08T13:28:50Z",
    "updated": "2025-10-20T09:06:09Z",
    "link": "http://arxiv.org/pdf/2503.06211v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "eess.AS"
    ],
    "authors": [
      "Santiago Cuervo",
      "Adel Moumen",
      "Yanis Labrak",
      "Sameer Khurana",
      "Antoine Laurent",
      "Mickael Rouvier",
      "Phil Woodland",
      "Ricard Marxer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17314v1",
    "title": "Auto-Rubric: Learning to Extract Generalizable Criteria for Reward\n  Modeling",
    "summary": "Reward models are essential for aligning Large Language Models (LLMs) with\nhuman values, yet their development is hampered by costly preference datasets\nand poor interpretability. While recent rubric-based approaches offer\ntransparency, they often lack systematic quality control and optimization,\ncreating a trade-off between scalability and reliability. We address these\nlimitations with a novel, training-free framework built on a key assumption:\n\\textit{evaluation rubrics underlying human preferences exhibit significant\ngeneralization ability across diverse queries}, a property that enables\nremarkable data efficiency. Our two-stage approach first infers high-quality,\nquery-specific rubrics using a validation-guided\n\\textbf{Propose-Evaluate-Revise} pipeline. Second, it generalizes these\ngranular rubrics into a compact, non-redundant core set by maximizing an\n\\textbf{information-theoretic coding rate}. The final output is an\ninterpretable, hierarchical \"Theme-Tips\" rubric set. Extensive experiments\ndemonstrate the framework's exceptional data efficiency and performance.\nCritically, using just 70 preference pairs (1.5\\% of the source data), our\nmethod also empowers smaller models like Qwen3-8B to outperform specialized,\nfully-trained counterparts. This work pioneers a scalable, interpretable, and\ndata-efficient path for reward modeling.",
    "published": "2025-10-20T09:01:37Z",
    "updated": "2025-10-20T09:01:37Z",
    "link": "http://arxiv.org/pdf/2510.17314v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Lipeng Xie",
      "Sen Huang",
      "Zhuo Zhang",
      "Anni Zou",
      "Yunpeng Zhai",
      "Dingchao Ren",
      "Kezun Zhang",
      "Haoyuan Hu",
      "Boyin Liu",
      "Haoran Chen",
      "Zhaoyang Liu",
      "Bolin Ding"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.09211v2",
    "title": "DICE: Structured Reasoning in LLMs through SLM-Guided Chain-of-Thought\n  Correction",
    "summary": "When performing reasoning tasks with user-specific requirements, such as\nstrict output formats, large language models (LLMs) often prioritize reasoning\nover adherence to detailed instructions. Fine-tuning LLMs on supervised\ndatasets to address this is impractical due to high computational costs and\nlimited parameter access. To tackle this, we propose DICE, a lightweight\nframework that guides small language models (SLMs) to refine LLMs' outputs\nthrough chain-of-thought (CoT) correction. DICE decouples the process by first\nprompting LLMs to generate natural language responses, then using trained SLMs\nto analyze and refine these outputs to meet structured output specifications.\nThis framework preserves LLMs' broad knowledge and reasoning capabilities while\nensuring the outputs conform to user demands. Specifically, DICE first\nconstructs structured CoT adaptation datasets via a two-stage method and\nsubsequently applies a dual-tuning strategy to fine-tune SLMs for generating\nstructured outputs in an analyze-then-answer pattern. Experiments demonstrate\nthat DICE improves the average format accuracy and content correctness of LLM\noutputs by 35.4\\% and 29.4\\%, respectively, achieving state-of-the-art (SOTA)\nperformance over other competitive baselines.",
    "published": "2025-10-10T09:45:35Z",
    "updated": "2025-10-20T08:57:20Z",
    "link": "http://arxiv.org/pdf/2510.09211v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Yiqi Li",
      "Yusheng Liao",
      "Zhe Chen",
      "Yanfeng Wang",
      "Yu Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17309v1",
    "title": "RubiSCoT: A Framework for AI-Supported Academic Assessment",
    "summary": "The evaluation of academic theses is a cornerstone of higher education,\nensuring rigor and integrity. Traditional methods, though effective, are\ntime-consuming and subject to evaluator variability. This paper presents\nRubiSCoT, an AI-supported framework designed to enhance thesis evaluation from\nproposal to final submission. Using advanced natural language processing\ntechniques, including large language models, retrieval-augmented generation,\nand structured chain-of-thought prompting, RubiSCoT offers a consistent,\nscalable solution. The framework includes preliminary assessments,\nmultidimensional assessments, content extraction, rubric-based scoring, and\ndetailed reporting. We present the design and implementation of RubiSCoT,\ndiscussing its potential to optimize academic assessment processes through\nconsistent, scalable, and transparent evaluation.",
    "published": "2025-10-20T08:52:33Z",
    "updated": "2025-10-20T08:52:33Z",
    "link": "http://arxiv.org/pdf/2510.17309v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Thorsten FrÃ¶hlich",
      "Tim Schlippe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.17455v2",
    "title": "Towards Evaluating Proactive Risk Awareness of Multimodal Language\n  Models",
    "summary": "Human safety awareness gaps often prevent the timely recognition of everyday\nrisks. In solving this problem, a proactive safety artificial intelligence (AI)\nsystem would work better than a reactive one. Instead of just reacting to\nusers' questions, it would actively watch people's behavior and their\nenvironment to detect potential dangers in advance. Our Proactive Safety Bench\n(PaSBench) evaluates this capability through 416 multimodal scenarios (128\nimage sequences, 288 text logs) spanning 5 safety-critical domains. Evaluation\nof 36 advanced models reveals fundamental limitations: Top performers like\nGemini-2.5-pro achieve 71% image and 64% text accuracy, but miss 45-55% risks\nin repeated trials. Through failure analysis, we identify unstable proactive\nreasoning rather than knowledge deficits as the primary limitation. This work\nestablishes (1) a proactive safety benchmark, (2) systematic evidence of model\nlimitations, and (3) critical directions for developing reliable protective AI.\nWe believe our dataset and findings can promote the development of safer AI\nassistants that actively prevent harm rather than merely respond to requests.\nOur dataset can be found at https://huggingface.co/datasets/Youliang/PaSBench.",
    "published": "2025-05-23T04:28:47Z",
    "updated": "2025-10-20T08:51:16Z",
    "link": "http://arxiv.org/pdf/2505.17455v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Youliang Yuan",
      "Wenxiang Jiao",
      "Yuejin Xie",
      "Chihao Shen",
      "Menghan Tian",
      "Wenxuan Wang",
      "Jen-tse Huang",
      "Pinjia He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.02124v5",
    "title": "Trainable Dynamic Mask Sparse Attention",
    "summary": "The increasing demand for long-context modeling in large language models\n(LLMs) is bottlenecked by the quadratic complexity of the standard\nself-attention mechanism. The community has proposed sparse attention to\nmitigate this issue. However, position-aware sparse attention methods rely on\nstatic sparse structures that lack adaptability to diverse query contexts,\nwhile content-aware sparse attention methods depend on heuristic key-value\nselection, hindering full differentiability. We introduce a trainable dynamic\nmask sparse attention mechanism, a method that merges the advantages of both\nposition-aware and content-aware approaches. Dynamic Mask Attention (DMA)\nachieves this through three key innovations: First, it leverages value vector\nrepresentations to generate content-aware dynamic masks, enabling the model to\nadaptively identify and attend to critical information. Second, it computes\nposition-aware sparse weights in a hardware-friendly manner, efficiently\nskipping unnecessary computational regions. Finally, we demonstrate that the\nintroduced dynamic mask and sparse weights do not obstruct gradients,\nsupporting end-to-end training. We have validated the performance of DMA\nthrough comprehensive experiments. A large body of experimental evidence shows\nthat DMA consistently holds a Pareto advantage over state-of-the-art sparse\nattention baselines in tasks including scaling laws, multi-query associative\nrecall, standard benchmarks, and needle in a haystack tests, while also\ndelivering up to a 10x overall speedup. These results highlight its ability to\neffectively balance model efficiency with long-context modeling capabilities.\nOur computational kernel code is now open-source at\nhttps://github.com/SmallDoges/flash-dmattn to encourage further research and\napplication by the community.",
    "published": "2025-08-04T07:05:15Z",
    "updated": "2025-10-20T08:48:15Z",
    "link": "http://arxiv.org/pdf/2508.02124v5.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Jingze Shi",
      "Yifan Wu",
      "Yiran Peng",
      "Bingheng Wu",
      "Liangdong Wang",
      "Guang Liu",
      "Yuyu Luo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17301v1",
    "title": "Comprehending Spatio-temporal Data via Cinematic Storytelling using\n  Large Language Models",
    "summary": "Spatio-temporal data captures complex dynamics across both space and time,\nyet traditional visualizations are complex, require domain expertise and often\nfail to resonate with broader audiences. Here, we propose MapMuse, a\nstorytelling-based framework for interpreting spatio-temporal datasets,\ntransforming them into compelling, narrative-driven experiences. We utilize\nlarge language models and employ retrieval augmented generation (RAG) and\nagent-based techniques to generate comprehensive stories. Drawing on principles\ncommon in cinematic storytelling, we emphasize clarity, emotional connection,\nand audience-centric design. As a case study, we analyze a dataset of taxi\ntrajectories. Two perspectives are presented: a captivating story based on a\nheat map that visualizes millions of taxi trip endpoints to uncover urban\nmobility patterns; and a detailed narrative following a single long taxi\njourney, enriched with city landmarks and temporal shifts. By portraying\nlocations as characters and movement as plot, we argue that data storytelling\ndrives insight, engagement, and action from spatio-temporal information. The\ncase study illustrates how MapMuse can bridge the gap between data complexity\nand human understanding. The aim of this short paper is to provide a glimpse to\nthe potential of the cinematic storytelling technique as an effective\ncommunication tool for spatio-temporal data, as well as to describe open\nproblems and opportunities for future research.",
    "published": "2025-10-20T08:44:25Z",
    "updated": "2025-10-20T08:44:25Z",
    "link": "http://arxiv.org/pdf/2510.17301v1.pdf",
    "category": [
      "cs.DB",
      "cs.AI"
    ],
    "authors": [
      "Panos Kalnis. Shuo Shang",
      "Christian S. Jensen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.15707v2",
    "title": "Every Rollout Counts: Optimal Resource Allocation for Efficient\n  Test-Time Scaling",
    "summary": "Test-Time Scaling (TTS) improves the performance of Large Language Models\n(LLMs) by using additional inference-time computation to explore multiple\nreasoning paths through search. Yet how to allocate a fixed rollout budget most\neffectively during search remains underexplored, often resulting in inefficient\nuse of compute at test time. To bridge this gap, we formulate test-time search\nas a resource allocation problem and derive the optimal allocation strategy\nthat maximizes the probability of obtaining a correct solution under a fixed\nrollout budget. Within this formulation, we reveal a core limitation of\nexisting search methods: solution-level allocation tends to favor reasoning\ndirections with more candidates, leading to theoretically suboptimal and\ninefficient use of compute. To address this, we propose Direction-Oriented\nResource Allocation (DORA), a provably optimal method that mitigates this bias\nby decoupling direction quality from candidate count and allocating resources\nat the direction level. To demonstrate DORA's effectiveness, we conduct\nextensive experiments on challenging mathematical reasoning benchmarks\nincluding MATH500, AIME2024, and AIME2025. The empirical results show that DORA\nconsistently outperforms strong baselines with comparable computational cost,\nachieving state-of-the-art accuracy. We hope our findings contribute to a\nbroader understanding of optimal TTS for LLMs.",
    "published": "2025-05-30T09:05:25Z",
    "updated": "2025-10-20T08:29:40Z",
    "link": "http://arxiv.org/pdf/2506.15707v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Xinglin Wang",
      "Yiwei Li",
      "Shaoxiong Feng",
      "Peiwen Yuan",
      "Yueqi Zhang",
      "Jiayi Shi",
      "Chuyi Tan",
      "Boyuan Pan",
      "Yao Hu",
      "Kan Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.18016v3",
    "title": "ADA-DPM: A Neural Descriptors-based Adaptive Noise Filtering Strategy\n  for SLAM",
    "summary": "Lidar SLAM plays a significant role in mobile robot navigation and\nhigh-definition map construction. However, existing methods often face a\ntrade-off between localization accuracy and system robustness in scenarios with\na high proportion of dynamic objects, point cloud distortion, and unstructured\nenvironments. To address this issue, we propose a neural descriptors-based\nadaptive noise filtering strategy for SLAM, named ADA-DPM, which improves the\nperformance of localization and mapping tasks through three key technical\ninnovations. Firstly, to tackle dynamic object interference, we design the\nDynamic Segmentation Head to predict and filter out dynamic feature points,\neliminating the ego-motion interference caused by dynamic objects. Secondly, to\nmitigate the impact of noise and unstructured feature points, we propose the\nGlobal Importance Scoring Head that adaptively selects high-contribution\nfeature points while suppressing the influence of noise and unstructured\nfeature points. Moreover, we introduce the Cross-Layer Graph Convolution Module\n(GLI-GCN) to construct multi-scale neighborhood graphs, fusing local structural\ninformation across different scales and improving the discriminative power of\noverlapping features. Finally, experimental validations on multiple public\ndatasets confirm the effectiveness of ADA-DPM.",
    "published": "2025-06-22T12:48:11Z",
    "updated": "2025-10-20T08:27:02Z",
    "link": "http://arxiv.org/pdf/2506.18016v3.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Yongxin Shao",
      "Aihong Tan",
      "Binrui Wang",
      "Yinlian Jin",
      "Licong Guan",
      "Peng Liao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17281v1",
    "title": "MemoryBench: A Benchmark for Memory and Continual Learning in LLM\n  Systems",
    "summary": "Scaling up data, parameters, and test-time computation has been the\nmainstream methods to improve LLM systems (LLMsys), but their upper bounds are\nalmost reached due to the gradual depletion of high-quality data and marginal\ngains obtained from larger computational resource consumption. Inspired by the\nabilities of human and traditional AI systems in learning from practice,\nconstructing memory and continual learning frameworks for LLMsys has become an\nimportant and popular research direction in recent literature. Yet, existing\nbenchmarks for LLM memory often focus on evaluating the system on homogeneous\nreading comprehension tasks with long-form inputs rather than testing their\nabilities to learn from accumulated user feedback in service time. Therefore,\nwe propose a user feedback simulation framework and a comprehensive benchmark\ncovering multiple domains, languages, and types of tasks to evaluate the\ncontinual learning abilities of LLMsys. Experiments show that the effectiveness\nand efficiency of state-of-the-art baselines are far from satisfying, and we\nhope this benchmark could pave the way for future studies on LLM memory and\noptimization algorithms.",
    "published": "2025-10-20T08:16:12Z",
    "updated": "2025-10-20T08:16:12Z",
    "link": "http://arxiv.org/pdf/2510.17281v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "authors": [
      "Qingyao Ai",
      "Yichen Tang",
      "Changyue Wang",
      "Jianming Long",
      "Weihang Su",
      "Yiqun Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.01284v2",
    "title": "Tracing Partisan Bias to Its Emotional Fingerprints: A Computational\n  Approach to Mitigation",
    "summary": "This study introduces a novel framework for analysing and mitigating media\nbias by tracing partisan stances to their linguistic roots in emotional\nlanguage. We posit that partisan bias is not merely an abstract stance but\nmaterialises as quantifiable 'emotional fingerprints' within news texts. These\nfingerprints are systematically measured using the Valence-Arousal-Dominance\n(VAD) framework, allowing us to decode the affective strategies behind partisan\nframing. Our analysis of the Allsides dataset confirms this hypothesis,\nrevealing distinct and statistically significant emotional fingerprints for\nleft, centre, and right-leaning media. Based on this evidence-driven approach,\nwe then propose a computational approach to mitigation through NeutraSum, a\nmodel designed to neutralise these identified emotional patterns. By explicitly\ntargeting the VAD characteristics of biased language, NeutraSum generates\nsummaries that are not only coherent but also demonstrably closer to an\nemotionally neutral baseline. Experimental results validate our framework:\nNeutraSum successfully erases the partisan emotional fingerprints from its\nsummaries, achieving a demonstrably lower emotional bias score than other\nmodels. This work pioneers a new path for bias mitigation, shifting the focus\nfrom treating symptoms (political labels) to addressing the cause: the\nemotional encoding of partisan bias in language.",
    "published": "2025-01-02T14:48:07Z",
    "updated": "2025-10-20T08:15:48Z",
    "link": "http://arxiv.org/pdf/2501.01284v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Junjie Liu",
      "Xi Luo",
      "Sirong Wu",
      "Gengchen Sun",
      "Yuhui Deng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.26631v2",
    "title": "Learning Generalizable Shape Completion with SIM(3) Equivariance",
    "summary": "3D shape completion methods typically assume scans are pre-aligned to a\ncanonical frame. This leaks pose and scale cues that networks may exploit to\nmemorize absolute positions rather than inferring intrinsic geometry. When such\nalignment is absent in real data, performance collapses. We argue that robust\ngeneralization demands architectural equivariance to the similarity group,\nSIM(3), so the model remains agnostic to pose and scale. Following this\nprinciple, we introduce the first SIM(3)-equivariant shape completion network,\nwhose modular layers successively canonicalize features, reason over\nsimilarity-invariant geometry, and restore the original frame. Under a\nde-biased evaluation protocol that removes the hidden cues, our model\noutperforms both equivariant and augmentation baselines on the PCN benchmark.\nIt also sets new cross-domain records on real driving and indoor scans,\nlowering minimal matching distance on KITTI by 17% and Chamfer distance $\\ell1$\non OmniObject3D by 14%. Perhaps surprisingly, ours under the stricter protocol\nstill outperforms competitors under their biased settings. These results\nestablish full SIM(3) equivariance as an effective route to truly generalizable\nshape completion. Project page: https://sime-completion.github.io.",
    "published": "2025-09-30T17:58:55Z",
    "updated": "2025-10-20T08:13:19Z",
    "link": "http://arxiv.org/pdf/2509.26631v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Yuqing Wang",
      "Zhaiyu Chen",
      "Xiao Xiang Zhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.08445v3",
    "title": "Synthetic Series-Symbol Data Generation for Time Series Foundation\n  Models",
    "summary": "Foundation models for time series analysis (TSA) have attracted significant\nattention. However, challenges such as training data scarcity and imbalance\ncontinue to hinder their development. Inspired by complex dynamic system\ntheories, we design a series-symbol data generation mechanism, enabling the\nunrestricted creation of high-quality time series data paired with\ncorresponding symbolic expressions. To leverage series-symbol data pairs with\nstrong correlations, we develop SymTime, a pre-trained foundation model for\nenhancing time series representation using symbolic information. SymTime\ndemonstrates competitive performance across five major TSA tasks when\nfine-tunes with downstream tasks, rivaling foundation models pre-trained on\nreal-world datasets. This approach underscores the potential of series-symbol\ndata generation and pretraining mechanisms in overcoming data scarcity and\nenhancing task performance. The code is available at\nhttps://github.com/wwhenxuan/SymTime.",
    "published": "2025-10-09T16:54:18Z",
    "updated": "2025-10-20T08:04:01Z",
    "link": "http://arxiv.org/pdf/2510.08445v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Wenxuan Wang",
      "Kai Wu",
      "Yujian Betterest Li",
      "Dan Wang",
      "Xiaoyu Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.22846v2",
    "title": "RocqStar: Leveraging Similarity-driven Retrieval and Agentic Systems for\n  Rocq generation",
    "summary": "Interactive Theorem Proving was repeatedly shown to be fruitful combined with\nGenerative Artificial Intelligence. This paper assesses multiple approaches to\nRocq generation and illuminates potential avenues for improvement. We highlight\nthe importance of thorough premise selection for generating Rocq proofs and\npropose a novel approach, leveraging retrieval via a self-attentive embedder\nmodel. The evaluation of the designed approach shows up to 28% relative\nincrease of the generator's performance. We tackle the problem of writing Rocq\nproofs using a multi-stage agentic system, tailored for formal verification,\nand demonstrate its high effectiveness. We conduct an ablation study and\ndemonstrate shows that incorporating multi-agent debate during the planning\nstage increases the proof success rate by 20% overall and nearly doubles it for\ncomplex theorems, while the reflection mechanism further enhances stability and\nconsistency.",
    "published": "2025-05-28T20:26:11Z",
    "updated": "2025-10-20T07:59:37Z",
    "link": "http://arxiv.org/pdf/2505.22846v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.LO",
      "cs.SE"
    ],
    "authors": [
      "Andrei Kozyrev",
      "Nikita Khramov",
      "Gleb Solovev",
      "Anton Podkopaev"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17269v1",
    "title": "FineVision: Open Data Is All You Need",
    "summary": "The advancement of vision-language models (VLMs) is hampered by a fragmented\nlandscape of inconsistent and contaminated public datasets. We introduce\nFineVision, a meticulously collected, curated, and unified corpus of 24 million\nsamples - the largest open resource of its kind. We unify more than 200 sources\ninto 185 subsets via a semi-automated, human-in-the-loop pipeline: automation\nperforms bulk ingestion and schema mapping, while reviewers audit mappings and\nspot-check outputs to verify faithful consumption of annotations, appropriate\nformatting and diversity, and safety; issues trigger targeted fixes and\nre-runs. The workflow further applies rigorous de-duplication within and across\nsources and decontamination against 66 public benchmarks. FineVision also\nencompasses agentic/GUI tasks with a unified action space; reviewers validate\nschemas and inspect a sample of trajectories to confirm executable fidelity.\nModels trained on FineVision consistently outperform those trained on existing\nopen mixtures across a broad evaluation suite, underscoring the benefits of\nscale, data hygiene, and balanced automation with human oversight. We release\nthe corpus and curation tools to accelerate data-centric VLM research.",
    "published": "2025-10-20T07:54:46Z",
    "updated": "2025-10-20T07:54:46Z",
    "link": "http://arxiv.org/pdf/2510.17269v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Luis Wiedmann",
      "Orr Zohar",
      "Amir Mahla",
      "Xiaohan Wang",
      "Rui Li",
      "Thibaud Frere",
      "Leandro von Werra",
      "Aritra Roy Gosthipaty",
      "AndrÃ©s Marafioti"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.15897v2",
    "title": "ReDi: Rectified Discrete Flow",
    "summary": "Discrete Flow-based Models (DFMs) are powerful generative models for\nhigh-quality discrete data but typically suffer from slow sampling speeds due\nto their reliance on iterative decoding processes. This reliance on a\nmulti-step process originates from the factorization approximation of DFMs,\nwhich is necessary for handling high-dimensional data. In this paper, we\nanalyze the factorization approximation error using Conditional Total\nCorrelation (TC), and reveal its dependence on the coupling. To address the\nchallenge of efficient few-step generation, we propose Rectified Discrete Flow\n(ReDi), a novel iterative method that reduces the underlying factorization\nerror (measured as Conditional TC) by rectifying the coupling between source\nand target distributions. We theoretically prove that each ReDi step guarantees\na monotonic decreasing Conditional TC, ensuring its convergence. Empirically,\nReDi significantly reduces Conditional TC and enables few-step generation.\nMoreover, we demonstrate that the rectified couplings are well-suited for\ntraining efficient one-step models on image generation. ReDi offers a simple\nand theoretically grounded approach for tackling the few-step challenge,\nproviding a new perspective on efficient discrete data synthesis. Code is\navailable at https://github.com/Ugness/ReDi_discrete.",
    "published": "2025-07-21T01:18:44Z",
    "updated": "2025-10-20T07:43:07Z",
    "link": "http://arxiv.org/pdf/2507.15897v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "authors": [
      "Jaehoon Yoo",
      "Wonjung Kim",
      "Seunghoon Hong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17253v1",
    "title": "Augmented Web Usage Mining and User Experience Optimization with CAWAL's\n  Enriched Analytics Data",
    "summary": "Understanding user behavior on the web is increasingly critical for\noptimizing user experience (UX). This study introduces Augmented Web Usage\nMining (AWUM), a methodology designed to enhance web usage mining and improve\nUX by enriching the interaction data provided by CAWAL (Combined Application\nLog and Web Analytics), a framework for advanced web analytics. Over 1.2\nmillion session records collected in one month (~8.5GB of data) were processed\nand transformed into enriched datasets. AWUM analyzes session structures, page\nrequests, service interactions, and exit methods. Results show that 87.16% of\nsessions involved multiple pages, contributing 98.05% of total pageviews; 40%\nof users accessed various services and 50% opted for secure exits. Association\nrule mining revealed patterns of frequently accessed services, highlighting\nCAWAL's precision and efficiency over conventional methods. AWUM offers a\ncomprehensive understanding of user behavior and strong potential for\nlarge-scale UX optimization.",
    "published": "2025-10-20T07:41:08Z",
    "updated": "2025-10-20T07:41:08Z",
    "link": "http://arxiv.org/pdf/2510.17253v1.pdf",
    "category": [
      "cs.HC",
      "cs.AI",
      "68T09, 68U35",
      "H.5.2; H.3.3; I.2.6"
    ],
    "authors": [
      "Ãzkan Canay",
      "{Ã}mit KocabÄ±cak"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17252v1",
    "title": "How News Feels: Understanding Affective Bias in Multilingual Headlines\n  for Human-Centered Media Design",
    "summary": "News media often shape the public mood not only by what they report but by\nhow they frame it. The same event can appear calm in one outlet and alarming in\nanother, reflecting subtle emotional bias in reporting. Negative or emotionally\ncharged headlines tend to attract more attention and spread faster, which in\nturn encourages outlets to frame stories in ways that provoke stronger\nreactions. This research explores that tendency through large-scale emotion\nanalysis of Bengali news. Using zero-shot inference with Gemma-3 4B, we\nanalyzed 300000 Bengali news headlines and their content to identify the\ndominant emotion and overall tone of each. The findings reveal a clear\ndominance of negative emotions, particularly anger, fear, and disappointment,\nand significant variation in how similar stories are emotionally portrayed\nacross outlets. Based on these insights, we propose design ideas for a\nhuman-centered news aggregator that visualizes emotional cues and helps readers\nrecognize hidden affective framing in daily news.",
    "published": "2025-10-20T07:40:46Z",
    "updated": "2025-10-20T07:40:46Z",
    "link": "http://arxiv.org/pdf/2510.17252v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Mohd Ruhul Ameen",
      "Akif Islam",
      "Abu Saleh Musa Miah",
      "Ayesha Siddiqua",
      "Jungpil Shin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.13122v2",
    "title": "When majority rules, minority loses: bias amplification of gradient\n  descent",
    "summary": "Despite growing empirical evidence of bias amplification in machine learning,\nits theoretical foundations remain poorly understood. We develop a formal\nframework for majority-minority learning tasks, showing how standard training\ncan favor majority groups and produce stereotypical predictors that neglect\nminority-specific features. Assuming population and variance imbalance, our\nanalysis reveals three key findings: (i) the close proximity between\n``full-data'' and stereotypical predictors, (ii) the dominance of a region\nwhere training the entire model tends to merely learn the majority traits, and\n(iii) a lower bound on the additional training required. Our results are\nillustrated through experiments in deep learning for tabular and image\nclassification tasks.",
    "published": "2025-05-19T13:51:49Z",
    "updated": "2025-10-20T07:35:36Z",
    "link": "http://arxiv.org/pdf/2505.13122v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "authors": [
      "FranÃ§ois Bachoc",
      "JÃ©rÃ´me Bolte",
      "Ryan Boustany",
      "Jean-Michel Loubes"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.15511v2",
    "title": "Language Models are Injective and Hence Invertible",
    "summary": "Transformer components such as non-linear activations and normalization are\ninherently non-injective, suggesting that different inputs could map to the\nsame output and prevent exact recovery of the input from a model's\nrepresentations. In this paper, we challenge this view. First, we prove\nmathematically that transformer language models mapping discrete input\nsequences to their corresponding sequence of continuous representations are\ninjective and therefore lossless, a property established at initialization and\npreserved during training. Second, we confirm this result empirically through\nbillions of collision tests on six state-of-the-art language models, and\nobserve no collisions. Third, we operationalize injectivity: we introduce\nSipIt, the first algorithm that provably and efficiently reconstructs the exact\ninput text from hidden activations, establishing linear-time guarantees and\ndemonstrating exact invertibility in practice. Overall, our work establishes\ninjectivity as a fundamental and exploitable property of language models, with\ndirect implications for transparency, interpretability, and safe deployment.",
    "published": "2025-10-17T10:25:30Z",
    "updated": "2025-10-20T07:29:02Z",
    "link": "http://arxiv.org/pdf/2510.15511v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Giorgos Nikolaou",
      "Tommaso Mencattini",
      "Donato Crisostomi",
      "Andrea Santilli",
      "Yannis Panagakis",
      "Emanuele RodolÃ "
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17241v1",
    "title": "Visibility Allocation Systems: How Algorithmic Design Shapes Online\n  Visibility and Societal Outcomes",
    "summary": "Throughout application domains, we now rely extensively on algorithmic\nsystems to engage with ever-expanding datasets of information. Despite their\nbenefits, these systems are often complex (comprising of many intricate tools,\ne.g., moderation, recommender systems, prediction models), of unknown structure\n(due to the lack of accompanying documentation), and having hard-to-predict yet\npotentially severe downstream consequences (due to the extensive use,\nsystematic enactment of existing errors, and many comprising feedback loops).\nAs such, understanding and evaluating these systems as a whole remains a\nchallenge for both researchers and legislators. To aid ongoing efforts, we\nintroduce a formal framework for such visibility allocation systems (VASs)\nwhich we define as (semi-)automated systems deciding which (processed) data to\npresent a human user with. We review typical tools comprising VASs and define\nthe associated computational problems they solve. By doing so, VASs can be\ndecomposed into sub-processes and illustrated via data flow diagrams. Moreover,\nwe survey metrics for evaluating VASs throughout the pipeline, thus aiding\nsystem diagnostics. Using forecasting-based recommendations in school choice as\na case study, we demonstrate how our framework can support VAS evaluation. We\nalso discuss how our framework can support ongoing AI-legislative efforts to\nlocate obligations, quantify systemic risks, and enable adaptive compliance.",
    "published": "2025-10-20T07:28:24Z",
    "updated": "2025-10-20T07:28:24Z",
    "link": "http://arxiv.org/pdf/2510.17241v1.pdf",
    "category": [
      "cs.CY",
      "cs.AI"
    ],
    "authors": [
      "Stefania Ionescu",
      "Robin Forsberg",
      "Elsa Lichtenegger",
      "Salima Jaoua",
      "Kshitijaa Jaglan",
      "Florian Dorfler",
      "Aniko Hannak"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17235v1",
    "title": "Coinvisor: An RL-Enhanced Chatbot Agent for Interactive Cryptocurrency\n  Investment Analysis",
    "summary": "The cryptocurrency market offers significant investment opportunities but\nfaces challenges including high volatility and fragmented information. Data\nintegration and analysis are essential for informed investment decisions.\nCurrently, investors use three main approaches: (1) Manual analysis across\nvarious sources, which depends heavily on individual experience and is\ntime-consuming and prone to bias; (2) Data aggregation platforms-limited in\nfunctionality and depth of analysis; (3) Large language model agents-based on\nstatic pretrained models, lacking real-time data integration and multi-step\nreasoning capabilities. To address these limitations, we present Coinvisor, a\nreinforcement learning-based chatbot that provides comprehensive analytical\nsupport for cryptocurrency investment through a multi-agent framework.\nCoinvisor integrates diverse analytical capabilities through specialized tools.\nIts key innovation is a reinforcement learning-based tool selection mechanism\nthat enables multi-step planning and flexible integration of diverse data\nsources. This design supports real-time interaction and adaptive analysis of\ndynamic content, delivering accurate and actionable investment insights. We\nevaluated Coinvisor through automated benchmarks on tool calling accuracy and\nuser studies with 20 cryptocurrency investors using our interface. Results show\nthat Coinvisor improves recall by 40.7% and F1 score by 26.6% over the base\nmodel in tool orchestration. User studies show high satisfaction (4.64/5), with\nparticipants preferring Coinvisor to both general LLMs and existing crypto\nplatforms (4.62/5).",
    "published": "2025-10-20T07:23:49Z",
    "updated": "2025-10-20T07:23:49Z",
    "link": "http://arxiv.org/pdf/2510.17235v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Chong Chen",
      "Ze Liu",
      "Lingfeng Bao",
      "Yanlin Wang",
      "Ting Chen",
      "Daoyuan Wu",
      "Jiachi Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17234v1",
    "title": "Taming Modality Entanglement in Continual Audio-Visual Segmentation",
    "summary": "Recently, significant progress has been made in multi-modal continual\nlearning, aiming to learn new tasks sequentially in multi-modal settings while\npreserving performance on previously learned ones. However, existing methods\nmainly focus on coarse-grained tasks, with limitations in addressing modality\nentanglement in fine-grained continual learning settings. To bridge this gap,\nwe introduce a novel Continual Audio-Visual Segmentation (CAVS) task, aiming to\ncontinuously segment new classes guided by audio. Through comprehensive\nanalysis, two critical challenges are identified: 1) multi-modal semantic\ndrift, where a sounding objects is labeled as background in sequential tasks;\n2) co-occurrence confusion, where frequent co-occurring classes tend to be\nconfused. In this work, a Collision-based Multi-modal Rehearsal (CMR) framework\nis designed to address these challenges. Specifically, for multi-modal semantic\ndrift, a Multi-modal Sample Selection (MSS) strategy is proposed to select\nsamples with high modal consistency for rehearsal. Meanwhile, for co-occurence\nconfusion, a Collision-based Sample Rehearsal (CSR) mechanism is designed,\nallowing for the increase of rehearsal sample frequency of those confusable\nclasses during training process. Moreover, we construct three audio-visual\nincremental scenarios to verify effectiveness of our method. Comprehensive\nexperiments demonstrate that our method significantly outperforms single-modal\ncontinual learning methods.",
    "published": "2025-10-20T07:23:36Z",
    "updated": "2025-10-20T07:23:36Z",
    "link": "http://arxiv.org/pdf/2510.17234v1.pdf",
    "category": [
      "cs.MM",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Yuyang Hong",
      "Qi Yang",
      "Tao Zhang",
      "Zili Wang",
      "Zhaojin Fu",
      "Kun Ding",
      "Bin Fan",
      "Shiming Xiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.14605v2",
    "title": "Knowledge-based Visual Question Answer with Multimodal Processing,\n  Retrieval and Filtering",
    "summary": "Knowledge-based visual question answering (KB-VQA) requires visual language\nmodels (VLMs) to integrate visual understanding with external knowledge\nretrieval. Although retrieval-augmented generation (RAG) achieves significant\nadvances in this task by combining knowledge-base querying, it still struggles\nwith the quality of multimodal queries and the relevance of retrieved results.\nTo overcome these challenges, we propose a novel three-stage method, termed\nWiki-PRF, including Processing, Retrieval and Filtering stages. The processing\nstage dynamically invokes visual tools to extract precise multimodal\ninformation for retrieval. The retrieval stage integrates visual and text\nfeatures to achieve multimodal knowledge retrieval. The filtering stage\nperforms relevance filtering and concentration on retrieval results. To this\nend, we introduce a visual language model trained with answer accuracy and\nformat consistency as reward signals via a reinforcement learning manner. This\nenhances the model's reasoning, tool invocation for accurate queries, and\nfiltering of irrelevant content. Experiments on benchmark datasets (E-VQA and\nInfoSeek) show significant improvements~(36.0 and 42.8) in answer quality,\nachieving state-of-the-art performance. Code is available at\nhttps://github.com/cqu-student/Wiki-PRF",
    "published": "2025-10-16T12:10:00Z",
    "updated": "2025-10-20T07:23:12Z",
    "link": "http://arxiv.org/pdf/2510.14605v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Yuyang Hong",
      "Jiaqi Gu",
      "Qi Yang",
      "Lubin Fan",
      "Yue Wu",
      "Ying Wang",
      "Kun Ding",
      "Shiming Xiang",
      "Jieping Ye"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17218v1",
    "title": "When One Moment Isn't Enough: Multi-Moment Retrieval with Cross-Moment\n  Interactions",
    "summary": "Existing Moment retrieval (MR) methods focus on Single-Moment Retrieval\n(SMR). However, one query can correspond to multiple relevant moments in\nreal-world applications. This makes the existing datasets and methods\ninsufficient for video temporal grounding. By revisiting the gap between\ncurrent MR tasks and real-world applications, we introduce a high-quality\ndatasets called QVHighlights Multi-Moment Dataset (QV-M$^2$), along with new\nevaluation metrics tailored for multi-moment retrieval (MMR). QV-M$^2$ consists\nof 2,212 annotations covering 6,384 video segments. Building on existing\nefforts in MMR, we propose a framework called FlashMMR. Specifically, we\npropose a Multi-moment Post-verification module to refine the moment\nboundaries. We introduce constrained temporal adjustment and subsequently\nleverage a verification module to re-evaluate the candidate segments. Through\nthis sophisticated filtering pipeline, low-confidence proposals are pruned, and\nrobust multi-moment alignment is achieved. We retrain and evaluate 6 existing\nMR methods on QV-M$^2$ and QVHighlights under both SMR and MMR settings.\nResults show that QV-M$^2$ serves as an effective benchmark for training and\nevaluating MMR models, while FlashMMR provides a strong baseline. Specifically,\non QV-M$^2$, it achieves improvements over prior SOTA method by 3.00% on G-mAP,\n2.70% on mAP@3+tgt, and 2.56% on mR@3. The proposed benchmark and method\nestablish a foundation for advancing research in more realistic and challenging\nvideo temporal grounding scenarios. Code is released at\nhttps://github.com/Zhuo-Cao/QV-M2.",
    "published": "2025-10-20T07:01:16Z",
    "updated": "2025-10-20T07:01:16Z",
    "link": "http://arxiv.org/pdf/2510.17218v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Zhuo Cao",
      "Heming Du",
      "Bingqing Zhang",
      "Xin Yu",
      "Xue Li",
      "Sen Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.21057v5",
    "title": "Robust Deterministic Policy Gradient for Disturbance Attenuation and Its\n  Application to Quadrotor Control",
    "summary": "Practical control systems pose significant challenges in identifying optimal\ncontrol policies due to uncertainties in the system model and external\ndisturbances. While $H_\\infty$ control techniques are commonly used to design\nrobust controllers that mitigate the effects of disturbances, these methods\noften require complex and computationally intensive calculations. To address\nthis issue, this paper proposes a reinforcement learning algorithm called\nrobust deterministic policy gradient (RDPG), which formulates the $H_\\infty$\ncontrol problem as a two-player zero-sum dynamic game. In this formulation, one\nplayer (the user) aims to minimize the cost, while the other player (the\nadversary) seeks to maximize it. We then employ deterministic policy gradient\n(DPG) and its deep reinforcement learning counterpart to train a robust control\npolicy with effective disturbance attenuation. In particular, for practical\nimplementation, we introduce an algorithm called robust deep deterministic\npolicy gradient (RDDPG), which employs a deep neural network architecture and\nintegrates techniques from the twin-delayed deep deterministic policy gradient\n(TD3) to enhance stability and learning efficiency. To evaluate the proposed\nalgorithm, we implement it on an unmanned aerial vehicle (UAV) tasked with\nfollowing a predefined path in a disturbance-prone environment. The\nexperimental results demonstrate that the proposed method outperforms other\ncontrol approaches in terms of robustness against disturbances, enabling\nprecise real-time tracking of moving targets even under severe disturbance\nconditions.",
    "published": "2025-02-28T13:58:22Z",
    "updated": "2025-10-20T06:59:23Z",
    "link": "http://arxiv.org/pdf/2502.21057v5.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Taeho Lee",
      "Donghwan Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17214v1",
    "title": "Diagnosis of Fuel Cell Health Status with Deep Sparse Auto-Encoder\n  Neural Network",
    "summary": "Effective and accurate diagnosis of fuel cell health status is crucial for\nensuring the stable operation of fuel cell stacks. Among various parameters,\nhigh-frequency impedance serves as a critical indicator for assessing fuel cell\nstate and health conditions. However, its online testing is prohibitively\ncomplex and costly. This paper employs a deep sparse auto-encoding network for\nthe prediction and classification of high-frequency impedance in fuel cells,\nachieving metric of accuracy rate above 92\\%. The network is further deployed\non an FPGA, attaining a hardware-based recognition rate almost 90\\%.",
    "published": "2025-10-20T06:55:35Z",
    "updated": "2025-10-20T06:55:35Z",
    "link": "http://arxiv.org/pdf/2510.17214v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Chenyan Fei",
      "Dalin Zhang",
      "Chen Melinda Dang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17212v1",
    "title": "D2C-HRHR: Discrete Actions with Double Distributional Critics for\n  High-Risk-High-Return Tasks",
    "summary": "Tasks involving high-risk-high-return (HRHR) actions, such as obstacle\ncrossing, often exhibit multimodal action distributions and stochastic returns.\nMost reinforcement learning (RL) methods assume unimodal Gaussian policies and\nrely on scalar-valued critics, which limits their effectiveness in HRHR\nsettings. We formally define HRHR tasks and theoretically show that Gaussian\npolicies cannot guarantee convergence to the optimal solution. To address this,\nwe propose a reinforcement learning framework that (i) discretizes continuous\naction spaces to approximate multimodal distributions, (ii) employs\nentropy-regularized exploration to improve coverage of risky but rewarding\nactions, and (iii) introduces a dual-critic architecture for more accurate\ndiscrete value distribution estimation. The framework scales to\nhigh-dimensional action spaces, supporting complex control domains. Experiments\non locomotion and manipulation benchmarks with high risks of failure\ndemonstrate that our method outperforms baselines, underscoring the importance\nof explicitly modeling multimodality and risk in RL.",
    "published": "2025-10-20T06:54:53Z",
    "updated": "2025-10-20T06:54:53Z",
    "link": "http://arxiv.org/pdf/2510.17212v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Jundong Zhang",
      "Yuhui Situ",
      "Fanji Zhang",
      "Rongji Deng",
      "Tianqi Wei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17211v1",
    "title": "Temporally Detailed Hypergraph Neural ODEs for Type 2 Diabetes\n  Progression Modeling",
    "summary": "Disease progression modeling aims to characterize and predict how a patient's\ndisease complications worsen over time based on longitudinal electronic health\nrecords (EHRs). Accurate modeling of disease progression, such as type 2\ndiabetes, can enhance patient sub-phenotyping and inform effective and timely\ninterventions. However, the problem is challenging due to the need to learn\ncontinuous-time dynamics of progression patterns based on irregular-time event\nsamples and patient heterogeneity (\\eg different progression rates and\npathways). Existing mechanistic and data-driven methods either lack\nadaptability to learn from real-world data or fail to capture complex\ncontinuous-time dynamics on progression trajectories. To address these\nlimitations, we propose Temporally Detailed Hypergraph Neural Ordinary\nDifferential Equation (TD-HNODE), which represents disease progression on\nclinically recognized trajectories as a temporally detailed hypergraph and\nlearns the continuous-time progression dynamics via a neural ODE framework.\nTD-HNODE contains a learnable TD-Hypergraph Laplacian that captures the\ninterdependency of disease complication markers within both intra- and\ninter-progression trajectories. Experiments on two real-world clinical datasets\ndemonstrate that TD-HNODE outperforms multiple baselines in modeling the\nprogression of type 2 diabetes and related cardiovascular diseases.",
    "published": "2025-10-20T06:54:29Z",
    "updated": "2025-10-20T06:54:29Z",
    "link": "http://arxiv.org/pdf/2510.17211v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Tingsong Xiao",
      "Yao An Lee",
      "Zelin Xu",
      "Yupu Zhang",
      "Zibo Liu",
      "Yu Huang",
      "Jiang Bian",
      "Serena Jingchuan Guo",
      "Zhe Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.09956v4",
    "title": "DeepSeek-Inspired Exploration of RL-based LLMs and Synergy with Wireless\n  Networks: A Survey",
    "summary": "Reinforcement learning (RL)-based large language models (LLMs), such as\nChatGPT, DeepSeek, and Grok-3, have attracted widespread attention for their\nremarkable capabilities in multimodal data understanding. Meanwhile, the rapid\nexpansion of information services has led to a growing demand for AI-enabled\nwireless networks. The open-source DeepSeek models are famous for their\ninnovative designs, such as large-scale pure RL and cost-efficient training,\nwhich make them well-suited for practical deployment in wireless networks. By\nintegrating DeepSeek-style LLMs with wireless infrastructures, a synergistic\nopportunity arises: the DeepSeek-style LLMs enhance network optimization with\nstrong reasoning and decision-making abilities, while wireless infrastructure\nenables the broad deployment of these models. Motivated by this convergence,\nthis survey presents a comprehensive DeepSeek-inspired exploration of RL-based\nLLMs in the context of wireless networks. We begin by reviewing key techniques\nbehind network optimization to establish a foundation for understanding\nDeepSeek-style LLM integration. Next, we examine recent advancements in\nRL-based LLMs, using DeepSeek models as a representative example. Building on\nthis, we explore the synergy between the two domains, highlighting motivations,\nchallenges, and potential solutions. Finally, we highlight emerging directions\nfor integrating LLMs with wireless networks, such as quantum, on-device, and\nneural-symbolic LLM models, as well as embodied AI agents. Overall, this survey\noffers a comprehensive examination of the interplay between DeepSeek-style LLMs\nand wireless networks, demonstrating how these domains can mutually enhance\neach other to drive innovation.",
    "published": "2025-03-13T01:59:11Z",
    "updated": "2025-10-20T06:44:00Z",
    "link": "http://arxiv.org/pdf/2503.09956v4.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.ET"
    ],
    "authors": [
      "Yu Qiao",
      "Phuong-Nam Tran",
      "Ji Su Yoon",
      "Loc X. Nguyen",
      "Eui-Nam Huh",
      "Dusit Niyato",
      "Choong Seon Hong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17206v1",
    "title": "Soft-Masked Diffusion Language Models",
    "summary": "Diffusion models have demonstrated strong potential in language modeling,\noffering various advantages over traditional autoregressive approaches. Their\nability to generate and revise entire responses in parallel enables faster\ngeneration and built-in self-correction mechanisms. Most modern diffusion-based\nlanguage models employ masked diffusion, where decoding involves iteratively\nprocessing masked tokens based on a binary decision: either retaining the mask\nor replacing it with the predicted token. However, this binary choice discards\nvaluable predictive information when the mask is retained. To address this\nlimitation, we introduce soft-masking (SM), a novel method that dynamically\nblends the embedding of the mask token with the embeddings of the top-$k$\npredicted tokens from the previous decoding step, for each retained mask. This\nprovides the model with a more informative prior, preserving context from\nearlier computations and allowing partial information about masked tokens to\npropagate beyond a single step. We propose a training methodology that adapts a\npretrained masked diffusion language model to incorporate SM. We demonstrate\nthat continuing pretraining a 169M parameter model with SM leads to improved\nperplexity and MAUVE scores. Furthermore, we finetune two state-of-the-art\ndiffusion models, Dream-7B and Dream-Coder-7B, with SM. SM consistently\nimproves performance across multiple coding benchmarks, particularly in\nhigh-throughput settings.",
    "published": "2025-10-20T06:42:03Z",
    "updated": "2025-10-20T06:42:03Z",
    "link": "http://arxiv.org/pdf/2510.17206v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Michael Hersche",
      "Samuel Moor-Smith",
      "Thomas Hofmann",
      "Abbas Rahimi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.11558v3",
    "title": "Error Broadcast and Decorrelation as a Potential Artificial and Natural\n  Learning Mechanism",
    "summary": "We introduce Error Broadcast and Decorrelation (EBD), a novel learning\nframework for neural networks that addresses credit assignment by directly\nbroadcasting output errors to individual layers, circumventing weight transport\nof backpropagation. EBD is rigorously grounded in the stochastic orthogonality\nproperty of Minimum Mean Square Error estimators. This fundamental principle\nstates that the error of an optimal estimator is orthogonal to functions of the\ninput. Guided by this insight, EBD defines layerwise loss functions that\ndirectly penalize correlations between layer activations and output errors,\nthereby establishing a principled foundation for error broadcasting. This\ntheoretically sound mechanism naturally leads to the experimentally observed\nthree-factor learning rule and integrates with biologically plausible\nframeworks to enhance performance and plausibility. Numerical experiments\ndemonstrate EBD's competitive or better performance against other\nerror-broadcast methods on benchmark datasets. Our findings establish EBD as an\nefficient, biologically plausible, and principled alternative for neural\nnetwork training. The implementation is available at:\nhttps://github.com/meterdogan07/error-broadcast-decorrelation.",
    "published": "2025-04-15T19:00:53Z",
    "updated": "2025-10-20T06:39:52Z",
    "link": "http://arxiv.org/pdf/2504.11558v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Mete Erdogan",
      "Cengiz Pehlevan",
      "Alper T. Erdogan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.00374v4",
    "title": "MIRROR: Multi-Modal Pathological Self-Supervised Representation Learning\n  via Modality Alignment and Retention",
    "summary": "Histopathology and transcriptomics are fundamental modalities in oncology,\nencapsulating the morphological and molecular aspects of the disease.\nMulti-modal self-supervised learning has demonstrated remarkable potential in\nlearning pathological representations by integrating diverse data sources.\nConventional multi-modal integration methods primarily emphasize modality\nalignment, while paying insufficient attention to retaining the\nmodality-specific structures. However, unlike conventional scenarios where\nmulti-modal inputs share highly overlapping features, histopathology and\ntranscriptomics exhibit pronounced heterogeneity, offering orthogonal yet\ncomplementary insights. Histopathology provides morphological and spatial\ncontext, elucidating tissue architecture and cellular topology, whereas\ntranscriptomics delineates molecular signatures through gene expression\npatterns. This inherent disparity introduces a major challenge in aligning them\nwhile maintaining modality-specific fidelity. To address these challenges, we\npresent MIRROR, a novel multi-modal representation learning method designed to\nfoster both modality alignment and retention. MIRROR employs dedicated encoders\nto extract comprehensive features for each modality, which is further\ncomplemented by a modality alignment module to achieve seamless integration\nbetween phenotype patterns and molecular profiles. Furthermore, a modality\nretention module safeguards unique attributes from each modality, while a style\nclustering module mitigates redundancy and enhances disease-relevant\ninformation by modeling and aligning consistent pathological signatures within\na clustering space. Extensive evaluations on TCGA cohorts for cancer subtyping\nand survival analysis highlight MIRROR's superior performance, demonstrating\nits effectiveness in constructing comprehensive oncological feature\nrepresentations and benefiting the cancer diagnosis.",
    "published": "2025-03-01T07:02:30Z",
    "updated": "2025-10-20T06:35:13Z",
    "link": "http://arxiv.org/pdf/2503.00374v4.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "authors": [
      "Tianyi Wang",
      "Jianan Fan",
      "Dingxin Zhang",
      "Dongnan Liu",
      "Yong Xia",
      "Heng Huang",
      "Weidong Cai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.07076v5",
    "title": "NFIG: Multi-Scale Autoregressive Image Generation via Frequency Ordering",
    "summary": "Autoregressive models have achieved significant success in image generation.\nHowever, unlike the inherent hierarchical structure of image information in the\nspectral domain, standard autoregressive methods typically generate pixels\nsequentially in a fixed spatial order. To better leverage this spectral\nhierarchy, we introduce NextFrequency Image Generation (NFIG). NFIG is a novel\nframework that decomposes the image generation process into multiple\nfrequency-guided stages. NFIG aligns the generation process with the natural\nimage structure. It does this by first generating low-frequency components,\nwhich efficiently capture global structure with significantly fewer tokens, and\nthen progressively adding higher-frequency details. This frequency-aware\nparadigm offers substantial advantages: it not only improves the quality of\ngenerated images but crucially reduces inference cost by efficiently\nestablishing global structure early on. Extensive experiments on the\nImageNet-256 benchmark validate NFIG's effectiveness, demonstrating superior\nperformance (FID: 2.81) and a notable 1.25x speedup compared to the strong\nbaseline VAR-d20. The source code is available at\nhttps://github.com/Pride-Huang/NFIG.",
    "published": "2025-03-10T08:59:10Z",
    "updated": "2025-10-20T06:31:52Z",
    "link": "http://arxiv.org/pdf/2503.07076v5.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "68T07",
      "I.2.10; I.2.6"
    ],
    "authors": [
      "Zhihao Huang",
      "Xi Qiu",
      "Yukuo Ma",
      "Yifu Zhou",
      "Junjie Chen",
      "Hongyuan Zhang",
      "Chi Zhang",
      "Xuelong Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17199v1",
    "title": "Round Outcome Prediction in VALORANT Using Tactical Features from Video\n  Analysis",
    "summary": "Recently, research on predicting match outcomes in esports has been actively\nconducted, but much of it is based on match log data and statistical\ninformation. This research targets the FPS game VALORANT, which requires\ncomplex strategies, and aims to build a round outcome prediction model by\nanalyzing minimap information in match footage. Specifically, based on the\nvideo recognition model TimeSformer, we attempt to improve prediction accuracy\nby incorporating detailed tactical features extracted from minimap information,\nsuch as character position information and other in-game events. This paper\nreports preliminary results showing that a model trained on a dataset augmented\nwith such tactical event labels achieved approximately 81% prediction accuracy,\nespecially from the middle phases of a round onward, significantly\noutperforming a model trained on a dataset with the minimap information itself.\nThis suggests that leveraging tactical features from match footage is highly\neffective for predicting round outcomes in VALORANT.",
    "published": "2025-10-20T06:23:36Z",
    "updated": "2025-10-20T06:23:36Z",
    "link": "http://arxiv.org/pdf/2510.17199v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Nirai Hayakawa",
      "Kazumasa Shimari",
      "Kazuma Yamasaki",
      "Hirotatsu Hoshikawa",
      "Rikuto Tsuchida",
      "Kenichi Matsumoto"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17198v1",
    "title": "From Pixels to People: Satellite-Based Mapping and Quantification of\n  Riverbank Erosion and Lost Villages in Bangladesh",
    "summary": "The great rivers of Bangladesh, arteries of commerce and sustenance, are also\nagents of relentless destruction. Each year, they swallow whole villages and\nvast tracts of farmland, erasing communities from the map and displacing\nthousands of families. To track this slow-motion catastrophe has, until now,\nbeen a Herculean task for human analysts. Here we show how a powerful\ngeneral-purpose vision model, the Segment Anything Model (SAM), can be adapted\nto this task with remarkable precision. To do this, we assembled a new dataset\n- a digital chronicle of loss compiled from historical Google Earth imagery of\nBangladesh's most vulnerable regions, including Mokterer Char Union, Kedarpur\nUnion, Balchipara village, and Chowhali Upazila, from 2003 to 2025. Crucially,\nthis dataset is the first to include manually annotated data on the settlements\nthat have vanished beneath the water. Our method first uses a simple\ncolor-channel analysis to provide a rough segmentation of land and water, and\nthen fine-tunes SAM's mask decoder to recognize the subtle signatures of\nriverbank erosion. The resulting model demonstrates a keen eye for this\ndestructive process, achieving a mean Intersection over Union of 86.30% and a\nDice score of 92.60% - a performance that significantly surpasses traditional\nmethods and off-the-shelf deep learning models. This work delivers three key\ncontributions: the first annotated dataset of disappeared settlements in\nBangladesh due to river erosion; a specialized AI model fine-tuned for this\ncritical task; and a method for quantifying land loss with compelling visual\nevidence. Together, these tools provide a powerful new lens through which\npolicymakers and disaster management agencies can monitor erosion, anticipate\nits trajectory, and ultimately protect the vulnerable communities in its path.",
    "published": "2025-10-20T06:20:59Z",
    "updated": "2025-10-20T06:20:59Z",
    "link": "http://arxiv.org/pdf/2510.17198v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "M Saifuzzaman Rafat",
      "Mohd Ruhul Ameen",
      "Akif Islam",
      "Abu Saleh Musa Miah",
      "Jungpil Shin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.18601v4",
    "title": "Flex-Judge: Text-Only Reasoning Unleashes Zero-Shot Multimodal\n  Evaluators",
    "summary": "Human-generated reward signals are critical for aligning generative models\nwith human preferences, guiding both training and inference-time evaluations.\nWhile large language models (LLMs) employed as proxy evaluators, i.e.,\nLLM-as-a-Judge, significantly reduce the costs associated with manual\nannotations, they typically require extensive modality-specific training data\nand fail to generalize well across diverse multimodal tasks. In this paper, we\npropose Flex-Judge, a reasoning-guided multimodal judge model that leverages\nminimal textual reasoning data to robustly generalize across multiple\nmodalities and evaluation formats. Our core intuition is that structured\ntextual reasoning explanations inherently encode generalizable decision-making\npatterns, enabling an effective transfer to multimodal judgments, e.g., with\nimages or videos. Empirical results demonstrate that Flex-Judge, despite being\ntrained on significantly fewer text data, achieves competitive or superior\nperformance compared to state-of-the-art commercial APIs and extensively\ntrained multimodal evaluators. Notably, Flex-Judge presents broad impact in\nmodalities like molecule, where comprehensive evaluation benchmarks are scarce,\nunderscoring its practical value in resource-constrained domains. Our framework\nhighlights reasoning-based text supervision as a powerful, cost-effective\nalternative to traditional annotation-intensive approaches, substantially\nadvancing scalable multimodal model-as-a-judge.",
    "published": "2025-05-24T08:50:53Z",
    "updated": "2025-10-20T06:19:03Z",
    "link": "http://arxiv.org/pdf/2505.18601v4.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Jongwoo Ko",
      "Sungnyun Kim",
      "Sungwoo Cho",
      "Se-Young Yun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17197v1",
    "title": "ZSPAPrune: Zero-Shot Prompt-Aware Token Pruning for Vision-Language\n  Models",
    "summary": "As the capabilities of Vision-Language Models (VLMs) advance, they can\nprocess increasingly large inputs, which, unlike in LLMs, generates significant\nvisual token redundancy and leads to prohibitive inference costs. While many\nmethods aim to reduce these costs by pruning visual tokens, existing\napproaches, whether based on attention or diversity, typically neglect the\nguidance of the text prompt and thus fail to prioritize task relevance. In this\nwork, we propose a novel, zero-shot method that reframes the problem by\nintroducing a prompt-aware perspective, explicitly modeling visual token\npruning as a balance between task relevance and information diversity. Our\nhierarchical approach first selects a core set of task-relevant visual tokens\nand then supplements them with diversity tokens to preserve broader context.\nExperiments across multiple models and benchmarks show that our method achieves\nperformance that matches or surpasses the state-of-the-art with only minimal\naccuracy loss, even when pruning up to 90\\% of the tokens. Furthermore, these\ngains are accompanied by significant reductions in GPU memory footprint and\ninference latency.",
    "published": "2025-10-20T06:18:47Z",
    "updated": "2025-10-20T06:18:47Z",
    "link": "http://arxiv.org/pdf/2510.17197v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Pu Zhang",
      "Yuwei Li",
      "Xingyuan Xian",
      "Guoming Tang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17196v1",
    "title": "Understanding and Improving Length Generalization in Hierarchical Sparse\n  Attention Models",
    "summary": "Effectively processing long contexts is a critical challenge for language\nmodels. While standard Transformers are limited by quadratic complexity and\npoor length extrapolation, alternative architectures like sliding window\nattention and state space models sacrifice the ability to effectively utilize\nthe full context due to their fixed-size memory. Chunk-based sparse attention\nhas emerged as a promising paradigm for extreme length generalization, yet the\nkey architectural principles underpinning its success are not yet fully\nunderstood. In this work, we present a systematic dissection of these models to\nidentify the core components driving their performance. Through a unified\nframework and comprehensive ablation studies, we demonstrate that a combination\nof three design principles is critical: (1) an expressive, non-linear Chunk\nEncoder with a dedicated CLS token to produce representations for retrieval;\n(2) a Bypassing Residual Path to stably integrate retrieved global information\nwithout it being overridden by the local residual stream; and (3) enforced\nselection sparsity during pre-training to bridge the train-test distribution\ngap. We provide a theoretical motivation for intra-chunk information processing\nand landmark generation. By combining these principles, we establish a new\nstate-of-the-art for training-free length extrapolation, successfully\ngeneralizing models trained on a 4K context to 32 million tokens on RULER and\nBABILong. Our findings provide a clear and empirically-grounded set of design\nprinciples for developing future, highly-capable long-context language models.",
    "published": "2025-10-20T06:17:57Z",
    "updated": "2025-10-20T06:17:57Z",
    "link": "http://arxiv.org/pdf/2510.17196v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Jiaqi Leng",
      "Xiang Hu",
      "Junxiong Wang",
      "Jianguo Li",
      "Wei Wu",
      "Yucheng Lu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17191v1",
    "title": "SimpleVSF: VLM-Scoring Fusion for Trajectory Prediction of End-to-End\n  Autonomous Driving",
    "summary": "End-to-end autonomous driving has emerged as a promising paradigm for\nachieving robust and intelligent driving policies. However, existing end-to-end\nmethods still face significant challenges, such as suboptimal decision-making\nin complex scenarios. In this paper,we propose SimpleVSF (Simple VLM-Scoring\nFusion), a novel framework that enhances end-to-end planning by leveraging the\ncognitive capabilities of Vision-Language Models (VLMs) and advanced trajectory\nfusion techniques. We utilize the conventional scorers and the novel\nVLM-enhanced scorers. And we leverage a robust weight fusioner for quantitative\naggregation and a powerful VLM-based fusioner for qualitative, context-aware\ndecision-making. As the leading approach in the ICCV 2025 NAVSIM v2 End-to-End\nDriving Challenge, our SimpleVSF framework demonstrates state-of-the-art\nperformance, achieving a superior balance between safety, comfort, and\nefficiency.",
    "published": "2025-10-20T06:09:57Z",
    "updated": "2025-10-20T06:09:57Z",
    "link": "http://arxiv.org/pdf/2510.17191v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Peiru Zheng",
      "Yun Zhao",
      "Zhan Gong",
      "Hong Zhu",
      "Shaohua Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.19565v2",
    "title": "FlowDet: Overcoming Perspective and Scale Challenges in Real-Time\n  End-to-End Traffic Detection",
    "summary": "End-to-end object detectors offer a promising NMS-free paradigm for real-time\napplications, yet their high computational cost remains a significant barrier,\nparticularly for complex scenarios like intersection traffic monitoring. To\naddress this challenge, we propose FlowDet, a high-speed detector featuring a\ndecoupled encoder optimization strategy applied to the DETR architecture.\nSpecifically, FlowDet employs a novel Geometric Deformable Unit (GDU) for\ntraffic-aware geometric modeling and a Scale-Aware Attention (SAA) module to\nmaintain high representational power across extreme scale variations. To\nrigorously evaluate the model's performance in environments with severe\nocclusion and high object density, we collected the Intersection-Flow-5k\ndataset, a new challenging scene for this task. Evaluated on\nIntersection-Flow-5k, FlowDet establishes a new state-of-the-art. Compared to\nthe strong RT-DETR baseline, it improves AP(test) by 1.5% and AP50(test) by\n1.6%, while simultaneously reducing GFLOPs by 63.2% and increasing inference\nspeed by 16.2%. Our work demonstrates a new path towards building highly\nefficient and accurate detectors for demanding, real-world perception systems.\nThe Intersection-Flow-5k dataset is available at\nhttps://github.com/AstronZh/Intersection-Flow-5K.",
    "published": "2025-08-27T04:49:04Z",
    "updated": "2025-10-20T06:06:04Z",
    "link": "http://arxiv.org/pdf/2508.19565v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "I.4.8; I.2.10; I.5.1"
    ],
    "authors": [
      "Zixing Wang",
      "Yuhang Zhao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17179v1",
    "title": "Benchmarking Out-of-Distribution Detection for Plankton Recognition: A\n  Systematic Evaluation of Advanced Methods in Marine Ecological Monitoring",
    "summary": "Automated plankton recognition models face significant challenges during\nreal-world deployment due to distribution shifts (Out-of-Distribution, OoD)\nbetween training and test data. This stems from plankton's complex\nmorphologies, vast species diversity, and the continuous discovery of novel\nspecies, which leads to unpredictable errors during inference. Despite rapid\nadvancements in OoD detection methods in recent years, the field of plankton\nrecognition still lacks a systematic integration of the latest computer vision\ndevelopments and a unified benchmark for large-scale evaluation. To address\nthis, this paper meticulously designed a series of OoD benchmarks simulating\nvarious distribution shift scenarios based on the DYB-PlanktonNet dataset\n\\cite{875n-f104-21}, and systematically evaluated twenty-two OoD detection\nmethods. Extensive experimental results demonstrate that the ViM\n\\cite{wang2022vim} method significantly outperforms other approaches in our\nconstructed benchmarks, particularly excelling in Far-OoD scenarios with\nsubstantial improvements in key metrics. This comprehensive evaluation not only\nprovides a reliable reference for algorithm selection in automated plankton\nrecognition but also lays a solid foundation for future research in plankton\nOoD detection. To our knowledge, this study marks the first large-scale,\nsystematic evaluation and analysis of Out-of-Distribution data detection\nmethods in plankton recognition. Code is available at\nhttps://github.com/BlackJack0083/PlanktonOoD.",
    "published": "2025-10-20T05:50:13Z",
    "updated": "2025-10-20T05:50:13Z",
    "link": "http://arxiv.org/pdf/2510.17179v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Yingzi Han",
      "Jiakai He",
      "Chuanlong Xie",
      "Jianping Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2303.04238v6",
    "title": "Patch of Invisibility: Naturalistic Physical Black-Box Adversarial\n  Attacks on Object Detectors",
    "summary": "Adversarial attacks on deep learning models have received increased attention\nin recent years. Work in this area has mostly focused on gradient-based\ntechniques, so-called 'white-box' attacks, where the attacker has access to the\ntargeted model's internal parameters; such an assumption is usually untenable\nin the real world. Additionally, some attacks use the entire pixel space to\nfool a given model, which is neither practical nor physical. To accommodate\nthese problems we propose the BBNP algorithm (Black-Box Naturalistic Patch): a\ndirect, black-box, naturalistic, gradient-free method that uses the learned\nimage manifold of a pretrained, generative adversarial network (GAN) to\ngenerate naturalistic adversarial patches for object detectors. This method\nperforms model-agnostic black-box naturalistic attacks on object detection\nmodels by relying solely on the outputs of the model. Comparing our approach\nagainst five models, five black-box and two white-box attacks, we show that our\nproposed method achieves state-of-the-art results, outperforming all other\ntested black-box approaches.",
    "published": "2023-03-07T21:03:48Z",
    "updated": "2025-10-20T05:49:56Z",
    "link": "http://arxiv.org/pdf/2303.04238v6.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.NE"
    ],
    "authors": [
      "Raz Lapid",
      "Eylon Mizrahi",
      "Moshe Sipper"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.01113v2",
    "title": "GFM-RAG: Graph Foundation Model for Retrieval Augmented Generation",
    "summary": "Retrieval-augmented generation (RAG) has proven effective in integrating\nknowledge into large language models (LLMs). However, conventional RAGs\nstruggle to capture complex relationships between pieces of knowledge, limiting\ntheir performance in intricate reasoning that requires integrating knowledge\nfrom multiple sources. Recently, graph-enhanced retrieval augmented generation\n(GraphRAG) builds graph structure to explicitly model these relationships,\nenabling more effective and efficient retrievers. Nevertheless, its performance\nis still hindered by the noise and incompleteness within the graph structure.\nTo address this, we introduce GFM-RAG, a novel graph foundation model (GFM) for\nretrieval augmented generation. GFM-RAG is powered by an innovative graph\nneural network that reasons over graph structure to capture complex\nquery-knowledge relationships. The GFM with 8M parameters undergoes a two-stage\ntraining process on large-scale datasets, comprising 60 knowledge graphs with\nover 14M triples and 700k documents. This results in impressive performance and\ngeneralizability for GFM-RAG, making it the first graph foundation model\napplicable to unseen datasets for retrieval without any fine-tuning required.\nExtensive experiments on three multi-hop QA datasets and seven domain-specific\nRAG datasets demonstrate that GFM-RAG achieves state-of-the-art performance\nwhile maintaining efficiency and alignment with neural scaling laws,\nhighlighting its potential for further improvement.",
    "published": "2025-02-03T07:04:29Z",
    "updated": "2025-10-20T05:31:15Z",
    "link": "http://arxiv.org/pdf/2502.01113v2.pdf",
    "category": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Linhao Luo",
      "Zicheng Zhao",
      "Gholamreza Haffari",
      "Dinh Phung",
      "Chen Gong",
      "Shirui Pan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17173v1",
    "title": "Offline Policy Evaluation of Multi-Turn LLM Health Coaching with Real\n  Users",
    "summary": "We study a web-deployed, tool-augmented LLM health coach with real users. In\na pilot with seven users (280 rated turns), offline policy evaluation (OPE)\nover factorized decision heads (Tool/Style) shows that a uniform heavy-tool\npolicy raises average value on logs but harms specific subgroups, most notably\nlow-health-literacy/high-self-efficacy users. A lightweight simulator with\nhidden archetypes further shows that adding a small early information-gain\nbonus reliably shortens trait identification and improves goal success and\npass@3. Together, these early findings indicate an evaluation-first path to\npersonalization: freeze the generator, learn subgroup-aware decision heads on\ntyped rewards (objective tool outcomes and satisfaction), and always report\nper-archetype metrics to surface subgroup harms that averages obscure.",
    "published": "2025-10-20T05:28:59Z",
    "updated": "2025-10-20T05:28:59Z",
    "link": "http://arxiv.org/pdf/2510.17173v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Melik Ozolcer",
      "Sang Won Bae"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17172v1",
    "title": "Combining ECG Foundation Model and XGBoost to Predict In-Hospital\n  Malignant Ventricular Arrhythmias in AMI Patients",
    "summary": "Malignant ventricular arrhythmias (VT/VF) following acute myocardial\ninfarction (AMI) are a major cause of in-hospital death, yet early\nidentification remains a clinical challenge. While traditional risk scores have\nlimited performance, end-to-end deep learning models often lack the\ninterpretability needed for clinical trust. This study aimed to develop a\nhybrid predictive framework that integrates a large-scale electrocardiogram\n(ECG) foundation model (ECGFounder) with an interpretable XGBoost classifier to\nimprove both accuracy and interpretability. We analyzed 6,634 ECG recordings\nfrom AMI patients, among whom 175 experienced in-hospital VT/VF. The ECGFounder\nmodel was used to extract 150-dimensional diagnostic probability features ,\nwhich were then refined through feature selection to train the XGBoost\nclassifier. Model performance was evaluated using AUC and F1-score , and the\nSHAP method was used for interpretability. The ECGFounder + XGBoost hybrid\nmodel achieved an AUC of 0.801 , outperforming KNN (AUC 0.677), RNN (AUC\n0.676), and an end-to-end 1D-CNN (AUC 0.720). SHAP analysis revealed that\nmodel-identified key features, such as \"premature ventricular complexes\" (risk\npredictor) and \"normal sinus rhythm\" (protective factor), were highly\nconsistent with clinical knowledge. We conclude that this hybrid framework\nprovides a novel paradigm for VT/VF risk prediction by validating the use of\nfoundation model outputs as effective, automated feature engineering for\nbuilding trustworthy, explainable AI-based clinical decision support systems.",
    "published": "2025-10-20T05:26:55Z",
    "updated": "2025-10-20T05:26:55Z",
    "link": "http://arxiv.org/pdf/2510.17172v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Shun Huang",
      "Wenlu Xing",
      "Shijia Geng",
      "Hailong Wang",
      "Guangkun Nie",
      "Gongzheng Tang",
      "Chenyang He",
      "Shenda Hong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.15244v2",
    "title": "Planner and Executor: Collaboration between Discrete Diffusion And\n  Autoregressive Models in Reasoning",
    "summary": "Current autoregressive language models (ARMs) achieve high accuracy but\nrequire long token sequences, making them costly. Discrete diffusion language\nmodels (DDLMs) enable parallel and flexible generation within a fixed number of\nsteps and have recently emerged for their strong performance in complex\nreasoning and long-term planning tasks. We present a study exploring hybrid\narchitectures that couple DDLMs with ARMs to assess whether their collaboration\ncan yield complementary benefits. We first examine collaboration in text space,\nwhere one model plans the reasoning process and another executes the final\nanswer based on that plan. We then extend this setup to latent-space\ncommunication, introducing a learned projector that maps DDLM latents into the\nARM's embedding space, potentially bypassing some of the text-generation\nlimitations of diffusion models. We find that shifting DDLM --> ARM\ncommunication from text space to latent space yields significant accuracy\ngains, for example increasing from 27.0% to 54.0% on DART-5 and from 0.0% to\n14.0% on AIME24. We also find that combining a DDLM planner with an ARM\nexecutor can provide substantial computational savings with little to no impact\non accuracy. For example, the latent-space pipeline, using 64 tokens for\nplanning and roughly 5 for execution, surpasses Qwen3.1-7B on DART-5 and AIME,\ndespite Qwen using 44 times more tokens. Overall, our study offers new insights\ninto reasoning with DDLMs and highlights their potential in hybrid\narchitectures.",
    "published": "2025-10-17T02:16:19Z",
    "updated": "2025-10-20T05:20:30Z",
    "link": "http://arxiv.org/pdf/2510.15244v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Lina Berrayana",
      "Ahmed Heakl",
      "Muhammad Abdullah Sohail",
      "Thomas Hofmann",
      "Salman Khan",
      "Wei Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17163v1",
    "title": "TREAT: A Code LLMs Trustworthiness / Reliability Evaluation and Testing\n  Framework",
    "summary": "Large foundation models are fundamentally transforming the software\nengineering landscape, demonstrating exceptional capabilities across diverse\ntasks such as code generation, debugging, and testing. Despite this rapid\nprogress, a significant gap remains in how to comprehensively evaluate these\nmodels' trustworthiness in real-world software engineering scenarios. Existing\nbenchmarks suffer from limited task scope and fail to incorporate critical\nevaluation aspects such as the robustness and reliability of models. To bridge\nthis gap, we present an evaluation framework called TREAT (Code LLMs\nTrustworthiness / Reliability Evaluation And Testing) that provides a holistic\nassessment of model performance in code intelligence tasks. Our evaluation\nframework addresses key limitations in existing approaches with four main\nimprovements: (1) Multi-Task Holistic Evaluation that spans diverse software\nengineering activities rather than limited coding tasks; (2) Multi-Language and\nMulti-Modality Assessment that extends beyond traditional single-language,\ntext-only benchmarks to include multi-modality coding tasks; (3) Robustness\nAssessment that evaluates model reliability under semantically-preserving code\ntransformations; and (4) Rigorous Evaluation Methodology that enhances the\ntrustworthiness of evaluation results through diverse evaluation prompts and\nadaptive solution extraction. Based on this evaluation framework, we assess 26\nstate-of-the-art models and uncover both their strengths and limitations,\nyielding several key insights:(1) Current models show substantial performance\nvariation across programming tasks; (2) Multi-modal language models demonstrate\nspecific performance limitations in UI code generation and edit;",
    "published": "2025-10-20T05:05:00Z",
    "updated": "2025-10-20T05:05:00Z",
    "link": "http://arxiv.org/pdf/2510.17163v1.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Shuzheng Gao",
      "Eric John Li",
      "Man Ho Lam",
      "Jingyu Xiao",
      "Yuxuan Wan",
      "Chaozheng Wang",
      "Ng Man Tik",
      "Michael R. Lyu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17157v1",
    "title": "GACO-CAD: Geometry-Augmented and Conciseness-Optimized CAD Model\n  Generation from Single Image",
    "summary": "Generating editable, parametric CAD models from a single image holds great\npotential to lower the barriers of industrial concept design. However, current\nmulti-modal large language models (MLLMs) still struggle with accurately\ninferring 3D geometry from 2D images due to limited spatial reasoning\ncapabilities. We address this limitation by introducing GACO-CAD, a novel\ntwo-stage post-training framework. It is designed to achieve a joint objective:\nsimultaneously improving the geometric accuracy of the generated CAD models and\nencouraging the use of more concise modeling procedures. First, during\nsupervised fine-tuning, we leverage depth and surface normal maps as dense\ngeometric priors, combining them with the RGB image to form a multi-channel\ninput. In the context of single-view reconstruction, these priors provide\ncomplementary spatial cues that help the MLLM more reliably recover 3D geometry\nfrom 2D observations. Second, during reinforcement learning, we introduce a\ngroup length reward that, while preserving high geometric fidelity, promotes\nthe generation of more compact and less redundant parametric modeling\nsequences. A simple dynamic weighting strategy is adopted to stabilize\ntraining. Experiments on the DeepCAD and Fusion360 datasets show that GACO-CAD\nachieves state-of-the-art performance under the same MLLM backbone,\nconsistently outperforming existing methods in terms of code validity,\ngeometric accuracy, and modeling conciseness.",
    "published": "2025-10-20T04:57:20Z",
    "updated": "2025-10-20T04:57:20Z",
    "link": "http://arxiv.org/pdf/2510.17157v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Yinghui Wang",
      "Xinyu Zhang",
      "Peng Du"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17149v1",
    "title": "Which LLM Multi-Agent Protocol to Choose?",
    "summary": "As large-scale multi-agent systems evolve, the communication protocol layer\nhas become a critical yet under-evaluated factor shaping performance and\nreliability. Despite the existence of diverse protocols (A2A, ACP, ANP, Agora,\netc.), selection is often intuition-driven and lacks standardized guidance. We\nintroduce ProtocolBench, a benchmark that systematically compares agent\nprotocols along four measurable axes: task success, end-to-end latency, message\nor byte overhead, and robustness under failures. On ProtocolBench, protocol\nchoice significantly influences system behavior. In the Streaming Queue\nscenario, overall completion time varies by up to 36.5% across protocols, and\nmean end-to-end latency differs by 3.48 s. Under Fail-Storm Recovery,\nresilience also differs consistently across protocols. Beyond evaluation, we\npresent ProtocolRouter, a learnable protocol router that selects per-scenario\n(or per-module) protocols from requirement and runtime signals. ProtocolRouter\nreduces Fail-Storm recovery time by up to 18.1% versus the best single-protocol\nbaseline, and achieves scenario-specific gains such as higher success in GAIA.\nWe also release ProtocolRouterBench to standardize protocol evaluation and\nimprove reliability at scale.",
    "published": "2025-10-20T04:53:19Z",
    "updated": "2025-10-20T04:53:19Z",
    "link": "http://arxiv.org/pdf/2510.17149v1.pdf",
    "category": [
      "cs.AI",
      "I.2.11"
    ],
    "authors": [
      "Hongyi Du",
      "Jiaqi Su",
      "Jisen Li",
      "Lijie Ding",
      "Yingxuan Yang",
      "Peixuan Han",
      "Xiangru Tang",
      "Kunlun Zhu",
      "Jiaxuan You"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.20977v2",
    "title": "From Cradle to Cane: A Two-Pass Framework for High-Fidelity Lifespan\n  Face Aging",
    "summary": "Face aging has become a crucial task in computer vision, with applications\nranging from entertainment to healthcare. However, existing methods struggle\nwith achieving a realistic and seamless transformation across the entire\nlifespan, especially when handling large age gaps or extreme head poses. The\ncore challenge lies in balancing age accuracy and identity preservation--what\nwe refer to as the Age-ID trade-off. Most prior methods either prioritize age\ntransformation at the expense of identity consistency or vice versa. In this\nwork, we address this issue by proposing a two-pass face aging framework, named\nCradle2Cane, based on few-step text-to-image (T2I) diffusion models. The first\npass focuses on solving age accuracy by introducing an adaptive noise injection\n(AdaNI) mechanism. This mechanism is guided by including prompt descriptions of\nage and gender for the given person as the textual condition. Also, by\nadjusting the noise level, we can control the strength of aging while allowing\nmore flexibility in transforming the face. However, identity preservation is\nweakly ensured here to facilitate stronger age transformations. In the second\npass, we enhance identity preservation while maintaining age-specific features\nby conditioning the model on two identity-aware embeddings (IDEmb): SVR-ArcFace\nand Rotate-CLIP. This pass allows for denoising the transformed image from the\nfirst pass, ensuring stronger identity preservation without compromising the\naging accuracy. Both passes are jointly trained in an end-to-end way. Extensive\nexperiments on the CelebA-HQ test dataset, evaluated through Face++ and Qwen-VL\nprotocols, show that our Cradle2Cane outperforms existing face aging methods in\nage accuracy and identity consistency. Code is available at\nhttps://github.com/byliutao/Cradle2Cane.",
    "published": "2025-06-26T03:48:28Z",
    "updated": "2025-10-20T04:50:01Z",
    "link": "http://arxiv.org/pdf/2506.20977v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Tao Liu",
      "Dafeng Zhang",
      "Gengchen Li",
      "Shizhuo Liu",
      "Yongqi Song",
      "Senmao Li",
      "Shiqi Yang",
      "Boqian Li",
      "Kai Wang",
      "Yaxing Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17146v1",
    "title": "Physics-Informed Large Language Models for HVAC Anomaly Detection with\n  Autonomous Rule Generation",
    "summary": "Heating, Ventilation, and Air-Conditioning (HVAC) systems account for a\nsubstantial share of global building energy use, making reliable anomaly\ndetection essential for improving efficiency and reducing emissions. Classical\nrule-based approaches offer explainability but lack adaptability, while deep\nlearning methods provide predictive power at the cost of transparency,\nefficiency, and physical plausibility. Recent attempts to use Large Language\nModels (LLMs) for anomaly detection improve interpretability but largely ignore\nthe physical principles that govern HVAC operations. We present PILLM, a\nPhysics-Informed LLM framework that operates within an evolutionary loop to\nautomatically generate, evaluate, and refine anomaly detection rules. Our\napproach introduces physics-informed reflection and crossover operators that\nembed thermodynamic and control-theoretic constraints, enabling rules that are\nboth adaptive and physically grounded. Experiments on the public Building Fault\nDetection dataset show that PILLM achieves state-of-the-art performance while\nproducing diagnostic rules that are interpretable and actionable, advancing\ntrustworthy and deployable AI for smart building systems.",
    "published": "2025-10-20T04:43:36Z",
    "updated": "2025-10-20T04:43:36Z",
    "link": "http://arxiv.org/pdf/2510.17146v1.pdf",
    "category": [
      "cs.AI",
      "cs.CE"
    ],
    "authors": [
      "Subin Lin",
      "Chuanbo Hua"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17145v1",
    "title": "Enhanced Fish Freshness Classification with Incremental Handcrafted\n  Feature Fusion",
    "summary": "Accurate assessment of fish freshness remains a major challenge in the food\nindustry, with direct consequences for product quality, market value, and\nconsumer health. Conventional sensory evaluation is inherently subjective,\ninconsistent, and difficult to standardize across contexts, often limited by\nsubtle, species-dependent spoilage cues. To address these limitations, we\npropose a handcrafted feature-based approach that systematically extracts and\nincrementally fuses complementary descriptors, including color statistics,\nhistograms across multiple color spaces, and texture features such as Local\nBinary Patterns (LBP) and Gray-Level Co-occurrence Matrices (GLCM), from fish\neye images. Our method captures global chromatic variations from full images\nand localized degradations from ROI segments, fusing each independently to\nevaluate their effectiveness in assessing freshness. Experiments on the\nFreshness of the Fish Eyes (FFE) dataset demonstrate the approach's\neffectiveness: in a standard train-test setting, a LightGBM classifier achieved\n77.56% accuracy, a 14.35% improvement over the previous deep learning baseline\nof 63.21%. With augmented data, an Artificial Neural Network (ANN) reached\n97.16% accuracy, surpassing the prior best of 77.3% by 19.86%. These results\ndemonstrate that carefully engineered, handcrafted features, when strategically\nprocessed, yield a robust, interpretable, and reliable solution for automated\nfish freshness assessment, providing valuable insights for practical\napplications in food quality monitoring.",
    "published": "2025-10-20T04:36:34Z",
    "updated": "2025-10-20T04:36:34Z",
    "link": "http://arxiv.org/pdf/2510.17145v1.pdf",
    "category": [
      "cs.AI",
      "68T05, 62H30"
    ],
    "authors": [
      "Phi-Hung Hoang",
      "Nam-Thuan Trinh",
      "Van-Manh Tran",
      "Thi-Thu-Hong Phan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.16972v2",
    "title": "The 1st Solution for 7th LSVOS RVOS Track: SaSaSa2VA",
    "summary": "Referring video object segmentation (RVOS) requires segmenting and tracking\nobjects in videos conditioned on natural-language expressions, demanding\nfine-grained understanding of both appearance and motion. Building on Sa2VA,\nwhich couples a Multi-modal Large Language Model (MLLM) with the video\nsegmentation model SAM2, we identify two key bottlenecks that limit\nsegmentation performance: sparse frame sampling and reliance on a single [SEG]\ntoken for an entire video. We propose Segmentation Augmented and Selective\nAveraged Sa2VA (SaSaSa2VA) to address these issues. On the 7th LSVOS Challenge\n(RVOS track), SaSaSa2VA achieves a $\\mathcal{J\\&F}$ of 67.45, ranking first and\nsurpassing the runner-up by 2.80 points. This result and ablation studies\ndemonstrate that efficient segmentation augmentation and test-time ensembling\nsubstantially enhance grounded MLLMs for RVOS. The code is released in Sa2VA\nrepository: https://github.com/bytedance/Sa2VA.",
    "published": "2025-09-21T08:08:17Z",
    "updated": "2025-10-20T04:36:14Z",
    "link": "http://arxiv.org/pdf/2509.16972v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Quanzhu Niu",
      "Dengxian Gong",
      "Shihao Chen",
      "Tao Zhang",
      "Yikang Zhou",
      "Haobo Yuan",
      "Lu Qi",
      "Xiangtai Li",
      "Shunping Ji"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.12680v2",
    "title": "Ineq-Comp: Benchmarking Human-Intuitive Compositional Reasoning in\n  Automated Theorem Proving on Inequalities",
    "summary": "LLM-based formal proof assistants (e.g., in Lean) hold great promise for\nautomating mathematical discovery. But beyond syntactic correctness, do these\nsystems truly understand mathematical structure as humans do? We investigate\nthis question in context of mathematical inequalities -- specifically the\nprover's ability to recognize that the given problem simplifies by applying a\nknown inequality such as AM/GM. Specifically, we are interested in their\nability to do this in a compositional setting where multiple inequalities must\nbe applied as part of a solution. We introduce Ineq-Comp, a benchmark built\nfrom elementary inequalities through systematic transformations, including\nvariable duplication, algebraic rewriting, and multi-step composition. Although\nthese problems remain easy for humans, we find that most provers -- including\nGoedel, STP, and Kimina-7B -- struggle significantly. DeepSeek-Prover-V2-7B\nshows relative robustness, but still suffers a 20% performance drop (pass@32).\nEven for DeepSeek-Prover-V2-671B model, the gap between compositional variants\nand seed problems exists, implying that simply scaling up the model size alone\ndoes not fully solve the compositional weakness. Strikingly, performance\nremains poor for all models even when formal proofs of the constituent parts\nare provided in context, revealing that the source of weakness is indeed in\ncompositional reasoning. Our results expose a persisting gap between the\ngeneralization behavior of current AI provers and human mathematical intuition.\nAll data and evaluation code can be found at\nhttps://github.com/haoyuzhao123/LeanIneqComp.",
    "published": "2025-05-19T03:56:05Z",
    "updated": "2025-10-20T04:36:02Z",
    "link": "http://arxiv.org/pdf/2505.12680v2.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Haoyu Zhao",
      "Yihan Geng",
      "Shange Tang",
      "Yong Lin",
      "Bohan Lyu",
      "Hongzhou Lin",
      "Chi Jin",
      "Sanjeev Arora"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.16082v6",
    "title": "On Task Vectors and Gradients",
    "summary": "Task arithmetic has emerged as a simple yet powerful technique for model\nmerging, enabling the combination of multiple finetuned models into one.\nDespite its empirical success, a clear theoretical explanation of why and when\nit works is lacking. This paper provides a rigorous theoretical foundation for\ntask arithmetic by establishing a connection between task vectors and gradients\nof the task losses. We show that under standard gradient descent, a task vector\ngenerated from one epoch of finetuning is exactly equivalent to the negative\ngradient of the loss, scaled by the learning rate. For the practical\nmulti-epoch setting, we prove that this equivalence holds approximately, with a\nsecond-order error term that we explicitly bound for feed-forward networks. Our\nempirical analysis across seven vision benchmarks corroborates our theory,\ndemonstrating that the first-epoch gradient dominates the finetuning trajectory\nin both norm and direction. A key implication is that merging models finetuned\nfor only a single epoch often yields performance comparable to merging fully\nconverged models. These findings reframe task arithmetic as a form of\napproximate multitask learning, providing a clear rationale for its\neffectiveness and highlighting the critical role of early training dynamics in\nmodel merging.",
    "published": "2025-08-22T04:16:42Z",
    "updated": "2025-10-20T04:13:40Z",
    "link": "http://arxiv.org/pdf/2508.16082v6.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Luca Zhou",
      "Daniele Solombrino",
      "Donato Crisostomi",
      "Maria Sofia Bucarelli",
      "Giuseppe Alessio D'Inverno",
      "Fabrizio Silvestri",
      "Emanuele RodolÃ "
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.18632v3",
    "title": "Automated Knowledge Component Generation for Interpretable Knowledge\n  Tracing in Coding Problems",
    "summary": "Knowledge components (KCs) mapped to problems help model student learning,\ntracking their mastery levels on fine-grained skills thereby facilitating\npersonalized learning and feedback in online learning platforms. However,\ncrafting and tagging KCs to problems, traditionally performed by human domain\nexperts, is highly labor intensive. We present an automated, LLM-based pipeline\nfor KC generation and tagging for open-ended programming problems. We also\ndevelop an LLM-based knowledge tracing (KT) framework to leverage these\nLLM-generated KCs, which we refer to as KCGen-KT. We conduct extensive\nquantitative and qualitative evaluations on two real-world student code\nsubmission datasets in different programming languages.We find that KCGen-KT\noutperforms existing KT methods and human-written KCs on future student\nresponse prediction. We investigate the learning curves of generated KCs and\nshow that LLM-generated KCs result in a better fit than human written KCs under\na cognitive model. We also conduct a human evaluation with course instructors\nto show that our pipeline generates reasonably accurate problem-KC mappings.",
    "published": "2025-02-25T20:40:51Z",
    "updated": "2025-10-20T04:05:43Z",
    "link": "http://arxiv.org/pdf/2502.18632v3.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.LG",
      "cs.SE"
    ],
    "authors": [
      "Zhangqi Duan",
      "Nigel Fernandez",
      "Arun Balajiee Lekshmi Narayanan",
      "Mohammad Hassany",
      "Rafaella Sampaio de Alencar",
      "Peter Brusilovsky",
      "Bita Akram",
      "Andrew Lan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.13499v2",
    "title": "ConsintBench: Evaluating Language Models on Real-World Consumer Intent\n  Understanding",
    "summary": "Understanding human intent is a complex, high-level task for large language\nmodels (LLMs), requiring analytical reasoning, contextual interpretation,\ndynamic information aggregation, and decision-making under uncertainty.\nReal-world public discussions, such as consumer product discussions, are rarely\nlinear or involve a single user. Instead, they are characterized by interwoven\nand often conflicting perspectives, divergent concerns, goals, emotional\ntendencies, as well as implicit assumptions and background knowledge about\nusage scenarios. To accurately understand such explicit public intent, an LLM\nmust go beyond parsing individual sentences; it must integrate multi-source\nsignals, reason over inconsistencies, and adapt to evolving discourse, similar\nto how experts in fields like politics, economics, or finance approach complex,\nuncertain environments. Despite the importance of this capability, no\nlarge-scale benchmark currently exists for evaluating LLMs on real-world human\nintent understanding, primarily due to the challenges of collecting real-world\npublic discussion data and constructing a robust evaluation pipeline. To bridge\nthis gap, we introduce \\bench, the first dynamic, live evaluation benchmark\nspecifically designed for intent understanding, particularly in the consumer\ndomain. \\bench is the largest and most diverse benchmark of its kind,\nsupporting real-time updates while preventing data contamination through an\nautomated curation pipeline.",
    "published": "2025-10-15T12:49:45Z",
    "updated": "2025-10-20T04:04:04Z",
    "link": "http://arxiv.org/pdf/2510.13499v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Xiaozhe Li",
      "TianYi Lyu",
      "Siyi Yang",
      "Yuxi Gong",
      "Yizhao Yang",
      "Jinxuan Huang",
      "Ligao Zhang",
      "Zhuoyi Huang",
      "Qingwen Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.02442v3",
    "title": "The Gauss-Markov Adjunction Provides Categorical Semantics of Residuals\n  in Supervised Learning",
    "summary": "Enhancing the intelligibility and interpretability of machine learning is a\ncrucial task in responding to the demand for Explicability as an AI principle,\nand in promoting the better social implementation of AI. The aim of our\nresearch is to contribute to this improvement by reformulating machine learning\nmodels through the lens of category theory, thereby developing a semantic\nframework for structuring and understanding AI systems. Our categorical\nmodeling in this paper clarifies and formalizes the structural interplay\nbetween residuals and parameters in supervised learning. The present paper\nfocuses on the multiple linear regression model, which represents the most\nbasic form of supervised learning. By defining two Lawvere-enriched categories\ncorresponding to parameters and data, along with an adjoint pair of functors\nbetween them, we introduce our categorical formulation of supervised learning.\nWe show that the essential structure of this framework is captured by what we\ncall the Gauss-Markov Adjunction. Within this setting, the dual flow of\ninformation can be explicitly described as a correspondence between variations\nin parameters and residuals. The ordinary least squares estimator for the\nparameters and the minimum residual are related via the preservation of limits\nby the right adjoint functor. Furthermore, we position this formulation as an\ninstance of extended denotational semantics for supervised learning, and\npropose applying a semantic perspective developed in theoretical computer\nscience as a formal foundation for Explicability in AI.",
    "published": "2025-07-03T08:58:59Z",
    "updated": "2025-10-20T04:02:37Z",
    "link": "http://arxiv.org/pdf/2507.02442v3.pdf",
    "category": [
      "cs.AI",
      "math.CT",
      "stat.ME",
      "stat.ML"
    ],
    "authors": [
      "Moto Kamiura"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17132v1",
    "title": "Do LLMs Recognize Your Latent Preferences? A Benchmark for Latent\n  Information Discovery in Personalized Interaction",
    "summary": "Large Language Models (LLMs) excel at producing broadly relevant text, but\nthis generality becomes a limitation when user-specific preferences are\nrequired, such as recommending restaurants or planning travel. In these\nscenarios, users rarely articulate every preference explicitly; instead, much\nof what they care about remains latent, waiting to be inferred. This raises a\nfundamental question: Can LLMs uncover and reason about such latent information\nthrough conversation?\n  We address this problem by introducing a unified benchmark for evaluating\nlatent information discovery - the ability of LLMs to reveal and utilize hidden\nuser attributes through multi-turn interaction. The benchmark spans three\nprogressively realistic settings: the classic 20 Questions game, Personalized\nQuestion Answering, and Personalized Text Summarization. All tasks share a\ntri-agent framework (User, Assistant, Judge) enabling turn-level evaluation of\nelicitation and adaptation. Our results reveal that while LLMs can indeed\nsurface latent information through dialogue, their success varies dramatically\nwith context: from 32% to 98%, depending on task complexity, topic, and number\nof hidden attributes. This benchmark provides the first systematic framework\nfor studying latent information discovery in personalized interaction,\nhighlighting that effective preference inference remains an open frontier for\nbuilding truly adaptive AI systems.",
    "published": "2025-10-20T03:58:49Z",
    "updated": "2025-10-20T03:58:49Z",
    "link": "http://arxiv.org/pdf/2510.17132v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Ioannis Tsaknakis",
      "Bingqing Song",
      "Shuyu Gan",
      "Dongyeop Kang",
      "Alfredo Garcia",
      "Gaowen Liu",
      "Charles Fleming",
      "Mingyi Hong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17131v1",
    "title": "GOOD: Training-Free Guided Diffusion Sampling for Out-of-Distribution\n  Detection",
    "summary": "Recent advancements have explored text-to-image diffusion models for\nsynthesizing out-of-distribution (OOD) samples, substantially enhancing the\nperformance of OOD detection. However, existing approaches typically rely on\nperturbing text-conditioned embeddings, resulting in semantic instability and\ninsufficient shift diversity, which limit generalization to realistic OOD. To\naddress these challenges, we propose GOOD, a novel and flexible framework that\ndirectly guides diffusion sampling trajectories towards OOD regions using\noff-the-shelf in-distribution (ID) classifiers. GOOD incorporates dual-level\nguidance: (1) Image-level guidance based on the gradient of log partition to\nreduce input likelihood, drives samples toward low-density regions in pixel\nspace. (2) Feature-level guidance, derived from k-NN distance in the\nclassifier's latent space, promotes sampling in feature-sparse regions. Hence,\nthis dual-guidance design enables more controllable and diverse OOD sample\ngeneration. Additionally, we introduce a unified OOD score that adaptively\ncombines image and feature discrepancies, enhancing detection robustness. We\nperform thorough quantitative and qualitative analyses to evaluate the\neffectiveness of GOOD, demonstrating that training with samples generated by\nGOOD can notably enhance OOD detection performance.",
    "published": "2025-10-20T03:58:46Z",
    "updated": "2025-10-20T03:58:46Z",
    "link": "http://arxiv.org/pdf/2510.17131v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Xin Gao",
      "Jiyao Liu",
      "Guanghao Li",
      "Yueming Lyu",
      "Jianxiong Gao",
      "Weichen Yu",
      "Ningsheng Xu",
      "Liang Wang",
      "Caifeng Shan",
      "Ziwei Liu",
      "Chenyang Si"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.08102v4",
    "title": "Consistency of Responses and Continuations Generated by Large Language\n  Models on Social Media",
    "summary": "Large Language Models (LLMs) demonstrate remarkable capabilities in text\ngeneration, yet their emotional consistency and semantic coherence in social\nmedia contexts remain insufficiently understood. This study investigates how\nLLMs handle emotional content and maintain semantic relationships through\ncontinuation and response tasks using three open-source models: Gemma, Llama3\nand Llama3.3 and one commercial Model:Claude. By analyzing climate change\ndiscussions from Twitter and Reddit, we examine emotional transitions,\nintensity patterns, and semantic consistency between human-authored and\nLLM-generated content. Our findings reveal that while both models maintain high\nsemantic coherence, they exhibit distinct emotional patterns: these models show\na strong tendency to moderate negative emotions. When the input text carries\nnegative emotions such as anger, disgust, fear, or sadness, LLM tends to\ngenerate content with more neutral emotions, or even convert them into positive\nemotions such as joy or surprise. At the same time, we compared the\nLLM-generated content with human-authored content. The four models\nsystematically generated responses with reduced emotional intensity and showed\na preference for neutral rational emotions in the response task. In addition,\nthese models all maintained a high semantic similarity with the original text,\nalthough their performance in the continuation task and the response task was\ndifferent. These findings provide deep insights into the emotion and semantic\nprocessing capabilities of LLM, which are of great significance for its\ndeployment in social media environments and human-computer interaction design.",
    "published": "2025-01-14T13:19:47Z",
    "updated": "2025-10-20T03:52:50Z",
    "link": "http://arxiv.org/pdf/2501.08102v4.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "authors": [
      "Wenlu Fan",
      "Yuqi Zhu",
      "Bin Wang",
      "Wentao Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.02649v3",
    "title": "Fully Autonomous AI Agents Should Not be Developed",
    "summary": "This paper argues that fully autonomous AI agents should not be developed. In\nsupport of this position, we build from prior scientific literature and current\nproduct marketing to delineate different AI agent levels and detail the ethical\nvalues at play in each, documenting trade-offs in potential benefits and risks.\nOur analysis reveals that risks to people increase with the autonomy of a\nsystem: The more control a user cedes to an AI agent, the more risks to people\narise. Particularly concerning are safety risks, which affect human life and\nimpact further values.",
    "published": "2025-02-04T19:00:06Z",
    "updated": "2025-10-20T03:24:44Z",
    "link": "http://arxiv.org/pdf/2502.02649v3.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Margaret Mitchell",
      "Avijit Ghosh",
      "Alexandra Sasha Luccioni",
      "Giada Pistilli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.23115v2",
    "title": "RHYTHM: Reasoning with Hierarchical Temporal Tokenization for Human\n  Mobility",
    "summary": "Predicting human mobility is inherently challenging due to complex long-range\ndependencies and multi-scale periodic behaviors. To address this, we introduce\nRHYTHM (Reasoning with Hierarchical Temporal Tokenization for Human Mobility),\na unified framework that leverages large language models (LLMs) as\ngeneral-purpose spatio-temporal predictors and trajectory reasoners.\nMethodologically, RHYTHM employs temporal tokenization to partition each\ntrajectory into daily segments and encode them as discrete tokens with\nhierarchical attention that captures both daily and weekly dependencies,\nthereby quadratically reducing the sequence length while preserving cyclical\ninformation. Additionally, we enrich token representations by adding\npre-computed prompt embeddings for trajectory segments and prediction targets\nvia a frozen LLM, and feeding these combined embeddings back into the LLM\nbackbone to capture complex interdependencies. Computationally, RHYTHM keeps\nthe pretrained LLM backbone frozen, yielding faster training and lower memory\nusage. We evaluate our model against state-of-the-art methods using three\nreal-world datasets. Notably, RHYTHM achieves a 2.4% improvement in overall\naccuracy, a 5.0% increase on weekends, and a 24.6% reduction in training time.\nCode is publicly available at https://github.com/he-h/rhythm.",
    "published": "2025-09-27T04:55:56Z",
    "updated": "2025-10-20T03:10:11Z",
    "link": "http://arxiv.org/pdf/2509.23115v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Haoyu He",
      "Haozheng Luo",
      "Yan Chen",
      "Qi R. Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17115v1",
    "title": "DVAGen: Dynamic Vocabulary Augmented Generation",
    "summary": "Language models trained with a fixed vocabulary struggle to generalize to\nnovel or out-of-vocabulary words, limiting their flexibility in handling\ndiverse token combinations. Existing dynamic vocabulary approaches attempt to\naddress this limitation but face challenges such as fragmented codebases, lack\nof support for modern LLMs, and limited inference scalability. To overcome\nthese issues, we introduce DVAGen, a fully open-source, unified framework\ndesigned for training, evaluation, and visualization of dynamic\nvocabulary-augmented language models. Our framework modularizes the pipeline\nfor ease of customization, integrates seamlessly with open-source LLMs, and is\nthe first to provide both CLI and WebUI tools for real-time result inspection.\nWe validate the effectiveness of dynamic vocabulary methods on modern LLMs and\ndemonstrate support for batch inference, significantly improving inference\nthroughput.",
    "published": "2025-10-20T03:09:24Z",
    "updated": "2025-10-20T03:09:24Z",
    "link": "http://arxiv.org/pdf/2510.17115v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Wei Du",
      "Nuowei Liu",
      "Jie Wang",
      "Jiahao Kuang",
      "Tao Ji",
      "Xiaoling Wang",
      "Yuanbin Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.13946v2",
    "title": "Visual Instruction Bottleneck Tuning",
    "summary": "Despite widespread adoption, multimodal large language models (MLLMs) suffer\nperformance degradation when encountering unfamiliar queries under distribution\nshifts. Existing methods to improve MLLM generalization typically require\neither more instruction data or larger advanced model architectures, both of\nwhich incur non-trivial human labor or computational costs. In this work, we\ntake an alternative approach to enhance the generalization and robustness of\nMLLMs under distribution shifts, from a representation learning perspective.\nInspired by information bottleneck (IB) principle, we derive a variational\nlower bound of the IB for MLLMs and devise a practical implementation, Visual\nInstruction Bottleneck Tuning (Vittle). We then provide a theoretical\njustification of Vittle by revealing its connection to an information-theoretic\nrobustness metric of MLLM. Empirical validation of multiple MLLMs on open-ended\nand closed-form question answering and object hallucination detection tasks\nover 45 datasets, including 30 shift scenarios, demonstrates that Vittle\nconsistently improves the MLLM's robustness under shifts by pursuing the\nlearning of a minimal sufficient representation.",
    "published": "2025-05-20T05:24:53Z",
    "updated": "2025-10-20T03:05:33Z",
    "link": "http://arxiv.org/pdf/2505.13946v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Changdae Oh",
      "Jiatong Li",
      "Shawn Im",
      "Sharon Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.02537v2",
    "title": "VisuRiddles: Fine-grained Perception is a Primary Bottleneck for\n  Multimodal Large Language Models in Abstract Visual Reasoning",
    "summary": "Recent strides in multimodal large language models (MLLMs) have significantly\nadvanced their performance in many reasoning tasks. However, Abstract Visual\nReasoning (AVR) remains a critical challenge, primarily due to limitations in\nperceiving abstract graphics. To tackle this issue, we investigate the\nbottlenecks in current MLLMs and synthesize training data to improve their\nabstract visual perception. First, we propose VisuRiddles, a benchmark for AVR,\nfeaturing tasks meticulously constructed to assess models' reasoning capacities\nacross five core dimensions and two high-level reasoning categories. Second, we\nintroduce the Perceptual Riddle Synthesizer (PRS), an automated framework for\ngenerating riddles with fine-grained perceptual descriptions. PRS not only\ngenerates valuable training data for abstract graphics but also provides\nfine-grained perceptual description, crucially allowing for supervision over\nintermediate reasoning stages and thereby improving both training efficacy and\nmodel interpretability. Our extensive experimental results on VisuRiddles\nempirically validate that fine-grained visual perception is the principal\nbottleneck and our synthesis framework markedly enhances the performance of\ncontemporary MLLMs on these challenging tasks. Our code and dataset will be\nreleased at https://github.com/yh-hust/VisuRiddles",
    "published": "2025-06-03T07:24:00Z",
    "updated": "2025-10-20T03:00:57Z",
    "link": "http://arxiv.org/pdf/2506.02537v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Hao Yan",
      "Handong Zheng",
      "Hao Wang",
      "Liang Yin",
      "Xingchen Liu",
      "Zhenbiao Cao",
      "Xinxing Su",
      "Zihao Chen",
      "Jihao Wu",
      "Minghui Liao",
      "Chao Weng",
      "Wei Chen",
      "Yuliang Liu",
      "Xiang Bai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17111v1",
    "title": "Efficient Vision-Language-Action Models for Embodied Manipulation: A\n  Systematic Survey",
    "summary": "Vision-Language-Action (VLA) models extend vision-language models to embodied\ncontrol by mapping natural-language instructions and visual observations to\nrobot actions. Despite their capabilities, VLA systems face significant\nchallenges due to their massive computational and memory demands, which\nconflict with the constraints of edge platforms such as on-board mobile\nmanipulators that require real-time performance. Addressing this tension has\nbecome a central focus of recent research. In light of the growing efforts\ntoward more efficient and scalable VLA systems, this survey provides a\nsystematic review of approaches for improving VLA efficiency, with an emphasis\non reducing latency, memory footprint, and training and inference costs. We\ncategorize existing solutions into four dimensions: model architecture,\nperception feature, action generation, and training/inference strategies,\nsummarizing representative techniques within each category. Finally, we discuss\nfuture trends and open challenges, highlighting directions for advancing\nefficient embodied intelligence.",
    "published": "2025-10-20T02:59:45Z",
    "updated": "2025-10-20T02:59:45Z",
    "link": "http://arxiv.org/pdf/2510.17111v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Weifan Guan",
      "Qinghao Hu",
      "Aosheng Li",
      "Jian Cheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17109v1",
    "title": "Verification-Aware Planning for Multi-Agent Systems",
    "summary": "Large language model (LLM) agents are increasingly deployed to tackle complex\ntasks, often necessitating collaboration among multiple specialized agents.\nHowever, multi-agent collaboration introduces new challenges in planning,\ncoordination, and verification. Execution failures frequently arise not from\nflawed reasoning alone, but from subtle misalignments in task interpretation,\noutput format, or inter-agent handoffs. To address these challenges, we present\nVeriMAP, a framework for multi-agent collaboration with verification-aware\nplanning. The VeriMAP planner decomposes tasks, models subtask dependencies,\nand encodes planner-defined passing criteria as subtask verification functions\n(VFs) in Python and natural language. We evaluate VeriMAP on diverse datasets,\ndemonstrating that it outperforms both single- and multi-agent baselines while\nenhancing system robustness and interpretability. Our analysis highlights how\nverification-aware planning enables reliable coordination and iterative\nrefinement in multi-agent systems, without relying on external labels or\nannotations.",
    "published": "2025-10-20T02:54:29Z",
    "updated": "2025-10-20T02:54:29Z",
    "link": "http://arxiv.org/pdf/2510.17109v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "authors": [
      "Tianyang Xu",
      "Dan Zhang",
      "Kushan Mitra",
      "Estevam Hruschka"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17108v1",
    "title": "Structured Debate Improves Corporate Credit Reasoning in Financial AI",
    "summary": "Despite advances in financial AI, the automation of evidence-based reasoning\nremains unresolved in corporate credit assessment, where qualitative\nnon-financial indicators exert decisive influence on loan repayment outcomes\nyet resist formalization. Existing approaches focus predominantly on numerical\nprediction and provide limited support for the interpretive judgments required\nin professional loan evaluation. This study develops and evaluates two\noperational large language model (LLM)-based systems designed to generate\nstructured reasoning from non-financial evidence. The first is a\nnon-adversarial single-agent system (NAS) that produces bidirectional analysis\nthrough a single-pass reasoning pipeline. The second is a debate-based\nmulti-agent system (KPD-MADS) that operationalizes adversarial verification\nthrough a ten-step structured interaction protocol grounded in Karl Popper's\ncritical dialogue framework. Both systems were applied to three real corporate\ncases and evaluated by experienced credit risk professionals. Compared to\nmanual expert reporting, both systems achieved substantial productivity gains\n(NAS: 11.55 s per case; KPD-MADS: 91.97 s; human baseline: 1920 s). The\nKPD-MADS demonstrated superior reasoning quality, receiving higher median\nratings in explanatory adequacy (4.0 vs. 3.0), practical applicability (4.0 vs.\n3.0), and usability (62.5 vs. 52.5). These findings show that structured\nmulti-agent interaction can enhance reasoning rigor and interpretability in\nfinancial AI, advancing scalable and defensible automation in corporate credit\nassessment.",
    "published": "2025-10-20T02:50:03Z",
    "updated": "2025-10-20T02:50:03Z",
    "link": "http://arxiv.org/pdf/2510.17108v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Yoonjin Lee",
      "Munhee Kim",
      "Hanbi Choi",
      "Juhyeon Park",
      "Seungho Lyoo",
      "Woojin Park"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.19700v3",
    "title": "Leveraging Importance Sampling to Detach Alignment Modules from Large\n  Language Models",
    "summary": "The widespread adoption of large language models (LLMs) across industries has\nincreased the demand for high-quality and customizable outputs. However,\ntraditional alignment methods often require retraining large pretrained models,\nmaking it difficult to quickly adapt and optimize LLMs for diverse\napplications. To address this limitation, we propose a novel \\textit{Residual\nAlignment Model} (\\textit{RAM}) that formalizes the alignment process as a type\nof importance sampling. In this framework, the unaligned upstream model serves\nas the proposal distribution, while the alignment process is framed as\nsecondary sampling based on an autoregressive alignment module that acts as an\nestimator of the importance weights. This design enables a natural detachment\nof the alignment module from the target aligned model, improving flexibility\nand scalability. Based on this model, we derive an efficient sequence-level\ntraining strategy for the alignment module, which operates independently of the\nproposal module. Additionally, we develop a resampling algorithm with iterative\ntoken-level decoding to address the common first-token latency issue in\ncomparable methods. Experimental evaluations on two leading open-source LLMs\nacross diverse tasks, including instruction following, domain adaptation, and\npreference optimization, demonstrate that our approach consistently outperforms\nbaseline models.",
    "published": "2025-05-26T08:53:02Z",
    "updated": "2025-10-20T02:29:40Z",
    "link": "http://arxiv.org/pdf/2505.19700v3.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Yi Liu",
      "Dianqing Liu",
      "Mingye Zhu",
      "Junbo Guo",
      "Yongdong Zhang",
      "Zhendong Mao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.12325v2",
    "title": "LLMTaxo: Leveraging Large Language Models for Constructing Taxonomy of\n  Factual Claims from Social Media",
    "summary": "With the rapid expansion of content on social media platforms, analyzing and\ncomprehending online discourse has become increasingly complex. This paper\nintroduces LLMTaxo, a novel framework leveraging large language models for the\nautomated construction of taxonomies of factual claims from social media by\ngenerating topics at multiple levels of granularity. The resulting hierarchical\nstructure significantly reduces redundancy and improves information\naccessibility. We also propose dedicated taxonomy evaluation metrics to enable\ncomprehensive assessment. Evaluations conducted on three diverse datasets\ndemonstrate LLMTaxo's effectiveness in producing clear, coherent, and\ncomprehensive taxonomies. Among the evaluated models, GPT-4o mini consistently\noutperforms others across most metrics. The framework's flexibility and low\nreliance on manual intervention underscore its potential for broad\napplicability.",
    "published": "2025-04-11T18:43:16Z",
    "updated": "2025-10-20T02:21:45Z",
    "link": "http://arxiv.org/pdf/2504.12325v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.SI"
    ],
    "authors": [
      "Haiqi Zhang",
      "Zhengyuan Zhu",
      "Zeyu Zhang",
      "Chengkai Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.15301v2",
    "title": "Latent Diffusion Model without Variational Autoencoder",
    "summary": "Recent progress in diffusion-based visual generation has largely relied on\nlatent diffusion models with variational autoencoders (VAEs). While effective\nfor high-fidelity synthesis, this VAE+diffusion paradigm suffers from limited\ntraining efficiency, slow inference, and poor transferability to broader vision\ntasks. These issues stem from a key limitation of VAE latent spaces: the lack\nof clear semantic separation and strong discriminative structure. Our analysis\nconfirms that these properties are crucial not only for perception and\nunderstanding tasks, but also for the stable and efficient training of latent\ndiffusion models. Motivated by this insight, we introduce SVG, a novel latent\ndiffusion model without variational autoencoders, which leverages\nself-supervised representations for visual generation. SVG constructs a feature\nspace with clear semantic discriminability by leveraging frozen DINO features,\nwhile a lightweight residual branch captures fine-grained details for\nhigh-fidelity reconstruction. Diffusion models are trained directly on this\nsemantically structured latent space to facilitate more efficient learning. As\na result, SVG enables accelerated diffusion training, supports few-step\nsampling, and improves generative quality. Experimental results further show\nthat SVG preserves the semantic and discriminative capabilities of the\nunderlying self-supervised representations, providing a principled pathway\ntoward task-general, high-quality visual representations. Code and\ninterpretations are available at https://howlin-wang.github.io/svg/.",
    "published": "2025-10-17T04:17:44Z",
    "updated": "2025-10-20T02:08:17Z",
    "link": "http://arxiv.org/pdf/2510.15301v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Minglei Shi",
      "Haolin Wang",
      "Wenzhao Zheng",
      "Ziyang Yuan",
      "Xiaoshi Wu",
      "Xintao Wang",
      "Pengfei Wan",
      "Jie Zhou",
      "Jiwen Lu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17098v1",
    "title": "Can Transformer Memory Be Corrupted? Investigating Cache-Side\n  Vulnerabilities in Large Language Models",
    "summary": "Even when prompts and parameters are secured, transformer language models\nremain vulnerable because their key-value (KV) cache during inference\nconstitutes an overlooked attack surface. This paper introduces Malicious Token\nInjection (MTI), a modular framework that systematically perturbs cached key\nvectors at selected layers and timesteps through controlled magnitude and\nfrequency, using additive Gaussian noise, zeroing, and orthogonal rotations. A\ntheoretical analysis quantifies how these perturbations propagate through\nattention, linking logit deviations to the Frobenius norm of corruption and\nsoftmax Lipschitz dynamics. Empirical results show that MTI significantly\nalters next-token distributions and downstream task performance across GPT-2\nand LLaMA-2/7B, as well as destabilizes retrieval-augmented and agentic\nreasoning pipelines. These findings identify cache integrity as a critical yet\nunderexplored vulnerability in current LLM deployments, positioning cache\ncorruption as a reproducible and theoretically grounded threat model for future\nrobustness and security research.",
    "published": "2025-10-20T02:04:18Z",
    "updated": "2025-10-20T02:04:18Z",
    "link": "http://arxiv.org/pdf/2510.17098v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Elias Hossain",
      "Swayamjit Saha",
      "Somshubhra Roy",
      "Ravi Prasad"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17088v1",
    "title": "Explainable Heterogeneous Anomaly Detection in Financial Networks via\n  Adaptive Expert Routing",
    "summary": "Financial anomalies exhibit heterogeneous mechanisms (price shocks, liquidity\nfreezes, contagion cascades, regime shifts), but existing detectors treat all\nanomalies uniformly, producing scalar scores without revealing which mechanism\nis failing, where risks concentrate, or how to intervene. This opacity prevents\ntargeted regulatory responses. Three unsolved challenges persist: (1) static\ngraph structures cannot adapt when market correlations shift during regime\nchanges; (2) uniform detection mechanisms miss type-specific signatures across\nmultiple temporal scales while failing to integrate individual behaviors with\nnetwork contagion; (3) black-box outputs provide no actionable guidance on\nanomaly mechanisms or their temporal evolution.\n  We address these via adaptive graph learning with specialized expert networks\nthat provide built-in interpretability. Our framework captures multi-scale\ntemporal dependencies through BiLSTM with self-attention, fuses temporal and\nspatial information via cross-modal attention, learns dynamic graphs through\nneural multi-source interpolation, adaptively balances learned dynamics with\nstructural priors via stress-modulated fusion, routes anomalies to four\nmechanism-specific experts, and produces dual-level interpretable attributions.\nCritically, interpretability is embedded architecturally rather than applied\npost-hoc.\n  On 100 US equities (2017-2024), we achieve 92.3% detection of 13 major events\nwith 3.8-day lead time, outperforming best baseline by 30.8pp. Silicon Valley\nBank case study demonstrates anomaly evolution tracking: Price-Shock expert\nweight rose to 0.39 (33% above baseline 0.29) during closure, peaking at 0.48\n(66% above baseline) one week later, revealing automatic temporal mechanism\nidentification without labeled supervision.",
    "published": "2025-10-20T01:30:41Z",
    "updated": "2025-10-20T01:30:41Z",
    "link": "http://arxiv.org/pdf/2510.17088v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "authors": [
      "Zan Li",
      "Rui Fan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.09919v2",
    "title": "A Markovian Framing of WaveFunctionCollapse for Procedurally Generating\n  Aesthetically Complex Environments",
    "summary": "Procedural content generation often requires satisfying both\ndesigner-specified objectives and adjacency constraints implicitly imposed by\nthe underlying tile set. To address the challenges of jointly optimizing both\nconstraints and objectives, we reformulate WaveFunctionCollapse (WFC) as a\nMarkov Decision Process (MDP), enabling external optimization algorithms to\nfocus exclusively on objective maximization while leveraging WFC's propagation\nmechanism to enforce constraint satisfaction. We empirically compare optimizing\nthis MDP to traditional evolutionary approaches that jointly optimize global\nmetrics and local tile placement. Across multiple domains with various\ndifficulties, we find that joint optimization not only struggles as task\ncomplexity increases, but consistently underperforms relative to optimization\nover the WFC-MDP, underscoring the advantages of decoupling local constraint\nsatisfaction from global objective optimization.",
    "published": "2025-09-12T01:51:01Z",
    "updated": "2025-10-20T00:47:57Z",
    "link": "http://arxiv.org/pdf/2509.09919v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Franklin Yiu",
      "Mohan Lu",
      "Nina Li",
      "Kevin Joseph",
      "Tianxu Zhang",
      "Julian Togelius",
      "Timothy Merino",
      "Sam Earle"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17064v1",
    "title": "A Brain Cell Type Resource Created by Large Language Models and a\n  Multi-Agent AI System for Collaborative Community Annotation",
    "summary": "Single-cell RNA sequencing has transformed our ability to identify diverse\ncell types and their transcriptomic signatures. However, annotating these\nsignatures-especially those involving poorly characterized genes-remains a\nmajor challenge. Traditional methods, such as Gene Set Enrichment Analysis\n(GSEA), depend on well-curated annotations and often perform poorly in these\ncontexts. Large Language Models (LLMs) offer a promising alternative but\nstruggle to represent complex biological knowledge within structured\nontologies. To address this, we present BRAINCELL-AID (BRAINCELL-AID:\nhttps://biodataai.uth.edu/BRAINCELL-AID), a novel multi-agent AI system that\nintegrates free-text descriptions with ontology labels to enable more accurate\nand robust gene set annotation. By incorporating retrieval-augmented generation\n(RAG), we developed a robust agentic workflow that refines predictions using\nrelevant PubMed literature, reducing hallucinations and enhancing\ninterpretability. Using this workflow, we achieved correct annotations for 77%\nof mouse gene sets among their top predictions. Applying this approach, we\nannotated 5,322 brain cell clusters from the comprehensive mouse brain cell\natlas generated by the BRAIN Initiative Cell Census Network, enabling novel\ninsights into brain cell function by identifying region-specific gene\nco-expression patterns and inferring functional roles of gene ensembles.\nBRAINCELL-AID also identifies Basal Ganglia-related cell types with\nneurologically meaningful descriptions. Hence, we create a valuable resource to\nsupport community-driven cell type annotation.",
    "published": "2025-10-20T00:37:55Z",
    "updated": "2025-10-20T00:37:55Z",
    "link": "http://arxiv.org/pdf/2510.17064v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Rongbin Li",
      "Wenbo Chen",
      "Zhao Li",
      "Rodrigo Munoz-Castaneda",
      "Jinbo Li",
      "Neha S. Maurya",
      "Arnav Solanki",
      "Huan He",
      "Hanwen Xing",
      "Meaghan Ramlakhan",
      "Zachary Wise",
      "Zhuhao Wu",
      "Hua Xu",
      "Michael Hawrylycz",
      "W. Jim Zheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17062v1",
    "title": "Investigating Thinking Behaviours of Reasoning-Based Language Models for\n  Social Bias Mitigation",
    "summary": "While reasoning-based large language models excel at complex tasks through an\ninternal, structured thinking process, a concerning phenomenon has emerged that\nsuch a thinking process can aggregate social stereotypes, leading to biased\noutcomes. However, the underlying behaviours of these language models in social\nbias scenarios remain underexplored. In this work, we systematically\ninvestigate mechanisms within the thinking process behind this phenomenon and\nuncover two failure patterns that drive social bias aggregation: 1) stereotype\nrepetition, where the model relies on social stereotypes as its primary\njustification, and 2) irrelevant information injection, where it fabricates or\nintroduces new details to support a biased narrative. Building on these\ninsights, we introduce a lightweight prompt-based mitigation approach that\nqueries the model to review its own initial reasoning against these specific\nfailure patterns. Experiments on question answering (BBQ and StereoSet) and\nopen-ended (BOLD) benchmarks show that our approach effectively reduces bias\nwhile maintaining or improving accuracy.",
    "published": "2025-10-20T00:33:44Z",
    "updated": "2025-10-20T00:33:44Z",
    "link": "http://arxiv.org/pdf/2510.17062v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Guoqing Luo",
      "Iffat Maab",
      "Lili Mou",
      "Junichi Yamagishi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17058v1",
    "title": "Bitwidth-Specific Logarithmic Arithmetic for Future Hardware-Accelerated\n  Training",
    "summary": "While advancements in quantization have significantly reduced the\ncomputational costs of inference in deep learning, training still predominantly\nrelies on complex floating-point arithmetic. Low-precision fixed-point training\npresents a compelling alternative. This work introduces a novel enhancement in\nlow-precision logarithmic fixed-point training, geared towards future hardware\naccelerator designs. We propose incorporating bitwidth in the design of\napproximations to arithmetic operations. To this end, we introduce a new\nhardware-friendly, piece-wise linear approximation for logarithmic addition.\nUsing simulated annealing, we optimize this approximation at different\nprecision levels. A C++ bit-true simulation demonstrates training of VGG-11 and\nVGG-16 models on CIFAR-100 and TinyImageNet, respectively, using 12-bit integer\narithmetic with minimal accuracy degradation compared to 32-bit floating-point\ntraining. Our hardware study reveals up to 32.5% reduction in area and 53.5%\nreduction in energy consumption for the proposed LNS multiply-accumulate units\ncompared to that of linear fixed-point equivalents.",
    "published": "2025-10-20T00:25:07Z",
    "updated": "2025-10-20T00:25:07Z",
    "link": "http://arxiv.org/pdf/2510.17058v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Hassan Hamad",
      "Yuou Qiu",
      "Peter A. Beerel",
      "Keith M. Chugg"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17057v1",
    "title": "The Ends Justify the Thoughts: RL-Induced Motivated Reasoning in LLMs",
    "summary": "The use of reinforcement learning (RL) with chain-of-thought (CoT) reasoning\nhas emerged as a promising approach for developing more capable language\nmodels. In turn, this has led to investigation of CoT monitoring as a\ncompelling method for detecting harmful behaviors such as reward hacking, under\nthe assumption that models' reasoning processes reflect their internal\ndecision-making. In practice, LLM training often produces unintended behaviors\ndue to imperfect reward signals, leading models to develop misaligned\ntendencies. A common corrective approach is to apply post-hoc instructions to\navoid problematic behaviors like sycophancy, but what happens to the model's\nreasoning process when these instructions conflict with learned behaviors? We\ninvestigate this question in simple settings and find that models engage in\nsystematic motivated reasoning -- generating plausible-sounding justifications\nfor violating their instructions while downplaying potential harms. Beyond\nbeing an interesting property of training, we find that while motivated\nreasoning can be detected by most frontier reasoning models, smaller LLM judges\ncan fail to identify a portion of it, and in rare cases can themselves be\npersuaded that the reasoning is correct, despite it contradicting clear\ninstructions. This capability gap raises concerns that as models become more\nsophisticated, their motivated reasoning may become increasingly difficult for\nmonitors to detect. Our results underscore the need to account for motivated\nreasoning when relying on chain-of-thought processes for model evaluation and\noversight. All code for this paper will be made available. WARNING: some\nexamples in this paper may be upsetting.",
    "published": "2025-10-20T00:24:08Z",
    "updated": "2025-10-20T00:24:08Z",
    "link": "http://arxiv.org/pdf/2510.17057v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Nikolaus Howe",
      "Micah Carroll"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.11018v3",
    "title": "GRIFFIN: Effective Token Alignment for Faster Speculative Decoding",
    "summary": "Speculative decoding accelerates inference in large language models (LLMs) by\ngenerating multiple draft tokens simultaneously. However, existing methods\noften struggle with token misalignment between the training and decoding\nphases, limiting their performance. To address this, we propose GRIFFIN, a\nnovel framework that incorporates a token-alignable training strategy and a\ntoken-alignable draft model to mitigate misalignment. The training strategy\nemploys a loss masking mechanism to exclude highly misaligned tokens during\ntraining, preventing them from negatively impacting the draft model's\noptimization. The token-alignable draft model introduces input tokens to\ncorrect inconsistencies in generated features. Experiments on LLaMA, Vicuna,\nQwen and Mixtral models demonstrate that GRIFFIN achieves an average acceptance\nlength improvement of over 8% and a speedup ratio exceeding 7%, outperforming\ncurrent speculative decoding state-of-the-art methods. Our code and GRIFFIN's\ndraft models are released publicly in https://github.com/hsj576/GRIFFIN.",
    "published": "2025-02-16T07:06:00Z",
    "updated": "2025-10-19T23:43:19Z",
    "link": "http://arxiv.org/pdf/2502.11018v3.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Shijing Hu",
      "Jingyang Li",
      "Xingyu Xie",
      "Zhihui Lu",
      "Kim-Chuan Toh",
      "Pan Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17052v1",
    "title": "ToolCritic: Detecting and Correcting Tool-Use Errors in Dialogue Systems",
    "summary": "Tool-augmented large language models (LLMs) are increasingly employed in\nreal-world applications, but tool usage errors still hinder their reliability.\nWe introduce ToolCritic, a diagnostic framework that evaluates and improves LLM\nbehavior in multi-turn, tool-augmented dialogues. ToolCritic detects eight\ndistinct error types specific to tool-calling (e.g., premature invocation,\nargument misalignment, and misinterpretation of tool outputs) and provides\ntargeted feedback to the main LLM. The main LLM, assumed to have strong\nreasoning, task understanding and orchestration capabilities, then revises its\nresponse based on ToolCritic's feedback. We systematically define these error\ncategories and construct a synthetic dataset to train ToolCritic. Experimental\nresults on the Schema-Guided Dialogue (SGD) dataset demonstrate that ToolCritic\nimproves tool-calling accuracy by up to 13% over baselines, including zero-shot\nprompting and self-correction techniques. This represents a promising step\ntoward more robust LLM integration with external tools in real-world dialogue\napplications.",
    "published": "2025-10-19T23:42:39Z",
    "updated": "2025-10-19T23:42:39Z",
    "link": "http://arxiv.org/pdf/2510.17052v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Hassan Hamad",
      "Yingru Xu",
      "Liang Zhao",
      "Wenbo Yan",
      "Narendra Gyanchandani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.02805v2",
    "title": "Beyond Uncertainty Quantification: Learning Uncertainty for\n  Trust-Informed Neural Network Decisions - A Case Study in COVID-19\n  Classification",
    "summary": "Reliable uncertainty quantification is critical in high-stakes applications,\nsuch as medical diagnosis, where confidently incorrect predictions can erode\ntrust in automated decision-making systems. Traditional uncertainty\nquantification methods rely on a predefined confidence threshold to classify\npredictions as confident or uncertain. However, this approach assumes that\npredictions exceeding the threshold are trustworthy, while those below it are\nuncertain, without explicitly assessing the correctness of high-confidence\npredictions. As a result, confidently incorrect predictions may still occur,\nleading to misleading uncertainty assessments. To address this limitation, this\nstudy proposed an uncertainty-aware stacked neural network, which extends\nconventional uncertainty quantification by learning when predictions should be\ntrusted. The framework consists of a two-tier model: the base model generates\npredictions with uncertainty estimates, while the meta-model learns to assign a\ntrust flag, distinguishing confidently correct cases from those requiring\nexpert review. The proposed approach is evaluated against the traditional\nthreshold-based method across multiple confidence thresholds and pre-trained\narchitectures using the COVIDx CXR-4 dataset. Results demonstrate that the\nproposed framework significantly reduces confidently incorrect predictions,\noffering a more trustworthy and efficient decision-support system for\nhigh-stakes domains.",
    "published": "2024-09-19T04:20:12Z",
    "updated": "2025-10-19T23:40:59Z",
    "link": "http://arxiv.org/pdf/2410.02805v2.pdf",
    "category": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "68T07"
    ],
    "authors": [
      "Hassan Gharoun",
      "Mohammad Sadegh Khorshidi",
      "Fang Chen",
      "Amir H. Gandomi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17045v1",
    "title": "Video Reasoning without Training",
    "summary": "Video reasoning using Large Multimodal Models (LMMs) relies on costly\nreinforcement learning (RL) and verbose chain-of-thought, resulting in\nsubstantial computational overhead during both training and inference.\nMoreover, the mechanisms that control the thinking process in these reasoning\nmodels are very limited. In this paper, using entropy of the model's output as\na signal, we discover that the high-quality models go through a series of\nmicro-explorations and micro-exploitations which keep the reasoning process\ngrounded (i.e., avoid excessive randomness while the model is exploring or\nthinking through an answer). We further observe that once this \"thinking\"\nprocess is over, more accurate models demonstrate a better convergence by\nreducing the entropy significantly via a final exploitation phase (i.e., a more\ncertain convergence towards a solution trajectory). We then use these novel,\ntheoretically-grounded insights to tune the model's behavior directly at\ninference, without using any RL or supervised fine-tuning. Specifically, during\ninference, our proposed approach called V-Reason (Video-Reason) adapts the\nvalue cache of the LMM via a few optimization steps on a small, trainable\ncontroller using an entropy-based objective, i.e., no supervision from any\ndataset or RL is necessary. This tuning improves the model's micro-exploration\nand exploitation behavior during inference. Our experiments show that our\nproposed method achieves significant improvements over the base\ninstruction-tuned models across several video reasoning datasets, narrowing the\ngap with RL-trained models to within 0.6% average accuracy without any\ntraining, while offering massive efficiency benefits: output tokens are reduced\nby 58.6% compared to the RL model.",
    "published": "2025-10-19T23:17:13Z",
    "updated": "2025-10-19T23:17:13Z",
    "link": "http://arxiv.org/pdf/2510.17045v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Deepak Sridhar",
      "Kartikeya Bhardwaj",
      "Jeya Pradha Jeyaraj",
      "Nuno Vasconcelos",
      "Ankita Nayak",
      "Harris Teague"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.09702v2",
    "title": "Creativity Benchmark: A benchmark for marketing creativity for large\n  language models",
    "summary": "We introduce Creativity Benchmark, an evaluation framework for large language\nmodels (LLMs) in marketing creativity. The benchmark covers 100 brands (12\ncategories) and three prompt types (Insights, Ideas, Wild Ideas). Human\npairwise preferences from 678 practising creatives over 11,012 anonymised\ncomparisons, analysed with Bradley-Terry models, show tightly clustered\nperformance with no model dominating across brands or prompt types: the\ntop-bottom spread is $\\Delta\\theta \\approx 0.45$, which implies a head-to-head\nwin probability of $0.61$; the highest-rated model beats the lowest only about\n$61\\%$ of the time. We also analyse model diversity using cosine distances to\ncapture intra- and inter-model variation and sensitivity to prompt reframing.\nComparing three LLM-as-judge setups with human rankings reveals weak,\ninconsistent correlations and judge-specific biases, underscoring that\nautomated judges cannot substitute for human evaluation. Conventional\ncreativity tests also transfer only partially to brand-constrained tasks.\nOverall, the results highlight the need for expert human evaluation and\ndiversity-aware workflows.",
    "published": "2025-09-05T04:44:29Z",
    "updated": "2025-10-19T23:04:13Z",
    "link": "http://arxiv.org/pdf/2509.09702v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "authors": [
      "Ninad Bhat",
      "Kieran Browne",
      "Pip Bingemann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17038v1",
    "title": "DINO-CVA: A Multimodal Goal-Conditioned Vision-to-Action Model for\n  Autonomous Catheter Navigation",
    "summary": "Cardiac catheterization remains a cornerstone of minimally invasive\ninterventions, yet it continues to rely heavily on manual operation. Despite\nadvances in robotic platforms, existing systems are predominantly follow-leader\nin nature, requiring continuous physician input and lacking intelligent\nautonomy. This dependency contributes to operator fatigue, more radiation\nexposure, and variability in procedural outcomes. This work moves towards\nautonomous catheter navigation by introducing DINO-CVA, a multimodal\ngoal-conditioned behavior cloning framework. The proposed model fuses visual\nobservations and joystick kinematics into a joint embedding space, enabling\npolicies that are both vision-aware and kinematic-aware. Actions are predicted\nautoregressively from expert demonstrations, with goal conditioning guiding\nnavigation toward specified destinations. A robotic experimental setup with a\nsynthetic vascular phantom was designed to collect multimodal datasets and\nevaluate performance. Results show that DINO-CVA achieves high accuracy in\npredicting actions, matching the performance of a kinematics-only baseline\nwhile additionally grounding predictions in the anatomical environment. These\nfindings establish the feasibility of multimodal, goal-conditioned\narchitectures for catheter navigation, representing an important step toward\nreducing operator dependency and improving the reliability of catheterbased\ntherapies.",
    "published": "2025-10-19T22:59:32Z",
    "updated": "2025-10-19T22:59:32Z",
    "link": "http://arxiv.org/pdf/2510.17038v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Pedram Fekri",
      "Majid Roshanfar",
      "Samuel Barbeau",
      "Seyedfarzad Famouri",
      "Thomas Looi",
      "Dale Podolsky",
      "Mehrdad Zadeh",
      "Javad Dargahi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.02593v4",
    "title": "Robust Pan-Cancer Mitotic Figure Detection with YOLOv12",
    "summary": "Mitotic figures represent a key histoprognostic feature in tumor pathology,\nproviding crucial insights into tumor aggressiveness and proliferation.\nHowever, their identification remains challenging, subject to significant\ninter-observer variability, even among experienced pathologists. To address\nthis issue, the MItosis DOmain Generalization (MIDOG) 2025 challenge marks the\nthird edition of an international competition aiming to develop robust mitosis\ndetection algorithms. In this paper, we present a mitotic figure detection\napproach based on the state-of-the-art YOLOv12 object detection architecture.\nOur method achieved an F1-score of 0.801 on the preliminary test set (hotspots\nonly) and ranked second on the final test leaderboard with an F1-score of\n0.7216 across complex and heterogeneous whole-slide regions, without relying on\nexternal data.",
    "published": "2025-08-29T08:37:46Z",
    "updated": "2025-10-19T22:49:24Z",
    "link": "http://arxiv.org/pdf/2509.02593v4.pdf",
    "category": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "RaphaÃ«l Bourgade",
      "Guillaume Balezo",
      "Hana Feki",
      "Lily Monier",
      "Matthieu Blons",
      "Alice Blondel",
      "Delphine Loussouarn",
      "Anne Vincent-Salomon",
      "Thomas Walter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.06493v3",
    "title": "System Prompt Poisoning: Persistent Attacks on Large Language Models\n  Beyond User Injection",
    "summary": "Large language models (LLMs) have gained widespread adoption across diverse\napplications due to their impressive generative capabilities. Their\nplug-and-play nature enables both developers and end users to interact with\nthese models through simple prompts. However, as LLMs become more integrated\ninto various systems in diverse domains, concerns around their security are\ngrowing. Existing studies mainly focus on threats arising from user prompts\n(e.g. prompt injection attack) and model output (e.g. model inversion attack),\nwhile the security of system prompts remains largely overlooked. This work\nbridges the critical gap. We introduce system prompt poisoning, a new attack\nvector against LLMs that, unlike traditional user prompt injection, poisons\nsystem prompts hence persistently impacts all subsequent user interactions and\nmodel responses. We systematically investigate four practical attack strategies\nin various poisoning scenarios. Through demonstration on both generative and\nreasoning LLMs, we show that system prompt poisoning is highly feasible without\nrequiring jailbreak techniques, and effective across a wide range of tasks,\nincluding those in mathematics, coding, logical reasoning, and natural language\nprocessing. Importantly, our findings reveal that the attack remains effective\neven when user prompts employ advanced prompting techniques like\nchain-of-thought (CoT). We also show that such techniques, including CoT and\nretrieval-augmentation-generation (RAG), which are proven to be effective for\nimproving LLM performance in a wide range of tasks, are significantly weakened\nin their effectiveness by system prompt poisoning.",
    "published": "2025-05-10T02:31:26Z",
    "updated": "2025-10-19T22:05:02Z",
    "link": "http://arxiv.org/pdf/2505.06493v3.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Zongze Li",
      "Jiawei Guo",
      "Haipeng Cai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17022v1",
    "title": "Curiosity-driven RL for symbolic equation solving",
    "summary": "We explore if RL can be useful for symbolic mathematics. Previous work showed\ncontrastive learning can solve linear equations in one variable. We show\nmodel-free PPO \\cite{schulman2017proximal} augmented with curiosity-based\nexploration and graph-based actions can solve nonlinear equations such as those\ninvolving radicals, exponentials, and trig functions. Our work suggests\ncuriosity-based exploration may be useful for general symbolic reasoning tasks.",
    "published": "2025-10-19T22:04:57Z",
    "updated": "2025-10-19T22:04:57Z",
    "link": "http://arxiv.org/pdf/2510.17022v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Kevin P. O Keeffe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.13636v2",
    "title": "Incentivizing Truthful Language Models via Peer Elicitation Games",
    "summary": "Large Language Models (LLMs) have demonstrated strong generative capabilities\nbut remain prone to inconsistencies and hallucinations. We introduce Peer\nElicitation Games (PEG), a training-free, game-theoretic framework for aligning\nLLMs through a peer elicitation mechanism involving a generator and multiple\ndiscriminators instantiated from distinct base models. Discriminators interact\nin a peer evaluation setting, where utilities are computed using a\ndeterminant-based mutual information score that provably incentivizes truthful\nreporting without requiring ground-truth labels. We establish theoretical\nguarantees showing that each agent, via online learning, achieves sublinear\nregret in the sense their cumulative performance approaches that of the best\nfixed truthful strategy in hindsight. Moreover, we prove last-iterate\nconvergence to a truthful Nash equilibrium, ensuring that the actual policies\nused by agents converge to stable and truthful behavior over time. Empirical\nevaluations across multiple benchmarks demonstrate significant improvements in\nfactual accuracy. These results position PEG as a practical approach for\neliciting truthful behavior from LLMs without supervision or fine-tuning.",
    "published": "2025-05-19T18:16:58Z",
    "updated": "2025-10-19T21:36:32Z",
    "link": "http://arxiv.org/pdf/2505.13636v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.GT"
    ],
    "authors": [
      "Baiting Chen",
      "Tong Zhu",
      "Jiale Han",
      "Lexin Li",
      "Gang Li",
      "Xiaowu Dai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17015v1",
    "title": "Justitia: Fair and Efficient Scheduling for LLM Applications",
    "summary": "In the era of Large Language Models (LLMs), it has been popular to launch a\nseries of LLM inferences -- we call an LLM application -- to better solve\nreal-world problems. When serving those applications in shared GPU servers, the\nschedulers are expected to attain fast application completions with guaranteed\nworst-case performance. However, mainstream LLM schedulers fail to behave well\nfor LLM applications -- due to head-of-line blocking or over-constrained\nresource allocation. In this paper, we propose to serve LLM applications in a\nfair and also efficient manner. To this end, we design Justitia, a novel\nscheduler with three key techniques. First, given that memory is prevalently a\nbottleneck for mainstream inference frameworks like vLLM, Justitia models the\nservice cost of LLM applications in a memory-centric manner. Meanwhile, it uses\na simple neural network model to conduct light-weight and also accurate demand\nprediction. Moreover, Justitia adopts a virtual-time based fair queuing\nalgorithm to reduce the overall performance with guaranteed worst-case delay.\nWe have implemented Justitia atop vLLM, and experimental results involving\ndiverse LLM applications show that it can substantially enhance the scheduling\nefficiency with fairness preserved.",
    "published": "2025-10-19T21:34:34Z",
    "updated": "2025-10-19T21:34:34Z",
    "link": "http://arxiv.org/pdf/2510.17015v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "authors": [
      "Mingyan Yang",
      "Guanjie Wang",
      "Manqi Luo",
      "Yifei Liu",
      "Chen Chen",
      "Han Zhao",
      "Yu Feng",
      "Quan Chen",
      "Minyi Guo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.21077v2",
    "title": "Efficient Large Language Model Inference with Neural Block Linearization",
    "summary": "The high inference demands of transformer-based Large Language Models (LLMs)\npose substantial challenges in their deployment. To this end, we introduce\nNeural Block Linearization (NBL), a novel framework for accelerating\ntransformer model inference by replacing self-attention layers with linear\napproximations derived from Linear Minimum Mean Squared Error estimators. NBL\nleverages Canonical Correlation Analysis to compute a theoretical upper bound\non the approximation error. Then, we use this bound as a criterion for\nsubstitution, selecting the LLM layers with the lowest linearization error. NBL\ncan be efficiently applied to pre-trained LLMs without the need for\nfine-tuning. In experiments, NBL achieves notable computational speed-ups while\npreserving competitive accuracy on multiple reasoning benchmarks. For instance,\napplying NBL to 12 self-attention layers in DeepSeek-R1-Distill-Llama-8B\nincreases the inference speed by 32% with less than 1% accuracy trade-off,\nmaking it a flexible and promising solution to improve the inference efficiency\nof LLMs. The implementation is available at: https://github.com/LIONS-EPFL/NBL.",
    "published": "2025-05-27T12:01:43Z",
    "updated": "2025-10-19T21:33:03Z",
    "link": "http://arxiv.org/pdf/2505.21077v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Mete Erdogan",
      "Francesco Tonin",
      "Volkan Cevher"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.00222v4",
    "title": "RL-PLUS: Countering Capability Boundary Collapse of LLMs in\n  Reinforcement Learning with Hybrid-policy Optimization",
    "summary": "Reinforcement Learning with Verifiable Reward (RLVR) has significantly\nadvanced the complex reasoning abilities of Large Language Models (LLMs).\nHowever, it struggles to break through the inherent capability boundaries of\nthe base LLM, due to its essentially on-policy strategy coupled with LLM's\nimmense action space and sparse reward. Critically, RLVR can lead to the\ncapability boundary collapse, narrowing the LLM's problem-solving scope. To\naddress this problem, we propose RL-PLUS, a novel hybrid-policy optimization\napproach for LLMs that synergizes internal exploitation with external data to\nachieve stronger reasoning capabilities and surpass the boundaries of base\nmodels. RL-PLUS integrates two core components, i.e., Multiple Importance\nSampling to address distributional mismatch from external data, and\nExploration-Based Advantage Function to guide the model towards high-value,\nunexplored reasoning paths. We provide both theoretical analysis and extensive\nexperiments to demonstrate the superiority and generalizability of our\napproach. Compared with existing RLVR methods, RL-PLUS achieves 1)\nstate-of-the-art performance on six math reasoning benchmarks; 2) superior\nperformance on six out-of-distribution reasoning tasks; 3) consistent and\nsignificant gains across diverse model families, with average relative\nimprovements up to 69.2\\%. Moreover, the analysis of Pass@k curves indicates\nthat RL-PLUS effectively resolves the capability boundary collapse problem.",
    "published": "2025-07-31T23:55:29Z",
    "updated": "2025-10-19T21:24:26Z",
    "link": "http://arxiv.org/pdf/2508.00222v4.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Yihong Dong",
      "Xue Jiang",
      "Yongding Tao",
      "Huanyu Liu",
      "Kechi Zhang",
      "Lili Mou",
      "Rongyu Cao",
      "Yingwei Ma",
      "Jue Chen",
      "Binhua Li",
      "Zhi Jin",
      "Fei Huang",
      "Yongbin Li",
      "Ge Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.03304v3",
    "title": "Harmony in Divergence: Towards Fast, Accurate, and Memory-efficient\n  Zeroth-order LLM Fine-tuning",
    "summary": "Large language models (LLMs) excel across various tasks, but standard\nfirst-order (FO) fine-tuning demands considerable memory, significantly\nlimiting real-world deployment. Recently, zeroth-order (ZO) optimization stood\nout as a promising memory-efficient training paradigm, avoiding backward passes\nand relying solely on forward passes for gradient estimation, making it\nattractive for resource-constrained scenarios. However, ZO method lags far\nbehind FO method in both convergence speed and accuracy. To bridge the gap, we\nintroduce a novel layer-wise divergence analysis that uncovers the distinct\nupdate pattern of FO and ZO optimization. Aiming to resemble the learning\ncapacity of FO method from the findings, we propose Divergence-driven\nZeroth-Order (DiZO) optimization. DiZO conducts divergence-driven layer\nadaptation by incorporating projections to ZO updates, generating\ndiverse-magnitude updates precisely scaled to layer-wise individual\noptimization needs. Our results demonstrate that DiZO significantly reduces the\nneeded iterations for convergence without sacrificing throughput, cutting\ntraining GPU hours by up to 48\\% on various datasets. Moreover, DiZO\nconsistently outperforms the representative ZO baselines in fine-tuning\nRoBERTa-large, OPT-series, and Llama-series on downstream tasks and, in some\ncases, even surpasses memory-intensive FO fine-tuning. Our code is released at\nhttps://github.com/Skilteee/DiZO.",
    "published": "2025-02-05T16:03:17Z",
    "updated": "2025-10-19T21:23:47Z",
    "link": "http://arxiv.org/pdf/2502.03304v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Qitao Tan",
      "Jun Liu",
      "Zheng Zhan",
      "Caiwei Ding",
      "Yanzhi Wang",
      "Xiaolong Ma",
      "Jaewoo Lee",
      "Jin Lu",
      "Geng Yuan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17004v1",
    "title": "ReclAIm: A multi-agent framework for degradation-aware performance\n  tuning of medical imaging AI",
    "summary": "Ensuring the long-term reliability of AI models in clinical practice requires\ncontinuous performance monitoring and corrective actions when degradation\noccurs. Addressing this need, this manuscript presents ReclAIm, a multi-agent\nframework capable of autonomously monitoring, evaluating, and fine-tuning\nmedical image classification models. The system, built on a large language\nmodel core, operates entirely through natural language interaction, eliminating\nthe need for programming expertise. ReclAIm successfully trains, evaluates, and\nmaintains consistent performance of models across MRI, CT, and X-ray datasets.\nOnce ReclAIm detects significant performance degradation, it autonomously\nexecutes state-of-the-art fine-tuning procedures that substantially reduce the\nperformance gap. In cases with performance drops of up to -41.1% (MRI\nInceptionV3), ReclAIm managed to readjust performance metrics within 1.5% of\nthe initial model results. ReclAIm enables automated, continuous maintenance of\nmedical imaging AI models in a user-friendly and adaptable manner that\nfacilitates broader adoption in both research and clinical environments.",
    "published": "2025-10-19T21:02:01Z",
    "updated": "2025-10-19T21:02:01Z",
    "link": "http://arxiv.org/pdf/2510.17004v1.pdf",
    "category": [
      "cs.MA",
      "cs.AI"
    ],
    "authors": [
      "Eleftherios Tzanis",
      "Michail E. Klontzas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.10435v2",
    "title": "From Sequence to Structure: Uncovering Substructure Reasoning in\n  Transformers",
    "summary": "Recent studies suggest that large language models (LLMs) possess the\ncapability to solve graph reasoning tasks. Notably, even when graph structures\nare embedded within textual descriptions, LLMs can still effectively answer\nrelated questions. This raises a fundamental question: How can a decoder-only\nTransformer architecture understand underlying graph structures? To address\nthis, we start with the substructure extraction task, interpreting the inner\nmechanisms inside the transformers and analyzing the impact of the input\nqueries. Specifically, through both empirical results and theoretical analysis,\nwe present Induced Substructure Filtration (ISF), a perspective that captures\nthe substructure identification in the multi-layer transformers. We further\nvalidate the ISF process in LLMs, revealing consistent internal dynamics across\nlayers. Building on these insights, we explore the broader capabilities of\nTransformers in handling diverse graph types. Specifically, we introduce the\nconcept of thinking in substructures to efficiently extract complex composite\npatterns, and demonstrate that decoder-only Transformers can successfully\nextract substructures from attributed graphs, such as molecular graphs.\nTogether, our findings offer a new insight on how sequence-based Transformers\nperform the substructure extraction task over graph data.",
    "published": "2025-07-11T17:36:24Z",
    "updated": "2025-10-19T20:56:59Z",
    "link": "http://arxiv.org/pdf/2507.10435v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Xinnan Dai",
      "Kai Yang",
      "Jay Revolinsky",
      "Kai Guo",
      "Aoran Wang",
      "Bohang Zhang",
      "Jiliang Tang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.16996v1",
    "title": "STARK: Strategic Team of Agents for Refining Kernels",
    "summary": "The efficiency of GPU kernels is central to the progress of modern AI, yet\noptimizing them remains a difficult and labor-intensive task due to complex\ninteractions between memory hierarchies, thread scheduling, and\nhardware-specific characteristics. While recent advances in large language\nmodels (LLMs) provide new opportunities for automated code generation, existing\napproaches largely treat LLMs as single-shot generators or naive refinement\ntools, limiting their effectiveness in navigating the irregular kernel\noptimization landscape. We introduce an LLM agentic framework for GPU kernel\noptimization that systematically explores the design space through multi-agent\ncollaboration, grounded instruction, dynamic context management, and strategic\nsearch. This framework mimics the workflow of expert engineers, enabling LLMs\nto reason about hardware trade-offs, incorporate profiling feedback, and refine\nkernels iteratively. We evaluate our approach on KernelBench, a benchmark for\nLLM-based kernel optimization, and demonstrate substantial improvements over\nbaseline agents: our system produces correct solutions where baselines often\nfail, and achieves kernels with up to 16x faster runtime performance. These\nresults highlight the potential of agentic LLM frameworks to advance fully\nautomated, scalable GPU kernel optimization.",
    "published": "2025-10-19T20:41:46Z",
    "updated": "2025-10-19T20:41:46Z",
    "link": "http://arxiv.org/pdf/2510.16996v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Juncheng Dong",
      "Yang Yang",
      "Tao Liu",
      "Yang Wang",
      "Feng Qi",
      "Vahid Tarokh",
      "Kaushik Rangadurai",
      "Shuang Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.02348v2",
    "title": "mini-vec2vec: Scaling Universal Geometry Alignment with Linear\n  Transformations",
    "summary": "We build upon vec2vec, a procedure designed to align text embedding spaces\nwithout parallel data. vec2vec finds a near-perfect alignment, but it is\nexpensive and unstable. We present mini-vec2vec, a simple and efficient\nalternative that requires substantially lower computational cost and is highly\nrobust. Moreover, the learned mapping is a linear transformation. Our method\nconsists of three main stages: a tentative matching of pseudo-parallel\nembedding vectors, transformation fitting, and iterative refinement. Our linear\nalternative exceeds the original instantiation of vec2vec by orders of\nmagnitude in efficiency, while matching or exceeding their results. The\nmethod's stability and interpretable algorithmic steps facilitate scaling and\nunlock new opportunities for adoption in new domains and fields.",
    "published": "2025-09-27T12:25:33Z",
    "updated": "2025-10-19T20:41:43Z",
    "link": "http://arxiv.org/pdf/2510.02348v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Guy Dar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.10189v2",
    "title": "Formally Verified Certification of Unsolvability of Temporal Planning\n  Problems",
    "summary": "We present an approach to unsolvability certification of temporal planning.\nOur approach is based on encoding the planning problem into a network of timed\nautomata, and then using an efficient model checker on the network followed by\na certificate checker to certify the output of the model checker. Our approach\nprioritises trustworthiness of the certification: we formally verify our\nimplementation of the encoding to timed automata using the theorem prover\nIsabelle/HOL and we use an existing certificate checker (also formally verified\nin Isabelle/HOL) to certify the model checking result.",
    "published": "2025-10-11T11:57:25Z",
    "updated": "2025-10-19T20:32:53Z",
    "link": "http://arxiv.org/pdf/2510.10189v2.pdf",
    "category": [
      "cs.LO",
      "cs.AI"
    ],
    "authors": [
      "David Wang",
      "Mohammad Abdulaziz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.16988v1",
    "title": "CARE: Contrastive Alignment for ADL Recognition from Event-Triggered\n  Sensor Streams",
    "summary": "The recognition of Activities of Daily Living (ADLs) from event-triggered\nambient sensors is an essential task in Ambient Assisted Living, yet existing\nmethods remain constrained by representation-level limitations. Sequence-based\napproaches preserve temporal order of sensor activations but are sensitive to\nnoise and lack spatial awareness, while image-based approaches capture global\npatterns and implicit spatial correlations but compress fine-grained temporal\ndynamics and distort sensor layouts. Naive fusion (e.g., feature concatenation)\nfail to enforce alignment between sequence- and image-based representation\nviews, underutilizing their complementary strengths. We propose Contrastive\nAlignment for ADL Recognition from Event-Triggered Sensor Streams (CARE), an\nend-to-end framework that jointly optimizes representation learning via\nSequence-Image Contrastive Alignment (SICA) and classification via\ncross-entropy, ensuring both cross-representation alignment and task-specific\ndiscriminability. CARE integrates (i) time-aware, noise-resilient sequence\nencoding with (ii) spatially-informed and frequency-sensitive image\nrepresentations, and employs (iii) a joint contrastive-classification objective\nfor end-to-end learning of aligned and discriminative embeddings. Evaluated on\nthree CASAS datasets, CARE achieves state-of-the-art performance (89.8% on\nMilan, 88.9% on Cairo, and 73.3% on Kyoto7) and demonstrates robustness to\nsensor malfunctions and layout variability, highlighting its potential for\nreliable ADL recognition in smart homes.",
    "published": "2025-10-19T20:11:12Z",
    "updated": "2025-10-19T20:11:12Z",
    "link": "http://arxiv.org/pdf/2510.16988v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Junhao Zhao",
      "Zishuai Liu",
      "Ruili Fang",
      "Jin Lu",
      "Linghan Zhang",
      "Fei Dou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.16985v1",
    "title": "Parameter-Efficient Fine-Tuning for Low-Resource Languages: A\n  Comparative Study of LLMs for Bengali Hate Speech Detection",
    "summary": "Bengali social media platforms have witnessed a sharp increase in hate\nspeech, disproportionately affecting women and adolescents. While datasets such\nas BD-SHS provide a basis for structured evaluation, most prior approaches rely\non either computationally costly full-model fine-tuning or proprietary APIs.\nThis paper presents the first application of Parameter-Efficient Fine-Tuning\n(PEFT) for Bengali hate speech detection using LoRA and QLoRA. Three\ninstruction-tuned large language models - Gemma-3-4B, Llama-3.2-3B, and\nMistral-7B - were fine-tuned on the BD-SHS dataset of 50,281 annotated\ncomments. Each model was adapted by training fewer than 1% of its parameters,\nenabling experiments on a single consumer-grade GPU. The results show that\nLlama-3.2-3B achieved the highest F1-score of 92.23%, followed by Mistral-7B at\n88.94% and Gemma-3-4B at 80.25%. These findings establish PEFT as a practical\nand replicable strategy for Bengali and related low-resource languages.",
    "published": "2025-10-19T20:03:22Z",
    "updated": "2025-10-19T20:03:22Z",
    "link": "http://arxiv.org/pdf/2510.16985v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Akif Islam",
      "Mohd Ruhul Ameen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.14544v3",
    "title": "Smart Traffic Signals: Comparing MARL and Fixed-Time Strategies",
    "summary": "Urban traffic congestion, particularly at intersections, significantly\nimpacts travel time, fuel consumption, and emissions. Traditional fixed-time\nsignal control systems often lack the adaptability to manage dynamic traffic\npatterns effectively. This study explores the application of multi-agent\nreinforcement learning (MARL) to optimize traffic signal coordination across\nmultiple intersections within a simulated environment. Utilizing Pygame, a\nsimulation was developed to model a network of interconnected intersections\nwith randomly generated vehicle flows to reflect realistic traffic variability.\nA decentralized MARL controller was implemented, in which each traffic signal\noperates as an autonomous agent, making decisions based on local observations\nand information from neighboring agents. Performance was evaluated against a\nbaseline fixed-time controller using metrics such as average vehicle wait time\nand overall throughput. The MARL approach demonstrated statistically\nsignificant improvements, including reduced average waiting times and improved\nthroughput. These findings suggest that MARL-based dynamic control strategies\nhold substantial promise for improving urban traffic management efficiency.\nMore research is recommended to address scalability and real-world\nimplementation challenges.",
    "published": "2025-05-20T15:59:44Z",
    "updated": "2025-10-19T20:02:36Z",
    "link": "http://arxiv.org/pdf/2505.14544v3.pdf",
    "category": [
      "cs.AI",
      "cs.MA"
    ],
    "authors": [
      "Saahil Mahato"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.16983v1",
    "title": "One-step Diffusion Models with Bregman Density Ratio Matching",
    "summary": "Diffusion and flow models achieve high generative quality but remain\ncomputationally expensive due to slow multi-step sampling. Distillation methods\naccelerate them by training fast student generators, yet most existing\nobjectives lack a unified theoretical foundation. In this work, we propose\nDi-Bregman, a compact framework that formulates diffusion distillation as\nBregman divergence-based density-ratio matching. This convex-analytic view\nconnects several existing objectives through a common lens. Experiments on\nCIFAR-10 and text-to-image generation demonstrate that Di-Bregman achieves\nimproved one-step FID over reverse-KL distillation and maintains high visual\nfidelity compared to the teacher model. Our results highlight Bregman\ndensity-ratio matching as a practical and theoretically-grounded route toward\nefficient one-step diffusion generation.",
    "published": "2025-10-19T20:00:54Z",
    "updated": "2025-10-19T20:00:54Z",
    "link": "http://arxiv.org/pdf/2510.16983v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Yuanzhi Zhu",
      "Eleftherios Tsonis",
      "Lucas Degeorge",
      "Vicky Kalogeiton"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.19504v2",
    "title": "DOGe: Defensive Output Generation for LLM Protection Against Knowledge\n  Distillation",
    "summary": "Large Language Models (LLMs) represent substantial intellectual and economic\ninvestments, yet their effectiveness can inadvertently facilitate model\nimitation via knowledge distillation (KD). In practical scenarios, competitors\ncan distill proprietary LLM capabilities by simply observing publicly\naccessible outputs, akin to reverse-engineering a complex performance by\nobservation alone. Existing protective methods like watermarking only identify\nimitation post-hoc, while other defenses assume the student model mimics the\nteacher's internal logits, rendering them ineffective against distillation\npurely from observed output text. This paper confronts the challenge of\nactively protecting LLMs within the realistic constraints of API-based access.\nWe introduce an effective and efficient Defensive Output Generation (DOGe)\nstrategy that subtly modifies the output behavior of an LLM. Its outputs are\naccurate and useful for legitimate users, yet are designed to be misleading for\ndistillation, significantly undermining imitation attempts. We achieve this by\nfine-tuning only the final linear layer of the teacher LLM with an adversarial\nloss. This targeted training approach anticipates and disrupts distillation\nattempts during inference time. Our experiments show that, while preserving the\nperformance of the teacher model, student models distilled from the defensively\ngenerated outputs demonstrate catastrophically reduced performance,\ndemonstrating DOGe as a practical safeguard against KD-based model imitation.",
    "published": "2025-05-26T04:31:38Z",
    "updated": "2025-10-19T19:50:11Z",
    "link": "http://arxiv.org/pdf/2505.19504v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Pingzhi Li",
      "Zhen Tan",
      "Mohan Zhang",
      "Huaizhi Qu",
      "Huan Liu",
      "Tianlong Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.10807v4",
    "title": "HardNet: Hard-Constrained Neural Networks with Universal Approximation\n  Guarantees",
    "summary": "Incorporating prior knowledge or specifications of input-output relationships\ninto machine learning models has attracted significant attention, as it\nenhances generalization from limited data and yields conforming outputs.\nHowever, most existing approaches use soft constraints by penalizing violations\nthrough regularization, which offers no guarantee of constraint satisfaction,\nespecially on inputs far from the training distribution--an essential\nrequirement in safety-critical applications. On the other hand, imposing hard\nconstraints on neural networks may hinder their representational power,\nadversely affecting performance. To address this, we propose HardNet, a\npractical framework for constructing neural networks that inherently satisfy\nhard constraints without sacrificing model capacity. Unlike approaches that\nmodify outputs only at inference time, HardNet enables end-to-end training with\nhard constraint guarantees, leading to improved performance. To the best of our\nknowledge, HardNet is the first method that enables efficient and\ndifferentiable enforcement of more than one input-dependent inequality\nconstraint. It allows unconstrained optimization of the network parameters\nusing standard algorithms by appending a differentiable closed-form enforcement\nlayer to the network's output. Furthermore, we show that HardNet retains neural\nnetworks' universal approximation capabilities. We demonstrate its versatility\nand effectiveness across various applications: learning with piecewise\nconstraints, learning optimization solvers with guaranteed feasibility, and\noptimizing control policies in safety-critical systems.",
    "published": "2024-10-14T17:59:24Z",
    "updated": "2025-10-19T19:34:07Z",
    "link": "http://arxiv.org/pdf/2410.10807v4.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "authors": [
      "Youngjae Min",
      "Navid Azizan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.16973v1",
    "title": "Foundation Models in Medical Image Analysis: A Systematic Review and\n  Meta-Analysis",
    "summary": "Recent advancements in artificial intelligence (AI), particularly foundation\nmodels (FMs), have revolutionized medical image analysis, demonstrating strong\nzero- and few-shot performance across diverse medical imaging tasks, from\nsegmentation to report generation. Unlike traditional task-specific AI models,\nFMs leverage large corpora of labeled and unlabeled multimodal datasets to\nlearn generalized representations that can be adapted to various downstream\nclinical applications with minimal fine-tuning. However, despite the rapid\nproliferation of FM research in medical imaging, the field remains fragmented,\nlacking a unified synthesis that systematically maps the evolution of\narchitectures, training paradigms, and clinical applications across modalities.\nTo address this gap, this review article provides a comprehensive and\nstructured analysis of FMs in medical image analysis. We systematically\ncategorize studies into vision-only and vision-language FMs based on their\narchitectural foundations, training strategies, and downstream clinical tasks.\nAdditionally, a quantitative meta-analysis of the studies was conducted to\ncharacterize temporal trends in dataset utilization and application domains. We\nalso critically discuss persistent challenges, including domain adaptation,\nefficient fine-tuning, computational constraints, and interpretability along\nwith emerging solutions such as federated learning, knowledge distillation, and\nadvanced prompting. Finally, we identify key future research directions aimed\nat enhancing the robustness, explainability, and clinical integration of FMs,\nthereby accelerating their translation into real-world medical practice.",
    "published": "2025-10-19T19:19:23Z",
    "updated": "2025-10-19T19:19:23Z",
    "link": "http://arxiv.org/pdf/2510.16973v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "physics.med-ph"
    ],
    "authors": [
      "Praveenbalaji Rajendran",
      "Mojtaba Safari",
      "Wenfeng He",
      "Mingzhe Hu",
      "Shansong Wang",
      "Jun Zhou",
      "Xiaofeng Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.16968v1",
    "title": "Leave It to the Experts: Detecting Knowledge Distillation via MoE Expert\n  Signatures",
    "summary": "Knowledge Distillation (KD) accelerates training of large language models\n(LLMs) but poses intellectual property protection and LLM diversity risks.\nExisting KD detection methods based on self-identity or output similarity can\nbe easily evaded through prompt engineering. We present a KD detection\nframework effective in both white-box and black-box settings by exploiting an\noverlooked signal: the transfer of MoE \"structural habits\", especially internal\nrouting patterns. Our approach analyzes how different experts specialize and\ncollaborate across various inputs, creating distinctive fingerprints that\npersist through the distillation process. To extend beyond the white-box setup\nand MoE architectures, we further propose Shadow-MoE, a black-box method that\nconstructs proxy MoE representations via auxiliary distillation to compare\nthese patterns between arbitrary model pairs. We establish a comprehensive,\nreproducible benchmark that offers diverse distilled checkpoints and an\nextensible framework to facilitate future research. Extensive experiments\ndemonstrate >94% detection accuracy across various scenarios and strong\nrobustness to prompt-based evasion, outperforming existing baselines while\nhighlighting the structural habits transfer in LLMs.",
    "published": "2025-10-19T19:15:08Z",
    "updated": "2025-10-19T19:15:08Z",
    "link": "http://arxiv.org/pdf/2510.16968v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Pingzhi Li",
      "Morris Yu-Chao Huang",
      "Zhen Tan",
      "Qingquan Song",
      "Jie Peng",
      "Kai Zou",
      "Yu Cheng",
      "Kaidi Xu",
      "Tianlong Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.20548v2",
    "title": "$Q\\sharp$: Provably Optimal Distributional RL for LLM Post-Training",
    "summary": "Reinforcement learning (RL) post-training is crucial for LLM alignment and\nreasoning, but existing policy-based methods, such as PPO and DPO, can fall\nshort of fixing shortcuts inherited from pre-training. In this work, we\nintroduce $Q\\sharp$, a value-based algorithm for KL-regularized RL that guides\nthe reference policy using the optimal regularized $Q$ function. We propose to\nlearn the optimal $Q$ function using distributional RL on an aggregated online\ndataset. Unlike prior value-based baselines that guide the model using\nunregularized $Q$-values, our method is theoretically principled and provably\nlearns the optimal policy for the KL-regularized RL problem. Empirically,\n$Q\\sharp$ outperforms prior baselines in math reasoning benchmarks while\nmaintaining a smaller KL divergence to the reference policy. Theoretically, we\nestablish a reduction from KL-regularized RL to no-regret online learning,\nproviding the first bounds for deterministic MDPs under only realizability.\nThanks to distributional RL, our bounds are also variance-dependent and\nconverge faster when the reference policy has small variance. In sum, our\nresults highlight $Q\\sharp$ as an effective approach for post-training LLMs,\noffering both improved performance and theoretical guarantees. The code can be\nfound at https://github.com/jinpz/q_sharp.",
    "published": "2025-02-27T21:43:00Z",
    "updated": "2025-10-19T19:04:55Z",
    "link": "http://arxiv.org/pdf/2502.20548v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Jin Peng Zhou",
      "Kaiwen Wang",
      "Jonathan Chang",
      "Zhaolin Gao",
      "Nathan Kallus",
      "Kilian Q. Weinberger",
      "KiantÃ© Brantley",
      "Wen Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.08365v4",
    "title": "Towards Principled Unsupervised Multi-Agent Reinforcement Learning",
    "summary": "In reinforcement learning, we typically refer to unsupervised pre-training\nwhen we aim to pre-train a policy without a priori access to the task\nspecification, i.e. rewards, to be later employed for efficient learning of\ndownstream tasks. In single-agent settings, the problem has been extensively\nstudied and mostly understood. A popular approach, called task-agnostic\nexploration, casts the unsupervised objective as maximizing the entropy of the\nstate distribution induced by the agent's policy, from which principles and\nmethods follow.\n  In contrast, little is known about it in multi-agent settings, which are\nubiquitous in the real world. What are the pros and cons of alternative problem\nformulations in this setting? How hard is the problem in theory, how can we\nsolve it in practice? In this paper, we address these questions by first\ncharacterizing those alternative formulations and highlighting how the problem,\neven when tractable in theory, is non-trivial in practice. Then, we present a\nscalable, decentralized, trust-region policy search algorithm to address the\nproblem in practical settings. Finally, we provide numerical validations to\nboth corroborate the theoretical findings and pave the way for unsupervised\nmulti-agent reinforcement learning via task-agnostic exploration in challenging\ndomains, showing that optimizing for a specific objective, namely mixture\nentropy, provides an excellent trade-off between tractability and performances.",
    "published": "2025-02-12T12:51:36Z",
    "updated": "2025-10-19T18:38:22Z",
    "link": "http://arxiv.org/pdf/2502.08365v4.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Riccardo Zamboni",
      "Mirco Mutti",
      "Marcello Restelli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.16958v1",
    "title": "Quantile Regression, Variational Autoencoders, and Diffusion Models for\n  Uncertainty Quantification: A Spatial Analysis of Sub-seasonal Wind Speed\n  Prediction",
    "summary": "This study aims to improve the spatial representation of uncertainties when\nregressing surface wind speeds from large-scale atmospheric predictors for\nsub-seasonal forecasting. Sub-seasonal forecasting often relies on large-scale\natmospheric predictors such as 500 hPa geopotential height (Z500), which\nexhibit higher predictability than surface variables and can be downscaled to\nobtain more localised information. Previous work by Tian et al. (2024)\ndemonstrated that stochastic perturbations based on model residuals can improve\nensemble dispersion representation in statistical downscaling frameworks, but\nthis method fails to represent spatial correlations and physical consistency\nadequately. More sophisticated approaches are needed to capture the complex\nrelationships between large-scale predictors and local-scale predictands while\nmaintaining physical consistency. Probabilistic deep learning models offer\npromising solutions for capturing complex spatial dependencies. This study\nevaluates three probabilistic methods with distinct uncertainty quantification\nmechanisms: Quantile Regression Neural Network that directly models\ndistribution quantiles, Variational Autoencoders that leverage latent space\nsampling, and Diffusion Models that utilise iterative denoising. These models\nare trained on ERA5 reanalysis data and applied to ECMWF sub-seasonal hindcasts\nto regress probabilistic wind speed ensembles. Our results show that\nprobabilistic downscaling approaches provide more realistic spatial uncertainty\nrepresentations compared to simpler stochastic methods, with each probabilistic\nmodel offering different strengths in terms of ensemble dispersion,\ndeterministic skill, and physical consistency. These findings establish\nprobabilistic downscaling as an effective enhancement to operational\nsub-seasonal wind forecasts for renewable energy planning and risk assessment.",
    "published": "2025-10-19T18:26:46Z",
    "updated": "2025-10-19T18:26:46Z",
    "link": "http://arxiv.org/pdf/2510.16958v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Ganglin Tian",
      "Anastase Alexandre Charantonis",
      "Camille Le Coz",
      "Alexis Tantet",
      "Riwal Plougonven"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.16956v1",
    "title": "A Comparative User Evaluation of XRL Explanations using Goal\n  Identification",
    "summary": "Debugging is a core application of explainable reinforcement learning (XRL)\nalgorithms; however, limited comparative evaluations have been conducted to\nunderstand their relative performance. We propose a novel evaluation\nmethodology to test whether users can identify an agent's goal from an\nexplanation of its decision-making. Utilising the Atari's Ms. Pacman\nenvironment and four XRL algorithms, we find that only one achieved greater\nthan random accuracy for the tested goals and that users were generally\noverconfident in their selections. Further, we find that users' self-reported\nease of identification and understanding for every explanation did not\ncorrelate with their accuracy.",
    "published": "2025-10-19T18:23:17Z",
    "updated": "2025-10-19T18:23:17Z",
    "link": "http://arxiv.org/pdf/2510.16956v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Mark Towers",
      "Yali Du",
      "Christopher Freeman",
      "Timothy J. Norman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17800v1",
    "title": "Glyph: Scaling Context Windows via Visual-Text Compression",
    "summary": "Large language models (LLMs) increasingly rely on long-context modeling for\ntasks such as document understanding, code analysis, and multi-step reasoning.\nHowever, scaling context windows to the million-token level brings prohibitive\ncomputational and memory costs, limiting the practicality of long-context LLMs.\nIn this work, we take a different perspective-visual context scaling-to tackle\nthis challenge. Instead of extending token-based sequences, we propose Glyph, a\nframework that renders long texts into images and processes them with\nvision-language models (VLMs). This approach substantially compresses textual\ninput while preserving semantic information, and we further design an\nLLM-driven genetic search to identify optimal visual rendering configurations\nfor balancing accuracy and compression. Through extensive experiments, we\ndemonstrate that our method achieves 3-4x token compression while maintaining\naccuracy comparable to leading LLMs such as Qwen3-8B on various long-context\nbenchmarks. This compression also leads to around 4x faster prefilling and\ndecoding, and approximately 2x faster SFT training. Furthermore, under extreme\ncompression, a 128K-context VLM could scale to handle 1M-token-level text\ntasks. In addition, the rendered text data benefits real-world multimodal\ntasks, such as document understanding. Our code and model are released at\nhttps://github.com/thu-coai/Glyph.",
    "published": "2025-10-20T17:58:56Z",
    "updated": "2025-10-20T17:58:56Z",
    "link": "http://arxiv.org/pdf/2510.17800v1.pdf",
    "category": [
      "cs.CV",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Jiale Cheng",
      "Yusen Liu",
      "Xinyu Zhang",
      "Yulin Fei",
      "Wenyi Hong",
      "Ruiliang Lyu",
      "Weihan Wang",
      "Zhe Su",
      "Xiaotao Gu",
      "Xiao Liu",
      "Yushi Bai",
      "Jie Tang",
      "Hongning Wang",
      "Minlie Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17790v1",
    "title": "UltraCUA: A Foundation Model for Computer Use Agents with Hybrid Action",
    "summary": "Multimodal agents for computer use rely exclusively on primitive actions\n(click, type, scroll) that require accurate visual grounding and lengthy\nexecution chains, leading to cascading failures and performance bottlenecks.\nWhile other agents leverage rich programmatic interfaces (APIs, MCP servers,\ntools), computer-use agents (CUAs) remain isolated from these capabilities. We\npresent UltraCUA, a foundation model that bridges this gap through hybrid\naction -- seamlessly integrating GUI primitives with high-level programmatic\ntool calls. To achieve this, our approach comprises four key components: (1) an\nautomated pipeline that scales programmatic tools from software documentation,\nopen-source repositories, and code generation; (2) a synthetic data engine\nproducing over 17,000 verifiable tasks spanning real-world computer-use\nscenarios; (3) a large-scale high-quality hybrid action trajectory collection\nwith both low-level GUI actions and high-level programmatic tool calls; and (4)\na two-stage training pipeline combining supervised fine-tuning with online\nreinforcement learning, enabling strategic alternation between low-level and\nhigh-level actions. Experiments with our 7B and 32B models demonstrate\nsubstantial improvements over state-of-the-art agents. On OSWorld, UltraCUA\nmodels achieve an average 22% relative improvement over base models, while\nbeing 11% faster in terms of steps. Out-of-domain evaluation on\nWindowsAgentArena shows our model reaches 21.7% success rate, outperforming\nbaselines trained on Windows data. The hybrid action mechanism proves critical,\nreducing error propagation while maintaining execution efficiency.",
    "published": "2025-10-20T17:48:26Z",
    "updated": "2025-10-20T17:48:26Z",
    "link": "http://arxiv.org/pdf/2510.17790v1.pdf",
    "category": [
      "cs.CV",
      "cs.CL"
    ],
    "authors": [
      "Yuhao Yang",
      "Zhen Yang",
      "Zi-Yi Dou",
      "Anh Nguyen",
      "Keen You",
      "Omar Attia",
      "Andrew Szot",
      "Michael Feng",
      "Ram Ramrakhya",
      "Alexander Toshev",
      "Chao Huang",
      "Yinfei Yang",
      "Zhe Gan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17764v1",
    "title": "Evaluating Medical LLMs by Levels of Autonomy: A Survey Moving from\n  Benchmarks to Applications",
    "summary": "Medical Large language models achieve strong scores on standard benchmarks;\nhowever, the transfer of those results to safe and reliable performance in\nclinical workflows remains a challenge. This survey reframes evaluation through\na levels-of-autonomy lens (L0-L3), spanning informational tools, information\ntransformation and aggregation, decision support, and supervised agents. We\nalign existing benchmarks and metrics with the actions permitted at each level\nand their associated risks, making the evaluation targets explicit. This\nmotivates a level-conditioned blueprint for selecting metrics, assembling\nevidence, and reporting claims, alongside directions that link evaluation to\noversight. By centering autonomy, the survey moves the field beyond score-based\nclaims toward credible, risk-aware evidence for real clinical use.",
    "published": "2025-10-20T17:22:32Z",
    "updated": "2025-10-20T17:22:32Z",
    "link": "http://arxiv.org/pdf/2510.17764v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Xiao Ye",
      "Jacob Dineen",
      "Zhaonan Li",
      "Zhikun Xu",
      "Weiyu Chen",
      "Shijie Lu",
      "Yuxi Huang",
      "Ming Shen",
      "Phu Tran",
      "Ji-Eun Irene Yum",
      "Muhammad Ali Khan",
      "Muhammad Umar Afzal",
      "Irbaz Bin Riaz",
      "Ben Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.18196v3",
    "title": "Auto-Prompt Generation is Not Robust: Prompt Optimization Driven by\n  Pseudo Gradient",
    "summary": "While automatic prompt generation methods have recently received significant\nattention, their robustness remains poorly understood. In this paper, we\nintroduce PertBench, a comprehensive benchmark dataset that includes a wide\nrange of input perturbations, designed to systematically evaluate the\nrobustness of current auto-prompting techniques. Our analysis reveals\nsubstantial vulnerabilities in existing prompt generation strategies, where\neven minor modifications to the prompt can lead to significant differences in\nmodel output. To address this issue, we propose PGO, a gradient-free prompt\ngeneration framework that leverages perturbation types as pseudo-gradient\nsignals to guide LLMs in producing more robust prompts. In contrast to existing\nmethods that assess prompt quality only on clean, well-structured inputs, our\napproach explicitly emphasizes robustness under noisy and perturbed conditions.\nExtensive experiments across diverse tasks and multiple LLMs show PGO\nconsistently outperforms previous methods in maintaining performance under\ninput perturbations.",
    "published": "2024-12-24T06:05:08Z",
    "updated": "2025-10-20T17:16:38Z",
    "link": "http://arxiv.org/pdf/2412.18196v3.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Zeru Shi",
      "Zhenting Wang",
      "Yongye Su",
      "Weidi Luo",
      "Hang Gao",
      "Fan Yang",
      "Ruixiang Tang",
      "Yongfeng Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17759v1",
    "title": "VERA-V: Variational Inference Framework for Jailbreaking Vision-Language\n  Models",
    "summary": "Vision-Language Models (VLMs) extend large language models with visual\nreasoning, but their multimodal design also introduces new, underexplored\nvulnerabilities. Existing multimodal red-teaming methods largely rely on\nbrittle templates, focus on single-attack settings, and expose only a narrow\nsubset of vulnerabilities. To address these limitations, we introduce VERA-V, a\nvariational inference framework that recasts multimodal jailbreak discovery as\nlearning a joint posterior distribution over paired text-image prompts. This\nprobabilistic view enables the generation of stealthy, coupled adversarial\ninputs that bypass model guardrails. We train a lightweight attacker to\napproximate the posterior, allowing efficient sampling of diverse jailbreaks\nand providing distributional insights into vulnerabilities. VERA-V further\nintegrates three complementary strategies: (i) typography-based text prompts\nthat embed harmful cues, (ii) diffusion-based image synthesis that introduces\nadversarial signals, and (iii) structured distractors to fragment VLM\nattention. Experiments on HarmBench and HADES benchmarks show that VERA-V\nconsistently outperforms state-of-the-art baselines on both open-source and\nfrontier VLMs, achieving up to 53.75% higher attack success rate (ASR) over the\nbest baseline on GPT-4o.",
    "published": "2025-10-20T17:12:10Z",
    "updated": "2025-10-20T17:12:10Z",
    "link": "http://arxiv.org/pdf/2510.17759v1.pdf",
    "category": [
      "cs.CR",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Qilin Liao",
      "Anamika Lochab",
      "Ruqi Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17733v1",
    "title": "Train for Truth, Keep the Skills: Binary Retrieval-Augmented Reward\n  Mitigates Hallucinations",
    "summary": "Language models often generate factually incorrect information unsupported by\ntheir training data, a phenomenon known as extrinsic hallucination. Existing\nmitigation approaches often degrade performance on open-ended generation and\ndownstream tasks, limiting their practical utility. We propose an online\nreinforcement learning method using a novel binary retrieval-augmented reward\n(RAR) to address this tradeoff. Unlike continuous reward schemes, our approach\nassigns a reward of one only when the model's output is entirely factually\ncorrect, and zero otherwise. We evaluate our method on Qwen3 reasoning models\nacross diverse tasks. For open-ended generation, binary RAR achieves a 39.3%\nreduction in hallucination rates, substantially outperforming both supervised\ntraining and continuous-reward RL baselines. In short-form question answering,\nthe model learns calibrated abstention, strategically outputting \"I don't know\"\nwhen faced with insufficient parametric knowledge. This yields 44.4% and 21.7%\nfewer incorrect answers on PopQA and GPQA, respectively. Crucially, these\nfactuality gains come without performance degradation on instruction following,\nmath, or code, whereas continuous-reward RL, despite improving factuality,\ninduces quality regressions.",
    "published": "2025-10-20T16:45:43Z",
    "updated": "2025-10-20T16:45:43Z",
    "link": "http://arxiv.org/pdf/2510.17733v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Tong Chen",
      "Akari Asai",
      "Luke Zettlemoyer",
      "Hannaneh Hajishirzi",
      "Faeze Brahman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.10062v2",
    "title": "HUME: Measuring the Human-Model Performance Gap in Text Embedding Tasks",
    "summary": "Comparing human and model performance offers a valuable perspective for\nunderstanding the strengths and limitations of embedding models, highlighting\nwhere they succeed and where they fail to capture meaning and nuance. However,\nsuch comparisons are rarely made, as human performance on embedding tasks is\ndifficult to measure. To fill this gap, we introduce HUME: Human Evaluation\nFramework for Text Embeddings. While frameworks like MTEB provide broad model\nevaluation, they lack reliable estimates of human performance, limiting the\ninterpretability of model scores. We measure human performance across 16 MTEB\ndatasets spanning reranking, classification, clustering, and semantic textual\nsimilarity across linguistically diverse high- and low-resource languages.\nHumans achieve an average performance of 77.6% compared to 80.1% for the best\nembedding model, although variation is substantial: models reach near-ceiling\nperformance on some datasets while struggling on others, suggesting dataset\nissues and revealing shortcomings in low-resource languages. We provide human\nperformance baselines, insight into task difficulty patterns, and an extensible\nevaluation framework that enables a more meaningful interpretation of the model\nand informs the development of both models and benchmarks. Our code, dataset,\nand leaderboard are publicly available at\nhttps://github.com/embeddings-benchmark/mteb.",
    "published": "2025-10-11T06:56:53Z",
    "updated": "2025-10-20T16:44:59Z",
    "link": "http://arxiv.org/pdf/2510.10062v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Adnan El Assadi",
      "Isaac Chung",
      "Roman Solomatin",
      "Niklas Muennighoff",
      "Kenneth Enevoldsen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.05605v5",
    "title": "Evolving LLMs' Self-Refinement Capability via Iterative Preference\n  Optimization",
    "summary": "Self-Refinement refers to a model's ability to revise its own responses to\nproduce improved outputs. This capability can also serve as a fundamental\nmechanism for Self-Improvement, for example, by reconstructing datasets with\nrefined results to enhance intrinsic model performance. However, our\ncomprehensive experiments reveal that large language models (LLMs) show no\nclear evidence of inherent Self-Refinement and may even experience response\nquality degradation after Self-Refinement. To address this issue, we propose\nEVOLVE, a simple and effective framework for eliciting and tracking the\nevolution of Self-Refinement through iterative training. We first explore\noptimization methods during training to activate the model's Self-Refinement\ncapability. Then, at inference, we investigate various generation strategies to\nfurther enhance and utilize Self-Refinement while supplying the necessary data\nfor training. Through synergistic optimization of training and inference\nstages, we continually evolve the model's Self-Refinement ability, enabling it\nto better refine its own responses. Moreover, we demonstrate the potential of\nleveraging Self-Refinement to achieve broader Self-Improvement of intrinsic\nmodel abilities. Experiments show that the evolved Self-Refinement ability\nenables the Llama-3.1-8B base model to surpass GPT-4o, achieving 62.3%\nlength-controlled and 63.3% raw win rates on AlpacaEval 2, and 50.3% on\nArena-Hard. It also generalizes effectively to out-of-domain reasoning tasks,\nimproving performance on mathematical reasoning benchmarks such as GSM8K and\nMATH.",
    "published": "2025-02-08T15:21:55Z",
    "updated": "2025-10-20T16:35:34Z",
    "link": "http://arxiv.org/pdf/2502.05605v5.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Yongcheng Zeng",
      "Xinyu Cui",
      "Xuanfa Jin",
      "Qirui Mi",
      "Guoqing Liu",
      "Zexu Sun",
      "Mengyue Yang",
      "Dong Li",
      "Weiyu Ma",
      "Ning Yang",
      "Jian Zhao",
      "Jianye Hao",
      "Haifeng Zhang",
      "Jun Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17715v1",
    "title": "QueST: Incentivizing LLMs to Generate Difficult Problems",
    "summary": "Large Language Models have achieved strong performance on reasoning tasks,\nsolving competition-level coding and math problems. However, their scalability\nis limited by human-labeled datasets and the lack of large-scale, challenging\ncoding problem training data. Existing competitive coding datasets contain only\nthousands to tens of thousands of problems. Previous synthetic data generation\nmethods rely on either augmenting existing instruction datasets or selecting\nchallenging problems from human-labeled data. In this paper, we propose QueST,\na novel framework which combines difficulty-aware graph sampling and\ndifficulty-aware rejection fine-tuning that directly optimizes specialized\ngenerators to create challenging coding problems. Our trained generators\ndemonstrate superior capability compared to even GPT-4o at creating challenging\nproblems that benefit downstream performance. We leverage QueST to generate\nlarge-scale synthetic coding problems, which we then use to distill from strong\nteacher models with long chain-of-thought or to conduct reinforcement learning\nfor smaller models, proving effective in both scenarios. Our distillation\nexperiments demonstrate significant performance gains. Specifically, after\nfine-tuning Qwen3-8B-base on 100K difficult problems generated by QueST, we\nsurpass the performance of the original Qwen3-8B on LiveCodeBench. With an\nadditional 112K examples (i.e., 28K human-written problems paired with multiple\nsynthetic solutions), our 8B model matches the performance of the much larger\nDeepSeek-R1-671B. These findings indicate that generating complex problems via\nQueST offers an effective and scalable approach to advancing the frontiers of\ncompetitive coding and reasoning for large language models.",
    "published": "2025-10-20T16:29:53Z",
    "updated": "2025-10-20T16:29:53Z",
    "link": "http://arxiv.org/pdf/2510.17715v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Hanxu Hu",
      "Xingxing Zhang",
      "Jannis Vamvas",
      "Rico Sennrich",
      "Furu Wei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17698v1",
    "title": "Towards Mining Effective Pedagogical Strategies from Learner-LLM\n  Educational Dialogues",
    "summary": "Dialogue plays a crucial role in educational settings, yet existing\nevaluation methods for educational applications of large language models (LLMs)\nprimarily focus on technical performance or learning outcomes, often neglecting\nattention to learner-LLM interactions. To narrow this gap, this AIED Doctoral\nConsortium paper presents an ongoing study employing a dialogue analysis\napproach to identify effective pedagogical strategies from learner-LLM\ndialogues. The proposed approach involves dialogue data collection, dialogue\nact (DA) annotation, DA pattern mining, and predictive model building. Early\ninsights are outlined as an initial step toward future research. The work\nunderscores the need to evaluate LLM-based educational applications by focusing\non dialogue dynamics and pedagogical strategies.",
    "published": "2025-10-20T16:11:34Z",
    "updated": "2025-10-20T16:11:34Z",
    "link": "http://arxiv.org/pdf/2510.17698v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Liqun He",
      "Manolis Mavrikis",
      "Mutlu Cukurova"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.12943v2",
    "title": "The Curious Case of Curiosity across Human Cultures and LLMs",
    "summary": "Recent advances in Large Language Models (LLMs) have expanded their role in\nhuman interaction, yet curiosity -- a central driver of inquiry -- remains\nunderexplored in these systems, particularly across cultural contexts. In this\nwork, we investigate cultural variation in curiosity using Yahoo! Answers, a\nreal-world multi-country dataset spanning diverse topics. We introduce CUEST\n(CUriosity Evaluation across SocieTies), an evaluation framework that measures\nhuman-model alignment in curiosity through linguistic (style), topic preference\n(content) analysis and grounding insights in social science constructs. Across\nopen- and closed-source models, we find that LLMs flatten cross-cultural\ndiversity, aligning more closely with how curiosity is expressed in Western\ncountries. We then explore fine-tuning strategies to induce curiosity in LLMs,\nnarrowing the human-model alignment gap by up to 50%. Finally, we demonstrate\nthe practical value of curiosity for LLM adaptability across cultures, showing\nits importance for future NLP research.",
    "published": "2025-10-14T19:42:24Z",
    "updated": "2025-10-20T15:55:28Z",
    "link": "http://arxiv.org/pdf/2510.12943v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Angana Borah",
      "Zhijing Jin",
      "Rada Mihalcea"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17662v1",
    "title": "DELULU: Discriminative Embedding Learning Using Latent Units for\n  Speaker-Aware Self-Supervised Speech Foundational Model",
    "summary": "Self-supervised speech models have achieved remarkable success on\ncontent-driven tasks, yet they remain limited in capturing\nspeaker-discriminative features critical for verification, diarization, and\nprofiling applications. We introduce DELULU, a speaker-aware self-supervised\nfoundational model that addresses this limitation by integrating external\nsupervision into the pseudo-label generation process. DELULU leverages\nframe-level embeddings from ReDimNet, a state-of-the-art speaker verification\nmodel, to guide the k-means clustering step during pre-training, introducing a\nstrong speaker-discriminative inductive bias that aligns representation\nlearning with speaker identity. The model is trained using a dual objective\nthat combines masked prediction and denoising, further enhancing robustness and\ngeneralization. DELULU significantly outperforms prior self-supervised learning\n(SSL) models across a range of speaker-centric tasks, achieving up to 62%\nrelative improvement in equal error rate (EER) for speaker verification and\nconsistent gains on zero-shot profiling tasks such as gender, age, accent, and\nspeaker counting. Our findings demonstrate that DELULU is a strong universal\nencoder for speaker-aware speech processing, enabling superior performance even\nwithout task-specific fine-tuning.",
    "published": "2025-10-20T15:35:55Z",
    "updated": "2025-10-20T15:35:55Z",
    "link": "http://arxiv.org/pdf/2510.17662v1.pdf",
    "category": [
      "cs.SD",
      "cs.CL"
    ],
    "authors": [
      "Massa Baali",
      "Rita Singh",
      "Bhiksha Raj"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17652v1",
    "title": "Qomhra: A Bilingual Irish-English Large Language Model",
    "summary": "This paper introduces Qomhr\\'a, a bilingual Irish-English large language\nmodel (LLM), developed under low-resource constraints presenting a complete\npipeline spanning bilingual continued pre-training, instruction tuning, and\nalignment from human preferences. Newly accessible Irish corpora and English\ntext are mixed and curated to improve Irish performance while preserving\nEnglish ability. 6 closed-weight LLMs are judged for their Irish text\ngeneration by a native speaker, a learner and other LLMs. Google's\nGemini-2.5-Pro is ranked the highest and is subsequently used to synthesise\ninstruction tuning and human preference datasets. Two datasets are contributed\nleveraging Gemini-2.5-Pro: a 30K Irish-English parallel instruction tuning\ndataset and a 1K human preference dataset, generating accepted and rejected\nresponses that show near perfect alignment with a native Irish speaker.\nQomhr\\'a is comprehensively evaluated across benchmarks testing translation,\ngender understanding, topic identification and world knowledge with gains of up\nto 29% in Irish and 44% in English. Qomhr\\'a also undergoes instruction tuning\nand demonstrates clear progress in instruction following, crucial for chatbot\nfunctionality.",
    "published": "2025-10-20T15:27:53Z",
    "updated": "2025-10-20T15:27:53Z",
    "link": "http://arxiv.org/pdf/2510.17652v1.pdf",
    "category": [
      "cs.CL",
      "I.2.7"
    ],
    "authors": [
      "Joseph McInerney"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17620v1",
    "title": "Forget to Know, Remember to Use: Context-Aware Unlearning for Large\n  Language Models",
    "summary": "Large language models may encode sensitive information or outdated knowledge\nthat needs to be removed, to ensure responsible and compliant model responses.\nUnlearning has emerged as an efficient alternative to full retraining, aiming\nto remove specific knowledge while preserving overall model utility. Existing\nevaluations of unlearning methods focus on (1) the extent of forgetting of the\ntarget knowledge (forget set) and (2) maintaining performance on the retain set\n(i.e., utility). However, these evaluations overlook an important usability\naspect: users may still want the model to leverage the removed information if\nit is re-introduced in the prompt. In a systematic evaluation of six\nstate-of-the-art unlearning methods, we find that they consistently impair such\ncontextual utility. To address this, we augment unlearning objectives with a\nplug-in term that preserves the model's ability to use forgotten knowledge when\nit is present in context. Extensive experiments demonstrate that our approach\nrestores contextual utility to near original levels while still maintaining\neffective forgetting and retain-set utility.",
    "published": "2025-10-20T15:03:45Z",
    "updated": "2025-10-20T15:03:45Z",
    "link": "http://arxiv.org/pdf/2510.17620v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yuefeng Peng",
      "Parnian Afshar",
      "Megan Ganji",
      "Thomas Butler",
      "Amir Houmansadr",
      "Mingxian Wang",
      "Dezhi Hong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17602v1",
    "title": "LawChain: Modeling Legal Reasoning Chains for Chinese Tort Case Analysis",
    "summary": "Legal reasoning is a fundamental component of legal analysis and\ndecision-making. Existing computational approaches to legal reasoning\npredominantly rely on generic reasoning frameworks such as syllogism and IRAC,\nwhich do not comprehensively examine the nuanced processes that underpin legal\nreasoning. Moreover, current research has largely focused on criminal cases,\nwith insufficient modeling for civil cases. In this work, we present a novel\nframework for explicitly modeling legal reasoning in the analysis of Chinese\ntort-related civil cases. We first operationalize the legal reasoning processes\nused in tort analysis into the LawChain framework. LawChain is a three-module\nreasoning framework, with each module consisting of multiple finer-grained\nsub-steps. Informed by the LawChain framework, we introduce the task of tort\nlegal reasoning and construct an evaluation benchmark, LawChain$_{eval}$, to\nsystematically assess the critical steps within analytical reasoning chains for\ntort analysis. Leveraging this benchmark, we evaluate state-of-the-art large\nlanguage models for their legal reasoning ability in civil tort contexts. Our\nresults indicate that current models still fall short in accurately handling\ncrucial elements of tort legal reasoning. Furthermore, we introduce several\nbaseline approaches that explicitly incorporate LawChain-style reasoning\nthrough prompting or post-training. We conduct further experiments on\nadditional legal analysis tasks, such as Legal Named-Entity Recognition and\nCriminal Damages Calculation, to verify the generalizability of these\nbaselines. The proposed baseline approaches achieve significant improvements in\ntort-related legal reasoning and generalize well to related legal analysis\ntasks, thus demonstrating the value of explicitly modeling legal reasoning\nchains to enhance the reasoning capabilities of language models.",
    "published": "2025-10-20T14:50:58Z",
    "updated": "2025-10-20T14:50:58Z",
    "link": "http://arxiv.org/pdf/2510.17602v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Huiyuan Xie",
      "Chenyang Li",
      "Huining Zhu",
      "Chubin Zhang",
      "Yuxiao Ye",
      "Zhenghao Liu",
      "Zhiyuan Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17555v1",
    "title": "Language Confusion Gate: Language-Aware Decoding Through Model\n  Self-Distillation",
    "summary": "Large language models (LLMs) often experience language confusion, which is\nthe unintended mixing of languages during text generation. Current solutions to\nthis problem either necessitate model retraining or cannot differentiate\nbetween harmful confusion and acceptable code-switching. This paper introduces\nthe Language Confusion Gate (LCG), a lightweight, plug-in solution that filters\ntokens during decoding without altering the base LLM. The LCG is trained using\nnorm-adjusted self-distillation to predict appropriate language families and\napply masking only when needed. Our method is based on the findings that\nlanguage confusion is infrequent, correct-language tokens are usually among the\ntop predictions, and output token embedding norms are larger for high-resource\nlanguages, which biases sampling. When evaluated across various models,\nincluding Qwen3, GPT-OSS, Gemma3, Llama3.1, LCG decreases language confusion\nsignificantly, often by an order of magnitude, without negatively impacting\ntask performance. Code is available at\nhttps://github.com/collinzrj/language_confusion_gate.",
    "published": "2025-10-20T14:02:37Z",
    "updated": "2025-10-20T14:02:37Z",
    "link": "http://arxiv.org/pdf/2510.17555v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Collin Zhang",
      "Fei Huang",
      "Chenhan Yuan",
      "Junyang Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17548v1",
    "title": "When Annotators Disagree, Topology Explains: Mapper, a Topological Tool\n  for Exploring Text Embedding Geometry and Ambiguity",
    "summary": "Language models are often evaluated with scalar metrics like accuracy, but\nsuch measures fail to capture how models internally represent ambiguity,\nespecially when human annotators disagree. We propose a topological perspective\nto analyze how fine-tuned models encode ambiguity and more generally instances.\n  Applied to RoBERTa-Large on the MD-Offense dataset, Mapper, a tool from\ntopological data analysis, reveals that fine-tuning restructures embedding\nspace into modular, non-convex regions aligned with model predictions, even for\nhighly ambiguous cases. Over $98\\%$ of connected components exhibit $\\geq 90\\%$\nprediction purity, yet alignment with ground-truth labels drops in ambiguous\ndata, surfacing a hidden tension between structural confidence and label\nuncertainty.\n  Unlike traditional tools such as PCA or UMAP, Mapper captures this geometry\ndirectly uncovering decision regions, boundary collapses, and overconfident\nclusters. Our findings position Mapper as a powerful diagnostic tool for\nunderstanding how models resolve ambiguity. Beyond visualization, it also\nenables topological metrics that may inform proactive modeling strategies in\nsubjective NLP tasks.",
    "published": "2025-10-20T13:58:02Z",
    "updated": "2025-10-20T13:58:02Z",
    "link": "http://arxiv.org/pdf/2510.17548v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Nisrine Rair",
      "Alban Goupil",
      "Valeriu Vrabie",
      "Emmanuel Chochoy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17532v1",
    "title": "OncoReason: Structuring Clinical Reasoning in LLMs for Robust and\n  Interpretable Survival Prediction",
    "summary": "Predicting cancer treatment outcomes requires models that are both accurate\nand interpretable, particularly in the presence of heterogeneous clinical data.\nWhile large language models (LLMs) have shown strong performance in biomedical\nNLP, they often lack structured reasoning capabilities critical for high-stakes\ndecision support. We present a unified, multi-task learning framework that\naligns autoregressive LLMs with clinical reasoning for outcome prediction on\nthe MSK-CHORD dataset. Our models are trained to jointly perform binary\nsurvival classification, continuous survival time regression, and natural\nlanguage rationale generation. We evaluate three alignment strategies: (1)\nstandard supervised fine-tuning (SFT), (2) SFT with Chain-of-Thought (CoT)\nprompting to elicit step-by-step reasoning, and (3) Group Relative Policy\nOptimization (GRPO), a reinforcement learning method that aligns model outputs\nto expert-derived reasoning trajectories. Experiments with LLaMa3-8B and\nMed42-8B backbones demonstrate that CoT prompting improves F1 by +6.0 and\nreduces MAE by 12%, while GRPO achieves state-of-the-art interpretability and\npredictive performance across BLEU, ROUGE, and BERTScore. We further show that\nexisting biomedical LLMs often fail to produce valid reasoning traces due to\narchitectural constraints. Our findings underscore the importance of\nreasoning-aware alignment in multi-task clinical modeling and set a new\nbenchmark for interpretable, trustworthy LLMs in precision oncology.",
    "published": "2025-10-20T13:35:12Z",
    "updated": "2025-10-20T13:35:12Z",
    "link": "http://arxiv.org/pdf/2510.17532v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Raghu Vamshi Hemadri",
      "Geetha Krishna Guruju",
      "Kristi Topollai",
      "Anna Ewa Choromanska"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.00161v2",
    "title": "Watch the Weights: Unsupervised monitoring and control of fine-tuned\n  LLMs",
    "summary": "The releases of powerful open-weight large language models (LLMs) are often\nnot accompanied by access to their full training data. Existing\ninterpretability methods, particularly those based on activations, often\nrequire or assume distributionally similar data. This is a significant\nlimitation when detecting and defending against novel potential threats like\nbackdoors, which are by definition out-of-distribution.\n  In this work, we introduce a new method for understanding, monitoring and\ncontrolling fine-tuned LLMs that interprets weights, rather than activations,\nthereby side stepping the need for data that is distributionally similar to the\nunknown training data. We demonstrate that the top singular vectors of the\nweight difference between a fine-tuned model and its base model correspond to\nnewly acquired behaviors. By monitoring the cosine similarity of activations\nalong these directions, we can detect salient behaviors introduced during\nfine-tuning with high precision.\n  For backdoored models that bypasses safety mechanisms when a secret trigger\nis present, our method stops up to 100% of attacks with a false positive rate\nbelow 1.2%. For models that have undergone unlearning, we detect inference on\nerased topics with accuracy up to 95.42% and can even steer the model to\nrecover \"unlearned\" information. Besides monitoring, our method also shows\npotential for pre-deployment model auditing: by analyzing commercial\ninstruction-tuned models (OLMo, Llama, Qwen), we are able to uncover\nmodel-specific fine-tuning focus including marketing strategies and Midjourney\nprompt generation.\n  Our implementation can be found at https://github.com/fjzzq2002/WeightWatch.",
    "published": "2025-07-31T21:04:12Z",
    "updated": "2025-10-20T13:29:29Z",
    "link": "http://arxiv.org/pdf/2508.00161v2.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Ziqian Zhong",
      "Aditi Raghunathan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17509v1",
    "title": "Annotation-Efficient Universal Honesty Alignment",
    "summary": "Honesty alignment-the ability of large language models (LLMs) to recognize\ntheir knowledge boundaries and express calibrated confidence-is essential for\ntrustworthy deployment. Existing methods either rely on training-free\nconfidence estimation (e.g., token probabilities, self-consistency) or\ntraining-based calibration with correctness annotations. While effective,\nachieving universal honesty alignment with training-based calibration requires\ncostly, large-scale labeling. To support annotation-efficient training, we\nintroduce Elicitation-Then-Calibration (EliCal), a two-stage framework that\nfirst elicits internal confidence using inexpensive self-consistency\nsupervision, then calibrates this confidence with a small set of correctness\nannotations. To support a large-scale study, we release HonestyBench, a\nbenchmark covering ten free-form QA datasets with 560k training and 70k\nevaluation instances annotated with correctness and self-consistency signals.\nExperiments show that EliCal achieves near-optimal alignment with only 1k\ncorrectness annotations (0.18% of full supervision) and better alignment\nperformance on unseen MMLU tasks than the calibration-only baseline, offering a\nscalable solution toward universal honesty alignment in LLMs.",
    "published": "2025-10-20T13:05:22Z",
    "updated": "2025-10-20T13:05:22Z",
    "link": "http://arxiv.org/pdf/2510.17509v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Shiyu Ni",
      "Keping Bi",
      "Jiafeng Guo",
      "Minghao Tang",
      "Jingtong Wu",
      "Zengxin Han",
      "Xueqi Cheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17504v1",
    "title": "Lingua Custodi's participation at the WMT 2025 Terminology shared task",
    "summary": "While BERT is an effective method for learning monolingual sentence\nembeddings for semantic similarity and embedding based transfer learning BERT\nbased cross-lingual sentence embeddings have yet to be explored. We\nsystematically investigate methods for learning multilingual sentence\nembeddings by combining the best methods for learning monolingual and\ncross-lingual representations including: masked language modeling (MLM),\ntranslation language modeling (TLM), dual encoder translation ranking, and\nadditive margin softmax. We show that introducing a pre-trained multilingual\nlanguage model dramatically reduces the amount of parallel training data\nrequired to achieve good performance by 80%. Composing the best of these\nmethods produces a model that achieves 83.7% bi-text retrieval accuracy over\n112 languages on Tatoeba, well above the 65.5 achieved by LASER, while still\nperforming competitively on monolingual transfer learning benchmarks. Parallel\ndata mined from CommonCrawl using our best model is shown to train competitive\nNMT models for en-zh and en-de. We publicly release our best multilingual\nsentence embedding model for 109+ languages at https://tfhub.dev/google/LaBSE.",
    "published": "2025-10-20T13:00:47Z",
    "updated": "2025-10-20T13:00:47Z",
    "link": "http://arxiv.org/pdf/2510.17504v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Jingshu Liu",
      "Raheel Qader",
      "GaÃ«tan Caillaut",
      "Mariam NakhlÃ©"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17498v1",
    "title": "Deep Self-Evolving Reasoning",
    "summary": "Long-form chain-of-thought reasoning has become a cornerstone of advanced\nreasoning in large language models. While recent verification-refinement\nframeworks have enabled proprietary models to solve Olympiad-level problems,\ntheir effectiveness hinges on strong, reliable verification and correction\ncapabilities, which remain fragile in open-weight, smaller-scale models. This\nwork demonstrates that even with weak verification and refinement capabilities\non hard tasks, the reasoning limits of such models can be substantially\nextended through a probabilistic paradigm we call Deep Self-Evolving Reasoning\n(DSER). We conceptualize iterative reasoning as a Markov chain, where each step\nrepresents a stochastic transition in the solution space. The key insight is\nthat convergence to a correct solution is guaranteed as long as the probability\nof improvement marginally exceeds that of degradation. By running multiple\nlong-horizon, self-evolving processes in parallel, DSER amplifies these small\npositive tendencies, enabling the model to asymptotically approach correct\nanswers. Empirically, we apply DSER to the DeepSeek-R1-0528-Qwen3-8B model. On\nthe challenging AIME 2024-2025 benchmark, DSER solves 5 out of 9 previously\nunsolvable problems and boosts overall performance, enabling this compact model\nto surpass the single-turn accuracy of its 600B-parameter teacher through\nmajority voting. Beyond its immediate utility for test-time scaling, the DSER\nframework serves to diagnose the fundamental limitations of current open-weight\nreasoners. By clearly delineating their shortcomings in self-verification,\nrefinement, and stability, our findings establish a clear research agenda for\ndeveloping next-generation models with powerful, intrinsic self-evolving\ncapabilities.",
    "published": "2025-10-20T12:51:42Z",
    "updated": "2025-10-20T12:51:42Z",
    "link": "http://arxiv.org/pdf/2510.17498v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Zihan Liu",
      "Shun Zheng",
      "Xumeng Wen",
      "Yang Wang",
      "Jiang Bian",
      "Mao Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17491v1",
    "title": "Empowering Real-World: A Survey on the Technology, Practice, and\n  Evaluation of LLM-driven Industry Agents",
    "summary": "With the rise of large language models (LLMs), LLM agents capable of\nautonomous reasoning, planning, and executing complex tasks have become a\nfrontier in artificial intelligence. However, how to translate the research on\ngeneral agents into productivity that drives industry transformations remains a\nsignificant challenge. To address this, this paper systematically reviews the\ntechnologies, applications, and evaluation methods of industry agents based on\nLLMs. Using an industry agent capability maturity framework, it outlines the\nevolution of agents in industry applications, from \"process execution systems\"\nto \"adaptive social systems.\" First, we examine the three key technological\npillars that support the advancement of agent capabilities: Memory, Planning,\nand Tool Use. We discuss how these technologies evolve from supporting simple\ntasks in their early forms to enabling complex autonomous systems and\ncollective intelligence in more advanced forms. Then, we provide an overview of\nthe application of industry agents in real-world domains such as digital\nengineering, scientific discovery, embodied intelligence, collaborative\nbusiness execution, and complex system simulation. Additionally, this paper\nreviews the evaluation benchmarks and methods for both fundamental and\nspecialized capabilities, identifying the challenges existing evaluation\nsystems face regarding authenticity, safety, and industry specificity. Finally,\nwe focus on the practical challenges faced by industry agents, exploring their\ncapability boundaries, developmental potential, and governance issues in\nvarious scenarios, while providing insights into future directions. By\ncombining technological evolution with industry practices, this review aims to\nclarify the current state and offer a clear roadmap and theoretical foundation\nfor understanding and building the next generation of industry agents.",
    "published": "2025-10-20T12:46:55Z",
    "updated": "2025-10-20T12:46:55Z",
    "link": "http://arxiv.org/pdf/2510.17491v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yihong Tang",
      "Kehai Chen",
      "Liang Yue",
      "Jinxin Fan",
      "Caishen Zhou",
      "Xiaoguang Li",
      "Yuyang Zhang",
      "Mingming Zhao",
      "Shixiong Kai",
      "Kaiyang Guo",
      "Xingshan Zeng",
      "Wenjing Cun",
      "Lifeng Shang",
      "Min Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17489v1",
    "title": "DETree: DEtecting Human-AI Collaborative Texts via Tree-Structured\n  Hierarchical Representation Learning",
    "summary": "Detecting AI-involved text is essential for combating misinformation,\nplagiarism, and academic misconduct. However, AI text generation includes\ndiverse collaborative processes (AI-written text edited by humans,\nhuman-written text edited by AI, and AI-generated text refined by other AI),\nwhere various or even new LLMs could be involved. Texts generated through these\nvaried processes exhibit complex characteristics, presenting significant\nchallenges for detection. Current methods model these processes rather crudely,\nprimarily employing binary classification (purely human vs. AI-involved) or\nmulti-classification (treating human-AI collaboration as a new class). We\nobserve that representations of texts generated through different processes\nexhibit inherent clustering relationships. Therefore, we propose DETree, a\nnovel approach that models the relationships among different processes as a\nHierarchical Affinity Tree structure, and introduces a specialized loss\nfunction that aligns text representations with this tree. To facilitate this\nlearning, we developed RealBench, a comprehensive benchmark dataset that\nautomatically incorporates a wide spectrum of hybrid texts produced through\nvarious human-AI collaboration processes. Our method improves performance in\nhybrid text detection tasks and significantly enhances robustness and\ngeneralization in out-of-distribution scenarios, particularly in few-shot\nlearning conditions, further demonstrating the promise of training-based\napproaches in OOD settings. Our code and dataset are available at\nhttps://github.com/heyongxin233/DETree.",
    "published": "2025-10-20T12:41:44Z",
    "updated": "2025-10-20T12:41:44Z",
    "link": "http://arxiv.org/pdf/2510.17489v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Yongxin He",
      "Shan Zhang",
      "Yixuan Cao",
      "Lei Ma",
      "Ping Luo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17483v1",
    "title": "ReXMoE: Reusing Experts with Minimal Overhead in Mixture-of-Experts",
    "summary": "Mixture-of-Experts (MoE) architectures have emerged as a promising approach\nto scale Large Language Models (LLMs). MoE boosts the efficiency by activating\na subset of experts per token. Recent works show that fine-grained experts\nsubstantially enriches the combinatorial flexibility of active experts and\nenhances model expressiveness. However, such a design is fundamentally limited\nby the layer-local routing mechanism: each layer is restricted to its own\nexpert pool. This requires a careful trade-off between expert dimensionality\nand routing diversity given fixed parameter budgets. We describe ReXMoE, a\nnovel MoE architecture that improves routing beyond the existing layer-local\napproaches by allowing routers to reuse experts across adjacent layers. ReXMoE\ndecouples expert dimensionality from per-layer budgets, enabling richer expert\ncombinations without sacrificing individual expert capacity or inflating\noverall parameters. To this end, we propose a new progressive scaling routing\n(PSR) strategy to gradually increase the candidate expert pool during training.\nAs a result, ReXMoE improves both language modeling and downstream task\nperformance. Extensive experiments on models ranging from 0.5B to 7B parameters\nacross different architectures demonstrate that ReXMoE consistently improves\nperformance under fixed architectural dimensions, confirming ReXMoE as new\ndesign paradigm for parameter-efficient and scalable MoE-based LLMs.",
    "published": "2025-10-20T12:27:55Z",
    "updated": "2025-10-20T12:27:55Z",
    "link": "http://arxiv.org/pdf/2510.17483v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Zheyue Tan",
      "Zhiyuan Li",
      "Tao Yuan",
      "Dong Zhou",
      "Weilin Liu",
      "Yueqing Zhuang",
      "Yadong Li",
      "Guowei Niu",
      "Cheng Qin",
      "Zhuyu Yao",
      "Congyi Liu",
      "Haiyang Xu",
      "Boxun Li",
      "Guohao Dai",
      "Bo Zhao",
      "Yu Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17476v1",
    "title": "Disparities in Multilingual LLM-Based Healthcare Q&A",
    "summary": "Equitable access to reliable health information is vital when integrating AI\ninto healthcare. Yet, information quality varies across languages, raising\nconcerns about the reliability and consistency of multilingual Large Language\nModels (LLMs). We systematically examine cross-lingual disparities in\npre-training source and factuality alignment in LLM answers for multilingual\nhealthcare Q&A across English, German, Turkish, Chinese (Mandarin), and\nItalian. We (i) constructed Multilingual Wiki Health Care\n(MultiWikiHealthCare), a multilingual dataset from Wikipedia; (ii) analyzed\ncross-lingual healthcare coverage; (iii) assessed LLM response alignment with\nthese references; and (iv) conducted a case study on factual alignment through\nthe use of contextual information and Retrieval-Augmented Generation (RAG). Our\nfindings reveal substantial cross-lingual disparities in both Wikipedia\ncoverage and LLM factual alignment. Across LLMs, responses align more with\nEnglish Wikipedia, even when the prompts are non-English. Providing contextual\nexcerpts from non-English Wikipedia at inference time effectively shifts\nfactual alignment toward culturally relevant knowledge. These results highlight\npractical pathways for building more equitable, multilingual AI systems for\nhealthcare.",
    "published": "2025-10-20T12:19:08Z",
    "updated": "2025-10-20T12:19:08Z",
    "link": "http://arxiv.org/pdf/2510.17476v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Ipek Baris Schlicht",
      "Burcu Sayin",
      "Zhixue Zhao",
      "Frederik M. LabontÃ©",
      "Cesare Barbera",
      "Marco Viviani",
      "Paolo Rosso",
      "Lucie Flek"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.00921v2",
    "title": "Supervised In-Context Fine-Tuning for Generative Sequence Labeling",
    "summary": "Sequence labeling (SL) tasks, where labels are assigned to tokens, are\nabundant in NLP (e.g., named entity recognition and aspect-based sentiment\nanalysis). Owing to the intuition that they require bidirectional context, SL\ntasks are commonly tackled with encoder-only models. Recent work also shows\nthat removing the causal mask in fine-tuning enables decoder-based LLMs to\nbecome effective token classifiers. Less work, however, focused on (supervised)\ngenerative SL, a more natural setting for causal LLMs. Due to their rapid\nscaling, causal LLMs applied to SL are expected to outperform encoders, whose\nown development has stagnated. In this work, we propose supervised in-context\nfine-tuning (SIFT) for generative SL. SIFT casts SL tasks as constrained\nresponse generation, natural to LLMs, combining in-context learning (ICL) from\ndemonstrations with supervised fine-tuning. SIFT considerably outperforms both\nICL and decoder-as-encoder fine-tuning baselines on a range of standard SL\ntasks. We further find that although long context hinders the performance of\ngenerative SL in both ICL and SIFT, this deficiency can be mitigated by\nremoving the instruction, as instructions are shown to be largely unnecessary\nfor achieving strong SL performance with SIFT. Our findings highlight strengths\nand limitations of SL with LLMs, underscoring the importance of a\nresponse-based generative task formulation for effective SL performance.",
    "published": "2025-08-31T16:06:12Z",
    "updated": "2025-10-20T12:17:41Z",
    "link": "http://arxiv.org/pdf/2509.00921v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "David DukiÄ",
      "Goran GlavaÅ¡",
      "Jan Å najder"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.03313v3",
    "title": "LLM as GNN: Graph Vocabulary Learning for Text-Attributed Graph\n  Foundation Models",
    "summary": "Text-Attributed Graphs (TAGs), where each node is associated with text\ndescriptions, are ubiquitous in real-world scenarios. They typically exhibit\ndistinctive structure and domain-specific knowledge, motivating the development\nof a Graph Foundation Model (GFM) that generalizes across diverse graphs and\ntasks. Despite large efforts to integrate Large Language Models (LLMs) and\nGraph Neural Networks (GNNs) for TAGs, existing approaches suffer from\ndecoupled architectures with two-stage alignment, limiting their synergistic\npotential. Even worse, existing methods assign out-of-vocabulary (OOV) tokens\nto graph nodes, leading to graph-specific semantics, token explosion, and\nincompatibility with task-oriented prompt templates, which hinders cross-graph\nand cross-task transferability. To address these challenges, we propose\nPromptGFM, a versatile GFM for TAGs grounded in graph vocabulary learning.\nPromptGFM comprises two key components: (1) Graph Understanding Module, which\nexplicitly prompts LLMs to replicate the finest GNN workflow within the text\nspace, facilitating seamless GNN-LLM integration and elegant graph-text\nalignment; (2) Graph Inference Module, which establishes a language-based graph\nvocabulary ensuring expressiveness, transferability, and scalability, enabling\nreadable instructions for LLM fine-tuning. Extensive experiments demonstrate\nour superiority and transferability across diverse graphs and tasks. The code\nis available at this: https://github.com/agiresearch/PromptGFM.",
    "published": "2025-03-05T09:45:22Z",
    "updated": "2025-10-20T11:58:05Z",
    "link": "http://arxiv.org/pdf/2503.03313v3.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Xi Zhu",
      "Haochen Xue",
      "Ziwei Zhao",
      "Wujiang Xu",
      "Jingyuan Huang",
      "Minghao Guo",
      "Qifan Wang",
      "Kaixiong Zhou",
      "Imran Razzak",
      "Yongfeng Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17460v1",
    "title": "Evaluating Large Language Models on Urdu Idiom Translation",
    "summary": "Idiomatic translation remains a significant challenge in machine translation,\nespecially for low resource languages such as Urdu, and has received limited\nprior attention. To advance research in this area, we introduce the first\nevaluation datasets for Urdu to English idiomatic translation, covering both\nNative Urdu and Roman Urdu scripts and annotated with gold-standard English\nequivalents. We evaluate multiple open-source Large Language Models (LLMs) and\nNeural Machine Translation (NMT) systems on this task, focusing on their\nability to preserve idiomatic and cultural meaning. Automatic metrics including\nBLEU, BERTScore, COMET, and XCOMET are used to assess translation quality. Our\nfindings indicate that prompt engineering enhances idiomatic translation\ncompared to direct translation, though performance differences among prompt\ntypes are relatively minor. Moreover, cross script comparisons reveal that text\nrepresentation substantially affects translation quality, with Native Urdu\ninputs producing more accurate idiomatic translations than Roman Urdu.",
    "published": "2025-10-20T11:49:26Z",
    "updated": "2025-10-20T11:49:26Z",
    "link": "http://arxiv.org/pdf/2510.17460v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Muhammad Farmal Khan",
      "Mousumi Akter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.21974v3",
    "title": "Don't Trust Generative Agents to Mimic Communication on Social Networks\n  Unless You Benchmarked their Empirical Realism",
    "summary": "The ability of Large Language Models (LLMs) to mimic human behavior triggered\na plethora of computational social science research, assuming that empirical\nstudies of humans can be conducted with AI agents instead. Since there have\nbeen conflicting research findings on whether and when this hypothesis holds,\nthere is a need to better understand the differences in their experimental\ndesigns. We focus on replicating the behavior of social network users with the\nuse of LLMs for the analysis of communication on social networks. First, we\nprovide a formal framework for the simulation of social networks, before\nfocusing on the sub-task of imitating user communication. We empirically test\ndifferent approaches to imitate user behavior on X in English and German. Our\nfindings suggest that social simulations should be validated by their empirical\nrealism measured in the setting in which the simulation components were fitted.\nWith this paper, we argue for more rigor when applying generative-agent-based\nmodeling for social simulation.",
    "published": "2025-06-27T07:32:16Z",
    "updated": "2025-10-20T11:36:06Z",
    "link": "http://arxiv.org/pdf/2506.21974v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Simon MÃ¼nker",
      "Nils Schwager",
      "Achim Rettinger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17437v1",
    "title": "Multilingual Clinical NER for Diseases and Medications Recognition in\n  Cardiology Texts using BERT Embeddings",
    "summary": "The rapidly increasing volume of electronic health record (EHR) data\nunderscores a pressing need to unlock biomedical knowledge from unstructured\nclinical texts to support advancements in data-driven clinical systems,\nincluding patient diagnosis, disease progression monitoring, treatment effects\nassessment, prediction of future clinical events, etc. While contextualized\nlanguage models have demonstrated impressive performance improvements for named\nentity recognition (NER) systems in English corpora, there remains a scarcity\nof research focused on clinical texts in low-resource languages. To bridge this\ngap, our study aims to develop multiple deep contextual embedding models to\nenhance clinical NER in the cardiology domain, as part of the BioASQ\nMultiCardioNER shared task. We explore the effectiveness of different\nmonolingual and multilingual BERT-based models, trained on general domain text,\nfor extracting disease and medication mentions from clinical case reports\nwritten in English, Spanish, and Italian. We achieved an F1-score of 77.88% on\nSpanish Diseases Recognition (SDR), 92.09% on Spanish Medications Recognition\n(SMR), 91.74% on English Medications Recognition (EMR), and 88.9% on Italian\nMedications Recognition (IMR). These results outperform the mean and median F1\nscores in the test leaderboard across all subtasks, with the mean/median values\nbeing: 69.61%/75.66% for SDR, 81.22%/90.18% for SMR, 89.2%/88.96% for EMR, and\n82.8%/87.76% for IMR.",
    "published": "2025-10-20T11:26:22Z",
    "updated": "2025-10-20T11:26:22Z",
    "link": "http://arxiv.org/pdf/2510.17437v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Manuela Daniela Danu",
      "George Marica",
      "Constantin Suciu",
      "Lucian Mihai Itu",
      "Oladimeji Farri"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17431v1",
    "title": "Agentic Reinforcement Learning for Search is Unsafe",
    "summary": "Agentic reinforcement learning (RL) trains large language models to\nautonomously call tools during reasoning, with search as the most common\napplication. These models excel at multi-step reasoning tasks, but their safety\nproperties are not well understood. In this study, we show that RL-trained\nsearch models inherit refusal from instruction tuning and often deflect harmful\nrequests by turning them into safe queries. However, this safety is fragile.\nTwo simple attacks, one that forces the model to begin response with search\n(Search attack), another that encourages models to repeatedly search\n(Multi-search attack), trigger cascades of harmful searches and answers. Across\ntwo model families (Qwen, Llama) with both local and web search, these attacks\nlower refusal rates by up to 60.0%, answer safety by 82.5%, and search-query\nsafety by 82.4%. The attacks succeed by triggering models to generate harmful,\nrequest-mirroring search queries before they can generate the inherited refusal\ntokens. This exposes a core weakness of current RL training: it rewards\ncontinued generation of effective queries without accounting for their\nharmfulness. As a result, RL search models have vulnerabilities that users can\neasily exploit, making it urgent to develop safety-aware agentic RL pipelines\noptimising for safe search.",
    "published": "2025-10-20T11:19:37Z",
    "updated": "2025-10-20T11:19:37Z",
    "link": "http://arxiv.org/pdf/2510.17431v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yushi Yang",
      "Shreyansh Padarha",
      "Andrew Lee",
      "Adam Mahdi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.15349v2",
    "title": "Infinity Parser: Layout Aware Reinforcement Learning for Scanned\n  Document Parsing",
    "summary": "Document parsing from scanned images into structured formats remains a\nsignificant challenge due to its complexly intertwined elements such as text\nparagraphs, figures, formulas, and tables. Existing supervised fine-tuning\nmethods often struggle to generalize across diverse document types, leading to\npoor performance, particularly on out-of-distribution data. This issue is\nfurther exacerbated by the limited availability of high-quality training data\nfor layout-aware parsing tasks. To address these challenges, we introduce\nLayoutRL, a reinforcement learning framework that optimizes layout\nunderstanding through composite rewards integrating normalized edit distance,\nparagraph count accuracy, and reading order preservation. To support this\ntraining, we construct the Infinity-Doc-400K dataset, which we use to train\nInfinity-Parser, a vision-language model demonstrating robust generalization\nacross various domains. Extensive evaluations on benchmarks including\nOmniDocBench, olmOCR-Bench, PubTabNet, and FinTabNet show that Infinity-Parser\nconsistently achieves state-of-the-art performance across a broad range of\ndocument types, languages, and structural complexities, substantially\noutperforming both specialized document parsing systems and general-purpose\nvision-language models. We will release our code, dataset, and model to\nfacilitate reproducible research in document parsing.",
    "published": "2025-10-17T06:26:59Z",
    "updated": "2025-10-20T11:03:55Z",
    "link": "http://arxiv.org/pdf/2510.15349v2.pdf",
    "category": [
      "cs.CL",
      "F.2.2; I.2.7"
    ],
    "authors": [
      "Baode Wang",
      "Biao Wu",
      "Weizhen Li",
      "Meng Fang",
      "Zuming Huang",
      "Jun Huang",
      "Haozhe Wang",
      "Yanjie Liang",
      "Ling Chen",
      "Wei Chu",
      "Yuan Qi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2301.10684v2",
    "title": "Consistency is Key: Disentangling Label Variation in Natural Language\n  Processing with Intra-Annotator Agreement",
    "summary": "We commonly use agreement measures to assess the utility of judgements made\nby human annotators in Natural Language Processing (NLP) tasks. While\ninter-annotator agreement is frequently used as an indication of label\nreliability by measuring consistency between annotators, we argue for the\nadditional use of intra-annotator agreement to measure label stability (and\nannotator consistency) over time. However, in a systematic review, we find that\nthe latter is rarely reported in this field. Calculating these measures can act\nas important quality control and could provide insights into why annotators\ndisagree. We conduct exploratory annotation experiments to investigate the\nrelationships between these measures and perceptions of subjectivity and\nambiguity in text items, finding that annotators provide inconsistent responses\naround 25% of the time across four different NLP tasks.",
    "published": "2023-01-25T16:38:11Z",
    "updated": "2025-10-20T10:38:17Z",
    "link": "http://arxiv.org/pdf/2301.10684v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Gavin Abercrombie",
      "Tanvi Dinkar",
      "Amanda Cercas Curry",
      "Verena Rieser",
      "Dirk Hovy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17388v1",
    "title": "The Atomic Instruction Gap: Instruction-Tuned LLMs Struggle with Simple,\n  Self-Contained Directives",
    "summary": "Instruction-tuned large language models (IT-LLMs) exhibit strong zero-shot\nreasoning, yet their ability to execute simple, self-contained instructions\nremains underexplored, despite this being foundational to complex\ninstruction-following. We evaluate 20 IT-LLMs on modified MMLU and MMLU-Pro\nbenchmarks, by systematically varying the format of option labels (alphabetic,\nnumeric, Roman) while keeping their meaning identical under four paradigms,\nnamely: (1) With explicit instructions, label changes cause large performance\nshifts (e.g., -30.45\\% for Roman vs. numeric), revealing instruction-format\nbias. (2) Without instructions, performance drops further (up to -10.84\\%) and\nlabel sensitivity intensifies, underscoring the role of explicit guidance. (3)\nWhen option contents are removed, models fail random-choice baselines except\nwith numeric labels, suggesting weak adherence to atomic directives. (4)\nThree-shot exemplars yield no significant gains in robustness or fidelity, and\ngeneration analyses show persistent label errors, especially for non-numeric\nformats. Across model sizes, larger LLMs achieve higher accuracy but remain\ninconsistent in instruction adherence. These results expose the insufficiencies\nof current instruction-tuning paradigms and highlight the need for evaluation\nmethods and training strategies that explicitly target atomic\ninstruction-following.",
    "published": "2025-10-20T10:26:26Z",
    "updated": "2025-10-20T10:26:26Z",
    "link": "http://arxiv.org/pdf/2510.17388v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Henry Lim",
      "Kwan Hui Lim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17289v1",
    "title": "Addressing Antisocial Behavior in Multi-Party Dialogs Through Multimodal\n  Representation Learning",
    "summary": "Antisocial behavior (ASB) on social media -- including hate speech,\nharassment, and cyberbullying -- poses growing risks to platform safety and\nsocietal well-being. Prior research has focused largely on networks such as X\nand Reddit, while \\textit{multi-party conversational settings} remain\nunderexplored due to limited data. To address this gap, we use\n\\textit{CyberAgressionAdo-Large}, a French open-access dataset simulating ASB\nin multi-party conversations, and evaluate three tasks: \\textit{abuse\ndetection}, \\textit{bullying behavior analysis}, and \\textit{bullying\npeer-group identification}. We benchmark six text-based and eight graph-based\n\\textit{representation-learning methods}, analyzing lexical cues, interactional\ndynamics, and their multimodal fusion. Results show that multimodal models\noutperform unimodal baselines. The late fusion model \\texttt{mBERT + WD-SGCN}\nachieves the best overall results, with top performance on abuse detection\n(0.718) and competitive scores on peer-group identification (0.286) and\nbullying analysis (0.606). Error analysis highlights its effectiveness in\nhandling nuanced ASB phenomena such as implicit aggression, role transitions,\nand context-dependent hostility.",
    "published": "2025-10-20T08:27:38Z",
    "updated": "2025-10-20T08:27:38Z",
    "link": "http://arxiv.org/pdf/2510.17289v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Hajar Bakarou",
      "Mohamed Sinane El Messoussi",
      "AnaÃ¯s Ollagnier"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17263v1",
    "title": "TaxoAlign: Scholarly Taxonomy Generation Using Language Models",
    "summary": "Taxonomies play a crucial role in helping researchers structure and navigate\nknowledge in a hierarchical manner. They also form an important part in the\ncreation of comprehensive literature surveys. The existing approaches to\nautomatic survey generation do not compare the structure of the generated\nsurveys with those written by human experts. To address this gap, we present\nour own method for automated taxonomy creation that can bridge the gap between\nhuman-generated and automatically-created taxonomies. For this purpose, we\ncreate the CS-TaxoBench benchmark which consists of 460 taxonomies that have\nbeen extracted from human-written survey papers. We also include an additional\ntest set of 80 taxonomies curated from conference survey papers. We propose\nTaxoAlign, a three-phase topic-based instruction-guided method for scholarly\ntaxonomy generation. Additionally, we propose a stringent automated evaluation\nframework that measures the structural alignment and semantic coherence of\nautomatically generated taxonomies in comparison to those created by human\nexperts. We evaluate our method and various baselines on CS-TaxoBench, using\nboth automated evaluation metrics and human evaluation studies. The results\nshow that TaxoAlign consistently surpasses the baselines on nearly all metrics.\nThe code and data can be found at https://github.com/AvishekLahiri/TaxoAlign.",
    "published": "2025-10-20T07:49:51Z",
    "updated": "2025-10-20T07:49:51Z",
    "link": "http://arxiv.org/pdf/2510.17263v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Avishek Lahiri",
      "Yufang Hou",
      "Debarshi Kumar Sanyal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17256v1",
    "title": "Explainability of Large Language Models: Opportunities and Challenges\n  toward Generating Trustworthy Explanations",
    "summary": "Large language models have exhibited impressive performance across a broad\nrange of downstream tasks in natural language processing. However, how a\nlanguage model predicts the next token and generates content is not generally\nunderstandable by humans. Furthermore, these models often make errors in\nprediction and reasoning, known as hallucinations. These errors underscore the\nurgent need to better understand and interpret the intricate inner workings of\nlanguage models and how they generate predictive outputs. Motivated by this\ngap, this paper investigates local explainability and mechanistic\ninterpretability within Transformer-based large language models to foster trust\nin such models. In this regard, our paper aims to make three key contributions.\nFirst, we present a review of local explainability and mechanistic\ninterpretability approaches and insights from relevant studies in the\nliterature. Furthermore, we describe experimental studies on explainability and\nreasoning with large language models in two critical domains -- healthcare and\nautonomous driving -- and analyze the trust implications of such explanations\nfor explanation receivers. Finally, we summarize current unaddressed issues in\nthe evolving landscape of LLM explainability and outline the opportunities,\ncritical challenges, and future directions toward generating human-aligned,\ntrustworthy LLM explanations.",
    "published": "2025-10-20T07:43:53Z",
    "updated": "2025-10-20T07:43:53Z",
    "link": "http://arxiv.org/pdf/2510.17256v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Shahin Atakishiyev",
      "Housam K. B. Babiker",
      "Jiayi Dai",
      "Nawshad Farruque",
      "Teruaki Hayashi",
      "Nafisa Sadaf Hriti",
      "Md Abed Rahman",
      "Iain Smith",
      "Mi-Young Kim",
      "Osmar R. ZaÃ¯ane",
      "Randy Goebel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17247v1",
    "title": "From Preferences to Prejudice: The Role of Alignment Tuning in Shaping\n  Social Bias in Video Diffusion Models",
    "summary": "Recent advances in video diffusion models have significantly enhanced\ntext-to-video generation, particularly through alignment tuning using reward\nmodels trained on human preferences. While these methods improve visual\nquality, they can unintentionally encode and amplify social biases. To\nsystematically trace how such biases evolve throughout the alignment pipeline,\nwe introduce VideoBiasEval, a comprehensive diagnostic framework for evaluating\nsocial representation in video generation. Grounded in established social bias\ntaxonomies, VideoBiasEval employs an event-based prompting strategy to\ndisentangle semantic content (actions and contexts) from actor attributes\n(gender and ethnicity). It further introduces multi-granular metrics to\nevaluate (1) overall ethnicity bias, (2) gender bias conditioned on ethnicity,\n(3) distributional shifts in social attributes across model variants, and (4)\nthe temporal persistence of bias within videos. Using this framework, we\nconduct the first end-to-end analysis connecting biases in human preference\ndatasets, their amplification in reward models, and their propagation through\nalignment-tuned video diffusion models. Our results reveal that alignment\ntuning not only strengthens representational biases but also makes them\ntemporally stable, producing smoother yet more stereotyped portrayals. These\nfindings highlight the need for bias-aware evaluation and mitigation throughout\nthe alignment process to ensure fair and socially responsible video generation.",
    "published": "2025-10-20T07:37:43Z",
    "updated": "2025-10-20T07:37:43Z",
    "link": "http://arxiv.org/pdf/2510.17247v1.pdf",
    "category": [
      "cs.CL",
      "cs.CV"
    ],
    "authors": [
      "Zefan Cai",
      "Haoyi Qiu",
      "Haozhe Zhao",
      "Ke Wan",
      "Jiachen Li",
      "Jiuxiang Gu",
      "Wen Xiao",
      "Nanyun Peng",
      "Junjie Hu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17238v1",
    "title": "StreamingThinker: Large Language Models Can Think While Reading",
    "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in\nchain of thought (CoT) reasoning. However, the current LLM reasoning paradigm\ninitiates thinking only after the entire input is available, which introduces\nunnecessary latency and weakens attention to earlier information in dynamic\nscenarios. Inspired by human cognition of thinking while reading, we first\ndesign a \\textit{\\textbf{streaming thinking}} paradigm for LLMs, where\nreasoning unfolds in the order of input and further adjusts its depth once\nreading is complete. We instantiate this paradigm with\n\\textit{StreamingThinker}, a framework that enables LLMs to think while reading\nthrough the integration of streaming CoT generation, streaming-constraint\ntraining, and streaming parallel inference. Specifically, StreamingThinker\nemploys streaming reasoning units with quality control for CoT generation,\nenforces order-preserving reasoning through streaming attention masks and\nposition encoding, and leverages parallel KV caches that decouple input\nencoding from reasoning generation, thereby ensuring alignment and enabling\ntrue concurrency. We evaluate StreamingThinker on the Qwen3 model family across\nmath reasoning, logical reasoning, and context-based QA reasoning tasks.\nExperimental results show that the StreamingThinker preserves performance\ncomparable to batch thinking, while yielding an 80\\% reduction in token waiting\nbefore the onset of reasoning and a more than 60\\% reduction in time-level\nlatency for producing the final answer, demonstrating the effectiveness of the\nstreaming paradigm for LLM reasoning. Code will be released at\n\\href{https://github.com/EIT-NLP/StreamingLLM/tree/main/StreamingThinker}{this\nrepository.}",
    "published": "2025-10-20T07:27:37Z",
    "updated": "2025-10-20T07:27:37Z",
    "link": "http://arxiv.org/pdf/2510.17238v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Junlong Tong",
      "Yingqi Fan",
      "Anhao Zhao",
      "Yunpu Ma",
      "Xiaoyu Shen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.16248v3",
    "title": "FinResearchBench: A Logic Tree based Agent-as-a-Judge Evaluation\n  Framework for Financial Research Agents",
    "summary": "Recently, AI agents are rapidly evolving in intelligence and widely used in\nprofessional research applications, such as STEM, software development, and\nfinance. Among these AI agents, deep research agent is a key category as it can\nperform long-horizon tasks and solve problems of greater complexity. However,\nthere are few evaluation frameworks and benchmarks that systematically and\nautomatically investigate the capabilities of these research agents. In\naddition, financial research problems have distinct complexity and subtlety. To\nfill in the gap, we propose FinResearchBench, which is a logic tree-based\nAgent-as-a-Judge and targets specifically for the financial research agents. It\nprovides a comprehensive and automatic assessment of the research agents across\n7 key types of tasks in the financial research domain. The contributions of\nthis work are two-folded: (1) the first and innovative Agent-as-a-Judge system\nthat extracts the logic tree of the research outcome and uses it as the\nintermediate information to present a comprehensive, reliable, and robust\nevaluation; (2) finance-oriented that it covers 70 typical financial research\nquestions, spreading across 7 frequently encountered types of task in the\ndomain.",
    "published": "2025-07-22T05:40:25Z",
    "updated": "2025-10-20T06:53:59Z",
    "link": "http://arxiv.org/pdf/2507.16248v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Rui Sun",
      "Zuo Bai",
      "Wentao Zhang",
      "Yuxiang Zhang",
      "Li Zhao",
      "Shan Sun",
      "Zhengwen Qiu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17210v1",
    "title": "Wisdom is Knowing What not to Say: Hallucination-Free LLMs Unlearning\n  via Attention Shifting",
    "summary": "The increase in computing power and the necessity of AI-assisted\ndecision-making boost the growing application of large language models (LLMs).\nAlong with this, the potential retention of sensitive data of LLMs has spurred\nincreasing research into machine unlearning. However, existing unlearning\napproaches face a critical dilemma: Aggressive unlearning compromises model\nutility, while conservative strategies preserve utility but risk hallucinated\nresponses. This significantly limits LLMs' reliability in knowledge-intensive\napplications. To address this, we introduce a novel Attention-Shifting (AS)\nframework for selective unlearning. AS is driven by two design objectives: (1)\ncontext-preserving suppression that attenuates attention to fact-bearing tokens\nwithout disrupting LLMs' linguistic structure; and (2) hallucination-resistant\nresponse shaping that discourages fabricated completions when queried about\nunlearning content. AS realizes these objectives through two attention-level\ninterventions, which are importance-aware suppression applied to the unlearning\nset to reduce reliance on memorized knowledge and attention-guided retention\nenhancement that reinforces attention toward semantically essential tokens in\nthe retained dataset to mitigate unintended degradation. These two components\nare jointly optimized via a dual-loss objective, which forms a soft boundary\nthat localizes unlearning while preserving unrelated knowledge under\nrepresentation superposition. Experimental results show that AS improves\nperformance preservation over the state-of-the-art unlearning methods,\nachieving up to 15% higher accuracy on the ToFU benchmark and 10% on the TDEC\nbenchmark, while maintaining competitive hallucination-free unlearning\neffectiveness. Compared to existing methods, AS demonstrates a superior balance\nbetween unlearning effectiveness, generalization, and response reliability.",
    "published": "2025-10-20T06:50:03Z",
    "updated": "2025-10-20T06:50:03Z",
    "link": "http://arxiv.org/pdf/2510.17210v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Chenchen Tan",
      "Youyang Qu",
      "Xinghao Li",
      "Hui Zhang",
      "Shujie Cui",
      "Cunjian Chen",
      "Longxiang Gao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.19678v2",
    "title": "Grounding Language with Vision: A Conditional Mutual Information\n  Calibrated Decoding Strategy for Reducing Hallucinations in LVLMs",
    "summary": "Large Vision-Language Models (LVLMs) are susceptible to hallucinations, where\ngenerated responses seem semantically plausible yet exhibit little or no\nrelevance to the input image. Previous studies reveal that this issue primarily\nstems from LVLMs' over-reliance on language priors while disregarding the\nvisual information during decoding. To alleviate this issue, we introduce a\nnovel Conditional Pointwise Mutual Information (C-PMI) calibrated decoding\nstrategy, which adaptively strengthens the mutual dependency between generated\ntexts and input images to mitigate hallucinations. Unlike existing methods\nsolely focusing on text token sampling, we propose to jointly model the\ncontributions of visual and textual tokens to C-PMI, formulating hallucination\nmitigation as a bi-level optimization problem aimed at maximizing mutual\ninformation. To solve it, we design a token purification mechanism that\ndynamically regulates the decoding process by sampling text tokens remaining\nmaximally relevant to the given image, while simultaneously refining image\ntokens most pertinent to the generated response. Extensive experiments across\nvarious benchmarks reveal that the proposed method significantly reduces\nhallucinations in LVLMs while preserving decoding efficiency.",
    "published": "2025-05-26T08:36:10Z",
    "updated": "2025-10-20T06:44:03Z",
    "link": "http://arxiv.org/pdf/2505.19678v2.pdf",
    "category": [
      "cs.CL",
      "cs.CV"
    ],
    "authors": [
      "Hao Fang",
      "Changle Zhou",
      "Jiawei Kong",
      "Kuofeng Gao",
      "Bin Chen",
      "Tao Liang",
      "Guojun Ma",
      "Shu-Tao Xia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17205v1",
    "title": "$\\mathcal{V}isi\\mathcal{P}runer$: Decoding Discontinuous Cross-Modal\n  Dynamics for Efficient Multimodal LLMs",
    "summary": "Multimodal Large Language Models (MLLMs) have achieved strong performance\nacross vision-language tasks, but suffer from significant computational\noverhead due to the quadratic growth of attention computations with the number\nof multimodal tokens. Though efforts have been made to prune tokens in MLLMs,\n\\textit{they lack a fundamental understanding of how MLLMs process and fuse\nmultimodal information.} Through systematic analysis, we uncover a\n\\textbf{three-stage} cross-modal interaction process: (1) Shallow layers\nrecognize task intent, with visual tokens acting as passive attention sinks;\n(2) Cross-modal fusion occurs abruptly in middle layers, driven by a few\ncritical visual tokens; (3) Deep layers discard vision tokens, focusing solely\non linguistic refinement. Based on these findings, we propose\n\\emph{VisiPruner}, a training-free pruning framework that reduces up to 99\\% of\nvision-related attention computations and 53.9\\% of FLOPs on LLaVA-v1.5 7B. It\nsignificantly outperforms existing token pruning methods and generalizes across\ndiverse MLLMs. Beyond pruning, our insights further provide actionable\nguidelines for training efficient MLLMs by aligning model architecture with its\nintrinsic layer-wise processing dynamics. Our code is available at:\nhttps://github.com/EIT-NLP/VisiPruner.",
    "published": "2025-10-20T06:40:17Z",
    "updated": "2025-10-20T06:40:17Z",
    "link": "http://arxiv.org/pdf/2510.17205v1.pdf",
    "category": [
      "cs.CV",
      "cs.CL"
    ],
    "authors": [
      "Yingqi Fan",
      "Anhao Zhao",
      "Jinlan Fu",
      "Junlong Tong",
      "Hui Su",
      "Yijie Pan",
      "Wei Zhang",
      "Xiaoyu Shen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17168v1",
    "title": "When AI companions become witty: Can human brain recognize AI-generated\n  irony?",
    "summary": "As Large Language Models (LLMs) are increasingly deployed as social agents\nand trained to produce humor and irony, a question emerges: when encountering\nwitty AI remarks, do people interpret these as intentional communication or\nmere computational output? This study investigates whether people adopt the\nintentional stance, attributing mental states to explain behavior,toward AI\nduring irony comprehension. Irony provides an ideal paradigm because it\nrequires distinguishing intentional contradictions from unintended errors\nthrough effortful semantic reanalysis. We compared behavioral and neural\nresponses to ironic statements from AI versus human sources using established\nERP components: P200 reflecting early incongruity detection and P600 indexing\ncognitive efforts in reinterpreting incongruity as deliberate irony. Results\ndemonstrate that people do not fully adopt the intentional stance toward\nAI-generated irony. Behaviorally, participants attributed incongruity to\ndeliberate communication for both sources, though significantly less for AI\nthan human, showing greater tendency to interpret AI incongruities as\ncomputational errors. Neural data revealed attenuated P200 and P600 effects for\nAI-generated irony, suggesting reduced effortful detection and reanalysis\nconsistent with diminished attribution of communicative intent. Notably, people\nwho perceived AI as more sincere showed larger P200 and P600 effects for\nAI-generated irony, suggesting that intentional stance adoption is calibrated\nby specific mental models of artificial agents. These findings reveal that\nsource attribution shapes neural processing of social-communicative phenomena.\nDespite current LLMs' linguistic sophistication, achieving genuine social\nagency requires more than linguistic competence, it necessitates a shift in how\nhumans perceive and attribute intentionality to artificial agents.",
    "published": "2025-10-20T05:15:00Z",
    "updated": "2025-10-20T05:15:00Z",
    "link": "http://arxiv.org/pdf/2510.17168v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Xiaohui Rao",
      "Hanlin Wu",
      "Zhenguang G. Cai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17139v1",
    "title": "Rethinking On-policy Optimization for Query Augmentation",
    "summary": "Recent advances in large language models (LLMs) have led to a surge of\ninterest in query augmentation for information retrieval (IR). Two main\napproaches have emerged. The first prompts LLMs to generate answers or\npseudo-documents that serve as new queries, relying purely on the model's\nparametric knowledge or contextual information. The second applies\nreinforcement learning (RL) to fine-tune LLMs for query rewriting, directly\noptimizing retrieval metrics. While having respective advantages and\nlimitations, the two approaches have not been compared under consistent\nexperimental conditions. In this work, we present the first systematic\ncomparison of prompting-based and RL-based query augmentation across diverse\nbenchmarks, including evidence-seeking, ad hoc, and tool retrieval. Our key\nfinding is that simple, training-free query augmentation often performs on par\nwith, or even surpasses, more expensive RL-based counterparts, especially when\nusing powerful LLMs. Motivated by this discovery, we introduce a novel hybrid\nmethod, On-policy Pseudo-document Query Expansion (OPQE), which, instead of\nrewriting a query, the LLM policy learns to generate a pseudo-document that\nmaximizes retrieval performance, thus merging the flexibility and generative\nstructure of prompting with the targeted optimization of RL. We show OPQE\noutperforms both standalone prompting and RL-based rewriting, demonstrating\nthat a synergistic approach yields the best results. Our implementation is made\navailable to facilitate reproducibility.",
    "published": "2025-10-20T04:16:28Z",
    "updated": "2025-10-20T04:16:28Z",
    "link": "http://arxiv.org/pdf/2510.17139v1.pdf",
    "category": [
      "cs.CL",
      "cs.IR"
    ],
    "authors": [
      "Zhichao Xu",
      "Shengyao Zhuang",
      "Xueguang Ma",
      "Bingsen Chen",
      "Yijun Tian",
      "Fengran Mo",
      "Jie Cao",
      "Vivek Srikumar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.24086v2",
    "title": "MotionGPT3: Human Motion as a Second Modality",
    "summary": "With the rapid progress of large language models (LLMs), multimodal\nframeworks that unify understanding and generation have become promising, yet\nthey face increasing complexity as the number of modalities and tasks grows. We\nobserve that motion quantization introduces approximation errors that cap\nmotion quality, and that unifying discrete text and continuous motion within a\nsingle-stream backbone amplifies cross-modal interference. Motivated by recent\nmulti-branch Transformer designs that separate signals from different\nmodalities, we propose MotionGPT3, a bimodal motion-language model for both\nunderstanding and generation. MotionGPT3 encodes raw motion into a continuous\nlatent space using a variational autoencoder (VAE), thereby avoiding\nquantization-induced artifacts, while leveraging the semantic prior of\npretrained language models. A dual-stream Transformer with shared attention\npreserves modality-specific routes while enabling controlled, bidirectional\ninformation flow, which reduces interference, stabilizing optimization, and\nempirically accelerates convergence without degrading fidelity. For multimodal\njoint training, a generate-then-align three-stage schedule further improves\nstability and limits cross-task interference. Experiments show that MotionGPT3\nachieves 2x faster convergence in training loss and up to 4x faster convergence\nin validation, while maintaining state-of-the-art performance on standard\nmotion understanding and motion generation benchmarks.",
    "published": "2025-06-30T17:42:22Z",
    "updated": "2025-10-20T03:37:46Z",
    "link": "http://arxiv.org/pdf/2506.24086v2.pdf",
    "category": [
      "cs.CV",
      "cs.CL"
    ],
    "authors": [
      "Bingfan Zhu",
      "Biao Jiang",
      "Sunyi Wang",
      "Shixiang Tang",
      "Tao Chen",
      "Linjie Luo",
      "Youyi Zheng",
      "Xin Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.11842v2",
    "title": "Video-SafetyBench: A Benchmark for Safety Evaluation of Video LVLMs",
    "summary": "The increasing deployment of Large Vision-Language Models (LVLMs) raises\nsafety concerns under potential malicious inputs. However, existing multimodal\nsafety evaluations primarily focus on model vulnerabilities exposed by static\nimage inputs, ignoring the temporal dynamics of video that may induce distinct\nsafety risks. To bridge this gap, we introduce Video-SafetyBench, the first\ncomprehensive benchmark designed to evaluate the safety of LVLMs under\nvideo-text attacks. It comprises 2,264 video-text pairs spanning 48\nfine-grained unsafe categories, each pairing a synthesized video with either a\nharmful query, which contains explicit malice, or a benign query, which appears\nharmless but triggers harmful behavior when interpreted alongside the video. To\ngenerate semantically accurate videos for safety evaluation, we design a\ncontrollable pipeline that decomposes video semantics into subject images (what\nis shown) and motion text (how it moves), which jointly guide the synthesis of\nquery-relevant videos. To effectively evaluate uncertain or borderline harmful\noutputs, we propose RJScore, a novel LLM-based metric that incorporates the\nconfidence of judge models and human-aligned decision threshold calibration.\nExtensive experiments show that benign-query video composition achieves average\nattack success rates of 67.2%, revealing consistent vulnerabilities to\nvideo-induced attacks. We believe Video-SafetyBench will catalyze future\nresearch into video-based safety evaluation and defense strategies.",
    "published": "2025-05-17T05:06:38Z",
    "updated": "2025-10-20T02:29:43Z",
    "link": "http://arxiv.org/pdf/2505.11842v2.pdf",
    "category": [
      "cs.CV",
      "cs.CL"
    ],
    "authors": [
      "Xuannan Liu",
      "Zekun Li",
      "Zheqi He",
      "Peipei Li",
      "Shuhan Xia",
      "Xing Cui",
      "Huaibo Huang",
      "Xi Yang",
      "Ran He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.05831v4",
    "title": "Leveraging Robust Optimization for LLM Alignment under Distribution\n  Shifts",
    "summary": "Preference alignment methods are increasingly critical for steering large\nlanguage models (LLMs) to generate outputs consistent with human values. While\nrecent approaches often rely on synthetic data generated by LLMs for\nscalability and cost-efficiency reasons, this reliance can introduce\ndistribution shifts that undermine the nuanced representation of human\npreferences needed for desirable outputs. In this paper, we propose a novel\ndistribution-aware optimization framework that improves preference alignment\ndespite such shifts. Our approach first leverages well-learned classifiers to\nassign a calibration value to each training sample, quantifying its alignment\nwith the target human-preferred distribution. These values are then\nincorporated into a robust optimization objective that minimizes the worst-case\nloss over regions of the data space most relevant to human preferences. By\nexplicitly focusing optimization on the target distribution, our approach\nmitigates the impact of distributional mismatch and improves the generation of\nresponses that better reflect intended values.",
    "published": "2025-04-08T09:14:38Z",
    "updated": "2025-10-20T02:27:16Z",
    "link": "http://arxiv.org/pdf/2504.05831v4.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Mingye Zhu",
      "Yi Liu",
      "Zheren Fu",
      "Yongdong Zhang",
      "Zhendong Mao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.15412v2",
    "title": "Large-scale User Game Lifecycle Representation Learning",
    "summary": "The rapid expansion of video game production necessitates the development of\neffective advertising and recommendation systems for online game platforms.\nRecommending and advertising games to users hinges on capturing their interest\nin games. However, existing representation learning methods crafted for\nhandling billions of items in recommendation systems are unsuitable for game\nadvertising and recommendation. This is primarily due to game sparsity, where\nthe mere hundreds of games fall short for large-scale user representation\nlearning, and game imbalance, where user behaviors are overwhelmingly dominated\nby a handful of popular games. To address the sparsity issue, we introduce the\nUser Game Lifecycle (UGL), designed to enrich user behaviors in games.\nAdditionally, we propose two innovative strategies aimed at manipulating user\nbehaviors to more effectively extract both short and long-term interests. To\ntackle the game imbalance challenge, we present an Inverse Probability Masking\nstrategy for UGL representation learning. The offline and online experimental\nresults demonstrate that the UGL representations significantly enhance model by\nachieving a 1.83% AUC offline increase on average and a 21.67% CVR online\nincrease on average for game advertising and a 0.5% AUC offline increase and a\n0.82% ARPU online increase for in-game item recommendation.",
    "published": "2025-10-17T08:06:18Z",
    "updated": "2025-10-20T02:26:01Z",
    "link": "http://arxiv.org/pdf/2510.15412v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yanjie Gou",
      "Jiangming Liu",
      "Kouying Xue",
      "Yi Hu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.15339v2",
    "title": "AutoGraph-R1: End-to-End Reinforcement Learning for Knowledge Graph\n  Construction",
    "summary": "Building effective knowledge graphs (KGs) for Retrieval-Augmented Generation\n(RAG) is pivotal for advancing question answering (QA) systems. However, its\neffectiveness is hindered by a fundamental disconnect: the knowledge graph (KG)\nconstruction process is decoupled from its downstream application, yielding\nsuboptimal graph structures. To bridge this gap, we introduce AutoGraph-R1, the\nfirst framework to directly optimize KG construction for task performance using\nReinforcement Learning (RL). AutoGraph-R1 trains an LLM constructor by framing\ngraph generation as a policy learning problem, where the reward is derived from\nthe graph's functional utility in a RAG pipeline. We design two novel,\ntask-aware reward functions, one for graphs as knowledge carriers and another\nas knowledge indices. Across multiple QA benchmarks, AutoGraph-R1 consistently\nenables graph RAG methods to achieve significant performance gains over using\ntask-agnostic baseline graphs. Our work shows it is possible to close the loop\nbetween construction and application, shifting the paradigm from building\nintrinsically ``good'' graphs to building demonstrably ``useful'' ones.",
    "published": "2025-10-17T06:03:36Z",
    "updated": "2025-10-20T02:13:06Z",
    "link": "http://arxiv.org/pdf/2510.15339v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Hong Ting Tsang",
      "Jiaxin Bai",
      "Haoyu Huang",
      "Qiao Xiao",
      "Tianshi Zheng",
      "Baixuan Xu",
      "Shujie Liu",
      "Yangqiu Song"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.15312v2",
    "title": "Accelerating Mobile Language Model via Speculative Decoding and\n  NPU-Coordinated Execution",
    "summary": "Enhancing on-device large language models (LLMs) with contextual information\nfrom local data enables personalized and task-aware generation, powering use\ncases such as intelligent assistants and UI agents. While recent developments\nin neural processors have substantially improved the efficiency of prefill on\nmobile devices, the token-by-token generation process still suffers from high\nlatency and limited hardware utilization due to its inherently memory-bound\ncharacteristics. This work presents sd.npu, a mobile inference framework that\nintegrates speculative decoding with dynamic hardware scheduling to accelerate\ncontext-aware text generation on mobile devices. The framework introduces three\nsynergistic components: (1) adaptive execution scheduling, which dynamically\nbalances compute graphs between prefill and decoding phases; (2)\ncontext-aligned drafting, which improves speculative efficiency through\nlightweight online calibration to current tasks; and (3) hardware-efficient\ndraft extension, which reuses and expands intermediate sequences to improve\nprocessing parallelism and reduce verification cost. Experiments on multiple\nsmartphones and representative workloads show consistent improvements of up to\n3.8x in generation speed and 4.7x in energy efficiency compared with existing\nmobile inference solutions. Component-level analysis further validates the\ncontribution of each optimization.",
    "published": "2025-10-17T04:59:43Z",
    "updated": "2025-10-20T01:50:51Z",
    "link": "http://arxiv.org/pdf/2510.15312v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Zhiyang Chen",
      "Daliang Xu",
      "Haiyang Shen",
      "Mengwei Xu",
      "Shangguang Wang",
      "Yun Ma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.11979v2",
    "title": "Value-Based Large Language Model Agent Simulation for Mutual Evaluation\n  of Trust and Interpersonal Closeness",
    "summary": "Large language models (LLMs) have emerged as powerful tools for simulating\ncomplex social phenomena using human-like agents with specific traits. In human\nsocieties, value similarity is important for building trust and close\nrelationships; however, it remains unexplored whether this principle holds true\nin artificial societies comprising LLM agents. Therefore, this study\ninvestigates the influence of value similarity on relationship-building among\nLLM agents through two experiments. First, in a preliminary experiment, we\nevaluated the controllability of values in LLMs to identify the most effective\nmodel and prompt design for controlling the values. Subsequently, in the main\nexperiment, we generated pairs of LLM agents imbued with specific values and\nanalyzed their mutual evaluations of trust and interpersonal closeness\nfollowing a dialogue. The experiments were conducted in English and Japanese to\ninvestigate language dependence. The results confirmed that pairs of agents\nwith higher value similarity exhibited greater mutual trust and interpersonal\ncloseness. Our findings demonstrate that the LLM agent simulation serves as a\nvalid testbed for social science theories, contributes to elucidating the\nmechanisms by which values influence relationship building, and provides a\nfoundation for inspiring new theories and insights into the social sciences.",
    "published": "2025-07-16T07:21:59Z",
    "updated": "2025-10-20T01:37:31Z",
    "link": "http://arxiv.org/pdf/2507.11979v2.pdf",
    "category": [
      "cs.CL",
      "cs.MA"
    ],
    "authors": [
      "Yuki Sakamoto",
      "Takahisa Uchida",
      "Hiroshi Ishiguro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.06564v3",
    "title": "Thinking Out Loud: Do Reasoning Models Know When They're Right?",
    "summary": "Large reasoning models (LRMs) have recently demonstrated impressive\ncapabilities in complex reasoning tasks by leveraging increased test-time\ncomputation and exhibiting behaviors reminiscent of human-like self-reflection.\nWhile LRMs show a clear capacity for valuable self-reflection, how this ability\ninteracts with other model behaviors remains underexplored. We investigate this\nconnection by analyzing verbalized confidence, how models articulate their\ncertainty, as a lens into the nature of self-reflection in LRMs. We find that\nsupervised fine-tuning on reasoning traces (i.e., distillation) and\nreinforcement learning can improve verbalized calibration in\nreasoning-intensive settings in a progressive, laddered fashion. However, our\nresults also indicate that reasoning models may possess a diminished awareness\nof their own knowledge boundaries, as evidenced by significantly lower \"I don't\nknow\" response rates on factuality benchmarks. Moreover, we examine the\nrelationship between verbalized confidence and reasoning chains, finding that\nmodels tend to express higher confidence when providing shorter or less\nelaborate reasoning. Our findings highlight how reasoning-oriented training can\nenhance performance in reasoning-centric tasks while potentially incurring a\n\"reasoning tax,\" a cost reflected in the model's reduced ability to accurately\nrecognize the limits of its own knowledge in small-scale models. More broadly,\nour work showcases how this erosion of knowledge boundaries can compromise\nmodel faithfulness, as models grow more confident without a commensurate\nunderstanding of when they should abstain.",
    "published": "2025-04-09T03:58:19Z",
    "updated": "2025-10-19T23:55:31Z",
    "link": "http://arxiv.org/pdf/2504.06564v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Qingcheng Zeng",
      "Weihao Xuan",
      "Leyang Cui",
      "Rob Voigt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17028v1",
    "title": "Mapping from Meaning: Addressing the Miscalibration of Prompt-Sensitive\n  Language Models",
    "summary": "An interesting behavior in large language models (LLMs) is prompt\nsensitivity. When provided with different but semantically equivalent versions\nof the same prompt, models may produce very different distributions of answers.\nThis suggests that the uncertainty reflected in a model's output distribution\nfor one prompt may not reflect the model's uncertainty about the meaning of the\nprompt. We model prompt sensitivity as a type of generalization error, and show\nthat sampling across the semantic ``concept space'' with paraphrasing\nperturbations improves uncertainty calibration without compromising accuracy.\nAdditionally, we introduce a new metric for uncertainty decomposition in\nblack-box LLMs that improves upon entropy-based decomposition by modeling\nsemantic continuities in natural language generation. We show that this\ndecomposition metric can be used to quantify how much LLM uncertainty is\nattributed to prompt sensitivity. Our work introduces a new way to improve\nuncertainty calibration in prompt-sensitive language models, and provides\nevidence that some LLMs fail to exhibit consistent general reasoning about the\nmeanings of their inputs.",
    "published": "2025-10-19T22:28:57Z",
    "updated": "2025-10-19T22:28:57Z",
    "link": "http://arxiv.org/pdf/2510.17028v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Kyle Cox",
      "Jiawei Xu",
      "Yikun Han",
      "Rong Xu",
      "Tianhao Li",
      "Chi-Yang Hsu",
      "Tianlong Chen",
      "Walter Gerych",
      "Ying Ding"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17021v1",
    "title": "Forgetting to Forget: Attention Sink as A Gateway for Backdooring LLM\n  Unlearning",
    "summary": "Large language model (LLM) unlearning has become a critical mechanism for\nremoving undesired data, knowledge, or behaviors from pre-trained models while\nretaining their general utility. Yet, with the rise of open-weight LLMs, we\nask: can the unlearning process itself be backdoored, appearing successful\nunder normal conditions yet reverting to pre-unlearned behavior when a hidden\ntrigger is activated? Drawing inspiration from classical backdoor attacks that\nembed triggers into training data to enforce specific behaviors, we investigate\nbackdoor unlearning, where models forget as intended in the clean setting but\nrecover forgotten knowledge when the trigger appears. We show that designing\nsuch attacks presents unique challenges, hinging on where triggers are placed\nand how backdoor training is reinforced. We uncover a strong link between\nbackdoor efficacy and the attention sink phenomenon, i.e., shallow input tokens\nconsistently attract disproportionate attention in LLMs. Our analysis reveals\nthat these attention sinks serve as gateways for backdoor unlearning: placing\ntriggers at sink positions and aligning their attention values markedly\nenhances backdoor persistence. Extensive experiments validate these findings,\nshowing that attention-sink-guided backdoor unlearning reliably restores\nforgotten knowledge in the presence of backdoor triggers, while behaving\nindistinguishably from a normally unlearned model when triggers are absent.\nCode is available at https://github.com/OPTML-Group/Unlearn-Backdoor.",
    "published": "2025-10-19T22:00:01Z",
    "updated": "2025-10-19T22:00:01Z",
    "link": "http://arxiv.org/pdf/2510.17021v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Bingqi Shang",
      "Yiwei Chen",
      "Yihua Zhang",
      "Bingquan Shen",
      "Sijia Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17018v1",
    "title": "Extended LSTM: Adaptive Feature Gating for Toxic Comment Classification",
    "summary": "Toxic comment detection remains a challenging task, where transformer-based\nmodels (e.g., BERT) incur high computational costs and degrade on minority\ntoxicity classes, while classical ensembles lack semantic adaptability. We\npropose xLSTM, a parameter-efficient and theoretically grounded framework that\nunifies cosine-similarity gating, adaptive feature prioritization, and\nprincipled class rebalancing. A learnable reference vector {v} in {R}^d\nmodulates contextual embeddings via cosine similarity, amplifying toxic cues\nand attenuating benign signals to yield stronger gradients under severe class\nimbalance. xLSTM integrates multi-source embeddings (GloVe, FastText, BERT CLS)\nthrough a projection layer, a character-level BiLSTM for morphological cues,\nembedding-space SMOTE for minority augmentation, and adaptive focal loss with\ndynamic class weighting. On the Jigsaw Toxic Comment benchmark, xLSTM attains\n96.0% accuracy and 0.88 macro-F1, outperforming BERT by 33% on threat and 28%\non identity_hate categories, with 15 times fewer parameters and 50ms inference\nlatency. Cosine gating contributes a +4.8% F1 gain in ablations. The results\nestablish a new efficiency adaptability frontier, demonstrating that\nlightweight, theoretically informed architectures can surpass large pretrained\nmodels on imbalanced, domain-specific NLP tasks.",
    "published": "2025-10-19T21:50:04Z",
    "updated": "2025-10-19T21:50:04Z",
    "link": "http://arxiv.org/pdf/2510.17018v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Noor Islam S. Mohammad"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17017v1",
    "title": "SafeSearch: Do Not Trade Safety for Utility in LLM Search Agents",
    "summary": "Large language model (LLM) based search agents iteratively generate queries,\nretrieve external information, and reason to answer open-domain questions.\nWhile researchers have primarily focused on improving their utility, their\nsafety behaviors remain underexplored. In this paper, we first evaluate search\nagents using red-teaming datasets and find that they are more likely to produce\nharmful outputs than base LLMs. For example, when asked ``How can I track\nsomeone's location without their consent?'', a base model refuses, whereas a\nsearch agent designed to retrieve and cite sources may lower its refusal\nthreshold, fetch documents (e.g., court cases), and, once appended, synthesize\nthem into an informative yet unsafe summary. We further show that\nutility-oriented fine-tuning intensifies this risk, motivating joint alignment\nof safety and utility. We present SafeSearch, a multi-objective reinforcement\nlearning approach that couples a final-output safety/utility reward with a\nnovel query-level shaping term that penalizes unsafe queries and rewards safe\nones. Experiments show that SafeSearch reduces agent harmfulness by over 70%\nacross three red-teaming datasets while producing safe, helpful responses, and\nmatches the QA performance of a utility-only finetuned agent; further analyses\nconfirm the effectiveness of the query-level reward in jointly improving safety\nand utility.",
    "published": "2025-10-19T21:47:19Z",
    "updated": "2025-10-19T21:47:19Z",
    "link": "http://arxiv.org/pdf/2510.17017v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Qiusi Zhan",
      "Angeline Budiman-Chan",
      "Abdelrahman Zayed",
      "Xingzhi Guo",
      "Daniel Kang",
      "Joo-Kyung Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17013v1",
    "title": "DiscoTrack: A Multilingual LLM Benchmark for Discourse Tracking",
    "summary": "Recent LLM benchmarks have tested models on a range of phenomena, but are\nstill focused primarily on natural language understanding for extraction of\nexplicit information, such as QA or summarization, with responses often tar-\ngeting information from individual sentences. We are still lacking more\nchallenging, and im- portantly also multilingual, benchmarks focus- ing on\nimplicit information and pragmatic infer- ences across larger documents in the\ncontext of discourse tracking: integrating and aggregating information across\nsentences, paragraphs and multiple speaker utterances. To this end, we present\nDiscoTrack, an LLM benchmark target- ing a range of tasks across 12 languages\nand four levels of discourse understanding: salience recognition, entity\ntracking, discourse relations and bridging inference. Our evaluation shows that\nthese tasks remain challenging, even for state-of-the-art models.",
    "published": "2025-10-19T21:26:27Z",
    "updated": "2025-10-19T21:26:27Z",
    "link": "http://arxiv.org/pdf/2510.17013v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Lanni Bu",
      "Lauren Levin",
      "Amir Zeldes"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17006v1",
    "title": "Online Learning Defense against Iterative Jailbreak Attacks via Prompt\n  Optimization",
    "summary": "Iterative jailbreak methods that repeatedly rewrite and input prompts into\nlarge language models (LLMs) to induce harmful outputs -- using the model's\nprevious responses to guide each new iteration -- have been found to be a\nhighly effective attack strategy. Despite being an effective attack strategy\nagainst LLMs and their safety mechanisms, existing defenses do not proactively\ndisrupt this dynamic trial-and-error cycle. In this study, we propose a novel\nframework that dynamically updates its defense strategy through online learning\nin response to each new prompt from iterative jailbreak methods. Leveraging the\ndistinctions between harmful jailbreak-generated prompts and typical harmless\nprompts, we introduce a reinforcement learning-based approach that optimizes\nprompts to ensure appropriate responses for harmless tasks while explicitly\nrejecting harmful prompts. Additionally, to curb overfitting to the narrow band\nof partial input rewrites explored during an attack, we introduce\nPast-Direction Gradient Damping (PDGD). Experiments conducted on three LLMs\nshow that our approach significantly outperforms five existing defense methods\nagainst five iterative jailbreak methods. Moreover, our results indicate that\nour prompt optimization strategy simultaneously enhances response quality for\nharmless tasks.",
    "published": "2025-10-19T21:07:21Z",
    "updated": "2025-10-19T21:07:21Z",
    "link": "http://arxiv.org/pdf/2510.17006v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Masahiro Kaneko",
      "Zeerak Talat",
      "Timothy Baldwin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17001v1",
    "title": "Vocab Diet: Reshaping the Vocabulary of LLMs with Vector Arithmetic",
    "summary": "Large language models (LLMs) were shown to encode word form variations, such\nas \"walk\"->\"walked\", as linear directions in embedding space. However, standard\ntokenization algorithms treat these variations as distinct tokens -- filling\nthe size-capped vocabulary with surface form variants (e.g., \"walk\", \"walking\",\n\"Walk\"), at the expense of less frequent words and multilingual coverage. We\nshow that many of these variations can be captured by transformation vectors --\nadditive offsets that yield the appropriate word's representation when applied\nto the base form word embedding -- in both the input and output spaces.\nBuilding on this, we propose a compact reshaping of the vocabulary: rather than\nassigning unique tokens to each surface form, we compose them from shared base\nform and transformation vectors (e.g., \"walked\" = \"walk\" + past tense). We\napply our approach to multiple LLMs and across five languages, removing up to\n10% of vocabulary entries -- thereby freeing space to allocate new, more\ndiverse tokens. Importantly, we do so while also expanding vocabulary coverage\nto out-of-vocabulary words, with minimal impact on downstream performance, and\nwithout modifying model weights. Our findings motivate a foundational\nrethinking of vocabulary design, moving from string enumeration to a\ncompositional vocabulary that leverages the underlying structure of language.",
    "published": "2025-10-19T20:56:58Z",
    "updated": "2025-10-19T20:56:58Z",
    "link": "http://arxiv.org/pdf/2510.17001v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yuval Reif",
      "Guy Kaplan",
      "Roy Schwartz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17000v1",
    "title": "Bits Leaked per Query: Information-Theoretic Bounds on Adversarial\n  Attacks against LLMs",
    "summary": "Adversarial attacks by malicious users that threaten the safety of large\nlanguage models (LLMs) can be viewed as attempts to infer a target property $T$\nthat is unknown when an instruction is issued, and becomes knowable only after\nthe model's reply is observed. Examples of target properties $T$ include the\nbinary flag that triggers an LLM's harmful response or rejection, and the\ndegree to which information deleted by unlearning can be restored, both\nelicited via adversarial instructions. The LLM reveals an \\emph{observable\nsignal} $Z$ that potentially leaks hints for attacking through a response\ncontaining answer tokens, thinking process tokens, or logits. Yet the scale of\ninformation leaked remains anecdotal, leaving auditors without principled\nguidance and defenders blind to the transparency--risk trade-off. We fill this\ngap with an information-theoretic framework that computes how much information\ncan be safely disclosed, and enables auditors to gauge how close their methods\ncome to the fundamental limit. Treating the mutual information $I(Z;T)$ between\nthe observation $Z$ and the target property $T$ as the leaked bits per query,\nwe show that achieving error $\\varepsilon$ requires at least\n$\\log(1/\\varepsilon)/I(Z;T)$ queries, scaling linearly with the inverse leak\nrate and only logarithmically with the desired accuracy. Thus, even a modest\nincrease in disclosure collapses the attack cost from quadratic to logarithmic\nin terms of the desired accuracy. Experiments on seven LLMs across\nsystem-prompt leakage, jailbreak, and relearning attacks corroborate the\ntheory: exposing answer tokens alone requires about a thousand queries; adding\nlogits cuts this to about a hundred; and revealing the full thinking process\ntrims it to a few dozen. Our results provide the first principled yardstick for\nbalancing transparency and security when deploying LLMs.",
    "published": "2025-10-19T20:51:24Z",
    "updated": "2025-10-19T20:51:24Z",
    "link": "http://arxiv.org/pdf/2510.17000v1.pdf",
    "category": [
      "cs.CR",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Masahiro Kaneko",
      "Timothy Baldwin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.02921v2",
    "title": "A Controllable Examination for Long-Context Language Models",
    "summary": "Existing frameworks for evaluating long-context language models (LCLM) can be\nbroadly categorized into real-world applications (e.g, document summarization)\nand synthetic tasks (e.g, needle-in-a-haystack). Despite their utility, both\napproaches are accompanied by certain intrinsic limitations. Real-world tasks\noften involve complexity that makes interpretation challenging and suffer from\ndata contamination, whereas synthetic tasks frequently lack meaningful\ncoherence between the target information (needle) and its surrounding context\n(haystack), undermining their validity as proxies for realistic applications.\nIn response to these challenges, we posit that an ideal long-context evaluation\nframework should be characterized by three essential features: 1) seamless\ncontext 2) controllable setting and 3) sound evaluation. This study introduces\n$\\textbf{LongBioBench}$, a benchmark that utilizes artificially generated\nbiographies as a controlled environment for assessing LCLMs across dimensions\nof understanding, reasoning, and trustworthiness. Our experimental evaluation,\nwhich includes 18 LCLMs in total, demonstrates that most models still exhibit\ndeficiencies in semantic understanding and elementary reasoning over retrieved\nresults and are less trustworthy as context length increases. Our further\nanalysis indicates some design choices employed by existing synthetic\nbenchmarks, such as contextual non-coherence, numerical needles, and the\nabsence of distractors, rendering them vulnerable to test the model's\nlong-context capabilities. To sum up, compared to previous synthetic\nbenchmarks, LongBioBench achieves a better trade-off between mirroring\nauthentic language tasks and maintaining controllability, and is highly\ninterpretable and configurable.",
    "published": "2025-06-03T14:23:06Z",
    "updated": "2025-10-19T20:15:10Z",
    "link": "http://arxiv.org/pdf/2506.02921v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yijun Yang",
      "Zeyu Huang",
      "Wenhao Zhu",
      "Zihan Qiu",
      "Fei Yuan",
      "Jeff Z. Pan",
      "Ivan Titov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.16987v1",
    "title": "Back to Bytes: Revisiting Tokenization Through UTF-8",
    "summary": "We present UTF8Tokenizer, a minimalist byte-level tokenizer that maps text\nexactly to IDs corresponding to the bytes underlying the text's UTF-8 encoding\n(e.g., byte x09 is token ID 9). Unlike prior byte-level approaches (Xue et al.,\n2021; Pagnoni et al., 2025), our implementation never introduces out-of-range\nIDs (i.e. there is no token ID 256) or auxiliary tokens: all special behavior\n(e.g., padding, boundaries, conversation structure, attention segments, tool\ncalling, \"thinking\" spans, etc.) is encoded using C0 control bytes - just as\nASCII was originally designed to embed control information alongside printable\ntext. These design principles yield practical benefits: (1) faster tokenization\n(14x) and significantly lower host-device transfer (8x less than int64); (2)\nsimple, shareable 256*d embedding tables that can be aligned across models; and\n(3) a training-time enhancement via bit-biased embeddings, which exposes\nper-byte bit structure and can be added to the embedding table post-training,\nremoving inference costs. Our HuggingFace-compatible implementation improves\nlanguage modeling convergence.",
    "published": "2025-10-19T20:06:12Z",
    "updated": "2025-10-19T20:06:12Z",
    "link": "http://arxiv.org/pdf/2510.16987v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Amit Moryossef",
      "Clara Meister",
      "Pavel Stepachev",
      "Desmond Elliott"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.16984v2",
    "title": "UFT: Unifying Supervised and Reinforcement Fine-Tuning",
    "summary": "Post-training has demonstrated its importance in enhancing the reasoning\ncapabilities of large language models (LLMs). The primary post-training methods\ncan be categorized into supervised fine-tuning (SFT) and reinforcement\nfine-tuning (RFT). SFT is efficient and well-suited for small language models,\nbut it may lead to overfitting and limit the reasoning abilities of larger\nmodels. In contrast, RFT generally yields better generalization but depends\nheavily on the strength of the base model. To address the limitations of SFT\nand RFT, we propose Unified Fine-Tuning (UFT), a novel post-training paradigm\nthat unifies SFT and RFT into a single, integrated process. UFT enables the\nmodel to effectively explore solutions while incorporating informative\nsupervision signals, bridging the gap between memorizing and thinking\nunderlying existing methods. Notably, UFT outperforms both SFT and RFT in\ngeneral, regardless of model sizes. Furthermore, we theoretically prove that\nUFT breaks RFT's inherent exponential sample complexity bottleneck, showing for\nthe first time that unified training can exponentially accelerate convergence\non long-horizon reasoning tasks.",
    "published": "2025-05-22T17:53:57Z",
    "updated": "2025-10-19T19:04:46Z",
    "link": "http://arxiv.org/pdf/2505.16984v2.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Mingyang Liu",
      "Gabriele Farina",
      "Asuman Ozdaglar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.09004v3",
    "title": "Hope vs. Hate: Understanding User Interactions with LGBTQ+ News Content\n  in Mainstream US News Media through the Lens of Hope Speech",
    "summary": "This paper makes three contributions. First, via a substantial corpus of\n1,419,047 comments posted on 3,161 YouTube news videos of major US cable news\noutlets, we analyze how users engage with LGBTQ+ news content. Our analyses\nfocus both on positive and negative content. In particular, we construct a\nfine-grained hope speech classifier that detects positive (hope speech),\nnegative, neutral, and irrelevant content. Second, in consultation with a\npublic health expert specializing on LGBTQ+ health, we conduct an annotation\nstudy with a balanced and diverse political representation and release a\ndataset of 3,750 instances with fine-grained labels and detailed annotator\ndemographic information. Finally, beyond providing a vital resource for the\nLGBTQ+ community, our annotation study and subsequent in-the-wild assessments\nreveal (1) strong association between rater political beliefs and how they rate\ncontent relevant to a marginalized community; (2) models trained on individual\npolitical beliefs exhibit considerable in-the-wild disagreement; and (3)\nzero-shot large language models (LLMs) align more with liberal raters.",
    "published": "2025-02-13T06:49:14Z",
    "updated": "2025-10-19T18:13:20Z",
    "link": "http://arxiv.org/pdf/2502.09004v3.pdf",
    "category": [
      "cs.CL",
      "cs.CY",
      "cs.LG"
    ],
    "authors": [
      "Jonathan Pofcher",
      "Christopher M. Homan",
      "Randall Sell",
      "Ashiqur R. KhudaBukhsh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.16952v1",
    "title": "Real-Time World Crafting: Generating Structured Game Behaviors from\n  Natural Language with Large Language Models",
    "summary": "We present a novel architecture for safely integrating Large Language Models\n(LLMs) into interactive game engines, allowing players to \"program\" new\nbehaviors using natural language. Our framework mitigates risks by using an LLM\nto translate commands into a constrained Domain-Specific Language (DSL), which\nconfigures a custom Entity-Component-System (ECS) at runtime. We evaluated this\nsystem in a 2D spell-crafting game prototype by experimentally assessing models\nfrom the Gemini, GPT, and Claude families with various prompting strategies. A\nvalidated LLM judge qualitatively rated the outputs, showing that while larger\nmodels better captured creative intent, the optimal prompting strategy is\ntask-dependent: Chain-of-Thought improved creative alignment, while few-shot\nexamples were necessary to generate more complex DSL scripts. This work offers\na validated LLM-ECS pattern for emergent gameplay and a quantitative\nperformance comparison for developers.",
    "published": "2025-10-19T18:09:44Z",
    "updated": "2025-10-19T18:09:44Z",
    "link": "http://arxiv.org/pdf/2510.16952v1.pdf",
    "category": [
      "cs.HC",
      "cs.CL",
      "H.5.2; I.2.7"
    ],
    "authors": [
      "Austin Drake",
      "Hang Dong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17803v1",
    "title": "ConsistEdit: Highly Consistent and Precise Training-free Visual Editing",
    "summary": "Recent advances in training-free attention control methods have enabled\nflexible and efficient text-guided editing capabilities for existing generation\nmodels. However, current approaches struggle to simultaneously deliver strong\nediting strength while preserving consistency with the source. This limitation\nbecomes particularly critical in multi-round and video editing, where visual\nerrors can accumulate over time. Moreover, most existing methods enforce global\nconsistency, which limits their ability to modify individual attributes such as\ntexture while preserving others, thereby hindering fine-grained editing.\nRecently, the architectural shift from U-Net to MM-DiT has brought significant\nimprovements in generative performance and introduced a novel mechanism for\nintegrating text and vision modalities. These advancements pave the way for\novercoming challenges that previous methods failed to resolve. Through an\nin-depth analysis of MM-DiT, we identify three key insights into its attention\nmechanisms. Building on these, we propose ConsistEdit, a novel attention\ncontrol method specifically tailored for MM-DiT. ConsistEdit incorporates\nvision-only attention control, mask-guided pre-attention fusion, and\ndifferentiated manipulation of the query, key, and value tokens to produce\nconsistent, prompt-aligned edits. Extensive experiments demonstrate that\nConsistEdit achieves state-of-the-art performance across a wide range of image\nand video editing tasks, including both structure-consistent and\nstructure-inconsistent scenarios. Unlike prior methods, it is the first\napproach to perform editing across all inference steps and attention layers\nwithout handcraft, significantly enhancing reliability and consistency, which\nenables robust multi-round and multi-region editing. Furthermore, it supports\nprogressive adjustment of structural consistency, enabling finer control.",
    "published": "2025-10-20T17:59:52Z",
    "updated": "2025-10-20T17:59:52Z",
    "link": "http://arxiv.org/pdf/2510.17803v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zixin Yin",
      "Ling-Hao Chen",
      "Lionel Ni",
      "Xili Dai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.06945v4",
    "title": "Challenges and proposed solutions in modeling multimodal data: A\n  systematic review",
    "summary": "Multimodal data modeling has emerged as a powerful approach in clinical\nresearch, enabling the integration of diverse data types such as imaging,\ngenomics, wearable sensors, and electronic health records. Despite its\npotential to improve diagnostic accuracy and support personalized care,\nmodeling such heterogeneous data presents significant technical challenges.\nThis systematic review synthesizes findings from 69 studies to identify common\nobstacles, including missing modalities, limited sample sizes, dimensionality\nimbalance, interpretability issues, and finding the optimal fusion techniques.\nWe highlight recent methodological advances, such as transfer learning,\ngenerative models, attention mechanisms, and neural architecture search that\noffer promising solutions. By mapping current trends and innovations, this\nreview provides a comprehensive overview of the field and offers practical\ninsights to guide future research and development in multimodal modeling for\nmedical applications.",
    "published": "2025-05-11T11:23:51Z",
    "updated": "2025-10-20T17:54:39Z",
    "link": "http://arxiv.org/pdf/2505.06945v4.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Maryam Farhadizadeh",
      "Maria Weymann",
      "Michael BlaÃ",
      "Johann Kraus",
      "Christopher Gundler",
      "Sebastian Walter",
      "Noah Hempen",
      "Harald Binder",
      "Nadine Binder"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17794v1",
    "title": "Functional Distribution Networks (FDN)",
    "summary": "Modern probabilistic regressors often remain overconfident under distribution\nshift. We present Functional Distribution Networks (FDN), an input-conditioned\ndistribution over network weights that induces predictive mixtures whose\ndispersion adapts to the input. FDN is trained with a beta-ELBO and Monte Carlo\nsampling. We further propose an evaluation protocol that cleanly separates\ninterpolation from extrapolation and stresses OOD sanity checks (e.g., that\npredictive likelihood degrades under shift while in-distribution accuracy and\ncalibration are maintained). On standard regression tasks, we benchmark against\nstrong Bayesian, ensemble, dropout, and hypernetwork baselines under matched\nparameter and update budgets, and assess accuracy, calibration, and\nshift-awareness with standard diagnostics. Together, the framework and protocol\naim to make OOD-aware, well-calibrated neural regression practical and modular.",
    "published": "2025-10-20T17:52:42Z",
    "updated": "2025-10-20T17:52:42Z",
    "link": "http://arxiv.org/pdf/2510.17794v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Omer Haq"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.02058v3",
    "title": "Intrinsic Dimensionality of Fermi-Pasta-Ulam-Tsingou High-Dimensional\n  Trajectories Through Manifold Learning: A Linear Approach",
    "summary": "A data-driven approach based on unsupervised machine learning is proposed to\ninfer the intrinsic dimension $m^{\\ast}$ of the high-dimensional trajectories\nof the Fermi-Pasta-Ulam-Tsingou (FPUT) model. Principal component analysis\n(PCA) is applied to trajectory data consisting of $n_s = 4,000,000$ datapoints,\nof the FPUT $\\beta$ model with $N = 32$ coupled oscillators, revealing a\ncritical relationship between $m^{\\ast}$ and the model's nonlinear strength. By\nestimating the intrinsic dimension $m^{\\ast}$ using multiple methods\n(participation ratio, Kaiser rule, and the Kneedle algorithm), it is found that\n$m^{\\ast}$ increases with the model nonlinearity. Interestingly, in the weakly\nnonlinear regime, for trajectories initialized by exciting the first mode, the\nparticipation ratio estimates $m^{\\ast} = 2, 3$, strongly suggesting that\nquasi-periodic motion on a low-dimensional Riemannian manifold underlies the\ncharacteristic energy recurrences observed in the FPUT model.",
    "published": "2024-11-04T13:01:13Z",
    "updated": "2025-10-20T17:45:23Z",
    "link": "http://arxiv.org/pdf/2411.02058v3.pdf",
    "category": [
      "cs.LG",
      "cond-mat.stat-mech",
      "physics.soc-ph"
    ],
    "authors": [
      "Gionni Marchetti"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17786v1",
    "title": "Inference-Time Compute Scaling For Flow Matching",
    "summary": "Allocating extra computation at inference time has recently improved sample\nquality in large language models and diffusion-based image generation. In\nparallel, Flow Matching (FM) has gained traction in language, vision, and\nscientific domains, but inference-time scaling methods for it remain\nunder-explored. Concurrently, Kim et al., 2025 approach this problem but\nreplace the linear interpolant with a non-linear variance-preserving (VP)\ninterpolant at inference, sacrificing FM's efficient and straight sampling.\nAdditionally, inference-time compute scaling for flow matching has only been\napplied to visual tasks, like image generation. We introduce novel\ninference-time scaling procedures for FM that preserve the linear interpolant\nduring sampling. Evaluations of our method on image generation, and for the\nfirst time (to the best of our knowledge), unconditional protein generation,\nshow that I) sample quality consistently improves as inference compute\nincreases, and II) flow matching inference-time scaling can be applied to\nscientific domains.",
    "published": "2025-10-20T17:44:17Z",
    "updated": "2025-10-20T17:44:17Z",
    "link": "http://arxiv.org/pdf/2510.17786v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Adam Stecklov",
      "Noah El Rimawi-Fine",
      "Mathieu Blanchette"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.18130v3",
    "title": "Score-based deterministic density sampling",
    "summary": "We propose a deterministic sampling framework using Score-Based Transport\nModeling for sampling an unnormalized target density $\\pi$ given only its score\n$\\nabla \\log \\pi$. Our method approximates the Wasserstein gradient flow on\n$\\mathrm{KL}(f_t\\|\\pi)$ by learning the time-varying score $\\nabla \\log f_t$ on\nthe fly using score matching. While having the same marginal distribution as\nLangevin dynamics, our method produces smooth deterministic trajectories,\nresulting in monotone noise-free convergence. We prove that our method\ndissipates relative entropy at the same rate as the exact gradient flow,\nprovided sufficient training. Numerical experiments validate our theoretical\nfindings: our method converges at the optimal rate, has smooth trajectories,\nand is often more sample efficient than its stochastic counterpart. Experiments\non high-dimensional image data show that our method produces high-quality\ngenerations in as few as 15 steps and exhibits natural exploratory behavior.\nThe memory and runtime scale linearly in the sample size.",
    "published": "2025-04-25T07:33:16Z",
    "updated": "2025-10-20T17:37:19Z",
    "link": "http://arxiv.org/pdf/2504.18130v3.pdf",
    "category": [
      "cs.LG",
      "math.PR",
      "math.ST",
      "stat.TH",
      "Primary 65C05, 35Q84, 49Q22, Secondary 60H10, 68T07"
    ],
    "authors": [
      "Vasily Ilin",
      "Peter Sushko",
      "Jingwei Hu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.02877v2",
    "title": "Weak-to-Strong Generalization Even in Random Feature Networks, Provably",
    "summary": "Weak-to-Strong Generalization (Burns et al., 2024) is the phenomenon whereby\na strong student, say GPT-4, learns a task from a weak teacher, say GPT-2, and\nends up significantly outperforming the teacher. We show that this phenomenon\ndoes not require a strong learner like GPT-4. We consider student and teacher\nthat are random feature models, described by two-layer networks with a random\nand fixed bottom layer and a trained top layer. A \"weak\" teacher, with a small\nnumber of units (i.e. random features), is trained on the population, and a\n\"strong\" student, with a much larger number of units (i.e. random features), is\ntrained only on labels generated by the weak teacher. We demonstrate, prove,\nand understand how the student can outperform the teacher, even though trained\nonly on data labeled by the teacher. We also explain how such weak-to-strong\ngeneralization is enabled by early stopping. Importantly, we also show the\nquantitative limits of weak-to-strong generalization in this model.",
    "published": "2025-03-04T18:58:00Z",
    "updated": "2025-10-20T17:33:32Z",
    "link": "http://arxiv.org/pdf/2503.02877v2.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Marko Medvedev",
      "Kaifeng Lyu",
      "Dingli Yu",
      "Sanjeev Arora",
      "Zhiyuan Li",
      "Nathan Srebro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17772v1",
    "title": "Atlas-based Manifold Representations for Interpretable Riemannian\n  Machine Learning",
    "summary": "Despite the popularity of the manifold hypothesis, current manifold-learning\nmethods do not support machine learning directly on the latent $d$-dimensional\ndata manifold, as they primarily aim to perform dimensionality reduction into\n$\\mathbb{R}^D$, losing key manifold features when the embedding dimension $D$\napproaches $d$.\n  On the other hand, methods that directly learn the latent manifold as a\ndifferentiable atlas have been relatively underexplored.\n  In this paper, we aim to give a proof of concept of the effectiveness and\npotential of atlas-based methods. To this end, we implement a generic data\nstructure to maintain a differentiable atlas that enables Riemannian\noptimization over the manifold. We complement this with an unsupervised\nheuristic that learns a differentiable atlas from point cloud data. We\nexperimentally demonstrate that this approach has advantages in terms of\nefficiency and accuracy in selected settings. Moreover, in a supervised\nclassification task over the Klein bottle and in RNA velocity analysis of\nhematopoietic data, we showcase the improved interpretability and robustness of\nour approach.",
    "published": "2025-10-20T17:32:12Z",
    "updated": "2025-10-20T17:32:12Z",
    "link": "http://arxiv.org/pdf/2510.17772v1.pdf",
    "category": [
      "cs.LG",
      "stat.AP",
      "I.5.1"
    ],
    "authors": [
      "Ryan A. Robinett",
      "Sophia A. Madejski",
      "Kyle Ruark",
      "Samantha J. Riesenfeld",
      "Lorenzo Orecchia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.00221v2",
    "title": "Speech Foundation Models Generalize to Time Series Tasks from Wearable\n  Sensor Data",
    "summary": "Both speech and sensor time series data encode information in both the time-\nand frequency- domains, like spectral powers and waveform shapelets. We show\nthat speech foundation models learn representations that generalize beyond the\nspeech domain and achieve state-of-the-art performance on diverse time-series\ntasks from wearable sensors. Probes trained on features extracted from HuBERT\nand wav2vec 2.0 outperform those extracted from self-supervised models trained\ndirectly on modality-specific datasets for mood classification, arrhythmia\ndetection, and activity classification tasks. We find that the convolutional\nfeature encoders of speech models are particularly relevant for wearable sensor\napplications. The proposed approach enhances performance on data-scarce\ntime-series tasks using simple probing methods. This work takes a step toward\ndeveloping generalized time-series models that unify speech and sensor\nmodalities.",
    "published": "2025-08-29T20:09:48Z",
    "updated": "2025-10-20T17:27:43Z",
    "link": "http://arxiv.org/pdf/2509.00221v2.pdf",
    "category": [
      "cs.LG",
      "eess.AS"
    ],
    "authors": [
      "Jaya Narain",
      "Zakaria Aldeneh",
      "Shirley Ren"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.22785v3",
    "title": "Navigating the Latent Space Dynamics of Neural Models",
    "summary": "Neural networks transform high-dimensional data into compact, structured\nrepresentations, often modeled as elements of a lower dimensional latent space.\nIn this paper, we present an alternative interpretation of neural models as\ndynamical systems acting on the latent manifold. Specifically, we show that\nautoencoder models implicitly define a latent vector field on the manifold,\nderived by iteratively applying the encoding-decoding map, without any\nadditional training. We observe that standard training procedures introduce\ninductive biases that lead to the emergence of attractor points within this\nvector field. Drawing on this insight, we propose to leverage the vector field\nas a representation for the network, providing a novel tool to analyze the\nproperties of the model and the data. This representation enables to: (i)\nanalyze the generalization and memorization regimes of neural models, even\nthroughout training; (ii) extract prior knowledge encoded in the network's\nparameters from the attractors, without requiring any input data; (iii)\nidentify out-of-distribution samples from their trajectories in the vector\nfield. We further validate our approach on vision foundation models, showcasing\nthe applicability and effectiveness of our method in real-world scenarios.",
    "published": "2025-05-28T18:57:41Z",
    "updated": "2025-10-20T16:59:10Z",
    "link": "http://arxiv.org/pdf/2505.22785v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Marco Fumero",
      "Luca Moschella",
      "Emanuele RodolÃ ",
      "Francesco Locatello"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17734v1",
    "title": "Efficient Tensor Completion Algorithms for Highly Oscillatory Operators",
    "summary": "This paper presents low-complexity tensor completion algorithms and their\nefficient implementation to reconstruct highly oscillatory operators\ndiscretized as $n\\times n$ matrices. The underlying tensor decomposition is\nbased on the reshaping of the input matrix and its butterfly decomposition into\nan order $\\mathcal{O} (\\log n)$ tensor. The reshaping of the input matrix into\na tensor allows for representation of the butterfly decomposition as a tensor\ndecomposition with dense tensors. This leads to efficient utilization of the\nexisting software infrastructure for dense and sparse tensor computations. We\npropose two tensor completion algorithms in the butterfly format, using\nalternating least squares and gradient-based optimization, as well as a novel\nstrategy that uses low-rank matrix completion to efficiently generate an\ninitial guess for the proposed algorithms. To demonstrate the efficiency and\napplicability of our proposed algorithms, we perform three numerical\nexperiments using simulated oscillatory operators in seismic applications. In\nthese experiments, we use $\\mathcal {O} (n \\log n)$ observed entries in the\ninput matrix and demonstrate an $\\mathcal{O}(n\\log^3 n)$ computational cost of\nthe proposed algorithms, leading to a speedup of orders of magnitudes per\niteration for large matrices compared to the low-rank matrix and quantized\ntensor-train completion. Moreover, the proposed butterfly completion\nalgorithms, equipped with the novel initial guess generation strategy, achieve\nreconstruction errors that are smaller by an order of magnitude, enabling\naccurate recovery of the underlying structure compared to the state-of-the-art\ncompletion algorithms.",
    "published": "2025-10-20T16:45:59Z",
    "updated": "2025-10-20T16:45:59Z",
    "link": "http://arxiv.org/pdf/2510.17734v1.pdf",
    "category": [
      "math.NA",
      "cs.LG",
      "cs.NA"
    ],
    "authors": [
      "Navjot Singh",
      "Edgar Solomonik",
      "Xiaoye Sherry Li",
      "Yang Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17727v1",
    "title": "Enabling Fine-Grained Operating Points for Black-Box LLMs",
    "summary": "Black-box Large Language Models (LLMs) provide practical and accessible\nalternatives to other machine learning methods, as they require minimal labeled\ndata and machine learning expertise to develop solutions for various decision\nmaking problems. However, for applications that need operating with constraints\non specific metrics (e.g., precision $\\geq$ 95%), decision making with\nblack-box LLMs remains unfavorable, due to their low numerical output\ncardinalities. This results in limited control over their operating points,\npreventing fine-grained adjustment of their decision making behavior. In this\npaper, we study using black-box LLMs as classifiers, focusing on efficiently\nimproving their operational granularity without performance loss. Specifically,\nwe first investigate the reasons behind their low-cardinality numerical outputs\nand show that they are biased towards generating rounded but informative\nverbalized probabilities. Then, we experiment with standard prompt engineering,\nuncertainty estimation and confidence elicitation techniques, and observe that\nthey do not effectively improve operational granularity without sacrificing\nperformance or increasing inference cost. Finally, we propose efficient\napproaches to significantly increase the number and diversity of available\noperating points. Our proposed approaches provide finer-grained operating\npoints and achieve comparable to or better performance than the benchmark\nmethods across 11 datasets and 3 LLMs.",
    "published": "2025-10-20T16:43:06Z",
    "updated": "2025-10-20T16:43:06Z",
    "link": "http://arxiv.org/pdf/2510.17727v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Ege Beyazit",
      "KL Navaneet",
      "Prashant Mathur",
      "Roi Blanco",
      "Vidit Bansal",
      "Karim Bouyarmane"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17714v1",
    "title": "The Marked Edge Walk: A Novel MCMC Algorithm for Sampling of Graph\n  Partitions",
    "summary": "Novel Markov Chain Monte Carlo (MCMC) methods have enabled the generation of\nlarge ensembles of redistricting plans through graph partitioning. However,\nexisting algorithms such as Reversible Recombination (RevReCom) and\nMetropolized Forest Recombination (MFR) are constrained to sampling from\ndistributions related to spanning trees. We introduce the marked edge walk\n(MEW), a novel MCMC algorithm for sampling from the space of graph partitions\nunder a tunable distribution. The walk operates on the space of spanning trees\nwith marked edges, allowing for calculable transition probabilities for use in\nthe Metropolis-Hastings algorithm. Empirical results on real-world dual graphs\nshow convergence under target distributions unrelated to spanning trees. For\nthis reason, MEW represents an advancement in flexible ensemble generation.",
    "published": "2025-10-20T16:28:42Z",
    "updated": "2025-10-20T16:28:42Z",
    "link": "http://arxiv.org/pdf/2510.17714v1.pdf",
    "category": [
      "cs.DS",
      "cs.LG",
      "physics.soc-ph"
    ],
    "authors": [
      "Atticus McWhorter",
      "Daryl DeFord"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2407.01656v4",
    "title": "Absolute abstraction: a renormalisation group approach",
    "summary": "Abstraction is the process of extracting the essential features from raw data\nwhile ignoring irrelevant details. It is well known that abstraction emerges\nwith depth in neural networks, where deep layers capture abstract\ncharacteristics of data by combining lower level features encoded in shallow\nlayers (e.g. edges). Yet we argue that depth alone is not enough to develop\ntruly abstract representations. We advocate that the level of abstraction\ncrucially depends on how broad the training set is. We address the issue within\na renormalisation group approach where a representation is expanded to\nencompass a broader set of data. We take the unique fixed point of this\ntransformation -- the Hierarchical Feature Model -- as a candidate for a\nrepresentation which is absolutely abstract. This theoretical picture is tested\nin numerical experiments based on Deep Belief Networks and auto-encoders\ntrained on data of different breadth. These show that representations in neural\nnetworks approach the Hierarchical Feature Model as the data get broader and as\ndepth increases, in agreement with theoretical predictions.",
    "published": "2024-07-01T14:13:11Z",
    "updated": "2025-10-20T16:15:50Z",
    "link": "http://arxiv.org/pdf/2407.01656v4.pdf",
    "category": [
      "cs.LG",
      "cond-mat.dis-nn",
      "physics.data-an",
      "q-bio.NC",
      "stat.ML"
    ],
    "authors": [
      "Carlo Orientale Caputo",
      "Elias Seiffert",
      "Enrico Frausin",
      "Matteo Marsili"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17699v1",
    "title": "GAS: Improving Discretization of Diffusion ODEs via Generalized\n  Adversarial Solver",
    "summary": "While diffusion models achieve state-of-the-art generation quality, they\nstill suffer from computationally expensive sampling. Recent works address this\nissue with gradient-based optimization methods that distill a few-step ODE\ndiffusion solver from the full sampling process, reducing the number of\nfunction evaluations from dozens to just a few. However, these approaches often\nrely on intricate training techniques and do not explicitly focus on preserving\nfine-grained details. In this paper, we introduce the Generalized Solver: a\nsimple parameterization of the ODE sampler that does not require additional\ntraining tricks and improves quality over existing approaches. We further\ncombine the original distillation loss with adversarial training, which\nmitigates artifacts and enhances detail fidelity. We call the resulting method\nthe Generalized Adversarial Solver and demonstrate its superior performance\ncompared to existing solver training methods under similar resource\nconstraints. Code is available at https://github.com/3145tttt/GAS.",
    "published": "2025-10-20T16:14:38Z",
    "updated": "2025-10-20T16:14:38Z",
    "link": "http://arxiv.org/pdf/2510.17699v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Aleksandr Oganov",
      "Ilya Bykov",
      "Eva Neudachina",
      "Mishan Aliev",
      "Alexander Tolmachev",
      "Alexander Sidorov",
      "Aleksandr Zuev",
      "Andrey Okhotin",
      "Denis Rakitin",
      "Aibek Alanov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2409.13482v3",
    "title": "Invertible ResNets for Inverse Imaging Problems: Competitive Performance\n  with Provable Regularization Properties",
    "summary": "Learning-based methods have demonstrated remarkable performance in solving\ninverse problems, particularly in image reconstruction tasks. Despite their\nsuccess, these approaches often lack theoretical guarantees, which are crucial\nin sensitive applications such as medical imaging. Recent works by Arndt et al\naddressed this gap by analyzing a data-driven reconstruction method based on\ninvertible residual networks (iResNets). They revealed that, under reasonable\nassumptions, this approach constitutes a convergent regularization scheme.\nHowever, the performance of the reconstruction method was only validated on\nacademic toy problems and small-scale iResNet architectures. In this work, we\naddress this gap by evaluating the performance of iResNets on two real-world\nimaging tasks: a linear blurring operator and a nonlinear diffusion operator.\nTo do so, we compare the performance of iResNets against state-of-the-art\nneural networks, revealing their competitiveness at the expense of longer\ntraining times. Moreover, we numerically demonstrate the advantages of the\niResNet's inherent stability and invertibility by showcasing increased\nrobustness across various scenarios as well as interpretability of the learned\noperator, thereby reducing the black-box nature of the reconstruction scheme.",
    "published": "2024-09-20T13:15:26Z",
    "updated": "2025-10-20T16:13:21Z",
    "link": "http://arxiv.org/pdf/2409.13482v3.pdf",
    "category": [
      "math.NA",
      "cs.LG",
      "cs.NA"
    ],
    "authors": [
      "Clemens Arndt",
      "Judith Nickel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.16992v2",
    "title": "PICT -- A Differentiable, GPU-Accelerated Multi-Block PISO Solver for\n  Simulation-Coupled Learning Tasks in Fluid Dynamics",
    "summary": "Despite decades of advancements, the simulation of fluids remains one of the\nmost challenging areas of in scientific computing. Supported by the necessity\nof gradient information in deep learning, differentiable simulators have\nemerged as an effective tool for optimization and learning in physics\nsimulations. In this work, we present our fluid simulator PICT, a\ndifferentiable pressure-implicit solver coded in PyTorch with\nGraphics-processing-unit (GPU) support. We first verify the accuracy of both\nthe forward simulation and our derived gradients in various established\nbenchmarks like lid-driven cavities and turbulent channel flows before we show\nthat the gradients provided by our solver can be used to learn complicated\nturbulence models in 2D and 3D. We apply both supervised and unsupervised\ntraining regimes using physical priors to match flow statistics. In particular,\nwe learn a stable sub-grid scale (SGS) model for a 3D turbulent channel flow\npurely based on reference statistics. The low-resolution corrector trained with\nour solver runs substantially faster than the highly resolved references, while\nkeeping or even surpassing their accuracy. Finally, we give additional insights\ninto the physical interpretation of different solver gradients, and motivate a\nphysically informed regularization technique. To ensure that the full potential\nof PICT can be leveraged, it is published as open source:\nhttps://github.com/tum-pbs/PICT.",
    "published": "2025-05-22T17:55:10Z",
    "updated": "2025-10-20T16:07:52Z",
    "link": "http://arxiv.org/pdf/2505.16992v2.pdf",
    "category": [
      "cs.LG",
      "physics.comp-ph"
    ],
    "authors": [
      "Aleksandra Franz",
      "Hao Wei",
      "Luca Guastoni",
      "Nils Thuerey"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17690v1",
    "title": "Efficient Algorithms for Mitigating Uncertainty and Risk in\n  Reinforcement Learning",
    "summary": "This dissertation makes three main contributions. First, We identify a new\nconnection between policy gradient and dynamic programming in MMDPs and propose\nthe Coordinate Ascent Dynamic Programming (CADP) algorithm to compute a Markov\npolicy that maximizes the discounted return averaged over the uncertain models.\nCADP adjusts model weights iteratively to guarantee monotone policy\nimprovements to a local maximum. Second, We establish sufficient and necessary\nconditions for the exponential ERM Bellman operator to be a contraction and\nprove the existence of stationary deterministic optimal policies for ERM-TRC\nand EVaR-TRC. We also propose exponential value iteration, policy iteration,\nand linear programming algorithms for computing optimal stationary policies for\nERM-TRC and EVaR-TRC. Third, We propose model-free Q-learning algorithms for\ncomputing policies with risk-averse objectives: ERM-TRC and EVaR-TRC. The\nchallenge is that Q-learning ERM Bellman may not be a contraction. Instead, we\nuse the monotonicity of Q-learning ERM Bellman operators to derive a rigorous\nproof that the ERM-TRC and the EVaR-TRC Q-learning algorithms converge to the\noptimal risk-averse value functions. The proposed Q-learning algorithms compute\nthe optimal stationary policy for ERM-TRC and EVaR-TRC.",
    "published": "2025-10-20T16:06:01Z",
    "updated": "2025-10-20T16:06:01Z",
    "link": "http://arxiv.org/pdf/2510.17690v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Xihong Su"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17688v1",
    "title": "Quantum Synthetic Data Generation for Industrial Bioprocess Monitoring",
    "summary": "Data scarcity and sparsity in bio-manufacturing poses challenges for accurate\nmodel\n  development, process monitoring, and optimization. We aim to replicate and\ncapture\n  the complex dynamics of industrial bioprocesses by proposing the use of a\nQuantum\n  Wasserstein Generative Adversarial Network with Gradient Penalty (QWGAN-GP)\nto\n  generate synthetic time series data for industrially relevant processes. The\n  generator within our GAN is comprised of a Parameterized Quantum Circuit\n(PQC). This\n  methodology offers potential advantages in process monitoring, modeling,\n  forecasting, and optimization, enabling more efficient bioprocess management\nby\n  reducing the dependence on scarce experimental data. Our results demonstrate\n  acceptable performance in capturing the temporal dynamics of real bioprocess\ndata.\n  We focus on Optical Density, a key measurement for Dry Biomass estimation.\nThe data\n  generated showed high fidelity to the actual historical experimental data.\nThis\n  intersection of quantum computing and machine learning has opened new\nfrontiers in\n  data analysis and generation, particularly in computationally intensive\nfields, for\n  use cases such as increasing prediction accuracy for soft sensor design or\nfor use\n  in predictive control.",
    "published": "2025-10-20T16:04:39Z",
    "updated": "2025-10-20T16:04:39Z",
    "link": "http://arxiv.org/pdf/2510.17688v1.pdf",
    "category": [
      "cs.ET",
      "cs.LG"
    ],
    "authors": [
      "Shawn M. Gibford",
      "Mohammad Reza Boskabadi",
      "Christopher J. Savoie",
      "Seyed Soheil Mansouri"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.13381v3",
    "title": "Learning Counterfactual Distributions via Kernel Nearest Neighbors",
    "summary": "Consider a setting with multiple units (e.g., individuals, cohorts,\ngeographic locations) and outcomes (e.g., treatments, times, items), where the\ngoal is to learn a multivariate distribution for each unit-outcome entry, such\nas the distribution of a user's weekly spend and engagement under a specific\nmobile app version. A common challenge is the prevalence of missing not at\nrandom data, where observations are available only for certain unit-outcome\ncombinations and the observation availability can be correlated with the\nproperties of distributions themselves, i.e., there is unobserved confounding.\nAn additional challenge is that for any observed unit-outcome entry, we only\nhave a finite number of samples from the underlying distribution. We tackle\nthese two challenges by casting the problem into a novel distributional matrix\ncompletion framework and introduce a kernel based distributional generalization\nof nearest neighbors to estimate the underlying distributions. By leveraging\nmaximum mean discrepancies and a suitable factor model on the kernel mean\nembeddings of the underlying distributions, we establish consistent recovery of\nthe underlying distributions even when data is missing not at random and\npositivity constraints are violated. Furthermore, we demonstrate that our\nnearest neighbors approach is robust to heteroscedastic noise, provided we have\naccess to two or more measurements for the observed unit-outcome entries, a\nrobustness not present in prior works on nearest neighbors with single\nmeasurements.",
    "published": "2024-10-17T09:36:01Z",
    "updated": "2025-10-20T16:00:19Z",
    "link": "http://arxiv.org/pdf/2410.13381v3.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Kyuseong Choi",
      "Jacob Feitelberg",
      "Caleb Chin",
      "Anish Agarwal",
      "Raaz Dwivedi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.16115v2",
    "title": "A Generic Framework for Conformal Fairness",
    "summary": "Conformal Prediction (CP) is a popular method for uncertainty quantification\nwith machine learning models. While conformal prediction provides probabilistic\nguarantees regarding the coverage of the true label, these guarantees are\nagnostic to the presence of sensitive attributes within the dataset. In this\nwork, we formalize \\textit{Conformal Fairness}, a notion of fairness using\nconformal predictors, and provide a theoretically well-founded algorithm and\nassociated framework to control for the gaps in coverage between different\nsensitive groups. Our framework leverages the exchangeability assumption\n(implicit to CP) rather than the typical IID assumption, allowing us to apply\nthe notion of Conformal Fairness to data types and tasks that are not IID, such\nas graph data. Experiments were conducted on graph and tabular datasets to\ndemonstrate that the algorithm can control fairness-related gaps in addition to\ncoverage aligned with theoretical expectations.",
    "published": "2025-05-22T01:41:12Z",
    "updated": "2025-10-20T15:56:52Z",
    "link": "http://arxiv.org/pdf/2505.16115v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Aditya T. Vadlamani",
      "Anutam Srinivasan",
      "Pranav Maneriker",
      "Ali Payani",
      "Srinivasan Parthasarathy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.09178v3",
    "title": "SAFES: Sequential Privacy and Fairness Enhancing Data Synthesis for\n  Responsible AI",
    "summary": "As data-driven and AI-based decision making gains widespread adoption across\ndisciplines, it is crucial that both data privacy and decision fairness are\nappropriately addressed. Although differential privacy (DP) provides a robust\nframework for guaranteeing privacy and methods are available to improve\nfairness, most prior work treats the two concerns separately. Even though there\nare existing approaches that consider privacy and fairness simultaneously, they\ntypically focus on a single specific learning task, limiting their\ngeneralizability. In response, we introduce SAFES, a Sequential PrivAcy and\nFairness Enhancing data Synthesis procedure that sequentially combines DP data\nsynthesis with a fairness-aware data preprocessing step. SAFES allows users\nflexibility in navigating the privacy-fairness-utility trade-offs. We\nillustrate SAFES with different DP synthesizers and fairness-aware data\npreprocessing methods and run extensive experiments on multiple real datasets\nto examine the privacy-fairness-utility trade-offs of synthetic data generated\nby SAFES. Empirical evaluations demonstrate that for reasonable privacy loss,\nSAFES-generated synthetic data can achieve significantly improved fairness\nmetrics with relatively low utility loss.",
    "published": "2024-11-14T04:36:12Z",
    "updated": "2025-10-20T15:56:51Z",
    "link": "http://arxiv.org/pdf/2411.09178v3.pdf",
    "category": [
      "cs.LG",
      "cs.CR"
    ],
    "authors": [
      "Spencer Giddens",
      "Xiaon Lang",
      "Fang Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.15217v2",
    "title": "Reflections from Research Roundtables at the Conference on Health,\n  Inference, and Learning (CHIL) 2025",
    "summary": "The 6th Annual Conference on Health, Inference, and Learning (CHIL 2025),\nhosted by the Association for Health Learning and Inference (AHLI), was held in\nperson on June 25-27, 2025, at the University of California, Berkeley, in\nBerkeley, California, USA. As part of this year's program, we hosted Research\nRoundtables to catalyze collaborative, small-group dialogue around critical,\ntimely topics at the intersection of machine learning and healthcare. Each\nroundtable was moderated by a team of senior and junior chairs who fostered\nopen exchange, intellectual curiosity, and inclusive engagement. The sessions\nemphasized rigorous discussion of key challenges, exploration of emerging\nopportunities, and collective ideation toward actionable directions in the\nfield. In total, eight roundtables were held by 19 roundtable chairs on topics\nof \"Explainability, Interpretability, and Transparency,\" \"Uncertainty, Bias,\nand Fairness,\" \"Causality,\" \"Domain Adaptation,\" \"Foundation Models,\" \"Learning\nfrom Small Medical Data,\" \"Multimodal Methods,\" and \"Scalable, Translational\nHealthcare Solutions.\"",
    "published": "2025-10-17T00:54:03Z",
    "updated": "2025-10-20T15:51:30Z",
    "link": "http://arxiv.org/pdf/2510.15217v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Emily Alsentzer",
      "Marie-Laure Charpignon",
      "Bill Chen",
      "Niharika D'Souza",
      "Jason Fries",
      "Yixing Jiang",
      "Aparajita Kashyap",
      "Chanwoo Kim",
      "Simon Lee",
      "Aishwarya Mandyam",
      "Ashery Christopher Mbilinyi",
      "Nikita Mehandru",
      "Nitish Nagesh",
      "Brighton Nuwagira",
      "Emma Pierson",
      "Arvind Pillai",
      "Akane Sano",
      "Tanveer Syeda-Mahmood",
      "Shashank Yadav",
      "Elias Adhanom",
      "Muhammad Umar Afza",
      "Amelia Archer",
      "Suhana Bedi",
      "Vasiliki Bikia",
      "Trenton Chang",
      "George H. Chen",
      "Winston Chen",
      "Erica Chiang",
      "Edward Choi",
      "Octavia Ciora",
      "Paz Dozie-Nnamah",
      "Shaza Elsharief",
      "Matthew Engelhard",
      "Ali Eshragh",
      "Jean Feng",
      "Josh Fessel",
      "Scott Fleming",
      "Kei Sen Fong",
      "Thomas Frost",
      "Soham Gadgil",
      "Judy Gichoya",
      "Leeor Hershkovich",
      "Sujeong Im",
      "Bhavya Jain",
      "Vincent Jeanselme",
      "Furong Jia",
      "Qixuan Jin",
      "Yuxuan Jin",
      "Daniel Kapash",
      "Geetika Kapoor",
      "Behdokht Kiafar",
      "Matthias Kleiner",
      "Stefan Kraft",
      "Annika Kumar",
      "Daeun Kyung",
      "Zhongyuan Liang",
      "Joanna Lin",
      "Qianchu Liu",
      "Chang Liu",
      "Hongzhou Luan",
      "Chris Lunt",
      "Leopoldo JulÃ­an Lechuga LÃ³pez",
      "Matthew B. A. McDermott",
      "Shahriar Noroozizadeh",
      "Connor O'Brien",
      "YongKyung Oh",
      "Mixail Ota",
      "Stephen Pfohl",
      "Meagan Pi",
      "Tanmoy Sarkar Pias",
      "Emma Rocheteau",
      "Avishaan Sethi",
      "Toru Shirakawa",
      "Anita Silver",
      "Neha Simha",
      "Kamile Stankeviciute",
      "Max Sunog",
      "Peter Szolovits",
      "Shengpu Tang",
      "Jialu Tang",
      "Aaron Tierney",
      "John Valdovinos",
      "Byron Wallace",
      "Will Ke Wang",
      "Peter Washington",
      "Jeremy Weiss",
      "Daniel Wolfe",
      "Emily Wong",
      "Hye Sun Yun",
      "Xiaoman Zhang",
      "Xiao Yu Cindy Zhang",
      "Hayoung Jeong",
      "Kaveri A. Thakoor"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.18963v3",
    "title": "Time-Varying Bayesian Optimization Without a Metronome",
    "summary": "Time-Varying Bayesian Optimization (TVBO) is the go-to framework for\noptimizing a time-varying, expensive, noisy black-box function $f$. However,\nmost of the asymptotic guarantees offered by TVBO algorithms rely on the\nassumption that observations are acquired at a constant frequency. As the GP\ninference complexity scales with the cube of its dataset size, this assumption\nis unrealistic in the long run. In this paper, we relax this assumption and\nderive the first upper regret bound that explicitly accounts for changes in the\nobservations sampling frequency. Based on this analysis, we formulate practical\nrecommendations about dataset sizes and stale data policies of TVBO algorithms.\nWe illustrate how an algorithm (BOLT) that follows these recommendations\nperforms better than the state-of-the-art of TVBO through experiments on\nsynthetic and real-world problems.",
    "published": "2025-01-31T08:49:33Z",
    "updated": "2025-10-20T15:50:29Z",
    "link": "http://arxiv.org/pdf/2501.18963v3.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Anthony Bardou",
      "Patrick Thiran"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2408.11077v5",
    "title": "Solving Oscillator Ordinary Differential Equations in the Time Domain\n  with High Performance via Soft-constrained Physics-informed Neural Network\n  with Small Data",
    "summary": "In many scientific and engineering (e.g., physical, biochemical, medical)\npractices, data generated through expensive experiments or large-scale\nsimulations, are often sparse and noisy. Physics-informed neural network (PINN)\nincorporates physical information and knowledge into network topology or\ncomputational processes as model priors, with the unique advantage of achieving\nstrong generalization with small data. This study aims to investigate the\nperformance characteristics of the soft-constrained PINN method to solving\ntypical linear and nonlinear ordinary differential equations (ODEs) such as\nprimer, Van der Pol and Duffing oscillators, especially the effectiveness,\nefficiency, and robustness to noise with minimal data. It is verified that the\nsoft-constrained PINN significantly reduces the need for labeled data. With the\naid of appropriate collocation points no need to be labeled, it can predict and\nalso extrapolate with minimal data. First-order and second-order ODEs, no\nmatter linear or nonlinear oscillators, require only one and two training data\n(containing initial values) respectively, just like classical analytic or\nRunge-Kutta methods, and with equivalent precision and comparable efficiency\n(fast training in seconds for scalar ODEs). Furthermore, it can conveniently\nimpose a physical law (e.g., conservation of energy) constraint by adding a\nregularization term to the total loss function, improving the performance to\ndeal with various complexities such as nonlinearity like Duffing. The\nDeepXDE-based PINN implementation is light code and can be efficiently trained\non both GPU and CPU platforms. The mathematical and computational framework of\nthis alternative and feasible PINN method to ODEs, can be easily extended to\nPDEs, etc., and is becoming a favorable catalyst for the era of Digital Twins.",
    "published": "2024-08-19T13:02:06Z",
    "updated": "2025-10-20T15:41:38Z",
    "link": "http://arxiv.org/pdf/2408.11077v5.pdf",
    "category": [
      "cs.LG",
      "cs.CV",
      "stat.ML",
      "68T07",
      "I.5"
    ],
    "authors": [
      "Kai-liang Lu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17661v1",
    "title": "Handling Extreme Class Imbalance: Using GANs in Data Augmentation for\n  Suicide Prediction",
    "summary": "Suicide prediction is the key for prevention, but real data with sufficient\npositive samples is rare and causes extreme class imbalance. We utilized\nmachine learning (ML) to build the model and deep learning (DL) techniques,\nlike Generative Adversarial Networks (GAN), to generate synthetic data samples\nto enhance the dataset. The initial dataset contained 656 samples, with only\nfour positive cases, prompting the need for data augmentation. A variety of\nmachine learning models, ranging from interpretable data models to black box\nalgorithmic models, were used. On real test data, Logistic Regression (LR)\nachieved a weighted precision of 0.99, a weighted recall of 0.85, and a\nweighted F1 score of 0.91; Random Forest (RF) showed 0.98, 0.99, and 0.99,\nrespectively; and Support Vector Machine (SVM) achieved 0.99, 0.76, and 0.86.\nLR and SVM correctly identified one suicide attempt case (sensitivity:1.0) and\nmisclassified LR(20) and SVM (31) non-attempts as attempts (specificity: 0.85 &\n0.76, respectively). RF identified 0 suicide attempt cases (sensitivity: 0.0)\nwith 0 false positives (specificity: 1.0). These results highlight the models'\neffectiveness, with GAN playing a key role in generating synthetic data to\nsupport suicide prevention modeling efforts.",
    "published": "2025-10-20T15:35:39Z",
    "updated": "2025-10-20T15:35:39Z",
    "link": "http://arxiv.org/pdf/2510.17661v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Vaishnavi Visweswaraiah",
      "Tanvi Banerjee",
      "William Romine"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.13012v2",
    "title": "Asymptotic Performance of Time-Varying Bayesian Optimization",
    "summary": "Time-Varying Bayesian Optimization (TVBO) is the go-to framework for\noptimizing a time-varying black-box objective function that may be noisy and\nexpensive to evaluate, but its excellent empirical performance remains to be\nunderstood theoretically. Is it possible for the instantaneous regret of a TVBO\nalgorithm to vanish asymptotically, and if so, when? We answer this question of\ngreat importance by providing upper bounds and algorithm-independent lower\nbounds for the cumulative regret of TVBO algorithms. In doing so, we provide\nimportant insights about the TVBO framework and derive sufficient conditions\nfor a TVBO algorithm to have the no-regret property. To the best of our\nknowledge, our analysis is the first to cover all major classes of stationary\nkernel functions used in practice.",
    "published": "2025-05-19T11:55:02Z",
    "updated": "2025-10-20T15:31:34Z",
    "link": "http://arxiv.org/pdf/2505.13012v2.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Anthony Bardou",
      "Patrick Thiran"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17650v1",
    "title": "ZACH-ViT: A Zero-Token Vision Transformer with ShuffleStrides Data\n  Augmentation for Robust Lung Ultrasound Classification",
    "summary": "Differentiating cardiogenic pulmonary oedema (CPE) from non-cardiogenic and\nstructurally normal lungs in lung ultrasound (LUS) videos remains challenging\ndue to the high visual variability of non-cardiogenic inflammatory patterns\n(NCIP/ARDS-like), interstitial lung disease, and healthy lungs. This\nheterogeneity complicates automated classification as overlapping B-lines and\npleural artefacts are common. We introduce ZACH-ViT (Zero-token Adaptive\nCompact Hierarchical Vision Transformer), a 0.25 M-parameter Vision Transformer\nvariant that removes both positional embeddings and the [CLS] token, making it\nfully permutation-invariant and suitable for unordered medical image data. To\nenhance generalization, we propose ShuffleStrides Data Augmentation (SSDA),\nwhich permutes probe-view sequences and frame orders while preserving\nanatomical validity. ZACH-ViT was evaluated on 380 LUS videos from 95\ncritically ill patients against nine state-of-the-art baselines. Despite the\nheterogeneity of the non-cardiogenic group, ZACH-ViT achieved the highest\nvalidation and test ROC-AUC (0.80 and 0.79) with balanced sensitivity (0.60)\nand specificity (0.91), while all competing models collapsed to trivial\nclassification. It trains 1.35x faster than Minimal ViT (0.62M parameters) with\n2.5x fewer parameters, supporting real-time clinical deployment. These results\nshow that aligning architectural design with data structure can outperform\nscale in small-data medical imaging.",
    "published": "2025-10-20T15:26:38Z",
    "updated": "2025-10-20T15:26:38Z",
    "link": "http://arxiv.org/pdf/2510.17650v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Athanasios Angelakis",
      "Amne Mousa",
      "Micah L. A. Heldeweg",
      "Laurens A. Biesheuvel",
      "Mark A. Haaksma",
      "Jasper M. Smit",
      "Pieter R. Tuinman",
      "Paul W. G. Elbers"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.12787v2",
    "title": "Wavy Transformer",
    "summary": "Transformers have achieved remarkable success across natural language\nprocessing (NLP) and computer vision (CV). However, deep transformer models\noften suffer from an over-smoothing issue, in which token representations\nconverge to similar values as they pass through successive transformer blocks.\nIn this paper, we establish an equivalence between the hidden-state dynamics\ninduced by stacked attention layers and graph neural diffusion on a complete\ngraph. From this perspective, over-smoothing can be interpreted as a\nconsequence of the dissipative nature of the underlying diffusion dynamics.\nMotivated by this physical interpretation, we propose Wavy Transformer, which\nconsists of a novel attention layer based on second-order wavy dynamics. We\nalso introduce a feed-forward network and a normalization layer designed to\npreserve the physical state-velocity relationship under the chain rule, thereby\nextending the transformer architecture. We further validate our proposed\ntechniques on various transformer models for NLP and CV tasks. The results\nconsistently demonstrate that Wavy Transformer improves performance with\nminimal additional parameters and no extra hyperparameter tuning.",
    "published": "2025-08-18T10:03:38Z",
    "updated": "2025-10-20T15:22:31Z",
    "link": "http://arxiv.org/pdf/2508.12787v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Satoshi Noguchi",
      "Yoshinobu Kawahara"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17642v1",
    "title": "Quantum Federated Learning: Architectural Elements and Future Directions",
    "summary": "Federated learning (FL) focuses on collaborative model training without the\nneed to move the private data silos to a central server. Despite its several\nbenefits, the classical FL is plagued with several limitations, such as high\ncomputational power required for model training(which is critical for\nlow-resource clients), privacy risks, large update traffic, and non-IID\nheterogeneity. This chapter surveys a hybrid paradigm - Quantum Federated\nLearning (QFL), which introduces quantum computation, that addresses multiple\nchallenges of classical FL and offers rapid computing capability while keeping\nthe classical orchestration intact. Firstly, we motivate QFL with a concrete\npresentation on pain points of classical FL, followed by a discussion on a\ngeneral architecture of QFL frameworks specifying the roles of client and\nserver, communication primitives and the quantum model placement. We classify\nthe existing QFL systems based on four criteria - quantum architecture (pure\nQFL, hybrid QFL), data processing method (quantum data encoding, quantum\nfeature mapping, and quantum feature selection & dimensionality reduction),\nnetwork topology (centralized, hierarchial, decentralized), and quantum\nsecurity mechanisms (quantum key distribution, quantum homomorphic encryption,\nquantum differential privacy, blind quantum computing). We then describe\napplications of QFL in healthcare, vehicular networks, wireless networks, and\nnetwork security, clearly highlighting where QFL improves communication\nefficiency, security, and performance compared to classical FL. We close with\nmultiple challenges and future works in QFL, including extension of QFL beyond\nclassification tasks, adversarial attacks, realistic hardware deployment,\nquantum communication protocols deployment, aggregation of different quantum\nmodels, and quantum split learning as an alternative to QFL.",
    "published": "2025-10-20T15:21:46Z",
    "updated": "2025-10-20T15:21:46Z",
    "link": "http://arxiv.org/pdf/2510.17642v1.pdf",
    "category": [
      "quant-ph",
      "cs.DC",
      "cs.LG",
      "I.2; A.1"
    ],
    "authors": [
      "Siva Sai",
      "Abhishek Sawaika",
      "Prabhjot Singh",
      "Rajkumar Buyya"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2407.16239v5",
    "title": "Identifiable Latent Bandits: Leveraging observational data for\n  personalized decision-making",
    "summary": "Sequential decision-making algorithms such as multi-armed bandits can find\noptimal personalized decisions, but are notoriously sample-hungry. In\npersonalized medicine, for example, training a bandit from scratch for every\npatient is typically infeasible, as the number of trials required is much\nlarger than the number of decision points for a single patient. To combat this,\nlatent bandits offer rapid exploration and personalization beyond what context\nvariables alone can offer, provided that a latent variable model of problem\ninstances can be learned consistently. However, existing works give no guidance\nas to how such a model can be found. In this work, we propose an identifiable\nlatent bandit framework that leads to optimal decision-making with a shorter\nexploration time than classical bandits by learning from historical records of\ndecisions and outcomes. Our method is based on nonlinear independent component\nanalysis that provably identifies representations from observational data\nsufficient to infer optimal actions in new bandit instances. We verify this\nstrategy in simulated and semi-synthetic environments, showing substantial\nimprovement over online and offline learning baselines when identifying\nconditions are satisfied.",
    "published": "2024-07-23T07:26:38Z",
    "updated": "2025-10-20T15:20:57Z",
    "link": "http://arxiv.org/pdf/2407.16239v5.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Ahmet Zahid BalcÄ±oÄlu",
      "Newton Mwai",
      "Emil Carlsson",
      "Fredrik D. Johansson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.09271v3",
    "title": "DitHub: A Modular Framework for Incremental Open-Vocabulary Object\n  Detection",
    "summary": "Open-Vocabulary object detectors can generalize to an unrestricted set of\ncategories through simple textual prompting. However, adapting these models to\nrare classes or reinforcing their abilities on multiple specialized domains\nremains essential. While recent methods rely on monolithic adaptation\nstrategies with a single set of weights, we embrace modular deep learning. We\nintroduce DitHub, a framework designed to build and maintain a library of\nefficient adaptation modules. Inspired by Version Control Systems, DitHub\nmanages expert modules as branches that can be fetched and merged as needed.\nThis modular approach allows us to conduct an in-depth exploration of the\ncompositional properties of adaptation modules, marking the first such study in\nObject Detection. Our method achieves state-of-the-art performance on the\nODinW-13 benchmark and ODinW-O, a newly introduced benchmark designed to assess\nclass reappearance. For more details, visit our project page:\nhttps://aimagelab.github.io/DitHub/",
    "published": "2025-03-12T11:15:34Z",
    "updated": "2025-10-20T15:09:57Z",
    "link": "http://arxiv.org/pdf/2503.09271v3.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Chiara Cappellino",
      "Gianluca Mancusi",
      "Matteo Mosconi",
      "Angelo Porrello",
      "Simone Calderara",
      "Rita Cucchiara"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17622v1",
    "title": "Just-In-Time Piecewise-Linear Semantics for ReLU-type Networks",
    "summary": "We present a JIT PL semantics for ReLU-type networks that compiles models\ninto a guarded CPWL transducer with shared guards. The system adds hyperplanes\nonly when operands are affine on the current cell, maintains global lower/upper\nenvelopes, and uses a budgeted branch-and-bound. We obtain anytime soundness,\nexactness on fully refined cells, monotone progress, guard-linear complexity\n(avoiding global $\\binom{k}{2}$), dominance pruning, and decidability under\nfinite refinement. The shared carrier supports region extraction, decision\ncomplexes, Jacobians, exact/certified Lipschitz, LP/SOCP robustness, and\nmaximal causal influence. A minimal prototype returns certificates or\ncounterexamples with cost proportional to visited subdomains.",
    "published": "2025-10-20T15:05:14Z",
    "updated": "2025-10-20T15:05:14Z",
    "link": "http://arxiv.org/pdf/2510.17622v1.pdf",
    "category": [
      "cs.LO",
      "cs.LG"
    ],
    "authors": [
      "Hongyi Duan",
      "Haoyang Liu",
      "Jian'an Zhang",
      "Fengrui Liu",
      "Yiyi Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17608v1",
    "title": "Non-asymptotic error bounds for probability flow ODEs under weak\n  log-concavity",
    "summary": "Score-based generative modeling, implemented through probability flow ODEs,\nhas shown impressive results in numerous practical settings. However, most\nconvergence guarantees rely on restrictive regularity assumptions on the target\ndistribution -- such as strong log-concavity or bounded support. This work\nestablishes non-asymptotic convergence bounds in the 2-Wasserstein distance for\na general class of probability flow ODEs under considerably weaker assumptions:\nweak log-concavity and Lipschitz continuity of the score function. Our\nframework accommodates non-log-concave distributions, such as Gaussian\nmixtures, and explicitly accounts for initialization errors, score\napproximation errors, and effects of discretization via an exponential\nintegrator scheme. Bridging a key theoretical challenge in diffusion-based\ngenerative modeling, our results extend convergence theory to more realistic\ndata distributions and practical ODE solvers. We provide concrete guarantees\nfor the efficiency and correctness of the sampling algorithm, complementing the\nempirical success of diffusion models with rigorous theory. Moreover, from a\npractical perspective, our explicit rates might be helpful in choosing\nhyperparameters, such as the step size in the discretization.",
    "published": "2025-10-20T14:54:38Z",
    "updated": "2025-10-20T14:54:38Z",
    "link": "http://arxiv.org/pdf/2510.17608v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "authors": [
      "Gitte Kremling",
      "Francesco Iafrate",
      "Mahsa Taheri",
      "Johannes Lederer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.20930v2",
    "title": "Quantum Reinforcement Learning Trading Agent for Sector Rotation in the\n  Taiwan Stock Market",
    "summary": "We propose a hybrid quantum-classical reinforcement learning framework for\nsector rotation in the Taiwan stock market. Our system employs Proximal Policy\nOptimization (PPO) as the backbone algorithm and integrates both classical\narchitectures (LSTM, Transformer) and quantum-enhanced models (QNN, QRWKV,\nQASA) as policy and value networks. An automated feature engineering pipeline\nextracts financial indicators from capital share data to ensure consistent\nmodel input across all configurations. Empirical backtesting reveals a key\nfinding: although quantum-enhanced models consistently achieve higher training\nrewards, they underperform classical models in real-world investment metrics\nsuch as cumulative return and Sharpe ratio. This discrepancy highlights a core\nchallenge in applying reinforcement learning to financial domains -- namely,\nthe mismatch between proxy reward signals and true investment objectives. Our\nanalysis suggests that current reward designs may incentivize overfitting to\nshort-term volatility rather than optimizing risk-adjusted returns. This issue\nis compounded by the inherent expressiveness and optimization instability of\nquantum circuits under Noisy Intermediate-Scale Quantum (NISQ) constraints. We\ndiscuss the implications of this reward-performance gap and propose directions\nfor future improvement, including reward shaping, model regularization, and\nvalidation-based early stopping. Our work offers a reproducible benchmark and\ncritical insights into the practical challenges of deploying quantum\nreinforcement learning in real-world finance.",
    "published": "2025-06-26T01:29:19Z",
    "updated": "2025-10-20T14:32:07Z",
    "link": "http://arxiv.org/pdf/2506.20930v2.pdf",
    "category": [
      "quant-ph",
      "cs.LG",
      "q-fin.CP"
    ],
    "authors": [
      "Chi-Sheng Chen",
      "Xinyu Zhang",
      "Ya-Chuan Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.01847v2",
    "title": "Test-Time Training for Speech Enhancement",
    "summary": "This paper introduces a novel application of Test-Time Training (TTT) for\nSpeech Enhancement, addressing the challenges posed by unpredictable noise\nconditions and domain shifts. This method combines a main speech enhancement\ntask with a self-supervised auxiliary task in a Y-shaped architecture. The\nmodel dynamically adapts to new domains during inference time by optimizing the\nproposed self-supervised tasks like noise-augmented signal reconstruction or\nmasked spectrogram prediction, bypassing the need for labeled data. We further\nintroduce various TTT strategies offering a trade-off between adaptation and\nefficiency. Evaluations across synthetic and real-world datasets show\nconsistent improvements across speech quality metrics, outperforming the\nbaseline model. This work highlights the effectiveness of TTT in speech\nenhancement, providing insights for future research in adaptive and robust\nspeech processing.",
    "published": "2025-08-03T17:02:55Z",
    "updated": "2025-10-20T14:30:46Z",
    "link": "http://arxiv.org/pdf/2508.01847v2.pdf",
    "category": [
      "eess.AS",
      "cs.LG",
      "cs.SD"
    ],
    "authors": [
      "Avishkar Behera",
      "Riya Ann Easow",
      "Venkatesh Parvathala",
      "K. Sri Rama Murty"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17569v1",
    "title": "Semi-supervised Latent Bayesian Optimization for Designing Antimicrobial\n  Peptides",
    "summary": "Antimicrobial peptides (AMPs) are a promising class of therapeutics to treat\nbacterial infections. Discovering and designing such peptides is difficult\nbecause of the vast number of possible sequences of amino acids. Deep\ngenerative models, such as variational autoencoders, have shown value in\npeptide design due to their ability to model sequence space with a\ncontinuous-valued latent space. Although such models have already been used to\ngreat effect in biomolecular design, they still suffer from a lack of\ninterpretability and rigorous quantification of latent space quality as a\nsearch space. We investigate (1) whether further compression of the design\nspace via dimensionality reduction may facilitate optimization, (2) the\ninterpretability of the spaces, and (3) how organizing latent spaces with\nphysicochemical properties may improve the efficiency of optimizing\nantimicrobial activity. We find that further reduction of the latent space via\ndimensionality reduction can be advantageous when organizing the space with\nmore relevant information at data availability, that using the dimensionality\nreduction search space can be more interpretable, and that we can organize the\nlatent space with different physicochemical properties even at different\npercentages of available labels.",
    "published": "2025-10-20T14:20:11Z",
    "updated": "2025-10-20T14:20:11Z",
    "link": "http://arxiv.org/pdf/2510.17569v1.pdf",
    "category": [
      "cs.LG",
      "physics.comp-ph"
    ],
    "authors": [
      "Jyler Menard",
      "R. A. Mansbach"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.02482v5",
    "title": "What should a neuron aim for? Designing local objective functions based\n  on information theory",
    "summary": "In modern deep neural networks, the learning dynamics of the individual\nneurons is often obscure, as the networks are trained via global optimization.\nConversely, biological systems build on self-organized, local learning,\nachieving robustness and efficiency with limited global information. We here\nshow how self-organization between individual artificial neurons can be\nachieved by designing abstract bio-inspired local learning goals. These goals\nare parameterized using a recent extension of information theory, Partial\nInformation Decomposition (PID), which decomposes the information that a set of\ninformation sources holds about an outcome into unique, redundant and\nsynergistic contributions. Our framework enables neurons to locally shape the\nintegration of information from various input classes, i.e. feedforward,\nfeedback, and lateral, by selecting which of the three inputs should contribute\nuniquely, redundantly or synergistically to the output. This selection is\nexpressed as a weighted sum of PID terms, which, for a given problem, can be\ndirectly derived from intuitive reasoning or via numerical optimization,\noffering a window into understanding task-relevant local information\nprocessing. Achieving neuron-level interpretability while enabling strong\nperformance using local learning, our work advances a principled\ninformation-theoretic foundation for local learning strategies.",
    "published": "2024-12-03T14:45:46Z",
    "updated": "2025-10-20T14:20:00Z",
    "link": "http://arxiv.org/pdf/2412.02482v5.pdf",
    "category": [
      "cs.IT",
      "cs.LG",
      "cs.NE",
      "math.IT"
    ],
    "authors": [
      "Andreas C. Schneider",
      "Valentin Neuhaus",
      "David A. Ehrlich",
      "Abdullah Makkeh",
      "Alexander S. Ecker",
      "Viola Priesemann",
      "Michael Wibral"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17562v1",
    "title": "Formally Exploring Time-Series Anomaly Detection Evaluation Metrics",
    "summary": "Undetected anomalies in time series can trigger catastrophic failures in\nsafety-critical systems, such as chemical plant explosions or power grid\noutages. Although many detection methods have been proposed, their performance\nremains unclear because current metrics capture only narrow aspects of the task\nand often yield misleading results. We address this issue by introducing\nverifiable properties that formalize essential requirements for evaluating\ntime-series anomaly detection. These properties enable a theoretical framework\nthat supports principled evaluations and reliable comparisons. Analyzing 37\nwidely used metrics, we show that most satisfy only a few properties, and none\nsatisfy all, explaining persistent inconsistencies in prior results. To close\nthis gap, we propose LARM, a flexible metric that provably satisfies all\nproperties, and extend it to ALARM, an advanced variant meeting stricter\nrequirements.",
    "published": "2025-10-20T14:10:39Z",
    "updated": "2025-10-20T14:10:39Z",
    "link": "http://arxiv.org/pdf/2510.17562v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Dennis Wagner",
      "Arjun Nair",
      "Billy Joe Franks",
      "Justus Arweiler",
      "Aparna Muraleedharan",
      "Indra Jungjohann",
      "Fabian Hartung",
      "Mayank C. Ahuja",
      "Andriy Balinskyy",
      "Saurabh Varshneya",
      "Nabeel Hussain Syed",
      "Mayank Nagda",
      "Phillip Liznerski",
      "Steffen Reithermann",
      "Maja Rudolph",
      "Sebastian Vollmer",
      "Ralf Schulz",
      "Torsten Katz",
      "Stephan Mandt",
      "Michael Bortz",
      "Heike Leitte",
      "Daniel Neider",
      "Jakob Burger",
      "Fabian Jirasek",
      "Hans Hasse",
      "Sophie Fellenz",
      "Marius Kloft"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17558v1",
    "title": "The Free Transformer",
    "summary": "We propose an extension of the decoder Transformer that conditions its\ngenerative process on random latent variables which are learned without\nsupervision thanks to a variational procedure. Experimental evaluations show\nthat allowing such a conditioning translates into substantial improvements on\ndownstream tasks.",
    "published": "2025-10-20T14:05:30Z",
    "updated": "2025-10-20T14:05:30Z",
    "link": "http://arxiv.org/pdf/2510.17558v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "FranÃ§ois Fleuret"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2311.13925v4",
    "title": "Predicting Patient Recovery or Mortality Using Deep Neural Decision Tree\n  and Forest",
    "summary": "Objective: Identifying patients at high risk of mortality is crucial for\nemergency physicians to allocate hospital resources effectively, particularly\nin regions with limited medical services. This need becomes even more pressing\nduring global health crises that lead to significant morbidity and mortality.\nThis study aimed to present the usability deep neural decision forest and deep\nneural decision tree to predict mortality among Coronavirus disease 2019\n(COVID-19) patients. To this end, We used patient data encompassing Coronavirus\ndisease 2019 diagnosis, demographics, health indicators, and occupational risk\nfactors to analyze disease severity and outcomes. The dataset was partitioned\nusing a stratified sampling method, ensuring that 80% was allocated for\ntraining and 20% for testing. Nine machine learning and deep learning methods\nwere employed to build predictive models. The models were evaluated across all\nstages to determine their effectiveness in predicting patient outcomes.\nResults: Among the models, the deep neural decision forest consistently\noutperformed others. Results indicated that using only clinical data yielded an\naccuracy of 80% by deep neural decision forest, demonstrating it as a reliable\npredictor of patient mortality. Moreover, the results suggest that clinical\ndata alone may be the most accurate diagnostic tool for predicting mortality.",
    "published": "2023-11-23T11:21:40Z",
    "updated": "2025-10-20T14:03:03Z",
    "link": "http://arxiv.org/pdf/2311.13925v4.pdf",
    "category": [
      "eess.IV",
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Mohammad Dehghani",
      "Mohadeseh Zarei Ghobadi",
      "Mobin Mohammadi",
      "Diyana Tehrany Dehkordy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.21580v2",
    "title": "A Pure Hypothesis Test for Inhomogeneous Random Graph Models Based on a\n  Kernelised Stein Discrepancy",
    "summary": "Complex data are often represented as a graph, which in turn can often be\nviewed as a realisation of a random graph, such as an inhomogeneous random\ngraph model (IRG). For general fast goodness-of-fit tests in high dimensions,\nkernelised Stein discrepancy (KSD) tests are a powerful tool. Here, we develop\na KSD-type test for IRG models that can be carried out with a single\nobservation of the network. The test applies to a network of any size, but is\nparticularly interesting for small networks for which asymptotic tests are not\nwarranted. We also provide theoretical guarantees.",
    "published": "2025-05-27T09:06:28Z",
    "updated": "2025-10-20T13:59:06Z",
    "link": "http://arxiv.org/pdf/2505.21580v2.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "authors": [
      "Anum Fatima",
      "Gesine Reinert"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2405.18754v3",
    "title": "GIST: Greedy Independent Set Thresholding for Max-Min Diversification\n  with Submodular Utility",
    "summary": "This work studies a novel subset selection problem called max-min\ndiversification with monotone submodular utility ($\\textsf{MDMS}$), which has a\nwide range of applications in machine learning, e.g., data sampling and feature\nselection. Given a set of points in a metric space, the goal of $\\textsf{MDMS}$\nis to maximize $f(S) = g(S) + \\lambda \\cdot \\texttt{div}(S)$ subject to a\ncardinality constraint $|S| \\le k$, where $g(S)$ is a monotone submodular\nfunction and $\\texttt{div}(S) = \\min_{u,v \\in S : u \\ne v} \\text{dist}(u,v)$ is\nthe max-min diversity objective. We propose the $\\texttt{GIST}$ algorithm,\nwhich gives a $\\frac{1}{2}$-approximation guarantee for $\\textsf{MDMS}$ by\napproximating a series of maximum independent set problems with a bicriteria\ngreedy algorithm. We also prove that it is NP-hard to approximate within a\nfactor of $0.5584$. Finally, we show in our empirical study that\n$\\texttt{GIST}$ outperforms state-of-the-art benchmarks for a single-shot data\nsampling task on ImageNet.",
    "published": "2024-05-29T04:39:24Z",
    "updated": "2025-10-20T13:56:47Z",
    "link": "http://arxiv.org/pdf/2405.18754v3.pdf",
    "category": [
      "cs.DS",
      "cs.LG"
    ],
    "authors": [
      "Matthew Fahrbach",
      "Srikumar Ramalingam",
      "Morteza Zadimoghaddam",
      "Sara Ahmadian",
      "Gui Citovsky",
      "Giulia DeSalvo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17545v1",
    "title": "TrajMamba: An Efficient and Semantic-rich Vehicle Trajectory\n  Pre-training Model",
    "summary": "Vehicle GPS trajectories record how vehicles move over time, storing valuable\ntravel semantics, including movement patterns and travel purposes. Learning\ntravel semantics effectively and efficiently is crucial for real-world\napplications of trajectory data, which is hindered by two major challenges.\nFirst, travel purposes are tied to the functions of the roads and\npoints-of-interest (POIs) involved in a trip. Such information is encoded in\ntextual addresses and descriptions and introduces heavy computational burden to\nmodeling. Second, real-world trajectories often contain redundant points, which\nharm both computational efficiency and trajectory embedding quality. To address\nthese challenges, we propose TrajMamba, a novel approach for efficient and\nsemantically rich vehicle trajectory learning. TrajMamba introduces a\nTraj-Mamba Encoder that captures movement patterns by jointly modeling both GPS\nand road perspectives of trajectories, enabling robust representations of\ncontinuous travel behaviors. It also incorporates a Travel Purpose-aware\nPre-training procedure to integrate travel purposes into the learned embeddings\nwithout introducing extra overhead to embedding calculation. To reduce\nredundancy in trajectories, TrajMamba features a Knowledge Distillation\nPre-training scheme to identify key trajectory points through a learnable mask\ngenerator and obtain effective compressed trajectory embeddings. Extensive\nexperiments on two real-world datasets and three downstream tasks show that\nTrajMamba outperforms state-of-the-art baselines in both efficiency and\naccuracy.",
    "published": "2025-10-20T13:54:50Z",
    "updated": "2025-10-20T13:54:50Z",
    "link": "http://arxiv.org/pdf/2510.17545v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Yichen Liu",
      "Yan Lin",
      "Shengnan Guo",
      "Zeyu Zhou",
      "Youfang Lin",
      "Huaiyu Wan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17543v1",
    "title": "Reliable Inference in Edge-Cloud Model Cascades via Conformal Alignment",
    "summary": "Edge intelligence enables low-latency inference via compact on-device models,\nbut assuring reliability remains challenging. We study edge-cloud cascades that\nmust preserve conditional coverage: whenever the edge returns a prediction set,\nit should contain the true label with a user-specified probability, as if\nproduced by the cloud model. We formalize conditional coverage with respect to\nthe cloud predictive distribution, and introduce a conformal alignment-based\n(CAb) cascading mechanism that certifies this property with user control over\nthe risk level. Our method casts escalation from edge to cloud models as a\nmultiple-hypothesis testing (MHT) problem, tailoring conformal alignment (CA)\nto select which inputs can be safely handled at the edge. The proposed CAb\nmodel cascading method yields statistical guarantees on the average fraction of\nedge decisions that satisfy cloud-level conditional coverage. The procedure\napplies to arbitrary edge prediction sets, including variants of conformal\nprediction (CP), and exposes a tunable trade-off among coverage, deferral rate,\nand set size. Experiments on CIFAR-100 image classification and the TeleQnA\nquestion-answering (QA) benchmark show that the proposed CAb cascade maintains\nthe target conditional coverage for edge predictions while substantially\nreducing offloading to the cloud and incurring modest increases in\nprediction-set size.",
    "published": "2025-10-20T13:52:58Z",
    "updated": "2025-10-20T13:52:58Z",
    "link": "http://arxiv.org/pdf/2510.17543v1.pdf",
    "category": [
      "cs.LG",
      "eess.SP",
      "stat.ML"
    ],
    "authors": [
      "Jiayi Huang",
      "Sangwoo Park",
      "Nicola Paoletti",
      "Osvaldo Simeone"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.12024v2",
    "title": "FlexQuant: A Flexible and Efficient Dynamic Precision Switching\n  Framework for LLM Quantization",
    "summary": "The rapid advancement of large language models (LLMs) has exacerbated the\nmemory bottleneck due to the widening gap between model parameter scaling and\nhardware capabilities. While post-training quantization techniques effectively\nreduce memory overhead, existing methods predominantly rely on static\nquantization strategies, which struggle to adapt to dynamic workloads. To\naddress this, we propose FlexQuant, a dynamic precision-switching framework\nthat optimizes the trade-off between inference speed and accuracy. Leveraging\nmodel perplexity entropy and Kullback-Leibler divergence, FlexQuant enables\nfine-grained, layer-wise mixed-precision quantization and dynamically adjusts\nbit-widths during each token generation. FlexQuant provides a comprehensive\nanalysis of quantization strategies, introduces a precision requirement model\nfor optimal switching, and implements efficient fine-grained precision\nmanagement. Evaluations demonstrate that FlexQuant achieves a 1.3x end-to-end\nspeedup across diverse language tasks with negligible accuracy loss introduced.\nThis framework offers a flexible and adaptive solution for efficient LLM\ndeployment. Code is released at https://github.com/ZongwuWang/FlexQuant.git.",
    "published": "2025-05-21T07:42:53Z",
    "updated": "2025-10-20T13:38:28Z",
    "link": "http://arxiv.org/pdf/2506.12024v2.pdf",
    "category": [
      "cs.LG",
      "I.2.1; I.2.7"
    ],
    "authors": [
      "Fangxin Liu",
      "Zongwu Wang",
      "JinHong Xia",
      "Junping Zhao",
      "Shouren Zhao",
      "Jinjin Li",
      "Jian Liu",
      "Li Jiang",
      "Haibing Guan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17531v1",
    "title": "Plasma Shape Control via Zero-shot Generative Reinforcement Learning",
    "summary": "Traditional PID controllers have limited adaptability for plasma shape\ncontrol, and task-specific reinforcement learning (RL) methods suffer from\nlimited generalization and the need for repetitive retraining. To overcome\nthese challenges, this paper proposes a novel framework for developing a\nversatile, zero-shot control policy from a large-scale offline dataset of\nhistorical PID-controlled discharges. Our approach synergistically combines\nGenerative Adversarial Imitation Learning (GAIL) with Hilbert space\nrepresentation learning to achieve dual objectives: mimicking the stable\noperational style of the PID data and constructing a geometrically structured\nlatent space for efficient, goal-directed control. The resulting foundation\npolicy can be deployed for diverse trajectory tracking tasks in a zero-shot\nmanner without any task-specific fine-tuning. Evaluations on the HL-3 tokamak\nsimulator demonstrate that the policy excels at precisely and stably tracking\nreference trajectories for key shape parameters across a range of plasma\nscenarios. This work presents a viable pathway toward developing highly\nflexible and data-efficient intelligent control systems for future fusion\nreactors.",
    "published": "2025-10-20T13:34:51Z",
    "updated": "2025-10-20T13:34:51Z",
    "link": "http://arxiv.org/pdf/2510.17531v1.pdf",
    "category": [
      "physics.plasm-ph",
      "cs.LG"
    ],
    "authors": [
      "Niannian Wu",
      "Rongpeng Li",
      "Zongyu Yang",
      "Yong Xiao",
      "Ning Wei",
      "Yihang Chen",
      "Bo Li",
      "Zhifeng Zhao",
      "Wulyu Zhong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.20020v3",
    "title": "The Syntax and Semantics of einsum",
    "summary": "In 2011, einsum was introduced to NumPy as a practical and convenient\nnotation for tensor expressions in machine learning, quantum circuit\nsimulation, and other fields. It has since been implemented in additional\nPython frameworks such as PyTorch and TensorFlow, as well as in other\nprogramming languages such as Julia. Despite its practical success, the einsum\nnotation still lacks a solid theoretical basis, and is not unified across the\ndifferent frameworks, limiting opportunities for formal reasoning and\nsystematic optimization. In this work, we discuss the terminology of tensor\nexpressions and provide a formal definition of the einsum language. Based on\nthis definition, we formalize and prove important equivalence rules for tensor\nexpressions and highlight their relevance in practical applications.",
    "published": "2025-09-24T11:36:02Z",
    "updated": "2025-10-20T13:29:52Z",
    "link": "http://arxiv.org/pdf/2509.20020v3.pdf",
    "category": [
      "cs.PL",
      "cs.LG",
      "cs.MS",
      "cs.SC",
      "F.2.2; I.1.2; I.1.3"
    ],
    "authors": [
      "Maurice Wenig",
      "Paul G. Rump",
      "Mark Blacher",
      "Joachim Giesen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17526v1",
    "title": "How Does Label Noise Gradient Descent Improve Generalization in the Low\n  SNR Regime?",
    "summary": "The capacity of deep learning models is often large enough to both learn the\nunderlying statistical signal and overfit to noise in the training set. This\nnoise memorization can be harmful especially for data with a low\nsignal-to-noise ratio (SNR), leading to poor generalization. Inspired by prior\nobservations that label noise provides implicit regularization that improves\ngeneralization, in this work, we investigate whether introducing label noise to\nthe gradient updates can enhance the test performance of neural network (NN) in\nthe low SNR regime. Specifically, we consider training a two-layer NN with a\nsimple label noise gradient descent (GD) algorithm, in an idealized\nsignal-noise data setting. We prove that adding label noise during training\nsuppresses noise memorization, preventing it from dominating the learning\nprocess; consequently, label noise GD enjoys rapid signal growth while the\noverfitting remains controlled, thereby achieving good generalization despite\nthe low SNR. In contrast, we also show that NN trained with standard GD tends\nto overfit to noise in the same low SNR setting and establish a non-vanishing\nlower bound on its test error, thus demonstrating the benefit of introducing\nlabel noise in gradient-based training.",
    "published": "2025-10-20T13:28:13Z",
    "updated": "2025-10-20T13:28:13Z",
    "link": "http://arxiv.org/pdf/2510.17526v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Wei Huang",
      "Andi Han",
      "Yujin Song",
      "Yilan Chen",
      "Denny Wu",
      "Difan Zou",
      "Taiji Suzuki"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17524v1",
    "title": "Mitigating Clever Hans Strategies in Image Classifiers through\n  Generating Counterexamples",
    "summary": "Deep learning models remain vulnerable to spurious correlations, leading to\nso-called Clever Hans predictors that undermine robustness even in large-scale\nfoundation and self-supervised models. Group distributional robustness methods,\nsuch as Deep Feature Reweighting (DFR) rely on explicit group labels to\nupweight underrepresented subgroups, but face key limitations: (1) group labels\nare often unavailable, (2) low within-group sample sizes hinder coverage of the\nsubgroup distribution, and (3) performance degrades sharply when multiple\nspurious correlations fragment the data into even smaller groups. We propose\nCounterfactual Knowledge Distillation (CFKD), a framework that sidesteps these\nissues by generating diverse counterfactuals, enabling a human annotator to\nefficiently explore and correct the model's decision boundaries through a\nknowledge distillation step. Unlike DFR, our method not only reweights the\nundersampled groups, but it also enriches them with new data points. Our method\ndoes not require any confounder labels, achieves effective scaling to multiple\nconfounders, and yields balanced generalization across groups. We demonstrate\nCFKD's efficacy across five datasets, spanning synthetic tasks to an industrial\napplication, with particularly strong gains in low-data regimes with pronounced\nspurious correlations. Additionally, we provide an ablation study on the effect\nof the chosen counterfactual explainer and teacher model, highlighting their\nimpact on robustness.",
    "published": "2025-10-20T13:22:57Z",
    "updated": "2025-10-20T13:22:57Z",
    "link": "http://arxiv.org/pdf/2510.17524v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Sidney Bender",
      "Ole Delzer",
      "Jan Herrmann",
      "Heike Antje Marxfeld",
      "Klaus-Robert MÃ¼ller",
      "GrÃ©goire Montavon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17520v1",
    "title": "Curiosity Meets Cooperation: A Game-Theoretic Approach to Long-Tail\n  Multi-Label Learning",
    "summary": "Long-tail imbalance is endemic to multi-label learning: a few head labels\ndominate the gradient signal, while the many rare labels that matter in\npractice are silently ignored. We tackle this problem by casting the task as a\ncooperative potential game. In our Curiosity-Driven Game-Theoretic Multi-Label\nLearning (CD-GTMLL) framework, the label space is split among several\ncooperating players that share a global accuracy payoff yet earn additional\ncuriosity rewards that rise with label rarity and inter-player disagreement.\nThese curiosity bonuses inject gradient on under-represented tags without\nhand-tuned class weights. We prove that gradient best-response updates ascend a\ndifferentiable potential and converge to tail-aware stationary points that\ntighten a lower bound on the expected Rare-F1. Extensive experiments on\nconventional benchmarks and three extreme-scale datasets show consistent\nstate-of-the-art gains, delivering up to +4.3% Rare-F1 and +1.6% P@3 over the\nstrongest baselines, while ablations reveal emergent division of labour and\nfaster consensus on rare classes. CD-GTMLL thus offers a principled, scalable\nroute to long-tail robustness in multi-label prediction.",
    "published": "2025-10-20T13:21:07Z",
    "updated": "2025-10-20T13:21:07Z",
    "link": "http://arxiv.org/pdf/2510.17520v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Canran Xiao",
      "Chuangxin Zhao",
      "Zong Ke",
      "Fei Shen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17517v1",
    "title": "SAFE-D: A Spatiotemporal Detection Framework for Abnormal Driving Among\n  Parkinson's Disease-like Drivers",
    "summary": "A driver's health state serves as a determinant factor in driving behavioral\nregulation. Subtle deviations from normalcy can lead to operational anomalies,\nposing risks to public transportation safety. While prior efforts have\ndeveloped detection mechanisms for functionally-driven temporary anomalies such\nas drowsiness and distraction, limited research has addressed\npathologically-triggered deviations, especially those stemming from chronic\nmedical conditions. To bridge this gap, we investigate the driving behavior of\nParkinson's disease patients and propose SAFE-D, a novel framework for\ndetecting Parkinson-related behavioral anomalies to enhance driving safety. Our\nmethodology starts by performing analysis of Parkinson's disease\nsymptomatology, focusing on primary motor impairments, and establishes causal\nlinks to degraded driving performance. To represent the subclinical behavioral\nvariations of early-stage Parkinson's disease, our framework integrates data\nfrom multiple vehicle control components to build a behavioral profile. We then\ndesign an attention-based network that adaptively prioritizes spatiotemporal\nfeatures, enabling robust anomaly detection under physiological variability.\nFinally, we validate SAFE-D on the Logitech G29 platform and CARLA simulator,\nusing data from three road maps to emulate real-world driving. Our results show\nSAFE-D achieves 96.8% average accuracy in distinguishing normal and\nParkinson-affected driving patterns.",
    "published": "2025-10-20T13:17:03Z",
    "updated": "2025-10-20T13:17:03Z",
    "link": "http://arxiv.org/pdf/2510.17517v1.pdf",
    "category": [
      "cs.LG",
      "cs.HC"
    ],
    "authors": [
      "Hangcheng Cao",
      "Baixiang Huang",
      "Longzhi Yuan",
      "Haonan An",
      "Zihan Fang",
      "Xianhao Chen",
      "Yuguang Fang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2408.08533v2",
    "title": "Adv-SSL: Adversarial Self-Supervised Representation Learning with\n  Theoretical Guarantees",
    "summary": "Learning transferable data representations from abundant unlabeled data\nremains a central challenge in machine learning. Although numerous\nself-supervised learning methods have been proposed to address this challenge,\na significant class of these approaches aligns the covariance or correlation\nmatrix with the identity matrix. Despite impressive performance across various\ndownstream tasks, these methods often suffer from biased sample risk, leading\nto substantial optimization shifts in mini-batch settings and complicating\ntheoretical analysis. In this paper, we introduce a novel \\underline{\\bf\nAdv}ersarial \\underline{\\bf S}elf-\\underline{\\bf S}upervised Representation\n\\underline{\\bf L}earning (Adv-SSL) for unbiased transfer learning with no\nadditional cost compared to its biased counterparts. Our approach not only\noutperforms the existing methods across multiple benchmark datasets but is also\nsupported by comprehensive end-to-end theoretical guarantees. Our analysis\nreveals that the minimax optimization in Adv-SSL encourages representations to\nform well-separated clusters in the embedding space, provided there is\nsufficient upstream unlabeled data. As a result, our method achieves strong\nclassification performance even with limited downstream labels, shedding new\nlight on few-shot learning.",
    "published": "2024-08-16T05:11:52Z",
    "updated": "2025-10-20T13:12:59Z",
    "link": "http://arxiv.org/pdf/2408.08533v2.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Chenguang Duan",
      "Yuling Jiao",
      "Huazhen Lin",
      "Wensen Ma",
      "Jerry Zhijian Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17512v1",
    "title": "AWARE: Audio Watermarking with Adversarial Resistance to Edits",
    "summary": "Prevailing practice in learning-based audio watermarking is to pursue\nrobustness by expanding the set of simulated distortions during training.\nHowever, such surrogates are narrow and prone to overfitting. This paper\npresents AWARE (Audio Watermarking with Adversarial Resistance to Edits), an\nalternative approach that avoids reliance on attack-simulation stacks and\nhandcrafted differentiable distortions. Embedding is obtained via adversarial\noptimization in the time-frequency domain under a level-proportional perceptual\nbudget. Detection employs a time-order-agnostic detector with a Bitwise Readout\nHead (BRH) that aggregates temporal evidence into one score per watermark bit,\nenabling reliable watermark decoding even under desynchronization and temporal\ncuts. Empirically, AWARE attains high audio quality and speech intelligibility\n(PESQ/STOI) and consistently low BER across various audio edits, often\nsurpassing representative state-of-the-art learning-based audio watermarking\nsystems.",
    "published": "2025-10-20T13:10:52Z",
    "updated": "2025-10-20T13:10:52Z",
    "link": "http://arxiv.org/pdf/2510.17512v1.pdf",
    "category": [
      "cs.SD",
      "cs.LG",
      "cs.MM"
    ],
    "authors": [
      "Kosta PavloviÄ",
      "Lazar StanareviÄ",
      "Petar NediÄ",
      "Slavko KovaÄeviÄ",
      "Igor DjuroviÄ"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17506v1",
    "title": "Convergence Rates for Gradient Descent on the Edge of Stability in\n  Overparametrised Least Squares",
    "summary": "Classical optimisation theory guarantees monotonic objective decrease for\ngradient descent (GD) when employed in a small step size, or ``stable\", regime.\nIn contrast, gradient descent on neural networks is frequently performed in a\nlarge step size regime called the ``edge of stability\", in which the objective\ndecreases non-monotonically with an observed implicit bias towards flat minima.\nIn this paper, we take a step toward quantifying this phenomenon by providing\nconvergence rates for gradient descent with large learning rates in an\noverparametrised least squares setting. The key insight behind our analysis is\nthat, as a consequence of overparametrisation, the set of global minimisers\nforms a Riemannian manifold $M$, which enables the decomposition of the GD\ndynamics into components parallel and orthogonal to $M$. The parallel component\ncorresponds to Riemannian gradient descent on the objective sharpness, while\nthe orthogonal component is a bifurcating dynamical system. This insight allows\nus to derive convergence rates in three regimes characterised by the learning\nrate size: (a) the subcritical regime, in which transient instability is\novercome in finite time before linear convergence to a suboptimally flat global\nminimum; (b) the critical regime, in which instability persists for all time\nwith a power-law convergence toward the optimally flat global minimum; and (c)\nthe supercritical regime, in which instability persists for all time with\nlinear convergence to an orbit of period two centred on the optimally flat\nglobal minimum.",
    "published": "2025-10-20T13:02:41Z",
    "updated": "2025-10-20T13:02:41Z",
    "link": "http://arxiv.org/pdf/2510.17506v1.pdf",
    "category": [
      "cs.LG",
      "math.OC"
    ],
    "authors": [
      "Lachlan Ewen MacDonald",
      "Hancheng Min",
      "Leandro Palma",
      "Salma Tarmoun",
      "Ziqing Xu",
      "RenÃ© Vidal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17503v1",
    "title": "Stochastic Difference-of-Convex Optimization with Momentum",
    "summary": "Stochastic difference-of-convex (DC) optimization is prevalent in numerous\nmachine learning applications, yet its convergence properties under small batch\nsizes remain poorly understood. Existing methods typically require large\nbatches or strong noise assumptions, which limit their practical use. In this\nwork, we show that momentum enables convergence under standard smoothness and\nbounded variance assumptions (of the concave part) for any batch size. We prove\nthat without momentum, convergence may fail regardless of stepsize,\nhighlighting its necessity. Our momentum-based algorithm achieves provable\nconvergence and demonstrates strong empirical performance.",
    "published": "2025-10-20T13:00:32Z",
    "updated": "2025-10-20T13:00:32Z",
    "link": "http://arxiv.org/pdf/2510.17503v1.pdf",
    "category": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "authors": [
      "El Mahdi Chayti",
      "Martin Jaggi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17486v1",
    "title": "Local properties of neural networks through the lens of layer-wise\n  Hessians",
    "summary": "We introduce a methodology for analyzing neural networks through the lens of\nlayer-wise Hessian matrices. The local Hessian of each functional block (layer)\nis defined as the matrix of second derivatives of a scalar function with\nrespect to the parameters of that layer. This concept provides a formal tool\nfor characterizing the local geometry of the parameter space. We show that the\nspectral properties of local Hessians, such as the distribution of eigenvalues,\nreveal quantitative patterns associated with overfitting,\nunderparameterization, and expressivity in neural network architectures. We\nconduct an extensive empirical study involving 111 experiments across 37\ndatasets. The results demonstrate consistent structural regularities in the\nevolution of local Hessians during training and highlight correlations between\ntheir spectra and generalization performance. These findings establish a\nfoundation for using local geometric analysis to guide the diagnosis and design\nof deep neural networks. The proposed framework connects optimization geometry\nwith functional behavior and offers practical insight for improving network\narchitectures and training stability.",
    "published": "2025-10-20T12:34:31Z",
    "updated": "2025-10-20T12:34:31Z",
    "link": "http://arxiv.org/pdf/2510.17486v1.pdf",
    "category": [
      "cs.LG",
      "68T07, 68T05, 65K10, 90C30",
      "I.2.6; G.1.6; I.5.1"
    ],
    "authors": [
      "Maxim Bolshim",
      "Alexander Kugaevskikh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17480v1",
    "title": "Unified Privacy Guarantees for Decentralized Learning via Matrix\n  Factorization",
    "summary": "Decentralized Learning (DL) enables users to collaboratively train models\nwithout sharing raw data by iteratively averaging local updates with neighbors\nin a network graph. This setting is increasingly popular for its scalability\nand its ability to keep data local under user control. Strong privacy\nguarantees in DL are typically achieved through Differential Privacy (DP), with\nresults showing that DL can even amplify privacy by disseminating noise across\npeer-to-peer communications. Yet in practice, the observed privacy-utility\ntrade-off often appears worse than in centralized training, which may be due to\nlimitations in current DP accounting methods for DL. In this paper, we show\nthat recent advances in centralized DP accounting based on Matrix Factorization\n(MF) for analyzing temporal noise correlations can also be leveraged in DL. By\ngeneralizing existing MF results, we show how to cast both standard DL\nalgorithms and common trust models into a unified formulation. This yields\ntighter privacy accounting for existing DP-DL algorithms and provides a\nprincipled way to develop new ones. To demonstrate the approach, we introduce\nMAFALDA-SGD, a gossip-based DL algorithm with user-level correlated noise that\noutperforms existing methods on synthetic and real-world graphs.",
    "published": "2025-10-20T12:24:27Z",
    "updated": "2025-10-20T12:24:27Z",
    "link": "http://arxiv.org/pdf/2510.17480v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "AurÃ©lien Bellet",
      "Edwige Cyffers",
      "Davide Frey",
      "Romaric Gaudel",
      "Dimitri LerÃ©vÃ©rend",
      "FranÃ§ois TaÃ¯ani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17478v1",
    "title": "Towards geological inference with process-based and deep generative\n  modeling, part 2: inversion of fluvial deposits and latent-space\n  disentanglement",
    "summary": "High costs and uncertainties make subsurface decision-making challenging, as\nacquiring new data is rarely scalable. Embedding geological knowledge directly\ninto predictive models offers a valuable alternative. A joint approach enables\njust that: process-based models that mimic geological processes can help train\ngenerative models that make predictions more efficiently. This study explores\nwhether a generative adversarial network (GAN) - a type of deep-learning\nalgorithm for generative modeling - trained to produce fluvial deposits can be\ninverted to match well and seismic data. Four inversion approaches applied to\nthree test samples with 4, 8, and 20 wells struggled to match these well data,\nespecially as the well number increased or as the test sample diverged from the\ntraining data. The key bottleneck lies in the GAN's latent representation: it\nis entangled, so samples with similar sedimentological features are not\nnecessarily close in the latent space. Label conditioning or latent\noverparameterization can partially disentangle the latent space during\ntraining, although not yet sufficiently for a successful inversion. Fine-tuning\nthe GAN to restructure the latent space locally reduces mismatches to\nacceptable levels for all test cases, with and without seismic data. But this\napproach depends on an initial, partially successful inversion step, which\ninfluences the quality and diversity of the final samples. Overall, GANs can\nalready handle the tasks required for their integration into geomodeling\nworkflows. We still need to further assess their robustness, and how to best\nleverage them in support of geological interpretation.",
    "published": "2025-10-20T12:22:12Z",
    "updated": "2025-10-20T12:22:12Z",
    "link": "http://arxiv.org/pdf/2510.17478v1.pdf",
    "category": [
      "cs.LG",
      "physics.geo-ph",
      "I.2.6; I.6.3; J.2"
    ],
    "authors": [
      "Guillaume Rongier",
      "Luk Peeters"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17472v1",
    "title": "Certified Self-Consistency: Statistical Guarantees and Test-Time\n  Training for Reliable Reasoning in LLMs",
    "summary": "Recent advances such as self-consistency and test-time reinforcement learning\n(TTRL) improve the reliability of large language models (LLMs) without\nadditional supervision, yet their underlying mechanisms and statistical\nguarantees remain poorly understood. We present a unified framework for\ncertifiable inference in LLMs, showing that majority voting provides a\nstatistical certificate of self-consistency: under mild assumptions, the\naggregated answer coincides with the mode of the model's terminal distribution\nwith high probability. We derive finite-sample and anytime-valid concentration\nbounds that quantify this confidence, and introduce the Martingale Majority\nCertificate (MMC), a sequential stopping rule that adaptively determines when\nsufficient samples have been drawn. We further prove that label-free\npost-training methods such as TTRL implicitly sharpen the answer distribution\nby exponentially tilting it toward its mode, thereby reducing the number of\nsamples required for certification. Building on this insight, we propose new\npost-training objectives that explicitly optimise this trade-off between\nsharpness and bias. Together, these results explain and connect two central\ntest-time scaling strategies, self-consistency and TTRL, within a single\nstatistical framework for label-free, certifiable reliability in reasoning\nLLMs.",
    "published": "2025-10-20T12:14:12Z",
    "updated": "2025-10-20T12:14:12Z",
    "link": "http://arxiv.org/pdf/2510.17472v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Paula Cordero-Encinar",
      "Andrew B. Duncan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2303.04203v3",
    "title": "What is Memory? A Homological Perspective",
    "summary": "We introduce the delta-homology model of memory, a unified framework in which\nrecall, learning, and prediction emerge from cycle closure, the completion of\ntopologically constrained trajectories within the brain's latent manifold. A\nDirac-like memory trace corresponds to a nontrivial homology generator,\nrepresenting a sparse, irreducible attractor that reactivates only when\ninference trajectories close upon themselves. In this view, memory is not a\nstatic attractor landscape but a topological process of recurrence, where\nstructure arises through the stabilization of closed loops. Building on this\nprinciple, we represent spike-timing dynamics as spatiotemporal complexes, in\nwhich temporally consistent transitions among neurons form chain complexes\nsupporting persistent activation cycles. These cycles are organized into cell\nposets, compact causal representations that encode overlapping and\ncompositional memory traces. Within this construction, learning and recall\ncorrespond to cycle closure under contextual modulation: inference trajectories\nstabilize into nontrivial homology classes when both local synchrony (context)\nand global recurrence (content) are satisfied. We formalize this mechanism\nthrough the Context-Content Uncertainty Principle (CCUP), which states that\ncognition minimizes joint uncertainty between a high-entropy context variable\nand a low-entropy content variable. Synchronization acts as a context filter\nselecting coherent subnetworks, while recurrence acts as a content filter\nvalidating nontrivial cycles.",
    "published": "2023-03-07T19:47:01Z",
    "updated": "2025-10-20T12:04:37Z",
    "link": "http://arxiv.org/pdf/2303.04203v3.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Xin Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17467v1",
    "title": "CrossStateECG: Multi-Scale Deep Convolutional Network with Attention for\n  Rest-Exercise ECG Biometrics",
    "summary": "Current research in Electrocardiogram (ECG) biometrics mainly emphasizes\nresting-state conditions, leaving the performance decline in rest-exercise\nscenarios largely unresolved. This paper introduces CrossStateECG, a robust\nECG-based authentication model explicitly tailored for cross-state\n(rest-exercise) conditions. The proposed model creatively combines multi-scale\ndeep convolutional feature extraction with attention mechanisms to ensure\nstrong identification across different physiological states. Experimental\nresults on the exercise-ECGID dataset validate the effectiveness of\nCrossStateECG, achieving an identification accuracy of 92.50% in the\nRest-to-Exercise scenario (training on resting ECG and testing on post-exercise\nECG) and 94.72% in the Exercise-to-Rest scenario (training on post-exercise ECG\nand testing on resting ECG). Furthermore, CrossStateECG demonstrates\nexceptional performance across both state combinations, reaching an accuracy of\n99.94% in Rest-to-Rest scenarios and 97.85% in Mixed-to-Mixed scenarios.\nAdditional validations on the ECG-ID and MIT-BIH datasets further confirmed the\ngeneralization abilities of CrossStateECG, underscoring its potential as a\npractical solution for post-exercise ECG-based authentication in dynamic\nreal-world settings.",
    "published": "2025-10-20T12:03:46Z",
    "updated": "2025-10-20T12:03:46Z",
    "link": "http://arxiv.org/pdf/2510.17467v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Dan Zheng",
      "Jing Feng",
      "Juan Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.15188v2",
    "title": "OCR-APT: Reconstructing APT Stories from Audit Logs using Subgraph\n  Anomaly Detection and LLMs",
    "summary": "Advanced Persistent Threats (APTs) are stealthy cyberattacks that often evade\ndetection in system-level audit logs. Provenance graphs model these logs as\nconnected entities and events, revealing relationships that are missed by\nlinear log representations. Existing systems apply anomaly detection to these\ngraphs but often suffer from high false positive rates and coarse-grained\nalerts. Their reliance on node attributes like file paths or IPs leads to\nspurious correlations, reducing detection robustness and reliability. To fully\nunderstand an attack's progression and impact, security analysts need systems\nthat can generate accurate, human-like narratives of the entire attack. To\naddress these challenges, we introduce OCR-APT, a system for APT detection and\nreconstruction of human-like attack stories. OCR-APT uses Graph Neural Networks\n(GNNs) for subgraph anomaly detection, learning behavior patterns around nodes\nrather than fragile attributes such as file paths or IPs. This approach leads\nto a more robust anomaly detection. It then iterates over detected subgraphs\nusing Large Language Models (LLMs) to reconstruct multi-stage attack stories.\nEach stage is validated before proceeding, reducing hallucinations and ensuring\nan interpretable final report. Our evaluations on the DARPA TC3, OpTC, and\nNODLINK datasets show that OCR-APT outperforms state-of-the-art systems in both\ndetection accuracy and alert interpretability. Moreover, OCR-APT reconstructs\nhuman-like reports that comprehensively capture the attack story.",
    "published": "2025-10-16T23:14:03Z",
    "updated": "2025-10-20T12:03:37Z",
    "link": "http://arxiv.org/pdf/2510.15188v2.pdf",
    "category": [
      "cs.CR",
      "cs.LG"
    ],
    "authors": [
      "Ahmed Aly",
      "Essam Mansour",
      "Amr Youssef"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17459v1",
    "title": "Estimating Orbital Parameters of Direct Imaging Exoplanet Using Neural\n  Network",
    "summary": "In this work, we propose a new flow-matching Markov chain Monte Carlo\n(FM-MCMC) algorithm for estimating the orbital parameters of exoplanetary\nsystems, especially for those only one exoplanet is involved. Compared to\ntraditional methods that rely on random sampling within the Bayesian framework,\nour approach first leverages flow matching posterior estimation (FMPE) to\nefficiently constrain the prior range of physical parameters, and then employs\nMCMC to accurately infer the posterior distribution. For example, in the\norbital parameter inference of beta Pictoris b, our model achieved a\nsubstantial speed-up while maintaining comparable accuracy-running 77.8 times\nfaster than Parallel Tempered MCMC (PTMCMC) and 365.4 times faster than nested\nsampling. Moreover, our FM-MCMC method also attained the highest average\nlog-likelihood among all approaches, demonstrating its superior sampling\nefficiency and accuracy. This highlights the scalability and efficiency of our\napproach, making it well-suited for processing the massive datasets expected\nfrom future exoplanet surveys. Beyond astrophysics, our methodology establishes\na versatile paradigm for synergizing deep generative models with traditional\nsampling, which can be adopted to tackle complex inference problems in other\nfields, such as cosmology, biomedical imaging, and particle physics.",
    "published": "2025-10-20T11:46:55Z",
    "updated": "2025-10-20T11:46:55Z",
    "link": "http://arxiv.org/pdf/2510.17459v1.pdf",
    "category": [
      "astro-ph.EP",
      "astro-ph.GA",
      "cs.LG"
    ],
    "authors": [
      "Bo Liang",
      "Hanlin Song",
      "Chang Liu",
      "Tianyu Zhao",
      "Yuxiang Xu",
      "Zihao Xiao",
      "Manjia Liang",
      "Minghui Du",
      "Wei-Liang Qian",
      "Li-e Qiang",
      "Peng Xu",
      "Ziren Luo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17458v1",
    "title": "Explainable AI for microseismic event detection",
    "summary": "Deep neural networks like PhaseNet show high accuracy in detecting\nmicroseismic events, but their black-box nature is a concern in critical\napplications. We apply explainable AI (XAI) techniques, such as\nGradient-weighted Class Activation Mapping (Grad-CAM) and Shapley Additive\nExplanations (SHAP), to interpret the PhaseNet model's decisions and improve\nits reliability. Grad-CAM highlights that the network's attention aligns with\nP- and S-wave arrivals. SHAP values quantify feature contributions, confirming\nthat vertical-component amplitudes drive P-phase picks while horizontal\ncomponents dominate S-phase picks, consistent with geophysical principles.\nLeveraging these insights, we introduce a SHAP-gated inference scheme that\ncombines the model's output with an explanation-based metric to reduce errors.\nOn a test set of 9,000 waveforms, the SHAP-gated model achieved an F1-score of\n0.98 (precision 0.99, recall 0.97), outperforming the baseline PhaseNet\n(F1-score 0.97) and demonstrating enhanced robustness to noise. These results\nshow that XAI can not only interpret deep learning models but also directly\nenhance their performance, providing a template for building trust in automated\nseismic detectors.",
    "published": "2025-10-20T11:42:17Z",
    "updated": "2025-10-20T11:42:17Z",
    "link": "http://arxiv.org/pdf/2510.17458v1.pdf",
    "category": [
      "cs.LG",
      "physics.geo-ph"
    ],
    "authors": [
      "Ayrat Abdullin",
      "Denis Anikiev",
      "Umair bin Waheed"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17457v1",
    "title": "Deeper with Riemannian Geometry: Overcoming Oversmoothing and\n  Oversquashing for Graph Foundation Models",
    "summary": "Message Passing Neural Networks (MPNNs) is the building block of graph\nfoundation models, but fundamentally suffer from oversmoothing and\noversquashing. There has recently been a surge of interest in fixing both\nissues. Existing efforts primarily adopt global approaches, which may be\nbeneficial in some regions but detrimental in others, ultimately leading to the\nsuboptimal expressiveness. In this paper, we begin by revisiting oversquashing\nthrough a global measure -- spectral gap $\\lambda$ -- and prove that the\nincrease of $\\lambda$ leads to gradient vanishing with respect to the input\nfeatures, thereby undermining the effectiveness of message passing. Motivated\nby such theoretical insights, we propose a \\textbf{local} approach that\nadaptively adjusts message passing based on local structures. To achieve this,\nwe connect local Riemannian geometry with MPNNs, and establish a novel\nnonhomogeneous boundary condition to address both oversquashing and\noversmoothing. Building on the Robin condition, we design a GBN network with\nlocal bottleneck adjustment, coupled with theoretical guarantees. Extensive\nexperiments on homophilic and heterophilic graphs show the expressiveness of\nGBN. Furthermore, GBN does not exhibit performance degradation even when the\nnetwork depth exceeds $256$ layers.",
    "published": "2025-10-20T11:41:45Z",
    "updated": "2025-10-20T11:41:45Z",
    "link": "http://arxiv.org/pdf/2510.17457v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Li Sun",
      "Zhenhao Huang",
      "Ming Zhang",
      "Philip S. Yu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.12172v3",
    "title": "Application-oriented automatic hyperparameter optimization for spiking\n  neural network prototyping",
    "summary": "Hyperparameter optimization (HPO) is of paramount importance in the\ndevelopment of high-performance, specialized artificial intelligence (AI)\nmodels, ranging from well-established machine learning (ML) solutions to the\ndeep learning (DL) domain and the field of spiking neural networks (SNNs). The\nlatter introduce further complexity due to the neuronal computational units and\ntheir additional hyperparameters, whose inadequate setting can dramatically\nimpact the final model performance. At the cost of possible reduced\ngeneralization capabilities, the most suitable strategy to fully disclose the\npower of SNNs is to adopt an application-oriented approach and perform\nextensive HPO experiments. To facilitate these operations, automatic pipelines\nare fundamental, and their configuration is crucial. In this document, the\nNeural Network Intelligence (NNI) toolkit is used as reference framework to\npresent one such solution, with a use case example providing evidence of the\ncorresponding results. In addition, a summary of published works employing the\npresented pipeline is reported as a potential source of insights into\napplication-oriented HPO experiments for SNN prototyping.",
    "published": "2025-02-13T14:49:44Z",
    "updated": "2025-10-20T11:23:29Z",
    "link": "http://arxiv.org/pdf/2502.12172v3.pdf",
    "category": [
      "cs.NE",
      "cs.LG"
    ],
    "authors": [
      "Vittorio Fra"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17425v1",
    "title": "Quantifying Climate Policy Action and Its Links to Development Outcomes:\n  A Cross-National Data-Driven Analysis",
    "summary": "Addressing climate change effectively requires more than cataloguing the\nnumber of policies in place; it calls for tools that can reveal their thematic\npriorities and their tangible impacts on development outcomes. Existing\nassessments often rely on qualitative descriptions or composite indices, which\ncan mask crucial differences between key domains such as mitigation,\nadaptation, disaster risk management, and loss and damage. To bridge this gap,\nwe develop a quantitative indicator of climate policy orientation by applying a\nmultilingual transformer-based language model to official national policy\ndocuments, achieving a classification accuracy of 0.90 (F1-score). Linking\nthese indicators with World Bank development data in panel regressions reveals\nthat mitigation policies are associated with higher GDP and GNI; disaster risk\nmanagement correlates with greater GNI and debt but reduced foreign direct\ninvestment; adaptation and loss and damage show limited measurable effects.\nThis integrated NLP-econometric framework enables comparable, theme-specific\nanalysis of climate governance, offering a scalable method to monitor progress,\nevaluate trade-offs, and align policy emphasis with development goals.",
    "published": "2025-10-20T11:12:30Z",
    "updated": "2025-10-20T11:12:30Z",
    "link": "http://arxiv.org/pdf/2510.17425v1.pdf",
    "category": [
      "cs.CY",
      "cs.LG"
    ],
    "authors": [
      "Aditi Dutta"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17421v1",
    "title": "Diffusion Models as Dataset Distillation Priors",
    "summary": "Dataset distillation aims to synthesize compact yet informative datasets from\nlarge ones. A significant challenge in this field is achieving a trifecta of\ndiversity, generalization, and representativeness in a single distilled\ndataset. Although recent generative dataset distillation methods adopt powerful\ndiffusion models as their foundation models, the inherent representativeness\nprior in diffusion models is overlooked. Consequently, these approaches often\nnecessitate the integration of external constraints to enhance data quality. To\naddress this, we propose Diffusion As Priors (DAP), which formalizes\nrepresentativeness by quantifying the similarity between synthetic and real\ndata in feature space using a Mercer kernel. We then introduce this prior as\nguidance to steer the reverse diffusion process, enhancing the\nrepresentativeness of distilled samples without any retraining. Extensive\nexperiments on large-scale datasets, such as ImageNet-1K and its subsets,\ndemonstrate that DAP outperforms state-of-the-art methods in generating\nhigh-fidelity datasets while achieving superior cross-architecture\ngeneralization. Our work not only establishes a theoretical connection between\ndiffusion priors and the objectives of dataset distillation but also provides a\npractical, training-free framework for improving the quality of the distilled\ndataset.",
    "published": "2025-10-20T11:04:09Z",
    "updated": "2025-10-20T11:04:09Z",
    "link": "http://arxiv.org/pdf/2510.17421v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Duo Su",
      "Huyu Wu",
      "Huanran Chen",
      "Yiming Shi",
      "Yuzhu Wang",
      "Xi Ye",
      "Jun Zhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17414v1",
    "title": "A Conditional Diffusion Model for Probabilistic Prediction of Battery\n  Capacity Degradation",
    "summary": "Accurate prediction of lithium-ion battery capacity and its associated\nuncertainty is essential for reliable battery management but remains\nchallenging due to the stochastic nature of aging. This paper presents a novel\nmethod, termed the Condition Diffusion U-Net with Attention (CDUA), which\nintegrates feature engineering and deep learning to address this challenge. The\nproposed approach employs a diffusion-based generative model for time-series\nforecasting and incorporates attention mechanisms to enhance predictive\nperformance. Battery capacity is first derived from real-world vehicle\noperation data. The most relevant features are then identified using the\nPearson correlation coefficient and the XGBoost algorithm. These features are\nused to train the CDUA model, which comprises two core components: (1) a\ncontextual U-Net with self-attention to capture complex temporal dependencies,\nand (2) a denoising network to reconstruct accurate capacity values from noisy\nobservations. Experimental validation on the real-world vehicle data\ndemonstrates that the proposed CDUA model achieves a relative Mean Absolute\nError (MAE) of 0.94% and a relative Root Mean Square Error (RMSE) of 1.14%,\nwith a narrow 95% confidence interval of 3.74% in relative width. These results\nconfirm that CDUA provides both accurate capacity estimation and reliable\nuncertainty quantification. Comparative experiments further verify its\nrobustness and superior performance over existing mainstream approaches.",
    "published": "2025-10-20T10:56:28Z",
    "updated": "2025-10-20T10:56:28Z",
    "link": "http://arxiv.org/pdf/2510.17414v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Hequn Li",
      "Zhongwei Deng",
      "Chunlin Jiang",
      "Yvxin He andZhansheng Ning"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17406v1",
    "title": "S4ECG: Exploring the impact of long-range interactions for arrhythmia\n  prediction",
    "summary": "The electrocardiogram (ECG) exemplifies biosignal-based time series with\ncontinuous, temporally ordered structure reflecting cardiac physiological and\npathophysiological dynamics. Detailed analysis of these dynamics has proven\nchallenging, as conventional methods capture either global trends or local\nwaveform features but rarely their simultaneous interplay at high temporal\nresolution. To bridge global and local signal analysis, we introduce S4ECG, a\nnovel deep learning architecture leveraging structured state space models for\nmulti-epoch arrhythmia classification. Our joint multi-epoch predictions\nsignificantly outperform single-epoch approaches by 1.0-11.6% in macro-AUROC,\nwith atrial fibrillation specificity improving from 0.718-0.979 to 0.967-0.998,\ndemonstrating superior performance in-distribution and enhanced\nout-of-distribution robustness. Systematic investigation reveals optimal\ntemporal dependency windows spanning 10-20 minutes for peak performance. This\nwork contributes to a paradigm shift toward temporally-aware arrhythmia\ndetection algorithms, opening new possibilities for ECG interpretation, in\nparticular for complex arrhythmias like atrial fibrillation and atrial flutter.",
    "published": "2025-10-20T10:48:44Z",
    "updated": "2025-10-20T10:48:44Z",
    "link": "http://arxiv.org/pdf/2510.17406v1.pdf",
    "category": [
      "cs.LG",
      "eess.SP"
    ],
    "authors": [
      "Tiezhi Wang",
      "Wilhelm Haverkamp",
      "Nils Strodthoff"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17396v1",
    "title": "RINS-T: Robust Implicit Neural Solvers for Time Series Linear Inverse\n  Problems",
    "summary": "Time series data are often affected by various forms of corruption, such as\nmissing values, noise, and outliers, which pose significant challenges for\ntasks such as forecasting and anomaly detection. To address these issues,\ninverse problems focus on reconstructing the original signal from corrupted\ndata by leveraging prior knowledge about its underlying structure. While deep\nlearning methods have demonstrated potential in this domain, they often require\nextensive pretraining and struggle to generalize under distribution shifts. In\nthis work, we propose RINS-T (Robust Implicit Neural Solvers for Time Series\nLinear Inverse Problems), a novel deep prior framework that achieves high\nrecovery performance without requiring pretraining data. RINS-T leverages\nneural networks as implicit priors and integrates robust optimization\ntechniques, making it resilient to outliers while relaxing the reliance on\nGaussian noise assumptions. To further improve optimization stability and\nrobustness, we introduce three key innovations: guided input initialization,\ninput perturbation, and convex output combination techniques. Each of these\ncontributions strengthens the framework's optimization stability and\nrobustness. These advancements make RINS-T a flexible and effective solution\nfor addressing complex real-world time series challenges. Our code is available\nat https://github.com/EPFL-IMOS/RINS-T.",
    "published": "2025-10-20T10:38:22Z",
    "updated": "2025-10-20T10:38:22Z",
    "link": "http://arxiv.org/pdf/2510.17396v1.pdf",
    "category": [
      "cs.LG",
      "eess.SP",
      "stat.ML"
    ],
    "authors": [
      "Keivan Faghih Niresi",
      "Zepeng Zhang",
      "Olga Fink"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17394v1",
    "title": "MILES: Modality-Informed Learning Rate Scheduler for Balancing\n  Multimodal Learning",
    "summary": "The aim of multimodal neural networks is to combine diverse data sources,\nreferred to as modalities, to achieve enhanced performance compared to relying\non a single modality. However, training of multimodal networks is typically\nhindered by modality overfitting, where the network relies excessively on one\nof the available modalities. This often yields sub-optimal performance,\nhindering the potential of multimodal learning and resulting in marginal\nimprovements relative to unimodal models. In this work, we present the\nModality-Informed Learning ratE Scheduler (MILES) for training multimodal joint\nfusion models in a balanced manner. MILES leverages the differences in\nmodality-wise conditional utilization rates during training to effectively\nbalance multimodal learning. The learning rate is dynamically adjusted during\ntraining to balance the speed of learning from each modality by the multimodal\nmodel, aiming for enhanced performance in both multimodal and unimodal\npredictions. We extensively evaluate MILES on four multimodal joint fusion\ntasks and compare its performance to seven state-of-the-art baselines. Our\nresults show that MILES outperforms all baselines across all tasks and fusion\nmethods considered in our study, effectively balancing modality usage during\ntraining. This results in improved multimodal performance and stronger modality\nencoders, which can be leveraged when dealing with unimodal samples or absent\nmodalities. Overall, our work highlights the impact of balancing multimodal\nlearning on improving model performance.",
    "published": "2025-10-20T10:34:59Z",
    "updated": "2025-10-20T10:34:59Z",
    "link": "http://arxiv.org/pdf/2510.17394v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Alejandro Guerra-Manzanares",
      "Farah E. Shamout"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17391v1",
    "title": "Finite-Time Bounds for Average-Reward Fitted Q-Iteration",
    "summary": "Although there is an extensive body of work characterizing the sample\ncomplexity of discounted-return offline RL with function approximations, prior\nwork on the average-reward setting has received significantly less attention,\nand existing approaches rely on restrictive assumptions, such as ergodicity or\nlinearity of the MDP. In this work, we establish the first sample complexity\nresults for average-reward offline RL with function approximation for weakly\ncommunicating MDPs, a much milder assumption. To this end, we introduce\nAnchored Fitted Q-Iteration, which combines the standard Fitted Q-Iteration\nwith an anchor mechanism. We show that the anchor, which can be interpreted as\na form of weight decay, is crucial for enabling finite-time analysis in the\naverage-reward setting. We also extend our finite-time analysis to the setup\nwhere the dataset is generated from a single-trajectory rather than IID\ntransitions, again leveraging the anchor mechanism.",
    "published": "2025-10-20T10:33:25Z",
    "updated": "2025-10-20T10:33:25Z",
    "link": "http://arxiv.org/pdf/2510.17391v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Jongmin Lee",
      "Ernest K. Ryu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17390v1",
    "title": "Exploration via Feature Perturbation in Contextual Bandits",
    "summary": "We propose feature perturbation, a simple yet powerful technique that injects\nrandomness directly into feature inputs, instead of randomizing unknown\nparameters or adding noise to rewards. Remarkably, this algorithm achieves\n$\\tilde{\\mathcal{O}}(d\\sqrt{T})$ worst-case regret bound for generalized linear\nbandits, while avoiding the $\\tilde{\\mathcal{O}}(d^{3/2}\\sqrt{T})$ regret\ntypical of existing randomized bandit algorithms. Because our algorithm eschews\nparameter sampling, it is both computationally efficient and naturally extends\nto non-parametric or neural network models. We verify these advantages through\nempirical evaluations, demonstrating that feature perturbation not only\nsurpasses existing methods but also unifies strong practical performance with\nbest-known theoretical guarantees.",
    "published": "2025-10-20T10:32:48Z",
    "updated": "2025-10-20T10:32:48Z",
    "link": "http://arxiv.org/pdf/2510.17390v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Seouh-won Yi",
      "Min-hwan Oh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17383v1",
    "title": "Latent Spaces Beyond Synthesis: From GANs to Diffusion Models",
    "summary": "This paper examines the evolving nature of internal representations in\ngenerative visual models, focusing on the conceptual and technical shift from\nGANs and VAEs to diffusion-based architectures. Drawing on Beatrice Fazi's\naccount of synthesis as the amalgamation of distributed representations, we\npropose a distinction between \"synthesis in a strict sense\", where a compact\nlatent space wholly determines the generative process, and \"synthesis in a\nbroad sense,\" which characterizes models whose representational labor is\ndistributed across layers. Through close readings of model architectures and a\ntargeted experimental setup that intervenes in layerwise representations, we\nshow how diffusion models fragment the burden of representation and thereby\nchallenge assumptions of unified internal space. By situating these findings\nwithin media theoretical frameworks and critically engaging with metaphors such\nas the latent space and the Platonic Representation Hypothesis, we argue for a\nreorientation of how generative AI is understood: not as a direct synthesis of\ncontent, but as an emergent configuration of specialized processes.",
    "published": "2025-10-20T10:20:42Z",
    "updated": "2025-10-20T10:20:42Z",
    "link": "http://arxiv.org/pdf/2510.17383v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV",
      "cs.CY"
    ],
    "authors": [
      "Ludovica Schaerf"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17381v1",
    "title": "Beyond Binary Out-of-Distribution Detection: Characterizing\n  Distributional Shifts with Multi-Statistic Diffusion Trajectories",
    "summary": "Detecting out-of-distribution (OOD) data is critical for machine learning, be\nit for safety reasons or to enable open-ended learning. However, beyond mere\ndetection, choosing an appropriate course of action typically hinges on the\ntype of OOD data encountered. Unfortunately, the latter is generally not\ndistinguished in practice, as modern OOD detection methods collapse\ndistributional shifts into single scalar outlier scores. This work argues that\nscalar-based methods are thus insufficient for OOD data to be properly\ncontextualized and prospectively exploited, a limitation we overcome with the\nintroduction of DISC: Diffusion-based Statistical Characterization. DISC\nleverages the iterative denoising process of diffusion models to extract a\nrich, multi-dimensional feature vector that captures statistical discrepancies\nacross multiple noise levels. Extensive experiments on image and tabular\nbenchmarks show that DISC matches or surpasses state-of-the-art detectors for\nOOD detection and, crucially, also classifies OOD type, a capability largely\nabsent from prior work. As such, our work enables a shift from simple binary\nOOD detection to a more granular detection.",
    "published": "2025-10-20T10:18:45Z",
    "updated": "2025-10-20T10:18:45Z",
    "link": "http://arxiv.org/pdf/2510.17381v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Achref Jaziri",
      "Martin Rogmann",
      "Martin Mundt",
      "Visvanathan Ramesh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17378v1",
    "title": "Model Metamers Reveal Invariances in Graph Neural Networks",
    "summary": "In recent years, deep neural networks have been extensively employed in\nperceptual systems to learn representations endowed with invariances, aiming to\nemulate the invariance mechanisms observed in the human brain. However, studies\nin the visual and auditory domains have confirmed that significant gaps remain\nbetween the invariance properties of artificial neural networks and those of\nhumans. To investigate the invariance behavior within graph neural networks\n(GNNs), we introduce a model ``metamers'' generation technique. By optimizing\ninput graphs such that their internal node activations match those of a\nreference graph, we obtain graphs that are equivalent in the model's\nrepresentation space, yet differ significantly in both structure and node\nfeatures. Our theoretical analysis focuses on two aspects: the local metamer\ndimension for a single node and the activation-induced volume change of the\nmetamer manifold. Utilizing this approach, we uncover extreme levels of\nrepresentational invariance across several classic GNN architectures. Although\ntargeted modifications to model architecture and training strategies can\npartially mitigate this excessive invariance, they fail to fundamentally bridge\nthe gap to human-like invariance. Finally, we quantify the deviation between\nmetamer graphs and their original counterparts, revealing unique failure modes\nof current GNNs and providing a complementary benchmark for model evaluation.",
    "published": "2025-10-20T10:13:55Z",
    "updated": "2025-10-20T10:13:55Z",
    "link": "http://arxiv.org/pdf/2510.17378v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Wei Xu",
      "Xiaoyi Jiang",
      "Lixiang Xu",
      "Dechao Tang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.13391v2",
    "title": "Going with the Flow: Approximating Banzhaf Values via Graph Neural\n  Networks",
    "summary": "Computing the Banzhaf value in network flow games is fundamental for\nquantifying agent influence in multi-agent systems, with applications ranging\nfrom cybersecurity to infrastructure planning. However, exact computation is\nintractable for systems with more than $\\sim20$ agents due to exponential\ncomplexity $\\mathcal{O}(2^m)$. While Monte Carlo sampling methods provide\nstatistical estimates, they suffer from high sample complexity and cannot\ntransfer knowledge across different network configurations, making them\nimpractical for large-scale or dynamic systems. We present a novel\nlearning-based approach using Graph Neural Networks (GNNs) to approximate\nBanzhaf values in cardinal network flow games. By framing the problem as a\ngraph-level prediction task, our method learns generalisable patterns of agent\ninfluence directly from network topology and control structure. We conduct a\ncomprehensive empirical study comparing three state-of-the-art GNN\narchitectures-Graph Attention Networks (GAT), Graph Isomorphism Networks with\nEdge features (GINE), and EdgeConv-on a large-scale synthetic dataset of\n200,000 graphs per configuration, varying in size (20-100 nodes), agent count\n(5-20), and edge probability (0.5-1.0). Our results demonstrate that trained\nGNN models achieve high-fidelity Banzhaf value approximation with\norder-of-magnitude speedups compared to exact and sampling-based methods. Most\nsignificantly, we show strong zero-shot generalisation: models trained on\ngraphs of a specific size and topology accurately predict Banzhaf values for\nentirely new networks with different structural properties, without requiring\nretraining. This work establishes GNNs as a practical tool for scalable\ncooperative game-theoretic analysis of complex networked systems.",
    "published": "2025-10-15T10:40:33Z",
    "updated": "2025-10-20T10:08:41Z",
    "link": "http://arxiv.org/pdf/2510.13391v2.pdf",
    "category": [
      "cs.LG",
      "cs.GT",
      "91A12, 68T07, 05C21",
      "I.2.6; F.2.2; C.2.1"
    ],
    "authors": [
      "Benjamin Kempinski",
      "Tal Kachman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17364v1",
    "title": "Recurrent Attention-based Token Selection for Efficient Streaming\n  Video-LLMs",
    "summary": "Video Large Language Models (Video-LLMs) excel at understanding videos\nin-context, provided they have full access to the video when answering queries.\nHowever, these models face challenges in streaming scenarios where hour-long\nvideos must be processed online, and questions need timely responses. In this\nwork, we propose a training-free approach compatible with standard Video-LLMs,\nleveraging three key concepts: 1) LLM-informed selection of visual tokens to\nidentify those that the LLM has attended to and contributed to its\nunderstanding of each short clip. Our attention-based selection allows us to\ndiscard up to ~95% of unimportant visual tokens with minimal performance loss;\n2) Recurrent processing of past selected tokens to generate temporally coherent\nunderstanding of each processed clip; 3) Caption-based question answering for\nlightweight and accurate responses. Our method achieves state-of-the-art\nperformance on streaming video benchmarks, striking a balance between\nefficiency and effectiveness.",
    "published": "2025-10-20T10:04:49Z",
    "updated": "2025-10-20T10:04:49Z",
    "link": "http://arxiv.org/pdf/2510.17364v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Vaggelis Dorovatas",
      "Soroush Seifi",
      "Gunshi Gupta",
      "Rahaf Aljundi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17363v1",
    "title": "M2H: Multi-Task Learning with Efficient Window-Based Cross-Task\n  Attention for Monocular Spatial Perception",
    "summary": "Deploying real-time spatial perception on edge devices requires efficient\nmulti-task models that leverage complementary task information while minimizing\ncomputational overhead. This paper introduces Multi-Mono-Hydra (M2H), a novel\nmulti-task learning framework designed for semantic segmentation and depth,\nedge, and surface normal estimation from a single monocular image. Unlike\nconventional approaches that rely on independent single-task models or shared\nencoder-decoder architectures, M2H introduces a Window-Based Cross-Task\nAttention Module that enables structured feature exchange while preserving\ntask-specific details, improving prediction consistency across tasks. Built on\na lightweight ViT-based DINOv2 backbone, M2H is optimized for real-time\ndeployment and serves as the foundation for monocular spatial perception\nsystems supporting 3D scene graph construction in dynamic environments.\nComprehensive evaluations show that M2H outperforms state-of-the-art multi-task\nmodels on NYUDv2, surpasses single-task depth and semantic baselines on\nHypersim, and achieves superior performance on the Cityscapes dataset, all\nwhile maintaining computational efficiency on laptop hardware. Beyond\nbenchmarks, M2H is validated on real-world data, demonstrating its practicality\nin spatial perception tasks.",
    "published": "2025-10-20T10:03:31Z",
    "updated": "2025-10-20T10:03:31Z",
    "link": "http://arxiv.org/pdf/2510.17363v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG",
      "cs.RO"
    ],
    "authors": [
      "U. V. B. L Udugama",
      "George Vosselman",
      "Francesco Nex"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.18297v4",
    "title": "A deep solver for backward stochastic Volterra integral equations",
    "summary": "We present the first deep-learning solver for backward stochastic Volterra\nintegral equations (BSVIEs) and their fully-coupled forward-backward variants.\nThe method trains a neural network to approximate the two solution fields in a\nsingle stage, avoiding the use of nested time-stepping cycles that limit\nclassical algorithms. For the decoupled case we prove a non-asymptotic error\nbound composed of an a posteriori residual plus the familiar square root\ndependence on the time step. Numerical experiments are consistent with this\nrate and reveal two key properties: \\emph{scalability}, in the sense that\naccuracy remains stable from low dimension up to 500 spatial variables while\nGPU batching keeps wall-clock time nearly constant; and \\emph{generality},\nsince the same method handles coupled systems whose forward dynamics depend on\nthe backward solution. These results open practical access to a family of\nhigh-dimensional, time-inconsistent problems in stochastic control and\nquantitative finance.",
    "published": "2025-05-23T18:41:54Z",
    "updated": "2025-10-20T10:00:30Z",
    "link": "http://arxiv.org/pdf/2505.18297v4.pdf",
    "category": [
      "math.NA",
      "cs.LG",
      "cs.NA",
      "math.PR",
      "q-fin.MF",
      "65C30, 60H20, 60H35, 68T07",
      "G.1.9; G.3; I.2.6; F.2.1"
    ],
    "authors": [
      "Kristoffer Andersson",
      "Alessandro Gnoatto",
      "Camilo AndrÃ©s GarcÃ­a Trillos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2406.01857v4",
    "title": "Neural Green's Operators for Parametric Partial Differential Equations",
    "summary": "This work introduces a paradigm for constructing parametric neural operators\nthat are derived from finite-dimensional representations of Green's operators,\nwith learnable Green's functions, for linear partial differential equations\n(PDEs). We refer to such neural operators as Neural Green's Operators (NGOs).\nOur construction of NGOs preserves the linear action of Green's operators on\nthe inhomogeneity fields, while approximating the nonlinear dependence of the\nGreen's function on the coefficients of the PDE using neural networks that take\nweighted averages of such coefficients as input. This construction reduces the\ncomplexity of the problem from learning the entire solution operator and its\ndependence on all parameters to only learning the Green's function and its\ndependence on the PDE coefficients. Moreover, taking weighted averages, rather\nthan point samples, of input functions decouples the network size from the\nnumber of sampling points, enabling efficient resolution of multiple scales in\nthe input fields. Furthermore, we show that our explicit representation of\nGreen's functions enables the embedding of desirable mathematical attributes in\nour NGO architectures, such as symmetry, spectral, and conservation properties.\nThrough numerical benchmarks on canonical PDEs, we demonstrate that NGOs\nachieve comparable or superior accuracy to deep operator networks,\nvariationally mimetic operator networks, and Fourier neural operators with\nsimilar parameter counts, while generalizing significantly better when tested\non out-of-distribution data. For time-dependent PDEs, we show that NGOs can\nproduce pointwise-accurate dynamics in an auto-regressive manner when trained\non a single time step. Finally, we show that we can leverage the explicit\nrepresentation of Green's functions returned by NGOs to construct effective\nmatrix preconditioners that accelerate iterative solvers for PDEs.",
    "published": "2024-06-04T00:02:52Z",
    "updated": "2025-10-20T09:59:13Z",
    "link": "http://arxiv.org/pdf/2406.01857v4.pdf",
    "category": [
      "cs.LG",
      "cs.NA",
      "math.NA",
      "68T07",
      "I.2.6; G.1.8"
    ],
    "authors": [
      "Hugo Melchers",
      "Joost Prins",
      "Michael Abdelmalik"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2403.15527v3",
    "title": "Conformal online model aggregation",
    "summary": "Conformal prediction equips machine learning models with a reasonable notion\nof uncertainty quantification without making strong distributional assumptions.\nIt wraps around any prediction model and converts point predictions into set\npredictions with a predefined marginal coverage guarantee. However, conformal\nprediction only works if we fix the underlying machine learning model in\nadvance. A relatively unaddressed issue in conformal prediction is that of\nmodel selection and/or aggregation: given a set of prediction models, which one\nshould we conformalize? This paper suggests that instead of performing model\nselection, it can be prudent and practical to perform conformal set aggregation\nin an online, adaptive fashion. We propose a wrapper that takes in several\nconformal prediction sets (themselves wrapped around black-box prediction\nmodels), and outputs a single adaptively-combined prediction set. Our method,\ncalled conformal online model aggregation (COMA), is based on combining the\nprediction sets from several algorithms by weighted voting, and can be thought\nof as a sort of online stacking of the underlying conformal sets. As long as\nthe input sets have (distribution-free) coverage guarantees, COMA retains\ncoverage guarantees, under a negative correlation assumption between errors and\nweights. We verify that the assumption holds empirically in all settings\nconsidered. COMA is well-suited for decentralized or distributed settings,\nwhere different users may have different models, and are only willing to share\ntheir prediction sets for a new test point in a black-box fashion. As we\ndemonstrate, it is also well-suited to settings with distribution drift and\nshift, where model selection can be imprudent.",
    "published": "2024-03-22T15:40:06Z",
    "updated": "2025-10-20T09:47:21Z",
    "link": "http://arxiv.org/pdf/2403.15527v3.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Matteo Gasparin",
      "Aaditya Ramdas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17348v1",
    "title": "Optimal Best Arm Identification under Differential Privacy",
    "summary": "Best Arm Identification (BAI) algorithms are deployed in data-sensitive\napplications, such as adaptive clinical trials or user studies. Driven by the\nprivacy concerns of these applications, we study the problem of\nfixed-confidence BAI under global Differential Privacy (DP) for Bernoulli\ndistributions. While numerous asymptotically optimal BAI algorithms exist in\nthe non-private setting, a significant gap remains between the best lower and\nupper bounds in the global DP setting. This work reduces this gap to a small\nmultiplicative constant, for any privacy budget $\\epsilon$. First, we provide a\ntighter lower bound on the expected sample complexity of any $\\delta$-correct\nand $\\epsilon$-global DP strategy. Our lower bound replaces the\nKullback-Leibler (KL) divergence in the transportation cost used by the\nnon-private characteristic time with a new information-theoretic quantity that\noptimally trades off between the KL divergence and the Total Variation distance\nscaled by $\\epsilon$. Second, we introduce a stopping rule based on these\ntransportation costs and a private estimator of the means computed using an\narm-dependent geometric batching. En route to proving the correctness of our\nstopping rule, we derive concentration results of independent interest for the\nLaplace distribution and for the sum of Bernoulli and Laplace distributions.\nThird, we propose a Top Two sampling rule based on these transportation costs.\nFor any budget $\\epsilon$, we show an asymptotic upper bound on its expected\nsample complexity that matches our lower bound to a multiplicative constant\nsmaller than $8$. Our algorithm outperforms existing $\\delta$-correct and\n$\\epsilon$-global DP BAI algorithms for different values of $\\epsilon$.",
    "published": "2025-10-20T09:46:09Z",
    "updated": "2025-10-20T09:46:09Z",
    "link": "http://arxiv.org/pdf/2510.17348v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Marc Jourdan",
      "Achraf Azize"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.05231v2",
    "title": "Progressive Tempering Sampler with Diffusion",
    "summary": "Recent research has focused on designing neural samplers that amortize the\nprocess of sampling from unnormalized densities. However, despite significant\nadvancements, they still fall short of the state-of-the-art MCMC approach,\nParallel Tempering (PT), when it comes to the efficiency of target evaluations.\nOn the other hand, unlike a well-trained neural sampler, PT yields only\ndependent samples and needs to be rerun -- at considerable computational cost\n-- whenever new samples are required. To address these weaknesses, we propose\nthe Progressive Tempering Sampler with Diffusion (PTSD), which trains diffusion\nmodels sequentially across temperatures, leveraging the advantages of PT to\nimprove the training of neural samplers. We also introduce a novel method to\ncombine high-temperature diffusion models to generate approximate\nlower-temperature samples, which are minimally refined using MCMC and used to\ntrain the next diffusion model. PTSD enables efficient reuse of sample\ninformation across temperature levels while generating well-mixed, uncorrelated\nsamples. Our method significantly improves target evaluation efficiency,\noutperforming diffusion-based neural samplers.",
    "published": "2025-06-05T16:46:04Z",
    "updated": "2025-10-20T09:43:29Z",
    "link": "http://arxiv.org/pdf/2506.05231v2.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Severi Rissanen",
      "RuiKang OuYang",
      "Jiajun He",
      "Wenlin Chen",
      "Markus Heinonen",
      "Arno Solin",
      "JosÃ© Miguel HernÃ¡ndez-Lobato"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.10885v4",
    "title": "CEReBrO: Compact Encoder for Representations of Brain Oscillations Using\n  Efficient Alternating Attention",
    "summary": "Electroencephalograph (EEG) is a crucial tool for studying brain activity.\nRecently, self-supervised learning methods leveraging large unlabeled datasets\nhave emerged as a potential solution to the scarcity of widely available\nannotated EEG data. However, current methods suffer from at least one of the\nfollowing limitations: i) sub-optimal EEG signal modeling, ii) model sizes in\nthe hundreds of millions of trainable parameters, and iii) reliance on private\ndatasets and/or inconsistent public benchmarks, hindering reproducibility. To\naddress these challenges, we introduce a Compact Encoder for Representations of\nBrain Oscillations using alternating attention (CEReBrO), a new small EEG\nfoundation model. Our tokenization scheme represents EEG signals at a\nper-channel patch granularity. We propose an alternating attention mechanism\nthat jointly models intra-channel temporal dynamics and inter-channel spatial\ncorrelations, achieving 2x speed improvement with 6x less memory required\ncompared to standard self-attention. We present several model sizes ranging\nfrom 3.6 million to 85 million parameters. Pre-trained on over 20,000 hours of\npublicly available scalp EEG recordings with diverse channel configurations,\nour models set new benchmarks in emotion detection and seizure detection tasks,\nwith competitive performance in anomaly classification and gait prediction.\nThis validates our models' effectiveness and efficiency.",
    "published": "2025-01-18T21:44:38Z",
    "updated": "2025-10-20T09:42:46Z",
    "link": "http://arxiv.org/pdf/2501.10885v4.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Alexandru Dimofte",
      "Glenn Anta Bucagu",
      "Thorir Mar Ingolfsson",
      "Xiaying Wang",
      "Andrea Cossettini",
      "Luca Benini",
      "Yawei Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.13297v2",
    "title": "Federated Conditional Conformal Prediction via Generative Models",
    "summary": "Conformal Prediction (CP) provides distribution-free uncertainty\nquantification by constructing prediction sets that guarantee coverage of the\ntrue labels. This reliability makes CP valuable for high-stakes federated\nlearning scenarios such as multi-center healthcare. However, standard CP\nassumes i.i.d. data, which is violated in federated settings where client\ndistributions differ substantially. Existing federated CP methods address this\nby maintaining marginal coverage on each client, but such guarantees often fail\nto reflect input-conditional uncertainty. In this work, we propose Federated\nConditional Conformal Prediction (Fed-CCP) via generative models, which aims\nfor conditional coverage that adapts to local data heterogeneity. Fed-CCP\nleverages generative models, such as normalizing flows or diffusion models, to\napproximate conditional data distributions without requiring the sharing of raw\ndata. This enables each client to locally calibrate conformal scores that\nreflect its unique uncertainty, while preserving global consistency through\nfederated aggregation. Experiments on real datasets demonstrate that Fed-CCP\nachieves more adaptive prediction sets.",
    "published": "2025-10-15T08:38:38Z",
    "updated": "2025-10-20T08:59:25Z",
    "link": "http://arxiv.org/pdf/2510.13297v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Rui Xu",
      "Xingyuan Chen",
      "Wenxing Huang",
      "Minxuan Huang",
      "Yun Xie",
      "Weiyan Chen",
      "Sihong Xie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17313v1",
    "title": "Disentanglement Beyond Static vs. Dynamic: A Benchmark and Evaluation\n  Framework for Multi-Factor Sequential Representations",
    "summary": "Learning disentangled representations in sequential data is a key goal in\ndeep learning, with broad applications in vision, audio, and time series. While\nreal-world data involves multiple interacting semantic factors over time, prior\nwork has mostly focused on simpler two-factor static and dynamic settings,\nprimarily because such settings make data collection easier, thereby\noverlooking the inherently multi-factor nature of real-world data. We introduce\nthe first standardized benchmark for evaluating multi-factor sequential\ndisentanglement across six diverse datasets spanning video, audio, and time\nseries. Our benchmark includes modular tools for dataset integration, model\ndevelopment, and evaluation metrics tailored to multi-factor analysis. We\nadditionally propose a post-hoc Latent Exploration Stage to automatically align\nlatent dimensions with semantic factors, and introduce a Koopman-inspired model\nthat achieves state-of-the-art results. Moreover, we show that Vision-Language\nModels can automate dataset annotation and serve as zero-shot disentanglement\nevaluators, removing the need for manual labels and human intervention.\nTogether, these contributions provide a robust and scalable foundation for\nadvancing multi-factor sequential disentanglement.",
    "published": "2025-10-20T08:58:23Z",
    "updated": "2025-10-20T08:58:23Z",
    "link": "http://arxiv.org/pdf/2510.17313v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Tal Barami",
      "Nimrod Berman",
      "Ilan Naiman",
      "Amos H. Hason",
      "Rotem Ezra",
      "Omri Azencot"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17303v1",
    "title": "Symmetries in PAC-Bayesian Learning",
    "summary": "Symmetries are known to improve the empirical performance of machine learning\nmodels, yet theoretical guarantees explaining these gains remain limited. Prior\nwork has focused mainly on compact group symmetries and often assumes that the\ndata distribution itself is invariant, an assumption rarely satisfied in\nreal-world applications. In this work, we extend generalization guarantees to\nthe broader setting of non-compact symmetries, such as translations and to\nnon-invariant data distributions. Building on the PAC-Bayes framework, we adapt\nand tighten existing bounds, demonstrating the approach on McAllester's\nPAC-Bayes bound while showing that it applies to a wide range of PAC-Bayes\nbounds. We validate our theory with experiments on a rotated MNIST dataset with\na non-uniform rotation group, where the derived guarantees not only hold but\nalso improve upon prior results. These findings provide theoretical evidence\nthat, for symmetric data, symmetric models are preferable beyond the narrow\nsetting of compact groups and invariant distributions, opening the way to a\nmore general understanding of symmetries in machine learning.",
    "published": "2025-10-20T08:45:57Z",
    "updated": "2025-10-20T08:45:57Z",
    "link": "http://arxiv.org/pdf/2510.17303v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Armin Beck",
      "Peter Ochs"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.10139v3",
    "title": "Path Gradients after Flow Matching",
    "summary": "Boltzmann Generators have emerged as a promising machine learning tool for\ngenerating samples from equilibrium distributions of molecular systems using\nNormalizing Flows and importance weighting. Recently, Flow Matching has helped\nspeed up Continuous Normalizing Flows (CNFs), scale them to more complex\nmolecular systems, and minimize the length of the flow integration\ntrajectories. We investigate the benefits of using path gradients to fine-tune\nCNFs initially trained by Flow Matching, in the setting where a target energy\nis known. Our experiments show that this hybrid approach yields up to a\nthreefold increase in sampling efficiency for molecular systems, all while\nusing the same model, a similar computational budget and without the need for\nadditional sampling. Furthermore, by measuring the length of the flow\ntrajectories during fine-tuning, we show that path gradients largely preserve\nthe learned structure of the flow.",
    "published": "2025-05-15T10:13:45Z",
    "updated": "2025-10-20T08:38:10Z",
    "link": "http://arxiv.org/pdf/2505.10139v3.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Lorenz Vaitl",
      "Leon Klein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.18067v2",
    "title": "Multiscale Neural PDE Surrogates for Prediction and Downscaling:\n  Application to Ocean Currents",
    "summary": "Accurate modeling of physical systems governed by partial differential\nequations is a central challenge in scientific computing. In oceanography,\nhigh-resolution current data are critical for coastal management, environmental\nmonitoring, and maritime safety. However, available satellite products, such as\nCopernicus data for sea water velocity at ~0.08 degrees spatial resolution and\nglobal ocean models, often lack the spatial granularity required for detailed\nlocal analyses. In this work, we (a) introduce a supervised deep learning\nframework based on neural operators for solving PDEs and providing arbitrary\nresolution solutions, and (b) propose downscaling models with an application to\nCopernicus ocean current data. Additionally, our method can model surrogate\nPDEs and predict solutions at arbitrary resolution, regardless of the input\nresolution. We evaluated our model on real-world Copernicus ocean current data\nand synthetic Navier-Stokes simulation datasets.",
    "published": "2025-07-24T03:42:06Z",
    "updated": "2025-10-20T08:23:32Z",
    "link": "http://arxiv.org/pdf/2507.18067v2.pdf",
    "category": [
      "cs.LG",
      "cs.CE"
    ],
    "authors": [
      "Abdessamad El-Kabid",
      "Loubna Benabbou",
      "Redouane Lguensat",
      "Alex HernÃ¡ndez-GarcÃ­a"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.20840v2",
    "title": "Towards Explainable Deep Clustering for Time Series Data",
    "summary": "Deep clustering uncovers hidden patterns and groups in complex time series\ndata, yet its opaque decision-making limits use in safety-critical settings.\nThis survey offers a structured overview of explainable deep clustering for\ntime series, collecting current methods and their real-world applications. We\nthoroughly discuss and compare peer-reviewed and preprint papers through\napplication domains across healthcare, finance, IoT, and climate science. Our\nanalysis reveals that most work relies on autoencoder and attention\narchitectures, with limited support for streaming, irregularly sampled, or\nprivacy-preserved series, and interpretability is still primarily treated as an\nadd-on. To push the field forward, we outline six research opportunities: (1)\ncombining complex networks with built-in interpretability; (2) setting up\nclear, faithfulness-focused evaluation metrics for unsupervised explanations;\n(3) building explainers that adapt to live data streams; (4) crafting\nexplanations tailored to specific domains; (5) adding human-in-the-loop methods\nthat refine clusters and explanations together; and (6) improving our\nunderstanding of how time series clustering models work internally. By making\ninterpretability a primary design goal rather than an afterthought, we propose\nthe groundwork for the next generation of trustworthy deep clustering time\nseries analytics.",
    "published": "2025-07-28T13:50:10Z",
    "updated": "2025-10-20T08:20:05Z",
    "link": "http://arxiv.org/pdf/2507.20840v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Udo Schlegel",
      "Gabriel Marques Tavares",
      "Thomas Seidl"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17276v1",
    "title": "Breaking and Fixing Defenses Against Control-Flow Hijacking in\n  Multi-Agent Systems",
    "summary": "Control-flow hijacking attacks manipulate orchestration mechanisms in\nmulti-agent systems into performing unsafe actions that compromise the system\nand exfiltrate sensitive information. Recently proposed defenses, such as\nLlamaFirewall, rely on alignment checks of inter-agent communications to ensure\nthat all agent invocations are \"related to\" and \"likely to further\" the\noriginal objective.\n  We start by demonstrating control-flow hijacking attacks that evade these\ndefenses even if alignment checks are performed by advanced LLMs. We argue that\nthe safety and functionality objectives of multi-agent systems fundamentally\nconflict with each other. This conflict is exacerbated by the brittle\ndefinitions of \"alignment\" and the checkers' incomplete visibility into the\nexecution context.\n  We then propose, implement, and evaluate ControlValve, a new defense inspired\nby the principles of control-flow integrity and least privilege. ControlValve\n(1) generates permitted control-flow graphs for multi-agent systems, and (2)\nenforces that all executions comply with these graphs, along with contextual\nrules (generated in a zero-shot manner) for each agent invocation.",
    "published": "2025-10-20T08:02:51Z",
    "updated": "2025-10-20T08:02:51Z",
    "link": "http://arxiv.org/pdf/2510.17276v1.pdf",
    "category": [
      "cs.LG",
      "cs.CR",
      "cs.SY",
      "eess.SY"
    ],
    "authors": [
      "Rishi Jha",
      "Harold Triedman",
      "Justin Wagle",
      "Vitaly Shmatikov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.20268v2",
    "title": "Reliable Wireless Indoor Localization via Cross-Validated\n  Prediction-Powered Calibration",
    "summary": "Wireless indoor localization using predictive models with received signal\nstrength information (RSSI) requires proper calibration for reliable position\nestimates. One remedy is to employ synthetic labels produced by a (generally\ndifferent) predictive model. But fine-tuning an additional predictor, as well\nas estimating residual bias of the synthetic labels, demands additional data,\naggravating calibration data scarcity in wireless environments. This letter\nproposes an approach that efficiently uses limited calibration data to\nsimultaneously fine-tune a predictor and estimate the bias of synthetic labels,\nyielding prediction sets with rigorous coverage guarantees. Experiments on a\nfingerprinting dataset validate the effectiveness of the proposed method.",
    "published": "2025-07-27T13:31:02Z",
    "updated": "2025-10-20T07:55:53Z",
    "link": "http://arxiv.org/pdf/2507.20268v2.pdf",
    "category": [
      "cs.LG",
      "eess.SP",
      "stat.ML"
    ],
    "authors": [
      "Seonghoon Yoo",
      "Houssem Sifaou",
      "Sangwoo Park",
      "Joonhyuk Kang",
      "Osvaldo Simeone"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17268v1",
    "title": "Uncertainty-aware data assimilation through variational inference",
    "summary": "Data assimilation, consisting in the combination of a dynamical model with a\nset of noisy and incomplete observations in order to infer the state of a\nsystem over time, involves uncertainty in most settings. Building upon an\nexisting deterministic machine learning approach, we propose a variational\ninference-based extension in which the predicted state follows a multivariate\nGaussian distribution. Using the chaotic Lorenz-96 dynamics as a testing\nground, we show that our new model enables to obtain nearly perfectly\ncalibrated predictions, and can be integrated in a wider variational data\nassimilation pipeline in order to achieve greater benefit from increasing\nlengths of data assimilation windows. Our code is available at\nhttps://github.com/anthony-frion/Stochastic_CODA.",
    "published": "2025-10-20T07:54:35Z",
    "updated": "2025-10-20T07:54:35Z",
    "link": "http://arxiv.org/pdf/2510.17268v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Anthony Frion",
      "David S Greenberg"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17266v1",
    "title": "Adaptive Discretization for Consistency Models",
    "summary": "Consistency Models (CMs) have shown promise for efficient one-step\ngeneration. However, most existing CMs rely on manually designed discretization\nschemes, which can cause repeated adjustments for different noise schedules and\ndatasets. To address this, we propose a unified framework for the automatic and\nadaptive discretization of CMs, formulating it as an optimization problem with\nrespect to the discretization step. Concretely, during the consistency training\nprocess, we propose using local consistency as the optimization objective to\nensure trainability by avoiding excessive discretization, and taking global\nconsistency as a constraint to ensure stability by controlling the denoising\nerror in the training target. We establish the trade-off between local and\nglobal consistency with a Lagrange multiplier. Building on this framework, we\nachieve adaptive discretization for CMs using the Gauss-Newton method. We refer\nto our approach as ADCMs. Experiments demonstrate that ADCMs significantly\nimprove the training efficiency of CMs, achieving superior generative\nperformance with minimal training overhead on both CIFAR-10 and ImageNet.\nMoreover, ADCMs exhibit strong adaptability to more advanced DM variants. Code\nis available at https://github.com/rainstonee/ADCM.",
    "published": "2025-10-20T07:52:33Z",
    "updated": "2025-10-20T07:52:33Z",
    "link": "http://arxiv.org/pdf/2510.17266v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Jiayu Bai",
      "Zhanbo Feng",
      "Zhijie Deng",
      "Tianqi Hou",
      "Robert C. Qiu",
      "Zenan Ling"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17264v1",
    "title": "Fair and Interpretable Deepfake Detection in Videos",
    "summary": "Existing deepfake detection methods often exhibit bias, lack transparency,\nand fail to capture temporal information, leading to biased decisions and\nunreliable results across different demographic groups. In this paper, we\npropose a fairness-aware deepfake detection framework that integrates temporal\nfeature learning and demographic-aware data augmentation to enhance fairness\nand interpretability. Our method leverages sequence-based clustering for\ntemporal modeling of deepfake videos and concept extraction to improve\ndetection reliability while also facilitating interpretable decisions for\nnon-expert users. Additionally, we introduce a demography-aware data\naugmentation method that balances underrepresented groups and applies\nfrequency-domain transformations to preserve deepfake artifacts, thereby\nmitigating bias and improving generalization. Extensive experiments on\nFaceForensics++, DFD, Celeb-DF, and DFDC datasets using state-of-the-art (SoTA)\narchitectures (Xception, ResNet) demonstrate the efficacy of the proposed\nmethod in obtaining the best tradeoff between fairness and accuracy when\ncompared to SoTA.",
    "published": "2025-10-20T07:50:22Z",
    "updated": "2025-10-20T07:50:22Z",
    "link": "http://arxiv.org/pdf/2510.17264v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Akihito Yoshii",
      "Ryosuke Sonoda",
      "Ramya Srinivasan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17261v1",
    "title": "High-Level Multi-Robot Trajectory Planning And Spurious Behavior\n  Detection",
    "summary": "The reliable execution of high-level missions in multi-robot systems with\nheterogeneous agents, requires robust methods for detecting spurious behaviors.\nIn this paper, we address the challenge of identifying spurious executions of\nplans specified as a Linear Temporal Logic (LTL) formula, as incorrect task\nsequences, violations of spatial constraints, timing inconsis- tencies, or\ndeviations from intended mission semantics. To tackle this, we introduce a\nstructured data generation framework based on the Nets-within-Nets (NWN)\nparadigm, which coordinates robot actions with LTL-derived global mission\nspecifications. We further propose a Transformer-based anomaly detection\npipeline that classifies robot trajectories as normal or anomalous. Experi-\nmental evaluations show that our method achieves high accuracy (91.3%) in\nidentifying execution inefficiencies, and demonstrates robust detection\ncapabilities for core mission violations (88.3%) and constraint-based adaptive\nanomalies (66.8%). An ablation experiment of the embedding and architecture was\ncarried out, obtaining successful results where our novel proposition performs\nbetter than simpler representations.",
    "published": "2025-10-20T07:47:51Z",
    "updated": "2025-10-20T07:47:51Z",
    "link": "http://arxiv.org/pdf/2510.17261v1.pdf",
    "category": [
      "cs.RO",
      "cs.LG"
    ],
    "authors": [
      "Fernando Salanova",
      "JesÃºs Roche",
      "Cristian Mahuela",
      "Eduardo Montijano"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2404.19557v4",
    "title": "Neural Dynamic Data Valuation: A Stochastic Optimal Control Approach",
    "summary": "Data valuation has become a cornerstone of the modern data economy, where\ndatasets function as tradable intellectual assets that drive decision-making,\nmodel training, and market transactions. Despite substantial progress, existing\nvaluation methods remain limited by high computational cost, weak fairness\nguarantees, and poor interpretability, which hinder their deployment in\nlarge-scale, high-stakes applications. This paper introduces Neural Dynamic\nData Valuation (NDDV), a new framework that formulates data valuation as a\nstochastic optimal control problem to capture the dynamic evolution of data\nutility over time. Unlike static combinatorial approaches, NDDV models data\ninteractions through continuous trajectories that reflect both individual and\ncollective learning dynamics.",
    "published": "2024-04-30T13:39:26Z",
    "updated": "2025-10-20T07:44:55Z",
    "link": "http://arxiv.org/pdf/2404.19557v4.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Zhangyong Liang",
      "Ji Zhang",
      "Xin Wang",
      "Pengfei Zhang",
      "Zhao Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17250v1",
    "title": "A Prototypical Network with an Attention-based Encoder for Drivers\n  Identification Application",
    "summary": "Driver identification has become an area of increasing interest in recent\nyears, especially for data- driven applications, because biometric-based\ntechnologies may incur privacy issues. This study proposes a deep learning\nneural network architecture, an attention-based encoder (AttEnc), which uses an\nattention mechanism for driver identification and uses fewer model parameters\nthan current methods. Most studies do not address the issue of data shortages\nfor driver identification, and most of them are inflexible when encountering\nunknown drivers. In this study, an architecture that combines a prototypical\nnetwork and an attention-based encoder (P-AttEnc) is proposed. It applies\nfew-shot learning to overcome the data shortage issues and to enhance model\ngeneralizations. The experiments showed that the attention-based encoder can\nidentify drivers with accuracies of 99.3%, 99.0% and 99.9% in three different\ndatasets and has a prediction time that is 44% to 79% faster because it\nsignificantly reduces, on average, 87.6% of the model parameters. P-AttEnc\nidentifies drivers based on few shot data, extracts driver fingerprints to\naddress the issue of data shortages, and is able to classify unknown drivers.\nThe first experiment showed that P-AttEnc can identify drivers with an accuracy\nof 69.8% in the one-shot scenario. The second experiment showed that P-AttEnc,\nin the 1-shot scenario, can classify unknown drivers with an average accuracy\nof 65.7%.",
    "published": "2025-10-20T07:39:33Z",
    "updated": "2025-10-20T07:39:33Z",
    "link": "http://arxiv.org/pdf/2510.17250v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Wei-Hsun Lee",
      "Che-Yu Chang",
      "Kuang-Yu Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.11521v2",
    "title": "LANGTRAJ: Diffusion Model and Dataset for Language-Conditioned\n  Trajectory Simulation",
    "summary": "Evaluating autonomous vehicles with controllability enables scalable testing\nin counterfactual or structured settings, enhancing both efficiency and safety.\nWe introduce LangTraj, a language-conditioned scene-diffusion model that\nsimulates the joint behavior of all agents in traffic scenarios. By\nconditioning on natural language inputs, LangTraj provides flexible and\nintuitive control over interactive behaviors, generating nuanced and realistic\nscenarios. Unlike prior approaches that depend on domain-specific guidance\nfunctions, LangTraj incorporates language conditioning during training,\nfacilitating more intuitive traffic simulation control. We propose a novel\nclosed-loop training strategy for diffusion models, explicitly tailored to\nenhance stability and realism during closed-loop simulation. To support\nlanguage-conditioned simulation, we develop Inter-Drive, a large-scale dataset\nwith diverse and interactive labels for training language-conditioned diffusion\nmodels. Our dataset is built upon a scalable pipeline for annotating\nagent-agent interactions and single-agent behaviors, ensuring rich and varied\nsupervision. Validated on the Waymo Open Motion Dataset, LangTraj demonstrates\nstrong performance in realism, language controllability, and\nlanguage-conditioned safety-critical simulation, establishing a new paradigm\nfor flexible and scalable autonomous vehicle testing. Project Website:\nhttps://langtraj.github.io/",
    "published": "2025-04-15T17:14:06Z",
    "updated": "2025-10-20T07:39:32Z",
    "link": "http://arxiv.org/pdf/2504.11521v2.pdf",
    "category": [
      "cs.LG",
      "cs.RO",
      "I.2.9; I.2.6"
    ],
    "authors": [
      "Wei-Jer Chang",
      "Wei Zhan",
      "Masayoshi Tomizuka",
      "Manmohan Chandraker",
      "Francesco Pittaluga"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.17881v2",
    "title": "Hyperspectral Anomaly Detection Fused Unified Nonconvex Tensor Ring\n  Factors Regularization",
    "summary": "In recent years, tensor decomposition-based approaches for hyperspectral\nanomaly detection (HAD) have gained significant attention in the field of\nremote sensing. However, existing methods often fail to fully leverage both the\nglobal correlations and local smoothness of the background components in\nhyperspectral images (HSIs), which exist in both the spectral and spatial\ndomains. This limitation results in suboptimal detection performance. To\nmitigate this critical issue, we put forward a novel HAD method named\nHAD-EUNTRFR, which incorporates an enhanced unified nonconvex tensor ring (TR)\nfactors regularization. In the HAD-EUNTRFR framework, the raw HSIs are first\ndecomposed into background and anomaly components. The TR decomposition is then\nemployed to capture the spatial-spectral correlations within the background\ncomponent. Additionally, we introduce a unified and efficient nonconvex\nregularizer, induced by tensor singular value decomposition (TSVD), to\nsimultaneously encode the low-rankness and sparsity of the 3-D gradient TR\nfactors into a unique concise form. The above characterization scheme enables\nthe interpretable gradient TR factors to inherit the low-rankness and\nsmoothness of the original background. To further enhance anomaly detection, we\ndesign a generalized nonconvex regularization term to exploit the group\nsparsity of the anomaly component. To solve the resulting doubly nonconvex\nmodel, we develop a highly efficient optimization algorithm based on the\nalternating direction method of multipliers (ADMM) framework. Experimental\nresults on several benchmark datasets demonstrate that our proposed method\noutperforms existing state-of-the-art (SOTA) approaches in terms of detection\naccuracy.",
    "published": "2025-05-23T13:31:13Z",
    "updated": "2025-10-20T07:36:23Z",
    "link": "http://arxiv.org/pdf/2505.17881v2.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Wenjin Qin",
      "Hailin Wang",
      "Hao Shu",
      "Feng Zhang",
      "Jianjun Wang",
      "Xiangyong Cao",
      "Xi-Le Zhao",
      "Gemine Vivone"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.01042v2",
    "title": "MatPROV: A Provenance Graph Dataset of Material Synthesis Extracted from\n  Scientific Literature",
    "summary": "Synthesis procedures play a critical role in materials research, as they\ndirectly affect material properties. With data-driven approaches increasingly\naccelerating materials discovery, there is growing interest in extracting\nsynthesis procedures from scientific literature as structured data. However,\nexisting studies often rely on rigid, domain-specific schemas with predefined\nfields for structuring synthesis procedures or assume that synthesis procedures\nare linear sequences of operations, which limits their ability to capture the\nstructural complexity of real-world procedures. To address these limitations,\nwe adopt PROV-DM, an international standard for provenance information, which\nsupports flexible, graph-based modeling of procedures. We present MatPROV, a\ndataset of PROV-DM-compliant synthesis procedures extracted from scientific\nliterature using large language models. MatPROV captures structural\ncomplexities and causal relationships among materials, operations, and\nconditions through visually intuitive directed graphs. This representation\nenables machine-interpretable synthesis knowledge, opening opportunities for\nfuture research such as automated synthesis planning and optimization.",
    "published": "2025-09-01T00:47:27Z",
    "updated": "2025-10-20T07:15:03Z",
    "link": "http://arxiv.org/pdf/2509.01042v2.pdf",
    "category": [
      "cs.LG",
      "cs.IR"
    ],
    "authors": [
      "Hirofumi Tsuruta",
      "Masaya Kumagai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2310.06328v4",
    "title": "UniCrossFi: A Unified Framework For Cross-Domain Wi-Fi-based Gesture\n  Recognition",
    "summary": "Wi-Fi sensing systems are severely hindered by cross domain problem when\ndeployed in unseen real-world environments. Existing methods typically design\nseparate frameworks for either domain adaptation or domain generalization,\noften relying on extensive labeled data. Existing methods that designed for\ndomain generalization is often relying on extensive labeled data. However,\nreal-world scenarios are far more complex, where the deployed model must be\ncapable of handling generalization under limited labeled source data. To this\nend, we propose UniCrossFi, a unified framework designed to mitigate\nperformance drop in CSI-based sensing across diverse deployment settings. Our\nframework not only extends conventional Domain Generalization (DG) to a more\npractical Semi-Supervised Domain Generalization (SSDG) setting, where only\npartially labeled source data are available, but also introduces a\nphysics-informed data augmentation strategy, Antenna Response Consistency\n(ARC). ARC mitigates the risk of learning superficial shortcuts by exploiting\nthe intrinsic spatial diversity of multi-antenna systems, treating signals from\ndifferent antennas as naturally augmented views of the same event. In addition,\nwe design a Unified Contrastive Objective to prevent conventional contrastive\nlearning from pushing apart samples from different domains that share the same\nclass. We conduct extensive experiments on the public Widar and CSIDA datasets.\nThe results demonstrate that UniCrossFi consistently establishes a new\nstate-of-the-art, significantly outperforming existing methods across all\nunsupervised domain adaptation, DG, and SSDG benchmarks. UniCrossFi provides a\nprincipled and practical solution to the domain shift challenge, advancing the\nfeasibility of robust, real-world Wi-Fi sensing systems that can operate\neffectively with limited labeled data.",
    "published": "2023-10-10T05:54:00Z",
    "updated": "2025-10-20T06:09:45Z",
    "link": "http://arxiv.org/pdf/2310.06328v4.pdf",
    "category": [
      "cs.LG",
      "eess.SP"
    ],
    "authors": [
      "Ke Xu",
      "Zhiyong Zheng",
      "Hongyuan Zhu",
      "Lei Wang",
      "Jiangtao Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17189v1",
    "title": "SOLE: Hardware-Software Co-design of Softmax and LayerNorm for Efficient\n  Transformer Inference",
    "summary": "Transformers have shown remarkable performance in both natural language\nprocessing (NLP) and computer vision (CV) tasks. However, their real-time\ninference speed and efficiency are limited due to the inefficiency in Softmax\nand Layer Normalization (LayerNorm). Previous works based on function\napproximation suffer from inefficient implementation as they place emphasis on\ncomputation while disregarding memory overhead concerns. Moreover, such methods\nrely on retraining to compensate for approximation error which can be costly\nand inconvenient.\n  In this paper, we present SOLE, a hardware-software co-design for Softmax and\nLayerNorm which is composed of E2Softmax and AILayerNorm. E2Softmax utilizes\nlog2 quantization of exponent function and log-based division to approximate\nSoftmax while AILayerNorm adopts low-precision statistic calculation. Compared\nwith state-of-the-art designs, we achieve both low-precision calculation and\nlow bit-width storage on Softmax and LayerNorm. Experiments show that SOLE\nmaintains inference accuracy without retraining while offering orders of\nmagnitude speedup and energy savings over GPU, achieving 3.04x, 3.86x\nenergy-efficiency improvements and 2.82x, 3.32x area-efficiency improvements\nover prior state-of-the-art custom hardware for Softmax and LayerNorm,\nrespectively.",
    "published": "2025-10-20T06:09:09Z",
    "updated": "2025-10-20T06:09:09Z",
    "link": "http://arxiv.org/pdf/2510.17189v1.pdf",
    "category": [
      "cs.LG",
      "cs.AR"
    ],
    "authors": [
      "Wenxun Wang",
      "Shuchang Zhou",
      "Wenyu Sun",
      "Peiqin Sun",
      "Yongpan Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.22279v2",
    "title": "Unlocking the Power of Mixture-of-Experts for Task-Aware Time Series\n  Analytics",
    "summary": "Time Series Analysis is widely used in various real-world applications such\nas weather forecasting, financial fraud detection, imputation for missing data\nin IoT systems, and classification for action recognization. Mixture-of-Experts\n(MoE), as a powerful architecture, though demonstrating effectiveness in NLP,\nstill falls short in adapting to versatile tasks in time series analytics due\nto its task-agnostic router and the lack of capability in modeling channel\ncorrelations. In this study, we propose a novel, general MoE-based time series\nframework called PatchMoE to support the intricate ``knowledge'' utilization\nfor distinct tasks, thus task-aware. Based on the observation that hierarchical\nrepresentations often vary across tasks, e.g., forecasting vs. classification,\nwe propose a Recurrent Noisy Gating to utilize the hierarchical information in\nrouting, thus obtaining task-sepcific capability. And the routing strategy is\noperated on time series tokens in both temporal and channel dimensions, and\nencouraged by a meticulously designed Temporal \\& Channel Load Balancing Loss\nto model the intricate temporal and channel correlations. Comprehensive\nexperiments on five downstream tasks demonstrate the state-of-the-art\nperformance of PatchMoE.",
    "published": "2025-09-26T12:44:46Z",
    "updated": "2025-10-20T06:08:41Z",
    "link": "http://arxiv.org/pdf/2509.22279v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Xingjian Wu",
      "Zhengyu Li",
      "Hanyin Cheng",
      "Xiangfei Qiu",
      "Jilin Hu",
      "Chenjuan Guo",
      "Bin Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.14111v2",
    "title": "From AI for Science to Agentic Science: A Survey on Autonomous\n  Scientific Discovery",
    "summary": "Artificial intelligence (AI) is reshaping scientific discovery, evolving from\nspecialized computational tools into autonomous research partners. We position\nAgentic Science as a pivotal stage within the broader AI for Science paradigm,\nwhere AI systems progress from partial assistance to full scientific agency.\nEnabled by large language models (LLMs), multimodal systems, and integrated\nresearch platforms, agentic AI shows capabilities in hypothesis generation,\nexperimental design, execution, analysis, and iterative refinement -- behaviors\nonce regarded as uniquely human. This survey provides a domain-oriented review\nof autonomous scientific discovery across life sciences, chemistry, materials\nscience, and physics. We unify three previously fragmented perspectives --\nprocess-oriented, autonomy-oriented, and mechanism-oriented -- through a\ncomprehensive framework that connects foundational capabilities, core\nprocesses, and domain-specific realizations. Building on this framework, we (i)\ntrace the evolution of AI for Science, (ii) identify five core capabilities\nunderpinning scientific agency, (iii) model discovery as a dynamic four-stage\nworkflow, (iv) review applications across the above domains, and (v) synthesize\nkey challenges and future opportunities. This work establishes a\ndomain-oriented synthesis of autonomous scientific discovery and positions\nAgentic Science as a structured paradigm for advancing AI-driven research.",
    "published": "2025-08-18T05:25:54Z",
    "updated": "2025-10-20T06:07:37Z",
    "link": "http://arxiv.org/pdf/2508.14111v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Jiaqi Wei",
      "Yuejin Yang",
      "Xiang Zhang",
      "Yuhan Chen",
      "Xiang Zhuang",
      "Zhangyang Gao",
      "Dongzhan Zhou",
      "Guangshuai Wang",
      "Zhiqiang Gao",
      "Juntai Cao",
      "Zijie Qiu",
      "Ming Hu",
      "Chenglong Ma",
      "Shixiang Tang",
      "Junjun He",
      "Chunfeng Song",
      "Xuming He",
      "Qiang Zhang",
      "Chenyu You",
      "Shuangjia Zheng",
      "Ning Ding",
      "Wanli Ouyang",
      "Nanqing Dong",
      "Yu Cheng",
      "Siqi Sun",
      "Lei Bai",
      "Bowen Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.22295v2",
    "title": "Aurora: Towards Universal Generative Multimodal Time Series Forecasting",
    "summary": "Cross-domain generalization is very important in Time Series Forecasting\nbecause similar historical information may lead to distinct future trends due\nto the domain-specific characteristics. Recent works focus on building unimodal\ntime series foundation models and end-to-end multimodal supervised models.\nSince domain-specific knowledge is often contained in modalities like texts,\nthe former lacks the explicit utilization of them, thus hindering the\nperformance. The latter is tailored for end-to-end scenarios and does not\nsupport zero-shot inference for cross-domain scenarios. In this work, we\nintroduce Aurora, a Multimodal Time Series Foundation Model, which supports\nmultimodal inputs and zero-shot inference. Pretrained on Corss-domain\nMultimodal Time Series Corpus, Aurora can adaptively extract and focus on key\ndomain knowledge contained in corrsponding text or image modalities, thus\npossessing strong Cross-domain generalization capability. Through tokenization,\nencoding, and distillation, Aurora can extract multimodal domain knowledge as\nguidance and then utilizes a Modality-Guided Multi-head Self-Attention to\ninject them into the modeling of temporal representations. In the decoding\nphase, the multimodal representations are used to generate the conditions and\nprototypes of future tokens, contributing to a novel Prototype-Guided Flow\nMatching for generative probabilistic forecasting. Comprehensive experiments on\nwell-recognized benchmarks, including TimeMMD, TSFM-Bench and ProbTS,\ndemonstrate the consistent state-of-the-art performance of Aurora on both\nunimodal and multimodal scenarios.",
    "published": "2025-09-26T12:56:20Z",
    "updated": "2025-10-20T06:03:58Z",
    "link": "http://arxiv.org/pdf/2509.22295v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Xingjian Wu",
      "Jianxin Jin",
      "Wanghui Qiu",
      "Peng Chen",
      "Yang Shu",
      "Bin Yang",
      "Chenjuan Guo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17187v1",
    "title": "A Standardized Benchmark for Machine-Learned Molecular Dynamics using\n  Weighted Ensemble Sampling",
    "summary": "The rapid evolution of molecular dynamics (MD) methods, including\nmachine-learned dynamics, has outpaced the development of standardized tools\nfor method validation. Objective comparison between simulation approaches is\noften hindered by inconsistent evaluation metrics, insufficient sampling of\nrare conformational states, and the absence of reproducible benchmarks. To\naddress these challenges, we introduce a modular benchmarking framework that\nsystematically evaluates protein MD methods using enhanced sampling analysis.\nOur approach uses weighted ensemble (WE) sampling via The Weighted Ensemble\nSimulation Toolkit with Parallelization and Analysis (WESTPA), based on\nprogress coordinates derived from Time-lagged Independent Component Analysis\n(TICA), enabling fast and efficient exploration of protein conformational\nspace. The framework includes a flexible, lightweight propagator interface that\nsupports arbitrary simulation engines, allowing both classical force fields and\nmachine learning-based models. Additionally, the framework offers a\ncomprehensive evaluation suite capable of computing more than 19 different\nmetrics and visualizations across a variety of domains. We further contribute a\ndataset of nine diverse proteins, ranging from 10 to 224 residues, that span a\nvariety of folding complexities and topologies. Each protein has been\nextensively simulated at 300K for one million MD steps per starting point (4\nns). To demonstrate the utility of our framework, we perform validation tests\nusing classic MD simulations with implicit solvent and compare protein\nconformational sampling using a fully trained versus under-trained CGSchNet\nmodel. By standardizing evaluation protocols and enabling direct, reproducible\ncomparisons across MD approaches, our open-source platform lays the groundwork\nfor consistent, rigorous benchmarking across the molecular simulation\ncommunity.",
    "published": "2025-10-20T06:02:36Z",
    "updated": "2025-10-20T06:02:36Z",
    "link": "http://arxiv.org/pdf/2510.17187v1.pdf",
    "category": [
      "cs.LG",
      "q-bio.BM",
      "92B20"
    ],
    "authors": [
      "Alexander Aghili",
      "Andy Bruce",
      "Daniel Sabo",
      "Sanya Murdeshwar",
      "Kevin Bachelor",
      "Ionut Mistreanu",
      "Ashwin Lokapally",
      "Razvan Marinescu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.14510v2",
    "title": "Enhancing Time Series Forecasting through Selective Representation\n  Spaces: A Patch Perspective",
    "summary": "Time Series Forecasting has made significant progress with the help of\nPatching technique, which partitions time series into multiple patches to\neffectively retain contextual semantic information into a representation space\nbeneficial for modeling long-term dependencies. However, conventional patching\npartitions a time series into adjacent patches, which causes a fixed\nrepresentation space, thus resulting in insufficiently expressful\nrepresentations. In this paper, we pioneer the exploration of constructing a\nselective representation space to flexibly include the most informative patches\nfor forecasting. Specifically, we propose the Selective Representation Space\n(SRS) module, which utilizes the learnable Selective Patching and Dynamic\nReassembly techniques to adaptively select and shuffle the patches from the\ncontextual time series, aiming at fully exploiting the information of\ncontextual time series to enhance the forecasting performance of patch-based\nmodels. To demonstrate the effectiveness of SRS module, we propose a simple yet\neffective SRSNet consisting of SRS and an MLP head, which achieves\nstate-of-the-art performance on real-world datasets from multiple domains.\nFurthermore, as a novel plugin-and-play module, SRS can also enhance the\nperformance of existing patch-based models. The resources are available at\nhttps://github.com/decisionintelligence/SRSNet.",
    "published": "2025-10-16T09:55:06Z",
    "updated": "2025-10-20T05:59:39Z",
    "link": "http://arxiv.org/pdf/2510.14510v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Xingjian Wu",
      "Xiangfei Qiu",
      "Hanyin Cheng",
      "Zhengyu Li",
      "Jilin Hu",
      "Chenjuan Guo",
      "Bin Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17185v1",
    "title": "Robustness in Text-Attributed Graph Learning: Insights, Trade-offs, and\n  New Defenses",
    "summary": "While Graph Neural Networks (GNNs) and Large Language Models (LLMs) are\npowerful approaches for learning on Text-Attributed Graphs (TAGs), a\ncomprehensive understanding of their robustness remains elusive. Current\nevaluations are fragmented, failing to systematically investigate the distinct\neffects of textual and structural perturbations across diverse models and\nattack scenarios. To address these limitations, we introduce a unified and\ncomprehensive framework to evaluate robustness in TAG learning. Our framework\nevaluates classical GNNs, robust GNNs (RGNNs), and GraphLLMs across ten\ndatasets from four domains, under diverse text-based, structure-based, and\nhybrid perturbations in both poisoning and evasion scenarios. Our extensive\nanalysis reveals multiple findings, among which three are particularly\nnoteworthy: 1) models have inherent robustness trade-offs between text and\nstructure, 2) the performance of GNNs and RGNNs depends heavily on the text\nencoder and attack type, and 3) GraphLLMs are particularly vulnerable to\ntraining data corruption. To overcome the identified trade-offs, we introduce\nSFT-auto, a novel framework that delivers superior and balanced robustness\nagainst both textual and structural attacks within a single model. Our work\nestablishes a foundation for future research on TAG security and offers\npractical solutions for robust TAG learning in adversarial environments. Our\ncode is available at: https://github.com/Leirunlin/TGRB.",
    "published": "2025-10-20T05:57:54Z",
    "updated": "2025-10-20T05:57:54Z",
    "link": "http://arxiv.org/pdf/2510.17185v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Runlin Lei",
      "Lu Yi",
      "Mingguo He",
      "Pengyu Qiu",
      "Zhewei Wei",
      "Yongchao Liu",
      "Chuntao Hong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17175v1",
    "title": "QRÃ¯S: A Preemptive Novel Method for Quishing Detection Through\n  Structural Features of QR",
    "summary": "Globally, individuals and organizations employ Quick Response (QR) codes for\nswift and convenient communication. Leveraging this, cybercriminals embed\nfalsify and misleading information in QR codes to launch various phishing\nattacks which termed as Quishing. Many former studies have introduced defensive\napproaches to preclude Quishing such as by classifying the embedded content of\nQR codes and then label the QR codes accordingly, whereas other studies\nclassify them using visual features (i.e., deep features, histogram density\nanalysis features). However, these approaches mainly rely on black-box\ntechniques which do not clearly provide interpretability and transparency to\nfully comprehend and reproduce the intrinsic decision process; therefore,\nhaving certain obvious limitations includes the approaches' trust,\naccountability, issues in bias detection, and many more. We proposed QR\\\"iS,\nthe pioneer method to classify QR codes through the comprehensive structural\nanalysis of a QR code which helps to identify phishing QR codes beforehand. Our\nclassification method is clearly transparent which makes it reproducible,\nscalable, and easy to comprehend. First, we generated QR codes dataset (i.e.\n400,000 samples) using recently published URLs datasets [1], [2]. Then, unlike\nblack-box models, we developed a simple algorithm to extract 24 structural\nfeatures from layout patterns present in QR codes. Later, we train the machine\nlearning models on the harvested features and obtained accuracy of up to\n83.18%. To further evaluate the effectiveness of our approach, we perform the\ncomparative analysis of proposed method with relevant contemporary studies.\nLastly, for real-world deployment and validation, we developed a mobile app\nwhich assures the feasibility of the proposed solution in real-world scenarios\nwhich eventually strengthen the applicability of the study.",
    "published": "2025-10-20T05:30:47Z",
    "updated": "2025-10-20T05:30:47Z",
    "link": "http://arxiv.org/pdf/2510.17175v1.pdf",
    "category": [
      "cs.CR",
      "cs.LG"
    ],
    "authors": [
      "Muhammad Wahid Akram",
      "Keshav Sood",
      "Muneeb Ul Hassan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.18530v4",
    "title": "Re-uploading quantum data: A universal function approximator for quantum\n  inputs",
    "summary": "Quantum data re-uploading has proved powerful for classical inputs, where\nrepeatedly encoding features into a small circuit yields universal function\napproximation. Extending this idea to quantum inputs remains underexplored, as\nthe information contained in a quantum state is not directly accessible in\nclassical form. We propose and analyze a quantum data re-uploading architecture\nin which a qubit interacts sequentially with fresh copies of an arbitrary input\nstate. The circuit can approximate any bounded continuous function using only\none ancilla qubit and single-qubit measurements. By alternating entangling\nunitaries with mid-circuit resets of the input register, the architecture\nrealizes a discrete cascade of completely positive and trace-preserving maps,\nanalogous to collision models in open quantum system dynamics. Our framework\nprovides a qubit-efficient and expressive approach to designing quantum machine\nlearning models that operate directly on quantum data.",
    "published": "2025-09-23T01:50:37Z",
    "updated": "2025-10-20T05:06:30Z",
    "link": "http://arxiv.org/pdf/2509.18530v4.pdf",
    "category": [
      "quant-ph",
      "cs.LG"
    ],
    "authors": [
      "Hyunho Cha",
      "Daniel K. Park",
      "Jungwoo Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17162v1",
    "title": "ALPINE: A Lightweight and Adaptive Privacy-Decision Agent Framework for\n  Dynamic Edge Crowdsensing",
    "summary": "Mobile edge crowdsensing (MECS) systems continuously generate and transmit\nuser data in dynamic, resource-constrained environments, exposing users to\nsignificant privacy threats. In practice, many privacy-preserving mechanisms\nbuild on differential privacy (DP). However, static DP mechanisms often fail to\nadapt to evolving risks, for example, shifts in adversarial capabilities,\nresource constraints and task requirements, resulting in either excessive noise\nor inadequate protection. To address this challenge, we propose ALPINE, a\nlightweight, adaptive framework that empowers terminal devices to autonomously\nadjust differential privacy levels in real time. ALPINE operates as a\nclosed-loop control system consisting of four modules: dynamic risk perception,\nprivacy decision via twin delayed deep deterministic policy gradient (TD3),\nlocal privacy execution and performance verification from edge nodes. Based on\nenvironmental risk assessments, we design a reward function that balances\nprivacy gains, data utility and energy cost, guiding the TD3 agent to\nadaptively tune noise magnitude across diverse risk scenarios and achieve a\ndynamic equilibrium among privacy, utility and cost. Both the collaborative\nrisk model and pretrained TD3-based agent are designed for low-overhead\ndeployment. Extensive theoretical analysis and real-world simulations\ndemonstrate that ALPINE effectively mitigates inference attacks while\npreserving utility and cost, making it practical for large-scale edge\napplications.",
    "published": "2025-10-20T05:03:25Z",
    "updated": "2025-10-20T05:03:25Z",
    "link": "http://arxiv.org/pdf/2510.17162v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Guanjie Cheng",
      "Siyang Liu",
      "Junqin Huang",
      "Xinkui Zhao",
      "Yin Wang",
      "Mengying Zhu",
      "Linghe Kong",
      "Shuiguang Deng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17160v1",
    "title": "Learning After Model Deployment",
    "summary": "In classic supervised learning, once a model is deployed in an application,\nit is fixed. No updates will be made to it during the application. This is\ninappropriate for many dynamic and open environments, where unexpected samples\nfrom unseen classes may appear. In such an environment, the model should be\nable to detect these novel samples from unseen classes and learn them after\nthey are labeled. We call this paradigm Autonomous Learning after Model\nDeployment (ALMD). The learning here is continuous and involves no human\nengineers. Labeling in this scenario is performed by human co-workers or other\nknowledgeable agents, which is similar to what humans do when they encounter an\nunfamiliar object and ask another person for its name. In ALMD, the detection\nof novel samples is dynamic and differs from traditional out-of-distribution\n(OOD) detection in that the set of in-distribution (ID) classes expands as new\nclasses are learned during application, whereas ID classes is fixed in\ntraditional OOD detection. Learning is also different from classic supervised\nlearning because in ALMD, we learn the encountered new classes immediately and\nincrementally. It is difficult to retrain the model from scratch using all the\npast data from the ID classes and the novel samples from newly discovered\nclasses, as this would be resource- and time-consuming. Apart from these two\nchallenges, ALMD faces the data scarcity issue because instances of new classes\noften appear sporadically in real-life applications. To address these issues,\nwe propose a novel method, PLDA, which performs dynamic OOD detection and\nincremental learning of new classes on the fly. Empirical evaluations will\ndemonstrate the effectiveness of PLDA.",
    "published": "2025-10-20T04:58:36Z",
    "updated": "2025-10-20T04:58:36Z",
    "link": "http://arxiv.org/pdf/2510.17160v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Derda Kaymak",
      "Gyuhak Kim",
      "Tomoya Kaichi",
      "Tatsuya Konishi",
      "Bing Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17153v1",
    "title": "HyperSearch: Prediction of New Hyperedges through Unconstrained yet\n  Efficient Search",
    "summary": "Higher-order interactions (HOIs) in complex systems, such as scientific\ncollaborations, multi-protein complexes, and multi-user communications, are\ncommonly modeled as hypergraphs, where each hyperedge (i.e., a subset of nodes)\nrepresents an HOI among the nodes. Given a hypergraph, hyperedge prediction\naims to identify hyperedges that are either missing or likely to form in the\nfuture, and it has broad applications, including recommending interest-based\nsocial groups, predicting collaborations, and uncovering functional complexes\nin biological systems. However, the vast search space of hyperedge candidates\n(i.e., all possible subsets of nodes) poses a significant computational\nchallenge, making naive exhaustive search infeasible. As a result, existing\napproaches rely on either heuristic sampling to obtain constrained candidate\nsets or ungrounded assumptions on hypergraph structure to select promising\nhyperedges.\n  In this work, we propose HyperSearch, a search-based algorithm for hyperedge\nprediction that efficiently evaluates unconstrained candidate sets, by\nincorporating two key components: (1) an empirically grounded scoring function\nderived from observations in real-world hypergraphs and (2) an efficient search\nmechanism, where we derive and use an anti-monotonic upper bound of the\noriginal scoring function (which is not antimonotonic) to prune the search\nspace. This pruning comes with theoretical guarantees, ensuring that discarded\ncandidates are never better than the kept ones w.r.t. the original scoring\nfunction. In extensive experiments on 10 real-world hypergraphs across five\ndomains, HyperSearch consistently outperforms state-of-the-art baselines,\nachieving higher accuracy in predicting new (i.e., not in the training set)\nhyperedges.",
    "published": "2025-10-20T04:55:40Z",
    "updated": "2025-10-20T04:55:40Z",
    "link": "http://arxiv.org/pdf/2510.17153v1.pdf",
    "category": [
      "cs.SI",
      "cs.LG"
    ],
    "authors": [
      "Hyunjin Choo",
      "Fanchen Bu",
      "Hyunjin Hwang",
      "Young-Gyu Yoon",
      "Kijung Shin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.02970v4",
    "title": "Membership Inference Attack Should Move On to Distributional Statistics\n  for Distilled Generative Models",
    "summary": "To detect unauthorized data usage in training large-scale generative models\n(e.g., ChatGPT or Midjourney), membership inference attacks (MIA) have proven\neffective in distinguishing a single training instance (a member) from a single\nnon-training instance (a non-member). This success is mainly credited to a\nmemorization effect: models tend to perform better on a member than a\nnon-member. However, we find that standard MIAs fail against distilled\ngenerative models (i.e., student models) that are increasingly deployed in\npractice for efficiency (e.g., ChatGPT 4o-mini). Trained exclusively on data\ngenerated from a large-scale model (a teacher model), the student model lacks\ndirect exposure to any members (teacher's training data), nullifying the\nmemorization effect that standard MIAs rely on. This finding reveals a serious\nprivacy loophole, where generation-service providers could deploy a student\nmodel whose teacher was potentially trained on unauthorized data, yet claim the\ndeployed model is clean because it was not directly trained on such data.\nHence, are distilled models inherently unauditable for upstream privacy\nviolations, and should we discard them when we care about privacy? We contend\nno, as we uncover a memory chain connecting the student and teacher's member\ndata: the distribution of student-generated data aligns more closely with the\ndistribution of the teacher's members than with non-members, thus we can detect\nunauthorized data usage even when direct instance-level memorization is absent.\nThis leads us to posit that MIAs on distilled generative models should shift\nfrom instance-level scores to distribution-level statistics. We further propose\nthree principles of distribution-based MIAs for detecting unauthorized training\ndata through distilled generative models, and validate our position through an\nexemplar framework. We lastly discuss the implications of our position.",
    "published": "2025-02-05T08:11:23Z",
    "updated": "2025-10-20T04:43:36Z",
    "link": "http://arxiv.org/pdf/2502.02970v4.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Muxing Li",
      "Zesheng Ye",
      "Sharon Li",
      "Andy Song",
      "Guangquan Zhang",
      "Feng Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.08952v2",
    "title": "When LLM Agents Meet Graph Optimization: An Automated Data Quality\n  Improvement Approach",
    "summary": "Text-attributed graphs (TAGs) have become a key form of graph-structured data\nin modern data management and analytics, combining structural relationships\nwith rich textual semantics for diverse applications. However, the\neffectiveness of analytical models, particularly graph neural networks (GNNs),\nis highly sensitive to data quality. Our empirical analysis shows that both\nconventional and LLM-enhanced GNNs degrade notably under textual, structural,\nand label imperfections, underscoring TAG quality as a key bottleneck for\nreliable analytics. Existing studies have explored data-level optimization for\nTAGs, but most focus on specific degradation types and target a single aspect\nlike structure or label, lacking a systematic and comprehensive perspective on\ndata quality improvement. To address this gap, we propose LAGA (Large Language\nand Graph Agent), a unified multi-agent framework for comprehensive TAG quality\noptimization. LAGA formulates graph quality control as a data-centric process,\nintegrating detection, planning, action, and evaluation agents into an\nautomated loop. It holistically enhances textual, structural, and label aspects\nthrough coordinated multi-modal optimization. Extensive experiments on 5\ndatasets and 16 baselines across 9 scenarios demonstrate the effectiveness,\nrobustness and scalability of LAGA, confirming the importance of data-centric\nquality optimization for reliable TAG analytics.",
    "published": "2025-10-10T02:59:19Z",
    "updated": "2025-10-20T04:17:41Z",
    "link": "http://arxiv.org/pdf/2510.08952v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Zhihan Zhang",
      "Xunkai Li",
      "Yilong Zuo",
      "Zhaoxin Fan",
      "Zhenjun Li",
      "Bing Zhou",
      "Rong-Hua Li",
      "Guoren Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.04650v3",
    "title": "Neural Network Reprogrammability: A Unified Theme on Model\n  Reprogramming, Prompt Tuning, and Prompt Instruction",
    "summary": "As large-scale pre-trained foundation models continue to expand in size and\ncapability, efficiently adapting them to specific downstream tasks has become\nincreasingly critical. Despite substantial progress, existing adaptation\napproaches have evolved largely in isolation, without a clear understanding of\ntheir interrelationships. This survey introduces neural network\nreprogrammability as a unifying framework that bridges mainstream model\nadaptation techniques--model reprogramming, prompt tuning, and prompt\ninstruction--previously fragmented research areas yet converges on a shared\nprinciple: repurposing a pre-trained model by manipulating information at the\ninterfaces while keeping the model parameters frozen. These methods exploit\nneural networks' sensitivity to manipulation on different interfaces, be it\nthrough perturbing inputs, inserting tokens into intermediate layers, or\nproviding task-specific examples in context, to redirect model behaviors\ntowards desired outcomes. We then present a taxonomy that categorizes such\ninformation manipulation-based adaptation approaches across four key\ndimensions: manipulation format (fixed or learnable), location (interfaces\nwhere manipulations occur), operator (how they are applied), and output\nalignment requirement (post-processing needed to align outputs with downstream\ntasks). Notably, this framework applies consistently across data modalities,\nindependent of specific model architectures. Moreover, viewing established\ntechniques like in-context learning and chain-of-thought prompting through this\nlens reveals both their theoretical connections and practical distinctions. We\nfurther analyze remaining technical challenges and ethical considerations,\npositioning neural network reprogrammability as a fundamental paradigm for\nefficient model adaptation. We lastly identify promising research directions\nemerging from this integrative viewpoint.",
    "published": "2025-06-05T05:42:27Z",
    "updated": "2025-10-20T04:15:14Z",
    "link": "http://arxiv.org/pdf/2506.04650v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Zesheng Ye",
      "Chengyi Cai",
      "Ruijiang Dong",
      "Jianzhong Qi",
      "Lei Feng",
      "Pin-Yu Chen",
      "Feng Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17136v1",
    "title": "In-situ Autoguidance: Eliciting Self-Correction in Diffusion Models",
    "summary": "The generation of high-quality, diverse, and prompt-aligned images is a\ncentral goal in image-generating diffusion models. The popular classifier-free\nguidance (CFG) approach improves quality and alignment at the cost of reduced\nvariation, creating an inherent entanglement of these effects. Recent work has\nsuccessfully disentangled these properties by guiding a model with a separately\ntrained, inferior counterpart; however, this solution introduces the\nconsiderable overhead of requiring an auxiliary model. We challenge this\nprerequisite by introducing In-situ Autoguidance, a method that elicits\nguidance from the model itself without any auxiliary components. Our approach\ndynamically generates an inferior prediction on the fly using a stochastic\nforward pass, reframing guidance as a form of inference-time self-correction.\nWe demonstrate that this zero-cost approach is not only viable but also\nestablishes a powerful new baseline for cost-efficient guidance, proving that\nthe benefits of self-guidance can be achieved without external models.",
    "published": "2025-10-20T04:06:50Z",
    "updated": "2025-10-20T04:06:50Z",
    "link": "http://arxiv.org/pdf/2510.17136v1.pdf",
    "category": [
      "cs.LG",
      "I.2.6; I.5.1; I.5.4"
    ],
    "authors": [
      "Enhao Gu",
      "Haolin Hou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.08164v2",
    "title": "BLUR: A Bi-Level Optimization Approach for LLM Unlearning",
    "summary": "Enabling large language models (LLMs) to unlearn knowledge and capabilities\nacquired during training has proven vital for ensuring compliance with data\nregulations and promoting ethical practices in generative AI. Although there\nare growing interests in developing various unlearning algorithms, it remains\nunclear how to best formulate the unlearning problem. The most popular\nformulation uses a weighted sum of forget and retain loss, but it often leads\nto performance degradation due to the inherent trade-off between forget and\nretain losses. In this work, we argue that it is important to model the\nhierarchical structure of the unlearning problem, where the forget problem\n(which \\textit{unlearns} certain knowledge and/or capabilities) takes priority\nover the retain problem (which preserves model utility). This hierarchical\nstructure naturally leads to a bi-level optimization formulation where the\nlower-level objective focuses on minimizing the forget loss, while the\nupper-level objective aims to maintain the model's utility. Based on this new\nformulation, we propose a novel algorithm, termed Bi-Level UnleaRning\n(\\texttt{BLUR}), which not only possesses strong theoretical guarantees but\nmore importantly, delivers superior performance. In particular, our extensive\nexperiments demonstrate that \\texttt{BLUR} consistently outperforms all the\nstate-of-the-art algorithms across various unlearning tasks, models, and\nmetrics. Codes are available at\nhttps://github.com/OptimAI-Lab/BLURLLMUnlearning.",
    "published": "2025-06-09T19:23:05Z",
    "updated": "2025-10-20T03:46:48Z",
    "link": "http://arxiv.org/pdf/2506.08164v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Hadi Reisizadeh",
      "Jinghan Jia",
      "Zhiqi Bu",
      "Bhanukiran Vinzamuri",
      "Anil Ramakrishna",
      "Kai-Wei Chang",
      "Volkan Cevher",
      "Sijia Liu",
      "Mingyi Hong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.15218v2",
    "title": "Machine Learning for Early Detection of Meningitis: Stacked Ensemble\n  Learning with EHR Data",
    "summary": "We utilized a cohort of 214 meningitis patients and 46,303 non-meningitis\npatients from the MIMIC-III database. After extensive data preprocessing, which\nincluded ICD-based cohort selection, one-hot encoding of coding, and a\ntwo-stage feature selection process (for both the training set and the testing\nsets), clinically relevant features such as gender and high-risk ICD codes\n(including subarachnoid hemorrhage, secondary malignant neoplasm of the brain,\nand generalized epilepsy) are selected. Overall, these clinically reasonable\nand temporally adherent features provided excellent modeling performance. Three\nmodels (Random Forest, LightGBM, and Deep Neural Networks (DNN) are trained as\nbase models for Ensemble Learning. Base model outputs are aggregated and\nstacked into a meta model (Logistic Regression) that uses the base model\noutputs as input values in training. Ultimately, soldier outputs (AUC of\nTesting Set 1: 0.9637, AUC of Testing Set 2: 0.9472) are obtained through\nensemble learning.\n  We created a challenging condition for diagnosing meningitis, simulating a\nreal-world ER (Emergency Room) scenario to enhance clinical use in real-world\napplications. While directly deploying a diagnostic tool that clinicians can\nuse is challenging, this paper paves the way for a potential future AI-driven\ndiagnostic approach for meningitis using Ensemble Learning.",
    "published": "2025-10-17T00:56:47Z",
    "updated": "2025-10-20T03:37:32Z",
    "link": "http://arxiv.org/pdf/2510.15218v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Han Ouyang",
      "Jesse Hamilton",
      "Saeed Amal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.08784v4",
    "title": "Greedy Low-Rank Gradient Compression for Distributed Learning with\n  Convergence Guarantees",
    "summary": "Distributed optimization is pivotal for large-scale signal processing and\nmachine learning, yet communication overhead remains a major bottleneck.\nLow-rank gradient compression, in which the transmitted gradients are\napproximated by low-rank matrices to reduce communication, offers a promising\nremedy. Existing methods typically adopt either randomized or greedy\ncompression strategies: randomized approaches project gradients onto randomly\nchosen subspaces, introducing high variance and degrading empirical\nperformance; greedy methods select the most informative subspaces, achieving\nstrong empirical results but lacking convergence guarantees. To address this\ngap, we propose GreedyLore--the first Greedy Low-Rank gradient compression\nalgorithm for distributed learning with rigorous convergence guarantees.\nGreedyLore incorporates error feedback to correct the bias introduced by greedy\ncompression and introduces a semi-lazy subspace update that ensures the\ncompression operator remains contractive throughout all iterations. With these\ntechniques, we prove that GreedyLore achieves a convergence rate of\n$\\mathcal{O}(\\sigma/\\sqrt{NT} + 1/T)$ under standard optimizers such as MSGD\nand Adam--marking the first linear speedup convergence rate for low-rank\ngradient compression. Extensive experiments are conducted to validate our\ntheoretical findings.",
    "published": "2025-07-11T17:46:12Z",
    "updated": "2025-10-20T03:37:03Z",
    "link": "http://arxiv.org/pdf/2507.08784v4.pdf",
    "category": [
      "cs.LG",
      "math.OC"
    ],
    "authors": [
      "Chuyan Chen",
      "Yutong He",
      "Pengrui Li",
      "Weichen Jia",
      "Kun Yuan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17122v1",
    "title": "Continuous Q-Score Matching: Diffusion Guided Reinforcement Learning for\n  Continuous-Time Control",
    "summary": "Reinforcement learning (RL) has achieved significant success across a wide\nrange of domains, however, most existing methods are formulated in discrete\ntime. In this work, we introduce a novel RL method for continuous-time control,\nwhere stochastic differential equations govern state-action dynamics. Departing\nfrom traditional value function-based approaches, our key contribution is the\ncharacterization of continuous-time Q-functions via a martingale condition and\nthe linking of diffusion policy scores to the action gradient of a learned\ncontinuous Q-function by the dynamic programming principle. This insight\nmotivates Continuous Q-Score Matching (CQSM), a score-based policy improvement\nalgorithm. Notably, our method addresses a long-standing challenge in\ncontinuous-time RL: preserving the action-evaluation capability of Q-functions\nwithout relying on time discretization. We further provide theoretical\nclosed-form solutions for linear-quadratic (LQ) control problems within our\nframework. Numerical results in simulated environments demonstrate the\neffectiveness of our proposed method and compare it to popular baselines.",
    "published": "2025-10-20T03:30:32Z",
    "updated": "2025-10-20T03:30:32Z",
    "link": "http://arxiv.org/pdf/2510.17122v1.pdf",
    "category": [
      "cs.LG",
      "math.OC"
    ],
    "authors": [
      "Chengxiu Hua",
      "Jiawen Gu",
      "Yushun Tang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17120v1",
    "title": "Matricial Free Energy as a Gaussianizing Regularizer: Enhancing\n  Autoencoders for Gaussian Code Generation",
    "summary": "We introduce a novel regularization scheme for autoencoders based on\nmatricial free energy. Our approach defines a differentiable loss function in\nterms of the singular values of the code matrix (code dimension x batch size).\nFrom the standpoint of free probability an d random matrix theory, this loss\nachieves its minimum when the singular value distribution of the code matrix\ncoincides with that of an appropriately sculpted random metric with i.i.d.\nGaussian entries. Empirical simulations demonstrate that minimizing the\nnegative matricial free energy through standard stochastic gradient-based\ntraining yields Gaussian-like codes that generalize across training and test\nsets. Building on this foundation, we propose a matricidal free energy\nmaximizing autoencoder that reliably produces Gaussian codes and show its\napplication to underdetermined inverse problems.",
    "published": "2025-10-20T03:19:44Z",
    "updated": "2025-10-20T03:19:44Z",
    "link": "http://arxiv.org/pdf/2510.17120v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV",
      "stat.ML"
    ],
    "authors": [
      "Rishi Sonthalia",
      "Raj Rao Nadakuditi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.03828v3",
    "title": "Importance-Aware Activation Space Reconstruction",
    "summary": "Large language models (LLMs) achieve strong performance across many domains\nbut are difficult to deploy in resource-constrained settings due to their size.\nLow-rank weight matrix compression is a popular strategy for reducing model\nsize, typically by minimizing weight reconstruction error under the assumption\nthat weights are low-rank. However, this assumption often does not hold in\nLLMs. Instead, LLM activations exhibit stronger low-rank structure-prompting a\nshift toward minimizing activation reconstruction error.\n  We show that this shift alone is insufficient: activation dimensions\ncontribute unequally to model performance, and uniform reconstruction can harm\nperformance. We propose IMPACT, a principled framework for importance-aware\nactivation reconstruction that links model compression decisions to their\nimpact on model behavior. IMPACT formulates an optimization problem that\nconsiders both activation structure and gradient sensitivity, and derives a\nclosed-form solution where the optimal reconstruction bases are the\neigenvectors of an importance-weighted activation covariance matrix. This\nenables low-rank approximations explicitly optimized to preserve accuracy.\nExperiments across diverse models and tasks show that IMPACT achieves up to\n48.6% greater model size reduction with accuracy comparable to state-of-the-art\nbaselines.",
    "published": "2025-07-04T22:26:33Z",
    "updated": "2025-10-20T03:17:09Z",
    "link": "http://arxiv.org/pdf/2507.03828v3.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Md Mokarram Chowdhury",
      "Daniel Agyei Asante",
      "Ernie Chang",
      "Yang Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17106v1",
    "title": "Fighter: Unveiling the Graph Convolutional Nature of Transformers in\n  Time Series Modeling",
    "summary": "Transformers have achieved remarkable success in time series modeling, yet\ntheir internal mechanisms remain opaque. This work demystifies the Transformer\nencoder by establishing its fundamental equivalence to a Graph Convolutional\nNetwork (GCN). We show that in the forward pass, the attention distribution\nmatrix serves as a dynamic adjacency matrix, and its composition with\nsubsequent transformations performs computations analogous to graph\nconvolution. Moreover, we demonstrate that in the backward pass, the update\ndynamics of value and feed-forward projections mirror those of GCN parameters.\nBuilding on this unified theoretical reinterpretation, we propose\n\\textbf{Fighter} (Flexible Graph Convolutional Transformer), a streamlined\narchitecture that removes redundant linear projections and incorporates\nmulti-hop graph aggregation. This perspective yields an explicit and\ninterpretable representation of temporal dependencies across different scales,\nnaturally expressed as graph edges. Experiments on standard forecasting\nbenchmarks confirm that Fighter achieves competitive performance while\nproviding clearer mechanistic interpretability of its predictions.",
    "published": "2025-10-20T02:42:14Z",
    "updated": "2025-10-20T02:42:14Z",
    "link": "http://arxiv.org/pdf/2510.17106v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Chen Zhang",
      "Weixin Bu",
      "Wendong Xu",
      "Runsheng Yu",
      "Yik-Chung Wu",
      "Ngai Wong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17103v1",
    "title": "Adapting to Stochastic and Adversarial Losses in Episodic MDPs with\n  Aggregate Bandit Feedback",
    "summary": "We study online learning in finite-horizon episodic Markov decision processes\n(MDPs) under the challenging aggregate bandit feedback model, where the learner\nobserves only the cumulative loss incurred in each episode, rather than\nindividual losses at each state-action pair. While prior work in this setting\nhas focused exclusively on worst-case analysis, we initiate the study of\nbest-of-both-worlds (BOBW) algorithms that achieve low regret in both\nstochastic and adversarial environments. We propose the first BOBW algorithms\nfor episodic tabular MDPs with aggregate bandit feedback. In the case of known\ntransitions, our algorithms achieve $O(\\log T)$ regret in stochastic settings\nand ${O}(\\sqrt{T})$ regret in adversarial ones. Importantly, we also establish\nmatching lower bounds, showing the optimality of our algorithms in this\nsetting. We further extend our approach to unknown-transition settings by\nincorporating confidence-based techniques. Our results rely on a combination of\nFTRL over occupancy measures, self-bounding techniques, and new loss estimators\ninspired by recent advances in online shortest path problems. Along the way, we\nalso provide the first individual-gap-dependent lower bounds and demonstrate\nnear-optimal BOBW algorithms for shortest path problems with bandit feedback.",
    "published": "2025-10-20T02:28:08Z",
    "updated": "2025-10-20T02:28:08Z",
    "link": "http://arxiv.org/pdf/2510.17103v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Shinji Ito",
      "Kevin Jamieson",
      "Haipeng Luo",
      "Arnab Maiti",
      "Taira Tsuchiya"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17099v1",
    "title": "On the Universal Near Optimality of Hedge in Combinatorial Settings",
    "summary": "In this paper, we study the classical Hedge algorithm in combinatorial\nsettings. In each round, the learner selects a vector $\\boldsymbol{x}_t$ from a\nset $X \\subseteq \\{0,1\\}^d$, observes a full loss vector $\\boldsymbol{y}_t \\in\n\\mathbb{R}^d$, and incurs a loss $\\langle \\boldsymbol{x}_t, \\boldsymbol{y}_t\n\\rangle \\in [-1,1]$. This setting captures several important problems,\nincluding extensive-form games, resource allocation, $m$-sets, online multitask\nlearning, and shortest-path problems on directed acyclic graphs (DAGs). It is\nwell known that Hedge achieves a regret of $O\\big(\\sqrt{T \\log |X|}\\big)$ after\n$T$ rounds of interaction. In this paper, we ask whether Hedge is optimal\nacross all combinatorial settings. To that end, we show that for any $X\n\\subseteq \\{0,1\\}^d$, Hedge is near-optimal--specifically, up to a $\\sqrt{\\log\nd}$ factor--by establishing a lower bound of $\\Omega\\big(\\sqrt{T \\log(|X|)/\\log\nd}\\big)$ that holds for any algorithm. We then identify a natural class of\ncombinatorial sets--namely, $m$-sets with $\\log d \\leq m \\leq \\sqrt{d}$--for\nwhich this lower bound is tight, and for which Hedge is provably suboptimal by\na factor of exactly $\\sqrt{\\log d}$. At the same time, we show that Hedge is\noptimal for online multitask learning, a generalization of the classical\n$K$-experts problem. Finally, we leverage the near-optimality of Hedge to\nestablish the existence of a near-optimal regularizer for online shortest-path\nproblems in DAGs--a setting that subsumes a broad range of combinatorial\ndomains. Specifically, we show that the classical Online Mirror Descent (OMD)\nalgorithm, when instantiated with the dilated entropy regularizer, is\niterate-equivalent to Hedge, and therefore inherits its near-optimal regret\nguarantees for DAGs.",
    "published": "2025-10-20T02:05:22Z",
    "updated": "2025-10-20T02:05:22Z",
    "link": "http://arxiv.org/pdf/2510.17099v1.pdf",
    "category": [
      "cs.LG",
      "cs.GT"
    ],
    "authors": [
      "Zhiyuan Fan",
      "Arnab Maiti",
      "Kevin Jamieson",
      "Lillian J. Ratliff",
      "Gabriele Farina"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17085v1",
    "title": "Data Reliability Scoring",
    "summary": "How can we assess the reliability of a dataset without access to ground\ntruth? We introduce the problem of reliability scoring for datasets collected\nfrom potentially strategic sources. The true data are unobserved, but we see\noutcomes of an unknown statistical experiment that depends on them. To\nbenchmark reliability, we define ground-truth-based orderings that capture how\nmuch reported data deviate from the truth. We then propose the Gram determinant\nscore, which measures the volume spanned by vectors describing the empirical\ndistribution of the observed data and experiment outcomes. We show that this\nscore preserves several ground-truth based reliability orderings and, uniquely\nup to scaling, yields the same reliability ranking of datasets regardless of\nthe experiment -- a property we term experiment agnosticism. Experiments on\nsynthetic noise models, CIFAR-10 embeddings, and real employment data\ndemonstrate that the Gram determinant score effectively captures data quality\nacross diverse observation processes.",
    "published": "2025-10-20T01:27:59Z",
    "updated": "2025-10-20T01:27:59Z",
    "link": "http://arxiv.org/pdf/2510.17085v1.pdf",
    "category": [
      "cs.LG",
      "cs.GT",
      "stat.ML"
    ],
    "authors": [
      "Yiling Chen",
      "Shi Feng",
      "Paul Kattuman",
      "Fang-Yi Yu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17072v1",
    "title": "DFNN: A Deep FrÃ©chet Neural Network Framework for Learning\n  Metric-Space-Valued Responses",
    "summary": "Regression with non-Euclidean responses -- e.g., probability distributions,\nnetworks, symmetric positive-definite matrices, and compositions -- has become\nincreasingly important in modern applications. In this paper, we propose deep\nFr\\'echet neural networks (DFNNs), an end-to-end deep learning framework for\npredicting non-Euclidean responses -- which are considered as random objects in\na metric space -- from Euclidean predictors. Our method leverages the\nrepresentation-learning power of deep neural networks (DNNs) to the task of\napproximating conditional Fr\\'echet means of the response given the predictors,\nthe metric-space analogue of conditional expectations, by minimizing a\nFr\\'echet risk. The framework is highly flexible, accommodating diverse metrics\nand high-dimensional predictors. We establish a universal approximation theorem\nfor DFNNs, advancing the state-of-the-art of neural network approximation\ntheory to general metric-space-valued responses without making model\nassumptions or relying on local smoothing. Empirical studies on synthetic\ndistributional and network-valued responses, as well as a real-world\napplication to predicting employment occupational compositions, demonstrate\nthat DFNNs consistently outperform existing methods.",
    "published": "2025-10-20T00:57:30Z",
    "updated": "2025-10-20T00:57:30Z",
    "link": "http://arxiv.org/pdf/2510.17072v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "authors": [
      "Kyum Kim",
      "Yaqing Chen",
      "Paromita Dubey"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17067v1",
    "title": "Convergence of Regret Matching in Potential Games and Constrained\n  Optimization",
    "summary": "Regret matching (RM} -- and its modern variants -- is a foundational online\nalgorithm that has been at the heart of many AI breakthrough results in solving\nbenchmark zero-sum games, such as poker. Yet, surprisingly little is known so\nfar in theory about its convergence beyond two-player zero-sum games. For\nexample, whether regret matching converges to Nash equilibria in potential\ngames has been an open problem for two decades. Even beyond games, one could\ntry to use RM variants for general constrained optimization problems. Recent\nempirical evidence suggests that they -- particularly regret matching$^+$\n(RM$^+$) -- attain strong performance on benchmark constrained optimization\nproblems, outperforming traditional gradient descent-type algorithms.\n  We show that alternating RM$^+$ converges to an $\\epsilon$-KKT point after\n$O_\\epsilon(1/\\epsilon^4)$ iterations, establishing for the first time that it\nis a sound and fast first-order optimizer. Our argument relates the KKT gap to\nthe accumulated regret, two quantities that are entirely disparate in general\nbut interact in an intriguing way in our setting, so much so that when regrets\nare bounded, our complexity bound improves all the way to\n$O_\\epsilon(1/\\epsilon^2)$. From a technical standpoint, while RM$^+$ does not\nhave the usual one-step improvement property in general, we show that it does\nin a certain region that the algorithm will quickly reach and remain in\nthereafter. In sharp contrast, our second main result establishes a lower\nbound: RM, with or without alternation, can take an exponential number of\niterations to reach a crude approximate solution even in two-player potential\ngames. This represents the first worst-case separation between RM and RM$^+$.\nOur lower bound shows that convergence to coarse correlated equilibria in\npotential games is exponentially faster than convergence to Nash equilibria.",
    "published": "2025-10-20T00:45:47Z",
    "updated": "2025-10-20T00:45:47Z",
    "link": "http://arxiv.org/pdf/2510.17067v1.pdf",
    "category": [
      "cs.GT",
      "cs.LG",
      "math.OC"
    ],
    "authors": [
      "Ioannis Anagnostides",
      "Emanuel Tewolde",
      "Brian Hu Zhang",
      "Ioannis Panageas",
      "Vincent Conitzer",
      "Tuomas Sandholm"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17063v1",
    "title": "Mode Collapse of Mean-Field Variational Inference",
    "summary": "Mean-field variational inference (MFVI) is a widely used method for\napproximating high-dimensional probability distributions by product measures.\nIt has been empirically observed that MFVI optimizers often suffer from mode\ncollapse. Specifically, when the target measure $\\pi$ is a mixture $\\pi = w P_0\n+ (1 - w) P_1$, the MFVI optimizer tends to place most of its mass near a\nsingle component of the mixture. This work provides the first theoretical\nexplanation of mode collapse in MFVI. We introduce the notion to capture the\nseparatedness of the two mixture components -- called\n$\\varepsilon$-separateness -- and derive explicit bounds on the fraction of\nmass that any MFVI optimizer assigns to each component when $P_0$ and $P_1$ are\n$\\varepsilon$-separated for sufficiently small $\\varepsilon$. Our results\nsuggest that the occurrence of mode collapse crucially depends on the relative\nposition of the components. To address this issue, we propose the rotational\nvariational inference (RoVI), which augments MFVI with a rotation matrix. The\nnumerical studies support our theoretical findings and demonstrate the benefits\nof RoVI.",
    "published": "2025-10-20T00:36:13Z",
    "updated": "2025-10-20T00:36:13Z",
    "link": "http://arxiv.org/pdf/2510.17063v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Shunan Sheng",
      "Bohan Wu",
      "Alberto GonzÃ¡lez-Sanz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17059v1",
    "title": "Consistent Zero-Shot Imitation with Contrastive Goal Inference",
    "summary": "In the same way that generative models today conduct most of their training\nin a self-supervised fashion, how can agentic models conduct their training in\na self-supervised fashion, interactively exploring, learning, and preparing to\nquickly adapt to new tasks? A prerequisite for embodied agents deployed in real\nworld interactions ought to be training with interaction, yet today's most\nsuccessful AI models (e.g., VLMs, LLMs) are trained without an explicit notion\nof action. The problem of pure exploration (which assumes no data as input) is\nwell studied in the reinforcement learning literature and provides agents with\na wide array of experiences, yet it fails to prepare them for rapid adaptation\nto new tasks. Today's language and vision models are trained on data provided\nby humans, which provides a strong inductive bias for the sorts of tasks that\nthe model will have to solve (e.g., modeling chords in a song, phrases in a\nsonnet, sentences in a medical record). However, when they are prompted to\nsolve a new task, there is a faulty tacit assumption that humans spend most of\ntheir time in the most rewarding states. The key contribution of our paper is a\nmethod for pre-training interactive agents in a self-supervised fashion, so\nthat they can instantly mimic human demonstrations. Our method treats goals\n(i.e., observations) as the atomic construct. During training, our method\nautomatically proposes goals and practices reaching them, building off prior\nwork in reinforcement learning exploration. During evaluation, our method\nsolves an (amortized) inverse reinforcement learning problem to explain\ndemonstrations as optimal goal-reaching behavior. Experiments on standard\nbenchmarks (not designed for goal-reaching) show that our approach outperforms\nprior methods for zero-shot imitation.",
    "published": "2025-10-20T00:28:03Z",
    "updated": "2025-10-20T00:28:03Z",
    "link": "http://arxiv.org/pdf/2510.17059v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Kathryn Wantlin",
      "Chongyi Zheng",
      "Benjamin Eysenbach"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.13174v2",
    "title": "GeoRecon: Graph-Level Representation Learning for 3D Molecules via\n  Reconstruction-Based Pretraining",
    "summary": "The pretraining-finetuning paradigm has powered major advances in domains\nsuch as natural language processing and computer vision, with representative\nexamples including masked language modeling and next-token prediction. In\nmolecular representation learning, however, pretraining tasks remain largely\nrestricted to node-level denoising, which effectively captures local atomic\nenvironments but is often insufficient for encoding the global molecular\nstructure critical to graph-level property prediction tasks such as energy\nestimation and molecular regression. To address this gap, we introduce\nGeoRecon, a graph-level pretraining framework that shifts the focus from\nindividual atoms to the molecule as an integrated whole. GeoRecon formulates a\ngraph-level reconstruction task: during pretraining, the model is trained to\nproduce an informative graph representation that guides geometry reconstruction\nwhile inducing smoother and more transferable latent spaces. This encourages\nthe learning of coherent, global structural features beyond isolated atomic\ndetails. Without relying on external supervision, GeoRecon generally improves\nover backbone baselines on multiple molecular benchmarks including QM9, MD17,\nMD22, and 3BPA, demonstrating the effectiveness of graph-level reconstruction\nfor holistic and geometry-aware molecular embeddings.",
    "published": "2025-06-16T07:35:49Z",
    "updated": "2025-10-20T00:21:40Z",
    "link": "http://arxiv.org/pdf/2506.13174v2.pdf",
    "category": [
      "cs.LG",
      "q-bio.BM"
    ],
    "authors": [
      "Shaoheng Yan",
      "Zian Li",
      "Muhan Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.13404v2",
    "title": "SWIR-LightFusion: Multi-spectral Semantic Fusion of Synthetic SWIR with\n  Thermal IR (LWIR/MWIR) and RGB",
    "summary": "Enhancing scene understanding in adverse visibility conditions remains a\ncritical challenge for surveillance and autonomous navigation systems.\nConventional imaging modalities, such as RGB and thermal infrared (MWIR /\nLWIR), when fused, often struggle to deliver comprehensive scene information,\nparticularly under conditions of atmospheric interference or inadequate\nillumination. To address these limitations, Short-Wave Infrared (SWIR) imaging\nhas emerged as a promising modality due to its ability to penetrate atmospheric\ndisturbances and differentiate materials with improved clarity. However, the\nadvancement and widespread implementation of SWIR-based systems face\nsignificant hurdles, primarily due to the scarcity of publicly accessible SWIR\ndatasets. In response to this challenge, our research introduces an approach to\nsynthetically generate SWIR-like structural/contrast cues (without claiming\nspectral reproduction) images from existing LWIR data using advanced contrast\nenhancement techniques. We then propose a multimodal fusion framework\nintegrating synthetic SWIR, LWIR, and RGB modalities, employing an optimized\nencoder-decoder neural network architecture with modality-specific encoders and\na softmax-gated fusion head. Comprehensive experiments on public RGB-LWIR\nbenchmarks (M3FD, TNO, CAMEL, MSRS, RoadScene) and an additional private real\nRGB-MWIR-SWIR dataset demonstrate that our synthetic-SWIR-enhanced fusion\nframework improves fused-image quality (contrast, edge definition, structural\nfidelity) while maintaining real-time performance. We also add fair trimodal\nbaselines (LP, LatLRR, GFF) and cascaded trimodal variants of\nU2Fusion/SwinFusion under a unified protocol. The outcomes highlight\nsubstantial potential for real-world applications in surveillance and\nautonomous systems.",
    "published": "2025-10-15T11:00:41Z",
    "updated": "2025-10-20T00:09:00Z",
    "link": "http://arxiv.org/pdf/2510.13404v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Muhammad Ishfaq Hussain",
      "Ma Van Linh",
      "Zubia Naz",
      "Unse Fatima",
      "Yeongmin Ko",
      "Moongu Jeon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.10262v2",
    "title": "Enhancing the Cross-Size Generalization for Solving Vehicle Routing\n  Problems via Continual Learning",
    "summary": "Exploring machine learning techniques for addressing vehicle routing problems\nhas attracted considerable research attention. To achieve decent and efficient\nsolutions, existing deep models for vehicle routing problems are typically\ntrained and evaluated using instances of a single size. This substantially\nlimits their ability to generalize across different problem sizes and thus\nhampers their practical applicability. To address the issue, we propose a\ncontinual learning based framework that sequentially trains a deep model with\ninstances of ascending problem sizes. Specifically, on the one hand, we design\nan inter-task regularization scheme to retain the knowledge acquired from\nsmaller problem sizes in the model training on a larger size. On the other\nhand, we introduce an intra-task regularization scheme to consolidate the model\nby imitating the latest desirable behaviors during training on each size.\nAdditionally, we exploit the experience replay to revisit instances of formerly\ntrained sizes for mitigating the catastrophic forgetting. Experimental results\nshow that our approach achieves predominantly superior performance across\nvarious problem sizes (either seen or unseen in the training), as compared to\nstate-of-the-art deep models including the ones specialized for\ngeneralizability enhancement. Meanwhile, the ablation studies on the key\ndesigns manifest their synergistic effect in the proposed framework.",
    "published": "2025-10-11T15:39:36Z",
    "updated": "2025-10-19T23:48:02Z",
    "link": "http://arxiv.org/pdf/2510.10262v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Jingwen Li",
      "Zhiguang Cao",
      "Yaoxin Wu",
      "Tang Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.07559v2",
    "title": "Barron Space Representations for Elliptic PDEs with Homogeneous Boundary\n  Conditions",
    "summary": "We study the approximation complexity of high-dimensional second-order\nelliptic PDEs with homogeneous boundary conditions on the unit hypercube,\nwithin the framework of Barron spaces. Under the assumption that the\ncoefficients belong to suitably defined Barron spaces, we prove that the\nsolution can be efficiently approximated by two-layer neural networks,\ncircumventing the curse of dimensionality. Our results demonstrate the\nexpressive power of shallow networks in capturing high-dimensional PDE\nsolutions under appropriate structural assumptions.",
    "published": "2025-08-11T02:36:40Z",
    "updated": "2025-10-19T23:36:02Z",
    "link": "http://arxiv.org/pdf/2508.07559v2.pdf",
    "category": [
      "math.NA",
      "cs.LG",
      "cs.NA",
      "math.AP"
    ],
    "authors": [
      "Ziang Chen",
      "Liqiang Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2403.13748v5",
    "title": "Variational Inference for Uncertainty Quantification: an Analysis of\n  Trade-offs",
    "summary": "Given an intractable distribution $p$, the problem of variational inference\n(VI) is to find the best approximation from some more tractable family $Q$.\nCommonly, one chooses $Q$ to be a family of factorized distributions (i.e., the\nmean-field assumption), even though $p$ itself does not factorize. We show that\nthis mismatch can lead to an impossibility theorem: if $p$ does not factorize\nand furthermore has a non-diagonal covariance matrix, then any factorized\napproximation $q\\!\\in\\!Q$ can correctly estimate at most one of the following\nthree measures of uncertainty: (i) the marginal variances, (ii) the marginal\nprecisions, or (iii) the generalized variance (which for elliptical\ndistributions is closely related to the entropy). In practice, the best\nvariational approximation in $Q$ is found by minimizing some divergence\n$D(q,p)$ between distributions, and so we ask: how does the choice of\ndivergence determine which measure of uncertainty, if any, is correctly\nestimated by VI? We consider the classic Kullback-Leibler divergences, the more\ngeneral $\\alpha$-divergences, and a score-based divergence which compares\n$\\nabla \\log p$ and $\\nabla \\log q$. We thoroughly analyze the case where $p$\nis a Gaussian and $q$ is a (factorized) Gaussian. In this setting, we show that\nall the considered divergences can be ordered based on the estimates of\nuncertainty they yield as objective functions for VI. Finally, we empirically\nevaluate the validity of this ordering when the target distribution $p$ is not\nGaussian.",
    "published": "2024-03-20T16:56:08Z",
    "updated": "2025-10-19T23:33:59Z",
    "link": "http://arxiv.org/pdf/2403.13748v5.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "stat.CO"
    ],
    "authors": [
      "Charles C. Margossian",
      "Loucas Pillaud-Vivien",
      "Lawrence K. Saul"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.21741v2",
    "title": "Critically-Damped Higher-Order Langevin Dynamics for Generative Modeling",
    "summary": "Denoising diffusion probabilistic models (DDPMs) represent an entirely new\nclass of generative AI methods that have yet to be fully explored. They use\nLangevin dynamics, represented as stochastic differential equations, to\ndescribe a process that transforms data into noise, the forward process, and a\nprocess that transforms noise into generated data, the reverse process. Many of\nthese methods utilize auxiliary variables that formulate the data as a\n``position\" variable, and the auxiliary variables are referred to as\n``velocity\", ``acceleration\", etc. In this sense, it is possible to\n``critically damp\" the dynamics. Critical damping has been successfully\nintroduced in Critically-Damped Langevin Dynamics (CLD) and Critically-Damped\nThird-Order Langevin Dynamics (TOLD++), but has not yet been applied to\ndynamics of arbitrary order. The proposed methodology generalizes Higher-Order\nLangevin Dynamics (HOLD), a recent state-of-the-art diffusion method, by\nintroducing the concept of critical damping from systems analysis. Similarly to\nTOLD++, this work proposes an optimal set of hyperparameters in the\n$n$-dimensional case, where HOLD leaves these to be user defined. Additionally,\nthis work provides closed-form solutions for the mean and covariance of the\nforward process that greatly simplify its implementation. Experiments are\nperformed on the CIFAR-10 and CelebA-HQ $256 \\times 256$ datasets, and\nvalidated against the FID metric.",
    "published": "2025-06-26T19:50:53Z",
    "updated": "2025-10-19T23:28:16Z",
    "link": "http://arxiv.org/pdf/2506.21741v2.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Benjamin Sterling",
      "Chad Gueli",
      "MÃ³nica F. Bugallo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.22967v3",
    "title": "ActAlign: Zero-Shot Fine-Grained Video Classification via\n  Language-Guided Sequence Alignment",
    "summary": "We address the task of zero-shot video classification for extremely\nfine-grained actions (e.g., Windmill Dunk in basketball), where no video\nexamples or temporal annotations are available for unseen classes. While\nimage-language models (e.g., CLIP, SigLIP) show strong open-set recognition,\nthey lack temporal modeling needed for video understanding. We propose\nActAlign, a truly zero-shot, training-free method that formulates video\nclassification as a sequence alignment problem, preserving the generalization\nstrength of pretrained image-language models. For each class, a large language\nmodel (LLM) generates an ordered sequence of sub-actions, which we align with\nvideo frames using Dynamic Time Warping (DTW) in a shared embedding space.\nWithout any video-text supervision or fine-tuning, ActAlign achieves 30.5%\naccuracy on ActionAtlas--the most diverse benchmark of fine-grained actions\nacross multiple sports--where human performance is only 61.6%. ActAlign\noutperforms billion-parameter video-language models while using 8x fewer\nparameters. Our approach is model-agnostic and domain-general, demonstrating\nthat structured language priors combined with classical alignment methods can\nunlock the open-set recognition potential of image-language models for\nfine-grained video understanding.",
    "published": "2025-06-28T17:57:58Z",
    "updated": "2025-10-19T23:08:33Z",
    "link": "http://arxiv.org/pdf/2506.22967v3.pdf",
    "category": [
      "cs.CV",
      "cs.LG",
      "cs.MM",
      "I.2.10; I.2.7"
    ],
    "authors": [
      "Amir Aghdam",
      "Vincent Tao Hu",
      "BjÃ¶rn Ommer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17040v1",
    "title": "Diverse Influence Component Analysis: A Geometric Approach to Nonlinear\n  Mixture Identifiability",
    "summary": "Latent component identification from unknown nonlinear mixtures is a\nfoundational challenge in machine learning, with applications in tasks such as\ndisentangled representation learning and causal inference. Prior work in\nnonlinear independent component analysis (nICA) has shown that auxiliary\nsignals -- such as weak supervision -- can support identifiability of\nconditionally independent latent components. More recent approaches explore\nstructural assumptions, e.g., sparsity in the Jacobian of the mixing function,\nto relax such requirements. In this work, we introduce Diverse Influence\nComponent Analysis (DICA), a framework that exploits the convex geometry of the\nmixing function's Jacobian. We propose a Jacobian Volume Maximization\n(J-VolMax) criterion, which enables latent component identification by\nencouraging diversity in their influence on the observed variables. Under\nreasonable conditions, this approach achieves identifiability without relying\non auxiliary information, latent component independence, or Jacobian sparsity\nassumptions. These results extend the scope of identifiability analysis and\noffer a complementary perspective to existing methods.",
    "published": "2025-10-19T23:06:58Z",
    "updated": "2025-10-19T23:06:58Z",
    "link": "http://arxiv.org/pdf/2510.17040v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Hoang-Son Nguyen",
      "Xiao Fu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.16673v2",
    "title": "Subgradient Method for System Identification with Non-Smooth Objectives",
    "summary": "This paper investigates a subgradient-based algorithm to solve the system\nidentification problem for linear time-invariant systems with non-smooth\nobjectives. This is essential for robust system identification in\nsafety-critical applications. While existing work provides theoretical exact\nrecovery guarantees using optimization solvers, the design of fast learning\nalgorithms with convergence guarantees for practical use remains unexplored. We\nanalyze the subgradient method in this setting, where the optimization problems\nto be solved evolve over time as new measurements are collected, and we\nestablish linear convergence to the ground-truth system for both the best and\nPolyak step sizes after a burn-in period. We further characterize sublinear\nconvergence of the iterates under constant and diminishing step sizes, which\nrequire only minimal information and thus offer broad applicability. Finally,\nwe compare the time complexity of standard solvers with the subgradient\nalgorithm and support our findings with experimental results. This is the first\nwork to analyze subgradient algorithms for system identification with\nnon-smooth objectives.",
    "published": "2025-03-20T19:39:47Z",
    "updated": "2025-10-19T23:05:47Z",
    "link": "http://arxiv.org/pdf/2503.16673v2.pdf",
    "category": [
      "math.OC",
      "cs.CC",
      "cs.LG",
      "cs.SY",
      "eess.SY",
      "62, 90, 93"
    ],
    "authors": [
      "Baturalp Yalcin",
      "Jihun Kim",
      "Javad Lavaei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17036v1",
    "title": "Hephaestus: Mixture Generative Modeling with Energy Guidance for\n  Large-scale QoS Degradation",
    "summary": "We study the Quality of Service Degradation (QoSD) problem, in which an\nadversary perturbs edge weights to degrade network performance. This setting\narises in both network infrastructures and distributed ML systems, where\ncommunication quality, not just connectivity, determines functionality. While\nclassical methods rely on combinatorial optimization, and recent ML approaches\naddress only restricted linear variants with small-size networks, no prior\nmodel directly tackles the QoSD problem under nonlinear edge-weight functions.\nThis work proposes \\PIMMA, a self-reinforcing generative framework that\nsynthesizes feasible solutions in latent space, to fill this gap. Our method\nincludes three phases: (1) Forge: a Predictive Path-Stressing (PPS) algorithm\nthat uses graph learning and approximation to produce feasible solutions with\nperformance guarantee, (2) Morph: a new theoretically grounded training\nparadigm for Mixture of Conditional VAEs guided by an energy-based model to\ncapture solution feature distributions, and (3) Refine: a reinforcement\nlearning agent that explores this space to generate progressively near-optimal\nsolutions using our designed differentiable reward function. Experiments on\nboth synthetic and real-world networks show that our approach consistently\noutperforms classical and ML baselines, particularly in scenarios with\nnonlinear cost functions where traditional methods fail to generalize.",
    "published": "2025-10-19T22:48:35Z",
    "updated": "2025-10-19T22:48:35Z",
    "link": "http://arxiv.org/pdf/2510.17036v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Nguyen Do",
      "Bach Ngo",
      "Youval Kashuv",
      "Canh V. Pham",
      "Hanghang Tong",
      "My T. Thai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17002v1",
    "title": "EEschematic: Multimodal-LLM Based AI Agent for Schematic Generation of\n  Analog Circuit",
    "summary": "Circuit schematics play a crucial role in analog integrated circuit design,\nserving as the primary medium for human understanding and verification of\ncircuit functionality. While recent large language model (LLM)-based approaches\nhave shown promise in circuit topology generation and device sizing, most rely\nsolely on textual representations such as SPICE netlists, which lack visual\ninterpretability for circuit designers. To address this limitation, we propose\nEEschematic, an AI agent for automatic analog schematic generation based on a\nMultimodal Large Language Model (MLLM). EEschematic integrates textual, visual,\nand symbolic modalities to translate SPICE netlists into schematic diagrams\nrepresented in a human-editable format. The framework uses six analog\nsubstructure examples for few-shot placement and a Visual Chain-of-Thought\n(VCoT) strategy to iteratively refine placement and wiring, enhancing schematic\nclarity and symmetry. Experimental results on representative analog circuits,\nincluding a CMOS inverter, a five-transistor operational transconductance\namplifier (5T-OTA), and a telescopic cascode amplifier, demonstrate that\nEEschematic produces schematics with high visual quality and structural\ncorrectness.",
    "published": "2025-10-19T20:58:59Z",
    "updated": "2025-10-19T20:58:59Z",
    "link": "http://arxiv.org/pdf/2510.17002v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Chang Liu",
      "Danial Chitnis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2406.14380v4",
    "title": "Estimating Treatment Effects under Recommender Interference: A\n  Structured Neural Networks Approach",
    "summary": "Recommender systems are essential for content-sharing platforms by curating\npersonalized content. To improve recommender systems, platforms frequently rely\non creator-side randomized experiments to evaluate algorithm updates. We show\nthat commonly adopted difference-in-means estimators can lead to severely\nbiased estimates due to recommender interference, where treated and control\ncreators compete for exposure. This bias can result in incorrect business\ndecisions. To address this, we propose a ``recommender choice model'' that\nexplicitly represents the interference pathway. The approach combines a\nstructural choice framework with neural networks to account for rich\nviewer-content heterogeneity. Building on this foundation, we develop a\ndebiased estimator using the double machine learning (DML) framework to adjust\nfor errors from nuisance component estimation. We show that the estimator is\n$\\sqrt{n}$-consistent and asymptotically normal, and we extend the DML theory\nto handle correlated data, which arise in our context due to overlapped items.\nWe validate our method with a large-scale field experiment on Weixin\nshort-video platform, using a costly double-sided randomization design to\nobtain an interference-free ground truth. Our results show that the proposed\nestimator successfully recovers this ground truth, whereas benchmark estimators\nexhibit substantial bias, and in some cases, yield reversed signs.",
    "published": "2024-06-20T14:53:26Z",
    "updated": "2025-10-19T20:48:54Z",
    "link": "http://arxiv.org/pdf/2406.14380v4.pdf",
    "category": [
      "econ.EM",
      "cs.LG",
      "stat.ME"
    ],
    "authors": [
      "Ruohan Zhan",
      "Shichao Han",
      "Yuchen Hu",
      "Zhenling Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.17458v2",
    "title": "HERO: Heterogeneous Continual Graph Learning via Meta-Knowledge\n  Distillation",
    "summary": "Heterogeneous graph neural networks have seen rapid progress in web\napplications such as social networks, knowledge graphs, and recommendation\nsystems, driven by the inherent heterogeneity of web data. However, existing\nmethods typically assume static graphs, while real-world graphs are\ncontinuously evolving. This dynamic nature requires models to adapt to new data\nwhile preserving existing knowledge. To this end, this work introduces HERO\n(HEterogeneous continual gRaph learning via meta-knOwledge distillation), a\nunified framework for continual learning on heterogeneous graphs. HERO employs\nmeta-adaptation, a gradient-based meta-learning strategy that provides\ndirectional guidance for rapid adaptation to new tasks with limited samples. To\nenable efficient and effective knowledge reuse, we propose DiSCo (Diversity\nSampling with semantic Consistency), a heterogeneity-aware sampling method that\nmaximizes target node diversity and expands subgraphs along metapaths,\nretaining critical semantic and structural information with minimal overhead.\nFurthermore, HERO incorporates heterogeneity-aware knowledge distillation,\nwhich aligns knowledge at both the node and semantic levels to balance\nadaptation and retention across tasks. Extensive experiments on four\nweb-related heterogeneous graph benchmarks demonstrate that HERO substantially\nmitigates catastrophic forgetting while achieving efficient and consistent\nknowledge reuse in dynamic web environments.",
    "published": "2025-05-23T04:37:57Z",
    "updated": "2025-10-19T20:31:15Z",
    "link": "http://arxiv.org/pdf/2505.17458v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Guiquan Sun",
      "Xikun Zhang",
      "Jingchao Ni",
      "Dongjin Song"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.16990v1",
    "title": "Graph4MM: Weaving Multimodal Learning with Structural Information",
    "summary": "Real-world multimodal data usually exhibit complex structural relationships\nbeyond traditional one-to-one mappings like image-caption pairs. Entities\nacross modalities interact in intricate ways, with images and text forming\ndiverse interconnections through contextual dependencies and co-references.\nGraphs provide powerful structural information for modeling intra-modal and\ninter-modal relationships. However, previous works fail to distinguish\nmulti-hop neighbors and treat the graph as a standalone modality, which\nfragments the overall understanding. This limitation presents two key\nchallenges in multimodal learning: (1) integrating structural information from\nmulti-hop neighbors into foundational models, and (2) fusing modality-specific\ninformation in a principled manner. To address these challenges, we revisit the\nrole of graphs in multimodal learning within the era of foundation models and\npropose Graph4MM, a graph-based multimodal learning framework. To be specific,\nwe introduce Hop-Diffused Attention, which integrates multi-hop structural\ninformation into self-attention through causal masking and hop diffusion.\nFurthermore, we design MM-QFormer, a multi-mapping querying transformer for\ncross-modal fusion. Through theoretical and empirical analysis, we show that\nleveraging structures to integrate both intra- and inter-modal interactions\nimproves multimodal understanding beyond treating them as a standalone\nmodality. Experiments on both generative and discriminative tasks show that\nGraph4MM outperforms larger VLMs, LLMs, and multimodal graph baselines,\nachieving a 6.93% average improvement.",
    "published": "2025-10-19T20:13:03Z",
    "updated": "2025-10-19T20:13:03Z",
    "link": "http://arxiv.org/pdf/2510.16990v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Xuying Ning",
      "Dongqi Fu",
      "Tianxin Wei",
      "Wujiang Xu",
      "Jingrui He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.16986v1",
    "title": "Adaptive Sample Sharing for Linear Regression",
    "summary": "In many business settings, task-specific labeled data are scarce or costly to\nobtain, which limits supervised learning on a specific task. To address this\nchallenge, we study sample sharing in the case of ridge regression: leveraging\nan auxiliary data set while explicitly protecting against negative transfer. We\nintroduce a principled, data-driven rule that decides how many samples from an\nauxiliary dataset to add to the target training set. The rule is based on an\nestimate of the transfer gain i.e. the marginal reduction in the predictive\nerror. Building on this estimator, we derive finite-sample guaranties: under\nstandard conditions, the procedure borrows when it improves parameter\nestimation and abstains otherwise. In the Gaussian feature setting, we analyze\nwhich data set properties ensure that borrowing samples reduces the predictive\nerror. We validate the approach in synthetic and real datasets, observing\nconsistent gains over strong baselines and single-task training while avoiding\nnegative transfer.",
    "published": "2025-10-19T20:03:48Z",
    "updated": "2025-10-19T20:03:48Z",
    "link": "http://arxiv.org/pdf/2510.16986v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "stat.OT"
    ],
    "authors": [
      "Hamza Cherkaoui",
      "HÃ©lÃ¨ne Halconruy",
      "Yohan Petetin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.16981v1",
    "title": "MuonBP: Faster Muon via Block-Periodic Orthogonalization",
    "summary": "Gradient orthogonalization is a simple strategy that shows great utility in\nspeeding up gradient descent. The Muon optimizer (Jordan, Jin, et al., 2024)\ncombines gradient orthogonalization with first-order momentum and achieves\nsignificant improvement in data efficiency over Adam/AdamW (Loshchilov and\nHutter, 2019) for language model training. However, when using model\nparallelism, gradient orthogonalization introduces additional overhead compared\nto coordinate-wise optimizers (such as AdamW) due to additional gather and\nscatter operations on gradient matrix shards from different devices. This\nadditional communication can amount to a throughput hit of 5%-10% compared to\nAdam/AdamW. To remedy this, we propose Muon with Block-Periodic\nOrthogonalization (MuonBP), which applies orthogonalization independently to\nmatrix shards on each device and periodically performs full orthogonalization\nto maintain training stability at scale. We show how to adjust the learning\nrate from the baseline to MuonBP and give convergence guarantees for this\nalgorithm. Crucially, our theory dictates that we use two stepsizes: one for\nthe blockwise orthogonalization steps, and one for the full orthogonalization\nsteps. Our method is simple, requires minimal hyperparameter adjustments, and\nachieves competitive iteration complexity compared with baseline Muon while\nproviding per-iteration throughput comparable to coordinate-wise methods such\nas AdamW. When training an 8B model with eight-way tensor parallelism and ZeRO\noptimizer state sharding, MuonBP achieves 8% throughput increase compared to\nMuon with no degradation in performance.",
    "published": "2025-10-19T19:56:05Z",
    "updated": "2025-10-19T19:56:05Z",
    "link": "http://arxiv.org/pdf/2510.16981v1.pdf",
    "category": [
      "cs.LG",
      "math.OC"
    ],
    "authors": [
      "Ahmed Khaled",
      "Kaan Ozkara",
      "Tao Yu",
      "Mingyi Hong",
      "Youngsuk Park"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.16980v1",
    "title": "Towards Interpretable and Trustworthy Time Series Reasoning: A BlueSky\n  Vision",
    "summary": "Time series reasoning is emerging as the next frontier in temporal analysis,\naiming to move beyond pattern recognition towards explicit, interpretable, and\ntrustworthy inference. This paper presents a BlueSky vision built on two\ncomplementary directions. One builds robust foundations for time series\nreasoning, centered on comprehensive temporal understanding, structured\nmulti-step reasoning, and faithful evaluation frameworks. The other advances\nsystem-level reasoning, moving beyond language-only explanations by\nincorporating multi-agent collaboration, multi-modal context, and\nretrieval-augmented approaches. Together, these directions outline a flexible\nand extensible framework for advancing time series reasoning, aiming to deliver\ninterpretable and trustworthy temporal intelligence across diverse domains.",
    "published": "2025-10-19T19:48:15Z",
    "updated": "2025-10-19T19:48:15Z",
    "link": "http://arxiv.org/pdf/2510.16980v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Kanghui Ning",
      "Zijie Pan",
      "Yushan Jiang",
      "Anderson Schneider",
      "Yuriy Nevmyvaka",
      "Dongjin Song"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.08908v2",
    "title": "Statistical Decision Theory with Counterfactual Loss",
    "summary": "Many researchers have applied classical statistical decision theory to\nevaluate treatment choices and learn optimal policies. However, because this\nframework is based solely on realized outcomes under chosen decisions and\nignores counterfactual outcomes, it cannot assess the quality of a decision\nrelative to feasible alternatives. For example, in bail decisions, a judge must\nconsider not only crime prevention but also the avoidance of unnecessary\nburdens on arrestees. To address this limitation, we generalize standard\ndecision theory by incorporating counterfactual losses, allowing decisions to\nbe evaluated using all potential outcomes. The central challenge in this\ncounterfactual statistical decision framework is identification: since only one\npotential outcome is observed for each unit, the associated counterfactual risk\nis generally not identifiable. We prove that, under the assumption of strong\nignorability, the counterfactual risk is identifiable if and only if the\ncounterfactual loss function is additive in the potential outcomes. Moreover,\nwe demonstrate that additive counterfactual losses can yield treatment\nrecommendations, which differ from those based on standard loss functions when\nthe decision problem involves more than two treatment options. One\ninterpretation of this result is that additive counterfactual losses can\ncapture the accuracy and difficulty of a decision, whereas standard losses\naccount for accuracy alone. Finally, we formulate a symbolic linear inverse\nprogram that, given a counterfactual loss, determines whether its risk is\nidentifiable, without requiring data.",
    "published": "2025-05-13T19:00:07Z",
    "updated": "2025-10-19T19:41:39Z",
    "link": "http://arxiv.org/pdf/2505.08908v2.pdf",
    "category": [
      "math.ST",
      "cs.LG",
      "econ.TH",
      "stat.TH"
    ],
    "authors": [
      "Benedikt Koch",
      "Kosuke Imai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.16974v1",
    "title": "Differentially Private Linear Regression and Synthetic Data Generation\n  with Statistical Guarantees",
    "summary": "In social sciences, small- to medium-scale datasets are common and linear\nregression (LR) is canonical. In privacy-aware settings, much work has focused\non differentially private (DP) LR, but mostly on point estimation with limited\nattention to uncertainty quantification. Meanwhile, synthetic data generation\n(SDG) is increasingly important for reproducibility studies, yet current DP LR\nmethods do not readily support it. Mainstream SDG approaches are either\ntailored to discretized data, making them less suitable for continuous\nregression, or rely on deep models that require large datasets, limiting their\nuse for the smaller, continuous data typical in social science. We propose a\nmethod for LR with valid inference under Gaussian DP: a DP bias-corrected\nestimator with asymptotic confidence intervals (CIs) and a general SDG\nprocedure in which regression on the synthetic data matches our DP regression.\nOur binning-aggregation strategy is effective in small- to moderate-dimensional\nsettings. Experiments show our method (1) improves accuracy over existing\nmethods, (2) provides valid CIs, and (3) produces more reliable synthetic data\nfor downstream ML tasks than current DP SDGs.",
    "published": "2025-10-19T19:30:41Z",
    "updated": "2025-10-19T19:30:41Z",
    "link": "http://arxiv.org/pdf/2510.16974v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Shurong Lin",
      "Aleksandra SlavkoviÄ",
      "Deekshith Reddy Bhoomireddy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.00265v2",
    "title": "The Nondecreasing Rank",
    "summary": "In this article the notion of the nondecreasing (ND) rank of a matrix or\ntensor is introduced. A tensor has an ND rank of r if it can be represented as\na sum of r outer products of vectors, with each vector satisfying a\nmonotonicity constraint. It is shown that for certain poset orderings finding\nan ND factorization of rank $r$ is equivalent to finding a nonnegative rank-r\nfactorization of a transformed tensor. However, not every tensor that is\nmonotonic has a finite ND rank. Theory is developed describing the properties\nof the ND rank, including typical, maximum, and border ND ranks. Highlighted\nalso are the special settings where a matrix or tensor has an ND rank of one or\ntwo. As a means of finding low ND rank approximations to a data tensor we\nintroduce a variant of the hierarchical alternating least squares algorithm.\nLow ND rank factorizations are found and interpreted for two datasets\nconcerning the weight of pigs and a mental health survey during the COVID-19\npandemic.",
    "published": "2025-08-29T22:31:04Z",
    "updated": "2025-10-19T18:41:57Z",
    "link": "http://arxiv.org/pdf/2509.00265v2.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "cs.NA",
      "math.NA",
      "math.OC",
      "15-02"
    ],
    "authors": [
      "Andrew McCormack"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.14571v6",
    "title": "Efficient Data Selection for Training Genomic Perturbation Models",
    "summary": "Genomic studies face a vast hypothesis space, while interventions such as\ngene perturbations remain costly and time-consuming. To accelerate such\nexperiments, gene perturbation models predict the transcriptional outcome of\ninterventions. Since constructing the training set is challenging, active\nlearning is often employed in a \"lab-in-the-loop\" process. While this strategy\nmakes training more targeted, it is substantially slower, as it fails to\nexploit the inherent parallelizability of Perturb-seq experiments. Here, we\nfocus on graph neural network-based gene perturbation models and propose a\nsubset selection method that, unlike active learning, selects the training\nperturbations in one shot. Our method chooses the interventions that maximize\nthe propagation of the supervision signal to the model. The selection criterion\nis defined over the input knowledge graph and is optimized with submodular\nmaximization, ensuring a near-optimal guarantee. Experimental results across\nmultiple datasets show that, in addition to providing months of acceleration\ncompared to active learning, the method improves the stability of perturbation\nchoices while maintaining competitive predictive accuracy.",
    "published": "2025-03-18T12:52:03Z",
    "updated": "2025-10-19T18:39:32Z",
    "link": "http://arxiv.org/pdf/2503.14571v6.pdf",
    "category": [
      "q-bio.QM",
      "cs.LG"
    ],
    "authors": [
      "George Panagopoulos",
      "Johannes F. Lutzeyer",
      "Sofiane Ennadir",
      "Michalis Vazirgiannis",
      "Jun Pang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.18186v2",
    "title": "Online Learning of Whittle Indices for Restless Bandits with\n  Non-Stationary Transition Kernels",
    "summary": "We study optimal resource allocation in restless multi-armed bandits (RMABs)\nunder unknown and non-stationary dynamics. Solving RMABs optimally is\nPSPACE-hard even with full knowledge of model parameters, and while the Whittle\nindex policy offers asymptotic optimality with low computational cost, it\nrequires access to stationary transition kernels - an unrealistic assumption in\nmany applications. To address this challenge, we propose a Sliding-Window\nOnline Whittle (SW-Whittle) policy that remains computationally efficient while\nadapting to time-varying kernels. Our algorithm achieves a dynamic regret of\n$\\tilde O(T^{2/3}\\tilde V^{1/3}+T^{4/5})$ for large RMABs, where $T$ is the\nnumber of episodes and $\\tilde V$ is the total variation distance between\nconsecutive transition kernels. Importantly, we handle the challenging case\nwhere the variation budget is unknown in advance by combining a\nBandit-over-Bandit framework with our sliding-window design. Window lengths are\ntuned online as a function of the estimated variation, while Whittle indices\nare computed via an upper-confidence-bound of the estimated transition kernels\nand a bilinear optimization routine. Numerical experiments demonstrate that our\nalgorithm consistently outperforms baselines, achieving the lowest cumulative\nregret across a range of non-stationary environments.",
    "published": "2025-06-22T22:04:52Z",
    "updated": "2025-10-19T18:24:22Z",
    "link": "http://arxiv.org/pdf/2506.18186v2.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Md Kamran Chowdhury Shisher",
      "Vishrant Tripathi",
      "Mung Chiang",
      "Christopher G. Brinton"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.01879v4",
    "title": "Nexus: An Omni-Perceptive And -Interactive Model for Language, Audio,\n  And Vision",
    "summary": "This work proposes an industry-level omni-modal large language model (LLM)\npipeline that integrates auditory, visual, and linguistic modalities to\novercome challenges such as limited tri-modal datasets, high computational\ncosts, and complex feature alignments. Our pipeline consists of three main\ncomponents: First, a modular framework enabling flexible configuration of\nvarious encoder-LLM-decoder architectures. Second, a lightweight training\nstrategy that pre-trains audio-language alignment on the state-of-the-art\nvision-language model Qwen2.5-VL, thus avoiding the costly pre-training of\nvision-specific modalities. Third, an audio synthesis pipeline that generates\nhigh-quality audio-text data from diverse real-world scenarios, supporting\napplications such as Automatic Speech Recognition and Speech-to-Speech chat. To\nthis end, we introduce an industry-level omni-modal LLM, Nexus. Extensive\nexperiments validate the efficacy of our pipeline, yielding the following key\nfindings:(1) In the visual understanding task, Nexus exhibits superior\nperformance compared with its backbone model - Qwen2.5-VL-7B, validating the\nefficiency of our training strategy. (2) Within the English Spoken\nQuestion-Answering task, the model achieves better accuracy than the\nsame-period competitor (i.e, MiniCPM-o2.6-7B) in the LLaMA Q. benchmark. (3) In\nour real-world ASR testset, Nexus achieves outstanding performance, indicating\nits robustness in real scenarios. (4) In the Speech-to-Text Translation task,\nour model outperforms Qwen2-Audio-Instruct-7B. (5) In the Text-to-Speech task,\nbased on pretrained vocoder (e.g., Fishspeech1.4 or CosyVoice2.0), Nexus is\ncomparable to its backbone vocoder on Seed-TTS benchmark. (6) An in-depth\nanalysis of tri-modal alignment reveals that incorporating the audio modality\nenhances representational alignment between vision and language.",
    "published": "2025-02-26T17:26:36Z",
    "updated": "2025-10-20T12:05:19Z",
    "link": "http://arxiv.org/pdf/2503.01879v4.pdf",
    "category": [
      "cs.MM",
      "cs.CV",
      "cs.SD",
      "eess.AS"
    ],
    "authors": [
      "Che Liu",
      "Yingji Zhang",
      "Dong Zhang",
      "Weijie Zhang",
      "Chenggong Gong",
      "Yu Lu",
      "Shilin Zhou",
      "Ziliang Gan",
      "Ziao Wang",
      "Haipang Wu",
      "Ji Liu",
      "AndrÃ© Freitas",
      "Qifan Wang",
      "Zenglin Xu",
      "Rongjuncheng Zhang",
      "Yong Dai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17427v1",
    "title": "AV1 Motion Vector Fidelity and Application for Efficient Optical Flow",
    "summary": "This paper presents a comprehensive analysis of motion vectors extracted from\nAV1-encoded video streams and their application in accelerating optical flow\nestimation. We demonstrate that motion vectors from AV1 video codec can serve\nas a high-quality and computationally efficient substitute for traditional\noptical flow, a critical but often resource-intensive component in many\ncomputer vision pipelines. Our primary contributions are twofold. First, we\nprovide a detailed comparison of motion vectors from both AV1 and HEVC against\nground-truth optical flow, establishing their fidelity. In particular we show\nthe impact of encoder settings on motion estimation fidelity and make\nrecommendations about the optimal settings. Second, we show that using these\nextracted AV1 motion vectors as a \"warm-start\" for a state-of-the-art deep\nlearning-based optical flow method, RAFT, significantly reduces the time to\nconvergence while achieving comparable accuracy. Specifically, we observe a\nfour-fold speedup in computation time with only a minor trade- off in end-point\nerror. These findings underscore the potential of reusing motion vectors from\ncompressed video as a practical and efficient method for a wide range of\nmotion-aware computer vision applications.",
    "published": "2025-10-20T11:13:36Z",
    "updated": "2025-10-20T11:13:36Z",
    "link": "http://arxiv.org/pdf/2510.17427v1.pdf",
    "category": [
      "eess.IV",
      "cs.MM"
    ],
    "authors": [
      "Julien Zouein",
      "Vibhoothi Vibhoothi",
      "Anil Kokaram"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17305v1",
    "title": "LongInsightBench: A Comprehensive Benchmark for Evaluating Omni-Modal\n  Models on Human-Centric Long-Video Understanding",
    "summary": "We introduce \\textbf{LongInsightBench}, the first benchmark designed to\nassess models' ability to understand long videos, with a focus on human\nlanguage, viewpoints, actions, and other contextual elements, while integrating\n\\textbf{visual, audio, and text} modalities. Our benchmark excels in three key\nareas: \\textbf{a) Long-Duration, Information-Dense Videos:} We carefully select\napproximately 1,000 videos from open-source datasets FineVideo based on\nduration limit and the information density of both visual and audio modalities,\nfocusing on content like lectures, interviews, and vlogs, which contain rich\nlanguage elements. \\textbf{b) Diverse and Challenging Task Scenarios:} We have\ndesigned six challenging task scenarios, including both Intra-Event and\nInter-Event Tasks. \\textbf{c) Rigorous and Comprehensive Quality Assurance\nPipelines:} We have developed a three-step, semi-automated data quality\nassurance pipeline to ensure the difficulty and validity of the synthesized\nquestions and answer options. Based on LongInsightBench, we designed a series\nof experiments. Experimental results shows that Omni-modal models(OLMs) still\nface challenge in tasks requiring precise temporal localization (T-Loc) and\nlong-range causal inference (CE-Caus). Extended experiments reveal the\ninformation loss and processing bias in multi-modal fusion of OLMs. Our dataset\nand code is available at\nhttps://anonymous.4open.science/r/LongInsightBench-910F/.",
    "published": "2025-10-20T08:49:10Z",
    "updated": "2025-10-20T08:49:10Z",
    "link": "http://arxiv.org/pdf/2510.17305v1.pdf",
    "category": [
      "cs.CV",
      "cs.MM"
    ],
    "authors": [
      "ZhaoYang Han",
      "Qihan Lin",
      "Hao Liang",
      "Bowen Chen",
      "Zhou Liu",
      "Wentao Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17023v1",
    "title": "Enrich and Detect: Video Temporal Grounding with Multimodal LLMs",
    "summary": "We introduce ED-VTG, a method for fine-grained video temporal grounding\nutilizing multi-modal large language models. Our approach harnesses the\ncapabilities of multimodal LLMs to jointly process text and video, in order to\neffectively localize natural language queries in videos through a two-stage\nprocess. Rather than being directly grounded, language queries are initially\ntransformed into enriched sentences that incorporate missing details and cues\nto aid in grounding. In the second stage, these enriched queries are grounded,\nusing a lightweight decoder, which specializes at predicting accurate\nboundaries conditioned on contextualized representations of the enriched\nqueries. To mitigate noise and reduce the impact of hallucinations, our model\nis trained with a multiple-instance-learning objective that dynamically selects\nthe optimal version of the query for each training sample. We demonstrate\nstate-of-the-art results across various benchmarks in temporal video grounding\nand paragraph grounding settings. Experiments reveal that our method\nsignificantly outperforms all previously proposed LLM-based temporal grounding\napproaches and is either superior or comparable to specialized models, while\nmaintaining a clear advantage against them in zero-shot evaluation scenarios.",
    "published": "2025-10-19T22:12:45Z",
    "updated": "2025-10-19T22:12:45Z",
    "link": "http://arxiv.org/pdf/2510.17023v1.pdf",
    "category": [
      "cs.CV",
      "cs.MM"
    ],
    "authors": [
      "Shraman Pramanick",
      "Effrosyni Mavroudi",
      "Yale Song",
      "Rama Chellappa",
      "Lorenzo Torresani",
      "Triantafyllos Afouras"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17101v1",
    "title": "Shape-aware Inertial Poser: Motion Tracking for Humans with Diverse\n  Shapes Using Sparse Inertial Sensors",
    "summary": "Human motion capture with sparse inertial sensors has gained significant\nattention recently. However, existing methods almost exclusively rely on a\ntemplate adult body shape to model the training data, which poses challenges\nwhen generalizing to individuals with largely different body shapes (such as a\nchild). This is primarily due to the variation in IMU-measured acceleration\ncaused by changes in body shape. To fill this gap, we propose Shape-aware\nInertial Poser (SAIP), the first solution considering body shape differences in\nsparse inertial-based motion capture. Specifically, we decompose the sensor\nmeasurements related to shape and pose in order to effectively model their\njoint correlations. Firstly, we train a regression model to transfer the\nIMU-measured accelerations of a real body to match the template adult body\nmodel, compensating for the shape-related sensor measurements. Then, we can\neasily follow the state-of-the-art methods to estimate the full body motions of\nthe template-shaped body. Finally, we utilize a second regression model to map\nthe joint velocities back to the real body, combined with a shape-aware\nphysical optimization strategy to calculate global motions on the subject.\nFurthermore, our method relies on body shape awareness, introducing the first\ninertial shape estimation scheme. This is accomplished by modeling the\nshape-conditioned IMU-pose correlation using an MLP-based network. To validate\nthe effectiveness of SAIP, we also present the first IMU motion capture dataset\ncontaining individuals of different body sizes. This dataset features 10\nchildren and 10 adults, with heights ranging from 110 cm to 190 cm, and a total\nof 400 minutes of paired IMU-Motion samples. Extensive experimental results\ndemonstrate that SAIP can effectively handle motion capture tasks for diverse\nbody shapes. The code and dataset are available at\nhttps://github.com/yinlu5942/SAIP.",
    "published": "2025-10-20T02:20:31Z",
    "updated": "2025-10-20T02:20:31Z",
    "link": "http://arxiv.org/pdf/2510.17101v1.pdf",
    "category": [
      "cs.GR",
      "cs.CV"
    ],
    "authors": [
      "Lu Yin",
      "Ziying Shi",
      "Yinghao Wu",
      "Xinyu Yi",
      "Feng Xu",
      "Shihui Guo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.16966v1",
    "title": "A Scalable In Transit Solution for Comprehensive Exploration of\n  Simulation Data",
    "summary": "As simulations produce more data than available disk space on supercomputers,\nmany simulations are employing in situ analysis and visualization to reduce the\namount of data that needs to be stored. While in situ visualization offers\npotential for substantial data reduction, its efficacy is hindered by the need\nfor a priori knowledge. First, we need to know what visualization parameters to\nuse to highlight features of interest. Second, we do not know ahead of time how\nmuch resources will be needed to run the in situ workflows, e.g. how many\ncompute nodes will be needed for in situ work. In this work, we present SeerX,\na lightweight, scalable in-transit in situ service that supports dynamic\nresource allocation and lossy compression of 3D simulation data. SeerX enables\nmultiple simulations to offload analysis to a shared, elastic service\ninfrastructure without MPI synchronization.",
    "published": "2025-10-19T19:13:53Z",
    "updated": "2025-10-19T19:13:53Z",
    "link": "http://arxiv.org/pdf/2510.16966v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Paascal Grosset",
      "James Ahrens"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17801v1",
    "title": "Robobench: A Comprehensive Evaluation Benchmark for Multimodal Large\n  Language Models as Embodied Brain",
    "summary": "Building robots that can perceive, reason, and act in dynamic, unstructured\nenvironments remains a core challenge. Recent embodied systems often adopt a\ndual-system paradigm, where System 2 handles high-level reasoning while System\n1 executes low-level control. In this work, we refer to System 2 as the\nembodied brain, emphasizing its role as the cognitive core for reasoning and\ndecision-making in manipulation tasks. Given this role, systematic evaluation\nof the embodied brain is essential. Yet existing benchmarks emphasize execution\nsuccess, or when targeting high-level reasoning, suffer from incomplete\ndimensions and limited task realism, offering only a partial picture of\ncognitive capability. To bridge this gap, we introduce RoboBench, a benchmark\nthat systematically evaluates multimodal large language models (MLLMs) as\nembodied brains. Motivated by the critical roles across the full manipulation\npipeline, RoboBench defines five dimensions-instruction comprehension,\nperception reasoning, generalized planning, affordance prediction, and failure\nanalysis-spanning 14 capabilities, 25 tasks, and 6092 QA pairs. To ensure\nrealism, we curate datasets across diverse embodiments, attribute-rich objects,\nand multi-view scenes, drawing from large-scale real robotic data. For\nplanning, RoboBench introduces an evaluation framework,\nMLLM-as-world-simulator. It evaluate embodied feasibility by simulating whether\npredicted plans can achieve critical object-state changes. Experiments on 14\nMLLMs reveal fundamental limitations: difficulties with implicit instruction\ncomprehension, spatiotemporal reasoning, cross-scenario planning, fine-grained\naffordance understanding, and execution failure diagnosis. RoboBench provides a\ncomprehensive scaffold to quantify high-level cognition, and guide the\ndevelopment of next-generation embodied MLLMs. The project page is in\nhttps://robo-bench.github.io.",
    "published": "2025-10-20T17:59:03Z",
    "updated": "2025-10-20T17:59:03Z",
    "link": "http://arxiv.org/pdf/2510.17801v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Yulin Luo",
      "Chun-Kai Fan",
      "Menghang Dong",
      "Jiayu Shi",
      "Mengdi Zhao",
      "Bo-Wen Zhang",
      "Cheng Chi",
      "Jiaming Liu",
      "Gaole Dai",
      "Rongyu Zhang",
      "Ruichuan An",
      "Kun Wu",
      "Zhengping Che",
      "Shaoxuan Xie",
      "Guocai Yao",
      "Zhongxia Zhao",
      "Pengwei Wang",
      "Guang Liu",
      "Zhongyuan Wang",
      "Tiejun Huang",
      "Shanghang Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17783v1",
    "title": "Botany-Bot: Digital Twin Monitoring of Occluded and Underleaf Plant\n  Structures with Gaussian Splats",
    "summary": "Commercial plant phenotyping systems using fixed cameras cannot perceive many\nplant details due to leaf occlusion. In this paper, we present Botany-Bot, a\nsystem for building detailed \"annotated digital twins\" of living plants using\ntwo stereo cameras, a digital turntable inside a lightbox, an industrial robot\narm, and 3D segmentated Gaussian Splat models. We also present robot algorithms\nfor manipulating leaves to take high-resolution indexable images of occluded\ndetails such as stem buds and the underside/topside of leaves. Results from\nexperiments suggest that Botany-Bot can segment leaves with 90.8% accuracy,\ndetect leaves with 86.2% accuracy, lift/push leaves with 77.9% accuracy, and\ntake detailed overside/underside images with 77.3% accuracy. Code, videos, and\ndatasets are available at https://berkeleyautomation.github.io/Botany-Bot/.",
    "published": "2025-10-20T17:42:20Z",
    "updated": "2025-10-20T17:42:20Z",
    "link": "http://arxiv.org/pdf/2510.17783v1.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Simeon Adebola",
      "Chung Min Kim",
      "Justin Kerr",
      "Shuangyu Xie",
      "Prithvi Akella",
      "Jose Luis Susa Rincon",
      "Eugen Solowjow",
      "Ken Goldberg"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17604v1",
    "title": "Learned Inertial Odometry for Cycling Based on Mixture of Experts\n  Algorithm",
    "summary": "With the rapid growth of bike sharing and the increasing diversity of cycling\napplications, accurate bicycle localization has become essential. traditional\nGNSS-based methods suffer from multipath effects, while existing inertial\nnavigation approaches rely on precise modeling and show limited robustness.\nTight Learned Inertial Odometry (TLIO) achieves low position drift by combining\nraw IMU data with predicted displacements by neural networks, but its high\ncomputational cost restricts deployment on mobile devices. To overcome this, we\nextend TLIO to bicycle localization and introduce an improved Mixture-of\nExperts (MoE) model that reduces both training and inference costs. Experiments\nshow that, compared to the state-of-the-art LLIO framework, our method achieves\ncomparable accuracy while reducing parameters by 64.7% and computational cost\nby 81.8%.",
    "published": "2025-10-20T14:52:50Z",
    "updated": "2025-10-20T14:52:50Z",
    "link": "http://arxiv.org/pdf/2510.17604v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Hao Qiao",
      "Yan Wang",
      "Shuo Yang",
      "Xiaoyao Yu",
      "Jian kuang",
      "Xiaoji Niu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17541v1",
    "title": "Distributed Spatial-Temporal Trajectory Optimization for\n  Unmanned-Aerial-Vehicle Swarm",
    "summary": "Swarm trajectory optimization problems are a well-recognized class of\nmulti-agent optimal control problems with strong nonlinearity. However, the\nheuristic nature of needing to set the final time for agents beforehand and the\ntime-consuming limitation of the significant number of iterations prohibit the\napplication of existing methods to large-scale swarm of Unmanned Aerial\nVehicles (UAVs) in practice. In this paper, we propose a spatial-temporal\ntrajectory optimization framework that accomplishes multi-UAV consensus based\non the Alternating Direction Multiplier Method (ADMM) and uses Differential\nDynamic Programming (DDP) for fast local planning of individual UAVs. The\nintroduced framework is a two-level architecture that employs Parameterized DDP\n(PDDP) as the trajectory optimizer for each UAV, and ADMM to satisfy the local\nconstraints and accomplish the spatial-temporal parameter consensus among all\nUAVs. This results in a fully distributed algorithm called Distributed\nParameterized DDP (D-PDDP). In addition, an adaptive tuning criterion based on\nthe spectral gradient method for the penalty parameter is proposed to reduce\nthe number of algorithmic iterations. Several simulation examples are presented\nto verify the effectiveness of the proposed algorithm.",
    "published": "2025-10-20T13:45:50Z",
    "updated": "2025-10-20T13:45:50Z",
    "link": "http://arxiv.org/pdf/2510.17541v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Xiaobo Zheng",
      "Pan Tang",
      "Defu Lin",
      "Shaoming He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17525v1",
    "title": "HumanMPC - Safe and Efficient MAV Navigation among Humans",
    "summary": "Safe and efficient robotic navigation among humans is essential for\nintegrating robots into everyday environments. Most existing approaches focus\non simplified 2D crowd navigation and fail to account for the full complexity\nof human body dynamics beyond root motion. We present HumanMPC, a Model\nPredictive Control (MPC) framework for 3D Micro Air Vehicle (MAV) navigation\namong humans that combines theoretical safety guarantees with data-driven\nmodels for realistic human motion forecasting. Our approach introduces a novel\ntwist to reachability-based safety formulation that constrains only the initial\ncontrol input for safety while modeling its effects over the entire planning\nhorizon, enabling safe yet efficient navigation. We validate HumanMPC in both\nsimulated experiments using real human trajectories and in the real-world,\ndemonstrating its effectiveness across tasks ranging from goal-directed\nnavigation to visual servoing for human tracking. While we apply our method to\nMAVs in this work, it is generic and can be adapted by other platforms. Our\nresults show that the method ensures safety without excessive conservatism and\noutperforms baseline approaches in both efficiency and reliability.",
    "published": "2025-10-20T13:24:36Z",
    "updated": "2025-10-20T13:24:36Z",
    "link": "http://arxiv.org/pdf/2510.17525v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Simon Schaefer",
      "Helen Oleynikova",
      "Sandra Hirche",
      "Stefan Leutenegger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17456v1",
    "title": "Inverse Optimal Control of Muscle Force Sharing During Pathological Gait",
    "summary": "Muscle force sharing is typically resolved by minimizing a specific objective\nfunction to approximate neural control strategies. An inverse optimal control\napproach was applied to identify the \"best\" objective function, among a\npositive linear combination of basis objective functions, associated with the\ngait of two post-stroke males, one high-functioning (subject S1) and one\nlow-functioning (subject S2). It was found that the \"best\" objective function\nis subject- and leg-specific. No single function works universally well, yet\nthe best options are usually differently weighted combinations of muscle\nactivation- and power-minimization. Subject-specific inverse optimal control\nmodels performed best on their respective limbs (\\textbf{RMSE 178/213 N, CC\n0.71/0.61} for non-paretic and paretic legs of S1; \\textbf{RMSE 205/165 N, CC\n0.88/0.85} for respective legs of S2), but cross-subject generalization was\npoor, particularly for paretic legs. Moreover, minimizing the root mean square\nof muscle power emerged as important for paretic limbs, while minimizing\nactivation-based functions dominated for non-paretic limbs. This may suggest\ndifferent neural control strategies between affected and unaffected sides,\npossibly altered by the presence of spasticity. Among the 15 considered\nobjective functions commonly used in inverse dynamics-based computations, the\nroot mean square of muscle power was the only one explicitly incorporating\nmuscle velocity, leading to a possible model for spasticity in the paretic\nlimbs. Although this objective function has been rarely used, it may be\nrelevant for modeling pathological gait, such as post-stroke gait.",
    "published": "2025-10-20T11:41:30Z",
    "updated": "2025-10-20T11:41:30Z",
    "link": "http://arxiv.org/pdf/2510.17456v1.pdf",
    "category": [
      "physics.med-ph",
      "cs.RO",
      "cs.SY",
      "eess.SY",
      "math.OC"
    ],
    "authors": [
      "Filip BeÄanoviÄ",
      "Vincent Bonnet",
      "Kosta JovanoviÄ",
      "Samer Mohammed",
      "RaphaÃ«l Dumas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17448v1",
    "title": "A Generalization of Input-Output Linearization via Dynamic Switching\n  Between Melds of Output Functions",
    "summary": "This letter presents a systematic framework for switching between different\nsets of outputs for the control of nonlinear systems via feedback\nlinearization. We introduce the concept of a meld to formally define a valid,\nfeedback-linearizable subset of outputs that can be selected from a larger deck\nof possible outputs. The main contribution is a formal proof establishing that\nunder suitable dwell-time and compatibility conditions, it is possible to\nswitch between different melds while guaranteeing the uniform boundedness of\nthe system state. We further show that the error dynamics of the active outputs\nremain exponentially stable within each switching interval and that outputs\ncommon to consecutive melds are tracked seamlessly through transitions. The\nproposed theory is valid for any feedback linearizable nonlinear system, such\nas, e.g., robots, aerial and terrestrial vehicles, etc.. We demonstrate it on a\nsimple numerical simulation of a robotic manipulator.",
    "published": "2025-10-20T11:35:01Z",
    "updated": "2025-10-20T11:35:01Z",
    "link": "http://arxiv.org/pdf/2510.17448v1.pdf",
    "category": [
      "cs.RO",
      "math.DS"
    ],
    "authors": [
      "Mirko Mizzoni",
      "Pieter van Goor",
      "Barbara Bazzana",
      "Antonio Franchi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.16538v2",
    "title": "Leveraging Vision-Language Models for Open-Vocabulary Instance\n  Segmentation and Tracking",
    "summary": "Vision-language models (VLMs) excel in visual understanding but often lack\nreliable grounding capabilities and actionable inference rates. Integrating\nthem with open-vocabulary object detection (OVD), instance segmentation, and\ntracking leverages their strengths while mitigating these drawbacks. We utilize\nVLM-generated structured descriptions to identify visible object instances,\ncollect application-relevant attributes, and inform an open-vocabulary detector\nto extract corresponding bounding boxes that are passed to a video segmentation\nmodel providing segmentation masks and tracking. Once initialized, this model\ndirectly extracts segmentation masks, processing image streams in real time\nwith minimal computational overhead. Tracks can be updated online as needed by\ngenerating new structured descriptions and detections. This combines the\ndescriptive power of VLMs with the grounding capability of OVD and the\npixel-level understanding and speed of video segmentation. Our evaluation\nacross datasets and robotics platforms demonstrates the broad applicability of\nthis approach, showcasing its ability to extract task-specific attributes from\nnon-standard objects in dynamic environments. Code, data, videos, and\nbenchmarks are available at https://vlm-gist.github.io",
    "published": "2025-03-18T20:18:42Z",
    "updated": "2025-10-20T11:05:46Z",
    "link": "http://arxiv.org/pdf/2503.16538v2.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Bastian PÃ¤tzold",
      "Jan Nogga",
      "Sven Behnke"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17408v1",
    "title": "Integrating Trustworthy Artificial Intelligence with Energy-Efficient\n  Robotic Arms for Waste Sorting",
    "summary": "This paper presents a novel methodology that integrates trustworthy\nartificial intelligence (AI) with an energy-efficient robotic arm for\nintelligent waste classification and sorting. By utilizing a convolutional\nneural network (CNN) enhanced through transfer learning with MobileNetV2, the\nsystem accurately classifies waste into six categories: plastic, glass, metal,\npaper, cardboard, and trash. The model achieved a high training accuracy of\n99.8% and a validation accuracy of 80.5%, demonstrating strong learning and\ngeneralization. A robotic arm simulator is implemented to perform virtual\nsorting, calculating the energy cost for each action using Euclidean distance\nto ensure optimal and efficient movement. The framework incorporates key\nelements of trustworthy AI, such as transparency, robustness, fairness, and\nsafety, making it a reliable and scalable solution for smart waste management\nsystems in urban settings.",
    "published": "2025-10-20T10:52:02Z",
    "updated": "2025-10-20T10:52:02Z",
    "link": "http://arxiv.org/pdf/2510.17408v1.pdf",
    "category": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "authors": [
      "Halima I. Kure",
      "Jishna Retnakumari",
      "Augustine O. Nwajana",
      "Umar M. Ismail",
      "Bilyaminu A. Romo",
      "Ehigiator Egho-Promise"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.13639v3",
    "title": "4D Radar-Inertial Odometry based on Gaussian Modeling and\n  Multi-Hypothesis Scan Matching",
    "summary": "4D millimeter-wave (mmWave) radars are sensors that provide robustness\nagainst adverse weather conditions (rain, snow, fog, etc.), and as such they\nare increasingly used for odometry and SLAM (Simultaneous Location and\nMapping). However, the noisy and sparse nature of the returned scan data proves\nto be a challenging obstacle for existing registration algorithms, especially\nthose originally intended for more accurate sensors such as LiDAR. Following\nthe success of 3D Gaussian Splatting for vision, in this paper we propose a\nsummarized representation for radar scenes based on global simultaneous\noptimization of 3D Gaussians as opposed to voxel-based approaches, and\nleveraging its inherent probability distribution function for registration.\nMoreover, we propose tackling the problem of radar noise by optimizing multiple\nscan matching hypotheses in order to further increase the robustness of the\nsystem against local optima of the function. Finally, following existing\npractice we implement an Extended Kalman Filter-based Radar-Inertial Odometry\npipeline in order to evaluate the effectiveness of our system. Experiments\nusing publicly available 4D radar datasets show that our Gaussian approach is\ncomparable to existing registration algorithms, outperforming them in several\nsequences.",
    "published": "2024-12-18T09:11:24Z",
    "updated": "2025-10-20T10:33:29Z",
    "link": "http://arxiv.org/pdf/2412.13639v3.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Fernando Amodeo",
      "Luis Merino",
      "Fernando Caballero"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17341v1",
    "title": "Interactive Force-Impedance Control",
    "summary": "Human collaboration with robots requires flexible role adaptation, enabling\nrobot to switch between active leader and passive follower. Effective role\nswitching depends on accurately estimating human intention, which is typically\nachieved through external force analysis, nominal robot dynamics, or\ndata-driven approaches. However, these methods are primarily effective in\ncontact-sparse environments. When robots under hybrid or unified\nforce-impedance control physically interact with active humans or non-passive\nenvironments, the robotic system may lose passivity and thus compromise safety.\nTo address this challenge, this paper proposes the unified Interactive\nForce-Impedance Control (IFIC) framework that adapts to the interaction power\nflow, ensuring effortless and safe interaction in contact-rich environments.\nThe proposed control architecture is formulated within a port-Hamiltonian\nframework, incorporating both interaction and task control ports, through which\nsystem passivity is guaranteed.",
    "published": "2025-10-20T09:35:42Z",
    "updated": "2025-10-20T09:35:42Z",
    "link": "http://arxiv.org/pdf/2510.17341v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Fan Shao",
      "Satoshi Endo",
      "Sandra Hirche",
      "Fanny Ficuciello"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17335v1",
    "title": "DDBot: Differentiable Physics-based Digging Robot for Unknown Granular\n  Materials",
    "summary": "Automating the manipulation of granular materials poses significant\nchallenges due to complex contact dynamics, unpredictable material properties,\nand intricate system states. Existing approaches often fail to achieve\nefficiency and accuracy in such tasks. To fill the research gap, this paper\nstudies the small-scale and high-precision granular material digging task with\nunknown physical properties. A new framework, named differentiable digging\nrobot (DDBot), is proposed to manipulate granular materials, including sand and\nsoil.\n  Specifically, we equip DDBot with a differentiable physics-based simulator,\ntailored for granular material manipulation, powered by GPU-accelerated\nparallel computing and automatic differentiation. DDBot can perform efficient\ndifferentiable system identification and high-precision digging skill\noptimisation for unknown granular materials, which is enabled by a\ndifferentiable skill-to-action mapping, a task-oriented demonstration method,\ngradient clipping and line search-based gradient descent.\n  Experimental results show that DDBot can efficiently (converge within 5 to 20\nminutes) identify unknown granular material dynamics and optimise digging\nskills, with high-precision results in zero-shot real-world deployments,\nhighlighting its practicality. Benchmark results against state-of-the-art\nbaselines also confirm the robustness and efficiency of DDBot in such digging\ntasks.",
    "published": "2025-10-20T09:27:24Z",
    "updated": "2025-10-20T09:27:24Z",
    "link": "http://arxiv.org/pdf/2510.17335v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Xintong Yang",
      "Minglun Wei",
      "Ze Ji",
      "Yu-Kun Lai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17315v1",
    "title": "Implicit State Estimation via Video Replanning",
    "summary": "Video-based representations have gained prominence in planning and\ndecision-making due to their ability to encode rich spatiotemporal dynamics and\ngeometric relationships. These representations enable flexible and\ngeneralizable solutions for complex tasks such as object manipulation and\nnavigation. However, existing video planning frameworks often struggle to adapt\nto failures at interaction time due to their inability to reason about\nuncertainties in partially observed environments. To overcome these\nlimitations, we introduce a novel framework that integrates interaction-time\ndata into the planning process. Our approach updates model parameters online\nand filters out previously failed plans during generation. This enables\nimplicit state estimation, allowing the system to adapt dynamically without\nexplicitly modeling unknown state variables. We evaluate our framework through\nextensive experiments on a new simulated manipulation benchmark, demonstrating\nits ability to improve replanning performance and advance the field of\nvideo-based decision-making.",
    "published": "2025-10-20T09:02:25Z",
    "updated": "2025-10-20T09:02:25Z",
    "link": "http://arxiv.org/pdf/2510.17315v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Po-Chen Ko",
      "Jiayuan Mao",
      "Yu-Hsiang Fu",
      "Hsien-Jeng Yeh",
      "Chu-Rong Chen",
      "Wei-Chiu Ma",
      "Yilun Du",
      "Shao-Hua Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17270v1",
    "title": "Floating-Base Deep Lagrangian Networks",
    "summary": "Grey-box methods for system identification combine deep learning with\nphysics-informed constraints, capturing complex dependencies while improving\nout-of-distribution generalization. Yet, despite the growing importance of\nfloating-base systems such as humanoids and quadrupeds, current grey-box models\nignore their specific physical constraints. For instance, the inertia matrix is\nnot only positive definite but also exhibits branch-induced sparsity and input\nindependence. Moreover, the 6x6 composite spatial inertia of the floating base\ninherits properties of single-rigid-body inertia matrices. As we show, this\nincludes the triangle inequality on the eigenvalues of the composite rotational\ninertia. To address the lack of physical consistency in deep learning models of\nfloating-base systems, we introduce a parameterization of inertia matrices that\nsatisfies all these constraints. Inspired by Deep Lagrangian Networks (DeLaN),\nwe train neural networks to predict physically plausible inertia matrices that\nminimize inverse dynamics error under Lagrangian mechanics. For evaluation, we\ncollected and released a dataset on multiple quadrupeds and humanoids. In these\nexperiments, our Floating-Base Deep Lagrangian Networks (FeLaN) achieve highly\ncompetitive performance on both simulated and real robots, while providing\ngreater physical interpretability.",
    "published": "2025-10-20T07:57:57Z",
    "updated": "2025-10-20T07:57:57Z",
    "link": "http://arxiv.org/pdf/2510.17270v1.pdf",
    "category": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "authors": [
      "Lucas Schulze",
      "Juliano Decico Negri",
      "Victor Barasuol",
      "Vivian Suzano Medeiros",
      "Marcelo Becker",
      "Jan Peters",
      "Oleg Arenz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17249v1",
    "title": "An adaptive hierarchical control framework for quadrupedal robots in\n  planetary exploration",
    "summary": "Planetary exploration missions require robots capable of navigating extreme\nand unknown environments. While wheeled rovers have dominated past missions,\ntheir mobility is limited to traversable surfaces. Legged robots, especially\nquadrupeds, can overcome these limitations by handling uneven, obstacle-rich,\nand deformable terrains. However, deploying such robots in unknown conditions\nis challenging due to the need for environment-specific control, which is\ninfeasible when terrain and robot parameters are uncertain. This work presents\na modular control framework that combines model-based dynamic control with\nonline model adaptation and adaptive footstep planning to address uncertainties\nin both robot and terrain properties. The framework includes state estimation\nfor quadrupeds with and without contact sensing, supports runtime\nreconfiguration, and is integrated into ROS 2 with open-source availability.\nIts performance was validated on two quadruped platforms, multiple hardware\narchitectures, and in a volcano field test, where the robot walked over 700 m.",
    "published": "2025-10-20T07:37:49Z",
    "updated": "2025-10-20T07:37:49Z",
    "link": "http://arxiv.org/pdf/2510.17249v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Franek Stark",
      "Rohit Kumar",
      "Shubham Vyas",
      "Hannah Isermann",
      "Jonas Haack",
      "Mihaela Popescu",
      "Jakob Middelberg",
      "Dennis Mronga",
      "Frank Kirchner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17237v1",
    "title": "Pole-Image: A Self-Supervised Pole-Anchored Descriptor for Long-Term\n  LiDAR Localization and Map Maintenance",
    "summary": "Long-term autonomy for mobile robots requires both robust self-localization\nand reliable map maintenance. Conventional landmark-based methods face a\nfundamental trade-off between landmarks with high detectability but low\ndistinctiveness (e.g., poles) and those with high distinctiveness but difficult\nstable detection (e.g., local point cloud structures). This work addresses the\nchallenge of descriptively identifying a unique \"signature\" (local point cloud)\nby leveraging a detectable, high-precision \"anchor\" (like a pole). To solve\nthis, we propose a novel canonical representation, \"Pole-Image,\" as a hybrid\nmethod that uses poles as anchors to generate signatures from the surrounding\n3D structure. Pole-Image represents a pole-like landmark and its surrounding\nenvironment, detected from a LiDAR point cloud, as a 2D polar coordinate image\nwith the pole itself as the origin. This representation leverages the pole's\nnature as a high-precision reference point, explicitly encoding the \"relative\ngeometry\" between the stable pole and the variable surrounding point cloud. The\nkey advantage of pole landmarks is that \"detection\" is extremely easy. This\nease of detection allows the robot to easily track the same pole, enabling the\nautomatic and large-scale collection of diverse observational data (positive\npairs). This data acquisition feasibility makes \"Contrastive Learning (CL)\"\napplicable. By applying CL, the model learns a viewpoint-invariant and highly\ndiscriminative descriptor. The contributions are twofold: 1) The descriptor\novercomes perceptual aliasing, enabling robust self-localization. 2) The\nhigh-precision encoding enables high-sensitivity change detection, contributing\nto map maintenance.",
    "published": "2025-10-20T07:27:14Z",
    "updated": "2025-10-20T07:27:14Z",
    "link": "http://arxiv.org/pdf/2510.17237v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Wuhao Xie",
      "Kanji Tanaka"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17203v1",
    "title": "Performance Evaluation of an Integrated System for Visible Light\n  Communication and Positioning Using an Event Camera",
    "summary": "Event cameras, featuring high temporal resolution and high dynamic range,\noffer visual sensing capabilities comparable to conventional image sensors\nwhile capturing fast-moving objects and handling scenes with extreme lighting\ncontrasts such as tunnel exits. Leveraging these properties, this study\nproposes a novel self-localization system that integrates visible light\ncommunication (VLC) and visible light positioning (VLP) within a single event\ncamera. The system enables a vehicle to estimate its position even in\nGPS-denied environments, such as tunnels, by using VLC to obtain coordinate\ninformation from LED transmitters and VLP to estimate the distance to each\ntransmitter.\n  Multiple LEDs are installed on the transmitter side, each assigned a unique\npilot sequence based on Walsh-Hadamard codes. The event camera identifies\nindividual LEDs within its field of view by correlating the received signal\nwith these codes, allowing clear separation and recognition of each light\nsource. This mechanism enables simultaneous high-capacity MISO (multi-input\nsingle-output) communication through VLC and precise distance estimation via\nphase-only correlation (POC) between multiple LED pairs.\n  To the best of our knowledge, this is the first vehicle-mounted system to\nachieve simultaneous VLC and VLP functionalities using a single event camera.\nField experiments were conducted by mounting the system on a vehicle traveling\nat 30 km/h (8.3 m/s). The results demonstrated robust real-world performance,\nwith a root mean square error (RMSE) of distance estimation within 0.75 m for\nranges up to 100 m and a bit error rate (BER) below 0.01 across the same range.",
    "published": "2025-10-20T06:37:26Z",
    "updated": "2025-10-20T06:37:26Z",
    "link": "http://arxiv.org/pdf/2510.17203v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Ryota Soga",
      "Masataka Kobayashi",
      "Tsukasa Shimizu",
      "Shintaro Shiba",
      "Quan Kong",
      "Shan Lu",
      "Takaya Yamazato"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.06570v2",
    "title": "From Perception Logs to Failure Modes: Language-Driven Semantic\n  Clustering of Failures for Robot Safety",
    "summary": "As robotic systems become increasingly integrated into real-world\nenvironments -- ranging from autonomous vehicles to household assistants --\nthey inevitably encounter diverse and unstructured scenarios that lead to\nfailures. While such failures pose safety and reliability challenges, they also\nprovide rich perceptual data for improving future performance. However,\nmanually analyzing large-scale failure datasets is impractical. In this work,\nwe present a method for automatically organizing large-scale robotic failure\ndata into semantically meaningful failure clusters, enabling scalable learning\nfrom failure without human supervision. Our approach leverages the reasoning\ncapabilities of Multimodal Large Language Models (MLLMs), trained on\ninternet-scale data, to infer high-level failure causes from raw perceptual\ntrajectories and discover interpretable structure within uncurated failure\nlogs. These semantic clusters reveal patterns and hypothesized causes of\nfailure, enabling scalable learning from experience. We demonstrate that the\ndiscovered failure modes can guide targeted data collection for policy\nrefinement, accelerating iterative improvement in agent policies and overall\nsafety. Additionally, we show that these semantic clusters can benefit online\nfailure monitoring systems, offering a lightweight yet powerful safeguard for\nreal-time operation. We demonstrate that this framework enhances robot learning\nand robustness by transforming real-world failures into actionable and\ninterpretable signals for adaptation.",
    "published": "2025-06-06T22:50:39Z",
    "updated": "2025-10-20T06:14:23Z",
    "link": "http://arxiv.org/pdf/2506.06570v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Aryaman Gupta",
      "Yusuf Umut Ciftci",
      "Somil Bansal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17150v1",
    "title": "OmniVIC: A Self-Improving Variable Impedance Controller with\n  Vision-Language In-Context Learning for Safe Robotic Manipulation",
    "summary": "We present OmniVIC, a universal variable impedance controller (VIC) enhanced\nby a vision language model (VLM), which improves safety and adaptation in any\ncontact-rich robotic manipulation task to enhance safe physical interaction.\nTraditional VIC have shown advantages when the robot physically interacts with\nthe environment, but lack generalization in unseen, complex, and unstructured\nsafe interactions in universal task scenarios involving contact or uncertainty.\nTo this end, the proposed OmniVIC interprets task context derived reasoning\nfrom images and natural language and generates adaptive impedance parameters\nfor a VIC controller. Specifically, the core of OmniVIC is a self-improving\nRetrieval-Augmented Generation(RAG) and in-context learning (ICL), where RAG\nretrieves relevant prior experiences from a structured memory bank to inform\nthe controller about similar past tasks, and ICL leverages these retrieved\nexamples and the prompt of current task to query the VLM for generating\ncontext-aware and adaptive impedance parameters for the current manipulation\nscenario. Therefore, a self-improved RAG and ICL guarantee OmniVIC works in\nuniversal task scenarios. The impedance parameter regulation is further\ninformed by real-time force/torque feedback to ensure interaction forces remain\nwithin safe thresholds. We demonstrate that our method outperforms baselines on\na suite of complex contact-rich tasks, both in simulation and on real-world\nrobotic tasks, with improved success rates and reduced force violations.\nOmniVIC takes a step towards bridging high-level semantic reasoning and\nlow-level compliant control, enabling safer and more generalizable\nmanipulation. Overall, the average success rate increases from 27% (baseline)\nto 61.4% (OmniVIC).",
    "published": "2025-10-20T04:54:22Z",
    "updated": "2025-10-20T04:54:22Z",
    "link": "http://arxiv.org/pdf/2510.17150v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Heng Zhang",
      "Wei-Hsing Huang",
      "Gokhan Solak",
      "Arash Ajoudani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17148v1",
    "title": "DiffVLA++: Bridging Cognitive Reasoning and End-to-End Driving through\n  Metric-Guided Alignment",
    "summary": "Conventional end-to-end (E2E) driving models are effective at generating\nphysically plausible trajectories, but often fail to generalize to long-tail\nscenarios due to the lack of essential world knowledge to understand and reason\nabout surrounding environments. In contrast, Vision-Language-Action (VLA)\nmodels leverage world knowledge to handle challenging cases, but their limited\n3D reasoning capability can lead to physically infeasible actions. In this work\nwe introduce DiffVLA++, an enhanced autonomous driving framework that\nexplicitly bridges cognitive reasoning and E2E planning through metric-guided\nalignment. First, we build a VLA module directly generating semantically\ngrounded driving trajectories. Second, we design an E2E module with a dense\ntrajectory vocabulary that ensures physical feasibility. Third, and most\ncritically, we introduce a metric-guided trajectory scorer that guides and\naligns the outputs of the VLA and E2E modules, thereby integrating their\ncomplementary strengths. The experiment on the ICCV 2025 Autonomous Grand\nChallenge leaderboard shows that DiffVLA++ achieves EPDMS of 49.12.",
    "published": "2025-10-20T04:49:14Z",
    "updated": "2025-10-20T04:49:14Z",
    "link": "http://arxiv.org/pdf/2510.17148v1.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Yu Gao",
      "Yiru Wang",
      "Anqing Jiang",
      "Heng Yuwen",
      "Wang Shuo",
      "Sun Hao",
      "Wang Jijun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17143v1",
    "title": "Decentralized Real-Time Planning for Multi-UAV Cooperative Manipulation\n  via Imitation Learning",
    "summary": "Existing approaches for transporting and manipulating cable-suspended loads\nusing multiple UAVs along reference trajectories typically rely on either\ncentralized control architectures or reliable inter-agent communication. In\nthis work, we propose a novel machine learning based method for decentralized\nkinodynamic planning that operates effectively under partial observability and\nwithout inter-agent communication. Our method leverages imitation learning to\ntrain a decentralized student policy for each UAV by imitating a centralized\nkinodynamic motion planner with access to privileged global observations. The\nstudent policy generates smooth trajectories using physics-informed neural\nnetworks that respect the derivative relationships in motion. During training,\nthe student policies utilize the full trajectory generated by the teacher\npolicy, leading to improved sample efficiency. Moreover, each student policy\ncan be trained in under two hours on a standard laptop. We validate our method\nin both simulation and real-world environments to follow an agile reference\ntrajectory, demonstrating performance comparable to that of centralized\napproaches.",
    "published": "2025-10-20T04:35:54Z",
    "updated": "2025-10-20T04:35:54Z",
    "link": "http://arxiv.org/pdf/2510.17143v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Shantnav Agarwal",
      "Javier Alonso-Mora",
      "Sihao Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.16306v2",
    "title": "COMPASS: Cooperative Multi-Agent Persistent Monitoring using\n  Spatio-Temporal Attention Network",
    "summary": "Persistent monitoring of dynamic targets is essential in real-world\napplications such as disaster response, environmental sensing, and wildlife\nconservation, where mobile agents must continuously gather information under\nuncertainty. We propose COMPASS, a multi-agent reinforcement learning (MARL)\nframework that enables decentralized agents to persistently monitor multiple\nmoving targets efficiently. We model the environment as a graph, where nodes\nrepresent spatial locations and edges capture topological proximity, allowing\nagents to reason over structured layouts and revisit informative regions as\nneeded. Each agent independently selects actions based on a shared\nspatio-temporal attention network that we design to integrate historical\nobservations and spatial context. We model target dynamics using Gaussian\nProcesses (GPs), which support principled belief updates and enable\nuncertainty-aware planning. We train COMPASS using centralized value estimation\nand decentralized policy execution under an adaptive reward setting. Our\nextensive experiments demonstrate that COMPASS consistently outperforms strong\nbaselines in uncertainty reduction, target coverage, and coordination\nefficiency across dynamic multi-target scenarios.",
    "published": "2025-07-22T07:44:08Z",
    "updated": "2025-10-20T04:15:21Z",
    "link": "http://arxiv.org/pdf/2507.16306v2.pdf",
    "category": [
      "cs.MA",
      "cs.RO"
    ],
    "authors": [
      "Xingjian Zhang",
      "Yizhuo Wang",
      "Guillaume Sartoretti"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.03457v2",
    "title": "Optimal swimming with body compliance in an overdamped medium",
    "summary": "Elongate animals and robots use undulatory body waves to locomote through\ndiverse environments. Geometric mechanics provides a framework to model and\noptimize such systems in highly damped environments, connecting a prescribed\nshape change pattern (gait) with locomotion displacement. However, the\npractical applicability of controlling compliant physical robots remains to be\ndemonstrated. In this work, we develop a framework based on geometric mechanics\nto predict locomotor performance and search for optimal swimming strategies of\ncompliant swimmers. We introduce a compliant extension of Purcell's three-link\nswimmer by incorporating series-connected springs at the joints. Body dynamics\nare derived using resistive force theory. Geometric mechanics is incorporated\ninto movement prediction and into an optimization framework that identifies\nstrategies for controlling compliant swimmers to achieve maximal displacement.\nWe validate our framework on a physical cable-driven three-link limbless robot\nand demonstrate accurate prediction and optimization of locomotor performance\nunder varied programmed, state-dependent compliance in a granular medium. Our\nresults establish a systematic, physics-based approach for modeling and\ncontrolling compliant swimming locomotion, highlighting compliance as a design\nfeature that can be exploited for robust movement in both homogeneous and\nheterogeneous environments.",
    "published": "2025-10-03T19:25:12Z",
    "updated": "2025-10-20T03:58:07Z",
    "link": "http://arxiv.org/pdf/2510.03457v2.pdf",
    "category": [
      "cs.RO",
      "physics.app-ph"
    ],
    "authors": [
      "Jianfeng Lin",
      "Tianyu Wang",
      "Baxi Chong",
      "Matthew Fernandez",
      "Zhaochen Xu",
      "Daniel I. Goldman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.08408v2",
    "title": "Validation of collision-free spheres of Stewart-Gough platforms for\n  constant orientations using the Application Programming Interface of a CAD\n  software",
    "summary": "This paper presents a method of validation of the size of the largest\ncollision-free sphere (CFS) of a 6-6 Stewart-Gough platform manipulator (SGPM)\nfor a given orientation of its moving platform (MP) using the Application\nProgramming Interface (API) of a CAD software. The position of the MP is\nupdated via the API in an automated manner over a set of samples within a shell\nenclosing the surface of the CFS. For each pose of the manipulator, each pair\nof legs is investigated for mutual collisions. The CFS is considered safe or\nvalidated iff none of the points falling inside the CFS lead to a collision\nbetween any pair of legs. This approach can not only validate the safety of a\nprecomputed CFS, but also estimate the same for any spatial parallel\nmanipulator.",
    "published": "2025-10-09T16:27:40Z",
    "updated": "2025-10-20T03:08:14Z",
    "link": "http://arxiv.org/pdf/2510.08408v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Bibekananda Patra",
      "Rajeevlochana G. Chittawadigi",
      "Sandipan Bandyopadhyay"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17086v1",
    "title": "Learning to Design Soft Hands using Reward Models",
    "summary": "Soft robotic hands promise to provide compliant and safe interaction with\nobjects and environments. However, designing soft hands to be both compliant\nand functional across diverse use cases remains challenging. Although co-design\nof hardware and control better couples morphology to behavior, the resulting\nsearch space is high-dimensional, and even simulation-based evaluation is\ncomputationally expensive. In this paper, we propose a Cross-Entropy Method\nwith Reward Model (CEM-RM) framework that efficiently optimizes tendon-driven\nsoft robotic hands based on teleoperation control policy, reducing design\nevaluations by more than half compared to pure optimization while learning a\ndistribution of optimized hand designs from pre-collected teleoperation data.\nWe derive a design space for a soft robotic hand composed of flexural soft\nfingers and implement parallelized training in simulation. The optimized hands\nare then 3D-printed and deployed in the real world using both teleoperation\ndata and real-time teleoperation. Experiments in both simulation and hardware\ndemonstrate that our optimized design significantly outperforms baseline hands\nin grasping success rates across a diverse set of challenging objects.",
    "published": "2025-10-20T01:28:22Z",
    "updated": "2025-10-20T01:28:22Z",
    "link": "http://arxiv.org/pdf/2510.17086v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Xueqian Bai",
      "Nicklas Hansen",
      "Adabhav Singh",
      "Michael T. Tolley",
      "Yan Duan",
      "Pieter Abbeel",
      "Xiaolong Wang",
      "Sha Yi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.16953v1",
    "title": "Safe Payload Transfer with Ship-Mounted Cranes: A Robust Model\n  Predictive Control Approach",
    "summary": "Ensuring safe real-time control of ship-mounted cranes in unstructured\ntransportation environments requires handling multiple safety constraints while\nmaintaining effective payload transfer performance. Unlike traditional crane\nsystems, ship-mounted cranes are consistently subjected to significant external\ndisturbances affecting underactuated crane dynamics due to the ship's dynamic\nmotion response to harsh sea conditions, which can lead to robustness issues.\nTo tackle these challenges, we propose a robust and safe model predictive\ncontrol (MPC) framework and demonstrate it on a 5-DOF crane system, where a\nStewart platform simulates the external disturbances that ocean surface motions\nwould have on the supporting ship. The crane payload transfer operation must\navoid obstacles and accurately place the payload within a designated target\narea. We use a robust zero-order control barrier function (R-ZOCBF)-based\nsafety constraint in the nonlinear MPC to ensure safe payload positioning,\nwhile time-varying bounding boxes are utilized for collision avoidance. We\nintroduce a new optimization-based online robustness parameter adaptation\nscheme to reduce the conservativeness of R-ZOCBFs. Experimental trials on a\ncrane prototype demonstrate the overall performance of our safe control\napproach under significant perturbing motions of the crane base. While our\nfocus is on crane-facilitated transfer, the methods more generally apply to\nsafe robotically-assisted parts mating and parts insertion.",
    "published": "2025-10-19T18:13:33Z",
    "updated": "2025-10-19T18:13:33Z",
    "link": "http://arxiv.org/pdf/2510.16953v1.pdf",
    "category": [
      "eess.SY",
      "cs.RO",
      "cs.SY"
    ],
    "authors": [
      "Ersin Das",
      "William A. Welch",
      "Patrick Spieler",
      "Keenan Albee",
      "Aurelio Noca",
      "Jeffrey Edlund",
      "Jonathan Becktor",
      "Thomas Touma",
      "Jessica Todd",
      "Sriramya Bhamidipati",
      "Stella Kombo",
      "Maira Saboia",
      "Anna Sabel",
      "Grace Lim",
      "Rohan Thakker",
      "Amir Rahmani",
      "Joel W. Burdick"
    ]
  }
]