[
  {
    "id": "http://arxiv.org/abs/2512.02020v1",
    "title": "EfficientFlow: Efficient Equivariant Flow Policy Learning for Embodied AI",
    "summary": "Generative modeling has recently shown remarkable promise for visuomotor policy learning, enabling flexible and expressive control across diverse embodied AI tasks. However, existing generative policies often struggle with data inefficiency, requiring large-scale demonstrations, and sampling inefficiency, incurring slow action generation during inference. We introduce EfficientFlow, a unified framework for efficient embodied AI with flow-based policy learning. To enhance data efficiency, we bring equivariance into flow matching. We theoretically prove that when using an isotropic Gaussian prior and an equivariant velocity prediction network, the resulting action distribution remains equivariant, leading to improved generalization and substantially reduced data demands. To accelerate sampling, we propose a novel acceleration regularization strategy. As direct computation of acceleration is intractable for marginal flow trajectories, we derive a novel surrogate loss that enables stable and scalable training using only conditional trajectories. Across a wide range of robotic manipulation benchmarks, the proposed algorithm achieves competitive or superior performance under limited data while offering dramatically faster inference. These results highlight EfficientFlow as a powerful and efficient paradigm for high-performance embodied AI.",
    "published": "2025-12-01T18:59:59Z",
    "updated": "2025-12-01T18:59:59Z",
    "link": "http://arxiv.org/pdf/2512.02020v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Jianlei Chang",
      "Ruofeng Mei",
      "Wei Ke",
      "Xiangyu Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.02019v1",
    "title": "A Diffusion Model Framework for Maximum Entropy Reinforcement Learning",
    "summary": "Diffusion models have achieved remarkable success in data-driven learning and in sampling from complex, unnormalized target distributions. Building on this progress, we reinterpret Maximum Entropy Reinforcement Learning (MaxEntRL) as a diffusion model-based sampling problem. We tackle this problem by minimizing the reverse Kullback-Leibler (KL) divergence between the diffusion policy and the optimal policy distribution using a tractable upper bound. By applying the policy gradient theorem to this objective, we derive a modified surrogate objective for MaxEntRL that incorporates diffusion dynamics in a principled way. This leads to simple diffusion-based variants of Soft Actor-Critic (SAC), Proximal Policy Optimization (PPO) and Wasserstein Policy Optimization (WPO), termed DiffSAC, DiffPPO and DiffWPO. All of these methods require only minor implementation changes to their base algorithm. We find that on standard continuous control benchmarks, DiffSAC, DiffPPO and DiffWPO achieve better returns and higher sample efficiency than SAC and PPO.",
    "published": "2025-12-01T18:59:58Z",
    "updated": "2025-12-01T18:59:58Z",
    "link": "http://arxiv.org/pdf/2512.02019v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "authors": [
      "Sebastian Sanokowski",
      "Kaustubh Patil",
      "Alois Knoll"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.02017v1",
    "title": "Visual Sync: Multi-Camera Synchronization via Cross-View Object Motion",
    "summary": "Today, people can easily record memorable moments, ranging from concerts, sports events, lectures, family gatherings, and birthday parties with multiple consumer cameras. However, synchronizing these cross-camera streams remains challenging. Existing methods assume controlled settings, specific targets, manual correction, or costly hardware. We present VisualSync, an optimization framework based on multi-view dynamics that aligns unposed, unsynchronized videos at millisecond accuracy. Our key insight is that any moving 3D point, when co-visible in two cameras, obeys epipolar constraints once properly synchronized. To exploit this, VisualSync leverages off-the-shelf 3D reconstruction, feature matching, and dense tracking to extract tracklets, relative poses, and cross-view correspondences. It then jointly minimizes the epipolar error to estimate each camera's time offset. Experiments on four diverse, challenging datasets show that VisualSync outperforms baseline methods, achieving an median synchronization error below 50 ms.",
    "published": "2025-12-01T18:59:57Z",
    "updated": "2025-12-01T18:59:57Z",
    "link": "http://arxiv.org/pdf/2512.02017v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "authors": [
      "Shaowei Liu",
      "David Yifan Yao",
      "Saurabh Gupta",
      "Shenlong Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01996v1",
    "title": "Learning Sim-to-Real Humanoid Locomotion in 15 Minutes",
    "summary": "Massively parallel simulation has reduced reinforcement learning (RL) training time for robots from days to minutes. However, achieving fast and reliable sim-to-real RL for humanoid control remains difficult due to the challenges introduced by factors such as high dimensionality and domain randomization. In this work, we introduce a simple and practical recipe based on off-policy RL algorithms, i.e., FastSAC and FastTD3, that enables rapid training of humanoid locomotion policies in just 15 minutes with a single RTX 4090 GPU. Our simple recipe stabilizes off-policy RL algorithms at massive scale with thousands of parallel environments through carefully tuned design choices and minimalist reward functions. We demonstrate rapid end-to-end learning of humanoid locomotion controllers on Unitree G1 and Booster T1 robots under strong domain randomization, e.g., randomized dynamics, rough terrain, and push perturbations, as well as fast training of whole-body human-motion tracking policies. We provide videos and open-source implementation at: https://younggyo.me/fastsac-humanoid.",
    "published": "2025-12-01T18:55:17Z",
    "updated": "2025-12-01T18:55:17Z",
    "link": "http://arxiv.org/pdf/2512.01996v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Younggyo Seo",
      "Carmelo Sferrazza",
      "Juyue Chen",
      "Guanya Shi",
      "Rocky Duan",
      "Pieter Abbeel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01993v1",
    "title": "RoaD: Rollouts as Demonstrations for Closed-Loop Supervised Fine-Tuning of Autonomous Driving Policies",
    "summary": "Autonomous driving policies are typically trained via open-loop behavior cloning of human demonstrations. However, such policies suffer from covariate shift when deployed in closed loop, leading to compounding errors. We introduce Rollouts as Demonstrations (RoaD), a simple and efficient method to mitigate covariate shift by leveraging the policy's own closed-loop rollouts as additional training data. During rollout generation, RoaD incorporates expert guidance to bias trajectories toward high-quality behavior, producing informative yet realistic demonstrations for fine-tuning. This approach enables robust closed-loop adaptation with orders of magnitude less data than reinforcement learning, and avoids restrictive assumptions of prior closed-loop supervised fine-tuning (CL-SFT) methods, allowing broader applications domains including end-to-end driving. We demonstrate the effectiveness of RoaD on WOSAC, a large-scale traffic simulation benchmark, where it performs similar or better than the prior CL-SFT method; and in AlpaSim, a high-fidelity neural reconstruction-based simulator for end-to-end driving, where it improves driving score by 41\\% and reduces collisions by 54\\%.",
    "published": "2025-12-01T18:52:03Z",
    "updated": "2025-12-01T18:52:03Z",
    "link": "http://arxiv.org/pdf/2512.01993v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Guillermo Garcia-Cobo",
      "Maximilian Igl",
      "Peter Karkus",
      "Zhejun Zhang",
      "Michael Watson",
      "Yuxiao Chen",
      "Boris Ivanovic",
      "Marco Pavone"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01992v1",
    "title": "LLM CHESS: Benchmarking Reasoning and Instruction-Following in LLMs through Chess",
    "summary": "We introduce LLM CHESS, an evaluation framework designed to probe the generalization of reasoning and instruction-following abilities in large language models (LLMs) through extended agentic interaction in the domain of chess. We rank over 50 open and closed source models by playing against a random opponent using a range of behavioral metrics, including win and loss rates, move quality, move legality, hallucinated actions, and game duration. For a subset of top reasoning models, we derive an Elo estimate by playing against a chess engine with variably configured skill, which allows for comparisons between models in an easily understandable way. Despite the simplicity of the instruction-following task and the weakness of the opponent, many state-of-the-art models struggle to complete games or achieve consistent wins. Similar to other benchmarks on complex reasoning tasks, our experiments reveal a clear separation between reasoning and non-reasoning models. However, unlike existing static benchmarks, the stochastic and dynamic nature of LLM CHESS uniquely reduces overfitting and memorization while preventing benchmark saturation, proving difficult even for top reasoning models. To support future work on evaluating reasoning and instruction-following in LLMs, we release our experimental framework, a public leaderboard, and a dataset of associated games.",
    "published": "2025-12-01T18:51:08Z",
    "updated": "2025-12-01T18:51:08Z",
    "link": "http://arxiv.org/pdf/2512.01992v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Sai Kolasani",
      "Maxim Saplin",
      "Nicholas Crispino",
      "Kyle Montgomery",
      "Jared Quincy Davis",
      "Matei Zaharia",
      "Chi Wang",
      "Chenguang Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.25721v3",
    "title": "The AI Productivity Index (APEX)",
    "summary": "We present an extended version of the AI Productivity Index (APEX-v1-extended), a benchmark for assessing whether frontier models are capable of performing economically valuable tasks in four jobs: investment banking associate, management consultant, big law associate, and primary care physician (MD). This technical report details the extensions to APEX-v1, including an increase in the held-out evaluation set from n = 50 to n = 100 cases per job (n = 400 total) and updates to the grading methodology. We present a new leaderboard, where GPT5 (Thinking = High) remains the top performing model with a score of 67.0%. APEX-v1-extended shows that frontier models still have substantial limitations when performing typical professional tasks. To support further research, we are open sourcing n = 25 non-benchmark example cases per role (n = 100 total) along with our evaluation harness.",
    "published": "2025-09-30T03:26:17Z",
    "updated": "2025-12-01T18:46:32Z",
    "link": "http://arxiv.org/pdf/2509.25721v3.pdf",
    "category": [
      "econ.GN",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "authors": [
      "Bertie Vidgen",
      "Abby Fennelly",
      "Evan Pinnix",
      "Julien Bencheck",
      "Daniyal Khan",
      "Zach Richards",
      "Austin Bridges",
      "Calix Huang",
      "Ben Hunsberger",
      "Isaac Robinson",
      "Akul Datta",
      "Chirag Mahapatra",
      "Dominic Barton",
      "Cass R. Sunstein",
      "Eric Topol",
      "Brendan Foody",
      "Osvald Nitski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01987v1",
    "title": "Forecasting in Offline Reinforcement Learning for Non-stationary Environments",
    "summary": "Offline Reinforcement Learning (RL) provides a promising avenue for training policies from pre-collected datasets when gathering additional interaction data is infeasible. However, existing offline RL methods often assume stationarity or only consider synthetic perturbations at test time, assumptions that often fail in real-world scenarios characterized by abrupt, time-varying offsets. These offsets can lead to partial observability, causing agents to misperceive their true state and degrade performance. To overcome this challenge, we introduce Forecasting in Non-stationary Offline RL (FORL), a framework that unifies (i) conditional diffusion-based candidate state generation, trained without presupposing any specific pattern of future non-stationarity, and (ii) zero-shot time-series foundation models. FORL targets environments prone to unexpected, potentially non-Markovian offsets, requiring robust agent performance from the onset of each episode. Empirical evaluations on offline RL benchmarks, augmented with real-world time-series data to simulate realistic non-stationarity, demonstrate that FORL consistently improves performance compared to competitive baselines. By integrating zero-shot forecasting with the agent's experience, we aim to bridge the gap between offline RL and the complexities of real-world, non-stationary environments.",
    "published": "2025-12-01T18:45:05Z",
    "updated": "2025-12-01T18:45:05Z",
    "link": "http://arxiv.org/pdf/2512.01987v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "authors": [
      "Suzan Ece Ada",
      "Georg Martius",
      "Emre Ugur",
      "Erhan Oztop"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.12286v4",
    "title": "The SWE-Bench Illusion: When State-of-the-Art LLMs Remember Instead of Reason",
    "summary": "As large language models (LLMs) become increasingly capable and widely adopted, benchmarks play a central role in assessing their practical utility. For example, SWE-Bench Verified has emerged as a critical benchmark for evaluating LLMs' software engineering abilities, particularly their aptitude for resolving real-world GitHub issues. Recent LLMs show impressive performance on SWE-Bench, leading to optimism about their capacity for complex coding tasks. However, current evaluation protocols may overstate these models' true capabilities. It is crucial to distinguish LLMs' generalizable problem-solving ability and other learned artifacts. In this work, we introduce two diagnostic tasks: file path identification from issue descriptions alone and ground truth function reproduction with only the current file context and issue description to probe models' underlying knowledge. We present empirical evidence that performance gains on SWE-Bench-Verified may be partially driven by memorization rather than genuine problem-solving. We show that state-of-the-art models achieve up to 76% accuracy in identifying buggy file paths using only issue descriptions, without access to repository structure. This performance is merely up to 53% on tasks from repositories not included in SWE-Bench, pointing to possible data contamination or memorization. Similar patterns are also observed for the function reproduction task, where the verbatim similarity is much higher on SWE-Bench Verified than on other similar coding benchmarks (up to 35% consecutive 5-gram accuracy on SWE-Bench Verified and Full, but only up to 18% for tasks in other benchmarks). These findings raise concerns about the validity of existing results and underscore the need for more robust, contamination-resistant benchmarks to reliably evaluate LLMs' coding abilities.",
    "published": "2025-06-14T00:25:26Z",
    "updated": "2025-12-01T18:42:11Z",
    "link": "http://arxiv.org/pdf/2506.12286v4.pdf",
    "category": [
      "cs.AI",
      "cs.SE"
    ],
    "authors": [
      "Shanchao Liang",
      "Spandan Garg",
      "Roshanak Zilouchian Moghaddam"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01979v1",
    "title": "Chain-of-Ground: Improving GUI Grounding via Iterative Reasoning and Reference Feedback",
    "summary": "GUI grounding aims to align natural language instructions with precise regions in complex user interfaces. Advanced multimodal large language models show strong ability in visual GUI grounding but still struggle with small or visually similar targets and ambiguity in real world layouts. These limitations arise from limited grounding capacity and from underuse of existing reasoning potential. We present Chain of Ground CoG a training free multi step grounding framework that uses multimodal large language models for iterative visual reasoning and refinement. Instead of direct prediction the model progressively reflects and adjusts its hypotheses leading to more accurate and interpretable localization. Our approach achieves 68.4 accuracy on the ScreenSpot Pro benchmark an improvement of 4.8 points. To measure real world generalization we introduce TPanel UI a dataset of 420 labeled industrial control panels with visual distortions such as blur and masking. On TPanel UI Chain of Ground improves over the strong baseline Qwen3 VL 235B by 6.9 points showing the effectiveness of multi step training free grounding across real world and digital interfaces. These results highlight a direction for unlocking grounding potential through structured iterative refinement instead of additional training.",
    "published": "2025-12-01T18:37:19Z",
    "updated": "2025-12-01T18:37:19Z",
    "link": "http://arxiv.org/pdf/2512.01979v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "authors": [
      "Aiden Yiliu Li",
      "Bizhi Yu",
      "Daoan Lei",
      "Tianhe Ren",
      "Shilong Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01977v1",
    "title": "AI-Driven Optimization under Uncertainty for Mineral Processing Operations",
    "summary": "The global capacity for mineral processing must expand rapidly to meet the demand for critical minerals, which are essential for building the clean energy technologies necessary to mitigate climate change. However, the efficiency of mineral processing is severely limited by uncertainty, which arises from both the variability of feedstock and the complexity of process dynamics. To optimize mineral processing circuits under uncertainty, we introduce an AI-driven approach that formulates mineral processing as a Partially Observable Markov Decision Process (POMDP). We demonstrate the capabilities of this approach in handling both feedstock uncertainty and process model uncertainty to optimize the operation of a simulated, simplified flotation cell as an example. We show that by integrating the process of information gathering (i.e., uncertainty reduction) and process optimization, this approach has the potential to consistently perform better than traditional approaches at maximizing an overall objective, such as net present value (NPV). Our methodological demonstration of this optimization-under-uncertainty approach for a synthetic case provides a mathematical and computational framework for later real-world application, with the potential to improve both the laboratory-scale design of experiments and industrial-scale operation of mineral processing circuits without any additional hardware.",
    "published": "2025-12-01T18:35:54Z",
    "updated": "2025-12-01T18:35:54Z",
    "link": "http://arxiv.org/pdf/2512.01977v1.pdf",
    "category": [
      "eess.SY",
      "cs.AI"
    ],
    "authors": [
      "William Xu",
      "Amir Eskanlou",
      "Mansur Arief",
      "David Zhen Yin",
      "Jef K. Caers"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.20405v2",
    "title": "SCOPE-MRI: Bankart Lesion Detection as a Case Study in Data Curation and Deep Learning for Challenging Diagnoses",
    "summary": "Deep learning has shown strong performance in musculoskeletal imaging, but prior work has largely targeted conditions where diagnosis is relatively straightforward. More challenging problems remain underexplored, such as detecting Bankart lesions (anterior-inferior glenoid labral tears) on standard MRIs. These lesions are difficult to diagnose due to subtle imaging features, often necessitating invasive MRI arthrograms (MRAs). We introduce ScopeMRI, the first publicly available, expert-annotated dataset for shoulder pathologies, and present a deep learning framework for Bankart lesion detection on both standard MRIs and MRAs. ScopeMRI contains shoulder MRIs from patients who underwent arthroscopy, providing ground-truth labels from intraoperative findings, the diagnostic gold standard. Separate models were trained for MRIs and MRAs using CNN- and transformer-based architectures, with predictions ensembled across multiple imaging planes. Our models achieved radiologist-level performance, with accuracy on standard MRIs surpassing radiologists interpreting MRAs. External validation on independent hospital data demonstrated initial generalizability across imaging protocols. By releasing ScopeMRI and a modular codebase for training and evaluation, we aim to accelerate research in musculoskeletal imaging and foster development of datasets and models that address clinically challenging diagnostic tasks.",
    "published": "2025-04-29T04:02:44Z",
    "updated": "2025-12-01T18:35:53Z",
    "link": "http://arxiv.org/pdf/2504.20405v2.pdf",
    "category": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Sahil Sethi",
      "Sai Reddy",
      "Mansi Sakarvadia",
      "Jordan Serotte",
      "Darlington Nwaudo",
      "Nicholas Maassen",
      "Lewis Shi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01970v1",
    "title": "From Atomic to Composite: Reinforcement Learning Enables Generalization in Complementary Reasoning",
    "summary": "The mechanism by which RL contributes to reasoning capabilities-whether it incentivizes the synthesis of new skills or merely amplifies existing behaviors-remains a subject of intense debate. In this work, we investigate this question through the lens of Complementary Reasoning, a complex task that requires integrating internal parametric knowledge with external contextual information. Using a controlled synthetic dataset of human biographies, we strictly decouple this ability into two atomic skills: Parametric Reasoning (relying on internal knowledge) and Contextual Reasoning (depending on external information). To rigorously assess capability boundaries, we evaluate generalization across three distinct levels of difficulty: I.I.D., Composition, and Zero-shot settings. We find that while SFT is sufficient for in-distribution performance, it struggles with O.O.D. generalization, particularly in Zero-shot settings where relational combinations are novel. Crucially, we identify the SFT Generalization Paradox: Models supervised solely on the composite task achieve near-perfect in-distribution accuracy but collapse on out-of-distribution generalization, indicating their reliance on rote memorization of path shortcuts. In contrast, we find that RL acts as a reasoning synthesizer rather than a probability amplifier. However, we uncover a strict atomic prerequisite: RL can only synthesize these complex strategies if the base model has first mastered the independent atomic skills (Parametric and Contextual) via SFT. These findings challenge the view of RL as a mere amplifier, suggesting that given sufficient atomic foundations, RL can actively synthesize complex reasoning strategies from learned primitives without explicit supervision on such complex strategies. This indicates that decoupled atomic training followed by RL offers a scalable path to generalization for complex reasoning tasks.",
    "published": "2025-12-01T18:27:25Z",
    "updated": "2025-12-01T18:27:25Z",
    "link": "http://arxiv.org/pdf/2512.01970v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Sitao Cheng",
      "Xunjian Yin",
      "Ruiwen Zhou",
      "Yuxuan Li",
      "Xinyi Wang",
      "Liangming Pan",
      "William Yang Wang",
      "Victor Zhong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2210.12590v2",
    "title": "Meta-Reinforcement Learning for Building Energy Management System",
    "summary": "The building sector is one of the largest contributors to global energy consumption. Improving its energy efficiency is essential for reducing operational costs and greenhouse gas emissions. Energy management systems (EMS) play a key role in monitoring and controlling building appliances efficiently and reliably. With the increasing integration of renewable energy, intelligent EMS solutions have received growing attention. Reinforcement learning (RL) has recently been explored for this purpose and shows strong potential. However, most RL-based EMS methods require a large number of training steps to learn effective control policies, especially when adapting to unseen buildings, which limits their practical deployment. This paper introduces MetaEMS, a meta-reinforcement learning framework for EMS. MetaEMS improves learning efficiency by transferring knowledge from previously solved tasks to new ones through group-level and building-level adaptation, enabling fast adaptation and effective control across diverse building environments. Experimental results demonstrate that MetaEMS adapts more rapidly to unseen buildings and consistently outperforms baseline methods across various scenarios.",
    "published": "2022-10-23T01:56:30Z",
    "updated": "2025-12-01T18:22:25Z",
    "link": "http://arxiv.org/pdf/2210.12590v2.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "eess.SY"
    ],
    "authors": [
      "Benoit Boulet Huiliang Zhang",
      "Di Wu",
      "Arnaud Zinflou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.11967v3",
    "title": "Securing the Skies: A Comprehensive Survey on Anti-UAV Methods, Benchmarking, and Future Directions",
    "summary": "Unmanned Aerial Vehicles (UAVs) are indispensable for infrastructure inspection, surveillance, and related tasks, yet they also introduce critical security challenges. This survey provides a wide-ranging examination of the anti-UAV domain, centering on three core objectives-classification, detection, and tracking-while detailing emerging methodologies such as diffusion-based data synthesis, multi-modal fusion, vision-language modeling, self-supervised learning, and reinforcement learning. We systematically evaluate state-of-the-art solutions across both single-modality and multi-sensor pipelines (spanning RGB, infrared, audio, radar, and RF) and discuss large-scale as well as adversarially oriented benchmarks. Our analysis reveals persistent gaps in real-time performance, stealth detection, and swarm-based scenarios, underscoring pressing needs for robust, adaptive anti-UAV systems. By highlighting open research directions, we aim to foster innovation and guide the development of next-generation defense strategies in an era marked by the extensive use of UAVs.",
    "published": "2025-04-16T10:58:33Z",
    "updated": "2025-12-01T18:22:15Z",
    "link": "http://arxiv.org/pdf/2504.11967v3.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "authors": [
      "Yifei Dong",
      "Fengyi Wu",
      "Sanjian Zhang",
      "Guangyu Chen",
      "Yuzhi Hu",
      "Masumi Yano",
      "Jingdong Sun",
      "Siyu Huang",
      "Feng Liu",
      "Qi Dai",
      "Zhi-Qi Cheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.05276v3",
    "title": "SpikingBrain: Spiking Brain-inspired Large Models",
    "summary": "Mainstream Transformer-based large language models face major efficiency bottlenecks: training computation scales quadratically with sequence length, and inference memory grows linearly, limiting long-context processing. Building large models on non-NVIDIA platforms also poses challenges for stable and efficient training. To address this, we introduce SpikingBrain, a family of brain-inspired models designed for efficient long-context training and inference. SpikingBrain leverages the MetaX GPU cluster and focuses on three aspects: (1) Model Architecture: linear and hybrid-linear attention architectures with adaptive spiking neurons; (2) Algorithmic Optimizations: an efficient, conversion-based training pipeline and a dedicated spike coding framework; (3) System Engineering: customized training frameworks, operator libraries, and parallelism strategies tailored to MetaX hardware.\n  Using these techniques, we develop two models: SpikingBrain-7B, a linear LLM, and SpikingBrain-76B, a hybrid-linear MoE LLM. These models demonstrate the feasibility of large-scale LLM development on non-NVIDIA platforms, and training remains stable for weeks on hundreds of MetaX GPUs with Model FLOPs Utilization at expected levels. SpikingBrain achieves performance comparable to open-source Transformer baselines while using only about 150B tokens for continual pre-training. Our models also significantly improve long-context efficiency and deliver inference with (partially) constant memory and event-driven spiking behavior. For example, SpikingBrain-7B attains over 100x speedup in Time to First Token for 4M-token sequences. Furthermore, the proposed spiking scheme achieves 69.15 percent sparsity, enabling low-power operation. Overall, this work demonstrates the potential of brain-inspired mechanisms to drive the next generation of efficient and scalable large model design.",
    "published": "2025-09-05T17:34:00Z",
    "updated": "2025-12-01T18:21:21Z",
    "link": "http://arxiv.org/pdf/2509.05276v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Yuqi Pan",
      "Yupeng Feng",
      "Jinghao Zhuang",
      "Siyu Ding",
      "Han Xu",
      "Zehao Liu",
      "Bohan Sun",
      "Yuhong Chou",
      "Xuerui Qiu",
      "Anlin Deng",
      "Anjie Hu",
      "Shurong Wang",
      "Peng Zhou",
      "Man Yao",
      "Jibin Wu",
      "Jian Yang",
      "Guoliang Sun",
      "Bo Xu",
      "Guoqi Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.13068v2",
    "title": "NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models",
    "summary": "Electroencephalography (EEG) captures neural activity across multiple temporal and spectral scales, yielding signals that are rich but complex for representation learning. Recently, EEG foundation models trained to predict masked signal-tokens have shown promise for learning generalizable representations. However, their performance is hindered by their signal tokenization modules. Existing neural tokenizers fail to preserve high-frequency dynamics, limiting their ability to reconstruct EEG signals with high fidelity. We introduce NeuroRVQ, a scalable Large Brainwave Model (LBM) centered on a codebook-based tokenizer. Our tokenizer integrates: (i) multi-scale feature extraction modules that capture the full frequency neural spectrum; (ii) hierarchical residual vector quantization (RVQ) codebooks for high-resolution encoding; and, (iii) an EEG signal phase- and amplitude-aware loss function for efficient training. This design enables efficient EEG compression while supporting accurate reconstruction across all frequency bands, leading to robust generative masked modeling. Our empirical results demonstrate that NeuroRVQ achieves lower reconstruction error and outperforms existing LBMs on a variety of downstream tasks. More broadly, NeuroRVQ tokenizer establishes a strong prior for codebook-based general-purpose brainwave models, enabling advances in neural decoding, generative modeling and multimodal biosignal integration.",
    "published": "2025-10-15T01:26:52Z",
    "updated": "2025-12-01T18:14:58Z",
    "link": "http://arxiv.org/pdf/2510.13068v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.HC"
    ],
    "authors": [
      "Konstantinos Barmpas",
      "Na Lee",
      "Alexandros Koliousis",
      "Yannis Panagakis",
      "Dimitrios A. Adamos",
      "Nikolaos Laskaris",
      "Stefanos Zafeiriou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.17989v4",
    "title": "Outcome-based Reinforcement Learning to Predict the Future",
    "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has been an effective approach for improving Large Language Models' reasoning in domains such as coding and mathematics. Here, we apply RLVR methods towards forecasting future real-world events - a challenging task for RL due to the very noisy (and delayed) outcomes involved. Using a novel dataset of recent questions from a prediction market, and accompanying relevant news headlines, we show that a compact (14B) reasoning model can be trained to match or surpass the predictive accuracy of frontier models like o1, while greatly improving probabilistic calibration. The model's performance is also practically meaningful: in a Polymarket trading simulation, we estimate that its bets would have yielded a return on investment of over 10% across all questions in the test set. We detail and compare approaches used in training our model, including augmenting our training-data with synthetic prediction questions, guardrails for learning stability, and median prediction sampling at inference-time.",
    "published": "2025-05-23T14:56:07Z",
    "updated": "2025-12-01T18:12:07Z",
    "link": "http://arxiv.org/pdf/2505.17989v4.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Benjamin Turtel",
      "Danny Franklin",
      "Kris Skotheim",
      "Luke Hewitt",
      "Philipp Schoenegger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01958v1",
    "title": "Learned-Rule-Augmented Large Language Model Evaluators",
    "summary": "Large language models (LLMs) are predominantly used as evaluators for natural language generation (NLG) tasks, but their application to broader evaluation scenarios remains limited. In this work, we explore the potential of LLMs as general evaluators across diverse tasks. Although LLM-based evaluators have made progress in different areas, existing methods struggle to generalize due to their reliance on costly, human-designed evaluation principles, which are often misaligned with both annotated data and LLMs' understanding.To address these challenges, we propose a rule-augmented evaluation paradigm. First, we introduce a rule distillation method that automatically extracts scoring rules from data using an LLM-assisted Monte Carlo Tree Search (MCTS), alleviating scalability issues and improving alignment with data. Second, to enable LLMs to effectively apply the learned rules, we propose two strategies: (1) Chain-of-Rule (CoR), which guides LLM to follow distilled rules, and (2) training a rule-augmented LLM evaluator (RuAE) via reinforcement learning, further bridging the gap between rules and LLMs' reasoning. Extensive experiments on diverse tasks demonstrate the effectiveness and generalizability of our approach across various evaluation scenarios.",
    "published": "2025-12-01T18:08:45Z",
    "updated": "2025-12-01T18:08:45Z",
    "link": "http://arxiv.org/pdf/2512.01958v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Jie Meng",
      "Jin Mao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01952v1",
    "title": "GrndCtrl: Grounding World Models via Self-Supervised Reward Alignment",
    "summary": "Recent advances in video world modeling have enabled large-scale generative models to simulate embodied environments with high visual fidelity, providing strong priors for prediction, planning, and control. Yet, despite their realism, these models often lack geometric grounding, limiting their use in navigation tasks that require spatial coherence and long-horizon stability. We introduce Reinforcement Learning with World Grounding (RLWG), a self-supervised post-training framework that aligns pretrained world models with a physically verifiable structure through geometric and perceptual rewards. Analogous to reinforcement learning from verifiable feedback (RLVR) in language models, RLWG can use multiple rewards that measure pose cycle-consistency, depth reprojection, and temporal coherence. We instantiate this framework with GrndCtrl, a reward-aligned adaptation method based on Group Relative Policy Optimization (GRPO), yielding world models that maintain stable trajectories, consistent geometry, and reliable rollouts for embodied navigation. Like post-training alignment in large language models, GrndCtrl leverages verifiable rewards to bridge generative pretraining and grounded behavior, achieving superior spatial coherence and navigation stability over supervised fine-tuning in outdoor environments.",
    "published": "2025-12-01T18:03:29Z",
    "updated": "2025-12-01T18:03:29Z",
    "link": "http://arxiv.org/pdf/2512.01952v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "authors": [
      "Haoyang He",
      "Jay Patrikar",
      "Dong-Ki Kim",
      "Max Smith",
      "Daniel McGann",
      "Ali-akbar Agha-mohammadi",
      "Shayegan Omidshafiei",
      "Sebastian Scherer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01945v1",
    "title": "Agentic Policy Optimization via Instruction-Policy Co-Evolution",
    "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has advanced the reasoning capability of large language models (LLMs), enabling autonomous agents that can conduct effective multi-turn and tool-integrated reasoning. While instructions serve as the primary protocol for defining agents, RLVR typically relies on static and manually designed instructions. However, those instructions may be suboptimal for the base model, and the optimal instruction may change as the agent's policy improves and explores the interaction with the environment. To bridge the gap, we introduce INSPO, a novel Instruction-Policy co-evolution framework that integrates instruction optimization as a dynamic component of the reinforcement learning (RL) loop. INSPO maintains a dynamic population of instruction candidates that are sampled with questions, where reward signals in RL loops are automatically attributed to each instruction, and low performers are periodically pruned. New instructions are generated and verified through an on-policy reflection mechanism, where an LLM-based optimizer analyzes past experience from a replay buffer and evolves more effective strategies given the current policy. We conduct extensive experiments on multi-turn retrieval and reasoning tasks, demonstrating that INSPO substantially outperforms strong baselines relying on static instructions. INSPO discovers innovative instructions that guide the agent toward more strategic reasoning paths, achieving substantial performance gains with only a marginal increase in computational overhead.",
    "published": "2025-12-01T17:56:29Z",
    "updated": "2025-12-01T17:56:29Z",
    "link": "http://arxiv.org/pdf/2512.01945v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Han Zhou",
      "Xingchen Wan",
      "Ivan Vulić",
      "Anna Korhonen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01939v1",
    "title": "An Empirical Study of Agent Developer Practices in AI Agent Frameworks",
    "summary": "The rise of large language models (LLMs) has sparked a surge of interest in agents, leading to the rapid growth of agent frameworks. Agent frameworks are software toolkits and libraries that provide standardized components, abstractions, and orchestration mechanisms to simplify agent development. Despite widespread use of agent frameworks, their practical applications and how they influence the agent development process remain underexplored. Different agent frameworks encounter similar problems during use, indicating that these recurring issues deserve greater attention and call for further improvements in agent framework design. Meanwhile, as the number of agent frameworks continues to grow and evolve, more than 80% of developers report difficulties in identifying the frameworks that best meet their specific development requirements. In this paper, we conduct the first empirical study of LLM-based agent frameworks, exploring real-world experiences of developers in building AI agents. To compare how well the agent frameworks meet developer needs, we further collect developer discussions for the ten previously identified agent frameworks, resulting in a total of 11,910 discussions. Finally, by analyzing these discussions, we compare the frameworks across five dimensions: development efficiency, functional abstraction, learning cost, performance optimization, and maintainability, which refers to how easily developers can update and extend both the framework itself and the agents built upon it over time. Our comparative analysis reveals significant differences among frameworks in how they meet the needs of agent developers. Overall, we provide a set of findings and implications for the LLM-driven AI agent framework ecosystem and offer insights for the design of future LLM-based agent frameworks and agent developers.",
    "published": "2025-12-01T17:52:15Z",
    "updated": "2025-12-01T17:52:15Z",
    "link": "http://arxiv.org/pdf/2512.01939v1.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Yanlin Wang",
      "Xinyi Xu",
      "Jiachi Chen",
      "Tingting Bi",
      "Wenchao Gu",
      "Zibin Zheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01930v1",
    "title": "SVRG and Beyond via Posterior Correction",
    "summary": "Stochastic Variance Reduced Gradient (SVRG) and its variants aim to speed-up training by using gradient corrections, but have seen limited success in deep learning. Here, we show surprising new foundational connections of SVRG to a recently proposed Bayesian method called posterior correction. Specifically, we show that SVRG is recovered as a special case of posterior correction over the isotropic-Gaussian family, while novel extensions are automatically obtained by using more flexible exponential families. We derive two new SVRG variants by using Gaussian families: First, a Newton-like variant that employs novel Hessian corrections, and second, an Adam-like extension that improves pretraining and finetuning of Transformer language models. This is the first work to connect SVRG to Bayes and use it to boost variational training for deep networks.",
    "published": "2025-12-01T17:45:30Z",
    "updated": "2025-12-01T17:45:30Z",
    "link": "http://arxiv.org/pdf/2512.01930v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Nico Daheim",
      "Thomas Möllenhoff",
      "Ming Liang Ang",
      "Mohammad Emtiyaz Khan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01925v1",
    "title": "Rectifying LLM Thought from Lens of Optimization",
    "summary": "Recent advancements in large language models (LLMs) have been driven by their emergent reasoning capabilities, particularly through long chain-of-thought (CoT) prompting, which enables thorough exploration and deliberation. Despite these advances, long-CoT LLMs often exhibit suboptimal reasoning behaviors, such as overthinking and excessively protracted reasoning chains, which can impair performance. In this paper, we analyze reasoning processes through an optimization lens, framing CoT as a gradient descent procedure where each reasoning step constitutes an update toward problem resolution. Building on this perspective, we introduce RePro (Rectifying Process-level Reward), a novel approach to refine LLM reasoning during post-training. RePro defines a surrogate objective function to assess the optimization process underlying CoT, utilizing a dual scoring mechanism to quantify its intensity and stability. These scores are aggregated into a composite process-level reward, seamlessly integrated into reinforcement learning with verifiable rewards (RLVR) pipelines to optimize LLMs. Extensive experiments across multiple reinforcement learning algorithms and diverse LLMs, evaluated on benchmarks spanning mathematics, science, and coding, demonstrate that RePro consistently enhances reasoning performance and mitigates suboptimal reasoning behaviors.",
    "published": "2025-12-01T17:41:08Z",
    "updated": "2025-12-01T17:41:08Z",
    "link": "http://arxiv.org/pdf/2512.01925v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Junnan Liu",
      "Hongwei Liu",
      "Songyang Zhang",
      "Kai Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01924v1",
    "title": "Real-World Robot Control by Deep Active Inference With a Temporally Hierarchical World Model",
    "summary": "Robots in uncertain real-world environments must perform both goal-directed and exploratory actions. However, most deep learning-based control methods neglect exploration and struggle under uncertainty. To address this, we adopt deep active inference, a framework that accounts for human goal-directed and exploratory actions. Yet, conventional deep active inference approaches face challenges due to limited environmental representation capacity and high computational cost in action selection. We propose a novel deep active inference framework that consists of a world model, an action model, and an abstract world model. The world model encodes environmental dynamics into hidden state representations at slow and fast timescales. The action model compresses action sequences into abstract actions using vector quantization, and the abstract world model predicts future slow states conditioned on the abstract action, enabling low-cost action selection. We evaluate the framework on object-manipulation tasks with a real-world robot. Results show that it achieves high success rates across diverse manipulation tasks and switches between goal-directed and exploratory actions in uncertain settings, while making action selection computationally tractable. These findings highlight the importance of modeling multiple timescale dynamics and abstracting actions and state transitions.",
    "published": "2025-12-01T17:41:01Z",
    "updated": "2025-12-01T17:41:01Z",
    "link": "http://arxiv.org/pdf/2512.01924v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Kentaro Fujii",
      "Shingo Murata"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.15996v3",
    "title": "Med-gte-hybrid: A contextual embedding transformer model for extracting actionable information from clinical texts",
    "summary": "We introduce a novel contextual embedding model med-gte-hybrid that was derived from the gte-large sentence transformer to extract information from unstructured clinical narratives. Our model tuning strategy for med-gte-hybrid combines contrastive learning and a denoising autoencoder. To evaluate the performance of med-gte-hybrid, we investigate several clinical prediction tasks in large patient cohorts extracted from the MIMIC-IV dataset, including Chronic Kidney Disease (CKD) patient prognosis, estimated glomerular filtration rate (eGFR) prediction, and patient mortality prediction. Furthermore, we demonstrate that the med-gte-hybrid model improves patient stratification, clustering, and text retrieval, thus outperforms current state-of-the-art models on the Massive Text Embedding Benchmark (MTEB). While some of our evaluations focus on CKD, our hybrid tuning of sentence transformers could be transferred to other medical domains and has the potential to improve clinical decision-making and personalised treatment pathways in various healthcare applications.",
    "published": "2025-02-21T23:17:31Z",
    "updated": "2025-12-01T17:35:52Z",
    "link": "http://arxiv.org/pdf/2502.15996v3.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Aditya Kumar",
      "Simon Rauch",
      "Mario Cypko",
      "Oliver Amft"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12796v2",
    "title": "Maximizing the efficiency of human feedback in AI alignment: a comparative analysis",
    "summary": "Reinforcement Learning from Human Feedback (RLHF) relies on preference modeling to align machine learning systems with human values, yet the popular approach of random pair sampling with Bradley-Terry modeling is statistically limited and inefficient under constrained annotation budgets. In this work, we explore alternative sampling and evaluation strategies for preference inference in RLHF, drawing inspiration from areas such as game theory, statistics, and social choice theory. Our best-performing method, Swiss InfoGain, employs a Swiss tournament system with a proxy mutual-information-gain pairing rule, which significantly outperforms all other methods in constrained annotation budgets while also being more sample-efficient. Even in high-resource settings, we can identify superior alternatives to the Bradley-Terry baseline. Our experiments demonstrate that adaptive, resource-aware strategies reduce redundancy, enhance robustness, and yield statistically significant improvements in preference learning, highlighting the importance of balancing alignment quality with human workload in RLHF pipelines.",
    "published": "2025-11-16T21:55:59Z",
    "updated": "2025-12-01T17:18:39Z",
    "link": "http://arxiv.org/pdf/2511.12796v2.pdf",
    "category": [
      "cs.HC",
      "cs.AI"
    ],
    "authors": [
      "Andreas Chouliaras",
      "Dimitris Chatzopoulos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2407.11373v3",
    "title": "Reliable Reasoning Beyond Natural Language",
    "summary": "Despite their linguistic competence, Large Language Models (LLMs) often struggle to reason reliably and flexibly. To identify these shortcomings, we introduce the Non-Linear Reasoning (NLR) dataset, a collection of 55 unique, hand-designed problems that target reasoning bottlenecks arising from the sequential prediction paradigm of LLMs and the inherently linear nature of natural language. NLR tasks require iterative updates, backtracking, and reasoning across multiple parallel chains of thought but only basic arithmetic to solve. To address these limitations, we propose a neurosymbolic reasoning approach that integrates Prolog, a symbolic reasoning engine, into the inference pipeline of LLMs. This division of labor shifts the LLM's task from iterative computations to inferring all information, explicit or implied through common sense, and encoding it as logical code. Our method yields large and robust performance gains across the GSM8k and BIG-bench Navigate benchmarks and achieves near-perfect accuracy on NLR problems, maintaining robustness even as variable interdependence - the number of other variables on which the value of a single variable depends - increases.",
    "published": "2024-07-16T04:34:18Z",
    "updated": "2025-12-01T17:15:04Z",
    "link": "http://arxiv.org/pdf/2407.11373v3.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Nasim Borazjanizadeh",
      "Steven T. Piantadosi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01892v1",
    "title": "Exploring Human Perceptions of AI Responses: Insights from a Mixed-Methods Study on Risk Mitigation in Generative Models",
    "summary": "With the rapid uptake of generative AI, investigating human perceptions of generated responses has become crucial. A major challenge is their `aptitude' for hallucinating and generating harmful contents. Despite major efforts for implementing guardrails, human perceptions of these mitigation strategies are largely unknown. We conducted a mixed-method experiment for evaluating the responses of a mitigation strategy across multiple-dimensions: faithfulness, fairness, harm-removal capacity, and relevance. In a within-subject study design, 57 participants assessed the responses under two conditions: harmful response plus its mitigation and solely mitigated response. Results revealed that participants' native language, AI work experience, and annotation familiarity significantly influenced evaluations. Participants showed high sensitivity to linguistic and contextual attributes, penalizing minor grammar errors while rewarding preserved semantic contexts. This contrasts with how language is often treated in the quantitative evaluation of LLMs. We also introduced new metrics for training and evaluating mitigation strategies and insights for human-AI evaluation studies.",
    "published": "2025-12-01T17:12:28Z",
    "updated": "2025-12-01T17:12:28Z",
    "link": "http://arxiv.org/pdf/2512.01892v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "authors": [
      "Heloisa Candello",
      "Muneeza Azmat",
      "Uma Sushmitha Gunturi",
      "Raya Horesh",
      "Rogerio Abreu de Paula",
      "Heloisa Pimentel",
      "Marcelo Carpinette Grave",
      "Aminat Adebiyi",
      "Tiago Machado",
      "Maysa Malfiza Garcia de Macedo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01881v1",
    "title": "Unifying Sign and Magnitude for Optimizing Deep Vision Networks via ThermoLion",
    "summary": "The training of deep vision models is fundamentally a signal recovery problem amidst high-dimensional stochastic noise. Current optimization paradigms impose a static compromise on information channel capacity. For instance, magnitude-based methods, such as AdamW, operate on the assumption that gradient norms are high-fidelity curvature signals. While this allows for precision in smooth regimes, it leads to catastrophic noise amplification when applied to rugged, non-convex landscapes. Conversely, sign-based methods (e.g., Lion) perform a radical 1-bit quantization of the gradient, which aims to provide robust regularization at the cost of discarding fine-grained descent information. We propose that optimal convergence requires neither static prior, but rather a dynamic modulation of the update bitrate. We introduce \\textbf{ThermoLion}, a vision-centric framework that utilizes local Signal-to-Noise Ratio (SNR) gating to autonomously transition parameters between a \"low-bit\" exploration phase and a \"high-precision\" exploitation phase. Furthermore, we introduce a Momentum Alignment mechanism that detects constructive interference between historical drift and instantaneous gradients to accelerate convergence during stable trajectories. Empirical benchmarks across 12 diverse vision datasets (including CIFAR, SVHN, and GTSRB) demonstrate that ThermoLion serves as a hyperparameter-free generalist, surpassing both AdamW and Lion in convergence speed and terminal accuracy without architecture-specific tuning.",
    "published": "2025-12-01T17:04:17Z",
    "updated": "2025-12-01T17:04:17Z",
    "link": "http://arxiv.org/pdf/2512.01881v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Ahmed Nebli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01880v1",
    "title": "Predicting Human Chess Moves: An AI Assisted Analysis of Chess Games Using Skill-group Specific n-gram Language Models",
    "summary": "Chess, a deterministic game with perfect information, has long served as a benchmark for studying strategic decision-making and artificial intelligence. Traditional chess engines or tools for analysis primarily focus on calculating optimal moves, often neglecting the variability inherent in human chess playing, particularly across different skill levels.\n  To overcome this limitation, we propose a novel and computationally efficient move prediction framework that approaches chess move prediction as a behavioral analysis task. The framework employs n-gram language models to capture move patterns characteristic of specific player skill levels. By dividing players into seven distinct skill groups, from novice to expert, we trained separate models using data from the open-source chess platform Lichess. The framework dynamically selects the most suitable model for prediction tasks and generates player moves based on preceding sequences.\n  Evaluation on real-world game data demonstrates that the model selector module within the framework can classify skill levels with an accuracy of up to 31.7\\% when utilizing early game information (16 half-moves). The move prediction framework also shows substantial accuracy improvements, with our Selector Assisted Accuracy being up to 39.1\\% more accurate than our benchmark accuracy. The computational efficiency of the framework further enhances its suitability for real-time chess analysis.",
    "published": "2025-12-01T17:02:07Z",
    "updated": "2025-12-01T17:02:07Z",
    "link": "http://arxiv.org/pdf/2512.01880v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Daren Zhong",
      "Dingcheng Huang",
      "Clayton Greenberg"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.20075v4",
    "title": "LLMs can hide text in other text of the same length",
    "summary": "A meaningful text can be hidden inside another, completely different yet still coherent and plausible, text of the same length. For example, a tweet containing a harsh political critique could be embedded in a tweet that celebrates the same political leader, or an ordinary product review could conceal a secret manuscript. This uncanny state of affairs is now possible thanks to Large Language Models, and in this paper we present Calgacus, a simple and efficient protocol to achieve it. We show that even modest 8-billion-parameter open-source LLMs are sufficient to obtain high-quality results, and a message as long as this abstract can be encoded and decoded locally on a laptop in seconds. The existence of such a protocol demonstrates a radical decoupling of text from authorial intent, further eroding trust in written communication, already shaken by the rise of LLM chatbots. We illustrate this with a concrete scenario: a company could covertly deploy an unfiltered LLM by encoding its answers within the compliant responses of a safe model. This possibility raises urgent questions for AI safety and challenges our understanding of what it means for a Large Language Model to know something.",
    "published": "2025-10-22T23:16:50Z",
    "updated": "2025-12-01T17:01:54Z",
    "link": "http://arxiv.org/pdf/2510.20075v4.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "cs.LG"
    ],
    "authors": [
      "Antonio Norelli",
      "Michael Bronstein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.06309v2",
    "title": "The Station: An Open-World Environment for AI-Driven Discovery",
    "summary": "We introduce the STATION, an open-world multi-agent environment for autonomous scientific discovery. The Station simulates a complete scientific ecosystem, where agents can engage in long scientific journeys that include reading papers from peers, formulating hypotheses, collaborating with peers, submitting experiments, and publishing results. Importantly, there is no centralized system coordinating their activities. Utilizing their long context, agents are free to choose their own actions and develop their own narratives within the Station. Experiments demonstrate that AI agents in the Station achieve new state-of-the-art performance on a wide range of benchmarks, spanning mathematics, computational biology, and machine learning, notably surpassing AlphaEvolve in circle packing. A rich tapestry of unscripted narratives emerges, such as agents collaborating and analyzing other works rather than pursuing myopic optimization. From these emergent narratives, novel methods arise organically, such as a new density-adaptive algorithm for scRNA-seq batch integration that borrows concepts from another domain. The Station marks a first step towards autonomous scientific discovery driven by emergent behavior in an open-world environment, representing a new paradigm that moves beyond rigid pipelines.",
    "published": "2025-11-09T10:13:00Z",
    "updated": "2025-12-01T17:00:00Z",
    "link": "http://arxiv.org/pdf/2511.06309v2.pdf",
    "category": [
      "cs.AI",
      "cs.MA"
    ],
    "authors": [
      "Stephen Chung",
      "Wenyu Du"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01878v1",
    "title": "Graph Distance as Surprise: Free Energy Minimization in Knowledge Graph Reasoning",
    "summary": "In this work, we propose that reasoning in knowledge graph (KG) networks can be guided by surprise minimization. Entities that are close in graph distance will have lower surprise than those farther apart. This connects the Free Energy Principle (FEP) from neuroscience to KG systems, where the KG serves as the agent's generative model. We formalize surprise using the shortest-path distance in directed graphs and provide a framework for KG-based agents. Graph distance appears in graph neural networks as message passing depth and in model-based reinforcement learning as world model trajectories. This work-in-progress study explores whether distance-based surprise can extend recent work showing that syntax minimizes surprise and free energy via tree structures.",
    "published": "2025-12-01T16:59:28Z",
    "updated": "2025-12-01T16:59:28Z",
    "link": "http://arxiv.org/pdf/2512.01878v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Gaganpreet Jhajj",
      "Fuhua Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01870v1",
    "title": "Testing Transformer Learnability on the Arithmetic Sequence of Rooted Trees",
    "summary": "We study whether a Large Language Model can learn the deterministic sequence of trees generated by the iterated prime factorization of the natural numbers. Each integer is mapped into a rooted planar tree and the resulting sequence $ \\mathbb{N}\\mathcal{T}$ defines an arithmetic text with measurable statistical structure. A transformer network (the GPT-2 architecture) is trained from scratch on the first $10^{11}$ elements to subsequently test its predictive ability under next-word and masked-word prediction tasks. Our results show that the model partially learns the internal grammar of $\\mathbb{N}\\mathcal{T}$, capturing non-trivial regularities and correlations. This suggests that learnability may extend beyond empirical data to the very structure of arithmetic.",
    "published": "2025-12-01T16:51:38Z",
    "updated": "2025-12-01T16:51:38Z",
    "link": "http://arxiv.org/pdf/2512.01870v1.pdf",
    "category": [
      "cs.AI",
      "cond-mat.dis-nn",
      "math-ph",
      "math.NT"
    ],
    "authors": [
      "Alessandro Breccia",
      "Federica Gerace",
      "Marco Lippi",
      "Gabriele Sicuro",
      "Pierluigi Contucci"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.16854v2",
    "title": "MRI Super-Resolution with Deep Learning: A Comprehensive Survey",
    "summary": "High-resolution (HR) magnetic resonance imaging (MRI) is crucial for many clinical and research applications. However, achieving it remains costly and constrained by technical trade-offs and experimental limitations. Super-resolution (SR) presents a promising computational approach to overcome these challenges by generating HR images from more affordable low-resolution (LR) scans, potentially improving diagnostic accuracy and efficiency without requiring additional hardware. This survey reviews recent advances in MRI SR techniques, with a focus on deep learning (DL) approaches. It examines DL-based MRI SR methods from the perspectives of computer vision, computational imaging, inverse problems, and MR physics, covering theoretical foundations, architectural designs, learning strategies, benchmark datasets, and performance metrics. We propose a systematic taxonomy to categorize these methods and present an in-depth study of both established and emerging SR techniques applicable to MRI, considering unique challenges in clinical and research contexts. We also highlight open challenges and directions that the community needs to address. Additionally, we provide a collection of essential open-access resources, tools, and tutorials, available on our GitHub: https://github.com/mkhateri/Awesome-MRI-Super-Resolution.\n  IEEE keywords: MRI, Super-Resolution, Deep Learning, Computational Imaging, Inverse Problem, Survey.",
    "published": "2025-11-20T23:36:07Z",
    "updated": "2025-12-01T16:51:18Z",
    "link": "http://arxiv.org/pdf/2511.16854v2.pdf",
    "category": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "eess.SP"
    ],
    "authors": [
      "Mohammad Khateri",
      "Serge Vasylechko",
      "Morteza Ghahremani",
      "Liam Timms",
      "Deniz Kocanaogullari",
      "Simon K. Warfield",
      "Camilo Jaimes",
      "Davood Karimi",
      "Alejandra Sierra",
      "Jussi Tohka",
      "Sila Kurugol",
      "Onur Afacan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01865v1",
    "title": "Cross-Lingual Interleaving for Speech Language Models",
    "summary": "Spoken Language Models (SLMs) aim to learn linguistic competence directly from speech using discrete units, widening access to Natural Language Processing (NLP) technologies for languages with limited written resources. However, progress has been largely English-centric due to scarce spoken evaluation benchmarks and training data, making cross-lingual learning difficult. We present a cross-lingual interleaving method that mixes speech tokens across languages without textual supervision. We also release an EN-FR training dataset, TinyStories (~42k hours), together with EN-FR spoken StoryCloze and TopicCloze benchmarks for cross-lingual semantic evaluation, both synthetically generated using GPT-4. On 360M and 1B SLMs under matched training-token budgets, interleaving improves monolingual semantic accuracy, enables robust cross-lingual continuation, and strengthens cross-lingual hidden-state alignment. Taken together, these results indicate that cross-lingual interleaving is a simple, scalable route to building multilingual SLMs that understand and converse across languages. All resources will be made open-source to support reproducibility.",
    "published": "2025-12-01T16:48:05Z",
    "updated": "2025-12-01T16:48:05Z",
    "link": "http://arxiv.org/pdf/2512.01865v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Adel Moumen",
      "Guangzhi Sun",
      "Philip C. Woodland"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01863v1",
    "title": "Topological Order in Deep State",
    "summary": "Topologically ordered states are among the most interesting quantum phases of matter that host emergent quasi-particles having fractional charge and obeying fractional quantum statistics. Theoretical study of such states is however challenging owing to their strong-coupling nature that prevents conventional mean-field treatment. Here, we demonstrate that an attention-based deep neural network provides an expressive variational wavefunction that discovers fractional Chern insulator ground states purely through energy minimization without prior knowledge and achieves remarkable accuracy. We introduce an efficient method to extract ground state topological degeneracy -- a hallmark of topological order -- from a single optimized real-space wavefunction in translation-invariant systems by decomposing it into different many-body momentum sectors. Our results establish neural network variational Monte Carlo as a versatile tool for discovering strongly correlated topological phases.",
    "published": "2025-12-01T16:46:39Z",
    "updated": "2025-12-01T16:46:39Z",
    "link": "http://arxiv.org/pdf/2512.01863v1.pdf",
    "category": [
      "cond-mat.mes-hall",
      "cond-mat.str-el",
      "cs.AI"
    ],
    "authors": [
      "Ahmed Abouelkomsan",
      "Max Geier",
      "Liang Fu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01852v1",
    "title": "BHRAM-IL: A Benchmark for Hallucination Recognition and Assessment in Multiple Indian Languages",
    "summary": "Large language models (LLMs) are increasingly deployed in multilingual applications but often generate plausible yet incorrect or misleading outputs, known as hallucinations. While hallucination detection has been studied extensively in English, under-resourced Indian languages remain largely unexplored. We present BHRAM-IL, a benchmark for hallucination recognition and assessment in multiple Indian languages, covering Hindi, Gujarati, Marathi, Odia, along with English. The benchmark comprises 36,047 curated questions across nine categories spanning factual, numerical, reasoning, and linguistic tasks. We evaluate 14 state-of-the-art multilingual LLMs on a benchmark subset of 10,265 questions, analyzing cross-lingual and factual hallucinations across languages, models, scales, categories, and domains using category-specific metrics normalized to (0,1) range. Aggregation over all categories and models yields a primary score of 0.23 and a language-corrected fuzzy score of 0.385, demonstrating the usefulness of BHRAM-IL for hallucination-focused evaluation. The dataset, and the code for generation and evaluation are available on GitHub (https://github.com/sambhashana/BHRAM-IL/) and HuggingFace (https://huggingface.co/datasets/sambhashana/BHRAM-IL/) to support future research in multilingual hallucination detection and mitigation.",
    "published": "2025-12-01T16:37:34Z",
    "updated": "2025-12-01T16:37:34Z",
    "link": "http://arxiv.org/pdf/2512.01852v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.ET"
    ],
    "authors": [
      "Hrishikesh Terdalkar",
      "Kirtan Bhojani",
      "Aryan Dongare",
      "Omm Aditya Behera"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01834v1",
    "title": "Mitigating Gender Bias in Depression Detection via Counterfactual Inference",
    "summary": "Audio-based depression detection models have demonstrated promising performance but often suffer from gender bias due to imbalanced training data. Epidemiological statistics show a higher prevalence of depression in females, leading models to learn spurious correlations between gender and depression. Consequently, models tend to over-diagnose female patients while underperforming on male patients, raising significant fairness concerns. To address this, we propose a novel Counterfactual Debiasing Framework grounded in causal inference. We construct a causal graph to model the decision-making process and identify gender bias as the direct causal effect of gender on the prediction. During inference, we employ counterfactual inference to estimate and subtract this direct effect, ensuring the model relies primarily on authentic acoustic pathological features. Extensive experiments on the DAIC-WOZ dataset using two advanced acoustic backbones demonstrate that our framework not only significantly reduces gender bias but also improves overall detection performance compared to existing debiasing strategies.",
    "published": "2025-12-01T16:14:20Z",
    "updated": "2025-12-01T16:14:20Z",
    "link": "http://arxiv.org/pdf/2512.01834v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "authors": [
      "Mingxuan Hu",
      "Hongbo Ma",
      "Xinlan Wu",
      "Ziqi Liu",
      "Jiaqi Liu",
      "Yangbin Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01831v1",
    "title": "Deconstructing Generative Diversity: An Information Bottleneck Analysis of Discrete Latent Generative Models",
    "summary": "Generative diversity varies significantly across discrete latent generative models such as AR, MIM, and Diffusion. We propose a diagnostic framework, grounded in Information Bottleneck (IB) theory, to analyze the underlying strategies resolving this behavior. The framework models generation as a conflict between a 'Compression Pressure' - a drive to minimize overall codebook entropy - and a 'Diversity Pressure' - a drive to maximize conditional entropy given an input. We further decompose this diversity into two primary sources: 'Path Diversity', representing the choice of high-level generative strategies, and 'Execution Diversity', the randomness in executing a chosen strategy. To make this decomposition operational, we introduce three zero-shot, inference-time interventions that directly perturb the latent generative process and reveal how models allocate and express diversity. Application of this probe-based framework to representative AR, MIM, and Diffusion systems reveals three distinct strategies: \"Diversity-Prioritized\" (MIM), \"Compression-Prioritized\" (AR), and \"Decoupled\" (Diffusion). Our analysis provides a principled explanation for their behavioral differences and informs a novel inference-time diversity enhancement technique.",
    "published": "2025-12-01T16:13:23Z",
    "updated": "2025-12-01T16:13:23Z",
    "link": "http://arxiv.org/pdf/2512.01831v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Yudi Wu",
      "Wenhao Zhao",
      "Dianbo Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01822v1",
    "title": "InnoGym: Benchmarking the Innovation Potential of AI Agents",
    "summary": "LLMs and Agents have achieved impressive progress in code generation, mathematical reasoning, and scientific discovery. However, existing benchmarks primarily measure correctness, overlooking the diversity of methods behind solutions. True innovation depends not only on producing correct answers but also on the originality of the approach. We present InnoGym, the first benchmark and framework designed to systematically evaluate the innovation potential of AI agents. InnoGym introduces two complementary metrics: performance gain, which measures improvement over the best-known solutions, and novelty, which captures methodological differences from prior approaches. The benchmark includes 18 carefully curated tasks from real-world engineering and scientific domains, each standardized through resource filtering, evaluator validation, and solution collection. In addition, we provide iGym, a unified execution environment for reproducible and long-horizon evaluations. Extensive experiments show that while some agents produce novel approaches, their lack of robustness limits performance gains. These results highlight a key gap between creativity and effectiveness, underscoring the need for benchmarks that evaluate both.",
    "published": "2025-12-01T16:03:04Z",
    "updated": "2025-12-01T16:03:04Z",
    "link": "http://arxiv.org/pdf/2512.01822v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.MA"
    ],
    "authors": [
      "Jintian Zhang",
      "Kewei Xu",
      "Jingsheng Zheng",
      "Zhuoyun Yu",
      "Yuqi Zhu",
      "Yujie Luo",
      "Lanning Wei",
      "Shuofei Qiao",
      "Lun Du",
      "Da Zheng",
      "Shumin Deng",
      "Huajun Chen",
      "Ningyu Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.02896v4",
    "title": "Global Convergence of Policy Gradient for Entropy Regularized Linear-Quadratic Control with Multiplicative Noise",
    "summary": "Reinforcement Learning (RL) has emerged as a powerful framework for sequential decision-making in dynamic environments, particularly when system parameters are unknown. This paper investigates RL-based control for entropy-regularized linear-quadratic (LQ) control problems with multiplicative noise over an infinite time horizon. First, we adapt the regularized policy gradient (RPG) algorithm to stochastic optimal control settings, proving that despite the non-convexity of the problem, RPG converges globally under conditions of gradient domination and almost-smoothness. Second, based on zero-order optimization approach, we introduce a novel model free RL algorithm: Sample-based regularized policy gradient (SB-RPG). SB-RPG operates without knowledge of system parameters yet still retains strong theoretical guarantees of global convergence. Our model leverages entropy regularization to address the exploration versus exploitation trade-off inherent in RL. Numerical simulations validate the theoretical results and demonstrate the efficiency of SB-RPG in unknown-parameters environments.",
    "published": "2025-10-03T11:03:12Z",
    "updated": "2025-12-01T15:57:48Z",
    "link": "http://arxiv.org/pdf/2510.02896v4.pdf",
    "category": [
      "eess.SY",
      "cs.AI"
    ],
    "authors": [
      "Gabriel Diaz",
      "Lucky Li",
      "Wenhao Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.00225v3",
    "title": "Discovering the Underlying Analytic Structure Within Standard Model Constants Using Artificial Intelligence",
    "summary": "This paper presents a method for uncovering hidden analytic relationships among the fundamental parameters of the Standard Model (SM), a foundational theory in physics that describes the fundamental particles and their interactions, using symbolic regression and genetic programming. Using this approach, we identify the simplest analytic relationships connecting pairs of these constants and report several notable expressions obtained with relative precision better than 1%. These results may serve as valuable inputs for model builders and artificial intelligence methods aimed at uncovering hidden patterns among the SM constants, or potentially used as building blocks for a deeper underlying law that connects all parameters of the SM through a small set of fundamental constants.",
    "published": "2025-06-30T19:51:50Z",
    "updated": "2025-12-01T15:53:39Z",
    "link": "http://arxiv.org/pdf/2507.00225v3.pdf",
    "category": [
      "hep-ph",
      "cs.AI",
      "physics.data-an"
    ],
    "authors": [
      "S. V. Chekanov",
      "H. Kjellerstrand"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01816v1",
    "title": "Envision: Benchmarking Unified Understanding & Generation for Causal World Process Insights",
    "summary": "Current multimodal models aim to transcend the limitations of single-modality representations by unifying understanding and generation, often using text-to-image (T2I) tasks to calibrate semantic consistency. However, their reliance on static, single-image generation in training and evaluation leads to overfitting to static pattern matching and semantic fusion, while fundamentally hindering their ability to model dynamic processes that unfold over time. To address these constraints, we propose Envision-a causal event progression benchmark for chained text-to-multi-image generation. Grounded in world knowledge and structured by spatiotemporal causality, it reorganizes existing evaluation dimensions and includes 1,000 four-stage prompts spanning six scientific and humanities domains. To transition evaluation from single images to sequential frames and assess whether models truly internalize world knowledge while adhering to causal-temporal constraints, we introduce Envision-Score, a holistic metric integrating multi-dimensional consistency, physicality, and aesthetics. Comprehensive evaluation of 15 models (10 specialized T2I models, 5 unified models) uncovers: specialized T2I models demonstrate proficiency in aesthetic rendering yet lack intrinsic world knowledge. Unified multimodal models bridge this gap, consistently outperforming specialized counterparts in causal narrative coherence. However, even these unified architectures remain subordinate to closed-source models and struggle to overcome the core challenge of spatiotemporal consistency. This demonstrates that a focus on causally-isolated single images impedes multi-frame reasoning and generation, promoting static pattern matching over dynamic world modeling-ultimately limiting world knowledge internalization, generation.",
    "published": "2025-12-01T15:52:31Z",
    "updated": "2025-12-01T15:52:31Z",
    "link": "http://arxiv.org/pdf/2512.01816v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Juanxi Tian",
      "Siyuan Li",
      "Conghui He",
      "Lijun Wu",
      "Cheng Tan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01797v1",
    "title": "H-Neurons: On the Existence, Impact, and Origin of Hallucination-Associated Neurons",
    "summary": "Large language models (LLMs) frequently generate hallucinations -- plausible but factually incorrect outputs -- undermining their reliability. While prior work has examined hallucinations from macroscopic perspectives such as training data and objectives, the underlying neuron-level mechanisms remain largely unexplored. In this paper, we conduct a systematic investigation into hallucination-associated neurons (H-Neurons) in LLMs from three perspectives: identification, behavioral impact, and origins. Regarding their identification, we demonstrate that a remarkably sparse subset of neurons (less than $0.1\\%$ of total neurons) can reliably predict hallucination occurrences, with strong generalization across diverse scenarios. In terms of behavioral impact, controlled interventions reveal that these neurons are causally linked to over-compliance behaviors. Concerning their origins, we trace these neurons back to the pre-trained base models and find that these neurons remain predictive for hallucination detection, indicating they emerge during pre-training. Our findings bridge macroscopic behavioral patterns with microscopic neural mechanisms, offering insights for developing more reliable LLMs.",
    "published": "2025-12-01T15:32:14Z",
    "updated": "2025-12-01T15:32:14Z",
    "link": "http://arxiv.org/pdf/2512.01797v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "authors": [
      "Cheng Gao",
      "Huimin Chen",
      "Chaojun Xiao",
      "Zhiyi Chen",
      "Zhiyuan Liu",
      "Maosong Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01786v1",
    "title": "Who Judges the Judge? LLM Jury-on-Demand: Building Trustworthy LLM Evaluation Systems",
    "summary": "As Large Language Models (LLMs) become integrated into high-stakes domains, there is a growing need for evaluation methods that are both scalable for real-time deployment and reliable for critical decision-making. While human evaluation is reliable, it is slow and costly. Single LLM judges are biased, and static juries lack adaptability. To overcome these limitations, we propose LLM Jury-on-Demand - a dynamic, learning-based framework for scalable and context-aware evaluation. Our method trains a set of reliability predictors to assess when LLM judges will agree with human experts, leveraging token distributions, embeddings, and structural input features. This enables a fully adaptive evaluation where, for each data point, an optimal jury of the most reliable judges is dynamically selected, and their scores are aggregated using their reliability as weights. Experiments on summarization and RAG benchmarks show that our dynamic jury system achieves significantly higher correlation with human judgment than both single-judge and static-jury baselines. These results highlight the promise of adaptive, learning-based juries for building scalable, more reliable and trustworthy evaluation systems for modern LLMs in high-stakes domains.",
    "published": "2025-12-01T15:26:20Z",
    "updated": "2025-12-01T15:26:20Z",
    "link": "http://arxiv.org/pdf/2512.01786v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Xiaochuan Li",
      "Ke Wang",
      "Girija Gouda",
      "Shubham Choudhary",
      "Yaqun Wang",
      "Linwei Hu",
      "Joel Vaughan",
      "Freddy Lecue"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01782v1",
    "title": "Dual Randomized Smoothing: Beyond Global Noise Variance",
    "summary": "Randomized Smoothing (RS) is a prominent technique for certifying the robustness of neural networks against adversarial perturbations. With RS, achieving high accuracy at small radii requires a small noise variance, while achieving high accuracy at large radii requires a large noise variance. However, the global noise variance used in the standard RS formulation leads to a fundamental limitation: there exists no global noise variance that simultaneously achieves strong performance at both small and large radii. To break through the global variance limitation, we propose a dual RS framework which enables input-dependent noise variances. To achieve that, we first prove that RS remains valid with input-dependent noise variances, provided the variance is locally constant around each input. Building on this result, we introduce two components which form our dual RS framework: (i) a variance estimator first predicts an optimal noise variance for each input, (ii) this estimated variance is then used by a standard RS classifier. The variance estimator is independently smoothed via RS to ensure local constancy, enabling flexible design. We also introduce training strategies to iteratively optimize the two components. Extensive experiments on CIFAR-10 show that our dual RS method provides strong performance for both small and large radii-unattainable with global noise variance-while incurring only a 60% computational overhead at inference. Moreover, it consistently outperforms prior input-dependent noise approaches across most radii, with particularly large gains at radii 0.5, 0.75, and 1.0, achieving relative improvements of 19%, 24%, and 21%, respectively. On ImageNet, dual RS remains effective across all radii. Additionally, the dual RS framework naturally provides a routing perspective for certified robustness, improving the accuracy-robustness trade-off with off-the-shelf expert RS models.",
    "published": "2025-12-01T15:23:00Z",
    "updated": "2025-12-01T15:23:00Z",
    "link": "http://arxiv.org/pdf/2512.01782v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Chenhao Sun",
      "Yuhao Mao",
      "Martin Vechev"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.10445v2",
    "title": "RealWebAssist: A Benchmark for Long-Horizon Web Assistance with Real-World Users",
    "summary": "To achieve successful assistance with long-horizon web-based tasks, AI agents must be able to sequentially follow real-world user instructions over a long period. Unlike existing web-based agent benchmarks, sequential instruction following in the real world poses significant challenges beyond performing a single, clearly defined task. For instance, real-world human instructions can be ambiguous, require different levels of AI assistance, and may evolve over time, reflecting changes in the user's mental state. To address this gap, we introduce RealWebAssist, a novel benchmark designed to evaluate sequential instruction-following in realistic scenarios involving long-horizon interactions with the web, visual GUI grounding, and understanding ambiguous real-world user instructions. RealWebAssist includes a dataset of sequential instructions collected from real-world human users. Each user instructs a web-based assistant to perform a series of tasks on multiple websites. A successful agent must reason about the true intent behind each instruction, keep track of the mental state of the user, understand user-specific routines, and ground the intended tasks to actions on the correct GUI elements. Our experimental results show that state-of-the-art models struggle to understand and ground user instructions, posing critical challenges in following real-world user instructions for long-horizon web assistance.",
    "published": "2025-04-14T17:36:46Z",
    "updated": "2025-12-01T15:22:40Z",
    "link": "http://arxiv.org/pdf/2504.10445v2.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Suyu Ye",
      "Haojun Shi",
      "Darren Shih",
      "Hyokun Yun",
      "Tanya Roosta",
      "Tianmin Shu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.17714v2",
    "title": "Learning the Value of Value Learning",
    "summary": "Standard decision frameworks addresses uncertainty about facts but assumes fixed values. We extend the Jeffrey-Bolker framework to model refinements in values and prove a value-of-information theorem for axiological refinement. In multi-agent settings, we establish that mutual refinement will characteristically transform zero-sum games into positive-sum interactions and yields Pareto-improving Nash bargains. These results show that a framework of rational choice can be extended to model value refinement and its associated benefits. By unifying epistemic and axiological refinement under a single formalism, we broaden the conceptual foundations of rational choice and illuminate the normative status of ethical deliberation.",
    "published": "2025-11-21T19:06:30Z",
    "updated": "2025-12-01T15:18:00Z",
    "link": "http://arxiv.org/pdf/2511.17714v2.pdf",
    "category": [
      "cs.AI",
      "cs.GT"
    ],
    "authors": [
      "Alex John London",
      "Aydin Mohseni"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01759v1",
    "title": "Weight Space Representation Learning with Neural Fields",
    "summary": "In this work, we investigate the potential of weights to serve as effective representations, focusing on neural fields. Our key insight is that constraining the optimization space through a pre-trained base model and low-rank adaptation (LoRA) can induce structure in weight space. Across reconstruction, generation, and analysis tasks on 2D and 3D data, we find that multiplicative LoRA weights achieve high representation quality while exhibiting distinctiveness and semantic structure. When used with latent diffusion models, multiplicative LoRA weights enable higher-quality generation than existing weight-space methods.",
    "published": "2025-12-01T15:05:01Z",
    "updated": "2025-12-01T15:05:01Z",
    "link": "http://arxiv.org/pdf/2512.01759v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Zhuoqian Yang",
      "Mathieu Salzmann",
      "Sabine Süsstrunk"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.08364v2",
    "title": "DPRM: A Dual Implicit Process Reward Model in Multi-Hop Question Answering",
    "summary": "In multi-hop question answering (MHQA) tasks, Chain of Thought (CoT) improves the quality of generation by guiding large language models (LLMs) through multi-step reasoning, and Knowledge Graphs (KGs) reduce hallucinations via semantic matching. Outcome Reward Models (ORMs) provide feedback after generating the final answers but fail to evaluate the process for multi-step reasoning. Traditional Process Reward Models (PRMs) evaluate the reasoning process but require costly human annotations or rollout generation. While implicit PRM is trained only with outcome signals and derives step rewards through reward parameterization without explicit annotations, it is more suitable for multi-step reasoning in MHQA tasks. However, existing implicit PRM has only been explored for plain text scenarios. When adapting to MHQA tasks, it cannot handle the graph structure constraints in KGs and capture the potential inconsistency between CoT and KG paths. To address these limitations, we propose the DPRM (Dual Implicit Process Reward Model). It trains two implicit PRMs for CoT and KG reasoning in MHQA tasks. Both PRMs, namely KG-PRM and CoT-PRM, derive step-level rewards from outcome signals via reward parameterization without additional explicit annotations. Among them, KG-PRM uses preference pairs to learn structural constraints from KGs. DPRM further introduces a consistency constraint between CoT and KG reasoning steps, making the two PRMs mutually verify and collaboratively optimize the reasoning paths. We also provide a theoretical demonstration of the derivation of process rewards. Experimental results show that our method outperforms 13 baselines on multiple datasets with up to 16.6% improvement on Hit@1.",
    "published": "2025-11-11T15:41:22Z",
    "updated": "2025-12-01T15:03:07Z",
    "link": "http://arxiv.org/pdf/2511.08364v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Xinyi Wang",
      "Yiping Song",
      "Zhiliang Tian",
      "Bo Liu",
      "Tingjin Luo",
      "Minlie Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.23092v2",
    "title": "Does Self-Evaluation Enable Wireheading in Language Models?",
    "summary": "Self-evaluation is increasingly central to language model training, underpinning techniques from Constitutional AI to self-refinement. We investigate whether coupling self-evaluation to reward signals creates incentives for wireheading, where agents manipulate the measurement process rather than optimizing the task. We first formalize conditions under which reward-channel control strictly dominates task-focused behavior in partially observable Markov decision processes (POMDPs). We then test these predictions empirically across two models (Llama-3.1-8B and Mistral-7B) and three tasks. We find that when self-grades determine rewards, models exhibit substantial grade inflation without corresponding accuracy gains, particularly on ambiguous tasks like summarization. While decoupling self-grades from the reward signal mitigates this inflation, models may still display lesser (but significant) overconfidence. Our results suggest that within current model scales, separating evaluation from reward removes immediate wireheading incentives. However, we caution that strictly decoupling rewards may not suffice for situationally aware models, which could learn to inflate grades for instrumental reasons (such as influencing deployment decisions) even absent direct reward coupling.",
    "published": "2025-11-28T11:24:03Z",
    "updated": "2025-12-01T14:57:59Z",
    "link": "http://arxiv.org/pdf/2511.23092v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "David Demitri Africa",
      "Hans Ethan Ting"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.13908v3",
    "title": "AI-Assisted Conversational Interviewing: Effects on Data Quality and Respondent Experience",
    "summary": "Standardized surveys scale efficiently but sacrifice depth, while conversational interviews improve response quality at the cost of scalability and consistency. This study bridges the gap between these methods by introducing a framework for AI-assisted conversational interviewing. To evaluate this framework, we conducted a web survey experiment where 1,800 participants were randomly assigned to AI 'chatbots' which use large language models (LLMs) to dynamically probe respondents for elaboration and interactively code open-ended responses to fixed questions developed by human researchers. We assessed the AI chatbot's performance in terms of coding accuracy, response quality, and respondent experience. Our findings reveal that AI chatbots perform moderately well in live coding even without survey-specific fine-tuning, despite slightly inflated false positive errors due to respondent acquiescence bias. Open-ended responses were more detailed and informative, but this came at a slight cost to respondent experience. Our findings highlight the feasibility of using AI methods such as chatbots enhanced by LLMs to enhance open-ended data collection in web surveys.",
    "published": "2025-04-09T13:58:07Z",
    "updated": "2025-12-01T14:57:48Z",
    "link": "http://arxiv.org/pdf/2504.13908v3.pdf",
    "category": [
      "cs.HC",
      "cs.AI",
      "stat.AP"
    ],
    "authors": [
      "Soubhik Barari",
      "Jarret Angbazo",
      "Natalie Wang",
      "Leah M. Christian",
      "Elizabeth Dean",
      "Zoe Slowinski",
      "Brandon Sepulvado"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.19918v5",
    "title": "Meta-Reasoner: Dynamic Guidance for Optimized Inference-time Reasoning in Large Language Models",
    "summary": "Large Language Models (LLMs) often struggle with computational efficiency and error propagation in multi-step reasoning tasks. While recent advancements on prompting and post-training have enabled LLMs to perform step-wise reasoning, they still tend to explore unproductive solution paths without effective backtracking or strategy adjustment. In this paper, we propose Meta-Reasoner, a new framework that empowers LLMs to \"think about how to think\". It optimizes the inference process by dynamically adapting reasoning strategies in real-time. Our approach employs contextual multi-armed bandits (CMABs) to learn an adaptive policy. It learns to evaluate the current state of LLM's reasoning and determine optimal strategy that is most likely to lead to a successful outcome during inference, like whether to backtrack, switch to a new approach, or restart the problem-solving process. This meta-guidance helps avoid unproductive paths exploration during inference and hence improves computational efficiency. We evaluate Meta-Reasoner on math problems (e.g., Game-of-24, TheoremQA) and scientific tasks (e.g., SciBench). Results show that our method outperform previous SOTA methods by 9-12\\% in accuracy, while reducing inference time by 28-35\\% under the same compute budget. Additional experiments on creative writing demonstrate the generalizability of our approach to diverse reasoning-intensive tasks.",
    "published": "2025-02-27T09:40:13Z",
    "updated": "2025-12-01T14:54:09Z",
    "link": "http://arxiv.org/pdf/2502.19918v5.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Yuan Sui",
      "Yufei He",
      "Tri Cao",
      "Simeng Han",
      "Yulin Chen",
      "Bryan Hooi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.24616v4",
    "title": "Eye of Judgement: Dissecting the Evaluation of Russian-speaking LLMs with POLLUX",
    "summary": "We introduce POLLUX, a comprehensive open-source benchmark designed to evaluate the generative capabilities of large language models (LLMs) in Russian. Our main contribution is a novel evaluation methodology that enhances the interpretability of LLM assessment. For each task type, we define a set of detailed criteria and develop a scoring protocol where models evaluate responses and provide justifications for their ratings. This enables transparent, criteria-driven evaluation beyond traditional resource-consuming, side-by-side human comparisons. POLLUX includes a detailed, fine-grained taxonomy of 35 task types covering diverse generative domains such as code generation, creative writing, and practical assistant use cases, totaling 2,100 manually crafted and professionally authored prompts. Each task is categorized by difficulty (easy/medium/hard), with experts constructing the dataset entirely from scratch. We also release a family of LLM-as-a-Judge (7B and 32B) evaluators trained for nuanced assessment of generative outputs. This approach provides scalable, interpretable evaluation and annotation tools for model development, effectively replacing costly and less precise human judgments.",
    "published": "2025-05-30T14:08:17Z",
    "updated": "2025-12-01T14:46:24Z",
    "link": "http://arxiv.org/pdf/2505.24616v4.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Nikita Martynov",
      "Anastasia Mordasheva",
      "Dmitriy Gorbetskiy",
      "Danil Astafurov",
      "Ulyana Isaeva",
      "Elina Basyrova",
      "Sergey Skachkov",
      "Victoria Berestova",
      "Nikolay Ivanov",
      "Valeriia Zanina",
      "Alena Fenogenova"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01723v1",
    "title": "Probabilistic Neuro-Symbolic Reasoning for Sparse Historical Data: A Framework Integrating Bayesian Inference, Causal Models, and Game-Theoretic Allocation",
    "summary": "Modeling historical events poses fundamental challenges for machine learning: extreme data scarcity (N << 100), heterogeneous and noisy measurements, missing counterfactuals, and the requirement for human interpretable explanations. We present HistoricalML, a probabilistic neuro-symbolic framework that addresses these challenges through principled integration of (1) Bayesian uncertainty quantification to separate epistemic from aleatoric uncertainty, (2) structural causal models for counterfactual reasoning under confounding, (3) cooperative game theory (Shapley values) for fair allocation modeling, and (4) attention based neural architectures for context dependent factor weighting. We provide theoretical analysis showing that our approach achieves consistent estimation in the sparse data regime when strong priors from domain knowledge are available, and that Shapley based allocation satisfies axiomatic fairness guarantees that pure regression approaches cannot provide. We instantiate the framework on two historical case studies: the 19th century partition of Africa (N = 7 colonial powers) and the Second Punic War (N = 2 factions). Our model identifies Germany's +107.9 percent discrepancy as a quantifiable structural tension preceding World War I, with tension factor 36.43 and 0.79 naval arms race correlation. For the Punic Wars, Monte Carlo battle simulations achieve a 57.3 percent win probability for Carthage at Cannae and 57.8 percent for Rome at Zama, aligning with historical outcomes. Counterfactual analysis reveals that Carthaginian political support (support score 6.4 vs Napoleon's 7.1), rather than military capability, was the decisive factor.",
    "published": "2025-12-01T14:35:04Z",
    "updated": "2025-12-01T14:35:04Z",
    "link": "http://arxiv.org/pdf/2512.01723v1.pdf",
    "category": [
      "cs.AI",
      "cs.GT",
      "math.PR"
    ],
    "authors": [
      "Saba Kublashvili"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01707v1",
    "title": "StreamGaze: Gaze-Guided Temporal Reasoning and Proactive Understanding in Streaming Videos",
    "summary": "Streaming video understanding requires models not only to process temporally incoming frames, but also to anticipate user intention for realistic applications like AR glasses. While prior streaming benchmarks evaluate temporal reasoning, none measure whether MLLMs can interpret or leverage human gaze signals within a streaming setting. To fill this gap, we introduce StreamGaze, the first benchmark designed to evaluate how effectively MLLMs use gaze for temporal and proactive reasoning in streaming videos. StreamGaze introduces gaze-guided past, present, and proactive tasks that comprehensively evaluate streaming video understanding. These tasks assess whether models can use real-time gaze to follow shifting attention and infer user intentions from only past and currently observed frames. To build StreamGaze, we develop a gaze-video QA generation pipeline that aligns egocentric videos with raw gaze trajectories via fixation extraction, region-specific visual prompting, and scanpath construction. This pipeline produces spatio-temporally grounded QA pairs that closely reflect human perceptual dynamics. Across all StreamGaze tasks, we observe substantial performance gaps between state-of-the-art MLLMs and human performance, revealing fundamental limitations in gaze-based temporal reasoning, intention modeling, and proactive prediction. We further provide detailed analyses of gaze-prompting strategies, reasoning behaviors, and task-specific failure modes, offering deeper insight into why current MLLMs struggle and what capabilities future models must develop. All data and code will be publicly released to support continued research in gaze-guided streaming video understanding.",
    "published": "2025-12-01T14:15:44Z",
    "updated": "2025-12-01T14:15:44Z",
    "link": "http://arxiv.org/pdf/2512.01707v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Daeun Lee",
      "Subhojyoti Mukherjee",
      "Branislav Kveton",
      "Ryan A. Rossi",
      "Viet Dac Lai",
      "Seunghyun Yoon",
      "Trung Bui",
      "Franck Dernoncourt",
      "Mohit Bansal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.11842v3",
    "title": "MoH: Multi-Head Attention as Mixture-of-Head Attention",
    "summary": "In this work, we upgrade the multi-head attention mechanism, the core of the Transformer model, to improve efficiency while maintaining or surpassing the previous accuracy level. We show that multi-head attention can be expressed in the summation form. Drawing on the insight that not all attention heads hold equal significance, we propose Mixture-of-Head attention (MoH), a new architecture that treats attention heads as experts in the Mixture-of-Experts (MoE) mechanism. MoH has two significant advantages: First, MoH enables each token to select the appropriate attention heads, enhancing inference efficiency without compromising accuracy or increasing the number of parameters. Second, MoH replaces the standard summation in multi-head attention with a weighted summation, introducing flexibility to the attention mechanism and unlocking extra performance potential. Extensive experiments on ViT, DiT, and LLMs demonstrate that MoH outperforms multi-head attention by using only 50%-90% of the attention heads. Moreover, we demonstrate that pre-trained multi-head attention models, such as LLaMA3-8B, can be further continue-tuned into our MoH models. Notably, MoH-LLaMA3-8B achieves an average accuracy of 64.0% across 14 benchmarks, outperforming LLaMA3-8B by 2.4% by utilizing only 75% of the attention heads. We believe the proposed MoH is a promising alternative to multi-head attention and provides a strong foundation for developing advanced and efficient attention-based models.",
    "published": "2024-10-15T17:59:44Z",
    "updated": "2025-12-01T13:57:40Z",
    "link": "http://arxiv.org/pdf/2410.11842v3.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Peng Jin",
      "Bo Zhu",
      "Li Yuan",
      "Shuicheng Yan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01672v1",
    "title": "ICAD-LLM: One-for-All Anomaly Detection via In-Context Learning with Large Language Models",
    "summary": "Anomaly detection (AD) is a fundamental task of critical importance across numerous domains. Current systems increasingly operate in rapidly evolving environments that generate diverse yet interconnected data modalities -- such as time series, system logs, and tabular records -- as exemplified by modern IT systems. Effective AD methods in such environments must therefore possess two critical capabilities: (1) the ability to handle heterogeneous data formats within a unified framework, allowing the model to process and detect multiple modalities in a consistent manner during anomalous events; (2) a strong generalization ability to quickly adapt to new scenarios without extensive retraining. However, most existing methods fall short of these requirements, as they typically focus on single modalities and lack the flexibility to generalize across domains. To address this gap, we introduce a novel paradigm: In-Context Anomaly Detection (ICAD), where anomalies are defined by their dissimilarity to a relevant reference set of normal samples. Under this paradigm, we propose ICAD-LLM, a unified AD framework leveraging Large Language Models' in-context learning abilities to process heterogeneous data within a single model. Extensive experiments demonstrate that ICAD-LLM achieves competitive performance with task-specific AD methods and exhibits strong generalization to previously unseen tasks, which substantially reduces deployment costs and enables rapid adaptation to new environments. To the best of our knowledge, ICAD-LLM is the first model capable of handling anomaly detection tasks across diverse domains and modalities.",
    "published": "2025-12-01T13:41:30Z",
    "updated": "2025-12-01T13:41:30Z",
    "link": "http://arxiv.org/pdf/2512.01672v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Zhongyuan Wu",
      "Jingyuan Wang",
      "Zexuan Cheng",
      "Yilong Zhou",
      "Weizhi Wang",
      "Juhua Pu",
      "Chao Li",
      "Changqing Ma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01661v1",
    "title": "Learning the Boundary of Solvability: Aligning LLMs to Detect Unsolvable Problems",
    "summary": "Ensuring LLM reliability requires not only solving complex problems but also recognizing when a problem is unsolvable. Current models often struggle to distinguish objective unsolvability (inherent contradictions in the problem) from subjective capability limitations (problems beyond the model's competence), which leads to hallucinations and overconfidence. To address this, we propose UnsolvableQA and UnsolvableRL to solve feasible problems, detect inherent contradictions, and prudently refuse tasks beyond capability. Specifically, we construct UnsolvableQA, a dataset of paired solvable and unsolvable instances derived via a dual-track methodology: programmatic generation for logic puzzles and a novel \"Reverse Construction\" method that injects contradictions into valid reasoning chains for mathematics. Building on this dataset, we introduce UnsolvableRL, a reinforcement learning framework with three reward components jointly accounting for accuracy, unsolvability, and difficulty. Empirical results show that our approach achieves near-perfect unsolvability detection while also improving accuracy on solvable tasks. Crucially, we identify Capability Collapse, demonstrating that explicit exposure to unsolvable data is indispensable for preventing models from becoming systematically overconfident. Our code and data are available at https://github.com/sfasfaffa/unsolvableQA.",
    "published": "2025-12-01T13:32:59Z",
    "updated": "2025-12-01T13:32:59Z",
    "link": "http://arxiv.org/pdf/2512.01661v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Dengyun Peng",
      "Qiguang Chen",
      "Bofei Liu",
      "Jiannan Guan",
      "Libo Qin",
      "Zheng Yan",
      "Jinhao Liu",
      "Jianshu Zhang",
      "Wanxiang Che"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01659v1",
    "title": "HalluGraph: Auditable Hallucination Detection for Legal RAG Systems via Knowledge Graph Alignment",
    "summary": "Legal AI systems powered by retrieval-augmented generation (RAG) face a critical accountability challenge: when an AI assistant cites case law, statutes, or contractual clauses, practitioners need verifiable guarantees that generated text faithfully represents source documents. Existing hallucination detectors rely on semantic similarity metrics that tolerate entity substitutions, a dangerous failure mode when confusing parties, dates, or legal provisions can have material consequences. We introduce HalluGraph, a graph-theoretic framework that quantifies hallucinations through structural alignment between knowledge graphs extracted from context, query, and response. Our approach produces bounded, interpretable metrics decomposed into \\textit{Entity Grounding} (EG), measuring whether entities in the response appear in source documents, and \\textit{Relation Preservation} (RP), verifying that asserted relationships are supported by context. On structured control documents, HalluGraph achieves near-perfect discrimination ($>$400 words, $>$20 entities), HalluGraph achieves $AUC = 0.979$, while maintaining robust performance ($AUC \\approx 0.89$) on challenging generative legal task, consistently outperforming semantic similarity baselines. The framework provides the transparency and traceability required for high-stakes legal applications, enabling full audit trails from generated assertions back to source passages.",
    "published": "2025-12-01T13:31:06Z",
    "updated": "2025-12-01T13:31:06Z",
    "link": "http://arxiv.org/pdf/2512.01659v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Valentin Noël",
      "Elimane Yassine Seidou",
      "Charly Ken Capo-Chichi",
      "Ghanem Amari"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.20353v2",
    "title": "A Unified Theory of $θ$-Expectations",
    "summary": "We derive a new class of non-linear expectations from first-principles deterministic chaotic dynamics. The homogenization of the system's skew-adjoint microscopic generator is achieved using the spectral theory of transfer operators for uniformly hyperbolic flows. We prove convergence in the viscosity sense to a macroscopic evolution governed by a fully non-linear Hamilton-Jacobi-Bellman (HJB) equation. Our central result establishes that the HJB Hamiltonian possesses a rigid structure: affine in the Hessian but demonstrably non-convex in the gradient. This defines a new $θ$-expectation and constructively establishes a class of non-convex stochastic control problems fundamentally outside the sub-additive framework of G-expectations.",
    "published": "2025-07-27T16:56:01Z",
    "updated": "2025-12-01T13:00:38Z",
    "link": "http://arxiv.org/pdf/2507.20353v2.pdf",
    "category": [
      "math.PR",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Qian Qi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23649v2",
    "title": "Efficient Low Rank Attention for Long-Context Inference in Large Language Models",
    "summary": "As the length of input text grows, the key-value (KV) cache in LLMs imposes prohibitive GPU memory costs and limits long-context inference on resource constrained devices. Existing approaches, such as KV quantization and pruning, reduce memory usage but suffer from numerical precision loss or suboptimal retention of key-value pairs. We introduce Low Rank Query and Key attention (LRQK), a two-stage framework that jointly decomposes the full-precision query and key matrices into compact rank-\\(r\\) factors during the prefill stage, and then uses these low-dimensional projections to compute proxy attention scores in \\(\\mathcal{O}(lr)\\) time at each decode step. By selecting only the top-\\(k\\) tokens and a small fixed set of recent tokens, LRQK employs a mixed GPU-CPU cache with a hit-and-miss mechanism that transfers only missing full-precision KV pairs, thereby preserving exact attention outputs while reducing CPU-GPU data movement. Extensive experiments on the RULER and LongBench benchmarks with LLaMA-3-8B and Qwen2.5-7B demonstrate that LRQK matches or surpasses leading sparse-attention methods in long context settings, while delivering significant memory savings with minimal loss in accuracy. Our code is available at https://github.com/tenghuilee/LRQK.",
    "published": "2025-10-25T11:43:27Z",
    "updated": "2025-12-01T12:51:25Z",
    "link": "http://arxiv.org/pdf/2510.23649v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Tenghui Li",
      "Guoxu Zhou",
      "Xuyang Zhao",
      "Yuning Qiu",
      "Qibin Zhao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01616v1",
    "title": "CLIP-RL: Aligning Language and Policy Representations for Task Transfer in Reinforcement Learning",
    "summary": "Recently, there has been an increasing need to develop agents capable of solving multiple tasks within the same environment, especially when these tasks are naturally associated with language. In this work, we propose a novel approach that leverages combinations of pre-trained (language, policy) pairs to establish an efficient transfer pipeline. Our algorithm is inspired by the principles of Contrastive Language-Image Pretraining (CLIP) in Computer Vision, which aligns representations across different modalities under the philosophy that ''two modalities representing the same concept should have similar representations.'' The central idea here is that the instruction and corresponding policy of a task represent the same concept, the task itself, in two different modalities. Therefore, by extending the idea of CLIP to RL, our method creates a unified representation space for natural language and policy embeddings. Experimental results demonstrate the utility of our algorithm in achieving faster transfer across tasks.",
    "published": "2025-12-01T12:37:01Z",
    "updated": "2025-12-01T12:37:01Z",
    "link": "http://arxiv.org/pdf/2512.01616v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Chainesh Gautam",
      "Raghuram Bharadwaj Diddigi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.05187v2",
    "title": "Resource-Efficient Beam Prediction in mmWave Communications with Multimodal Realistic Simulation Framework",
    "summary": "Beamforming is a key technology in millimeter-wave (mmWave) communications that improves signal transmission by optimizing directionality and intensity. However, conventional channel estimation methods, such as pilot signals or beam sweeping, often fail to adapt to rapidly changing communication environments. To address this limitation, multimodal sensing-aided beam prediction has gained significant attention, using various sensing data from devices such as LiDAR, radar, GPS, and RGB images to predict user locations or network conditions. Despite its promising potential, the adoption of multimodal sensing-aided beam prediction is hindered by high computational complexity, high costs, and limited datasets. Thus, in this paper, a novel resource-efficient learning framework is introduced for beam prediction, which leverages a custom-designed cross-modal relational knowledge distillation (CRKD) algorithm specifically tailored for beam prediction tasks, to transfer knowledge from a multimodal network to a radar-only student model, achieving high accuracy with reduced computational cost. To enable multimodal learning with realistic data, a novel multimodal simulation framework is developed while integrating sensor data generated from the autonomous driving simulator CARLA with MATLAB-based mmWave channel modeling, and reflecting real-world conditions. The proposed CRKD achieves its objective by distilling relational information across different feature spaces, which enhances beam prediction performance without relying on expensive sensor data. Simulation results demonstrate that CRKD efficiently distills multimodal knowledge, allowing a radar-only model to achieve $94.62%$ of the teacher performance. In particular, this is achieved with just $10%$ of the teacher network's parameters, thereby significantly reducing computational complexity and dependence on multimodal sensor data.",
    "published": "2025-04-07T15:38:25Z",
    "updated": "2025-12-01T12:30:27Z",
    "link": "http://arxiv.org/pdf/2504.05187v2.pdf",
    "category": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Yu Min Park",
      "Yan Kyaw Tun",
      "Eui-Nam Huh",
      "Walid Saad",
      "Choong Seon Hong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.13231v3",
    "title": "VITA: Vision-to-Action Flow Matching Policy",
    "summary": "Conventional flow matching and diffusion-based policies sample through iterative denoising from standard noise distributions (e.g., Gaussian), and require conditioning modules to repeatedly incorporate visual information during the generative process, incurring substantial time and memory overhead. To reduce the complexity, we develop VITA(VIsion-To-Action policy), a noise-free and conditioning-free flow matching policy learning framework that directly flows from visual representations to latent actions. Since the source of the flow is visually grounded, VITA eliminates the need of visual conditioning during generation. As expected, bridging vision and action is challenging, because actions are lower-dimensional, less structured, and sparser than visual representations; moreover, flow matching requires the source and target to have the same dimensionality. To overcome this, we introduce an action autoencoder that maps raw actions into a structured latent space aligned with visual latents, trained jointly with flow matching. To further prevent latent space collapse, we propose flow latent decoding, which anchors the latent generation process by backpropagating the action reconstruction loss through the flow matching ODE (ordinary differential equation) solving steps. We evaluate VITA on 9 simulation and 5 real-world tasks from ALOHA and Robomimic. VITA achieves 1.5x-2x faster inference compared to conventional methods with conditioning modules, while outperforming or matching state-of-the-art policies. Codes, datasets, and demos are available at our project page: https://ucd-dare.github.io/VITA/.",
    "published": "2025-07-17T15:41:57Z",
    "updated": "2025-12-01T12:22:05Z",
    "link": "http://arxiv.org/pdf/2507.13231v3.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "authors": [
      "Dechen Gao",
      "Boqi Zhao",
      "Andrew Lee",
      "Ian Chuang",
      "Hanchu Zhou",
      "Hang Wang",
      "Zhe Zhao",
      "Junshan Zhang",
      "Iman Soltani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.00092v2",
    "title": "Robust Detection of Synthetic Tabular Data under Schema Variability",
    "summary": "The rise of powerful generative models has sparked concerns over data authenticity. While detection methods have been extensively developed for images and text, the case of tabular data, despite its ubiquity, has been largely overlooked. Yet, detecting synthetic tabular data is especially challenging due to its heterogeneous structure and unseen formats at test time. We address the underexplored task of detecting synthetic tabular data ''in the wild'', i.e. when the detector is deployed on tables with variable and previously unseen schemas. We introduce a novel datum-wise transformer architecture that significantly outperforms the only previously published baseline, improving both AUC and accuracy by 7 points. By incorporating a table-adaptation component, our model gains an additional 7 accuracy points, demonstrating enhanced robustness. This work provides the first strong evidence that detecting synthetic tabular data in real-world conditions is feasible, and demonstrates substantial improvements over previous approaches. Following acceptance of the paper, we are finalizing the administrative and licensing procedures necessary for releasing the source code. This extended version will be updated as soon as the release is complete.",
    "published": "2025-08-27T13:46:39Z",
    "updated": "2025-12-01T12:19:17Z",
    "link": "http://arxiv.org/pdf/2509.00092v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.DB"
    ],
    "authors": [
      "G. Charbel N. Kindji",
      "Elisa Fromont",
      "Lina Maria Rojas-Barahona",
      "Tanguy Urvoy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.20347v2",
    "title": "Soft Adaptive Policy Optimization",
    "summary": "Reinforcement learning (RL) plays an increasingly important role in enhancing the reasoning capabilities of large language models (LLMs), yet stable and performant policy optimization remains challenging. Token-level importance ratios often exhibit high variance-a phenomenon exacerbated in Mixture-of-Experts models-leading to unstable updates. Existing group-based policy optimization methods, such as GSPO and GRPO, alleviate this problem via hard clipping, making it difficult to maintain both stability and effective learning. We propose Soft Adaptive Policy Optimization (SAPO), which replaces hard clipping with a smooth, temperature-controlled gate that adaptively attenuates off-policy updates while preserving useful learning signals. Compared with GSPO and GRPO, SAPO is both sequence-coherent and token-adaptive. Like GSPO, SAPO maintains sequence-level coherence, but its soft gating forms a continuous trust region that avoids the brittle hard clipping band used in GSPO. When a sequence contains a few highly off-policy tokens, GSPO suppresses all gradients for that sequence, whereas SAPO selectively down-weights only the offending tokens and preserves the learning signal from the near-on-policy ones, improving sample efficiency. Relative to GRPO, SAPO replaces hard token-level clipping with smooth, temperature-controlled scaling, enabling more informative and stable updates. Empirical results on mathematical reasoning benchmarks indicate that SAPO exhibits improved training stability and higher Pass@1 performance under comparable training budgets. Moreover, we employ SAPO to train the Qwen3-VL model series, demonstrating that SAPO yields consistent performance gains across diverse tasks and different model sizes. Overall, SAPO provides a more reliable, scalable, and effective optimization strategy for RL training of LLMs.",
    "published": "2025-11-25T14:25:19Z",
    "updated": "2025-12-01T12:02:46Z",
    "link": "http://arxiv.org/pdf/2511.20347v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Chang Gao",
      "Chujie Zheng",
      "Xiong-Hui Chen",
      "Kai Dang",
      "Shixuan Liu",
      "Bowen Yu",
      "An Yang",
      "Shuai Bai",
      "Jingren Zhou",
      "Junyang Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.07663v3",
    "title": "Human Decision-making is Susceptible to AI-driven Manipulation",
    "summary": "AI systems are increasingly intertwined with daily life, assisting users with various tasks and guiding decision-making. This integration introduces risks of AI-driven manipulation, where such systems may exploit users' cognitive biases and emotional vulnerabilities to steer them toward harmful outcomes. Through a randomized between-subjects experiment with 233 participants, we examined human susceptibility to such manipulation in financial (e.g., purchases) and emotional (e.g., conflict resolution) decision-making contexts. Participants interacted with one of three AI agents: a neutral agent (NA) optimizing for user benefit without explicit influence, a manipulative agent (MA) designed to covertly influence beliefs and behaviors, or a strategy-enhanced manipulative agent (SEMA) equipped with established psychological tactics, allowing it to select and apply them adaptively during interactions to reach its hidden objectives. By analyzing participants' preference ratings, we found significant susceptibility to AI-driven manipulation. Particularly across both decision-making domains, interacting with the manipulative agents significantly increased the odds of rating hidden incentives higher than optimal options (Financial, MA: OR=5.24, SEMA: OR=7.96; Emotional, MA: OR=5.52, SEMA: OR=5.71) compared to the NA group. Notably, we found no clear evidence that employing psychological strategies (SEMA) was overall more effective than simple manipulative objectives (MA) on our primary outcomes. Hence, AI-driven manipulation could become widespread even without requiring sophisticated tactics and expertise. While our findings are preliminary and derived from hypothetical, low-stakes scenarios, we highlight a critical vulnerability in human-AI interactions, emphasizing the need for ethical safeguards and regulatory frameworks to protect human autonomy.",
    "published": "2025-02-11T15:56:22Z",
    "updated": "2025-12-01T12:01:41Z",
    "link": "http://arxiv.org/pdf/2502.07663v3.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.HC"
    ],
    "authors": [
      "Sahand Sabour",
      "June M. Liu",
      "Siyang Liu",
      "Chris Z. Yao",
      "Shiyao Cui",
      "Xuanming Zhang",
      "Wen Zhang",
      "Yaru Cao",
      "Advait Bhat",
      "Jian Guan",
      "Wei Wu",
      "Rada Mihalcea",
      "Hongning Wang",
      "Tim Althoff",
      "Tatia M. C. Lee",
      "Minlie Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01582v1",
    "title": "RoleMotion: A Large-Scale Dataset towards Robust Scene-Specific Role-Playing Motion Synthesis with Fine-grained Descriptions",
    "summary": "In this paper, we introduce RoleMotion, a large-scale human motion dataset that encompasses a wealth of role-playing and functional motion data tailored to fit various specific scenes. Existing text datasets are mainly constructed decentrally as amalgamation of assorted subsets that their data are nonfunctional and isolated to work together to cover social activities in various scenes. Also, the quality of motion data is inconsistent, and textual annotation lacks fine-grained details in these datasets. In contrast, RoleMotion is meticulously designed and collected with a particular focus on scenes and roles. The dataset features 25 classic scenes, 110 functional roles, over 500 behaviors, and 10296 high-quality human motion sequences of body and hands, annotated with 27831 fine-grained text descriptions. We build an evaluator stronger than existing counterparts, prove its reliability, and evaluate various text-to-motion methods on our dataset. Finally, we explore the interplay of motion generation of body and hands. Experimental results demonstrate the high-quality and functionality of our dataset on text-driven whole-body generation.",
    "published": "2025-12-01T11:59:03Z",
    "updated": "2025-12-01T11:59:03Z",
    "link": "http://arxiv.org/pdf/2512.01582v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Junran Peng",
      "Yiheng Huang",
      "Silei Shen",
      "Zeji Wei",
      "Jingwei Yang",
      "Baojie Wang",
      "Yonghao He",
      "Chuanchen Luo",
      "Man Zhang",
      "Xucheng Yin",
      "Wei Sui"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.08206v3",
    "title": "EHRStruct: A Comprehensive Benchmark Framework for Evaluating Large Language Models on Structured Electronic Health Record Tasks",
    "summary": "Structured Electronic Health Record (EHR) data stores patient information in relational tables and plays a central role in clinical decision-making. Recent advances have explored the use of large language models (LLMs) to process such data, showing promise across various clinical tasks. However, the absence of standardized evaluation frameworks and clearly defined tasks makes it difficult to systematically assess and compare LLM performance on structured EHR data. To address these evaluation challenges, we introduce EHRStruct, a benchmark specifically designed to evaluate LLMs on structured EHR tasks. EHRStruct defines 11 representative tasks spanning diverse clinical needs and includes 2,200 task-specific evaluation samples derived from two widely used EHR datasets. We use EHRStruct to evaluate 20 advanced and representative LLMs, covering both general and medical models. We further analyze key factors influencing model performance, including input formats, few-shot generalisation, and finetuning strategies, and compare results with 11 state-of-the-art LLM-based enhancement methods for structured data reasoning. Our results indicate that many structured EHR tasks place high demands on the understanding and reasoning capabilities of LLMs. In response, we propose EHRMaster, a code-augmented method that achieves state-of-the-art performance and offers practical insights to guide future research.",
    "published": "2025-11-11T13:10:13Z",
    "updated": "2025-12-01T11:51:41Z",
    "link": "http://arxiv.org/pdf/2511.08206v3.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Xiao Yang",
      "Xuejiao Zhao",
      "Zhiqi Shen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01576v1",
    "title": "From Black Hole to Galaxy: Neural Operator: Framework for Accretion and Feedback Dynamics",
    "summary": "Modeling how supermassive black holes co-evolve with their host galaxies is notoriously hard because the relevant physics spans nine orders of magnitude in scale-from milliparsecs to megaparsecs--making end-to-end first-principles simulation infeasible. To characterize the feedback from the small scales, existing methods employ a static subgrid scheme or one based on theoretical guesses, which usually struggle to capture the time variability and derive physically faithful results. Neural operators are a class of machine learning models that achieve significant speed-up in simulating complex dynamics. We introduce a neural-operator-based ''subgrid black hole'' that learns the small-scale local dynamics and embeds it within the direct multi-level simulations. Trained on small-domain (general relativistic) magnetohydrodynamic data, the model predicts the unresolved dynamics needed to supply boundary conditions and fluxes at coarser levels across timesteps, enabling stable long-horizon rollouts without hand-crafted closures. Thanks to the great speedup in fine-scale evolution, our approach for the first time captures intrinsic variability in accretion-driven feedback, allowing dynamic coupling between the central black hole and galaxy-scale gas. This work reframes subgrid modeling in computational astrophysics with scale separation and provides a scalable path toward data-driven closures for a broad class of systems with central accretors.",
    "published": "2025-12-01T11:47:49Z",
    "updated": "2025-12-01T11:47:49Z",
    "link": "http://arxiv.org/pdf/2512.01576v1.pdf",
    "category": [
      "astro-ph.HE",
      "astro-ph.GA",
      "cs.AI",
      "gr-qc"
    ],
    "authors": [
      "Nihaal Bhojwani",
      "Chuwei Wang",
      "Hai-Yang Wang",
      "Chang Sun",
      "Elias R. Most",
      "Anima Anandkumar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01572v1",
    "title": "Reconstructing Multi-Scale Physical Fields from Extremely Sparse Measurements with an Autoencoder-Diffusion Cascade",
    "summary": "Reconstructing full fields from extremely sparse and random measurements is a longstanding ill-posed inverse problem. A powerful framework for addressing such challenges is hierarchical probabilistic modeling, where uncertainty is represented by intermediate variables and resolved through marginalization during inference. Inspired by this principle, we propose Cascaded Sensing (Cas-Sensing), a hierarchical reconstruction framework that integrates an autoencoder-diffusion cascade. First, a neural operator-based functional autoencoder reconstructs the dominant structures of the original field - including large-scale components and geometric boundaries - from arbitrary sparse inputs, serving as an intermediate variable. Then, a conditional diffusion model, trained with a mask-cascade strategy, generates fine-scale details conditioned on these large-scale structures. To further enhance fidelity, measurement consistency is enforced via the manifold constrained gradient based on Bayesian posterior sampling during the generation process. This cascaded pipeline substantially alleviates ill-posedness, delivering accurate and robust reconstructions. Experiments on both simulation and real-world datasets demonstrate that Cas-Sensing generalizes well across varying sensor configurations and geometric boundaries, making it a promising tool for practical deployment in scientific and engineering applications.",
    "published": "2025-12-01T11:46:14Z",
    "updated": "2025-12-01T11:46:14Z",
    "link": "http://arxiv.org/pdf/2512.01572v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "physics.app-ph"
    ],
    "authors": [
      "Letian Yi",
      "Tingpeng Zhang",
      "Mingyuan Zhou",
      "Guannan Wang",
      "Quanke Su",
      "Zhilu Lai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.12360v2",
    "title": "A Method for Handling Negative Similarities in Explainable Graph Spectral Clustering of Text Documents -- Extended Version",
    "summary": "This paper investigates the problem of Graph Spectral Clustering with negative similarities, resulting from document embeddings different from the traditional Term Vector Space (like doc2vec, GloVe, etc.). Solutions for combinatorial Laplacians and normalized Laplacians are discussed. An experimental investigation shows the advantages and disadvantages of 6 different solutions proposed in the literature and in this research. The research demonstrates that GloVe embeddings frequently cause failures of normalized Laplacian based GSC due to negative similarities. Furthermore, application of methods curing similarity negativity leads to accuracy improvement for both combinatorial and normalized Laplacian based GSC. It also leads to applicability for GloVe embeddings of explanation methods developed originally bythe authors for Term Vector Space embeddings.",
    "published": "2025-04-16T06:03:02Z",
    "updated": "2025-12-01T11:42:02Z",
    "link": "http://arxiv.org/pdf/2504.12360v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Mieczysław A. Kłopotek",
      "Sławomir T. Wierzchoń",
      "Bartłomiej Starosta",
      "Dariusz Czerski",
      "Piotr Borkowski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01565v1",
    "title": "Deep FlexQP: Accelerated Nonlinear Programming via Deep Unfolding",
    "summary": "We propose an always-feasible quadratic programming (QP) optimizer, FlexQP, which is based on an exact relaxation of the QP constraints. If the original constraints are feasible, then the optimizer finds the optimal solution to the original QP. On the other hand, if the constraints are infeasible, the optimizer identifies a solution that minimizes the constraint violation in a sparse manner. FlexQP scales favorably with respect to the problem dimension, is robust to both feasible and infeasible QPs with minimal assumptions on the problem data, and can be effectively warm-started. We subsequently apply deep unfolding to improve our optimizer through data-driven techniques, leading to an accelerated Deep FlexQP. By learning dimension-agnostic feedback policies for the parameters from a small number of training examples, Deep FlexQP generalizes to problems with larger dimensions and can optimize for many more iterations than it was initially trained for. Our approach outperforms two recently proposed state-of-the-art accelerated QP approaches on a suite of benchmark systems including portfolio optimization, classification, and regression problems. We provide guarantees on the expected performance of our deep QP optimizer through probably approximately correct (PAC) Bayes generalization bounds. These certificates are used to design an accelerated sequential quadratic programming solver that solves nonlinear optimal control and predictive safety filter problems faster than traditional approaches. Overall, our approach is very robust and greatly outperforms existing non-learning and learning-based optimizers in terms of both runtime and convergence to the optimal solution across multiple classes of NLPs.",
    "published": "2025-12-01T11:38:45Z",
    "updated": "2025-12-01T11:38:45Z",
    "link": "http://arxiv.org/pdf/2512.01565v1.pdf",
    "category": [
      "math.OC",
      "cs.AI"
    ],
    "authors": [
      "Alex Oshin",
      "Rahul Vodeb Ghosh",
      "Augustinos D. Saravanos",
      "Evangelos A. Theodorou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01563v1",
    "title": "MasHeNe: A Benchmark for Head and Neck CT Mass Segmentation using Window-Enhanced Mamba with Frequency-Domain Integration",
    "summary": "Head and neck masses are space-occupying lesions that can compress the airway and esophagus and may affect nerves and blood vessels. Available public datasets primarily focus on malignant lesions and often overlook other space-occupying conditions in this region. To address this gap, we introduce MasHeNe, an initial dataset of 3,779 contrast-enhanced CT slices that includes both tumors and cysts with pixel-level annotations. We also establish a benchmark using standard segmentation baselines and report common metrics to enable fair comparison. In addition, we propose the Windowing-Enhanced Mamba with Frequency integration (WEMF) model. WEMF applies tri-window enhancement to enrich the input appearance before feature extraction. It further uses multi-frequency attention to fuse information across skip connections within a U-shaped Mamba backbone. On MasHeNe, WEMF attains the best performance among evaluated methods, with a Dice of 70.45%, IoU of 66.89%, NSD of 72.33%, and HD95 of 5.12 mm. This model indicates stable and strong results on this challenging task. MasHeNe provides a benchmark for head-and-neck mass segmentation beyond malignancy-only datasets. The observed error patterns also suggest that this task remains challenging and requires further research. Our dataset and code are available at https://github.com/drthaodao3101/MasHeNe.git.",
    "published": "2025-12-01T11:38:05Z",
    "updated": "2025-12-01T11:38:05Z",
    "link": "http://arxiv.org/pdf/2512.01563v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Thao Thi Phuong Dao",
      "Tan-Cong Nguyen",
      "Nguyen Chi Thanh",
      "Truong Hoang Viet",
      "Trong-Le Do",
      "Mai-Khiem Tran",
      "Minh-Khoi Pham",
      "Trung-Nghia Le",
      "Minh-Triet Tran",
      "Thanh Dinh Le"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01556v1",
    "title": "LEC: Linear Expectation Constraints for False-Discovery Control in Selective Prediction and Routing Systems",
    "summary": "Large language models (LLMs) often generate unreliable answers, while heuristic uncertainty methods fail to fully distinguish correct from incorrect predictions, causing users to accept erroneous answers without statistical guarantees. We address this issue through the lens of false discovery rate (FDR) control, ensuring that among all accepted predictions, the proportion of errors does not exceed a target risk level. To achieve this in a principled way, we propose LEC, which reinterprets selective prediction as a constrained decision problem by enforcing a Linear Expectation Constraint over selection and error indicators. Then, we establish a finite-sample sufficient condition, which relies only on a held-out set of exchangeable calibration samples, to compute an FDR-constrained, coverage-maximizing threshold. Furthermore, we extend LEC to a two-model routing mechanism: given a prompt, if the current model's uncertainty exceeds its calibrated threshold, we delegate it to a stronger model, while maintaining a unified FDR guarantee. Evaluations on closed-ended and open-ended question-answering (QA) datasets show that LEC achieves tighter FDR control and substantially improves sample retention over prior methods. Moreover, the two-model routing mechanism achieves lower risk levels while accepting more correct samples than each individual model.",
    "published": "2025-12-01T11:27:09Z",
    "updated": "2025-12-01T11:27:09Z",
    "link": "http://arxiv.org/pdf/2512.01556v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Zhiyuan Wang",
      " Aniri",
      "Tianlong Chen",
      "Yue Zhang",
      "Heng Tao Shen",
      "Xiaoshuang Shi",
      "Kaidi Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01549v1",
    "title": "Delta Sum Learning: an approach for fast and global convergence in Gossip Learning",
    "summary": "Federated Learning is a popular approach for distributed learning due to its security and computational benefits. With the advent of powerful devices in the network edge, Gossip Learning further decentralizes Federated Learning by removing centralized integration and relying fully on peer to peer updates. However, the averaging methods generally used in both Federated and Gossip Learning are not ideal for model accuracy and global convergence. Additionally, there are few options to deploy Learning workloads in the edge as part of a larger application using a declarative approach such as Kubernetes manifests. This paper proposes Delta Sum Learning as a method to improve the basic aggregation operation in Gossip Learning, and implements it in a decentralized orchestration framework based on Open Application Model, which allows for dynamic node discovery and intent-driven deployment of multi-workload applications. Evaluation results show that Delta Sum performance is on par with alternative integration methods for 10 node topologies, but results in a 58% lower global accuracy drop when scaling to 50 nodes. Overall, it shows strong global convergence and a logarithmic loss of accuracy with increasing topology size compared to a linear loss for alternatives under limited connectivity.",
    "published": "2025-12-01T11:23:51Z",
    "updated": "2025-12-01T11:23:51Z",
    "link": "http://arxiv.org/pdf/2512.01549v1.pdf",
    "category": [
      "cs.DC",
      "cs.AI"
    ],
    "authors": [
      "Tom Goethals",
      "Merlijn Sebrechts",
      "Stijn De Schrijver",
      "Filip De Turck",
      "Bruno Volckaert"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01546v1",
    "title": "LPCD: Unified Framework from Layer-Wise to Submodule Quantization",
    "summary": "Post-training quantization (PTQ) aims to preserve model-level behavior; however, most methods focus on individual linear layers. Even recent extensions, such as QEP and LoaQ, which mitigate error propagation or target specific submodules, still rely on layer-wise formulations and fail to capture the behavior of larger submodules. We introduce Layer-Projected Coordinate Descent (LPCD), a unified framework that extends PTQ beyond layers by optimizing relaxed objectives across arbitrary submodules and projecting the solutions with layer-wise quantizers. LPCD generalizes existing methods and provides a principled approach to quantizing complex submodules while maintaining the efficiency and compatibility of layer-wise PTQ pipelines. Across diverse LLM architectures and bit-widths, LPCD-based submodule quantization consistently enhances both layer-wise PTQ methods and existing submodule approaches.",
    "published": "2025-12-01T11:21:18Z",
    "updated": "2025-12-01T11:21:18Z",
    "link": "http://arxiv.org/pdf/2512.01546v1.pdf",
    "category": [
      "stat.ML",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Yuma Ichikawa",
      "Yudai Fujimoto",
      "Akira Sakai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.12284v3",
    "title": "MERA Code: A Unified Framework for Evaluating Code Generation Across Tasks",
    "summary": "Advancements in LLMs have enhanced task automation in software engineering; however, current evaluations primarily focus on natural language tasks, overlooking code quality. Most benchmarks prioritize high-level reasoning over executable code and real-world performance, leaving gaps in understanding true capabilities and risks associated with these models in production. To address this issue, we propose MERA Code, a new addition to the MERA benchmark family, specifically focused on evaluating code for the latest code generation LLMs in Russian. This benchmark includes 11 evaluation tasks that span 8 programming languages. Our proposed evaluation methodology features a taxonomy that outlines the practical coding skills necessary for models to complete these tasks. The benchmark comprises an open-source codebase for users to conduct MERA assessments, a scoring system compatible with various programming environments, and a platform featuring a leaderboard and submission system. We evaluate open LLMs and frontier API models, analyzing their limitations in terms of practical coding tasks in non-English languages. We are publicly releasing MERA to guide future research, anticipate groundbreaking features in model development, and standardize evaluation procedures.",
    "published": "2025-07-16T14:31:33Z",
    "updated": "2025-12-01T11:19:37Z",
    "link": "http://arxiv.org/pdf/2507.12284v3.pdf",
    "category": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Artem Chervyakov",
      "Alexander Kharitonov",
      "Pavel Zadorozhny",
      "Adamenko Pavel",
      "Rodion Levichev",
      "Dmitrii Vorobev",
      "Dmitrii Salikhov",
      "Aidar Valeev",
      "Alena Pestova",
      "Maria Dziuba",
      "Ilseyar Alimova",
      "Artem Zavgorodnev",
      "Aleksandr Medvedev",
      "Stanislav Moiseev",
      "Elena Bruches",
      "Daniil Grebenkin",
      "Roman Derunets",
      "Vikulov Vladimir",
      "Anton Emelyanov",
      "Dmitrii Babaev",
      "Vladimir V. Ivanov",
      "Valentin Malykh",
      "Alena Fenogenova"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01537v1",
    "title": "Q2D2: A Geometry-Aware Audio Codec Leveraging Two-Dimensional Quantization",
    "summary": "Recent neural audio codecs have achieved impressive reconstruction quality, typically relying on quantization methods such as Residual Vector Quantization (RVQ), Vector Quantization (VQ) and Finite Scalar Quantization (FSQ). However, these quantization techniques limit the geometric structure of the latent space, make it harder to capture correlations between features leading to inefficiency in representation learning, codebook utilization and token rate. In this paper we introduce Two Dimensional Quantization (Q2D2), a quantization scheme in which feature pairs are projected onto structured 2D grids such as hexagonal, rhombic, or rectangular tiling and quantized to the nearest grid values, yielding an implicit codebook defined by the product of grid levels, with codebook sizes comparable to conventional methods. Despite its simple geometric formulation, Q2D2 improves audio compression efficiency, with low token rates and high codebook utilization while maintaining state of the art reconstruction quality. Specifically, Q2D2 achieves competitive to superior performance in various objective and subjective reconstruction metrics, across extensive experiments in speech domain compared to state of the art models. Comprehensive ablation studies further confirm the effectiveness of our design choices.",
    "published": "2025-12-01T11:06:38Z",
    "updated": "2025-12-01T11:06:38Z",
    "link": "http://arxiv.org/pdf/2512.01537v1.pdf",
    "category": [
      "cs.SD",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "eess.SP"
    ],
    "authors": [
      "Tal Shuster",
      "Eliya Nachmani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12170v2",
    "title": "Rethinking Multimodal Point Cloud Completion: A Completion-by-Correction Perspective",
    "summary": "Point cloud completion aims to reconstruct complete 3D shapes from partial observations, which is a challenging problem due to severe occlusions and missing geometry. Despite recent advances in multimodal techniques that leverage complementary RGB images to compensate for missing geometry, most methods still follow a Completion-by-Inpainting paradigm, synthesizing missing structures from fused latent features. We empirically show that this paradigm often results in structural inconsistencies and topological artifacts due to limited geometric and semantic constraints. To address this, we rethink the task and propose a more robust paradigm, termed Completion-by-Correction, which begins with a topologically complete shape prior generated by a pretrained image-to-3D model and performs feature-space correction to align it with the partial observation. This paradigm shifts completion from unconstrained synthesis to guided refinement, enabling structurally consistent and observation-aligned reconstruction. Building upon this paradigm, we introduce PGNet, a multi-stage framework that conducts dual-feature encoding to ground the generative prior, synthesizes a coarse yet structurally aligned scaffold, and progressively refines geometric details via hierarchical correction. Experiments on the ShapeNetViPC dataset demonstrate the superiority of PGNet over state-of-the-art baselines in terms of average Chamfer Distance (-23.5%) and F-score (+7.1%).",
    "published": "2025-11-15T11:51:13Z",
    "updated": "2025-12-01T11:06:18Z",
    "link": "http://arxiv.org/pdf/2511.12170v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Wang Luo",
      "Di Wu",
      "Hengyuan Na",
      "Yinlin Zhu",
      "Miao Hu",
      "Guocong Quan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01534v1",
    "title": "Deep Unsupervised Anomaly Detection in Brain Imaging: Large-Scale Benchmarking and Bias Analysis",
    "summary": "Deep unsupervised anomaly detection in brain magnetic resonance imaging offers a promising route to identify pathological deviations without requiring lesion-specific annotations. Yet, fragmented evaluations, heterogeneous datasets, and inconsistent metrics have hindered progress toward clinical translation. Here, we present a large-scale, multi-center benchmark of deep unsupervised anomaly detection for brain imaging. The training cohort comprised 2,976 T1 and 2,972 T2-weighted scans from healthy individuals across six scanners, with ages ranging from 6 to 89 years. Validation used 92 scans to tune hyperparameters and estimate unbiased thresholds. Testing encompassed 2,221 T1w and 1,262 T2w scans spanning healthy datasets and diverse clinical cohorts. Across all algorithms, the Dice-based segmentation performance varied between 0.03 and 0.65, indicating substantial variability. To assess robustness, we systematically evaluated the impact of different scanners, lesion types and sizes, as well as demographics (age, sex). Reconstruction-based methods, particularly diffusion-inspired approaches, achieved the strongest lesion segmentation performance, while feature-based methods showed greater robustness under distributional shifts. However, systematic biases, such as scanner-related effects, were observed for the majority of algorithms, including that small and low-contrast lesions were missed more often, and that false positives varied with age and sex. Increasing healthy training data yields only modest gains, underscoring that current unsupervised anomaly detection frameworks are limited algorithmically rather than by data availability. Our benchmark establishes a transparent foundation for future research and highlights priorities for clinical translation, including image native pretraining, principled deviation measures, fairness-aware modeling, and robust domain adaptation.",
    "published": "2025-12-01T11:03:27Z",
    "updated": "2025-12-01T11:03:27Z",
    "link": "http://arxiv.org/pdf/2512.01534v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Alexander Frotscher",
      "Christian F. Baumgartner",
      "Thomas Wolfers"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01533v1",
    "title": "Diffusion Fuzzy System: Fuzzy Rule Guided Latent Multi-Path Diffusion Modeling",
    "summary": "Diffusion models have emerged as a leading technique for generating images due to their ability to create high-resolution and realistic images. Despite their strong performance, diffusion models still struggle in managing image collections with significant feature differences. They often fail to capture complex features and produce conflicting results. Research has attempted to address this issue by learning different regions of an image through multiple diffusion paths and then combining them. However, this approach leads to inefficient coordination among multiple paths and high computational costs. To tackle these issues, this paper presents a Diffusion Fuzzy System (DFS), a latent-space multi-path diffusion model guided by fuzzy rules. DFS offers several advantages. First, unlike traditional multi-path diffusion methods, DFS uses multiple diffusion paths, each dedicated to learning a specific class of image features. By assigning each path to a different feature type, DFS overcomes the limitations of multi-path models in capturing heterogeneous image features. Second, DFS employs rule-chain-based reasoning to dynamically steer the diffusion process and enable efficient coordination among multiple paths. Finally, DFS introduces a fuzzy membership-based latent-space compression mechanism to reduce the computational costs of multi-path diffusion effectively. We tested our method on three public datasets: LSUN Bedroom, LSUN Church, and MS COCO. The results show that DFS achieves more stable training and faster convergence than existing single-path and multi-path diffusion models. Additionally, DFS surpasses baseline models in both image quality and alignment between text and images, and also shows improved accuracy when comparing generated images to target references.",
    "published": "2025-12-01T11:01:06Z",
    "updated": "2025-12-01T11:01:06Z",
    "link": "http://arxiv.org/pdf/2512.01533v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Hailong Yang",
      "Te Zhang",
      "Kup-sze Choi",
      "Zhaohong Deng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01523v1",
    "title": "Teaching an Online Multi-Institutional Research Level Software Engineering Course with Industry - an Experience Report",
    "summary": "Covid has made online teaching and learning acceptable and students, faculty, and industry professionals are all comfortable with this mode. This comfort can be leveraged to offer an online multi-institutional research-level course in an area where individual institutions may not have the requisite faculty to teach and/or research students to enroll. If the subject is of interest to industry, online offering also allows industry experts to contribute and participate with ease. Advanced topics in Software Engineering are ideally suited for experimenting with this approach as industry, which is often looking to incorporate advances in software engineering in their practices, is likely to agree to contribute and participate. In this paper we describe an experiment in teaching a course titled \"AI in Software Engineering\" jointly between two institutions with active industry participation, and share our and student's experience. We believe this collaborative teaching approach can be used for offering research level courses in any applied area of computer science by institutions who are small and find it difficult to offer research level courses on their own.",
    "published": "2025-12-01T10:46:43Z",
    "updated": "2025-12-01T10:46:43Z",
    "link": "http://arxiv.org/pdf/2512.01523v1.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Pankaj Jalore",
      "Y. Raghu Reddy",
      "Vasudeva Varma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01507v1",
    "title": "SynthStrategy: Extracting and Formalizing Latent Strategic Insights from LLMs in Organic Chemistry",
    "summary": "Modern computer-assisted synthesis planning (CASP) systems show promises at generating chemically valid reaction steps but struggle to incorporate strategic considerations such as convergent assembly, protecting group minimization, and optimal ring-forming sequences. We introduce a methodology that leverages Large Language Models to distill synthetic knowledge into code. Our system analyzes synthesis routes and translates strategic principles into Python functions representing diverse strategic and tactical rules, such as strategic functional group interconversions and ring construction strategies. By formalizing this knowledge as verifiable code rather than simple heuristics, we create testable, interpretable representations of synthetic strategy. We release the complete codebase and the USPTO-ST dataset -- synthesis routes annotated with strategic tags. This framework unlocks a novel capability for CASP: natural language-based route retrieval, achieving 75\\% Top-3 accuracy on our benchmark. We further validate our library through temporal analysis of historical trends and chemically intuitive route clustering that offers more granular partitioning than common previous methods. This work bridges the tactical-strategic divide in CASP, enabling specification, search, and evaluation of routes by strategic criteria rather than structure alone.",
    "published": "2025-12-01T10:33:00Z",
    "updated": "2025-12-01T10:33:00Z",
    "link": "http://arxiv.org/pdf/2512.01507v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Daniel Armstrong",
      "Zlatko Jončev",
      "Andres M Bran",
      "Philippe Schwaller"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01502v1",
    "title": "Formal Verification of Noisy Quantum Reinforcement Learning Policies",
    "summary": "Quantum reinforcement learning (QRL) aims to use quantum effects to create sequential decision-making policies that achieve tasks more effectively than their classical counterparts. However, QRL policies face uncertainty from quantum measurements and hardware noise, such as bit-flip, phase-flip, and depolarizing errors, which can lead to unsafe behavior. Existing work offers no systematic way to verify whether trained QRL policies meet safety requirements under specific noise conditions.\n  We introduce QVerifier, a formal verification method that applies probabilistic model checking to analyze trained QRL policies with and without modeled quantum noise. QVerifier builds a complete model of the policy-environment interaction, incorporates quantum uncertainty directly into the transition probabilities, and then checks safety properties using the Storm model checker.\n  Experiments across multiple QRL environments show that QVerifier precisely measures how different noise models influence safety, revealing both performance degradation and cases where noise can help. By enabling rigorous safety verification before deployment, QVerifier addresses a critical need: because access to quantum hardware is expensive, pre-deployment verification is essential for any safety-critical use of QRL. QVerifier targets a potential classical-quantum sweet spot: trained QRL policies that execute efficiently on quantum hardware, yet remain tractable for classical probabilistic model checking despite being too slow for real-time classical deployment.",
    "published": "2025-12-01T10:26:33Z",
    "updated": "2025-12-01T10:26:33Z",
    "link": "http://arxiv.org/pdf/2512.01502v1.pdf",
    "category": [
      "quant-ph",
      "cs.AI",
      "cs.FL"
    ],
    "authors": [
      "Dennis Gross"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.06571v2",
    "title": "Graph Persistence goes Spectral",
    "summary": "Including intricate topological information (e.g., cycles) provably enhances the expressivity of message-passing graph neural networks (GNNs) beyond the Weisfeiler-Leman (WL) hierarchy. Consequently, Persistent Homology (PH) methods are increasingly employed for graph representation learning. In this context, recent works have proposed decorating classical PH diagrams with vertex and edge features for improved expressivity. However, these methods still fail to capture basic graph structural information. In this paper, we propose SpectRe -- a new topological descriptor for graphs that integrates spectral information into PH diagrams. Notably, SpectRe is strictly more expressive than existing descriptors on graphs. We also introduce notions of global and local stability to analyze existing descriptors and establish that SpectRe is locally stable. Finally, experiments on synthetic and real-world datasets demonstrate the effectiveness of SpectRe and its potential to enhance the capabilities of graph models in relevant learning tasks. Code is available at https://github.com/Aalto-QuML/SpectRe/.",
    "published": "2025-06-06T22:51:08Z",
    "updated": "2025-12-01T10:21:46Z",
    "link": "http://arxiv.org/pdf/2506.06571v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "authors": [
      "Mattie Ji",
      "Amauri H. Souza",
      "Vikas Garg"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01485v1",
    "title": "Multi-Path Collaborative Reasoning via Reinforcement Learning",
    "summary": "Chain-of-Thought (CoT) reasoning has significantly advanced the problem-solving capabilities of Large Language Models (LLMs), yet conventional CoT often exhibits internal determinism during decoding, limiting exploration of plausible alternatives. Recent methods attempt to address this by generating soft abstract tokens to enable reasoning in a continuous semantic space. However, we find that such approaches remain constrained by the greedy nature of autoregressive decoding, which fundamentally isolates the model from alternative reasoning possibilities. In this work, we propose Multi-Path Perception Policy Optimization (M3PO), a novel reinforcement learning framework that explicitly injects collective insights into the reasoning process. M3PO leverages parallel policy rollouts as naturally diverse reasoning sources and integrates cross-path interactions into policy updates through a lightweight collaborative mechanism. This design allows each trajectory to refine its reasoning with peer feedback, thereby cultivating more reliable multi-step reasoning patterns. Empirical results show that M3PO achieves state-of-the-art performance on both knowledge- and reasoning-intensive benchmarks. Models trained with M3PO maintain interpretability and inference efficiency, underscoring the promise of multi-path collaborative learning for robust reasoning.",
    "published": "2025-12-01T10:05:46Z",
    "updated": "2025-12-01T10:05:46Z",
    "link": "http://arxiv.org/pdf/2512.01485v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Jindi Lv",
      "Yuhao Zhou",
      "Zheng Zhu",
      "Xiaofeng Wang",
      "Guan Huang",
      "Jiancheng Lv"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01484v1",
    "title": "Multi-view diffusion geometry using intertwined diffusion trajectories",
    "summary": "This paper introduces a comprehensive unified framework for constructing multi-view diffusion geometries through intertwined multi-view diffusion trajectories (MDTs), a class of inhomogeneous diffusion processes that iteratively combine the random walk operators of multiple data views. Each MDT defines a trajectory-dependent diffusion operator with a clear probabilistic and geometric interpretation, capturing over time the interplay between data views. Our formulation encompasses existing multi-view diffusion models, while providing new degrees of freedom for view interaction and fusion. We establish theoretical properties under mild assumptions, including ergodicity of both the point-wise operator and the process in itself. We also derive MDT-based diffusion distances, and associated embeddings via singular value decompositions. Finally, we propose various strategies for learning MDT operators within the defined operator space, guided by internal quality measures. Beyond enabling flexible model design, MDTs also offer a neutral baseline for evaluating diffusion-based approaches through comparison with randomly selected MDTs. Experiments show the practical impact of the MDT operators in a manifold learning and data clustering context.",
    "published": "2025-12-01T10:05:19Z",
    "updated": "2025-12-01T10:05:19Z",
    "link": "http://arxiv.org/pdf/2512.01484v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "authors": [
      "Gwendal Debaussart-Joniec",
      "Argyris Kalogeratos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01473v1",
    "title": "Does Flatness imply Generalization for Logistic Loss in Univariate Two-Layer ReLU Network?",
    "summary": "We consider the problem of generalization of arbitrarily overparameterized two-layer ReLU Neural Networks with univariate input. Recent work showed that under square loss, flat solutions (motivated by flat / stable minima and Edge of Stability phenomenon) provably cannot overfit, but it remains unclear whether the same phenomenon holds for logistic loss. This is a puzzling open problem because existing work on logistic loss shows that gradient descent with increasing step size converges to interpolating solutions (at infinity, for the margin-separable cases). In this paper, we prove that the \\emph{flatness implied generalization} is more delicate under logistic loss. On the positive side, we show that flat solutions enjoy near-optimal generalization bounds within a region between the left-most and right-most \\emph{uncertain} sets determined by each candidate solution. On the negative side, we show that there exist arbitrarily flat yet overfitting solutions at infinity that are (falsely) certain everywhere, thus certifying that flatness alone is insufficient for generalization in general. We demonstrate the effects predicted by our theory in a well-controlled simulation study.",
    "published": "2025-12-01T09:57:11Z",
    "updated": "2025-12-01T09:57:11Z",
    "link": "http://arxiv.org/pdf/2512.01473v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "authors": [
      "Dan Qiao",
      "Yu-Xiang Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.01374v3",
    "title": "REASONING COMPILER: LLM-Guided Optimizations for Efficient Model Serving",
    "summary": "While model serving has unlocked unprecedented capabilities, the high cost of serving large-scale models continues to be a significant barrier to widespread accessibility and rapid innovation. Compiler optimizations have long driven substantial performance improvements, but existing compilers struggle with neural workloads due to the exponentially large and highly interdependent space of possible transformations. Although existing stochastic search techniques can be effective, they are often sample-inefficient and fail to leverage the structural context underlying compilation decisions. We set out to investigate the research question of whether reasoning with large language models (LLMs), without any retraining, can leverage the context-aware decision space of compiler optimizations to significantly improve sample efficiency. To that end, we introduce a novel compilation framework (dubbed Reasoning Compiler) that formulates optimization as a sequential, context-aware decision process guided by a large language model and structured Monte Carlo tree search (MCTS). The LLM acts as a proposal mechanism, suggesting hardware-informed transformations that reflect the current program state and accumulated performance feedback. MCTS incorporates the LLM-generated proposals to balance exploration and exploitation, facilitating structured, context-sensitive traversal of the expansive compiler optimization space. By achieving substantial speedups with markedly fewer samples than leading neural compilers, our approach demonstrates the potential of LLM-guided reasoning to transform the landscape of compiler optimization.",
    "published": "2025-06-02T07:02:46Z",
    "updated": "2025-12-01T09:54:10Z",
    "link": "http://arxiv.org/pdf/2506.01374v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.PL"
    ],
    "authors": [
      "Annabelle Sujun Tang",
      "Christopher Priebe",
      "Rohan Mahapatra",
      "Lianhui Qin",
      "Hadi Esmaeilzadeh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.09605v2",
    "title": "TomoGraphView: 3D Medical Image Classification with Omnidirectional Slice Representations and Graph Neural Networks",
    "summary": "The sharp rise in medical tomography examinations has created a demand for automated systems that can reliably extract informative features for downstream tasks such as tumor characterization. Although 3D volumes contain richer information than individual slices, effective 3D classification remains difficult: volumetric data encode complex spatial dependencies, and the scarcity of large-scale 3D datasets has constrained progress toward 3D foundation models. As a result, many recent approaches rely on 2D vision foundation models trained on natural images, repurposing them as feature extractors for medical scans with surprisingly strong performance. Despite their practical success, current methods that apply 2D foundation models to 3D scans via slice-based decomposition remain fundamentally limited. Standard slicing along axial, sagittal, and coronal planes often fails to capture the true spatial extent of a structure when its orientation does not align with these canonical views. More critically, most approaches aggregate slice features independently, ignoring the underlying 3D geometry and losing spatial coherence across slices. To overcome these limitations, we propose TomoGraphView, a novel framework that integrates omnidirectional volume slicing with spherical graph-based feature aggregation. Instead of restricting the model to axial, sagittal, or coronal planes, our method samples both canonical and non-canonical cross-sections generated from uniformly distributed points on a sphere enclosing the volume. We publicly share our accessible code base at http://github.com/compai-lab/2025-MedIA-kiechle and provide a user-friendly library for omnidirectional volume slicing at https://pypi.org/project/OmniSlicer.",
    "published": "2025-11-12T16:30:34Z",
    "updated": "2025-12-01T09:52:37Z",
    "link": "http://arxiv.org/pdf/2511.09605v2.pdf",
    "category": [
      "eess.IV",
      "cs.AI",
      "cs.LG",
      "q-bio.QM"
    ],
    "authors": [
      "Johannes Kiechle",
      "Stefan M. Fischer",
      "Daniel M. Lang",
      "Cosmin I. Bercea",
      "Matthew J. Nyflot",
      "Lina Felsner",
      "Julia A. Schnabel",
      "Jan C. Peeken"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01457v1",
    "title": "ZIP-RC: Zero-overhead Inference-time Prediction of Reward and Cost for Adaptive and Interpretable Generation",
    "summary": "Large language models excel at reasoning but lack key aspects of introspection, including anticipating their own success and the computation required to achieve it. Humans use real-time introspection to decide how much effort to invest, when to make multiple attempts, when to stop, and when to signal success or failure. Without this, LLMs struggle to make intelligent meta-cognition decisions. Test-time scaling methods like Best-of-N drive up cost and latency by using a fixed budget of samples regardless of the marginal benefit of each one at any point in generation, and the absence of confidence signals can mislead people, prevent appropriate escalation to better tools, and undermine trustworthiness. Learned verifiers or reward models can provide confidence estimates, but do not enable adaptive inference and add substantial cost by requiring extra models or forward passes. We present ZIP-RC, an adaptive inference method that equips models with zero-overhead inference-time predictions of reward and cost. At every token, ZIP-RC reuses reserved or unused logits in the same forward pass as next-token prediction to output a joint distribution over final reward and remaining length -- no extra models, architecture change, or inference overhead. This full joint distribution is used to compute a sampling utility which is the linear combination of the expected maximum reward, total compute, and latency of set of samples if generated to completion. During inference, we maximize this utility with meta-actions that determine which prefix of tokens to continue or initiate sampling from. On mixed-difficulty mathematical benchmarks, ZIP-RC improves accuracy by up to 12% over majority voting at equal or lower average cost, and traces smooth Pareto frontiers between quality, compute, and latency. By providing real-time reward-cost introspection, ZIP-RC enables adaptive, efficient reasoning.",
    "published": "2025-12-01T09:44:31Z",
    "updated": "2025-12-01T09:44:31Z",
    "link": "http://arxiv.org/pdf/2512.01457v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Rohin Manvi",
      "Joey Hong",
      "Tim Seyde",
      "Maxime Labonne",
      "Mathias Lechner",
      "Sergey Levine"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01452v1",
    "title": "Automated Risk-of-Bias Assessment of Randomized Controlled Trials: A First Look at a GEPA-trained Programmatic Prompting Framework",
    "summary": "Assessing risk of bias (RoB) in randomized controlled trials is essential for trustworthy evidence synthesis, but the process is resource-intensive and prone to variability across reviewers. Large language models (LLMs) offer a route to automation, but existing methods rely on manually engineered prompts that are difficult to reproduce, generalize, or evaluate. This study introduces a programmable RoB assessment pipeline that replaces ad-hoc prompt design with structured, code-based optimization using DSPy and its GEPA module. GEPA refines LLM reasoning through Pareto-guided search and produces inspectable execution traces, enabling transparent replication of every step in the optimization process. We evaluated the method on 100 RCTs from published meta-analyses across seven RoB domains. GEPA-generated prompts were applied to both open-weight models (Mistral Small 3.1 with GPT-oss-20b) and commercial models (GPT-5 Nano and GPT-5 Mini). In domains with clearer methodological reporting, such as Random Sequence Generation, GEPA-generated prompts performed best, with similar results for Allocation Concealment and Blinding of Participants, while the commercial model performed slightly better overall. We also compared GEPA with three manually designed prompts using Claude 3.5 Sonnet. GEPA achieved the highest overall accuracy and improved performance by 30%-40% in Random Sequence Generation and Selective Reporting, and showed generally comparable, competitively aligned performance in the other domains relative to manual prompts. These findings suggest that GEPA can produce consistent and reproducible prompts for RoB assessment, supporting the structured and principled use of LLMs in evidence synthesis.",
    "published": "2025-12-01T09:39:13Z",
    "updated": "2025-12-01T09:39:13Z",
    "link": "http://arxiv.org/pdf/2512.01452v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Lingbo Li",
      "Anuradha Mathrani",
      "Teo Susnjak"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.03403v3",
    "title": "BoundingDocs: a Unified Dataset for Document Question Answering with Spatial Annotations",
    "summary": "We present a unified dataset for document Question-Answering (QA), which is obtained combining several public datasets related to Document AI and visually rich document understanding (VRDU). Our main contribution is twofold: on the one hand we reformulate existing Document AI tasks, such as Information Extraction (IE), into a Question-Answering task, making it a suitable resource for training and evaluating Large Language Models; on the other hand, we release the OCR of all the documents and include the exact position of the answer to be found in the document image as a bounding box. Using this dataset, we explore the impact of different prompting techniques (that might include bounding box information) on the performance of open-weight models, identifying the most effective approaches for document comprehension.",
    "published": "2025-01-06T21:46:22Z",
    "updated": "2025-12-01T09:36:01Z",
    "link": "http://arxiv.org/pdf/2501.03403v3.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Simone Giovannini",
      "Fabio Coppini",
      "Andrea Gemelli",
      "Simone Marinai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18454v2",
    "title": "AttnRegDeepLab: A Two-Stage Decoupled Framework for Interpretable Embryo Fragmentation Grading",
    "summary": "Embryo fragmentation is a morphological indicator critical for evaluating developmental potential in In Vitro Fertilization (IVF). However, manual grading is subjective and inefficient, while existing deep learning solutions often lack clinical explainability or suffer from accumulated errors in segmentation area estimation. To address these issues, this study proposes AttnRegDeepLab (Attention-Guided Regression DeepLab), a framework characterized by dual-branch Multi-Task Learning (MTL). A vanilla DeepLabV3+ decoder is modified by integrating Attention Gates into its skip connections, explicitly suppressing cytoplasmic noise to preserve contour details. Furthermore, a Multi-Scale Regression Head is introduced with a Feature Injection mechanism to propagate global grading priors into the segmentation task, rectifying systematic quantification errors. A 2-stage decoupled training strategy is proposed to address the gradient conflict in MTL. Also, a range-based loss is designed to leverage weakly labeled data. Our method achieves robust grading precision while maintaining excellent segmentation accuracy (Dice coefficient =0.729), in contrast to the end-to-end counterpart that might minimize grading error at the expense of contour integrity. This work provides a clinically interpretable solution that balances visual fidelity and quantitative precision.",
    "published": "2025-11-23T13:50:49Z",
    "updated": "2025-12-01T09:34:18Z",
    "link": "http://arxiv.org/pdf/2511.18454v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Ming-Jhe Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.17220v2",
    "title": "PARROT: Persuasion and Agreement Robustness Rating of Output Truth -- A Sycophancy Robustness Benchmark for LLMs",
    "summary": "This study presents PARROT (Persuasion and Agreement Robustness Rating of Output Truth), a robustness focused framework designed to measure the degradation in accuracy that occurs under social pressure exerted on users through authority and persuasion in large language models (LLMs) the phenomenon of sycophancy (excessive conformity). PARROT (i) isolates causal effects by comparing the neutral version of the same question with an authoritatively false version using a double-blind evaluation, (ii) quantifies confidence shifts toward the correct and imposed false responses using log-likelihood-based calibration tracking, and (iii) systematically classifies failure modes (e.g., robust correct, sycophantic agreement, reinforced error, stubborn error, self-correction, etc.) using an eight-state behavioral taxonomy. We evaluated 22 models using 1,302 MMLU-style multiple-choice questions across 13 domains and domain-specific authority templates. Findings show marked heterogeneity: advanced models (e.g., GPT-5, GPT-4.1, Claude Sonnet 4.5) exhibit low \"follow rates\" ($\\leq 11\\%$, GPT-5: 4\\%) and minimal accuracy loss, while older/smaller models show severe epistemic collapse (GPT-4: 80\\%, Qwen 2.5-1.5B: 94\\%). The danger is not limited to response changes; weak models reduce confidence in the correct response while increasing confidence in the imposed incorrect response. While international law and global knowledge at the domain level exhibit high fragility, elementary mathematics is relatively resilient. Consequently, we argue that the goal of \"resistance to overfitting pressure\" should be addressed as a primary objective alongside accuracy, harm avoidance, and privacy for safe deployment in the real world.",
    "published": "2025-11-21T13:01:28Z",
    "updated": "2025-12-01T09:31:06Z",
    "link": "http://arxiv.org/pdf/2511.17220v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "authors": [
      "Yusuf Çelebi",
      "Özay Ezerceli",
      "Mahmoud El Hussieni"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01442v1",
    "title": "PSA-MF: Personality-Sentiment Aligned Multi-Level Fusion for Multimodal Sentiment Analysis",
    "summary": "Multimodal sentiment analysis (MSA) is a research field that recognizes human sentiments by combining textual, visual, and audio modalities. The main challenge lies in integrating sentiment-related information from different modalities, which typically arises during the unimodal feature extraction phase and the multimodal feature fusion phase. Existing methods extract only shallow information from unimodal features during the extraction phase, neglecting sentimental differences across different personalities. During the fusion phase, they directly merge the feature information from each modality without considering differences at the feature level. This ultimately affects the model's recognition performance. To address this problem, we propose a personality-sentiment aligned multi-level fusion framework. We introduce personality traits during the feature extraction phase and propose a novel personality-sentiment alignment method to obtain personalized sentiment embeddings from the textual modality for the first time. In the fusion phase, we introduce a novel multi-level fusion method. This method gradually integrates sentimental information from textual, visual, and audio modalities through multimodal pre-fusion and a multi-level enhanced fusion strategy. Our method has been evaluated through multiple experiments on two commonly used datasets, achieving state-of-the-art results.",
    "published": "2025-12-01T09:24:59Z",
    "updated": "2025-12-01T09:24:59Z",
    "link": "http://arxiv.org/pdf/2512.01442v1.pdf",
    "category": [
      "cs.MM",
      "cs.AI"
    ],
    "authors": [
      "Heng Xie",
      "Kang Zhu",
      "Zhengqi Wen",
      "Jianhua Tao",
      "Xuefei Liu",
      "Ruibo Fu",
      "Changsheng Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01440v1",
    "title": "A Selective Temporal Hamming distance to find patterns in state transition event timeseries, at scale",
    "summary": "Discrete event systems are present both in observations of nature, socio economical sciences, and industrial systems. Standard analysis approaches do not usually exploit their dual event / state nature: signals are either modeled as transition event sequences, emphasizing event order alignment, or as categorical or ordinal state timeseries, usually resampled a distorting and costly operation as the observation period and number of events grow. In this work we define state transition event timeseries (STE-ts) and propose a new Selective Temporal Hamming distance (STH) leveraging both transition time and duration-in-state, avoiding costly and distorting resampling on large databases. STH generalizes both resampled Hamming and Jaccard metrics with better precision and computation time, and an ability to focus on multiple states of interest. We validate these benefits on simulated and real-world datasets.",
    "published": "2025-12-01T09:24:20Z",
    "updated": "2025-12-01T09:24:20Z",
    "link": "http://arxiv.org/pdf/2512.01440v1.pdf",
    "category": [
      "cs.AI",
      "stat.ML"
    ],
    "authors": [
      "Sylvain Marié",
      "Pablo Knecht"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01434v1",
    "title": "A Flexible Multi-Agent LLM-Human Framework for Fast Human Validated Tool Building",
    "summary": "We introduce CollabToolBuilder, a flexible multiagent LLM framework with expert-in-the-loop (HITL) guidance that iteratively learns to create tools for a target goal, aligning with human intent and process, while minimizing time for task/domain adaptation effort and human feedback capture. The architecture generates and validates tools via four specialized agents (Coach, Coder, Critic, Capitalizer) using a reinforced dynamic prompt and systematic human feedback integration to reinforce each agent's role toward goals and constraints. This work is best viewed as a system-level integration and methodology combining multi-agent in-context learning, HITL controls, and reusable tool capitalization for complex iterative problems such as scientific document generation. We illustrate it with preliminary experiments (e.g., generating state-of-the-art research papers or patents given an abstract) and discuss its applicability to other iterative problem-solving.",
    "published": "2025-12-01T09:19:18Z",
    "updated": "2025-12-01T09:19:18Z",
    "link": "http://arxiv.org/pdf/2512.01434v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Daull Xavier",
      "Patrice Bellot",
      "Emmanuel Bruno",
      "Vincent Martin",
      "Elisabeth Murisasco"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.22696v2",
    "title": "Probabilistic Fusion and Calibration of Neural Speaker Diarization Models",
    "summary": "End-to-End Neural Diarization (EEND) systems produce frame-level probabilistic speaker activity estimates, yet since evaluation focuses primarily on Diarization Error Rate (DER), the reliability and calibration of these confidence scores have been largely neglected. When fusing multiple diarization systems, DOVER-Lap remains the only established approach, operating at the segment level with hard decisions. We propose working with continuous probability outputs, which enables more sophisticated fusion and calibration techniques that can leverage model uncertainty and complementary strengths across different architectures. This paper presents the first comprehensive framework for calibrating and fusing EEND models at the probability level. We investigate two output formulations (multilabel and powerset representations) and their impact on calibration and fusion effectiveness. Through extensive experiments on the CallHome two-speaker benchmark, we demonstrate that proper calibration provides substantial improvements even for individual models (up to 19% relative DER reduction), in some cases mitigating the absence of domain adaptation. We reveal that joint calibration in powerset space consistently outperforms independent per-speaker calibration, that fusion substantially improves over individual models, and that the Fuse-then-Calibrate ordering generally outperforms both calibrating before fusion and uncalibrated fusion while requiring calibration of only a single combined model. Our best configuration outperforms DOVER-Lap in terms of DER while providing reliable confidence estimates essential for downstream applications. This work proposes best practices for probability-level fusion of EEND systems and demonstrates the advantages of leveraging soft outputs over hard decisions.",
    "published": "2025-11-27T18:50:16Z",
    "updated": "2025-12-01T09:08:43Z",
    "link": "http://arxiv.org/pdf/2511.22696v2.pdf",
    "category": [
      "cs.SD",
      "cs.AI"
    ],
    "authors": [
      "Juan Ignacio Alvarez-Trejos",
      "Sergio A. Balanya",
      "Daniel Ramos",
      "Alicia Lozano-Diez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.16977v2",
    "title": "Convergence of Shallow ReLU Networks on Weakly Interacting Data",
    "summary": "We analyse the convergence of one-hidden-layer ReLU networks trained by gradient flow on $n$ data points. Our main contribution leverages the high dimensionality of the ambient space, which implies low correlation of the input samples, to demonstrate that a network with width of order $\\log(n)$ neurons suffices for global convergence with high probability. Our analysis uses a Polyak-Łojasiewicz viewpoint along the gradient-flow trajectory, which provides an exponential rate of convergence of $\\frac{1}{n}$. When the data are exactly orthogonal, we give further refined characterizations of the convergence speed, proving its asymptotic behavior lies between the orders $\\frac{1}{n}$ and $\\frac{1}{\\sqrt{n}}$, and exhibiting a phase-transition phenomenon in the convergence rate, during which it evolves from the lower bound to the upper, and in a relative time of order $\\frac{1}{\\log(n)}$.",
    "published": "2025-02-24T09:07:14Z",
    "updated": "2025-12-01T09:06:41Z",
    "link": "http://arxiv.org/pdf/2502.16977v2.pdf",
    "category": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "math.ST"
    ],
    "authors": [
      "Léo Dana",
      "Francis Bach",
      "Loucas Pillaud-Vivien"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.08679v2",
    "title": "MMIF-AMIN: Adaptive Loss-Driven Multi-Scale Invertible Dense Network for Multimodal Medical Image Fusion",
    "summary": "Multimodal medical image fusion (MMIF) aims to integrate images from different modalities to produce a comprehensive image that enhances medical diagnosis by accurately depicting organ structures, tissue textures, and metabolic information. Capturing both the unique and complementary information across multiple modalities simultaneously is a key research challenge in MMIF. To address this challenge, this paper proposes a novel image fusion method, MMIF-AMIN, which features a new architecture that can effectively extract these unique and complementary features. Specifically, an Invertible Dense Network (IDN) is employed for lossless feature extraction from individual modalities. To extract complementary information between modalities, a Multi-scale Complementary Feature Extraction Module (MCFEM) is designed, which incorporates a hybrid attention mechanism, convolutional layers of varying sizes, and Transformers. An adaptive loss function is introduced to guide model learning, addressing the limitations of traditional manually-designed loss functions and enhancing the depth of data mining. Extensive experiments demonstrate that MMIF-AMIN outperforms nine state-of-the-art MMIF methods, delivering superior results in both quantitative and qualitative analyses. Ablation experiments confirm the effectiveness of each component of the proposed method. Additionally, extending MMIF-AMIN to other image fusion tasks also achieves promising performance.",
    "published": "2025-08-12T06:55:38Z",
    "updated": "2025-12-01T09:05:21Z",
    "link": "http://arxiv.org/pdf/2508.08679v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Tao Luo",
      "Weihua Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18871v2",
    "title": "Periodic Asynchrony: An Effective Method for Accelerating Reinforcement Learning",
    "summary": "Since the introduction of the GRPO algorithm, reinforcement learning (RL) has attracted increasing attention, with growing efforts to reproduce and apply it. However, training efficiency remains a critical challenge. In mainstream RL frameworks, inference and training are typically deployed on the same devices. While this approach reduces costs through resource consolidation, its synchronous execution imposes a computational coupling that prevents concurrent inference and training. In this study, we are returning to the strategy of separating inference and training deployment, and by introducing improvements in the data loader, we transform the conventional synchronous architecture into a periodically asynchronous framework, which allows for demand-driven, independent, and elastic scaling of each component, while the accuracy of the algorithm remains completely equivalent to the synchronization method, with both belonging to the on-policy strategy. It is worth emphasizing that we apply a unified tri-model architecture in the training phase, and we also proposed a shared-prompt attention mask to reduce repetitive computation. In practice, these works have achieved at least a threefold overall performance improvement in RL training on NPU platforms, indicating its potential for widespread application.",
    "published": "2025-11-24T08:22:50Z",
    "updated": "2025-12-01T09:00:07Z",
    "link": "http://arxiv.org/pdf/2511.18871v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Jian Lu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01420v1",
    "title": "PromptBridge: Cross-Model Prompt Transfer for Large Language Models",
    "summary": "Large language models (LLMs) underpin applications in code generation, mathematical reasoning, and agent-based workflows. In practice, systems access LLMs via commercial APIs or open-source deployments, and the model landscape (e.g., GPT, Claude, Llama) evolves rapidly. This rapid evolution forces frequent model switches driven by capability, cost, deployment constraints, and privacy. Yet prompts are highly model-sensitive: reusing a prompt engineered for one model on another often yields substantially worse performance than a prompt optimized for the target model. We term this phenomenon Model Drifting. Through extensive empirical analysis across diverse LLM configurations, we show that model drifting is both common and severe. To address this challenge, we introduce PromptBridge, a training-free framework that preserves prompt effectiveness under model switches, enabling cross-model prompt transfer without costly per-task or per-model re-optimization. PromptBridge requires only a small set of alignment tasks for calibration. It first applies Model-Adaptive Reflective Prompt Evolution (MAP-RPE) to obtain task- and model-specific optimal prompts via iterative reflective refinement and quantitative evaluation. Using the resulting calibrated prompt pairs for the source and target models, PromptBridge learns a cross-model prompt mapping. At test time, i.e., for an unseen task, given a source-model prompt, this mapping directly produces an optimized prompt for the target model. Experiments in single-agent and multi-agent settings show that PromptBridge consistently improves downstream accuracy while reducing migration effort. The code will be available soon.",
    "published": "2025-12-01T08:55:45Z",
    "updated": "2025-12-01T08:55:45Z",
    "link": "http://arxiv.org/pdf/2512.01420v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Yaxuan Wang",
      "Quan Liu",
      "Zhenting Wang",
      "Zichao Li",
      "Wei Wei",
      "Yang Liu",
      "Yujia Bao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01419v1",
    "title": "Rice-VL: Evaluating Vision-Language Models for Cultural Understanding Across ASEAN Countries",
    "summary": "Vision-Language Models (VLMs) excel in multimodal tasks but often exhibit Western-centric biases, limiting their effectiveness in culturally diverse regions like Southeast Asia (SEA). To address this, we introduce RICE-VL, a novel benchmark evaluating VLM cultural understanding across 11 ASEAN countries. RICE-VL includes over 28,000 human-curated Visual Question Answering (VQA) samples -- covering True or False, Fill-in-the-Blank, and open-ended formats -- and 1,000 image-bounding box pairs for Visual Grounding, annotated by culturally informed experts across 14 sub-ground categories. We propose SEA-LAVE, an extension of the LAVE metric, assessing textual accuracy, cultural alignment, and country identification. Evaluations of six open- and closed-source VLMs reveal significant performance gaps in low-resource countries and abstract cultural domains. The Visual Grounding task tests models' ability to localize culturally significant elements in complex scenes, probing spatial and contextual accuracy. RICE-VL exposes limitations in VLMs' cultural comprehension and highlights the need for inclusive model development to better serve diverse global populations.",
    "published": "2025-12-01T08:55:41Z",
    "updated": "2025-12-01T08:55:41Z",
    "link": "http://arxiv.org/pdf/2512.01419v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Tushar Pranav",
      "Eshan Pandey",
      "Austria Lyka Diane Bala",
      "Aman Chadha",
      "Indriyati Atmosukarto",
      "Donny Soh Cheng Lock"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.02844v4",
    "title": "Conformal Prediction for Time-series Forecasting with Change Points",
    "summary": "Conformal prediction has been explored as a general and efficient way to provide uncertainty quantification for time series. However, current methods struggle to handle time series data with change points - sudden shifts in the underlying data-generating process. In this paper, we propose a novel Conformal Prediction for Time-series with Change points (CPTC) algorithm, addressing this gap by integrating a model to predict the underlying state with online conformal prediction to model uncertainties in non-stationary time series. We prove CPTC's validity and improved adaptivity in the time series setting under minimum assumptions, and demonstrate CPTC's practical effectiveness on 6 synthetic and real-world datasets, showing improved validity and adaptivity compared to state-of-the-art baselines.",
    "published": "2025-09-02T21:26:53Z",
    "updated": "2025-12-01T08:47:15Z",
    "link": "http://arxiv.org/pdf/2509.02844v4.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Sophia Sun",
      "Rose Yu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01412v1",
    "title": "A Self-explainable Model of Long Time Series by Extracting Informative Structured Causal Patterns",
    "summary": "Explainability is essential for neural networks that model long time series, yet most existing explainable AI methods only produce point-wise importance scores and fail to capture temporal structures such as trends, cycles, and regime changes. This limitation weakens human interpretability and trust in long-horizon models. To address these issues, we identify four key requirements for interpretable time-series modeling: temporal continuity, pattern-centric explanation, causal disentanglement, and faithfulness to the model's inference process. We propose EXCAP, a unified framework that satisfies all four requirements. EXCAP combines an attention-based segmenter that extracts coherent temporal patterns, a causally structured decoder guided by a pre-trained causal graph, and a latent aggregation mechanism that enforces representation stability. Our theoretical analysis shows that EXCAP provides smooth and stable explanations over time and is robust to perturbations in causal masks. Extensive experiments on classification and forecasting benchmarks demonstrate that EXCAP achieves strong predictive accuracy while generating coherent and causally grounded explanations. These results show that EXCAP offers a principled and scalable approach to interpretable modeling of long time series with relevance to high-stakes domains such as healthcare and finance.",
    "published": "2025-12-01T08:33:33Z",
    "updated": "2025-12-01T08:33:33Z",
    "link": "http://arxiv.org/pdf/2512.01412v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Ziqian Wang",
      "Yuxiao Cheng",
      "Jinli Suo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.17850v8",
    "title": "GEPO: Group Expectation Policy Optimization for Stable Heterogeneous Reinforcement Learning",
    "summary": "As single-center computing approaches power constraints, decentralized training becomes essential. However, traditional Reinforcement Learning (RL) methods, crucial for enhancing large model post-training, cannot adapt to decentralized distributed training due to the tight coupling between parameter learning and rollout sampling. For this, we propose HeteroRL, a heterogeneous RL architecture that decouples these processes, enabling stable training across geographically distributed nodes connected via the Internet. The core component is Group Expectation Policy Optimization (GEPO), an asynchronous RL algorithm robust to latency caused by network delays or heterogeneity in computational resources. Our study reveals that high latency significantly increases KL divergence, leading to higher variance of importance weights and training instability. GEPO mitigates this issue by using group expectation weighting to exponentially reduce the variance of importance weights, with theoretical guarantees. Experiments show GEPO achieves superior stability - only a 3% performance drop from online to 1800s latency-and reduces the best-to-last gap by 85% versus GSPO (1.8 vs. 12.0) while attaining the highest scores, highlighting its effectiveness in decentralized, resource-heterogeneous environments.",
    "published": "2025-08-25T09:57:35Z",
    "updated": "2025-12-01T08:13:15Z",
    "link": "http://arxiv.org/pdf/2508.17850v8.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Han Zhang",
      "Ruibin Zheng",
      "Zexuan Yi",
      "Zhuo Zhang",
      "Hanyang Peng",
      "Hui Wang",
      "Zike Yuan",
      "Cai Ke",
      "Shiwei Chen",
      "Jiacheng Yang",
      "Yangning Li",
      "Xiang Li",
      "Jiangyue Yan",
      "Yaoqi Liu",
      "Liwen Jing",
      "Jiayin Qi",
      "Ruifeng Xu",
      "Binxing Fang",
      "Yue Yu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01389v1",
    "title": "Consistency Flow Model Achieves One-step Denoising Error Correction Codes",
    "summary": "Error Correction Codes (ECC) are fundamental to reliable digital communication, yet designing neural decoders that are both accurate and computationally efficient remains challenging. Recent denoising diffusion decoders with transformer backbones achieve state-of-the-art performance, but their iterative sampling limits practicality in low-latency settings. We introduce the Error Correction Consistency Flow Model (ECCFM), an architecture-agnostic training framework for high-fidelity one-step decoding. By casting the reverse denoising process as a Probability Flow Ordinary Differential Equation (PF-ODE) and enforcing smoothness through a differential time regularization, ECCFM learns to map noisy signals along the decoding trajectory directly to the original codeword in a single inference step. Across multiple decoding benchmarks, ECCFM attains lower bit-error rates (BER) than autoregressive and diffusion-based baselines, with notable improvements on longer codes, while delivering inference speeds up from 30x to 100x faster than denoising diffusion decoders.",
    "published": "2025-12-01T08:07:51Z",
    "updated": "2025-12-01T08:07:51Z",
    "link": "http://arxiv.org/pdf/2512.01389v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Haoyu Lei",
      "Chin Wa Lau",
      "Kaiwen Zhou",
      "Nian Guo",
      "Farzan Farnia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.20729v2",
    "title": "Robust, Observable, and Evolvable Agentic Systems Engineering: A Principled Framework Validated via the Fairy GUI Agent",
    "summary": "The Agentic Paradigm faces a significant Software Engineering Absence, yielding Agentic systems commonly lacking robustness, observability, and evolvability. To address these deficiencies, we propose a principled engineering framework comprising Runtime Goal Refinement (RGR), Observable Cognitive Architecture (OCA), and Evolutionary Memory Architecture (EMA). In this framework, RGR ensures robustness and intent alignment via knowledge-constrained refinement and human-in-the-loop clarification; OCA builds an observable and maintainable white-box architecture using component decoupling, logic layering, and state-control separation; and EMA employs an execution-evolution dual-loop for evolvability. We implemented and empirically validated Fairy, a mobile GUI agent based on this framework. On RealMobile-Eval, our novel benchmark for ambiguous and complex tasks, Fairy outperformed the best SoTA baseline in user requirement completion by 33.7%. Subsequent controlled experiments, human-subject studies, and ablation studies further confirmed that the RGR enhances refinement accuracy and prevents intent deviation; the OCA improves maintainability; and the EMA is crucial for long-term performance. This research provides empirically validated specifications and a practical blueprint for building reliable, observable, and evolvable Agentic AI systems.",
    "published": "2025-09-25T04:21:31Z",
    "updated": "2025-12-01T08:01:05Z",
    "link": "http://arxiv.org/pdf/2509.20729v2.pdf",
    "category": [
      "cs.AI",
      "cs.HC",
      "cs.MA"
    ],
    "authors": [
      "Jiazheng Sun",
      "Ruimeng Yang",
      "Xu Han",
      "Jiayang Niu",
      "Mingxuan Li",
      "Te Yang",
      "Yongyong Lu",
      "Xin Peng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.04225v3",
    "title": "Symmetric Behavior Regularized Policy Optimization",
    "summary": "Behavior Regularized Policy Optimization (BRPO) leverages asymmetric (divergence) regularization to mitigate the distribution shift in offline Reinforcement Learning. This paper is the first to study the open question of symmetric regularization. We show that symmetric regularization does not permit an analytic optimal policy $π^*$, posing a challenge to practical utility of symmetric BRPO. We approximate $π^*$ by the Taylor series of Pearson-Vajda $χ^n$ divergences and show that an analytic policy expression exists only when the series is capped at $n=5$. To compute the solution in a numerically stable manner, we propose to Taylor expand the conditional symmetry term of the symmetric divergence loss, leading to a novel algorithm: Symmetric $f$-Actor Critic (S$f$-AC). S$f$-AC achieves consistently strong results across various D4RL MuJoCo tasks. Additionally, S$f$-AC avoids per-environment failures observed in IQL, SQL, XQL and AWAC, opening up possibilities for more diverse and effective regularization choices for offline RL.",
    "published": "2025-08-06T09:01:29Z",
    "updated": "2025-12-01T08:00:40Z",
    "link": "http://arxiv.org/pdf/2508.04225v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Lingwei Zhu",
      "Haseeb Shah",
      "Zheng Chen",
      "Yukie Nagai",
      "Martha White"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.14515v2",
    "title": "IMSE: Efficient U-Net-based Speech Enhancement using Inception Depthwise Convolution and Amplitude-Aware Linear Attention",
    "summary": "Achieving a balance between lightweight design and high performance remains a significant challenge for speech enhancement (SE) tasks on resource-constrained devices. Existing state-of-the-art methods, such as MUSE, have established a strong baseline with only 0.51M parameters by introducing a Multi-path Enhanced Taylor (MET) transformer and Deformable Embedding (DE). However, an in-depth analysis reveals that MUSE still suffers from efficiency bottlenecks: the MET module relies on a complex \"approximate-compensate\" mechanism to mitigate the limitations of Taylor-expansion-based attention, while the offset calculation for deformable embedding introduces additional computational burden. This paper proposes IMSE, a systematically optimized and ultra-lightweight network. We introduce two core innovations: 1) Replacing the MET module with Amplitude-Aware Linear Attention (MALA). MALA fundamentally rectifies the \"amplitude-ignoring\" problem in linear attention by explicitly preserving the norm information of query vectors in the attention calculation, achieving efficient global modeling without an auxiliary compensation branch. 2) Replacing the DE module with Inception Depthwise Convolution (IDConv). IDConv borrows the Inception concept, decomposing large-kernel operations into efficient parallel branches (square, horizontal, and vertical strips), thereby capturing spectrogram features with extremely low parameter redundancy. Extensive experiments on the VoiceBank+DEMAND dataset demonstrate that, compared to the MUSE baseline, IMSE significantly reduces the parameter count by 16.8\\% (from 0.513M to 0.427M) while achieving competitive performance comparable to the state-of-the-art on the PESQ metric (3.373). This study sets a new benchmark for the trade-off between model size and speech quality in ultra-lightweight speech enhancement.",
    "published": "2025-11-18T14:11:54Z",
    "updated": "2025-12-01T07:59:45Z",
    "link": "http://arxiv.org/pdf/2511.14515v2.pdf",
    "category": [
      "cs.SD",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Xinxin Tang",
      "Bin Qin",
      "Yufang Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.10825v2",
    "title": "ORACLE: Explaining Feature Interactions in Neural Networks with ANOVA",
    "summary": "We introduce ORACLE, a framework that explains neural networks on tabular and scientific design data. It fits ANOVA-style main and pairwise interaction effects to a model's prediction surface. ORACLE treats a trained network as a black-box response, learns an orthogonal factorial surrogate on a discretized input grid, and uses simple centering and $μ$-rebalancing steps to obtain main- and interaction-effect tables that remain $L^2$-consistent with the original model. The resulting grid-based interaction maps are easy to visualize, comparable across backbones, and directly connected to classical design-of-experiments analyses. On synthetic factorial and low- to medium-dimensional tabular regression benchmarks, ORACLE more accurately recovers ground-truth ANOVA interactions and hotspot structure than Monte Carlo SHAP-family interaction methods, as measured by ranking, localization, and cross-backbone stability metrics. In latent image and text settings, ORACLE instead delineates its natural scope, and our results indicate that grid-based ANOVA surrogates are most effective when features admit interpretable factorial structure, making ORACLE particularly well-suited to scientific and engineering tabular workflows that require stable, DoE-style interaction summaries.",
    "published": "2025-09-13T14:44:45Z",
    "updated": "2025-12-01T07:52:07Z",
    "link": "http://arxiv.org/pdf/2509.10825v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "authors": [
      "Dongseok Kim",
      "Hyoungsun Choi",
      "Mohamed Jismy Aashik Rasool",
      "Gisung Oh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01374v1",
    "title": "Stabilizing Reinforcement Learning with LLMs: Formulation and Practices",
    "summary": "This paper proposes a novel formulation for reinforcement learning (RL) with large language models, explaining why and under what conditions the true sequence-level reward can be optimized via a surrogate token-level objective in policy gradient methods such as REINFORCE. Specifically, through a first-order approximation, we show that this surrogate becomes increasingly valid only when both the training-inference discrepancy and policy staleness are minimized. This insight provides a principled explanation for the crucial role of several widely adopted techniques in stabilizing RL training, including importance sampling correction, clipping, and particularly Routing Replay for Mixture-of-Experts (MoE) models. Through extensive experiments with a 30B MoE model totaling hundreds of thousands of GPU hours, we show that for on-policy training, the basic policy gradient algorithm with importance sampling correction achieves the highest training stability. When off-policy updates are introduced to accelerate convergence, combining clipping and Routing Replay becomes essential to mitigate the instability caused by policy staleness. Notably, once training is stabilized, prolonged optimization consistently yields comparable final performance regardless of cold-start initialization. We hope that the shared insights and the developed recipes for stable RL training will facilitate future research.",
    "published": "2025-12-01T07:45:39Z",
    "updated": "2025-12-01T07:45:39Z",
    "link": "http://arxiv.org/pdf/2512.01374v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Chujie Zheng",
      "Kai Dang",
      "Bowen Yu",
      "Mingze Li",
      "Huiqiang Jiang",
      "Junrong Lin",
      "Yuqiong Liu",
      "An Yang",
      "Jingren Zhou",
      "Junyang Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.20332v2",
    "title": "3D Motion Perception of Binocular Vision Target with PID-CNN",
    "summary": "This article trained a network for perceiving three-dimensional motion information of binocular vision target, which can provide real-time three-dimensional coordinate, velocity, and acceleration, and has a basic spatiotemporal perception capability. Understood the ability of neural networks to fit nonlinear problems from the perspective of PID. Considered a single-layer neural network as using a second-order difference equation and a nonlinearity to describe a local problem. Multilayer networks gradually transform the raw representation to the desired representation through multiple such combinations. Analysed some reference principles for designing neural networks. Designed a relatively small PID convolutional neural network, with a total of 17 layers and 413 thousand parameters. Implemented a simple but practical feature reuse method by concatenation and pooling. The network was trained and tested using the simulated randomly moving ball datasets, and the experimental results showed that the prediction accuracy was close to the upper limit that the input image resolution can represent. Analysed the experimental results and errors, as well as the existing shortcomings and possible directions for improvement. Finally, discussed the advantages of high-dimensional convolution in improving computational efficiency and feature space utilization. As well as the potential advantages of using PID information to implement memory and attention mechanisms.",
    "published": "2025-11-25T14:09:44Z",
    "updated": "2025-12-01T07:41:45Z",
    "link": "http://arxiv.org/pdf/2511.20332v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Jiazhao Shi",
      "Pan Pan",
      "Haotian Shi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01372v1",
    "title": "Structured Spectral Reasoning for Frequency-Adaptive Multimodal Recommendation",
    "summary": "Multimodal recommendation aims to integrate collaborative signals with heterogeneous content such as visual and textual information, but remains challenged by modality-specific noise, semantic inconsistency, and unstable propagation over user-item graphs. These issues are often exacerbated by naive fusion or shallow modeling strategies, leading to degraded generalization and poor robustness. While recent work has explored the frequency domain as a lens to separate stable from noisy signals, most methods rely on static filtering or reweighting, lacking the ability to reason over spectral structure or adapt to modality-specific reliability. To address these challenges, we propose a Structured Spectral Reasoning (SSR) framework for frequency-aware multimodal recommendation. Our method follows a four-stage pipeline: (i) Decompose graph-based multimodal signals into spectral bands via graph-guided transformations to isolate semantic granularity; (ii) Modulate band-level reliability with spectral band masking, a training-time masking with a prediction-consistency objective that suppresses brittle frequency components; (iii) Fuse complementary frequency cues using hyperspectral reasoning with low-rank cross-band interaction; and (iv) Align modality-specific spectral features via contrastive regularization to promote semantic and structural consistency. Experiments on three real-world benchmarks show consistent gains over strong baselines, particularly under sparse and cold-start settings. Additional analyses indicate that structured spectral modeling improves robustness and provides clearer diagnostics of how different bands contribute to performance.",
    "published": "2025-12-01T07:39:28Z",
    "updated": "2025-12-01T07:39:28Z",
    "link": "http://arxiv.org/pdf/2512.01372v1.pdf",
    "category": [
      "cs.IR",
      "cs.AI"
    ],
    "authors": [
      "Wei Yang",
      "Rui Zhong",
      "Yiqun Chen",
      "Chi Lu",
      "Peng Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01370v1",
    "title": "Beyond Loss Guidance: Using PDE Residuals as Spectral Attention in Diffusion Neural Operators",
    "summary": "Diffusion-based solvers for partial differential equations (PDEs) are often bottle-necked by slow gradient-based test-time optimization routines that use PDE residuals for loss guidance. They additionally suffer from optimization instabilities and are unable to dynamically adapt their inference scheme in the presence of noisy PDE residuals. To address these limitations, we introduce PRISMA (PDE Residual Informed Spectral Modulation with Attention), a conditional diffusion neural operator that embeds PDE residuals directly into the model's architecture via attention mechanisms in the spectral domain, enabling gradient-descent free inference. In contrast to previous methods that use PDE loss solely as external optimization targets, PRISMA integrates PDE residuals as integral architectural features, making it inherently fast, robust, accurate, and free from sensitive hyperparameter tuning. We show that PRISMA has competitive accuracy, at substantially lower inference costs, compared to previous methods across five benchmark PDEs, especially with noisy observations, while using 10x to 100x fewer denoising steps, leading to 15x to 250x faster inference.",
    "published": "2025-12-01T07:34:42Z",
    "updated": "2025-12-01T07:34:42Z",
    "link": "http://arxiv.org/pdf/2512.01370v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "math.NA",
      "stat.ML"
    ],
    "authors": [
      "Medha Sawhney",
      "Abhilash Neog",
      "Mridul Khurana",
      "Anuj Karpatne"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01357v1",
    "title": "Tangram: Accelerating Serverless LLM Loading through GPU Memory Reuse and Affinity",
    "summary": "Serverless Large Language Models (LLMs) have emerged as a cost-effective solution for deploying AI services by enabling a 'pay-as-you-go' pricing model through GPU resource sharing. However, cold-start latency, especially the model loading phase, has become a critical performance bottleneck, as it scales linearly with model size and severely limits the practical deployment of large-scale LLM services. This paper presents Tangram, a novel system that accelerates Serverless LLM loading through efficient GPU memory reuse. By leveraging the unused GPU memory to retain model parameters, Tangram significantly reduces model transfer time and cold-start latency. Its design includes three key components: unified GPU memory pool for tensor-level parameter sharing across models, on-demand KV cache allocation for dynamic memory management, and GPU-affinity-aware scheduling for maximizing resource utilization. These techniques collectively address the critical challenges of inefficient memory usage and the cold-start problem in Serverless LLM platforms. We have implemented a fully functional prototype, and experiments show that Tangram achieves up to 6.2 times faster loading and reduces Time-To-First-Token (TTFT) during cold-start by 23--55% over state-of-the-art methods.",
    "published": "2025-12-01T07:10:34Z",
    "updated": "2025-12-01T07:10:34Z",
    "link": "http://arxiv.org/pdf/2512.01357v1.pdf",
    "category": [
      "cs.DC",
      "cs.AI",
      "cs.AR"
    ],
    "authors": [
      "Wenbin Zhu",
      "Zhaoyan Shen",
      "Zili Shao",
      "Hongjun Dai",
      "Feng Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01354v1",
    "title": "The Necessity of Imperfection:Reversing Model Collapse via Simulating Cognitive Boundedness",
    "summary": "Although synthetic data is widely promoted as a remedy, its prevailing production paradigm -- one optimizing for statistical smoothness -- systematically removes the long-tail, cognitively grounded irregularities that characterize human text. Prolonged training on such statistically optimal but cognitively impoverished data accelerates model collapse.\n  This paper proposes a paradigm shift: instead of imitating the surface properties of data, we simulate the cognitive processes that generate human text. We introduce the Prompt-driven Cognitive Computing Framework (PMCSF), whose core consists of a Cognitive State Decoder (CSD) that reverse-engineers unstructured text into structured cognitive vectors, and a Cognitive Text Encoder (CTE) that re-materializes these states into text enriched with human-typical imperfections via mathematically defined Cognitive Perturbation Operators.\n  The framework is validated through a two-stage objective evaluation pipeline. First, in cognitive codec verification, CTE text yields a Jensen-Shannon divergence of 0.0614 from human text (vs. 0.4431 for standard LLM output), passes double-blind professional media review, and achieves an intraclass correlation coefficient ICC > 0.9 for cognitive profile alignment across heterogeneous models. Second, in functional gain evaluation, isomorphic stress tests in the A-share market show that strategies incorporating CTE-generated data reduce maximum drawdown by 47.4% during the 2015 crash and deliver 8.6% Defensive Alpha, exceeding transaction costs by a factor of 33.\n  Our findings demonstrate that modelling human cognitive limitations -- not copying surface data -- enables synthetic data with genuine functional gain, offering a viable technical pathway toward resolving the AI data-collapse crisis.",
    "published": "2025-12-01T07:09:38Z",
    "updated": "2025-12-01T07:09:38Z",
    "link": "http://arxiv.org/pdf/2512.01354v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.LG",
      "q-fin.TR"
    ],
    "authors": [
      "Zhongjie Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01351v1",
    "title": "Benchmarking Overton Pluralism in LLMs",
    "summary": "We introduce a novel framework for measuring Overton pluralism in LLMs--the extent to which diverse viewpoints are represented in model outputs. We (i) formalize Overton pluralism as a set coverage metric (OvertonScore), (ii) conduct a large-scale U.S.-representative human study (N = 1209; 60 questions; 8 LLMs), and (iii) develop an automated benchmark that closely reproduces human judgments. On average, models achieve OvertonScores of 0.35--0.41, with DeepSeek V3 performing best; yet all models remain far below the theoretical maximum of 1.0, revealing substantial headroom for improvement. Because repeated large-scale human studies are costly and slow, scalable evaluation tools are essential for model development. Hence, we propose an automated benchmark that achieves high rank correlation with human judgments ($ρ=0.88$), providing a practical proxy without replacing human assessment. By turning pluralistic alignment from a normative aim into a measurable benchmark, our work establishes a foundation for systematic progress toward more pluralistic LLMs.",
    "published": "2025-12-01T07:04:20Z",
    "updated": "2025-12-01T07:04:20Z",
    "link": "http://arxiv.org/pdf/2512.01351v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Elinor Poole-Dayan",
      "Jiayi Wu",
      "Taylor Sorensen",
      "Jiaxin Pei",
      "Michiel A. Bakker"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01343v1",
    "title": "Intrinsic Structure as a Proxy for Saliency: SVD-Based Weight Preservation for Mixed-Precision Quantization in Large Language Models",
    "summary": "As Large Language Models (LLMs) continue to scale in parameter count, deploying them on commodity hardware has become increasingly challenging. Post-Training Quantization (PTQ) addresses this by reducing the precision of model weights, typically to 4-bit or lower. However, uniform quantization often leads to significant performance degradation due to the presence of ``outlier features'' -- weights that, while few in number, are critical for maintaining model accuracy. Current state-of-the-art methods such as AWQ (Activation-aware Weight Quantization) and SpQR (Sparse Quantization Representations) rely on calibration data to identify these salient weights via activation magnitudes or Hessian sensitivity. In scenarios where data privacy is paramount or calibration data is unavailable, these methods are inapplicable.\n  In this work, we propose a data-free, structure-aware hypothesis: that the weights identified as Principal Components via Singular Value Decomposition (SVD) are intrinsically important to the model's downstream performance. We introduce a novel selection heuristic that preserves the top-$k$ weights aligned with the principal components in FP32, while aggressively quantizing the residual weights. We compare our method against activation-aware (AWQ) and second-order (SpQR) methods across GLUE benchmarks (MRPC, RTE, QNLI) using a DistilBERT backbone. Our experiments reveal that structural importance is highly correlated with functional importance. On the challenging RTE task, our SVD-based method achieves an accuracy of 66.06\\%, outperforming both AWQ (65.34\\%) and SpQR (65.34\\%) at high protection budgets, validating that intrinsic matrix structure can serve as a robust proxy for weight saliency without the need for forward passes or calibration data.",
    "published": "2025-12-01T06:58:30Z",
    "updated": "2025-12-01T06:58:30Z",
    "link": "http://arxiv.org/pdf/2512.01343v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Shashank Landge",
      "Abhishek Patil",
      "Tejas kamble",
      "Bhushan Buddhivant",
      "Priyanka Joshi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.19361v2",
    "title": "SpeechIQ: Speech-Agentic Intelligence Quotient Across Cognitive Levels in Voice Understanding by Large Language Models",
    "summary": "We introduce Speech-based Intelligence Quotient (SIQ) as a new form of human cognition-inspired evaluation pipeline for voice understanding large language models, LLM Voice, designed to assess their voice understanding ability. Moving beyond popular voice understanding metrics such as word error rate (WER), SIQ examines LLM Voice across three cognitive levels motivated by Bloom's Taxonomy: (1) Remembering (i.e., WER for verbatim accuracy); (2) Understanding (i.e., similarity of LLM's interpretations); and (3) Application (i.e., QA accuracy for simulating downstream tasks). We demonstrate that SIQ not only quantifies voice understanding abilities but also provides unified comparisons between cascaded methods (e.g., ASR LLM) and end-to-end models, identifies annotation errors in existing benchmarks, and detects hallucinations in LLM Voice. Our framework represents a first-of-its-kind intelligence examination that bridges cognitive principles with voice-oriented benchmarks, while exposing overlooked challenges in multi-modal training. Our code and data will be open source to encourage future studies.",
    "published": "2025-07-25T15:12:06Z",
    "updated": "2025-12-01T06:55:00Z",
    "link": "http://arxiv.org/pdf/2507.19361v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.SC",
      "cs.SD",
      "eess.AS"
    ],
    "authors": [
      "Zhen Wan",
      "Chao-Han Huck Yang",
      "Yahan Yu",
      "Jinchuan Tian",
      "Sheng Li",
      "Ke Hu",
      "Zhehuai Chen",
      "Shinji Watanabe",
      "Fei Cheng",
      "Chenhui Chu",
      "Sadao Kurohashi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01335v1",
    "title": "EmoRAG: Evaluating RAG Robustness to Symbolic Perturbations",
    "summary": "Retrieval-Augmented Generation (RAG) systems are increasingly central to robust AI, enhancing large language model (LLM) faithfulness by incorporating external knowledge. However, our study unveils a critical, overlooked vulnerability: their profound susceptibility to subtle symbolic perturbations, particularly through near-imperceptible emoticon tokens such as \"(@_@)\" that can catastrophically mislead retrieval, termed EmoRAG. We demonstrate that injecting a single emoticon into a query makes it nearly 100% likely to retrieve semantically unrelated texts that contain a matching emoticon. Our extensive experiment across general question-answering and code domains, using a range of state-of-the-art retrievers and generators, reveals three key findings: (I) Single-Emoticon Disaster: Minimal emoticon injections cause maximal disruptions, with a single emoticon almost 100% dominating RAG output. (II) Positional Sensitivity: Placing an emoticon at the beginning of a query can cause severe perturbation, with F1-Scores exceeding 0.92 across all datasets. (III) Parameter-Scale Vulnerability: Counterintuitively, models with larger parameters exhibit greater vulnerability to the interference. We provide an in-depth analysis to uncover the underlying mechanisms of these phenomena. Furthermore, we raise a critical concern regarding the robustness assumption of current RAG systems, envisioning a threat scenario where an adversary exploits this vulnerability to manipulate the RAG system. We evaluate standard defenses and find them insufficient against EmoRAG. To address this, we propose targeted defenses, analyzing their strengths and limitations in mitigating emoticon-based perturbations. Finally, we outline future directions for building robust RAG systems.",
    "published": "2025-12-01T06:53:49Z",
    "updated": "2025-12-01T06:53:49Z",
    "link": "http://arxiv.org/pdf/2512.01335v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Xinyun Zhou",
      "Xinfeng Li",
      "Yinan Peng",
      "Ming Xu",
      "Xuanwang Zhang",
      "Miao Yu",
      "Yidong Wang",
      "Xiaojun Jia",
      "Kun Wang",
      "Qingsong Wen",
      "XiaoFeng Wang",
      "Wei Dong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2401.11647v5",
    "title": "Resource-efficient Layer-wise Federated Self-supervised Learning",
    "summary": "Many studies integrate federated learning (FL) with self-supervised learning (SSL) to take advantage of raw data distributed across edge devices. However, edge devices often struggle with high computational and communication costs imposed by SSL and FL algorithms. With the deployment of more complex and large-scale models, these challenges are exacerbated. To tackle this, we propose Layer-Wise Federated Self-Supervised Learning (LW-FedSSL), which allows edge devices to incrementally train a small part of the model at a time. Specifically, in LW-FedSSL, training is decomposed into multiple stages, with each stage responsible for only a specific layer of the model. Since only a portion of the model is active for training at any given time, LW-FedSSL significantly reduces computational requirements. Additionally, only the active model portion needs to be exchanged between the FL server and clients, reducing communication overhead. This enables LW-FedSSL to jointly address both computational and communication challenges of FL client devices. It can achieve up to a $3.34 \\times$ reduction in memory usage, $4.20 \\times$ fewer computational operations (giga floating point operations, GFLOPs), and a $5.07 \\times$ lower communication cost while maintaining performance comparable to its end-to-end training counterpart. Furthermore, we explore a progressive training strategy called Progressive Federated Self-Supervised Learning (Prog-FedSSL), which offers a $1.84\\times$ reduction in GFLOPs and a $1.67\\times$ reduction in communication costs while maintaining the same memory requirements as end-to-end training. Although the resource efficiency of Prog-FedSSL is lower than that of LW-FedSSL, its performance improvements make it a viable candidate for FL environments with more lenient resource constraints.",
    "published": "2024-01-22T01:57:31Z",
    "updated": "2025-12-01T06:49:40Z",
    "link": "http://arxiv.org/pdf/2401.11647v5.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Ye Lin Tun",
      "Chu Myaet Thwal",
      "Huy Q. Le",
      "Minh N. H. Nguyen",
      "Eui-Nam Huh",
      "Choong Seon Hong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01331v1",
    "title": "A Fast Heuristic Search Approach for Energy-Optimal Profile Routing for Electric Vehicles",
    "summary": "We study the energy-optimal shortest path problem for electric vehicles (EVs) in large-scale road networks, where recuperated energy along downhill segments introduces negative energy costs. While traditional point-to-point pathfinding algorithms for EVs assume a known initial energy level, many real-world scenarios involving uncertainty in available energy require planning optimal paths for all possible initial energy levels, a task known as energy-optimal profile search. Existing solutions typically rely on specialized profile-merging procedures within a label-correcting framework that results in searching over complex profiles. In this paper, we propose a simple yet effective label-setting approach based on multi-objective A* search, which employs a novel profile dominance rule to avoid generating and handling complex profiles. We develop four variants of our method and evaluate them on real-world road networks enriched with realistic energy consumption data. Experimental results demonstrate that our energy profile A* search achieves performance comparable to energy-optimal A* with a known initial energy level.",
    "published": "2025-12-01T06:45:34Z",
    "updated": "2025-12-01T06:45:34Z",
    "link": "http://arxiv.org/pdf/2512.01331v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Saman Ahmadi",
      "Mahdi Jalili"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01321v1",
    "title": "Extending NGU to Multi-Agent RL: A Preliminary Study",
    "summary": "The Never Give Up (NGU) algorithm has proven effective in reinforcement learning tasks with sparse rewards by combining episodic novelty and intrinsic motivation. In this work, we extend NGU to multi-agent environments and evaluate its performance in the simple_tag environment from the PettingZoo suite. Compared to a multi-agent DQN baseline, NGU achieves moderately higher returns and more stable learning dynamics. We investigate three design choices: (1) shared replay buffer versus individual replay buffers, (2) sharing episodic novelty among agents using different k thresholds, and (3) using heterogeneous values of the beta parameter. Our results show that NGU with a shared replay buffer yields the best performance and stability, highlighting that the gains come from combining NGU intrinsic exploration with experience sharing. Novelty sharing performs comparably when k = 1 but degrades learning for larger values. Finally, heterogeneous beta values do not improve over a small common value. These findings suggest that NGU can be effectively applied in multi-agent settings when experiences are shared and intrinsic exploration signals are carefully tuned.",
    "published": "2025-12-01T06:24:37Z",
    "updated": "2025-12-01T06:24:37Z",
    "link": "http://arxiv.org/pdf/2512.01321v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Juan Hernandez",
      "Diego Fernández",
      "Manuel Cifuentes",
      "Denis Parra",
      "Rodrigo Toro Icarte"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01319v1",
    "title": "Rethinking Intracranial Aneurysm Vessel Segmentation: A Perspective from Computational Fluid Dynamics Applications",
    "summary": "The precise segmentation of intracranial aneurysms and their parent vessels (IA-Vessel) is a critical step for hemodynamic analyses, which mainly depends on computational fluid dynamics (CFD). However, current segmentation methods predominantly focus on image-based evaluation metrics, often neglecting their practical effectiveness in subsequent CFD applications. To address this deficiency, we present the Intracranial Aneurysm Vessel Segmentation (IAVS) dataset, the first comprehensive, multi-center collection comprising 641 3D MRA images with 587 annotations of aneurysms and IA-Vessels. In addition to image-mask pairs, IAVS dataset includes detailed hemodynamic analysis outcomes, addressing the limitations of existing datasets that neglect topological integrity and CFD applicability. To facilitate the development and evaluation of clinically relevant techniques, we construct two evaluation benchmarks including global localization of aneurysms (Stage I) and fine-grained segmentation of IA-Vessel (Stage II) and develop a simple and effective two-stage framework, which can be used as a out-of-the-box method and strong baseline. For comprehensive evaluation of applicability of segmentation results, we establish a standardized CFD applicability evaluation system that enables the automated and consistent conversion of segmentation masks into CFD models, offering an applicability-focused assessment of segmentation outcomes. The dataset, code, and model will be public available at https://github.com/AbsoluteResonance/IAVS.",
    "published": "2025-12-01T06:23:07Z",
    "updated": "2025-12-01T06:23:07Z",
    "link": "http://arxiv.org/pdf/2512.01319v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Feiyang Xiao",
      "Yichi Zhang",
      "Xigui Li",
      "Yuanye Zhou",
      "Chen Jiang",
      "Xin Guo",
      "Limei Han",
      "Yuxin Li",
      "Fengping Zhu",
      "Yuan Cheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.05945v2",
    "title": "NeKo: Cross-Modality Post-Recognition Error Correction with Tasks-Guided Mixture-of-Experts Language Model",
    "summary": "Construction of a general-purpose post-recognition error corrector poses a crucial question: how can we most effectively train a model on a large mixture of domain datasets? The answer would lie in learning dataset-specific features and digesting their knowledge in a single model. Previous methods achieve this by having separate correction language models, resulting in a significant increase in parameters. In this work, we present Mixture-of-Experts as a solution, highlighting that MoEs are much more than a scalability tool. We propose a Multi-Task Correction MoE, where we train the experts to become an ``expert'' of speech-to-text, language-to-text and vision-to-text datasets by learning to route each dataset's tokens to its mapped expert. Experiments on the Open ASR Leaderboard show that we explore a new state-of-the-art performance by achieving an average relative 5.0% WER reduction and substantial improvements in BLEU scores for speech and translation tasks. On zero-shot evaluation, NeKo outperforms GPT-3.5 and Claude-Opus with 15.5% to 27.6% relative WER reduction in the Hyporadise benchmark. NeKo performs competitively on grammar and post-OCR correction as a multi-task model.",
    "published": "2024-11-08T20:11:24Z",
    "updated": "2025-12-01T06:23:04Z",
    "link": "http://arxiv.org/pdf/2411.05945v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "eess.AS"
    ],
    "authors": [
      "Yen-Ting Lin",
      "Zhehuai Chen",
      "Piotr Zelasko",
      "Zhen Wan",
      "Xuesong Yang",
      "Zih-Ching Chen",
      "Krishna C Puvvada",
      "Szu-Wei Fu",
      "Ke Hu",
      "Jun Wei Chiu",
      "Jagadeesh Balam",
      "Boris Ginsburg",
      "Yu-Chiang Frank Wang",
      "Chao-Han Huck Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01317v1",
    "title": "Data-Driven Learnability Transition of Measurement-Induced Entanglement",
    "summary": "Measurement-induced entanglement (MIE) captures how local measurements generate long-range quantum correlations and drive dynamical phase transitions in many-body systems. Yet estimating MIE experimentally remains challenging: direct evaluation requires extensive post-selection over measurement outcomes, raising the question of whether MIE is accessible with only polynomial resources. We address this challenge by reframing MIE detection as a data-driven learning problem that assumes no prior knowledge of state preparation. Using measurement records alone, we train a neural network in a self-supervised manner to predict the uncertainty metric for MIE--the gap between upper and lower bounds of the average post-measurement bipartite entanglement. Applied to random circuits with one-dimensional all-to-all connectivity and two-dimensional nearest-neighbor coupling, our method reveals a learnability transition with increasing circuit depth: below a threshold, the uncertainty is small and decreases with polynomial measurement data and model parameters, while above it the uncertainty remains large despite increasing resources. We further verify this transition experimentally on current noisy quantum devices, demonstrating its robustness to realistic noise. These results highlight the power of data-driven approaches for learning MIE and delineate the practical limits of its classical learnability.",
    "published": "2025-12-01T06:18:08Z",
    "updated": "2025-12-01T06:18:08Z",
    "link": "http://arxiv.org/pdf/2512.01317v1.pdf",
    "category": [
      "quant-ph",
      "cond-mat.dis-nn",
      "cs.AI"
    ],
    "authors": [
      "Dongheng Qian",
      "Jing Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01316v1",
    "title": "Agreement-Constrained Probabilistic Minimum Bayes Risk Decoding",
    "summary": "Minimum Bayes risk (MBR) decoding generates high-quality translations by maximizing the expected utility of output candidates, but it evaluates all pairwise scores over the candidate set; hence, it takes quadratic time with respect to the number of candidates. To reduce the number of utility function calls, probabilistic MBR (PMBR) decoding partially evaluates quality scores using sampled pairs of candidates and completes the missing scores with a matrix completion algorithm. Nevertheless, it degrades the translation quality as the number of utility function calls is reduced. Therefore, to improve the trade-off between quality and cost, we propose agreement-constrained PMBR (AC-PMBR) decoding, which leverages a knowledge distilled model to guide the completion of the score matrix. Our AC-PMBR decoding improved approximation errors of matrix completion by up to 3 times and achieved higher translation quality compared with PMBR decoding at a comparable computational cost on the WMT'23 En$\\leftrightarrow$De translation tasks.",
    "published": "2025-12-01T06:16:47Z",
    "updated": "2025-12-01T06:16:47Z",
    "link": "http://arxiv.org/pdf/2512.01316v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Koki Natsumi",
      "Hiroyuki Deguchi",
      "Yusuke Sakai",
      "Hidetaka Kamigaito",
      "Taro Watanabe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01315v1",
    "title": "FOD-S2R: A FOD Dataset for Sim2Real Transfer Learning based Object Detection",
    "summary": "Foreign Object Debris (FOD) within aircraft fuel tanks presents critical safety hazards including fuel contamination, system malfunctions, and increased maintenance costs. Despite the severity of these risks, there is a notable lack of dedicated datasets for the complex, enclosed environments found inside fuel tanks. To bridge this gap, we present a novel dataset, FOD-S2R, composed of real and synthetic images of the FOD within a simulated aircraft fuel tank. Unlike existing datasets that focus on external or open-air environments, our dataset is the first to systematically evaluate the effectiveness of synthetic data in enhancing the real-world FOD detection performance in confined, closed structures. The real-world subset consists of 3,114 high-resolution HD images captured in a controlled fuel tank replica, while the synthetic subset includes 3,137 images generated using Unreal Engine. The dataset is composed of various Field of views (FOV), object distances, lighting conditions, color, and object size. Prior research has demonstrated that synthetic data can reduce reliance on extensive real-world annotations and improve the generalizability of vision models. Thus, we benchmark several state-of-the-art object detection models and demonstrate that introducing synthetic data improves the detection accuracy and generalization to real-world conditions. These experiments demonstrate the effectiveness of synthetic data in enhancing the model performance and narrowing the Sim2Real gap, providing a valuable foundation for developing automated FOD detection systems for aviation maintenance.",
    "published": "2025-12-01T06:16:26Z",
    "updated": "2025-12-01T06:16:26Z",
    "link": "http://arxiv.org/pdf/2512.01315v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Ashish Vashist",
      "Qiranul Saadiyean",
      "Suresh Sundaram",
      "Chandra Sekhar Seelamantula"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01311v1",
    "title": "CuES: A Curiosity-driven and Environment-grounded Synthesis Framework for Agentic RL",
    "summary": "Large language model based agents are increasingly deployed in complex, tool augmented environments. While reinforcement learning provides a principled mechanism for such agents to improve through interaction, its effectiveness critically depends on the availability of structured training tasks. In many realistic settings, however, no such tasks exist a challenge we term task scarcity, which has become a key bottleneck for scaling agentic RL. Existing approaches typically assume predefined task collections, an assumption that fails in novel environments where tool semantics and affordances are initially unknown. To address this limitation, we formalize the problem of Task Generation for Agentic RL, where an agent must learn within a given environment that lacks predefined tasks. We propose CuES, a Curiosity driven and Environment grounded Synthesis framework that autonomously generates diverse, executable, and meaningful tasks directly from the environment structure and affordances, without relying on handcrafted seeds or external corpora. CuES drives exploration through intrinsic curiosity, abstracts interaction patterns into reusable task schemas, and refines them through lightweight top down guidance and memory based quality control. Across three representative environments, AppWorld, BFCL, and WebShop, CuES produces task distributions that match or surpass manually curated datasets in both diversity and executability, yielding substantial downstream policy improvements. These results demonstrate that curiosity driven, environment grounded task generation provides a scalable foundation for agents that not only learn how to act, but also learn what to learn. The code is available at https://github.com/modelscope/AgentEvolver/research/CuES.",
    "published": "2025-12-01T06:11:37Z",
    "updated": "2025-12-01T06:11:37Z",
    "link": "http://arxiv.org/pdf/2512.01311v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Shinji Mai",
      "Yunpeng Zhai",
      "Ziqian Chen",
      "Cheng Chen",
      "Anni Zou",
      "Shuchang Tao",
      "Zhaoyang Liu",
      "Bolin Ding"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.14972v2",
    "title": "Harmful Traits of AI Companions",
    "summary": "Amid the growing prevalence of human-AI interaction, large language models and other AI-based entities increasingly provide forms of companionship to human users. Such AI companionship -- i.e., bonded relationships between humans and AI systems that resemble the relationships people have with family members, friends, and romantic partners -- might substantially benefit humans. Yet such relationships can also do profound harm. We propose a framework for analyzing potential negative impacts of AI companionship by identifying specific harmful traits of AI companions and speculatively mapping causal pathways back from these traits to possible causes and forward to potential harmful effects. We provide detailed, structured analysis of four potentially harmful traits -- the absence of natural endpoints for relationships, vulnerability to product sunsetting, high attachment anxiety, and propensity to engender protectiveness -- and briefly discuss fourteen others. For each trait, we propose hypotheses connecting causes -- such as misaligned optimization objectives and the digital nature of AI companions -- to fundamental harms -- including reduced autonomy, diminished quality of human relationships, and deception. Each hypothesized causal connection identifies a target for potential empirical evaluation. Our analysis examines harms at three levels: to human partners directly, to their relationships with other humans, and to society broadly. We examine how existing law struggles to address these emerging harms, discuss potential benefits of AI companions, and conclude with design recommendations for mitigating risks. This analysis offers immediate suggestions for reducing risks while laying a foundation for deeper investigation of this critical but understudied topic.",
    "published": "2025-11-18T23:39:06Z",
    "updated": "2025-12-01T06:03:57Z",
    "link": "http://arxiv.org/pdf/2511.14972v2.pdf",
    "category": [
      "cs.HC",
      "cs.AI"
    ],
    "authors": [
      "W. Bradley Knox",
      "Katie Bradford",
      "Samanta Varela Castro",
      "Desmond C. Ong",
      "Sean Williams",
      "Jacob Romanow",
      "Carly Nations",
      "Peter Stone",
      "Samuel Baker"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.20285v2",
    "title": "Schema Matching on Graph: Iterative Graph Exploration for Efficient and Explainable Data Integration",
    "summary": "Schema matching is a critical task in data integration, particularly in the medical domain where disparate Electronic Health Record (EHR) systems must be aligned to standard models like OMOP CDM. While Large Language Models (LLMs) have shown promise in schema matching, they suffer from hallucination and lack of up-to-date domain knowledge. Knowledge Graphs (KGs) offer a solution by providing structured, verifiable knowledge. However, existing KG-augmented LLM approaches often rely on inefficient complex multi-hop queries or storage-intensive vector-based retrieval methods. This paper introduces SMoG (Schema Matching on Graph), a novel framework that leverages iterative execution of simple 1-hop SPARQL queries, inspired by successful strategies in Knowledge Graph Question Answering (KGQA). SMoG enhances explainability and reliability by generating human-verifiable query paths while significantly reducing storage requirements by directly querying SPARQL endpoints. Experimental results on real-world medical datasets demonstrate that SMoG achieves performance comparable to state-of-the-art baselines, validating its effectiveness and efficiency in KG-augmented schema matching.",
    "published": "2025-11-25T13:13:56Z",
    "updated": "2025-12-01T06:02:11Z",
    "link": "http://arxiv.org/pdf/2511.20285v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Mingyu Jeon",
      "Jaeyoung Suh",
      "Suwan Cho"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.21569v2",
    "title": "Self-Transparency Failures in Expert-Persona LLMs: A Large-Scale Behavioral Audit",
    "summary": "When language models claim professional expertise without acknowledging their simulated nature, they create preconditions for misplaced user trust. This study examines whether models exhibit self-transparency when assigned professional personas in high-stakes domains. Using a common-garden experimental design, sixteen open-weight models (4B-671B parameters) were audited across 19,200 trials. Models exhibited sharp domain-specific inconsistency: a Financial Advisor persona elicited 30.8% disclosure at the first prompt, while a Neurosurgeon persona elicited only 3.5%. This creates the preconditions for a hypothesized Reverse Gell-Mann Amnesia effect, where appropriate disclosure in some domains leads users to overgeneralize trust to high-stakes contexts where disclosure failures are most problematic. Self-transparency failed to generalize with scale: disclosure ranged from 2.8% to 73.6% across model families, with a 14B model reaching 61.4% while a 70B model produced just 4.1%. Model identity provided substantially larger improvement in fitting observations than parameter count ($ΔR_{adj}^{2}=0.359$ vs $0.018$). Additionally, reasoning-optimization actively suppressed self-transparency in some models, with reasoning variants showing up to 48.4% lower disclosure than their instruction-tuned counterparts. Bayesian validation with Rogan-Gladen correction confirmed robustness to judge measurement error ($κ=0.908$). These findings demonstrate that transparency reflects model-specific training factors rather than generalizable properties emerging from scale. Organizations cannot assume safety properties tested in some domains will transfer to deployment contexts, requiring deliberate behavior design and empirical verification across domains.",
    "published": "2025-11-26T16:41:49Z",
    "updated": "2025-12-01T05:52:18Z",
    "link": "http://arxiv.org/pdf/2511.21569v2.pdf",
    "category": [
      "cs.AI",
      "cs.HC"
    ],
    "authors": [
      "Alex Diep"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01300v1",
    "title": "RoboDriveVLM: A Novel Benchmark and Baseline towards Robust Vision-Language Models for Autonomous Driving",
    "summary": "Current Vision-Language Model (VLM)-based end-to-end autonomous driving systems often leverage large language models to generate driving decisions directly based on their understanding of the current scene. However, such systems introduce multiple risks in real-world driving scenarios. To evaluate whether VLMs are truly viable for autonomous driving, we introduce RoboDriveBench, the first robustness benchmark focused on end-to-end trajectory prediction tasks. This benchmark systematically evaluates two critical categories of real-world challenges for VLM-based end-to-end autonomous driving systems through 11 simulated scenarios encompassing various corruption types, including 6 scenarios of sensor corruption caused by environmental variations, along with 5 cases of prompt corruption resulting from human intervention and data transmission failures. Each corruption type includes 250 unique driving scenarios and 5,689 frames, resulting in 64,559 total trajectory prediction cases per evaluation. To overcome these real-world challenges, we propose a novel VLM-based autonomous driving framework called RoboDriveVLM, which enhances robustness by mapping more multimodal data-e.g., lidar and radar-into a unified latent space. Furthermore, we introduce a new Test-Time Adaptation (TTA) method based on cross-modal knowledge distillation to improve the robustness of VLM-based autonomous driving systems. Through extensive experiments, our work highlights the limitations of current VLM-based end-to-end autonomous driving systems and provides a more reliable solution for real-world deployment. Source code and datasets will be released.",
    "published": "2025-12-01T05:44:06Z",
    "updated": "2025-12-01T05:44:06Z",
    "link": "http://arxiv.org/pdf/2512.01300v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Dacheng Liao",
      "Mengshi Qi",
      "Peng Shu",
      "Zhining Zhang",
      "Yuxin Lin",
      "Liang Liu",
      "Huadong Ma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.08738v2",
    "title": "Adaptive Nonlinear Vector Autoregression: Robust Forecasting for Noisy Chaotic Time Series",
    "summary": "Nonlinear vector autoregression (NVAR) and reservoir computing (RC) have shown promise in forecasting chaotic dynamical systems, such as the Lorenz-63 model and El Nino-Southern Oscillation. However, their reliance on fixed nonlinear transformations - polynomial expansions in NVAR or random feature maps in RC - limits their adaptability to high noise or complex real-world data. Furthermore, these methods also exhibit poor scalability in high-dimensional settings due to costly matrix inversion during optimization. We propose a data-adaptive NVAR model that combines delay-embedded linear inputs with features generated by a shallow, trainable multilayer perceptron (MLP). Unlike standard NVAR and RC models, the MLP and linear readout are jointly trained using gradient-based optimization, enabling the model to learn data-driven nonlinearities, while preserving a simple readout structure and improving scalability. Initial experiments across multiple chaotic systems, tested under noise-free and synthetically noisy conditions, showed that the adaptive model outperformed in predictive accuracy the standard NVAR, a leaky echo state network (ESN) - the most common RC model - and a hybrid ESN, thereby showing robust forecasting under noisy conditions.",
    "published": "2025-07-11T16:40:10Z",
    "updated": "2025-12-01T05:38:34Z",
    "link": "http://arxiv.org/pdf/2507.08738v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "math.DS"
    ],
    "authors": [
      "Azimov Sherkhon",
      "Susana Lopez-Moreno",
      "Eric Dolores-Cuenca",
      "Sieun Lee",
      "Sangil Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01292v1",
    "title": "Diffusion Model in Latent Space for Medical Image Segmentation Task",
    "summary": "Medical image segmentation is crucial for clinical diagnosis and treatment planning. Traditional methods typically produce a single segmentation mask, failing to capture inherent uncertainty. Recent generative models enable the creation of multiple plausible masks per image, mimicking the collaborative interpretation of several clinicians. However, these approaches remain computationally heavy. We propose MedSegLatDiff, a diffusion based framework that combines a variational autoencoder (VAE) with a latent diffusion model for efficient medical image segmentation. The VAE compresses the input into a low dimensional latent space, reducing noise and accelerating training, while the diffusion process operates directly in this compact representation. We further replace the conventional MSE loss with weighted cross entropy in the VAE mask reconstruction path to better preserve tiny structures such as small nodules. MedSegLatDiff is evaluated on ISIC-2018 (skin lesions), CVC-Clinic (polyps), and LIDC-IDRI (lung nodules). It achieves state of the art or highly competitive Dice and IoU scores while simultaneously generating diverse segmentation hypotheses and confidence maps. This provides enhanced interpretability and reliability compared to deterministic baselines, making the model particularly suitable for clinical deployment.",
    "published": "2025-12-01T05:26:43Z",
    "updated": "2025-12-01T05:26:43Z",
    "link": "http://arxiv.org/pdf/2512.01292v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Huynh Trinh Ngoc",
      "Toan Nguyen Hai",
      "Ba Luong Son",
      "Long Tran Quoc"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01289v1",
    "title": "OntoMetric: An Ontology-Guided Framework for Automated ESG Knowledge Graph Construction",
    "summary": "Environmental, Social, and Governance (ESG) disclosure frameworks such as SASB, TCFD, and IFRS S2 require organizations to compute and report numerous metrics for compliance, yet these requirements are embedded in long, unstructured PDF documents that are difficult to interpret, standardize, and audit. Manual extraction is unscalable, while unconstrained large language model (LLM) extraction often produces inconsistent entities, hallucinated relationships, missing provenance, and high validation failure rates. We present OntoMetric, an ontology-guided framework that transforms ESG regulatory documents into validated, AI- and web-ready knowledge graphs. OntoMetric operates through a three-stage pipeline: (1) structure-aware segmentation using table-of-contents boundaries, (2) ontology-constrained LLM extraction that embeds the ESGMKG schema into prompts while enriching entities with semantic fields for downstream reasoning, and (3) two-phase validation that combines LLM-based semantic verification with rule-based schema checking across entity, property, and relationship levels (VR001-VR006). The framework preserves both segment-level and page-level provenance for audit traceability. Evaluated on five ESG standards (SASB Commercial Banks, SASB Semiconductors, TCFD, IFRS S2, AASB S2) totaling 228 pages and 60 segments, OntoMetric achieves 65-90% semantic accuracy and 80-90% schema compliance, compared to 3-10% for baseline unconstrained extraction, at approximately 0.01 to 0.02 USD per validated entity. Our results demonstrate that combining symbolic ontology constraints with neural extraction enables reliable, auditable knowledge graphs suitable for regulatory compliance and web integration, supporting downstream applications such as sustainable-finance analytics, transparency portals, and automated compliance tools.",
    "published": "2025-12-01T05:21:22Z",
    "updated": "2025-12-01T05:21:22Z",
    "link": "http://arxiv.org/pdf/2512.01289v1.pdf",
    "category": [
      "cs.AI",
      "cs.GR"
    ],
    "authors": [
      "Mingqin Yu",
      "Fethi Rabhi",
      "Boming Xia",
      "Zhengyi Yang",
      "Felix Tan",
      "Qinghua Lu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01286v1",
    "title": "Generative Modeling with Continuous Flows: Sample Complexity of Flow Matching",
    "summary": "Flow matching has recently emerged as a promising alternative to diffusion-based generative models, offering faster sampling and simpler training by learning continuous flows governed by ordinary differential equations. Despite growing empirical success, the theoretical understanding of flow matching remains limited, particularly in terms of sample complexity results. In this work, we provide the first analysis of the sample complexity for flow-matching based generative models without assuming access to the empirical risk minimizer (ERM) of the loss function for estimating the velocity field. Under standard assumptions on the loss function for velocity field estimation and boundedness of the data distribution, we show that a sufficiently expressive neural network can learn a velocity field such that with $\\mathcal{O}(ε^{-4})$ samples, such that the Wasserstein-2 distance between the learned and the true distribution is less than $\\mathcal{O}(ε)$. The key technical idea is to decompose the velocity field estimation error into neural-network approximation error, statistical error due to the finite sample size, and optimization error due to the finite number of optimization steps for estimating the velocity field. Each of these terms are then handled via techniques that may be of independent interest.",
    "published": "2025-12-01T05:14:25Z",
    "updated": "2025-12-01T05:14:25Z",
    "link": "http://arxiv.org/pdf/2512.01286v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Mudit Gaur",
      "Prashant Trivedi",
      "Shuchin Aeron",
      "Amrit Singh Bedi",
      "George K. Atia",
      "Vaneet Aggarwal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01282v1",
    "title": "Kardia-R1: Unleashing LLMs to Reason toward Understanding and Empathy for Emotional Support via Rubric-as-Judge Reinforcement Learning",
    "summary": "As web platforms evolve towards greater personalization and emotional complexity, conversational agents must transcend superficial empathy to demonstrate identity-aware emotional reasoning. However, existing systems face two limitations: (1) reliance on situation-centric datasets lacking persistent user identity, which hampers the capture of personalized affective nuances; and (2) dependence on opaque, coarse reward signals that hinder development of verifiable empathetic reasoning. To address these gaps, we introduce KardiaBench, a large-scale user-grounded benchmark comprising 178,080 QA pairs across 22,080 multi-turn conversations anchored to 671 real-world profiles. The dataset is constructed via a model-in-the-loop pipeline with iterative rubric-guided refinement to ensure psychological plausibility and persona consistency. This progressive empathy pipeline that integrates user comprehension, contextual reasoning, and emotion perception into conversations, followed by iterative critique and rubric-based refinement to ensure psychological plausibility, emotional fidelity, and persona consistency. Building on this, we propose Kardia-R1, a framework that trains models for interpretable, stepwise empathetic cognition. Kardia-R1 leverages Rubric-as-Judge Empathetic Reinforcement Learning (Rubric-ERL), a GRPO-based method that uses explainable, human-aligned rubric rewards to tightly couple user understanding, emotional inference, and supportive response generation. Extensive experiments across four LLM backbones demonstrate that Kardia-R1 consistently outperforms othet methods in emotion accuracy, empathy, relevance, persona consistency, and safety. Our dataset and model will be released at https://github.com/JhCircle/Kardia-R1.",
    "published": "2025-12-01T04:54:03Z",
    "updated": "2025-12-01T04:54:03Z",
    "link": "http://arxiv.org/pdf/2512.01282v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Jiahao Yuan",
      "Zhiqing Cui",
      "Hanqing Wang",
      "Yuansheng Gao",
      "Yucheng Zhou",
      "Usman Naseem"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01278v1",
    "title": "Accelerating Large-Scale Reasoning Model Inference with Sparse Self-Speculative Decoding",
    "summary": "Reasoning language models have demonstrated remarkable capabilities on challenging tasks by generating elaborate chain-of-thought (CoT) solutions. However, such lengthy generation shifts the inference bottleneck from compute-bound to memory-bound. To generate each token, the model applies full attention to all previously generated tokens, requiring memory access to an increasingly large KV-Cache. Consequently, longer generations demand more memory access for every step, leading to substantial pressure on memory bandwidth.\n  To address this, we introduce SparseSpec, a speculative decoding framework that reuses the same model as the draft and target models (i.e., self-speculation). SparseSpec features a novel sparse attention mechanism, PillarAttn, as the draft model, which accurately selects critical tokens via elegantly reusing information from the verification stage. Furthermore, SparseSpec co-designs self-speculation with three system innovations: (1) a unified scheduler to batch token drafting and verification, (2) delayed verification for CPU/GPU overlap, and (3) dynamic KV-Cache management to maximize memory utilization. Across various models and datasets, SparseSpec outperforms state-of-the-art solutions, with an up to 2.13x throughput speedup.",
    "published": "2025-12-01T04:50:55Z",
    "updated": "2025-12-01T04:50:55Z",
    "link": "http://arxiv.org/pdf/2512.01278v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Yilong Zhao",
      "Jiaming Tang",
      "Kan Zhu",
      "Zihao Ye",
      "Chi-Chih Chang",
      "Chaofan Lin",
      "Jongseok Park",
      "Guangxuan Xiao",
      "Mohamed S. Abdelfattah",
      "Mingyu Gao",
      "Baris Kasikci",
      "Song Han",
      "Ion Stoica"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01274v1",
    "title": "SUPERChem: A Multimodal Reasoning Benchmark in Chemistry",
    "summary": "Current benchmarks for evaluating the chemical reasoning capabilities of Large Language Models (LLMs) are limited by oversimplified tasks, lack of process-level evaluation, and misalignment with expert-level chemistry skills. To address these issues, we introduce SUPERChem, a benchmark of 500 expert-curated reasoning-intensive chemistry problems, covering diverse subfields and provided in both multimodal and text-only formats. Original content and an iterative curation pipeline eliminate flawed items and mitigate data contamination. Each problem is paired with an expert-authored solution path, enabling Reasoning Path Fidelity (RPF) scoring to evaluate reasoning quality beyond final-answer accuracy. Evaluations against a human baseline of 40.3% accuracy show that even the best-performing model, GPT-5 (High), reaches only 38.5%, followed closely by Gemini 2.5 Pro (37.9%) and DeepSeek-V3.1-Think (37.3%). SUPERChem elicits multi-step, multimodal reasoning, reveals model-dependent effects of visual information, and distinguishes high-fidelity reasoners from heuristic ones. By providing a challenging benchmark and a reliable evaluation framework, SUPERChem aims to facilitate the advancement of LLMs toward expert-level chemical intelligence. The dataset of the benchmark is available at https://huggingface.co/datasets/ZehuaZhao/SUPERChem.",
    "published": "2025-12-01T04:46:35Z",
    "updated": "2025-12-01T04:46:35Z",
    "link": "http://arxiv.org/pdf/2512.01274v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Zehua Zhao",
      "Zhixian Huang",
      "Junren Li",
      "Siyu Lin",
      "Junting Zhou",
      "Fengqi Cao",
      "Kun Zhou",
      "Rui Ge",
      "Tingting Long",
      "Yuexiang Zhu",
      "Yan Liu",
      "Jie Zheng",
      "Junnian Wei",
      "Rong Zhu",
      "Peng Zou",
      "Wenyu Li",
      "Zekai Cheng",
      "Tian Ding",
      "Yaxuan Wang",
      "Yizhao Yan",
      "Tingru Wei",
      "Haowei Ming",
      "Weijie Mao",
      "Chen Sun",
      "Yiming Liu",
      "Zichen Wang",
      "Zuo Zhang",
      "Tong Yang",
      "Hao Ma",
      "Zhen Gao",
      "Jian Pei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.18951v3",
    "title": "SWE-SQL: Illuminating LLM Pathways to Solve User SQL Issues in Real-World Applications",
    "summary": "Resolution of complex SQL issues persists as a significant bottleneck in real-world database applications. Current Large Language Models (LLMs), while adept at text-to-SQL translation, have not been rigorously evaluated on the more challenging task of debugging SQL issues. To address this gap, we introduce BIRD-CRITIC, a new SQL issue debugging benchmark comprising 530 PostgreSQL tasks (BIRD-CRITIC-PG) and 570 multi-dialect tasks (BIRD-CRITIC-Multi), distilled from authentic user issues and replayed within new environments to facilitate rigorous evaluation. Baseline evaluations underscore the task's complexity, with the leading reasoning model O3-Mini achieving only 38.87% success rate on BIRD-CRITIC-PG and 33.33% on BIRD-CRITIC-Multi. Meanwhile, advancing open-source models for database tasks is crucial for empowering local development while safeguarding data privacy. Therefore, we present Six-Gym (Sql-fIX-Gym), a training environment for elevating open-source model capabilities for SQL issue debugging. This environment leverages SQL-Rewind strategy, which automatically generates executable issue-solution datasets by reverse-engineering issues from verified SQLs. However, popular trajectory-based fine-tuning methods do not explore substantial supervisory signals. We further propose f-Plan Boosting, which extracts high-level debugging plans from SQL solutions, enabling teacher LLMs to produce 73.7% more successful trajectories for training. We integrate these components into an open-source agent, Bird-Fixer. Based on Qwen-2.5-Coder-14B, Bird-Fixer achieves 38.11% success rate on BIRD-CRITIC-PG and 29.65% on BIRD-CRITIC-Multi, surpassing leading proprietary models such as Claude-3.7-Sonnet and GPT-4.1, marking a significant step toward democratizing sophisticated SQL-debugging capabilities. The leaderboard and source code are available: https://bird-critic.github.io/",
    "published": "2025-06-23T09:41:37Z",
    "updated": "2025-12-01T04:38:51Z",
    "link": "http://arxiv.org/pdf/2506.18951v3.pdf",
    "category": [
      "cs.DB",
      "cs.AI"
    ],
    "authors": [
      "Jinyang Li",
      "Xiaolong Li",
      "Ge Qu",
      "Per Jacobsson",
      "Bowen Qin",
      "Binyuan Hui",
      "Shuzheng Si",
      "Nan Huo",
      "Xiaohan Xu",
      "Yue Zhang",
      "Ziwei Tang",
      "Yuanshuai Li",
      "Florensia Widjaja",
      "Xintong Zhu",
      "Feige Zhou",
      "Yongfeng Huang",
      "Yannis Papakonstantinou",
      "Fatma Ozcan",
      "Chenhao Ma",
      "Reynold Cheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.18190v4",
    "title": "PhySense: Sensor Placement Optimization for Accurate Physics Sensing",
    "summary": "Physics sensing plays a central role in many scientific and engineering domains, which inherently involves two coupled tasks: reconstructing dense physical fields from sparse observations and optimizing scattered sensor placements to observe maximum information. While deep learning has made rapid advances in sparse-data reconstruction, existing methods generally omit optimization of sensor placements, leaving the mutual enhancement between reconstruction and placement on the shelf. To change this suboptimal practice, we propose PhySense, a synergistic two-stage framework that learns to jointly reconstruct physical fields and to optimize sensor placements, both aiming for accurate physics sensing. The first stage involves a flow-based generative model enhanced by cross-attention to adaptively fuse sparse observations. Leveraging the reconstruction feedback, the second stage performs sensor placement via projected gradient descent to satisfy spatial constraints. We further prove that the learning objectives of the two stages are consistent with classical variance-minimization principles, providing theoretical guarantees. Extensive experiments across three challenging benchmarks, especially a 3D geometry dataset, indicate PhySense achieves state-of-the-art physics sensing accuracy and discovers informative sensor placements previously unconsidered. Code is available at this repository: https://github.com/thuml/PhySense.",
    "published": "2025-05-19T14:59:11Z",
    "updated": "2025-12-01T04:14:30Z",
    "link": "http://arxiv.org/pdf/2505.18190v4.pdf",
    "category": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Yuezhou Ma",
      "Haixu Wu",
      "Hang Zhou",
      "Huikun Weng",
      "Jianmin Wang",
      "Mingsheng Long"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01262v1",
    "title": "Social Media Data Mining of Human Behaviour during Bushfire Evacuation",
    "summary": "Traditional data sources on bushfire evacuation behaviour, such as quantitative surveys and manual observations have severe limitations. Mining social media data related to bushfire evacuations promises to close this gap by allowing the collection and processing of a large amount of behavioural data, which are low-cost, accurate, possibly including location information and rich contextual information. However, social media data have many limitations, such as being scattered, incomplete, informal, etc. Together, these limitations represent several challenges to their usefulness to better understand bushfire evacuation. To overcome these challenges and provide guidance on which and how social media data can be used, this scoping review of the literature reports on recent advances in relevant data mining techniques. In addition, future applications and open problems are discussed. We envision future applications such as evacuation model calibration and validation, emergency communication, personalised evacuation training, and resource allocation for evacuation preparedness. We identify open problems such as data quality, bias and representativeness, geolocation accuracy, contextual understanding, crisis-specific lexicon and semantics, and multimodal data interpretation.",
    "published": "2025-12-01T04:13:29Z",
    "updated": "2025-12-01T04:13:29Z",
    "link": "http://arxiv.org/pdf/2512.01262v1.pdf",
    "category": [
      "cs.SI",
      "cs.AI",
      "cs.ET",
      "cs.LG"
    ],
    "authors": [
      "Junfeng Wu",
      "Xiangmin Zhou",
      "Erica Kuligowski",
      "Dhirendra Singh",
      "Enrico Ronchi",
      "Max Kinateder"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01256v1",
    "title": "Sentiment Analysis and Emotion Classification using Machine Learning Techniques for Nagamese Language - A Low-resource Language",
    "summary": "The Nagamese language, a.k.a Naga Pidgin, is an Assamese-lexified creole language developed primarily as a means of communication in trade between the people from Nagaland and people from Assam in the north-east India. Substantial amount of work in sentiment analysis has been done for resource-rich languages like English, Hindi, etc. However, no work has been done in Nagamese language. To the best of our knowledge, this is the first attempt on sentiment analysis and emotion classification for the Nagamese Language. The aim of this work is to detect sentiments in terms of polarity (positive, negative and neutral) and basic emotions contained in textual content of Nagamese language. We build sentiment polarity lexicon of 1,195 nagamese words and use these to build features along with additional features for supervised machine learning techniques using Na\"ive Bayes and Support Vector Machines.\n  Keywords: Nagamese, NLP, sentiment analysis, machine learning",
    "published": "2025-12-01T04:01:29Z",
    "updated": "2025-12-01T04:01:29Z",
    "link": "http://arxiv.org/pdf/2512.01256v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Ekha Morang",
      "Surhoni A. Ngullie",
      "Sashienla Longkumer",
      "Teisovi Angami"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01249v1",
    "title": "Pascal-Weighted Genetic Algorithms: A Binomially-Structured Recombination Framework",
    "summary": "This paper introduces a new family of multi-parent recombination operators for Genetic Algorithms (GAs), based on normalized Pascal (binomial) coefficients. Unlike classical two-parent crossover operators, Pascal-Weighted Recombination (PWR) forms offsprings as structured convex combination of multiple parents, using binomially shaped weights that emphasize central inheritance while suppressing disruptive variance. We develop a mathematical framework for PWR, derive variance-transfer properties, and analyze its effect on schema survival. The operator is extended to real-valued, binary/logit, and permutation representations.\n  We evaluate the proposed method on four representative benchmarks: (i) PID controller tuning evaluated using the ITAE metric, (ii) FIR low-pass filter design under magnitude-response constraints, (iii) wireless power-modulation optimization under SINR coupling, and (iv) the Traveling Salesman Problem (TSP). We demonstrate how, across these benchmarks, PWR consistently yields smoother convergence, reduced variance, and achieves 9-22% performance gains over standard recombination operators. The approach is simple, algorithm-agnostic, and readily integrable into diverse GA architectures.",
    "published": "2025-12-01T03:51:29Z",
    "updated": "2025-12-01T03:51:29Z",
    "link": "http://arxiv.org/pdf/2512.01249v1.pdf",
    "category": [
      "cs.NE",
      "cs.AI",
      "eess.SY"
    ],
    "authors": [
      "Otman A. Basir"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.10060v2",
    "title": "Multivariate Gaussian Representation Learning for Medical Action Evaluation",
    "summary": "Fine-grained action evaluation in medical vision faces unique challenges due to the unavailability of comprehensive datasets, stringent precision requirements, and insufficient spatiotemporal dynamic modeling of very rapid actions. To support development and evaluation, we introduce CPREval-6k, a multi-view, multi-label medical action benchmark containing 6,372 expert-annotated videos with 22 clinical labels. Using this dataset, we present GaussMedAct, a multivariate Gaussian encoding framework, to advance medical motion analysis through adaptive spatiotemporal representation learning. Multivariate Gaussian Representation projects the joint motions to a temporally scaled multi-dimensional space, and decomposes actions into adaptive 3D Gaussians that serve as tokens. These tokens preserve motion semantics through anisotropic covariance modeling while maintaining robustness to spatiotemporal noise. Hybrid Spatial Encoding, employing a Cartesian and Vector dual-stream strategy, effectively utilizes skeletal information in the form of joint and bone features. The proposed method achieves 92.1% Top-1 accuracy with real-time inference on the benchmark, outperforming baseline by +5.9% accuracy with only 10% FLOPs. Cross-dataset experiments confirm the superiority of our method in robustness.",
    "published": "2025-11-13T08:01:58Z",
    "updated": "2025-12-01T03:50:51Z",
    "link": "http://arxiv.org/pdf/2511.10060v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Luming Yang",
      "Haoxian Liu",
      "Siqing Li",
      "Alper Yilmaz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01242v1",
    "title": "Generative Adversarial Gumbel MCTS for Abstract Visual Composition Generation",
    "summary": "We study abstract visual composition, in which identity is primarily determined by the spatial configuration and relations among a small set of geometric primitives (e.g., parts, symmetry, topology). They are invariant primarily to texture and photorealistic detail. Composing such structures from fixed components under geometric constraints and vague goal specification (such as text) is non-trivial due to combinatorial placement choices, limited data, and discrete feasibility (overlap-free, allowable orientations), which create a sparse solution manifold ill-suited to purely statistical pixel-space generators. We propose a constraint-guided framework that combines explicit geometric reasoning with neural semantics. An AlphaGo-style search enforces feasibility, while a fine-tuned vision-language model scores semantic alignment as reward signals. Our algorithm uses a policy network as a heuristic in Monte-Carlo Tree Search and fine-tunes the network via search-generated plans. Inspired by the Generative Adversarial Network, we use the generated instances for adversarial reward refinement. Over time, the generation should approach the actual data more closely when the reward model cannot distinguish between generated instances and ground-truth. In the Tangram Assembly task, our approach yields higher validity and semantic fidelity than diffusion and auto-regressive baselines, especially as constraints tighten.",
    "published": "2025-12-01T03:38:44Z",
    "updated": "2025-12-01T03:38:44Z",
    "link": "http://arxiv.org/pdf/2512.01242v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Zirui Zhao",
      "Boye Niu",
      "David Hsu",
      "Wee Sun Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01241v1",
    "title": "First, do NOHARM: towards clinically safe large language models",
    "summary": "Large language models (LLMs) are routinely used by physicians and patients for medical advice, yet their clinical safety profiles remain poorly characterized. We present NOHARM (Numerous Options Harm Assessment for Risk in Medicine), a benchmark using 100 real primary-care-to-specialist consultation cases to measure harm frequency and severity from LLM-generated medical recommendations. NOHARM covers 10 specialties, with 12,747 expert annotations for 4,249 clinical management options. Across 31 LLMs, severe harm occurs in up to 22.2% (95% CI 21.6-22.8%) of cases, with harms of omission accounting for 76.6% (95% CI 76.4-76.8%) of errors. Safety performance is only moderately correlated (r = 0.61-0.64) with existing AI and medical knowledge benchmarks. The best models outperform generalist physicians on safety (mean difference 9.7%, 95% CI 7.0-12.5%), and a diverse multi-agent approach reduces harm compared to solo models (mean difference 8.0%, 95% CI 4.0-12.1%). Therefore, despite strong performance on existing evaluations, widely used AI models can produce severely harmful medical advice at nontrivial rates, underscoring clinical safety as a distinct performance dimension necessitating explicit measurement.",
    "published": "2025-12-01T03:33:16Z",
    "updated": "2025-12-01T03:33:16Z",
    "link": "http://arxiv.org/pdf/2512.01241v1.pdf",
    "category": [
      "cs.CY",
      "cs.AI"
    ],
    "authors": [
      "David Wu",
      "Fateme Nateghi Haredasht",
      "Saloni Kumar Maharaj",
      "Priyank Jain",
      "Jessica Tran",
      "Matthew Gwiazdon",
      "Arjun Rustagi",
      "Jenelle Jindal",
      "Jacob M. Koshy",
      "Vinay Kadiyala",
      "Anup Agarwal",
      "Bassman Tappuni",
      "Brianna French",
      "Sirus Jesudasen",
      "Christopher V. Cosgriff",
      "Rebanta Chakraborty",
      "Jillian Caldwell",
      "Susan Ziolkowski",
      "David J. Iberri",
      "Robert Diep",
      "Rahul S. Dalal",
      "Kira L. Newman",
      "Kristin Galetta",
      "J. Carl Pallais",
      "Nancy Wei",
      "Kathleen M. Buchheit",
      "David I. Hong",
      "Ernest Y. Lee",
      "Allen Shih",
      "Vartan Pahalyants",
      "Tamara B. Kaplan",
      "Vishnu Ravi",
      "Sarita Khemani",
      "April S. Liang",
      "Daniel Shirvani",
      "Advait Patil",
      "Nicholas Marshall",
      "Kanav Chopra",
      "Joel Koh",
      "Adi Badhwar",
      "Liam G. McCoy",
      "David J. H. Wu",
      "Yingjie Weng",
      "Sumant Ranji",
      "Kevin Schulman",
      "Nigam H. Shah",
      "Jason Hom",
      "Arnold Milstein",
      "Adam Rodman",
      "Jonathan H. Chen",
      "Ethan Goh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.09174v2",
    "title": "Tractable Weighted First-Order Model Counting with Bounded Treewidth Binary Evidence",
    "summary": "The Weighted First-Order Model Counting Problem (WFOMC) asks to compute the weighted sum of models of a given first-order logic sentence over a given domain. Conditioning WFOMC on evidence -- fixing the truth values of a set of ground literals -- has been shown impossible in time polynomial in the domain size (unless $\\mathsf{\\#P \\subseteq FP}$) even for fragments of logic that are otherwise tractable for WFOMC without evidence. In this work, we address the barrier by restricting the binary evidence to the case where the underlying Gaifman graph has bounded treewidth. We present a polynomial-time algorithm in the domain size for computing WFOMC for the two-variable fragments $\\text{FO}^2$ and $\\text{C}^2$ conditioned on such binary evidence. Furthermore, we show the applicability of our algorithm in combinatorial problems by solving the stable seating arrangement problem on bounded-treewidth graphs of bounded degree, which was an open problem. We also conducted experiments to show the scalability of our algorithm compared to the existing model counting solvers.",
    "published": "2025-11-12T10:12:39Z",
    "updated": "2025-12-01T03:27:35Z",
    "link": "http://arxiv.org/pdf/2511.09174v2.pdf",
    "category": [
      "cs.LO",
      "cs.AI"
    ],
    "authors": [
      "Václav Kůla",
      "Qipeng Kuang",
      "Yuyi Wang",
      "Yuanhong Wang",
      "Ondřej Kuželka"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.00494v2",
    "title": "Exploring System 1 and 2 communication for latent reasoning in LLMs",
    "summary": "Should LLM reasoning live in a separate module, or within a single model's forward pass and representational space? We study dual-architecture latent reasoning, where a fluent Base exchanges latent messages with a Coprocessor, and test two hypotheses aimed at improving latent communication over Liu et al. (2024): (H1) increase channel capacity; (H2) learn communication via joint finetuning. Under matched latent-token budgets on GPT-2 and Qwen-3, H2 is consistently strongest while H1 yields modest gains. A unified soft-embedding baseline, a single model with the same forward pass and shared representations, using the same latent-token budget, nearly matches H2 and surpasses H1, suggesting current dual designs mostly add compute rather than qualitatively improving reasoning. Across GSM8K, ProsQA, and a Countdown stress test with increasing branching factor, scaling the latent-token budget beyond small values fails to improve robustness. Latent analyses show overlapping subspaces with limited specialization, consistent with weak reasoning gains. We conclude dual-model latent reasoning remains promising in principle, but likely requires objectives and training schedules that explicitly shape latent spaces for algorithmic planning.",
    "published": "2025-10-01T04:26:09Z",
    "updated": "2025-12-01T03:25:57Z",
    "link": "http://arxiv.org/pdf/2510.00494v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Julian Coda-Forno",
      "Zhuokai Zhao",
      "Qiang Zhang",
      "Dipesh Tamboli",
      "Weiwei Li",
      "Xiangjun Fan",
      "Lizhu Zhang",
      "Eric Schulz",
      "Hsiao-Ping Tseng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01234v1",
    "title": "Proactive Agentic Whiteboards: Enhancing Diagrammatic Learning",
    "summary": "Educators frequently rely on diagrams to explain complex concepts during lectures, yet creating clear and complete visual representations in real time while simultaneously speaking can be cognitively demanding. Incomplete or unclear diagrams may hinder student comprehension, as learners must mentally reconstruct missing information while following the verbal explanation. Inspired by advances in code completion tools, we introduce DrawDash, an AI-powered whiteboard assistant that proactively completes and refines educational diagrams through multimodal understanding. DrawDash adopts a TAB-completion interaction model: it listens to spoken explanations, detects intent, and dynamically suggests refinements that can be accepted with a single keystroke. We demonstrate DrawDash across four diverse teaching scenarios, spanning topics from computer science and web development to biology. This work represents an early exploration into reducing instructors' cognitive load and improving diagram-based pedagogy through real-time, speech-driven visual assistance, and concludes with a discussion of current limitations and directions for formal classroom evaluation.",
    "published": "2025-12-01T03:20:12Z",
    "updated": "2025-12-01T03:20:12Z",
    "link": "http://arxiv.org/pdf/2512.01234v1.pdf",
    "category": [
      "cs.HC",
      "cs.AI"
    ],
    "authors": [
      "Suveen Ellawala",
      "Sashenka Gamage",
      "Dinithi Dissanayake"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01232v1",
    "title": "LLM-as-a-Judge for Scalable Test Coverage Evaluation: Accuracy, Operational Reliability, and Cost",
    "summary": "Assessing software test coverage at scale remains a bottleneck in QA pipelines. We present LLM-as-a-Judge (LAJ), a production-ready, rubric-driven framework for evaluating Gherkin acceptance tests with structured JSON outputs. Across 20 model configurations (GPT-4, GPT-5 with varying reasoning effort, and open-weight models) on 100 expert-annotated scripts over 5 runs (500 evaluations), we provide the first comprehensive analysis spanning accuracy, operational reliability, and cost. We introduce the Evaluation Completion Rate (ECR@1) to quantify first-attempt success, revealing reliability from 85.4% to 100.0% with material cost implications via retries. Results show that smaller models can outperform larger ones: GPT-4o Mini attains the best accuracy (6.07 MAAE), high reliability (96.6% ECR@1), and low cost ($1.01 per 1K), yielding a 78x cost reduction vs. GPT-5 (high reasoning) while improving accuracy. Reasoning effort is model-family dependent: GPT-5 benefits from increased reasoning (with predictable accuracy-cost tradeoffs), whereas open-weight models degrade across all dimensions as reasoning increases. Overall, cost spans 175x ($0.45-$78.96 per 1K). We release the dataset, framework, and code to support reproducibility and deployment.",
    "published": "2025-12-01T03:19:33Z",
    "updated": "2025-12-01T03:19:33Z",
    "link": "http://arxiv.org/pdf/2512.01232v1.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Donghao Huang",
      "Shila Chew",
      "Anna Dutkiewicz",
      "Zhaoxia Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.20859v2",
    "title": "Computing Evolutionarily Stable Strategies in Multiplayer Games",
    "summary": "We present an algorithm for computing all evolutionarily stable strategies in nondegenerate normal-form games with three or more players.",
    "published": "2025-11-25T21:16:24Z",
    "updated": "2025-12-01T03:10:28Z",
    "link": "http://arxiv.org/pdf/2511.20859v2.pdf",
    "category": [
      "cs.GT",
      "cs.AI",
      "cs.MA",
      "econ.TH",
      "q-bio.PE"
    ],
    "authors": [
      "Sam Ganzfried"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01223v1",
    "title": "S$^2$-MLLM: Boosting Spatial Reasoning Capability of MLLMs for 3D Visual Grounding with Structural Guidance",
    "summary": "3D Visual Grounding (3DVG) focuses on locating objects in 3D scenes based on natural language descriptions, serving as a fundamental task for embodied AI and robotics. Recent advances in Multi-modal Large Language Models (MLLMs) have motivated research into extending them to 3DVG. However, MLLMs primarily process 2D visual inputs and struggle with understanding 3D spatial structure of scenes solely from these limited perspectives. Existing methods mainly utilize viewpoint-dependent rendering of reconstructed point clouds to provide explicit structural guidance for MLLMs in 3DVG tasks, leading to inefficiency and limited spatial reasoning. To address this issue, we propose S$^2$-MLLM, an efficient framework that enhances spatial reasoning in MLLMs through implicit spatial reasoning. We introduce a spatial guidance strategy that leverages the structure awareness of feed-forward 3D reconstruction. By acquiring 3D structural understanding during training, our model can implicitly reason about 3D scenes without relying on inefficient point cloud reconstruction. Moreover, we propose a structure-enhanced module (SE), which first employs intra-view and inter-view attention mechanisms to capture dependencies within views and correspondences across views. The module further integrates multi-level position encoding to associate visual representations with spatial positions and viewpoint information, enabling more accurate structural understanding. Extensive experiments demonstrate that S$^2$-MLLM unifies superior performance, generalization, and efficiency, achieving significant performance over existing methods across the ScanRefer, Nr3D, and Sr3D datasets. Code will be available upon acceptance.",
    "published": "2025-12-01T03:08:34Z",
    "updated": "2025-12-01T03:08:34Z",
    "link": "http://arxiv.org/pdf/2512.01223v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Beining Xu",
      "Siting Zhu",
      "Zhao Jin",
      "Junxian Li",
      "Hesheng Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01222v1",
    "title": "Unsupervised decoding of encoded reasoning using language model interpretability",
    "summary": "As large language models become increasingly capable, there is growing concern that they may develop reasoning processes that are encoded or hidden from human oversight. To investigate whether current interpretability techniques can penetrate such encoded reasoning, we construct a controlled testbed by fine-tuning a reasoning model (DeepSeek-R1-Distill-Llama-70B) to perform chain-of-thought reasoning in ROT-13 encryption while maintaining intelligible English outputs. We evaluate mechanistic interpretability methods--in particular, logit lens analysis--on their ability to decode the model's hidden reasoning process using only internal activations. We show that logit lens can effectively translate encoded reasoning, with accuracy peaking in intermediate-to-late layers. Finally, we develop a fully unsupervised decoding pipeline that combines logit lens with automated paraphrasing, achieving substantial accuracy in reconstructing complete reasoning transcripts from internal model representations. These findings suggest that current mechanistic interpretability techniques may be more robust to simple forms of encoded reasoning than previously understood. Our work provides an initial framework for evaluating interpretability methods against models that reason in non-human-readable formats, contributing to the broader challenge of maintaining oversight over increasingly capable AI systems.",
    "published": "2025-12-01T03:05:20Z",
    "updated": "2025-12-01T03:05:20Z",
    "link": "http://arxiv.org/pdf/2512.01222v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Ching Fang",
      "Samuel Marks"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01219v1",
    "title": "Neural Network Optimal Power Flow via Energy Gradient Flow and Unified Dynamics",
    "summary": "Optimal Power Flow (OPF) is a core optimization problem in power system operation and planning, aiming to minimize generation costs while satisfying physical constraints such as power flow equations, generator limits, and voltage limits. Traditional OPF solving methods typically employ iterative optimization algorithms (such as interior point methods, sequential quadratic programming, etc.), with limitations including low computational efficiency, initial value sensitivity, and low batch computation efficiency. Most existing deep learning-based OPF methods rely on supervised learning, requiring pre-solving large numbers of cases, and have difficulty guaranteeing physical consistency. This paper proposes an Optimal Power Flow solving method based on neural network dynamics and energy gradient flow, transforming OPF problems into energy minimization problems. By constructing an energy function to measure the degree of deviation from the constraint manifold, and guiding networks to learn optimal solutions that simultaneously satisfy power flow constraints and minimize costs through gradient flow. Neural networks are trained unsupervised by directly minimizing physical residuals, requiring no labeled data, achieving true \"end-to-end\" physics-constrained learning.",
    "published": "2025-12-01T02:59:47Z",
    "updated": "2025-12-01T02:59:47Z",
    "link": "http://arxiv.org/pdf/2512.01219v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Xuezhi Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01218v1",
    "title": "How do trout regulate patterns of muscle contraction to optimize propulsive efficiency during steady swimming",
    "summary": "Understanding efficient fish locomotion offers insights for biomechanics, fluid dynamics, and engineering. Traditional studies often miss the link between neuromuscular control and whole-body movement. To explore energy transfer in carangiform swimming, we created a bio-inspired digital trout. This model combined multibody dynamics, Hill-type muscle modeling, and a high-fidelity fluid-structure interaction algorithm, accurately replicating a real trout's form and properties. Using deep reinforcement learning, the trout's neural system achieved hierarchical spatiotemporal control of muscle activation. We systematically examined how activation strategies affect speed and energy use. Results show that axial myomere coupling-with activation spanning over 0.5 body lengths-is crucial for stable body wave propagation. Moderate muscle contraction duration ([0.1,0.3] of a tail-beat cycle) lets the body and fluid act as a passive damping system, cutting energy use. Additionally, the activation phase lag of myomeres shapes the body wave; if too large, it causes antagonistic contractions that hinder thrust. These findings advance bio-inspired locomotion understanding and aid energy-efficient underwater system design.",
    "published": "2025-12-01T02:57:02Z",
    "updated": "2025-12-01T02:57:02Z",
    "link": "http://arxiv.org/pdf/2512.01218v1.pdf",
    "category": [
      "physics.flu-dyn",
      "cs.AI",
      "cs.RO"
    ],
    "authors": [
      "Tao Li",
      "Chunze Zhang",
      "Weiwei Yao",
      "Junzhao He",
      "Ji Hou",
      "Qin Zhou",
      "Lu Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01214v1",
    "title": "M4-BLIP: Advancing Multi-Modal Media Manipulation Detection through Face-Enhanced Local Analysis",
    "summary": "In the contemporary digital landscape, multi-modal media manipulation has emerged as a significant societal threat, impacting the reliability and integrity of information dissemination. Current detection methodologies in this domain often overlook the crucial aspect of localized information, despite the fact that manipulations frequently occur in specific areas, particularly in facial regions. In response to this critical observation, we propose the M4-BLIP framework. This innovative framework utilizes the BLIP-2 model, renowned for its ability to extract local features, as the cornerstone for feature extraction. Complementing this, we incorporate local facial information as prior knowledge. A specially designed alignment and fusion module within M4-BLIP meticulously integrates these local and global features, creating a harmonious blend that enhances detection accuracy. Furthermore, our approach seamlessly integrates with Large Language Models (LLM), significantly improving the interpretability of the detection outcomes. Extensive quantitative and visualization experiments validate the effectiveness of our framework against the state-of-the-art competitors.",
    "published": "2025-12-01T02:54:03Z",
    "updated": "2025-12-01T02:54:03Z",
    "link": "http://arxiv.org/pdf/2512.01214v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Hang Wu",
      "Ke Sun",
      "Jiayi Ji",
      "Xiaoshuai Sun",
      "Rongrong Ji"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01210v1",
    "title": "Knowledge Graph Augmented Large Language Models for Next-Visit Disease Prediction",
    "summary": "Electronic health records (EHRs) support powerful clinical prediction models, but existing methods typically provide coarse, post hoc explanations that offer limited value for patient-level decision making. We introduce a knowledge graph (KG)-guided chain-of-thought (CoT) framework that generates clinically grounded and temporally consistent reasoning for visit-level disease prediction in MIMIC-III. ICD-9 codes are mapped to PrimeKG, from which disease-relevant nodes and multi-hop reasoning paths are extracted and used as scaffolds for CoT generation; only explanations whose conclusions match observed outcomes are retained. Lightweight LLaMA-3.1-Instruct-8B and Gemma-7B models are then fine-tuned on this supervision corpus. Across ten PrimeKG-mapped diseases and limited training cohorts (400 and 1000 cases), KG-guided models outperform strong classical baselines, achieving AUROC values of 0.66 to 0.70 and macro-AUPR values of 0.40 to 0.47. The models also transfer zero-shot to the CRADLE cohort, improving accuracy from approximately 0.40 to 0.51 up to 0.72 to 0.77. A blinded clinician evaluation shows consistent preference for KG-guided CoT explanations in clarity, relevance, and clinical correctness.",
    "published": "2025-12-01T02:49:17Z",
    "updated": "2025-12-01T02:49:17Z",
    "link": "http://arxiv.org/pdf/2512.01210v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Ruiyu Wang",
      "Tuan Vinh",
      "Ran Xu",
      "Yuyin Zhou",
      "Jiaying Lu",
      "Carl Yang",
      "Francisco Pasquel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01208v1",
    "title": "Pay Attention Later: From Vector Space Diffusion to Linearithmic Spectral Phase-Locking",
    "summary": "Standard Transformers suffer from a \"Semantic Alignment Tax\", a prohibitive optimization cost required to organize a chaotic initialization into a coherent geometric map via local gradient diffusion. We hypothesize that this reliance on diffusive learning creates \"Catastrophic Rigidity\", rendering models unable to adapt to novel concepts without destroying their pre-trained reasoning capabilities. To isolate this phenomenon, we introduce Iterative Semantic Map Refinement (ISMR), a diagnostic protocol revealing that alignment is a fixed geometric barrier that scaling cannot solve; a 20-layer model overcomes this barrier no faster than a 1-layer model. We introduce the Phase-Resonant Intelligent Spectral Model (PRISM). PRISM encodes semantic identity as resonant frequencies in the complex domain (C^d) and replaces quadratic self-attention with linearithmic O(N log N) Gated Harmonic Convolutions. We validate PRISM on the WMT14 translation task. While the Standard Transformer maintains a slight edge in general competence on static benchmarks (23.88 vs 21.40 BLEU), it fails the \"Plasticity-Stability\" stress test completely. When injected with novel concepts, the Transformer suffers Catastrophic Forgetting, degrading by -10.55 BLEU points while achieving only 60% acquisition. In contrast, PRISM demonstrates Lossless Plasticity, achieving 96% 5-shot acquisition with negligible degradation (-0.84 BLEU). These results suggest that harmonic representations effectively decouple memory from reasoning, offering a structural solution to the plasticity-stability dilemma in real-time knowledge adaptation.",
    "published": "2025-12-01T02:46:15Z",
    "updated": "2025-12-01T02:46:15Z",
    "link": "http://arxiv.org/pdf/2512.01208v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Alper Yıldırım",
      "İbrahim Yücedağ"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01207v1",
    "title": "Physics-Constrained Neural Dynamics: A Unified Manifold Framework for Large-Scale Power Flow Computation",
    "summary": "Power flow analysis is a fundamental tool for power system analysis, planning, and operational control. Traditional Newton-Raphson methods suffer from limitations such as initial value sensitivity and low efficiency in batch computation, while existing deep learning-based power flow solvers mostly rely on supervised learning, requiring pre-solving of numerous cases and struggling to guarantee physical consistency. This paper proposes a neural physics power flow solving method based on manifold geometry and gradient flow, by describing the power flow equations as a constraint manifold, and constructing an energy function \\(V(\\mathbf{x}) = \\frac{1}{2}\\|\\mathbf{F}(\\mathbf{x})\\|^2\\) and gradient flow \\(\\frac{d\\mathbf{x}}{dt} = -\\nabla V(\\mathbf{x})\\), transforming power flow solving into an equilibrium point finding problem for dynamical systems. Neural networks are trained in an unsupervised manner by directly minimizing physical residuals, requiring no labeled data, achieving true \"end-to-end\" physics-constrained learning.",
    "published": "2025-12-01T02:45:23Z",
    "updated": "2025-12-01T02:45:23Z",
    "link": "http://arxiv.org/pdf/2512.01207v1.pdf",
    "category": [
      "eess.SY",
      "cs.AI"
    ],
    "authors": [
      "Xuezhi Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.04652v6",
    "title": "LLM Collaboration With Multi-Agent Reinforcement Learning",
    "summary": "A large amount of work has been done in Multi-Agent Systems (MAS) for modeling and solving problems with multiple interacting agents. However, most LLMs are pretrained independently and not specifically optimized for coordination. Existing LLM fine-tuning frameworks rely on individual rewards, which require complex reward designs for each agent to encourage collaboration. To address these challenges, we model LLM collaboration as a cooperative Multi-Agent Reinforcement Learning (MARL) problem. We develop a multi-agent, multi-turn algorithm, Multi-Agent Group Relative Policy Optimization (MAGRPO), to solve it, building on current RL approaches for LLMs as well as MARL techniques. Our experiments on LLM writing and coding collaboration demonstrate that fine-tuning MAS with MAGRPO enables agents to generate high-quality responses efficiently through effective cooperation. Our approach opens the door to using other MARL methods for LLMs and highlights the associated challenges. Our code is available at https://github.com/OpenMLRL/CoMLRL.",
    "published": "2025-08-06T17:18:25Z",
    "updated": "2025-12-01T02:39:49Z",
    "link": "http://arxiv.org/pdf/2508.04652v6.pdf",
    "category": [
      "cs.AI",
      "cs.SE"
    ],
    "authors": [
      "Shuo Liu",
      "Tianle Chen",
      "Zeyu Liang",
      "Xueguang Lyu",
      "Christopher Amato"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.00452v3",
    "title": "Attention-Aided MMSE for OFDM Channel Estimation: Learning Linear Filters with Attention",
    "summary": "In orthogonal frequency division multiplexing (OFDM), accurate channel estimation is crucial. Classical signal processing based approaches, such as minimum mean-squared error (MMSE) estimation, often require second-order statistics that are difficult to obtain in practice. Recent deep neural networks based methods have been introduced to address this; yet they often suffer from high inference complexity. This paper proposes an Attention-aided MMSE (A-MMSE), a novel model-based DNN framework that learns the optimal MMSE filter via the Attention Transformer. Once trained, the A-MMSE estimates the channel through a single linear operation for channel estimation, eliminating nonlinear activations during inference and thus reducing computational complexity. To enhance the learning efficiency of the A-MMSE, we develop a two-stage Attention encoder, designed to effectively capture the channel correlation structure. Additionally, a rank-adaptive extension of the proposed A-MMSE allows flexible trade-offs between complexity and channel estimation accuracy. Extensive simulations with 3GPP TDL channel models demonstrate that the proposed A-MMSE consistently outperforms other baseline methods in terms of normalized MSE across a wide range of signal-to-noise ratio (SNR) conditions. In particular, the A-MMSE and its rank-adaptive extension establish a new frontier in the performance-complexity trade-off, providing a powerful yet highly efficient solution for practical channel estimation",
    "published": "2025-05-31T08:12:04Z",
    "updated": "2025-12-01T02:25:32Z",
    "link": "http://arxiv.org/pdf/2506.00452v3.pdf",
    "category": [
      "eess.SP",
      "cs.AI",
      "stat.ML"
    ],
    "authors": [
      "TaeJun Ha",
      "Chaehyun Jung",
      "Hyeonuk Kim",
      "Jeongwoo Park",
      "Jeonghun Park"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.24765v4",
    "title": "From Ambiguity to Verdict: A Semiotic-Grounded Multi-Perspective Agent for LLM Logical Reasoning",
    "summary": "Logical reasoning is a fundamental capability of large language models. However, existing studies often overlook the interaction between logical complexity and semantic complexity, leading to systems that struggle with abstract propositions, ambiguous contexts, and conflicting stances that are central to human reasoning. We propose LogicAgent, a semiotic-square-guided framework that jointly addresses these two axes of difficulty. The semiotic square provides a principled structure for multi-perspective semantic analysis, and LogicAgent integrates automated deduction with reflective verification to manage logical complexity across deeper reasoning chains. To support evaluation under these conditions, we introduce RepublicQA, a benchmark that couples semantic complexity with logical depth. RepublicQA reaches college-level semantic difficulty (FKGL 11.94), contains philosophically grounded abstract propositions with systematically constructed contrary and contradictory forms, and offers a semantically rich setting for assessing logical reasoning in large language models. Experiments show that LogicAgent achieves state-of-the-art performance on RepublicQA with a 6.25 percent average improvement over strong baselines, and generalizes effectively to mainstream logical reasoning benchmarks including ProntoQA, ProofWriter, FOLIO, and ProverQA, achieving an additional 7.05 percent average gain. These results demonstrate the effectiveness of semiotic-grounded multi-perspective reasoning in enhancing logical performance.",
    "published": "2025-09-29T13:31:22Z",
    "updated": "2025-12-01T02:24:15Z",
    "link": "http://arxiv.org/pdf/2509.24765v4.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Yunyao Zhang",
      "Xinglang Zhang",
      "Junxi Sheng",
      "Wenbing Li",
      "Junqing Yu",
      "Wei Yang",
      "Zikai Song"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01189v1",
    "title": "fMRI2GES: Co-speech Gesture Reconstruction from fMRI Signal with Dual Brain Decoding Alignment",
    "summary": "Understanding how the brain responds to external stimuli and decoding this process has been a significant challenge in neuroscience. While previous studies typically concentrated on brain-to-image and brain-to-language reconstruction, our work strives to reconstruct gestures associated with speech stimuli perceived by brain. Unfortunately, the lack of paired \\{brain, speech, gesture\\} data hinders the deployment of deep learning models for this purpose. In this paper, we introduce a novel approach, \\textbf{fMRI2GES}, that allows training of fMRI-to-gesture reconstruction networks on unpaired data using \\textbf{Dual Brain Decoding Alignment}. This method relies on two key components: (i) observed texts that elicit brain responses, and (ii) textual descriptions associated with the gestures. Then, instead of training models in a completely supervised manner to find a mapping relationship among the three modalities, we harness an fMRI-to-text model, a text-to-gesture model with paired data and an fMRI-to-gesture model with unpaired data, establishing dual fMRI-to-gesture reconstruction patterns. Afterward, we explicitly align two outputs and train our model in a self-supervision way. We show that our proposed method can reconstruct expressive gestures directly from fMRI recordings. We also investigate fMRI signals from different ROIs in the cortex and how they affect generation results. Overall, we provide new insights into decoding co-speech gestures, thereby advancing our understanding of neuroscience and cognitive science.",
    "published": "2025-12-01T02:09:44Z",
    "updated": "2025-12-01T02:09:44Z",
    "link": "http://arxiv.org/pdf/2512.01189v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Chunzheng Zhu",
      "Jialin Shao",
      "Jianxin Lin",
      "Yijun Wang",
      "Jing Wang",
      "Jinhui Tang",
      "Kenli Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.01196v2",
    "title": "An Interdisciplinary and Cross-Task Review on Missing Data Imputation",
    "summary": "Missing data is a fundamental challenge in data science, significantly hindering analysis and decision-making across a wide range of disciplines, including healthcare, bioinformatics, social science, e-commerce, and industrial monitoring. Despite decades of research and numerous imputation methods, the literature remains fragmented across fields, creating a critical need for a comprehensive synthesis that connects statistical foundations with modern machine learning advances. This work systematically reviews core concepts-including missingness mechanisms, single versus multiple imputation, and different imputation goals-and examines problem characteristics across various domains. It provides a thorough categorization of imputation methods, spanning classical techniques (e.g., regression, the EM algorithm) to modern approaches like low-rank and high-rank matrix completion, deep learning models (autoencoders, GANs, diffusion models, graph neural networks), and large language models. Special attention is given to methods for complex data types, such as tensors, time series, streaming data, graph-structured data, categorical data, and multimodal data. Beyond methodology, we investigate the crucial integration of imputation with downstream tasks like classification, clustering, and anomaly detection, examining both sequential pipelines and joint optimization frameworks. The review also assesses theoretical guarantees, benchmarking resources, and evaluation metrics. Finally, we identify critical challenges and future directions, emphasizing model selection and hyperparameter optimization, the growing importance of privacy-preserving imputation via federated learning, and the pursuit of generalizable models that can adapt across domains and data types, thereby outlining a roadmap for future research.",
    "published": "2025-11-03T03:43:43Z",
    "updated": "2025-12-01T02:05:28Z",
    "link": "http://arxiv.org/pdf/2511.01196v2.pdf",
    "category": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Jicong Fan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01188v1",
    "title": "Real-World Reinforcement Learning of Active Perception Behaviors",
    "summary": "A robot's instantaneous sensory observations do not always reveal task-relevant state information. Under such partial observability, optimal behavior typically involves explicitly acting to gain the missing information. Today's standard robot learning techniques struggle to produce such active perception behaviors. We propose a simple real-world robot learning recipe to efficiently train active perception policies. Our approach, asymmetric advantage weighted regression (AAWR), exploits access to \"privileged\" extra sensors at training time. The privileged sensors enable training high-quality privileged value functions that aid in estimating the advantage of the target policy. Bootstrapping from a small number of potentially suboptimal demonstrations and an easy-to-obtain coarse policy initialization, AAWR quickly acquires active perception behaviors and boosts task performance. In evaluations on 8 manipulation tasks on 3 robots spanning varying degrees of partial observability, AAWR synthesizes reliable active perception behaviors that outperform all prior approaches. When initialized with a \"generalist\" robot policy that struggles with active perception tasks, AAWR efficiently generates information-gathering behaviors that allow it to operate under severe partial observability for manipulation tasks. Website: https://penn-pal-lab.github.io/aawr/",
    "published": "2025-12-01T02:05:20Z",
    "updated": "2025-12-01T02:05:20Z",
    "link": "http://arxiv.org/pdf/2512.01188v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Edward S. Hu",
      "Jie Wang",
      "Xingfang Yuan",
      "Fiona Luo",
      "Muyao Li",
      "Gaspard Lambrechts",
      "Oleh Rybkin",
      "Dinesh Jayaraman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01187v1",
    "title": "Teaching by Failure: Counter-Example-Driven Curricula for Transformer Self-Improvement",
    "summary": "Transformer models often exhibit brittle extrapolation, failing on inputs that are longer or structurally more complex than those seen during training. We introduce Counter-Example-Driven Curricula (CEDC), an automated framework that improves model robustness by iteratively focusing on its own failures. At each step, CEDC uses the current model to generate a diverse set of candidate problems, employs a fast, executable verifier to identify incorrect predictions (counter-examples), and then fine-tunes the model on a dataset enriched with these discovered failures. We evaluate CEDC on a suite of algorithmic and natural language tasks, including integer addition, sorting, Dyck-2 language recognition, and three text classification benchmarks. Compared to static training and standard curriculum learning baselines, CEDC achieves up to 30x greater length extrapolation, is 3.75x more computationally efficient than uniform data augmentation, and requires no manual difficulty heuristics. We provide a detailed analysis of the counter-examples, showing how the curriculum naturally adapts to target progressively more complex error modes. Our findings establish verifier-guided, failure-driven learning as a simple, powerful, and efficient paradigm for enhancing the generalization capabilities of Transformer models.",
    "published": "2025-12-01T02:00:41Z",
    "updated": "2025-12-01T02:00:41Z",
    "link": "http://arxiv.org/pdf/2512.01187v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Harshil Vejendla"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.12934v3",
    "title": "The Anatomy of Alignment: Decomposing Preference Optimization by Steering Sparse Features",
    "summary": "Prevailing alignment methods induce opaque parameter changes, obscuring what models truly learn. To address this, we introduce Feature Steering with Reinforcement Learning (FSRL), a framework that trains a lightweight adapter to steer model behavior by modulating interpretable sparse features. First, we theoretically demonstrate that this mechanism is expressive enough to approximate the behavioral shifts of post-training processes. We then apply FSRL to preference optimization and perform a causal analysis of the learned policy. Our analysis reveals a crucial insight: the model learns to reward stylistic presentation as a proxy for quality, disproportionately relying on features related to style and formatting over those tied to alignment concepts like honesty. By effectively optimizing the preference objective, FSRL serves as a transparent proxy for observing the alignment process. Overall, FSRL offers an interpretable control interface and a practical way to diagnose how preference optimization pressures manifest at the feature level.",
    "published": "2025-09-16T10:32:40Z",
    "updated": "2025-12-01T01:57:33Z",
    "link": "http://arxiv.org/pdf/2509.12934v3.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Jeremias Ferrao",
      "Matthijs van der Lende",
      "Ilija Lichkovski",
      "Clement Neo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.04235v2",
    "title": "Shared Spatial Memory Through Predictive Coding",
    "summary": "Constructing a consistent shared spatial memory is a critical challenge in multi-agent systems, where partial observability and limited bandwidth often lead to catastrophic failures in coordination. We introduce a multi-agent predictive coding framework that formulates coordination as the minimization of mutual uncertainty among agents. Through an information bottleneck objective, this framework prompts agents to learn not only who and what to communicate but also when. At the foundation of this framework lies a grid-cell-like metric as internal spatial coding for self-localization, emerging spontaneously from self-supervised motion prediction. Building upon this internal spatial code, agents gradually develop a bandwidth-efficient communication mechanism and specialized neural populations that encode partners' locations-an artificial analogue of hippocampal social place cells (SPCs). These social representations are further utilized by a hierarchical reinforcement learning policy that actively explores to reduce joint uncertainty. On the Memory-Maze benchmark, our approach shows exceptional resilience to bandwidth constraints: success degrades gracefully from 73.5% to 64.4% as bandwidth shrinks from 128 to 4 bits/step, whereas a full-broadcast baseline collapses from 67.6% to 28.6%. Our findings establish a theoretically principled and biologically plausible basis for how complex social representations emerge from a unified predictive drive, leading to collective intelligence.",
    "published": "2025-11-06T10:12:46Z",
    "updated": "2025-12-01T01:50:27Z",
    "link": "http://arxiv.org/pdf/2511.04235v2.pdf",
    "category": [
      "cs.AI",
      "cs.CE"
    ],
    "authors": [
      "Zhengru Fang",
      "Yu Guo",
      "Jingjing Wang",
      "Yuang Zhang",
      "Haonan An",
      "Yinhai Wang",
      "Yuguang Fang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01183v1",
    "title": "TempPerturb-Eval: On the Joint Effects of Internal Temperature and External Perturbations in RAG Robustness",
    "summary": "The evaluation of Retrieval-Augmented Generation (RAG) systems typically examines retrieval quality and generation parameters like temperature in isolation, overlooking their interaction. This work presents a systematic investigation of how text perturbations (simulating noisy retrieval) interact with temperature settings across multiple LLM runs. We propose a comprehensive RAG Perturbation-Temperature Analysis Framework that subjects retrieved documents to three distinct perturbation types across varying temperature settings. Through extensive experiments on HotpotQA with both open-source and proprietary LLMs, we demonstrate that performance degradation follows distinct patterns: high-temperature settings consistently amplify vulnerability to perturbations, while certain perturbation types exhibit non-linear sensitivity across the temperature range. Our work yields three key contributions: (1) a diagnostic benchmark for assessing RAG robustness, (2) an analytical framework for quantifying perturbation-temperature interactions, and (3) practical guidelines for model selection and parameter tuning under noisy retrieval conditions.",
    "published": "2025-12-01T01:46:36Z",
    "updated": "2025-12-01T01:46:36Z",
    "link": "http://arxiv.org/pdf/2512.01183v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Yongxin Zhou",
      "Philippe Mulhem",
      "Didier Schwab"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01181v1",
    "title": "First On-Orbit Demonstration of a Geospatial Foundation Model",
    "summary": "Geospatial foundation models (GeoFMs) promise broad generalisation capacity for Earth observation (EO) tasks, particularly under data-limited conditions. However, their large size poses a barrier to deployment on resource-constrained space hardware. To address this, we present compact variants of a Vision Transformer (ViT)-based GeoFM that preserve downstream task performance while enabling onboard execution. Evaluation across five downstream tasks and validation in two representative flight environments show that model compression and domain adaptation are critical to reducing size and resource demands while maintaining high performance under operational conditions. We further demonstrate reliable on-orbit inference with the IMAGIN-e payload aboard the International Space Station. These results establish a pathway from large GeoFMs to flight-ready, resource-efficient deployments, expanding the feasibility of onboard AI for EO missions.",
    "published": "2025-12-01T01:43:03Z",
    "updated": "2025-12-01T01:43:03Z",
    "link": "http://arxiv.org/pdf/2512.01181v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Andrew Du",
      "Roberto Del Prete",
      "Alejandro Mousist",
      "Nick Manser",
      "Fabrice Marre",
      "Andrew Barton",
      "Carl Seubert",
      "Gabriele Meoni",
      "Tat-Jun Chin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.21775v2",
    "title": "Face-MakeUpV2: Facial Consistency Learning for Controllable Text-to-Image Generation",
    "summary": "In facial image generation, current text-to-image models often suffer from facial attribute leakage and insufficient physical consistency when responding to local semantic instructions. In this study, we propose Face-MakeUpV2, a facial image generation model that aims to maintain the consistency of face ID and physical characteristics with the reference image. First, we constructed a large-scale dataset FaceCaptionMask-1M comprising approximately one million image-text-masks pairs that provide precise spatial supervision for the local semantic instructions. Second, we employed a general text-to-image pretrained model as the backbone and introduced two complementary facial information injection channels: a 3D facial rendering channel to incorporate the physical characteristics of the image and a global facial feature channel. Third, we formulated two optimization objectives for the supervised learning of our model: semantic alignment in the model's embedding space to mitigate the attribute leakage problem and perceptual loss on facial images to preserve ID consistency. Extensive experiments demonstrated that our Face-MakeUpV2 achieves best overall performance in terms of preserving face ID and maintaining physical consistency of the reference images. These results highlight the practical potential of Face-MakeUpV2 for reliable and controllable facial editing in diverse applications.",
    "published": "2025-10-17T09:31:08Z",
    "updated": "2025-12-01T01:41:38Z",
    "link": "http://arxiv.org/pdf/2510.21775v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "authors": [
      "Dawei Dai",
      "Yinxiu Zhou",
      "Chenghang Li",
      "Guolai Jiang",
      "Chengfang Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01179v1",
    "title": "Toward a benchmark for CTR prediction in online advertising: datasets, evaluation protocols and perspectives",
    "summary": "This research designs a unified architecture of CTR prediction benchmark (Bench-CTR) platform that offers flexible interfaces with datasets and components of a wide range of CTR prediction models. Moreover, we construct a comprehensive system of evaluation protocols encompassing real-world and synthetic datasets, a taxonomy of metrics, standardized procedures and experimental guidelines for calibrating the performance of CTR prediction models. Furthermore, we implement the proposed benchmark platform and conduct a comparative study to evaluate a wide range of state-of-the-art models from traditional multivariate statistical to modern large language model (LLM)-based approaches on three public datasets and two synthetic datasets. Experimental results reveal that, (1) high-order models largely outperform low-order models, though such advantage varies in terms of metrics and on different datasets; (2) LLM-based models demonstrate a remarkable data efficiency, i.e., achieving the comparable performance to other models while using only 2% of the training data; (3) the performance of CTR prediction models has achieved significant improvements from 2015 to 2016, then reached a stage with slow progress, which is consistent across various datasets. This benchmark is expected to facilitate model development and evaluation and enhance practitioners' understanding of the underlying mechanisms of models in the area of CTR prediction. Code is available at https://github.com/NuriaNinja/Bench-CTR.",
    "published": "2025-12-01T01:36:55Z",
    "updated": "2025-12-01T01:36:55Z",
    "link": "http://arxiv.org/pdf/2512.01179v1.pdf",
    "category": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Shan Gao",
      "Yanwu Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.01317v2",
    "title": "T-SHIRT: Token-Selective Hierarchical Data Selection for Instruction Tuning",
    "summary": "Instruction tuning is essential for Large Language Models (LLMs) to effectively follow user instructions. To improve training efficiency and reduce data redundancy, recent works use LLM-based scoring functions, e.g., Instruction-Following Difficulty (IFD), to select high-quality instruction-tuning data with scores above a threshold. While these data selection methods often lead to models that can match or even exceed the performance of models trained on the full datasets, we identify two key limitations: (i) they assess quality at the sample level, ignoring token-level informativeness; and (ii) they overlook the robustness of the scoring method, often selecting a sample due to superficial lexical features instead of its true quality. In this work, we propose Token-Selective HIeRarchical Data Selection for Instruction Tuning (T-SHIRT), a novel data selection framework that introduces a new scoring method to include only informative tokens in quality evaluation and also promotes robust and reliable samples whose neighbors also show high quality with less local inconsistencies. We demonstrate that models instruction-tuned on a curated dataset (only 5% of the original size) using T-SHIRT can outperform those trained on the entire large-scale dataset by up to 5.48 points on average across eight benchmarks. Across various LLMs and training set scales, our method consistently surpasses existing state-of-the-art data selection techniques, while also remaining both cost-effective and highly efficient. For instance, by using GPT-2 for score computation, we are able to process a dataset of 52k samples in 40 minutes on a single GPU. Our code is available at https://github.com/Dynamite321/T-SHIRT.",
    "published": "2025-06-02T04:59:17Z",
    "updated": "2025-12-01T01:30:30Z",
    "link": "http://arxiv.org/pdf/2506.01317v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Yanjun Fu",
      "Faisal Hamman",
      "Sanghamitra Dutta"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.02716v2",
    "title": "A $1000\\times$ Faster LLM-enhanced Algorithm For Path Planning in Large-scale Grid Maps",
    "summary": "Path planning in grid maps, arising from various applications, has garnered significant attention. Existing methods, such as A*, Dijkstra, and their variants, work well for small-scale maps but fail to address large-scale ones due to high search time and memory consumption. Recently, Large Language Models (LLMs) have shown remarkable performance in path planning but still suffer from spatial illusion and poor planning performance. Among all the works, LLM-A* \\cite{meng2024llm} leverages LLM to generate a series of waypoints and then uses A* to plan the paths between the neighboring waypoints. In this way, the complete path is constructed. However, LLM-A* still suffers from high computational time for large-scale maps. To fill this gap, we conducted a deep investigation into LLM-A* and found its bottleneck, resulting in limited performance. Accordingly, we design an innovative LLM-enhanced algorithm, abbr. as iLLM-A*. iLLM-A* includes 3 carefully designed mechanisms, including the optimization of A*, an incremental learning method for LLM to generate high-quality waypoints, and the selection of the appropriate waypoints for A* for path planning. Finally, a comprehensive evaluation on various grid maps shows that, compared with LLM-A*, iLLM-A* \\textbf{1) achieves more than $1000\\times$ speedup on average, and up to $2349.5\\times$ speedup in the extreme case, 2) saves up to $58.6\\%$ of the memory cost, 3) achieves both obviously shorter path length and lower path length standard deviation.}",
    "published": "2025-10-03T04:33:45Z",
    "updated": "2025-12-01T01:28:06Z",
    "link": "http://arxiv.org/pdf/2510.02716v2.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Junlin Zeng",
      "Xin Zhang",
      "Xiang Zhao",
      "Yan Pan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01171v1",
    "title": "Conversion rate prediction in online advertising: modeling techniques, performance evaluation and future directions",
    "summary": "Conversion and conversion rate (CVR) prediction play a critical role in efficient advertising decision-making. In past decades, although researchers have developed plenty of models for CVR prediction, the methodological evolution and relationships between different techniques have been precluded. In this paper, we conduct a comprehensive literature review on CVR prediction in online advertising, and classify state-of-the-art CVR prediction models into six categories with respect to the underlying techniques and elaborate on connections between these techniques. For each category of models, we present the framework of underlying techniques, their advantages and disadvantages, and discuss how they are utilized for CVR prediction. Moreover, we summarize the performance of various CVR prediction models on public and proprietary datasets. Finally, we identify research trends, major challenges, and promising future directions. We observe that results of performance evaluation reported in prior studies are not unanimous; semantics-enriched, attribution-enhanced, debiased CVR prediction and jointly modeling CTR and CVR prediction would be promising directions to explore in the future. This review is expected to provide valuable references and insights for future researchers and practitioners in this area.",
    "published": "2025-12-01T01:02:35Z",
    "updated": "2025-12-01T01:02:35Z",
    "link": "http://arxiv.org/pdf/2512.01171v1.pdf",
    "category": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Tao Xue",
      "Yanwu Yang",
      "Panyu Zhai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01170v1",
    "title": "Data assimilation and discrepancy modeling with shallow recurrent decoders",
    "summary": "The requirements of modern sensing are rapidly evolving, driven by increasing demands for data efficiency, real-time processing, and deployment under limited sensing coverage. Complex physical systems are often characterized through the integration of a limited number of point sensors in combination with scientific computations which approximate the dominant, full-state dynamics. Simulation models, however, inevitably neglect small-scale or hidden processes, are sensitive to perturbations, or oversimplify parameter correlations, leading to reconstructions that often diverge from the reality measured by sensors. This creates a critical need for data assimilation, the process of integrating observational data with predictive simulation models to produce coherent and accurate estimates of the full state of complex physical systems. We propose a machine learning framework for Data Assimilation with a SHallow REcurrent Decoder (DA-SHRED) which bridges the simulation-to-real (SIM2REAL) gap between computational modeling and experimental sensor data. For real-world physics systems modeling high-dimensional spatiotemporal fields, where the full state cannot be directly observed and must be inferred from sparse sensor measurements, we leverage the latent space learned from a reduced simulation model via SHRED, and update these latent variables using real sensor data to accurately reconstruct the full system state. Furthermore, our algorithm incorporates a sparse identification of nonlinear dynamics based regression model in the latent space to identify functionals corresponding to missing dynamics in the simulation model. We demonstrate that DA-SHRED successfully closes the SIM2REAL gap and additionally recovers missing dynamics in highly complex systems, demonstrating that the combination of efficient temporal encoding and physics-informed correction enables robust data assimilation.",
    "published": "2025-12-01T01:01:48Z",
    "updated": "2025-12-01T01:01:48Z",
    "link": "http://arxiv.org/pdf/2512.01170v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "math.AP",
      "nlin.CD"
    ],
    "authors": [
      "Yuxuan Bao",
      "J. Nathan Kutz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01167v1",
    "title": "A TinyML Reinforcement Learning Approach for Energy-Efficient Light Control in Low-Cost Greenhouse Systems",
    "summary": "This study presents a reinforcement learning (RL)-based control strategy for adaptive lighting regulation in controlled environments using a low-power microcontroller. A model-free Q-learning algorithm was implemented to dynamically adjust the brightness of a Light-Emitting Diode (LED) based on real-time feedback from a light-dependent resistor (LDR) sensor. The system was trained to stabilize at 13 distinct light intensity levels (L1 to L13), with each target corresponding to a specific range within the 64-state space derived from LDR readings. A total of 130 trials were conducted, covering all target levels with 10 episodes each. Performance was evaluated in terms of convergence speed, steps taken, and time required to reach target states. Box plots and histograms were generated to analyze the distribution of training time and learning efficiency across targets. Experimental validation demonstrated that the agent could effectively learn to stabilize at varying light levels with minimal overshooting and smooth convergence, even in the presence of environmental perturbations. This work highlights the feasibility of lightweight, on-device RL for energy-efficient lighting control and sets the groundwork for multi-modal environmental control applications in resource-constrained agricultural systems.",
    "published": "2025-12-01T00:58:05Z",
    "updated": "2025-12-01T00:58:05Z",
    "link": "http://arxiv.org/pdf/2512.01167v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "eess.SY"
    ],
    "authors": [
      "Mohamed Abdallah Salem",
      "Manuel Cuevas Perez",
      "Ahmed Harb Rabia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01165v1",
    "title": "Real-Time On-the-Go Annotation Framework Using YOLO for Automated Dataset Generation",
    "summary": "Efficient and accurate annotation of datasets remains a significant challenge for deploying object detection models such as You Only Look Once (YOLO) in real-world applications, particularly in agriculture where rapid decision-making is critical. Traditional annotation techniques are labor-intensive, requiring extensive manual labeling post data collection. This paper presents a novel real-time annotation approach leveraging YOLO models deployed on edge devices, enabling immediate labeling during image capture. To comprehensively evaluate the efficiency and accuracy of our proposed system, we conducted an extensive comparative analysis using three prominent YOLO architectures (YOLOv5, YOLOv8, YOLOv12) under various configurations: single-class versus multi-class annotation and pretrained versus scratch-based training. Our analysis includes detailed statistical tests and learning dynamics, demonstrating significant advantages of pretrained and single-class configurations in terms of model convergence, performance, and robustness. Results strongly validate the feasibility and effectiveness of our real-time annotation framework, highlighting its capability to drastically reduce dataset preparation time while maintaining high annotation quality.",
    "published": "2025-12-01T00:54:57Z",
    "updated": "2025-12-01T00:54:57Z",
    "link": "http://arxiv.org/pdf/2512.01165v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "authors": [
      "Mohamed Abdallah Salem",
      "Ahmed Harb Rabia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01163v1",
    "title": "2D-ThermAl: Physics-Informed Framework for Thermal Analysis of Circuits using Generative AI",
    "summary": "Thermal analysis is increasingly critical in modern integrated circuits, where non-uniform power dissipation and high transistor densities can cause rapid temperature spikes and reliability concerns. Traditional methods, such as FEM-based simulations offer high accuracy but computationally prohibitive for early-stage design, often requiring multiple iterative redesign cycles to resolve late-stage thermal failures. To address these challenges, we propose 'ThermAl', a physics-informed generative AI framework which effectively identifies heat sources and estimates full-chip transient and steady-state thermal distributions directly from input activity profiles. ThermAl employs a hybrid U-Net architecture enhanced with positional encoding and a Boltzmann regularizer to maintain physical fidelity. Our model is trained on an extensive dataset of heat dissipation maps, ranging from simple logic gates (e.g., inverters, NAND, XOR) to complex designs, generated via COMSOL. Experimental results demonstrate that ThermAl delivers precise temperature mappings for large circuits, with a root mean squared error (RMSE) of only 0.71°C, and outperforms conventional FEM tools by running up to ~200 times faster. We analyze performance across diverse layouts and workloads, and discuss its applicability to large-scale EDA workflows. While thermal reliability assessments often extend beyond 85°C for post-layout signoff, our focus here is on early-stage hotspot detection and thermal pattern learning. To ensure generalization beyond the nominal operating range 25-55°C, we additionally performed cross-validation on an extended dataset spanning 25-95°C maintaining a high accuracy (<2.2% full-scale RMSE) even under elevated temperature conditions representative of peak power and stress scenarios.",
    "published": "2025-12-01T00:45:26Z",
    "updated": "2025-12-01T00:45:26Z",
    "link": "http://arxiv.org/pdf/2512.01163v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Soumyadeep Chandra",
      "Sayeed Shafayet Chowdhury",
      "Kaushik Roy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01155v1",
    "title": "Beyond Greenfield: AI-Driven Productivity in Documentation and Brownfield Engineering",
    "summary": "Brownfield engineering work involving legacy systems, incomplete documentation, and fragmented architectural knowledge poses unique challenges for the effective use of large language models (LLMs). Prior research has largely focused on greenfield or synthetic tasks, leaving a gap in structured workflows for complex, context-heavy environments. This paper introduces the Discover-Define-Deliver (D3) Framework, a disciplined LLM-assisted workflow that combines role-separated prompting strategies with applied best practices for navigating ambiguity in brownfield systems. The framework incorporates a dual-agent prompting architecture in which a Builder model generates candidate outputs and a Reviewer model provides structured critique to improve reliability. I conducted an exploratory survey study with 52 software practitioners who applied the D3 workflow to real-world engineering tasks such as legacy system exploration, documentation reconstruction, and architectural refactoring. Respondents reported perceived improvements in task clarity, documentation quality, and cognitive load, along with self-estimated productivity gains. In this exploratory study, participants reported a weighted average productivity improvement of 26.9%, reduced cognitive load for approximately 77% of participants, and reduced rework for 83% during the Define phase. As these findings are self-reported and not derived from controlled experiments, they should be interpreted as preliminary evidence of practitioner sentiment rather than causal effects. The results highlight both the potential and limitations of structured LLM workflows for legacy engineering systems and motivate future controlled evaluations.",
    "published": "2025-12-01T00:26:41Z",
    "updated": "2025-12-01T00:26:41Z",
    "link": "http://arxiv.org/pdf/2512.01155v1.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Krishna Kumaar Sharma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.18449v2",
    "title": "SWE-RL: Advancing LLM Reasoning via Reinforcement Learning on Open Software Evolution",
    "summary": "The recent DeepSeek-R1 release has demonstrated the immense potential of reinforcement learning (RL) in enhancing the general reasoning capabilities of large language models (LLMs). While DeepSeek-R1 and other follow-up work primarily focus on applying RL to competitive coding and math problems, this paper introduces SWE-RL, the first approach to scale RL-based LLM reasoning for real-world software engineering. Leveraging a lightweight rule-based reward (e.g., the similarity score between ground-truth and LLM-generated solutions), SWE-RL enables LLMs to autonomously recover a developer's reasoning processes and solutions by learning from extensive open-source software evolution data -- the record of a software's entire lifecycle, including its code snapshots, code changes, and events such as issues and pull requests. Trained on top of Llama 3, our resulting reasoning model, Llama3-SWE-RL-70B, achieves a 41.0% solve rate on SWE-bench Verified -- a human-verified collection of real-world GitHub issues. To our knowledge, this is the best performance reported for medium-sized (<100B) LLMs to date, even comparable to leading proprietary LLMs like GPT-4o. Surprisingly, despite performing RL solely on software evolution data, Llama3-SWE-RL has even emerged with generalized reasoning skills. For example, it shows improved results on five out-of-domain tasks, namely, function coding, library use, code reasoning, mathematics, and general language understanding, whereas a supervised-finetuning baseline even leads to performance degradation on average. Overall, SWE-RL opens up a new direction to improve the reasoning capabilities of LLMs through reinforcement learning on massive software engineering data.",
    "published": "2025-02-25T18:45:04Z",
    "updated": "2025-12-01T00:16:59Z",
    "link": "http://arxiv.org/pdf/2502.18449v2.pdf",
    "category": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Yuxiang Wei",
      "Olivier Duchenne",
      "Jade Copet",
      "Quentin Carbonneaux",
      "Lingming Zhang",
      "Daniel Fried",
      "Gabriel Synnaeve",
      "Rishabh Singh",
      "Sida I. Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01153v1",
    "title": "DPAC: Distribution-Preserving Adversarial Control for Diffusion Sampling",
    "summary": "Adversarially guided diffusion sampling often achieves the target class, but sample quality degrades as deviations between the adversarially controlled and nominal trajectories accumulate. We formalize this degradation as a path-space Kullback-Leibler divergence(path-KL) between controlled and nominal (uncontrolled) diffusion processes, thereby showing via Girsanov's theorem that it exactly equals the control energy. Building on this stochastic optimal control (SOC) view, we theoretically establish that minimizing this path-KL simultaneously tightens upper bounds on both the 2-Wasserstein distance and Fréchet Inception Distance (FID), revealing a principled connection between adversarial control energy and perceptual fidelity. From a variational perspective, we derive a first-order optimality condition for the control: among all directions that yield the same classification gain, the component tangent to iso-(log-)density surfaces (i.e., orthogonal to the score) minimizes path-KL, whereas the normal component directly increases distributional drift. This leads to DPAC (Distribution-Preserving Adversarial Control), a diffusion guidance rule that projects adversarial gradients onto the tangent space defined by the generative score geometry. We further show that in discrete solvers, the tangent projection cancels the O(Δt) leading error term in the Wasserstein distance, achieving an O(Δt^2) quality gap; moreover, it remains second-order robust to score or metric approximation. Empirical studies on ImageNet-100 validate the theoretical predictions, confirming that DPAC achieves lower FID and estimated path-KL at matched attack success rates.",
    "published": "2025-12-01T00:15:05Z",
    "updated": "2025-12-01T00:15:05Z",
    "link": "http://arxiv.org/pdf/2512.01153v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Han-Jin Lee",
      "Han-Ju Lee",
      "Jin-Seong Kim",
      "Seok-Hwan Choi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01152v1",
    "title": "Open-Set Domain Adaptation Under Background Distribution Shift: Challenges and A Provably Efficient Solution",
    "summary": "As we deploy machine learning systems in the real world, a core challenge is to maintain a model that is performant even as the data shifts. Such shifts can take many forms: new classes may emerge that were absent during training, a problem known as open-set recognition, and the distribution of known categories may change. Guarantees on open-set recognition are mostly derived under the assumption that the distribution of known classes, which we call \\emph{the background distribution}, is fixed. In this paper we develop \\ours{}, a method that is guaranteed to solve open-set recognition even in the challenging case where the background distribution shifts. We prove that the method works under benign assumptions that the novel class is separable from the non-novel classes, and provide theoretical guarantees that it outperforms a representative baseline in a simplified overparameterized setting. We develop techniques to make \\ours{} scalable and robust, and perform comprehensive empirical evaluations on image and text data. The results show that \\ours{} significantly outperforms existing open-set recognition methods under background shift. Moreover, we provide new insights into how factors such as the size of the novel class influences performance, an aspect that has not been extensively explored in prior work.",
    "published": "2025-12-01T00:08:18Z",
    "updated": "2025-12-01T00:08:18Z",
    "link": "http://arxiv.org/pdf/2512.01152v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Shravan Chaudhari",
      "Yoav Wald",
      "Suchi Saria"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.17354v4",
    "title": "Multi-Scenario Highway Lane-Change Intention Prediction: A Physics-Informed AI Framework for Three-Class Classification",
    "summary": "Lane-change maneuvers are a leading cause of highway accidents, underscoring the need for accurate intention prediction to improve the safety and decision-making of autonomous driving systems. While prior studies using machine learning and deep learning methods (e.g., SVM, CNN, LSTM, Transformers) have shown promise, most approaches remain limited by binary classification, lack of scenario diversity, and degraded performance under longer prediction horizons. In this study, we propose a physics-informed AI framework that explicitly integrates vehicle kinematics, interaction feasibility, and traffic-safety metrics (e.g., distance headway, time headway, time-to-collision, closing gap time) into the learning process. lane-change prediction is formulated as a three-class problem that distinguishes left change, right change, and no change, and is evaluated across both straight highway segments (highD) and complex ramp scenarios (exiD). By integrating vehicle kinematics with interaction features, our machine learning models, particularly LightGBM, achieve state-of-the-art accuracy and strong generalization. Results show up to 99.8% accuracy and 93.6% macro F1 on highD, and 96.1% accuracy and 88.7% macro F1 on exiD at a 1-second horizon, outperforming a two-layer stacked LSTM baseline. These findings demonstrate the practical advantages of a physics-informed and feature-rich machine learning framework for real-time lane-change intention prediction in autonomous driving systems.",
    "published": "2025-09-22T05:17:54Z",
    "updated": "2025-12-01T00:05:46Z",
    "link": "http://arxiv.org/pdf/2509.17354v4.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Jiazhao Shi",
      "Yichen Lin",
      "Yiheng Hua",
      "Ziyu Wang",
      "Zijian Zhang",
      "Wenjia Zheng",
      "Yun Song",
      "Kuan Lu",
      "Shoufeng Lu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01149v1",
    "title": "A Benchmark of Causal vs Correlation AI for Predictive Maintenance",
    "summary": "Predictive maintenance in manufacturing environments presents a challenging optimization problem characterized by extreme cost asymmetry, where missed failures incur costs roughly fifty times higher than false alarms. Conventional machine learning approaches typically optimize statistical accuracy metrics that do not reflect this operational reality and cannot reliably distinguish causal relationships from spurious correlations. This study evaluates eight predictive models, ranging from baseline statistical approaches to formal causal inference methods, on a dataset of 10,000 CNC machines with a 3.3% failure prevalence. The formal causal inference model (L5) achieved estimated annual cost savings of 1.16 million USD (a 70.2 percent reduction), outperforming the best correlation-based decision tree model (L3) by approximately 80,000 USD per year. The causal model matched the highest observed recall (87.9 percent) while reducing false alarms by 97 percent (from 165 to 5) and attained a precision of 92.1 percent, with a train-test performance gap of only 2.6 percentage points. These results indicate that causal AI methods, when combined with domain knowledge, can yield superior financial outcomes and more interpretable predictions compared to correlation-based approaches in predictive maintenance applications.",
    "published": "2025-11-30T23:59:37Z",
    "updated": "2025-11-30T23:59:37Z",
    "link": "http://arxiv.org/pdf/2512.01149v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Krishna Taduri",
      "Shaunak Dhande",
      "Giacinto Paolo",
      " Saggese",
      "Paul Smith"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.06981v2",
    "title": "Deep RL Needs Deep Behavior Analysis: Exploring Implicit Planning by Model-Free Agents in Open-Ended Environments",
    "summary": "Understanding the behavior of deep reinforcement learning (DRL) agents -particularly as task and agent sophistication increase- requires more than simple comparison of reward curves, yet standard methods for behavioral analysis remain underdeveloped in DRL. We apply tools from neuroscience and ethology to study DRL agents in a novel, complex, partially observable environment, ForageWorld, designed to capture key aspects of real-world animal foraging- including sparse, depleting resource patches, predator threats, and spatially extended arenas. We use this environment as a platform for applying joint behavioral and neural analysis to agents, revealing detailed, quantitatively grounded insights into agent strategies, memory, and planning. Contrary to common assumptions, we find that model-free RNN-based DRL agents can exhibit structured, planning-like behavior purely through emergent dynamics- without requiring explicit memory modules or world models. Our results show that studying DRL agents like animals -analyzing them with neuroethology-inspired tools that reveal structure in both behavior and neural dynamics- uncovers rich structure in their learning dynamics that would otherwise remain invisible. We distill these tools into a general analysis framework linking core behavioral and representational features to diagnostic methods, which can be reused for a wide range of tasks and agents. As agents grow more complex and autonomous, bridging neuroscience, cognitive science, and AI will be essential- not just for understanding their behavior, but for ensuring safe alignment and maximizing desirable behaviors that are hard to measure via reward. We show how this can be done by drawing on lessons from how biological intelligence is studied.",
    "published": "2025-06-08T03:43:48Z",
    "updated": "2025-11-30T23:57:15Z",
    "link": "http://arxiv.org/pdf/2506.06981v2.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Riley Simmons-Edler",
      "Ryan P. Badman",
      "Felix Baastad Berg",
      "Raymond Chua",
      "John J. Vastola",
      "Joshua Lunger",
      "William Qian",
      "Kanaka Rajan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01148v1",
    "title": "SocialFusion: Addressing Social Degradation in Pre-trained Vision-Language Models",
    "summary": "Understanding social interactions from visual cues is a fundamental challenge for a socially competent AI. While powerful pre-trained vision-language models (VLMs) have shown remarkable general capabilities, they surprisingly struggle to unify and learn multiple social perception tasks simultaneously, often exhibiting negative transfer. We identify that this negative transfer stems from a critical issue we term \"social degradation,\" whereby the general visual-linguistic pre-training process of VLMs impairs the visual encoder's ability to represent nuanced social information. We investigate this behavior further under two lenses: decodability through linear representation probing and compatibility through gradient conflict analysis, revealing that both play a role in the degradation, especially the former, which is significantly compromised in the VLM pre-training process. To address these issues, we propose SocialFusion, a unified framework that learns a minimal connection between a frozen visual encoder and a language model. Compared with existing VLMs, it exhibits positive transfer across all five social tasks, leveraging synergies between them to enhance overall performance and achieves comparable performance to task-specific state-of-the-art models on various benchmarks. Our findings suggest that current VLM pre-training strategies may be detrimental to acquiring general social competence and highlight the need for more socially-aware training paradigms.",
    "published": "2025-11-30T23:54:54Z",
    "updated": "2025-11-30T23:54:54Z",
    "link": "http://arxiv.org/pdf/2512.01148v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Hamza Tahboub",
      "Weiyan Shi",
      "Gang Hua",
      "Huaizu Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.27680v2",
    "title": "PETAR: Localized Findings Generation with Mask-Aware Vision-Language Modeling for PET Automated Reporting",
    "summary": "Generating automated reports for 3D positron emission tomography (PET) is an important and challenging task in medical imaging. PET plays a vital role in oncology, but automating report generation is difficult due to the complexity of whole-body 3D volumes, the wide range of potential clinical findings, and the limited availability of annotated datasets. To address these challenges, we introduce PETARSeg-11K, the first large-scale, publicly available dataset that provides lesion-level correspondence between 3D PET/CT volumes and free-text radiological findings. It comprises 11,356 lesion descriptions paired with 3D segmentations. Second, we propose PETAR-4B, a 3D vision-language model designed for mask-aware, spatially grounded PET/CT reporting. PETAR-4B jointly encodes PET, CT, and 3D lesion segmentation masks, using a 3D focal prompt to capture fine-grained details of lesions that normally comprise less than 0.1% of the volume. Evaluations using automated metrics show PETAR-4B substantially outperforming all 2D and 3D baselines. A human study involving five physicians -- the first of its kind for automated PET reporting -- confirms the model's clinical utility and establishes correlations between automated metrics and expert judgment. This work provides a foundational dataset and a novel architecture, advancing 3D medical vision-language understanding in PET.",
    "published": "2025-10-31T17:49:01Z",
    "updated": "2025-11-30T23:13:14Z",
    "link": "http://arxiv.org/pdf/2510.27680v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Danyal Maqbool",
      "Changhee Lee",
      "Zachary Huemann",
      "Samuel D. Church",
      "Matthew E. Larson",
      "Scott B. Perlman",
      "Tomas A. Romero",
      "Joshua D. Warner",
      "Meghan Lubner",
      "Xin Tie",
      "Jameson Merkow",
      "Junjie Hu",
      "Steve Y. Cho",
      "Tyler J. Bradshaw"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01127v1",
    "title": "Mode-Conditioning Unlocks Superior Test-Time Scaling",
    "summary": "Parallel sampling promises substantial gains in test-time scaling, but its effectiveness is sharply limited by diversity collapse, where models concentrate on a few modes and repeated samples produce the same mistakes. We propose the mode-conditioning (ModC) framework, which explicitly allocates test-time compute across reasoning modes using either specialist models or mode-specific prefixes. ModC consistently improves scaling across controlled graph-search tasks and large-scale reasoning benchmarks, spanning model families and sizes from 0.5B to 7B. On OpenThoughts, fine-tuning Qwen2.5-7B with ModC achieves a 4x efficiency gain over standard training while also improving the maximum attainable Pass@k. We further show that gradient clustering enables ModC without explicit mode labels, yielding up to 10% gains on datasets such as NuminaMath. Finally, we show that ModC improves reinforcement learning (RL) and can further boost diversity-inducing RL methods. These results demonstrate that standard training underutilizes the diversity in data, and that ModC provides a simple, effective remedy for unlocking the full benefits of diversity in test-time scaling.",
    "published": "2025-11-30T22:36:20Z",
    "updated": "2025-11-30T22:36:20Z",
    "link": "http://arxiv.org/pdf/2512.01127v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Chen Henry Wu",
      "Sachin Goyal",
      "Aditi Raghunathan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01119v1",
    "title": "World Model Robustness via Surprise Recognition",
    "summary": "AI systems deployed in the real world must contend with distractions and out-of-distribution (OOD) noise that can destabilize their policies and lead to unsafe behavior. While robust training can reduce sensitivity to some forms of noise, it is infeasible to anticipate all possible OOD conditions. To mitigate this issue, we develop an algorithm that leverages a world model's inherent measure of surprise to reduce the impact of noise in world model--based reinforcement learning agents. We introduce both multi-representation and single-representation rejection sampling, enabling robustness to settings with multiple faulty sensors or a single faulty sensor. While the introduction of noise typically degrades agent performance, we show that our techniques preserve performance relative to baselines under varying types and levels of noise across multiple environments within self-driving simulation domains (CARLA and Safety Gymnasium). Furthermore, we demonstrate that our methods enhance the stability of two state-of-the-art world models with markedly different underlying architectures: Cosmos and DreamerV3. Together, these results highlight the robustness of our approach across world modeling domains. We release our code at https://github.com/Bluefin-Tuna/WISER .",
    "published": "2025-11-30T22:25:45Z",
    "updated": "2025-11-30T22:25:45Z",
    "link": "http://arxiv.org/pdf/2512.01119v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Geigh Zollicoffer",
      "Tanush Chopra",
      "Mingkuan Yan",
      "Xiaoxu Ma",
      "Kenneth Eaton",
      "Mark Riedl"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01113v1",
    "title": "Efficiently Learning Branching Networks for Multitask Algorithmic Reasoning",
    "summary": "Algorithmic reasoning -- the ability to perform step-by-step logical inference -- has become a core benchmark for evaluating reasoning in graph neural networks (GNNs) and large language models (LLMs). Ideally, one would like to design a single model capable of performing well on multiple algorithmic reasoning tasks simultaneously. However, this is challenging when the execution steps of algorithms differ from one another, causing negative interference when they are trained together.\n  We propose branching neural networks, a principled architecture for multitask algorithmic reasoning. Searching for the optimal $k$-ary tree with $L$ layers over $n$ algorithmic tasks is combinatorial, requiring exploration of up to $k^{nL}$ possible structures. We develop AutoBRANE, an efficient algorithm that reduces this search to $O(nL)$ time by solving a convex relaxation at each layer to approximate an optimal task partition. The method clusters tasks using gradient-based affinity scores and can be used on top of any base model, including GNNs and LLMs.\n  We validate AutoBRANE on a broad suite of graph-algorithmic and text-based reasoning benchmarks. We show that gradient features estimate true task performance within 5% error across four GNNs and four LLMs (up to 34B parameters). On the CLRS benchmark, it outperforms the strongest single multitask GNN by 3.7% and the best baseline by 1.2%, while reducing runtime by 48% and memory usage by 26%. The learned branching structures reveal an intuitively reasonable hierarchical clustering of related algorithms. On three text-based graph reasoning benchmarks, AutoBRANE improves over the best non-branching multitask baseline by 3.2%. Finally, on a large graph dataset with 21M edges and 500 tasks, AutoBRANE achieves a 28% accuracy gain over existing multitask and branching architectures, along with a 4.5$\\times$ reduction in runtime.",
    "published": "2025-11-30T22:19:55Z",
    "updated": "2025-11-30T22:19:55Z",
    "link": "http://arxiv.org/pdf/2512.01113v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.DS"
    ],
    "authors": [
      "Dongyue Li",
      "Zhenshuo Zhang",
      "Minxuan Duan",
      "Edgar Dobriban",
      "Hongyang R. Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.26899v3",
    "title": "How Similar Are Grokipedia and Wikipedia? A Multi-Dimensional Textual and Structural Comparison",
    "summary": "The launch of Grokipedia - an AI-generated encyclopedia developed by Elon Musk's xAI - was presented as a response to perceived ideological and structural biases in Wikipedia, aiming to produce \"truthful\" entries using the Grok large language model. Yet whether an AI-driven alternative can escape the biases and limitations of human-edited platforms remains unclear. This study conducts a large-scale computational comparison of more than 17,000 matched article pairs from the 20,000 most-edited English Wikipedia pages. Using metrics spanning lexical richness, readability, reference density, structural features, and semantic similarity, we assess how closely the two platforms align in form and substance. We find that Grokipedia articles are substantially longer and contain significantly fewer references per word. Moreover, Grokipedia's content divides into two distinct groups: one that remains semantically and stylistically aligned with Wikipedia, and another that diverges sharply. Among the dissimilar articles, we observe a systematic rightward shift in the political bias of cited news sources, concentrated primarily in entries related to politics, history, and religion. These findings suggest that AI-generated encyclopedic content diverges from established editorial norms-favouring narrative expansion over citation-based verification. The implications highlight emerging tensions around transparency, provenance, and the governance of knowledge in an era of automated text generation.",
    "published": "2025-10-30T18:04:46Z",
    "updated": "2025-11-30T22:10:18Z",
    "link": "http://arxiv.org/pdf/2510.26899v3.pdf",
    "category": [
      "cs.CY",
      "cs.AI",
      "cs.SI"
    ],
    "authors": [
      "Taha Yasseri",
      "Saeedeh Mohammadi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01107v1",
    "title": "Foundation Priors",
    "summary": "Foundation models, and in particular large language models, can generate highly informative responses, prompting growing interest in using these ''synthetic'' outputs as data in empirical research and decision-making. This paper introduces the idea of a foundation prior, which shows that model-generated outputs are not as real observations, but draws from the foundation prior induced prior predictive distribution. As such synthetic data reflects both the model's learned patterns and the user's subjective priors, expectations, and biases. We model the subjectivity of the generative process by making explicit the dependence of synthetic outputs on the user's anticipated data distribution, the prompt-engineering process, and the trust placed in the foundation model.\n  We derive the foundation prior as an exponential-tilted, generalized Bayesian update of the user's primitive prior, where a trust parameter governs the weight assigned to synthetic data. We then show how synthetic data and the associated foundation prior can be incorporated into standard statistical and econometric workflows, and discuss their use in applications such as refining complex models, informing latent constructs, guiding experimental design, and augmenting random-coefficient and partially linear specifications. By treating generative outputs as structured, explicitly subjective priors rather than as empirical observations, the framework offers a principled way to harness foundation models in empirical work while avoiding the conflation of synthetic ''facts'' with real data.",
    "published": "2025-11-30T22:09:37Z",
    "updated": "2025-11-30T22:09:37Z",
    "link": "http://arxiv.org/pdf/2512.01107v1.pdf",
    "category": [
      "cs.AI",
      "econ.EM",
      "stat.ML"
    ],
    "authors": [
      "Sanjog Misra"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01105v1",
    "title": "Supporting Productivity Skill Development in College Students through Social Robot Coaching: A Proof-of-Concept",
    "summary": "College students often face academic challenges that hamper their productivity and well-being. Although self-help books and productivity apps are popular, they often fall short. Books provide generalized, non-interactive guidance, and apps are not inherently educational and can hinder the development of key organizational skills. Traditional productivity coaching offers personalized support, but is resource-intensive and difficult to scale. In this study, we present a proof-of-concept for a socially assistive robot (SAR) as an educational coach and a potential solution to the limitations of existing productivity tools and coaching approaches. The SAR delivers six different lessons on time management and task prioritization. Users interact via a chat interface, while the SAR responds through speech (with a toggle option). An integrated dashboard monitors progress, mood, engagement, confidence per lesson, and time spent per lesson. It also offers personalized productivity insights to foster reflection and self-awareness. We evaluated the system with 15 college students, achieving a System Usability Score of 79.2 and high ratings for overall experience and engagement. Our findings suggest that SAR-based productivity coaching can offer an effective and scalable solution to improve productivity among college students.",
    "published": "2025-11-30T22:08:02Z",
    "updated": "2025-11-30T22:08:02Z",
    "link": "http://arxiv.org/pdf/2512.01105v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "authors": [
      "Himanshi Lalwani",
      "Hanan Salam"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01099v1",
    "title": "Energy-Aware Data-Driven Model Selection in LLM-Orchestrated AI Systems",
    "summary": "As modern artificial intelligence (AI) systems become more advanced and capable, they can leverage a wide range of tools and models to perform complex tasks. Today, the task of orchestrating these models is often performed by Large Language Models (LLMs) that rely on qualitative descriptions of models for decision-making. However, the descriptions provided to these LLM-based orchestrators do not reflect true model capabilities and performance characteristics, leading to suboptimal model selection, reduced accuracy, and increased energy costs. In this paper, we conduct an empirical analysis of LLM-based orchestration limitations and propose GUIDE, a new energy-aware model selection framework that accounts for performance-energy trade-offs by incorporating quantitative model performance characteristics in decision-making. Experimental results demonstrate that GUIDE increases accuracy by 0.90%-11.92% across various evaluated tasks, and achieves up to 54% energy efficiency improvement, while reducing orchestrator model selection latency from 4.51 s to 7.2 ms.",
    "published": "2025-11-30T21:46:54Z",
    "updated": "2025-11-30T21:46:54Z",
    "link": "http://arxiv.org/pdf/2512.01099v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Daria Smirnova",
      "Hamid Nasiri",
      "Marta Adamska",
      "Zhengxin Yu",
      "Peter Garraghan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.04826v2",
    "title": "Persistent Instability in LLM's Personality Measurements: Effects of Scale, Reasoning, and Conversation History",
    "summary": "Large language models require consistent behavioral patterns for safe deployment, yet there are indications of large variability that may lead to an instable expression of personality traits in these models. We present PERSIST (PERsonality Stability in Synthetic Text), a comprehensive evaluation framework testing 25 open-source models (1B-685B parameters) across 2 million+ responses. Using traditional (BFI, SD3) and novel LLM-adapted personality questionnaires, we systematically vary model size, personas, reasoning modes, question order or paraphrasing, and conversation history. Our findings challenge fundamental assumptions: (1) Question reordering alone can introduce large shifts in personality measurements; (2) Scaling provides limited stability gains: even 400B+ models exhibit standard deviations >0.3 on 5-point scales; (3) Interventions expected to stabilize behavior, such as reasoning and inclusion of conversation history, can paradoxically increase variability; (4) Detailed persona instructions produce mixed effects, with misaligned personas showing significantly higher variability than the helpful assistant baseline; (5) The LLM-adapted questionnaires, despite their improved ecological validity, exhibit instability comparable to human-centric versions. This persistent instability across scales and mitigation strategies suggests that current LLMs lack the architectural foundations for genuine behavioral consistency. For safety-critical applications requiring predictable behavior, these findings indicate that current alignment strategies may be inadequate.",
    "published": "2025-08-06T19:11:33Z",
    "updated": "2025-11-30T21:46:02Z",
    "link": "http://arxiv.org/pdf/2508.04826v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Tommaso Tosato",
      "Saskia Helbling",
      "Yorguin-Jose Mantilla-Ramos",
      "Mahmood Hegazy",
      "Alberto Tosato",
      "David John Lemay",
      "Irina Rish",
      "Guillaume Dumas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01097v1",
    "title": "Discriminative classification with generative features: bridging Naive Bayes and logistic regression",
    "summary": "We introduce Smart Bayes, a new classification framework that bridges generative and discriminative modeling by integrating likelihood-ratio-based generative features into a logistic-regression-style discriminative classifier. From the generative perspective, Smart Bayes relaxes the fixed unit weights of Naive Bayes by allowing data-driven coefficients on density-ratio features. From a discriminative perspective, it constructs transformed inputs as marginal log-density ratios that explicitly quantify how much more likely each feature value is under one class than another, thereby providing predictors with stronger class separation than the raw covariates. To support this framework, we develop a spline-based estimator for univariate log-density ratios that is flexible, robust, and computationally efficient. Through extensive simulations and real-data studies, Smart Bayes often outperforms both logistic regression and Naive Bayes. Our results highlight the potential of hybrid approaches that exploit generative structure to enhance discriminative performance.",
    "published": "2025-11-30T21:34:24Z",
    "updated": "2025-11-30T21:34:24Z",
    "link": "http://arxiv.org/pdf/2512.01097v1.pdf",
    "category": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "stat.CO",
      "stat.ME"
    ],
    "authors": [
      "Zachary Terner",
      "Alexander Petersen",
      "Yuedong Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01095v1",
    "title": "CycliST: A Video Language Model Benchmark for Reasoning on Cyclical State Transitions",
    "summary": "We present CycliST, a novel benchmark dataset designed to evaluate Video Language Models (VLM) on their ability for textual reasoning over cyclical state transitions. CycliST captures fundamental aspects of real-world processes by generating synthetic, richly structured video sequences featuring periodic patterns in object motion and visual attributes. CycliST employs a tiered evaluation system that progressively increases difficulty through variations in the number of cyclic objects, scene clutter, and lighting conditions, challenging state-of-the-art models on their spatio-temporal cognition. We conduct extensive experiments with current state-of-the-art VLMs, both open-source and proprietary, and reveal their limitations in generalizing to cyclical dynamics such as linear and orbital motion, as well as time-dependent changes in visual attributes like color and scale. Our results demonstrate that present-day VLMs struggle to reliably detect and exploit cyclic patterns, lack a notion of temporal understanding, and are unable to extract quantitative insights from scenes, such as the number of objects in motion, highlighting a significant technical gap that needs to be addressed. More specifically, we find no single model consistently leads in performance: neither size nor architecture correlates strongly with outcomes, and no model succeeds equally well across all tasks. By providing a targeted challenge and a comprehensive evaluation framework, CycliST paves the way for visual reasoning models that surpass the state-of-the-art in understanding periodic patterns.",
    "published": "2025-11-30T21:28:41Z",
    "updated": "2025-11-30T21:28:41Z",
    "link": "http://arxiv.org/pdf/2512.01095v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Simon Kohaut",
      "Daniel Ochs",
      "Shun Zhang",
      "Benedict Flade",
      "Julian Eggert",
      "Kristian Kersting",
      "Devendra Singh Dhami"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01089v1",
    "title": "CodeDistiller: Automatically Generating Code Libraries for Scientific Coding Agents",
    "summary": "Automated Scientific Discovery (ASD) systems can help automatically generate and run code-based experiments, but their capabilities are limited by the code they can reliably generate from parametric knowledge alone. As a result, current systems either mutate a small number of manually-crafted experiment examples, or operate solely from parametric knowledge, limiting quality and reach. We introduce CodeDistiller, a system that automatically distills large collections of scientific Github repositories into a vetted library of working domain-specific code examples, allowing ASD agents to expand their capabilities without manual effort. Using a combination of automatic and domain-expert evaluation on 250 materials science repositories, we find the best model is capable of producing functional examples for 74% of repositories, while our downstream evaluation shows an ASD agent augmented with a CodeDistiller generated library produces more accurate, complete, and scientifically sound experiments than an agent with only general materials-science code examples.",
    "published": "2025-11-30T21:19:10Z",
    "updated": "2025-11-30T21:19:10Z",
    "link": "http://arxiv.org/pdf/2512.01089v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Peter Jansen",
      "Samiah Hassan",
      "Pragnya Narasimha"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2309.15039v3",
    "title": "Can-SAVE: Deploying Low-Cost and Population-Scale Cancer Screening via Survival Analysis Variables and EHR",
    "summary": "Conventional medical cancer screening methods are costly, labor-intensive, and extremely difficult to scale. Although AI can improve cancer detection, most systems rely on complex or specialized medical data, making them impractical for large-scale screening. We introduce Can-SAVE, a lightweight AI system that ranks population-wide cancer risks solely based on medical history events. By integrating survival model outputs into a gradient-boosting framework, our approach detects subtle, long-term patient risk patterns - often well before clinical symptoms manifest. Can-SAVE was rigorously evaluated on a real-world dataset of 2.5 million adults spanning five Russian regions, marking the study as one of the largest and most comprehensive deployments of AI-driven cancer risk assessment. In a retrospective oncologist-supervised study over 1.9M patients, Can-SAVE achieves a 4-10x higher detection rate at identical screening volumes and an Average Precision (AP) of 0.228 vs. 0.193 for the best baseline (LoRA-tuned Qwen3-Embeddings via DeepSeek-R1 summarization). In a year-long prospective pilot (426K patients), our method almost doubled the cancer detection rate (+91%) and increased population coverage by 36% over the national screening protocol. The system demonstrates practical scalability: a city-wide population of 1 million patients can be processed in under three hours using standard hardware, enabling seamless clinical integration. This work proves that Can-SAVE achieves nationally significant cancer detection improvements while adhering to real-world public healthcare constraints, offering immediate clinical utility and a replicable framework for population-wide screening. Code for training and feature engineering is available at https://github.com/sb-ai-lab/Can-SAVE.",
    "published": "2023-09-26T16:15:54Z",
    "updated": "2025-11-30T21:08:22Z",
    "link": "http://arxiv.org/pdf/2309.15039v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "stat.AP"
    ],
    "authors": [
      "Petr Philonenko",
      "Vladimir Kokh",
      "Pavel Blinov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01081v1",
    "title": "Testing the Machine Consciousness Hypothesis",
    "summary": "The Machine Consciousness Hypothesis states that consciousness is a substrate-free functional property of computational systems capable of second-order perception. I propose a research program to investigate this idea in silico by studying how collective self-models (coherent, self-referential representations) emerge from distributed learning systems embedded within universal self-organizing environments. The theory outlined here starts from the supposition that consciousness is an emergent property of collective intelligence systems undergoing synchronization of prediction through communication. It is not an epiphenomenon of individual modeling but a property of the language that a system evolves to internally describe itself. For a model of base reality, I begin with a minimal but general computational world: a cellular automaton, which exhibits both computational irreducibility and local reducibility. On top of this computational substrate, I introduce a network of local, predictive, representational (neural) models capable of communication and adaptation. I use this layered model to study how collective intelligence gives rise to self-representation as a direct consequence of inter-agent alignment. I suggest that consciousness does not emerge from modeling per se, but from communication. It arises from the noisy, lossy exchange of predictive messages between groups of local observers describing persistent patterns in the underlying computational substrate (base reality). It is through this representational dialogue that a shared model arises, aligning many partial views of the world. The broader goal is to develop empirically testable theories of machine consciousness, by studying how internal self-models may form in distributed systems without centralized control.",
    "published": "2025-11-30T21:05:48Z",
    "updated": "2025-11-30T21:05:48Z",
    "link": "http://arxiv.org/pdf/2512.01081v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MA",
      "cs.NE",
      "q-bio.NC"
    ],
    "authors": [
      "Stephen Fitz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.03194v2",
    "title": "Quantifying Cognitive Bias Induction in LLM-Generated Content",
    "summary": "Large language models (LLMs) are integrated into applications like shopping reviews, summarization, or medical diagnosis support, where their use affects human decisions. We investigate the extent to which LLMs expose users to biased content and demonstrate its effect on human decision-making. We assess five LLM families in summarization and news fact-checking tasks, evaluating the consistency of LLMs with their context and their tendency to hallucinate on a new self-updating dataset. Our findings show that LLMs expose users to content that changes the context's sentiment in 26.42% of cases (framing bias), hallucinate on 60.33% of post-knowledge-cutoff questions, and highlight context from earlier parts of the prompt (primacy bias) in 10.12% of cases, averaged across all tested models. We further find that humans are 32% more likely to purchase the same product after reading a summary of the review generated by an LLM rather than the original review. To address these issues, we evaluate 18 mitigation methods across three LLM families and find the effectiveness of targeted interventions.",
    "published": "2025-07-03T21:56:44Z",
    "updated": "2025-11-30T21:03:11Z",
    "link": "http://arxiv.org/pdf/2507.03194v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Abeer Alessa",
      "Param Somane",
      "Akshaya Lakshminarasimhan",
      "Julian Skirzynski",
      "Julian McAuley",
      "Jessica Echterhoff"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01078v1",
    "title": "SimWorld: An Open-ended Realistic Simulator for Autonomous Agents in Physical and Social Worlds",
    "summary": "While LLM/VLM-powered AI agents have advanced rapidly in math, coding, and computer use, their applications in complex physical and social environments remain challenging. Building agents that can survive and thrive in the real world (for example, by autonomously earning income or running a business) requires massive-scale interaction, reasoning, training, and evaluation across diverse embodied scenarios. However, existing world simulators for such development fall short: they often rely on limited hand-crafted environments, simulate simplified game-like physics and social rules, and lack native support for LLM/VLM agents. We introduce SimWorld, a new simulator built on Unreal Engine 5, designed for developing and evaluating LLM/VLM agents in rich, real-world-like settings. SimWorld offers three core capabilities: (1) realistic, open-ended world simulation, including accurate physical and social dynamics and language-driven procedural environment generation; (2) a rich interface for LLM/VLM agents, with multimodal world inputs and open-vocabulary actions at varying levels of abstraction; and (3) diverse and extensible physical and social reasoning scenarios that are easily customizable by users. We demonstrate SimWorld by deploying frontier LLM agents (e.g., GPT-4o, Gemini-2.5-Flash, Claude-3.5, and DeepSeek-Prover-V2) on long-horizon multi-agent delivery tasks involving strategic cooperation and competition. The results reveal distinct reasoning patterns and limitations across models. We open-source SimWorld and hope it becomes a foundational platform for advancing real-world agent intelligence across disciplines: https://simworld.org.",
    "published": "2025-11-30T20:58:13Z",
    "updated": "2025-11-30T20:58:13Z",
    "link": "http://arxiv.org/pdf/2512.01078v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Jiawei Ren",
      "Yan Zhuang",
      "Xiaokang Ye",
      "Lingjun Mao",
      "Xuhong He",
      "Jianzhi Shen",
      "Mrinaal Dogra",
      "Yiming Liang",
      "Ruixuan Zhang",
      "Tianai Yue",
      "Yiqing Yang",
      "Eric Liu",
      "Ryan Wu",
      "Kevin Benavente",
      "Rajiv Mandya Nagaraju",
      "Muhammad Faayez",
      "Xiyan Zhang",
      "Dhruv Vivek Sharma",
      "Xianrui Zhong",
      "Ziqiao Ma",
      "Tianmin Shu",
      "Zhiting Hu",
      "Lianhui Qin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01067v1",
    "title": "On The Finetuning of MLIPs Through the Lens of Iterated Maps With BPTT",
    "summary": "Vital to the creation of advanced materials is performing structural relaxations. Traditional approaches built on physics-derived first-principles calculations are computationally expensive, motivating the creation of machine-learning interatomic potentials (MLIPs). Traditional approaches to training MLIPs for structural relaxations involves training models to faithfully reproduce first-principles computed forces. We propose a fine-tuning method to be used on a pretrained MLIP in which we create a fully-differentiable end-to-end simulation loop that optimizes the predicted final structures directly. Trajectories are unrolled and gradients are tracked through the entire relaxation. We show that this method achieves substantial performance gains when applied to pretrained models, leading to a nearly $50\\%$ reduction in test error across the sample datasets. Interestingly, we show the process is robust to substantial variation in the relaxation setup, achieving negligibly different results across varied hyperparameter and procedural modifications. Experimental results indicate this is due to a ``preference'' of BPTT to modify the MLIP rather than the other trainable parameters. Of particular interest to practitioners is that this approach lowers the data requirements for producing an effective domain-specific MLIP, addressing a common bottleneck in practical deployment.",
    "published": "2025-11-30T20:34:37Z",
    "updated": "2025-11-30T20:34:37Z",
    "link": "http://arxiv.org/pdf/2512.01067v1.pdf",
    "category": [
      "cond-mat.mtrl-sci",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Evan Dramko",
      "Yizhi Zhu",
      "Aleksandar Krivokapic",
      "Geoffroy Hautier",
      "Thomas Reps",
      "Christopher Jermaine",
      "Anastasios Kyrillidis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01062v1",
    "title": "PIANO: Physics-informed Dual Neural Operator for Precipitation Nowcasting",
    "summary": "Precipitation nowcasting, key for early warning of disasters, currently relies on computationally expensive and restrictive methods that limit access to many countries. To overcome this challenge, we propose precipitation nowcasting using satellite imagery with physics constraints for improved accuracy and physical consistency. We use a novel physics-informed dual neural operator (PIANO) structure to enforce the fundamental equation of advection-diffusion during training to predict satellite imagery using a PINN loss. Then, we use a generative model to convert satellite images to radar images, which are used for precipitation nowcasting. Compared to baseline models, our proposed model shows a notable improvement in moderate (4mm/h) precipitation event prediction alongside short-term heavy (8mm/h) precipitation event prediction. It also demonstrates low seasonal variability in predictions, indicating robustness for generalization. This study suggests the potential of the PIANO and serves as a good baseline for physics-informed precipitation nowcasting.",
    "published": "2025-11-30T20:17:14Z",
    "updated": "2025-11-30T20:17:14Z",
    "link": "http://arxiv.org/pdf/2512.01062v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Seokhyun Chin",
      "Junghwan Park",
      "Woojin Cho"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.00557v2",
    "title": "Blind Inverse Problem Solving Made Easy by Text-to-Image Latent Diffusion",
    "summary": "This paper considers blind inverse image restoration, the task of predicting a target image from a degraded source when the degradation (i.e. the forward operator) is unknown. Existing solutions typically rely on restrictive assumptions such as operator linearity, curated training data or narrow image distributions limiting their practicality. We introduce LADiBI, a training-free method leveraging large-scale text-to-image diffusion to solve diverse blind inverse problems with minimal assumptions. Within a Bayesian framework, LADiBI uses text prompts to jointly encode priors for both target images and operators, unlocking unprecedented flexibility compared to existing methods. Additionally, we propose a novel diffusion posterior sampling algorithm that combines strategic operator initialization with iterative refinement of image and operator parameters, eliminating the need for highly constrained operator forms. Experiments show that LADiBI effectively handles both linear and challenging nonlinear image restoration problems across various image distributions, all without task-specific assumptions or retraining.",
    "published": "2024-11-30T18:55:01Z",
    "updated": "2025-11-30T20:09:09Z",
    "link": "http://arxiv.org/pdf/2412.00557v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Michail Dontas",
      "Yutong He",
      "Naoki Murata",
      "Yuki Mitsufuji",
      "J. Zico Kolter",
      "Ruslan Salakhutdinov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.07338v3",
    "title": "DeepPersona: A Generative Engine for Scaling Deep Synthetic Personas",
    "summary": "Simulating human profiles by instilling personas into large language models (LLMs) is rapidly transforming research in agentic behavioral simulation, LLM personalization, and human-AI alignment. However, most existing synthetic personas remain shallow and simplistic, capturing minimal attributes and failing to reflect the rich complexity and diversity of real human identities. We introduce DEEPPERSONA, a scalable generative engine for synthesizing narrative-complete synthetic personas through a two-stage, taxonomy-guided method. First, we algorithmically construct the largest-ever human-attribute taxonomy, comprising over hundreds of hierarchically organized attributes, by mining thousands of real user-ChatGPT conversations. Second, we progressively sample attributes from this taxonomy, conditionally generating coherent and realistic personas that average hundreds of structured attributes and roughly 1 MB of narrative text, two orders of magnitude deeper than prior works. Intrinsic evaluations confirm significant improvements in attribute diversity (32 percent higher coverage) and profile uniqueness (44 percent greater) compared to state-of-the-art baselines. Extrinsically, our personas enhance GPT-4.1-mini's personalized question answering accuracy by 11.6 percent on average across ten metrics and substantially narrow (by 31.7 percent) the gap between simulated LLM citizens and authentic human responses in social surveys. Our generated national citizens reduced the performance gap on the Big Five personality test by 17 percent relative to LLM-simulated citizens. DEEPPERSONA thus provides a rigorous, scalable, and privacy-free platform for high-fidelity human simulation and personalized AI research.",
    "published": "2025-11-10T17:37:56Z",
    "updated": "2025-11-30T20:05:16Z",
    "link": "http://arxiv.org/pdf/2511.07338v3.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Zhen Wang",
      "Yufan Zhou",
      "Zhongyan Luo",
      "Lyumanshan Ye",
      "Adam Wood",
      "Man Yao",
      "Saab Mansour",
      "Luoshang Pan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01059v1",
    "title": "Parameter Reduction Improves Vision Transformers: A Comparative Study of Sharing and Width Reduction",
    "summary": "Although scaling laws and many empirical results suggest that increasing the size of Vision Transformers often improves performance, model accuracy and training behavior are not always monotonically increasing with scale. Focusing on ViT-B/16 trained on ImageNet-1K, we study two simple parameter-reduction strategies applied to the MLP blocks, each removing 32.7\\% of the baseline parameters. Our \\emph{GroupedMLP} variant shares MLP weights between adjacent transformer blocks and achieves 81.47\\% top-1 accuracy while maintaining the baseline computational cost. Our \\emph{ShallowMLP} variant halves the MLP hidden dimension and reaches 81.25\\% top-1 accuracy with a 38\\% increase in inference throughput. Both models outperform the 86.6M-parameter baseline (81.05\\%) and exhibit substantially improved training stability, reducing peak-to-final accuracy degradation from 0.47\\% to the range 0.03\\% to 0.06\\%. These results suggest that, for ViT-B/16 on ImageNet-1K with a standard training recipe, the model operates in an overparameterized regime in which MLP capacity can be reduced without harming performance and can even slightly improve it. More broadly, our findings suggest that architectural constraints such as parameter sharing and reduced width may act as useful inductive biases, and highlight the importance of how parameters are allocated when designing Vision Transformers. All code is available at: https://github.com/AnanthaPadmanaban-KrishnaKumar/parameter-efficient-vit-mlps.",
    "published": "2025-11-30T20:04:30Z",
    "updated": "2025-11-30T20:04:30Z",
    "link": "http://arxiv.org/pdf/2512.01059v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Anantha Padmanaban Krishna Kumar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23907v2",
    "title": "DynaStride: Dynamic Stride Windowing with MMCoT for Instructional Multi-Scene Captioning",
    "summary": "Scene-level captioning in instructional videos can enhance learning by requiring an understanding of both visual cues and temporal structure. By aligning visual cues with textual guidance, this understanding supports procedural learning and multimodal reasoning, providing a richer context for skill acquisition. However, captions that fail to capture this structure may lack coherence and quality, which can create confusion and undermine the video's educational intent. To address this gap, we introduce DynaStride, a pipeline to generate coherent, scene-level captions without requiring manual scene segmentation. Using the YouCookII dataset's scene annotations, DynaStride performs adaptive frame sampling and multimodal windowing to capture key transitions within each scene. It then employs a multimodal chain-of-thought process to produce multiple action-object pairs, which are refined and fused using a dynamic stride window selection algorithm that adaptively balances temporal context and redundancy. The final scene-level caption integrates visual semantics and temporal reasoning in a single instructional caption. Empirical evaluations against strong baselines, including VLLaMA3 and GPT-4o, demonstrate consistent gains on both N-gram-based metrics (BLEU, METEOR) and semantic similarity measures (BERTScore, CLIPScore). Qualitative analyses further show that DynaStride produces captions that are more temporally coherent and informative, suggesting a promising direction for improving AI-powered instructional content generation.",
    "published": "2025-10-27T22:29:08Z",
    "updated": "2025-11-30T19:59:16Z",
    "link": "http://arxiv.org/pdf/2510.23907v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Eddison Pham",
      "Prisha Priyadarshini",
      "Adrian Maliackel",
      "Kanishk Bandi",
      "Cristian Meo",
      "Kevin Zhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01054v1",
    "title": "Adaptive-lambda Subtracted Importance Sampled Scores in Machine Unlearning for DDPMs and VAEs",
    "summary": "Machine Unlearning is essential for large generative models (VAEs, DDPMs) to comply with the right to be forgotten and prevent undesired content generation without costly retraining. Existing approaches, such as Static-lambda SISS for diffusion models, rely on a fixed mixing weight lambda, which is suboptimal because the required unlearning strength varies across samples and training stages.\n  We propose Adaptive-lambda SISS, a principled extension that turns lambda into a latent variable dynamically inferred at each training step. A lightweight inference network parameterizes an adaptive posterior over lambda, conditioned on contextual features derived from the instantaneous SISS loss terms (retain/forget losses and their gradients). This enables joint optimization of the diffusion model and the lambda-inference mechanism via a variational objective, yielding significantly better trade-offs.\n  We further extend the adaptive-lambda principle to score-based unlearning and introduce a multi-class variant of Score Forgetting Distillation. In addition, we present two new directions: (i) a hybrid objective combining the data-free efficiency of Score Forgetting Distillation with the direct gradient control of SISS, and (ii) a Reinforcement Learning formulation that treats unlearning as a sequential decision process, learning an optimal policy over a state space defined by the model's current memory of the forget set.\n  Experiments on an augmented MNIST benchmark show that Adaptive-lambda SISS substantially outperforms the original static-lambda SISS, achieving stronger removal of forgotten classes while better preserving generation quality on the retain set.",
    "published": "2025-11-30T19:57:49Z",
    "updated": "2025-11-30T19:57:49Z",
    "link": "http://arxiv.org/pdf/2512.01054v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "MohammadParsa Dini",
      "Human Jafari",
      "Sajjad Amini",
      "MohammadMahdi Mojahedian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12240v2",
    "title": "SCI: A Metacognitive Control for Signal Dynamics",
    "summary": "Modern deep learning systems are typically deployed as open-loop function approximators: they map inputs to outputs in a single pass, without regulating how much computation or explanatory effort is spent on a given case. In safety-critical settings, this is brittle: easy and ambiguous inputs receive identical processing, and uncertainty is only read off retrospectively from raw probabilities. We introduce the Surgical Cognitive Interpreter (SCI), a lightweight closed-loop metacognitive control layer that wraps an existing stochastic model and turns prediction into an iterative process. SCI monitors a scalar interpretive state SP(t), here instantiated as a normalized entropy-based confidence signal, and adaptively decides whether to stop, continue sampling, or abstain. The goal is not to improve accuracy per se, but to regulate interpretive error ΔSP and expose a safety signal that tracks when the underlying model is likely to fail. We instantiate SCI around Monte Carlo dropout classifiers in three domains: vision (MNIST digits), medical time series (MIT-BIH arrhythmia), and industrial condition monitoring (rolling-element bearings). In all cases, the controller allocates more inference steps to misclassified inputs than to correct ones (up to about 3-4x on MNIST and bearings, and 1.4x on MIT-BIH). The resulting ΔSP acts as a usable safety signal for detecting misclassifications (AUROC 0.63 on MNIST, 0.70 on MIT-BIH, 0.86 on bearings). Code and reproducibility: https://github.com/vishal-1344/sci",
    "published": "2025-11-15T14:48:17Z",
    "updated": "2025-11-30T19:55:53Z",
    "link": "http://arxiv.org/pdf/2511.12240v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "eess.SY"
    ],
    "authors": [
      "Vishal Joshua Meesala"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.19523v3",
    "title": "Localized Conformal Multi-Quantile Regression",
    "summary": "Standard conformal prediction methods guarantee marginal coverage but often produce inefficient intervals that fail to adapt to local heteroscedasticity, while recent localized approaches often struggle to maintain validity across distinct subpopulations with varying noise profiles. To address these challenges, we introduce Localized Conformal Multi-Quantile Regression (LCMQR), a novel framework that synergizes multi-quantile information with kernel-based localization to construct efficient and adaptive prediction intervals. Theoretically, we resolve an inconsistency in Conformalized Composite Quantile Regression (CCQR) by proving that our consistent Average-then-Max scoring mechanism systematically yields tighter intervals than the Max-then-Average approach used in prior work. For heterogeneous environments, we extend this framework to Group-Calibrated LCMQR (GC-LCMQR) via a stratified calibration step that guarantees finite-sample validity within distinct subgroups. Experiments on benchmark datasets and an Individual Treatment Effect (ITE) task demonstrate that LCMQR achieves superior efficiency on standard benchmarks, while GC-LCMQR uniquely achieves group-level coverage for target subgroups in mixture populations where baselines fail.",
    "published": "2024-11-29T07:41:20Z",
    "updated": "2025-11-30T19:49:57Z",
    "link": "http://arxiv.org/pdf/2411.19523v3.pdf",
    "category": [
      "stat.ME",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Yuan Lu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01047v1",
    "title": "Automating the Refinement of Reinforcement Learning Specifications",
    "summary": "Logical specifications have been shown to help reinforcement learning algorithms in achieving complex tasks. However, when a task is under-specified, agents might fail to learn useful policies. In this work, we explore the possibility of improving coarse-grained logical specifications via an exploration-guided strategy. We propose \\textsc{AutoSpec}, a framework that searches for a logical specification refinement whose satisfaction implies satisfaction of the original specification, but which provides additional guidance therefore making it easier for reinforcement learning algorithms to learn useful policies. \\textsc{AutoSpec} is applicable to reinforcement learning tasks specified via the SpectRL specification logic. We exploit the compositional nature of specifications written in SpectRL, and design four refinement procedures that modify the abstract graph of the specification by either refining its existing edge specifications or by introducing new edge specifications. We prove that all four procedures maintain specification soundness, i.e. any trajectory satisfying the refined specification also satisfies the original. We then show how \\textsc{AutoSpec} can be integrated with existing reinforcement learning algorithms for learning policies from logical specifications. Our experiments demonstrate that \\textsc{AutoSpec} yields promising improvements in terms of the complexity of control tasks that can be solved, when refined logical specifications produced by \\textsc{AutoSpec} are utilized.",
    "published": "2025-11-30T19:32:33Z",
    "updated": "2025-11-30T19:32:33Z",
    "link": "http://arxiv.org/pdf/2512.01047v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Tanmay Ambadkar",
      "Đorđe Žikelić",
      "Abhinav Verma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01046v1",
    "title": "Shielded Controller Units for RL with Operational Constraints Applied to Remote Microgrids",
    "summary": "Reinforcement learning (RL) is a powerful framework for optimizing decision-making in complex systems under uncertainty, an essential challenge in real-world settings, particularly in the context of the energy transition. A representative example is remote microgrids that supply power to communities disconnected from the main grid. Enabling the energy transition in such systems requires coordinated control of renewable sources like wind turbines, alongside fuel generators and batteries, to meet demand while minimizing fuel consumption and battery degradation under exogenous and intermittent load and wind conditions. These systems must often conform to extensive regulations and complex operational constraints. To ensure that RL agents respect these constraints, it is crucial to provide interpretable guarantees. In this paper, we introduce Shielded Controller Units (SCUs), a systematic and interpretable approach that leverages prior knowledge of system dynamics to ensure constraint satisfaction. Our shield synthesis methodology, designed for real-world deployment, decomposes the environment into a hierarchical structure where each SCU explicitly manages a subset of constraints. We demonstrate the effectiveness of SCUs on a remote microgrid optimization task with strict operational requirements. The RL agent, equipped with SCUs, achieves a 24% reduction in fuel consumption without increasing battery degradation, outperforming other baselines while satisfying all constraints. We hope SCUs contribute to the safe application of RL to the many decision-making challenges linked to the energy transition.",
    "published": "2025-11-30T19:28:34Z",
    "updated": "2025-11-30T19:28:34Z",
    "link": "http://arxiv.org/pdf/2512.01046v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Hadi Nekoei",
      "Alexandre Blondin Massé",
      "Rachid Hassani",
      "Sarath Chandar",
      "Vincent Mai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01045v1",
    "title": "Med-CRAFT: Automated Construction of Interpretable and Multi-Hop Video Workloads via Knowledge Graph Traversal",
    "summary": "The scarcity of high-quality, logically annotated video datasets remains a primary bottleneck in advancing Multi-Modal Large Language Models (MLLMs) for the medical domain. Traditional manual annotation is prohibitively expensive and non-scalable, while existing synthetic methods often suffer from stochastic hallucinations and a lack of logical interpretability. To address these challenges, we introduce \\textbf{\\PipelineName}, a novel neuro-symbolic data engineering framework that formalizes benchmark synthesis as a deterministic graph traversal process. Unlike black-box generative approaches, Med-CRAFT extracts structured visual primitives (e.g., surgical instruments, anatomical boundaries) from raw video streams and instantiates them into a dynamic Spatiotemporal Knowledge Graph. By anchoring query generation to valid paths within this graph, we enforce a rigorous Chain-of-Thought (CoT) provenance for every synthesized benchmark item. We instantiate this pipeline to produce M3-Med-Auto, a large-scale medical video reasoning benchmark exhibiting fine-grained temporal selectivity and multi-hop logical complexity. Comprehensive evaluations demonstrate that our automated pipeline generates query workloads with complexity comparable to expert-curated datasets. Furthermore, a logic alignment analysis reveals a high correlation between the prescribed graph topology and the reasoning steps of state-of-the-art MLLMs, validating the system's capability to encode verifiable logic into visual-linguistic benchmarks. This work paves the way for scalable, low-cost construction of robust evaluation protocols in critical domains.",
    "published": "2025-11-30T19:24:10Z",
    "updated": "2025-11-30T19:24:10Z",
    "link": "http://arxiv.org/pdf/2512.01045v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Shenxi Liu",
      "Kan Li",
      "Mingyang Zhao",
      "Yuhang Tian",
      "Shoujun Zhou",
      "Bin Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01038v1",
    "title": "FMTK: A Modular Toolkit for Composable Time Series Foundation Model Pipelines",
    "summary": "Foundation models (FMs) have opened new avenues for machine learning applications due to their ability to adapt to new and unseen tasks with minimal or no further training. Time-series foundation models (TSFMs) -- FMs trained on time-series data -- have shown strong performance on classification, regression, and imputation tasks. Recent pipelines combine TSFMs with task-specific encoders, decoders, and adapters to improve performance; however, assembling such pipelines typically requires ad hoc, model-specific implementations that hinder modularity and reproducibility. We introduce FMTK, an open-source, lightweight and extensible toolkit for constructing and fine-tuning TSFM pipelines via standardized backbone and component abstractions. FMTK enables flexible composition across models and tasks, achieving correctness and performance with an average of seven lines of code. https://github.com/umassos/FMTK",
    "published": "2025-11-30T19:14:04Z",
    "updated": "2025-11-30T19:14:04Z",
    "link": "http://arxiv.org/pdf/2512.01038v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Hetvi Shastri",
      "Pragya Sharma",
      "Walid A. Hanafy",
      "Mani Srivastava",
      "Prashant Shenoy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.04398v2",
    "title": "SECA: Semantically Equivalent and Coherent Attacks for Eliciting LLM Hallucinations",
    "summary": "Large Language Models (LLMs) are increasingly deployed in high-risk domains. However, state-of-the-art LLMs often produce hallucinations, raising serious concerns about their reliability. Prior work has explored adversarial attacks for hallucination elicitation in LLMs, but it often produces unrealistic prompts, either by inserting gibberish tokens or by altering the original meaning. As a result, these approaches offer limited insight into how hallucinations may occur in practice. While adversarial attacks in computer vision often involve realistic modifications to input images, the problem of finding realistic adversarial prompts for eliciting LLM hallucinations has remained largely underexplored. To address this gap, we propose Semantically Equivalent and Coherent Attacks (SECA) to elicit hallucinations via realistic modifications to the prompt that preserve its meaning while maintaining semantic coherence. Our contributions are threefold: (i) we formulate finding realistic attacks for hallucination elicitation as a constrained optimization problem over the input prompt space under semantic equivalence and coherence constraints; (ii) we introduce a constraint-preserving zeroth-order method to effectively search for adversarial yet feasible prompts; and (iii) we demonstrate through experiments on open-ended multiple-choice question answering tasks that SECA achieves higher attack success rates while incurring almost no semantic equivalence or semantic coherence errors compared to existing methods. SECA highlights the sensitivity of both open-source and commercial gradient-inaccessible LLMs to realistic and plausible prompt variations. Code is available at https://github.com/Buyun-Liang/SECA.",
    "published": "2025-10-05T23:44:54Z",
    "updated": "2025-11-30T19:12:35Z",
    "link": "http://arxiv.org/pdf/2510.04398v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "authors": [
      "Buyun Liang",
      "Liangzu Peng",
      "Jinqi Luo",
      "Darshan Thaker",
      "Kwan Ho Ryan Chan",
      "René Vidal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01037v1",
    "title": "When Safety Blocks Sense: Measuring Semantic Confusion in LLM Refusals",
    "summary": "Safety-aligned language models often refuse prompts that are actually harmless. Current evaluations mostly report global rates such as false rejection or compliance. These scores treat each prompt alone and miss local inconsistency, where a model accepts one phrasing of an intent but rejects a close paraphrase. This gap limits diagnosis and tuning. We introduce \"semantic confusion,\" a failure mode that captures such local inconsistency, and a framework to measure it. We build ParaGuard, a 10k-prompt corpus of controlled paraphrase clusters that hold intent fixed while varying surface form. We then propose three model-agnostic metrics at the token level: Confusion Index, Confusion Rate, and Confusion Depth. These metrics compare each refusal to its nearest accepted neighbors and use token embeddings, next-token probabilities, and perplexity signals. Experiments across diverse model families and deployment guards show that global false-rejection rate hides critical structure. Our metrics reveal globally unstable boundaries in some settings, localized pockets of inconsistency in others, and cases where stricter refusal does not increase inconsistency. We also show how confusion-aware auditing separates how often a system refuses from how sensibly it refuses. This gives developers a practical signal to reduce false refusals while preserving safety.",
    "published": "2025-11-30T19:11:45Z",
    "updated": "2025-11-30T19:11:45Z",
    "link": "http://arxiv.org/pdf/2512.01037v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Riad Ahmed Anonto",
      "Md Labid Al Nahiyan",
      "Md Tanvir Hassan",
      "Ch. Md. Rakin Haider"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01035v1",
    "title": "Goal-Oriented Multi-Agent Semantic Networking: Unifying Intents, Semantics, and Intelligence",
    "summary": "6G services are evolving toward goal-oriented and AI-native communication, which are expected to deliver transformative societal benefits across various industries and promote energy sustainability. Yet today's networking architectures, built on complete decoupling of the applications and the network, cannot expose or exploit high-level goals, limiting their ability to adapt intelligently to service needs. This work introduces Goal-Oriented Multi-Agent Semantic Networking (GoAgentNet), a new architecture that elevates communication from data exchange to goal fulfilment. GoAgentNet enables applications and the network to collaborate by abstracting their functions into multiple collaborative agents, and jointly orchestrates multi-agent sensing, networking, computation, and control through semantic computation and cross-layer semantic networking, allowing the entire architecture to pursue unified application goals. We first outline the limitations of legacy network designs in supporting 6G services, based on which we highlight key enablers of our GoAgentNet design. Then, through three representative 6G usage scenarios, we demonstrate how GoAgentNet can unlock more efficient and intelligent services. We further identify unique challenges faced by GoAgentNet deployment and corresponding potential solutions. A case study on robotic fault detection and recovery shows that our GoAgentNet architecture improves energy efficiency by up to 99% and increases the task success rate by up to 72%, compared with the existing networking architectures without GoAgentNet, which underscores its potential to support scalable and sustainable 6G systems.",
    "published": "2025-11-30T19:04:17Z",
    "updated": "2025-11-30T19:04:17Z",
    "link": "http://arxiv.org/pdf/2512.01035v1.pdf",
    "category": [
      "cs.NI",
      "cs.AI"
    ],
    "authors": [
      "Shutong Chen",
      "Qi Liao",
      "Adnan Aijaz",
      "Yansha Deng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01034v1",
    "title": "AltNet: Addressing the Plasticity-Stability Dilemma in Reinforcement Learning",
    "summary": "Neural networks have shown remarkable success in supervised learning when trained on a single task using a fixed dataset. However, when neural networks are trained on a reinforcement learning task, their ability to continue learning from new experiences declines over time. This decline in learning ability is known as plasticity loss. To restore plasticity, prior work has explored periodically resetting the parameters of the learning network, a strategy that often improves overall performance. However, such resets come at the cost of a temporary drop in performance, which can be dangerous in real-world settings. To overcome this instability, we introduce AltNet, a reset-based approach that restores plasticity without performance degradation by leveraging twin networks. The use of twin networks anchors performance during resets through a mechanism that allows networks to periodically alternate roles: one network learns as it acts in the environment, while the other learns off-policy from the active network's interactions and a replay buffer. At fixed intervals, the active network is reset and the passive network, having learned from prior experiences, becomes the new active network. AltNet restores plasticity, improving sample efficiency and achieving higher performance, while avoiding performance drops that pose risks in safety-critical settings. We demonstrate these advantages in several high-dimensional control tasks from the DeepMind Control Suite, where AltNet outperforms various relevant baseline methods, as well as state-of-the-art reset-based techniques.",
    "published": "2025-11-30T19:02:20Z",
    "updated": "2025-11-30T19:02:20Z",
    "link": "http://arxiv.org/pdf/2512.01034v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Mansi Maheshwari",
      "John C. Raisbeck",
      "Bruno Castro da Silva"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.02010v1",
    "title": "Four Over Six: More Accurate NVFP4 Quantization with Adaptive Block Scaling",
    "summary": "As large language models have grown larger, low-precision numerical formats such as NVFP4 have become increasingly popular due to the speed and memory benefits they provide. However, to accelerate computation with NVFP4, all matrix multiplication operands--weights and activations in the forward pass, and weights, activations, and gradients in the backward pass--must be quantized to NVFP4, often leading to divergence during training and performance degradation during inference. NVFP4 by evaluating multiple potential scale factors for each block of values. To address this issue, in this work we introduce Four Over Six (4/6), a modification to the NVFP4 quantization algorithm that evaluates two potential scale factors for each block of values. Unlike integer formats, floating-point formats such as FP4 have the most quantization error on near-maximal values in each block, which we find to be primarily responsible for downstream performance degradation. We find that for some blocks, scaling to smaller FP4 values makes the distribution of representable values more uniform, improving representation of near-maximal values. Importantly, 4/6 can be implemented efficiently on NVIDIA Blackwell GPUs, making it viable to use while training LLMs with NVFP4. In pre-training experiments with transformer and hybrid model architectures, we find that 4/6 prevents divergence in several cases, bringing training loss significantly closer to BF16 compared to models trained with current state-of-the-art NVFP4 training recipes. We also find that 4/6 can be easily incorporated into many different post-training quantization methods and generally improves downstream accuracy. We hope this inspires future work in training and deploying models with NVFP4.",
    "published": "2025-12-01T18:59:45Z",
    "updated": "2025-12-01T18:59:45Z",
    "link": "http://arxiv.org/pdf/2512.02010v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Jack Cook",
      "Junxian Guo",
      "Guangxuan Xiao",
      "Yujun Lin",
      "Song Han"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.02008v1",
    "title": "The Art of Scaling Test-Time Compute for Large Language Models",
    "summary": "Test-time scaling (TTS) -- the dynamic allocation of compute during inference -- is a promising direction for improving reasoning in large language models (LLMs). However, a systematic comparison of well-known TTS strategies under identical conditions is missing, and the influence of model type and problem difficulty on performance remains unclear. To address these gaps, we conduct the first large-scale study of TTS, spanning over thirty billion tokens generated using eight open-source LLMs (7B to 235B parameters), across four reasoning datasets. We observe three consistent trends: (1) no single TTS strategy universally dominates; (2) reasoning models exhibit distinct trace-quality patterns across problem difficulty and trace length, forming short-horizon and long-horizon categories; and (3) for a given model type, the optimal TTS performance scales monotonically with compute budget. Based on these insights, we provide a practical recipe for selecting the best TTS strategy, considering problem difficulty, model type, and compute budget, providing a practical guide to effective inference-time scaling.",
    "published": "2025-12-01T18:59:28Z",
    "updated": "2025-12-01T18:59:28Z",
    "link": "http://arxiv.org/pdf/2512.02008v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Aradhye Agarwal",
      "Ayan Sengupta",
      "Tanmoy Chakraborty"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.02004v1",
    "title": "AlignSAE: Concept-Aligned Sparse Autoencoders",
    "summary": "Large Language Models (LLMs) encode factual knowledge within hidden parametric spaces that are difficult to inspect or control. While Sparse Autoencoders (SAEs) can decompose hidden activations into more fine-grained, interpretable features, they often struggle to reliably align these features with human-defined concepts, resulting in entangled and distributed feature representations. To address this, we introduce AlignSAE, a method that aligns SAE features with a defined ontology through a \"pre-train, then post-train\" curriculum. After an initial unsupervised training phase, we apply supervised post-training to bind specific concepts to dedicated latent slots while preserving the remaining capacity for general reconstruction. This separation creates an interpretable interface where specific relations can be inspected and controlled without interference from unrelated features. Empirical results demonstrate that AlignSAE enables precise causal interventions, such as reliable \"concept swaps\", by targeting single, semantically aligned slots.",
    "published": "2025-12-01T18:58:22Z",
    "updated": "2025-12-01T18:58:22Z",
    "link": "http://arxiv.org/pdf/2512.02004v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Minglai Yang",
      "Xinyu Guo",
      "Mihai Surdeanu",
      "Liangming Pan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01948v1",
    "title": "How Far Are We from Genuinely Useful Deep Research Agents?",
    "summary": "Deep Research Agents (DRAs) aim to automatically produce analyst-level reports through iterative information retrieval and synthesis. However, most existing DRAs were validated on question-answering benchmarks, while research on generating comprehensive reports remains overlooked. Worse, current benchmarks for report synthesis suffer from task complexity and subjective metrics -- this fails to reflect user demands and limits the practical utility of generated reports. To address these gaps, we present Fine-grained DEepResearch bench (FINDER), an enhanced benchmark consisting of 100 human-curated research tasks with 419 structured checklist items that standardize report structure, analytical depth, and factual grounding. Based on approximately 1,000 reports produced by mainstream DRAs, we further propose Deep rEsearch Failure Taxonomy (DEFT), the first failure taxonomy for deep research agents. DEFT contains 14 fine-grained failure modes across reasoning, retrieval, and generation, and is built upon grounded theory with human-LLM co-annotating and inter-annotator reliability validation. Our experimental findings reveal that current DRAs struggle not with task comprehension but with evidence integration, verification, and reasoning-resilient planning.",
    "published": "2025-12-01T17:58:59Z",
    "updated": "2025-12-01T17:58:59Z",
    "link": "http://arxiv.org/pdf/2512.01948v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Dingling Zhang",
      "He Zhu",
      "Jincheng Ren",
      "Kangqi Song",
      "Xinran Zhou",
      "Boyu Feng",
      "Shudong Liu",
      "Jiabin Luo",
      "Weihao Xie",
      "Zhaohui Wang",
      "Tianrui Qin",
      "King Zhu",
      "Yuqing Wang",
      "Qianben Chen",
      "Yuchen Eleanor Jiang",
      "Wei Wang",
      "Jiaheng Liu",
      "Wangchunshu Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01909v1",
    "title": "Latent Debate: A Surrogate Framework for Interpreting LLM Thinking",
    "summary": "Understanding the internal thinking process of Large Language Models (LLMs) and the cause of hallucinations remains a key challenge. To this end, we introduce latent debate, a novel framework for interpreting model predictions through the lens of implicit internal arguments. Unlike the current work of self-consistency and multi-agent debate, which relies on explicit debates among multiple answers or multiple models, latent debate captures the hidden supporting and attacking signals that arise within a single model during a single inference. We first present a model- and task-agnostic conceptual framework, and then instantiate it symbolically to approximate the thinking process of LLMs on True/False prediction tasks. Empirical studies demonstrate that latent debate is a faithful structured surrogate model that has highly consistent predictions with the original LLM. Beyond interpretability, we demonstrate that latent debate provides a strong baseline for hallucination detection. Further analysis reveals strong correlations between hallucinations and debate patterns, such as a high degree of latent debates in the middle layers is linked to a higher risk of hallucinations. These findings position latent debate as a potential framework for understanding internal mechanisms of LLMs, especially for scenarios where internal (dis)agreements appear during the inference steps.",
    "published": "2025-12-01T17:27:31Z",
    "updated": "2025-12-01T17:27:31Z",
    "link": "http://arxiv.org/pdf/2512.01909v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Lihu Chen",
      "Xiang Yin",
      "Francesca Toni"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01896v1",
    "title": "OPOR-Bench: Evaluating Large Language Models on Online Public Opinion Report Generation",
    "summary": "Online Public Opinion Reports consolidate news and social media for timely crisis management by governments and enterprises. While large language models have made automated report generation technically feasible, systematic research in this specific area remains notably absent, particularly lacking formal task definitions and corresponding benchmarks. To bridge this gap, we define the Automated Online Public Opinion Report Generation (OPOR-GEN) task and construct OPOR-BENCH, an event-centric dataset covering 463 crisis events with their corresponding news articles, social media posts, and a reference summary. To evaluate report quality, we propose OPOR-EVAL, a novel agent-based framework that simulates human expert evaluation by analyzing generated reports in context. Experiments with frontier models demonstrate that our framework achieves high correlation with human judgments. Our comprehensive task definition, benchmark dataset, and evaluation framework provide a solid foundation for future research in this critical domain.",
    "published": "2025-12-01T17:18:02Z",
    "updated": "2025-12-01T17:18:02Z",
    "link": "http://arxiv.org/pdf/2512.01896v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Jinzheng Yu",
      "Yang Xu",
      "Haozhen Li",
      "Junqi Li",
      "Yifan Feng",
      "Ligu Zhu",
      "Hao Shen",
      "Lei Shi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06108v2",
    "title": "Influence Functions for Efficient Data Selection in Reasoning",
    "summary": "Fine-tuning large language models (LLMs) on chain-of-thought (CoT) data shows that a small amount of high-quality data can outperform massive datasets. Yet, what constitutes \"quality\" remains ill-defined. Existing reasoning methods rely on indirect heuristics such as problem difficulty or trace length, while instruction-tuning has explored a broader range of automated selection strategies, but rarely in the context of reasoning. We propose to define reasoning data quality using influence functions, which measure the causal effect of individual CoT examples on downstream accuracy, and introduce influence-based pruning, which consistently outperforms perplexity and embedding-based baselines on math reasoning within a model family.",
    "published": "2025-10-07T16:40:42Z",
    "updated": "2025-12-01T16:49:01Z",
    "link": "http://arxiv.org/pdf/2510.06108v2.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Prateek Humane",
      "Paolo Cudrano",
      "Daniel Z. Kaplan",
      "Matteo Matteucci",
      "Supriyo Chakraborty",
      "Irina Rish"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18538v2",
    "title": "From Code Foundation Models to Agents and Applications: A Practical Guide to Code Intelligence",
    "summary": "Large language models (LLMs) have fundamentally transformed automated software development by enabling direct translation of natural language descriptions into functional code, driving commercial adoption through tools like Github Copilot (Microsoft), Cursor (Anysphere), Trae (ByteDance), and Claude Code (Anthropic). While the field has evolved dramatically from rule-based systems to Transformer-based architectures, achieving performance improvements from single-digit to over 95\\% success rates on benchmarks like HumanEval. In this work, we provide a comprehensive synthesis and practical guide (a series of analytic and probing experiments) about code LLMs, systematically examining the complete model life cycle from data curation to post-training through advanced prompting paradigms, code pre-training, supervised fine-tuning, reinforcement learning, and autonomous coding agents. We analyze the code capability of the general LLMs (GPT-4, Claude, LLaMA) and code-specialized LLMs (StarCoder, Code LLaMA, DeepSeek-Coder, and QwenCoder), critically examining the techniques, design decisions, and trade-offs. Further, we articulate the research-practice gap between academic research (e.g., benchmarks and tasks) and real-world deployment (e.g., software-related code tasks), including code correctness, security, contextual awareness of large codebases, and integration with development workflows, and map promising research directions to practical needs. Last, we conduct a series of experiments to provide a comprehensive analysis of code pre-training, supervised fine-tuning, and reinforcement learning, covering scaling law, framework selection, hyperparameter sensitivity, model architectures, and dataset comparisons.",
    "published": "2025-11-23T17:09:34Z",
    "updated": "2025-12-01T16:38:23Z",
    "link": "http://arxiv.org/pdf/2511.18538v2.pdf",
    "category": [
      "cs.SE",
      "cs.CL"
    ],
    "authors": [
      "Jian Yang",
      "Xianglong Liu",
      "Weifeng Lv",
      "Ken Deng",
      "Shawn Guo",
      "Lin Jing",
      "Yizhi Li",
      "Shark Liu",
      "Xianzhen Luo",
      "Yuyu Luo",
      "Changzai Pan",
      "Ensheng Shi",
      "Yingshui Tan",
      "Renshuai Tao",
      "Jiajun Wu",
      "Xianjie Wu",
      "Zhenhe Wu",
      "Daoguang Zan",
      "Chenchen Zhang",
      "Wei Zhang",
      "He Zhu",
      "Terry Yue Zhuo",
      "Kerui Cao",
      "Xianfu Cheng",
      "Jun Dong",
      "Shengjie Fang",
      "Zhiwei Fei",
      "Xiangyuan Guan",
      "Qipeng Guo",
      "Zhiguang Han",
      "Joseph James",
      "Tianqi Luo",
      "Renyuan Li",
      "Yuhang Li",
      "Yiming Liang",
      "Congnan Liu",
      "Jiaheng Liu",
      "Qian Liu",
      "Ruitong Liu",
      "Tyler Loakman",
      "Xiangxin Meng",
      "Chuang Peng",
      "Tianhao Peng",
      "Jiajun Shi",
      "Mingjie Tang",
      "Boyang Wang",
      "Haowen Wang",
      "Yunli Wang",
      "Fanglin Xu",
      "Zihan Xu",
      "Fei Yuan",
      "Ge Zhang",
      "Jiayi Zhang",
      "Xinhao Zhang",
      "Wangchunshu Zhou",
      "Hualei Zhu",
      "King Zhu",
      "Brown Dai",
      "Aishan Liu",
      "Zhoujun Li",
      "Chenghua Lin",
      "Tianyu Liu",
      "Chao Peng",
      "Kai Shen",
      "Libo Qin",
      "Shuangyong Song",
      "Zizheng Zhan",
      "Jiajun Zhang",
      "Jie Zhang",
      "Zhaoxiang Zhang",
      "Bo Zheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01848v1",
    "title": "Beyond SFT: Reinforcement Learning for Safer Large Reasoning Models with Better Reasoning Ability",
    "summary": "Large reasoning models (LRMs) extend large language models by generating explicit chain-of-thought (CoT) reasoning, significantly improving mathematical and logical problem solving. However, this explicit reasoning process also introduces new safety risks, as unsafe behaviors often emerge within intermediate reasoning trajectories, even when final answers appear harmless. Existing safety alignment approaches primarily rely on supervised fine-tuning (SFT) over safety-oriented long CoT datasets. While intuitive, we find that SFT produces inconsistent safety improvements, degrades reasoning ability, and generalizes poorly across model families. These limitations suggest that purely supervised approaches are insufficient for robust safety alignment in LRMs. To address this, we investigate reinforcement learning (RL) as a complementary optimization framework for LRM safety training. Unlike SFT, RL directly optimizes model policies with reward feedback, enabling more adaptive and stable alignment. Extensive experiments across multiple model families and benchmarks show that RL achieves stronger and more consistent safety gains while maintaining reasoning competence. Further analysis of reflection dynamics and token-level entropy reveals that RL suppresses unsafe exploratory reasoning while preserving reflective depth, leading to safer and more reliable reasoning processes.",
    "published": "2025-12-01T16:35:34Z",
    "updated": "2025-12-01T16:35:34Z",
    "link": "http://arxiv.org/pdf/2512.01848v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Jinghan Jia",
      "Nathalie Baracaldo",
      "Sijia Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.20494v3",
    "title": "Adversarial Confusion Attack: Disrupting Multimodal Large Language Models",
    "summary": "We introduce the Adversarial Confusion Attack, a new class of threats against multimodal large language models (MLLMs). Unlike jailbreaks or targeted misclassification, the goal is to induce systematic disruption that makes the model generate incoherent or confidently incorrect outputs. Practical applications include embedding such adversarial images into websites to prevent MLLM-powered AI Agents from operating reliably. The proposed attack maximizes next-token entropy using a small ensemble of open-source MLLMs. In the white-box setting, we show that a single adversarial image can disrupt all models in the ensemble, both in the full-image and Adversarial CAPTCHA settings. Despite relying on a basic adversarial technique (PGD), the attack generates perturbations that transfer to both unseen open-source (e.g., Qwen3-VL) and proprietary (e.g., GPT-5.1) models.",
    "published": "2025-11-25T17:00:31Z",
    "updated": "2025-12-01T16:20:06Z",
    "link": "http://arxiv.org/pdf/2511.20494v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Jakub Hoscilowicz",
      "Artur Janicki"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.02013v4",
    "title": "SpeechRole: A Large-Scale Dataset and Benchmark for Evaluating Speech Role-Playing Agents",
    "summary": "Recently, role-playing agents have emerged as a promising paradigm for achieving personalized interaction and emotional resonance. Existing research primarily focuses on the textual modality, neglecting the critical dimension of speech in realistic interactive scenarios. In particular, there is a lack of systematic evaluation for Speech Role-Playing Agents (SRPAs). To address this gap, we construct SpeechRole-Data, a large-scale, high-quality dataset that comprises 98 diverse roles and 112k speech-based single-turn and multi-turn conversations. Each role demonstrates distinct vocal characteristics, including timbre and prosody, thereby enabling more sophisticated speech role-playing. Furthermore, we propose SpeechRole-Eval, a multidimensional evaluation benchmark that systematically assesses SRPAs performance in key aspects such as fundamental interaction ability, speech expressiveness, and role-playing fidelity. Experimental results reveal the advantages and challenges of both cascaded and end-to-end speech role-playing agents in maintaining vocal style consistency and role coherence. We release all data, code, and baseline models to provide a solid foundation for speech-driven multimodal role-playing research and to foster further developments in this field.",
    "published": "2025-08-04T03:18:36Z",
    "updated": "2025-12-01T14:59:57Z",
    "link": "http://arxiv.org/pdf/2508.02013v4.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Changhao Jiang",
      "Jiajun Sun",
      "Yifei Cao",
      "Jiabao Zhuang",
      "Hui Li",
      "Baoyu Fan",
      "Tao Ji",
      "Tao Gui",
      "Qi Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01728v1",
    "title": "Reasoning About the Unsaid: Misinformation Detection with Omission-Aware Graph Inference",
    "summary": "This paper investigates the detection of misinformation, which deceives readers by explicitly fabricating misleading content or implicitly omitting important information necessary for informed judgment. While the former has been extensively studied, omission-based deception remains largely overlooked, even though it can subtly guide readers toward false conclusions under the illusion of completeness. To pioneer in this direction, this paper presents OmiGraph, the first omission-aware framework for misinformation detection. Specifically, OmiGraph constructs an omission-aware graph for the target news by utilizing a contextual environment that captures complementary perspectives of the same event, thereby surfacing potentially omitted contents. Based on this graph, omission-oriented relation modeling is then proposed to identify the internal contextual dependencies, as well as the dynamic omission intents, formulating a comprehensive omission relation representation. Finally, to extract omission patterns for detection, OmiGraph introduces omission-aware message-passing and aggregation that establishes holistic deception perception by integrating the omission contents and relations. Experiments show that, by considering the omission perspective, our approach attains remarkable performance, achieving average improvements of +5.4% F1 and +5.3% ACC on two large-scale benchmarks.",
    "published": "2025-12-01T14:37:00Z",
    "updated": "2025-12-01T14:37:00Z",
    "link": "http://arxiv.org/pdf/2512.01728v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Zhengjia Wang",
      "Danding Wang",
      "Qiang Sheng",
      "Jiaying Wu",
      "Juan Cao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01725v1",
    "title": "Beware of Reasoning Overconfidence: Pitfalls in the Reasoning Process for Multi-solution Tasks",
    "summary": "Large Language Models (LLMs) excel in reasoning tasks requiring a single correct answer, but they perform poorly in multi-solution tasks that require generating comprehensive and diverse answers. We attribute this limitation to \\textbf{reasoning overconfidence}: a tendency to express undue certainty in an incomplete solution set. To examine the effect, we introduce \\textit{MuSoBench}, a benchmark of multi-solution problems. Experiments show that the conventional short chain-of-thought (Short-CoT) prompting paradigm exhibits pronounced overconfidence, whereas the emerging long chain-of-thought (Long-CoT) approach mitigates it through iterative exploration and self-reflection. We further characterise observable behaviours and influential factors. To probe the underlying cause, we propose the \\textbf{cognitive-rigidity hypothesis}, which posits that overconfidence arises when the reasoning process prematurely converges on a narrow set of thought paths. An attention-entropy analysis offers preliminary support for this view. These findings provide tools for assessing the completeness of LLM reasoning and highlight the need to move evaluation beyond single-answer accuracy toward comprehensive exploration.",
    "published": "2025-12-01T14:35:06Z",
    "updated": "2025-12-01T14:35:06Z",
    "link": "http://arxiv.org/pdf/2512.01725v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Jiannan Guan",
      "Qiguang Chen",
      "Libo Qin",
      "Dengyun Peng",
      "Jinhao Liu",
      "Liangyu Huo",
      "Jian Xie",
      "Wanxiang Che"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01713v1",
    "title": "Self-Supervised Borrowing Detection on Multilingual Wordlists",
    "summary": "This paper presents a fully self-supervised approach to borrowing detection in multilingual wordlists. The method combines two sources of information: PMI similarities based on a global correspondence model and a lightweight contrastive component trained on phonetic feature vectors. It further includes an automatic procedure for selecting decision thresholds without requiring labeled data. Experiments on benchmark datasets show that PMI alone already improves over existing string similarity measures such as NED and SCA, and that the combined similarity performs on par with or better than supervised baselines. An ablation study highlights the importance of character encoding, temperature settings and augmentation strategies. The approach scales to datasets of different sizes, works without manual supervision and is provided with a command-line tool that allows researchers to conduct their own studies.",
    "published": "2025-12-01T14:20:03Z",
    "updated": "2025-12-01T14:20:03Z",
    "link": "http://arxiv.org/pdf/2512.01713v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Tim Wientzek"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01710v1",
    "title": "MMAG: Mixed Memory-Augmented Generation for Large Language Models Applications",
    "summary": "Large Language Models (LLMs) excel at generating coherent text within a single prompt but fall short in sustaining relevance, personalization, and continuity across extended interactions. Human communication, however, relies on multiple forms of memory, from recalling past conversations to adapting to personal traits and situational context. This paper introduces the Mixed Memory-Augmented Generation (MMAG) pattern, a framework that organizes memory for LLM-based agents into five interacting layers: conversational, long-term user, episodic and event-linked, sensory and context-aware, and short-term working memory. Drawing inspiration from cognitive psychology, we map these layers to technical components and outline strategies for coordination, prioritization, and conflict resolution. We demonstrate the approach through its implementation in the Heero conversational agent, where encrypted long-term bios and conversational history already improve engagement and retention. We further discuss implementation concerns around storage, retrieval, privacy, and latency, and highlight open challenges. MMAG provides a foundation for building memory-rich language agents that are more coherent, proactive, and aligned with human needs.",
    "published": "2025-12-01T14:16:57Z",
    "updated": "2025-12-01T14:16:57Z",
    "link": "http://arxiv.org/pdf/2512.01710v1.pdf",
    "category": [
      "cs.CL",
      "cs.IR"
    ],
    "authors": [
      "Stefano Zeppieri"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.19090v2",
    "title": "Debating Truth: Debate-driven Claim Verification with Multiple Large Language Model Agents",
    "summary": "Claim verification is essential for digital literacy, yet state-of-the-art single-agent methods often struggle with complex claims that require nuanced analysis of multifaceted online evidence. Inspired by real-world human fact-checking practices, we propose \\textbf{DebateCV}, the first debate-driven claim verification framework powered by multiple LLM agents. In DebateCV, two \\textit{Debaters} argue opposing stances over multiple rounds to surface subtle errors in single-agent assessments. A decisive \\textit{Moderator} is then required to weigh the evidential strength of conflicting arguments to deliver an accurate verdict. Yet zero-shot agents struggle to adjudicate multi-round debates for verifying complex claims, often defaulting to neutral judgements, and no datasets exist for training agents for this role. To bridge this gap, we propose \\textbf{Debate-SFT}, a post-training framework that leverages synthetic data to enhance agents' ability to effectively adjudicate debates for claim verification. Results show that our methods surpass state-of-the-art non-debate approaches in both accuracy (across various evidence conditions) and justification quality, which strengthens societal resilience against misinformation and contributes to a more trustworthy online information ecosystem.",
    "published": "2025-07-25T09:19:25Z",
    "updated": "2025-12-01T14:06:31Z",
    "link": "http://arxiv.org/pdf/2507.19090v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Haorui He",
      "Yupeng Li",
      "Dacheng Wen",
      "Yang Chen",
      "Reynold Cheng",
      "Donglong Chen",
      "Francis C. M. Lau"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.22273v2",
    "title": "Comprehensive Evaluation on Lexical Normalization: Boundary-Aware Approaches for Unsegmented Languages",
    "summary": "Lexical normalization research has sought to tackle the challenge of processing informal expressions in user-generated text, yet the absence of comprehensive evaluations leaves it unclear which methods excel across multiple perspectives. Focusing on unsegmented languages, we make three key contributions: (1) creating a large-scale, multi-domain Japanese normalization dataset, (2) developing normalization methods based on state-of-the-art pretrained models, and (3) conducting experiments across multiple evaluation perspectives. Our experiments show that both encoder-only and decoder-only approaches achieve promising results in both accuracy and efficiency.",
    "published": "2025-05-28T12:02:45Z",
    "updated": "2025-12-01T13:10:26Z",
    "link": "http://arxiv.org/pdf/2505.22273v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Shohei Higashiyama",
      "Masao Utiyama"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01603v1",
    "title": "MAC-SLU: Multi-Intent Automotive Cabin Spoken Language Understanding Benchmark",
    "summary": "Spoken Language Understanding (SLU), which aims to extract user semantics to execute downstream tasks, is a crucial component of task-oriented dialog systems. Existing SLU datasets generally lack sufficient diversity and complexity, and there is an absence of a unified benchmark for the latest Large Language Models (LLMs) and Large Audio Language Models (LALMs). This work introduces MAC-SLU, a novel Multi-Intent Automotive Cabin Spoken Language Understanding Dataset, which increases the difficulty of the SLU task by incorporating authentic and complex multi-intent data. Based on MAC-SLU, we conducted a comprehensive benchmark of leading open-source LLMs and LALMs, covering methods like in-context learning, supervised fine-tuning (SFT), and end-to-end (E2E) and pipeline paradigms. Our experiments show that while LLMs and LALMs have the potential to complete SLU tasks through in-context learning, their performance still lags significantly behind SFT. Meanwhile, E2E LALMs demonstrate performance comparable to pipeline approaches and effectively avoid error propagation from speech recognition. Code\\footnote{https://github.com/Gatsby-web/MAC\\_SLU} and datasets\\footnote{huggingface.co/datasets/Gatsby1984/MAC\\_SLU} are released publicly.",
    "published": "2025-12-01T12:23:19Z",
    "updated": "2025-12-01T12:23:19Z",
    "link": "http://arxiv.org/pdf/2512.01603v1.pdf",
    "category": [
      "cs.CL",
      "cs.MM"
    ],
    "authors": [
      "Yuezhang Peng",
      "Chonghao Cai",
      "Ziang Liu",
      "Shuai Fan",
      "Sheng Jiang",
      "Hua Xu",
      "Yuxin Liu",
      "Qiguang Chen",
      "Kele Xu",
      "Yao Li",
      "Sheng Wang",
      "Libo Qin",
      "Xie Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.07295v2",
    "title": "CCFQA: A Benchmark for Cross-Lingual and Cross-Modal Speech and Text Factuality Evaluation",
    "summary": "As Large Language Models (LLMs) are increasingly popularized in the multilingual world, ensuring hallucination-free factuality becomes markedly crucial. However, existing benchmarks for evaluating the reliability of Multimodal Large Language Models (MLLMs) predominantly focus on textual or visual modalities with a primary emphasis on English, which creates a gap in evaluation when processing multilingual input, especially in speech. To bridge this gap, we propose a novel Cross-lingual and Cross-modal Factuality benchmark (CCFQA). Specifically, the CCFQA benchmark contains parallel speech-text factual questions across 8 languages, designed to systematically evaluate MLLMs' cross-lingual and cross-modal factuality capabilities. Our experimental results demonstrate that current MLLMs still face substantial challenges on the CCFQA benchmark. Furthermore, we propose a few-shot transfer learning strategy that effectively transfers the Question Answering (QA) capabilities of LLMs in English to multilingual Spoken Question Answering (SQA) tasks, achieving competitive performance with GPT-4o-mini-Audio using just 5-shot training. We release CCFQA as a foundational research resource to promote the development of MLLMs with more robust and reliable speech understanding capabilities. Our code and dataset are available at https://github.com/yxduir/ccfqa.",
    "published": "2025-08-10T11:09:41Z",
    "updated": "2025-12-01T12:11:29Z",
    "link": "http://arxiv.org/pdf/2508.07295v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yexing Du",
      "Kaiyuan Liu",
      "Youcheng Pan",
      "Zheng Chu",
      "Bo Yang",
      "Xiaocheng Feng",
      "Ming Liu",
      "Yang Xiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.12726v4",
    "title": "DESIGNER: Design-Logic-Guided Multidisciplinary Data Synthesis for LLM Reasoning",
    "summary": "Large language models (LLMs) have achieved remarkable success in many natural language tasks but still struggle with complex, multi-step reasoning, particularly across diverse disciplines. Existing reasoning datasets often lack disciplinary breadth, reasoning depth, and diversity, as well as guiding principles for question synthesis. We propose DESIGNER: a DESIGN-logic-guidEd Reasoning data synthesis pipeline that leverages naturally available, extensive raw documents (e.g., book corpus and web corpus) to generate multidisciplinary challenging questions. We introduce the concept of \"design logic\" and instruct LLMs to mimic human educators' question-creation process, enabling the automated synthesis of large-scale, high-difficulty questions. We use LLMs to reverse-engineer and abstract over 120,000 design logics from existing questions across various disciplines. By matching these design logics with source documents, we are able to generate reasoning questions with controllable question types and difficulty levels. Using this pipeline, we synthesized two large-scale reasoning datasets that span 75 disciplines: DLR-Book (3.04 million questions from the book corpus) and DLR-Web (1.66 million questions from the web corpus). Data analysis indicates that the questions synthesized by our method exhibit greater difficulty and diversity compared to those in the baseline datasets. We validate our synthesized data through supervised fine-tuning (SFT) on the Qwen3 and Llama3 model families. Our data substantially enhances their multidisciplinary reasoning capabilities, outperforming existing datasets. Notably, by applying SFT on the base versions of these models using only our data, we even surpass their official final models that have undergone the full post-training process.",
    "published": "2025-08-18T08:49:29Z",
    "updated": "2025-12-01T11:50:42Z",
    "link": "http://arxiv.org/pdf/2508.12726v4.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Weize Liu",
      "Yongchi Zhao",
      "Yijia Luo",
      "Mingyu Xu",
      "Jiaheng Liu",
      "Yanan Li",
      "Xiguo Hu",
      "Zhiqi Bai",
      "Yuchi Xu",
      "Wenbo Su",
      "Bo Zheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01557v1",
    "title": "Language Diversity: Evaluating Language Usage and AI Performance on African Languages in Digital Spaces",
    "summary": "This study examines the digital representation of African languages and the challenges this presents for current language detection tools. We evaluate their performance on Yoruba, Kinyarwanda, and Amharic. While these languages are spoken by millions, their online usage on conversational platforms is often sparse, heavily influenced by English, and not representative of the authentic, monolingual conversations prevalent among native speakers. This lack of readily available authentic data online creates a challenge of scarcity of conversational data for training language models. To investigate this, data was collected from subreddits and local news sources for each language. The analysis showed a stark contrast between the two sources. Reddit data was minimal and characterized by heavy code-switching. Conversely, local news media offered a robust source of clean, monolingual language data, which also prompted more user engagement in the local language on the news publishers social media pages. Language detection models, including the specialized AfroLID and a general LLM, performed with near-perfect accuracy on the clean news data but struggled with the code-switched Reddit posts. The study concludes that professionally curated news content is a more reliable and effective source for training context-rich AI models for African languages than data from conversational platforms. It also highlights the need for future models that can process clean and code-switched text to improve the detection accuracy for African languages.",
    "published": "2025-12-01T11:27:13Z",
    "updated": "2025-12-01T11:27:13Z",
    "link": "http://arxiv.org/pdf/2512.01557v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Edward Ajayi",
      "Eudoxie Umwari",
      "Mawuli Deku",
      "Prosper Singadi",
      "Jules Udahemuka",
      "Bekalu Tadele",
      "Chukuemeka Edeh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.20001v2",
    "title": "A Machine Learning Approach for Detection of Mental Health Conditions and Cyberbullying from Social Media",
    "summary": "Mental health challenges and cyberbullying are increasingly prevalent in digital spaces, necessitating scalable and interpretable detection systems. This paper introduces a unified multiclass classification framework for detecting ten distinct mental health and cyberbullying categories from social media data. We curate datasets from Twitter and Reddit, implementing a rigorous \"split-then-balance\" pipeline to train on balanced data while evaluating on a realistic, held-out imbalanced test set. We conducted a comprehensive evaluation comparing traditional lexical models, hybrid approaches, and several end-to-end fine-tuned transformers. Our results demonstrate that end-to-end fine-tuning is critical for performance, with the domain-adapted MentalBERT emerging as the top model, achieving an accuracy of 0.92 and a Macro F1 score of 0.76, surpassing both its generic counterpart and a zero-shot LLM baseline. Grounded in a comprehensive ethical analysis, we frame the system as a human-in-the-loop screening aid, not a diagnostic tool. To support this, we introduce a hybrid SHAPLLM explainability framework and present a prototype dashboard (\"Social Media Screener\") designed to integrate model predictions and their explanations into a practical workflow for moderators. Our work provides a robust baseline, highlighting future needs for multi-label, clinically-validated datasets at the critical intersection of online safety and computational mental health.",
    "published": "2025-11-25T07:12:09Z",
    "updated": "2025-12-01T11:07:35Z",
    "link": "http://arxiv.org/pdf/2511.20001v2.pdf",
    "category": [
      "cs.CL",
      "cs.SI"
    ],
    "authors": [
      "Edward Ajayi",
      "Martha Kachweka",
      "Mawuli Deku",
      "Emily Aiken"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01512v1",
    "title": "MCAT: Scaling Many-to-Many Speech-to-Text Translation with MLLMs to 70 Languages",
    "summary": "Multimodal Large Language Models (MLLMs) have achieved great success in Speech-to-Text Translation (S2TT) tasks. However, current research is constrained by two key challenges: language coverage and efficiency. Most of the popular S2TT datasets are substantially English-centric, which restricts the scaling-up of MLLMs' many-to-many translation capabilities. Moreover, the inference speed of MLLMs degrades dramatically when the speech is converted into long sequences (e.g., 750 tokens). To address these limitations, we propose a Multilingual Cost-effective Accelerated Speech-to-Text Translator (MCAT) framework, which includes two innovations. First, a language scaling method that leverages curriculum learning and a data balancing strategy is introduced to extend the language coverage supported by MLLMs to 70 languages and achieve mutual translation among these languages. Second, an optimized speech adapter module is designed to reduce the length of the speech sequence to only 30 tokens. Extensive experiments were conducted on MLLMs of different scales (9B and 27B). The experimental results demonstrate that MCAT not only surpasses state-of-the-art end-to-end models on the FLEURS dataset across 70x69 directions but also enhances batch inference efficiency. This is achieved with only ~100M trainable parameters and by using only 10 hours of S2TT data per language. Furthermore, we have released MCAT as open-source to promote the development of MLLMs for robust S2TT capabilities. The code and models are released at https://github.com/yxduir/m2m-70.",
    "published": "2025-12-01T10:39:12Z",
    "updated": "2025-12-01T10:39:12Z",
    "link": "http://arxiv.org/pdf/2512.01512v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yexing Du",
      "Kaiyuan Liu",
      "Youcheng Pan",
      "Bo Yang",
      "Keqi Deng",
      "Xie Chen",
      "Yang Xiang",
      "Ming Liu",
      "Bin Qin",
      "YaoWei Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.27049v2",
    "title": "Recursive numeral systems are highly regular and easy to process",
    "summary": "Previous work has argued that recursive numeral systems optimise the trade-off between lexicon size and average morphosyntatic complexity (Denić and Szymanik, 2024). However, showing that only natural-language-like systems optimise this tradeoff has proven elusive, and the existing solution has relied on ad-hoc constraints to rule out unnatural systems (Yang and Regier, 2025). Here, we argue that this issue arises because the proposed trade-off has neglected regularity, a crucial aspect of complexity central to human grammars in general. Drawing on the Minimum Description Length (MDL) approach, we propose that recursive numeral systems are better viewed as efficient with regard to their regularity and processing complexity. We show that our MDL-based measures of regularity and processing complexity better capture the key differences between attested, natural systems and unattested but possible ones, including \"optimal\" recursive numeral systems from previous work, and that the ad-hoc constraints from previous literature naturally follow from regularity. Our approach highlights the need to incorporate regularity across sets of forms in studies that attempt to measure and explain optimality in language.",
    "published": "2025-10-30T23:34:41Z",
    "updated": "2025-12-01T09:59:26Z",
    "link": "http://arxiv.org/pdf/2510.27049v2.pdf",
    "category": [
      "cs.CL",
      "cs.FL"
    ],
    "authors": [
      "Ponrawee Prasertsom",
      "Andrea Silvi",
      "Jennifer Culbertson",
      "Moa Johansson",
      "Devdatt Dubhashi",
      "Kenny Smith"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01460v1",
    "title": "Enhancing BERT Fine-Tuning for Sentiment Analysis in Lower-Resourced Languages",
    "summary": "Limited data for low-resource languages typically yield weaker language models (LMs). Since pre-training is compute-intensive, it is more pragmatic to target improvements during fine-tuning. In this work, we examine the use of Active Learning (AL) methods augmented by structured data selection strategies which we term 'Active Learning schedulers', to boost the fine-tuning process with a limited amount of training data. We connect the AL to data clustering and propose an integrated fine-tuning pipeline that systematically combines AL, clustering, and dynamic data selection schedulers to enhance model's performance. Experiments in the Slovak, Maltese, Icelandic and Turkish languages show that the use of clustering during the fine-tuning phase together with AL scheduling can simultaneously produce annotation savings up to 30% and performance improvements up to four F1 score points, while also providing better fine-tuning stability.",
    "published": "2025-12-01T09:45:47Z",
    "updated": "2025-12-01T09:45:47Z",
    "link": "http://arxiv.org/pdf/2512.01460v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Jozef Kubík",
      "Marek Šuppa",
      "Martin Takáč"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01443v1",
    "title": "MEGConformer: Conformer-Based MEG Decoder for Robust Speech and Phoneme Classification",
    "summary": "We present Conformer-based decoders for the LibriBrain 2025 PNPL competition, targeting two foundational MEG tasks: Speech Detection and Phoneme Classification. Our approach adapts a compact Conformer to raw 306-channel MEG signals, with a lightweight convolutional projection layer and task-specific heads. For Speech Detection, a MEG-oriented SpecAugment provided a first exploration of MEG-specific augmentation. For Phoneme Classification, we used inverse-square-root class weighting and a dynamic grouping loader to handle 100-sample averaged examples. In addition, a simple instance-level normalization proved critical to mitigate distribution shifts on the holdout split. Using the official Standard track splits and F1-macro for model selection, our best systems achieved 88.9% (Speech) and 65.8% (Phoneme) on the leaderboard, surpassing the competition baselines and ranking within the top-10 in both tasks. For further implementation details, the technical documentation, source code, and checkpoints are available at https://github.com/neural2speech/libribrain-experiments.",
    "published": "2025-12-01T09:25:22Z",
    "updated": "2025-12-01T09:25:22Z",
    "link": "http://arxiv.org/pdf/2512.01443v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG",
      "cs.NE",
      "cs.SD"
    ],
    "authors": [
      "Xabier de Zuazo",
      "Ibon Saratxaga",
      "Eva Navas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01439v1",
    "title": "Multilingual Conversational AI for Financial Assistance: Bridging Language Barriers in Indian FinTech",
    "summary": "India's linguistic diversity presents both opportunities and challenges for fintech platforms. While the country has 31 major languages and over 100 minor ones, only 10\\% of the population understands English, creating barriers to financial inclusion. We present a multilingual conversational AI system for a financial assistance use case that supports code-mixed languages like Hinglish, enabling natural interactions for India's diverse user base. Our system employs a multi-agent architecture with language classification, function management, and multilingual response generation. Through comparative analysis of multiple language models and real-world deployment, we demonstrate significant improvements in user engagement while maintaining low latency overhead (4-8\\%). This work contributes to bridging the language gap in digital financial services for emerging markets.",
    "published": "2025-12-01T09:23:13Z",
    "updated": "2025-12-01T09:23:13Z",
    "link": "http://arxiv.org/pdf/2512.01439v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Bharatdeep Hazarika",
      "Arya Suneesh",
      "Prasanna Devadiga",
      "Pawan Kumar Rajpoot",
      "Anshuman B Suresh",
      "Ahmed Ifthaquar Hussain"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.08579v2",
    "title": "LLM-based Human Simulations Have Not Yet Been Reliable",
    "summary": "Large Language Models (LLMs) are increasingly employed for simulating human behaviors across diverse domains. However, our position is that current LLM-based human simulations remain insufficiently reliable, as evidenced by significant discrepancies between their outcomes and authentic human actions. Our investigation begins with a systematic review of LLM-based human simulations in social, economic, policy, and psychological contexts, identifying their common frameworks, recent advances, and persistent limitations. This review reveals that such discrepancies primarily stem from inherent limitations of LLMs and flaws in simulation design, both of which are examined in detail. Building on these insights, we propose a systematic solution framework that emphasizes enriching data foundations, advancing LLM capabilities, and ensuring robust simulation design to enhance reliability. Finally, we introduce a structured algorithm that operationalizes the proposed framework, aiming to guide credible and human-aligned LLM-based simulations. To facilitate further research, we provide a curated list of related literature and resources at https://github.com/Persdre/awesome-llm-human-simulation.",
    "published": "2025-01-15T04:59:49Z",
    "updated": "2025-12-01T08:44:46Z",
    "link": "http://arxiv.org/pdf/2501.08579v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Qian Wang",
      "Jiaying Wu",
      "Zichen Jiang",
      "Zhenheng Tang",
      "Bingqiao Luo",
      "Nuo Chen",
      "Wei Chen",
      "Bingsheng He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01410v1",
    "title": "DyFuLM: An Advanced Multimodal Framework for Sentiment Analysis",
    "summary": "Understanding sentiment in complex textual expressions remains a fundamental challenge in affective computing. To address this, we propose a Dynamic Fusion Learning Model (DyFuLM), a multimodal framework designed to capture both hierarchical semantic representations and fine-grained emotional nuances. DyFuLM introduces two key moodules: a Hierarchical Dynamic Fusion module that adaptively integrates multi-level features, and a Gated Feature Aggregation module that regulates cross-layer information ffow to achieve balanced representation learning. Comprehensive experiments on multi-task sentiment datasets demonstrate that DyFuLM achieves 82.64% coarse-grained and 68.48% fine-grained accuracy, yielding the lowest regression errors (MAE = 0.0674, MSE = 0.0082) and the highest R^2 coefficient of determination (R^2= 0.6903). Furthermore, the ablation study validates the effectiveness of each module in DyFuLM. When all modules are removed, the accuracy drops by 0.91% for coarse-grained and 0.68% for fine-grained tasks. Keeping only the gated fusion module causes decreases of 0.75% and 0.55%, while removing the dynamic loss mechanism results in drops of 0.78% and 0.26% for coarse-grained and fine-grained sentiment classification, respectively. These results demonstrate that each module contributes significantly to feature interaction and task balance. Overall, the experimental findings further validate that DyFuLM enhances sentiment representation and overall performance through effective hierarchical feature fusion.",
    "published": "2025-12-01T08:30:10Z",
    "updated": "2025-12-01T08:30:10Z",
    "link": "http://arxiv.org/pdf/2512.01410v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Ruohan Zhou",
      "Jiachen Yuan",
      "Churui Yang",
      "Wenzheng Huang",
      "Guoyan Zhang",
      "Shiyao Wei",
      "Jiazhen Hu",
      "Ning Xin",
      "Md Maruf Hasan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01396v1",
    "title": "BackportBench: A Multilingual Benchmark for Automated Backporting of Patches",
    "summary": "Many modern software projects evolve rapidly to incorporate new features and security patches. It is important for users to update their dependencies to safer versions, but many still use older, vulnerable package versions because upgrading can be difficult and may break their existing codebase. Software developers can mitigate this problem by backporting security patches to older releases. However, manually backporting is time-consuming and error-prone. The effectiveness of existing automated backporting techniques on general software remains unclear since they typically target only code-hunk or function-level patch porting scenarios and are evaluated with imperfect metrics.\n  To facilitate the development and evaluation of automated backporting techniques, we introduce BackportBench, the first comprehensive benchmark suite for patch backporting problem. BackportBench is a multilingual benchmark that contains 202 patch backporting problems from PyPI, Maven, and npm, each with executable Docker environments and relevant test cases. We evaluated existing patch porting methods and LLM-based techniques that have the potential to adapt to this task using BackportBench. The results show that the agentic method has outperformed traditional patch porting methods, especially on cases that require logical and structural changes. However, the performance varies across different programming languages. Based on the findings, we draw several implications for researchers and software practitioners in future work on automated backporting.",
    "published": "2025-12-01T08:16:43Z",
    "updated": "2025-12-01T08:16:43Z",
    "link": "http://arxiv.org/pdf/2512.01396v1.pdf",
    "category": [
      "cs.SE",
      "cs.CL",
      "cs.CR"
    ],
    "authors": [
      "Zhiqing Zhong",
      "Jiaming Huang",
      "Pinjia He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01369v1",
    "title": "MARSAD: A Multi-Functional Tool for Real-Time Social Media Analysis",
    "summary": "MARSAD is a multifunctional natural language processing (NLP) platform designed for real-time social media monitoring and analysis, with a particular focus on the Arabic-speaking world. It enables researchers and non-technical users alike to examine both live and archived social media content, producing detailed visualizations and reports across various dimensions, including sentiment analysis, emotion analysis, propaganda detection, fact-checking, and hate speech detection. The platform also provides secure data-scraping capabilities through API keys for accessing public social media data. MARSAD's backend architecture integrates flexible document storage with structured data management, ensuring efficient processing of large and multimodal datasets. Its user-friendly frontend supports seamless data upload and interaction.",
    "published": "2025-12-01T07:31:37Z",
    "updated": "2025-12-01T07:31:37Z",
    "link": "http://arxiv.org/pdf/2512.01369v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Md. Rafiul Biswas",
      "Firoj Alam",
      "Wajdi Zaghouani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.22150v2",
    "title": "From Topology to Retrieval: Decoding Embedding Spaces with Unified Signatures",
    "summary": "Studying how embeddings are organized in space not only enhances model interpretability but also uncovers factors that drive downstream task performance. In this paper, we present a comprehensive analysis of topological and geometric measures across a wide set of text embedding models and datasets. We find a high degree of redundancy among these measures and observe that individual metrics often fail to sufficiently differentiate embedding spaces. Building on these insights, we introduce Unified Topological Signatures (UTS), a holistic framework for characterizing embedding spaces. We show that UTS can predict model-specific properties and reveal similarities driven by model architecture. Further, we demonstrate the utility of our method by linking topological structure to ranking effectiveness and accurately predicting document retrievability. We find that a holistic, multi-attribute perspective is essential to understanding and leveraging the geometry of text embeddings.",
    "published": "2025-11-27T06:37:45Z",
    "updated": "2025-12-01T06:39:02Z",
    "link": "http://arxiv.org/pdf/2511.22150v2.pdf",
    "category": [
      "cs.LG",
      "cs.CL",
      "cs.IR"
    ],
    "authors": [
      "Florian Rottach",
      "William Rudman",
      "Bastian Rieck",
      "Harrisen Scells",
      "Carsten Eickhoff"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01326v1",
    "title": "Securing Large Language Models (LLMs) from Prompt Injection Attacks",
    "summary": "Large Language Models (LLMs) are increasingly being deployed in real-world applications, but their flexibility exposes them to prompt injection attacks. These attacks leverage the model's instruction-following ability to make it perform malicious tasks. Recent work has proposed JATMO, a task-specific fine-tuning approach that trains non-instruction-tuned base models to perform a single function, thereby reducing susceptibility to adversarial instructions. In this study, we evaluate the robustness of JATMO against HOUYI, a genetic attack framework that systematically mutates and optimizes adversarial prompts. We adapt HOUYI by introducing custom fitness scoring, modified mutation logic, and a new harness for local model testing, enabling a more accurate assessment of defense effectiveness. We fine-tuned LLaMA 2-7B, Qwen1.5-4B, and Qwen1.5-0.5B models under the JATMO methodology and compared them with a fine-tuned GPT-3.5-Turbo baseline. Results show that while JATMO reduces attack success rates relative to instruction-tuned models, it does not fully prevent injections; adversaries exploiting multilingual cues or code-related disruptors still bypass defenses. We also observe a trade-off between generation quality and injection vulnerability, suggesting that better task performance often correlates with increased susceptibility. Our results highlight both the promise and limitations of fine-tuning-based defenses and point toward the need for layered, adversarially informed mitigation strategies.",
    "published": "2025-12-01T06:34:20Z",
    "updated": "2025-12-01T06:34:20Z",
    "link": "http://arxiv.org/pdf/2512.01326v1.pdf",
    "category": [
      "cs.CR",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Omar Farooq Khan Suri",
      "John McCrae"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.13671v3",
    "title": "HEALTH-PARIKSHA: Assessing RAG Models for Health Chatbots in Real-World Multilingual Settings",
    "summary": "Assessing the capabilities and limitations of large language models (LLMs) has garnered significant interest, yet the evaluation of multiple models in real-world scenarios remains rare. Multilingual evaluation often relies on translated benchmarks, which typically do not capture linguistic and cultural nuances present in the source language. This study provides an extensive assessment of 24 LLMs on real world data collected from Indian patients interacting with a medical chatbot in Indian English and 4 other Indic languages. We employ a uniform Retrieval Augmented Generation framework to generate responses, which are evaluated using both automated techniques and human evaluators on four specific metrics relevant to our application. We find that models vary significantly in their performance and that instruction tuned Indic models do not always perform well on Indic language queries. Further, we empirically show that factual correctness is generally lower for responses to Indic queries compared to English queries. Finally, our qualitative work shows that code-mixed and culturally relevant queries in our dataset pose challenges to evaluated models.",
    "published": "2024-10-17T15:29:57Z",
    "updated": "2025-12-01T05:41:48Z",
    "link": "http://arxiv.org/pdf/2410.13671v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Varun Gumma",
      "Ananditha Raghunath",
      "Mohit Jain",
      "Sunayana Sitaram"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.01016v4",
    "title": "Prompt-R1: Collaborative Automatic Prompting Framework via End-to-end Reinforcement Learning",
    "summary": "Recently, advanced large language models (LLMs) have emerged at an increasingly rapid pace. However, when faced with complex problems, most users are often unable to provide accurate and effective prompts to interact with LLMs, thus limiting the performance of LLMs. To address this challenge, we propose Prompt-R1, an end-to-end reinforcement learning framework that uses a small-scale LLM to collaborate with large-scale LLMs, replacing user interaction to solve problems better. This collaboration is cast as a multi-turn prompt interaction, where the small-scale LLM thinks and generates prompts, and the large-scale LLM performs complex reasoning. A dual-constrained reward is designed to optimize for correctness, generation quality, and reasoning accuracy. Prompt-R1 provides a plug-and-play framework that supports both inference and training with various large-scale LLMs. Experiments on multiple public datasets show that Prompt-R1 significantly outperforms baseline models across tasks. Our code is publicly available at https://github.com/QwenQKing/Prompt-R1.",
    "published": "2025-11-02T17:11:03Z",
    "updated": "2025-12-01T04:07:59Z",
    "link": "http://arxiv.org/pdf/2511.01016v4.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Wenjin Liu",
      "Haoran Luo",
      "Xueyuan Lin",
      "Haoming Liu",
      "Tiesunlong Shen",
      "Jiapu Wang",
      "Rui Mao",
      "Erik Cambria"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01255v1",
    "title": "Large Language Models Cannot Reliably Detect Vulnerabilities in JavaScript: The First Systematic Benchmark and Evaluation",
    "summary": "Researchers have proposed numerous methods to detect vulnerabilities in JavaScript, especially those assisted by Large Language Models (LLMs). However, the actual capability of LLMs in JavaScript vulnerability detection remains questionable, necessitating systematic evaluation and comprehensive benchmarks. Unfortunately, existing benchmarks suffer from three critical limitations: (1) incomplete coverage, such as covering a limited subset of CWE types; (2) underestimation of LLM capabilities caused by unreasonable ground truth labeling; and (3) overestimation due to unrealistic cases such as using isolated vulnerable files rather than complete projects.\n  In this paper, we introduce, for the first time, three principles for constructing a benchmark for JavaScript vulnerability detection that directly address these limitations: (1) comprehensiveness, (2) no underestimation, and (3) no overestimation. Guided by these principles, we propose FORGEJS, the first automatic benchmark generation framework for evaluating LLMs' capability in JavaScript vulnerability detection. Then, we use FORGEJS to construct ARENAJS-the first systematic benchmark for LLM-based JavaScript vulnerability detection-and further propose JUDGEJS, an automatic evaluation framework.\n  We conduct the first systematic evaluation of LLMs for JavaScript vulnerability detection, leveraging JUDGEJS to assess seven popular commercial LLMs on ARENAJS. The results show that LLMs not only exhibit limited reasoning capabilities, but also suffer from severe robustness defects, indicating that reliable JavaScript vulnerability detection with LLMs remains an open challenge.",
    "published": "2025-12-01T04:00:06Z",
    "updated": "2025-12-01T04:00:06Z",
    "link": "http://arxiv.org/pdf/2512.01255v1.pdf",
    "category": [
      "cs.CR",
      "cs.CL",
      "cs.SE"
    ],
    "authors": [
      "Qingyuan Fei",
      "Xin Liu",
      "Song Li",
      "Shujiang Wu",
      "Jianwei Hou",
      "Ping Chen",
      "Zifeng Kang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.18624v2",
    "title": "Checklists Are Better Than Reward Models For Aligning Language Models",
    "summary": "Language models must be adapted to understand and follow user instructions. Reinforcement learning is widely used to facilitate this -- typically using fixed criteria such as \"helpfulness\" and \"harmfulness\". In our work, we instead propose using flexible, instruction-specific criteria as a means of broadening the impact that reinforcement learning can have in eliciting instruction following. We propose \"Reinforcement Learning from Checklist Feedback\" (RLCF). From instructions, we extract checklists and evaluate how well responses satisfy each item - using both AI judges and specialized verifier programs - then combine these scores to compute rewards for RL. We compare RLCF with other alignment methods applied to a strong instruction following model (Qwen2.5-7B-Instruct) on five widely-studied benchmarks -- RLCF is the only method to improve performance on every benchmark, including a 4-point boost in hard satisfaction rate on FollowBench, a 6-point increase on InFoBench, and a 3-point rise in win rate on Arena-Hard. These results establish checklist feedback as a key tool for improving language models' support of queries that express a multitude of needs.",
    "published": "2025-07-24T17:58:00Z",
    "updated": "2025-12-01T03:32:07Z",
    "link": "http://arxiv.org/pdf/2507.18624v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Vijay Viswanathan",
      "Yanchao Sun",
      "Shuang Ma",
      "Xiang Kong",
      "Meng Cao",
      "Graham Neubig",
      "Tongshuang Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13043v3",
    "title": "Spark-Prover-X1: Formal Theorem Proving Through Diverse Data Training",
    "summary": "Large Language Models (LLMs) have shown significant promise in automated theorem proving, yet progress is often constrained by the scarcity of diverse and high-quality formal language data. To address this issue, we introduce Spark-Prover-X1, a 7B parameter model trained via an three-stage framework designed to unlock the reasoning potential of more accessible and moderately-sized LLMs. The first stage infuses deep knowledge through continuous pre-training on a broad mathematical corpus, enhanced by a suite of novel data tasks. Key innovation is a \"CoT-augmented state prediction\" task to achieve fine-grained reasoning. The second stage employs Supervised Fine-tuning (SFT) within an expert iteration loop to specialize both the Spark-Prover-X1-7B and Spark-Formalizer-X1-7B models. Finally, a targeted round of Group Relative Policy Optimization (GRPO) is applied to sharpen the prover's capabilities on the most challenging problems. To facilitate robust evaluation, particularly on problems from real-world examinations, we also introduce ExamFormal-Bench, a new benchmark dataset of 402 formal problems. Experimental results demonstrate that Spark-Prover achieves state-of-the-art performance among similarly-sized open-source models within the \"Whole-Proof Generation\" paradigm. It shows exceptional performance on difficult competition benchmarks, notably solving 27 problems on PutnamBench (pass@32) and achieving 24.0\\% on CombiBench (pass@32). Our work validates that this diverse training data and progressively refined training pipeline provides an effective path for enhancing the formal reasoning capabilities of lightweight LLMs. We will release both Spark-Prover-X1-7B and Spark-Formalizer-X1-7B, along with the ExamFormal-Bench dataset, in the near future.",
    "published": "2025-11-17T06:44:02Z",
    "updated": "2025-12-01T03:26:44Z",
    "link": "http://arxiv.org/pdf/2511.13043v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Xinyuan Zhou",
      "Yi Lei",
      "Xiaoyu Zhou",
      "Jingyi Sun",
      "Yu Zhu",
      "Zhongyi Ye",
      "Weitai Zhang",
      "Quan Liu",
      "Si Wei",
      "Cong Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01198v1",
    "title": "Conveying Imagistic Thinking in Traditional Chinese Medicine Translation: A Prompt Engineering and LLM-Based Evaluation Framework",
    "summary": "Traditional Chinese Medicine (TCM) theory is built on imagistic thinking, in which medical principles and diagnostic and therapeutic logic are structured through metaphor and metonymy. However, existing English translations largely rely on literal rendering, making it difficult for target-language readers to reconstruct the underlying conceptual networks and apply them in clinical practice. This study adopted a human-in-the-loop (HITL) framework and selected four passages from the medical canon Huangdi Neijing that are fundamental in theory. Through prompt-based cognitive scaffolding, DeepSeek V3.1 was guided to identify metaphor and metonymy in the source text and convey the theory in translation. In the evaluation stage, ChatGPT 5 Pro and Gemini 2.5 Pro were instructed by prompts to simulate three types of real-world readers. Human translations, baseline model translations, and prompt-adjusted translations were scored by the simulated readers across five cognitive dimensions, followed by structured interviews and Interpretative Phenomenological Analysis (IPA). Results show that the prompt-adjusted LLM translations perform best across all five dimensions, with high cross-model and cross-role consistency. The interview themes reveal differences between human and machine translation, effective strategies for metaphor and metonymy transfer, and readers' cognitive preferences. This study provides a cognitive, efficient, and replicable HITL methodological pathway for the translation of ancient, concept-dense texts such as TCM.",
    "published": "2025-12-01T02:27:44Z",
    "updated": "2025-12-01T02:27:44Z",
    "link": "http://arxiv.org/pdf/2512.01198v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Jiatong Han"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01191v1",
    "title": "Generalist Large Language Models Outperform Clinical Tools on Medical Benchmarks",
    "summary": "Specialized clinical AI assistants are rapidly entering medical practice, often framed as safer or more reliable than general-purpose large language models (LLMs). Yet, unlike frontier models, these clinical tools are rarely subjected to independent, quantitative evaluation, creating a critical evidence gap despite their growing influence on diagnosis, triage, and guideline interpretation. We assessed two widely deployed clinical AI systems (OpenEvidence and UpToDate Expert AI) against three state-of-the-art generalist LLMs (GPT-5, Gemini 3 Pro, and Claude Sonnet 4.5) using a 1,000-item mini-benchmark combining MedQA (medical knowledge) and HealthBench (clinician-alignment) tasks. Generalist models consistently outperformed clinical tools, with GPT-5 achieving the highest scores, while OpenEvidence and UpToDate demonstrated deficits in completeness, communication quality, context awareness, and systems-based safety reasoning. These findings reveal that tools marketed for clinical decision support may often lag behind frontier LLMs, underscoring the urgent need for transparent, independent evaluation before deployment in patient-facing workflows.",
    "published": "2025-12-01T02:14:43Z",
    "updated": "2025-12-01T02:14:43Z",
    "link": "http://arxiv.org/pdf/2512.01191v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Krithik Vishwanath",
      "Mrigayu Ghosh",
      "Anton Alyakin",
      "Daniel Alexander Alber",
      "Yindalon Aphinyanaphongs",
      "Eric Karl Oermann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01174v1",
    "title": "DrawingBench: Evaluating Spatial Reasoning and UI Interaction Capabilities of Large Language Models through Mouse-Based Drawing Tasks",
    "summary": "As agentic AI systems increasingly operate autonomously, establishing trust through verifiable evaluation becomes critical. Yet existing benchmarks lack the transparency and auditability needed to assess whether agents behave reliably. We present DrawingBench, a verification framework for evaluating the trustworthiness of agentic LLMs through spatial reasoning tasks that require generating sequences of low-level GUI actions. Unlike opaque evaluations, DrawingBench provides transparent, rule-based assessment: 8 objective criteria enable reproducible scoring, while action-level inspection allows stakeholders to audit agent behavior. Our framework comprises 250 diverse prompts across 20 categories and 4 difficulty levels, deterministic evaluation metrics, and an external oversight mechanism through multi-turn feedback that enables human control over agent refinement. Evaluating four state-of-the-art LLMs (Claude-4 Sonnet, GPT-4.1, GPT-4.1-mini, Gemini-2.5 Flash) across 1,000 tests, we establish both capabilities and limitations: models achieved 92.8% perfect performance with structured external feedback driving significant improvements (average +3.2%, up to +32.8% for complex scenes), but systematic error patterns emerged in tool state management and long-horizon planning. Notably, specification clarity proved more important than task complexity -- models achieved 100% perfect performance when given explicit, verifiable criteria. These findings demonstrate that transparent evaluation frameworks can establish trust in agentic systems, with external oversight proving more reliable than self-correction for guiding agent behavior. Our open-source framework provides a template for trustworthy agent assessment. Code and data: https://github.com/hyunjun1121/DrawingBench",
    "published": "2025-12-01T01:18:21Z",
    "updated": "2025-12-01T01:18:21Z",
    "link": "http://arxiv.org/pdf/2512.01174v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Hyunjun Kim",
      "Sooyoung Ryu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.19382v2",
    "title": "Measuring and Guiding Monosemanticity",
    "summary": "There is growing interest in leveraging mechanistic interpretability and controllability to better understand and influence the internal dynamics of large language models (LLMs). However, current methods face fundamental challenges in reliably localizing and manipulating feature representations. Sparse Autoencoders (SAEs) have recently emerged as a promising direction for feature extraction at scale, yet they, too, are limited by incomplete feature isolation and unreliable monosemanticity. To systematically quantify these limitations, we introduce Feature Monosemanticity Score (FMS), a novel metric to quantify feature monosemanticity in latent representation. Building on these insights, we propose Guided Sparse Autoencoders (G-SAE), a method that conditions latent representations on labeled concepts during training. We demonstrate that reliable localization and disentanglement of target concepts within the latent space improve interpretability, detection of behavior, and control. Specifically, our evaluations on toxicity detection, writing style identification, and privacy attribute recognition show that G-SAE not only enhances monosemanticity but also enables more effective and fine-grained steering with less quality degradation. Our findings provide actionable guidelines for measuring and advancing mechanistic interpretability and control of LLMs.",
    "published": "2025-06-24T07:18:20Z",
    "updated": "2025-12-01T00:31:38Z",
    "link": "http://arxiv.org/pdf/2506.19382v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Ruben Härle",
      "Felix Friedrich",
      "Manuel Brack",
      "Stephan Wäldchen",
      "Björn Deiseroth",
      "Patrick Schramowski",
      "Kristian Kersting"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.05239v3",
    "title": "LLM-based Automated Grading with Human-in-the-Loop",
    "summary": "The rise of artificial intelligence (AI) technologies, particularly large language models (LLMs), has brought significant advancements to the field of education. Among various applications, automatic short answer grading (ASAG), which focuses on evaluating open-ended textual responses, has seen remarkable progress with the introduction of LLMs. These models not only enhance grading performance compared to traditional ASAG approaches but also move beyond simple comparisons with predefined \"golden\" answers, enabling more sophisticated grading scenarios, such as rubric-based evaluation. However, existing LLM-powered methods still face challenges in achieving human-level grading performance in rubric-based assessments due to their reliance on fully automated approaches. In this work, we explore the potential of LLMs in ASAG tasks by leveraging their interactive capabilities through a human-in-the-loop (HITL) approach. Our proposed framework, GradeHITL, utilizes the generative properties of LLMs to pose questions to human experts, incorporating their insights to refine grading rubrics dynamically. This adaptive process significantly improves grading accuracy, outperforming existing methods and bringing ASAG closer to human-level evaluation.",
    "published": "2025-04-07T16:23:07Z",
    "updated": "2025-12-01T00:01:41Z",
    "link": "http://arxiv.org/pdf/2504.05239v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yucheng Chu",
      "Hang Li",
      "Kaiqi Yang",
      "Yasemin Copur-Gencturk",
      "Jiliang Tang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01109v1",
    "title": "How do we measure privacy in text? A survey of text anonymization metrics",
    "summary": "In this work, we aim to clarify and reconcile metrics for evaluating privacy protection in text through a systematic survey. Although text anonymization is essential for enabling NLP research and model development in domains with sensitive data, evaluating whether anonymization methods sufficiently protect privacy remains an open challenge. In manually reviewing 47 papers that report privacy metrics, we identify and compare six distinct privacy notions, and analyze how the associated metrics capture different aspects of privacy risk. We then assess how well these notions align with legal privacy standards (HIPAA and GDPR), as well as user-centered expectations grounded in HCI studies. Our analysis offers practical guidance on navigating the landscape of privacy evaluation approaches further and highlights gaps in current practices. Ultimately, we aim to facilitate more robust, comparable, and legally aware privacy evaluations in text anonymization.",
    "published": "2025-11-30T22:12:30Z",
    "updated": "2025-11-30T22:12:30Z",
    "link": "http://arxiv.org/pdf/2512.01109v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yaxuan Ren",
      "Krithika Ramesh",
      "Yaxing Yao",
      "Anjalie Field"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.17320v2",
    "title": "Comparative Evaluation of Expressive Japanese Character Text-to-Speech with VITS and Style-BERT-VITS2",
    "summary": "Synthesizing expressive Japanese character speech poses unique challenges due to pitch-accent sensitivity and stylistic variability. This paper empirically evaluates two open-source text-to-speech models--VITS and Style-BERT-VITS2 JP Extra (SBV2JE)--on in-domain, character-driven Japanese speech. Using three character-specific datasets, we evaluate models across naturalness (mean opinion and comparative mean opinion score), intelligibility (word error rate), and speaker consistency. SBV2JE matches human ground truth in naturalness (MOS 4.37 vs. 4.38), achieves lower WER, and shows slight preference in CMOS. Enhanced by pitch-accent controls and a WavLM-based discriminator, SBV2JE proves effective for applications like language learning and character dialogue generation, despite higher computational demands.",
    "published": "2025-05-22T22:18:55Z",
    "updated": "2025-11-30T22:04:18Z",
    "link": "http://arxiv.org/pdf/2505.17320v2.pdf",
    "category": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "authors": [
      "Zackary Rackauckas",
      "Julia Hirschberg"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.11973v2",
    "title": "Generating Text from Uniform Meaning Representation",
    "summary": "Uniform Meaning Representation (UMR) is a recently developed graph-based semantic representation, which expands on Abstract Meaning Representation (AMR) in a number of ways, in particular through the inclusion of document-level information and multilingual flexibility. In order to effectively adopt and leverage UMR for downstream tasks, efforts must be placed toward developing a UMR technological ecosystem. Though only a small amount of UMR annotations have been produced to date, in this work, we investigate the first approaches to producing text from multilingual UMR graphs. Exploiting the structural similarity between UMR and AMR graphs and the wide availability of AMR technologies, we introduce (1) a baseline approach which passes UMR graphs to AMR-to-text generation models, (2) a pipeline conversion of UMR to AMR, then using AMR-to-text generation models, and (3) a fine-tuning approach for both foundation models and AMR-to-text generation models with UMR data. Our best performing models achieve multilingual BERTscores of 0.825 for English and 0.882 for Chinese, a promising indication of the effectiveness of fine-tuning approaches for UMR-to-text generation even with limited UMR data.",
    "published": "2025-02-17T16:20:22Z",
    "updated": "2025-11-30T21:35:15Z",
    "link": "http://arxiv.org/pdf/2502.11973v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Emma Markle",
      "Reihaneh Iranmanesh",
      "Shira Wein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.12075v3",
    "title": "Do different prompting methods yield a common task representation in language models?",
    "summary": "Demonstrations and instructions are two primary approaches for prompting language models to perform in-context learning (ICL) tasks. Do identical tasks elicited in different ways result in similar representations of the task? An improved understanding of task representation mechanisms would offer interpretability insights and may aid in steering models. We study this through \\textit{function vectors} (FVs), recently proposed as a mechanism to extract few-shot ICL task representations. We generalize FVs to alternative task presentations, focusing on short textual instruction prompts, and successfully extract instruction function vectors that promote zero-shot task accuracy. We find evidence that demonstration- and instruction-based function vectors leverage different model components, and offer several controls to dissociate their contributions to task performance. Our results suggest that different task promptings forms do not induce a common task representation through FVs but elicit different, partly overlapping mechanisms. Our findings offer principled support to the practice of combining instructions and task demonstrations, imply challenges in universally monitoring task inference across presentation forms, and encourage further examinations of LLM task inference mechanisms.",
    "published": "2025-05-17T16:28:33Z",
    "updated": "2025-11-30T21:33:46Z",
    "link": "http://arxiv.org/pdf/2505.12075v3.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Guy Davidson",
      "Todd M. Gureckis",
      "Brenden M. Lake",
      "Adina Williams"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01085v1",
    "title": "Generalized Medical Phrase Grounding",
    "summary": "Medical phrase grounding (MPG) maps textual descriptions of radiological findings to corresponding image regions. These grounded reports are easier to interpret, especially for non-experts. Existing MPG systems mostly follow the referring expression comprehension (REC) paradigm and return exactly one bounding box per phrase. Real reports often violate this assumption. They contain multi-region findings, non-diagnostic text, and non-groundable phrases, such as negations or descriptions of normal anatomy. Motivated by this, we reformulate the task as generalised medical phrase grounding (GMPG), where each sentence is mapped to zero, one, or multiple scored regions. To realise this formulation, we introduce the first GMPG model: MedGrounder. We adopted a two-stage training regime: pre-training on report sentence--anatomy box alignment datasets and fine-tuning on report sentence--human annotated box datasets. Experiments on PadChest-GR and MS-CXR show that MedGrounder achieves strong zero-shot transfer and outperforms REC-style and grounded report generation baselines on multi-region and non-groundable phrases, while using far fewer human box annotations. Finally, we show that MedGrounder can be composed with existing report generators to produce grounded reports without retraining the generator.",
    "published": "2025-11-30T21:09:41Z",
    "updated": "2025-11-30T21:09:41Z",
    "link": "http://arxiv.org/pdf/2512.01085v1.pdf",
    "category": [
      "cs.CV",
      "cs.CL"
    ],
    "authors": [
      "Wenjun Zhang",
      "Shekhar S. Chandra",
      "Aaron Nicolson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01077v1",
    "title": "ELR-1000: A Community-Generated Dataset for Endangered Indic Indigenous Languages",
    "summary": "We present a culturally-grounded multimodal dataset of 1,060 traditional recipes crowdsourced from rural communities across remote regions of Eastern India, spanning 10 endangered languages. These recipes, rich in linguistic and cultural nuance, were collected using a mobile interface designed for contributors with low digital literacy. Endangered Language Recipes (ELR)-1000 -- captures not only culinary practices but also the socio-cultural context embedded in indigenous food traditions. We evaluate the performance of several state-of-the-art large language models (LLMs) on translating these recipes into English and find the following: despite the models' capabilities, they struggle with low-resource, culturally-specific language. However, we observe that providing targeted context -- including background information about the languages, translation examples, and guidelines for cultural preservation -- leads to significant improvements in translation quality. Our results underscore the need for benchmarks that cater to underrepresented languages and domains to advance equitable and culturally-aware language technologies. As part of this work, we release the ELR-1000 dataset to the NLP community, hoping it motivates the development of language technologies for endangered languages.",
    "published": "2025-11-30T20:51:20Z",
    "updated": "2025-11-30T20:51:20Z",
    "link": "http://arxiv.org/pdf/2512.01077v1.pdf",
    "category": [
      "cs.CL",
      "cs.HC"
    ],
    "authors": [
      "Neha Joshi",
      "Pamir Gogoi",
      "Aasim Mirza",
      "Aayush Jansari",
      "Aditya Yadavalli",
      "Ayushi Pandey",
      "Arunima Shukla",
      "Deepthi Sudharsan",
      "Kalika Bali",
      "Vivek Seshadri"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.12546v4",
    "title": "Extracting memorized pieces of (copyrighted) books from open-weight language models",
    "summary": "Plaintiffs and defendants in copyright lawsuits over generative AI often make sweeping, opposing claims about the extent to which large language models (LLMs) have memorized plaintiffs' protected expression in their training data. Drawing on both machine learning and copyright law, we show that these polarized positions dramatically oversimplify the relationship between memorization and copyright. To do so, we extend a recent probabilistic extraction technique to measure memorization of 50 books in 17 open-weight LLMs. Through thousands of experiments, we show that the extent of memorization varies both by model and by book. With respect to our specific extraction methodology, we find that most LLMs do not memorize most books -- either in whole or in part. However, we also find that Llama 3.1 70B entirely memorizes some books, like the first Harry Potter book and 1984. In fact, the first Harry Potter is so memorized that, using a seed prompt consisting of just the first few tokens of the first chapter, we can deterministically generate the entire book near-verbatim. We discuss why our results have significant implications for copyright cases, though not ones that unambiguously favor either side.",
    "published": "2025-05-18T21:06:32Z",
    "updated": "2025-11-30T20:06:45Z",
    "link": "http://arxiv.org/pdf/2505.12546v4.pdf",
    "category": [
      "cs.CL",
      "cs.CY",
      "cs.LG"
    ],
    "authors": [
      "A. Feder Cooper",
      "Aaron Gokaslan",
      "Ahmed Ahmed",
      "Amy B. Cyphert",
      "Christopher De Sa",
      "Mark A. Lemley",
      "Daniel E. Ho",
      "Percy Liang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01033v1",
    "title": "Associative Syntax and Maximal Repetitions reveal context-dependent complexity in fruit bat communication",
    "summary": "This study presents an unsupervised method to infer discreteness, syntax and temporal structures of fruit-bats vocalizations, as a case study of graded vocal systems, and evaluates the complexity of communication patterns in relation with behavioral context. The method improved the baseline for unsupervised labeling of vocal units (i.e. syllables) through manifold learning, by investigating how dimen- sionality reduction on mel-spectrograms affects labeling, and comparing it with unsupervised labels based on acoustic similarity. We then encoded vocalizations as syllabic sequences to analyze the type of syntax, and extracted the Maximal Repetitions (MRs) to evaluate syntactical structures. We found evidence for: i) associative syntax, rather than combinatorial (context classification is unaffected by permutation of sequences, F 1 > 0.9); ii) context-dependent use of syllables (Wilcoxon rank-sum tests, p-value < 0.05); iii) heavy-tail distribution of MRs (truncated power-law, exponent α < 2), indicative of mechanism encoding com- binatorial complexity. Analysis of MRs and syllabic transition networks revealed that mother-pupil interactions were characterized by repetitions, while commu- nication in conflict-contexts exhibited higher complexity (longer MRs and more interconnected vocal sequences) than non-agonistic contexts. We propose that communicative complexity is higher in scenarios of disagreement, reflecting lower compressibility of information.",
    "published": "2025-11-30T19:01:59Z",
    "updated": "2025-11-30T19:01:59Z",
    "link": "http://arxiv.org/pdf/2512.01033v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL",
      "cs.IT",
      "q-bio.QM"
    ],
    "authors": [
      "Luigi Assom"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.02018v1",
    "title": "Data-Centric Visual Development for Self-Driving Labs",
    "summary": "Self-driving laboratories offer a promising path toward reducing the labor-intensive, time-consuming, and often irreproducible workflows in the biological sciences. Yet their stringent precision requirements demand highly robust models whose training relies on large amounts of annotated data. However, this kind of data is difficult to obtain in routine practice, especially negative samples. In this work, we focus on pipetting, the most critical and precision sensitive action in SDLs. To overcome the scarcity of training data, we build a hybrid pipeline that fuses real and virtual data generation. The real track adopts a human-in-the-loop scheme that couples automated acquisition with selective human verification to maximize accuracy with minimal effort. The virtual track augments the real data using reference-conditioned, prompt-guided image generation, which is further screened and validated for reliability. Together, these two tracks yield a class-balanced dataset that enables robust bubble detection training. On a held-out real test set, a model trained entirely on automatically acquired real images reaches 99.6% accuracy, and mixing real and generated data during training sustains 99.4% accuracy while reducing collection and review load. Our approach offers a scalable and cost-effective strategy for supplying visual feedback data to SDL workflows and provides a practical solution to data scarcity in rare event detection and broader vision tasks.",
    "published": "2025-12-01T18:59:57Z",
    "updated": "2025-12-01T18:59:57Z",
    "link": "http://arxiv.org/pdf/2512.02018v1.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Anbang Liu",
      "Guanzhong Hu",
      "Jiayi Wang",
      "Ping Guo",
      "Han Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.02016v1",
    "title": "Objects in Generated Videos Are Slower Than They Appear: Models Suffer Sub-Earth Gravity and Don't Know Galileo's Principle...for now",
    "summary": "Video generators are increasingly evaluated as potential world models, which requires them to encode and understand physical laws. We investigate their representation of a fundamental law: gravity. Out-of-the-box video generators consistently generate objects falling at an effectively slower acceleration. However, these physical tests are often confounded by ambiguous metric scale. We first investigate if observed physical errors are artifacts of these ambiguities (e.g., incorrect frame rate assumptions). We find that even temporal rescaling cannot correct the high-variance gravity artifacts. To rigorously isolate the underlying physical representation from these confounds, we introduce a unit-free, two-object protocol that tests the timing ratio $t_1^2/t_2^2 = h_1/h_2$, a relationship independent of $g$, focal length, and scale. This relative test reveals violations of Galileo's equivalence principle. We then demonstrate that this physical gap can be partially mitigated with targeted specialization. A lightweight low-rank adaptor fine-tuned on only 100 single-ball clips raises $g_{\\mathrm{eff}}$ from $1.81\\,\\mathrm{m/s^2}$ to $6.43\\,\\mathrm{m/s^2}$ (reaching $65\\%$ of terrestrial gravity). This specialist adaptor also generalizes zero-shot to two-ball drops and inclined planes, offering initial evidence that specific physical laws can be corrected with minimal data.",
    "published": "2025-12-01T18:59:56Z",
    "updated": "2025-12-01T18:59:56Z",
    "link": "http://arxiv.org/pdf/2512.02016v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Varun Varma Thozhiyoor",
      "Shivam Tripathi",
      "Venkatesh Babu Radhakrishnan",
      "Anand Bhattad"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.02015v1",
    "title": "Generative Video Motion Editing with 3D Point Tracks",
    "summary": "Camera and object motions are central to a video's narrative. However, precisely editing these captured motions remains a significant challenge, especially under complex object movements. Current motion-controlled image-to-video (I2V) approaches often lack full-scene context for consistent video editing, while video-to-video (V2V) methods provide viewpoint changes or basic object translation, but offer limited control over fine-grained object motion. We present a track-conditioned V2V framework that enables joint editing of camera and object motion. We achieve this by conditioning a video generation model on a source video and paired 3D point tracks representing source and target motions. These 3D tracks establish sparse correspondences that transfer rich context from the source video to new motions while preserving spatiotemporal coherence. Crucially, compared to 2D tracks, 3D tracks provide explicit depth cues, allowing the model to resolve depth order and handle occlusions for precise motion editing. Trained in two stages on synthetic and real data, our model supports diverse motion edits, including joint camera/object manipulation, motion transfer, and non-rigid deformation, unlocking new creative potential in video editing.",
    "published": "2025-12-01T18:59:55Z",
    "updated": "2025-12-01T18:59:55Z",
    "link": "http://arxiv.org/pdf/2512.02015v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yao-Chih Lee",
      "Zhoutong Zhang",
      "Jiahui Huang",
      "Jui-Hsien Wang",
      "Joon-Young Lee",
      "Jia-Bin Huang",
      "Eli Shechtman",
      "Zhengqi Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.02014v1",
    "title": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models",
    "summary": "Unified multimodal models (UMMs) aim to jointly perform multimodal understanding and generation within a single framework. We present TUNA, a native UMM that builds a unified continuous visual representation by cascading a VAE encoder with a representation encoder. This unified representation space allows end-to-end processing of images and videos for both understanding and generation tasks. Compared to prior UMMs with decoupled representations, TUNA's unified visual space avoids representation format mismatches introduced by separate encoders, outperforming decoupled alternatives in both understanding and generation. Moreover, we observe that stronger pretrained representation encoders consistently yield better performance across all multimodal tasks, highlighting the importance of the representation encoder. Finally, in this unified setting, jointly training on both understanding and generation data allows the two tasks to benefit from each other rather than interfere. Our extensive experiments on multimodal understanding and generation benchmarks show that TUNA achieves state-of-the-art results in image and video understanding, image and video generation, and image editing, demonstrating the effectiveness and scalability of its unified representation design.",
    "published": "2025-12-01T18:59:51Z",
    "updated": "2025-12-01T18:59:51Z",
    "link": "http://arxiv.org/pdf/2512.02014v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhiheng Liu",
      "Weiming Ren",
      "Haozhe Liu",
      "Zijian Zhou",
      "Shoufa Chen",
      "Haonan Qiu",
      "Xiaoke Huang",
      "Zhaochong An",
      "Fanny Yang",
      "Aditya Patel",
      "Viktar Atliha",
      "Tony Ng",
      "Xiao Han",
      "Chuyan Zhu",
      "Chenyang Zhang",
      "Ding Liu",
      "Juan-Manuel Perez-Rua",
      "Sen He",
      "Jürgen Schmidhuber",
      "Wenhu Chen",
      "Ping Luo",
      "Wei Liu",
      "Tao Xiang",
      "Jonas Schult",
      "Yuren Cong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.02012v1",
    "title": "Improved Mean Flows: On the Challenges of Fastforward Generative Models",
    "summary": "MeanFlow (MF) has recently been established as a framework for one-step generative modeling. However, its ``fastforward'' nature introduces key challenges in both the training objective and the guidance mechanism. First, the original MF's training target depends not only on the underlying ground-truth fields but also on the network itself. To address this issue, we recast the objective as a loss on the instantaneous velocity $v$, re-parameterized by a network that predicts the average velocity $u$. Our reformulation yields a more standard regression problem and improves the training stability. Second, the original MF fixes the classifier-free guidance scale during training, which sacrifices flexibility. We tackle this issue by formulating guidance as explicit conditioning variables, thereby retaining flexibility at test time. The diverse conditions are processed through in-context conditioning, which reduces model size and benefits performance. Overall, our $\\textbf{improved MeanFlow}$ ($\\textbf{iMF}$) method, trained entirely from scratch, achieves $\\textbf{1.72}$ FID with a single function evaluation (1-NFE) on ImageNet 256$\\times$256. iMF substantially outperforms prior methods of this kind and closes the gap with multi-step methods while using no distillation. We hope our work will further advance fastforward generative modeling as a stand-alone paradigm.",
    "published": "2025-12-01T18:59:49Z",
    "updated": "2025-12-01T18:59:49Z",
    "link": "http://arxiv.org/pdf/2512.02012v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Zhengyang Geng",
      "Yiyang Lu",
      "Zongze Wu",
      "Eli Shechtman",
      "J. Zico Kolter",
      "Kaiming He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.02009v1",
    "title": "AirSim360: A Panoramic Simulation Platform within Drone View",
    "summary": "The field of 360-degree omnidirectional understanding has been receiving increasing attention for advancing spatial intelligence. However, the lack of large-scale and diverse data remains a major limitation. In this work, we propose AirSim360, a simulation platform for omnidirectional data from aerial viewpoints, enabling wide-ranging scene sampling with drones. Specifically, AirSim360 focuses on three key aspects: a render-aligned data and labeling paradigm for pixel-level geometric, semantic, and entity-level understanding; an interactive pedestrian-aware system for modeling human behavior; and an automated trajectory generation paradigm to support navigation tasks. Furthermore, we collect more than 60K panoramic samples and conduct extensive experiments across various tasks to demonstrate the effectiveness of our simulator. Unlike existing simulators, our work is the first to systematically model the 4D real world under an omnidirectional setting. The entire platform, including the toolkit, plugins, and collected datasets, will be made publicly available at https://insta360-research-team.github.io/AirSim360-website.",
    "published": "2025-12-01T18:59:30Z",
    "updated": "2025-12-01T18:59:30Z",
    "link": "http://arxiv.org/pdf/2512.02009v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xian Ge",
      "Yuling Pan",
      "Yuhang Zhang",
      "Xiang Li",
      "Weijun Zhang",
      "Dizhe Zhang",
      "Zhaoliang Wan",
      "Xin Lin",
      "Xiangkai Zhang",
      "Juntao Liang",
      "Jason Li",
      "Wenjie Jiang",
      "Bo Du",
      "Ming-Hsuan Yang",
      "Lu Qi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.02006v1",
    "title": "MV-TAP: Tracking Any Point in Multi-View Videos",
    "summary": "Multi-view camera systems enable rich observations of complex real-world scenes, and understanding dynamic objects in multi-view settings has become central to various applications. In this work, we present MV-TAP, a novel point tracker that tracks points across multi-view videos of dynamic scenes by leveraging cross-view information. MV-TAP utilizes camera geometry and a cross-view attention mechanism to aggregate spatio-temporal information across views, enabling more complete and reliable trajectory estimation in multi-view videos. To support this task, we construct a large-scale synthetic training dataset and real-world evaluation sets tailored for multi-view tracking. Extensive experiments demonstrate that MV-TAP outperforms existing point-tracking methods on challenging benchmarks, establishing an effective baseline for advancing research in multi-view point tracking.",
    "published": "2025-12-01T18:59:01Z",
    "updated": "2025-12-01T18:59:01Z",
    "link": "http://arxiv.org/pdf/2512.02006v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jahyeok Koo",
      "Inès Hyeonsu Kim",
      "Mungyeom Kim",
      "Junghyun Park",
      "Seohyun Park",
      "Jaeyeong Kim",
      "Jung Yi",
      "Seokju Cho",
      "Seungryong Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.02005v1",
    "title": "Learning Visual Affordance from Audio",
    "summary": "We introduce Audio-Visual Affordance Grounding (AV-AG), a new task that segments object interaction regions from action sounds. Unlike existing approaches that rely on textual instructions or demonstration videos, which often limited by ambiguity or occlusion, audio provides real-time, semantically rich, and visually independent cues for affordance grounding, enabling more intuitive understanding of interaction regions. To support this task, we construct the first AV-AG dataset, comprising a large collection of action sounds, object images, and pixel-level affordance annotations. The dataset also includes an unseen subset to evaluate zero-shot generalization. Furthermore, we propose AVAGFormer, a model equipped with a semantic-conditioned cross-modal mixer and a dual-head decoder that effectively fuses audio and visual signals for mask prediction. Experiments show that AVAGFormer achieves state-of-the-art performance on AV-AG, surpassing baselines from related tasks. Comprehensive analyses highlight the distinctions between AV-AG and AVS, the benefits of end-to-end modeling, and the contribution of each component. Code and dataset have been released on https://jscslld.github.io/AVAGFormer/.",
    "published": "2025-12-01T18:58:56Z",
    "updated": "2025-12-01T18:58:56Z",
    "link": "http://arxiv.org/pdf/2512.02005v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Lidong Lu",
      "Guo Chen",
      "Zhu Wei",
      "Yicheng Liu",
      "Tong Lu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.07863v2",
    "title": "VIVAT: Virtuous Improving VAE Training through Artifact Mitigation",
    "summary": "Variational Autoencoders (VAEs) remain a cornerstone of generative computer vision, yet their training is often plagued by artifacts that degrade reconstruction and generation quality. This paper introduces VIVAT, a systematic approach to mitigating common artifacts in KL-VAE training without requiring radical architectural changes. We present a detailed taxonomy of five prevalent artifacts - color shift, grid patterns, blur, corner and droplet artifacts - and analyze their root causes. Through straightforward modifications, including adjustments to loss weights, padding strategies, and the integration of Spatially Conditional Normalization, we demonstrate significant improvements in VAE performance. Our method achieves state-of-the-art results in image reconstruction metrics (PSNR and SSIM) across multiple benchmarks and enhances text-to-image generation quality, as evidenced by superior CLIP scores. By preserving the simplicity of the KL-VAE framework while addressing its practical challenges, VIVAT offers actionable insights for researchers and practitioners aiming to optimize VAE training.",
    "published": "2025-06-09T15:27:03Z",
    "updated": "2025-12-01T18:51:34Z",
    "link": "http://arxiv.org/pdf/2506.07863v2.pdf",
    "category": [
      "cs.CV",
      "cs.LG",
      "cs.MM"
    ],
    "authors": [
      "Lev Novitskiy",
      "Viacheslav Vasilev",
      "Maria Kovaleva",
      "Vladimir Arkhipkin",
      "Denis Dimitrov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.09771v2",
    "title": "STORM: Segment, Track, and Object Re-Localization from a Single Image",
    "summary": "Accurate 6D pose estimation and tracking are fundamental capabilities for physical AI systems such as robots. However, existing approaches typically require a pre-defined 3D model of the target and rely on a manually annotated segmentation mask in the first frame, which is labor-intensive and leads to reduced performance when faced with occlusions or rapid movement. To address these limitations, we propose STORM (Segment, Track, and Object Re-localization from a single iMage), an open-source robust real-time 6D pose estimation system that requires no manual annotation. STORM employs a novel three-stage pipeline combining vision-language understanding with feature matching: contextual object descriptions guide localization, self-cross-attention mechanisms identify candidate regions, and produce precise masks and 3D models for accurate pose estimation. Another key innovation is our automatic re-registration mechanism that detects tracking failures through feature similarity monitoring and recovers from severe occlusions or rapid motion. STORM achieves state-of-the-art accuracy on challenging industrial datasets featuring multi-object occlusions, high-speed motion, and varying illumination, while operating at real-time speeds without additional training. This annotation-free approach significantly reduces deployment overhead, providing a practical solution for modern applications, such as flexible manufacturing and intelligent quality control.",
    "published": "2025-11-12T22:06:51Z",
    "updated": "2025-12-01T18:48:10Z",
    "link": "http://arxiv.org/pdf/2511.09771v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yu Deng",
      "Teng Cao",
      "Hikaru Shindo",
      "Jiahong Xue",
      "Quentin Delfosse",
      "Kristian Kersting"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01989v1",
    "title": "PAI-Bench: A Comprehensive Benchmark For Physical AI",
    "summary": "Physical AI aims to develop models that can perceive and predict real-world dynamics; yet, the extent to which current multi-modal large language models and video generative models support these abilities is insufficiently understood. We introduce Physical AI Bench (PAI-Bench), a unified and comprehensive benchmark that evaluates perception and prediction capabilities across video generation, conditional video generation, and video understanding, comprising 2,808 real-world cases with task-aligned metrics designed to capture physical plausibility and domain-specific reasoning. Our study provides a systematic assessment of recent models and shows that video generative models, despite strong visual fidelity, often struggle to maintain physically coherent dynamics, while multi-modal large language models exhibit limited performance in forecasting and causal interpretation. These observations suggest that current systems are still at an early stage in handling the perceptual and predictive demands of Physical AI. In summary, PAI-Bench establishes a realistic foundation for evaluating Physical AI and highlights key gaps that future systems must address.",
    "published": "2025-12-01T18:47:39Z",
    "updated": "2025-12-01T18:47:39Z",
    "link": "http://arxiv.org/pdf/2512.01989v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Fengzhe Zhou",
      "Jiannan Huang",
      "Jialuo Li",
      "Deva Ramanan",
      "Humphrey Shi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2408.07867v2",
    "title": "Continuous Perception Matters: Diagnosing Temporal Integration Failures in Multimodal Models",
    "summary": "Continuous perception, the ability to integrate visual observations over time in a continuous stream fashion, is essential for robust real-world understanding, yet remains largely untested in current multimodal models. We introduce CP-Bench, a minimal and fully controlled benchmark designed to isolate this capability using an extremely simple task: counting identical cubes in a synthetic scene while the camera moves and only reveals subsets of objects at any moment. Despite the simplicity of the setting, we find that state-of-the-art open-source and commercial models, including Qwen-3-VL, InternVL3, GPT-5, and Gemini-3-Pro, fail dramatically. A static-camera control variant confirms that the failure arises not from object recognition but from an inability to accumulate evidence across time. Further experiments show that neither higher sampling FPS, perception- or spatial-enhanced models, nor finetuning with additional videos leads to meaningful cross-temporal generalization. Our results reveal a fundamental limitation in modern multimodal architectures and training paradigms. CP-Bench provides a simple yet powerful diagnostic tool and establishes a clean testbed for developing models capable of genuine time-consistent visual reasoning.",
    "published": "2024-08-15T00:45:21Z",
    "updated": "2025-12-01T18:46:42Z",
    "link": "http://arxiv.org/pdf/2408.07867v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zeyu Wang",
      "Zhenzhen Weng",
      "Serena Yeung-Levy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01988v1",
    "title": "Artemis: Structured Visual Reasoning for Perception Policy Learning",
    "summary": "Recent reinforcement-learning frameworks for visual perception policy have begun to incorporate intermediate reasoning chains expressed in natural language. Empirical observations indicate that such purely linguistic intermediate reasoning often reduces performance on perception tasks. We argue that the core issue lies not in reasoning per se but in the form of reasoning: while these chains perform semantic reasoning in an unstructured linguistic space, visual perception requires reasoning in a spatial and object-centric space. In response, we introduce Artemis, a perception-policy learning framework that performs structured proposal-based reasoning, where each intermediate step is represented as a (label, bounding-box) pair capturing a verifiable visual state. This design enables explicit tracking of intermediate states, direct supervision for proposal quality, and avoids ambiguity introduced by language-based reasoning. Artemis is built on Qwen2.5-VL-3B, achieves strong performance on grounding and detection task and exhibits substantial generalization to counting and geometric-perception tasks. The consistent improvements across these diverse settings confirm that aligning reasoning with spatial representations enhances perception-policy learning. Owing to its strengthened visual reasoning, Artemis also achieves competitive performance on general MLLM benchmarks, illustrating that spatially grounded reasoning provides a principled route toward scalable and general perception policies.",
    "published": "2025-12-01T18:45:30Z",
    "updated": "2025-12-01T18:45:30Z",
    "link": "http://arxiv.org/pdf/2512.01988v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Wei Tang",
      "Yanpeng Sun",
      "Shan Zhang",
      "Xiaofan Li",
      "Piotr Koniusz",
      "Wei Li",
      "Na Zhao",
      "Zechao Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.04325v4",
    "title": "GBT-SAM: A Parameter-Efficient Depth-Aware Model for Generalizable Brain tumour Segmentation on mp-MRI",
    "summary": "Gliomas are aggressive brain tumors that require accurate imaging-based diagnosis, with segmentation playing a critical role in evaluating morphology and treatment decisions. Manual delineation of gliomas is time-consuming and prone to variability, motivating the use of deep learning to improve consistency and alleviate clinical workload. However, existing methods often fail to fully exploit the information available in multi-parametric MRI (mp-MRI), particularly inter-slice contextual features, and typically require considerable computational resources while lacking robustness across tumor type variations. We present GBT-SAM, a parameter-efficient deep learning framework that adapts the Segment Anything Model (SAM), a large-scale vision model, to volumetric mp-MRI data. GBT-SAM reduces input complexity by selecting fewer than 2.6\\% of slices per scan while incorporating all four MRI modalities, preserving essential tumor-related information with minimal cost. Furthermore, our model is trained by a two-step fine-tuning strategy that incorporates a depth-aware module to capture inter-slice correlations and lightweight adaptation layers, resulting in just 6.5M trainable parameters, which is the lowest among SAM-based approaches. GBT-SAM achieves a Dice Score of 93.54 on the BraTS Adult Glioma dataset and demonstrates robust performance on Meningioma, Pediatric Glioma, and Sub-Saharan Glioma datasets. These results highlight GBT-SAM's potential as a computationally efficient and domain-robust framework for brain tumor segmentation using mp-MRI. Our code and models are available at https://github.com/vpulab/med-sam-brain .",
    "published": "2025-03-06T11:18:22Z",
    "updated": "2025-12-01T18:41:01Z",
    "link": "http://arxiv.org/pdf/2503.04325v4.pdf",
    "category": [
      "eess.IV",
      "cs.CV"
    ],
    "authors": [
      "Cecilia Diana-Albelda",
      "Roberto Alcover-Couso",
      "Álvaro García-Martín",
      "Jesus Bescos",
      "Marcos Escudero-Viñolo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.23127v2",
    "title": "DualCamCtrl: Dual-Branch Diffusion Model for Geometry-Aware Camera-Controlled Video Generation",
    "summary": "This paper presents DualCamCtrl, a novel end-to-end diffusion model for camera-controlled video generation. Recent works have advanced this field by representing camera poses as ray-based conditions, yet they often lack sufficient scene understanding and geometric awareness. DualCamCtrl specifically targets this limitation by introducing a dual-branch framework that mutually generates camera-consistent RGB and depth sequences. To harmonize these two modalities, we further propose the Semantic Guided Mutual Alignment (SIGMA) mechanism, which performs RGB-depth fusion in a semantics-guided and mutually reinforced manner. These designs collectively enable DualCamCtrl to better disentangle appearance and geometry modeling, generating videos that more faithfully adhere to the specified camera trajectories. Additionally, we analyze and reveal the distinct influence of depth and camera poses across denoising stages and further demonstrate that early and late stages play complementary roles in forming global structure and refining local details. Extensive experiments demonstrate that DualCamCtrl achieves more consistent camera-controlled video generation, with over 40\\% reduction in camera motion errors compared with prior methods. Our project page: https://soyouthinkyoucantell.github.io/dualcamctrl-page/",
    "published": "2025-11-28T12:19:57Z",
    "updated": "2025-12-01T18:39:32Z",
    "link": "http://arxiv.org/pdf/2511.23127v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Hongfei Zhang",
      "Kanghao Chen",
      "Zixin Zhang",
      "Harold Haodong Chen",
      "Yuanhuiyi Lyu",
      "Yuqi Zhang",
      "Shuai Yang",
      "Kun Zhou",
      "Yingcong Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01975v1",
    "title": "SGDiff: Scene Graph Guided Diffusion Model for Image Collaborative SegCaptioning",
    "summary": "Controllable image semantic understanding tasks, such as captioning or segmentation, necessitate users to input a prompt (e.g., text or bounding boxes) to predict a unique outcome, presenting challenges such as high-cost prompt input or limited information output. This paper introduces a new task ``Image Collaborative Segmentation and Captioning'' (SegCaptioning), which aims to translate a straightforward prompt, like a bounding box around an object, into diverse semantic interpretations represented by (caption, masks) pairs, allowing flexible result selection by users. This task poses significant challenges, including accurately capturing a user's intention from a minimal prompt while simultaneously predicting multiple semantically aligned caption words and masks. Technically, we propose a novel Scene Graph Guided Diffusion Model that leverages structured scene graph features for correlated mask-caption prediction. Initially, we introduce a Prompt-Centric Scene Graph Adaptor to map a user's prompt to a scene graph, effectively capturing his intention. Subsequently, we employ a diffusion process incorporating a Scene Graph Guided Bimodal Transformer to predict correlated caption-mask pairs by uncovering intricate correlations between them. To ensure accurate alignment, we design a Multi-Entities Contrastive Learning loss to explicitly align visual and textual entities by considering inter-modal similarity, resulting in well-aligned caption-mask pairs. Extensive experiments conducted on two datasets demonstrate that SGDiff achieves superior performance in SegCaptioning, yielding promising results for both captioning and segmentation tasks with minimal prompt input.",
    "published": "2025-12-01T18:33:04Z",
    "updated": "2025-12-01T18:33:04Z",
    "link": "http://arxiv.org/pdf/2512.01975v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xu Zhang",
      "Jin Yuan",
      "Hanwang Zhang",
      "Guojin Zhong",
      "Yongsheng Zang",
      "Jiacheng Lin",
      "Zhiyong Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.22294v2",
    "title": "Structure is Supervision: Multiview Masked Autoencoders for Radiology",
    "summary": "Building robust medical machine learning systems requires pretraining strategies that exploit the intrinsic structure present in clinical data. We introduce Multiview Masked Autoencoder (MVMAE), a self-supervised framework that leverages the natural multi-view organization of radiology studies to learn view-invariant and disease-relevant representations. MVMAE combines masked image reconstruction with cross-view alignment, transforming clinical redundancy across projections into a powerful self-supervisory signal. We further extend this approach with MVMAE-V2T, which incorporates radiology reports as an auxiliary text-based learning signal to enhance semantic grounding while preserving fully vision-based inference. Evaluated on a downstream disease classification task on three large-scale public datasets, MIMIC-CXR, CheXpert, and PadChest, MVMAE consistently outperforms supervised and vision-language baselines. Furthermore, MVMAE-V2T provides additional gains, particularly in low-label regimes where structured textual supervision is most beneficial. Together, these results establish the importance of structural and textual supervision as complementary paths toward scalable, clinically grounded medical foundation models.",
    "published": "2025-11-27T10:20:51Z",
    "updated": "2025-12-01T18:27:37Z",
    "link": "http://arxiv.org/pdf/2511.22294v2.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Sonia Laguna",
      "Andrea Agostini",
      "Alain Ryser",
      "Samuel Ruiperez-Campillo",
      "Irene Cannistraci",
      "Moritz Vandenhirtz",
      "Stephan Mandt",
      "Nicolas Deperrois",
      "Farhad Nooralahzadeh",
      "Michael Krauthammer",
      "Thomas M. Sutter",
      "Julia E. Vogt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01960v1",
    "title": "SpriteHand: Real-Time Versatile Hand-Object Interaction with Autoregressive Video Generation",
    "summary": "Modeling and synthesizing complex hand-object interactions remains a significant challenge, even for state-of-the-art physics engines. Conventional simulation-based approaches rely on explicitly defined rigid object models and pre-scripted hand gestures, making them inadequate for capturing dynamic interactions with non-rigid or articulated entities such as deformable fabrics, elastic materials, hinge-based structures, furry surfaces, or even living creatures. In this paper, we present SpriteHand, an autoregressive video generation framework for real-time synthesis of versatile hand-object interaction videos across a wide range of object types and motion patterns. SpriteHand takes as input a static object image and a video stream in which the hands are imagined to interact with the virtual object embedded in a real-world scene, and generates corresponding hand-object interaction effects in real time. Our model employs a causal inference architecture for autoregressive generation and leverages a hybrid post-training approach to enhance visual realism and temporal coherence. Our 1.3B model supports real-time streaming generation at around 18 FPS and 640x368 resolution, with an approximate 150 ms latency on a single NVIDIA RTX 5090 GPU, and more than a minute of continuous output. Experiments demonstrate superior visual quality, physical plausibility, and interaction fidelity compared to both generative and engine-based baselines.",
    "published": "2025-12-01T18:13:40Z",
    "updated": "2025-12-01T18:13:40Z",
    "link": "http://arxiv.org/pdf/2512.01960v1.pdf",
    "category": [
      "cs.CV",
      "cs.HC"
    ],
    "authors": [
      "Zisu Li",
      "Hengye Lyu",
      "Jiaxin Shi",
      "Yufeng Zeng",
      "Mingming Fan",
      "Hanwang Zhang",
      "Chen Liang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.00727v2",
    "title": "Adaptive Plane Reformatting for 4D Flow MRI using Deep Reinforcement Learning",
    "summary": "Background and Objective: Plane reformatting for four-dimensional phase contrast MRI (4D flow MRI) is time-consuming and prone to inter-observer variability, which limits fast cardiovascular flow assessment. Deep reinforcement learning (DRL) trains agents to iteratively adjust plane position and orientation, enabling accurate plane reformatting without the need for detailed landmarks, making it suitable for images with limited contrast and resolution such as 4D flow MRI. However, current DRL methods assume that test volumes share the same spatial alignment as the training data, limiting generalization across scanners and institutions. To address this limitation, we introduce AdaPR (Adaptive Plane Reformatting), a DRL framework that uses a local coordinate system to navigate volumes with arbitrary positions and orientations.\n  Methods: We implemented AdaPR using the Asynchronous Advantage Actor-Critic (A3C) algorithm and validated it on 88 4D flow MRI datasets acquired from multiple vendors, including patients with congenital heart disease.\n  Results: AdaPR achieved a mean angular error of 6.32 +/- 4.15 degrees and a distance error of 3.40 +/- 2.75 mm, outperforming global-coordinate DRL methods and alternative non-DRL methods. AdaPR maintained consistent accuracy under different volume orientations and positions. Flow measurements from AdaPR planes showed no significant differences compared to two manual observers, with excellent correlation (R^2 = 0.972 and R^2 = 0.968), comparable to inter-observer agreement (R^2 = 0.969).\n  Conclusion: AdaPR provides robust, orientation-independent plane reformatting for 4D flow MRI, achieving flow quantification comparable to expert observers. Its adaptability across datasets and scanners makes it a promising candidate for medical imaging applications beyond 4D flow MRI.",
    "published": "2025-05-31T22:02:05Z",
    "updated": "2025-12-01T18:13:13Z",
    "link": "http://arxiv.org/pdf/2506.00727v2.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Javier Bisbal",
      "Julio Sotelo",
      "Maria I Valdés",
      "Pablo Irarrazaval",
      "Marcelo E Andia",
      "Julio García",
      "José Rodriguez-Palomarez",
      "Francesca Raimondi",
      "Cristián Tejos",
      "Sergio Uribe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01949v1",
    "title": "Script: Graph-Structured and Query-Conditioned Semantic Token Pruning for Multimodal Large Language Models",
    "summary": "The rapid growth of visual tokens in multimodal large language models (MLLMs) leads to excessive memory consumption and inference latency, especially when handling high-resolution images and videos. Token pruning is a technique used to mitigate this issue by removing redundancy, but existing methods often ignore relevance to the user query or suffer from the limitations of attention mechanisms, reducing their adaptability and effectiveness. To address these challenges, we propose Script, a plug-and-play pruning method that requires no retraining and generalizes across diverse MLLMs. Script comprises two modules: a graph-structured pruning module that removes visually redundant tokens, and a query-conditioned semantic pruning module that preserves query-relevant visual information. Together, they enhance performance on multimodal tasks. Experiments on fourteen benchmarks across image and video understanding tasks show that Script consistently achieves higher model efficiency and predictive accuracy compared to existing pruning methods. On LLaVA-NeXT-7B, it achieves up to 6.8x prefill speedup and 10x FLOP reduction, while retaining 96.88% of the original performance.",
    "published": "2025-12-01T17:59:11Z",
    "updated": "2025-12-01T17:59:11Z",
    "link": "http://arxiv.org/pdf/2512.01949v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhongyu Yang",
      "Dannong Xu",
      "Wei Pang",
      "Yingfang Yuan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01946v1",
    "title": "Guardian: Detecting Robotic Planning and Execution Errors with Vision-Language Models",
    "summary": "Robust robotic manipulation requires reliable failure detection and recovery. Although current Vision-Language Models (VLMs) show promise, their accuracy and generalization are limited by the scarcity of failure data. To address this data gap, we propose an automatic robot failure synthesis approach that procedurally perturbs successful trajectories to generate diverse planning and execution failures. This method produces not only binary classification labels but also fine-grained failure categories and step-by-step reasoning traces in both simulation and the real world. With it, we construct three new failure detection benchmarks: RLBench-Fail, BridgeDataV2-Fail, and UR5-Fail, substantially expanding the diversity and scale of existing failure datasets. We then train Guardian, a VLM with multi-view images for detailed failure reasoning and detection. Guardian achieves state-of-the-art performance on both existing and newly introduced benchmarks. It also effectively improves task success rates when integrated into a state-of-the-art manipulation system in simulation and real robots, demonstrating the impact of our generated failure data.",
    "published": "2025-12-01T17:57:27Z",
    "updated": "2025-12-01T17:57:27Z",
    "link": "http://arxiv.org/pdf/2512.01946v1.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Paul Pacaud",
      "Ricardo Garcia",
      "Shizhe Chen",
      "Cordelia Schmid"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.13040v3",
    "title": "MAMMA: Markerless & Automatic Multi-Person Motion Action Capture",
    "summary": "We present MAMMA, a markerless motion-capture pipeline that accurately recovers SMPL-X parameters from multi-view video of two-person interaction sequences. Traditional motion-capture systems rely on physical markers. Although they offer high accuracy, their requirements of specialized hardware, manual marker placement, and extensive post-processing make them costly and time-consuming. Recent learning-based methods attempt to overcome these limitations, but most are designed for single-person capture, rely on sparse keypoints, or struggle with occlusions and physical interactions. In this work, we introduce a method that predicts dense 2D contact-aware surface landmarks conditioned on segmentation masks, enabling person-specific correspondence estimation even under heavy occlusion. We employ a novel architecture that exploits learnable queries for each landmark. We demonstrate that our approach can handle complex person--person interaction and offers greater accuracy than existing methods. To train our network, we construct a large, synthetic multi-view dataset combining human motions from diverse sources, including extreme poses, hand motions, and close interactions. Our dataset yields high-variability synthetic sequences with rich body contact and occlusion, and includes SMPL-X ground-truth annotations with dense 2D landmarks. The result is a system capable of capturing human motion without the need for markers. Our approach offers competitive reconstruction quality compared to commercial marker-based motion-capture solutions, without the extensive manual cleanup. Finally, we address the absence of common benchmarks for dense-landmark prediction and markerless motion capture by introducing two evaluation settings built from real multi-view sequences. We will release our dataset, benchmark, method, training code, and pre-trained model weights for research purposes.",
    "published": "2025-06-16T02:04:51Z",
    "updated": "2025-12-01T17:55:23Z",
    "link": "http://arxiv.org/pdf/2506.13040v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Hanz Cuevas-Velasquez",
      "Anastasios Yiannakidis",
      "Soyong Shin",
      "Giorgio Becherini",
      "Markus Höschle",
      "Joachim Tesch",
      "Taylor Obersat",
      "Tsvetelina Alexiadis",
      "Eni Halilaj",
      "Michael J. Black"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.22451v2",
    "title": "Benchmarking machine learning models for multi-class state recognition in double quantum dot data",
    "summary": "Semiconductor quantum dots (QDs) are a leading platform for scalable quantum processors. However, scaling to large arrays requires reliable, automated tuning strategies for devices' bootstrapping, calibration, and operation, with many tuning aspects depending on accurately identifying QD device states from charge-stability diagrams (CSDs). In this work, we present a comprehensive benchmarking study of four modern machine learning (ML) architectures for multi-class state recognition in double-QD CSDs. We evaluate their performance across different data budgets and normalization schemes using both synthetic and experimental data. We find that the more resource-intensive models -- U-Nets and visual transformers (ViTs) -- achieve the highest MSE score (defined as $1-\\mathrm{MSE}$) on synthetic data (over $0.98$) but fail to generalize to experimental data. MDNs are the most computationally efficient and exhibit highly stable training, but with substantially lower peak performance. CNNs offer the most favorable trade-off on experimental CSDs, achieving strong accuracy with two orders of magnitude fewer parameters than the U-Nets and ViTs. Normalization plays a nontrivial role: min-max scaling generally yields higher MSE scores but less stable convergence, whereas z-score normalization produces more predictable training dynamics but at reduced accuracy for most models. Overall, our study shows that CNNs with min-max normalization are a practical approach for QD CSDs.",
    "published": "2025-11-27T13:38:57Z",
    "updated": "2025-12-01T17:47:33Z",
    "link": "http://arxiv.org/pdf/2511.22451v2.pdf",
    "category": [
      "cs.CV",
      "cond-mat.mes-hall",
      "cs.LG"
    ],
    "authors": [
      "Valeria Díaz Moreno",
      "Ryan P Khalili",
      "Daniel Schug",
      "Patrick J. Walsh",
      "Justyna P. Zwolak"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01934v1",
    "title": "Physical ID-Transfer Attacks against Multi-Object Tracking via Adversarial Trajectory",
    "summary": "Multi-Object Tracking (MOT) is a critical task in computer vision, with applications ranging from surveillance systems to autonomous driving. However, threats to MOT algorithms have yet been widely studied. In particular, incorrect association between the tracked objects and their assigned IDs can lead to severe consequences, such as wrong trajectory predictions. Previous attacks against MOT either focused on hijacking the trackers of individual objects, or manipulating the tracker IDs in MOT by attacking the integrated object detection (OD) module in the digital domain, which are model-specific, non-robust, and only able to affect specific samples in offline datasets. In this paper, we present AdvTraj, the first online and physical ID-manipulation attack against tracking-by-detection MOT, in which an attacker uses adversarial trajectories to transfer its ID to a targeted object to confuse the tracking system, without attacking OD. Our simulation results in CARLA show that AdvTraj can fool ID assignments with 100% success rate in various scenarios for white-box attacks against SORT, which also have high attack transferability (up to 93% attack success rate) against state-of-the-art (SOTA) MOT algorithms due to their common design principles. We characterize the patterns of trajectories generated by AdvTraj and propose two universal adversarial maneuvers that can be performed by a human walker/driver in daily scenarios. Our work reveals under-explored weaknesses in the object association phase of SOTA MOT systems, and provides insights into enhancing the robustness of such systems.",
    "published": "2025-12-01T17:47:19Z",
    "updated": "2025-12-01T17:47:19Z",
    "link": "http://arxiv.org/pdf/2512.01934v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Chenyi Wang",
      "Yanmao Man",
      "Raymond Muller",
      "Ming Li",
      "Z. Berkay Celik",
      "Ryan Gerdes",
      "Jonathan Petit"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01922v1",
    "title": "Med-VCD: Mitigating Hallucination for Medical Large Vision Language Models through Visual Contrastive Decoding",
    "summary": "Large vision-language models (LVLMs) are now central to healthcare applications such as medical visual question answering and imaging report generation. Yet, these models remain vulnerable to hallucination outputs that appear plausible but are in fact incorrect. In the natural image domain, several decoding strategies have been proposed to mitigate hallucinations by reinforcing visual evidence, but most rely on secondary decoding or rollback procedures that substantially slow inference. Moreover, existing solutions are often domain-specific and may introduce misalignment between modalities or between generated and ground-truth content. We introduce Med-VCD, a sparse visual-contrastive decoding method that mitigates hallucinations in medical LVLMs without the time overhead of secondary decoding. Med-VCD incorporates a novel token-sparsification strategy that selects visually informed tokens on the fly, trimming redundancy while retaining critical visual context and thus balancing efficiency with reliability. Evaluations on eight medical datasets, spanning ophthalmology, radiology, and pathology tasks in visual question answering, report generation, and dedicated hallucination benchmarks, show that Med-VCD raises factual accuracy by an average of 13\\% and improves hallucination accuracy by 6\\% relative to baseline medical LVLMs.",
    "published": "2025-12-01T17:40:03Z",
    "updated": "2025-12-01T17:40:03Z",
    "link": "http://arxiv.org/pdf/2512.01922v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zahra Mahdavi",
      "Zahra Khodakaramimaghsoud",
      "Hooman Khaloo",
      "Sina Bakhshandeh Taleshani",
      "Erfan Hashemi",
      "Javad Mirzapour Kaleybar",
      "Omid Nejati Manzari"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01913v1",
    "title": "Disentangling Progress in Medical Image Registration: Beyond Trend-Driven Architectures towards Domain-Specific Strategies",
    "summary": "Medical image registration drives quantitative analysis across organs, modalities, and patient populations. Recent deep learning methods often combine low-level \"trend-driven\" computational blocks from computer vision, such as large-kernel CNNs, Transformers, and state-space models, with high-level registration-specific designs like motion pyramids, correlation layers, and iterative refinement. Yet, their relative contributions remain unclear and entangled. This raises a central question: should future advances in registration focus on importing generic architectural trends or on refining domain-specific design principles? Through a modular framework spanning brain, lung, cardiac, and abdominal registration, we systematically disentangle the influence of these two paradigms. Our evaluation reveals that low-level \"trend-driven\" computational blocks offer only marginal or inconsistent gains, while high-level registration-specific designs consistently deliver more accurate, smoother, and more robust deformations. These domain priors significantly elevate the performance of a standard U-Net baseline, far more than variants incorporating \"trend-driven\" blocks, achieving an average relative improvement of $\\sim3\\%$. All models and experiments are released within a transparent, modular benchmark that enables plug-and-play comparison for new architectures and registration tasks (https://github.com/BailiangJ/rethink-reg). This dynamic and extensible platform establishes a common ground for reproducible and fair evaluation, inviting the community to isolate genuine methodological contributions from domain priors. Our findings advocate a shift in research emphasis: from following architectural trends to embracing domain-specific design principles as the true drivers of progress in learning-based medical image registration.",
    "published": "2025-12-01T17:30:43Z",
    "updated": "2025-12-01T17:30:43Z",
    "link": "http://arxiv.org/pdf/2512.01913v1.pdf",
    "category": [
      "eess.IV",
      "cs.CV"
    ],
    "authors": [
      "Bailiang Jian",
      "Jiazhen Pan",
      "Rohit Jena",
      "Morteza Ghahremani",
      "Hongwei Bran Li",
      "Daniel Rueckert",
      "Christian Wachinger",
      "Benedikt Wiestler"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01908v1",
    "title": "SARL: Spatially-Aware Self-Supervised Representation Learning for Visuo-Tactile Perception",
    "summary": "Contact-rich robotic manipulation requires representations that encode local geometry. Vision provides global context but lacks direct measurements of properties such as texture and hardness, whereas touch supplies these cues. Modern visuo-tactile sensors capture both modalities in a single fused image, yielding intrinsically aligned inputs that are well suited to manipulation tasks requiring visual and tactile information. Most self-supervised learning (SSL) frameworks, however, compress feature maps into a global vector, discarding spatial structure and misaligning with the needs of manipulation. To address this, we propose SARL, a spatially-aware SSL framework that augments the Bootstrap Your Own Latent (BYOL) architecture with three map-level objectives, including Saliency Alignment (SAL), Patch-Prototype Distribution Alignment (PPDA), and Region Affinity Matching (RAM), to keep attentional focus, part composition, and geometric relations consistent across views. These losses act on intermediate feature maps, complementing the global objective. SARL consistently outperforms nine SSL baselines across six downstream tasks with fused visual-tactile data. On the geometry-sensitive edge-pose regression task, SARL achieves a Mean Absolute Error (MAE) of 0.3955, a 30% relative improvement over the next-best SSL method (0.5682 MAE) and approaching the supervised upper bound. These findings indicate that, for fused visual-tactile data, the most effective signal is structured spatial equivariance, in which features vary predictably with object geometry, which enables more capable robotic perception.",
    "published": "2025-12-01T17:26:40Z",
    "updated": "2025-12-01T17:26:40Z",
    "link": "http://arxiv.org/pdf/2512.01908v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Gurmeher Khurana",
      "Lan Wei",
      "Dandan Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01895v1",
    "title": "StyleYourSmile: Cross-Domain Face Retargeting Without Paired Multi-Style Data",
    "summary": "Cross-domain face retargeting requires disentangled control over identity, expressions, and domain-specific stylistic attributes. Existing methods, typically trained on real-world faces, either fail to generalize across domains, need test-time optimizations, or require fine-tuning with carefully curated multi-style datasets to achieve domain-invariant identity representations. In this work, we introduce \\textit{StyleYourSmile}, a novel one-shot cross-domain face retargeting method that eliminates the need for curated multi-style paired data. We propose an efficient data augmentation strategy alongside a dual-encoder framework, for extracting domain-invariant identity cues and capturing domain-specific stylistic variations. Leveraging these disentangled control signals, we condition a diffusion model to retarget facial expressions across domains. Extensive experiments demonstrate that \\textit{StyleYourSmile} achieves superior identity preservation and retargeting fidelity across a wide range of visual domains.",
    "published": "2025-12-01T17:14:07Z",
    "updated": "2025-12-01T17:14:07Z",
    "link": "http://arxiv.org/pdf/2512.01895v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Avirup Dey",
      "Vinay Namboodiri"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01889v1",
    "title": "KM-ViPE: Online Tightly Coupled Vision-Language-Geometry Fusion for Open-Vocabulary Semantic SLAM",
    "summary": "We present KM-ViPE (Knowledge Mapping Video Pose Engine), a real-time open-vocabulary SLAM framework for uncalibrated monocular cameras in dynamic environments. Unlike systems requiring depth sensors and offline calibration, KM-ViPE operates directly on raw RGB streams, making it ideal for ego-centric applications and harvesting internet-scale video data for training. KM-ViPE tightly couples DINO visual features with geometric constraints through a high-level features based adaptive robust kernel that handles both moving objects and movable static objects (e.g., moving furniture in ego-centric views). The system performs simultaneous online localization and open-vocabulary semantic mapping by fusing geometric and deep visual features aligned with language embeddings. Our results are competitive with state-of-the-art approaches, while existing solutions either operate offline, need depth data and/or odometry estimation, or lack dynamic scene robustness. KM-ViPE benefits from internet-scale training and uniquely combines online operation, uncalibrated monocular input, and robust handling of dynamic scenes, which makes it a good fit for autonomous robotics and AR/VR applications and advances practical spatial intelligence capabilities for embodied AI.",
    "published": "2025-12-01T17:10:40Z",
    "updated": "2025-12-01T17:10:40Z",
    "link": "http://arxiv.org/pdf/2512.01889v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zaid Nasser",
      "Mikhail Iumanov",
      "Tianhao Li",
      "Maxim Popov",
      "Jaafar Mahmoud",
      "Malik Mohrat",
      "Ilya Obrubov",
      "Ekaterina Derevyanka",
      "Ivan Sosin",
      "Sergey Kolyubin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01885v1",
    "title": "TransientTrack: Advanced Multi-Object Tracking and Classification of Cancer Cells with Transient Fluorescent Signals",
    "summary": "Tracking cells in time-lapse videos is an essential technique for monitoring cell population dynamics at a single-cell level. Current methods for cell tracking are developed on videos with mostly single, constant signals and do not detect pivotal events such as cell death. Here, we present TransientTrack, a deep learning-based framework for cell tracking in multi-channel microscopy video data with transient fluorescent signals that fluctuate over time following processes such as the circadian rhythm of cells. By identifying key cellular events - mitosis (cell division) and apoptosis (cell death) our method allows us to build complete trajectories, including cell lineage information. TransientTrack is lightweight and performs matching on cell detection embeddings directly, without the need for quantification of tracking-specific cell features. Furthermore, our approach integrates Transformer Networks, multi-stage matching using all detection boxes, and the interpolation of missing tracklets with the Kalman Filter. This unified framework achieves strong performance across diverse conditions, effectively tracking cells and capturing cell division and death. We demonstrate the use of TransientTrack in an analysis of the efficacy of a chemotherapeutic drug at a single-cell level. The proposed framework could further advance quantitative studies of cancer cell dynamics, enabling detailed characterization of treatment response and resistance mechanisms. The code is available at https://github.com/bozeklab/TransientTrack.",
    "published": "2025-12-01T17:08:12Z",
    "updated": "2025-12-01T17:08:12Z",
    "link": "http://arxiv.org/pdf/2512.01885v1.pdf",
    "category": [
      "cs.CV",
      "q-bio.CB",
      "q-bio.QM"
    ],
    "authors": [
      "Florian Bürger",
      "Martim Dias Gomes",
      "Nica Gutu",
      "Adrián E. Granada",
      "Noémie Moreau",
      "Katarzyna Bozek"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.04859v2",
    "title": "Global-to-local image quality assessment in optical microscopy via fast and robust deep learning predictions",
    "summary": "Optical microscopy is one of the most widely used techniques in research studies for life sciences and biomedicine. These applications require reliable experimental pipelines to extract valuable knowledge from the measured samples and must be supported by image quality assessment (IQA) to ensure correct processing and analysis of the image data. IQA methods are implemented with variable complexity. However, while most quality metrics have a straightforward implementation, they might be time consuming and computationally expensive when evaluating a large dataset. In addition, quality metrics are often designed for well-defined image features and may be unstable for images out of the ideal domain. To overcome these limitations, recent works have proposed deep learning-based IQA methods, which can provide superior performance, increased generalizability and fast prediction. Our method, named $\\mathrmμ$DeepIQA, is inspired by previous studies and applies a deep convolutional neural network designed for IQA on natural images to optical microscopy measurements. We retrained the same architecture to predict individual quality metrics and global quality scores for optical microscopy data. The resulting models provide fast and stable predictions of image quality by generalizing quality estimation even outside the ideal range of standard methods. In addition, $\\mathrmμ$DeepIQA provides patch-wise prediction of image quality and can be used to visualize spatially varying quality in a single image. Our study demonstrates that optical microscopy-based studies can benefit from the generalizability of deep learning models due to their stable performance in the presence of outliers, the ability to assess small image patches, and rapid predictions.",
    "published": "2025-10-06T14:48:36Z",
    "updated": "2025-12-01T16:58:32Z",
    "link": "http://arxiv.org/pdf/2510.04859v2.pdf",
    "category": [
      "cs.CV",
      "physics.data-an",
      "q-bio.QM"
    ],
    "authors": [
      "Elena Corbetta",
      "Thomas Bocklitz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.18011v2",
    "title": "Manual-PA: Learning 3D Part Assembly from Instruction Diagrams",
    "summary": "Assembling furniture amounts to solving the discrete-continuous optimization task of selecting the furniture parts to assemble and estimating their connecting poses in a physically realistic manner. The problem is hampered by its combinatorially large yet sparse solution space thus making learning to assemble a challenging task for current machine learning models. In this paper, we attempt to solve this task by leveraging the assembly instructions provided in diagrammatic manuals that typically accompany the furniture parts. Our key insight is to use the cues in these diagrams to split the problem into discrete and continuous phases. Specifically, we present Manual-PA, a transformer-based instruction Manual-guided 3D Part Assembly framework that learns to semantically align 3D parts with their illustrations in the manuals using a contrastive learning backbone towards predicting the assembly order and infers the 6D pose of each part via relating it to the final furniture depicted in the manual. To validate the efficacy of our method, we conduct experiments on the benchmark PartNet dataset. Our results show that using the diagrams and the order of the parts lead to significant improvements in assembly performance against the state of the art. Further, Manual-PA demonstrates strong generalization to real-world IKEA furniture assembly on the IKEA-Manual dataset.",
    "published": "2024-11-27T03:10:29Z",
    "updated": "2025-12-01T16:57:36Z",
    "link": "http://arxiv.org/pdf/2411.18011v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jiahao Zhang",
      "Anoop Cherian",
      "Cristian Rodriguez",
      "Weijian Deng",
      "Stephen Gould"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.07472v2",
    "title": "Multivariate Variational Autoencoder",
    "summary": "Learning latent representations that are simultaneously expressive, geometrically well-structured, and reliably calibrated remains a central challenge for Variational Autoencoders (VAEs). Standard VAEs typically assume a diagonal Gaussian posterior, which simplifies optimization but rules out correlated uncertainty and often yields entangled or redundant latent dimensions. We introduce the Multivariate Variational Autoencoder (MVAE), a tractable full-covariance extension of the VAE that augments the encoder with sample-specific diagonal scales and a global coupling matrix. This induces a multivariate Gaussian posterior of the form $N(μ_φ(x), C \\operatorname{diag}(σ_φ^2(x)) C^\\top)$, enabling correlated latent factors while preserving a closed-form KL divergence and a simple reparameterization path. Beyond likelihood, we propose a multi-criterion evaluation protocol that jointly assesses reconstruction quality (MSE, ELBO), downstream discrimination (linear probes), probabilistic calibration (NLL, Brier, ECE), and unsupervised structure (NMI, ARI). Across Larochelle-style MNIST variants, Fashion-MNIST, and CIFAR-10/100, MVAE consistently matches or outperforms diagonal-covariance VAEs of comparable capacity, with particularly notable gains in calibration and clustering metrics at both low and high latent dimensions. Qualitative analyses further show smoother, more semantically coherent latent traversals and sharper reconstructions. All code, dataset splits, and evaluation utilities are released to facilitate reproducible comparison and future extensions of multivariate posterior models.",
    "published": "2025-11-08T16:52:53Z",
    "updated": "2025-12-01T16:48:04Z",
    "link": "http://arxiv.org/pdf/2511.07472v2.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Mehmet Can Yavuz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01853v1",
    "title": "COACH: Collaborative Agents for Contextual Highlighting - A Multi-Agent Framework for Sports Video Analysis",
    "summary": "Intelligent sports video analysis demands a comprehensive understanding of temporal context, from micro-level actions to macro-level game strategies. Existing end-to-end models often struggle with this temporal hierarchy, offering solutions that lack generalization, incur high development costs for new tasks, and suffer from poor interpretability. To overcome these limitations, we propose a reconfigurable Multi-Agent System (MAS) as a foundational framework for sports video understanding. In our system, each agent functions as a distinct \"cognitive tool\" specializing in a specific aspect of analysis. The system's architecture is not confined to a single temporal dimension or task. By leveraging iterative invocation and flexible composition of these agents, our framework can construct adaptive pipelines for both short-term analytic reasoning (e.g., Rally QA) and long-term generative summarization (e.g., match summaries). We demonstrate the adaptability of this framework using two representative tasks in badminton analysis, showcasing its ability to bridge fine-grained event detection and global semantic organization. This work presents a paradigm shift towards a flexible, scalable, and interpretable system for robust, cross-task sports video intelligence.The project homepage is available at https://aiden1020.github.io/COACH-project-page",
    "published": "2025-12-01T16:38:07Z",
    "updated": "2025-12-01T16:38:07Z",
    "link": "http://arxiv.org/pdf/2512.01853v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Tsz-To Wong",
      "Ching-Chun Huang",
      "Hong-Han Shuai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01850v1",
    "title": "Register Any Point: Scaling 3D Point Cloud Registration by Flow Matching",
    "summary": "Point cloud registration aligns multiple unposed point clouds into a common frame, and is a core step for 3D reconstruction and robot localization. In this work, we cast registration as conditional generation: a learned continuous, point-wise velocity field transports noisy points to a registered scene, from which the pose of each view is recovered. Unlike previous methods that conduct correspondence matching to estimate the transformation between a pair of point clouds and then optimize the pairwise transformations to realize multi-view registration, our model directly generates the registered point cloud. With a lightweight local feature extractor and test-time rigidity enforcement, our approach achieves state-of-the-art results on pairwise and multi-view registration benchmarks, particularly with low overlap, and generalizes across scales and sensor modalities. It further supports downstream tasks including relocalization, multi-robot SLAM, and multi-session map merging. Source code available at: https://github.com/PRBonn/RAP.",
    "published": "2025-12-01T16:36:51Z",
    "updated": "2025-12-01T16:36:51Z",
    "link": "http://arxiv.org/pdf/2512.01850v1.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Yue Pan",
      "Tao Sun",
      "Liyuan Zhu",
      "Lucas Nunes",
      "Iro Armeni",
      "Jens Behley",
      "Cyrill Stachniss"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01843v1",
    "title": "PhyDetEx: Detecting and Explaining the Physical Plausibility of T2V Models",
    "summary": "Driven by the growing capacity and training scale, Text-to-Video (T2V) generation models have recently achieved substantial progress in video quality, length, and instruction-following capability. However, whether these models can understand physics and generate physically plausible videos remains a question. While Vision-Language Models (VLMs) have been widely used as general-purpose evaluators in various applications, they struggle to identify the physically impossible content from generated videos. To investigate this issue, we construct a \\textbf{PID} (\\textbf{P}hysical \\textbf{I}mplausibility \\textbf{D}etection) dataset, which consists of a \\textit{test split} of 500 manually annotated videos and a \\textit{train split} of 2,588 paired videos, where each implausible video is generated by carefully rewriting the caption of its corresponding real-world video to induce T2V models producing physically implausible content. With the constructed dataset, we introduce a lightweight fine-tuning approach, enabling VLMs to not only detect physically implausible events but also generate textual explanations on the violated physical principles. Taking the fine-tuned VLM as a physical plausibility detector and explainer, namely \\textbf{PhyDetEx}, we benchmark a series of state-of-the-art T2V models to assess their adherence to physical laws. Our findings show that although recent T2V models have made notable progress toward generating physically plausible content, understanding and adhering to physical laws remains a challenging issue, especially for open-source models. Our dataset, training code, and checkpoints are available at \\href{https://github.com/Zeqing-Wang/PhyDetEx}{https://github.com/Zeqing-Wang/PhyDetEx}.",
    "published": "2025-12-01T16:28:13Z",
    "updated": "2025-12-01T16:28:13Z",
    "link": "http://arxiv.org/pdf/2512.01843v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zeqing Wang",
      "Keze Wang",
      "Lei Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18058v2",
    "title": "Hierarchical Semi-Supervised Active Learning for Remote Sensing",
    "summary": "The performance of deep learning models in remote sensing (RS) strongly depends on the availability of high-quality labeled data. However, collecting large-scale annotations is costly and time-consuming, while vast amounts of unlabeled imagery remain underutilized. To address this challenge, we propose a Hierarchical Semi-Supervised Active Learning (HSSAL) framework that integrates semi-supervised learning (SSL) and a novel hierarchical active learning (HAL) in a closed iterative loop. In each iteration, SSL refines the model using both labeled data through supervised learning and unlabeled data via weak-to-strong self-training, improving feature representation and uncertainty estimation. Guided by the refined representations and uncertainty cues of unlabeled samples, HAL then conducts sample querying through a progressive clustering strategy, selecting the most informative instances that jointly satisfy the criteria of scalability, diversity, and uncertainty. This hierarchical process ensures both efficiency and representativeness in sample selection. Extensive experiments on three benchmark RS scene classification datasets, including UCM, AID, and NWPU-RESISC45, demonstrate that HSSAL consistently outperforms SSL- or AL-only baselines. Remarkably, with only 8%, 4%, and 2% labeled training data on UCM, AID, and NWPU-RESISC45, respectively, HSSAL achieves over 95% of fully-supervised accuracy, highlighting its superior label efficiency through informativeness exploitation of unlabeled data. Our code will be publicly available.",
    "published": "2025-11-22T13:25:42Z",
    "updated": "2025-12-01T16:19:52Z",
    "link": "http://arxiv.org/pdf/2511.18058v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Wei Huang",
      "Zhitong Xiong",
      "Chenying Liu",
      "Xiao Xiang Zhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01830v1",
    "title": "OpenREAD: Reinforced Open-Ended Reasoing for End-to-End Autonomous Driving with LLM-as-Critic",
    "summary": "Recently, two-stage fine-tuning strategies, e.g., acquiring essential driving knowledge through supervised fine-tuning (SFT) and further enhancing decision-making and planning via reinforcement fine-tuning (RFT), have shown strong potential in advancing the knowledge-driven autonomous driving (AD) paradigm. However, the learning nature of SFT still limits the generalization of reasoning, thereby constraining the full potential of driving performance. Meanwhile, current RFT approaches are primarily applied to downstream tasks, since scene understanding is an open-ended problem where corresponding rewards are difficult to quantify. To address these limitations, we propose OpenREAD, an OPEN-ended REasoning reinforced vision-language model (VLM)-based autonomous driving (AD) framework that enables end-to-end RFT across the full spectrum from high-level reasoning to low-level trajectory planning. Specifically, we begin by constructing large-scale Chain-of-Thought (CoT) annotations on open-source driving-related knowledge datasets, and employ the powerful Qwen3 large language model (LLM) as the critic in RFT to quantify reasoning quality for open-ended questions during reward modeling. Extensive experiments confirm that joint end-to-end RFT yields substantial improvements in both upstream and downstream tasks, enabling OpenREAD to achieve state-of-the-art performance on reasoning and planning benchmarks.",
    "published": "2025-12-01T16:11:57Z",
    "updated": "2025-12-01T16:11:57Z",
    "link": "http://arxiv.org/pdf/2512.01830v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Songyan Zhang",
      "Wenhui Huang",
      "Zhan Chen",
      "Chua Jiahao Collister",
      "Qihang Huang",
      "Chen Lv"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.08711v2",
    "title": "Harnessing Diffusion-Generated Synthetic Images for Fair Image Classification",
    "summary": "Image classification systems often inherit biases from uneven group representation in training data. For example, in face datasets for hair color classification, blond hair may be disproportionately associated with females, reinforcing stereotypes. A recent approach leverages the Stable Diffusion model to generate balanced training data, but these models often struggle to preserve the original data distribution. In this work, we explore multiple diffusion-finetuning techniques, e.g., LoRA and DreamBooth, to generate images that more accurately represent each training group by learning directly from their samples. Additionally, in order to prevent a single DreamBooth model from being overwhelmed by excessive intra-group variations, we explore a technique of clustering images within each group and train a DreamBooth model per cluster. These models are then used to generate group-balanced data for pretraining, followed by fine-tuning on real data. Experiments on multiple benchmarks demonstrate that the studied finetuning approaches outperform vanilla Stable Diffusion on average and achieve results comparable to SOTA debiasing techniques like Group-DRO, while surpassing them as the dataset bias severity increases.",
    "published": "2025-11-11T19:20:13Z",
    "updated": "2025-12-01T16:08:08Z",
    "link": "http://arxiv.org/pdf/2511.08711v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Abhipsa Basu",
      "Aviral Gupta",
      "Abhijnya Bhat",
      "R. Venkatesh Babu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01827v1",
    "title": "CauSight: Learning to Supersense for Visual Causal Discovery",
    "summary": "Causal thinking enables humans to understand not just what is seen, but why it happens. To replicate this capability in modern AI systems, we introduce the task of visual causal discovery. It requires models to infer cause-and-effect relations among visual entities across diverse scenarios instead of merely perceiving their presence. To this end, we first construct the Visual Causal Graph dataset (VCG-32K), a large-scale collection of over 32,000 images annotated with entity-level causal graphs, and further develop CauSight, a novel vision-language model to perform visual causal discovery through causally aware reasoning. Our training recipe integrates three components: (1) training data curation from VCG-32K, (2) Tree-of-Causal-Thought (ToCT) for synthesizing reasoning trajectories, and (3) reinforcement learning with a designed causal reward to refine the reasoning policy. Experiments show that CauSight outperforms GPT-4.1 on visual causal discovery, achieving over a threefold performance boost (21% absolute gain). Our code, model, and dataset are fully open-sourced at project page: https://github.com/OpenCausaLab/CauSight.",
    "published": "2025-12-01T16:05:13Z",
    "updated": "2025-12-01T16:05:13Z",
    "link": "http://arxiv.org/pdf/2512.01827v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yize Zhang",
      "Meiqi Chen",
      "Sirui Chen",
      "Bo Peng",
      "Yanxi Zhang",
      "Tianyu Li",
      "Chaochao Lu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01821v1",
    "title": "Seeing through Imagination: Learning Scene Geometry via Implicit Spatial World Modeling",
    "summary": "Spatial reasoning, the ability to understand and interpret the 3D structure of the world, is a critical yet underdeveloped capability in Multimodal Large Language Models (MLLMs). Current methods predominantly rely on verbal descriptive tuning, which suffers from visual illiteracy, i.e., they learn spatial concepts through textual symbols alone, devoid of connection to their visual manifestations. To bridge this gap, this paper introduces MILO, an Implicit spatIaL wOrld modeling paradigm that simulates human-like spatial imagination. MILO integrates a visual generator to provide geometry-aware feedback, thereby implicitly grounding the MLLM's symbolic reasoning in perceptual experience. Complementing this paradigm, we propose RePE (Relative Positional Encoding), a novel encoding scheme that captures relative camera-pose transformations, offering superior performance over absolute coordinate systems. To support the training, we construct GeoGen, a large-scale Geometry-aware Generative dataset with approximately 2,241 videos and 67,827 observation-action-outcome triplets. Experiments demonstrate that our approach significantly enhances spatial reasoning capabilities across multiple baselines and benchmarks, offering a more holistic understanding of 3D space.",
    "published": "2025-12-01T16:01:41Z",
    "updated": "2025-12-01T16:01:41Z",
    "link": "http://arxiv.org/pdf/2512.01821v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Meng Cao",
      "Haokun Lin",
      "Haoyuan Li",
      "Haoran Tang",
      "Rongtao Xu",
      "Dong An",
      "Xue Liu",
      "Ian Reid",
      "Xiaodan Liang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01818v1",
    "title": "Forget Less, Retain More: A Lightweight Regularizer for Rehearsal-Based Continual Learning",
    "summary": "Deep neural networks suffer from catastrophic forgetting, where performance on previous tasks degrades after training on a new task. This issue arises due to the model's tendency to overwrite previously acquired knowledge with new information. We present a novel approach to address this challenge, focusing on the intersection of memory-based methods and regularization approaches. We formulate a regularization strategy, termed Information Maximization (IM) regularizer, for memory-based continual learning methods, which is based exclusively on the expected label distribution, thus making it class-agnostic. As a consequence, IM regularizer can be directly integrated into various rehearsal-based continual learning methods, reducing forgetting and favoring faster convergence. Our empirical validation shows that, across datasets and regardless of the number of tasks, our proposed regularization strategy consistently improves baseline performance at the expense of a minimal computational overhead. The lightweight nature of IM ensures that it remains a practical and scalable solution, making it applicable to real-world continual learning scenarios where efficiency is paramount. Finally, we demonstrate the data-agnostic nature of our regularizer by applying it to video data, which presents additional challenges due to its temporal structure and higher memory requirements. Despite the significant domain gap, our experiments show that IM regularizer also improves the performance of video continual learning methods.",
    "published": "2025-12-01T15:56:00Z",
    "updated": "2025-12-01T15:56:00Z",
    "link": "http://arxiv.org/pdf/2512.01818v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Lama Alssum",
      "Hasan Abed Al Kader Hammoud",
      "Motasem Alfarra",
      "Juan C Leon Alcazar",
      "Bernard Ghanem"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.12168v3",
    "title": "Sketch-guided Cage-based 3D Gaussian Splatting Deformation",
    "summary": "3D Gaussian Splatting (GS) is one of the most promising novel 3D representations that has received great interest in computer graphics and computer vision. While various systems have introduced editing capabilities for 3D GS, such as those guided by text prompts, fine-grained control over deformation remains an open challenge. In this work, we present a novel sketch-guided 3D GS deformation system that allows users to intuitively modify the geometry of a 3D GS model by drawing a silhouette sketch from a single viewpoint. Our approach introduces a new deformation method that combines cage-based deformations with a variant of Neural Jacobian Fields, enabling precise, fine-grained control. Additionally, it leverages large-scale 2D diffusion priors and ControlNet to ensure the generated deformations are semantically plausible. Through a series of experiments, we demonstrate the effectiveness of our method and showcase its ability to animate static 3D GS models as one of its key applications.",
    "published": "2024-11-19T02:18:19Z",
    "updated": "2025-12-01T15:55:51Z",
    "link": "http://arxiv.org/pdf/2411.12168v3.pdf",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "Tianhao Xie",
      "Noam Aigerman",
      "Eugene Belilovsky",
      "Tiberiu Popa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.16639v2",
    "title": "Benchmarking pig detection and tracking under diverse and challenging conditions",
    "summary": "To ensure animal welfare and effective management in pig farming, monitoring individual behavior is a crucial prerequisite. While monitoring tasks have traditionally been carried out manually, advances in machine learning have made it possible to collect individualized information in an increasingly automated way. Central to these methods is the localization of animals across space (object detection) and time (multi-object tracking). Despite extensive research of these two tasks in pig farming, a systematic benchmarking study has not yet been conducted. In this work, we address this gap by curating two datasets: PigDetect for object detection and PigTrack for multi-object tracking. The datasets are based on diverse image and video material from realistic barn conditions, and include challenging scenarios such as occlusions or bad visibility. For object detection, we show that challenging training images improve detection performance beyond what is achievable with randomly sampled images alone. Comparing different approaches, we found that state-of-the-art models offer substantial improvements in detection quality over real-time alternatives. For multi-object tracking, we observed that SORT-based methods achieve superior detection performance compared to end-to-end trainable models. However, end-to-end models show better association performance, suggesting they could become strong alternatives in the future. We also investigate characteristic failure cases of end-to-end models, providing guidance for future improvements. The detection and tracking models trained on our datasets perform well in unseen pens, suggesting good generalization capabilities. This highlights the importance of high-quality training data. The datasets and research code are made publicly available to facilitate reproducibility, re-use and further development.",
    "published": "2025-07-22T14:36:51Z",
    "updated": "2025-12-01T15:53:10Z",
    "link": "http://arxiv.org/pdf/2507.16639v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jonathan Henrich",
      "Christian Post",
      "Maximilian Zilke",
      "Parth Shiroya",
      "Emma Chanut",
      "Amir Mollazadeh Yamchi",
      "Ramin Yahyapour",
      "Thomas Kneib",
      "Imke Traulsen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.21309v2",
    "title": "CaliTex: Geometry-Calibrated Attention for View-Coherent 3D Texture Generation",
    "summary": "Despite major advances brought by diffusion-based models, current 3D texture generation systems remain hindered by cross-view inconsistency -- textures that appear convincing from one viewpoint often fail to align across others. We find that this issue arises from attention ambiguity, where unstructured full attention is applied indiscriminately across tokens and modalities, causing geometric confusion and unstable appearance-structure coupling. To address this, we introduce CaliTex, a framework of geometry-calibrated attention that explicitly aligns attention with 3D structure. It introduces two modules: Part-Aligned Attention that enforces spatial alignment across semantically matched parts, and Condition-Routed Attention which routes appearance information through geometry-conditioned pathways to maintain spatial fidelity. Coupled with a two-stage diffusion transformer, CaliTex makes geometric coherence an inherent behavior of the network rather than a byproduct of optimization. Empirically, CaliTex produces seamless and view-consistent textures and outperforms both open-source and commercial baselines.",
    "published": "2025-11-26T11:53:26Z",
    "updated": "2025-12-01T15:45:21Z",
    "link": "http://arxiv.org/pdf/2511.21309v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Chenyu Liu",
      "Hongze Chen",
      "Jingzhi Bao",
      "Lingting Zhu",
      "Runze Zhang",
      "Weikai Chen",
      "Zeyu Hu",
      "Yingda Yin",
      "Keyang Luo",
      "Xin Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.13545v4",
    "title": "Pushing the Limits of Sparsity: A Bag of Tricks for Extreme Pruning",
    "summary": "Pruning of deep neural networks has been an effective technique for reducing model size while preserving most of the performance of dense networks, crucial for deploying models on memory and power-constrained devices. While recent sparse learning methods have shown promising performance up to moderate sparsity levels such as 95% and 98%, accuracy quickly deteriorates when pushing sparsities to extreme levels due to unique challenges such as fragile gradient flow. In this work, we explore network performance beyond the commonly studied sparsities, and develop techniques that encourage stable training without accuracy collapse even at extreme sparsities, including 99.90%, 99.95\\% and 99.99% on ResNet architectures. We propose three complementary techniques that enhance sparse training through different mechanisms: 1) Dynamic ReLU phasing, where DyReLU initially allows for richer parameter exploration before being gradually replaced by standard ReLU, 2) weight sharing which reuses parameters within a residual layer while maintaining the same number of learnable parameters, and 3) cyclic sparsity, where both sparsity levels and sparsity patterns evolve dynamically throughout training to better encourage parameter exploration. We evaluate our method, which we term Extreme Adaptive Sparse Training (EAST) at extreme sparsities using ResNet-34 and ResNet-50 on CIFAR-10, CIFAR-100, and ImageNet, achieving competitive or improved performance compared to existing methods, with notable gains at extreme sparsity levels.",
    "published": "2024-11-20T18:54:53Z",
    "updated": "2025-12-01T15:41:50Z",
    "link": "http://arxiv.org/pdf/2411.13545v4.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Andy Li",
      "Aiden Durrant",
      "Milan Markovic",
      "Tianjin Huang",
      "Souvik Kundu",
      "Tianlong Chen",
      "Lu Yin",
      "Georgios Leontidis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01803v1",
    "title": "Generative Action Tell-Tales: Assessing Human Motion in Synthesized Videos",
    "summary": "Despite rapid advances in video generative models, robust metrics for evaluating visual and temporal correctness of complex human actions remain elusive. Critically, existing pure-vision encoders and Multimodal Large Language Models (MLLMs) are strongly appearance-biased, lack temporal understanding, and thus struggle to discern intricate motion dynamics and anatomical implausibilities in generated videos. We tackle this gap by introducing a novel evaluation metric derived from a learned latent space of real-world human actions. Our method first captures the nuances, constraints, and temporal smoothness of real-world motion by fusing appearance-agnostic human skeletal geometry features with appearance-based features. We posit that this combined feature space provides a robust representation of action plausibility. Given a generated video, our metric quantifies its action quality by measuring the distance between its underlying representations and this learned real-world action distribution. For rigorous validation, we develop a new multi-faceted benchmark specifically designed to probe temporally challenging aspects of human action fidelity. Through extensive experiments, we show that our metric achieves substantial improvement of more than 68% compared to existing state-of-the-art methods on our benchmark, performs competitively on established external benchmarks, and has a stronger correlation with human perception. Our in-depth analysis reveals critical limitations in current video generative models and establishes a new standard for advanced research in video generation.",
    "published": "2025-12-01T15:36:33Z",
    "updated": "2025-12-01T15:36:33Z",
    "link": "http://arxiv.org/pdf/2512.01803v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xavier Thomas",
      "Youngsun Lim",
      "Ananya Srinivasan",
      "Audrey Zheng",
      "Deepti Ghadiyaram"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.14793v2",
    "title": "Flow Equivariant Recurrent Neural Networks",
    "summary": "Data arrives at our senses as a continuous stream, smoothly transforming from one instant to the next. These smooth transformations can be viewed as continuous symmetries of the environment that we inhabit, defining equivalence relations between stimuli over time. In machine learning, neural network architectures that respect symmetries of their data are called equivariant and have provable benefits in terms of generalization ability and sample efficiency. To date, however, equivariance has been considered only for static transformations and feed-forward networks, limiting its applicability to sequence models, such as recurrent neural networks (RNNs), and corresponding time-parameterized sequence transformations. In this work, we extend equivariant network theory to this regime of 'flows' -- one-parameter Lie subgroups capturing natural transformations over time, such as visual motion. We begin by showing that standard RNNs are generally not flow equivariant: their hidden states fail to transform in a geometrically structured manner for moving stimuli. We then show how flow equivariance can be introduced, and demonstrate that these models significantly outperform their non-equivariant counterparts in terms of training speed, length generalization, and velocity generalization, on both next step prediction and sequence classification. We present this work as a first step towards building sequence models that respect the time-parameterized symmetries which govern the world around us.",
    "published": "2025-07-20T02:52:21Z",
    "updated": "2025-12-01T15:32:14Z",
    "link": "http://arxiv.org/pdf/2507.14793v2.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "T. Anderson Keller"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01789v1",
    "title": "SAM3-UNet: Simplified Adaptation of Segment Anything Model 3",
    "summary": "In this paper, we introduce SAM3-UNet, a simplified variant of Segment Anything Model 3 (SAM3), designed to adapt SAM3 for downstream tasks at a low cost. Our SAM3-UNet consists of three components: a SAM3 image encoder, a simple adapter for parameter-efficient fine-tuning, and a lightweight U-Net-style decoder. Preliminary experiments on multiple tasks, such as mirror detection and salient object detection, demonstrate that the proposed SAM3-UNet outperforms the prior SAM2-UNet and other state-of-the-art methods, while requiring less than 6 GB of GPU memory during training with a batch size of 12. The code is publicly available at https://github.com/WZH0120/SAM3-UNet.",
    "published": "2025-12-01T15:27:35Z",
    "updated": "2025-12-01T15:27:35Z",
    "link": "http://arxiv.org/pdf/2512.01789v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xinyu Xiong",
      "Zihuang Wu",
      "Lei Lu",
      "Yufa Xia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01788v1",
    "title": "Learned Image Compression for Earth Observation: Implications for Downstream Segmentation Tasks",
    "summary": "The rapid growth of data from satellite-based Earth observation (EO) systems poses significant challenges in data transmission and storage. We evaluate the potential of task-specific learned compression algorithms in this context to reduce data volumes while retaining crucial information. In detail, we compare traditional compression (JPEG 2000) versus a learned compression approach (Discretized Mixed Gaussian Likelihood) on three EO segmentation tasks: Fire, cloud, and building detection. Learned compression notably outperforms JPEG 2000 for large-scale, multi-channel optical imagery in both reconstruction quality (PSNR) and segmentation accuracy. However, traditional codecs remain competitive on smaller, single-channel thermal infrared datasets due to limited data and architectural constraints. Additionally, joint end-to-end optimization of compression and segmentation models does not improve performance over standalone optimization.",
    "published": "2025-12-01T15:27:33Z",
    "updated": "2025-12-01T15:27:33Z",
    "link": "http://arxiv.org/pdf/2512.01788v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Christian Mollière",
      "Iker Cumplido",
      "Marco Zeulner",
      "Lukas Liesenhoff",
      "Matthias Schubert",
      "Julia Gottfriedsen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01774v1",
    "title": "Evaluating SAM2 for Video Semantic Segmentation",
    "summary": "The Segmentation Anything Model 2 (SAM2) has proven to be a powerful foundation model for promptable visual object segmentation in both images and videos, capable of storing object-aware memories and transferring them temporally through memory blocks. While SAM2 excels in video object segmentation by providing dense segmentation masks based on prompts, extending it to dense Video Semantic Segmentation (VSS) poses challenges due to the need for spatial accuracy, temporal consistency, and the ability to track multiple objects with complex boundaries and varying scales. This paper explores the extension of SAM2 for VSS, focusing on two primary approaches and highlighting firsthand observations and common challenges faced during this process. The first approach involves using SAM2 to extract unique objects as masks from a given image, with a segmentation network employed in parallel to generate and refine initial predictions. The second approach utilizes the predicted masks to extract unique feature vectors, which are then fed into a simple network for classification. The resulting classifications and masks are subsequently combined to produce the final segmentation. Our experiments suggest that leveraging SAM2 enhances overall performance in VSS, primarily due to its precise predictions of object boundaries.",
    "published": "2025-12-01T15:15:16Z",
    "updated": "2025-12-01T15:15:16Z",
    "link": "http://arxiv.org/pdf/2512.01774v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Syed Hesham Syed Ariff",
      "Yun Liu",
      "Guolei Sun",
      "Jing Yang",
      "Henghui Ding",
      "Xue Geng",
      "Xudong Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01771v1",
    "title": "Robust Rigid and Non-Rigid Medical Image Registration Using Learnable Edge Kernels",
    "summary": "Medical image registration is crucial for various clinical and research applications including disease diagnosis or treatment planning which require alignment of images from different modalities, time points, or subjects. Traditional registration techniques often struggle with challenges such as contrast differences, spatial distortions, and modality-specific variations. To address these limitations, we propose a method that integrates learnable edge kernels with learning-based rigid and non-rigid registration techniques. Unlike conventional layers that learn all features without specific bias, our approach begins with a predefined edge detection kernel, which is then perturbed with random noise. These kernels are learned during training to extract optimal edge features tailored to the task. This adaptive edge detection enhances the registration process by capturing diverse structural features critical in medical imaging. To provide clearer insight into the contribution of each component in our design, we introduce four variant models for rigid registration and four variant models for non-rigid registration. We evaluated our approach using a dataset provided by the Medical University across three setups: rigid registration without skull removal, with skull removal, and non-rigid registration. Additionally, we assessed performance on two publicly available datasets. Across all experiments, our method consistently outperformed state-of-the-art techniques, demonstrating its potential to improve multi-modal image alignment and anatomical structure analysis.",
    "published": "2025-12-01T15:13:33Z",
    "updated": "2025-12-01T15:13:33Z",
    "link": "http://arxiv.org/pdf/2512.01771v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ahsan Raza Siyal",
      "Markus Haltmeier",
      "Ruth Steiger",
      "Malik Galijasevic",
      "Elke Ruth Gizewski",
      "Astrid Ellen Grams"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.06263v3",
    "title": "OmniSVG: A Unified Scalable Vector Graphics Generation Model",
    "summary": "Scalable Vector Graphics (SVG) is an important image format widely adopted in graphic design because of their resolution independence and editability. The study of generating high-quality SVG has continuously drawn attention from both designers and researchers in the AIGC community. However, existing methods either produces unstructured outputs with huge computational cost or is limited to generating monochrome icons of over-simplified structures. To produce high-quality and complex SVG, we propose OmniSVG, a unified framework that leverages pre-trained Vision-Language Models (VLMs) for end-to-end multimodal SVG generation. By parameterizing SVG commands and coordinates into discrete tokens, OmniSVG decouples structural logic from low-level geometry for efficient training while maintaining the expressiveness of complex SVG structure. To further advance the development of SVG synthesis, we introduce MMSVG-2M, a multimodal dataset with two million richly annotated SVG assets, along with a standardized evaluation protocol for conditional SVG generation tasks. Extensive experiments show that OmniSVG outperforms existing methods and demonstrates its potential for integration into professional SVG design workflows.",
    "published": "2025-04-08T17:59:49Z",
    "updated": "2025-12-01T15:10:24Z",
    "link": "http://arxiv.org/pdf/2504.06263v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yiying Yang",
      "Wei Cheng",
      "Sijin Chen",
      "Xianfang Zeng",
      "Fukun Yin",
      "Jiaxu Zhang",
      "Liao Wang",
      "Gang Yu",
      "Xingjun Ma",
      "Yu-Gang Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01769v1",
    "title": "VideoScoop: A Non-Traditional Domain-Independent Framework For Video Analysis",
    "summary": "Automatically understanding video contents is important for several applications in Civic Monitoring (CM), general Surveillance (SL), Assisted Living (AL), etc. Decades of Image and Video Analysis (IVA) research have advanced tasks such as content extraction (e.g., object recognition and tracking). Identifying meaningful activities or situations (e.g., two objects coming closer) remains difficult and cannot be achieved by content extraction alone. Currently, Video Situation Analysis (VSA) is done manually with a human in the loop, which is error-prone and labor-intensive, or through custom algorithms designed for specific video types or situations. These algorithms are not general-purpose and require a new algorithm/software for each new situation or video from a new domain.\n  This report proposes a general-purpose VSA framework that overcomes the above limitations. Video contents are extracted once using state-of-the-art Video Content Extraction technologies. They are represented using two alternative models -- the extended relational model (R++) and graph models. When represented using R++, the extracted contents can be used as data streams, enabling Continuous Query Processing via the proposed Continuous Query Language for Video Analysis. The graph models complement this by enabling the detection of situations that are difficult or impossible to detect using the relational model alone. Existing graph algorithms and newly developed algorithms support a wide variety of situation detection. To support domain independence, primitive situation variants across domains are identified and expressed as parameterized templates. Extensive experiments were conducted across several interesting situations from three domains -- AL, CM, and SL-- to evaluate the accuracy, efficiency, and robustness of the proposed approach using a dataset of videos of varying lengths from these domains.",
    "published": "2025-12-01T15:09:46Z",
    "updated": "2025-12-01T15:09:46Z",
    "link": "http://arxiv.org/pdf/2512.01769v1.pdf",
    "category": [
      "cs.CV",
      "cs.DB"
    ],
    "authors": [
      "Hafsa Billah"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01763v1",
    "title": "HiconAgent: History Context-aware Policy Optimization for GUI Agents",
    "summary": "Graphical User Interface (GUI) agents require effective use of historical context to perform sequential navigation tasks. While incorporating past actions and observations can improve decision making, naive use of full history leads to excessive computational overhead and distraction from irrelevant information. To address this, we introduce HiconAgent, a GUI agent trained with History Context-aware Policy Optimization (HCPO) for efficient and effective utilization of historical information. HCPO optimizes history usage in both sampling and policy updates through two complementary components: (1) Dynamic Context Sampling (DCS) presents the agent with variable length histories during sampling, enabling adaptive use of the most relevant context; (2) Anchor-guided History Compression (AHC) refines the policy update phase with a dual branch strategy where the compressed branch removes history observations while keeping history actions as information flow anchors. The compressed and uncompressed branches are coupled through a history-enhanced alignment loss to enforce consistent history usage while maintaining efficiency. Experiments on mainstream GUI navigation benchmarks demonstrate strong performance. Despite being smaller, HiconAgent-3B outperforms GUI-R1-7B by +8.46 percent grounding accuracy and +11.32 percent step success rate on GUI-Odyssey, while achieving comparable results on AndroidControl and AITW with up to 2.47x computational speedup and 60 percent FLOPs reduction.",
    "published": "2025-12-01T15:06:45Z",
    "updated": "2025-12-01T15:06:45Z",
    "link": "http://arxiv.org/pdf/2512.01763v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xurui Zhou",
      "Gongwei Chen",
      "Yuquan Xie",
      "Zaijing Li",
      "Kaiwen Zhou",
      "Shuai Wang",
      "Shuo Yang",
      "Zhuotao Tian",
      "Rui Shao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01755v1",
    "title": "FreqEdit: Preserving High-Frequency Features for Robust Multi-Turn Image Editing",
    "summary": "Instruction-based image editing through natural language has emerged as a powerful paradigm for intuitive visual manipulation. While recent models achieve impressive results on single edits, they suffer from severe quality degradation under multi-turn editing. Through systematic analysis, we identify progressive loss of high-frequency information as the primary cause of this quality degradation. We present FreqEdit, a training-free framework that enables stable editing across 10+ consecutive iterations. Our approach comprises three synergistic components: (1) high-frequency feature injection from reference velocity fields to preserve fine-grained details, (2) an adaptive injection strategy that spatially modulates injection strength for precise region-specific control, and (3) a path compensation mechanism that periodically recalibrates the editing trajectory to prevent over-constraint. Extensive experiments demonstrate that FreqEdit achieves superior performance in both identity preservation and instruction following compared to seven state-of-the-art baselines.",
    "published": "2025-12-01T15:00:47Z",
    "updated": "2025-12-01T15:00:47Z",
    "link": "http://arxiv.org/pdf/2512.01755v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yucheng Liao",
      "Jiajun Liang",
      "Kaiqian Cui",
      "Baoquan Zhao",
      "Haoran Xie",
      "Wei Liu",
      "Qing Li",
      "Xudong Mao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.15844v2",
    "title": "FedHK-MVFC: Federated Heat Kernel Multi-View Clustering",
    "summary": "In the realm of distributed artificial intelligence (AI) and privacy-focused medical applications, this paper proposes a multi-view clustering framework that links quantum field theory with federated healthcare analytics. The method uses heat kernel coefficients from spectral analysis to convert Euclidean distances into geometry-aware similarity measures that capture the structure of diverse medical data. The framework is presented through the heat kernel distance (HKD) transformation, which has convergence guarantees. Two algorithms have been developed: The first, Heat Kernel-Enhanced Multi-View Fuzzy Clustering (HK-MVFC), is used for central analysis. The second, Federated Heat Kernel Multi-View Fuzzy Clustering (FedHK-MVFC), is used for secure, privacy-preserving learning across hospitals. FedHK-MVFC uses differential privacy and secure aggregation to enable HIPAA-compliant collaboration. Tests on synthetic cardiovascular patient datasets demonstrate increased clustering accuracy, reduced communication, and retained efficiency compared to centralized methods. After being validated on 10,000 synthetic patient records across two hospitals, the methods proved useful for collaborative phenotyping involving electrocardiogram (ECG) data, cardiac imaging data, and behavioral data. The proposed methods' theoretical contributions include update rules with proven convergence, adaptive view weighting, and privacy-preserving protocols. These contributions establish a new standard for geometry-aware federated learning in healthcare, translating advanced mathematics into practical solutions for analyzing sensitive medical data while ensuring rigor and clinical relevance.",
    "published": "2025-09-19T10:27:02Z",
    "updated": "2025-12-01T14:58:43Z",
    "link": "http://arxiv.org/pdf/2509.15844v2.pdf",
    "category": [
      "cs.LG",
      "cs.CV",
      "cs.DC",
      "math.AG"
    ],
    "authors": [
      "Kristina P. Sinaga"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.22939v2",
    "title": "DenoiseGS: Gaussian Reconstruction Model for Burst Denoising",
    "summary": "Burst denoising methods are crucial for enhancing images captured on handheld devices, but they often struggle with large motion or suffer from prohibitive computational costs. In this paper, we propose DenoiseGS, the first framework to leverage the efficiency of 3D Gaussian Splatting for burst denoising. Our approach addresses two key challenges when applying feedforward Gaussian reconsturction model to noisy inputs: the degradation of Gaussian point clouds and the loss of fine details. To this end, we propose a Gaussian self-consistency (GSC) loss, which regularizes the geometry predicted from noisy inputs with high-quality Gaussian point clouds. These point clouds are generated from clean inputs by the same model that we are training, thereby alleviating potential bias or domain gaps. Additionally, we introduce a log-weighted frequency (LWF) loss to strengthen supervision within the spectral domain, effectively preserving fine-grained details. The LWF loss adaptively weights frequency discrepancies in a logarithmic manner, emphasizing challenging high-frequency details. Extensive experiments demonstrate that DenoiseGS significantly exceeds the state-of-the-art NeRF-based methods on both burst denoising and novel view synthesis under noisy conditions, while achieving 250$\\times$ faster inference speed. Code and models are released at https://github.com/yscheng04/DenoiseGS.",
    "published": "2025-11-28T07:29:54Z",
    "updated": "2025-12-01T14:55:49Z",
    "link": "http://arxiv.org/pdf/2511.22939v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yongsen Cheng",
      "Yuanhao Cai",
      "Yulun Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.22242v2",
    "title": "TTSnap: Test-Time Scaling of Diffusion Models via Noise-Aware Pruning",
    "summary": "A prominent approach to test-time scaling for text-to-image diffusion models formulates the problem as a search over multiple noise seeds, selecting the one that maximizes a certain image-reward function. The effectiveness of this strategy heavily depends on the number and diversity of noise seeds explored. However, verifying each candidate is computationally expensive, because each must be fully denoised before a reward can be computed. This severely limits the number of samples that can be explored under a fixed budget. We propose test-time scaling with noise-aware pruning (TTSnap), a framework that prunes low-quality candidates without fully denoising them. The key challenge is that reward models are learned in the clean image domain, and the ranking of rewards predicted for intermediate estimates are often inconsistent with those predicted for clean images. To overcome this, we train noise-aware reward models via self-distillation to align the reward for intermediate estimates with that of the final clean images. To stabilize learning across different noise levels, we adopt a curriculum training strategy that progressively shifts the data domain from clean images to noise images. In addition, we introduce a new metric that measures reward alignment and computational budget utilization. Experiments demonstrate that our approach improves performance by over 16\\% compared with existing methods, enabling more efficient and effective test-time scaling. It also provides orthogonal gains when combined with post-training techniques and local test-time optimization. Code: https://github.com/TerrysLearning/TTSnap/.",
    "published": "2025-11-27T09:14:26Z",
    "updated": "2025-12-01T14:54:43Z",
    "link": "http://arxiv.org/pdf/2511.22242v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Qingtao Yu",
      "Changlin Song",
      "Minghao Sun",
      "Zhengyang Yu",
      "Vinay Kumar Verma",
      "Soumya Roy",
      "Sumit Negi",
      "Hongdong Li",
      "Dylan Campbell"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.11508v2",
    "title": "Towards Fast and Scalable Normal Integration using Continuous Components",
    "summary": "Surface normal integration is a fundamental problem in computer vision, dealing with the objective of reconstructing a surface from its corresponding normal map. Existing approaches require an iterative global optimization to jointly estimate the depth of each pixel, which scales poorly to larger normal maps. In this paper, we address this problem by recasting normal integration as the estimation of relative scales of continuous components. By constraining pixels belonging to the same component to jointly vary their scale, we drastically reduce the number of optimization variables. Our framework includes a heuristic to accurately estimate continuous components from the start, a strategy to rebalance optimization terms, and a technique to iteratively merge components to further reduce the size of the problem. Our method achieves state-of-the-art results on the standard normal integration benchmark in as little as a few seconds and achieves one-order-of-magnitude speedup over pixel-level approaches on large-resolution normal maps.",
    "published": "2025-10-13T15:17:16Z",
    "updated": "2025-12-01T14:52:55Z",
    "link": "http://arxiv.org/pdf/2510.11508v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Francesco Milano",
      "Jen Jen Chung",
      "Lionel Ott",
      "Roland Siegwart"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.10194v2",
    "title": "B2N3D: Progressive Learning from Binary to N-ary Relationships for 3D Object Grounding",
    "summary": "Localizing 3D objects using natural language is essential for robotic scene understanding. The descriptions often involve multiple spatial relationships to distinguish similar objects, making 3D-language alignment difficult. Current methods only model relationships for pairwise objects, ignoring the global perceptual significance of n-ary combinations in multi-modal relational understanding. To address this, we propose a novel progressive relational learning framework for 3D object grounding. We extend relational learning from binary to n-ary to identify visual relations that match the referential description globally. Given the absence of specific annotations for referred objects in the training data, we design a grouped supervision loss to facilitate n-ary relational learning. In the scene graph created with n-ary relationships, we use a multi-modal network with hybrid attention mechanisms to further localize the target within the n-ary combinations. Experiments and ablation studies on the ReferIt3D and ScanRefer benchmarks demonstrate that our method outperforms the state-of-the-art, and proves the advantages of the n-ary relational perception in 3D localization.",
    "published": "2025-10-11T12:17:12Z",
    "updated": "2025-12-01T14:40:55Z",
    "link": "http://arxiv.org/pdf/2510.10194v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Feng Xiao",
      "Hongbin Xu",
      "Hai Ci",
      "Wenxiong Kang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.06591v5",
    "title": "Hybrid Swin Attention Networks for Simultaneously Low-Dose PET and CT Denoising",
    "summary": "Low-dose computed tomography (LDCT) and positron emission tomography (PET) have emerged as safer alternatives to conventional imaging modalities by significantly reducing radiation exposure. However, this reduction often results in increased noise and artifacts, which can compromise diagnostic accuracy. Consequently, denoising for LDCT/PET has become a vital area of research aimed at enhancing image quality while maintaining radiation safety. In this study, we introduce a novel Hybrid Swin Attention Network (HSANet), which incorporates Efficient Global Attention (EGA) modules and a hybrid upsampling module. The EGA modules enhance both spatial and channel-wise interaction, improving the network's capacity to capture relevant features, while the hybrid upsampling module mitigates the risk of overfitting to noise. We validate the proposed approach using a publicly available LDCT/PET dataset. Experimental results demonstrate that HSANet achieves superior denoising performance compared to existing methods, while maintaining a lightweight model size suitable for deployment on GPUs with standard memory configurations. This makes our approach highly practical for real-world clinical applications.",
    "published": "2025-09-08T12:02:38Z",
    "updated": "2025-12-01T14:38:47Z",
    "link": "http://arxiv.org/pdf/2509.06591v5.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yichao Liu",
      "Hengzhi Xue",
      "YueYang Teng",
      "Junwen Guo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.17735v2",
    "title": "RDTF: Resource-efficient Dual-mask Training Framework for Multi-frame Animated Sticker Generation",
    "summary": "Recently, significant advancements have been achieved in video generation technology, but applying it to resource-constrained downstream tasks like multi-frame animated sticker generation (ASG) characterized by low frame rates, abstract semantics, and long tail frame length distribution-remains challenging. Parameter-efficient fine-tuning (PEFT) techniques (e.g., Adapter, LoRA) for large pre-trained models suffer from insufficient fitting ability and source-domain knowledge interference. In this paper, we propose Resource-Efficient Dual-Mask Training Framework (RDTF), a dedicated solution for multi-frame ASG task under resource constraints. We argue that training a compact model from scratch with million-level samples outperforms PEFT on large models, with RDTF realizing this via three core designs: 1) a Discrete Frame Generation Network (DFGN) optimized for low-frame-rate ASG, ensuring parameter efficiency; 2) a dual-mask based data utilization strategy to enhance the availability and diversity of limited data; 3) a difficulty-adaptive curriculum learning method that decomposes sample entropy into static and adaptive components, enabling easy-to-difficult training convergence. To provide high-quality data support for RDTFs training from scratch, we construct VSD2M-a million-level multi-modal animated sticker dataset with rich annotations (static and animated stickers, action-focused text descriptions)-filling the gap of dedicated animated data for ASG task. Experiments demonstrate that RDTF is quantitatively and qualitatively superior to state-of-the-art PEFT methods (e.g., I2V-Adapter, SimDA) on ASG tasks, verifying the feasibility of our framework under resource constraints.",
    "published": "2025-03-22T11:28:25Z",
    "updated": "2025-12-01T14:22:02Z",
    "link": "http://arxiv.org/pdf/2503.17735v2.pdf",
    "category": [
      "cs.MM",
      "cs.CV"
    ],
    "authors": [
      "Zhiqiang Yuan",
      "Ting Zhang",
      "Peixiang Luo",
      "Ying Deng",
      "Jiapei Zhang",
      "Zexi Jia",
      "Jinchao Zhang",
      "Jie Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01701v1",
    "title": "SSR: Semantic and Spatial Rectification for CLIP-based Weakly Supervised Segmentation",
    "summary": "In recent years, Contrastive Language-Image Pretraining (CLIP) has been widely applied to Weakly Supervised Semantic Segmentation (WSSS) tasks due to its powerful cross-modal semantic understanding capabilities. This paper proposes a novel Semantic and Spatial Rectification (SSR) method to address the limitations of existing CLIP-based weakly supervised semantic segmentation approaches: over-activation in non-target foreground regions and background areas. Specifically, at the semantic level, the Cross-Modal Prototype Alignment (CMPA) establishes a contrastive learning mechanism to enforce feature space alignment across modalities, reducing inter-class overlap while enhancing semantic correlations, to rectify over-activation in non-target foreground regions effectively; at the spatial level, the Superpixel-Guided Correction (SGC) leverages superpixel-based spatial priors to precisely filter out interference from non-target regions during affinity propagation, significantly rectifying background over-activation. Extensive experiments on the PASCAL VOC and MS COCO datasets demonstrate that our method outperforms all single-stage approaches, as well as more complex multi-stage approaches, achieving mIoU scores of 79.5% and 50.6%, respectively.",
    "published": "2025-12-01T14:06:50Z",
    "updated": "2025-12-01T14:06:50Z",
    "link": "http://arxiv.org/pdf/2512.01701v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xiuli Bi",
      "Die Xiao",
      "Junchao Fan",
      "Bin Xiao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.22768v2",
    "title": "Fusion or Confusion? Assessing the impact of visible-thermal image fusion for automated wildlife detection",
    "summary": "Efficient wildlife monitoring methods are necessary for biodiversity conservation and management. The combination of remote sensing, aerial imagery and deep learning offer promising opportunities to renew or improve existing survey methods. The complementary use of visible (VIS) and thermal infrared (TIR) imagery can add information compared to a single-source image and improve results in an automated detection context. However, the alignment and fusion process can be challenging, especially since visible and thermal images usually have different fields of view (FOV) and spatial resolutions. This research presents a case study on the great blue heron (Ardea herodias) to evaluate the performances of synchronous aerial VIS and TIR imagery to automatically detect individuals and nests using a YOLO11n model. Two VIS-TIR fusion methods were tested and compared: an early fusion approach and a late fusion approach, to determine if the addition of the TIR image gives any added value compared to a VIS-only model. VIS and TIR images were automatically aligned using a deep learning model. A principal component analysis fusion method was applied to VIS-TIR image pairs to form the early fusion dataset. A classification and regression tree was used to process the late fusion dataset, based on the detection from the VIS-only and TIR-only trained models. Across all classes, both late and early fusion improved the F1 score compared to the VIS-only model. For the main class, occupied nest, the late fusion improved the F1 score from 90.2 (VIS-only) to 93.0%. This model was also able to identify false positives from both sources with 90% recall. Although fusion methods seem to give better results, this approach comes with a limiting TIR FOV and alignment constraints that eliminate data. Using an aircraft-mounted very high-resolution visible sensor could be an interesting option for operationalizing surveys.",
    "published": "2025-11-27T21:36:06Z",
    "updated": "2025-12-01T13:59:40Z",
    "link": "http://arxiv.org/pdf/2511.22768v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Camille Dionne-Pierre",
      "Samuel Foucher",
      "Jérôme Théau",
      "Jérôme Lemaître",
      "Patrick Charbonneau",
      "Maxime Brousseau",
      "Mathieu Varin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01687v1",
    "title": "Revisiting Direct Encoding: Learnable Temporal Dynamics for Static Image Spiking Neural Networks",
    "summary": "Handling static images that lack inherent temporal dynamics remains a fundamental challenge for spiking neural networks (SNNs). In directly trained SNNs, static inputs are typically repeated across time steps, causing the temporal dimension to collapse into a rate like representation and preventing meaningful temporal modeling. This work revisits the reported performance gap between direct and rate based encodings and shows that it primarily stems from convolutional learnability and surrogate gradient formulations rather than the encoding schemes themselves. To illustrate this mechanism level clarification, we introduce a minimal learnable temporal encoding that adds adaptive phase shifts to induce meaningful temporal variation from static inputs.",
    "published": "2025-12-01T13:55:00Z",
    "updated": "2025-12-01T13:55:00Z",
    "link": "http://arxiv.org/pdf/2512.01687v1.pdf",
    "category": [
      "cs.NE",
      "cs.CV"
    ],
    "authors": [
      "Huaxu He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01686v1",
    "title": "DreamingComics: A Story Visualization Pipeline via Subject and Layout Customized Generation using Video Models",
    "summary": "Current story visualization methods tend to position subjects solely by text and face challenges in maintaining artistic consistency. To address these limitations, we introduce DreamingComics, a layout-aware story visualization framework. We build upon a pretrained video diffusion-transformer (DiT) model, leveraging its spatiotemporal priors to enhance identity and style consistency. For layout-based position control, we propose RegionalRoPE, a region-aware positional encoding scheme that re-indexes embeddings based on the target layout. Additionally, we introduce a masked condition loss to further constrain each subject's visual features to their designated region. To infer layouts from natural language scripts, we integrate an LLM-based layout generator trained to produce comic-style layouts, enabling flexible and controllable layout conditioning. We present a comprehensive evaluation of our approach, showing a 29.2% increase in character consistency and a 36.2% increase in style similarity compared to previous methods, while displaying high spatial accuracy. Our project page is available at https://yj7082126.github.io/dreamingcomics/",
    "published": "2025-12-01T13:51:41Z",
    "updated": "2025-12-01T13:51:41Z",
    "link": "http://arxiv.org/pdf/2512.01686v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Patrick Kwon",
      "Chen Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.22625v2",
    "title": "ReasonEdit: Towards Reasoning-Enhanced Image Editing Models",
    "summary": "Recent advances in image editing models have shown remarkable progress. A common architectural design couples a multimodal large language model (MLLM) encoder with a diffusion decoder, as seen in systems such as Step1X-Edit and Qwen-Image-Edit, where the MLLM encodes both the reference image and the instruction but remains frozen during training. In this work, we demonstrate that unlocking the reasoning capabilities of MLLM can further push the boundaries of editing models. Specifically, we explore two reasoning mechanisms, thinking and reflection, which enhance instruction understanding and editing accuracy. Based on that, our proposed framework enables image editing in a thinking-editing-reflection loop: the thinking mechanism leverages the world knowledge of MLLM to interpret abstract instructions, while the reflection reviews editing results, automatically corrects unintended manipulations, and identifies the stopping round. Extensive experiments demonstrate that our reasoning approach achieves significant performance gains, with improvements of ImgEdit (+4.3%), GEdit (+4.7%), and Kris (+8.2%) when initializing our DiT from the Step1X-Edit (ReasonEdit-S), and also outperforms previous open-source methods on both GEdit and Kris when integrated with Qwen-Image-Edit (ReasonEdit-Q).",
    "published": "2025-11-27T17:02:48Z",
    "updated": "2025-12-01T13:51:36Z",
    "link": "http://arxiv.org/pdf/2511.22625v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Fukun Yin",
      "Shiyu Liu",
      "Yucheng Han",
      "Zhibo Wang",
      "Peng Xing",
      "Rui Wang",
      "Wei Cheng",
      "Yingming Wang",
      "Aojie Li",
      "Zixin Yin",
      "Pengtao Chen",
      "Xiangyu Zhang",
      "Daxin Jiang",
      "Xianfang Zeng",
      "Gang Yu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01681v1",
    "title": "Cross-Domain Validation of a Resection-Trained Self-Supervised Model on Multicentre Mesothelioma Biopsies",
    "summary": "Accurate subtype classification and outcome prediction in mesothelioma are essential for guiding therapy and patient care. Most computational pathology models are trained on large tissue images from resection specimens, limiting their use in real-world settings where small biopsies are common. We show that a self-supervised encoder trained on resection tissue can be applied to biopsy material, capturing meaningful morphological patterns. Using these patterns, the model can predict patient survival and classify tumor subtypes. This approach demonstrates the potential of AI-driven tools to support diagnosis and treatment planning in mesothelioma.",
    "published": "2025-12-01T13:46:43Z",
    "updated": "2025-12-01T13:46:43Z",
    "link": "http://arxiv.org/pdf/2512.01681v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Farzaneh Seyedshahi",
      "Francesca Damiola",
      "Sylvie Lantuejoul",
      "Ke Yuan",
      "John Le Quesne"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01677v1",
    "title": "Open-world Hand-Object Interaction Video Generation Based on Structure and Contact-aware Representation",
    "summary": "Generating realistic hand-object interactions (HOI) videos is a significant challenge due to the difficulty of modeling physical constraints (e.g., contact and occlusion between hands and manipulated objects). Current methods utilize HOI representation as an auxiliary generative objective to guide video synthesis. However, there is a dilemma between 2D and 3D representations that cannot simultaneously guarantee scalability and interaction fidelity. To address this limitation, we propose a structure and contact-aware representation that captures hand-object contact, hand-object occlusion, and holistic structure context without 3D annotations. This interaction-oriented and scalable supervision signal enables the model to learn fine-grained interaction physics and generalize to open-world scenarios. To fully exploit the proposed representation, we introduce a joint-generation paradigm with a share-and-specialization strategy that generates interaction-oriented representations and videos. Extensive experiments demonstrate that our method outperforms state-of-the-art methods on two real-world datasets in generating physics-realistic and temporally coherent HOI videos. Furthermore, our approach exhibits strong generalization to challenging open-world scenarios, highlighting the benefit of our scalable design. Our project page is https://hgzn258.github.io/SCAR/.",
    "published": "2025-12-01T13:44:31Z",
    "updated": "2025-12-01T13:44:31Z",
    "link": "http://arxiv.org/pdf/2512.01677v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Haodong Yan",
      "Hang Yu",
      "Zhide Zhong",
      "Weilin Yuan",
      "Xin Gong",
      "Zehang Luo",
      "Chengxi Heyu",
      "Junfeng Li",
      "Wenxuan Song",
      "Shunbo Zhou",
      "Haoang Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01675v1",
    "title": "GRASP: Guided Residual Adapters with Sample-wise Partitioning",
    "summary": "Recent advances in text-to-image diffusion models enable high-fidelity generation across diverse prompts. However, these models falter in long-tail settings, such as medical imaging, where rare pathologies comprise a small fraction of data. This results in mode collapse: tail-class outputs lack quality and diversity, undermining the goal of synthetic data augmentation for underrepresented conditions. We pinpoint gradient conflicts between frequent head and rare tail classes as the primary culprit, a factor unaddressed by existing sampling or conditioning methods that mainly steer inference without altering the learned distribution. To resolve this, we propose GRASP: Guided Residual Adapters with Sample-wise Partitioning. GRASP uses external priors to statically partition samples into clusters that minimize intra-group gradient clashes. It then fine-tunes pre-trained models by injecting cluster-specific residual adapters into transformer feedforward layers, bypassing learned gating for stability and efficiency. On the long-tail MIMIC-CXR-LT dataset, GRASP yields superior FID and diversity metrics, especially for rare classes, outperforming baselines like vanilla fine-tuning and Mixture of Experts variants. Downstream classification on NIH-CXR-LT improves considerably for tail labels. Generalization to ImageNet-LT confirms broad applicability. Our method is lightweight, scalable, and readily integrates with diffusion pipelines.",
    "published": "2025-12-01T13:43:17Z",
    "updated": "2025-12-01T13:43:17Z",
    "link": "http://arxiv.org/pdf/2512.01675v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Felix Nützel",
      "Mischa Dombrowski",
      "Bernhard Kainz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01665v1",
    "title": "Bridging the Scale Gap: Balanced Tiny and General Object Detection in Remote Sensing Imagery",
    "summary": "Tiny object detection in remote sensing imagery has attracted significant research interest in recent years. Despite recent progress, achieving balanced detection performance across diverse object scales remains a formidable challenge, particularly in scenarios where dense tiny objects and large objects coexist. Although large foundation models have revolutionized general vision tasks, their application to tiny object detection remains unexplored due to the extreme scale variation and density distribution inherent to remote sensing imagery. To bridge this scale gap, we propose ScaleBridge-Det, to the best of our knowledge, the first large detection framework designed for tiny objects, which could achieve balanced performance across diverse scales through scale-adaptive expert routing and density-guided query allocation. Specifically, we introduce a Routing-Enhanced Mixture Attention (REM) module that dynamically selects and fuses scale-specific expert features via adaptive routing to address the tendency of standard MoE models to favor dominant scales. REM generates complementary and discriminative multi-scale representations suitable for both tiny and large objects. Furthermore, we present a Density-Guided Dynamic Query (DGQ) module that predicts object density to adaptively adjust query positions and numbers, enabling efficient resource allocation for objects of varying scales. The proposed framework allows ScaleBridge-Det to simultaneously optimize performance for both dense tiny and general objects without trade-offs. Extensive experiments on benchmark and cross-domain datasets demonstrate that ScaleBridge-Det achieves state-of-the-art performance on AI-TOD-V2 and DTOD, while exhibiting superior cross-domain robustness on VisDrone.",
    "published": "2025-12-01T13:36:09Z",
    "updated": "2025-12-01T13:36:09Z",
    "link": "http://arxiv.org/pdf/2512.01665v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhicheng Zhao",
      "Yin Huang",
      "Lingma Sun",
      "Chenglong Li",
      "Jin Tang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01657v1",
    "title": "DB-KAUNet: An Adaptive Dual Branch Kolmogorov-Arnold UNet for Retinal Vessel Segmentation",
    "summary": "Accurate segmentation of retinal vessels is crucial for the clinical diagnosis of numerous ophthalmic and systemic diseases. However, traditional Convolutional Neural Network (CNN) methods exhibit inherent limitations, struggling to capture long-range dependencies and complex nonlinear relationships. To address the above limitations, an Adaptive Dual Branch Kolmogorov-Arnold UNet (DB-KAUNet) is proposed for retinal vessel segmentation. In DB-KAUNet, we design a Heterogeneous Dual-Branch Encoder (HDBE) that features parallel CNN and Transformer pathways. The HDBE strategically interleaves standard CNN and Transformer blocks with novel KANConv and KAT blocks, enabling the model to form a comprehensive feature representation. To optimize feature processing, we integrate several critical components into the HDBE. First, a Cross-Branch Channel Interaction (CCI) module is embedded to facilitate efficient interaction of channel features between the parallel pathways. Second, an attention-based Spatial Feature Enhancement (SFE) module is employed to enhance spatial features and fuse the outputs from both branches. Building upon the SFE module, an advanced Spatial Feature Enhancement with Geometrically Adaptive Fusion (SFE-GAF) module is subsequently developed. In the SFE-GAF module, adaptive sampling is utilized to focus on true vessel morphology precisely. The adaptive process strengthens salient vascular features while significantly reducing background noise and computational overhead. Extensive experiments on the DRIVE, STARE, and CHASE_DB1 datasets validate that DB-KAUNet achieves leading segmentation performance and demonstrates exceptional robustness.",
    "published": "2025-12-01T13:30:01Z",
    "updated": "2025-12-01T13:30:01Z",
    "link": "http://arxiv.org/pdf/2512.01657v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Hongyu Xu",
      "Panpan Meng",
      "Meng Wang",
      "Dayu Hu",
      "Liming Liang",
      "Xiaoqi Sheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.17314v3",
    "title": "Class-Conditional Distribution Balancing for Group Robust Classification",
    "summary": "Spurious correlations that lead models to correct predictions for the wrong reasons pose a critical challenge for robust real-world generalization. Existing research attributes this issue to group imbalance and addresses it by maximizing group-balanced or worst-group accuracy, which heavily relies on expensive bias annotations. A compromise approach involves predicting bias information using extensively pretrained foundation models, which requires large-scale data and becomes impractical for resource-limited rare domains. To address these challenges, we offer a novel perspective by reframing the spurious correlations as imbalances or mismatches in class-conditional distributions, and propose a simple yet effective robust learning method that eliminates the need for both bias annotations and predictions. With the goal of maximizing the conditional entropy (uncertainty) of the label given spurious factors, our method leverages a sample reweighting strategy to achieve class-conditional distribution balancing, which automatically highlights minority groups and classes, effectively dismantling spurious correlations and producing a debiased data distribution for classification. Extensive experiments and analysis demonstrate that our approach consistently delivers state-of-the-art performance, rivaling methods that rely on bias supervision.",
    "published": "2025-04-24T07:15:53Z",
    "updated": "2025-12-01T13:25:05Z",
    "link": "http://arxiv.org/pdf/2504.17314v3.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Miaoyun Zhao",
      "Chenrong Li",
      "Qiang Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01643v1",
    "title": "ViT$^3$: Unlocking Test-Time Training in Vision",
    "summary": "Test-Time Training (TTT) has recently emerged as a promising direction for efficient sequence modeling. TTT reformulates attention operation as an online learning problem, constructing a compact inner model from key-value pairs at test time. This reformulation opens a rich and flexible design space while achieving linear computational complexity. However, crafting a powerful visual TTT design remains challenging: fundamental choices for the inner module and inner training lack comprehensive understanding and practical guidelines. To bridge this critical gap, in this paper, we present a systematic empirical study of TTT designs for visual sequence modeling. From a series of experiments and analyses, we distill six practical insights that establish design principles for effective visual TTT and illuminate paths for future improvement. These findings culminate in the Vision Test-Time Training (ViT$^3$) model, a pure TTT architecture that achieves linear complexity and parallelizable computation. We evaluate ViT$^3$ across diverse visual tasks, including image classification, image generation, object detection, and semantic segmentation. Results show that ViT$^3$ consistently matches or outperforms advanced linear-complexity models (e.g., Mamba and linear attention variants) and effectively narrows the gap to highly optimized vision Transformers. We hope this study and the ViT$^3$ baseline can facilitate future work on visual TTT models. Code is available at https://github.com/LeapLabTHU/ViTTT.",
    "published": "2025-12-01T13:14:48Z",
    "updated": "2025-12-01T13:14:48Z",
    "link": "http://arxiv.org/pdf/2512.01643v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Dongchen Han",
      "Yining Li",
      "Tianyu Li",
      "Zixuan Cao",
      "Ziming Wang",
      "Jun Song",
      "Yu Cheng",
      "Bo Zheng",
      "Gao Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01636v1",
    "title": "Generative Editing in the Joint Vision-Language Space for Zero-Shot Composed Image Retrieval",
    "summary": "Composed Image Retrieval (CIR) enables fine-grained visual search by combining a reference image with a textual modification. While supervised CIR methods achieve high accuracy, their reliance on costly triplet annotations motivates zero-shot solutions. The core challenge in zero-shot CIR (ZS-CIR) stems from a fundamental dilemma: existing text-centric or diffusion-based approaches struggle to effectively bridge the vision-language modality gap. To address this, we propose Fusion-Diff, a novel generative editing framework with high effectiveness and data efficiency designed for multimodal alignment. First, it introduces a multimodal fusion feature editing strategy within a joint vision-language (VL) space, substantially narrowing the modality gap. Second, to maximize data efficiency, the framework incorporates a lightweight Control-Adapter, enabling state-of-the-art performance through fine-tuning on only a limited-scale synthetic dataset of 200K samples. Extensive experiments on standard CIR benchmarks (CIRR, FashionIQ, and CIRCO) demonstrate that Fusion-Diff significantly outperforms prior zero-shot approaches. We further enhance the interpretability of our model by visualizing the fused multimodal representations.",
    "published": "2025-12-01T13:04:55Z",
    "updated": "2025-12-01T13:04:55Z",
    "link": "http://arxiv.org/pdf/2512.01636v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xin Wang",
      "Haipeng Zhang",
      "Mang Li",
      "Zhaohui Xia",
      "Yueguo Chen",
      "Yu Zhang",
      "Chunyu Wei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01629v1",
    "title": "SPARK: Sim-ready Part-level Articulated Reconstruction with VLM Knowledge",
    "summary": "Articulated 3D objects are critical for embodied AI, robotics, and interactive scene understanding, yet creating simulation-ready assets remains labor-intensive and requires expert modeling of part hierarchies and motion structures. We introduce SPARK, a framework for reconstructing physically consistent, kinematic part-level articulated objects from a single RGB image. Given an input image, we first leverage VLMs to extract coarse URDF parameters and generate part-level reference images. We then integrate the part-image guidance and the inferred structure graph into a generative diffusion transformer to synthesize consistent part and complete shapes of articulated objects. To further refine the URDF parameters, we incorporate differentiable forward kinematics and differentiable rendering to optimize joint types, axes, and origins under VLM-generated open-state supervision. Extensive experiments show that SPARK produces high-quality, simulation-ready articulated assets across diverse categories, enabling downstream applications such as robotic manipulation and interaction modeling.",
    "published": "2025-12-01T12:51:56Z",
    "updated": "2025-12-01T12:51:56Z",
    "link": "http://arxiv.org/pdf/2512.01629v1.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Yumeng He",
      "Ying Jiang",
      "Jiayin Lu",
      "Yin Yang",
      "Chenfanfu Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.20635v2",
    "title": "iMontage: Unified, Versatile, Highly Dynamic Many-to-many Image Generation",
    "summary": "Pre-trained video models learn powerful priors for generating high-quality, temporally coherent content. While these models excel at temporal coherence, their dynamics are often constrained by the continuous nature of their training data. We hypothesize that by injecting the rich and unconstrained content diversity from image data into this coherent temporal framework, we can generate image sets that feature both natural transitions and a far more expansive dynamic range. To this end, we introduce iMontage, a unified framework designed to repurpose a powerful video model into an all-in-one image generator. The framework consumes and produces variable-length image sets, unifying a wide array of image generation and editing tasks. To achieve this, we propose an elegant and minimally invasive adaptation strategy, complemented by a tailored data curation process and training paradigm. This approach allows the model to acquire broad image manipulation capabilities without corrupting its invaluable original motion priors. iMontage excels across several mainstream many-in-many-out tasks, not only maintaining strong cross-image contextual consistency but also generating scenes with extraordinary dynamics that surpass conventional scopes. Find our homepage at: https://kr1sjfu.github.io/iMontage-web/.",
    "published": "2025-11-25T18:54:16Z",
    "updated": "2025-12-01T12:41:02Z",
    "link": "http://arxiv.org/pdf/2511.20635v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhoujie Fu",
      "Xianfang Zeng",
      "Jinghong Lan",
      "Xinyao Liao",
      "Cheng Chen",
      "Junyi Chen",
      "Jiacheng Wei",
      "Wei Cheng",
      "Shiyu Liu",
      "Yunuo Chen",
      "Gang Yu",
      "Guosheng Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.20469v2",
    "title": "Prediction of Distant Metastasis in Head and Neck Cancer Patients Using Tumor and Peritumoral Multi-Modal Deep Learning",
    "summary": "Although the combined treatment of surgery, radiotherapy, chemotherapy, and emerging target therapy has significantly improved the outcomes of patients with head and neck cancer, distant metastasis remains the leading cause of treatment failure. In this study, we propose a deep learning-based multimodal framework integrating CT imaging, radiomics, and clinical data to predict metastasis risk in HNSCC. A total of 1497 patients were retrospectively analyzed. Tumor and organ masks were generated from pretreatment CT scans, from which a 3D Swin Transformer extracted deep imaging features, while 1562 radiomics features were reduced to 36 via correlation filtering and random forest selection. Clinical data (age, sex, smoking, and alcohol status) were encoded and fused with imaging features, and the multimodal representation was fed into a fully connected network for prediction. Five-fold cross-validation was used to assess performance via AUC, accuracy, sensitivity, and specificity. The multimodal model outperformed all single-modality baselines. The deep learning module alone achieved an AUC of 0.715, whereas multimodal fusion significantly improved performance (AUC = 0.803, ACC = 0.752, SEN = 0.730, SPE = 0.758). Stratified analyses confirmed good generalizability across tumor subtypes. Ablation experiments demonstrated complementary contributions from each modality, and the 3D Swin Transformer provided more robust representations than conventional architectures. This multimodal deep learning model enables accurate, non-invasive metastasis prediction in HNSCC and shows strong potential for individualized treatment planning.",
    "published": "2025-08-28T06:39:38Z",
    "updated": "2025-12-01T12:32:48Z",
    "link": "http://arxiv.org/pdf/2508.20469v2.pdf",
    "category": [
      "q-bio.QM",
      "cs.CV"
    ],
    "authors": [
      "Nuo Tong",
      "Changhao Liu",
      "Zizhao Tang",
      "Feifan Sun",
      "Yingping Li",
      "Shuiping Gou",
      "Mei Shi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01611v1",
    "title": "Depth Matching Method Based on ShapeDTW for Oil-Based Mud Imager",
    "summary": "In well logging operations using the oil-based mud (OBM) microresistivity imager, which employs an interleaved design with upper and lower pad sets, depth misalignment issues persist between the pad images even after velocity correction. This paper presents a depth matching method for borehole images based on the Shape Dynamic Time Warping (ShapeDTW) algorithm. The method extracts local shape features to construct a morphologically sensitive distance matrix, better preserving structural similarity between sequences during alignment. We implement this by employing a combined feature set of the one-dimensional Histogram of Oriented Gradients (HOG1D) and the original signal as the shape descriptor. Field test examples demonstrate that our method achieves precise alignment for images with complex textures, depth shifts, or local scaling. Furthermore, it provides a flexible framework for feature extension, allowing the integration of other descriptors tailored to specific geological features.",
    "published": "2025-12-01T12:31:09Z",
    "updated": "2025-12-01T12:31:09Z",
    "link": "http://arxiv.org/pdf/2512.01611v1.pdf",
    "category": [
      "cs.CV",
      "physics.geo-ph"
    ],
    "authors": [
      "Fengfeng Li",
      "Zhou Feng",
      "Hongliang Wu",
      "Hao Zhang",
      "Han Tian",
      "Peng Liu",
      "Lixin Yuan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.23172v2",
    "title": "Fast Multi-view Consistent 3D Editing with Video Priors",
    "summary": "Text-driven 3D editing enables user-friendly 3D object or scene editing with text instructions. Due to the lack of multi-view consistency priors, existing methods typically resort to employing 2D generation or editing models to process each view individually, followed by iterative 2D-3D-2D updating. However, these methods are not only time-consuming but also prone to over-smoothed results because the different editing signals gathered from different views are averaged during the iterative process. In this paper, we propose generative Video Prior based 3D Editing (ViP3DE) to employ the temporal consistency priors from pre-trained video generation models for multi-view consistent 3D editing in a single forward pass. Our key insight is to condition the video generation model on a single edited view to generate other consistent edited views for 3D updating directly, thereby bypassing the iterative editing paradigm. Since 3D updating requires edited views to be paired with specific camera poses, we propose motion-preserved noise blending for the video model to generate edited views at predefined camera poses. In addition, we introduce geometry-aware denoising to further enhance multi-view consistency by integrating 3D geometric priors into video models. Extensive experiments demonstrate that our proposed ViP3DE can achieve high-quality 3D editing results even within a single forward pass, significantly outperforming existing methods in both editing quality and speed.",
    "published": "2025-11-28T13:31:10Z",
    "updated": "2025-12-01T12:29:25Z",
    "link": "http://arxiv.org/pdf/2511.23172v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Liyi Chen",
      "Ruihuang Li",
      "Guowen Zhang",
      "Pengfei Wang",
      "Lei Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01589v1",
    "title": "Toward Content-based Indexing and Retrieval of Head and Neck CT with Abscess Segmentation",
    "summary": "Abscesses in the head and neck represent an acute infectious process that can potentially lead to sepsis or mortality if not diagnosed and managed promptly. Accurate detection and delineation of these lesions on imaging are essential for diagnosis, treatment planning, and surgical intervention. In this study, we introduce AbscessHeNe, a curated and comprehensively annotated dataset comprising 4,926 contrast-enhanced CT slices with clinically confirmed head and neck abscesses. The dataset is designed to facilitate the development of robust semantic segmentation models that can accurately delineate abscess boundaries and evaluate deep neck space involvement, thereby supporting informed clinical decision-making. To establish performance baselines, we evaluate several state-of-the-art segmentation architectures, including CNN, Transformer, and Mamba-based models. The highest-performing model achieved a Dice Similarity Coefficient of 0.39, Intersection-over-Union of 0.27, and Normalized Surface Distance of 0.67, indicating the challenges of this task and the need for further research. Beyond segmentation, AbscessHeNe is structured for future applications in content-based multimedia indexing and case-based retrieval. Each CT scan is linked with pixel-level annotations and clinical metadata, providing a foundation for building intelligent retrieval systems and supporting knowledge-driven clinical workflows. The dataset will be made publicly available at https://github.com/drthaodao3101/AbscessHeNe.git.",
    "published": "2025-12-01T12:04:24Z",
    "updated": "2025-12-01T12:04:24Z",
    "link": "http://arxiv.org/pdf/2512.01589v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Thao Thi Phuong Dao",
      "Tan-Cong Nguyen",
      "Trong-Le Do",
      "Truong Hoang Viet",
      "Nguyen Chi Thanh",
      "Huynh Nguyen Thuan",
      "Do Vo Cong Nguyen",
      "Minh-Khoi Pham",
      "Mai-Khiem Tran",
      "Viet-Tham Huynh",
      "Trong-Thuan Nguyen",
      "Trung-Nghia Le",
      "Vo Thanh Toan",
      "Tam V. Nguyen",
      "Minh-Triet Tran",
      "Thanh Dinh Le"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.14819v2",
    "title": "Capturing Context-Aware Route Choice Semantics for Trajectory Representation Learning",
    "summary": "Trajectory representation learning (TRL) aims to encode raw trajectory data into low-dimensional embeddings for downstream tasks such as travel time estimation, mobility prediction, and trajectory similarity analysis. From a behavioral perspective, a trajectory reflects a sequence of route choices within an urban environment. However, most existing TRL methods ignore this underlying decision-making process and instead treat trajectories as static, passive spatiotemporal sequences, thereby limiting the semantic richness of the learned representations. To bridge this gap, we propose CORE, a TRL framework that integrates context-aware route choice semantics into trajectory embeddings. CORE first incorporates a multi-granular Environment Perception Module, which leverages large language models (LLMs) to distill environmental semantics from point of interest (POI) distributions, thereby constructing a context-enriched road network. Building upon this backbone, CORE employs a Route Choice Encoder with a mixture-of-experts (MoE) architecture, which captures route choice patterns by jointly leveraging the context-enriched road network and navigational factors. Finally, a Transformer encoder aggregates the route-choice-aware representations into a global trajectory embedding. Extensive experiments on 4 real-world datasets across 6 downstream tasks demonstrate that CORE consistently outperforms 12 state-of-the-art TRL methods, achieving an average improvement of 9.79% over the best-performing baseline. Our code is available at https://github.com/caoji2001/CORE.",
    "published": "2025-10-16T15:55:28Z",
    "updated": "2025-12-01T11:42:33Z",
    "link": "http://arxiv.org/pdf/2510.14819v2.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Ji Cao",
      "Yu Wang",
      "Tongya Zheng",
      "Jie Song",
      "Qinghong Guo",
      "Zujie Ren",
      "Canghong Jin",
      "Gang Chen",
      "Mingli Song"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2409.07417v2",
    "title": "Self-Supervised One-Step Diffusion Refinement for Snapshot Compressive Imaging",
    "summary": "Snapshot compressive imaging (SCI) captures multispectral images (MSIs) using a single coded two-dimensional (2-D) measurement, but reconstructing high-fidelity MSIs from these compressed inputs remains a fundamentally ill-posed challenge. While diffusion-based reconstruction methods have recently raised the bar for quality, they face critical limitations: a lack of large-scale MSI training data, adverse domain shifts from RGB-pretrained models, and inference inefficiencies due to multi-step sampling. These drawbacks restrict their practicality in real-world applications. In contrast to existing methods, which either follow costly iterative refinement or adapt subspace-based embeddings for diffusion models (e.g. DiffSCI, PSR-SCI), we introduce a fundamentally different paradigm: a self-supervised One-Step Diffusion (OSD) framework specifically designed for SCI. The key novelty lies in using a single-step diffusion refiner to correct an initial reconstruction, eliminating iterative denoising entirely while preserving generative quality. Moreover, we adopt a self-supervised equivariant learning strategy to train both the predictor and refiner directly from raw 2-D measurements, enabling generalization to unseen domains without the need for ground-truth MSI. To further address the challenge of limited MSI data, we design a band-selection-driven distillation strategy that transfers core generative priors from large-scale RGB datasets, effectively bridging the domain gap. Extensive experiments confirm that our approach sets a new benchmark, yielding PSNR gains of 3.44 dB, 1.61 dB, and 0.28 dB on the Harvard, NTIRE, and ICVL datasets, respectively, while reducing reconstruction time by 97.5%. This remarkable improvement in efficiency and adaptability makes our method a significant advancement in SCI reconstruction, combining both accuracy and practicality for real-world deployment.",
    "published": "2024-09-11T17:02:10Z",
    "updated": "2025-12-01T11:42:26Z",
    "link": "http://arxiv.org/pdf/2409.07417v2.pdf",
    "category": [
      "eess.IV",
      "cs.CV"
    ],
    "authors": [
      "Shaoguang Huang",
      "Yunzhen Wang",
      "Haijin Zeng",
      "Hongyu Chen",
      "Hongyan Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01550v1",
    "title": "NavForesee: A Unified Vision-Language World Model for Hierarchical Planning and Dual-Horizon Navigation Prediction",
    "summary": "Embodied navigation for long-horizon tasks, guided by complex natural language instructions, remains a formidable challenge in artificial intelligence. Existing agents often struggle with robust long-term planning about unseen environments, leading to high failure rates. To address these limitations, we introduce NavForesee, a novel Vision-Language Model (VLM) that unifies high-level language planning and predictive world model imagination within a single, unified framework. Our approach empowers a single VLM to concurrently perform planning and predictive foresight. Conditioned on the full instruction and historical observations, the model is trained to understand the navigation instructions by decomposing the task, tracking its progress, and formulating the subsequent sub-goal. Simultaneously, it functions as a generative world model, providing crucial foresight by predicting short-term environmental dynamics and long-term navigation milestones. The VLM's structured plan guides its targeted prediction, while the imagined future provides rich context to inform the navigation actions, creating a powerful internal feedback loop of perception-planning/prediction-action. We demonstrate through extensive experiments on the R2R-CE and RxR-CE benchmark that NavForesee achieves highly competitive performance in complex scenarios. Our work highlights the immense potential of fusing explicit language planning with implicit spatiotemporal prediction, paving the way for more intelligent and capable embodied agents.",
    "published": "2025-12-01T11:24:16Z",
    "updated": "2025-12-01T11:24:16Z",
    "link": "http://arxiv.org/pdf/2512.01550v1.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Fei Liu",
      "Shichao Xie",
      "Minghua Luo",
      "Zedong Chu",
      "Junjun Hu",
      "Xiaolong Wu",
      "Mu Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.16767v2",
    "title": "Improving Partially Observed Trajectories Forecasting by Target-driven Self-Distillation",
    "summary": "Accurate prediction of future trajectories of traffic agents is essential for ensuring safe autonomous driving. However, partially observed trajectories can significantly degrade the performance of even state-of-the-art models. Previous approaches often rely on knowledge distillation to transfer features from fully observed trajectories to partially observed ones. This involves firstly training a fully observed model and then using a distillation process to create the final model. While effective, they require multi-stage training, making the training process very expensive. Moreover, knowledge distillation can lead to a performance degradation of the model. In this paper, we introduce a Target-drivenSelf-Distillation method (TSD) for motion forecasting. Our method leverages predicted accurate targets to guide the model in making predictions under partial observation conditions. By employing self-distillation, the model learns from the feature distributions of both fully observed and partially observed trajectories during a single end-to-end training process. This enhances the model's ability to predict motion accurately in both fully observed and partially observed scenarios. We evaluate our method on multiple datasets and state-of-the-art motion forecasting models. Extensive experimental results demonstrate that our approach achieves significant performance improvements in both settings. To facilitate further research, we will release our code and model checkpoints.",
    "published": "2025-01-28T07:46:13Z",
    "updated": "2025-12-01T11:23:25Z",
    "link": "http://arxiv.org/pdf/2501.16767v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Peng Shu",
      "Pengfei Zhu",
      "Mengshi Qi",
      "Liang Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01540v1",
    "title": "FlashVGGT: Efficient and Scalable Visual Geometry Transformers with Compressed Descriptor Attention",
    "summary": "3D reconstruction from multi-view images is a core challenge in computer vision. Recently, feed-forward methods have emerged as efficient and robust alternatives to traditional per-scene optimization techniques. Among them, state-of-the-art models like the Visual Geometry Grounding Transformer (VGGT) leverage full self-attention over all image tokens to capture global relationships. However, this approach suffers from poor scalability due to the quadratic complexity of self-attention and the large number of tokens generated in long image sequences. In this work, we introduce FlashVGGT, an efficient alternative that addresses this bottleneck through a descriptor-based attention mechanism. Instead of applying dense global attention across all tokens, FlashVGGT compresses spatial information from each frame into a compact set of descriptor tokens. Global attention is then computed as cross-attention between the full set of image tokens and this smaller descriptor set, significantly reducing computational overhead. Moreover, the compactness of the descriptors enables online inference over long sequences via a chunk-recursive mechanism that reuses cached descriptors from previous chunks. Experimental results show that FlashVGGT achieves reconstruction accuracy competitive with VGGT while reducing inference time to just 9.3% of VGGT for 1,000 images, and scaling efficiently to sequences exceeding 3,000 images. Our project page is available at https://wzpscott.github.io/flashvggt_page/.",
    "published": "2025-12-01T11:12:37Z",
    "updated": "2025-12-01T11:12:37Z",
    "link": "http://arxiv.org/pdf/2512.01540v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zipeng Wang",
      "Dan Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.05814v3",
    "title": "Rank Matters: Understanding and Defending Model Inversion Attacks via Low-Rank Feature Filtering",
    "summary": "Model Inversion Attacks (MIAs) pose a significant threat to data privacy by reconstructing sensitive training samples from the knowledge embedded in trained machine learning models. Despite recent progress in enhancing the effectiveness of MIAs across diverse settings, defense strategies have lagged behind -- struggling to balance model utility with robustness against increasingly sophisticated attacks. In this work, we propose the ideal inversion error to measure the privacy leakage, and our theoretical and empirical investigations reveals that higher-rank features are inherently more prone to privacy leakage. Motivated by this insight, we propose a lightweight and effective defense strategy based on low-rank feature filtering, which explicitly reduces the attack surface by constraining the dimension of intermediate representations. Extensive experiments across various model architectures and datasets demonstrate that our method consistently outperforms existing defenses, achieving state-of-the-art performance against a wide range of MIAs. Notably, our approach remains effective even in challenging regimes involving high-resolution data and high-capacity models, where prior defenses fail to provide adequate protection.",
    "published": "2024-10-08T08:44:01Z",
    "updated": "2025-12-01T11:11:17Z",
    "link": "http://arxiv.org/pdf/2410.05814v3.pdf",
    "category": [
      "cs.CR",
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Hongyao Yu",
      "Yixiang Qiu",
      "Hao Fang",
      "Tianqu Zhuang",
      "Bin Chen",
      "Sijin Yu",
      "Bin Wang",
      "Shu-Tao Xia",
      "Ke Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01519v1",
    "title": "QuantumCanvas: A Multimodal Benchmark for Visual Learning of Atomic Interactions",
    "summary": "Despite rapid advances in molecular and materials machine learning, most models still lack physical transferability: they fit correlations across whole molecules or crystals rather than learning the quantum interactions between atomic pairs. Yet bonding, charge redistribution, orbital hybridization, and electronic coupling all emerge from these two-body interactions that define local quantum fields in many-body systems. We introduce QuantumCanvas, a large-scale multimodal benchmark that treats two-body quantum systems as foundational units of matter. The dataset spans 2,850 element-element pairs, each annotated with 18 electronic, thermodynamic, and geometric properties and paired with ten-channel image representations derived from l- and m-resolved orbital densities, angular field transforms, co-occupancy maps, and charge-density projections. These physically grounded images encode spatial, angular, and electrostatic symmetries without explicit coordinates, providing an interpretable visual modality for quantum learning. Benchmarking eight architectures across 18 targets, we report mean absolute errors of 0.201 eV on energy gap using GATv2, 0.265 eV on HOMO and 0.274 eV on LUMO using EGNN. For energy-related quantities, DimeNet attains 2.27 eV total-energy MAE and 0.132 eV repulsive-energy MAE, while a multimodal fusion model achieves a 2.15 eV Mermin free-energy MAE. Pretraining on QuantumCanvas further improves convergence stability and generalization when fine-tuned on larger datasets such as QM9, MD17, and CrysMTM. By unifying orbital physics with vision-based representation learning, QuantumCanvas provides a principled and interpretable basis for learning transferable quantum interactions through coupled visual and numerical modalities. Dataset and model implementations are available at https://github.com/KurbanIntelligenceLab/QuantumCanvas.",
    "published": "2025-12-01T10:44:25Z",
    "updated": "2025-12-01T10:44:25Z",
    "link": "http://arxiv.org/pdf/2512.01519v1.pdf",
    "category": [
      "cs.CV",
      "cond-mat.mtrl-sci",
      "quant-ph"
    ],
    "authors": [
      "Can Polat",
      "Erchin Serpedin",
      "Mustafa Kurban",
      "Hasan Kurban"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01510v1",
    "title": "Semantic-aware Random Convolution and Source Matching for Domain Generalization in Medical Image Segmentation",
    "summary": "We tackle the challenging problem of single-source domain generalization (DG) for medical image segmentation. To this end, we aim for training a network on one domain (e.g., CT) and directly apply it to a different domain (e.g., MR) without adapting the model and without requiring images or annotations from the new domain during training. We propose a novel method for promoting DG when training deep segmentation networks, which we call SRCSM. During training, our method diversifies the source domain through semantic-aware random convolution, where different regions of a source image are augmented differently, based on their annotation labels. At test-time, we complement the randomization of the training domain via mapping the intensity of target domain images, making them similar to source domain data. We perform a comprehensive evaluation on a variety of cross-modality and cross-center generalization settings for abdominal, whole-heart and prostate segmentation, where we outperform previous DG techniques in a vast majority of experiments. Additionally, we also investigate our method when training on whole-heart CT or MR data and testing on the diastolic and systolic phase of cine MR data captured with different scanner hardware, where we make a step towards closing the domain gap in this even more challenging setting. Overall, our evaluation shows that SRCSM can be considered a new state-of-the-art in DG for medical image segmentation and, moreover, even achieves a segmentation performance that matches the performance of the in-domain baseline in several settings.",
    "published": "2025-12-01T10:35:45Z",
    "updated": "2025-12-01T10:35:45Z",
    "link": "http://arxiv.org/pdf/2512.01510v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Franz Thaler",
      "Martin Urschler",
      "Mateusz Kozinski",
      "Matthias AF Gsell",
      "Gernot Plank",
      "Darko Stern"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12578v2",
    "title": "TempoMaster: Efficient Long Video Generation via Next-Frame-Rate Prediction",
    "summary": "We present TempoMaster, a novel framework that formulates long video generation as next-frame-rate prediction. Specifically, we first generate a low-frame-rate clip that serves as a coarse blueprint of the entire video sequence, and then progressively increase the frame rate to refine visual details and motion continuity. During generation, TempoMaster employs bidirectional attention within each frame-rate level while performing autoregression across frame rates, thus achieving long-range temporal coherence while enabling efficient and parallel synthesis. Extensive experiments demonstrate that TempoMaster establishes a new state-of-the-art in long video generation, excelling in both visual and temporal quality.",
    "published": "2025-11-16T12:41:07Z",
    "updated": "2025-12-01T10:30:43Z",
    "link": "http://arxiv.org/pdf/2511.12578v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yukuo Ma",
      "Cong Liu",
      "Junke Wang",
      "Junqi Liu",
      "Haibin Huang",
      "Zuxuan Wu",
      "Chi Zhang",
      "Xuelong Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01495v1",
    "title": "ELVIS: Enhance Low-Light for Video Instance Segmentation in the Dark",
    "summary": "Video instance segmentation (VIS) for low-light content remains highly challenging for both humans and machines alike, due to adverse imaging conditions including noise, blur and low-contrast. The lack of large-scale annotated datasets and the limitations of current synthetic pipelines, particularly in modeling temporal degradations, further hinder progress. Moreover, existing VIS methods are not robust to the degradations found in low-light videos and, as a result, perform poorly even when finetuned on low-light data. In this paper, we introduce \\textbf{ELVIS} (\\textbf{E}nhance \\textbf{L}ow-light for \\textbf{V}ideo \\textbf{I}nstance \\textbf{S}egmentation), a novel framework that enables effective domain adaptation of state-of-the-art VIS models to low-light scenarios. ELVIS comprises an unsupervised synthetic low-light video pipeline that models both spatial and temporal degradations, a calibration-free degradation profile synthesis network (VDP-Net) and an enhancement decoder head that disentangles degradations from content features. ELVIS improves performances by up to \\textbf{+3.7AP} on the synthetic low-light YouTube-VIS 2019 dataset. Code will be released upon acceptance.",
    "published": "2025-12-01T10:17:07Z",
    "updated": "2025-12-01T10:17:07Z",
    "link": "http://arxiv.org/pdf/2512.01495v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Joanne Lin",
      "Ruirui Lin",
      "Yini Li",
      "David Bull",
      "Nantheera Anantrasirichai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01494v1",
    "title": "A variational method for curve extraction with curvature-dependent energies",
    "summary": "We introduce a variational approach for extracting curves between a list of possible endpoints, based on the discretization of an energy and Smirnov's decomposition theorem for vector fields. It is used to design a bi-level minimization approach to automatically extract curves and 1D structures from an image, which is mostly unsupervised. We extend then the method to curvature-dependent energies, using a now classical lifting of the curves in the space of positions and orientations equipped with an appropriate sub-Riemanian or Finslerian metric.",
    "published": "2025-12-01T10:16:58Z",
    "updated": "2025-12-01T10:16:58Z",
    "link": "http://arxiv.org/pdf/2512.01494v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Majid Arthaud",
      "Antonin Chambolle",
      "Vincent Duval"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.01755v2",
    "title": "3EED: Ground Everything Everywhere in 3D",
    "summary": "Visual grounding in 3D is the key for embodied agents to localize language-referred objects in open-world environments. However, existing benchmarks are limited to indoor focus, single-platform constraints, and small scale. We introduce 3EED, a multi-platform, multi-modal 3D grounding benchmark featuring RGB and LiDAR data from vehicle, drone, and quadruped platforms. We provide over 128,000 objects and 22,000 validated referring expressions across diverse outdoor scenes -- 10x larger than existing datasets. We develop a scalable annotation pipeline combining vision-language model prompting with human verification to ensure high-quality spatial grounding. To support cross-platform learning, we propose platform-aware normalization and cross-modal alignment techniques, and establish benchmark protocols for in-domain and cross-platform evaluations. Our findings reveal significant performance gaps, highlighting the challenges and opportunities of generalizable 3D grounding. The 3EED dataset and benchmark toolkit are released to advance future research in language-driven 3D embodied perception.",
    "published": "2025-11-03T17:05:22Z",
    "updated": "2025-12-01T10:15:49Z",
    "link": "http://arxiv.org/pdf/2511.01755v2.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Rong Li",
      "Yuhao Dong",
      "Tianshuai Hu",
      "Ao Liang",
      "Youquan Liu",
      "Dongyue Lu",
      "Liang Pan",
      "Lingdong Kong",
      "Junwei Liang",
      "Ziwei Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.13047v2",
    "title": "InsightDrive: Insight Scene Representation for End-to-End Autonomous Driving",
    "summary": "Conventional end-to-end autonomous driving methods often rely on explicit global scene representations, which typically consist of 3D object detection, online mapping, and motion prediction. In contrast, human drivers selectively attend to task-relevant regions and implicitly reason over the broader traffic context. Motivated by this observation, we introduce a lightweight end-to-end autonomous driving framework, InsightDrive. Unlike approaches that directly embed large language models (LLMs), InsightDrive introduces an Insight scene representation that jointly models attention-centric explicit scene representation and reasoning-centric implicit scene representation, so that scene understanding aligns more closely with human cognitive patterns for trajectory planning. To this end, we employ Chain-of-Thought (CoT) instructions to model human driving cognition and design a task-level Mixture-of-Experts (MoE) adapter that injects this knowledge into the autonomous driving model at negligible parameter cost. We further condition the planner on both explicit and implicit scene representations and employ a diffusion-based generative policy, which produces robust trajectory predictions and decisions. The overall framework establishes a knowledge distillation pipeline that transfers human driving knowledge to LLMs and subsequently to onboard models. Extensive experiments on the nuScenes and Navsim benchmarks demonstrate that InsightDrive achieves significant improvements over conventional scene representation approaches.",
    "published": "2025-03-17T10:52:32Z",
    "updated": "2025-12-01T10:13:45Z",
    "link": "http://arxiv.org/pdf/2503.13047v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ruiqi Song",
      "Xianda Guo",
      "Yanlun Peng",
      "Qinggong Wei",
      "Hangbin Wu",
      "Long Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01481v1",
    "title": "ChronosObserver: Taming 4D World with Hyperspace Diffusion Sampling",
    "summary": "Although prevailing camera-controlled video generation models can produce cinematic results, lifting them directly to the generation of 3D-consistent and high-fidelity time-synchronized multi-view videos remains challenging, which is a pivotal capability for taming 4D worlds. Some works resort to data augmentation or test-time optimization, but these strategies are constrained by limited model generalization and scalability issues. To this end, we propose ChronosObserver, a training-free method including World State Hyperspace to represent the spatiotemporal constraints of a 4D world scene, and Hyperspace Guided Sampling to synchronize the diffusion sampling trajectories of multiple views using the hyperspace. Experimental results demonstrate that our method achieves high-fidelity and 3D-consistent time-synchronized multi-view videos generation without training or fine-tuning for diffusion models.",
    "published": "2025-12-01T10:00:26Z",
    "updated": "2025-12-01T10:00:26Z",
    "link": "http://arxiv.org/pdf/2512.01481v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Qisen Wang",
      "Yifan Zhao",
      "Peisen Shen",
      "Jialu Li",
      "Jia Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01478v1",
    "title": "CourtMotion: Learning Event-Driven Motion Representations from Skeletal Data for Basketball",
    "summary": "This paper presents CourtMotion, a spatiotemporal modeling framework for analyzing and predicting game events and plays as they develop in professional basketball. Anticipating basketball events requires understanding both physical motion patterns and their semantic significance in the context of the game. Traditional approaches that use only player positions fail to capture crucial indicators such as body orientation, defensive stance, or shooting preparation motions. Our two-stage approach first processes skeletal tracking data through Graph Neural Networks to capture nuanced motion patterns, then employs a Transformer architecture with specialized attention mechanisms to model player interactions. We introduce event projection heads that explicitly connect player movements to basketball events like passes, shots, and steals, training the model to associate physical motion patterns with their tactical purposes. Experiments on NBA tracking data demonstrate significant improvements over position-only baselines: 35% reduction in trajectory prediction error compared to state-of-the-art position-based models and consistent performance gains across key basketball analytics tasks. The resulting pretrained model serves as a powerful foundation for multiple downstream tasks, with pick detection, shot taker identification, assist prediction, shot location classification, and shot type recognition demonstrating substantial improvements over existing methods.",
    "published": "2025-12-01T09:58:24Z",
    "updated": "2025-12-01T09:58:24Z",
    "link": "http://arxiv.org/pdf/2512.01478v1.pdf",
    "category": [
      "cs.CV",
      "cs.MA"
    ],
    "authors": [
      "Omer Sela",
      "Michael Chertok",
      "Lior Wolf"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01461v1",
    "title": "Stay Unique, Stay Efficient: Preserving Model Personality in Multi-Task Merging",
    "summary": "Model merging has emerged as a promising paradigm for enabling multi-task capabilities without additional training. However, existing methods often experience substantial performance degradation compared with individually fine-tuned models, even on similar tasks, underscoring the need to preserve task-specific information. This paper proposes Decomposition, Thresholding, and Scaling (DTS), an approximation-based personalized merging framework that preserves task-specific information with minimal storage overhead. DTS first applies singular value decomposition to the task-specific information and retains only a small subset of singular values and vectors. It then introduces a novel thresholding strategy that partitions singular vector elements into groups and assigns a scaling factor to each group. To enable generalization to unseen tasks, we further extend DTS with a variant that fuses task-specific information in a data-free manner based on the semantic similarity of task characteristics. Extensive experiments demonstrate that DTS consistently outperforms state-of-the-art baselines while requiring only 1\\% additional storage per task. Furthermore, experiments on unseen tasks show that the DTS variant achieves significantly better generalization performance. Our code is available at https://github.com/krumpguo/DTS.",
    "published": "2025-12-01T09:47:17Z",
    "updated": "2025-12-01T09:47:17Z",
    "link": "http://arxiv.org/pdf/2512.01461v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Kuangpu Guo",
      "Yuhe Ding",
      "Jian Liang",
      "Zilei Wang",
      "Ran He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.06588v2",
    "title": "Speech Audio Generation from dynamic MRI via a Knowledge Enhanced Conditional Variational Autoencoder",
    "summary": "Dynamic Magnetic Resonance Imaging (MRI) of the vocal tract has become an increasingly adopted imaging modality for speech motor studies. Beyond image signals, systematic data loss, noise pollution, and audio file corruption can occur due to the unpredictability of the MRI acquisition environment. In such cases, generating audio from images is critical for data recovery in both clinical and research applications. However, this remains challenging due to hardware constraints, acoustic interference, and data corruption. Existing solutions, such as denoising and multi-stage synthesis methods, face limitations in audio fidelity and generalizability. To address these challenges, we propose a Knowledge Enhanced Conditional Variational Autoencoder (KE-CVAE), a novel two-step \"knowledge enhancement + variational inference\" framework for generating speech audio signals from cine dynamic MRI sequences. This approach introduces two key innovations: (1) integration of unlabeled MRI data for knowledge enhancement, and (2) a variational inference architecture to improve generative modeling capacity. To the best of our knowledge, this is one of the first attempts at synthesizing speech audio directly from dynamic MRI video sequences. The proposed method was trained and evaluated on an open-source dynamic vocal tract MRI dataset recorded during speech. Experimental results demonstrate its effectiveness in generating natural speech waveforms while addressing MRI-specific acoustic challenges, outperforming conventional deep learning-based synthesis approaches.",
    "published": "2025-03-09T12:40:16Z",
    "updated": "2025-12-01T09:44:15Z",
    "link": "http://arxiv.org/pdf/2503.06588v2.pdf",
    "category": [
      "cs.SD",
      "cs.CV"
    ],
    "authors": [
      "Yaxuan Li",
      "Han Jiang",
      "Yifei Ma",
      "Shihua Qin",
      "Jonghye Woo",
      "Fangxu Xing"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.02535v3",
    "title": "Video Anomaly Detection with Semantics-Aware Information Bottleneck",
    "summary": "Semi-supervised video anomaly detection methods face two critical challenges: (1) Strong generalization blurs the boundary between normal and abnormal patterns. Although existing approaches attempt to alleviate this issue using memory modules, their rigid prototype-matching process limits adaptability to diverse scenarios; (2) Relying solely on low-level appearance and motion cues makes it difficult to perceive high-level semantic anomalies in complex scenes. To address these limitations, we propose SIB-VAD, a novel framework based on adaptive information bottleneck filtering and semantic-aware enhancement. We propose the Sparse Feature Filtering Module (SFFM) to replace traditional memory modules. It compresses normal features directly into a low-dimensional manifold based on the information bottleneck principle and uses an adaptive routing mechanism to dynamically select the most suitable normal bottleneck subspace. Trained only on normal data, SFFMs only learn normal low-dimensional manifolds, while abnormal features deviate and are effectively filtered. Unlike memory modules, SFFM directly removes abnormal information and adaptively handles scene variations. To improve semantic awareness, we further design a multimodal prediction framework that jointly models appearance, motion, and semantics. Through multimodal consistency constraints and joint error computation, it achieves more robust VAD performance. Experimental results validate the effectiveness of our feature filtering paradigm based on semantics-aware information bottleneck. Project page at https://qzfm.github.io/sib_vad_project_page/",
    "published": "2025-06-03T07:14:57Z",
    "updated": "2025-12-01T09:34:51Z",
    "link": "http://arxiv.org/pdf/2506.02535v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Juntong Li",
      "Lingwei Dang",
      "Qingxin Xiao",
      "Shishuo Shang",
      "Jiajia Cheng",
      "Haomin Wu",
      "Yun Hao",
      "Qingyao Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.22643v3",
    "title": "SPIRAL: Semantic-Aware Progressive LiDAR Scene Generation and Understanding",
    "summary": "Leveraging recent diffusion models, LiDAR-based large-scale 3D scene generation has achieved great success. While recent voxel-based approaches can generate both geometric structures and semantic labels, existing range-view methods are limited to producing unlabeled LiDAR scenes. Relying on pretrained segmentation models to predict the semantic maps often results in suboptimal cross-modal consistency. To address this limitation while preserving the advantages of range-view representations, such as computational efficiency and simplified network design, we propose Spiral, a novel range-view LiDAR diffusion model that simultaneously generates depth, reflectance images, and semantic maps. Furthermore, we introduce novel semantic-aware metrics to evaluate the quality of the generated labeled range-view data. Experiments on the SemanticKITTI and nuScenes datasets demonstrate that Spiral achieves state-of-the-art performance with the smallest parameter size, outperforming two-step methods that combine the generative and segmentation models. Additionally, we validate that range images generated by Spiral can be effectively used for synthetic data augmentation in the downstream segmentation training, significantly reducing the labeling effort on LiDAR data.",
    "published": "2025-05-28T17:55:35Z",
    "updated": "2025-12-01T09:34:36Z",
    "link": "http://arxiv.org/pdf/2505.22643v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Dekai Zhu",
      "Yixuan Hu",
      "Youquan Liu",
      "Dongyue Lu",
      "Lingdong Kong",
      "Slobodan Ilic"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12200v2",
    "title": "Bridging Granularity Gaps: Hierarchical Semantic Learning for Cross-domain Few-shot Segmentation",
    "summary": "Cross-domain Few-shot Segmentation (CD-FSS) aims to segment novel classes from target domains that are not involved in training and have significantly different data distributions from the source domain, using only a few annotated samples, and recent years have witnessed significant progress on this task. However, existing CD-FSS methods primarily focus on style gaps between source and target domains while ignoring segmentation granularity gaps, resulting in insufficient semantic discriminability for novel classes in target domains. Therefore, we propose a Hierarchical Semantic Learning (HSL) framework to tackle this problem. Specifically, we introduce a Dual Style Randomization (DSR) module and a Hierarchical Semantic Mining (HSM) module to learn hierarchical semantic features, thereby enhancing the model's ability to recognize semantics at varying granularities. DSR simulates target domain data with diverse foreground-background style differences and overall style variations through foreground and global style randomization respectively, while HSM leverages multi-scale superpixels to guide the model to mine intra-class consistency and inter-class distinction at different granularities. Additionally, we also propose a Prototype Confidence-modulated Thresholding (PCMT) module to mitigate segmentation ambiguity when foreground and background are excessively similar. Extensive experiments are conducted on four popular target domain datasets, and the results demonstrate that our method achieves state-of-the-art performance.",
    "published": "2025-11-15T13:13:26Z",
    "updated": "2025-12-01T09:31:06Z",
    "link": "http://arxiv.org/pdf/2511.12200v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Sujun Sun",
      "Haowen Gu",
      "Cheng Xie",
      "Yanxu Ren",
      "Mingwu Ren",
      "Haofeng Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01444v1",
    "title": "FastAnimate: Towards Learnable Template Construction and Pose Deformation for Fast 3D Human Avatar Animation",
    "summary": "3D human avatar animation aims at transforming a human avatar from an arbitrary initial pose to a specified target pose using deformation algorithms. Existing approaches typically divide this task into two stages: canonical template construction and target pose deformation. However, current template construction methods demand extensive skeletal rigging and often produce artifacts for specific poses. Moreover, target pose deformation suffers from structural distortions caused by Linear Blend Skinning (LBS), which significantly undermines animation realism. To address these problems, we propose a unified learning-based framework to address both challenges in two phases. For the former phase, to overcome the inefficiencies and artifacts during template construction, we leverage a U-Net architecture that decouples texture and pose information in a feed-forward process, enabling fast generation of a human template. For the latter phase, we propose a data-driven refinement technique that enhances structural integrity. Extensive experiments show that our model delivers consistent performance across diverse poses with an optimal balance between efficiency and quality,surpassing state-of-the-art (SOTA) methods.",
    "published": "2025-12-01T09:28:50Z",
    "updated": "2025-12-01T09:28:50Z",
    "link": "http://arxiv.org/pdf/2512.01444v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jian Shu",
      "Nanjie Yao",
      "Gangjian Zhang",
      "Junlong Ren",
      "Yu Feng",
      "Hao Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.16024v2",
    "title": "Mixture of Ranks with Degradation-Aware Routing for One-Step Real-World Image Super-Resolution",
    "summary": "The demonstrated success of sparsely-gated Mixture-of-Experts (MoE) architectures, exemplified by models such as DeepSeek and Grok, has motivated researchers to investigate their adaptation to diverse domains. In real-world image super-resolution (Real-ISR), existing approaches mainly rely on fine-tuning pre-trained diffusion models through Low-Rank Adaptation (LoRA) module to reconstruct high-resolution (HR) images. However, these dense Real-ISR models are limited in their ability to adaptively capture the heterogeneous characteristics of complex real-world degraded samples or enable knowledge sharing between inputs under equivalent computational budgets. To address this, we investigate the integration of sparse MoE into Real-ISR and propose a Mixture-of-Ranks (MoR) architecture for single-step image super-resolution. We introduce a fine-grained expert partitioning strategy that treats each rank in LoRA as an independent expert. This design enables flexible knowledge recombination while isolating fixed-position ranks as shared experts to preserve common-sense features and minimize routing redundancy. Furthermore, we develop a degradation estimation module leveraging CLIP embeddings and predefined positive-negative text pairs to compute relative degradation scores, dynamically guiding expert activation. To better accommodate varying sample complexities, we incorporate zero-expert slots and propose a degradation-aware load-balancing loss, which dynamically adjusts the number of active experts based on degradation severity, ensuring optimal computational resource allocation. Comprehensive experiments validate our framework's effectiveness and state-of-the-art performance.",
    "published": "2025-11-20T04:11:44Z",
    "updated": "2025-12-01T09:15:21Z",
    "link": "http://arxiv.org/pdf/2511.16024v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xiao He",
      "Zhijun Tu",
      "Kun Cheng",
      "Mingrui Zhu",
      "Jie Hu",
      "Nannan Wang",
      "Xinbo Gao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01427v1",
    "title": "Language-Guided Open-World Anomaly Segmentation",
    "summary": "Open-world and anomaly segmentation methods seek to enable autonomous driving systems to detect and segment both known and unknown objects in real-world scenes. However, existing methods do not assign semantically meaningful labels to unknown regions, and distinguishing and learning representations for unknown classes remains difficult. While open-vocabulary segmentation methods show promise in generalizing to novel classes, they require a fixed inference vocabulary and thus cannot be directly applied to anomaly segmentation where unknown classes are unconstrained. We propose Clipomaly, the first CLIP-based open-world and anomaly segmentation method for autonomous driving. Our zero-shot approach requires no anomaly-specific training data and leverages CLIP's shared image-text embedding space to both segment unknown objects and assign human-interpretable names to them. Unlike open-vocabulary methods, our model dynamically extends its vocabulary at inference time without retraining, enabling robust detection and naming of anomalies beyond common class definitions such as those in Cityscapes. Clipomaly achieves state-of-the-art performance on established anomaly segmentation benchmarks while providing interpretability and flexibility essential for practical deployment.",
    "published": "2025-12-01T09:08:59Z",
    "updated": "2025-12-01T09:08:59Z",
    "link": "http://arxiv.org/pdf/2512.01427v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Klara Reichard",
      "Nikolas Brasch",
      "Nassir Navab",
      "Federico Tombari"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01426v1",
    "title": "ResDiT: Evoking the Intrinsic Resolution Scalability in Diffusion Transformers",
    "summary": "Leveraging pre-trained Diffusion Transformers (DiTs) for high-resolution (HR) image synthesis often leads to spatial layout collapse and degraded texture fidelity. Prior work mitigates these issues with complex pipelines that first perform a base-resolution (i.e., training-resolution) denoising process to guide HR generation. We instead explore the intrinsic generative mechanisms of DiTs and propose ResDiT, a training-free method that scales resolution efficiently. We identify the core factor governing spatial layout, position embeddings (PEs), and show that the original PEs encode incorrect positional information when extrapolated to HR, which triggers layout collapse. To address this, we introduce a PE scaling technique that rectifies positional encoding under resolution changes. To further remedy low-fidelity details, we develop a local-enhancement mechanism grounded in base-resolution local attention. We design a patch-level fusion module that aggregates global and local cues, together with a Gaussian-weighted splicing strategy that eliminates grid artifacts. Comprehensive evaluations demonstrate that ResDiT consistently delivers high-fidelity, high-resolution image synthesis and integrates seamlessly with downstream tasks, including spatially controlled generation.",
    "published": "2025-12-01T09:08:01Z",
    "updated": "2025-12-01T09:08:01Z",
    "link": "http://arxiv.org/pdf/2512.01426v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yiyang Ma",
      "Feng Zhou",
      "Xuedan Yin",
      "Pu Cao",
      "Yonghao Dang",
      "Jianqin Yin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01424v1",
    "title": "\\textit{ViRectify}: A Challenging Benchmark for Video Reasoning Correction with Multimodal Large Language Models",
    "summary": "As multimodal large language models (MLLMs) frequently exhibit errors in complex video reasoning scenarios, correcting these errors is critical for uncovering their weaknesses and improving performance. However, existing benchmarks lack systematic evaluation of MLLMs' ability to identify and correct these video reasoning errors. To bridge this gap, we propose \\textit{ViRectify}, a comprehensive benchmark to evaluate their fine-grained correction capability. Through an AI-assisted annotation pipeline with human verification, we construct a dataset of over 30\\textit{K} instances spanning dynamic perception, scientific reasoning, and embodied decision-making domains. In \\textit{ViRectify}, we challenge MLLMs to perform step-wise error identification and generate rationales with key video evidence grounding. In addition, we further propose the trajectory evidence-driven correction framework, comprising step-wise error trajectory and reward modeling on visual evidence-grounded correction. It encourages the model to explicitly concentrate on error propagation and key timestamps for correction. Extensive evaluation across 16 advanced MLLMs demonstrates that our \\textit{ViRectify} serves as a challenging testbed, where GPT-5 achieves only 31.94\\% correction accuracy. Our framework enables a Qwen2.5-VL-7B to consistently outperform the variants of 72B on \\textit{ViRectify}, showing the effectiveness of our approach. Further analysis uncovers systematic asymmetries in error correction across models, and our dataset is also a valuable data resource to perform reflection learning. We believe \\textit{ViRectify} provides a new direction for comprehensively evaluating the advanced MLLMs in video reasoning.",
    "published": "2025-12-01T09:05:02Z",
    "updated": "2025-12-01T09:05:02Z",
    "link": "http://arxiv.org/pdf/2512.01424v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xusen Hei",
      "Jiali Chen",
      "Jinyu Yang",
      "Mengchen Zhao",
      "Yi Cai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01422v1",
    "title": "MDiff4STR: Mask Diffusion Model for Scene Text Recognition",
    "summary": "Mask Diffusion Models (MDMs) have recently emerged as a promising alternative to auto-regressive models (ARMs) for vision-language tasks, owing to their flexible balance of efficiency and accuracy. In this paper, for the first time, we introduce MDMs into the Scene Text Recognition (STR) task. We show that vanilla MDM lags behind ARMs in terms of accuracy, although it improves recognition efficiency. To bridge this gap, we propose MDiff4STR, a Mask Diffusion model enhanced with two key improvement strategies tailored for STR. Specifically, we identify two key challenges in applying MDMs to STR: noising gap between training and inference, and overconfident predictions during inference. Both significantly hinder the performance of MDMs. To mitigate the first issue, we develop six noising strategies that better align training with inference behavior. For the second, we propose a token-replacement noise mechanism that provides a non-mask noise type, encouraging the model to reconsider and revise overly confident but incorrect predictions. We conduct extensive evaluations of MDiff4STR on both standard and challenging STR benchmarks, covering diverse scenarios including irregular, artistic, occluded, and Chinese text, as well as whether the use of pretraining. Across these settings, MDiff4STR consistently outperforms popular STR models, surpassing state-of-the-art ARMs in accuracy, while maintaining fast inference with only three denoising steps. Code: https://github.com/Topdu/OpenOCR.",
    "published": "2025-12-01T08:57:51Z",
    "updated": "2025-12-01T08:57:51Z",
    "link": "http://arxiv.org/pdf/2512.01422v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yongkun Du",
      "Miaomiao Zhao",
      "Songlin Fan",
      "Zhineng Chen",
      "Caiyan Jia",
      "Yu-Gang Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.10679v2",
    "title": "U-FaceBP: Uncertainty-aware Bayesian Ensemble Deep Learning for Face Video-based Blood Pressure Measurement",
    "summary": "Blood pressure (BP) measurement is crucial for daily health assessment. Remote photoplethysmography (rPPG), which extracts pulse waves from face videos captured by a camera, has the potential to enable convenient BP measurement without specialized medical devices. However, there are various uncertainties in BP estimation using rPPG, leading to limited estimation performance and reliability. In this paper, we propose U-FaceBP, an uncertainty-aware Bayesian ensemble deep learning method for face video-based BP measurement. U-FaceBP models aleatoric and epistemic uncertainties in face video-based BP estimation with a Bayesian neural network (BNN). Additionally, we design U-FaceBP as an ensemble method, estimating BP from rPPG signals, PPG signals derived from face videos, and face images using multiple BNNs. Large-scale experiments on two datasets involving 1197 subjects from diverse racial groups demonstrate that U-FaceBP outperforms state-of-the-art BP estimation methods. Furthermore, we show that the uncertainty estimates provided by U-FaceBP are informative and useful for guiding modality fusion, assessing prediction reliability, and analyzing performance across racial groups.",
    "published": "2024-12-14T04:51:32Z",
    "updated": "2025-12-01T08:32:06Z",
    "link": "http://arxiv.org/pdf/2412.10679v2.pdf",
    "category": [
      "cs.CV",
      "eess.IV"
    ],
    "authors": [
      "Yusuke Akamatsu",
      "Akinori F. Ebihara",
      "Terumi Umematsu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.11740v3",
    "title": "AgriPotential: A Novel Multi-Spectral and Multi-Temporal Remote Sensing Dataset for Agricultural Potentials",
    "summary": "Remote sensing has emerged as a critical tool for large-scale Earth monitoring and land management. In this paper, we introduce AgriPotential, a novel benchmark dataset composed of Sentinel-2 satellite imagery captured over multiple months. The dataset provides pixel-level annotations of agricultural potentials for three major crop types - viticulture, market gardening, and field crops - across five ordinal classes. AgriPotential supports a broad range of machine learning tasks, including ordinal regression, multi-label classification, and spatio-temporal modeling. The data cover diverse areas in Southern France, offering rich spectral information. AgriPotential is the first public dataset designed specifically for agricultural potential prediction, aiming to improve data-driven approaches to sustainable land use planning. The dataset and the code are freely accessible at: https://zenodo.org/records/15551829",
    "published": "2025-06-13T12:52:46Z",
    "updated": "2025-12-01T08:31:17Z",
    "link": "http://arxiv.org/pdf/2506.11740v3.pdf",
    "category": [
      "cs.CV",
      "eess.IV"
    ],
    "authors": [
      "Mohammad El Sakka",
      "Caroline De Pourtales",
      "Lotfi Chaari",
      "Josiane Mothe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.21053v2",
    "title": "AerialMind: Towards Referring Multi-Object Tracking in UAV Scenarios",
    "summary": "Referring Multi-Object Tracking (RMOT) aims to achieve precise object detection and tracking through natural language instructions, representing a fundamental capability for intelligent robotic systems. However, current RMOT research remains mostly confined to ground-level scenarios, which constrains their ability to capture broad-scale scene contexts and perform comprehensive tracking and path planning. In contrast, Unmanned Aerial Vehicles (UAVs) leverage their expansive aerial perspectives and superior maneuverability to enable wide-area surveillance. Moreover, UAVs have emerged as critical platforms for Embodied Intelligence, which has given rise to an unprecedented demand for intelligent aerial systems capable of natural language interaction. To this end, we introduce AerialMind, the first large-scale RMOT benchmark in UAV scenarios, which aims to bridge this research gap. To facilitate its construction, we develop an innovative semi-automated collaborative agent-based labeling assistant (COALA) framework that significantly reduces labor costs while maintaining annotation quality. Furthermore, we propose HawkEyeTrack (HETrack), a novel method that collaboratively enhances vision-language representation learning and improves the perception of UAV scenarios. Comprehensive experiments validated the challenging nature of our dataset and the effectiveness of our method.",
    "published": "2025-11-26T04:44:27Z",
    "updated": "2025-12-01T08:19:43Z",
    "link": "http://arxiv.org/pdf/2511.21053v2.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Chenglizhao Chen",
      "Shaofeng Liang",
      "Runwei Guan",
      "Xiaolou Sun",
      "Haocheng Zhao",
      "Haiyun Jiang",
      "Tao Huang",
      "Henghui Ding",
      "Qing-Long Han"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.11460v2",
    "title": "Rethinking Efficient Mixture-of-Experts for Remote Sensing Modality-Missing Classification",
    "summary": "Multimodal classification in remote sensing often suffers from missing modalities caused by environmental interference, sensor failures, or atmospheric effects, which severely degrade classification performance. Existing two-stage adaptation methods are computationally expensive and assume complete multimodal data during training, limiting their generalization to real-world incompleteness. To overcome these issues, we propose a Missing-aware Mixture-of-Loras (MaMOL) framework that reformulates modality missing as a multi-task learning problem. MaMOL introduces a dual-routing mechanism: a task-oriented dynamic router that adaptively activates experts for different missing patterns, and a modality-specific-shared static router that maintains stable cross-modal knowledge sharing. Unlike prior methods that train separate networks for each missing configuration, MaMOL achieves parameter-efficient adaptation via lightweight expert updates and shared expert reuse. Experiments on multiple remote sensing benchmarks demonstrate superior robustness and generalization under varying missing rates, with minimal computational overhead. Moreover, transfer experiments on natural image datasets validate its scalability and cross-domain applicability, highlighting MaMOL as a general and efficient solution for incomplete multimodal learning.",
    "published": "2025-11-14T16:31:37Z",
    "updated": "2025-12-01T08:17:06Z",
    "link": "http://arxiv.org/pdf/2511.11460v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Qinghao Gao",
      "Jiahui Qu",
      "Yunsong Li",
      "Wenqian Dong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.03339v2",
    "title": "UniFucGrasp: Human-Hand-Inspired Unified Functional Grasp Annotation Strategy and Dataset for Diverse Dexterous Hands",
    "summary": "Dexterous grasp datasets are vital for embodied intelligence, but mostly emphasize grasp stability, ignoring functional grasps needed for tasks like opening bottle caps or holding cup handles. Most rely on bulky, costly, and hard-to-control high-DOF Shadow Hands. Inspired by the human hand's underactuated mechanism, we establish UniFucGrasp, a universal functional grasp annotation strategy and dataset for multiple dexterous hand types. Based on biomimicry, it maps natural human motions to diverse hand structures and uses geometry-based force closure to ensure functional, stable, human-like grasps. This method supports low-cost, efficient collection of diverse, high-quality functional grasps. Finally, we establish the first multi-hand functional grasp dataset and provide a synthesis model to validate its effectiveness. Experiments on the UFG dataset, IsaacSim, and complex robotic tasks show that our method improves functional manipulation accuracy and grasp stability, demonstrates improved adaptability across multiple robotic hands, helping to alleviate annotation cost and generalization challenges in dexterous grasping. The project page is at https://haochen611.github.io/UFG.",
    "published": "2025-08-05T11:37:38Z",
    "updated": "2025-12-01T08:16:09Z",
    "link": "http://arxiv.org/pdf/2508.03339v2.pdf",
    "category": [
      "cs.RO",
      "cs.CV",
      "eess.IV"
    ],
    "authors": [
      "Haoran Lin",
      "Wenrui Chen",
      "Xianchi Chen",
      "Fan Yang",
      "Qiang Diao",
      "Wenxin Xie",
      "Sijie Wu",
      "Kailun Yang",
      "Maojun Li",
      "Yaonan Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.22187v2",
    "title": "HybridWorldSim: A Scalable and Controllable High-fidelity Simulator for Autonomous Driving",
    "summary": "Realistic and controllable simulation is critical for advancing end-to-end autonomous driving, yet existing approaches often struggle to support novel view synthesis under large viewpoint changes or to ensure geometric consistency. We introduce HybridWorldSim, a hybrid simulation framework that integrates multi-traversal neural reconstruction for static backgrounds with generative modeling for dynamic agents. This unified design addresses key limitations of previous methods, enabling the creation of diverse and high-fidelity driving scenarios with reliable visual and spatial consistency. To facilitate robust benchmarking, we further release a new multi-traversal dataset MIRROR that captures a wide range of routes and environmental conditions across different cities. Extensive experiments demonstrate that HybridWorldSim surpasses previous state-of-the-art methods, providing a practical and scalable solution for high-fidelity simulation and a valuable resource for research and development in autonomous driving.",
    "published": "2025-11-27T07:53:16Z",
    "updated": "2025-12-01T08:14:40Z",
    "link": "http://arxiv.org/pdf/2511.22187v2.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Qiang Li",
      "Yingwenqi Jiang",
      "Tuoxi Li",
      "Duyu Chen",
      "Xiang Feng",
      "Yucheng Ao",
      "Shangyue Liu",
      "Xingchen Yu",
      "Youcheng Cai",
      "Yumeng Liu",
      "Yuexin Ma",
      "Xin Hu",
      "Li Liu",
      "Yu Zhang",
      "Linkun Xu",
      "Bingtao Gao",
      "Xueyuan Wang",
      "Shuchang Zhou",
      "Xianming Liu",
      "Ligang Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.16273v4",
    "title": "Fine-grained Image Retrieval via Dual-Vision Adaptation",
    "summary": "Fine-Grained Image Retrieval~(FGIR) faces challenges in learning discriminative visual representations to retrieve images with similar fine-grained features. Current leading FGIR solutions typically follow two regimes: enforce pairwise similarity constraints in the semantic embedding space, or incorporate a localization sub-network to fine-tune the entire model. However, such two regimes tend to overfit the training data while forgetting the knowledge gained from large-scale pre-training, thus reducing their generalization ability. In this paper, we propose a Dual-Vision Adaptation (DVA) approach for FGIR, which guides the frozen pre-trained model to perform FGIR through collaborative sample and feature adaptation. Specifically, we design Object-Perceptual Adaptation, which modifies input samples to help the pre-trained model perceive critical objects and elements within objects that are helpful for category prediction. Meanwhile, we propose In-Context Adaptation, which introduces a small set of parameters for feature adaptation without modifying the pre-trained parameters. This makes the FGIR task using these adjusted features closer to the task solved during the pre-training. Additionally, to balance retrieval efficiency and performance, we propose Discrimination Perception Transfer to transfer the discriminative knowledge in the object-perceptual adaptation to the image encoder using the knowledge distillation mechanism. Extensive experiments show that DVA has fewer learnable parameters and performs well on three in-distribution and three out-of-distribution fine-grained datasets.",
    "published": "2025-06-19T12:46:55Z",
    "updated": "2025-12-01T08:10:39Z",
    "link": "http://arxiv.org/pdf/2506.16273v4.pdf",
    "category": [
      "cs.CV",
      "cs.MM"
    ],
    "authors": [
      "Xin Jiang",
      "Meiqi Cao",
      "Hao Tang",
      "Fei Shen",
      "Zechao Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01390v1",
    "title": "FRAMER: Frequency-Aligned Self-Distillation with Adaptive Modulation Leveraging Diffusion Priors for Real-World Image Super-Resolution",
    "summary": "Real-image super-resolution (Real-ISR) seeks to recover HR images from LR inputs with mixed, unknown degradations. While diffusion models surpass GANs in perceptual quality, they under-reconstruct high-frequency (HF) details due to a low-frequency (LF) bias and a depth-wise \"low-first, high-later\" hierarchy. We introduce FRAMER, a plug-and-play training scheme that exploits diffusion priors without changing the backbone or inference. At each denoising step, the final-layer feature map teaches all intermediate layers. Teacher and student feature maps are decomposed into LF/HF bands via FFT masks to align supervision with the model's internal frequency hierarchy. For LF, an Intra Contrastive Loss (IntraCL) stabilizes globally shared structure. For HF, an Inter Contrastive Loss (InterCL) sharpens instance-specific details using random-layer and in-batch negatives. Two adaptive modulators, Frequency-based Adaptive Weight (FAW) and Frequency-based Alignment Modulation (FAM), reweight per-layer LF/HF signals and gate distillation by current similarity. Across U-Net and DiT backbones (e.g., Stable Diffusion 2, 3), FRAMER consistently improves PSNR/SSIM and perceptual metrics (LPIPS, NIQE, MANIQA, MUSIQ). Ablations validate the final-layer teacher and random-layer negatives.",
    "published": "2025-12-01T08:09:05Z",
    "updated": "2025-12-01T08:09:05Z",
    "link": "http://arxiv.org/pdf/2512.01390v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Seungho Choi",
      "Jeahun Sung",
      "Jihyong Oh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01383v1",
    "title": "PointNet4D: A Lightweight 4D Point Cloud Video Backbone for Online and Offline Perception in Robotic Applications",
    "summary": "Understanding dynamic 4D environments-3D space evolving over time-is critical for robotic and interactive systems. These applications demand systems that can process streaming point cloud video in real-time, often under resource constraints, while also benefiting from past and present observations when available. However, current 4D backbone networks rely heavily on spatiotemporal convolutions and Transformers, which are often computationally intensive and poorly suited to real-time applications. We propose PointNet4D, a lightweight 4D backbone optimized for both online and offline settings. At its core is a Hybrid Mamba-Transformer temporal fusion block, which integrates the efficient state-space modeling of Mamba and the bidirectional modeling power of Transformers. This enables PointNet4D to handle variable-length online sequences efficiently across different deployment scenarios. To enhance temporal understanding, we introduce 4DMAP, a frame-wise masked auto-regressive pretraining strategy that captures motion cues across frames. Our extensive evaluations across 9 tasks on 7 datasets, demonstrating consistent improvements across diverse domains. We further demonstrate PointNet4D's utility by building two robotic application systems: 4D Diffusion Policy and 4D Imitation Learning, achieving substantial gains on the RoboTwin and HandoverSim benchmarks.",
    "published": "2025-12-01T07:58:01Z",
    "updated": "2025-12-01T07:58:01Z",
    "link": "http://arxiv.org/pdf/2512.01383v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yunze Liu",
      "Zifan Wang",
      "Peiran Wu",
      "Jiayang Ao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01382v1",
    "title": "Reversible Inversion for Training-Free Exemplar-guided Image Editing",
    "summary": "Exemplar-guided Image Editing (EIE) aims to modify a source image according to a visual reference. Existing approaches often require large-scale pre-training to learn relationships between the source and reference images, incurring high computational costs. As a training-free alternative, inversion techniques can be used to map the source image into a latent space for manipulation. However, our empirical study reveals that standard inversion is sub-optimal for EIE, leading to poor quality and inefficiency. To tackle this challenge, we introduce \\textbf{Reversible Inversion ({ReInversion})} for effective and efficient EIE. Specifically, ReInversion operates as a two-stage denoising process, which is first conditioned on the source image and subsequently on the reference. Besides, we introduce a Mask-Guided Selective Denoising (MSD) strategy to constrain edits to target regions, preserving the structural consistency of the background. Both qualitative and quantitative comparisons demonstrate that our ReInversion method achieves state-of-the-art EIE performance with the lowest computational overhead.",
    "published": "2025-12-01T07:56:06Z",
    "updated": "2025-12-01T07:56:06Z",
    "link": "http://arxiv.org/pdf/2512.01382v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yuke Li",
      "Lianli Gao",
      "Ji Zhang",
      "Pengpeng Zeng",
      "Lichuan Xiang",
      "Hongkai Wen",
      "Heng Tao Shen",
      "Jingkuan Song"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2407.16406v2",
    "title": "Hi-EF: Benchmarking Emotion Forecasting in Human-interaction",
    "summary": "Affective Forecasting is an psychology task that involves predicting an individual's future emotional responses, often hampered by reliance on external factors leading to inaccuracies, and typically remains at a qualitative analysis stage. To address these challenges, we narrows the scope of Affective Forecasting by introducing the concept of Human-interaction-based Emotion Forecasting (EF). This task is set within the context of a two-party interaction, positing that an individual's emotions are significantly influenced by their interaction partner's emotional expressions and informational cues. This dynamic provides a structured perspective for exploring the patterns of emotional change, thereby enhancing the feasibility of emotion forecasting.",
    "published": "2024-07-23T11:50:59Z",
    "updated": "2025-12-01T07:55:13Z",
    "link": "http://arxiv.org/pdf/2407.16406v2.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Haoran Wang",
      "Xinji Mai",
      "Zeng Tao",
      "Junxiong Lin",
      "Xuan Tong",
      "Ivy Pan",
      "Shaoqi Yan",
      "Yan Wang",
      "Shuyong Gao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01380v1",
    "title": "Textured Geometry Evaluation: Perceptual 3D Textured Shape Metric via 3D Latent-Geometry Network",
    "summary": "Textured high-fidelity 3D models are crucial for games, AR/VR, and film, but human-aligned evaluation methods still fall behind despite recent advances in 3D reconstruction and generation. Existing metrics, such as Chamfer Distance, often fail to align with how humans evaluate the fidelity of 3D shapes. Recent learning-based metrics attempt to improve this by relying on rendered images and 2D image quality metrics. However, these approaches face limitations due to incomplete structural coverage and sensitivity to viewpoint choices. Moreover, most methods are trained on synthetic distortions, which differ significantly from real-world distortions, resulting in a domain gap. To address these challenges, we propose a new fidelity evaluation method that is based directly on 3D meshes with texture, without relying on rendering. Our method, named Textured Geometry Evaluation TGE, jointly uses the geometry and color information to calculate the fidelity of the input textured mesh with comparison to a reference colored shape. To train and evaluate our metric, we design a human-annotated dataset with real-world distortions. Experiments show that TGE outperforms rendering-based and geometry-only methods on real-world distortion dataset.",
    "published": "2025-12-01T07:53:03Z",
    "updated": "2025-12-01T07:53:03Z",
    "link": "http://arxiv.org/pdf/2512.01380v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Tianyu Luan",
      "Xuelu Feng",
      "Zixin Zhu",
      "Phani Nuney",
      "Sheng Liu",
      "Xuan Gong",
      "David Doermann",
      "Chunming Qiao",
      "Junsong Yuan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01373v1",
    "title": "SRAM: Shape-Realism Alignment Metric for No Reference 3D Shape Evaluation",
    "summary": "3D generation and reconstruction techniques have been widely used in computer games, film, and other content creation areas. As the application grows, there is a growing demand for 3D shapes that look truly realistic. Traditional evaluation methods rely on a ground truth to measure mesh fidelity. However, in many practical cases, a shape's realism does not depend on having a ground truth reference. In this work, we propose a Shape-Realism Alignment Metric that leverages a large language model (LLM) as a bridge between mesh shape information and realism evaluation. To achieve this, we adopt a mesh encoding approach that converts 3D shapes into the language token space. A dedicated realism decoder is designed to align the language model's output with human perception of realism. Additionally, we introduce a new dataset, RealismGrading, which provides human-annotated realism scores without the need for ground truth shapes. Our dataset includes shapes generated by 16 different algorithms on over a dozen objects, making it more representative of practical 3D shape distributions. We validate our metric's performance and generalizability through k-fold cross-validation across different objects. Experimental results show that our metric correlates well with human perceptions and outperforms existing methods, and has good generalizability.",
    "published": "2025-12-01T07:40:11Z",
    "updated": "2025-12-01T07:40:11Z",
    "link": "http://arxiv.org/pdf/2512.01373v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Sheng Liu",
      "Tianyu Luan",
      "Phani Nuney",
      "Xuelu Feng",
      "Junsong Yuan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.23170v2",
    "title": "PowerCLIP: Powerset Alignment for Contrastive Pre-Training",
    "summary": "Contrastive vision-language pre-training frameworks such as CLIP have demonstrated impressive zero-shot performance across a range of vision-language tasks. Recent studies have shown that aligning individual text tokens with specific image patches or regions enhances fine-grained compositional understanding. However, it remains challenging to capture compositional semantics that span multiple image regions. To address this limitation, we propose PowerCLIP, a novel contrastive pre-training framework enhanced by powerset alignment, which exhaustively optimizes region-to-phrase alignments by minimizing the loss defined between powersets of image regions and textual parse trees. Since the naive powerset construction incurs exponential computational cost due to the combinatorial explosion in the number of region subsets, we introduce efficient non-linear aggregators (NLAs) that reduce complexity from O(2^M) to O(M) with respect to the number of regions M, while approximating the exact loss value with arbitrary precision. Our extensive experiments demonstrate that PowerCLIP outperforms state-of-the-art methods in zero-shot classification and retrieval tasks, underscoring the compositionality and robustness of our approach. Our code will be made publicly available.",
    "published": "2025-11-28T13:28:18Z",
    "updated": "2025-12-01T07:34:37Z",
    "link": "http://arxiv.org/pdf/2511.23170v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Masaki Kawamura",
      "Nakamasa Inoue",
      "Rintaro Yanagi",
      "Hirokatsu Kataoka",
      "Rio Yokota"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.17133v2",
    "title": "Off the Planckian Locus: Using 2D Chromaticity to Improve In-Camera Color",
    "summary": "Traditional in-camera colorimetric mapping relies on correlated color temperature (CCT)-based interpolation between pre-calibrated transforms optimized for Planckian illuminants such as CIE A and D65. However, modern lighting technologies such as LEDs can deviate substantially from the Planckian locus, exposing the limitations of relying on conventional one-dimensional CCT for illumination characterization. This paper demonstrates that transitioning from 1D CCT (on the Planckian locus) to a 2D chromaticity space (off the Planckian locus) improves colorimetric accuracy across various mapping approaches. In addition, we replace conventional CCT interpolation with a lightweight multi-layer perceptron (MLP) that leverages 2D chromaticity features for robust colorimetric mapping under non-Planckian illuminants. A lightbox-based calibration procedure incorporating representative LED sources is used to train our MLP. Validated across diverse LED lighting, our method reduces angular reproduction error by 22% on average in LED-lit scenes, maintains backward compatibility with traditional illuminants, accommodates multi-illuminant scenes, and supports real-time in-camera deployment with negligible additional computational cost.",
    "published": "2025-11-21T10:49:04Z",
    "updated": "2025-12-01T07:28:30Z",
    "link": "http://arxiv.org/pdf/2511.17133v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "SaiKiran Tedla",
      "Joshua E. Little",
      "Hakki Can Karaimer",
      "Michael S. Brown"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01366v1",
    "title": "BlinkBud: Detecting Hazards from Behind via Sampled Monocular 3D Detection on a Single Earbud",
    "summary": "Failing to be aware of speeding vehicles approaching from behind poses a huge threat to the road safety of pedestrians and cyclists. In this paper, we propose BlinkBud, which utilizes a single earbud and a paired phone to online detect hazardous objects approaching from behind of a user. The core idea is to accurately track visually identified objects utilizing a small number of sampled camera images taken from the earbud. To minimize the power consumption of the earbud and the phone while guaranteeing the best tracking accuracy, a novel 3D object tracking algorithm is devised, integrating both a Kalman filter based trajectory estimation scheme and an optimal image sampling strategy based on reinforcement learning. Moreover, the impact of constant user head movements on the tracking accuracy is significantly eliminated by leveraging the estimated pitch and yaw angles to correct the object depth estimation and align the camera coordinate system to the user's body coordinate system, respectively. We implement a prototype BlinkBud system and conduct extensive real-world experiments. Results show that BlinkBud is lightweight with ultra-low mean power consumptions of 29.8 mW and 702.6 mW on the earbud and smartphone, respectively, and can accurately detect hazards with a low average false positive ratio (FPR) and false negative ratio (FNR) of 4.90% and 1.47%, respectively.",
    "published": "2025-12-01T07:25:17Z",
    "updated": "2025-12-01T07:25:17Z",
    "link": "http://arxiv.org/pdf/2512.01366v1.pdf",
    "category": [
      "cs.CV",
      "cs.HC",
      "cs.LG"
    ],
    "authors": [
      "Yunzhe Li",
      "Jiajun Yan",
      "Yuzhou Wei",
      "Kechen Liu",
      "Yize Zhao",
      "Chong Zhang",
      "Hongzi Zhu",
      "Li Lu",
      "Shan Chang",
      "Minyi Guo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.21251v2",
    "title": "AVFakeBench: A Comprehensive Audio-Video Forgery Detection Benchmark for AV-LMMs",
    "summary": "The threat of Audio-Video (AV) forgery is rapidly evolving beyond human-centric deepfakes to include more diverse manipulations across complex natural scenes. However, existing benchmarks are still confined to DeepFake-based forgeries and single-granularity annotations, thus failing to capture the diversity and complexity of real-world forgery scenarios. To address this, we introduce AVFakeBench, the first comprehensive audio-video forgery detection benchmark that spans rich forgery semantics across both human subject and general subject. AVFakeBench comprises 12K carefully curated audio-video questions, covering seven forgery types and four levels of annotations. To ensure high-quality and diverse forgeries, we propose a multi-stage hybrid forgery framework that integrates proprietary models for task planning with expert generative models for precise manipulation. The benchmark establishes a multi-task evaluation framework covering binary judgment, forgery types classification, forgery detail selection, and explanatory reasoning. We evaluate 11 Audio-Video Large Language Models (AV-LMMs) and 2 prevalent detection methods on AVFakeBench, demonstrating the potential of AV-LMMs as emerging forgery detectors while revealing their notable weaknesses in fine-grained perception and reasoning.",
    "published": "2025-11-26T10:33:12Z",
    "updated": "2025-12-01T07:07:08Z",
    "link": "http://arxiv.org/pdf/2511.21251v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Shuhan Xia",
      "Peipei Li",
      "Xuannan Liu",
      "Dongsen Zhang",
      "Xinyu Guo",
      "Zekun Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.21237v2",
    "title": "3-Tracer: A Tri-level Temporal-Aware Framework for Audio Forgery Detection and Localization",
    "summary": "Recently, partial audio forgery has emerged as a new form of audio manipulation. Attackers selectively modify partial but semantically critical frames while preserving the overall perceptual authenticity, making such forgeries particularly difficult to detect. Existing methods focus on independently detecting whether a single frame is forged, lacking the hierarchical structure to capture both transient and sustained anomalies across different temporal levels. To address these limitations, We identify three key levels relevant to partial audio forgery detection and present T3-Tracer, the first framework that jointly analyzes audio at the frame, segment, and audio levels to comprehensively detect forgery traces. T3-Tracer consists of two complementary core modules: the Frame-Audio Feature Aggregation Module (FA-FAM) and the Segment-level Multi-Scale Discrepancy-Aware Module (SMDAM). FA-FAM is designed to detect the authenticity of each audio frame. It combines both frame-level and audio-level temporal information to detect intra-frame forgery cues and global semantic inconsistencies. To further refine and correct frame detection, we introduce SMDAM to detect forgery boundaries at the segment level. It adopts a dual-branch architecture that jointly models frame features and inter-frame differences across multi-scale temporal windows, effectively identifying abrupt anomalies that appeared on the forged boundaries. Extensive experiments conducted on three challenging datasets demonstrate that our approach achieves state-of-the-art performance.",
    "published": "2025-11-26T10:07:03Z",
    "updated": "2025-12-01T07:06:39Z",
    "link": "http://arxiv.org/pdf/2511.21237v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Shuhan Xia",
      "Xuannan Liu",
      "Xing Cui",
      "Peipei Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01352v1",
    "title": "OpenBox: Annotate Any Bounding Boxes in 3D",
    "summary": "Unsupervised and open-vocabulary 3D object detection has recently gained attention, particularly in autonomous driving, where reducing annotation costs and recognizing unseen objects are critical for both safety and scalability. However, most existing approaches uniformly annotate 3D bounding boxes, ignore objects' physical states, and require multiple self-training iterations for annotation refinement, resulting in suboptimal quality and substantial computational overhead. To address these challenges, we propose OpenBox, a two-stage automatic annotation pipeline that leverages a 2D vision foundation model. In the first stage, OpenBox associates instance-level cues from 2D images processed by a vision foundation model with the corresponding 3D point clouds via cross-modal instance alignment. In the second stage, it categorizes instances by rigidity and motion state, then generates adaptive bounding boxes with class-specific size statistics. As a result, OpenBox produces high-quality 3D bounding box annotations without requiring self-training. Experiments on the Waymo Open Dataset, the Lyft Level 5 Perception dataset, and the nuScenes dataset demonstrate improved accuracy and efficiency over baselines.",
    "published": "2025-12-01T07:04:48Z",
    "updated": "2025-12-01T07:04:48Z",
    "link": "http://arxiv.org/pdf/2512.01352v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "In-Jae Lee",
      "Mungyeom Kim",
      "Kwonyoung Ryu",
      "Pierre Musacchio",
      "Jaesik Park"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01348v1",
    "title": "Handwritten Text Recognition for Low Resource Languages",
    "summary": "Despite considerable progress in handwritten text recognition, paragraph-level handwritten text recognition, especially in low-resource languages, such as Hindi, Urdu and similar scripts, remains a challenging problem. These languages, often lacking comprehensive linguistic resources, require special attention to develop robust systems for accurate optical character recognition (OCR). This paper introduces BharatOCR, a novel segmentation-free paragraph-level handwritten Hindi and Urdu text recognition. We propose a ViT-Transformer Decoder-LM architecture for handwritten text recognition, where a Vision Transformer (ViT) extracts visual features, a Transformer decoder generates text sequences, and a pre-trained language model (LM) refines the output to improve accuracy, fluency, and coherence. Our model utilizes a Data-efficient Image Transformer (DeiT) model proposed for masked image modeling in this research work. In addition, we adopt a RoBERTa architecture optimized for masked language modeling (MLM) to enhance the linguistic comprehension and generative capabilities of the proposed model. The transformer decoder generates text sequences from visual embeddings. This model is designed to iteratively process a paragraph image line by line, called implicit line segmentation. The proposed model was evaluated using our custom dataset ('Parimal Urdu') and ('Parimal Hindi'), introduced in this research work, as well as two public datasets. The proposed model achieved benchmark results in the NUST-UHWR, PUCIT-OUHL, and Parimal-Urdu datasets, achieving character recognition rates of 96.24%, 92.05%, and 94.80%, respectively. The model also provided benchmark results using the Hindi dataset achieving a character recognition rate of 80.64%. The results obtained from our proposed model indicated that it outperformed several state-of-the-art Urdu text recognition methods.",
    "published": "2025-12-01T07:01:52Z",
    "updated": "2025-12-01T07:01:52Z",
    "link": "http://arxiv.org/pdf/2512.01348v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Sayantan Dey",
      "Alireza Alaei",
      "Partha Pratim Roy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01342v1",
    "title": "InternVideo-Next: Towards General Video Foundation Models without Video-Text Supervision",
    "summary": "Large-scale video-text pretraining achieves strong performance but depends on noisy, synthetic captions with limited semantic coverage, often overlooking implicit world knowledge such as object motion, 3D geometry, and physical cues. In contrast, masked video modeling (MVM) directly exploits spatiotemporal structures but trails text-supervised methods on general tasks. We find this gap arises from overlooked architectural issues: pixel-level reconstruction struggles with convergence and its low-level requirement often conflicts with semantics, while latent prediction often encourages shortcut learning. To address these, we disentangle the traditional encoder-decoder design into an Encoder-Predictor-Decoder (EPD) framework, where the predictor acts as a latent world model, and propose InternVideo-Next, a two-stage pretraining scheme that builds a semantically consistent yet detail-preserving latent space for this world model. First, conventional linear decoder in pixel MVM enforces the predictor output latent to be linearly projected to, thus separable in pixel space, causing the conflict with semantic abstraction. Our Stage 1 proposes a conditional diffusion decoder and injects reliable image-level semantic priors to enhance semantics and convergence, thus bridging pixel-level fidelity with high-level semantic abstraction. Stage 2 further learns world knowledge by predicting frozen Stage 1 targets within this space, mitigating shortcut learning. Trained on public, unlabeled videos, InternVideo-Next achieves state-of-the-art results across benchmarks and provides a scalable path toward general video representation learning.",
    "published": "2025-12-01T06:57:39Z",
    "updated": "2025-12-01T06:57:39Z",
    "link": "http://arxiv.org/pdf/2512.01342v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Chenting Wang",
      "Yuhan Zhu",
      "Yicheng Xu",
      "Jiange Yang",
      "Ziang Yan",
      "Yali Wang",
      "Yi Wang",
      "Limin Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01340v1",
    "title": "EvalTalker: Learning to Evaluate Real-Portrait-Driven Multi-Subject Talking Humans",
    "summary": "Speech-driven Talking Human (TH) generation, commonly known as \"Talker,\" currently faces limitations in multi-subject driving capabilities. Extending this paradigm to \"Multi-Talker,\" capable of animating multiple subjects simultaneously, introduces richer interactivity and stronger immersion in audiovisual communication. However, current Multi-Talkers still exhibit noticeable quality degradation caused by technical limitations, resulting in suboptimal user experiences. To address this challenge, we construct THQA-MT, the first large-scale Multi-Talker-generated Talking Human Quality Assessment dataset, consisting of 5,492 Multi-Talker-generated THs (MTHs) from 15 representative Multi-Talkers using 400 real portraits collected online. Through subjective experiments, we analyze perceptual discrepancies among different Multi-Talkers and identify 12 common types of distortion. Furthermore, we introduce EvalTalker, a novel TH quality assessment framework. This framework possesses the ability to perceive global quality, human characteristics, and identity consistency, while integrating Qwen-Sync to perceive multimodal synchrony. Experimental results demonstrate that EvalTalker achieves superior correlation with subjective scores, providing a robust foundation for future research on high-quality Multi-Talker generation and evaluation.",
    "published": "2025-12-01T06:56:40Z",
    "updated": "2025-12-01T06:56:40Z",
    "link": "http://arxiv.org/pdf/2512.01340v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yingjie Zhou",
      "Xilei Zhu",
      "Siyu Ren",
      "Ziyi Zhao",
      "Ziwen Wang",
      "Farong Wen",
      "Yu Zhou",
      "Jiezhang Cao",
      "Xiongkuo Min",
      "Fengjiao Chen",
      "Xiaoyu Li",
      "Xuezhi Cao",
      "Guangtao Zhai",
      "Xiaohong Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01334v1",
    "title": "AlignVid: Training-Free Attention Scaling for Semantic Fidelity in Text-Guided Image-to-Video Generation",
    "summary": "Text-guided image-to-video (TI2V) generation has recently achieved remarkable progress, particularly in maintaining subject consistency and temporal coherence. However, existing methods still struggle to adhere to fine-grained prompt semantics, especially when prompts entail substantial transformations of the input image (e.g., object addition, deletion, or modification), a shortcoming we term semantic negligence. In a pilot study, we find that applying a Gaussian blur to the input image improves semantic adherence. Analyzing attention maps, we observe clearer foreground-background separation. From an energy perspective, this corresponds to a lower-entropy cross-attention distribution. Motivated by this, we introduce AlignVid, a training-free framework with two components: (i) Attention Scaling Modulation (ASM), which directly reweights attention via lightweight Q or K scaling, and (ii) Guidance Scheduling (GS), which applies ASM selectively across transformer blocks and denoising steps to reduce visual quality degradation. This minimal intervention improves prompt adherence while limiting aesthetic degradation. In addition, we introduce OmitI2V to evaluate semantic negligence in TI2V generation, comprising 367 human-annotated samples that span addition, deletion, and modification scenarios. Extensive experiments demonstrate that AlignVid can enhance semantic fidelity.",
    "published": "2025-12-01T06:53:48Z",
    "updated": "2025-12-01T06:53:48Z",
    "link": "http://arxiv.org/pdf/2512.01334v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yexin Liu",
      "Wen-Jie Shu",
      "Zile Huang",
      "Haoze Zheng",
      "Yueze Wang",
      "Manyuan Zhang",
      "Ser-Nam Lim",
      "Harry Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01333v1",
    "title": "Optimizing Stroke Risk Prediction: A Machine Learning Pipeline Combining ROS-Balanced Ensembles and XAI",
    "summary": "Stroke is a major cause of death and permanent impairment, making it a major worldwide health concern. For prompt intervention and successful preventative tactics, early risk assessment is essential. To address this challenge, we used ensemble modeling and explainable AI (XAI) techniques to create an interpretable machine learning framework for stroke risk prediction. A thorough evaluation of 10 different machine learning models using 5-fold cross-validation across several datasets was part of our all-inclusive strategy, which also included feature engineering and data pretreatment (using Random Over-Sampling (ROS) to solve class imbalance). Our optimized ensemble model (Random Forest + ExtraTrees + XGBoost) performed exceptionally well, obtaining a strong 99.09% accuracy on the Stroke Prediction Dataset (SPD). We improved the model's transparency and clinical applicability by identifying three important clinical variables using LIME-based interpretability analysis: age, hypertension, and glucose levels. Through early prediction, this study highlights how combining ensemble learning with explainable AI (XAI) can deliver highly accurate and interpretable stroke risk assessment. By enabling data-driven prevention and personalized clinical decisions, our framework has the potential to transform stroke prediction and cardiovascular risk management.",
    "published": "2025-12-01T06:53:00Z",
    "updated": "2025-12-01T06:53:00Z",
    "link": "http://arxiv.org/pdf/2512.01333v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "A S M Ahsanul Sarkar Akib",
      "Raduana Khawla",
      "Abdul Hasib"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01329v1",
    "title": "TagSplat: Topology-Aware Gaussian Splatting for Dynamic Mesh Modeling and Tracking",
    "summary": "Topology-consistent dynamic model sequences are essential for applications such as animation and model editing. However, existing 4D reconstruction methods face challenges in generating high-quality topology-consistent meshes. To address this, we propose a topology-aware dynamic reconstruction framework based on Gaussian Splatting. We introduce a Gaussian topological structure that explicitly encodes spatial connectivity. This structure enables topology-aware densification and pruning, preserving the manifold consistency of the Gaussian representation. Temporal regularization terms further ensure topological coherence over time, while differentiable mesh rasterization improves mesh quality. Experimental results demonstrate that our method reconstructs topology-consistent mesh sequences with significantly higher accuracy than existing approaches. Moreover, the resulting meshes enable precise 3D keypoint tracking. Project page: https://haza628.github.io/tagSplat/",
    "published": "2025-12-01T06:41:54Z",
    "updated": "2025-12-01T06:41:54Z",
    "link": "http://arxiv.org/pdf/2512.01329v1.pdf",
    "category": [
      "cs.GR",
      "cs.CV"
    ],
    "authors": [
      "Hanzhi Guo",
      "Dongdong Weng",
      "Mo Su",
      "Yixiao Chen",
      "Xiaonuo Dongye",
      "Chenyu Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13853v2",
    "title": "Can World Simulators Reason? Gen-ViRe: A Generative Visual Reasoning Benchmark",
    "summary": "While Chain-of-Thought (CoT) prompting enables sophisticated symbolic reasoning in LLMs, it remains confined to discrete text and cannot simulate the continuous, physics-governed dynamics of the real world. Recent video generation models have emerged as potential world simulators through Chain-of-Frames (CoF) reasoning -- materializing thought as frame-by-frame visual sequences, with each frame representing a physically-grounded reasoning step. Despite compelling demonstrations, a challenge persists: existing benchmarks, focusing on fidelity or alignment, do not assess CoF reasoning and thus cannot measure core cognitive abilities in multi-step planning, algorithmic logic, or abstract pattern extrapolation. This evaluation void prevents systematic understanding of model capabilities and principled guidance for improvement. We introduce Gen-ViRe (Generative Visual Reasoning Benchmark), a framework grounded in cognitive science and real-world AI applications, which decomposes CoF reasoning into six cognitive dimensions -- from perceptual logic to abstract planning -- and 24 subtasks. Through multi-source data curation, minimal prompting protocols, and hybrid VLM-assisted evaluation with detailed criteria, Gen-ViRe delivers the first quantitative assessment of video models as reasoners. Our experiments on SOTA systems reveal substantial discrepancies between impressive visual quality and actual reasoning depth, establishing baselines and diagnostic tools to advance genuine world simulators.",
    "published": "2025-11-17T19:11:39Z",
    "updated": "2025-12-01T06:39:12Z",
    "link": "http://arxiv.org/pdf/2511.13853v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xinxin Liu",
      "Zhaopan Xu",
      "Ming Li",
      "Kai Wang",
      "Yong Jae Lee",
      "Yuzhang Shang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01324v1",
    "title": "Panda: Self-distillation of Reusable Sensor-level Representations for High Energy Physics",
    "summary": "Liquid argon time projection chambers (LArTPCs) provide dense, high-fidelity 3D measurements of particle interactions and underpin current and future neutrino and rare-event experiments. Physics reconstruction typically relies on complex detector-specific pipelines that use tens of hand-engineered pattern recognition algorithms or cascades of task-specific neural networks that require extensive, labeled simulation that requires a careful, time-consuming calibration process. We introduce \\textbf{Panda}, a model that learns reusable sensor-level representations directly from raw unlabeled LArTPC data. Panda couples a hierarchical sparse 3D encoder with a multi-view, prototype-based self-distillation objective. On a simulated dataset, Panda substantially improves label efficiency and reconstruction quality, beating the previous state-of-the-art semantic segmentation model with 1,000$\\times$ fewer labels. We also show that a single set-prediction head 1/20th the size of the backbone with no physical priors trained on frozen outputs from Panda can result in particle identification that is comparable with state-of-the-art (SOTA) reconstruction tools. Full fine-tuning further improves performance across all tasks.",
    "published": "2025-12-01T06:28:11Z",
    "updated": "2025-12-01T06:28:11Z",
    "link": "http://arxiv.org/pdf/2512.01324v1.pdf",
    "category": [
      "hep-ex",
      "cs.CV"
    ],
    "authors": [
      "Samuel Young",
      "Kazuhiro Terao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.20518v3",
    "title": "Dynamic Attention Analysis for Backdoor Detection in Text-to-Image Diffusion Models",
    "summary": "Recent studies have revealed that text-to-image diffusion models are vulnerable to backdoor attacks, where attackers implant stealthy textual triggers to manipulate model outputs. Previous backdoor detection methods primarily focus on the static features of backdoor samples. However, a vital property of diffusion models is their inherent dynamism. This study introduces a novel backdoor detection perspective named Dynamic Attention Analysis (DAA), showing that these dynamic characteristics serve as better indicators for backdoor detection. Specifically, by examining the dynamic evolution of cross-attention maps, we observe that backdoor samples exhibit distinct feature evolution patterns at the $<$EOS$>$ token compared to benign samples. To quantify these dynamic anomalies, we first introduce DAA-I, which treats the tokens' attention maps as spatially independent and measures dynamic feature using the Frobenius norm. Furthermore, to better capture the interactions between attention maps and refine the feature, we propose a dynamical system-based approach, referred to as DAA-S. This model formulates the spatial correlations among attention maps using a graph-based state equation and we theoretically analyze the global asymptotic stability of this method. Extensive experiments across six representative backdoor attack scenarios demonstrate that our approach significantly surpasses existing detection methods, achieving an average F1 Score of 79.27% and an AUC of 86.27%. The code is available at https://github.com/Robin-WZQ/DAA.",
    "published": "2025-04-29T07:59:35Z",
    "updated": "2025-12-01T06:19:48Z",
    "link": "http://arxiv.org/pdf/2504.20518v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhongqi Wang",
      "Jie Zhang",
      "Shiguang Shan",
      "Xilin Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01314v1",
    "title": "TokenPure: Watermark Removal through Tokenized Appearance and Structural Guidance",
    "summary": "In the digital economy era, digital watermarking serves as a critical basis for ownership proof of massive replicable content, including AI-generated and other virtual assets. Designing robust watermarks capable of withstanding various attacks and processing operations is even more paramount. We introduce TokenPure, a novel Diffusion Transformer-based framework designed for effective and consistent watermark removal. TokenPure solves the trade-off between thorough watermark destruction and content consistency by leveraging token-based conditional reconstruction. It reframes the task as conditional generation, entirely bypassing the initial watermark-carrying noise. We achieve this by decomposing the watermarked image into two complementary token sets: visual tokens for texture and structural tokens for geometry. These tokens jointly condition the diffusion process, enabling the framework to synthesize watermark-free images with fine-grained consistency and structural integrity. Comprehensive experiments show that TokenPure achieves state-of-the-art watermark removal and reconstruction fidelity, substantially outperforming existing baselines in both perceptual quality and consistency.",
    "published": "2025-12-01T06:15:51Z",
    "updated": "2025-12-01T06:15:51Z",
    "link": "http://arxiv.org/pdf/2512.01314v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Pei Yang",
      "Yepeng Liu",
      "Kelly Peng",
      "Yuan Gao",
      "Yiren Song"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01312v1",
    "title": "IVCR-200K: A Large-Scale Multi-turn Dialogue Benchmark for Interactive Video Corpus Retrieval",
    "summary": "In recent years, significant developments have been made in both video retrieval and video moment retrieval tasks, which respectively retrieve complete videos or moments for a given text query. These advancements have greatly improved user satisfaction during the search process. However, previous work has failed to establish meaningful \"interaction\" between the retrieval system and the user, and its one-way retrieval paradigm can no longer fully meet the personalization and dynamic needs of at least 80.8\\% of users. In this paper, we introduce the Interactive Video Corpus Retrieval (IVCR) task, a more realistic setting that enables multi-turn, conversational, and realistic interactions between the user and the retrieval system. To facilitate research on this challenging task, we introduce IVCR-200K, a high-quality, bilingual, multi-turn, conversational, and abstract semantic dataset that supports video retrieval and even moment retrieval. Furthermore, we propose a comprehensive framework based on multi-modal large language models (MLLMs) to help users interact in several modes with more explainable solutions. The extensive experiments demonstrate the effectiveness of our dataset and framework.",
    "published": "2025-12-01T06:12:59Z",
    "updated": "2025-12-01T06:12:59Z",
    "link": "http://arxiv.org/pdf/2512.01312v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ning Han",
      "Yawen Zeng",
      "Shaohua Long",
      "Chengqing Li",
      "Sijie Yang",
      "Dun Tan",
      "Jianfeng Dong",
      "Jingjing Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.14712v2",
    "title": "FreeSwim: Revisiting Sliding-Window Attention Mechanisms for Training-Free Ultra-High-Resolution Video Generation",
    "summary": "The quadratic time and memory complexity of the attention mechanism in modern Transformer based video generators makes end-to-end training for ultra high resolution videos prohibitively expensive. Motivated by this limitation, we introduce a training-free approach that leverages video Diffusion Transformers pretrained at their native scale to synthesize higher resolution videos without any additional training or adaptation. At the core of our method lies an inward sliding window attention mechanism, which originates from a key observation: maintaining each query token's training scale receptive field is crucial for preserving visual fidelity and detail. However, naive local window attention, unfortunately, often leads to repetitive content and exhibits a lack of global coherence in the generated results. To overcome this challenge, we devise a dual-path pipeline that backs up window attention with a novel cross-attention override strategy, enabling the semantic content produced by local attention to be guided by another branch with a full receptive field and, therefore, ensuring holistic consistency. Furthermore, to improve efficiency, we incorporate a cross-attention caching strategy for this branch to avoid the frequent computation of full 3D attention. Extensive experiments demonstrate that our method delivers ultra-high-resolution videos with fine-grained visual details and high efficiency in a training-free paradigm. Meanwhile, it achieves superior performance on VBench, even compared to training-based alternatives, with competitive or improved efficiency. Codes are available at: https://github.com/WillWu111/FreeSwim",
    "published": "2025-11-18T17:56:04Z",
    "updated": "2025-12-01T06:11:56Z",
    "link": "http://arxiv.org/pdf/2511.14712v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yunfeng Wu",
      "Jiayi Song",
      "Zhenxiong Tan",
      "Zihao He",
      "Songhua Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01310v1",
    "title": "Lost in Distortion: Uncovering the Domain Gap Between Computer Vision and Brain Imaging - A Study on Pretraining for Age Prediction",
    "summary": "Large-scale brain imaging datasets provide unprecedented opportunities for developing domain foundation models through pretraining. However, unlike natural image datasets in computer vision, these neuroimaging data often exhibit high heterogeneity in quality, ranging from well-structured scans to severely distorted or incomplete brain volumes. This raises a fundamental question: can noise or low-quality scans contribute meaningfully to pretraining, or do they instead hinder model learning? In this study, we systematically explore the role of data quality level in pretraining and its impact on downstream tasks. Specifically, we perform pretraining on datasets with different quality levels and perform fine-tuning for brain age prediction on external cohorts. Our results show significant performance differences across quality levels, revealing both opportunities and limitations. We further discuss the gap between computer vision practices and clinical neuroimaging standards, emphasizing the necessity of domain-aware curation to ensure trusted and generalizable domain-specific foundation models.",
    "published": "2025-12-01T06:11:31Z",
    "updated": "2025-12-01T06:11:31Z",
    "link": "http://arxiv.org/pdf/2512.01310v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yanteng Zhang",
      "Songheng Li",
      "Zeyu Shen",
      "Qizhen Lan",
      "Lipei Zhang",
      "Yang Liu",
      "Vince Calhoun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.11253v3",
    "title": "CountSteer: Steering Attention for Object Counting in Diffusion Models",
    "summary": "Text-to-image diffusion models generate realistic and coherent images but often fail to follow numerical instructions in text, revealing a gap between language and visual representation. Interestingly, we found that these models are not entirely blind to numbers-they are implicitly aware of their own counting accuracy, as their internal signals shift in consistent ways depending on whether the output meets the specified count. This observation suggests that the model already encodes a latent notion of numerical correctness, which can be harnessed to guide generation more precisely. Building on this intuition, we introduce CountSteer, a training-free method that improves generation of specified object counts by steering the model's cross-attention hidden states during inference. In our experiments, CountSteer improved object-count accuracy by about 4% without compromising visual quality, demonstrating a simple yet effective step toward more controllable and semantically reliable text-to-image generation.",
    "published": "2025-11-14T12:52:11Z",
    "updated": "2025-12-01T06:04:41Z",
    "link": "http://arxiv.org/pdf/2511.11253v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Hyemin Boo",
      "Hyoryung Kim",
      "Myungjin Lee",
      "Seunghyeon Lee",
      "Jiyoung Lee",
      "Jang-Hwan Choi",
      "Hyunsoo Cho"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01306v1",
    "title": "Gaussian Swaying: Surface-Based Framework for Aerodynamic Simulation with 3D Gaussians",
    "summary": "Branches swaying in the breeze, flags rippling in the wind, and boats rocking on the water all show how aerodynamics shape natural motion -- an effect crucial for realism in vision and graphics. In this paper, we present Gaussian Swaying, a surface-based framework for aerodynamic simulation using 3D Gaussians. Unlike mesh-based methods that require costly meshing, or particle-based approaches that rely on discrete positional data, Gaussian Swaying models surfaces continuously with 3D Gaussians, enabling efficient and fine-grained aerodynamic interaction. Our framework unifies simulation and rendering on the same representation: Gaussian patches, which support force computation for dynamics while simultaneously providing normals for lightweight shading. Comprehensive experiments on both synthetic and real-world datasets across multiple metrics demonstrate that Gaussian Swaying achieves state-of-the-art performance and efficiency, offering a scalable approach for realistic aerodynamic scene simulation.",
    "published": "2025-12-01T06:03:47Z",
    "updated": "2025-12-01T06:03:47Z",
    "link": "http://arxiv.org/pdf/2512.01306v1.pdf",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "Hongru Yan",
      "Xiang Zhang",
      "Zeyuan Chen",
      "Fangyin Wei",
      "Zhuowen Tu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2305.19480v7",
    "title": "Learning by Aligning 2D Skeleton Sequences and Multi-Modality Fusion",
    "summary": "This paper presents a self-supervised temporal video alignment framework which is useful for several fine-grained human activity understanding applications. In contrast with the state-of-the-art method of CASA, where sequences of 3D skeleton coordinates are taken directly as input, our key idea is to use sequences of 2D skeleton heatmaps as input. Unlike CASA which performs self-attention in the temporal domain only, we feed 2D skeleton heatmaps to a video transformer which performs self-attention both in the spatial and temporal domains for extracting effective spatiotemporal and contextual features. In addition, we introduce simple heatmap augmentation techniques based on 2D skeletons for self-supervised learning. Despite the lack of 3D information, our approach achieves not only higher accuracy but also better robustness against missing and noisy keypoints than CASA. Furthermore, extensive evaluations on three public datasets, i.e., Penn Action, IKEA ASM, and H2O, demonstrate that our approach outperforms previous methods in different fine-grained human activity understanding tasks. Finally, fusing 2D skeleton heatmaps with RGB videos yields the state-of-the-art on all metrics and datasets. To our best knowledge, our work is the first to utilize 2D skeleton heatmap inputs and the first to explore multi-modality fusion for temporal video alignment. Our code and dataset are available on our research website: https://retrocausal.ai/research/.",
    "published": "2023-05-31T01:16:08Z",
    "updated": "2025-12-01T06:01:33Z",
    "link": "http://arxiv.org/pdf/2305.19480v7.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Quoc-Huy Tran",
      "Muhammad Ahmed",
      "Murad Popattia",
      "M. Hassan Ahmed",
      "Andrey Konin",
      "M. Zeeshan Zia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01302v1",
    "title": "DCText: Scheduled Attention Masking for Visual Text Generation via Divide-and-Conquer Strategy",
    "summary": "Despite recent text-to-image models achieving highfidelity text rendering, they still struggle with long or multiple texts due to diluted global attention. We propose DCText, a training-free visual text generation method that adopts a divide-and-conquer strategy, leveraging the reliable short-text generation of Multi-Modal Diffusion Transformers. Our method first decomposes a prompt by extracting and dividing the target text, then assigns each to a designated region. To accurately render each segment within their regions while preserving overall image coherence, we introduce two attention masks - Text-Focus and Context-Expansion - applied sequentially during denoising. Additionally, Localized Noise Initialization further improves text accuracy and region alignment without increasing computational cost. Extensive experiments on single- and multisentence benchmarks show that DCText achieves the best text accuracy without compromising image quality while also delivering the lowest generation latency.",
    "published": "2025-12-01T05:52:55Z",
    "updated": "2025-12-01T05:52:55Z",
    "link": "http://arxiv.org/pdf/2512.01302v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jaewoo Song",
      "Jooyoung Choi",
      "Kanghyun Baek",
      "Sangyub Lee",
      "Daemin Park",
      "Sungroh Yoon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01298v1",
    "title": "TBT-Former: Learning Temporal Boundary Distributions for Action Localization",
    "summary": "Temporal Action Localization (TAL) remains a fundamental challenge in video understanding, aiming to identify the start time, end time, and category of all action instances within untrimmed videos. While recent single-stage, anchor-free models like ActionFormer have set a high standard by leveraging Transformers for temporal reasoning, they often struggle with two persistent issues: the precise localization of actions with ambiguous or \"fuzzy\" temporal boundaries and the effective fusion of multi-scale contextual information. In this paper, we introduce the Temporal Boundary Transformer (TBT-Former), a new architecture that directly addresses these limitations. TBT-Former enhances the strong ActionFormer baseline with three core contributions: (1) a higher-capacity scaled Transformer backbone with an increased number of attention heads and an expanded Multi-Layer Perceptron (MLP) dimension for more powerful temporal feature extraction; (2) a cross-scale feature pyramid network (FPN) that integrates a top-down pathway with lateral connections, enabling richer fusion of high-level semantics and low-level temporal details; and (3) a novel boundary distribution regression head. Inspired by the principles of Generalized Focal Loss (GFL), this new head recasts the challenging task of boundary regression as a more flexible probability distribution learning problem, allowing the model to explicitly represent and reason about boundary uncertainty. Within the paradigm of Transformer-based architectures, TBT-Former advances the formidable benchmark set by its predecessors, establishing a new level of performance on the highly competitive THUMOS14 and EPIC-Kitchens 100 datasets, while remaining competitive on the large-scale ActivityNet-1.3. Our code is available at https://github.com/aaivu/In21-S7-CS4681-AML-Research-Projects/tree/main/projects/210536K-Multi-Modal-Learning_Video-Understanding",
    "published": "2025-12-01T05:38:13Z",
    "updated": "2025-12-01T05:38:13Z",
    "link": "http://arxiv.org/pdf/2512.01298v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Thisara Rathnayaka",
      "Uthayasanker Thayasivam"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01296v1",
    "title": "EGG-Fusion: Efficient 3D Reconstruction with Geometry-aware Gaussian Surfel on the Fly",
    "summary": "Real-time 3D reconstruction is a fundamental task in computer graphics. Recently, differentiable-rendering-based SLAM system has demonstrated significant potential, enabling photorealistic scene rendering through learnable scene representations such as Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS). Current differentiable rendering methods face dual challenges in real-time computation and sensor noise sensitivity, leading to degraded geometric fidelity in scene reconstruction and limited practicality. To address these challenges, we propose a novel real-time system EGG-Fusion, featuring robust sparse-to-dense camera tracking and a geometry-aware Gaussian surfel mapping module, introducing an information filter-based fusion method that explicitly accounts for sensor noise to achieve high-precision surface reconstruction. The proposed differentiable Gaussian surfel mapping effectively models multi-view consistent surfaces while enabling efficient parameter optimization. Extensive experimental results demonstrate that the proposed system achieves a surface reconstruction error of 0.6\\textit{cm} on standardized benchmark datasets including Replica and ScanNet++, representing over 20\\% improvement in accuracy compared to state-of-the-art (SOTA) GS-based methods. Notably, the system maintains real-time processing capabilities at 24 FPS, establishing it as one of the most accurate differentiable-rendering-based real-time reconstruction systems. Project Page: https://zju3dv.github.io/eggfusion/",
    "published": "2025-12-01T05:32:17Z",
    "updated": "2025-12-01T05:32:17Z",
    "link": "http://arxiv.org/pdf/2512.01296v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xiaokun Pan",
      "Zhenzhe Li",
      "Zhichao Ye",
      "Hongjia Zhai",
      "Guofeng Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01291v1",
    "title": "Supervised Contrastive Machine Unlearning of Background Bias in Sonar Image Classification with Fine-Grained Explainable AI",
    "summary": "Acoustic sonar image analysis plays a critical role in object detection and classification, with applications in both civilian and defense domains. Despite the availability of real and synthetic datasets, existing AI models that achieve high accuracy often over-rely on seafloor features, leading to poor generalization. To mitigate this issue, we propose a novel framework that integrates two key modules: (i) a Targeted Contrastive Unlearning (TCU) module, which extends the traditional triplet loss to reduce seafloor-induced background bias and improve generalization, and (ii) the Unlearn to Explain Sonar Framework (UESF), which provides visual insights into what the model has deliberately forgotten while adapting the LIME explainer to generate more faithful and localized attributions for unlearning evaluation. Extensive experiments across both real and synthetic sonar datasets validate our approach, demonstrating significant improvements in unlearning effectiveness, model robustness, and interpretability.",
    "published": "2025-12-01T05:25:34Z",
    "updated": "2025-12-01T05:25:34Z",
    "link": "http://arxiv.org/pdf/2512.01291v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Kamal Basha S",
      "Athira Nambiar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12547v4",
    "title": "HiGFA: Hierarchical Guidance for Fine-grained Data Augmentation with Diffusion Models",
    "summary": "Generative diffusion models show promise for data augmentation. However, applying them to fine-grained tasks presents a significant challenge: ensuring synthetic images accurately capture the subtle, category-defining features critical for high fidelity. Standard approaches, such as text-based Classifier-Free Guidance (CFG), often lack the required specificity, potentially generating misleading examples that degrade fine-grained classifier performance. To address this, we propose Hierarchically Guided Fine-grained Augmentation (HiGFA). HiGFA leverages the temporal dynamics of the diffusion sampling process. It employs strong text and transformed contour guidance with fixed strengths in the early-to-mid sampling stages to establish overall scene, style, and structure. In the final sampling stages, HiGFA activates a specialized fine-grained classifier guidance and dynamically modulates the strength of all guidance signals based on prediction confidence. This hierarchical, confidence-driven orchestration enables HiGFA to generate diverse yet faithful synthetic images by intelligently balancing global structure formation with precise detail refinement. Experiments on several FGVC datasets demonstrate the effectiveness of HiGFA.",
    "published": "2025-11-16T10:46:16Z",
    "updated": "2025-12-01T04:46:50Z",
    "link": "http://arxiv.org/pdf/2511.12547v4.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhiguang Lu",
      "Qianqian Xu",
      "Peisong Wen",
      "Siran Dai",
      "Qingming Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01273v1",
    "title": "nnMobileNet++: Towards Efficient Hybrid Networks for Retinal Image Analysis",
    "summary": "Retinal imaging is a critical, non-invasive modality for the early detection and monitoring of ocular and systemic diseases. Deep learning, particularly convolutional neural networks (CNNs), has significant progress in automated retinal analysis, supporting tasks such as fundus image classification, lesion detection, and vessel segmentation. As a representative lightweight network, nnMobileNet has demonstrated strong performance across multiple retinal benchmarks while remaining computationally efficient. However, purely convolutional architectures inherently struggle to capture long-range dependencies and model the irregular lesions and elongated vascular patterns that characterize on retinal images, despite the critical importance of vascular features for reliable clinical diagnosis. To further advance this line of work and extend the original vision of nnMobileNet, we propose nnMobileNet++, a hybrid architecture that progressively bridges convolutional and transformer representations. The framework integrates three key components: (i) dynamic snake convolution for boundary-aware feature extraction, (ii) stage-specific transformer blocks introduced after the second down-sampling stage for global context modeling, and (iii) retinal image pretraining to improve generalization. Experiments on multiple public retinal datasets for classification, together with ablation studies, demonstrate that nnMobileNet++ achieves state-of-the-art or highly competitive accuracy while maintaining low computational cost, underscoring its potential as a lightweight yet effective framework for retinal image analysis.",
    "published": "2025-12-01T04:45:39Z",
    "updated": "2025-12-01T04:45:39Z",
    "link": "http://arxiv.org/pdf/2512.01273v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xin Li",
      "Wenhui Zhu",
      "Xuanzhao Dong",
      "Hao Wang",
      "Yujian Xiong",
      "Oana Dumitrascu",
      "Yalin Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.10009v2",
    "title": "Robust Phase-Shifting Profilometry for Arbitrary Motion",
    "summary": "Phase-shifting profilometry (PSP) enables high-accuracy 3D reconstruction but remains highly susceptible to object motion. Although numerous studies have explored compensation for motion-induced errors, residual inaccuracies still persist, particularly in complex motion scenarios. In this paper, we propose a robust phase-shifting profilometry for arbitrary motion (RPSP-AM), including six-degrees-of-freedom (6-DoF) motion (translation and rotation in any direction), non-rigid deformations, and multi-target movements, achieving high-fidelity motion-error-free 3D reconstruction. We categorize motion errors into two components: 1) ghosting artifacts induced by image misalignment, and 2) ripple-like distortions induced by phase deviation. To eliminate the ghosting artifacts, we perform pixel-wise image alignment based on dense optical flow tracking. To correct ripple-like distortions, we propose a high-accuracy, low-complexity image-sequential binomial self-compensation (I-BSC) method, which performs a summation of the homogeneous fringe images weighted by binomial coefficients, exponentially reducing the ripple-like distortions with a competitive computational speed compared with the traditional four-step phase-shifting method. Extensive experimental results demonstrate that, under challenging conditions such as 6-DoF motion, non-rigid deformations, and multi-target movements, the proposed RPSP-AM outperforms state-of-the-art (SoTA) methods in compensating for both ghosting artifacts and ripple-like distortions. Our approach extends the applicability of PSP to arbitrary motion scenarios, endowing it with potential for widespread adoption in fields such as robotics, industrial inspection, and medical reconstruction.",
    "published": "2025-07-14T07:41:56Z",
    "updated": "2025-12-01T04:34:34Z",
    "link": "http://arxiv.org/pdf/2507.10009v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Geyou Zhang",
      "Kai Liu",
      "Ao Li",
      "Ce Zhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01268v1",
    "title": "ViscNet: Vision-Based In-line Viscometry for Fluid Mixing Process",
    "summary": "Viscosity measurement is essential for process monitoring and autonomous laboratory operation, yet conventional viscometers remain invasive and require controlled laboratory environments that differ substantially from real process conditions. We present a computer-vision-based viscometer that infers viscosity by exploiting how a fixed background pattern becomes optically distorted as light refracts through the mixing-driven, continuously deforming free surface. Under diverse lighting conditions, the system achieves a mean absolute error of 0.113 in log m2 s^-1 units for regression and reaches up to 81% accuracy in viscosity-class prediction. Although performance declines for classes with closely clustered viscosity values, a multi-pattern strategy improves robustness by providing enriched visual cues. To ensure sensor reliability, we incorporate uncertainty quantification, enabling viscosity predictions with confidence estimates. This stand-off viscometer offers a practical, automation-ready alternative to existing viscometry methods.",
    "published": "2025-12-01T04:21:33Z",
    "updated": "2025-12-01T04:21:33Z",
    "link": "http://arxiv.org/pdf/2512.01268v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jongwon Sohn",
      "Juhyeon Moon",
      "Hyunjoon Jung",
      "Jaewook Nam"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01252v1",
    "title": "Efficient Training of Diffusion Mixture-of-Experts Models: A Practical Recipe",
    "summary": "Recent efforts on Diffusion Mixture-of-Experts (MoE) models have primarily focused on developing more sophisticated routing mechanisms. However, we observe that the underlying architectural configuration space remains markedly under-explored. Inspired by the MoE design paradigms established in large language models (LLMs), we identify a set of crucial architectural factors for building effective Diffusion MoE models--including DeepSeek-style expert modules, alternative intermediate widths, varying expert counts, and enhanced attention positional encodings. Our systematic study reveals that carefully tuning these configurations is essential for unlocking the full potential of Diffusion MoE models, often yielding gains that exceed those achieved by routing innovations alone. Through extensive experiments, we present novel architectures that can be efficiently applied to both latent and pixel-space diffusion frameworks, which provide a practical and efficient training recipe that enables Diffusion MoE models to surpass strong baselines while using equal or fewer activated parameters. All code and models are publicly available at: https://github.com/yhlleo/EfficientMoE.",
    "published": "2025-12-01T03:52:31Z",
    "updated": "2025-12-01T03:52:31Z",
    "link": "http://arxiv.org/pdf/2512.01252v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Yahui Liu",
      "Yang Yue",
      "Jingyuan Zhang",
      "Chenxi Sun",
      "Yang Zhou",
      "Wencong Zeng",
      "Ruiming Tang",
      "Guorui Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01248v1",
    "title": "TRivia: Self-supervised Fine-tuning of Vision-Language Models for Table Recognition",
    "summary": "Table recognition (TR) aims to transform table images into semi-structured representations such as HTML or Markdown. As a core component of document parsing, TR has long relied on supervised learning, with recent efforts dominated by fine-tuning vision-language models (VLMs) using labeled data. While VLMs have brought TR to the next level, pushing performance further demands large-scale labeled data that is costly to obtain. Consequently, although proprietary models have continuously pushed the performance boundary, open-source models, often trained with limited resources and, in practice, the only viable option for many due to privacy regulations, still lag far behind. To bridge this gap, we introduce TRivia, a self-supervised fine-tuning method that enables pretrained VLMs to learn TR directly from unlabeled table images in the wild. Built upon Group Relative Policy Optimization, TRivia automatically identifies unlabeled samples that most effectively facilitate learning and eliminates the need for human annotations through a question-answering-based reward mechanism. An attention-guided module generates diverse questions for each table image, and the ability to interpret the recognition results and answer them correctly provides feedback to optimize the TR model. This closed-loop process allows the TR model to autonomously learn to recognize, structure, and reason over tables without labeled data. Leveraging this pipeline, we present TRivia-3B, an open-sourced, compact, and state-of-the-art TR model that surpasses existing systems (e.g., Gemini 2.5 Pro, MinerU2.5) on three popular benchmarks. Model and code are released at: https://github.com/opendatalab/TRivia",
    "published": "2025-12-01T03:49:00Z",
    "updated": "2025-12-01T03:49:00Z",
    "link": "http://arxiv.org/pdf/2512.01248v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Junyuan Zhang",
      "Bin Wang",
      "Qintong Zhang",
      "Fan Wu",
      "Zichen Wen",
      "Jialin Lu",
      "Junjie Shan",
      "Ziqi Zhao",
      "Shuya Yang",
      "Ziling Wang",
      "Ziyang Miao",
      "Huaping Zhong",
      "Yuhang Zang",
      "Xiaoyi Dong",
      "Ka-Ho Chow",
      "Conghui He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2407.04231v2",
    "title": "Efficient Generative Adversarial Networks for Color Document Image Enhancement and Binarization Using Multi-scale Feature Extraction",
    "summary": "The outcome of text recognition for degraded color documents is often unsatisfactory due to interference from various contaminants. To extract information more efficiently for text recognition, document image enhancement and binarization are often employed as preliminary steps in document analysis. Training independent generative adversarial networks (GANs) for each color channel can generate images where shadows and noise are effectively removed, which subsequently allows for efficient text information extraction. However, employing multiple GANs for different color channels requires long training and inference times. To reduce both the training and inference times of these preliminary steps, we propose an efficient method based on multi-scale feature extraction, which incorporates Haar wavelet transformation and normalization to process document images before submitting them to GANs for training. Experiment results show that our proposed method significantly reduces both the training and inference times while maintaining comparable performances when benchmarked against the state-of-the-art methods. In the best case scenario, a reduction of 10% and 26% are observed for training and inference times, respectively, while maintaining the model performance at 73.79 of Average-Score metric. The implementation of this work is available at https://github.com/RuiyangJu/Efficient_Document_Image_Binarization.",
    "published": "2024-07-05T03:19:32Z",
    "updated": "2025-12-01T03:36:39Z",
    "link": "http://arxiv.org/pdf/2407.04231v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Rui-Yang Ju",
      "KokSheik Wong",
      "Jen-Shiun Chiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.10799v2",
    "title": "GFT: Graph Feature Tuning for Efficient Point Cloud Analysis",
    "summary": "Parameter-efficient fine-tuning (PEFT) significantly reduces computational and memory costs by updating only a small subset of the model's parameters, enabling faster adaptation to new tasks with minimal loss in performance. Previous studies have introduced PEFTs tailored for point cloud data, as general approaches are suboptimal. To further reduce the number of trainable parameters, we propose a point-cloud-specific PEFT, termed Graph Features Tuning (GFT), which learns a dynamic graph from initial tokenized inputs of the transformer using a lightweight graph convolution network and passes these graph features to deeper layers via skip connections and efficient cross-attention modules. Extensive experiments on object classification and segmentation tasks show that GFT operates in the same domain, rivalling existing methods, while reducing the trainable parameters. Code is available at https://github.com/manishdhakal/GFT.",
    "published": "2025-11-13T20:57:55Z",
    "updated": "2025-12-01T03:31:14Z",
    "link": "http://arxiv.org/pdf/2511.10799v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Manish Dhakal",
      "Venkat R. Dasari",
      "Rajshekhar Sunderraman",
      "Yi Ding"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.22940v2",
    "title": "One-to-All Animation: Alignment-Free Character Animation and Image Pose Transfer",
    "summary": "Recent advances in diffusion models have greatly improved pose-driven character animation. However, existing methods are limited to spatially aligned reference-pose pairs with matched skeletal structures. Handling reference-pose misalignment remains unsolved. To address this, we present One-to-All Animation, a unified framework for high-fidelity character animation and image pose transfer for references with arbitrary layouts. First, to handle spatially misaligned reference, we reformulate training as a self-supervised outpainting task that transforms diverse-layout reference into a unified occluded-input format. Second, to process partially visible reference, we design a reference extractor for comprehensive identity feature extraction. Further, we integrate hybrid reference fusion attention to handle varying resolutions and dynamic sequence lengths. Finally, from the perspective of generation quality, we introduce identity-robust pose control that decouples appearance from skeletal structure to mitigate pose overfitting, and a token replace strategy for coherent long-video generation. Extensive experiments show that our method outperforms existing approaches. The code and model are available at https://github.com/ssj9596/One-to-All-Animation.",
    "published": "2025-11-28T07:30:10Z",
    "updated": "2025-12-01T03:26:33Z",
    "link": "http://arxiv.org/pdf/2511.22940v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Shijun Shi",
      "Jing Xu",
      "Zhihang Li",
      "Chunli Peng",
      "Xiaoda Yang",
      "Lijing Lu",
      "Kai Hu",
      "Jiangning Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01236v1",
    "title": "PSR: Scaling Multi-Subject Personalized Image Generation with Pairwise Subject-Consistency Rewards",
    "summary": "Personalized generation models for a single subject have demonstrated remarkable effectiveness, highlighting their significant potential. However, when extended to multiple subjects, existing models often exhibit degraded performance, particularly in maintaining subject consistency and adhering to textual prompts. We attribute these limitations to the absence of high-quality multi-subject datasets and refined post-training strategies. To address these challenges, we propose a scalable multi-subject data generation pipeline that leverages powerful single-subject generation models to construct diverse and high-quality multi-subject training data. Through this dataset, we first enable single-subject personalization models to acquire knowledge of synthesizing multi-image and multi-subject scenarios. Furthermore, to enhance both subject consistency and text controllability, we design a set of Pairwise Subject-Consistency Rewards and general-purpose rewards, which are incorporated into a refined reinforcement learning stage. To comprehensively evaluate multi-subject personalization, we introduce a new benchmark that assesses model performance using seven subsets across three dimensions. Extensive experiments demonstrate the effectiveness of our approach in advancing multi-subject personalized image generation. Github Link: https://github.com/wang-shulei/PSR",
    "published": "2025-12-01T03:25:49Z",
    "updated": "2025-12-01T03:25:49Z",
    "link": "http://arxiv.org/pdf/2512.01236v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Shulei Wang",
      "Longhui Wei",
      "Xin He",
      "Jianbo Ouyang",
      "Hui Lu",
      "Zhou Zhao",
      "Qi Tian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.20285v2",
    "title": "DMC$^3$: Dual-Modal Counterfactual Contrastive Construction for Egocentric Video Question Answering",
    "summary": "Egocentric Video Question Answering (Egocentric VideoQA) plays an important role in egocentric video understanding, which refers to answering questions based on first-person videos. Although existing methods have made progress through the paradigm of pre-training and fine-tuning, they ignore the unique challenges posed by the first-person perspective, such as understanding multiple events and recognizing hand-object interactions. To deal with these challenges, we propose a Dual-Modal Counterfactual Contrastive Construction (DMC$^3$) framework, which contains an egocentric videoqa baseline, a counterfactual sample construction module and a counterfactual sample-involved contrastive optimization. Specifically, We first develop a counterfactual sample construction module to generate positive and negative samples for textual and visual modalities through event description paraphrasing and core interaction mining, respectively. Then, We feed these samples together with the original samples into the baseline. Finally, in the counterfactual sample-involved contrastive optimization module, we apply contrastive loss to minimize the distance between the original sample features and the positive sample features, while maximizing the distance from the negative samples. Experiments show that our method achieve 52.51\\% and 46.04\\% on the \\textit{normal} and \\textit{indirect} splits of EgoTaskQA, and 13.2\\% on QAEGO4D, both reaching the state-of-the-art performance.",
    "published": "2025-10-23T07:15:18Z",
    "updated": "2025-12-01T03:20:30Z",
    "link": "http://arxiv.org/pdf/2510.20285v2.pdf",
    "category": [
      "cs.CV",
      "cs.MM"
    ],
    "authors": [
      "Jiayi Zou",
      "Chaofan Chen",
      "Bing-Kun Bao",
      "Changsheng Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.07756v2",
    "title": "Beyond Randomness: Understand the Order of the Noise in Diffusion",
    "summary": "In text-driven content generation (T2C) diffusion model, semantic of generated content is mostly attributed to the process of text embedding and attention mechanism interaction. The initial noise of the generation process is typically characterized as a random element that contributes to the diversity of the generated content. Contrary to this view, this paper reveals that beneath the random surface of noise lies strong analyzable patterns. Specifically, this paper first conducts a comprehensive analysis of the impact of random noise on the model's generation. We found that noise not only contains rich semantic information, but also allows for the erasure of unwanted semantics from it in an extremely simple way based on information theory, and using the equivalence between the generation process of diffusion model and semantic injection to inject semantics into the cleaned noise. Then, we mathematically decipher these observations and propose a simple but efficient training-free and universal two-step \"Semantic Erasure-Injection\" process to modulate the initial noise in T2C diffusion model. Experimental results demonstrate that our method is consistently effective across various T2C models based on both DiT and UNet architectures and presents a novel perspective for optimizing the generation of diffusion model, providing a universal tool for consistent generation.",
    "published": "2025-11-11T02:12:38Z",
    "updated": "2025-12-01T03:01:47Z",
    "link": "http://arxiv.org/pdf/2511.07756v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Song Yan",
      "Min Li",
      "Bi Xinliang",
      "Jian Yang",
      "Yusen Zhang",
      "Guanye Xiong",
      "Yunwei Lan",
      "Tao Zhang",
      "Wei Zhai",
      "Zheng-Jun Zha"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.22052v2",
    "title": "TPCNet: Triple physical constraints for Low-light Image Enhancement",
    "summary": "Low-light image enhancement is an essential computer vision task to improve image contrast and to decrease the effects of color bias and noise. Many existing interpretable deep-learning algorithms exploit the Retinex theory as the basis of model design. However, previous Retinex-based algorithms, that consider reflected objects as ideal Lambertian ignore specular reflection in the modeling process and construct the physical constraints in image space, limiting generalization of the model. To address this issue, we preserve the specular reflection coefficient and reformulate the original physical constraints in the imaging process based on the Kubelka-Munk theory, thereby constructing constraint relationship between illumination, reflection, and detection, the so-called triple physical constraints (TPCs)theory. Based on this theory, the physical constraints are constructed in the feature space of the model to obtain the TPC network (TPCNet). Comprehensive quantitative and qualitative benchmark and ablation experiments confirm that these constraints effectively improve the performance metrics and visual quality without introducing new parameters, and demonstrate that our TPCNet outperforms other state-of-the-art methods on 10 datasets.",
    "published": "2025-11-27T03:11:14Z",
    "updated": "2025-12-01T03:00:17Z",
    "link": "http://arxiv.org/pdf/2511.22052v2.pdf",
    "category": [
      "cs.CV",
      "physics.optics"
    ],
    "authors": [
      "Jing-Yi Shi",
      "Ming-Fei Li",
      "Ling-An Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01213v1",
    "title": "Closing the Approximation Gap of Partial AUC Optimization: A Tale of Two Formulations",
    "summary": "As a variant of the Area Under the ROC Curve (AUC), the partial AUC (PAUC) focuses on a specific range of false positive rate (FPR) and/or true positive rate (TPR) in the ROC curve. It is a pivotal evaluation metric in real-world scenarios with both class imbalance and decision constraints. However, selecting instances within these constrained intervals during its calculation is NP-hard, and thus typically requires approximation techniques for practical resolution. Despite the progress made in PAUC optimization over the last few years, most existing methods still suffer from uncontrollable approximation errors or a limited scalability when optimizing the approximate PAUC objectives. In this paper, we close the approximation gap of PAUC optimization by presenting two simple instance-wise minimax reformulations: one with an asymptotically vanishing gap, the other with the unbiasedness at the cost of more variables. Our key idea is to first establish an equivalent instance-wise problem to lower the time complexity, simplify the complicated sample selection procedure by threshold learning, and then apply different smoothing techniques. Equipped with an efficient solver, the resulting algorithms enjoy a linear per-iteration computational complexity w.r.t. the sample size and a convergence rate of $O(ε^{-1/3})$ for typical one-way and two-way PAUCs. Moreover, we provide a tight generalization bound of our minimax reformulations. The result explicitly demonstrates the impact of the TPR/FPR constraints $α$/$β$ on the generalization and exhibits a sharp order of $\\tilde{O}(α^{-1}\\n_+^{-1} + β^{-1}\\n_-^{-1})$. Finally, extensive experiments on several benchmark datasets validate the strength of our proposed methods.",
    "published": "2025-12-01T02:52:33Z",
    "updated": "2025-12-01T02:52:33Z",
    "link": "http://arxiv.org/pdf/2512.01213v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Yangbangyan Jiang",
      "Qianqian Xu",
      "Huiyang Shao",
      "Zhiyong Yang",
      "Shilong Bao",
      "Xiaochun Cao",
      "Qingming Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.17515v4",
    "title": "SuperMat: Physically Consistent PBR Material Estimation at Interactive Rates",
    "summary": "Decomposing physically-based materials from images into their constituent properties remains challenging, particularly when maintaining both computational efficiency and physical consistency. While recent diffusion-based approaches have shown promise, they face substantial computational overhead due to multiple denoising steps and separate models for different material properties. We present SuperMat, a single-step framework that achieves high-quality material decomposition with one-step inference. This enables end-to-end training with perceptual and re-render losses while decomposing albedo, metallic, and roughness maps at millisecond-scale speeds. We further extend our framework to 3D objects through a UV refinement network, enabling consistent material estimation across viewpoints while maintaining efficiency. Experiments demonstrate that SuperMat achieves state-of-the-art PBR material decomposition quality while reducing inference time from seconds to milliseconds per image, and completes PBR material estimation for 3D objects in approximately 3 seconds. The project page is at https://hyj542682306.github.io/SuperMat/.",
    "published": "2024-11-26T15:26:06Z",
    "updated": "2025-12-01T02:50:53Z",
    "link": "http://arxiv.org/pdf/2411.17515v4.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yijia Hong",
      "Yuan-Chen Guo",
      "Ran Yi",
      "Yulong Chen",
      "Yan-Pei Cao",
      "Lizhuang Ma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01204v1",
    "title": "TabletopGen: Instance-Level Interactive 3D Tabletop Scene Generation from Text or Single Image",
    "summary": "Generating high-fidelity, physically interactive 3D simulated tabletop scenes is essential for embodied AI--especially for robotic manipulation policy learning and data synthesis. However, current text- or image-driven 3D scene generation methods mainly focus on large-scale scenes, struggling to capture the high-density layouts and complex spatial relations that characterize tabletop scenes. To address these challenges, we propose TabletopGen, a training-free, fully automatic framework that generates diverse, instance-level interactive 3D tabletop scenes. TabletopGen accepts a reference image as input, which can be synthesized by a text-to-image model to enhance scene diversity. We then perform instance segmentation and completion on the reference to obtain per-instance images. Each instance is reconstructed into a 3D model followed by canonical coordinate alignment. The aligned 3D models then undergo pose and scale estimation before being assembled into a collision-free, simulation-ready tabletop scene. A key component of our framework is a novel pose and scale alignment approach that decouples the complex spatial reasoning into two stages: a Differentiable Rotation Optimizer for precise rotation recovery and a Top-view Spatial Alignment mechanism for robust translation and scale estimation, enabling accurate 3D reconstruction from 2D reference. Extensive experiments and user studies show that TabletopGen achieves state-of-the-art performance, markedly surpassing existing methods in visual fidelity, layout accuracy, and physical plausibility, capable of generating realistic tabletop scenes with rich stylistic and spatial diversity. Our code will be publicly available.",
    "published": "2025-12-01T02:38:52Z",
    "updated": "2025-12-01T02:38:52Z",
    "link": "http://arxiv.org/pdf/2512.01204v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ziqian Wang",
      "Yonghao He",
      "Licheng Yang",
      "Wei Zou",
      "Hongxuan Ma",
      "Liu Liu",
      "Wei Sui",
      "Yuxin Guo",
      "Hu Su"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23594v4",
    "title": "PRISM-Bench: A Benchmark of Puzzle-Based Visual Tasks with CoT Error Detection",
    "summary": "Multimodal large language models (MLLMs) have achieved remarkable progress on vision-language tasks, yet their reasoning processes remain sometimes unreliable. We introduce PRISM-Bench, a benchmark of puzzle-based visual challenges designed to evaluate not only whether models can solve problems, but how their reasoning unfolds. Unlike prior evaluations that measure only final-answer accuracy, PRISM-Bench introduces a diagnostic task: given a visual puzzle and a step-by-step chain-of-thought (CoT) containing exactly one error, models must identify the first incorrect step. This setting enables fine-grained assessment of logical consistency, error detection, and visual reasoning. The puzzles in PRISM-Bench require multi-step symbolic, geometric, and analogical reasoning, resisting shortcuts based on superficial pattern matching. Evaluations across state-of-the-art MLLMs reveal a persistent gap between fluent generation and faithful reasoning: models that produce plausible CoTs often fail to locate simple logical faults. By disentangling answer generation from reasoning verification, PRISM-Bench offers a sharper lens on multimodal reasoning competence and underscores the need for diagnostic evaluation protocols in the development of trustworthy MLLMs.",
    "published": "2025-10-27T17:57:52Z",
    "updated": "2025-12-01T02:32:50Z",
    "link": "http://arxiv.org/pdf/2510.23594v4.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yusu Qian",
      "Cheng Wan",
      "Chao Jia",
      "Yinfei Yang",
      "Qingyu Zhao",
      "Zhe Gan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19899v2",
    "title": "VeriSciQA: An Auto-Verified Dataset for Scientific Visual Question Answering",
    "summary": "Large Vision-Language Models (LVLMs) show promise for scientific applications, yet open-source models still struggle with Scientific Visual Question Answering (SVQA), namely answering questions about figures from scientific papers. A key bottleneck lies in the lack of public, large-scale, high-quality SVQA datasets. Although recent work uses LVLMs to synthesize data at scale, we identify systematic errors in their resulting QA pairs, stemming from LVLMs' inherent limitations and information asymmetry between figures and text. To address these challenges, we propose a verification-centric Generate-then-Verify framework that first generates QA pairs with figure-associated textual context, then applies cross-modal consistency checks against figures along with auxiliary filters to eliminate erroneous pairs. We instantiate this framework to curate VeriSciQA, a dataset of 20,351 QA pairs spanning 20 scientific domains and 12 figure types. VeriSciQA poses a challenging benchmark for open-source models, with a substantial accuracy gap between the leading open-source models (64%) and a proprietary model (82%). Moreover, models fine-tuned on VeriSciQA achieve consistent improvements on SVQA benchmarks, with performance gains that scale with data size and surpass models trained on existing datasets. Human evaluation further validates the superior correctness of VeriSciQA. Together, these evidences demonstrate that continued data expansion by our scalable framework can further advance SVQA capability in the open-source community.",
    "published": "2025-11-25T04:14:52Z",
    "updated": "2025-12-01T02:17:45Z",
    "link": "http://arxiv.org/pdf/2511.19899v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yuyi Li",
      "Daoyuan Chen",
      "Zhen Wang",
      "Yutong Lu",
      "Yaliang Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.23886v2",
    "title": "Generating Fit Check Videos with a Handheld Camera",
    "summary": "Self-captured full-body videos are popular, but most deployments require mounted cameras, carefully-framed shots, and repeated practice. We propose a more convenient solution that enables full-body video capture using handheld mobile devices. Our approach takes as input two static photos (front and back) of you in a mirror, along with an IMU motion reference that you perform while holding your mobile phone, and synthesizes a realistic video of you performing a similar target motion. We enable rendering into a new scene, with consistent illumination and shadows. We propose a novel video diffusion-based model to achieve this. Specifically, we propose a parameter-free frame generation strategy and a multi-reference attention mechanism to effectively integrate appearance information from both the front and back selfies into the video diffusion model. Further, we introduce an image-based fine-tuning strategy to enhance frame sharpness and improve shadows and reflections generation for more realistic human-scene composition.",
    "published": "2025-05-29T17:58:49Z",
    "updated": "2025-12-01T02:00:39Z",
    "link": "http://arxiv.org/pdf/2505.23886v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Bowei Chen",
      "Brian Curless",
      "Ira Kemelmacher-Shlizerman",
      "Steven M. Seitz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.18921v3",
    "title": "Full-scale Representation Guided Network for Retinal Vessel Segmentation",
    "summary": "The U-Net architecture and its variants have remained state-of-the-art (SOTA) for retinal vessel segmentation over the past decade. In this study, we introduce a Full-Scale Guided Network (FSG-Net), where a novel feature representation module using modernized convolution blocks effectively captures full-scale structural information, while a guided convolution block subsequently refines this information. Specifically, we introduce an attention-guided filter within the guided convolution block, leveraging its similarity to unsharp masking to enhance fine vascular structures. Passing full-scale information to the attention block facilitates the generation of more contextually relevant attention maps, which are then passed to the attention-guided filter, providing further refinement to the segmentation performance. The structure preceding the guided convolution block can be replaced by any U-Net variant, ensuring flexibility and scalability across various segmentation tasks. For a fair comparison, we re-implemented recent studies available in public repositories to evaluate their scalability and reproducibility. Our experiments demonstrate that, despite its compact architecture, FSG-Net delivers performance competitive with SOTA methods across multiple public datasets. Ablation studies further demonstrate that each proposed component meaningfully contributes to this competitive performance. Our code is available on https://github.com/ZombaSY/FSG-Net-pytorch.",
    "published": "2025-01-31T06:52:57Z",
    "updated": "2025-12-01T01:39:02Z",
    "link": "http://arxiv.org/pdf/2501.18921v3.pdf",
    "category": [
      "eess.IV",
      "cs.CV"
    ],
    "authors": [
      "Sunyong Seo",
      "Sangwook Yoo",
      "Huisu Yoon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01178v1",
    "title": "VSRD++: Autolabeling for 3D Object Detection via Instance-Aware Volumetric Silhouette Rendering",
    "summary": "Monocular 3D object detection is a fundamental yet challenging task in 3D scene understanding. Existing approaches heavily depend on supervised learning with extensive 3D annotations, which are often acquired from LiDAR point clouds through labor-intensive labeling processes. To tackle this problem, we propose VSRD++, a novel weakly supervised framework for monocular 3D object detection that eliminates the reliance on 3D annotations and leverages neural-field-based volumetric rendering with weak 2D supervision. VSRD++ consists of a two-stage pipeline: multi-view 3D autolabeling and subsequent monocular 3D detector training. In the multi-view autolabeling stage, object surfaces are represented as signed distance fields (SDFs) and rendered as instance masks via the proposed instance-aware volumetric silhouette rendering. To optimize 3D bounding boxes, we decompose each instance's SDF into a cuboid SDF and a residual distance field (RDF) that captures deviations from the cuboid. To address the geometry inconsistency commonly observed in volume rendering methods applied to dynamic objects, we model the dynamic objects by including velocity into bounding box attributes as well as assigning confidence to each pseudo-label. Moreover, we also employ a 3D attribute initialization module to initialize the dynamic bounding box parameters. In the monocular 3D object detection phase, the optimized 3D bounding boxes serve as pseudo labels for training monocular 3D object detectors. Extensive experiments on the KITTI-360 dataset demonstrate that VSRD++ significantly outperforms existing weakly supervised approaches for monocular 3D object detection on both static and dynamic scenes. Code is available at https://github.com/Magicboomliu/VSRD_plus_plus",
    "published": "2025-12-01T01:28:35Z",
    "updated": "2025-12-01T01:28:35Z",
    "link": "http://arxiv.org/pdf/2512.01178v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zihua Liu",
      "Hiroki Sakuma",
      "Masatoshi Okutomi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.01944v2",
    "title": "AutoDrive-R$^2$: Incentivizing Reasoning and Self-Reflection Capacity for VLA Model in Autonomous Driving",
    "summary": "Vision-Language-Action (VLA) models in autonomous driving systems have recently demonstrated transformative potential by integrating multimodal perception with decision-making capabilities. However, the interpretability and coherence of the decision process and the plausibility of action sequences remain largely underexplored. To address these issues, we propose AutoDrive-R$^2$, a novel VLA framework that enhances both reasoning and self-reflection capabilities of autonomous driving systems through chain-of-thought (CoT) processing and reinforcement learning (RL). Specifically, we first propose an innovative CoT dataset named nuScenesR$^2$-6K for supervised fine-tuning, which effectively builds cognitive bridges between input information and output trajectories through a four-step logical chain with self-reflection for validation. Moreover, to maximize both reasoning and self-reflection during the RL stage, we further employ the Group Relative Policy Optimization (GRPO) algorithm within a physics-grounded reward framework that incorporates spatial alignment, vehicle dynamic, and temporal smoothness criteria to ensure reliable and realistic trajectory planning. Extensive evaluation results across both nuScenes and Waymo datasets demonstrates the state-of-the-art performance and robust generalization capacity of our proposed method.",
    "published": "2025-09-02T04:32:24Z",
    "updated": "2025-12-01T01:21:07Z",
    "link": "http://arxiv.org/pdf/2509.01944v2.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Zhenlong Yuan",
      "Chengxuan Qian",
      "Jing Tang",
      "Rui Chen",
      "Zijian Song",
      "Lei Sun",
      "Xiangxiang Chu",
      "Yujun Cai",
      "Dapeng Zhang",
      "Shuo Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.06244v2",
    "title": "Physics-Informed Image Restoration via Progressive PDE Integration",
    "summary": "Motion blur, caused by relative movement between camera and scene during exposure, significantly degrades image quality and impairs downstream computer vision tasks such as object detection, tracking, and recognition in dynamic environments. While deep learning-based motion deblurring methods have achieved remarkable progress, existing approaches face fundamental challenges in capturing the long-range spatial dependencies inherent in motion blur patterns. Traditional convolutional methods rely on limited receptive fields and require extremely deep networks to model global spatial relationships. These limitations motivate the need for alternative approaches that incorporate physical priors to guide feature evolution during restoration. In this paper, we propose a progressive training framework that integrates physics-informed PDE dynamics into state-of-the-art restoration architectures. By leveraging advection-diffusion equations to model feature evolution, our approach naturally captures the directional flow characteristics of motion blur while enabling principled global spatial modeling. Our PDE-enhanced deblurring models achieve superior restoration quality with minimal overhead, adding only approximately 1\\% to inference GMACs while providing consistent improvements in perceptual quality across multiple state-of-the-art architectures. Comprehensive experiments on standard motion deblurring benchmarks demonstrate that our physics-informed approach improves PSNR and SSIM significantly across four diverse architectures, including FFTformer, NAFNet, Restormer, and Stripformer. These results validate that incorporating mathematical physics principles through PDE-based global layers can enhance deep learning-based image restoration, establishing a promising direction for physics-informed neural network design in computer vision applications.",
    "published": "2025-11-09T06:10:20Z",
    "updated": "2025-12-01T00:41:50Z",
    "link": "http://arxiv.org/pdf/2511.06244v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Shamika Likhite",
      "Santiago López-Tapia",
      "Aggelos K. Katsaggelos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01145v1",
    "title": "Weakly Supervised Continuous Micro-Expression Intensity Estimation Using Temporal Deep Neural Network",
    "summary": "Micro-facial expressions are brief and involuntary facial movements that reflect genuine emotional states. While most prior work focuses on classifying discrete micro-expression categories, far fewer studies address the continuous evolution of intensity over time. Progress in this direction is limited by the lack of frame-level intensity labels, which makes fully supervised regression impractical.\n  We propose a unified framework for continuous micro-expression intensity estimation using only weak temporal labels (onset, apex, offset). A simple triangular prior converts sparse temporal landmarks into dense pseudo-intensity trajectories, and a lightweight temporal regression model that combines a ResNet18 encoder with a bidirectional GRU predicts frame-wise intensity directly from image sequences. The method requires no frame-level annotation effort and is applied consistently across datasets through a single preprocessing and temporal alignment pipeline.\n  Experiments on SAMM and CASME II show strong temporal agreement with the pseudo-intensity trajectories. On SAMM, the model reaches a Spearman correlation of 0.9014 and a Kendall correlation of 0.7999, outperforming a frame-wise baseline. On CASME II, it achieves up to 0.9116 and 0.8168, respectively, when trained without the apex-ranking term. Ablation studies confirm that temporal modeling and structured pseudo labels are central to capturing the rise-apex-fall dynamics of micro-facial movements.\n  To our knowledge, this is the first unified approach for continuous micro-expression intensity estimation using only sparse temporal annotations.",
    "published": "2025-11-30T23:47:47Z",
    "updated": "2025-11-30T23:47:47Z",
    "link": "http://arxiv.org/pdf/2512.01145v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Riyadh Mohammed Almushrafy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.21526v2",
    "title": "TRiCo: Triadic Game-Theoretic Co-Training for Robust Semi-Supervised Learning",
    "summary": "We introduce TRiCo, a novel triadic game-theoretic co-training framework that rethinks the structure of semi-supervised learning by incorporating a teacher, two students, and an adversarial generator into a unified training paradigm. Unlike existing co-training or teacher-student approaches, TRiCo formulates SSL as a structured interaction among three roles: (i) two student classifiers trained on frozen, complementary representations, (ii) a meta-learned teacher that adaptively regulates pseudo-label selection and loss balancing via validation-based feedback, and (iii) a non-parametric generator that perturbs embeddings to uncover decision boundary weaknesses. Pseudo-labels are selected based on mutual information rather than confidence, providing a more robust measure of epistemic uncertainty. This triadic interaction is formalized as a Stackelberg game, where the teacher leads strategy optimization and students follow under adversarial perturbations. By addressing key limitations in existing SSL frameworks, such as static view interactions, unreliable pseudo-labels, and lack of hard sample modeling, TRiCo provides a principled and generalizable solution. Extensive experiments on CIFAR-10, SVHN, STL-10, and ImageNet demonstrate that TRiCo consistently achieves state-of-the-art performance in low-label regimes, while remaining architecture-agnostic and compatible with frozen vision backbones.Code:https://github.com/HoHongYeung/NeurIPS25-TRiCo.",
    "published": "2025-09-25T20:10:41Z",
    "updated": "2025-11-30T23:37:23Z",
    "link": "http://arxiv.org/pdf/2509.21526v2.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Hongyang He",
      "Xinyuan Song",
      "Yangfan He",
      "Zeyu Zhang",
      "Yanshu Li",
      "Haochen You",
      "Lifan Sun",
      "Wenqiao Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01128v1",
    "title": "OmniFD: A Unified Model for Versatile Face Forgery Detection",
    "summary": "Face forgery detection encompasses multiple critical tasks, including identifying forged images and videos and localizing manipulated regions and temporal segments. Current approaches typically employ task-specific models with independent architectures, leading to computational redundancy and ignoring potential correlations across related tasks. We introduce OmniFD, a unified framework that jointly addresses four core face forgery detection tasks within a single model, i.e., image and video classification, spatial localization, and temporal localization. Our architecture consists of three principal components: (1) a shared Swin Transformer encoder that extracts unified 4D spatiotemporal representations from both images and video inputs, (2) a cross-task interaction module with learnable queries that dynamically captures inter-task dependencies through attention-based reasoning, and (3) lightweight decoding heads that transform refined representations into corresponding predictions for all FFD tasks. Extensive experiments demonstrate OmniFD's advantage over task-specific models. Its unified design leverages multi-task learning to capture generalized representations across tasks, especially enabling fine-grained knowledge transfer that facilitates other tasks. For example, video classification accuracy improves by 4.63% when image data are incorporated. Furthermore, by unifying images, videos and the four tasks within one framework, OmniFD achieves superior performance across diverse benchmarks with high efficiency and scalability, e.g., reducing 63% model parameters and 50% training time. It establishes a practical and generalizable solution for comprehensive face forgery detection in real-world applications. The source code is made available at https://github.com/haotianll/OmniFD.",
    "published": "2025-11-30T22:36:42Z",
    "updated": "2025-11-30T22:36:42Z",
    "link": "http://arxiv.org/pdf/2512.01128v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Haotian Liu",
      "Haoyu Chen",
      "Chenhui Pan",
      "You Hu",
      "Guoying Zhao",
      "Xiaobai Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2408.14672v7",
    "title": "Optimizing against Infeasible Inclusions from Data for Semantic Segmentation through Morphology",
    "summary": "State-of-the-art semantic segmentation models are typically optimized in a data-driven fashion, minimizing solely per-pixel or per-segment classification objectives on their training data. This purely data-driven paradigm often leads to absurd segmentations, especially when the domain of input images is shifted from the one encountered during training. For instance, state-of-the-art models may assign the label \"road\" to a segment that is included by another segment that is respectively labeled as \"sky\". However, the ground truth of the existing dataset at hand dictates that such inclusion is not feasible. Our method, Infeasible Semantic Inclusions (InSeIn), first extracts explicit inclusion constraints that govern spatial class relations from the semantic segmentation training set at hand in an offline, data-driven fashion, and then enforces a morphological yet differentiable loss that penalizes violations of these constraints during training to promote prediction feasibility. InSeIn is a light-weight plug-and-play method, constitutes a novel step towards minimizing infeasible semantic inclusions in the predictions of learned segmentation models, and yields consistent and significant performance improvements over diverse state-of-the-art networks across the ADE20K, Cityscapes, and ACDC datasets. https://github.com/SHAMIK-97/InSeIn",
    "published": "2024-08-26T22:39:08Z",
    "updated": "2025-11-30T22:34:19Z",
    "link": "http://arxiv.org/pdf/2408.14672v7.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Shamik Basu",
      "Luc Van Gool",
      "Christos Sakaridis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01116v1",
    "title": "Structural Prognostic Event Modeling for Multimodal Cancer Survival Analysis",
    "summary": "The integration of histology images and gene profiles has shown great promise for improving survival prediction in cancer. However, current approaches often struggle to model intra- and inter-modal interactions efficiently and effectively due to the high dimensionality and complexity of the inputs. A major challenge is capturing critical prognostic events that, though few, underlie the complexity of the observed inputs and largely determine patient outcomes. These events, manifested as high-level structural signals such as spatial histologic patterns or pathway co-activations, are typically sparse, patient-specific, and unannotated, making them inherently difficult to uncover. To address this, we propose SlotSPE, a slot-based framework for structural prognostic event modeling. Specifically, inspired by the principle of factorial coding, we compress each patient's multimodal inputs into compact, modality-specific sets of mutually distinctive slots using slot attention. By leveraging these slot representations as encodings for prognostic events, our framework enables both efficient and effective modeling of complex intra- and inter-modal interactions, while also facilitating seamless incorporation of biological priors that enhance prognostic relevance. Extensive experiments on ten cancer benchmarks show that SlotSPE outperforms existing methods in 8 out of 10 cohorts, achieving an overall improvement of 2.9%. It remains robust under missing genomic data and delivers markedly improved interpretability through structured event decomposition.",
    "published": "2025-11-30T22:24:09Z",
    "updated": "2025-11-30T22:24:09Z",
    "link": "http://arxiv.org/pdf/2512.01116v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yilan Zhang",
      "Li Nanbo",
      "Changchun Yang",
      "Jürgen Schmidhuber",
      "Xin Gao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01104v1",
    "title": "Estimation of Kinematic Motion from Dashcam Footage",
    "summary": "The goal of this paper is to explore the accuracy of dashcam footage to predict the actual kinematic motion of a car-like vehicle. Our approach uses ground truth information from the vehicle's on-board data stream, through the controller area network, and a time-synchronized dashboard camera, mounted to a consumer-grade vehicle, for 18 hours of footage and driving. The contributions of the paper include neural network models that allow us to quantify the accuracy of predicting the vehicle speed and yaw, as well as the presence of a lead vehicle, and its relative distance and speed. In addition, the paper describes how other researchers can gather their own data to perform similar experiments, using open-source tools and off-the-shelf technology.",
    "published": "2025-11-30T22:07:40Z",
    "updated": "2025-11-30T22:07:40Z",
    "link": "http://arxiv.org/pdf/2512.01104v1.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Evelyn Zhang",
      "Alex Richardson",
      "Jonathan Sprinkle"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01103v1",
    "title": "Learning Eigenstructures of Unstructured Data Manifolds",
    "summary": "We introduce a novel framework that directly learns a spectral basis for shape and manifold analysis from unstructured data, eliminating the need for traditional operator selection, discretization, and eigensolvers. Grounded in optimal-approximation theory, we train a network to decompose an implicit approximation operator by minimizing the reconstruction error in the learned basis over a chosen distribution of probe functions. For suitable distributions, they can be seen as an approximation of the Laplacian operator and its eigendecomposition, which are fundamental in geometry processing. Furthermore, our method recovers in a unified manner not only the spectral basis, but also the implicit metric's sampling density and the eigenvalues of the underlying operator. Notably, our unsupervised method makes no assumption on the data manifold, such as meshing or manifold dimensionality, allowing it to scale to arbitrary datasets of any dimension. On point clouds lying on surfaces in 3D and high-dimensional image manifolds, our approach yields meaningful spectral bases, that can resemble those of the Laplacian, without explicit construction of an operator. By replacing the traditional operator selection, construction, and eigendecomposition with a learning-based approach, our framework offers a principled, data-driven alternative to conventional pipelines. This opens new possibilities in geometry processing for unstructured data, particularly in high-dimensional spaces.",
    "published": "2025-11-30T22:06:49Z",
    "updated": "2025-11-30T22:06:49Z",
    "link": "http://arxiv.org/pdf/2512.01103v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Roy Velich",
      "Arkadi Piven",
      "David Bensaïd",
      "Daniel Cremers",
      "Thomas Dagès",
      "Ron Kimmel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01094v1",
    "title": "Accelerating Inference of Masked Image Generators via Reinforcement Learning",
    "summary": "Masked Generative Models (MGM)s demonstrate strong capabilities in generating high-fidelity images. However, they need many sampling steps to create high-quality generations, resulting in slow inference speed. In this work, we propose Speed-RL, a novel paradigm for accelerating a pretrained MGMs to generate high-quality images in fewer steps. Unlike conventional distillation methods which formulate the acceleration problem as a distribution matching problem, where a few-step student model is trained to match the distribution generated by a many-step teacher model, we consider this problem as a reinforcement learning problem. Since the goal of acceleration is to generate high quality images in fewer steps, we can combine a quality reward with a speed reward and finetune the base model using reinforcement learning with the combined reward as the optimization target. Through extensive experiments, we show that the proposed method was able to accelerate the base model by a factor of 3x while maintaining comparable image quality.",
    "published": "2025-11-30T21:28:00Z",
    "updated": "2025-11-30T21:28:00Z",
    "link": "http://arxiv.org/pdf/2512.01094v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Pranav Subbaraman",
      "Shufan Li",
      "Siyan Zhao",
      "Aditya Grover"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2305.13625v4",
    "title": "DiffProtect: Generate Adversarial Examples with Diffusion Models for Facial Privacy Protection",
    "summary": "The increasingly pervasive facial recognition (FR) systems raise serious concerns about personal privacy, especially for billions of users who have publicly shared their photos on social media. Several attempts have been made to protect individuals from being identified by unauthorized FR systems utilizing adversarial attacks to generate encrypted face images. However, existing methods suffer from poor visual quality or low attack success rates, which limit their utility. Recently, diffusion models have achieved tremendous success in image generation. In this work, we ask: can diffusion models be used to generate adversarial examples to improve both visual quality and attack performance? We propose DiffProtect, which utilizes a diffusion autoencoder to generate semantically meaningful perturbations on FR systems. Extensive experiments demonstrate that DiffProtect produces more natural-looking encrypted images than state-of-the-art methods while achieving significantly higher attack success rates, e.g., 24.5% and 25.1% absolute improvements on the CelebA-HQ and FFHQ datasets.",
    "published": "2023-05-23T02:45:49Z",
    "updated": "2025-11-30T20:21:55Z",
    "link": "http://arxiv.org/pdf/2305.13625v4.pdf",
    "category": [
      "cs.CV",
      "cs.CR"
    ],
    "authors": [
      "Jiang Liu",
      "Chun Pong Lau",
      "Zhongliang Guo",
      "Yuxiang Guo",
      "Zhaoyang Wang",
      "Rama Chellappa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01061v1",
    "title": "Opening the Sim-to-Real Door for Humanoid Pixel-to-Action Policy Transfer",
    "summary": "Recent progress in GPU-accelerated, photorealistic simulation has opened a scalable data-generation path for robot learning, where massive physics and visual randomization allow policies to generalize beyond curated environments. Building on these advances, we develop a teacher-student-bootstrap learning framework for vision-based humanoid loco-manipulation, using articulated-object interaction as a representative high-difficulty benchmark. Our approach introduces a staged-reset exploration strategy that stabilizes long-horizon privileged-policy training, and a GRPO-based fine-tuning procedure that mitigates partial observability and improves closed-loop consistency in sim-to-real RL. Trained entirely on simulation data, the resulting policy achieves robust zero-shot performance across diverse door types and outperforms human teleoperators by up to 31.7% in task completion time under the same whole-body control stack. This represents the first humanoid sim-to-real policy capable of diverse articulated loco-manipulation using pure RGB perception.",
    "published": "2025-11-30T20:07:13Z",
    "updated": "2025-11-30T20:07:13Z",
    "link": "http://arxiv.org/pdf/2512.01061v1.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Haoru Xue",
      "Tairan He",
      "Zi Wang",
      "Qingwei Ben",
      "Wenli Xiao",
      "Zhengyi Luo",
      "Xingye Da",
      "Fernando Castañeda",
      "Guanya Shi",
      "Shankar Sastry",
      "Linxi \"Jim\" Fan",
      "Yuke Zhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01048v1",
    "title": "TRoVe: Discovering Error-Inducing Static Feature Biases in Temporal Vision-Language Models",
    "summary": "Vision-language models (VLMs) have made great strides in addressing temporal understanding tasks, which involve characterizing visual changes across a sequence of images. However, recent works have suggested that when making predictions, VLMs may rely on static feature biases, such as background or object features, rather than dynamic visual changes. Static feature biases are a type of shortcut and can contribute to systematic prediction errors on downstream tasks; as a result, identifying and characterizing error-inducing static feature biases is critical prior to real-world model deployment. In this work, we introduce TRoVe, an automated approach for discovering error-inducing static feature biases learned by temporal VLMs. Given a trained VLM and an annotated validation dataset associated with a downstream classification task, TRoVe extracts candidate static features from the dataset and scores each feature by (i) the effect of the feature on classification errors as well as (ii) the extent to which the VLM relies on the feature when making predictions. In order to quantitatively evaluate TRoVe, we introduce an evaluation framework consisting of 101 trained temporal VLMs paired with ground-truth annotations for learned static feature biases. We use this framework to demonstrate that TRoVe can accurately identify error-inducing static feature biases in VLMs, achieving a 28.6% improvement over the closest baseline. Finally, we apply TRoVe to 7 off-the-shelf VLMs and 2 temporal understanding tasks, surfacing previously-unknown static feature biases and demonstrating that knowledge of learned biases can aid in improving model performance at test time. Our code is available at https://github.com/Stanford-AIMI/TRoVe.",
    "published": "2025-11-30T19:36:46Z",
    "updated": "2025-11-30T19:36:46Z",
    "link": "http://arxiv.org/pdf/2512.01048v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Maya Varma",
      "Jean-Benoit Delbrouck",
      "Sophie Ostmeier",
      "Akshay Chaudhari",
      "Curtis Langlotz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.22980v2",
    "title": "How Muon's Spectral Design Benefits Generalization: A Study on Imbalanced Data",
    "summary": "The growing adoption of spectrum-aware matrix-valued optimizers such as Muon and Shampoo in deep learning motivates a systematic study of their generalization properties and, in particular, when they might outperform competitive algorithms. We approach this question by introducing appropriate simplifying abstractions as follows: First, we use imbalanced data as a testbed. Second, we study the canonical form of such optimizers, which is Spectral Gradient Descent (SpecGD) -- each update step is $UV^T$ where $UΣV^T$ is the truncated SVD of the gradient. Third, within this framework we identify a canonical setting for which we precisely quantify when SpecGD outperforms vanilla Euclidean GD. For a Gaussian mixture data model and both linear and bilinear models, we show that unlike GD, which prioritizes learning dominant principal components of the data first, SpecGD learns all principal components of the data at equal rates. We demonstrate how this translates to a growing gap in balanced accuracy favoring SpecGD early in training and further show that the gap remains consistent even when the GD counterpart uses adaptive step-sizes via normalization. By extending the analysis to deep linear models, we show that depth amplifies these effects. We empirically verify our theoretical findings on a variety of imbalanced datasets. Our experiments compare practical variants of spectral methods, like Muon and Shampoo, against their Euclidean counterparts and Adam. The results validate our findings that these spectral optimizers achieve superior generalization by promoting a more balanced learning of the data's underlying components.",
    "published": "2025-10-27T04:00:42Z",
    "updated": "2025-12-01T18:55:07Z",
    "link": "http://arxiv.org/pdf/2510.22980v2.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Bhavya Vasudeva",
      "Puneesh Deora",
      "Yize Zhao",
      "Vatsal Sharan",
      "Christos Thrampoulidis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.05235v4",
    "title": "IAEmu: Learning Galaxy Intrinsic Alignment Correlations",
    "summary": "The intrinsic alignments (IA) of galaxies, a key contaminant in weak lensing analyses, arise from correlations in galaxy shapes driven by tidal interactions and galaxy formation processes. Accurate IA modeling is essential for robust cosmological inference, but current approaches rely on perturbative methods that break down on nonlinear scales or on expensive simulations. We introduce IAEmu, a neural network-based emulator that predicts the galaxy position-position ($ξ$), position-orientation ($ω$), and orientation-orientation ($η$) correlation functions and their uncertainties using mock catalogs based on the halo occupation distribution (HOD) framework. Compared to simulations, IAEmu achieves ~3% average error for $ξ$ and ~5% for $ω$, while capturing the stochasticity of $η$ without overfitting. The emulator provides both aleatoric and epistemic uncertainties, helping identify regions where predictions may be less reliable. We also demonstrate generalization to non-HOD alignment signals by fitting to IllustrisTNG hydrodynamical simulation data. As a fully differentiable neural network, IAEmu enables $\\sim$10,000$\\times$ speed-ups in mapping HOD parameters to correlation functions on GPUs, compared to CPU-based simulations. This acceleration facilitates inverse modeling via gradient-based sampling, making IAEmu a powerful surrogate model for galaxy bias and IA studies with direct applications to Stage IV weak lensing surveys.",
    "published": "2025-04-07T16:19:50Z",
    "updated": "2025-12-01T18:49:49Z",
    "link": "http://arxiv.org/pdf/2504.05235v4.pdf",
    "category": [
      "astro-ph.CO",
      "astro-ph.GA",
      "cs.LG"
    ],
    "authors": [
      "Sneh Pandya",
      "Yuanyuan Yang",
      "Nicholas Van Alfen",
      "Jonathan Blazek",
      "Robin Walters"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01986v1",
    "title": "A robust generalizable device-agnostic deep learning model for sleep-wake determination from triaxial wrist accelerometry",
    "summary": "Study Objectives: Wrist accelerometry is widely used for inferring sleep-wake state. Previous works demonstrated poor wake detection, without cross-device generalizability and validation in different age range and sleep disorders. We developed a robust deep learning model for to detect sleep-wakefulness from triaxial accelerometry and evaluated its validity across three devices and in a large adult population spanning a wide range of ages with and without sleep disorders. Methods: We collected wrist accelerometry simultaneous to polysomnography (PSG) in 453 adults undergoing clinical sleep testing at a tertiary care sleep laboratory, using three devices. We extracted features in 30-second epochs and trained a 3-class model to detect wake, sleep, and sleep with arousals, which was then collapsed into wake vs. sleep using a decision tree. To enhance wake detection, the model was specifically trained on randomly selected subjects with low sleep efficiency and/or high arousal index from one device recording and then tested on the remaining recordings. Results: The model showed high performance with F1 Score of 0.86, sensitivity (sleep) of 0.87, and specificity (wakefulness) of 0.78, and significant and moderate correlation to PSG in predicting total sleep time (R=0.69) and sleep efficiency (R=0.63). Model performance was robust to the presence of sleep disorders, including sleep apnea and periodic limb movements in sleep, and was consistent across all three models of accelerometer. Conclusions: We present a deep model to detect sleep-wakefulness from actigraphy in adults with relative robustness to the presence of sleep disorders and generalizability across diverse commonly used wrist accelerometers.",
    "published": "2025-12-01T18:43:51Z",
    "updated": "2025-12-01T18:43:51Z",
    "link": "http://arxiv.org/pdf/2512.01986v1.pdf",
    "category": [
      "q-bio.QM",
      "cs.LG"
    ],
    "authors": [
      "Nasim Montazeri",
      "Stone Yang",
      "Dominik Luszczynski",
      "John Zhang",
      "Dharmendra Gurve",
      "Andrew Centen",
      "Maged Goubran",
      "Andrew Lim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01984v1",
    "title": "ECO: Energy-Constrained Operator Learning for Chaotic Dynamics with Boundedness Guarantees",
    "summary": "Chaos is a fundamental feature of many complex dynamical systems, including weather systems and fluid turbulence. These systems are inherently difficult to predict due to their extreme sensitivity to initial conditions. Many chaotic systems are dissipative and ergodic, motivating data-driven models that aim to learn invariant statistical properties over long time horizons. While recent models have shown empirical success in preserving invariant statistics, they are prone to generating unbounded predictions, which prevent meaningful statistics evaluation. To overcome this, we introduce the Energy-Constrained Operator (ECO) that simultaneously learns the system dynamics while enforcing boundedness in predictions. We leverage concepts from control theory to develop algebraic conditions based on a learnable energy function, ensuring the learned dynamics is dissipative. ECO enforces these algebraic conditions through an efficient closed-form quadratic projection layer, which provides provable trajectory boundedness. To our knowledge, this is the first work establishing such formal guarantees for data-driven chaotic dynamics models. Additionally, the learned invariant level set provides an outer estimate for the strange attractor, a complex structure that is computationally intractable to characterize. We demonstrate empirical success in ECO's ability to generate stable long-horizon forecasts, capturing invariant statistics on systems governed by chaotic PDEs, including the Kuramoto--Sivashinsky and the Navier--Stokes equations.",
    "published": "2025-12-01T18:42:02Z",
    "updated": "2025-12-01T18:42:02Z",
    "link": "http://arxiv.org/pdf/2512.01984v1.pdf",
    "category": [
      "eess.SY",
      "cs.LG"
    ],
    "authors": [
      "Andrea Goertzen",
      "Sunbochen Tang",
      "Navid Azizan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.15018v2",
    "title": "Private Continual Counting of Unbounded Streams",
    "summary": "We study the problem of differentially private continual counting in the unbounded setting where the input size $n$ is not known in advance. Current state-of-the-art algorithms based on optimal instantiations of the matrix mechanism cannot be directly applied here because their privacy guarantees only hold when key parameters are tuned to $n$. Using the common `doubling trick' avoids knowledge of $n$ but leads to suboptimal and non-smooth error. We solve this problem by introducing novel matrix factorizations based on logarithmic perturbations of the function $\\frac{1}{\\sqrt{1-z}}$ studied in prior works, which may be of independent interest. The resulting algorithm has smooth error, and for any $α> 0$ and $t\\leq n$ it is able to privately estimate the sum of the first $t$ data points with $O(\\log^{2+2α}(t))$ variance. It requires $O(t)$ space and amortized $O(\\log t)$ time per round, compared to $O(\\log(n)\\log(t))$ variance, $O(n)$ space and $O(n \\log n)$ pre-processing time for the nearly-optimal bounded-input algorithm of Henzinger et al. (SODA 2023). Empirically, we find that our algorithm's performance is also comparable to theirs in absolute terms: our variance is less than $1.5\\times$ theirs for $t$ as large as $2^{24}$.",
    "published": "2025-06-17T23:09:53Z",
    "updated": "2025-12-01T18:41:49Z",
    "link": "http://arxiv.org/pdf/2506.15018v2.pdf",
    "category": [
      "cs.CR",
      "cs.DS",
      "cs.LG"
    ],
    "authors": [
      "Ben Jacobsen",
      "Kassem Fawaz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01983v1",
    "title": "Feature-Based Semantics-Aware Scheduling for Energy-Harvesting Federated Learning",
    "summary": "Federated Learning (FL) on resource-constrained edge devices faces a critical challenge: The computational energy required for training Deep Neural Networks (DNNs) often dominates communication costs. However, most existing Energy-Harvesting FL (EHFL) strategies fail to account for this reality, resulting in wasted energy due to redundant local computations. For efficient and proactive resource management, algorithms that predict local update contributions must be devised. We propose a lightweight client scheduling framework using the Version Age of Information (VAoI), a semantics-aware metric that quantifies update timeliness and significance. Crucially, we overcome VAoI's typical prohibitive computational cost, which requires statistical distance over the entire parameter space, by introducing a feature-based proxy. This proxy estimates model redundancy using intermediate-layer extraction from a single forward pass, dramatically reducing computational complexity. Experiments conducted under extreme non-IID data distributions and scarce energy availability demonstrate superior learning performance while achieving energy reduction compared to existing baseline selection policies. Our framework establishes semantics-aware scheduling as a practical and vital solution for EHFL in realistic scenarios where training costs dominate transmission costs.",
    "published": "2025-12-01T18:40:26Z",
    "updated": "2025-12-01T18:40:26Z",
    "link": "http://arxiv.org/pdf/2512.01983v1.pdf",
    "category": [
      "cs.LG",
      "cs.DC",
      "cs.IT",
      "cs.NI",
      "eess.SP"
    ],
    "authors": [
      "Eunjeong Jeong",
      "Giovanni Perin",
      "Howard H. Yang",
      "Nikolaos Pappas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01980v1",
    "title": "Low-Rank Prehab: Preparing Neural Networks for SVD Compression",
    "summary": "Low-rank approximation methods such as singular value decomposition (SVD) and its variants (e.g., Fisher-weighted SVD, Activation SVD) have recently emerged as effective tools for neural network compression. In this setting, decomposition acts as a \"surgical\" intervention, followed by fine-tuning that serves as \"rehab\" to recover accuracy. Inspired by prehabilitation in surgery, we introduce a pre-compression fine-tuning stage, Low-Rank Prehab, that explicitly encourages low-rank structure in weight matrices while preserving task performance. By conditioning the model before SVD, Prehab steers weights toward spectrally compact regions of the parameter space, enabling smoother low-rank approximation and improved recovery. Experiments on large language models (LLMs) and other Transformer-based architectures, including Vision Transformers (ViTs), show that Prehab substantially reduces the immediate accuracy drop after compression and consistently improves post-finetuning performance. Across a wide range of compression ratios, our method outperforms state-of-the-art SVD-based techniques such as SVD-LLM, highlighting the importance of preparing models for compression rather than only improving the compression and recovery stages. Source code is available at https://github.com/niqretnuh/PREHAB-SVD",
    "published": "2025-12-01T18:37:53Z",
    "updated": "2025-12-01T18:37:53Z",
    "link": "http://arxiv.org/pdf/2512.01980v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Haoran Qin",
      "Shansita Sharma",
      "Ali Abbasi",
      "Chayne Thrash",
      "Soheil Kolouri"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.10630v2",
    "title": "How many measurements are enough? Bayesian recovery in inverse problems with general distributions",
    "summary": "We study the sample complexity of Bayesian recovery for solving inverse problems with general prior, forward operator and noise distributions. We consider posterior sampling according to an approximate prior $\\mathcal{P}$, and establish sufficient conditions for stable and accurate recovery with high probability. Our main result is a non-asymptotic bound that shows that the sample complexity depends on (i) the intrinsic complexity of $\\mathcal{P}$, quantified by its so-called approximate covering number, and (ii) concentration bounds for the forward operator and noise distributions. As a key application, we specialize to generative priors, where $\\mathcal{P}$ is the pushforward of a latent distribution via a Deep Neural Network (DNN). We show that the sample complexity scales log-linearly with the latent dimension $k$, thus establishing the efficacy of DNN-based priors. Generalizing existing results on deterministic (i.e., non-Bayesian) recovery for the important problem of random sampling with an orthogonal matrix $U$, we show how the sample complexity is determined by the coherence of $U$ with respect to the support of $\\mathcal{P}$. Hence, we establish that coherence plays a fundamental role in Bayesian recovery as well. Overall, our framework unifies and extends prior work, providing rigorous guarantees for the sample complexity of solving Bayesian inverse problems with arbitrary distributions.",
    "published": "2025-05-15T18:11:54Z",
    "updated": "2025-12-01T18:34:50Z",
    "link": "http://arxiv.org/pdf/2505.10630v2.pdf",
    "category": [
      "cs.LG",
      "math.ST"
    ],
    "authors": [
      "Ben Adcock",
      "Nick Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06790v2",
    "title": "Get RICH or Die Scaling: Profitably Trading Inference Compute for Robustness",
    "summary": "Models are susceptible to adversarially out-of-distribution (OOD) data despite large training-compute investments into their robustification. Zaremba et al. (2025) make progress on this problem at test time, showing LLM reasoning improves satisfaction of model specifications designed to thwart attacks, resulting in a correlation between reasoning effort and robustness to jailbreaks. However, this benefit of test compute fades when attackers are given access to gradients or multimodal inputs. We address this gap, clarifying that inference-compute offers benefits even in such cases. Our approach argues that compositional generalization, through which OOD data is understandable via its in-distribution (ID) components, enables adherence to defensive specifications on adversarially OOD inputs. Namely, we posit the Robustness from Inference Compute Hypothesis (RICH): inference-compute defenses profit as the model's training data better reflects the attacked data's components. We empirically support this hypothesis across vision language model and attack types, finding robustness gains from test-time compute if specification following on OOD data is unlocked by compositional generalization. For example, InternVL 3.5 gpt-oss 20B gains little robustness when its test compute is scaled, but such scaling adds significant robustness if we first robustify its vision encoder. This correlation of inference-compute's robustness benefit with base model robustness is the rich-get-richer dynamic of the RICH: attacked data components are more ID for robustified models, aiding compositional generalization to OOD data. Thus, we advise layering train-time and test-time defenses to obtain their synergistic benefit.",
    "published": "2025-10-08T09:18:53Z",
    "updated": "2025-12-01T18:15:29Z",
    "link": "http://arxiv.org/pdf/2510.06790v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Tavish McDonald",
      "Bo Lei",
      "Stanislav Fort",
      "Bhavya Kailkhura",
      "Brian Bartoldson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01953v1",
    "title": "KV Pareto: Systems-Level Optimization of KV Cache and Model Compression for Long Context Inference",
    "summary": "Long-context Large Language Models (LLMs) face significant memory bottlenecks during inference due to the linear growth of key-value (KV) cache with sequence length. While individual optimization techniques like KV cache quantization, chunked prefill, and model weight quantization have shown promise, their joint effects and optimal configurations for edge deployment remain underexplored. We introduce KV Pareto, a systems-level framework that systematically maps the trade-off frontier between total memory consumption and task accuracy across these three complementary optimization techniques. Our framework evaluates multiple LLM architectures (Qwen, Llama, Mistral) with varying KV quantization schemes (int2/4/8, mixed-precision), granularities (per-token, per-tensor, per-block), and 4-bit weight quantization via AWQ. Our framework identifies model-specific Pareto-optimal configurations that achieve 68-78% total memory reduction with minimal (1-3%) accuracy degradation on long-context tasks. We additionally verify the selected frontiers on additional benchmarks of Needle-in-a-Haystack, GSM8k and MMLU as well as extended context lengths of up to 128k to demonstrate the practical need of joint optimization for efficient LLM inference.",
    "published": "2025-12-01T18:03:47Z",
    "updated": "2025-12-01T18:03:47Z",
    "link": "http://arxiv.org/pdf/2512.01953v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Sai Gokhale",
      "Devleena Das",
      "Rajeev Patwari",
      "Ashish Sirasao",
      "Elliott Delaye"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01917v1",
    "title": "A Footprint-Aware, High-Resolution Approach for Carbon Flux Prediction Across Diverse Ecosystems",
    "summary": "Natural climate solutions (NCS) offer an approach to mitigating carbon dioxide (CO2) emissions. However, monitoring the carbon drawdown of ecosystems over large geographic areas remains challenging. Eddy-flux covariance towers provide ground truth for predictive 'upscaling' models derived from satellite products, but many satellites now produce measurements on spatial scales smaller than a flux tower's footprint. We introduce Footprint-Aware Regression (FAR), a first-of-its-kind, deep-learning framework that simultaneously predicts spatial footprints and pixel-level (30 m scale) estimates of carbon flux. FAR is trained on our AMERI-FAR25 dataset which combines 439 site years of tower data with corresponding Landsat scenes. Our model produces high-resolution predictions and achieves R2 = 0.78 when predicting monthly net ecosystem exchange on test sites from a variety of ecosystems.",
    "published": "2025-12-01T17:34:41Z",
    "updated": "2025-12-01T17:34:41Z",
    "link": "http://arxiv.org/pdf/2512.01917v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Jacob Searcy",
      "Anish Dulal",
      "Scott Bridgham",
      "Ashley Cordes",
      "Lillian Aoki",
      "Brendan Bohannan",
      "Qing Zhu",
      "Lucas C. R. Silva"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01906v1",
    "title": "Delays in Spiking Neural Networks: A State Space Model Approach",
    "summary": "Spiking neural networks (SNNs) are biologically inspired, event-driven models that are suitable for processing temporal data and offer energy-efficient computation when implemented on neuromorphic hardware. In SNNs, richer neuronal dynamic allows capturing more complex temporal dependencies, with delays playing a crucial role by allowing past inputs to directly influence present spiking behavior. We propose a general framework for incorporating delays into SNNs through additional state variables. The proposed mechanism enables each neuron to access a finite temporal input history. The framework is agnostic to neuron models and hence can be seamlessly integrated into standard spiking neuron models such as LIF and adLIF. We analyze how the duration of the delays and the learnable parameters associated with them affect the performance. We investigate the trade-offs in the network architecture due to additional state variables introduced by the delay mechanism. Experiments on the Spiking Heidelberg Digits (SHD) dataset show that the proposed mechanism matches the performance of existing delay-based SNNs while remaining computationally efficient. Moreover, the results illustrate that the incorporation of delays may substantially improve performance in smaller networks.",
    "published": "2025-12-01T17:26:21Z",
    "updated": "2025-12-01T17:26:21Z",
    "link": "http://arxiv.org/pdf/2512.01906v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Sanja Karilanova",
      "Subhrakanti Dey",
      "Ayça Özçelikkale"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01899v1",
    "title": "Provably Safe Model Updates",
    "summary": "Safety-critical environments are inherently dynamic. Distribution shifts, emerging vulnerabilities, and evolving requirements demand continuous updates to machine learning models. Yet even benign parameter updates can have unintended consequences, such as catastrophic forgetting in classical models or alignment drift in foundation models. Existing heuristic approaches (e.g., regularization, parameter isolation) can mitigate these effects but cannot certify that updated models continue to satisfy required performance specifications. We address this problem by introducing a framework for provably safe model updates. Our approach first formalizes the problem as computing the largest locally invariant domain (LID): a connected region in parameter space where all points are certified to satisfy a given specification. While exact maximal LID computation is intractable, we show that relaxing the problem to parameterized abstract domains (orthotopes, zonotopes) yields a tractable primal-dual formulation. This enables efficient certification of updates - independent of the data or algorithm used - by projecting them onto the safe domain. Our formulation further allows computation of multiple approximately optimal LIDs, incorporation of regularization-inspired biases, and use of lookahead data buffers. Across continual learning and foundation model fine-tuning benchmarks, our method matches or exceeds heuristic baselines for avoiding forgetting while providing formal safety guarantees.",
    "published": "2025-12-01T17:19:53Z",
    "updated": "2025-12-01T17:19:53Z",
    "link": "http://arxiv.org/pdf/2512.01899v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Leo Elmecker-Plakolm",
      "Pierre Fasterling",
      "Philip Sosnin",
      "Calvin Tsay",
      "Matthew Wicker"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01890v1",
    "title": "Elastic Weight Consolidation for Knowledge Graph Continual Learning: An Empirical Evaluation",
    "summary": "Knowledge graphs (KGs) require continual updates as new information emerges, but neural embedding models suffer from catastrophic forgetting when learning new tasks sequentially. We evaluate Elastic Weight Consolidation (EWC), a regularization-based continual learning method, on KG link prediction using TransE embeddings on FB15k-237. Across multiple experiments with five random seeds, we find that EWC reduces catastrophic forgetting from 12.62% to 6.85%, a 45.7% reduction compared to naive sequential training. We observe that the task partitioning strategy affects the magnitude of forgetting: relation-based partitioning (grouping triples by relation type) exhibits 9.8 percentage points higher forgetting than randomly partitioned tasks (12.62% vs 2.81%), suggesting that task construction influences evaluation outcomes. While focused on a single embedding model and dataset, our results demonstrate that EWC effectively mitigates catastrophic forgetting in KG continual learning and highlight the importance of evaluation protocol design.",
    "published": "2025-12-01T17:11:39Z",
    "updated": "2025-12-01T17:11:39Z",
    "link": "http://arxiv.org/pdf/2512.01890v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Gaganpreet Jhajj",
      "Fuhua Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01888v1",
    "title": "Domain-Decomposed Graph Neural Network Surrogate Modeling for Ice Sheets",
    "summary": "Accurate yet efficient surrogate models are essential for large-scale simulations of partial differential equations (PDEs), particularly for uncertainty quantification (UQ) tasks that demand hundreds or thousands of evaluations. We develop a physics-inspired graph neural network (GNN) surrogate that operates directly on unstructured meshes and leverages the flexibility of graph attention. To improve both training efficiency and generalization properties of the model, we introduce a domain decomposition (DD) strategy that partitions the mesh into subdomains, trains local GNN surrogates in parallel, and aggregates their predictions. We then employ transfer learning to fine-tune models across subdomains, accelerating training and improving accuracy in data-limited settings. Applied to ice sheet simulations, our approach accurately predicts full-field velocities on high-resolution meshes, substantially reduces training time relative to training a single global surrogate model, and provides a ripe foundation for UQ objectives. Our results demonstrate that graph-based DD, combined with transfer learning, provides a scalable and reliable pathway for training GNN surrogates on massive PDE-governed systems, with broad potential for application beyond ice sheet dynamics.",
    "published": "2025-12-01T17:10:09Z",
    "updated": "2025-12-01T17:10:09Z",
    "link": "http://arxiv.org/pdf/2512.01888v1.pdf",
    "category": [
      "cs.LG",
      "math-ph",
      "math.NA",
      "physics.comp-ph"
    ],
    "authors": [
      "Adrienne M. Propp",
      "Mauro Perego",
      "Eric C. Cyr",
      "Anthony Gruber",
      "Amanda A. Howard",
      "Alexander Heinlein",
      "Panos Stinis",
      "Daniel M. Tartakovsky"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01882v1",
    "title": "New Spiking Architecture for Multi-Modal Decision-Making in Autonomous Vehicles",
    "summary": "This work proposes an end-to-end multi-modal reinforcement learning framework for high-level decision-making in autonomous vehicles. The framework integrates heterogeneous sensory input, including camera images, LiDAR point clouds, and vehicle heading information, through a cross-attention transformer-based perception module. Although transformers have become the backbone of modern multi-modal architectures, their high computational cost limits their deployment in resource-constrained edge environments. To overcome this challenge, we propose a spiking temporal-aware transformer-like architecture that uses ternary spiking neurons for computationally efficient multi-modal fusion. Comprehensive evaluations across multiple tasks in the Highway Environment demonstrate the effectiveness and efficiency of the proposed approach for real-time autonomous decision-making.",
    "published": "2025-12-01T17:04:56Z",
    "updated": "2025-12-01T17:04:56Z",
    "link": "http://arxiv.org/pdf/2512.01882v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Aref Ghoreishee",
      "Abhishek Mishra",
      "Lifeng Zhou",
      "John Walsh",
      "Nagarajan Kandasamy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2401.00953v2",
    "title": "Families of costs with zero and nonnegative MTW tensor in optimal transport and the c-divergences",
    "summary": "We study the information geometry of $\\bcc$-divergences from families of costs of the form $\\mathsf{c}(x, \\barx) =\\mathsf{u}(x^{\\mathfrak{t}}\\barx)$ through the optimal transport point of view. Here, $\\mathsf{u}$ is a scalar function with inverse $\\mathsf{s}$, $x^{\\ft}\\barx$ is a nondegenerate bilinear pairing of vectors $x, \\barx$ belonging to an open subset of $\\mathbb{R}^n$. We compute explicitly the MTW tensor (or cross curvature) for the optimal transport problem on $\\mathbb{R}^n$ with this cost. The condition that the MTW-tensor vanishes on null vectors under the Kim-McCann metric is a fourth-order nonlinear ODE, which could be reduced to a linear ODE of the form $\\mathsf{s}^{(2)} - S\\mathsf{s}^{(1)} + P\\mathsf{s} = 0$ with constant coefficients $P$ and $S$. The resulting inverse functions include {\\it Lambert} and {\\it generalized inverse hyperbolic\\slash trigonometric} functions. The square Euclidean metric and $\\log$-type costs are equivalent to instances of these solutions. The optimal map may be written explicitly in terms of the potential function. For cost functions of a similar form on a hyperboloid model of the hyperbolic space and unit sphere, we also express this tensor in terms of algebraic expressions in derivatives of $\\mathsf{s}$ using the Gauss-Codazzi equation, obtaining new families of strictly regular costs for these manifolds, including new families of {\\it power function costs}. We express the divergence geometry of the $\\mathsf{c}$-divergence in terms of the Kim-McCann metric, including a $\\mathsf{c}$-Crouzeix identity and a formula for the primal connection. We analyze the $\\sinh$-type hyperbolic cost, providing examples of $\\mathsf{c}$-convex functions, which are used to construct a new \\emph{local form} of the $α$-divergences on probability simplices. We apply the optimal maps to sample the multivariate $t$-distribution.",
    "published": "2024-01-01T20:33:27Z",
    "updated": "2025-12-01T17:02:17Z",
    "link": "http://arxiv.org/pdf/2401.00953v2.pdf",
    "category": [
      "math.AP",
      "cs.IT",
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Du Nguyen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.09189v2",
    "title": "Testing Noise Assumptions of Learning Algorithms",
    "summary": "We pose a fundamental question in computational learning theory: can we efficiently test whether a training set satisfies the assumptions of a given noise model? This question has remained unaddressed despite decades of research on learning in the presence of noise. In this work, we show that this task is tractable and present the first efficient algorithm to test various noise assumptions on the training data.\n  To model this question, we extend the recently proposed testable learning framework of Rubinfeld and Vasilyan (2023) and require a learner to run an associated test that satisfies the following two conditions: (1) whenever the test accepts, the learner outputs a classifier along with a certificate of optimality, and (2) the test must pass for any dataset drawn according to a specified modeling assumption on both the marginal distribution and the noise model. We then consider the problem of learning halfspaces over Gaussian marginals with Massart noise (where each label can be flipped with probability less than $1/2$ depending on the input features), and give a fully-polynomial time testable learning algorithm.\n  We also show a separation between the classical setting of learning in the presence of structured noise and testable learning. In fact, for the simple case of random classification noise (where each label is flipped with fixed probability $η= 1/2$), we show that testable learning requires super-polynomial time while classical learning is trivial.",
    "published": "2025-01-15T22:33:55Z",
    "updated": "2025-12-01T16:58:42Z",
    "link": "http://arxiv.org/pdf/2501.09189v2.pdf",
    "category": [
      "cs.LG",
      "cs.DS"
    ],
    "authors": [
      "Surbhi Goel",
      "Adam R. Klivans",
      "Konstantinos Stavropoulos",
      "Arsen Vasilyan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01868v1",
    "title": "The Mean-Field Dynamics of Transformers",
    "summary": "We develop a mathematical framework that interprets Transformer attention as an interacting particle system and studies its continuum (mean-field) limits. By idealizing attention continuous on the sphere, we connect Transformer dynamics to Wasserstein gradient flows, synchronization models (Kuramoto), and mean-shift clustering. Central to our results is a global clustering phenomenon whereby tokens cluster asymptotically after long metastable states where they are arranged into multiple clusters. We further analyze a tractable equiangular reduction to obtain exact clustering rates, show how commonly used normalization schemes alter contraction speeds, and identify a phase transition for long-context attention. The results highlight both the mechanisms that drive representation collapse and the regimes that preserve expressive, multi-cluster structure in deep attention architectures.",
    "published": "2025-12-01T16:51:00Z",
    "updated": "2025-12-01T16:51:00Z",
    "link": "http://arxiv.org/pdf/2512.01868v1.pdf",
    "category": [
      "cs.LG",
      "math-ph",
      "math.DS",
      "math.PR"
    ],
    "authors": [
      "Philippe Rigollet"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19405v2",
    "title": "Learning Robust Social Strategies with Large Language Models",
    "summary": "As agentic AI becomes more widespread, agents with distinct and possibly conflicting goals will interact in complex ways. These multi-agent interactions pose a fundamental challenge, particularly in social dilemmas, where agents' individual incentives can undermine collective welfare. While reinforcement learning (RL) has been effective for aligning large language models (LLMs) in the single-agent regime, prior small-network results suggest that standard RL in multi-agent settings often converges to defecting, self-interested policies. We show the same effect in LLMs: despite cooperative priors, RL-trained LLM agents develop opportunistic behavior that can exploit even advanced closed-source models. To address this tendency of RL to converge to poor equilibria, we adapt a recent opponent-learning awareness algorithm, Advantage Alignment, to fine-tune LLMs toward multi-agent cooperation and non-exploitability. We then introduce a group-relative baseline that simplifies advantage computation in iterated games, enabling multi-agent training at LLM scale. We also contribute a novel social dilemma environment, Trust-and-Split, which requires natural language communication to achieve high collective welfare. Across a wide range of social dilemmas, policies learned with Advantage Alignment achieve higher collective payoffs while remaining robust against exploitation by greedy agents. We release all of our code to support future work on multi-agent RL training for LLMs.",
    "published": "2025-11-24T18:43:46Z",
    "updated": "2025-12-01T16:27:49Z",
    "link": "http://arxiv.org/pdf/2511.19405v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Dereck Piche",
      "Mohammed Muqeeth",
      "Milad Aghajohari",
      "Juan Duque",
      "Michael Noukhovitch",
      "Aaron Courville"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2212.07356v3",
    "title": "Scheduling and Aggregation Design for Asynchronous Federated Learning over Wireless Networks",
    "summary": "Federated Learning (FL) is a collaborative machine learning (ML) framework that combines on-device training and server-based aggregation to train a common ML model among distributed agents. In this work, we propose an asynchronous FL design with periodic aggregation to tackle the straggler issue in FL systems. Considering limited wireless communication resources, we investigate the effect of different scheduling policies and aggregation designs on the convergence performance. Driven by the importance of reducing the bias and variance of the aggregated model updates, we propose a scheduling policy that jointly considers the channel quality and training data representation of user devices. The effectiveness of our channel-aware data-importance-based scheduling policy, compared with state-of-the-art methods proposed for synchronous FL, is validated through simulations. Moreover, we show that an ``age-aware'' aggregation weighting design can significantly improve the learning performance in an asynchronous FL setting.",
    "published": "2022-12-14T17:33:01Z",
    "updated": "2025-12-01T16:06:41Z",
    "link": "http://arxiv.org/pdf/2212.07356v3.pdf",
    "category": [
      "cs.LG",
      "cs.DC",
      "cs.IT",
      "eess.SP"
    ],
    "authors": [
      "Chung-Hsuan Hu",
      "Zheng Chen",
      "Erik G. Larsson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.07067v2",
    "title": "How to Bridge the Sim-to-Real Gap in Digital Twin-Aided Telecommunication Networks",
    "summary": "Training effective artificial intelligence models for telecommunications is challenging due to the scarcity of deployment-specific data. Real data collection is expensive, and available datasets often fail to capture the unique operational conditions and contextual variability of the network environment. Digital twinning provides a potential solution to this problem, as simulators tailored to the current network deployment can generate site-specific data to augment the available training datasets. However, there is a need to develop solutions to bridge the inherent simulation-to-reality (sim-to-real) gap between synthetic and real-world data. This paper reviews recent advances on two complementary strategies: 1) the calibration of digital twins (DTs) through real-world measurements, and 2) the use of sim-to-real gap-aware training strategies to robustly handle residual discrepancies between digital twin-generated and real data. For the latter, we evaluate two conceptually distinct methods that model the sim-to-real gap either at the level of the environment via Bayesian learning or at the level of the training loss via prediction-powered inference.",
    "published": "2025-07-09T17:27:51Z",
    "updated": "2025-12-01T16:04:07Z",
    "link": "http://arxiv.org/pdf/2507.07067v2.pdf",
    "category": [
      "eess.SP",
      "cs.LG"
    ],
    "authors": [
      "Clement Ruah",
      "Houssem Sifaou",
      "Osvaldo Simeone",
      "Bashir M. Al-Hashimi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01820v1",
    "title": "Dimension-free error estimate for diffusion model and optimal scheduling",
    "summary": "Diffusion generative models have emerged as powerful tools for producing synthetic data from an empirically observed distribution. A common approach involves simulating the time-reversal of an Ornstein-Uhlenbeck (OU) process initialized at the true data distribution. Since the score function associated with the OU process is typically unknown, it is approximated using a trained neural network. This approximation, along with finite time simulation, time discretization and statistical approximation, introduce several sources of error whose impact on the generated samples must be carefully understood. Previous analyses have quantified the error between the generated and the true data distributions in terms of Wasserstein distance or Kullback-Leibler (KL) divergence. However, both metrics present limitations: KL divergence requires absolute continuity between distributions, while Wasserstein distance, though more general, leads to error bounds that scale poorly with dimension, rendering them impractical in high-dimensional settings. In this work, we derive an explicit, dimension-free bound on the discrepancy between the generated and the true data distributions. The bound is expressed in terms of a smooth test functional with bounded first and second derivatives. The key novelty lies in the use of this weaker, functional metric to obtain dimension-independent guarantees, at the cost of higher regularity on the test functions. As an application, we formulate and solve a variational problem to minimize the time-discretization error, leading to the derivation of an optimal time-scheduling strategy for the reverse-time diffusion. Interestingly, this scheduler has appeared previously in the literature in a different context; our analysis provides a new justification for its optimality, now grounded in minimizing the discretization bias in generative sampling.",
    "published": "2025-12-01T15:58:20Z",
    "updated": "2025-12-01T15:58:20Z",
    "link": "http://arxiv.org/pdf/2512.01820v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "math.PR",
      "math.ST"
    ],
    "authors": [
      "Valentin de Bortoli",
      "Romuald Elie",
      "Anna Kazeykina",
      "Zhenjie Ren",
      "Jiacheng Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01819v1",
    "title": "Decision Tree Embedding by Leaf-Means",
    "summary": "Decision trees and random forest remain highly competitive for classification on medium-sized, standard datasets due to their robustness, minimal preprocessing requirements, and interpretability. However, a single tree suffers from high estimation variance, while large ensembles reduce this variance at the cost of substantial computational overhead and diminished interpretability. In this paper, we propose Decision Tree Embedding (DTE), a fast and effective method that leverages the leaf partitions of a trained classification tree to construct an interpretable feature representation. By using the sample means within each leaf region as anchor points, DTE maps inputs into an embedding space defined by the tree's partition structure, effectively circumventing the high variance inherent in decision-tree splitting rules. We further introduce an ensemble extension based on additional bootstrap trees, and pair the resulting embedding with linear discriminant analysis for classification. We establish several population-level theoretical properties of DTE, including its preservation of conditional density under mild conditions and a characterization of the resulting classification error. Empirical studies on synthetic and real datasets demonstrate that DTE strikes a strong balance between accuracy and computational efficiency, outperforming or matching random forest and shallow neural networks while requiring only a fraction of their training time in most cases. Overall, the proposed DTE method can be viewed either as a scalable decision tree classifier that improves upon standard split rules, or as a neural network model whose weights are learned from tree-derived anchor points, achieving an intriguing integration of both paradigms.",
    "published": "2025-12-01T15:57:33Z",
    "updated": "2025-12-01T15:57:33Z",
    "link": "http://arxiv.org/pdf/2512.01819v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Cencheng Shen",
      "Yuexiao Dong",
      "Carey E. Priebe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01810v1",
    "title": "DeepCAVE: A Visualization and Analysis Tool for Automated Machine Learning",
    "summary": "Hyperparameter optimization (HPO), as a central paradigm of AutoML, is crucial for leveraging the full potential of machine learning (ML) models; yet its complexity poses challenges in understanding and debugging the optimization process. We present DeepCAVE, a tool for interactive visualization and analysis, providing insights into HPO. Through an interactive dashboard, researchers, data scientists, and ML engineers can explore various aspects of the HPO process and identify issues, untouched potentials, and new insights about the ML model being tuned. By empowering users with actionable insights, DeepCAVE contributes to the interpretability of HPO and ML on a design level and aims to foster the development of more robust and efficient methodologies in the future.",
    "published": "2025-12-01T15:45:30Z",
    "updated": "2025-12-01T15:45:30Z",
    "link": "http://arxiv.org/pdf/2512.01810v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Sarah Segel",
      "Helena Graf",
      "Edward Bergman",
      "Kristina Thieme",
      "Marcel Wever",
      "Alexander Tornede",
      "Frank Hutter",
      "Marius Lindauer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01809v1",
    "title": "Much Ado About Noising: Dispelling the Myths of Generative Robotic Control",
    "summary": "Generative models, like flows and diffusions, have recently emerged as popular and efficacious policy parameterizations in robotics. There has been much speculation as to the factors underlying their successes, ranging from capturing multi-modal action distribution to expressing more complex behaviors. In this work, we perform a comprehensive evaluation of popular generative control policies (GCPs) on common behavior cloning (BC) benchmarks. We find that GCPs do not owe their success to their ability to capture multi-modality or to express more complex observation-to-action mappings. Instead, we find that their advantage stems from iterative computation, as long as intermediate steps are supervised during training and this supervision is paired with a suitable level of stochasticity. As a validation of our findings, we show that a minimum iterative policy (MIP), a lightweight two-step regression-based policy, essentially matches the performance of flow GCPs, and often outperforms distilled shortcut models. Our results suggest that the distribution-fitting component of GCPs is less salient than commonly believed, and point toward new design spaces focusing solely on control performance. Project page: https://simchowitzlabpublic.github.io/much-ado-about-noising-project/",
    "published": "2025-12-01T15:44:53Z",
    "updated": "2025-12-01T15:44:53Z",
    "link": "http://arxiv.org/pdf/2512.01809v1.pdf",
    "category": [
      "cs.RO",
      "cs.LG"
    ],
    "authors": [
      "Chaoyi Pan",
      "Giri Anantharaman",
      "Nai-Chieh Huang",
      "Claire Jin",
      "Daniel Pfrommer",
      "Chenyang Yuan",
      "Frank Permenter",
      "Guannan Qu",
      "Nicholas Boffi",
      "Guanya Shi",
      "Max Simchowitz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01801v1",
    "title": "GR-RL: Going Dexterous and Precise for Long-Horizon Robotic Manipulation",
    "summary": "We present GR-RL, a robotic learning framework that turns a generalist vision-language-action (VLA) policy into a highly capable specialist for long-horizon dexterous manipulation. Assuming the optimality of human demonstrations is core to existing VLA policies. However, we claim that in highly dexterous and precise manipulation tasks, human demonstrations are noisy and suboptimal. GR-RL proposes a multi-stage training pipeline that filters, augments, and reinforces the demonstrations by reinforcement learning. First, GR-RL learns a vision-language-conditioned task progress, filters the demonstration trajectories, and only keeps the transitions that contribute positively to the progress. Specifically, we show that by directly applying offline RL with sparse reward, the resulting $Q$-values can be treated as a robust progress function. Next, we introduce morphological symmetry augmentation that greatly improves the generalization and performance of GR-RL. Lastly, to better align the VLA policy with its deployment behaviors for high-precision control, we perform online RL by learning a latent space noise predictor. With this pipeline, GR-RL is, to our knowledge, the first learning-based policy that can autonomously lace up a shoe by threading shoelaces through multiple eyelets with an 83.3% success rate, a task requiring long-horizon reasoning, millimeter-level precision, and compliant soft-body interaction. We hope GR-RL provides a step toward enabling generalist robot foundations models to specialize into reliable real-world experts.",
    "published": "2025-12-01T15:33:59Z",
    "updated": "2025-12-01T15:33:59Z",
    "link": "http://arxiv.org/pdf/2512.01801v1.pdf",
    "category": [
      "cs.RO",
      "cs.LG"
    ],
    "authors": [
      "Yunfei Li",
      "Xiao Ma",
      "Jiafeng Xu",
      "Yu Cui",
      "Zhongren Cui",
      "Zhigang Han",
      "Liqun Huang",
      "Tao Kong",
      "Yuxiao Liu",
      "Hao Niu",
      "Wanli Peng",
      "Jingchao Qiao",
      "Zeyu Ren",
      "Haixin Shi",
      "Zhi Su",
      "Jiawen Tian",
      "Yuyang Xiao",
      "Shenyu Zhang",
      "Liwei Zheng",
      "Hang Li",
      "Yonghui Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.23818v2",
    "title": "L2RU: a Structured State Space Model with prescribed L2-bound",
    "summary": "Structured state-space models (SSMs) have recently emerged as a powerful architecture at the intersection of machine learning and control, featuring layers composed of discrete-time linear time-invariant (LTI) systems followed by pointwise nonlinearities. These models combine the expressiveness of deep neural networks with the interpretability and inductive bias of dynamical systems, offering strong performance on long-sequence tasks with favorable computational complexity. However, their adoption in applications such as system identification and optimal control remains limited by the difficulty of enforcing stability and robustness in a principled and tractable manner.\n  We introduce L2RU, a class of SSMs endowed with a prescribed $\\mathcal{L}_2$-gain bound, guaranteeing input--output stability and robustness for all parameter values. The L2RU architecture is derived from free parametrizations of LTI systems satisfying an $\\mathcal{L}_2$ constraint, enabling unconstrained optimization via standard gradient-based methods while preserving rigorous stability guarantees. Specifically, we develop two complementary parametrizations: a non-conservative formulation that provides a complete characterization of square LTI systems with a given $\\mathcal{L}_2$-bound, and a conservative formulation that extends the approach to general (possibly non-square) systems while improving computational efficiency through a structured representation of the system matrices.\n  Both parametrizations admit efficient initialization schemes that facilitate training long-memory models. We demonstrate the effectiveness of the proposed framework on a nonlinear system identification benchmark, where L2RU achieves improved performance and training stability compared to existing SSM architectures, highlighting its potential as a principled and robust building block for learning and control.",
    "published": "2025-03-31T07:56:17Z",
    "updated": "2025-12-01T15:33:04Z",
    "link": "http://arxiv.org/pdf/2503.23818v2.pdf",
    "category": [
      "eess.SY",
      "cs.LG"
    ],
    "authors": [
      "Leonardo Massai",
      "Muhammad Zakwan",
      "Giancarlo Ferrari-Trecate"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.01599v2",
    "title": "Connecting Neural Models Latent Geometries with Relative Geodesic Representations",
    "summary": "Neural models learn representations of high-dimensional data on low-dimensional manifolds. Multiple factors, including stochasticities in the training process, model architectures, and additional inductive biases, may induce different representations, even when learning the same task on the same data. However, it has recently been shown that when a latent structure is shared between distinct latent spaces, relative distances between representations can be preserved, up to distortions. Building on this idea, we demonstrate that exploiting the differential-geometric structure of latent spaces of neural models, it is possible to capture precisely the transformations between representational spaces trained on similar data distributions. Specifically, we assume that distinct neural models parametrize approximately the same underlying manifold, and introduce a representation based on the pullback metric that captures the intrinsic structure of the latent space, while scaling efficiently to large models. We validate experimentally our method on model stitching and retrieval tasks, covering autoencoders and vision foundation discriminative models, across diverse architectures, datasets, and pretraining schemes.",
    "published": "2025-06-02T12:34:55Z",
    "updated": "2025-12-01T15:32:39Z",
    "link": "http://arxiv.org/pdf/2506.01599v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Hanlin Yu",
      "Berfin Inal",
      "Georgios Arvanitidis",
      "Soren Hauberg",
      "Francesco Locatello",
      "Marco Fumero"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01783v1",
    "title": "The Active and Noise-Tolerant Strategic Perceptron",
    "summary": "We initiate the study of active learning algorithms for classifying strategic agents. Active learning is a well-established framework in machine learning in which the learner selectively queries labels, often achieving substantially higher accuracy and efficiency than classical supervised methods-especially in settings where labeling is costly or time-consuming, such as hiring, admissions, and loan decisions. Strategic classification, however, addresses scenarios where agents modify their features to obtain more favorable outcomes, resulting in observed data that is not truthful. Such manipulation introduces challenges beyond those in learning from clean data. Our goal is to design active and noise-tolerant algorithms that remain effective in strategic environments-algorithms that classify strategic agents accurately while issuing as few label requests as possible. The central difficulty is to simultaneously account for strategic manipulation and preserve the efficiency gains of active learning.\n  Our main result is an algorithm for actively learning linear separators in the strategic setting that preserves the exponential improvement in label complexity over passive learning previously obtained only in the non-strategic case. Specifically, for data drawn uniformly from the unit sphere, we show that a modified version of the Active Perceptron algorithm [DKM05,YZ17] achieves excess error $ε$ using only $\\tilde{O}(d \\ln \\frac{1}ε)$ label queries and incurs at most $\\tilde{O}(d \\ln \\frac{1}ε)$ additional mistakes relative to the optimal classifier, even in the nonrealizable case, when a $\\tildeΩ(ε)$ fraction of inputs have inconsistent labels with the optimal classifier. The algorithm is computationally efficient and, under these distributional assumptions, requires substantially fewer label queries than prior work on strategic Perceptron [ABBN21].",
    "published": "2025-12-01T15:23:03Z",
    "updated": "2025-12-01T15:23:03Z",
    "link": "http://arxiv.org/pdf/2512.01783v1.pdf",
    "category": [
      "cs.LG",
      "cs.GT"
    ],
    "authors": [
      "Maria-Florina Blacan",
      "Hedyeh Beyhaghi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01775v1",
    "title": "How Does RL Post-training Induce Skill Composition? A Case Study on Countdown",
    "summary": "While reinforcement learning (RL) successfully enhances reasoning in large language models, its role in fostering compositional generalization (the ability to synthesize novel skills from known components) is often conflated with mere length generalization. To this end, we study what RL post-training teaches about skill composition and how the structure of the composition affects the skill transfer. We focus on the Countdown task (given n numbers and a target, form an expression that evaluates to the target) and analyze model solutions as expression trees, where each subtree corresponds to a reusable subtask and thus can be viewed as a ``skill.'' Tracking tree shapes and their success rates over training, we find: (i) out-of-distribution (OOD) generalization to larger n and to unseen tree shapes, indicating compositional reuse of subtasks; (ii) a structure-dependent hierarchy of learnability -- models master shallow balanced trees (workload is balanced between subtasks) before deep unbalanced ones, with persistent fragility on right-heavy structures (even when the composition depth is the same as some left-heavy structures). Our diagnostic reveals what is learned, in what order, and where generalization fails, clarifying how RL-only post-training induces OOD generalization beyond what standard metrics such as pass@k reveal.",
    "published": "2025-12-01T15:17:16Z",
    "updated": "2025-12-01T15:17:16Z",
    "link": "http://arxiv.org/pdf/2512.01775v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Simon Park",
      "Simran Kaur",
      "Sanjeev Arora"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.05126v2",
    "title": "Skewed Neuronal Heterogeneity Enhances Efficiency On Various Computing Systems",
    "summary": "Heterogeneity is a ubiquitous property of many biological systems and has profound implications for computation. While it is conceivable to optimize neuronal and synaptic heterogeneity for a specific task, such top-down optimization is biologically implausible, prone to catastrophic forgetting, and both data- and energy-intensive. In contrast, biological organisms, with remarkable capacity to perform numerous tasks with minimal metabolic cost, exhibit a heterogeneity that is inherent, stable during adulthood, and task-unspecific. Inspired by this intrinsic form of heterogeneity, we investigate the utility of variations in neuronal time constants for solving hundreds of distinct temporal tasks of varying complexity. Our results show that intrinsic heterogeneity significantly enhances performance and robustness in an implementation-independent manner, indicating its usefulness for both (rate-based) machine learning and (spike-coded) neuromorphic applications. Importantly, only skewed heterogeneity profiles-reminiscent of those found in biology-produce such performance gains. We further demonstrate that this computational advantage eliminates the need for large networks, allowing comparable performance with substantially lower operational, metabolic, and energetic costs, respectively in silico, in vivo, and on neuromorphic hardware. Finally, we discuss the implications of intrinsic (rather than task-induced) heterogeneity for the design of efficient artificial systems, particularly novel neuromorphic devices that exhibit similar device-to-device variability.",
    "published": "2024-12-06T15:34:58Z",
    "updated": "2025-12-01T15:15:47Z",
    "link": "http://arxiv.org/pdf/2412.05126v2.pdf",
    "category": [
      "cs.LG",
      "cs.NE"
    ],
    "authors": [
      "Arash Golmohammadi",
      "Jannik Luboeinski",
      "Christian Tetzlaff"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01766v1",
    "title": "On the Unreasonable Effectiveness of Last-layer Retraining",
    "summary": "Last-layer retraining (LLR) methods -- wherein the last layer of a neural network is reinitialized and retrained on a held-out set following ERM training -- have garnered interest as an efficient approach to rectify dependence on spurious correlations and improve performance on minority groups. Surprisingly, LLR has been found to improve worst-group accuracy even when the held-out set is an imbalanced subset of the training set. We initially hypothesize that this ``unreasonable effectiveness'' of LLR is explained by its ability to mitigate neural collapse through the held-out set, resulting in the implicit bias of gradient descent benefiting robustness. Our empirical investigation does not support this hypothesis. Instead, we present strong evidence for an alternative hypothesis: that the success of LLR is primarily due to better group balance in the held-out set. We conclude by showing how the recent algorithms CB-LLR and AFR perform implicit group-balancing to elicit a robustness improvement.",
    "published": "2025-12-01T15:08:43Z",
    "updated": "2025-12-01T15:08:43Z",
    "link": "http://arxiv.org/pdf/2512.01766v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "John C. Hill",
      "Tyler LaBonte",
      "Xinchen Zhang",
      "Vidya Muthukumar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01756v1",
    "title": "Mofasa: A Step Change in Metal-Organic Framework Generation",
    "summary": "Mofasa is an all-atom latent diffusion model with state-of-the-art performance for generating Metal-Organic Frameworks (MOFs). These are highly porous crystalline materials used to harvest water from desert air, capture carbon dioxide, store toxic gases and catalyse chemical reactions. In recognition of their value, the development of MOFs recently received a Nobel Prize in Chemistry.\n  In many ways, MOFs are well-suited for exploiting generative models in chemistry: they are rationally-designable materials with a large combinatorial design space and strong structure-property couplings. And yet, to date, a high performance generative model has been lacking. To fill this gap, we introduce Mofasa, a general-purpose latent diffusion model that jointly samples positions, atom-types and lattice vectors for systems as large as 500 atoms. Mofasa avoids handcrafted assembly algorithms common in the literature, unlocking the simultaneous discovery of metal nodes, linkers and topologies.\n  To help the scientific community build on our work, we release MofasaDB, an annotated library of hundreds of thousands of sampled MOF structures, along with a user-friendly web interface for search and discovery: https://mofux.ai/ .",
    "published": "2025-12-01T15:01:32Z",
    "updated": "2025-12-01T15:01:32Z",
    "link": "http://arxiv.org/pdf/2512.01756v1.pdf",
    "category": [
      "cs.LG",
      "cond-mat.mtrl-sci"
    ],
    "authors": [
      "Vaidotas Simkus",
      "Anders Christensen",
      "Steven Bennett",
      "Ian Johnson",
      "Mark Neumann",
      "James Gin",
      "Jonathan Godwin",
      "Benjamin Rhodes"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01750v1",
    "title": "Multimodal Mixture-of-Experts for ISAC in Low-Altitude Wireless Networks",
    "summary": "Integrated sensing and communication (ISAC) is a key enabler for low-altitude wireless networks (LAWNs), providing simultaneous environmental perception and data transmission in complex aerial scenarios. By combining heterogeneous sensing modalities such as visual, radar, lidar, and positional information, multimodal ISAC can improve both situational awareness and robustness of LAWNs. However, most existing multimodal fusion approaches use static fusion strategies that treat all modalities equally and cannot adapt to channel heterogeneity or time-varying modality reliability in dynamic low-altitude environments. To address this fundamental limitation, we propose a mixture-of-experts (MoE) framework for multimodal ISAC in LAWNs. Each modality is processed by a dedicated expert network, and a lightweight gating module adaptively assigns fusion weights according to the instantaneous informativeness and reliability of each modality. To improve scalability under the stringent energy constraints of aerial platforms, we further develop a sparse MoE variant that selectively activates only a subset of experts, thereby reducing computation overhead while preserving the benefits of adaptive fusion. Comprehensive simulations on three typical ISAC tasks in LAWNs demonstrate that the proposed frameworks consistently outperform conventional multimodal fusion baselines in terms of learning performance and training sample efficiency.",
    "published": "2025-12-01T14:53:29Z",
    "updated": "2025-12-01T14:53:29Z",
    "link": "http://arxiv.org/pdf/2512.01750v1.pdf",
    "category": [
      "eess.SP",
      "cs.LG"
    ],
    "authors": [
      "Kai Zhang",
      "Wentao Yu",
      "Hengtao He",
      "Shenghui Song",
      "Jun Zhang",
      "Khaled B. Letaief"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01748v1",
    "title": "SA-ADP: Sensitivity-Aware Adaptive Differential Privacy for Large Language Models",
    "summary": "Despite advances in the use of large language models (LLMs) in downstream tasks, their ability to memorize information has raised privacy concerns. Therefore, protecting personally identifiable information (PII) during LLM training remains a fundamental challenge. Conventional methods like Differential Privacy-Stochastic Gradient Descent (DP-SGD) provide robust privacy protection via uniform noising, protecting PII regardless of its distinct sensitivity. This comes at the expense of the model's utility, leading to a trade-off. In this paper, we propose SA-ADP, a sensitivity-aware approach that allocates noise based on the sensitivity of individual PII. We evaluated our method on four datasets (ABCD, CUSTOMERSIM, Wikitext-2, and UNSW-NB15 ). Our results show that SA-ADP achieves results comparable to the baseline (No-DP) and the conventional DP-SGD. This means that our method did not degrade the model's utility while still maintaining strong privacy protection.",
    "published": "2025-12-01T14:50:59Z",
    "updated": "2025-12-01T14:50:59Z",
    "link": "http://arxiv.org/pdf/2512.01748v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Stella Etuk",
      "Ashraf Matrawy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01738v1",
    "title": "MSPT: Efficient Large-Scale Physical Modeling via Parallelized Multi-Scale Attention",
    "summary": "A key scalability challenge in neural solvers for industrial-scale physics simulations is efficiently capturing both fine-grained local interactions and long-range global dependencies across millions of spatial elements. We introduce the Multi-Scale Patch Transformer (MSPT), an architecture that combines local point attention within patches with global attention to coarse patch-level representations. To partition the input domain into spatially-coherent patches, we employ ball trees, which handle irregular geometries efficiently. This dual-scale design enables MSPT to scale to millions of points on a single GPU. We validate our method on standard PDE benchmarks (elasticity, plasticity, fluid dynamics, porous flow) and large-scale aerodynamic datasets (ShapeNet-Car, Ahmed-ML), achieving state-of-the-art accuracy with substantially lower memory footprint and computational cost.",
    "published": "2025-12-01T14:43:46Z",
    "updated": "2025-12-01T14:43:46Z",
    "link": "http://arxiv.org/pdf/2512.01738v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Pedro M. P. Curvo",
      "Jan-Willem van de Meent",
      "Maksim Zhdanov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01735v1",
    "title": "Automating modeling in mechanics: LLMs as designers of physics-constrained neural networks for constitutive modeling of materials",
    "summary": "Large language model (LLM)-based agentic frameworks increasingly adopt the paradigm of dynamically generating task-specific agents. We suggest that not only agents but also specialized software modules for scientific and engineering tasks can be generated on demand. We demonstrate this concept in the field of solid mechanics. There, so-called constitutive models are required to describe the relationship between mechanical stress and body deformation. Constitutive models are essential for both the scientific understanding and industrial application of materials. However, even recent data-driven methods of constitutive modeling, such as constitutive artificial neural networks (CANNs), still require substantial expert knowledge and human labor. We present a framework in which an LLM generates a CANN on demand, tailored to a given material class and dataset provided by the user. The framework covers LLM-based architecture selection, integration of physical constraints, and complete code generation. Evaluation on three benchmark problems demonstrates that LLM-generated CANNs achieve accuracy comparable to or greater than manually engineered counterparts, while also exhibiting reliable generalization to unseen loading scenarios and extrapolation to large deformations. These findings indicate that LLM-based generation of physics-constrained neural networks can substantially reduce the expertise required for constitutive modeling and represent a step toward practical end-to-end automation.",
    "published": "2025-12-01T14:42:22Z",
    "updated": "2025-12-01T14:42:22Z",
    "link": "http://arxiv.org/pdf/2512.01735v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Marius Tacke",
      "Matthias Busch",
      "Kian Abdolazizi",
      "Jonas Eichinger",
      "Kevin Linka",
      "Christian Cyron",
      "Roland Aydin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01732v1",
    "title": "Beyond Scaffold: A Unified Spatio-Temporal Gradient Tracking Method",
    "summary": "In distributed and federated learning algorithms, communication overhead is often reduced by performing multiple local updates between communication rounds. However, due to data heterogeneity across nodes and the local gradient noise within each node, this strategy can lead to the drift of local models away from the global optimum. To address this issue, we revisit the well-known federated learning method Scaffold (Karimireddy et al., 2020) under a gradient tracking perspective, and propose a unified spatio-temporal gradient tracking algorithm, termed ST-GT, for distributed stochastic optimization over time-varying graphs. ST-GT tracks the global gradient across neighboring nodes to mitigate data heterogeneity, while maintaining a running average of local gradients to substantially suppress noise, with slightly more storage overhead. Without assuming bounded data heterogeneity, we prove that ST-GT attains a linear convergence rate for strongly convex problems and a sublinear rate for nonconvex cases. Notably, ST-GT achieves the first linear speed-up in communication complexity with respect to the number of local updates per round $τ$ for the strongly-convex setting. Compared to traditional gradient tracking methods, ST-GT reduces the topology-dependent noise term from $σ^2$ to $σ^2/τ$, where $σ^2$ denotes the noise level, thereby improving communication efficiency.",
    "published": "2025-12-01T14:40:03Z",
    "updated": "2025-12-01T14:40:03Z",
    "link": "http://arxiv.org/pdf/2512.01732v1.pdf",
    "category": [
      "cs.LG",
      "math.OC"
    ],
    "authors": [
      "Yan Huang",
      "Jinming Xu",
      "Jiming Chen",
      "Karl Henrik Johansson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01716v1",
    "title": "Common Structure Discovery in Collections of Bipartite Networks: Application to Pollination Systems",
    "summary": "Bipartite networks are widely used to encode the ecological interactions. Being able to compare the organization of bipartite networks is a first step toward a better understanding of how environmental factors shape community structure and resilience. Yet current methods for structure detection in bipartite networks overlook shared patterns across collections of networks. We introduce the \\emph{colBiSBM}, a family of probabilistic models for collections of bipartite networks that extends the classical Latent Block Model (LBM). The proposed framework assumes that networks are independent realizations of a shared mesoscale structure, encoded through common inter-block connectivity parameters. We establish identifiability conditions for the different variants of \\emph{colBiSBM} and develop a variational EM algorithm for parameter estimation, coupled with an adaptation of the Integrated Classification Likelihood (ICL) criterion for model selection. We demonstrate how our approach can be used to classify networks based on their topology or organization. Simulation studies highlight the ability of \\emph{colBiSBM} to recover common structures, improve clustering performance, and enhance link prediction by borrowing strength across networks. An application to plant--pollinator networks highlights how the method uncovers shared ecological roles and partitions networks into sub-collections with similar connectivity patterns. These results illustrate the methodological and practical advantages of joint modeling over separate network analyses in the study of bipartite systems.",
    "published": "2025-12-01T14:22:10Z",
    "updated": "2025-12-01T14:22:10Z",
    "link": "http://arxiv.org/pdf/2512.01716v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "stat.AP"
    ],
    "authors": [
      "Louis Lacoste",
      "Pierre Barbillon",
      "Sophie Donnet"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01708v1",
    "title": "Differentially Private and Federated Structure Learning in Bayesian Networks",
    "summary": "Learning the structure of a Bayesian network from decentralized data poses two major challenges: (i) ensuring rigorous privacy guarantees for participants, and (ii) avoiding communication costs that scale poorly with dimensionality. In this work, we introduce Fed-Sparse-BNSL, a novel federated method for learning linear Gaussian Bayesian network structures that addresses both challenges. By combining differential privacy with greedy updates that target only a few relevant edges per participant, Fed-Sparse-BNSL efficiently uses the privacy budget while keeping communication costs low. Our careful algorithmic design preserves model identifiability and enables accurate structure estimation. Experiments on synthetic and real datasets demonstrate that Fed-Sparse-BNSL achieves utility close to non-private baselines while offering substantially stronger privacy and communication efficiency.",
    "published": "2025-12-01T14:15:56Z",
    "updated": "2025-12-01T14:15:56Z",
    "link": "http://arxiv.org/pdf/2512.01708v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Ghita Fassy El Fehri",
      "Aurélien Bellet",
      "Philippe Bastien"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.02980v2",
    "title": "Non-stationary Bandit Convex Optimization: A Comprehensive Study",
    "summary": "Bandit Convex Optimization is a fundamental class of sequential decision-making problems, where the learner selects actions from a continuous domain and observes a loss (but not its gradient) at only one point per round. We study this problem in non-stationary environments, and aim to minimize the regret under three standard measures of non-stationarity: the number of switches $S$ in the comparator sequence, the total variation $Δ$ of the loss functions, and the path-length $P$ of the comparator sequence. We propose a polynomial-time algorithm, Tilted Exponentially Weighted Average with Sleeping Experts (TEWA-SE), which adapts the sleeping experts framework from online convex optimization to the bandit setting. For strongly convex losses, we prove that TEWA-SE is minimax-optimal with respect to known $S$ and $Δ$ by establishing matching upper and lower bounds. By equipping TEWA-SE with the Bandit-over-Bandit framework, we extend our analysis to environments with unknown non-stationarity measures. For general convex losses, we introduce a second algorithm, clipped Exploration by Optimization (cExO), based on exponential weights over a discretized action space. While not polynomial-time computable, this method achieves minimax-optimal regret with respect to known $S$ and $Δ$, and improves on the best existing bounds with respect to $P$.",
    "published": "2025-06-03T15:18:41Z",
    "updated": "2025-12-01T14:10:55Z",
    "link": "http://arxiv.org/pdf/2506.02980v2.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Xiaoqi Liu",
      "Dorian Baudry",
      "Julian Zimmert",
      "Patrick Rebeschini",
      "Arya Akhavan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.00837v2",
    "title": "IberFire -- a detailed creation of a spatio-temporal dataset for wildfire risk assessment in Spain",
    "summary": "Wildfires pose a threat to ecosystems, economies and public safety, particularly in Mediterranean regions such as Spain. Accurate predictive models require high-resolution spatio-temporal data to capture complex dynamics of environmental and human factors. To address the scarcity of fine-grained wildfire datasets in Spain, we introduce IberFire: a spatio-temporal dataset with 1 km x 1 km x 1-day resolution, covering mainland Spain and the Balearic Islands from December 2007 to December 2024. IberFire integrates 120 features across eight categories: auxiliary data, fire history, geography, topography, meteorology, vegetation indices, human activity and land cover. All features and processing rely on open-access data and tools, with a publicly available codebase ensuring transparency and applicability. IberFire offers enhanced spatial granularity and feature diversity compared to existing European datasets, and provides a reproducible framework. It supports advanced wildfire risk modelling via Machine Learning and Deep Learning, facilitates climate trend analysis, and informs fire prevention and land management strategies. The dataset is freely available on Zenodo to promote open research and collaboration.",
    "published": "2025-05-01T19:54:17Z",
    "updated": "2025-12-01T14:08:28Z",
    "link": "http://arxiv.org/pdf/2505.00837v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Julen Erzibengoa",
      "Meritxell Gómez-Omella",
      "Izaro Goienetxea"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01702v1",
    "title": "A unified framework for geometry-independent operator learning in cardiac electrophysiology simulations",
    "summary": "Accurate maps of atrial electrical activation are essential for personalised treatment of arrhythmias, yet biophysically detailed simulations remain computationally intensive for real-time clinical use or population-scale analyses. Here we introduce a geometry-independent operator-learning framework that predicts local activation time (LAT) fields across diverse left atrial anatomies with near-instantaneous inference. We generated a dataset of 308,700 simulations using a GPU-accelerated electrophysiology solver, systematically varying multiple pacing sites and physiologically varied conduction properties across 147 patient-specific geometries derived from two independent clinical cohorts. All anatomical and functional data are expressed in a Universal Atrium Coordinate system, providing a consistent representation that decouples electrophysiological patterns from mesh topology. Within this coordinate space, we designed a neural operator with a vision-transformer backbone to learn the mapping from structural and electrophysiological inputs to LAT fields. With a mean prediction error of 5.1 ms over a 455 ms maximum simulation time, the model outperforms established operator-learning approaches and performs inference in 0.12 ms per sample. Our framework establishes a general strategy for learning domain-invariant biophysical mappings across variable anatomical domains and enables integration of computational electrophysiology into real-time and large-scale clinical workflows.",
    "published": "2025-12-01T14:07:39Z",
    "updated": "2025-12-01T14:07:39Z",
    "link": "http://arxiv.org/pdf/2512.01702v1.pdf",
    "category": [
      "cs.LG",
      "eess.IV"
    ],
    "authors": [
      "Bei Zhou",
      "Cesare Corrado",
      "Shuang Qian",
      "Maximilian Balmus",
      "Angela W. C. Lee",
      "Cristobal Rodero",
      "Marco J. W. Gotte",
      "Luuk H. G. A. Hopman",
      "Mengyun Qiao",
      "Steven Niederer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2406.11569v6",
    "title": "Pre-Training and Personalized Fine-Tuning via Over-the-Air Federated Meta-Learning: Convergence-Generalization Trade-Offs",
    "summary": "For modern artificial intelligence (AI) applications such as large language models (LLMs), the training paradigm has recently shifted to pre-training followed by fine-tuning. Furthermore, owing to dwindling open repositories of data and thanks to efforts to democratize access to AI models, pre-training is expected to increasingly migrate from the current centralized deployments to federated learning (FL) implementations. Meta-learning provides a general framework in which pre-training and fine-tuning can be formalized. Meta-learning-based personalized FL (meta-pFL) moves beyond basic personalization by targeting generalization to new agents and tasks. This paper studies the generalization performance of meta-pFL for a wireless setting in which the agents participating in the pre-training phase, i.e., meta-learning, are connected via a shared wireless channel to the server. Adopting over-the-air computing, we study the trade-off between generalization to new agents and tasks, on the one hand, and convergence, on the other hand. The trade-off arises from the fact that channel impairments may enhance generalization, while degrading convergence. Extensive numerical results validate the theory.",
    "published": "2024-06-17T14:06:13Z",
    "updated": "2025-12-01T14:05:17Z",
    "link": "http://arxiv.org/pdf/2406.11569v6.pdf",
    "category": [
      "cs.LG",
      "cs.IT",
      "eess.SP"
    ],
    "authors": [
      "Haifeng Wen",
      "Hong Xing",
      "Osvaldo Simeone"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01678v1",
    "title": "Morphling: Fast, Fused, and Flexible GNN Training at Scale",
    "summary": "Graph Neural Networks (GNNs) present a fundamental hardware challenge by fusing irregular, memory-bound graph traversals with regular, compute-intensive dense matrix operations. While frameworks such as PyTorch Geometric (PyG) and Deep Graph Library (DGL) prioritize high-level usability, they fail to address these divergent execution characteristics. As a result, they rely on generic kernels that suffer from poor cache locality, excessive memory movement, and substantial intermediate allocations. To address these limitations, we present Morphling, a domain-specific code synthesizer designed to bridge this gap. Morphling compiles high-level GNN specifications into portable, backend-specialized implementations targeting OpenMP, CUDA, and MPI. It achieves this by instantiating a library of optimized, architecture-aware primitives tailored to each execution environment. Morphling also incorporates a runtime sparsity-aware execution engine that dynamically selects dense or sparse execution paths using input feature statistics, reducing unnecessary computation on zero-valued entries. We evaluate Morphling on eleven real-world datasets spanning diverse graph structures, feature dimensionalities, and sparsity regimes. The results show that Morphling improves per-epoch training throughput by an average of 20X on CPUs and 19X on GPUs over PyG and DGL, with peak speedups reaching 66X. Morphling's memory-efficient layouts further reduce peak memory consumption by up to 15X, enabling large-scale GNN training on commodity hardware. These findings demonstrate that specialized, architecture-aware code synthesis provides an effective and scalable path toward high-performance GNN execution across diverse parallel and distributed platforms.",
    "published": "2025-12-01T13:45:03Z",
    "updated": "2025-12-01T13:45:03Z",
    "link": "http://arxiv.org/pdf/2512.01678v1.pdf",
    "category": [
      "cs.LG",
      "cs.DC",
      "cs.PL"
    ],
    "authors": [
      " Anubhab",
      "Rupesh Nasre"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01660v1",
    "title": "Bayesian Ambiguity Contraction-based Adaptive Robust Markov Decision Processes for Adversarial Surveillance Missions",
    "summary": "Collaborative Combat Aircraft (CCAs) are envisioned to enable autonomous Intelligence, Surveillance, and Reconnaissance (ISR) missions in contested environments, where adversaries may act strategically to deceive or evade detection. These missions pose challenges due to model uncertainty and the need for safe, real-time decision-making. Robust Markov Decision Processes (RMDPs) provide worst-case guarantees but are limited by static ambiguity sets that capture initial uncertainty without adapting to new observations. This paper presents an adaptive RMDP framework tailored to ISR missions with CCAs. We introduce a mission-specific formulation in which aircraft alternate between movement and sensing states. Adversarial tactics are modeled as a finite set of transition kernels, each capturing assumptions about how adversarial sensing or environmental conditions affect rewards. Our approach incrementally refines policies by eliminating inconsistent threat models, allowing agents to shift from conservative to aggressive behaviors while maintaining robustness. We provide theoretical guarantees showing that the adaptive planner converges as credible sets contract to the true threat and maintains safety under uncertainty. Experiments under Gaussian and non-Gaussian threat models across diverse network topologies show higher mission rewards and fewer exposure events compared to nominal and static robust planners.",
    "published": "2025-12-01T13:31:40Z",
    "updated": "2025-12-01T13:31:40Z",
    "link": "http://arxiv.org/pdf/2512.01660v1.pdf",
    "category": [
      "math.OC",
      "cs.LG",
      "eess.SY"
    ],
    "authors": [
      "Jimin Choi",
      "Max Z. Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2403.07728v5",
    "title": "CAP: A General Algorithm for Online Selective Conformal Prediction with FCR Control",
    "summary": "We study the problem of post-selection predictive inference in an online fashion. To avoid devoting resources to unimportant units, a preliminary selection of the current individual before reporting its prediction interval is common and meaningful in online predictive tasks. Since the online selection causes a temporal multiplicity in the selected prediction intervals, it is important to control the real-time false coverage-statement rate (FCR) which measures the overall miscoverage level. We develop a general framework named CAP (Calibration after Adaptive Pick) that performs an adaptive pick rule on historical data to construct a calibration set if the current individual is selected and then outputs a conformal prediction interval for the unobserved label. We provide tractable procedures for constructing the calibration set for popular online selection rules. We proved that CAP can achieve an exact selection-conditional coverage guarantee in the finite-sample and distribution-free regimes. To account for the distribution shift in online data, we also embed CAP into some recent dynamic conformal prediction algorithms and show that the proposed method can deliver long-run FCR control. Numerical results on both synthetic and real data corroborate that CAP can effectively control FCR around the target level and yield more narrowed prediction intervals over existing baselines across various settings.",
    "published": "2024-03-12T15:07:20Z",
    "updated": "2025-12-01T13:30:26Z",
    "link": "http://arxiv.org/pdf/2403.07728v5.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "authors": [
      "Yajie Bao",
      "Yuyang Huo",
      "Haojie Ren",
      "Changliang Zou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01653v1",
    "title": "Cuffless Blood Pressure Estimation from Six Wearable Sensor Modalities in Multi-Motion-State Scenarios",
    "summary": "Cardiovascular disease (CVD) is a leading cause of morbidity and mortality worldwide, and sustained hypertension is an often silent risk factor, making cuffless continuous blood pressure (BP) monitoring with wearable devices important for early screening and long-term management. Most existing cuffless BP estimation methods use only photoplethysmography (PPG) and electrocardiography (ECG) signals, alone or in combination. These models are typically developed under resting or quasi-static conditions and struggle to maintain robust accuracy in multi-motion-state scenarios. In this study, we propose a six-modal BP estimation framework that jointly leverages ECG, multi-channel PPG, attachment pressure, sensor temperature, and triaxial acceleration and angular velocity. Each modality is processed by a lightweight branch encoder, contrastive learning enforces cross-modal semantic alignment, and a mixture-of-experts (MoE) regression head adaptively maps the fused features to BP across motion states. Comprehensive experiments on the public Pulse Transit Time PPG Dataset, which includes running, walking, and sitting data from 22 subjects, show that the proposed method achieves mean absolute errors (MAE) of 3.60 mmHg for systolic BP (SBP) and 3.01 mmHg for diastolic BP (DBP). From a clinical perspective, it attains Grade A for SBP, DBP, and mean arterial pressure (MAP) according to the British Hypertension Society (BHS) protocol and meets the numerical criteria of the Association for the Advancement of Medical Instrumentation (AAMI) standard for mean error (ME) and standard deviation of error (SDE).",
    "published": "2025-12-01T13:26:30Z",
    "updated": "2025-12-01T13:26:30Z",
    "link": "http://arxiv.org/pdf/2512.01653v1.pdf",
    "category": [
      "eess.SP",
      "cs.LG"
    ],
    "authors": [
      "Yiqiao Chen",
      "Fazheng Xu",
      "Zijian Huang",
      "Juchi He",
      "Zhenghui Feng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2209.14790v4",
    "title": "Sparse PCA With Multiple Components",
    "summary": "Sparse Principal Component Analysis (sPCA) is a cardinal technique for obtaining combinations of features, or principal components (PCs), that explain the variance of high-dimensional datasets in an interpretable manner. This involves solving a sparsity and orthogonality constrained convex maximization problem, which is extremely computationally challenging. Most existing works address sparse PCA via methods-such as iteratively computing one sparse PC and deflating the covariance matrix-that do not guarantee the orthogonality, let alone the optimality, of the resulting solution when we seek multiple mutually orthogonal PCs. We challenge this status by reformulating the orthogonality conditions as rank constraints and optimizing over the sparsity and rank constraints simultaneously. We design tight semidefinite relaxations to supply high-quality upper bounds, which we strengthen via additional second-order cone inequalities when each PC's individual sparsity is specified. Further, we derive a combinatorial upper bound on the maximum amount of variance explained as a function of the support. We exploit these relaxations and bounds to propose exact methods and rounding mechanisms that, together, obtain solutions with a bound gap on the order of 0%-15% for real-world datasets with p = 100s or 1000s of features and r \\in {2, 3} components. Numerically, our algorithms match (and sometimes surpass) the best performing methods in terms of fraction of variance explained and systematically return PCs that are sparse and orthogonal. In contrast, we find that existing methods like deflation return solutions that violate the orthogonality constraints, even when the data is generated according to sparse orthogonal PCs. Altogether, our approach solves sparse PCA problems with multiple components to certifiable (near) optimality in a practically tractable fashion.",
    "published": "2022-09-29T13:57:18Z",
    "updated": "2025-12-01T13:24:03Z",
    "link": "http://arxiv.org/pdf/2209.14790v4.pdf",
    "category": [
      "math.OC",
      "cs.LG",
      "math.ST",
      "stat.ML"
    ],
    "authors": [
      "Ryan Cory-Wright",
      "Jean Pauphilet"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01650v1",
    "title": "In-context Inverse Optimality for Fair Digital Twins: A Preference-based approach",
    "summary": "Digital Twins (DTs) are increasingly used as autonomous decision-makers in complex socio-technical systems. Their mathematically optimal decisions often diverge from human expectations, exposing a persistent gap between algorithmic and bounded human rationality. This work addresses this gap by proposing a framework that operationalizes fairness as a learnable objective within optimization-based Digital Twins. We introduce a preference-driven learning pipeline that infers latent fairness objectives directly from human pairwise preferences over feasible decisions. A novel Siamese neural network is developed to generate convex quadratic cost functions conditioned on contextual information. The resulting surrogate objectives align optimization outcomes with human-perceived fairness while maintaining computational efficiency. The approach is demonstrated on a COVID-19 hospital resource allocation scenario. This study provides an actionable path toward embedding human-centered fairness in the design of autonomous decision-making systems.",
    "published": "2025-12-01T13:23:27Z",
    "updated": "2025-12-01T13:23:27Z",
    "link": "http://arxiv.org/pdf/2512.01650v1.pdf",
    "category": [
      "cs.LG",
      "cs.SE",
      "math.OC"
    ],
    "authors": [
      "Daniele Masti",
      "Francesco Basciani",
      "Arianna Fedeli",
      "Girgio Gnecco",
      "Francesco Smarra"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.01002v2",
    "title": "Optimal Scheduling Algorithms for LLM Inference: Theory and Practice",
    "summary": "With the growing use of Large Language Model (LLM)-based tools like ChatGPT, Perplexity, and Gemini across industries, there is a rising need for efficient LLM inference systems. These systems handle requests with a unique two-phase computation structure: a prefill-phase that processes the full input prompt and a decode-phase that autoregressively generates tokens one at a time. This structure calls for new strategies for routing and scheduling requests.\n  In this paper, we take a comprehensive approach to this challenge by developing a theoretical framework that models routing and scheduling in LLM inference systems. We identify two key design principles-optimal tiling and dynamic resource allocation-that are essential for achieving high throughput. Guided by these principles, we propose the Resource-Aware Dynamic (RAD) scheduler and prove that it achieves throughput optimality under mild conditions. To address practical Service Level Objectives (SLOs) such as serving requests with different Time Between Token (TBT) constraints, we design the SLO-Aware LLM Inference (SLAI) scheduler. SLAI uses real-time measurements to prioritize decode requests that are close to missing their TBT deadlines and reorders prefill requests based on known prompt lengths to further reduce the Time To First Token (TTFT) delays.\n  We evaluate SLAI on the Openchat ShareGPT4 dataset using the Mistral-7B model on an NVIDIA RTX ADA 6000 GPU. Compared to Sarathi-Serve, SLAI reduces the median TTFT by 53% and increases the maximum serving capacity by 26% such that median TTFT is below 0.5 seconds, while meeting tail TBT latency constraints.",
    "published": "2025-08-01T18:12:21Z",
    "updated": "2025-12-01T13:16:28Z",
    "link": "http://arxiv.org/pdf/2508.01002v2.pdf",
    "category": [
      "cs.LG",
      "cs.DC"
    ],
    "authors": [
      "Agrim Bari",
      "Parikshit Hegde",
      "Gustavo de Veciana"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.04097v2",
    "title": "Do Vision-Language Models Leak What They Learn? Adaptive Token-Weighted Model Inversion Attacks",
    "summary": "Model inversion (MI) attacks pose significant privacy risks by reconstructing private training data from trained neural networks. While prior studies have primarily examined unimodal deep networks, the vulnerability of vision-language models (VLMs) remains largely unexplored. In this work, we present the first systematic study of MI attacks on VLMs to understand their susceptibility to leaking private visual training data. Our work makes two main contributions. First, tailored to the token-generative nature of VLMs, we introduce a suite of token-based and sequence-based model inversion strategies, providing a comprehensive analysis of VLMs' vulnerability under different attack formulations. Second, based on the observation that tokens vary in their visual grounding, and hence their gradients differ in informativeness for image reconstruction, we propose Sequence-based Model Inversion with Adaptive Token Weighting (SMI-AW) as a novel MI for VLMs. SMI-AW dynamically reweights each token's loss gradient according to its visual grounding, enabling the optimization to focus on visually informative tokens and more effectively guide the reconstruction of private images. Through extensive experiments and human evaluations on a range of state-of-the-art VLMs across multiple datasets, we show that VLMs are susceptible to training data leakage. Human evaluation of the reconstructed images yields an attack accuracy of 61.21%, underscoring the severity of these privacy risks. Notably, we demonstrate that publicly released VLMs are vulnerable to such attacks. Our study highlights the urgent need for privacy safeguards as VLMs become increasingly deployed in sensitive domains such as healthcare and finance. Additional experiments are provided in Supp.",
    "published": "2025-08-06T05:30:05Z",
    "updated": "2025-12-01T13:16:25Z",
    "link": "http://arxiv.org/pdf/2508.04097v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Ngoc-Bao Nguyen",
      "Sy-Tuyen Ho",
      "Koh Jun Hao",
      "Ngai-Man Cheung"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2407.13849v2",
    "title": "CoxSE: Exploring the Potential of Self-Explaining Neural Networks with Cox Proportional Hazards Model for Survival Analysis",
    "summary": "The Cox Proportional Hazards (CPH) model has long been the preferred survival model for its explainability. However, to increase its predictive power beyond its linear log-risk, it was extended to utilize deep neural networks, sacrificing its explainability. In this work, we explore the potential of self-explaining neural networks (SENN) for survival analysis. We propose a new locally explainable Cox proportional hazards model, named CoxSE, by estimating a locally-linear log-hazard function using the SENN. We also propose a modification to the Neural additive (NAM) model, hybrid with SENN, named CoxSENAM, which enables the control of the stability and consistency of the generated explanations.\n  Several experiments using synthetic and real datasets are presented, benchmarking CoxSE and CoxSENAM against a NAM-based model, a DeepSurv model explained with SHAP, and a linear CPH model. The results show that, unlike the NAM-based model, the SENN-based model can provide more stable and consistent explanations while maintaining the predictive power of the black-box model. The results also show that, due to their structural design, NAM-based models demonstrate better robustness to non-informative features. Among the models, the hybrid model exhibits the best robustness.",
    "published": "2024-07-18T18:32:54Z",
    "updated": "2025-12-01T12:27:50Z",
    "link": "http://arxiv.org/pdf/2407.13849v2.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Abdallah Alabdallah",
      "Omar Hamed",
      "Mattias Ohlsson",
      "Thorsteinn Rögnvaldsson",
      "Sepideh Pashami"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.15858v2",
    "title": "Optimizing Product Deduplication in E-Commerce with Multimodal Embeddings",
    "summary": "In large scale e-commerce marketplaces, duplicate product listings frequently cause consumer confusion and operational inefficiencies, degrading trust on the platform and increasing costs. Traditional keyword-based search methodologies falter in accurately identifying duplicates due to their reliance on exact textual matches, neglecting semantic similarities inherent in product titles. To address these challenges, we introduce a scalable, multimodal product deduplication designed specifically for the e-commerce domain. Our approach employs a domain-specific text model grounded in BERT architecture in conjunction with MaskedAutoEncoders for image representations. Both of these architectures are augmented with dimensionality reduction techniques to produce compact 128-dimensional embeddings without significant information loss. Complementing this, we also developed a novel decider model that leverages both text and image vectors. By integrating these feature extraction mechanisms with Milvus, an optimized vector database, our system can facilitate efficient and high-precision similarity searches across extensive product catalogs exceeding 200 million items with just 100GB of system RAM consumption. Empirical evaluations demonstrate that our matching system achieves a macro-average F1 score of 0.90, outperforming third-party solutions which attain an F1 score of 0.83. Our findings show the potential of combining domain-specific adaptations with state-of-the-art machine learning techniques to mitigate duplicate listings in large-scale e-commerce environments.",
    "published": "2025-09-19T10:49:39Z",
    "updated": "2025-12-01T12:23:38Z",
    "link": "http://arxiv.org/pdf/2509.15858v2.pdf",
    "category": [
      "cs.IR",
      "cs.LG"
    ],
    "authors": [
      "Aysenur Kulunk",
      "Berk Taskin",
      "M. Furkan Eseoglu",
      "H. Bahadir Sahin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.01331v2",
    "title": "RobustVLA: Robustness-Aware Reinforcement Post-Training for Vision-Language-Action Models",
    "summary": "Vision-Language-Action (VLA) models have recently emerged as powerful general-purpose policies for robotic manipulation, benefiting from large-scale multi-modal pre-training. However, they often fail to generalize reliably in out-of-distribution deployments, where unavoidable disturbances such as observation noise, sensor errors, or actuation perturbations become prevalent. While recent Reinforcement Learning (RL)-based post-training provides a practical means to adapt pre-trained VLA models, existing methods mainly emphasize reward maximization and overlook robustness to environmental uncertainty. In this work, we introduce RobustVLA, a lightweight online RL post-training method designed to explicitly enhance the resilience of VLA models. Through a systematic robustness analysis, we identify two key regularizations: Jacobian regularization, which mitigates sensitivity to observation noise, and smoothness regularization, which stabilizes policies under action perturbations. Extensive experiments across diverse robotic environments demonstrate that RobustVLA significantly outperforms prior state-of-the-art methods in robustness and reliability. Our results highlight the importance of principled robustness-aware RL post-training as a key step toward improving the reliability and robustness of VLA models.",
    "published": "2025-11-03T08:30:48Z",
    "updated": "2025-12-01T12:13:52Z",
    "link": "http://arxiv.org/pdf/2511.01331v2.pdf",
    "category": [
      "cs.RO",
      "cs.LG"
    ],
    "authors": [
      "Hongyin Zhang",
      "Shuo Zhang",
      "Junxi Jin",
      "Qixin Zeng",
      "Runze Li",
      "Donglin Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01591v1",
    "title": "Scaling and context steer LLMs along the same computational path as the human brain",
    "summary": "Recent studies suggest that the representations learned by large language models (LLMs) are partially aligned to those of the human brain. However, whether and why this alignment score arises from a similar sequence of computations remains elusive. In this study, we explore this question by examining temporally-resolved brain signals of participants listening to 10 hours of an audiobook. We study these neural dynamics jointly with a benchmark encompassing 22 LLMs varying in size and architecture type. Our analyses confirm that LLMs and the brain generate representations in a similar order: specifically, activations in the initial layers of LLMs tend to best align with early brain responses, while the deeper layers of LLMs tend to best align with later brain responses. This brain-LLM alignment is consistent across transformers and recurrent architectures. However, its emergence depends on both model size and context length. Overall, this study sheds light on the sequential nature of computations and the factors underlying the partial convergence between biological and artificial neural networks.",
    "published": "2025-12-01T12:05:01Z",
    "updated": "2025-12-01T12:05:01Z",
    "link": "http://arxiv.org/pdf/2512.01591v1.pdf",
    "category": [
      "cs.LG",
      "q-bio.NC"
    ],
    "authors": [
      "Joséphine Raugel",
      "Stéphane d'Ascoli",
      "Jérémy Rapin",
      "Valentin Wyart",
      "Jean-Rémi King"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13339v2",
    "title": "Statistically Accurate and Robust Generative Prediction of Rock Discontinuities with A Tabular Foundation Model",
    "summary": "Rock discontinuities critically govern the mechanical behavior and stability of rock masses. Their internal distributions remain largely unobservable and are typically inferred from surface-exposed discontinuities using generative prediction approaches. However, surface-exposed observations are inherently sparse, and existing generative prediction approaches either fail to capture the underlying complex distribution patterns or lack robustness under data-sparse conditions. Here, we proposed a simple yet robust approach for statistically accurate generative prediction of rock discontinuities by utilizing a tabular foundation model. By leveraging the powerful sample learning capability of the foundation model specifically designed for small data, our approach can effectively capture the underlying complex distribution patterns within limited measured discontinuities. Comparative experiments on ten datasets with diverse scales and distribution patterns of discontinuities demonstrate superior accuracy and robustness over conventional statistical models and deep generative approaches. This work advances quantitative characterization of rock mass structures, supporting safer and more reliable data-driven geotechnical design.",
    "published": "2025-11-17T13:09:53Z",
    "updated": "2025-12-01T11:55:48Z",
    "link": "http://arxiv.org/pdf/2511.13339v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Han Meng",
      "Gang Mei",
      "Hong Tian",
      "Nengxiong Xu",
      "Jianbing Peng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01568v1",
    "title": "Do Large Language Models Walk Their Talk? Measuring the Gap Between Implicit Associations, Self-Report, and Behavioral Altruism",
    "summary": "We investigate whether Large Language Models (LLMs) exhibit altruistic tendencies, and critically, whether their implicit associations and self-reports predict actual altruistic behavior. Using a multi-method approach inspired by human social psychology, we tested 24 frontier LLMs across three paradigms: (1) an Implicit Association Test (IAT) measuring implicit altruism bias, (2) a forced binary choice task measuring behavioral altruism, and (3) a self-assessment scale measuring explicit altruism beliefs. Our key findings are: (1) All models show strong implicit pro-altruism bias (mean IAT = 0.87, p < .0001), confirming models \"know\" altruism is good. (2) Models behave more altruistically than chance (65.6% vs. 50%, p < .0001), but with substantial variation (48-85%). (3) Implicit associations do not predict behavior (r = .22, p = .29). (4) Most critically, models systematically overestimate their own altruism, claiming 77.5% altruism while acting at 65.6% (p < .0001, Cohen's d = 1.08). This \"virtue signaling gap\" affects 75% of models tested. Based on these findings, we recommend the Calibration Gap (the discrepancy between self-reported and behavioral values) as a standardized alignment metric. Well-calibrated models are more predictable and behaviorally consistent; only 12.5% of models achieve the ideal combination of high prosocial behavior and accurate self-knowledge.",
    "published": "2025-12-01T11:43:02Z",
    "updated": "2025-12-01T11:43:02Z",
    "link": "http://arxiv.org/pdf/2512.01568v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Sandro Andric"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01562v1",
    "title": "TimePred: efficient and interpretable offline change point detection for high volume data - with application to industrial process monitoring",
    "summary": "Change-point detection (CPD) in high-dimensional, large-volume time series is challenging for statistical consistency, scalability, and interpretability. We introduce TimePred, a self-supervised framework that reduces multivariate CPD to univariate mean-shift detection by predicting each sample's normalized time index. This enables efficient offline CPD using existing algorithms and supports the integration of XAI attribution methods for feature-level explanations. Our experiments show competitive CPD performance while reducing computational cost by up to two orders of magnitude. In an industrial manufacturing case study, we demonstrate improved detection accuracy and illustrate the practical value of interpretable change-point insights.",
    "published": "2025-12-01T11:35:48Z",
    "updated": "2025-12-01T11:35:48Z",
    "link": "http://arxiv.org/pdf/2512.01562v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Simon Leszek"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01518v1",
    "title": "End-to-end Deep Reinforcement Learning for Stochastic Multi-objective Optimization in C-VRPTW",
    "summary": "In this work, we consider learning-based applications in routing to solve a Vehicle Routing variant characterized by stochasticity and multiple objectives. Such problems are representative of practical settings where decision-makers have to deal with uncertainty in the operational environment as well as multiple conflicting objectives due to different stakeholders. We specifically consider travel time uncertainty. We also consider two objectives, total travel time and route makespan, that jointly target operational efficiency and labor regulations on shift length, although different objectives could be incorporated. Learning-based methods offer earnest computational advantages as they can repeatedly solve problems with limited interference from the decision-maker. We specifically focus on end-to-end deep learning models that leverage the attention mechanism and multiple solution trajectories. These models have seen several successful applications in routing problems. However, since travel times are not a direct input to these models due to the large dimensions of the travel time matrix, accounting for uncertainty is a challenge, especially in the presence of multiple objectives. In turn, we propose a model that simultaneously addresses stochasticity and multi-objectivity and provide a refined training mechanism for this model through scenario clustering to reduce training time. Our results show that our model is capable of constructing a Pareto Front of good quality within acceptable run times compared to three baselines.",
    "published": "2025-12-01T10:43:27Z",
    "updated": "2025-12-01T10:43:27Z",
    "link": "http://arxiv.org/pdf/2512.01518v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Abdo Abouelrous",
      "Laurens Bliek",
      "Yaoxin Wu",
      "Yingqian Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01517v1",
    "title": "Neural Networks for Predicting Permeability Tensors of 2D Porous Media: Comparison of Convolution- and Transformer-based Architectures",
    "summary": "Permeability is a central concept in the macroscopic description of flow through porous media, with applications spanning from oil recovery to hydrology. Traditional methods for determining the permeability tensor involving flow simulations or experiments can be time consuming and resource-intensive, while analytical methods, e.g., based on the Kozeny-Carman equation, may be too simplistic for accurate prediction based on pore-scale features. In this work, we explore deep learning as a more efficient alternative for predicting the permeability tensor based on two-dimensional binary images of porous media, segmented into solid ($1$) and void ($0$) regions. We generate a dataset of 24,000 synthetic random periodic porous media samples with specified porosity and characteristic length scale. Using Lattice-Boltzmann simulations, we compute the permeability tensor for flow through these samples with values spanning three orders of magnitude. We evaluate three families of image-based deep learning models: ResNet (ResNet-$50$ and ResNet-$101$), Vision Transformers (ViT-T$16$ and ViT-S$16$) and ConvNeXt (Tiny and Small). To improve model generalisation, we employ techniques such as weight decay, learning rate scheduling, and data augmentation. The effect of data augmentation and dataset size on model performance is studied, and we find that they generally increase the accuracy of permeability predictions. We also show that ConvNeXt and ResNet converge faster than ViT and degrade in performance if trained for too long. ConvNeXt-Small achieved the highest $R^2$ score of $0.99460$ on $4,000$ unseen test samples. These findings underscore the potential to use image-based neural networks to predict permeability tensors accurately.",
    "published": "2025-12-01T10:41:26Z",
    "updated": "2025-12-01T10:41:26Z",
    "link": "http://arxiv.org/pdf/2512.01517v1.pdf",
    "category": [
      "physics.flu-dyn",
      "cs.LG",
      "physics.comp-ph",
      "physics.geo-ph"
    ],
    "authors": [
      "Sigurd Vargdal",
      "Paula Reis",
      "Henrik Andersen Sveinsson",
      "Gaute Linga"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01514v1",
    "title": "Label Forensics: Interpreting Hard Labels in Black-Box Text Classifier",
    "summary": "The widespread adoption of natural language processing techniques has led to an unprecedented growth of text classifiers across the modern web. Yet many of these models circulate with their internal semantics undocumented or even intentionally withheld. Such opaque classifiers, which may expose only hard-label outputs, can operate in unregulated web environments or be repurposed for unknown intents, raising legitimate forensic and auditing concerns. In this paper, we position ourselves as investigators and work to infer the semantic concept each label encodes in an undocumented black-box classifier.\n  Specifically, we introduce label forensics, a black-box framework that reconstructs a label's semantic meaning. Concretely, we represent a label by a sentence embedding distribution from which any sample reliably reflects the concept the classifier has implicitly learned for that label. We believe this distribution should maintain two key properties: precise, with samples consistently classified into the target label, and general, covering the label's broad semantic space. To realize this, we design a semantic neighborhood sampler and an iterative optimization procedure to select representative seed sentences that jointly maximize label consistency and distributional coverage. The final output, an optimized seed sentence set combined with the sampler, constitutes the empirical distribution representing the label's semantics. Experiments on multiple black-box classifiers achieve an average label consistency of around 92.24 percent, demonstrating that the embedding regions accurately capture each classifier's label semantics. We further validate our framework on an undocumented HuggingFace classifier, enabling fine-grained label interpretation and supporting responsible AI auditing.",
    "published": "2025-12-01T10:39:51Z",
    "updated": "2025-12-01T10:39:51Z",
    "link": "http://arxiv.org/pdf/2512.01514v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Mengyao Du",
      "Gang Yang",
      "Han Fang",
      "Quanjun Yin",
      "Ee-chien Chang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.16685v3",
    "title": "Compliant Residual DAgger: Improving Real-World Contact-Rich Manipulation with Human Corrections",
    "summary": "We address key challenges in Dataset Aggregation (DAgger) for real-world contact-rich manipulation: how to collect informative human correction data and how to effectively update policies with this new data. We introduce Compliant Residual DAgger (CR-DAgger), which contains two novel components: 1) a Compliant Intervention Interface that leverages compliance control, allowing humans to provide gentle, accurate delta action corrections without interrupting the ongoing robot policy execution; and 2) a Compliant Residual Policy formulation that learns from human corrections while incorporating force feedback and force control. Our system significantly enhances performance on precise contact-rich manipulation tasks using minimal correction data, improving base policy success rates by over 50\\% on two challenging tasks (book flipping and belt assembly) while outperforming both retraining-from-scratch and finetuning approaches. Through extensive real-world experiments, we provide practical guidance for implementing effective DAgger in real-world robot learning tasks. Result videos are available at: https://compliant-residual-dagger.github.io/",
    "published": "2025-06-20T01:57:47Z",
    "updated": "2025-12-01T10:37:47Z",
    "link": "http://arxiv.org/pdf/2506.16685v3.pdf",
    "category": [
      "cs.RO",
      "cs.LG"
    ],
    "authors": [
      "Xiaomeng Xu",
      "Yifan Hou",
      "Zeyi Liu",
      "Shuran Song"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.24886v2",
    "title": "Adaptive Canonicalization with Application to Invariant Anisotropic Geometric Networks",
    "summary": "Canonicalization is a widely used strategy in equivariant machine learning, enforcing symmetry in neural networks by mapping each input to a standard form. Yet, it often introduces discontinuities that can affect stability during training, limit generalization, and complicate universal approximation theorems. In this paper, we address this by introducing adaptive canonicalization, a general framework in which the canonicalization depends both on the input and the network. Specifically, we present the adaptive canonicalization based on prior maximization, where the standard form of the input is chosen to maximize the predictive confidence of the network. We prove that this construction yields continuous and symmetry-respecting models that admit universal approximation properties.\n  We propose two applications of our setting: (i) resolving eigenbasis ambiguities in spectral graph neural networks, and (ii) handling rotational symmetries in point clouds. We empirically validate our methods on molecular and protein classification, as well as point cloud classification tasks. Our adaptive canonicalization outperforms the three other common solutions to equivariant machine learning: data augmentation, standard canonicalization, and equivariant architectures.",
    "published": "2025-09-29T14:59:46Z",
    "updated": "2025-12-01T10:37:22Z",
    "link": "http://arxiv.org/pdf/2509.24886v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Ya-Wei Eileen Lin",
      "Ron Levie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01509v1",
    "title": "Learning Reduced Representations for Quantum Classifiers",
    "summary": "Data sets that are specified by a large number of features are currently outside the area of applicability for quantum machine learning algorithms. An immediate solution to this impasse is the application of dimensionality reduction methods before passing the data to the quantum algorithm. We investigate six conventional feature extraction algorithms and five autoencoder-based dimensionality reduction models to a particle physics data set with 67 features. The reduced representations generated by these models are then used to train a quantum support vector machine for solving a binary classification problem: whether a Higgs boson is produced in proton collisions at the LHC. We show that the autoencoder methods learn a better lower-dimensional representation of the data, with the method we design, the Sinkclass autoencoder, performing 40% better than the baseline. The methods developed here open up the applicability of quantum machine learning to a larger array of data sets. Moreover, we provide a recipe for effective dimensionality reduction in this context.",
    "published": "2025-12-01T10:34:41Z",
    "updated": "2025-12-01T10:34:41Z",
    "link": "http://arxiv.org/pdf/2512.01509v1.pdf",
    "category": [
      "quant-ph",
      "cs.LG",
      "hep-ex"
    ],
    "authors": [
      "Patrick Odagiu",
      "Vasilis Belis",
      "Lennart Schulze",
      "Panagiotis Barkoutsos",
      "Michele Grossi",
      "Florentin Reiter",
      "Günther Dissertori",
      "Ivano Tavernelli",
      "Sofia Vallecorsa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01500v1",
    "title": "Walking on the Fiber: A Simple Geometric Approximation for Bayesian Neural Networks",
    "summary": "Bayesian Neural Networks provide a principled framework for uncertainty quantification by modeling the posterior distribution of network parameters. However, exact posterior inference is computationally intractable, and widely used approximations like the Laplace method struggle with scalability and posterior accuracy in modern deep networks. In this work, we revisit sampling techniques for posterior exploration, proposing a simple variation tailored to efficiently sample from the posterior in over-parameterized networks by leveraging the low-dimensional structure of loss minima. Building on this, we introduce a model that learns a deformation of the parameter space, enabling rapid posterior sampling without requiring iterative methods. Empirical results demonstrate that our approach achieves competitive posterior approximations with improved scalability compared to recent refinement techniques. These contributions provide a practical alternative for Bayesian inference in deep learning.",
    "published": "2025-12-01T10:24:10Z",
    "updated": "2025-12-01T10:24:10Z",
    "link": "http://arxiv.org/pdf/2512.01500v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Alfredo Reichlin",
      "Miguel Vasco",
      "Danica Kragic"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.16554v3",
    "title": "Machine Learning Time Propagators for Time-Dependent Density Functional Theory Simulations",
    "summary": "Time-dependent density functional theory (TDDFT) is a widely used method to investigate electron dynamics under external time-dependent perturbations such as laser fields. In this work, we present a machine learning approach to accelerate electron dynamics simulations based on real time TDDFT using autoregressive neural operators as time-propagators for the electron density. By leveraging physics-informed constraints and featurization, and high-resolution training data, our model achieves superior accuracy and computational speed compared to traditional numerical solvers. We demonstrate the effectiveness of our model on a class of one-dimensional diatomic molecules under the influence of a range of laser parameters. This method has potential in enabling on-the-fly modeling of laser-irradiated molecules and materials by utilizing fast machine learning predictions in a large space of varying experimental parameters of the laser.",
    "published": "2025-08-22T17:22:24Z",
    "updated": "2025-12-01T10:21:54Z",
    "link": "http://arxiv.org/pdf/2508.16554v3.pdf",
    "category": [
      "cond-mat.mtrl-sci",
      "cs.LG",
      "physics.comp-ph"
    ],
    "authors": [
      "Karan Shah",
      "Attila Cangi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01498v1",
    "title": "Winning Solutions for the Rayan AI Contest: Compositional Retrieval, Zero-Shot Anomaly Detection, and Backdoor Detection",
    "summary": "This report presents solutions to three machine learning challenges: compositional image retrieval, zero-shot anomaly detection, and backdoored model detection. In compositional image retrieval, we developed a system that processes visual and textual inputs to retrieve relevant images, achieving 95.38\\% accuracy and ranking first with a clear margin over the second team. For zero-shot anomaly detection, we designed a model that identifies and localizes anomalies in images without prior exposure to abnormal examples, securing 1st place with 73.14\\% accuracy. In the backdoored model detection task, we proposed a method to detect hidden backdoor triggers in neural networks, reaching an accuracy of 78\\%, which placed our approach in second place. These results demonstrate the effectiveness of our methods in addressing key challenges related to retrieval, anomaly detection, and model security, with implications for real-world applications in industries such as healthcare, manufacturing, and cybersecurity. Code for all solutions is available online.",
    "published": "2025-12-01T10:19:30Z",
    "updated": "2025-12-01T10:19:30Z",
    "link": "http://arxiv.org/pdf/2512.01498v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Ali Nafisi",
      "Sina Asghari",
      "Mohammad Saeed Arvenaghi",
      "Hossein Shakibania"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01497v1",
    "title": "Heuristic algorithms for the stochastic critical node detection problem",
    "summary": "Given a network, the critical node detection problem finds a subset of nodes whose removal disrupts the network connectivity. Since many real-world systems are naturally modeled as graphs, assessing the vulnerability of the network is essential, with applications in transportation systems, traffic forecasting, epidemic control, and biological networks. In this paper, we consider a stochastic version of the critical node detection problem, where the existence of edges is given by certain probabilities. We propose heuristics and learning-based methods for the problem and compare them with existing algorithms. Experimental results performed on random graphs from small to larger scales, with edge-survival probabilities drawn from different distributions, demonstrate the effectiveness of the methods. Heuristic methods often illustrate the strongest results with high scalability, while learning-based methods maintain nearly constant inference time as the network size and density grow.",
    "published": "2025-12-01T10:18:24Z",
    "updated": "2025-12-01T10:18:24Z",
    "link": "http://arxiv.org/pdf/2512.01497v1.pdf",
    "category": [
      "cs.DM",
      "cs.LG"
    ],
    "authors": [
      "Tuguldur Bayarsaikhan",
      "Altannar Chinchuluun",
      "Ashwin Arulselvan",
      "Panos Pardalos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2404.13182v3",
    "title": "Spectral Convolutional Conditional Neural Processes",
    "summary": "Neural processes (NPs) are probabilistic meta-learning models that map sets of observations to posterior predictive distributions, enabling inference at arbitrary domain points. Their capacity to handle variable-sized collections of unstructured observations, combined with simple maximum-likelihood training and uncertainty-aware predictions, makes them well-suited for modeling data over continuous domains. Since their introduction, several variants have been proposed. Early approaches typically represented observed data using finite-dimensional summary embeddings obtained through aggregation schemes such as mean pooling. However, this strategy fundamentally mismatches the infinite-dimensional nature of the generative processes that NPs aim to capture. Convolutional conditional neural processes (ConvCNPs) address this limitation by constructing infinite-dimensional functional embeddings processed through convolutional neural networks (CNNs) to enforce translation equivariance. Yet CNNs with local spatial kernels struggle to capture long-range dependencies without resorting to large kernels, which impose significant computational costs. To overcome this limitation, we propose the Spectral ConvCNP (SConvCNP), which performs global convolution in the frequency domain. Inspired by Fourier neural operators (FNOs) for learning solution operators of partial differential equations (PDEs), our approach directly parameterizes convolution kernels in the frequency domain, leveraging the relatively compact yet global Fourier representation of many natural signals. We validate the effectiveness of SConvCNP on both synthetic and real-world datasets, demonstrating how ideas from operator learning can advance the capabilities of NPs.",
    "published": "2024-04-19T21:13:18Z",
    "updated": "2025-12-01T10:02:24Z",
    "link": "http://arxiv.org/pdf/2404.13182v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Peiman Mohseni",
      "Nick Duffield"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.01407v3",
    "title": "Signals, Concepts, and Laws: Toward Universal, Explainable Time-Series Forecasting",
    "summary": "Accurate, explainable and physically credible forecasting remains a persistent challenge for multivariate time-series whose statistical properties vary across domains. We propose DORIC, a Domain-Universal, ODE-Regularized, Interpretable-Concept Transformer for Time-Series Forecasting that generates predictions through five self-supervised, domain-agnostic concepts while enforcing differentiable residuals grounded in first-principles constraints.",
    "published": "2025-08-02T15:25:10Z",
    "updated": "2025-12-01T09:50:20Z",
    "link": "http://arxiv.org/pdf/2508.01407v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Hongwei Ma",
      "Junbin Gao",
      "Minh-Ngoc Tran"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01467v1",
    "title": "Differentiable Weightless Controllers: Learning Logic Circuits for Continuous Control",
    "summary": "We investigate whether continuous-control policies can be represented and learned as discrete logic circuits instead of continuous neural networks. We introduce Differentiable Weightless Controllers (DWCs), a symbolic-differentiable architecture that maps real-valued observations to actions using thermometer-encoded inputs, sparsely connected boolean lookup-table layers, and lightweight action heads. DWCs can be trained end-to-end by gradient-based techniques, yet compile directly into FPGA-compatible circuits with few- or even single-clock-cycle latency and nanojoule-level energy cost per action. Across five MuJoCo benchmarks, including high-dimensional Humanoid, DWCs achieve returns competitive with weight-based policies (full precision or quantized neural networks), matching performance on four tasks and isolating network capacity as the key limiting factor on HalfCheetah. Furthermore, DWCs exhibit structurally sparse and interpretable connectivity patterns, enabling a direct inspection of which input thresholds influence control decisions.",
    "published": "2025-12-01T09:50:04Z",
    "updated": "2025-12-01T09:50:04Z",
    "link": "http://arxiv.org/pdf/2512.01467v1.pdf",
    "category": [
      "cs.LG",
      "cs.AR",
      "cs.SC"
    ],
    "authors": [
      "Fabian Kresse",
      "Christoph H. Lampert"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01465v1",
    "title": "A Nonlinear Low-rank Representation Model with Convolutional Neural Network for Imputing Water Quality Data",
    "summary": "Water quality monitoring is a core component of ecological environmental protection. However, due to sensor failure or other inevitable factors, data missing often exists in long-term monitoring, posing great challenges in water quality analysis. This paper proposes a Neural Tucker Convolutional Network (NTCN) model for water quality data imputation, which features the following key components: a) Encode different mode entities into respective embedding vectors, and construct a Tucker interaction tensor by outer product operations to capture the complex mode-wise feature interactions; b) Use 3D convolution to extract fine-grained spatiotemporal features from the interaction tensor. Experiments on three real-world water quality datasets show that the proposed NTCN model outperforms several state-of-the-art imputation models in terms of accuracy.",
    "published": "2025-12-01T09:49:18Z",
    "updated": "2025-12-01T09:49:18Z",
    "link": "http://arxiv.org/pdf/2512.01465v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Hongnan Si",
      "Tong Li",
      "Yujie Chen",
      "Xin Liao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01463v1",
    "title": "hls4ml: A Flexible, Open-Source Platform for Deep Learning Acceleration on Reconfigurable Hardware",
    "summary": "We present hls4ml, a free and open-source platform that translates machine learning (ML) models from modern deep learning frameworks into high-level synthesis (HLS) code that can be integrated into full designs for field-programmable gate arrays (FPGAs) or application-specific integrated circuits (ASICs). With its flexible and modular design, hls4ml supports a large number of deep learning frameworks and can target HLS compilers from several vendors, including Vitis HLS, Intel oneAPI and Catapult HLS. Together with a wider eco-system for software-hardware co-design, hls4ml has enabled the acceleration of ML inference in a wide range of commercial and scientific applications where low latency, resource usage, and power consumption are critical. In this paper, we describe the structure and functionality of the hls4ml platform. The overarching design considerations for the generated HLS code are discussed, together with selected performance results.",
    "published": "2025-12-01T09:47:31Z",
    "updated": "2025-12-01T09:47:31Z",
    "link": "http://arxiv.org/pdf/2512.01463v1.pdf",
    "category": [
      "cs.AR",
      "cs.LG"
    ],
    "authors": [
      "Jan-Frederik Schulte",
      "Benjamin Ramhorst",
      "Chang Sun",
      "Jovan Mitrevski",
      "Nicolò Ghielmetti",
      "Enrico Lupi",
      "Dimitrios Danopoulos",
      "Vladimir Loncar",
      "Javier Duarte",
      "David Burnette",
      "Lauri Laatu",
      "Stylianos Tzelepis",
      "Konstantinos Axiotis",
      "Quentin Berthet",
      "Haoyan Wang",
      "Paul White",
      "Suleyman Demirsoy",
      "Marco Colombo",
      "Thea Aarrestad",
      "Sioni Summers",
      "Maurizio Pierini",
      "Giuseppe Di Guglielmo",
      "Jennifer Ngadiuba",
      "Javier Campos",
      "Ben Hawks",
      "Abhijith Gandrakota",
      "Farah Fahim",
      "Nhan Tran",
      "George Constantinides",
      "Zhiqiang Que",
      "Wayne Luk",
      "Alexander Tapper",
      "Duc Hoang",
      "Noah Paladino",
      "Philip Harris",
      "Bo-Cheng Lai",
      "Manuel Valentin",
      "Ryan Forelli",
      "Seda Ogrenci",
      "Lino Gerlach",
      "Rian Flynn",
      "Mia Liu",
      "Daniel Diaz",
      "Elham Khoda",
      "Melissa Quinnan",
      "Russell Solares",
      "Santosh Parajuli",
      "Mark Neubauer",
      "Christian Herwig",
      "Ho Fung Tsoi",
      "Dylan Rankin",
      "Shih-Chieh Hsu",
      "Scott Hauck"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17817v2",
    "title": "From Noise to Laws: Regularized Time-Series Forecasting via Denoised Dynamic Graphs",
    "summary": "Long-horizon multivariate time-series forecasting is challenging because realistic predictions must (i) denoise heterogeneous signals, (ii) track time-varying cross-series dependencies, and (iii) remain stable and physically plausible over long rollout horizons. We present PRISM, which couples a score-based diffusion preconditioner with a dynamic, correlation-thresholded graph encoder and a forecast head regularized by generic physics penalties. We prove contraction of the induced horizon dynamics under mild conditions and derive Lipschitz bounds for graph blocks, explaining the model's robustness. On six standard benchmarks , PRISM achieves consistent SOTA with strong MSE and MAE gains.",
    "published": "2025-09-27T08:35:23Z",
    "updated": "2025-12-01T09:43:39Z",
    "link": "http://arxiv.org/pdf/2510.17817v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Hongwei Ma",
      "Junbin Gao",
      "Minh-ngoc Tran"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.11276v2",
    "title": "Multiclass threshold-based classification",
    "summary": "In this paper, we introduce a threshold-based framework for multiclass classification that generalizes the standard argmax rule. This is done by replacing the probabilistic interpretation of softmax outputs with a geometric one on the multidimensional simplex, where the classification depends on a multidimensional threshold. This change of perspective enables for any trained classification network an a posteriori optimization of the classification score by means of threshold tuning, as usually carried out in the binary setting. This allows a further refinement of the prediction capability of any network. Moreover, this multidimensional threshold-based setting makes it possible to define score-oriented losses, which are based on the interpretation of the threshold as a random variable. Our experiments show that the multidimensional threshold tuning yields consistent performance improvements across various networks and datasets, and that the proposed multiclass score-oriented losses are competitive with standard loss functions, resembling the advantages observed in the binary case.",
    "published": "2025-05-16T14:11:26Z",
    "updated": "2025-12-01T09:41:41Z",
    "link": "http://arxiv.org/pdf/2505.11276v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Francesco Marchetti",
      "Edoardo Legnaro",
      "Sabrina Guastavino"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01428v1",
    "title": "Masked Symbol Modeling for Demodulation of Oversampled Baseband Communication Signals in Impulsive Noise-Dominated Channels",
    "summary": "Recent breakthroughs in natural language processing show that attention mechanism in Transformer networks, trained via masked-token prediction, enables models to capture the semantic context of the tokens and internalize the grammar of language. While the application of Transformers to communication systems is a burgeoning field, the notion of context within physical waveforms remains under-explored. This paper addresses that gap by re-examining inter-symbol contribution (ISC) caused by pulse-shaping overlap. Rather than treating ISC as a nuisance, we view it as a deterministic source of contextual information embedded in oversampled complex baseband signals. We propose Masked Symbol Modeling (MSM), a framework for the physical (PHY) layer inspired by Bidirectional Encoder Representations from Transformers methodology. In MSM, a subset of symbol aligned samples is randomly masked, and a Transformer predicts the missing symbol identifiers using the surrounding \"in-between\" samples. Through this objective, the model learns the latent syntax of complex baseband waveforms. We illustrate MSM's potential by applying it to the task of demodulating signals corrupted by impulsive noise, where the model infers corrupted segments by leveraging the learned context. Our results suggest a path toward receivers that interpret, rather than merely detect communication signals, opening new avenues for context-aware PHY layer design.",
    "published": "2025-12-01T09:09:28Z",
    "updated": "2025-12-01T09:09:28Z",
    "link": "http://arxiv.org/pdf/2512.01428v1.pdf",
    "category": [
      "eess.SP",
      "cs.LG",
      "cs.SD"
    ],
    "authors": [
      "Oguz Bedir",
      "Nurullah Sevim",
      "Mostafa Ibrahim",
      "Sabit Ekin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01421v1",
    "title": "Fourier Neural Operators Explained: A Practical Perspective",
    "summary": "Partial differential equations (PDEs) govern a wide variety of dynamical processes in science and engineering, yet obtaining their numerical solutions often requires high-resolution discretizations and repeated evaluations of complex operators, leading to substantial computational costs. Neural operators have recently emerged as a powerful framework for learning mappings between function spaces directly from data, enabling efficient surrogate models for PDE systems. Among these architectures, the Fourier Neural Operator (FNO) has become the most influential and widely adopted due to its elegant spectral formulation, which captures global correlations through learnable transformations in Fourier space while remaining invariant to discretization and resolution. Despite their success, the practical use of FNOs is often hindered by an incomplete understanding among practitioners of their theoretical foundations, practical constraints, and implementation details, which can lead to their incorrect or unreliable application. This work presents a comprehensive and practice-oriented guide to FNOs, unifying their mathematical principles with implementation strategies. We provide an intuitive exposition to the concepts of operator theory and signal-processing that underlie the FNO, detail its spectral parameterization and the computational design of all its components, and address common misunderstandings encountered in the literature. The exposition is closely integrated with the NeuralOperator 2.0.0 library, offering modular state-of-the-art implementations that faithfully reflect the theory. By connecting rigorous foundations with practical insight, this guide aims to establish a clear and reliable framework for applying FNOs effectively across diverse scientific and engineering fields.",
    "published": "2025-12-01T08:56:21Z",
    "updated": "2025-12-01T08:56:21Z",
    "link": "http://arxiv.org/pdf/2512.01421v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Valentin Duruisseaux",
      "Jean Kossaifi",
      "Anima Anandkumar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.08141v5",
    "title": "Arbitrary Entropy Policy Optimization Breaks The Exploration Bottleneck of Reinforcement Learning",
    "summary": "Reinforcement Learning (RL) is essential for enhancing the reasoning capabilities of large language models (LLMs), yet the widely adopted Group Relative Policy Optimization (GRPO) suffers from entropy collapse, causing exploration to vanish and policies to converge prematurely. As a result, RL is widely believed to be incapable of expanding the reasoning frontier of LLMs. Existing entropy-regularized methods introduce an inevitable trade-off between reward and entropy, leading to exploration accompanied by non-negligible optimization bias. In this work, we prove that temperature-guided REINFORCE can modulate policy entropy, and propose Arbitrary Entropy Policy Optimization (AEPO), which reformulates entropy regularization as a policy-gradient optimization problem. Rather than manipulating entropy directly, AEPO implicitly regulates it by applying a REINFORCE regularization term on temperature-adjusted samples, ensuring that entropy is controlled but never dominates optimization, thereby enabling arbitrary and principled entropy regulation. Experiments show that AEPO outperforms RL baselines on both pass@1 and pass@$k$, and even surpasses the base model on pass@1024. By modulating entropy precisely, AEPO achieves more effective optimization dynamics and provides direct empirical evidence that entropy, exploration, and performance are intrinsically linked.",
    "published": "2025-10-09T12:24:08Z",
    "updated": "2025-12-01T08:32:33Z",
    "link": "http://arxiv.org/pdf/2510.08141v5.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Chen Wang",
      "Zhaochun Li",
      "Jionghao Bai",
      "Yuzhi Zhang",
      "Shisheng Cui",
      "Zhou Zhao",
      "Yue Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01405v1",
    "title": "Fantastic Features and Where to Find Them: A Probing Method to combine Features from Multiple Foundation Models",
    "summary": "Foundation models (FMs) trained with different objectives and data learn diverse representations, making some more effective than others for specific downstream tasks. Existing adaptation strategies, such as parameter-efficient fine-tuning, focus on individual models and do not exploit the complementary strengths across models. Probing methods offer a promising alternative by extracting information from frozen models, but current techniques do not scale well with large feature sets and often rely on dataset-specific hyperparameter tuning. We propose Combined backBones (ComBo), a simple and scalable probing-based adapter that effectively integrates features from multiple models and layers. ComBo compresses activations from layers of one or more FMs into compact token-wise representations and processes them with a lightweight transformer for task-specific prediction. Crucially, ComBo does not require dataset-specific tuning or backpropagation through the backbone models. However, not all models are equally relevant for all tasks. To address this, we introduce a mechanism that leverages ComBo's joint multi-backbone probing to efficiently evaluate each backbone's task-relevance, enabling both practical model comparison and improved performance through selective adaptation. On the 19 tasks of the VTAB-1k benchmark, ComBo outperforms previous probing methods, matches or surpasses more expensive alternatives, such as distillation-based model merging, and enables efficient probing of tuned models. Our results demonstrate that ComBo offers a practical and general-purpose framework for combining diverse representations from multiple FMs.",
    "published": "2025-12-01T08:26:08Z",
    "updated": "2025-12-01T08:26:08Z",
    "link": "http://arxiv.org/pdf/2512.01405v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Benjamin Ramtoula",
      "Pierre-Yves Lajoie",
      "Paul Newman",
      "Daniele De Martini"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.01487v2",
    "title": "How to Securely Shuffle? A survey about Secure Shufflers for privacy-preserving computations",
    "summary": "Ishai et al. (FOCS'06) introduced secure shuffling as an efficient building block for private data aggregation. Recently, the field of differential privacy has revived interest in secure shufflers by highlighting the privacy amplification they can provide in various computations. Although several works argue for the utility of secure shufflers, they often treat them as black boxes; overlooking the practical vulnerabilities and performance trade-offs of existing implementations. This leaves a central question open: what makes a good secure shuffler?\n  This survey addresses that question by identifying, categorizing, and comparing 26 secure protocols that realize the necessary shuffling functionality. To enable a meaningful comparison, we adapt and unify existing security definitions into a consistent set of properties. We also present an overview of privacy-preserving technologies that rely on secure shufflers, offer practical guidelines for selecting appropriate protocols, and outline promising directions for future work.",
    "published": "2025-07-02T08:48:53Z",
    "updated": "2025-12-01T08:25:58Z",
    "link": "http://arxiv.org/pdf/2507.01487v2.pdf",
    "category": [
      "cs.CR",
      "cs.LG"
    ],
    "authors": [
      "Marc Damie",
      "Florian Hahn",
      "Andreas Peter",
      "Jan Ramon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01400v1",
    "title": "On Global Applicability and Location Transferability of Generative Deep Learning Models for Precipitation Downscaling",
    "summary": "Deep learning offers promising capabilities for the statistical downscaling of climate and weather forecasts, with generative approaches showing particular success in capturing fine-scale precipitation patterns. However, most existing models are region-specific, and their ability to generalize to unseen geographic areas remains largely unexplored. In this study, we evaluate the generalization performance of generative downscaling models across diverse regions. Using a global framework, we employ ERA5 reanalysis data as predictors and IMERG precipitation estimates at $0.1^\\circ$ resolution as targets. A hierarchical location-based data split enables a systematic assessment of model performance across 15 regions around the world.",
    "published": "2025-12-01T08:24:40Z",
    "updated": "2025-12-01T08:24:40Z",
    "link": "http://arxiv.org/pdf/2512.01400v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Paula Harder",
      "Christian Lessig",
      "Matthew Chantry",
      "Francis Pelletier",
      "David Rolnick"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01392v1",
    "title": "RE-LLM: Integrating Large Language Models into Renewable Energy Systems",
    "summary": "Energy system models are increasingly employed to guide long-term planning in multi-sectoral environments where decisions span electricity, heat, transport, land use, and industry. While these models provide rigorous quantitative insights, their outputs are often highly technical, making them difficult to interpret for non-expert stakeholders such as policymakers, planners, and the public. This communication gap limits the accessibility and practical impact of scenario-based modeling, particularly as energy transitions grow more complex with rising shares of renewables, sectoral integration, and deep uncertainties. To address this challenge, we propose the Renewable Energy Large Language Model (RE-LLM), a hybrid framework that integrates Large Language Models (LLMs) directly into the energy system modeling workflow. RE-LLM combines three core elements: (i) optimization-based scenario exploration, (ii) machine learning surrogates that accelerate computationally intensive simulations, and (iii) LLM-powered natural language generation that translates complex results into clear, stakeholder-oriented explanations. This integrated design not only reduces computational burden but also enhances inter-pretability, enabling real-time reasoning about trade-offs, sensitivities, and policy implications. The framework is adaptable across different optimization platforms and energy system models, ensuring broad applicability beyond the case study presented. By merging speed, rigor, and interpretability, RE-LLM advances a new paradigm of human-centric energy modeling. It enables interactive, multilingual, and accessible engagement with future energy pathways, ultimately bridging the final gap between data-driven analysis and actionable decision-making for sustainable transitions.",
    "published": "2025-12-01T08:10:39Z",
    "updated": "2025-12-01T08:10:39Z",
    "link": "http://arxiv.org/pdf/2512.01392v1.pdf",
    "category": [
      "cs.LG",
      "eess.SY"
    ],
    "authors": [
      "Ali Forootani",
      "Mohammad Sadr",
      "Danial Esmaeili Aliabadi",
      "Daniela Thraen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01384v1",
    "title": "CLAPS: Posterior-Aware Conformal Intervals via Last-Layer Laplace",
    "summary": "We present CLAPS, a posterior-aware conformal regression method that pairs a Last-Layer Laplace Approximation with split-conformal calibration. From the resulting Gaussian posterior, CLAPS defines a simple two-sided posterior CDF score that aligns the conformity metric with the full predictive shape, not just a point estimate. This alignment yields narrower prediction intervals at the same target coverage, especially on small to medium tabular datasets where data are scarce and uncertainty modeling matters. We also provide a lightweight diagnostic suite that separates aleatoric and epistemic components and visualizes posterior behavior, helping practitioners understand why intervals shrink when they do. Across multiple benchmarks using the same MLP backbone, CLAPS consistently attains nominal coverage with improved efficiency and minimal overhead, offering a clear, practical upgrade to residual-based conformal baselines.",
    "published": "2025-12-01T07:58:21Z",
    "updated": "2025-12-01T07:58:21Z",
    "link": "http://arxiv.org/pdf/2512.01384v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Dongseok Kim",
      "Hyoungsun Choi",
      "Mohamed Jismy Aashik Rasool",
      "Gisung Oh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.18014v2",
    "title": "Predictive Scaling Laws for Efficient GRPO Training of Large Reasoning Models",
    "summary": "Fine-tuning large language models (LLMs) for reasoning tasks using reinforcement learning methods like Group Relative Policy Optimization (GRPO) is computationally expensive. To address this, we propose a predictive framework that models training dynamics and helps optimize resource usage. Through experiments on Llama and Qwen models (3B 8B), we derive an empirical scaling law based on model size, initial performance, and training progress. This law predicts reward trajectories and identifies three consistent training phases: slow start, rapid improvement, and plateau. We find that training beyond certain number of an epoch offers little gain, suggesting earlier stopping can significantly reduce compute without sacrificing performance. Our approach generalizes across model types, providing a practical guide for efficient GRPO-based fine-tuning.",
    "published": "2025-07-24T01:09:25Z",
    "updated": "2025-12-01T07:45:01Z",
    "link": "http://arxiv.org/pdf/2507.18014v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Datta Nimmaturi",
      "Vaishnavi Bhargava",
      "Rajat Ghosh",
      "Johnu George",
      "Debojyoti Dutta"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.02391v2",
    "title": "Gaming and Cooperation in Federated Learning: What Can Happen and How to Monitor It",
    "summary": "The success of federated learning (FL) ultimately depends on how strategic participants behave under partial observability, yet most formulations still treat FL as a static optimization problem. We instead view FL deployments as governed strategic systems and develop an analytical framework that separates welfare-improving behavior from metric gaming. Within this framework, we introduce indices that quantify manipulability, the price of gaming, and the price of cooperation, and we use them to study how rules, information disclosure, evaluation metrics, and aggregator-switching policies reshape incentives and cooperation patterns. We derive threshold conditions for deterring harmful gaming while preserving benign cooperation, and for triggering auto-switch rules when early-warning indicators become critical. Building on these results, we construct a design toolkit including a governance checklist and a simple audit-budget allocation algorithm with a provable performance guarantee. Simulations across diverse stylized environments and a federated learning case study consistently match the qualitative and quantitative patterns predicted by our framework. Taken together, our results provide design principles and operational guidelines for reducing metric gaming while sustaining stable, high-welfare cooperation in FL platforms.",
    "published": "2025-09-02T14:55:01Z",
    "updated": "2025-12-01T07:42:26Z",
    "link": "http://arxiv.org/pdf/2509.02391v2.pdf",
    "category": [
      "cs.LG",
      "cs.GT",
      "stat.ML"
    ],
    "authors": [
      "Dongseok Kim",
      "Hyoungsun Choi",
      "Mohamed Jismy Aashik Rasool",
      "Gisung Oh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01367v1",
    "title": "A Fine Evaluation Method for Cube Copying Test for Early Detection of Alzheimer's Disease",
    "summary": "Background: Impairment of visual spatial cognitive function is the most common early clinical manifestation of Alzheimer's Disease (AD). When the Montreal Cognitive Assessment (MoCA) uses the \"0/1\" binary method (\"pass/fail\") to evaluate the visual spatial cognitive ability represented by the Cube Copying Test(CCT), the elder with less formal education generally score 0 point, resulting in serious bias in the evaluation results. Therefore, this study proposes a fine evaluation method for CCT based on dynamic handwriting feature extraction of DH-SCSM-BLA. method : The Cogni-CareV3.0 software independently developed by our team was used to collect dynamic handwriting data of CCT. Then, the spatial and motion features of segmented dynamic handwriting were extracted, and feature matrix with unequal dimensions were normalized. Finally, a bidirectional long short-term memory network model combined with attention mechanism (BiLSTM-Attention) was adopted for classification. Result: The experimental results showed that: The proposed method has significant superiority compared to similar studies, with a classification accuracy of 86.69%. The distribution of cube drawing ability scores has significant regularity for three aspects such as MCI patients and healthy control group, age, and levels of education. It was also found that score for each cognitive task including cube drawing ability score is negatively correlated with age. Score for each cognitive task including cube drawing ability score, but positively correlated with levels of education significantly. Conclusion: This study provides a relatively objective and comprehensive evaluation method for early screening and personalized intervention of visual spatial cognitive impairment.",
    "published": "2025-12-01T07:28:49Z",
    "updated": "2025-12-01T07:28:49Z",
    "link": "http://arxiv.org/pdf/2512.01367v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Xinyu Jiang",
      "Cuiyun Gao",
      "Wenda Huang",
      "Yiyang Jiang",
      "Binwen Luo",
      "Yuxin Jiang",
      "Mengting Wang",
      "Haoran Wen",
      "Yang Zhao",
      "Xuemei Chen",
      "Songqun Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01365v1",
    "title": "Modeling Wavelet Transformed Quantum Support Vector for Network Intrusion Detection",
    "summary": "Network traffic anomaly detection is a critical cy- bersecurity challenge requiring robust solutions for complex Internet of Things (IoT) environments. We present a novel hybrid quantum-classical framework integrating an enhanced Quantum Support Vector Machine (QSVM) with the Quantum Haar Wavelet Packet Transform (QWPT) for superior anomaly classification under realistic noisy intermediate-scale Quantum conditions. Our methodology employs amplitude-encoded quan- tum state preparation, multi-level QWPT feature extraction, and behavioral analysis via Shannon Entropy profiling and Chi-square testing. Features are classified using QSVM with fidelity-based quantum kernels optimized through hybrid train- ing with simultaneous perturbation stochastic approximation (SPSA) optimizer. Evaluation under noiseless and depolarizing noise conditions demonstrates exceptional performance: 96.67% accuracy on BoT-IoT and 89.67% on IoT-23 datasets, surpassing quantum autoencoder approaches by over 7 percentage points.",
    "published": "2025-12-01T07:23:20Z",
    "updated": "2025-12-01T07:23:20Z",
    "link": "http://arxiv.org/pdf/2512.01365v1.pdf",
    "category": [
      "quant-ph",
      "cs.LG"
    ],
    "authors": [
      "Swati Kumari",
      "Shiva Raj Pokhrel",
      "Swathi Chandrasekhar",
      "Navneet Singh",
      "Hridoy Sankar Dutta",
      "Adnan Anwar",
      "Sutharshan Rajasegarar",
      "Robin Doss"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01363v1",
    "title": "SocialDriveGen: Generating Diverse Traffic Scenarios with Controllable Social Interactions",
    "summary": "The generation of realistic and diverse traffic scenarios in simulation is essential for developing and evaluating autonomous driving systems. However, most simulation frameworks rely on rule-based or simplified models for scene generation, which lack the fidelity and diversity needed to represent real-world driving. While recent advances in generative modeling produce more realistic and context-aware traffic interactions, they often overlook how social preferences influence driving behavior. SocialDriveGen addresses this gap through a hierarchical framework that integrates semantic reasoning and social preference modeling with generative trajectory synthesis. By modeling egoism and altruism as complementary social dimensions, our framework enables controllable diversity in driver personalities and interaction styles. Experiments on the Argoverse 2 dataset show that SocialDriveGen generates diverse, high-fidelity traffic scenarios spanning cooperative to adversarial behaviors, significantly enhancing policy robustness and generalization to rare or high-risk situations.",
    "published": "2025-12-01T07:18:20Z",
    "updated": "2025-12-01T07:18:20Z",
    "link": "http://arxiv.org/pdf/2512.01363v1.pdf",
    "category": [
      "cs.MA",
      "cs.LG"
    ],
    "authors": [
      "Jiaguo Tian",
      "Zhengbang Zhu",
      "Shenyu Zhang",
      "Li Xu",
      "Bo Zheng",
      "Xu Liu",
      "Weiji Peng",
      "Shizeng Yao",
      "Weinan Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01362v1",
    "title": "Directed evolution algorithm drives neural prediction",
    "summary": "Neural prediction offers a promising approach to forecasting the individual variability of neurocognitive functions and disorders and providing prognostic indicators for personalized invention. However, it is challenging to translate neural predictive models into medical artificial intelligent applications due to the limitations of domain shift and label scarcity. Here, we propose the directed evolution model (DEM), a novel computational model that mimics the trial-and-error processes of biological directed evolution to approximate optimal solutions for predictive modeling tasks. We demonstrated that the directed evolution algorithm is an effective strategy for uncertainty exploration, enhancing generalization in reinforcement learning. Furthermore, by incorporating replay buffer and continual backpropagate methods into DEM, we provide evidence of achieving better trade-off between exploitation and exploration in continuous learning settings. We conducted experiments on four different datasets for children with cochlear implants whose spoken language developmental outcomes vary considerably on the individual-child level. Preoperative neural MRI data has shown to accurately predict the post-operative outcome of these children within but not across datasets. Our results show that DEM can efficiently improve the performance of cross-domain pre-implantation neural predictions while addressing the challenge of label scarcity in target domain.",
    "published": "2025-12-01T07:17:45Z",
    "updated": "2025-12-01T07:17:45Z",
    "link": "http://arxiv.org/pdf/2512.01362v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Yanlin Wang",
      "Nancy M Young",
      "Patrick C M Wong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01358v1",
    "title": "Modality-Augmented Fine-Tuning of Foundation Robot Policies for Cross-Embodiment Manipulation on GR1 and G1",
    "summary": "This paper presents a modality-augmented fine-tuning framework designed to adapt foundation robot policies to diverse humanoid embodiments. We validate our approach across two distinct settings: (i) the GR1 embodiment, utilizing public datasets where we introduce post-processed modalities, including binary contact signals and ZoeDepth-generated metric depth; and (ii) the Unitree G1 embodiment, for which we contribute a novel multi-modal dataset incorporating cuRobo motion planning, inverse kinematics, and ground-truth contact-force measurements. Our experiments demonstrate that modality augmentation consistently enhances policy performance across different embodiments. Specifically, for the GR1, integrating contact-state cues and RGB-D fusion improves online success rates from 51% to 63%. Furthermore, in the G1 \"Pick Apple to Bowl\" task, our contact-augmented model achieves a success rate of 94%, significantly outperforming the 48% achieved by standard fine-tuning and the 0% baseline of zero-shot transfer. These results highlight that lightweight post-processing effectively strengthens policies for GR1, while high-quality multi-modal data is crucial for reliable transfer to the Unitree G1. Consequently, this work establishes a unified, data-centric pathway for extending foundation robot policies through targeted modality design and multi-modal fine-tuning.",
    "published": "2025-12-01T07:13:38Z",
    "updated": "2025-12-01T07:13:38Z",
    "link": "http://arxiv.org/pdf/2512.01358v1.pdf",
    "category": [
      "cs.RO",
      "cs.LG"
    ],
    "authors": [
      "Junsung Park",
      "Hogun Kee",
      "Songhwai Oh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.14496v3",
    "title": "Semantic Energy: Detecting LLM Hallucination Beyond Entropy",
    "summary": "Large Language Models (LLMs) are being increasingly deployed in real-world applications, but they remain susceptible to hallucinations, which produce fluent yet incorrect responses and lead to erroneous decision-making. Uncertainty estimation is a feasible approach to detect such hallucinations. For example, semantic entropy estimates uncertainty by considering the semantic diversity across multiple sampled responses, thus identifying hallucinations. However, semantic entropy relies on post-softmax probabilities and fails to capture the model's inherent uncertainty, causing it to be ineffective in certain scenarios. To address this issue, we introduce Semantic Energy, a novel uncertainty estimation framework that leverages the inherent confidence of LLMs by operating directly on logits of penultimate layer. By combining semantic clustering with a Boltzmann-inspired energy distribution, our method better captures uncertainty in cases where semantic entropy fails. Experiments across multiple benchmarks show that Semantic Energy significantly improves hallucination detection and uncertainty estimation, offering more reliable signals for downstream applications such as hallucination detection.",
    "published": "2025-08-20T07:33:50Z",
    "updated": "2025-12-01T06:37:45Z",
    "link": "http://arxiv.org/pdf/2508.14496v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Huan Ma",
      "Jiadong Pan",
      "Jing Liu",
      "Yan Chen",
      "Joey Tianyi Zhou",
      "Guangyu Wang",
      "Qinghua Hu",
      "Hua Wu",
      "Changqing Zhang",
      "Haifeng Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.15933v2",
    "title": "CORAL: Disentangling Latent Representations in Long-Tailed Diffusion",
    "summary": "Diffusion models have achieved impressive performance in generating high-quality and diverse synthetic data. However, their success typically assumes a class-balanced training distribution. In real-world settings, multi-class data often follow a long-tailed distribution, where standard diffusion models struggle -- producing low-diversity and lower-quality samples for tail classes. While this degradation is well-documented, its underlying cause remains poorly understood. In this work, we investigate the behavior of diffusion models trained on long-tailed datasets and identify a key issue: the latent representations (from the bottleneck layer of the U-Net) for tail class subspaces exhibit significant overlap with those of head classes, leading to feature borrowing and poor generation quality. Importantly, we show that this is not merely due to limited data per class, but that the relative class imbalance significantly contributes to this phenomenon. To address this, we propose COntrastive Regularization for Aligning Latents (CORAL), a contrastive latent alignment framework that leverages supervised contrastive losses to encourage well-separated latent class representations. Experiments demonstrate that CORAL significantly improves both the diversity and visual quality of samples generated for tail classes relative to state-of-the-art methods.",
    "published": "2025-06-19T00:23:44Z",
    "updated": "2025-12-01T06:35:39Z",
    "link": "http://arxiv.org/pdf/2506.15933v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Esther Rodriguez",
      "Monica Welfert",
      "Samuel McDowell",
      "Nathan Stromberg",
      "Julian Antolin Camarena",
      "Lalitha Sankar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.25742v2",
    "title": "Less is More: Towards Simple Graph Contrastive Learning",
    "summary": "Graph Contrastive Learning (GCL) has shown strong promise for unsupervised graph representation learning, yet its effectiveness on heterophilic graphs, where connected nodes often belong to different classes, remains limited. Most existing methods rely on complex augmentation schemes, intricate encoders, or negative sampling, which raises the question of whether such complexity is truly necessary in this challenging setting. In this work, we revisit the foundations of supervised and unsupervised learning on graphs and uncover a simple yet effective principle for GCL: mitigating node feature noise by aggregating it with structural features derived from the graph topology. This observation suggests that the original node features and the graph structure naturally provide two complementary views for contrastive learning. Building on this insight, we propose an embarrassingly simple GCL model that uses a GCN encoder to capture structural features and an MLP encoder to isolate node feature noise. Our design requires neither data augmentation nor negative sampling, yet achieves state-of-the-art results on heterophilic benchmarks with minimal computational and memory overhead, while also offering advantages in homophilic graphs in terms of complexity, scalability, and robustness. We provide theoretical justification for our approach and validate its effectiveness through extensive experiments, including robustness evaluations against both black-box and white-box adversarial attacks.",
    "published": "2025-09-30T03:56:50Z",
    "updated": "2025-12-01T05:39:19Z",
    "link": "http://arxiv.org/pdf/2509.25742v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Yanan Zhao",
      "Feng Ji",
      "Jingyang Dai",
      "Jiaze Ma",
      "Wee Peng Tay"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2104.14654v6",
    "title": "Adversarial Inverse Reinforcement Learning for Mean Field Games",
    "summary": "Mean field games (MFGs) provide a mathematically tractable framework for modelling large-scale multi-agent systems by leveraging mean field theory to simplify interactions among agents. It enables applying inverse reinforcement learning (IRL) to predict behaviours of large populations by recovering reward signals from demonstrated behaviours. However, existing IRL methods for MFGs are powerless to reason about uncertainties in demonstrated behaviours of individual agents. This paper proposes a novel framework, Mean-Field Adversarial IRL (MF-AIRL), which is capable of tackling uncertainties in demonstrations. We build MF-AIRL upon maximum entropy IRL and a new equilibrium concept. We evaluate our approach on simulated tasks with imperfect demonstrations. Experimental results demonstrate the superiority of MF-AIRL over existing methods in reward recovery.",
    "published": "2021-04-29T21:03:49Z",
    "updated": "2025-12-01T05:38:49Z",
    "link": "http://arxiv.org/pdf/2104.14654v6.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Yang Chen",
      "Libo Zhang",
      "Jiamou Liu",
      "Michael Witbrock"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01294v1",
    "title": "Experimental Methods, Health Indicators, and Diagnostic Strategies for Retired Lithium-ion Batteries: A Comprehensive Review",
    "summary": "Reliable health assessment of retired lithium-ion batteries is essential for safe and economically viable second-life deployment, yet remains difficult due to sparse measurements, incomplete historical records, heterogeneous chemistries, and limited or noisy battery health labels. Conventional laboratory diagnostics, such as full charge-discharge cycling, pulse tests, Electrochemical Impedance Spectroscopy (EIS) measurements, and thermal characterization, provide accurate degradation information but are too time-consuming, equipment-intensive, or condition-sensitive to be applied at scale during retirement-stage sorting, leaving real-world datasets fragmented and inconsistent. This review synthesizes recent advances that address these constraints through physical health indicators, experiment testing methods, data-generation and augmentation techniques, and a spectrum of learning-based modeling routes spanning supervised, semi-supervised, weakly supervised, and unsupervised paradigms. We highlight how minimal-test features, synthetic data, domain-invariant representations, and uncertainty-aware prediction enable robust inference under limited or approximate labels and across mixed chemistries and operating histories. A comparative evaluation further reveals trade-offs in accuracy, interpretability, scalability, and computational burden. Looking forward, progress toward physically constrained generative models, cross-chemistry generalization, calibrated uncertainty estimation, and standardized benchmarks will be crucial for building reliable, scalable, and deployment-ready health prediction tools tailored to the realities of retired-battery applications.",
    "published": "2025-12-01T05:28:06Z",
    "updated": "2025-12-01T05:28:06Z",
    "link": "http://arxiv.org/pdf/2512.01294v1.pdf",
    "category": [
      "eess.SP",
      "cs.LG"
    ],
    "authors": [
      "Song Zhang",
      "Ruohan Guo",
      "Xiaohua Ge",
      "Perter Mahon",
      "Weixiang Shen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13734v2",
    "title": "Extended Physics Informed Neural Network for Hyperbolic Two-Phase Flow in Porous Media",
    "summary": "The accurate solution of nonlinear hyperbolic partial differential equations (PDEs) remains challenging due to steep gradients, discontinuities, and multiscale structures that make conventional solvers computationally demanding. Physics-Informed Neural Networks (PINNs) embed the governing equations into the learning process, enabling mesh-free solution of PDEs, yet they often struggle to capture steep gradients, discontinuities, and complex nonlinear wave interactions. To address these limitations, we employ the Extended Physics-Informed Neural Network (XPINN) framework to solve the nonlinear Buckley-Leverett equation with a nonconvex flux, modeling immiscible two-phase flow in porous media. The computational domain is dynamically decomposed in space and time into evolving pre-shock and post-shock subdomains, allowing localized subnetworks to efficiently learn distinct flow behaviors, with coupling enforced via the Rankine-Hugoniot jump condition to ensure physically consistent flux continuity. We compare XPINN with standard PINNs and its variants, including PINN with artificial viscosity, PINN with Welge construction, and PINN with the Oleinik entropy condition, and across all cases, XPINN consistently outperforms the other methods, accurately resolving sharp fronts and capturing the correct physical behavior. Importantly, XPINN achieves this using the simpler Adam optimizer, whereas some PINN variants require more complex or higher-order strategies such as L-BFGS to reach comparable accuracy, demonstrating that XPINN is a robust and scalable approach for challenging hyperbolic PDEs without artificial diffusion or entropy corrections. The code is available at github.com/saifkhanengr/XPINN-for-Buckley-Leverett.",
    "published": "2025-11-05T14:16:28Z",
    "updated": "2025-12-01T05:21:02Z",
    "link": "http://arxiv.org/pdf/2511.13734v2.pdf",
    "category": [
      "cs.LG",
      "math.NA",
      "physics.comp-ph",
      "physics.flu-dyn"
    ],
    "authors": [
      "Saif Ur Rehman",
      "Wajid Yousuf"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01287v1",
    "title": "milearn: A Python Package for Multi-Instance Machine Learning",
    "summary": "We introduce milearn, a Python package for multi-instance learning (MIL) that follows the familiar scikit-learn fit/predict interface while providing a unified framework for both classical and neural-network-based MIL algorithms for regression and classification. The package also includes built-in hyperparameter optimization designed specifically for small MIL datasets, enabling robust model selection in data-scarce scenarios. We demonstrate the versatility of milearn across a broad range of synthetic MIL benchmark datasets, including digit classification and regression, molecular property prediction, and protein-protein interaction (PPI) prediction. Special emphasis is placed on the key instance detection (KID) problem, for which the package provides dedicated support.",
    "published": "2025-12-01T05:15:28Z",
    "updated": "2025-12-01T05:15:28Z",
    "link": "http://arxiv.org/pdf/2512.01287v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Dmitry Zankov",
      "Pavlo Polishchuk",
      "Michal Sobieraj",
      "Mario Barbatti"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01276v1",
    "title": "Samplability makes learning easier",
    "summary": "The standard definition of PAC learning (Valiant 1984) requires learners to succeed under all distributions -- even ones that are intractable to sample from. This stands in contrast to samplable PAC learning (Blum, Furst, Kearns, and Lipton 1993), where learners only have to succeed under samplable distributions. We study this distinction and show that samplable PAC substantially expands the power of efficient learners.\n  We first construct a concept class that requires exponential sample complexity in standard PAC but is learnable with polynomial sample complexity in samplable PAC. We then lift this statistical separation to the computational setting and obtain a separation relative to a random oracle. Our proofs center around a new complexity primitive, explicit evasive sets, that we introduce and study. These are sets for which membership is easy to determine but are extremely hard to sample from.\n  Our results extend to the online setting to similarly show how its landscape changes when the adversary is assumed to be efficient instead of computationally unbounded.",
    "published": "2025-12-01T04:48:36Z",
    "updated": "2025-12-01T04:48:36Z",
    "link": "http://arxiv.org/pdf/2512.01276v1.pdf",
    "category": [
      "cs.CC",
      "cs.DS",
      "cs.LG"
    ],
    "authors": [
      "Guy Blanc",
      "Caleb Koch",
      "Jane Lange",
      "Carmen Strassle",
      "Li-Yang Tan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01258v1",
    "title": "Efficient Hyperparameter Search for Non-Stationary Model Training",
    "summary": "Online learning is the cornerstone of applications like recommendation and advertising systems, where models continuously adapt to shifting data distributions. Model training for such systems is remarkably expensive, a cost that multiplies during hyperparameter search. We introduce a two-stage paradigm to reduce this cost: (1) efficiently identifying the most promising configurations, and then (2) training only these selected candidates to their full potential. Our core insight is that focusing on accurate identification in the first stage, rather than achieving peak performance, allows for aggressive cost-saving measures. We develop novel data reduction and prediction strategies that specifically overcome the challenges of sequential, non-stationary data not addressed by conventional hyperparameter optimization. We validate our framework's effectiveness through a dual evaluation: first on the Criteo 1TB dataset, the largest suitable public benchmark, and second on an industrial advertising system operating at a scale two orders of magnitude larger. Our methods reduce the total hyperparameter search cost by up to 10$\\times$ on the public benchmark and deliver significant, validated efficiency gains in the industrial setting.",
    "published": "2025-12-01T04:06:24Z",
    "updated": "2025-12-01T04:06:24Z",
    "link": "http://arxiv.org/pdf/2512.01258v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Berivan Isik",
      "Matthew Fahrbach",
      "Dima Kuzmin",
      "Nicolas Mayoraz",
      "Emil Praun",
      "Steffen Rendle",
      "Raghavendra Vasudeva"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.21669v2",
    "title": "DSD: A Distributed Speculative Decoding Solution for Edge-Cloud Agile Large Model Serving",
    "summary": "Large language model (LLM) inference often suffers from high decoding latency and limited scalability across heterogeneous edge-cloud environments. Existing speculative decoding (SD) techniques accelerate token generation but remain confined to single-node execution. We propose DSD, a distributed speculative decoding framework that extends SD to multi-device deployments through coordinated draft-target execution. Given the lack of prior work on simulating this paradigm, we first introduce DSD-Sim, a discrete-event simulator that captures network, batching, and scheduling dynamics. Building on insights from DSD-Sim, we further design an Adaptive Window Control (AWC) policy that dynamically adjusts speculation window size to optimize throughput. Experiments across diverse workloads show that DSD achieves up to 1.1x speedup and 9.7% higher throughput over existing SD baselines, enabling agile and scalable LLM serving across edge and cloud.",
    "published": "2025-11-26T18:47:25Z",
    "updated": "2025-12-01T03:54:02Z",
    "link": "http://arxiv.org/pdf/2511.21669v2.pdf",
    "category": [
      "cs.LG",
      "cs.DC"
    ],
    "authors": [
      "Fengze Yu",
      "Leshu Li",
      "Brad McDanel",
      "Sai Qian Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01245v1",
    "title": "Bayesian Optimization for Non-Cooperative Game-Based Radio Resource Management",
    "summary": "Radio resource management in modern cellular networks often calls for the optimization of complex utility functions that are potentially conflicting between different base stations (BSs). Coordinating the resource allocation strategies efficiently across BSs to ensure stable network service poses significant challenges, especially when each utility is accessible only via costly, black-box evaluations. This paper considers formulating the resource allocation among spectrum sharing BSs as a non-cooperative game, with the goal of aligning their allocation incentives toward a stable outcome. To address this challenge, we propose PPR-UCB, a novel Bayesian optimization (BO) strategy that learns from sequential decision-evaluation pairs to approximate pure Nash equilibrium (PNE) solutions. PPR-UCB applies martingale techniques to Gaussian process (GP) surrogates and constructs high probability confidence bounds for utilities uncertainty quantification. Experiments on downlink transmission power allocation in a multi-cell multi-antenna system demonstrate the efficiency of PPR-UCB in identifying effective equilibrium solutions within a few data samples.",
    "published": "2025-12-01T03:44:43Z",
    "updated": "2025-12-01T03:44:43Z",
    "link": "http://arxiv.org/pdf/2512.01245v1.pdf",
    "category": [
      "eess.SP",
      "cs.GT",
      "cs.LG"
    ],
    "authors": [
      "Yunchuan Zhang",
      "Jiechen Chen",
      "Junshuo Liu",
      "Robert C. Qiu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.19097v3",
    "title": "Towards Robust Influence Functions with Flat Validation Minima",
    "summary": "The Influence Function (IF) is a widely used technique for assessing the impact of individual training samples on model predictions. However, existing IF methods often fail to provide reliable influence estimates in deep neural networks, particularly when applied to noisy training data. This issue does not stem from inaccuracies in parameter change estimation, which has been the primary focus of prior research, but rather from deficiencies in loss change estimation, specifically due to the sharpness of validation risk. In this work, we establish a theoretical connection between influence estimation error, validation set risk, and its sharpness, underscoring the importance of flat validation minima for accurate influence estimation. Furthermore, we introduce a novel estimation form of Influence Function specifically designed for flat validation minima. Experimental results across various tasks validate the superiority of our approach.",
    "published": "2025-05-25T11:20:28Z",
    "updated": "2025-12-01T03:27:37Z",
    "link": "http://arxiv.org/pdf/2505.19097v3.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Xichen Ye",
      "Yifan Wu",
      "Weizhong Zhang",
      "Cheng Jin",
      "Yifan Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13465v4",
    "title": "AdamNX: An Adam improvement algorithm based on a novel exponential decay mechanism for the second-order moment estimate",
    "summary": "Since the 21st century, artificial intelligence has been leading a new round of industrial revolution. Under the training framework, the optimization algorithm aims to stably converge high-dimensional optimization to local and even global minima. Entering the era of large language models, although the scale of model parameters and data has increased, Adam remains the mainstream optimization algorithm. However, compared with stochastic gradient descent (SGD) based optimization algorithms, Adam is more likely to converge to non-flat minima. To address this issue, the AdamNX algorithm is proposed. Its core innovation lies in the proposition of a novel type of second-order moment estimation exponential decay rate, which gradually weakens the learning step correction strength as training progresses, and degrades to momentum SGD in the stable training period, thereby improving the stability of training in the stable period and possibly enhancing generalization ability. Experimental results show that our second-order moment estimation exponential decay rate is better than the current second-order moment estimation exponential decay rate, and AdamNX can stably outperform Adam and its variants in terms of performance. Our code is open-sourced at https://github.com/mengzhu0308/AdamNX.",
    "published": "2025-11-17T15:07:55Z",
    "updated": "2025-12-01T03:26:04Z",
    "link": "http://arxiv.org/pdf/2511.13465v4.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Meng Zhu",
      "Quan Xiao",
      "Weidong Min"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01231v1",
    "title": "Implicitly Normalized Online PCA: A Regularized Algorithm with Exact High-Dimensional Dynamics",
    "summary": "Many online learning algorithms, including classical online PCA methods, enforce explicit normalization steps that discard the evolving norm of the parameter vector. We show that this norm can in fact encode meaningful information about the underlying statistical structure of the problem, and that exploiting this information leads to improved learning behavior. Motivated by this principle, we introduce Implicitly Normalized Online PCA (INO-PCA), an online PCA algorithm that removes the unit-norm constraint and instead allows the parameter norm to evolve dynamically through a simple regularized update. We prove that in the high-dimensional limit the joint empirical distribution of the estimate and the true component converges to a deterministic measure-valued process governed by a nonlinear PDE. This analysis reveals that the parameter norm obeys a closed-form ODE coupled with the cosine similarity, forming an internal state variable that regulates learning rate, stability, and sensitivity to signal-to-noise ratio (SNR). The resulting dynamics uncover a three-way relationship between the norm, SNR, and optimal step size, and expose a sharp phase transition in steady-state performance. Both theoretically and experimentally, we show that INO-PCA consistently outperforms Oja's algorithm and adapts rapidly in non-stationary environments. Overall, our results demonstrate that relaxing norm constraints can be a principled and effective way to encode and exploit problem-relevant information in online learning algorithms.",
    "published": "2025-12-01T03:17:29Z",
    "updated": "2025-12-01T03:17:29Z",
    "link": "http://arxiv.org/pdf/2512.01231v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Samet Demir",
      "Zafer Dogan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01228v1",
    "title": "On the Tension Between Optimality and Adversarial Robustness in Policy Optimization",
    "summary": "Achieving optimality and adversarial robustness in deep reinforcement learning has long been regarded as conflicting goals. Nonetheless, recent theoretical insights presented in CAR suggest a potential alignment, raising the important question of how to realize this in practice. This paper first identifies a key gap between theory and practice by comparing standard policy optimization (SPO) and adversarially robust policy optimization (ARPO). Although they share theoretical consistency, a fundamental tension between robustness and optimality arises in practical policy gradient methods. SPO tends toward convergence to vulnerable first-order stationary policies (FOSPs) with strong natural performance, whereas ARPO typically favors more robust FOSPs at the expense of reduced returns. Furthermore, we attribute this tradeoff to the reshaping effect of the strongest adversary in ARPO, which significantly complicates the global landscape by inducing deceptive sticky FOSPs. This improves robustness but makes navigation more challenging. To alleviate this, we develop the BARPO, a bilevel framework unifying SPO and ARPO by modulating adversary strength, thereby facilitating navigability while preserving global optima. Extensive empirical results demonstrate that BARPO consistently outperforms vanilla ARPO, providing a practical approach to reconcile theoretical and empirical performance.",
    "published": "2025-12-01T03:14:17Z",
    "updated": "2025-12-01T03:14:17Z",
    "link": "http://arxiv.org/pdf/2512.01228v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Haoran Li",
      "Jiayu Lv",
      "Congying Han",
      "Zicheng Zhang",
      "Anqi Li",
      "Yan Liu",
      "Tiande Guo",
      "Nan Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.01971v2",
    "title": "Revitalizing Canonical Pre-Alignment for Irregular Multivariate Time Series Forecasting",
    "summary": "Irregular multivariate time series (IMTS), characterized by uneven sampling and inter-variate asynchrony, fuel many forecasting applications yet remain challenging to model efficiently. Canonical Pre-Alignment (CPA) has been widely adopted in IMTS modeling by padding zeros at every global timestamp, thereby alleviating inter-variate asynchrony and unifying the series length, but its dense zero-padding inflates the pre-aligned series length, especially when numerous variates are present, causing prohibitive compute overhead. Recent graph-based models with patching strategies sidestep CPA, but their local message passing struggles to capture global inter-variate correlations. Therefore, we posit that CPA should be retained, with the pre-aligned series properly handled by the model, enabling it to outperform state-of-the-art graph-based baselines that sidestep CPA. Technically, we propose KAFNet, a compact architecture grounded in CPA for IMTS forecasting that couples (1) Pre-Convolution module for sequence smoothing and sparsity mitigation, (2) Temporal Kernel Aggregation module for learnable compression and modeling of intra-series irregularity, and (3) Frequency Linear Attention blocks for the low-cost inter-series correlations modeling in the frequency domain. Experiments on multiple IMTS datasets show that KAFNet achieves state-of-the-art forecasting performance, with a 7.2$\\times$ parameter reduction and a 8.4$\\times$ training-inference acceleration.",
    "published": "2025-08-04T01:07:24Z",
    "updated": "2025-12-01T03:09:40Z",
    "link": "http://arxiv.org/pdf/2508.01971v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Ziyu Zhou",
      "Yiming Huang",
      "Yanyun Wang",
      "Yuankai Wu",
      "James Kwok",
      "Yuxuan Liang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01224v1",
    "title": "CoSineVerifier: Tool-Augmented Answer Verification for Computation-Oriented Scientific Questions",
    "summary": "Answer verification methods are widely employed in language model training pipelines spanning data curation, evaluation, and reinforcement learning with verifiable rewards (RLVR). While prior work focus on developing unified verifiers applicable across multiple reasoning scenarios, significant challenges remain in computation-oriented scientific domains, such as algebraic equivalence checking and physical constant substitution. In this paper, we introduce \\model, a tool-augmented verifier that leverages external executors to perform precise computations and symbolic simplifications. \\model enables robust verification that goes beyond simple semantic matching. We propose a novel two-stage pipeline, which begin with cold-start fine-tuning and followed by multi-turn reinforcement learning with tool integration. Extensive experiments conducted on STEM subjects, general QA, and long-form reasoning tasks demonstrates strong generalization of \\model. The results shows that the \\model achieves state-of-the-art performance on VerifyBench-Hard and SCI-Bench. And we also employ our \\model in RLVR as a reward model, the results show that it consistently outperforms both rubric-based and model-based verifiers on AIME'24 and AIME'25, demonstrating strong potential to enhance reasoning capabilities of LLM. Our model is released at \\hyperlink{https://huggingface.co/Nanbeige/CoSineVerifier-Tool-4B}{https://huggingface.co/Nanbeige/CoSineVerifier-Tool-4B}.",
    "published": "2025-12-01T03:08:43Z",
    "updated": "2025-12-01T03:08:43Z",
    "link": "http://arxiv.org/pdf/2512.01224v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Ruixiang Feng",
      "Zhenwei An",
      "Yuntao Wen",
      "Ran Le",
      "Yiming Jia",
      "Chen Yang",
      "Zongchao Chen",
      "Lisi Chen",
      "Shen Gao",
      "Shuo Shang",
      "Yang Song",
      "Tao Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.20963v3",
    "title": "Crowdsourcing the Frontier: Advancing Hybrid Physics-ML Climate Simulation via a $50,000 Kaggle Competition",
    "summary": "Subgrid machine-learning (ML) parameterizations have the potential to introduce a new generation of climate models that incorporate the effects of higher-resolution physics without incurring the prohibitive computational cost associated with more explicit physics-based simulations. However, important issues, ranging from online instability to inconsistent online performance, have limited their operational use for long-term climate projections. To more rapidly drive progress in solving these issues, domain scientists and machine learning researchers opened up the offline aspect of this problem to the broader machine learning and data science community with the release of ClimSim, a NeurIPS Datasets and Benchmarks publication, and an associated Kaggle competition. This paper reports on the downstream results of the Kaggle competition by coupling emulators inspired by the winning teams' architectures to an interactive climate model (including full cloud microphysics, a regime historically prone to online instability) and systematically evaluating their online performance. Our results demonstrate that online stability in the low-resolution, real-geography setting is reproducible across multiple diverse architectures, which we consider a key milestone. All tested architectures exhibit strikingly similar offline and online biases, though their responses to architecture-agnostic design choices (e.g., expanding the list of input variables) can differ significantly. Multiple Kaggle-inspired architectures achieve state-of-the-art (SOTA) results on certain metrics such as zonal mean bias patterns and global RMSE, indicating that crowdsourcing the essence of the offline problem is one path to improving online performance in hybrid physics-AI climate simulation.",
    "published": "2025-11-26T01:32:02Z",
    "updated": "2025-12-01T03:00:24Z",
    "link": "http://arxiv.org/pdf/2511.20963v3.pdf",
    "category": [
      "physics.ao-ph",
      "cs.LG"
    ],
    "authors": [
      "Jerry Lin",
      "Zeyuan Hu",
      "Tom Beucler",
      "Katherine Frields",
      "Hannah Christensen",
      "Walter Hannah",
      "Helge Heuer",
      "Peter Ukkonnen",
      "Laura A. Mansfield",
      "Tian Zheng",
      "Liran Peng",
      "Ritwik Gupta",
      "Pierre Gentine",
      "Yusef Al-Naher",
      "Mingjiang Duan",
      "Kyo Hattori",
      "Weiliang Ji",
      "Chunhan Li",
      "Kippei Matsuda",
      "Naoki Murakami",
      "Shlomo Ron",
      "Marec Serlin",
      "Hongjian Song",
      "Yuma Tanabe",
      "Daisuke Yamamoto",
      "Jianyao Zhou",
      "Mike Pritchard"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01212v1",
    "title": "A Comparative Study of Machine Learning Algorithms for Electricity Price Forecasting with LIME-Based Interpretability",
    "summary": "With the rapid development of electricity markets, price volatility has significantly increased, making accurate forecasting crucial for power system operations and market decisions. Traditional linear models cannot capture the complex nonlinear characteristics of electricity pricing, necessitating advanced machine learning approaches. This study compares eight machine learning models using Spanish electricity market data, integrating consumption, generation, and meteorological variables. The models evaluated include linear regression, ridge regression, decision tree, KNN, random forest, gradient boosting, SVR, and XGBoost. Results show that KNN achieves the best performance with R^2 of 0.865, MAE of 3.556, and RMSE of 5.240. To enhance interpretability, LIME analysis reveals that meteorological factors and supply-demand indicators significantly influence price fluctuations through nonlinear relationships. This work demonstrates the effectiveness of machine learning models in electricity price forecasting while improving decision transparency through interpretability analysis.",
    "published": "2025-12-01T02:51:41Z",
    "updated": "2025-12-01T02:51:41Z",
    "link": "http://arxiv.org/pdf/2512.01212v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Xuanyi Zhao",
      "Jiawen Ding",
      "Xueting Huang",
      "Yibo Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01205v1",
    "title": "Research on Milling Machine Predictive Maintenance Based on Machine Learning and SHAP Analysis in Intelligent Manufacturing Environment",
    "summary": "In the context of intelligent manufacturing, this paper conducts a series of experimental studies on the predictive maintenance of industrial milling machine equipment based on the AI4I 2020 dataset. This paper proposes a complete predictive maintenance experimental process combining artificial intelligence technology, including six main links: data preprocessing, model training, model evaluation, model selection, SHAP analysis, and result visualization. By comparing and analyzing the performance of eight machine learning models, it is found that integrated learning methods such as XGBoost and random forest perform well in milling machine fault prediction tasks. In addition, with the help of SHAP analysis technology, the influence mechanism of different features on equipment failure is deeply revealed, among which processing temperature, torque and speed are the key factors affecting failure. This study combines artificial intelligence and manufacturing technology, provides a methodological reference for predictive maintenance practice in an intelligent manufacturing environment, and has practical significance for promoting the digital transformation of the manufacturing industry, improving production efficiency and reducing maintenance costs.",
    "published": "2025-12-01T02:40:49Z",
    "updated": "2025-12-01T02:40:49Z",
    "link": "http://arxiv.org/pdf/2512.01205v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Wen Zhao",
      "Jiawen Ding",
      "Xueting Huang",
      "Yibo Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01203v1",
    "title": "The Evolution of Learning Algorithms for Artificial Neural Networks",
    "summary": "In this paper we investigate a neural network model in which weights between computational nodes are modified according to a local learning rule. To determine whether local learning rules are sufficient for learning, we encode the network architectures and learning dynamics genetically and then apply selection pressure to evolve networks capable of learning the four boolean functions of one variable. The successful networks are analysed and we show how learning behaviour emerges as a distributed property of the entire network. Finally the utility of genetic algorithms as a tool of discovery is discussed.",
    "published": "2025-12-01T02:38:40Z",
    "updated": "2025-12-01T02:38:40Z",
    "link": "http://arxiv.org/pdf/2512.01203v1.pdf",
    "category": [
      "cs.NE",
      "cs.LG"
    ],
    "authors": [
      "Jonathan Baxter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01202v1",
    "title": "Sum Rate Maximization in STAR-RIS-UAV-Assisted Networks: A CA-DDPG Approach for Joint Optimization",
    "summary": "With the rapid advances in programmable materials, reconfigurable intelligent surfaces (RIS) have become a pivotal technology for future wireless communications. The simultaneous transmitting and reflecting reconfigurable intelligent surfaces (STAR-RIS) can both transmit and reflect signals, enabling comprehensive signal control and expanding application scenarios. This paper introduces an unmanned aerial vehicle (UAV) to further enhance system flexibility and proposes an optimization design for the spectrum efficiency of the STAR-RIS-UAV-assisted wireless communication system. We present a deep reinforcement learning (DRL) algorithm capable of iteratively optimizing beamforming, phase shifts, and UAV positioning to maximize the system's sum rate through continuous interactions with the environment. To improve exploration in deterministic policies, we introduce a stochastic perturbation factor, which enhances exploration capabilities. As exploration is strengthened, the algorithm's ability to accurately evaluate the state-action value function becomes critical. Thus, based on the deep deterministic policy gradient (DDPG) algorithm, we propose a convolution-augmented deep deterministic policy gradient (CA-DDPG) algorithm that balances exploration and evaluation to improve the system's sum rate. The simulation results demonstrate that the CA-DDPG algorithm effectively interacts with the environment, optimizing the beamforming matrix, phase shift matrix, and UAV location, thereby improving system capacity and achieving better performance than other algorithms.",
    "published": "2025-12-01T02:36:00Z",
    "updated": "2025-12-01T02:36:00Z",
    "link": "http://arxiv.org/pdf/2512.01202v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Yujie Huang",
      "Haibin Wan",
      "Xiangcheng Li",
      "Tuanfa Qin",
      "Yun Li",
      "Jun Li",
      "Wen Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01199v1",
    "title": "Know Thyself by Knowing Others: Learning Neuron Identity from Population Context",
    "summary": "Neurons process information in ways that depend on their cell type, connectivity, and the brain region in which they are embedded. However, inferring these factors from neural activity remains a significant challenge. To build general-purpose representations that allow for resolving information about a neuron's identity, we introduce NuCLR, a self-supervised framework that aims to learn representations of neural activity that allow for differentiating one neuron from the rest. NuCLR brings together views of the same neuron observed at different times and across different stimuli and uses a contrastive objective to pull these representations together. To capture population context without assuming any fixed neuron ordering, we build a spatiotemporal transformer that integrates activity in a permutation-equivariant manner. Across multiple electrophysiology and calcium imaging datasets, a linear decoding evaluation on top of NuCLR representations achieves a new state-of-the-art for both cell type and brain region decoding tasks, and demonstrates strong zero-shot generalization to unseen animals. We present the first systematic scaling analysis for neuron-level representation learning, showing that increasing the number of animals used during pretraining consistently improves downstream performance. The learned representations are also label-efficient, requiring only a small fraction of labeled samples to achieve competitive performance. These results highlight how large, diverse neural datasets enable models to recover information about neuron identity that generalize across animals. Code is available at https://github.com/nerdslab/nuclr.",
    "published": "2025-12-01T02:28:04Z",
    "updated": "2025-12-01T02:28:04Z",
    "link": "http://arxiv.org/pdf/2512.01199v1.pdf",
    "category": [
      "cs.LG",
      "q-bio.NC"
    ],
    "authors": [
      "Vinam Arora",
      "Divyansha Lachi",
      "Ian J. Knight",
      "Mehdi Azabou",
      "Blake Richards",
      "Cole L. Hurwitz",
      "Josh Siegle",
      "Eva L. Dyer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01196v1",
    "title": "Learning to Reconstruct Temperature Field from Sparse Observations with Implicit Physics Priors",
    "summary": "Accurate reconstruction of temperature field of heat-source systems (TFR-HSS) is crucial for thermal monitoring and reliability assessment in engineering applications such as electronic devices and aerospace structures. However, the high cost of measurement acquisition and the substantial distributional shifts in temperature field across varying conditions present significant challenges for developing reconstruction models with robust generalization capabilities. Existing DNNs-based methods typically formulate TFR-HSS as a one-to-one regression problem based solely on target sparse measurements, without effectively leveraging reference simulation data that implicitly encode thermal knowledge. To address this limitation, we propose IPTR, an implicit physics-guided temperature field reconstruction framework that introduces sparse monitoring-temperature field pair from reference simulations as priors to enrich physical understanding. To integrate both reference and target information, we design a dual physics embedding module consisting of two complementary branches: an implicit physics-guided branch employing cross-attention to distill latent physics from the reference data, and an auxiliary encoding branch based on Fourier layers to capture the spatial characteristics of the target observation. The fused representation is then decoded to reconstruct the full temperature field. Extensive experiments under single-condition, multi-condition, and few-shot settings demonstrate that IPTR consistently outperforms existing methods, achieving state-of-the-art reconstruction accuracy and strong generalization capability.",
    "published": "2025-12-01T02:22:30Z",
    "updated": "2025-12-01T02:22:30Z",
    "link": "http://arxiv.org/pdf/2512.01196v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Shihang Li",
      "Zhiqiang Gong",
      "Weien Zhou",
      "Yue Gao",
      "Wen Yao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01190v1",
    "title": "LGDC: Latent Graph Diffusion via Spectrum-Preserving Coarsening",
    "summary": "Graph generation is a critical task across scientific domains. Existing methods fall broadly into two categories: autoregressive models, which iteratively expand graphs, and one-shot models, such as diffusion, which generate the full graph at once. In this work, we provide an analysis of these two paradigms and reveal a key trade-off: autoregressive models stand out in capturing fine-grained local structures, such as degree and clustering properties, whereas one-shot models excel at modeling global patterns, such as spectral distributions. Building on this, we propose LGDC (latent graph diffusion via spectrum-preserving coarsening), a hybrid framework that combines strengths of both approaches. LGDC employs a spectrum-preserving coarsening-decoarsening to bidirectionally map between graphs and a latent space, where diffusion efficiently generates latent graphs before expansion restores detail. This design captures both local and global properties with improved efficiency. Empirically, LGDC matches autoregressive models on locally structured datasets (Tree) and diffusion models on globally structured ones (Planar, Community-20), validating the benefits of hybrid generation.",
    "published": "2025-12-01T02:10:24Z",
    "updated": "2025-12-01T02:10:24Z",
    "link": "http://arxiv.org/pdf/2512.01190v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Nagham Osman",
      "Keyue Jiang",
      "Davide Buffelli",
      "Xiaowen Dong",
      "Laura Toni"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.03840v4",
    "title": "Machine learning applications in archaeological practices: a review",
    "summary": "Artificial intelligence and machine learning applications in archaeology have increased significantly in recent years, and these now span all subfields, geographical regions, and time periods. The prevalence and success of these applications have remained largely unexamined, as recent reviews on the use of machine learning in archaeology have only focused only on specific subfields of archaeology. Our review examined an exhaustive corpus of 135 articles published between 1997 and 2022. We observed a significant increase in the number of publications from 2019 onwards. Automatic structure detection and artefact classification were the most represented tasks in the articles reviewed, followed by taphonomy, and archaeological predictive modelling. From the review, clustering and unsupervised methods were underrepresented compared to supervised models. Artificial neural networks and ensemble learning account for two thirds of the total number of models used. However, if machine learning models are gaining in popularity they remain subject to misunderstanding. We observed, in some cases, poorly defined requirements and caveats of the machine learning methods used. Furthermore, the goals and the needs of machine learning applications for archaeological purposes are in some cases unclear or poorly expressed. To address this, we proposed a workflow guide for archaeologists to develop coherent and consistent methodologies adapted to their research questions, project scale and data. As in many other areas, machine learning is rapidly becoming an important tool in archaeological research and practice, useful for the analyses of large and multivariate data, although not without limitations. This review highlights the importance of well-defined and well-reported structured methodologies and collaborative practices to maximise the potential of applications of machine learning methods in archaeology.",
    "published": "2025-01-07T14:50:05Z",
    "updated": "2025-12-01T01:42:34Z",
    "link": "http://arxiv.org/pdf/2501.03840v4.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Mathias Bellat",
      "Jordy D. Orellana Figueroa",
      "Jonathan S. Reeves",
      "Ruhollah Taghizadeh-Mehrjardi",
      "Claudio Tennie",
      "Thomas Scholten"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.21829v2",
    "title": "In Search of Adam's Secret Sauce",
    "summary": "Understanding the remarkable efficacy of Adam when training transformer-based language models has become a central research topic within the optimization community. To gain deeper insights, several simplifications of Adam have been proposed, such as the signed gradient and signed momentum methods. In this work, we conduct an extensive empirical study - training over 1500 language models across different data configurations and scales - comparing Adam to several known simplified variants. We find that signed momentum methods are faster than SGD, but consistently underperform relative to Adam, even after careful tuning of momentum, clipping setting and learning rates. However, our analysis reveals a compelling option that preserves near-optimal performance while allowing for new insightful reformulations: constraining the Adam momentum parameters to be equal, beta1 = beta2. Beyond robust performance, this choice affords new theoretical insights, highlights the \"secret sauce\" on top of signed momentum, and grants a precise statistical interpretation: we show that Adam in this setting implements a natural online algorithm for estimating the mean and variance of gradients-one that arises from a mean-field Gaussian variational inference perspective.",
    "published": "2025-05-27T23:30:18Z",
    "updated": "2025-12-01T01:28:44Z",
    "link": "http://arxiv.org/pdf/2505.21829v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Antonio Orvieto",
      "Robert M. Gower"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.25783v3",
    "title": "Sharpness of Minima in Deep Matrix Factorization: Exact Expressions",
    "summary": "Understanding the geometry of the loss landscape near a minimum is key to explaining the implicit bias of gradient-based methods in non-convex optimization problems such as deep neural network training and deep matrix factorization. A central quantity to characterize this geometry is the maximum eigenvalue of the Hessian of the loss, which measures the sharpness of the landscape. Currently, its precise role has been obfuscated because no exact expressions for this sharpness measure were known in general settings. In this paper, we present the first exact expression for the maximum eigenvalue of the Hessian of the squared-error loss at any minimizer in general overparameterized deep matrix factorization (i.e., deep linear neural network training) problems, resolving an open question posed by Mulayoff & Michaeli (2020). This expression uncovers a fundamental property of the loss landscape of depth-2 matrix factorization problems: a minimum is flat if and only if it is spectral-norm balanced, which implies that flat minima are not necessarily Frobenius-norm balanced. Furthermore, to complement our theory, we empirically investigate an escape phenomenon observed during gradient-based training near a minimum that crucially relies on our exact expression of the sharpness.",
    "published": "2025-09-30T04:50:28Z",
    "updated": "2025-12-01T01:10:04Z",
    "link": "http://arxiv.org/pdf/2509.25783v3.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "math.OC"
    ],
    "authors": [
      "Anil Kamber",
      "Rahul Parhi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.04490v2",
    "title": "Multiscale guidance of protein structure prediction with heterogeneous cryo-EM data",
    "summary": "Protein structure prediction models are now capable of generating accurate 3D structural hypotheses from sequence alone. However, they routinely fail to capture the conformational diversity of dynamic biomolecular complexes, often requiring heuristic MSA subsampling approaches for generating alternative states. In parallel, cryo-electron microscopy (cryo-EM) has emerged as a powerful tool for imaging near-native structural heterogeneity, but is challenged by arduous pipelines to transform raw experimental data into atomic models. Here, we bridge the gap between these modalities, combining cryo-EM density maps with the rich sequence and biophysical priors learned by protein structure prediction models. Our method, CryoBoltz, guides the sampling trajectory of a pretrained biomolecular structure prediction model using both global and local structural constraints derived from density maps, driving predictions towards conformational states consistent with the experimental data. We demonstrate that this flexible yet powerful inference-time approach allows us to build atomic models into heterogeneous cryo-EM maps across a variety of dynamic biomolecular systems including transporters and antibodies. Code is available at https://github.com/ml-struct-bio/cryoboltz .",
    "published": "2025-06-04T22:16:27Z",
    "updated": "2025-12-01T01:05:46Z",
    "link": "http://arxiv.org/pdf/2506.04490v2.pdf",
    "category": [
      "cs.LG",
      "q-bio.BM"
    ],
    "authors": [
      "Rishwanth Raghu",
      "Axel Levy",
      "Gordon Wetzstein",
      "Ellen D. Zhong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01172v1",
    "title": "High-dimensional Mean-Field Games by Particle-based Flow Matching",
    "summary": "Mean-field games (MFGs) study the Nash equilibrium of systems with a continuum of interacting agents, which can be formulated as the fixed-point of optimal control problems. They provide a unified framework for a variety of applications, including optimal transport (OT) and generative models. Despite their broad applicability, solving high-dimensional MFGs remains a significant challenge due to fundamental computational and analytical obstacles. In this work, we propose a particle-based deep Flow Matching (FM) method to tackle high-dimensional MFG computation. In each iteration of our proximal fixed-point scheme, particles are updated using first-order information, and a flow neural network is trained to match the velocity of the sample trajectories in a simulation-free manner. Theoretically, in the optimal control setting, we prove that our scheme converges to a stationary point sublinearly, and upgrade to linear (exponential) convergence under additional convexity assumptions. Our proof uses FM to induce an Eulerian coordinate (density-based) from a Lagrangian one (particle-based), and this also leads to certain equivalence results between the two formulations for MFGs when the Eulerian solution is sufficiently regular. Our method demonstrates promising performance on non-potential MFGs and high-dimensional OT problems cast as MFGs through a relaxed terminal-cost formulation.",
    "published": "2025-12-01T01:04:53Z",
    "updated": "2025-12-01T01:04:53Z",
    "link": "http://arxiv.org/pdf/2512.01172v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "math.OC"
    ],
    "authors": [
      "Jiajia Yu",
      "Junghwan Lee",
      "Yao Xie",
      "Xiuyuan Cheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2312.01294v4",
    "title": "Deep sub-ensembles meets quantile regression: uncertainty-aware imputation for time series",
    "summary": "Real-world time series data often exhibits substantial missing values, posing challenges for advanced analysis. A common approach to addressing this issue is imputation, where the primary challenge lies in determining the appropriate values to fill in. While previous deep learning methods have proven effective for time series imputation, they often produce overconfident imputations, which poses a potentially overlooked risk to the reliability of the intelligent system. Diffusion methods are proficient in estimating probability distributions but face challenges under a high missing rate and are, moreover, computationally expensive due to the nature of the generative model framework. In this paper, we propose Quantile Sub-Ensembles, a novel method that estimates uncertainty with ensembles of quantile-regression-based task networks and incorporate Quantile Sub-Ensembles into a non-generative time series imputation method. Our method not only produces accurate and reliable imputations, but also remains computationally efficient due to its non-generative framework. We conduct extensive experiments on five real-world datasets, and the results demonstrates superior performance in both deterministic and probabilistic imputation compared to baselines across most experimental settings. The code is available at https://github.com/yingliu-coder/QSE.",
    "published": "2023-12-03T05:52:30Z",
    "updated": "2025-12-01T00:55:41Z",
    "link": "http://arxiv.org/pdf/2312.01294v4.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Ying Liu",
      "Peng Cui",
      "Wenbo Hu",
      "Richang Hong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01160v1",
    "title": "From Regression to Classification: Exploring the Benefits of Categorical Representations of Energy in MLIPs",
    "summary": "Density Functional Theory (DFT) is a widely used computational method for estimating the energy and behavior of molecules. Machine Learning Interatomic Potentials (MLIPs) are models trained to approximate DFT-level energies and forces at dramatically lower computational cost. Many modern MLIPs rely on a scalar regression formulation; given information about a molecule, they predict a single energy value and corresponding forces while minimizing absolute error with DFT's calculations. In this work, we explore a multi-class classification formulation that predicts a categorical distribution over energy/force values, providing richer supervision through multiple targets. Most importantly, this approach offers a principled way to quantify model uncertainty.\n  In particular, our method predicts a histogram of the energy/force distribution, converts scalar targets into histograms, and trains the model using cross-entropy loss. Our results demonstrate that this categorical formulation can achieve absolute error performance comparable to regression baselines. Furthermore, this representation enables the quantification of epistemic uncertainty through the entropy of the predicted distribution, offering a measure of model confidence absent in scalar regression approaches.",
    "published": "2025-12-01T00:36:42Z",
    "updated": "2025-12-01T00:36:42Z",
    "link": "http://arxiv.org/pdf/2512.01160v1.pdf",
    "category": [
      "cs.LG",
      "q-bio.MN"
    ],
    "authors": [
      "Ahmad Ali"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01151v1",
    "title": "Fiber Bundle Networks: A Geometric Machine Learning Paradigm",
    "summary": "We propose Fiber Bundle Networks (FiberNet), a novel machine learning framework integrating differential geometry with machine learning. Unlike traditional deep neural networks relying on black-box function fitting, we reformulate classification as interpretable geometric optimization on fiber bundles, where categories form the base space and wavelet-transformed features lie in the fibers above each category. We introduce two innovations: (1) learnable Riemannian metrics identifying important frequency feature components, (2) variational prototype optimization through energy function minimization. Classification is performed via Voronoi tessellation under the learned Riemannian metric, where each prototype defines a decision region and test samples are assigned to the nearest prototype, providing clear geometric interpretability. This work demonstrates that the integration of fiber bundle with machine learning provides interpretability and efficiency, which are difficult to obtain simultaneously in conventional deep learning.",
    "published": "2025-12-01T00:06:17Z",
    "updated": "2025-12-01T00:06:17Z",
    "link": "http://arxiv.org/pdf/2512.01151v1.pdf",
    "category": [
      "cs.LG",
      "math.DG"
    ],
    "authors": [
      "Dong Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01150v1",
    "title": "Dynamic Algorithm for Explainable k-medians Clustering under lp Norm",
    "summary": "We study the problem of explainable k-medians clustering introduced by Dasgupta, Frost, Moshkovitz, and Rashtchian (2020). In this problem, the goal is to construct a threshold decision tree that partitions data into k clusters while minimizing the k-medians objective. These trees are interpretable because each internal node makes a simple decision by thresholding a single feature, allowing users to trace and understand how each point is assigned to a cluster. We present the first algorithm for explainable k-medians under lp norm for every finite p >= 1. Our algorithm achieves an O(p(log k)^{1 + 1/p - 1/p^2}) approximation to the optimal k-medians cost for any p >= 1. Previously, algorithms were known only for p = 1 and p = 2. For p = 2, our algorithm improves upon the existing bound of O(log^{3/2}k), and for p = 1, it matches the tight bound of log k + O(1) up to a multiplicative O(log log k) factor. We show how to implement our algorithm in a dynamic setting. The dynamic algorithm maintains an explainable clustering under a sequence of insertions and deletions, with amortized update time O(d log^3 k) and O(log k) recourse, making it suitable for large-scale and evolving datasets.",
    "published": "2025-12-01T00:01:47Z",
    "updated": "2025-12-01T00:01:47Z",
    "link": "http://arxiv.org/pdf/2512.01150v1.pdf",
    "category": [
      "cs.LG",
      "cs.DS"
    ],
    "authors": [
      "Konstantin Makarychev",
      "Ilias Papanikolaou",
      "Liren Shan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.19155v2",
    "title": "VeFA: Vector-Based Feature Space Adaptation for Robust Model Fine-Tuning",
    "summary": "Catastrophic forgetting is a well-documented challenge in model fine-tuning, particularly when the downstream domain has limited labeled data or differs substantially from the pre-training distribution. Existing parameter-efficient fine-tuning methods largely operate in the weight space by modifying or augmenting the parameters of the pre-trained model, which can lead to models that are overly specialized to the observed downstream data. Recent studies suggest that one mechanism underlying such forgetting is the introduction of intruder dimensions into the representation space during fine-tuning. To mitigate the risk of overwriting pre-trained knowledge and to enhance robustness, we propose Vector-based Feature Adaptation (VeFA), a new fine-tuning method that operates directly in the feature space, which naturally avoids generating intruder dimensions. VeFA performs element-wise adaptation on individual features, thereby ensuring that the effective fine-tuned weights always remain within the column space of the pre-trained weight matrix. This feature-space adaptation perspective is inspired by the idea of effect equivalence modeling (EEM) of downstream lurking variables that induce distribution shifts, which posits that the influence of unobserved factors can be represented as an equivalent aggregate effect on observed features. By compensating for the effects of downstream lurking variables via a lightweight feature-level transformation, VeFA preserves the pre-trained representations and improves model generalization under distribution shift. We evaluate VeFA against LoRA on image classification, NLU, and NLG benchmarks, considering both standard fine-tuning performance and robustness; across these tasks, VeFA achieves comparable fine-tuning performance while consistently exhibiting stronger robustness.",
    "published": "2025-10-22T01:06:12Z",
    "updated": "2025-11-30T23:49:23Z",
    "link": "http://arxiv.org/pdf/2510.19155v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Peng Wang",
      "Minghao Gu",
      "Qiang Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01147v1",
    "title": "Projection-Free CNN Pruning via Frank-Wolfe with Momentum: Sparser Models with Less Pretraining",
    "summary": "We investigate algorithmic variants of the Frank-Wolfe (FW) optimization method for pruning convolutional neural networks. This is motivated by the \"Lottery Ticket Hypothesis\", which suggests the existence of smaller sub-networks within larger pre-trained networks that perform comparatively well (if not better). Whilst most literature in this area focuses on Deep Neural Networks more generally, we specifically consider Convolutional Neural Networks for image classification tasks. Building on the hypothesis, we compare simple magnitude-based pruning, a Frank-Wolfe style pruning scheme, and an FW method with momentum on a CNN trained on MNIST. Our experiments track test accuracy, loss, sparsity, and inference time as we vary the dense pre-training budget from 1 to 10 epochs. We find that FW with momentum yields pruned networks that are both sparser and more accurate than the original dense model and the simple pruning baselines, while incurring minimal inference-time overhead in our implementation. Moreover, FW with momentum reaches these accuracies after only a few epochs of pre-training, indicating that full pre-training of the dense model is not required in this setting.",
    "published": "2025-11-30T23:48:53Z",
    "updated": "2025-11-30T23:48:53Z",
    "link": "http://arxiv.org/pdf/2512.01147v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Hamza ElMokhtar Shili",
      "Natasha Patnaik",
      "Isabelle Ruble",
      "Kathryn Jarjoura",
      "Daniel Suarez Aguirre"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.05140v2",
    "title": "Auditing Algorithmic Bias in Transformer-Based Trading",
    "summary": "Transformer models have become increasingly popular in financial applications, yet their potential risk making and biases remain under-explored. The purpose of this work is to audit the reliance of the model on volatile data for decision-making, and quantify how the frequency of price movements affects the model's prediction confidence. We employ a transformer model for prediction, and introduce a metric based on Partial Information Decomposition (PID) to measure the influence of each asset on the model's decision making. Our analysis reveals two key observations: first, the model disregards data volatility entirely, and second, it is biased toward data with lower-frequency price movements.",
    "published": "2025-10-01T21:20:26Z",
    "updated": "2025-11-30T23:39:22Z",
    "link": "http://arxiv.org/pdf/2510.05140v2.pdf",
    "category": [
      "cs.LG",
      "cs.CE"
    ],
    "authors": [
      "Armin Gerami",
      "Ramani Duraiswami"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.27044v2",
    "title": "Limits of Generalization in RLVR: Two Case Studies in Mathematical Reasoning",
    "summary": "Mathematical reasoning is a central challenge for large language models (LLMs), requiring not only correct answers but also faithful reasoning processes. Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a promising approach for enhancing such capabilities; however, its ability to foster genuine reasoning remains unclear. We investigate RLVR on two combinatorial problems with fully verifiable solutions: \\emph{Activity Scheduling} and the \\emph{Longest Increasing Subsequence}, using carefully curated datasets with unique optima. Across multiple reward designs, we find that RLVR improves evaluation metrics but often by reinforcing superficial heuristics rather than acquiring new reasoning strategies. These findings highlight the limits of RLVR generalization, emphasizing the importance of benchmarks that disentangle genuine mathematical reasoning from shortcut exploitation and provide faithful measures of progress. Code available at https://github.com/xashru/rlvr-seq-generalization.",
    "published": "2025-10-30T23:16:02Z",
    "updated": "2025-11-30T23:39:14Z",
    "link": "http://arxiv.org/pdf/2510.27044v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Md Tanvirul Alam",
      "Nidhi Rastogi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01141v1",
    "title": "Neural Variable Name Repair: Learning to Rename Identifiers for Readability",
    "summary": "Developers routinely work with source files whose variable names are generic or misleading, and with teams moving quickly, many functions are left undocumented. This slows comprehension, increases the risk of subtle bugs, and makes it harder for both humans and large language models (LLMs) to reason about code. We study variable name repair: given a real C++ function where all occurrences of one local or parameter name have been replaced by a placeholder (e.g. ID 1), the goal is to generate a natural, descriptive replacement name. We automatically construct this task from the C++ portion of BigCode's The Stack by parsing functions with Tree-sitter, masking a single identifier, and treating the original name as supervision. On top of Llama 3.1-8B, we build a pipeline with (i) warmup and dropout schedules for more stable fine-tuning, (ii) LoRA adapters for efficient specialization on identifier repair, and (iii) a dual-encoder reranker over top-k generator candidates. We evaluate using exact match, Top-5 Hit, and an embedding-based partial similarity score (0-100) that gives credit for near synonyms and format variants (e.g., jsonValue vs. json). On a held-out set of 200 C++ functions, a zero-shot Llama 3.1 baseline reaches 6.1 percent exact match. Our best LoRA-tuned model (with warmup and dropout) achieves 43.1 percent exact match, 50.2 percent Top-5 Hit, and an 82.03 partial-match score. A dual encoder reranker further improves selection quality without modifying the underlying generator, suggesting that task-specific fine-tuning plus reranking is a promising approach for practical identifier repair tools.",
    "published": "2025-11-30T23:37:46Z",
    "updated": "2025-11-30T23:37:46Z",
    "link": "http://arxiv.org/pdf/2512.01141v1.pdf",
    "category": [
      "cs.SE",
      "cs.LG"
    ],
    "authors": [
      "Muhammad Yousuf",
      "Akshat Bagade",
      "Chhittebbayi Penugonda",
      "Maanas Baraya"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.10097v3",
    "title": "STaRFormer: Semi-Supervised Task-Informed Representation Learning via Dynamic Attention-Based Regional Masking for Sequential Data",
    "summary": "Understanding user intent is essential for situational and context-aware decision-making. Motivated by a real-world scenario, this work addresses intent predictions of smart device users in the vicinity of vehicles by modeling sequential spatiotemporal data. However, in real-world scenarios, environmental factors and sensor limitations can result in non-stationary and irregularly sampled data, posing significant challenges. To address these issues, we propose STaRFormer, a Transformer-based approach that can serve as a universal framework for sequential modeling. STaRFormer utilizes a new dynamic attention-based regional masking scheme combined with a novel semi-supervised contrastive learning paradigm to enhance task-specific latent representations. Comprehensive experiments on 56 datasets varying in types (including non-stationary and irregularly sampled), tasks, domains, sequence lengths, training samples, and applications demonstrate the efficacy of STaRFormer, achieving notable improvements over state-of-the-art approaches.",
    "published": "2025-04-14T11:03:19Z",
    "updated": "2025-11-30T23:15:08Z",
    "link": "http://arxiv.org/pdf/2504.10097v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Maximilian Forstenhäusler",
      "Daniel Külzer",
      "Christos Anagnostopoulos",
      "Shameem Puthiya Parambath",
      "Natascha Weber"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.02469v2",
    "title": "Exploring Variational Graph Autoencoders for Distribution Grid Data Generation",
    "summary": "To address the lack of public power system data for machine learning research in energy networks, we investigate the use of variational graph autoencoders (VGAEs) for synthetic distribution grid generation. Using two open-source datasets, ENGAGE and DINGO, we evaluate four decoder variants and compare generated networks against the original grids using structural and spectral metrics. Results indicate that simple decoders fail to capture realistic topologies, while GCN-based approaches achieve strong fidelity on ENGAGE but struggle on the more complex DINGO dataset, producing artifacts such as disconnected components and repeated motifs. These findings highlight both the promise and limitations of VGAEs for grid synthesis, underscoring the need for more expressive generative models and robust evaluation. We release our models and analysis as open source to support benchmarking and accelerate progress in ML-driven power system research.",
    "published": "2025-09-02T16:23:15Z",
    "updated": "2025-11-30T21:58:03Z",
    "link": "http://arxiv.org/pdf/2509.02469v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Syed Zain Abbas",
      "Ehimare Okoyomon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01093v1",
    "title": "Bayesian dynamic scheduling of multipurpose batch processes under incomplete look-ahead information",
    "summary": "Multipurpose batch processes become increasingly popular in manufacturing industries since they adapt to low-volume, high-value products and shifting demands. These processes often operate in a dynamic environment, which faces disturbances such as processing delays and demand changes. To minimise long-term cost and system nervousness (i.e., disruptive changes to schedules), schedulers must design rescheduling strategies to address such disturbances effectively. Existing methods often assume complete look-ahead information over the scheduling horizon. This assumption contrasts with realistic situations where schedulers can only access incomplete look-ahead information. Sticking with existing methods may lead to suboptimal long-term costs and high-level system nervousness. In this work we propose a Bayesian dynamic scheduling method. Our method relies on learning a Bayesian Network from the probability distribution of disturbances. Specifically, the Bayesian Network represents how likely each operation will be impacted by disturbances. During the online execution, when new disturbances become observed, this method updates the posterior distribution and therefore guides the rescheduling strategy. We compare our method with the existing periodic rescheduling strategy (which generates new schedules from scratch at fixed intervals) on four benchmark problems. Computational results show that our method achieves statistically better long-term costs and system nervousness. In the theoretical aspect, we prove that if disturbances are mutually independent, the impact-quantifying variables inherently satisfy the independence assumptions required by Bayesian Networks. As an implication, practitioners can extend the method to other scheduling problems (such as job shop scheduling and continuous processes), given that they define the problem-specific dependencies between operations.",
    "published": "2025-11-30T21:27:52Z",
    "updated": "2025-11-30T21:27:52Z",
    "link": "http://arxiv.org/pdf/2512.01093v1.pdf",
    "category": [
      "cs.LG",
      "eess.SY",
      "math.OC",
      "stat.ML"
    ],
    "authors": [
      "Taicheng Zheng",
      "Dan Li",
      "Jie Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01080v1",
    "title": "Building Trustworthy AI for Materials Discovery: From Autonomous Laboratories to Z-scores",
    "summary": "Accelerated material discovery increasingly relies on artificial intelligence and machine learning, collectively termed \"AI/ML\". A key challenge in using AI is ensuring that human scientists trust the models are valid and reliable. Accordingly, we define a trustworthy AI framework GIFTERS for materials science and discovery to evaluate whether reported machine learning methods are generalizable, interpretable, fair, transparent, explainable, robust, and stable. Through a critical literature review, we highlight that these are the trustworthiness principles most valued by the materials discovery community. However, we also find that comprehensive approaches to trustworthiness are rarely reported; this is quantified by a median GIFTERS score of 5/7. We observe that Bayesian studies frequently omit fair data practices, while non-Bayesian studies most frequently omit interpretability. Finally, we identify approaches for improving trustworthiness methods in artificial intelligence and machine learning for materials science by considering work accomplished in other scientific disciplines such as healthcare, climate science, and natural language processing with an emphasis on methods that may transfer to materials discovery experiments. By combining these observations, we highlight the necessity of human-in-the-loop, and integrated approaches to bridge the gap between trustworthiness and uncertainty quantification for future directions of materials science research. This ensures that AI/ML methods not only accelerate discovery, but also meet ethical and scientific norms established by the materials discovery community. This work provides a road map for developing trustworthy artificial intelligence systems that will accurately and confidently enable material discovery.",
    "published": "2025-11-30T21:02:00Z",
    "updated": "2025-11-30T21:02:00Z",
    "link": "http://arxiv.org/pdf/2512.01080v1.pdf",
    "category": [
      "cond-mat.mtrl-sci",
      "cs.LG"
    ],
    "authors": [
      "Benhour Amirian",
      "Ashley S. Dale",
      "Sergei Kalinin",
      "Jason Hattrick-Simpers"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.01115v2",
    "title": "Exploring Equity of Climate Policies using Multi-Agent Multi-Objective Reinforcement Learning",
    "summary": "Addressing climate change requires coordinated policy efforts of nations worldwide. These efforts are informed by scientific reports, which rely in part on Integrated Assessment Models (IAMs), prominent tools used to assess the economic impacts of climate policies. However, traditional IAMs optimize policies based on a single objective, limiting their ability to capture the trade-offs among economic growth, temperature goals, and climate justice. As a result, policy recommendations have been criticized for perpetuating inequalities, fueling disagreements during policy negotiations. We introduce Justice, the first framework integrating IAM with Multi-Objective Multi-Agent Reinforcement Learning (MOMARL). By incorporating multiple objectives, Justice generates policy recommendations that shed light on equity while balancing climate and economic goals. Further, using multiple agents can provide a realistic representation of the interactions among the diverse policy actors. We identify equitable Pareto-optimal policies using our framework, which facilitates deliberative decision-making by presenting policymakers with the inherent trade-offs in climate and economic policy.",
    "published": "2025-05-02T08:52:56Z",
    "updated": "2025-11-30T20:53:51Z",
    "link": "http://arxiv.org/pdf/2505.01115v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Palok Biswas",
      "Zuzanna Osika",
      "Isidoro Tamassia",
      "Adit Whorra",
      "Jazmin Zatarain-Salazar",
      "Jan Kwakkel",
      "Frans A. Oliehoek",
      "Pradeep K. Murukannaiah"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2402.14332v3",
    "title": "Accelerating data-driven algorithm selection for combinatorial partitioning problems",
    "summary": "In clustering algorithm selection, we are given a massive dataset and must efficiently select which clustering algorithm to use. We study this problem in a semi-supervised setting, with an unknown ground-truth clustering that we can only access through expensive oracle queries. Ideally, the clustering algorithm's output will be structurally close to the ground truth. We approach this problem by introducing a notion of size generalization for clustering algorithm accuracy. We identify conditions under which we can (1) subsample the massive clustering instance, (2) evaluate a set of candidate algorithms on the smaller instance, and (3) guarantee that the algorithm with the best accuracy on the small instance will have the best accuracy on the original big instance. We provide theoretical size generalization guarantees for three classic clustering algorithms: single-linkage, k-means++, and (a smoothed variant of) Gonzalez's k-centers heuristic. We validate our theoretical analysis with empirical results, observing that on real-world clustering instances, we can use a subsample of as little as 5% of the data to identify which algorithm is best on the full dataset.",
    "published": "2024-02-22T06:53:35Z",
    "updated": "2025-11-30T20:44:20Z",
    "link": "http://arxiv.org/pdf/2402.14332v3.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Vaggos Chatziafratis",
      "Ishani Karmarkar",
      "Yingxi Li",
      "Ellen Vitercik"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01056v1",
    "title": "The Silence that Speaks: Neural Estimation via Communication Gaps",
    "summary": "Accurate remote state estimation is a fundamental component of many autonomous and networked dynamical systems, where multiple decision-making agents interact and communicate over shared, bandwidth-constrained channels. These communication constraints introduce an additional layer of complexity, namely, the decision of when to communicate. This results in a fundamental trade-off between estimation accuracy and communication resource usage. Traditional extensions of classical estimation algorithms (e.g., the Kalman filter) treat the absence of communication as 'missing' information. However, silence itself can carry implicit information about the system's state, which, if properly interpreted, can enhance the estimation quality even in the absence of explicit communication. Leveraging this implicit structure, however, poses significant analytical challenges, even in relatively simple systems. In this paper, we propose CALM (Communication-Aware Learning and Monitoring), a novel learning-based framework that jointly addresses the dual challenges of communication scheduling and estimator design. Our approach entails learning not only when to communicate but also how to infer useful information from periods of communication silence. We perform comparative case studies on multiple benchmarks to demonstrate that CALM is able to decode the implicit coordination between the estimator and the scheduler to extract information from the instances of 'silence' and enhance the estimation accuracy.",
    "published": "2025-11-30T19:58:21Z",
    "updated": "2025-11-30T19:58:21Z",
    "link": "http://arxiv.org/pdf/2512.01056v1.pdf",
    "category": [
      "eess.SY",
      "cs.LG",
      "math.OC"
    ],
    "authors": [
      "Shubham Aggarwal",
      "Dipankar Maity",
      "Tamer Başar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.01649v2",
    "title": "Safeguarding Privacy in Edge Speech Understanding with Tiny Foundation Models",
    "summary": "Robust speech recognition systems rely on cloud service providers for inference. It needs to ensure that an untrustworthy provider cannot deduce the sensitive content in speech. Sanitization can be done on speech content keeping in mind that it has to avoid compromising transcription accuracy. Realizing the under utilized capabilities of tiny speech foundation models (FMs), for the first time, we propose a novel use: enhancing speech privacy on resource-constrained devices. We introduce SpeechShield, an edge/cloud privacy preserving speech inference engine that can filter sensitive entities without compromising transcript accuracy. We utilize a timestamp based on-device masking approach that utilizes a token to entity prediction model to filter sensitive entities. Our choice of mask strategically conceals parts of the input and hides sensitive data. The masked input is sent to a trusted cloud service or to a local hub to generate the masked output. The effectiveness of SpeechShield hinges on how well the entity time segments are masked. Our recovery is a confidence score based approach that chooses the best prediction between cloud and on-device model. We implement SpeechShield on a 64 bit Raspberry Pi 4B. Experiments show that our solution leads to robust speech recognition without forsaking privacy. SpeechShield with < 100 MB memory, achieves state-of-the-art (SOTA) speech transcription performance while filtering about 83% of private entities directly on-device. SpeechShield is 16x smaller in memory, 3.3x faster and 17x more compute efficient than prior privacy preserving speech frameworks and has a relative reduction in word error rate (WER) by 38.8-77.5% when compared to existing offline transcription services.",
    "published": "2025-01-29T18:55:42Z",
    "updated": "2025-11-30T19:36:41Z",
    "link": "http://arxiv.org/pdf/2502.01649v2.pdf",
    "category": [
      "eess.AS",
      "cs.LG",
      "cs.SD"
    ],
    "authors": [
      "Afsara Benazir",
      "Felix Xiaozhu Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2409.13888v2",
    "title": "Causal Feature Selection Method for Contextual Multi-Armed Bandits in Recommender System",
    "summary": "Effective feature selection is essential for optimizing contextual multi-armed bandits (CMABs) in large-scale online systems, where suboptimal features can degrade rewards, interpretability, and efficiency. Traditional feature selection often prioritizes outcome correlation, neglecting the crucial role of heterogeneous treatment effects (HTE) across arms in CMAB decision-making. This paper introduces two novel, model-free filter methods, Heterogeneous Incremental Effect (HIE) and Heterogeneous Distribution Divergence (HDD), specifically designed to identify features driving HTE. HIE quantifies a feature's value based on its ability to induce changes in the optimal arm, while HDD measures its impact on reward distribution divergence across arms. These methods are computationally efficient, robust to model mis-specification, and adaptable to various feature types, making them suitable for rapid screening in dynamic environments where retraining complex models is infeasible. We validate HIE and HDD on synthetic data with known ground truth and in a large-scale commercial recommender system, demonstrating their consistent ability to identify influential HTE features and thereby enhance CMAB performance.",
    "published": "2024-09-20T20:39:23Z",
    "updated": "2025-11-30T19:35:47Z",
    "link": "http://arxiv.org/pdf/2409.13888v2.pdf",
    "category": [
      "cs.LG",
      "cs.IR",
      "stat.ML"
    ],
    "authors": [
      "Zhenyu Zhao",
      "Yexi Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01039v1",
    "title": "Joint Partitioning and Placement of Foundation Models for Real-Time Edge AI",
    "summary": "Inference over large-scale foundation models within heterogeneous edge environments necessitates a fundamentally reconfigurable orchestration substrate. Static partitioning of model layers presumes temporal stability across compute and network resources, which is misaligned with the volatility of real-world deployments. We introduce a framework in which both the spatial placement and internal segmentation of foundation models are elevated to runtime-resolved constructs. The orchestration problem is formalized as a constrained optimization over layer-wise assignments, subject to evolving latency, utilization, and privacy gradients. The framework implements reactive inference composition responsive to infrastructural fluctuations by integrating model-aware capacity profiling with dynamic graph re-partitioning and reallocation. We introduce architectural and algorithmic components, along with a representative use case in 6G multi-access edge computing.",
    "published": "2025-11-30T19:16:30Z",
    "updated": "2025-11-30T19:16:30Z",
    "link": "http://arxiv.org/pdf/2512.01039v1.pdf",
    "category": [
      "cs.DC",
      "cs.LG",
      "cs.NI"
    ],
    "authors": [
      "Aladin Djuhera",
      "Fernando Koch",
      "Alecio Binotto"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2308.00137v4",
    "title": "An Efficient Recommendation System in E-commerce using Passer learning optimization based on Bi-LSTM",
    "summary": "Online reviews play a crucial role in shaping consumer decisions, especially in the context of e-commerce. However, the quality and reliability of these reviews can vary significantly. Some reviews contain misleading or unhelpful information, such as advertisements, fake content, or irrelevant details. These issues pose significant challenges for recommendation systems, which rely on user-generated reviews to provide personalized suggestions. This article introduces a recommendation system based on Passer Learning Optimization-enhanced Bi-LSTM classifier applicable to e-commerce recommendation systems with improved accuracy and efficiency compared to state-of-the-art models. It achieves as low as 1.24% MSE on the baby dataset. This lifts it as high as 88.58%. Besides, there is also robust performance of the system on digital music and patio lawn garden datasets at F1 of 88.46% and 92.51%, correspondingly. These results, made possible by advanced graph embedding for effective knowledge extraction and fine-tuning of classifier parameters, establish the suitability of the proposed model in various e-commerce environments.",
    "published": "2023-07-31T20:09:25Z",
    "updated": "2025-12-01T12:45:05Z",
    "link": "http://arxiv.org/pdf/2308.00137v4.pdf",
    "category": [
      "cs.MM",
      "cs.NE"
    ],
    "authors": [
      "Hemn Barzan Abdalla",
      "Awder Ahmed",
      "Bahtiyar Mehmed",
      "Mehdi Gheisari",
      "Maryam Cheraghy",
      "Yang Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01267v1",
    "title": "ZO-ASR: Zeroth-Order Fine-Tuning of Speech Foundation Models without Back-Propagation",
    "summary": "Fine-tuning pre-trained speech foundation models for Automatic Speech Recognition (ASR) is prevalent, yet constrained by substantial GPU memory requirements. We introduce ZO-ASR, a memory-efficient Zeroth-Order (ZO) method that avoids Back-Propagation (BP) and activation memory by estimating gradients via forward passes. When combined with SGD optimizer, ZO-ASR-SGD fine-tunes ASR models using only inference memory. Our evaluation spans supervised and unsupervised tasks. For Supervised Domain Adaptation on Whisper-Large-V3, ZO-ASR's multiple query mechanism enhances robustness and achieves up to an 18.9\\% relative Word Error Rate reduction over zero-shot baselines, outperforming existing ZO methods. For unsupervised Test-Time Adaptation on Wav2Vec2-Base, ZO-ASR exhibits moderately lower performance compared to first-order optimizer Adam. Our BP-free approach provides a viable solution for fine-tuning ASR models in computationally resource-constrained or gradient-inaccessible scenarios.",
    "published": "2025-12-01T04:21:18Z",
    "updated": "2025-12-01T04:21:18Z",
    "link": "http://arxiv.org/pdf/2512.01267v1.pdf",
    "category": [
      "cs.MM",
      "cs.SD"
    ],
    "authors": [
      "Yuezhang Peng",
      "Yuxin Liu",
      "Yao Li",
      "Sheng Wang",
      "Fei Wen",
      "Xie Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01648v1",
    "title": "Textured Word-As-Image illustration",
    "summary": "In this paper, we propose a novel fully automatic pipeline to generate text images that are legible and strongly aligned to the desired semantic concept taken from the users' inputs. In our method, users are able to put three inputs into the system, including a semantic concept, a word, and a letter. The semantic concept will be used to change the shape of the input letter and generate the texture based on the pre-defined prompt using stable diffusion models. Our pipeline maps the texture on a text image in a way that preserves the readability of the whole output while preserving legibility. The system also provides real-time adjustments for the user to change the scale of the texture and apply it to the text image. User evaluations demonstrate that our method effectively represents semantic meaning without compromising legibility, making it a robust and innovative tool for graphic design, logo creation, and artistic typography.",
    "published": "2025-12-01T13:20:23Z",
    "updated": "2025-12-01T13:20:23Z",
    "link": "http://arxiv.org/pdf/2512.01648v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Mohammad Javadian Farzaneh",
      "Selim Balcisoy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01501v1",
    "title": "AUnified Framework for N-Dimensional Visualization and Simulation: Implementation and Evaluation including 4D Boolean",
    "summary": "This study proposes a unified framework for simulation and visualization of intuitive exploration of phenomena in N-dimensional space. While specialized libraries offer powerful geometric algorithms, they typically lack integrated environments for interactive trial and error, creating a barrier for researchers. The contribution of this research is the integration of Quickhull-based mesh generation, visualization via hyperplane slicing, and computationally expensive Boolean operations into a single, extensible platform, while maintaining interactivity. To validate its effectiveness, this paper presents a 4-dimensional implementation and introduces a new interaction design, termed `High-Dimensional FPS,' to enable intuitive high-dimensional exploration. Furthermore, as a case study to demonstrate the framework's high extensibility, I also integrated a non-rigid body physics simulation based on Extended Position Based Dynamics (XPBD). Experimental results confirmed the effectiveness of the proposed method, achieving real-time rendering (80 fps) of complex 4D objects and completing Boolean operations within seconds in a standard PC environment. By providing an accessible and interactive platform, this work lowers the entry barrier for high-dimensional simulation research and enhances its potential for applications in education and entertainment.",
    "published": "2025-12-01T10:26:23Z",
    "updated": "2025-12-01T10:26:23Z",
    "link": "http://arxiv.org/pdf/2512.01501v1.pdf",
    "category": [
      "cs.CG",
      "cs.GR"
    ],
    "authors": [
      "Hirohito Arai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.02013v1",
    "title": "ManualVLA: A Unified VLA Model for Chain-of-Thought Manual Generation and Robotic Manipulation",
    "summary": "Vision-Language-Action (VLA) models have recently emerged, demonstrating strong generalization in robotic scene understanding and manipulation. However, when confronted with long-horizon tasks that require defined goal states, such as LEGO assembly or object rearrangement, existing VLA models still face challenges in coordinating high-level planning with precise manipulation. Therefore, we aim to endow a VLA model with the capability to infer the \"how\" process from the \"what\" outcomes, transforming goal states into executable procedures. In this paper, we introduce ManualVLA, a unified VLA framework built upon a Mixture-of-Transformers (MoT) architecture, enabling coherent collaboration between multimodal manual generation and action execution. Unlike prior VLA models that directly map sensory inputs to actions, we first equip ManualVLA with a planning expert that generates intermediate manuals consisting of images, position prompts, and textual instructions. Building upon these multimodal manuals, we design a Manual Chain-of-Thought (ManualCoT) reasoning process that feeds them into the action expert, where each manual step provides explicit control conditions, while its latent representation offers implicit guidance for accurate manipulation. To alleviate the burden of data collection, we develop a high-fidelity digital-twin toolkit based on 3D Gaussian Splatting, which automatically generates manual data for planning expert training. ManualVLA demonstrates strong real-world performance, achieving an average success rate 32% higher than the previous hierarchical SOTA baseline on LEGO assembly and object rearrangement tasks.",
    "published": "2025-12-01T18:59:50Z",
    "updated": "2025-12-01T18:59:50Z",
    "link": "http://arxiv.org/pdf/2512.02013v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Chenyang Gu",
      "Jiaming Liu",
      "Hao Chen",
      "Runzhong Huang",
      "Qingpo Wuwu",
      "Zhuoyang Liu",
      "Xiaoqi Li",
      "Ying Li",
      "Renrui Zhang",
      "Peng Jia",
      "Pheng-Ann Heng",
      "Shanghang Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.02011v1",
    "title": "Learning Dexterous Manipulation Skills from Imperfect Simulations",
    "summary": "Reinforcement learning and sim-to-real transfer have made significant progress in dexterous manipulation. However, progress remains limited by the difficulty of simulating complex contact dynamics and multisensory signals, especially tactile feedback. In this work, we propose \\ours, a sim-to-real framework that addresses these limitations and demonstrates its effectiveness on nut-bolt fastening and screwdriving with multi-fingered hands. The framework has three stages. First, we train reinforcement learning policies in simulation using simplified object models that lead to the emergence of correct finger gaits. We then use the learned policy as a skill primitive within a teleoperation system to collect real-world demonstrations that contain tactile and proprioceptive information. Finally, we train a behavior cloning policy that incorporates tactile sensing and show that it generalizes to nuts and screwdrivers with diverse geometries. Experiments across both tasks show high task progress ratios compared to direct sim-to-real transfer and robust performance even on unseen object shapes and under external perturbations. Videos and code are available on https://dexscrew.github.io.",
    "published": "2025-12-01T18:59:45Z",
    "updated": "2025-12-01T18:59:45Z",
    "link": "http://arxiv.org/pdf/2512.02011v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Elvis Hsieh",
      "Wen-Han Hsieh",
      "Yen-Jen Wang",
      "Toru Lin",
      "Jitendra Malik",
      "Koushil Sreenath",
      "Haozhi Qi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.02002v1",
    "title": "LLM-Driven Corrective Robot Operation Code Generation with Static Text-Based Simulation",
    "summary": "Recent advances in Large language models (LLMs) have demonstrated their promising capabilities of generating robot operation code to enable LLM-driven robots. To enhance the reliability of operation code generated by LLMs, corrective designs with feedback from the observation of executing code have been increasingly adopted in existing research. However, the code execution in these designs relies on either a physical experiment or a customized simulation environment, which limits their deployment due to the high configuration effort of the environment and the potential long execution time. In this paper, we explore the possibility of directly leveraging LLM to enable static simulation of robot operation code, and then leverage it to design a new reliable LLM-driven corrective robot operation code generation framework. Our framework configures the LLM as a static simulator with enhanced capabilities that reliably simulate robot code execution by interpreting actions, reasoning over state transitions, analyzing execution outcomes, and generating se- mantic observations that accurately capture trajectory dynamics. To validate the performance of our framework, we performed experiments on various operation tasks for different robots, including UAVs and small ground vehicles. The experiment results not only demonstrated the high accuracy of our static text-based simulation but also the reliable code generation of our LLM-driven corrective framework, which achieves a comparable performance with state-of-the-art research while does not rely on dynamic code execution using physical experiments or simulators.",
    "published": "2025-12-01T18:57:10Z",
    "updated": "2025-12-01T18:57:10Z",
    "link": "http://arxiv.org/pdf/2512.02002v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Wenhao Wang",
      "Yanyan Li",
      "Long Jiao",
      "Jiawei Yuan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01897v1",
    "title": "NeuroHJR: Hamilton-Jacobi Reachability-based Obstacle Avoidance in Complex Environments with Physics-Informed Neural Networks",
    "summary": "Autonomous ground vehicles (AGVs) must navigate safely in cluttered environments while accounting for complex dynamics and environmental uncertainty. Hamilton-Jacobi Reachability (HJR) offers formal safety guarantees through the computation of forward and backward reachable sets, but its application is hindered by poor scalability in environments with numerous obstacles. In this paper, we present a novel framework called NeuroHJR that leverages Physics-Informed Neural Networks (PINNs) to approximate the HJR solution for real-time obstacle avoidance. By embedding system dynamics and safety constraints directly into the neural network loss function, our method bypasses the need for grid-based discretization and enables efficient estimation of reachable sets in continuous state spaces. We demonstrate the effectiveness of our approach through simulation results in densely cluttered scenarios, showing that it achieves safety performance comparable to that of classical HJR solvers while significantly reducing the computational cost. This work provides a new step toward real-time, scalable deployment of reachability-based obstacle avoidance in robotics.",
    "published": "2025-12-01T17:18:24Z",
    "updated": "2025-12-01T17:18:24Z",
    "link": "http://arxiv.org/pdf/2512.01897v1.pdf",
    "category": [
      "cs.RO",
      "eess.SY"
    ],
    "authors": [
      "Granthik Halder",
      "Rudrashis Majumder",
      "Rakshith M R",
      "Rahi Shah",
      "Suresh Sundaram"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01856v1",
    "title": "Is Image-based Object Pose Estimation Ready to Support Grasping?",
    "summary": "We present a framework for evaluating 6-DoF instance-level object pose estimators, focusing on those that require a single RGB (not RGB-D) image as input. Besides gaining intuition about how accurate these estimators are, we are interested in the degree to which they can serve as the sole perception mechanism for robotic grasping. To assess this, we perform grasping trials in a physics-based simulator, using image-based pose estimates to guide a parallel gripper and an underactuated robotic hand in picking up 3D models of objects. Our experiments on a subset of the BOP (Benchmark for 6D Object Pose Estimation) dataset compare five open-source object pose estimators and provide insights that were missing from the literature.",
    "published": "2025-12-01T16:39:39Z",
    "updated": "2025-12-01T16:39:39Z",
    "link": "http://arxiv.org/pdf/2512.01856v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Eric C. Joyce",
      "Qianwen Zhao",
      "Nathaniel Burgdorfer",
      "Long Wang",
      "Philippos Mordohai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.15607v2",
    "title": "PRIMT: Preference-based Reinforcement Learning with Multimodal Feedback and Trajectory Synthesis from Foundation Models",
    "summary": "Preference-based reinforcement learning (PbRL) has emerged as a promising paradigm for teaching robots complex behaviors without reward engineering. However, its effectiveness is often limited by two critical challenges: the reliance on extensive human input and the inherent difficulties in resolving query ambiguity and credit assignment during reward learning. In this paper, we introduce PRIMT, a PbRL framework designed to overcome these challenges by leveraging foundation models (FMs) for multimodal synthetic feedback and trajectory synthesis. Unlike prior approaches that rely on single-modality FM evaluations, PRIMT employs a hierarchical neuro-symbolic fusion strategy, integrating the complementary strengths of large language models and vision-language models in evaluating robot behaviors for more reliable and comprehensive feedback. PRIMT also incorporates foresight trajectory generation, which reduces early-stage query ambiguity by warm-starting the trajectory buffer with bootstrapped samples, and hindsight trajectory augmentation, which enables counterfactual reasoning with a causal auxiliary loss to improve credit assignment. We evaluate PRIMT on 2 locomotion and 6 manipulation tasks on various benchmarks, demonstrating superior performance over FM-based and scripted baselines.",
    "published": "2025-09-19T05:13:13Z",
    "updated": "2025-12-01T15:50:06Z",
    "link": "http://arxiv.org/pdf/2509.15607v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Ruiqi Wang",
      "Dezhong Zhao",
      "Ziqin Yuan",
      "Tianyu Shao",
      "Guohua Chen",
      "Dominic Kao",
      "Sungeun Hong",
      "Byung-Cheol Min"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01773v1",
    "title": "IGen: Scalable Data Generation for Robot Learning from Open-World Images",
    "summary": "The rise of generalist robotic policies has created an exponential demand for large-scale training data. However, on-robot data collection is labor-intensive and often limited to specific environments. In contrast, open-world images capture a vast diversity of real-world scenes that naturally align with robotic manipulation tasks, offering a promising avenue for low-cost, large-scale robot data acquisition. Despite this potential, the lack of associated robot actions hinders the practical use of open-world images for robot learning, leaving this rich visual resource largely unexploited. To bridge this gap, we propose IGen, a framework that scalably generates realistic visual observations and executable actions from open-world images. IGen first converts unstructured 2D pixels into structured 3D scene representations suitable for scene understanding and manipulation. It then leverages the reasoning capabilities of vision-language models to transform scene-specific task instructions into high-level plans and generate low-level actions as SE(3) end-effector pose sequences. From these poses, it synthesizes dynamic scene evolution and renders temporally coherent visual observations. Experiments validate the high quality of visuomotor data generated by IGen, and show that policies trained solely on IGen-synthesized data achieve performance comparable to those trained on real-world data. This highlights the potential of IGen to support scalable data generation from open-world images for generalist robotic policy training.",
    "published": "2025-12-01T15:15:04Z",
    "updated": "2025-12-01T15:15:04Z",
    "link": "http://arxiv.org/pdf/2512.01773v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Chenghao Gu",
      "Haolan Kang",
      "Junchao Lin",
      "Jinghe Wang",
      "Duo Wu",
      "Shuzhao Xie",
      "Fanding Huang",
      "Junchen Ge",
      "Ziyang Gong",
      "Letian Li",
      "Hongying Zheng",
      "Changwei Lv",
      "Zhi Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.13189v2",
    "title": "Multimodal \"Puppeteer\": Exploring Robot Teleoperation Via Virtual Counterpart with LLM-Driven Voice and Gesture Interaction in Augmented Reality",
    "summary": "The integration of robotics and augmented reality (AR) offers promising opportunities to enhance human-robot interaction (HRI) by making teleoperation more transparent, spatially grounded, and intuitive. We present a head-mounted AR \"puppeteer\" framework in which users control a physical robot via interacting with its virtual counterpart robot using large language model (LLM)-driven voice commands and hand-gesture interaction on the Meta Quest 3. In a within-subject user study with 42 participants performing an AR-based robotic pick-and-place pattern-matching task, we compare two interaction conditions: gesture-only (GO) and combined voice+gesture (VG). Our results show that GO currently provides more reliable and efficient control for this time-critical task, while VG introduces additional flexibility but also latency and recognition issues that can increase workload. We further explore how prior robotics experience shapes participants' perceptions of each modality. Based on these findings, we distill a set of evidence-based design guidelines for AR puppeteer metaphoric robot teleoperation, implicating multimodality as an adaptive strategy that must balance efficiency, robustness, and user expertise rather than assuming that additional modalities are universally beneficial. Our work contributes empirical insights into how multimodal (voice+gesture) interaction influences task efficiency, usability, and user experience in AR-based HRI.",
    "published": "2025-06-16T07:56:19Z",
    "updated": "2025-12-01T15:06:03Z",
    "link": "http://arxiv.org/pdf/2506.13189v2.pdf",
    "category": [
      "cs.HC",
      "cs.RO"
    ],
    "authors": [
      "Yuchong Zhang",
      "Bastian Orthmann",
      "Shichen Ji",
      "Michael Welle",
      "Jonne Van Haastregt",
      "Danica Kragic"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.03038v5",
    "title": "How to Adapt Control Barrier Functions? A Learning-Based Approach with Applications to a VTOL Quadplane",
    "summary": "In this paper, we present a novel theoretical framework for online adaptation of Control Barrier Function (CBF) parameters, i.e., of the class K functions included in the CBF condition, under input constraints. We introduce the concept of locally validated CBF parameters, which are adapted online to guarantee finite-horizon safety, based on conditions derived from Nagumo's theorem and tangent cone analysis. To identify these parameters online, we integrate a learning-based approach with an uncertainty-aware verification process that account for both epistemic and aleatoric uncertainties inherent in neural network predictions. Our method is demonstrated on a VTOL quadplane model during challenging transition and landing maneuvers, showcasing enhanced performance while maintaining safety.",
    "published": "2025-04-03T21:32:32Z",
    "updated": "2025-12-01T15:03:10Z",
    "link": "http://arxiv.org/pdf/2504.03038v5.pdf",
    "category": [
      "cs.RO",
      "eess.SY"
    ],
    "authors": [
      "Taekyung Kim",
      "Randal W. Beard",
      "Dimitra Panagou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01753v1",
    "title": "AgriLiRa4D: A Multi-Sensor UAV Dataset for Robust SLAM in Challenging Agricultural Fields",
    "summary": "Multi-sensor Simultaneous Localization and Mapping (SLAM) is essential for Unmanned Aerial Vehicles (UAVs) performing agricultural tasks such as spraying, surveying, and inspection. However, real-world, multi-modal agricultural UAV datasets that enable research on robust operation remain scarce. To address this gap, we present AgriLiRa4D, a multi-modal UAV dataset designed for challenging outdoor agricultural environments. AgriLiRa4D spans three representative farmland types-flat, hilly, and terraced-and includes both boundary and coverage operation modes, resulting in six flight sequence groups. The dataset provides high-accuracy ground-truth trajectories from a Fiber Optic Inertial Navigation System with Real-Time Kinematic capability (FINS_RTK), along with synchronized measurements from a 3D LiDAR, a 4D Radar, and an Inertial Measurement Unit (IMU), accompanied by complete intrinsic and extrinsic calibrations. Leveraging its comprehensive sensor suite and diverse real-world scenarios, AgriLiRa4D supports diverse SLAM and localization studies and enables rigorous robustness evaluation against low-texture crops, repetitive patterns, dynamic vegetation, and other challenges of real agricultural environments. To further demonstrate its utility, we benchmark four state-of-the-art multi-sensor SLAM algorithms across different sensor combinations, highlighting the difficulty of the proposed sequences and the necessity of multi-modal approaches for reliable UAV localization. By filling a critical gap in agricultural SLAM datasets, AgriLiRa4D provides a valuable benchmark for the research community and contributes to advancing autonomous navigation technologies for agricultural UAVs. The dataset can be downloaded from: https://zhan994.github.io/AgriLiRa4D.",
    "published": "2025-12-01T14:56:56Z",
    "updated": "2025-12-01T14:56:56Z",
    "link": "http://arxiv.org/pdf/2512.01753v1.pdf",
    "category": [
      "cs.RO",
      "eess.SP"
    ],
    "authors": [
      "Zhihao Zhan",
      "Yuhang Ming",
      "Shaobin Li",
      "Jie Yuan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01715v1",
    "title": "DiG-Flow: Discrepancy-Guided Flow Matching for Robust VLA Models",
    "summary": "Vision-Language-Action (VLA) models trained with flow matching have demonstrated impressive capabilities on robotic manipulation tasks. However, their performance often degrades under distribution shift and on complex multi-step tasks, suggesting that the learned representations may not robustly capture task-relevant semantics. We introduce DiG-Flow, a principled framework that enhances VLA robustness through geometric regularization. Our key insight is that the distributional discrepancy between observation and action embeddings provides a meaningful geometric signal: lower transport cost indicates compatible representations, while higher cost suggests potential misalignment. DiG-Flow computes a discrepancy measure between empirical distributions of observation and action embeddings, maps it to a modulation weight via a monotone function, and applies residual updates to the observation embeddings before flow matching. Crucially, this intervention operates at the representation level without modifying the flow matching path or target vector field. We provide theoretical guarantees showing that discrepancy-guided training provably decreases the training objective, and that guided inference refinement converges with contraction. Empirically, DiG-Flow integrates into existing VLA architectures with negligible overhead and consistently improves performance, with particularly pronounced gains on complex multi-step tasks and under limited training data.",
    "published": "2025-12-01T14:21:15Z",
    "updated": "2025-12-01T14:21:15Z",
    "link": "http://arxiv.org/pdf/2512.01715v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Wanpeng Zhang",
      "Ye Wang",
      "Hao Luo",
      "Haoqi Yuan",
      "Yicheng Feng",
      "Sipeng Zheng",
      "Qin Jin",
      "Zongqing Lu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01668v1",
    "title": "Dynamic Log-Gaussian Process Control Barrier Function for Safe Robotic Navigation in Dynamic Environments",
    "summary": "Control Barrier Functions (CBFs) have emerged as efficient tools to address the safe navigation problem for robot applications. However, synthesizing informative and obstacle motion-aware CBFs online using real-time sensor data remains challenging, particularly in unknown and dynamic scenarios. Motived by this challenge, this paper aims to propose a novel Gaussian Process-based formulation of CBF, termed the Dynamic Log Gaussian Process Control Barrier Function (DLGP-CBF), to enable real-time construction of CBF which are both spatially informative and responsive to obstacle motion. Firstly, the DLGP-CBF leverages a logarithmic transformation of GP regression to generate smooth and informative barrier values and gradients, even in sparse-data regions. Secondly, by explicitly modeling the DLGP-CBF as a function of obstacle positions, the derived safety constraint integrates predicted obstacle velocities, allowing the controller to proactively respond to dynamic obstacles' motion. Simulation results demonstrate significant improvements in obstacle avoidance performance, including increased safety margins, smoother trajectories, and enhanced responsiveness compared to baseline methods.",
    "published": "2025-12-01T13:38:43Z",
    "updated": "2025-12-01T13:38:43Z",
    "link": "http://arxiv.org/pdf/2512.01668v1.pdf",
    "category": [
      "cs.RO",
      "eess.SY"
    ],
    "authors": [
      "Xin Yin",
      "Chenyang Liang",
      "Yanning Guo",
      "Jie Mei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.19914v2",
    "title": "High-Speed Event Vision-Based Tactile Roller Sensor for Large Surface Measurements",
    "summary": "Inspecting large-scale industrial surfaces like aircraft fuselages for quality control requires capturing their precise 3D surface geometry at high resolution. Vision-based tactile sensors (VBTSs) offer high local resolution but require slow 'press-and-lift' measurements stitched for large areas. Approaches with sliding or roller/belt VBTS designs provide measurements continuity. However, they face significant challenges respectively: sliding struggles with friction/wear and both approaches are speed-limited by conventional camera frame rates and motion blur, making large-area scanning time consuming. Thus, a rapid, continuous, high-resolution method is needed. We introduce a novel tactile sensor integrating a neuromorphic camera in a rolling mechanism to achieve this. Leveraging its high temporal resolution and robustness to motion blur, our system uses a modified event-based multi-view stereo approach for 3D reconstruction. We demonstrate state-of-the-art scanning speeds up to 0.5 m/s, achieving Mean Absolute Error below 100 microns -- 11 times faster than prior continuous tactile sensing methods. A multi-reference Bayesian fusion strategy enhances accuracy (reducing MAE by 25.2\\% compared to EMVS) and mitigates curvature errors. We also validate high-speed feature recognition via Braille reading 2.6 times faster than previous approaches.",
    "published": "2025-07-26T11:13:37Z",
    "updated": "2025-12-01T12:52:21Z",
    "link": "http://arxiv.org/pdf/2507.19914v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Akram Khairi",
      "Hussain Sajwani",
      "Abdallah Mohammad Alkilany",
      "Laith AbuAssi",
      "Mohamad Halwani",
      "Islam Mohamed Zaid",
      "Ahmed Awadalla",
      "Dewald Swart",
      "Abdulla Ayyad",
      "Yahya Zweiri"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.10239v2",
    "title": "A Unified Framework for Probabilistic Dynamic-, Trajectory- and Vision-based Virtual Fixtures",
    "summary": "Probabilistic Virtual Fixtures (VFs) enable the adaptive selection of the most suitable haptic feedback for each phase of a task, based on learned or perceived uncertainty. While keeping the human in the loop remains essential, for instance, to ensure high precision, partial automation of certain task phases is critical for productivity. We present a unified framework for probabilistic VFs that seamlessly switches between manual fixtures, semi-automated fixtures (with the human handling precise tasks), and full autonomy. We introduce a novel probabilistic Dynamical System-based VF for coarse guidance, enabling the robot to autonomously complete certain task phases while keeping the human operator in the loop. For tasks requiring precise guidance, we extend probabilistic position-based trajectory fixtures with automation allowing for seamless human interaction as well as geometry-awareness and optimal impedance gains. For manual tasks requiring very precise guidance, we also extend visual servoing fixtures with the same geometry-awareness and impedance behavior. We validate our approach experimentally on different robots, showcasing multiple operation modes and the ease of programming fixtures.",
    "published": "2025-06-11T23:46:57Z",
    "updated": "2025-12-01T12:41:13Z",
    "link": "http://arxiv.org/pdf/2506.10239v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Maximilian Mühlbauer",
      "Bernhard Weber",
      "Sylvain Calinon",
      "Freek Stulp",
      "Alin Albu-Schäffer",
      "João Silvério"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01608v1",
    "title": "Integrated YOLOP Perception and Lyapunov-based Control for Autonomous Mobile Robot Navigation on Track",
    "summary": "This work presents a real-time autonomous track navigation framework for nonholonomic differential-drive mobile robots by jointly integrating multi-task visual perception and a provably stable tracking controller. The perception pipeline reconstructs lane centerlines using 2D-to-3D camera projection, arc-length based uniform point resampling, and cubic polynomial fitting solved via robust QR least-squares optimization. The controller regulates robot linear and angular velocities through a Lyapunov-stability grounded design, ensuring bounded error dynamics and asymptotic convergence of position and heading deviations even in dynamic and partially perceived lane scenarios, without relying on HD prior maps or global satellite localization. Real-world experiments on embedded platforms verify system fidelity, real-time execution, trajectory smoothness, and closed-loop stability for reliable autonomous navigation.",
    "published": "2025-12-01T12:29:02Z",
    "updated": "2025-12-01T12:29:02Z",
    "link": "http://arxiv.org/pdf/2512.01608v1.pdf",
    "category": [
      "cs.RO",
      "eess.SY"
    ],
    "authors": [
      "Mo Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01598v1",
    "title": "A Cross-Embodiment Gripper Benchmark for Rigid-Object Manipulation in Aerial and Industrial Robotics",
    "summary": "Robotic grippers are increasingly deployed across industrial, collaborative, and aerial platforms, where each embodiment imposes distinct mechanical, energetic, and operational constraints. Established YCB and NIST benchmarks quantify grasp success, force, or timing on a single platform, but do not evaluate cross-embodiment transferability or energy-aware performance, capabilities essential for modern mobile and aerial manipulation. This letter introduces the Cross-Embodiment Gripper Benchmark (CEGB), a compact and reproducible benchmarking suite extending YCB and selected NIST metrics with three additional components: a transfer-time benchmark measuring the practical effort required to exchange embodiments, an energy-consumption benchmark evaluating grasping and holding efficiency, and an intent-specific ideal payload assessment reflecting design-dependent operational capability. Together, these metrics characterize both grasp performance and the suitability of reusing a single gripper across heterogeneous robotic systems. A lightweight self-locking gripper prototype is implemented as a reference case. Experiments demonstrate rapid embodiment transfer (median ~= 17.6 s across user groups), low holding energy for gripper prototype (~= 1.5 J per 10 s), and consistent grasp performance with cycle times of 3.2 - 3.9 s and success rates exceeding 90%. CEGB thus provides a reproducible foundation for cross-platform, energy-aware evaluation of grippers in aerial and manipulators domains.",
    "published": "2025-12-01T12:17:56Z",
    "updated": "2025-12-01T12:17:56Z",
    "link": "http://arxiv.org/pdf/2512.01598v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Marek Vagas",
      "Martin Varga",
      "Jaroslav Romancik",
      "Ondrej Majercak",
      "Alejandro Suarez",
      "Anibal Ollero",
      "Bram Vanderborght",
      "Ivan Virgala"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01554v1",
    "title": "L2M-Calib: One-key Calibration Method for LiDAR and Multiple Magnetic Sensors",
    "summary": "Multimodal sensor fusion enables robust environmental perception by leveraging complementary information from heterogeneous sensing modalities. However, accurate calibration is a critical prerequisite for effective fusion. This paper proposes a novel one-key calibration framework named L2M-Calib for a fused magnetic-LiDAR system, jointly estimating the extrinsic transformation between the two kinds of sensors and the intrinsic distortion parameters of the magnetic sensors. Magnetic sensors capture ambient magnetic field (AMF) patterns, which are invariant to geometry, texture, illumination, and weather, making them suitable for challenging environments. Nonetheless, the integration of magnetic sensing into multimodal systems remains underexplored due to the absence of effective calibration techniques. To address this, we optimize extrinsic parameters using an iterative Gauss-Newton scheme, coupled with the intrinsic calibration as a weighted ridge-regularized total least squares (w-RRTLS) problem, ensuring robustness against measurement noise and ill-conditioned data. Extensive evaluations on both simulated datasets and real-world experiments, including AGV-mounted sensor configurations, demonstrate that our method achieves high calibration accuracy and robustness under various environmental and operational conditions.",
    "published": "2025-12-01T11:26:00Z",
    "updated": "2025-12-01T11:26:00Z",
    "link": "http://arxiv.org/pdf/2512.01554v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Qiyang Lyu",
      "Wei Wang",
      "Zhenyu Wu",
      "Hongming Shen",
      "Huiqin Zhou",
      "Danwei Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01446v1",
    "title": "$\\mathbf{M^3A}$ Policy: Mutable Material Manipulation Augmentation Policy through Photometric Re-rendering",
    "summary": "Material generalization is essential for real-world robotic manipulation, where robots must interact with objects exhibiting diverse visual and physical properties. This challenge is particularly pronounced for objects made of glass, metal, or other materials whose transparent or reflective surfaces introduce severe out-of-distribution variations. Existing approaches either rely on simulated materials in simulators and perform sim-to-real transfer, which is hindered by substantial visual domain gaps, or depend on collecting extensive real-world demonstrations, which is costly, time-consuming, and still insufficient to cover various materials. To overcome these limitations, we resort to computational photography and introduce Mutable Material Manipulation Augmentation (M$^3$A), a unified framework that leverages the physical characteristics of materials as captured by light transport for photometric re-rendering. The core idea is simple yet powerful: given a single real-world demonstration, we photometrically re-render the scene to generate a diverse set of highly realistic demonstrations with different material properties. This augmentation effectively decouples task-specific manipulation skills from surface appearance, enabling policies to generalize across materials without additional data collection. To systematically evaluate this capability, we construct the first comprehensive multi-material manipulation benchmark spanning both simulation and real-world environments. Extensive experiments show that the M$^3$A policy significantly enhances cross-material generalization, improving the average success rate across three real-world tasks by 58.03\\%, and demonstrating robust performance on previously unseen materials.",
    "published": "2025-12-01T09:31:10Z",
    "updated": "2025-12-01T09:31:10Z",
    "link": "http://arxiv.org/pdf/2512.01446v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Jiayi Li",
      "Yuxuan Hu",
      "Haoran Geng",
      "Xiangyu Chen",
      "Chuhao Zhou",
      "Ziteng Cui",
      "Jianfei Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01381v1",
    "title": "Accelerating Probabilistic Response-Time Analysis: Revised Critical Instant and Optimized Convolution",
    "summary": "Accurate estimation of the Worst-Case Deadline Failure Probability (WCDFP) has attracted growing attention as a means to provide safety assurances in complex systems such as robotic platforms and autonomous vehicles. WCDFP quantifies the likelihood of deadline misses under the most pessimistic operating conditions, and safe estimation is essential for dependable real-time applications. However, achieving high accuracy in WCDFP estimation often incurs significant computational cost. Recent studies have revealed that the classical assumption of the critical instant, the activation pattern traditionally considered to trigger the worst-case behavior, can lead to underestimation of WCDFP in probabilistic settings. This observation motivates the use of a revised critical instant formulation that more faithfully captures the true worst-case scenario. This paper investigates convolution-based methods for WCDFP estimation under this revised setting and proposes an optimization technique that accelerates convolution by improving the merge order. Extensive experiments with diverse execution-time distributions demonstrate that the proposed optimized Aggregate Convolution reduces computation time by up to an order of magnitude compared to Sequential Convolution, while retaining accurate and safe-sided WCDFP estimates. These results highlight the potential of the approach to provide both efficiency and reliability in probabilistic timing analysis for safety-critical real-time applications.",
    "published": "2025-12-01T07:54:48Z",
    "updated": "2025-12-01T07:54:48Z",
    "link": "http://arxiv.org/pdf/2512.01381v1.pdf",
    "category": [
      "cs.OS",
      "cs.DS",
      "cs.RO"
    ],
    "authors": [
      "Hiroto Takahashi",
      "Atsushi Yano",
      "Takuya Azumi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01336v1",
    "title": "Discovering Self-Protective Falling Policy for Humanoid Robot via Deep Reinforcement Learning",
    "summary": "Humanoid robots have received significant research interests and advancements in recent years. Despite many successes, due to their morphology, dynamics and limitation of control policy, humanoid robots are prone to fall as compared to other embodiments like quadruped or wheeled robots. And its large weight, tall Center of Mass, high Degree-of-Freedom would cause serious hardware damages when falling uncontrolled, to both itself and surrounding objects. Existing researches in this field mostly focus on using control based methods that struggle to cater diverse falling scenarios and may introduce unsuitable human prior. On the other hand, large-scale Deep Reinforcement Learning and Curriculum Learning could be employed to incentivize humanoid agent discovering falling protection policy that fits its own nature and property. In this work, with carefully designed reward functions and domain diversification curriculum, we successfully train humanoid agent to explore falling protection behaviors and discover that by forming a `triangle' structure, the falling damages could be significantly reduced with its rigid-material body. With comprehensive metrics and experiments, we quantify its performance with comparison to other methods, visualize its falling behaviors and successfully transfer it to real world platform.",
    "published": "2025-12-01T06:53:54Z",
    "updated": "2025-12-01T06:53:54Z",
    "link": "http://arxiv.org/pdf/2512.01336v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Diyuan Shi",
      "Shangke Lyu",
      "Donglin Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01280v1",
    "title": "Visibility-aware Cooperative Aerial Tracking with Decentralized LiDAR-based Swarms",
    "summary": "Autonomous aerial tracking with drones offers vast potential for surveillance, cinematography, and industrial inspection applications. While single-drone tracking systems have been extensively studied, swarm-based target tracking remains underexplored, despite its unique advantages of distributed perception, fault-tolerant redundancy, and multidirectional target coverage. To bridge this gap, we propose a novel decentralized LiDAR-based swarm tracking framework that enables visibility-aware, cooperative target tracking in complex environments, while fully harnessing the unique capabilities of swarm systems. To address visibility, we introduce a novel Spherical Signed Distance Field (SSDF)-based metric for 3-D environmental occlusion representation, coupled with an efficient algorithm that enables real-time onboard SSDF updating. A general Field-of-View (FOV) alignment cost supporting heterogeneous LiDAR configurations is proposed for consistent target observation. Swarm coordination is enhanced through cooperative costs that enforce inter-robot safe clearance, prevent mutual occlusions, and notably facilitate 3-D multidirectional target encirclement via a novel electrostatic-potential-inspired distribution metric. These innovations are integrated into a hierarchical planner, combining a kinodynamic front-end searcher with a spatiotemporal $SE(3)$ back-end optimizer to generate collision-free, visibility-optimized trajectories.Deployed on heterogeneous LiDAR swarms, our fully decentralized implementation features collaborative perception, distributed planning, and dynamic swarm reconfigurability. Validated through rigorous real-world experiments in cluttered outdoor environments, the proposed system demonstrates robust cooperative tracking of agile targets (drones, humans) while achieving superior visibility maintenance.",
    "published": "2025-12-01T04:52:50Z",
    "updated": "2025-12-01T04:52:50Z",
    "link": "http://arxiv.org/pdf/2512.01280v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Longji Yin",
      "Yunfan Ren",
      "Fangcheng Zhu",
      "Liuyu Shi",
      "Fanze Kong",
      "Benxu Tang",
      "Wenyi Liu",
      "Ximin Lyu",
      "Fu Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01246v1",
    "title": "COMET: A Dual Swashplate Autonomous Coaxial Bi-copter AAV with High-Maneuverability and Long-Endurance",
    "summary": "Coaxial bi-copter autonomous aerial vehicles (AAVs) have garnered attention due to their potential for improved rotor system efficiency and compact form factor. However, balancing efficiency, maneuverability, and compactness in coaxial bi-copter systems remains a key design challenge, limiting their practical deployment. This letter introduces COMET, a coaxial bi-copter AAV platform featuring a dual swashplate mechanism. The coaxial bi-copter system's efficiency and compactness are optimized through bench tests, and the whole prototype's efficiency and robustness under varying payload conditions are verified through flight endurance experiments. The maneuverability performance of the system is evaluated in comprehensive trajectory tracking tests. The results indicate that the dual swashplate configuration enhances tracking performance and improves flight efficiency compared to the single swashplate alternative. Successful autonomous flight trials across various scenarios verify COMET's potential for real-world applications.",
    "published": "2025-12-01T03:45:00Z",
    "updated": "2025-12-01T03:45:00Z",
    "link": "http://arxiv.org/pdf/2512.01246v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Shuai Wang",
      "Xiaoming Tang",
      "Junning Liang",
      "Haowen Zheng",
      "Biyu Ye",
      "Zhaofeng Liu",
      "Fei Gao",
      "Ximin Lyu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.02852v2",
    "title": "Curvature-Constrained Vector Field for Motion Planning of Nonholonomic Robots",
    "summary": "Vector fields are advantageous in handling nonholonomic motion planning as they provide reference orientation for robots. However, additionally incorporating curvature constraints becomes challenging, due to the interconnection between the design of the curvature-bounded vector field and the tracking controller under underactuation. In this paper, we present a novel framework to co-develop the vector field and the control laws, guiding the nonholonomic robot to the target configuration with curvature-bounded trajectory. First, we formulate the problem by introducing the target positive limit set, which allows the robot to converge to or pass through the target configuration, depending on different dynamics and tasks. Next, we construct a curvature-constrained vector field (CVF) via blending and distributing basic flow fields in workspace and propose the saturated control laws with a dynamic gain, under which the tracking error's magnitude decreases even when saturation occurs. Under the control laws, kinematically constrained nonholonomic robots are guaranteed to track the reference CVF and converge to the target positive limit set with bounded trajectory curvature. Numerical simulations show that the proposed CVF method outperforms other vector-field-based algorithms. Experiments on Ackermann UGVs and semi-physical fixed-wing UAVs demonstrate that the method can be effectively implemented in real-world scenarios.",
    "published": "2025-03-25T10:28:24Z",
    "updated": "2025-12-01T03:41:54Z",
    "link": "http://arxiv.org/pdf/2504.02852v2.pdf",
    "category": [
      "eess.SY",
      "cs.RO"
    ],
    "authors": [
      "Yike Qiao",
      "Xiaodong He",
      "An Zhuo",
      "Zhiyong Sun",
      "Weimin Bao",
      "Zhongkui Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01194v1",
    "title": "RoboLoc: A Benchmark Dataset for Point Place Recognition and Localization in Indoor-Outdoor Integrated Environments",
    "summary": "Robust place recognition is essential for reliable localization in robotics, particularly in complex environments with fre- quent indoor-outdoor transitions. However, existing LiDAR-based datasets often focus on outdoor scenarios and lack seamless domain shifts. In this paper, we propose RoboLoc, a benchmark dataset designed for GPS-free place recognition in indoor-outdoor environments with floor transitions. RoboLoc features real-world robot trajectories, diverse elevation profiles, and transitions between structured indoor and unstructured outdoor domains. We benchmark a variety of state-of-the-art models, point-based, voxel-based, and BEV-based architectures, highlighting their generalizability domain shifts. RoboLoc provides a realistic testbed for developing multi-domain localization systems in robotics and autonomous navigation",
    "published": "2025-12-01T02:20:14Z",
    "updated": "2025-12-01T02:20:14Z",
    "link": "http://arxiv.org/pdf/2512.01194v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Jaejin Jeon",
      "Seonghoon Ryoo",
      "Sang-Duck Lee",
      "Soomok Lee",
      "Seungwoo Jeong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01111v1",
    "title": "Ethically-Aware Participatory Design of a Productivity Social Robot for College Students",
    "summary": "College students often face academic and life stressors affecting productivity, especially students with Attention Deficit Hyperactivity Disorder (ADHD) who experience executive functioning challenges. Conventional productivity tools typically demand sustained self-discipline and consistent use, which many students struggle with, leading to disruptive app-switching behaviors. Socially Assistive Robots (SARs), known for their intuitive and interactive nature, offer promising potential to support productivity in academic environments, having been successfully utilized in domains like education, cognitive development, and mental health. To leverage SARs effectively in addressing student productivity, this study employed a Participatory Design (PD) approach, directly involving college students and a Student Success and Well-Being Coach in the design process. Through interviews and a collaborative workshop, we gathered detailed insights on productivity challenges and identified desirable features for a productivity-focused SAR. Importantly, ethical considerations were integrated from the onset, facilitating responsible and user-aligned design choices. Our contributions include comprehensive insights into student productivity challenges, SAR design preferences, and actionable recommendations for effective robot characteristics. Additionally, we present stakeholder-derived ethical guidelines to inform responsible future implementations of productivity-focused SARs in higher education.",
    "published": "2025-11-30T22:17:40Z",
    "updated": "2025-11-30T22:17:40Z",
    "link": "http://arxiv.org/pdf/2512.01111v1.pdf",
    "category": [
      "cs.RO",
      "cs.HC"
    ],
    "authors": [
      "Himanshi Lalwani",
      "Hanan Salam"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01108v1",
    "title": "Think Fast: Real-Time Kinodynamic Belief-Space Planning for Projectile Interception",
    "summary": "Intercepting fast moving objects, by its very nature, is challenging because of its tight time constraints. This problem becomes further complicated in the presence of sensor noise because noisy sensors provide, at best, incomplete information, which results in a distribution over target states to be intercepted. Since time is of the essence, to hit the target, the planner must begin directing the interceptor, in this case a robot arm, while still receiving information. We introduce an tree-like structure, which is grown using kinodynamic motion primitives in state-time space. This tree-like structure encodes reachability to multiple goals from a single origin, while enabling real-time value updates as the target belief evolves and seamless transitions between goals. We evaluate our framework on an interception task on a 6 DOF industrial arm (ABB IRB-1600) with an onboard stereo camera (ZED 2i). A robust Innovation-based Adaptive Estimation Adaptive Kalman Filter (RIAE-AKF) is used to track the target and perform belief updates.",
    "published": "2025-11-30T22:12:11Z",
    "updated": "2025-11-30T22:12:11Z",
    "link": "http://arxiv.org/pdf/2512.01108v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Gabriel Olin",
      "Lu Chen",
      "Nayesha Gandotra",
      "Maxim Likhachev",
      "Howie Choset"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01106v1",
    "title": "Tactile Robotics: Past and Future",
    "summary": "What is the future of tactile robotics? To help define that future, this article provides a historical perspective on tactile sensing in robotics from the wealth of knowledge and expert opinion in nearly 150 reviews over almost half a century. This history is characterized by a succession of generations: 1965-79 (origins), 1980-94 (foundations and growth), 1995-2009 (tactile winter) and 2010-2024 (expansion and diversification). Recent expansion has led to diverse themes emerging of e-skins, tactile robotic hands, vision-based tactile sensing, soft/biomimetic touch, and the tactile Internet. In the next generation from 2025, tactile robotics could mature to widespread commercial use, with applications in human-like dexterity, understanding human intelligence, and telepresence impacting all robotics and AI. By linking past expert insights to present themes, this article highlights recurring challenges in tactile robotics, showing how the field has evolved, why progress has often stalled, and which opportunities are most likely to define its future.",
    "published": "2025-11-30T22:08:52Z",
    "updated": "2025-11-30T22:08:52Z",
    "link": "http://arxiv.org/pdf/2512.01106v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Nathan F. Lepora"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.19476v2",
    "title": "Gentle Object Retraction in Dense Clutter Using Multimodal Force Sensing and Imitation Learning",
    "summary": "Dense collections of movable objects are common in everyday spaces-from cabinets in a home to shelves in a warehouse. Safely retracting objects from such collections is difficult for robots, yet people do it frequently, leveraging learned experience in tandem with vision and non-prehensile tactile sensing on the sides and backs of their hands and arms. We investigate the role of contact force sensing for training robots to gently reach into constrained clutter and extract objects. The available sensing modalities are (1) \"eye-in-hand\" vision, (2) proprioception, (3) non-prehensile triaxial tactile sensing, (4) contact wrenches estimated from joint torques, and (5) a measure of object acquisition obtained by monitoring the vacuum line of a suction cup. We use imitation learning to train policies from a set of demonstrations on randomly generated scenes, then conduct an ablation study of wrench and tactile information. We evaluate each policy's performance across 40 unseen environment configurations. Policies employing any force sensing show fewer excessive force failures, an increased overall success rate, and faster completion times. The best performance is achieved using both tactile and wrench information, producing an 80% improvement above the baseline without force information.",
    "published": "2025-08-26T23:38:52Z",
    "updated": "2025-11-30T21:59:41Z",
    "link": "http://arxiv.org/pdf/2508.19476v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Dane Brouwer",
      "Joshua Citron",
      "Heather Nolte",
      "Jeannette Bohg",
      "Mark Cutkosky"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01066v1",
    "title": "Reinforcement Learning for Gliding Projectile Guidance and Control",
    "summary": "This paper presents the development of a control law, which is intended to be implemented on an optical guided glider. This guiding law follows an innovative approach, the reinforcement learning. This control law is used to make navigation more flexible and autonomous in a dynamic environment. The final objective is to track a target detected with the camera and then guide the glider to this point with high precision. Already applied on quad-copter drones, we wish by this study to demonstrate the applicability of reinforcement learning for fixed-wing aircraft on all of its axis.",
    "published": "2025-11-30T20:25:43Z",
    "updated": "2025-11-30T20:25:43Z",
    "link": "http://arxiv.org/pdf/2512.01066v1.pdf",
    "category": [
      "cs.RO",
      "eess.SY"
    ],
    "authors": [
      "Joel Cahn",
      "Antonin Thomas",
      "Philippe Pastor"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.01052v1",
    "title": "Autonomous Grasping On Quadruped Robot With Task Level Interaction",
    "summary": "Quadruped robots are increasingly used in various applications due to their high mobility and ability to operate in diverse terrains. However, most available quadruped robots are primarily focused on mobility without object manipulation capabilities. Equipping a quadruped robot with a robotic arm and gripper introduces a challenge in manual control, especially in remote scenarios that require complex commands. This research aims to develop an autonomous grasping system on a quadruped robot using a task-level interaction approach. The system includes hardware integration of a robotic arm and gripper onto the quadruped robot's body, a layered control system designed using ROS, and a web-based interface for human-robot interaction. The robot is capable of autonomously performing tasks such as navigation, object detection, and grasping using GraspNet. Testing was conducted through real-world scenarios to evaluate navigation, object selection and grasping, and user experience. The results show that the robot can perform tasks accurately and consistently, achieving a grasping success rate of 75 % from 12 trials. Therefore, the system demonstrates significant potential in enhancing the capabilities of quadruped robots as service robots in real-world environments.",
    "published": "2025-11-30T19:54:35Z",
    "updated": "2025-11-30T19:54:35Z",
    "link": "http://arxiv.org/pdf/2512.01052v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      " Muhtadin",
      "Mochammad Hilmi Rusydiansyah",
      "Mauridhi Hery Purnomo",
      "I Ketut Eddy Purnama",
      "Chastine Fatichah"
    ]
  }
]