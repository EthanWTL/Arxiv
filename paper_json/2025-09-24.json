[
  {
    "id": "http://arxiv.org/abs/cs/9308101v1",
    "title": "Dynamic Backtracking",
    "summary": "Because of their occasional need to return to shallow points in a search\ntree, existing backtracking methods can sometimes erase meaningful progress\ntoward solving a search problem. In this paper, we present a method by which\nbacktrack points can be moved deeper in the search space, thereby avoiding this\ndifficulty. The technique developed is a variant of dependency-directed\nbacktracking that uses only polynomial space while still providing useful\ncontrol information and retaining the completeness guarantees provided by\nearlier approaches.",
    "published": "1993-08-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9308101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "M. L. Ginsberg"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9308102v1",
    "title": "A Market-Oriented Programming Environment and its Application to\n  Distributed Multicommodity Flow Problems",
    "summary": "Market price systems constitute a well-understood class of mechanisms that\nunder certain conditions provide effective decentralization of decision making\nwith minimal communication overhead. In a market-oriented programming approach\nto distributed problem solving, we derive the activities and resource\nallocations for a set of computational agents by computing the competitive\nequilibrium of an artificial economy. WALRAS provides basic constructs for\ndefining computational market structures, and protocols for deriving their\ncorresponding price equilibria. In a particular realization of this approach\nfor a form of multicommodity flow problem, we see that careful construction of\nthe decision process according to economic principles can lead to efficient\ndistributed resource allocation, and that the behavior of the system can be\nmeaningfully analyzed in economic terms.",
    "published": "1993-08-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9308102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "M. P. Wellman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9309101v1",
    "title": "An Empirical Analysis of Search in GSAT",
    "summary": "We describe an extensive study of search in GSAT, an approximation procedure\nfor propositional satisfiability. GSAT performs greedy hill-climbing on the\nnumber of satisfied clauses in a truth assignment. Our experiments provide a\nmore complete picture of GSAT's search than previous accounts. We describe in\ndetail the two phases of search: rapid hill-climbing followed by a long plateau\nsearch. We demonstrate that when applied to randomly generated 3SAT problems,\nthere is a very simple scaling with problem size for both the mean number of\nsatisfied clauses and the mean branching rate. Our results allow us to make\ndetailed numerical conjectures about the length of the hill-climbing phase, the\naverage gradient of this phase, and to conjecture that both the average score\nand average branching rate decay exponentially during plateau search. We end by\nshowing how these results can be used to direct future theoretical analysis.\nThis work provides a case study of how computer experiments can be used to\nimprove understanding of the theoretical properties of algorithms.",
    "published": "1993-09-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9309101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "I. P. Gent",
      "T. Walsh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9311101v1",
    "title": "The Difficulties of Learning Logic Programs with Cut",
    "summary": "As real logic programmers normally use cut (!), an effective learning\nprocedure for logic programs should be able to deal with it. Because the cut\npredicate has only a procedural meaning, clauses containing cut cannot be\nlearned using an extensional evaluation method, as is done in most learning\nsystems. On the other hand, searching a space of possible programs (instead of\na space of independent clauses) is unfeasible. An alternative solution is to\ngenerate first a candidate base program which covers the positive examples, and\nthen make it consistent by inserting cut where appropriate. The problem of\nlearning programs with cut has not been investigated before and this seems to\nbe a natural and reasonable approach. We generalize this scheme and investigate\nthe difficulties that arise. Some of the major shortcomings are actually\ncaused, in general, by the need for intensional evaluation. As a conclusion,\nthe analysis of this paper suggests, on precise and technical grounds, that\nlearning cut is difficult, and current induction techniques should probably be\nrestricted to purely declarative logic languages.",
    "published": "1993-11-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9311101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "F. Bergadano",
      "D. Gunetti",
      "U. Trinchero"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9311102v1",
    "title": "Software Agents: Completing Patterns and Constructing User Interfaces",
    "summary": "To support the goal of allowing users to record and retrieve information,\nthis paper describes an interactive note-taking system for pen-based computers\nwith two distinctive features. First, it actively predicts what the user is\ngoing to write. Second, it automatically constructs a custom, button-box user\ninterface on request. The system is an example of a learning-apprentice\nsoftware- agent. A machine learning component characterizes the syntax and\nsemantics of the user's information. A performance system uses this learned\ninformation to generate completion strings and construct a user interface.\nDescription of Online Appendix: People like to record information. Doing this\non paper is initially efficient, but lacks flexibility. Recording information\non a computer is less efficient but more powerful. In our new note taking\nsoftwre, the user records information directly on a computer. Behind the\ninterface, an agent acts for the user. To help, it provides defaults and\nconstructs a custom user interface. The demonstration is a QuickTime movie of\nthe note taking agent in action. The file is a binhexed self-extracting\narchive. Macintosh utilities for binhex are available from\nmac.archive.umich.edu. QuickTime is available from ftp.apple.com in the\ndts/mac/sys.soft/quicktime.",
    "published": "1993-11-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9311102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "J. C. Schlimmer",
      "L. A. Hermens"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9312101v1",
    "title": "Decidable Reasoning in Terminological Knowledge Representation Systems",
    "summary": "Terminological knowledge representation systems (TKRSs) are tools for\ndesigning and using knowledge bases that make use of terminological languages\n(or concept languages). We analyze from a theoretical point of view a TKRS\nwhose capabilities go beyond the ones of presently available TKRSs. The new\nfeatures studied, often required in practical applications, can be summarized\nin three main points. First, we consider a highly expressive terminological\nlanguage, called ALCNR, including general complements of concepts, number\nrestrictions and role conjunction. Second, we allow to express inclusion\nstatements between general concepts, and terminological cycles as a particular\ncase. Third, we prove the decidability of a number of desirable TKRS-deduction\nservices (like satisfiability, subsumption and instance checking) through a\nsound, complete and terminating calculus for reasoning in ALCNR-knowledge\nbases. Our calculus extends the general technique of constraint systems. As a\nbyproduct of the proof, we get also the result that inclusion statements in\nALCNR can be simulated by terminological cycles, if descriptive semantics is\nadopted.",
    "published": "1993-12-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9312101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "M. Buchheit",
      "F. M. Donini",
      "A. Schaerf"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9401101v1",
    "title": "Teleo-Reactive Programs for Agent Control",
    "summary": "A formalism is presented for computing and organizing actions for autonomous\nagents in dynamic environments. We introduce the notion of teleo-reactive (T-R)\nprograms whose execution entails the construction of circuitry for the\ncontinuous computation of the parameters and conditions on which agent action\nis based. In addition to continuous feedback, T-R programs support parameter\nbinding and recursion. A primary difference between T-R programs and many other\ncircuit-based systems is that the circuitry of T-R programs is more compact; it\nis constructed at run time and thus does not have to anticipate all the\ncontingencies that might arise over all possible runs. In addition, T-R\nprograms are intuitive and easy to write and are written in a form that is\ncompatible with automatic planning and learning methods. We briefly describe\nsome experimental applications of T-R programs in the control of simulated and\nactual mobile robots.",
    "published": "1994-01-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9401101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "N. Nilsson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9402101v1",
    "title": "Learning the Past Tense of English Verbs: The Symbolic Pattern\n  Associator vs. Connectionist Models",
    "summary": "Learning the past tense of English verbs - a seemingly minor aspect of\nlanguage acquisition - has generated heated debates since 1986, and has become\na landmark task for testing the adequacy of cognitive modeling. Several\nartificial neural networks (ANNs) have been implemented, and a challenge for\nbetter symbolic models has been posed. In this paper, we present a\ngeneral-purpose Symbolic Pattern Associator (SPA) based upon the decision-tree\nlearning algorithm ID3. We conduct extensive head-to-head comparisons on the\ngeneralization ability between ANN models and the SPA under different\nrepresentations. We conclude that the SPA generalizes the past tense of unseen\nverbs better than ANN models by a wide margin, and we offer insights as to why\nthis should be the case. We also discuss a new default strategy for\ndecision-tree learning algorithms.",
    "published": "1994-02-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9402101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "C. X. Ling"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9402102v1",
    "title": "Substructure Discovery Using Minimum Description Length and Background\n  Knowledge",
    "summary": "The ability to identify interesting and repetitive substructures is an\nessential component to discovering knowledge in structural data. We describe a\nnew version of our SUBDUE substructure discovery system based on the minimum\ndescription length principle. The SUBDUE system discovers substructures that\ncompress the original data and represent structural concepts in the data. By\nreplacing previously-discovered substructures in the data, multiple passes of\nSUBDUE produce a hierarchical description of the structural regularities in the\ndata. SUBDUE uses a computationally-bounded inexact graph match that identifies\nsimilar, but not identical, instances of a substructure and finds an\napproximate measure of closeness of two substructures when under computational\nconstraints. In addition to the minimum description length principle, other\nbackground knowledge can be used by SUBDUE to guide the search towards more\nappropriate substructures. Experiments in a variety of domains demonstrate\nSUBDUE's ability to find substructures capable of compressing the original data\nand to discover structural concepts important to the domain. Description of\nOnline Appendix: This is a compressed tar file containing the SUBDUE discovery\nsystem, written in C. The program accepts as input databases represented in\ngraph form, and will output discovered substructures with their corresponding\nvalue.",
    "published": "1994-02-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9402102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "D. J. Cook",
      "L. B. Holder"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9402103v1",
    "title": "Bias-Driven Revision of Logical Domain Theories",
    "summary": "The theory revision problem is the problem of how best to go about revising a\ndeficient domain theory using information contained in examples that expose\ninaccuracies. In this paper we present our approach to the theory revision\nproblem for propositional domain theories. The approach described here, called\nPTR, uses probabilities associated with domain theory elements to numerically\ntrack the ``flow'' of proof through the theory. This allows us to measure the\nprecise role of a clause or literal in allowing or preventing a (desired or\nundesired) derivation for a given example. This information is used to\nefficiently locate and repair flawed elements of the theory. PTR is proved to\nconverge to a theory which correctly classifies all examples, and shown\nexperimentally to be fast and accurate even for deep theories.",
    "published": "1994-02-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9402103v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "M. Koppel",
      "R. Feldman",
      "A. M. Segre"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9403101v1",
    "title": "Exploring the Decision Forest: An Empirical Investigation of Occam's\n  Razor in Decision Tree Induction",
    "summary": "We report on a series of experiments in which all decision trees consistent\nwith the training data are constructed. These experiments were run to gain an\nunderstanding of the properties of the set of consistent decision trees and the\nfactors that affect the accuracy of individual trees. In particular, we\ninvestigated the relationship between the size of a decision tree consistent\nwith some training data and the accuracy of the tree on test data. The\nexperiments were performed on a massively parallel Maspar computer. The results\nof the experiments on several artificial and two real world problems indicate\nthat, for many of the problems investigated, smaller consistent decision trees\nare on average less accurate than the average accuracy of slightly larger\ntrees.",
    "published": "1994-03-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9403101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "P. M. Murphy",
      "M. J. Pazzani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9406101v1",
    "title": "A Semantics and Complete Algorithm for Subsumption in the CLASSIC\n  Description Logic",
    "summary": "This paper analyzes the correctness of the subsumption algorithm used in\nCLASSIC, a description logic-based knowledge representation system that is\nbeing used in practical applications. In order to deal efficiently with\nindividuals in CLASSIC descriptions, the developers have had to use an\nalgorithm that is incomplete with respect to the standard, model-theoretic\nsemantics for description logics. We provide a variant semantics for\ndescriptions with respect to which the current implementation is complete, and\nwhich can be independently motivated. The soundness and completeness of the\npolynomial-time subsumption algorithm is established using description graphs,\nwhich are an abstracted version of the implementation structures used in\nCLASSIC, and are of independent interest.",
    "published": "1994-06-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9406101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "A. Borgida",
      "P. F. Patel-Schneider"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9406102v1",
    "title": "Applying GSAT to Non-Clausal Formulas",
    "summary": "In this paper we describe how to modify GSAT so that it can be applied to\nnon-clausal formulas. The idea is to use a particular ``score'' function which\ngives the number of clauses of the CNF conversion of a formula which are false\nunder a given truth assignment. Its value is computed in linear time, without\nconstructing the CNF conversion itself. The proposed methodology applies to\nmost of the variants of GSAT proposed so far.",
    "published": "1994-06-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9406102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "R. Sebastiani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9408101v1",
    "title": "Random Worlds and Maximum Entropy",
    "summary": "Given a knowledge base KB containing first-order and statistical facts, we\nconsider a principled method, called the random-worlds method, for computing a\ndegree of belief that some formula Phi holds given KB. If we are reasoning\nabout a world or system consisting of N individuals, then we can consider all\npossible worlds, or first-order models, with domain {1,...,N} that satisfy KB,\nand compute the fraction of them in which Phi is true. We define the degree of\nbelief to be the asymptotic value of this fraction as N grows large. We show\nthat when the vocabulary underlying Phi and KB uses constants and unary\npredicates only, we can naturally associate an entropy with each world. As N\ngrows larger, there are many more worlds with higher entropy. Therefore, we can\nuse a maximum-entropy computation to compute the degree of belief. This result\nis in a similar spirit to previous work in physics and artificial intelligence,\nbut is far more general. Of equal interest to the result itself are the\nlimitations on its scope. Most importantly, the restriction to unary predicates\nseems necessary. Although the random-worlds method makes sense in general, the\nconnection to maximum entropy seems to disappear in the non-unary case. These\nobservations suggest unexpected limitations to the applicability of\nmaximum-entropy methods.",
    "published": "1994-08-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9408101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "A. J. Grove",
      "J. Y. Halpern",
      "D. Koller"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9408102v1",
    "title": "Pattern Matching and Discourse Processing in Information Extraction from\n  Japanese Text",
    "summary": "Information extraction is the task of automatically picking up information of\ninterest from an unconstrained text. Information of interest is usually\nextracted in two steps. First, sentence level processing locates relevant\npieces of information scattered throughout the text; second, discourse\nprocessing merges coreferential information to generate the output. In the\nfirst step, pieces of information are locally identified without recognizing\nany relationships among them. A key word search or simple pattern search can\nachieve this purpose. The second step requires deeper knowledge in order to\nunderstand relationships among separately identified pieces of information.\nPrevious information extraction systems focused on the first step, partly\nbecause they were not required to link up each piece of information with other\npieces. To link the extracted pieces of information and map them onto a\nstructured output format, complex discourse processing is essential. This paper\nreports on a Japanese information extraction system that merges information\nusing a pattern matcher and discourse processor. Evaluation results show a high\nlevel of system performance which approaches human performance.",
    "published": "1994-08-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9408102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "T. Kitani",
      "Y. Eriguchi",
      "M. Hara"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9408103v1",
    "title": "A System for Induction of Oblique Decision Trees",
    "summary": "This article describes a new system for induction of oblique decision trees.\nThis system, OC1, combines deterministic hill-climbing with two forms of\nrandomization to find a good oblique split (in the form of a hyperplane) at\neach node of a decision tree. Oblique decision tree methods are tuned\nespecially for domains in which the attributes are numeric, although they can\nbe adapted to symbolic or mixed symbolic/numeric attributes. We present\nextensive empirical studies, using both real and artificial data, that analyze\nOC1's ability to construct oblique trees that are smaller and more accurate\nthan their axis-parallel counterparts. We also examine the benefits of\nrandomization for the construction of oblique decision trees.",
    "published": "1994-08-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9408103v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "S. K. Murthy",
      "S. Kasif",
      "S. Salzberg"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9409101v1",
    "title": "On Planning while Learning",
    "summary": "This paper introduces a framework for Planning while Learning where an agent\nis given a goal to achieve in an environment whose behavior is only partially\nknown to the agent. We discuss the tractability of various plan-design\nprocesses. We show that for a large natural class of Planning while Learning\nsystems, a plan can be presented and verified in a reasonable time. However,\ncoming up algorithmically with a plan, even for simple classes of systems is\napparently intractable. We emphasize the role of off-line plan-design\nprocesses, and show that, in most natural cases, the verification (projection)\npart can be carried out in an efficient algorithmic manner.",
    "published": "1994-09-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9409101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "S. Safra",
      "M. Tennenholtz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9412101v1",
    "title": "Wrap-Up: a Trainable Discourse Module for Information Extraction",
    "summary": "The vast amounts of on-line text now available have led to renewed interest\nin information extraction (IE) systems that analyze unrestricted text,\nproducing a structured representation of selected information from the text.\nThis paper presents a novel approach that uses machine learning to acquire\nknowledge for some of the higher level IE processing. Wrap-Up is a trainable IE\ndiscourse component that makes intersentential inferences and identifies\nlogical relations among information extracted from the text. Previous\ncorpus-based approaches were limited to lower level processing such as\npart-of-speech tagging, lexical disambiguation, and dictionary construction.\nWrap-Up is fully trainable, and not only automatically decides what classifiers\nare needed, but even derives the feature set for each classifier automatically.\nPerformance equals that of a partially trainable discourse module requiring\nmanual customization for each domain.",
    "published": "1994-12-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9412101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "S. Soderland",
      "Lehnert. W"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9412102v1",
    "title": "Operations for Learning with Graphical Models",
    "summary": "This paper is a multidisciplinary review of empirical, statistical learning\nfrom a graphical model perspective. Well-known examples of graphical models\ninclude Bayesian networks, directed graphs representing a Markov chain, and\nundirected networks representing a Markov field. These graphical models are\nextended to model data analysis and empirical learning using the notation of\nplates. Graphical operations for simplifying and manipulating a problem are\nprovided including decomposition, differentiation, and the manipulation of\nprobability models from the exponential family. Two standard algorithm schemas\nfor learning are reviewed in a graphical framework: Gibbs sampling and the\nexpectation maximization algorithm. Using these operations and schemas, some\npopular algorithms can be synthesized from their graphical specification. This\nincludes versions of linear regression, techniques for feed-forward networks,\nand learning Gaussian and discrete Bayesian networks from data. The paper\nconcludes by sketching some implications for data analysis and summarizing how\nsome popular algorithms fall within the framework presented. The main original\ncontributions here are the decomposition techniques and the demonstration that\ngraphical models provide a framework for understanding and developing complex\nlearning algorithms.",
    "published": "1994-12-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9412102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "W. L. Buntine"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9412103v1",
    "title": "Total-Order and Partial-Order Planning: A Comparative Analysis",
    "summary": "For many years, the intuitions underlying partial-order planning were largely\ntaken for granted. Only in the past few years has there been renewed interest\nin the fundamental principles underlying this paradigm. In this paper, we\npresent a rigorous comparative analysis of partial-order and total-order\nplanning by focusing on two specific planners that can be directly compared. We\nshow that there are some subtle assumptions that underly the wide-spread\nintuitions regarding the supposed efficiency of partial-order planning. For\ninstance, the superiority of partial-order planning can depend critically upon\nthe search strategy and the structure of the search space. Understanding the\nunderlying assumptions is crucial for constructing efficient planners.",
    "published": "1994-12-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9412103v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "S. Minton",
      "J. Bresina",
      "M. Drummond"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9501101v1",
    "title": "Solving Multiclass Learning Problems via Error-Correcting Output Codes",
    "summary": "Multiclass learning problems involve finding a definition for an unknown\nfunction f(x) whose range is a discrete set containing k &gt 2 values (i.e., k\n``classes''). The definition is acquired by studying collections of training\nexamples of the form [x_i, f (x_i)]. Existing approaches to multiclass learning\nproblems include direct application of multiclass algorithms such as the\ndecision-tree algorithms C4.5 and CART, application of binary concept learning\nalgorithms to learn individual binary functions for each of the k classes, and\napplication of binary concept learning algorithms with distributed output\nrepresentations. This paper compares these three approaches to a new technique\nin which error-correcting codes are employed as a distributed output\nrepresentation. We show that these output representations improve the\ngeneralization performance of both C4.5 and backpropagation on a wide range of\nmulticlass learning tasks. We also demonstrate that this approach is robust\nwith respect to changes in the size of the training sample, the assignment of\ndistributed representations to particular classes, and the application of\noverfitting avoidance techniques such as decision-tree pruning. Finally, we\nshow that---like the other methods---the error-correcting code technique can\nprovide reliable class probability estimates. Taken together, these results\ndemonstrate that error-correcting output codes provide a general-purpose method\nfor improving the performance of inductive learning programs on multiclass\nproblems.",
    "published": "1995-01-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9501101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "T. G. Dietterich",
      "G. Bakiri"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9501102v1",
    "title": "A Domain-Independent Algorithm for Plan Adaptation",
    "summary": "The paradigms of transformational planning, case-based planning, and plan\ndebugging all involve a process known as plan adaptation - modifying or\nrepairing an old plan so it solves a new problem. In this paper we provide a\ndomain-independent algorithm for plan adaptation, demonstrate that it is sound,\ncomplete, and systematic, and compare it to other adaptation algorithms in the\nliterature. Our approach is based on a view of planning as searching a graph of\npartial plans. Generative planning starts at the graph's root and moves from\nnode to node using plan-refinement operators. In planning by adaptation, a\nlibrary plan - an arbitrary node in the plan graph - is the starting point for\nthe search, and the plan-adaptation algorithm can apply both the same\nrefinement operators available to a generative planner and can also retract\nconstraints and steps from the plan. Our algorithm's completeness ensures that\nthe adaptation algorithm will eventually search the entire graph and its\nsystematicity ensures that it will do so without redundantly searching any\nparts of the graph.",
    "published": "1995-01-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9501102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "S. Hanks",
      "D. S. Weld"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9501103v1",
    "title": "Truncating Temporal Differences: On the Efficient Implementation of\n  TD(lambda) for Reinforcement Learning",
    "summary": "Temporal difference (TD) methods constitute a class of methods for learning\npredictions in multi-step prediction problems, parameterized by a recency\nfactor lambda. Currently the most important application of these methods is to\ntemporal credit assignment in reinforcement learning. Well known reinforcement\nlearning algorithms, such as AHC or Q-learning, may be viewed as instances of\nTD learning. This paper examines the issues of the efficient and general\nimplementation of TD(lambda) for arbitrary lambda, for use with reinforcement\nlearning algorithms optimizing the discounted sum of rewards. The traditional\napproach, based on eligibility traces, is argued to suffer from both\ninefficiency and lack of generality. The TTD (Truncated Temporal Differences)\nprocedure is proposed as an alternative, that indeed only approximates\nTD(lambda), but requires very little computation per action and can be used\nwith arbitrary function representation methods. The idea from which it is\nderived is fairly simple and not new, but probably unexplored so far.\nEncouraging experimental results are presented, suggesting that using lambda\n&gt 0 with the TTD procedure allows one to obtain a significant learning\nspeedup at essentially the same cost as usual TD(0) learning.",
    "published": "1995-01-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9501103v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "P. Cichosz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9503101v1",
    "title": "On the Informativeness of the DNA Promoter Sequences Domain Theory",
    "summary": "The DNA promoter sequences domain theory and database have become popular for\ntesting systems that integrate empirical and analytical learning. This note\nreports a simple change and reinterpretation of the domain theory in terms of\nM-of-N concepts, involving no learning, that results in an accuracy of 93.4% on\nthe 106 items of the database. Moreover, an exhaustive search of the space of\nM-of-N domain theory interpretations indicates that the expected accuracy of a\nrandomly chosen interpretation is 76.5%, and that a maximum accuracy of 97.2%\nis achieved in 12 cases. This demonstrates the informativeness of the domain\ntheory, without the complications of understanding the interactions between\nvarious learning algorithms and the theory. In addition, our results help\ncharacterize the difficulty of learning using the DNA promoters theory.",
    "published": "1995-03-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9503101v1.pdf",
    "category": [
      "cs.AI",
      "q-bio"
    ],
    "authors": [
      "J. Ortega"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9503102v1",
    "title": "Cost-Sensitive Classification: Empirical Evaluation of a Hybrid Genetic\n  Decision Tree Induction Algorithm",
    "summary": "This paper introduces ICET, a new algorithm for cost-sensitive\nclassification. ICET uses a genetic algorithm to evolve a population of biases\nfor a decision tree induction algorithm. The fitness function of the genetic\nalgorithm is the average cost of classification when using the decision tree,\nincluding both the costs of tests (features, measurements) and the costs of\nclassification errors. ICET is compared here with three other algorithms for\ncost-sensitive classification - EG2, CS-ID3, and IDX - and also with C4.5,\nwhich classifies without regard to cost. The five algorithms are evaluated\nempirically on five real-world medical datasets. Three sets of experiments are\nperformed. The first set examines the baseline performance of the five\nalgorithms on the five datasets and establishes that ICET performs\nsignificantly better than its competitors. The second set tests the robustness\nof ICET under a variety of conditions and shows that ICET maintains its\nadvantage. The third set looks at ICET's search in bias space and discovers a\nway to improve the search.",
    "published": "1995-03-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9503102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "P. D. Turney"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9504101v1",
    "title": "Rerepresenting and Restructuring Domain Theories: A Constructive\n  Induction Approach",
    "summary": "Theory revision integrates inductive learning and background knowledge by\ncombining training examples with a coarse domain theory to produce a more\naccurate theory. There are two challenges that theory revision and other\ntheory-guided systems face. First, a representation language appropriate for\nthe initial theory may be inappropriate for an improved theory. While the\noriginal representation may concisely express the initial theory, a more\naccurate theory forced to use that same representation may be bulky,\ncumbersome, and difficult to reach. Second, a theory structure suitable for a\ncoarse domain theory may be insufficient for a fine-tuned theory. Systems that\nproduce only small, local changes to a theory have limited value for\naccomplishing complex structural alterations that may be required.\nConsequently, advanced theory-guided learning systems require flexible\nrepresentation and flexible structure. An analysis of various theory revision\nsystems and theory-guided learning systems reveals specific strengths and\nweaknesses in terms of these two desired properties. Designed to capture the\nunderlying qualities of each system, a new system uses theory-guided\nconstructive induction. Experiments in three domains show improvement over\nprevious theory-guided systems. This leads to a study of the behavior,\nlimitations, and potential of theory-guided constructive induction.",
    "published": "1995-04-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9504101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "S. K. Donoho",
      "L. A. Rendell"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9505101v1",
    "title": "Using Pivot Consistency to Decompose and Solve Functional CSPs",
    "summary": "Many studies have been carried out in order to increase the search efficiency\nof constraint satisfaction problems; among them, some make use of structural\nproperties of the constraint network; others take into account semantic\nproperties of the constraints, generally assuming that all the constraints\npossess the given property. In this paper, we propose a new decomposition\nmethod benefiting from both semantic properties of functional constraints (not\nbijective constraints) and structural properties of the network; furthermore,\nnot all the constraints need to be functional. We show that under some\nconditions, the existence of solutions can be guaranteed. We first characterize\na particular subset of the variables, which we name a root set. We then\nintroduce pivot consistency, a new local consistency which is a weak form of\npath consistency and can be achieved in O(n^2d^2) complexity (instead of\nO(n^3d^3) for path consistency), and we present associated properties; in\nparticular, we show that any consistent instantiation of the root set can be\nlinearly extended to a solution, which leads to the presentation of the\naforementioned new method for solving by decomposing functional CSPs.",
    "published": "1995-05-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9505101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "P. David"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9505102v1",
    "title": "Adaptive Load Balancing: A Study in Multi-Agent Learning",
    "summary": "We study the process of multi-agent reinforcement learning in the context of\nload balancing in a distributed system, without use of either central\ncoordination or explicit communication. We first define a precise framework in\nwhich to study adaptive load balancing, important features of which are its\nstochastic nature and the purely local information available to individual\nagents. Given this framework, we show illuminating results on the interplay\nbetween basic adaptive behavior parameters and their effect on system\nefficiency. We then investigate the properties of adaptive load balancing in\nheterogeneous populations, and address the issue of exploration vs.\nexploitation in that context. Finally, we show that naive use of communication\nmay not improve, and might even harm system efficiency.",
    "published": "1995-05-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9505102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "A. Schaerf",
      "Y. Shoham",
      "M. Tennenholtz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9505103v1",
    "title": "Provably Bounded-Optimal Agents",
    "summary": "Since its inception, artificial intelligence has relied upon a theoretical\nfoundation centered around perfect rationality as the desired property of\nintelligent systems. We argue, as others have done, that this foundation is\ninadequate because it imposes fundamentally unsatisfiable requirements. As a\nresult, there has arisen a wide gap between theory and practice in AI,\nhindering progress in the field. We propose instead a property called bounded\noptimality. Roughly speaking, an agent is bounded-optimal if its program is a\nsolution to the constrained optimization problem presented by its architecture\nand the task environment. We show how to construct agents with this property\nfor a simple class of machine architectures in a broad class of real-time\nenvironments. We illustrate these results using a simple model of an automated\nmail sorting facility. We also define a weaker property, asymptotic bounded\noptimality (ABO), that generalizes the notion of optimality in classical\ncomplexity theory. We then construct universal ABO programs, i.e., programs\nthat are ABO no matter what real-time constraints are applied. Universal ABO\nprograms can be used as building blocks for more complex systems. We conclude\nwith a discussion of the prospects for bounded optimality as a theoretical\nbasis for AI, and relate it to similar trends in philosophy, economics, and\ngame theory.",
    "published": "1995-05-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9505103v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "S. J. Russell",
      "D. Subramanian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9505104v1",
    "title": "Pac-Learning Recursive Logic Programs: Efficient Algorithms",
    "summary": "We present algorithms that learn certain classes of function-free recursive\nlogic programs in polynomial time from equivalence queries. In particular, we\nshow that a single k-ary recursive constant-depth determinate clause is\nlearnable. Two-clause programs consisting of one learnable recursive clause and\none constant-depth determinate non-recursive clause are also learnable, if an\nadditional ``basecase'' oracle is assumed. These results immediately imply the\npac-learnability of these classes. Although these classes of learnable\nrecursive programs are very constrained, it is shown in a companion paper that\nthey are maximally general, in that generalizing either class in any natural\nway leads to a computationally difficult learning problem. Thus, taken together\nwith its companion paper, this paper establishes a boundary of efficient\nlearnability for recursive logic programs.",
    "published": "1995-05-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9505104v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "W. W. Cohen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9505105v1",
    "title": "Pac-learning Recursive Logic Programs: Negative Results",
    "summary": "In a companion paper it was shown that the class of constant-depth\ndeterminate k-ary recursive clauses is efficiently learnable. In this paper we\npresent negative results showing that any natural generalization of this class\nis hard to learn in Valiant's model of pac-learnability. In particular, we show\nthat the following program classes are cryptographically hard to learn:\nprograms with an unbounded number of constant-depth linear recursive clauses;\nprograms with one constant-depth determinate clause containing an unbounded\nnumber of recursive calls; and programs with one linear recursive clause of\nconstant locality. These results immediately imply the non-learnability of any\nmore general class of programs. We also show that learning a constant-depth\ndeterminate program with either two linear recursive clauses or one linear\nrecursive clause and one non-recursive clause is as hard as learning boolean\nDNF. Together with positive results from the companion paper, these negative\nresults establish a boundary of efficient learnability for recursive\nfunction-free clauses.",
    "published": "1995-05-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9505105v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "W. W. Cohen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9506101v1",
    "title": "FLECS: Planning with a Flexible Commitment Strategy",
    "summary": "There has been evidence that least-commitment planners can efficiently handle\nplanning problems that involve difficult goal interactions. This evidence has\nled to the common belief that delayed-commitment is the \"best\" possible\nplanning strategy. However, we recently found evidence that eager-commitment\nplanners can handle a variety of planning problems more efficiently, in\nparticular those with difficult operator choices. Resigned to the futility of\ntrying to find a universally successful planning strategy, we devised a planner\nthat can be used to study which domains and problems are best for which\nplanning strategies. In this article we introduce this new planning algorithm,\nFLECS, which uses a FLExible Commitment Strategy with respect to plan-step\norderings. It is able to use any strategy from delayed-commitment to\neager-commitment. The combination of delayed and eager operator-ordering\ncommitments allows FLECS to take advantage of the benefits of explicitly using\na simulated execution state and reasoning about planning constraints. FLECS can\nvary its commitment strategy across different problems and domains, and also\nduring the course of a single planning problem. FLECS represents a novel\ncontribution to planning in that it explicitly provides the choice of which\ncommitment strategy to use while planning. FLECS provides a framework to\ninvestigate the mapping from planning domains and problems to efficient\nplanning strategies.",
    "published": "1995-06-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9506101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "M. Veloso",
      "P. Stone"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9506102v1",
    "title": "Induction of First-Order Decision Lists: Results on Learning the Past\n  Tense of English Verbs",
    "summary": "This paper presents a method for inducing logic programs from examples that\nlearns a new class of concepts called first-order decision lists, defined as\nordered lists of clauses each ending in a cut. The method, called FOIDL, is\nbased on FOIL (Quinlan, 1990) but employs intensional background knowledge and\navoids the need for explicit negative examples. It is particularly useful for\nproblems that involve rules with specific exceptions, such as learning the\npast-tense of English verbs, a task widely studied in the context of the\nsymbolic/connectionist debate. FOIDL is able to learn concise, accurate\nprograms for this problem from significantly fewer examples than previous\nmethods (both connectionist and symbolic).",
    "published": "1995-06-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9506102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "R. J. Mooney",
      "M. E. Califf"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9507101v1",
    "title": "Building and Refining Abstract Planning Cases by Change of\n  Representation Language",
    "summary": "ion is one of the most promising approaches to improve the performance of\nproblem solvers. In several domains abstraction by dropping sentences of a\ndomain description -- as used in most hierarchical planners -- has proven\nuseful. In this paper we present examples which illustrate significant\ndrawbacks of abstraction by dropping sentences. To overcome these drawbacks, we\npropose a more general view of abstraction involving the change of\nrepresentation language. We have developed a new abstraction methodology and a\nrelated sound and complete learning algorithm that allows the complete change\nof representation language of planning cases from concrete to abstract.\nHowever, to achieve a powerful change of the representation language, the\nabstract language itself as well as rules which describe admissible ways of\nabstracting states must be provided in the domain model. This new abstraction\napproach is the core of Paris (Plan Abstraction and Refinement in an Integrated\nSystem), a system in which abstract planning cases are automatically learned\nfrom given concrete cases. An empirical study in the domain of process planning\nin mechanical engineering shows significant advantages of the proposed\nreasoning from abstract cases over classical hierarchical planning.",
    "published": "1995-07-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9507101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "R. Bergmann",
      "W. Wilke"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9508101v1",
    "title": "Using Qualitative Hypotheses to Identify Inaccurate Data",
    "summary": "Identifying inaccurate data has long been regarded as a significant and\ndifficult problem in AI. In this paper, we present a new method for identifying\ninaccurate data on the basis of qualitative correlations among related data.\nFirst, we introduce the definitions of related data and qualitative\ncorrelations among related data. Then we put forward a new concept called\nsupport coefficient function (SCF). SCF can be used to extract, represent, and\ncalculate qualitative correlations among related data within a dataset. We\npropose an approach to determining dynamic shift intervals of inaccurate data,\nand an approach to calculating possibility of identifying inaccurate data,\nrespectively. Both of the approaches are based on SCF. Finally we present an\nalgorithm for identifying inaccurate data by using qualitative correlations\namong related data as confirmatory or disconfirmatory evidence. We have\ndeveloped a practical system for interpreting infrared spectra by applying the\nmethod, and have fully tested the system against several hundred real spectra.\nThe experimental results show that the method is significantly better than the\nconventional methods used in many similar systems.",
    "published": "1995-08-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9508101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Q. Zhao",
      "T. Nishida"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9508102v1",
    "title": "An Integrated Framework for Learning and Reasoning",
    "summary": "Learning and reasoning are both aspects of what is considered to be\nintelligence. Their studies within AI have been separated historically,\nlearning being the topic of machine learning and neural networks, and reasoning\nfalling under classical (or symbolic) AI. However, learning and reasoning are\nin many ways interdependent. This paper discusses the nature of some of these\ninterdependencies and proposes a general framework called FLARE, that combines\ninductive learning using prior knowledge together with reasoning in a\npropositional setting. Several examples that test the framework are presented,\nincluding classical induction, many important reasoning protocols and two\nsimple expert systems.",
    "published": "1995-08-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9508102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "C. G. Giraud-Carrier",
      "T. R. Martinez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9510101v1",
    "title": "Diffusion of Context and Credit Information in Markovian Models",
    "summary": "This paper studies the problem of ergodicity of transition probability\nmatrices in Markovian models, such as hidden Markov models (HMMs), and how it\nmakes very difficult the task of learning to represent long-term context for\nsequential data. This phenomenon hurts the forward propagation of long-term\ncontext information, as well as learning a hidden state representation to\nrepresent long-term context, which depends on propagating credit information\nbackwards in time. Using results from Markov chain theory, we show that this\nproblem of diffusion of context and credit is reduced when the transition\nprobabilities approach 0 or 1, i.e., the transition probability matrices are\nsparse and the model essentially deterministic. The results found in this paper\napply to learning approaches based on continuous optimization, such as gradient\ndescent and the Baum-Welch algorithm.",
    "published": "1995-10-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9510101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Y. Bengio",
      "P. Frasconi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9510102v1",
    "title": "Improving Connectionist Energy Minimization",
    "summary": "Symmetric networks designed for energy minimization such as Boltzman machines\nand Hopfield nets are frequently investigated for use in optimization,\nconstraint satisfaction and approximation of NP-hard problems. Nevertheless,\nfinding a global solution (i.e., a global minimum for the energy function) is\nnot guaranteed and even a local solution may take an exponential number of\nsteps. We propose an improvement to the standard local activation function used\nfor such networks. The improved algorithm guarantees that a global minimum is\nfound in linear time for tree-like subnetworks. The algorithm, called activate,\nis uniform and does not assume that the network is tree-like. It can identify\ntree-like subnetworks even in cyclic topologies (arbitrary networks) and avoid\nlocal minima along these trees. For acyclic networks, the algorithm is\nguaranteed to converge to a global minimum from any initial state of the system\n(self-stabilization) and remains correct under various types of schedulers. On\nthe negative side, we show that in the presence of cycles, no uniform algorithm\nexists that guarantees optimality even under a sequential asynchronous\nscheduler. An asynchronous scheduler can activate only one unit at a time while\na synchronous scheduler can activate any number of units in a single time step.\nIn addition, no uniform algorithm exists to optimize even acyclic networks when\nthe scheduler is synchronous. Finally, we show how the algorithm can be\nimproved using the cycle-cutset scheme. The general algorithm, called\nactivate-with-cutset, improves over activate and has some performance\nguarantees that are related to the size of the network's cycle-cutset.",
    "published": "1995-10-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9510102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "G. Pinkas",
      "R. Dechter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9510103v1",
    "title": "Learning Membership Functions in a Function-Based Object Recognition\n  System",
    "summary": "Functionality-based recognition systems recognize objects at the category\nlevel by reasoning about how well the objects support the expected function.\nSuch systems naturally associate a ``measure of goodness'' or ``membership\nvalue'' with a recognized object. This measure of goodness is the result of\ncombining individual measures, or membership values, from potentially many\nprimitive evaluations of different properties of the object's shape. A\nmembership function is used to compute the membership value when evaluating a\nprimitive of a particular physical property of an object. In previous versions\nof a recognition system known as Gruff, the membership function for each of the\nprimitive evaluations was hand-crafted by the system designer. In this paper,\nwe provide a learning component for the Gruff system, called Omlet, that\nautomatically learns membership functions given a set of example objects\nlabeled with their desired category measure. The learning algorithm is\ngenerally applicable to any problem in which low-level membership values are\ncombined through an and-or tree structure to give a final overall membership\nvalue.",
    "published": "1995-10-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9510103v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "K. Woods",
      "D. Cook",
      "L. Hall",
      "K. Bowyer",
      "L. Stark"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9511101v1",
    "title": "Flexibly Instructable Agents",
    "summary": "This paper presents an approach to learning from situated, interactive\ntutorial instruction within an ongoing agent. Tutorial instruction is a\nflexible (and thus powerful) paradigm for teaching tasks because it allows an\ninstructor to communicate whatever types of knowledge an agent might need in\nwhatever situations might arise. To support this flexibility, however, the\nagent must be able to learn multiple kinds of knowledge from a broad range of\ninstructional interactions. Our approach, called situated explanation, achieves\nsuch learning through a combination of analytic and inductive techniques. It\ncombines a form of explanation-based learning that is situated for each\ninstruction with a full suite of contextually guided responses to incomplete\nexplanations. The approach is implemented in an agent called Instructo-Soar\nthat learns hierarchies of new tasks and other domain knowledge from\ninteractive natural language instructions. Instructo-Soar meets three key\nrequirements of flexible instructability that distinguish it from previous\nsystems: (1) it can take known or unknown commands at any instruction point;\n(2) it can handle instructions that apply to either its current situation or to\na hypothetical situation specified in language (as in, for instance,\nconditional instructions); and (3) it can learn, from instructions, each class\nof knowledge it uses to perform tasks.",
    "published": "1995-11-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9511101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "S. B. Huffman",
      "J. E. Laird"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9512101v1",
    "title": "OPUS: An Efficient Admissible Algorithm for Unordered Search",
    "summary": "OPUS is a branch and bound search algorithm that enables efficient admissible\nsearch through spaces for which the order of search operator application is not\nsignificant. The algorithm's search efficiency is demonstrated with respect to\nvery large machine learning search spaces. The use of admissible search is of\npotential value to the machine learning community as it means that the exact\nlearning biases to be employed for complex learning tasks can be precisely\nspecified and manipulated. OPUS also has potential for application in other\nareas of artificial intelligence, notably, truth maintenance.",
    "published": "1995-12-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9512101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "G. I. Webb"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9512102v1",
    "title": "Vision-Based Road Detection in Automotive Systems: A Real-Time\n  Expectation-Driven Approach",
    "summary": "The main aim of this work is the development of a vision-based road detection\nsystem fast enough to cope with the difficult real-time constraints imposed by\nmoving vehicle applications. The hardware platform, a special-purpose massively\nparallel system, has been chosen to minimize system production and operational\ncosts. This paper presents a novel approach to expectation-driven low-level\nimage segmentation, which can be mapped naturally onto mesh-connected massively\nparallel SIMD architectures capable of handling hierarchical data structures.\nThe input image is assumed to contain a distorted version of a given template;\na multiresolution stretching process is used to reshape the original template\nin accordance with the acquired image content, minimizing a potential function.\nThe distorted template is the process output.",
    "published": "1995-12-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9512102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "A. Broggi",
      "S. Berte"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9512103v1",
    "title": "Generalization of Clauses under Implication",
    "summary": "In the area of inductive learning, generalization is a main operation, and\nthe usual definition of induction is based on logical implication. Recently\nthere has been a rising interest in clausal representation of knowledge in\nmachine learning. Almost all inductive learning systems that perform\ngeneralization of clauses use the relation theta-subsumption instead of\nimplication. The main reason is that there is a well-known and simple technique\nto compute least general generalizations under theta-subsumption, but not under\nimplication. However generalization under theta-subsumption is inappropriate\nfor learning recursive clauses, which is a crucial problem since recursion is\nthe basic program structure of logic programs. We note that implication between\nclauses is undecidable, and we therefore introduce a stronger form of\nimplication, called T-implication, which is decidable between clauses. We show\nthat for every finite set of clauses there exists a least general\ngeneralization under T-implication. We describe a technique to reduce\ngeneralizations under implication of a clause to generalizations under\ntheta-subsumption of what we call an expansion of the original clause. Moreover\nwe show that for every non-tautological clause there exists a T-complete\nexpansion, which means that every generalization under T-implication of the\nclause is reduced to a generalization under theta-subsumption of the expansion.",
    "published": "1995-12-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9512103v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "P. Idestam-Almquist"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9512104v1",
    "title": "Decision-Theoretic Foundations for Causal Reasoning",
    "summary": "We present a definition of cause and effect in terms of decision-theoretic\nprimitives and thereby provide a principled foundation for causal reasoning.\nOur definition departs from the traditional view of causation in that causal\nassertions may vary with the set of decisions available. We argue that this\napproach provides added clarity to the notion of cause. Also in this paper, we\nexamine the encoding of causal relationships in directed acyclic graphs. We\ndescribe a special class of influence diagrams, those in canonical form, and\nshow its relationship to Pearl's representation of cause and effect. Finally,\nwe show how canonical form facilitates counterfactual reasoning.",
    "published": "1995-12-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9512104v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "D. Heckerman",
      "R. Shachter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9512105v1",
    "title": "Translating between Horn Representations and their Characteristic Models",
    "summary": "Characteristic models are an alternative, model based, representation for\nHorn expressions. It has been shown that these two representations are\nincomparable and each has its advantages over the other. It is therefore\nnatural to ask what is the cost of translating, back and forth, between these\nrepresentations. Interestingly, the same translation questions arise in\ndatabase theory, where it has applications to the design of relational\ndatabases. This paper studies the computational complexity of these problems.\nOur main result is that the two translation problems are equivalent under\npolynomial reductions, and that they are equivalent to the corresponding\ndecision problem. Namely, translating is equivalent to deciding whether a given\nset of models is the set of characteristic models for a given Horn expression.\nWe also relate these problems to the hypergraph transversal problem, a well\nknown problem which is related to other applications in AI and for which no\npolynomial time algorithm is known. It is shown that in general our translation\nproblems are at least as hard as the hypergraph transversal problem, and in a\nspecial case they are equivalent to it.",
    "published": "1995-12-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9512105v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "R. Khardon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9512106v1",
    "title": "Statistical Feature Combination for the Evaluation of Game Positions",
    "summary": "This article describes an application of three well-known statistical methods\nin the field of game-tree search: using a large number of classified Othello\npositions, feature weights for evaluation functions with a\ngame-phase-independent meaning are estimated by means of logistic regression,\nFisher's linear discriminant, and the quadratic discriminant function for\nnormally distributed features. Thereafter, the playing strengths are compared\nby means of tournaments between the resulting versions of a world-class Othello\nprogram. In this application, logistic regression - which is used here for the\nfirst time in the context of game playing - leads to better results than the\nother approaches.",
    "published": "1995-12-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9512106v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "M. Buro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9512107v1",
    "title": "Rule-based Machine Learning Methods for Functional Prediction",
    "summary": "We describe a machine learning method for predicting the value of a\nreal-valued function, given the values of multiple input variables. The method\ninduces solutions from samples in the form of ordered disjunctive normal form\n(DNF) decision rules. A central objective of the method and representation is\nthe induction of compact, easily interpretable solutions. This rule-based\ndecision model can be extended to search efficiently for similar cases prior to\napproximating function values. Experimental results on real-world data\ndemonstrate that the new techniques are competitive with existing machine\nlearning and statistical methods and can sometimes yield superior regression\nperformance.",
    "published": "1995-12-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9512107v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "S. M. Weiss",
      "N. Indurkhya"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9601101v1",
    "title": "The Design and Experimental Analysis of Algorithms for Temporal\n  Reasoning",
    "summary": "Many applications -- from planning and scheduling to problems in molecular\nbiology -- rely heavily on a temporal reasoning component. In this paper, we\ndiscuss the design and empirical analysis of algorithms for a temporal\nreasoning system based on Allen's influential interval-based framework for\nrepresenting temporal information. At the core of the system are algorithms for\ndetermining whether the temporal information is consistent, and, if so, finding\none or more scenarios that are consistent with the temporal information. Two\nimportant algorithms for these tasks are a path consistency algorithm and a\nbacktracking algorithm. For the path consistency algorithm, we develop\ntechniques that can result in up to a ten-fold speedup over an already highly\noptimized implementation. For the backtracking algorithm, we develop variable\nand value ordering heuristics that are shown empirically to dramatically\nimprove the performance of the algorithm. As well, we show that a previously\nsuggested reformulation of the backtracking search problem can reduce the time\nand space requirements of the backtracking search. Taken together, the\ntechniques we develop allow a temporal reasoning component to solve problems\nthat are of practical size.",
    "published": "1996-01-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9601101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "P. vanBeek",
      "D. W. Manchak"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9602101v1",
    "title": "Well-Founded Semantics for Extended Logic Programs with Dynamic\n  Preferences",
    "summary": "The paper describes an extension of well-founded semantics for logic programs\nwith two types of negation. In this extension information about preferences\nbetween rules can be expressed in the logical language and derived dynamically.\nThis is achieved by using a reserved predicate symbol and a naming technique.\nConflicts among rules are resolved whenever possible on the basis of derived\npreference information. The well-founded conclusions of prioritized logic\nprograms can be computed in polynomial time. A legal reasoning example\nillustrates the usefulness of the approach.",
    "published": "1996-02-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9602101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "G. Brewka"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9602102v1",
    "title": "Logarithmic-Time Updates and Queries in Probabilistic Networks",
    "summary": "Traditional databases commonly support efficient query and update procedures\nthat operate in time which is sublinear in the size of the database. Our goal\nin this paper is to take a first step toward dynamic reasoning in probabilistic\ndatabases with comparable efficiency. We propose a dynamic data structure that\nsupports efficient algorithms for updating and querying singly connected\nBayesian networks. In the conventional algorithm, new evidence is absorbed in\nO(1) time and queries are processed in time O(N), where N is the size of the\nnetwork. We propose an algorithm which, after a preprocessing phase, allows us\nto answer queries in time O(log N) at the expense of O(log N) time per evidence\nabsorption. The usefulness of sub-linear processing time manifests itself in\napplications requiring (near) real-time response over large probabilistic\ndatabases. We briefly discuss a potential application of dynamic probabilistic\nreasoning in computational biology.",
    "published": "1996-02-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9602102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "A. L. Delcher",
      "A. J. Grove",
      "S. Kasif",
      "J. Pearl"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9603101v1",
    "title": "Quantum Computing and Phase Transitions in Combinatorial Search",
    "summary": "We introduce an algorithm for combinatorial search on quantum computers that\nis capable of significantly concentrating amplitude into solutions for some NP\nsearch problems, on average. This is done by exploiting the same aspects of\nproblem structure as used by classical backtrack methods to avoid unproductive\nsearch choices. This quantum algorithm is much more likely to find solutions\nthan the simple direct use of quantum parallelism. Furthermore, empirical\nevaluation on small problems shows this quantum algorithm displays the same\nphase transition behavior, and at the same location, as seen in many previously\nstudied classical search methods. Specifically, difficult problem instances are\nconcentrated near the abrupt change from underconstrained to overconstrained\nproblems.",
    "published": "1996-03-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9603101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "T. Hogg"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9603102v1",
    "title": "Mean Field Theory for Sigmoid Belief Networks",
    "summary": "We develop a mean field theory for sigmoid belief networks based on ideas\nfrom statistical mechanics. Our mean field theory provides a tractable\napproximation to the true probability distribution in these networks; it also\nyields a lower bound on the likelihood of evidence. We demonstrate the utility\nof this framework on a benchmark problem in statistical pattern\nrecognition---the classification of handwritten digits.",
    "published": "1996-03-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9603102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "L. K. Saul",
      "T. Jaakkola",
      "M. I. Jordan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9603103v1",
    "title": "Improved Use of Continuous Attributes in C4.5",
    "summary": "A reported weakness of C4.5 in domains with continuous attributes is\naddressed by modifying the formation and evaluation of tests on continuous\nattributes. An MDL-inspired penalty is applied to such tests, eliminating some\nof them from consideration and altering the relative desirability of all tests.\nEmpirical trials show that the modifications lead to smaller decision trees\nwith higher predictive accuracies. Results also confirm that a new version of\nC4.5 incorporating these changes is superior to recent approaches that use\nglobal discretization and that construct small trees with multi-interval\nsplits.",
    "published": "1996-03-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9603103v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "J. R. Quinlan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9603104v1",
    "title": "Active Learning with Statistical Models",
    "summary": "For many types of machine learning algorithms, one can compute the\nstatistically `optimal' way to select training data. In this paper, we review\nhow optimal data selection techniques have been used with feedforward neural\nnetworks. We then show how the same principles may be used to select data for\ntwo alternative, statistically-based learning architectures: mixtures of\nGaussians and locally weighted regression. While the techniques for neural\nnetworks are computationally expensive and approximate, the techniques for\nmixtures of Gaussians and locally weighted regression are both efficient and\naccurate. Empirically, we observe that the optimality criterion sharply\ndecreases the number of training examples the learner needs in order to achieve\ngood performance.",
    "published": "1996-03-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9603104v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "D. A. Cohn",
      "Z. Ghahramani",
      "M. I. Jordan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9604101v1",
    "title": "A Divergence Critic for Inductive Proof",
    "summary": "Inductive theorem provers often diverge. This paper describes a simple\ncritic, a computer program which monitors the construction of inductive proofs\nattempting to identify diverging proof attempts. Divergence is recognized by\nmeans of a ``difference matching'' procedure. The critic then proposes lemmas\nand generalizations which ``ripple'' these differences away so that the proof\ncan go through without divergence. The critic enables the theorem prover Spike\nto prove many theorems completely automatically from the definitions alone.",
    "published": "1996-04-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9604101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "T. Walsh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9604102v1",
    "title": "Practical Methods for Proving Termination of General Logic Programs",
    "summary": "Termination of logic programs with negated body atoms (here called general\nlogic programs) is an important topic. One reason is that many computational\nmechanisms used to process negated atoms, like Clark's negation as failure and\nChan's constructive negation, are based on termination conditions. This paper\nintroduces a methodology for proving termination of general logic programs\nw.r.t. the Prolog selection rule. The idea is to distinguish parts of the\nprogram depending on whether or not their termination depends on the selection\nrule. To this end, the notions of low-, weakly up-, and up-acceptable program\nare introduced. We use these notions to develop a methodology for proving\ntermination of general logic programs, and show how interesting problems in\nnon-monotonic reasoning can be formalized and implemented by means of\nterminating general logic programs.",
    "published": "1996-04-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9604102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "E. Marchiori"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9604103v1",
    "title": "Iterative Optimization and Simplification of Hierarchical Clusterings",
    "summary": "Clustering is often used for discovering structure in data. Clustering\nsystems differ in the objective function used to evaluate clustering quality\nand the control strategy used to search the space of clusterings. Ideally, the\nsearch strategy should consistently construct clusterings of high quality, but\nbe computationally inexpensive as well. In general, we cannot have it both\nways, but we can partition the search so that a system inexpensively constructs\na `tentative' clustering for initial examination, followed by iterative\noptimization, which continues to search in background for improved clusterings.\nGiven this motivation, we evaluate an inexpensive strategy for creating initial\nclusterings, coupled with several control strategies for iterative\noptimization, each of which repeatedly modifies an initial clustering in search\nof a better one. One of these methods appears novel as an iterative\noptimization strategy in clustering contexts. Once a clustering has been\nconstructed it is judged by analysts -- often according to task-specific\ncriteria. Several authors have abstracted these criteria and posited a generic\nperformance task akin to pattern completion, where the error rate over\ncompleted patterns is used to `externally' judge clustering utility. Given this\nperformance task, we adapt resampling-based pruning strategies used by\nsupervised learning systems to the task of simplifying hierarchical\nclusterings, thus promising to ease post-clustering analysis. Finally, we\npropose a number of objective functions, based on attribute-selection measures\nfor decision-tree induction, that might perform well on the error rate and\nsimplicity dimensions.",
    "published": "1996-04-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9604103v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "D. Fisher"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9605101v1",
    "title": "Further Experimental Evidence against the Utility of Occam's Razor",
    "summary": "This paper presents new experimental evidence against the utility of Occam's\nrazor. A~systematic procedure is presented for post-processing decision trees\nproduced by C4.5. This procedure was derived by rejecting Occam's razor and\ninstead attending to the assumption that similar objects are likely to belong\nto the same class. It increases a decision tree's complexity without altering\nthe performance of that tree on the training data from which it is inferred.\nThe resulting more complex decision trees are demonstrated to have, on average,\nfor a variety of common learning tasks, higher predictive accuracy than the\nless complex original decision trees. This result raises considerable doubt\nabout the utility of Occam's razor as it is commonly applied in modern machine\nlearning.",
    "published": "1996-05-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9605101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "G. I. Webb"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9605102v1",
    "title": "Least Generalizations and Greatest Specializations of Sets of Clauses",
    "summary": "The main operations in Inductive Logic Programming (ILP) are generalization\nand specialization, which only make sense in a generality order. In ILP, the\nthree most important generality orders are subsumption, implication and\nimplication relative to background knowledge. The two languages used most often\nare languages of clauses and languages of only Horn clauses. This gives a total\nof six different ordered languages. In this paper, we give a systematic\ntreatment of the existence or non-existence of least generalizations and\ngreatest specializations of finite sets of clauses in each of these six ordered\nsets. We survey results already obtained by others and also contribute some\nanswers of our own. Our main new results are, firstly, the existence of a\ncomputable least generalization under implication of every finite set of\nclauses containing at least one non-tautologous function-free clause (among\nother, not necessarily function-free clauses). Secondly, we show that such a\nleast generalization need not exist under relative implication, not even if\nboth the set that is to be generalized and the background knowledge are\nfunction-free. Thirdly, we give a complete discussion of existence and\nnon-existence of greatest specializations in each of the six ordered languages.",
    "published": "1996-05-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9605102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "S. H. Nienhuys-Cheng",
      "R. deWolf"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9605103v1",
    "title": "Reinforcement Learning: A Survey",
    "summary": "This paper surveys the field of reinforcement learning from a\ncomputer-science perspective. It is written to be accessible to researchers\nfamiliar with machine learning. Both the historical basis of the field and a\nbroad selection of current work are summarized. Reinforcement learning is the\nproblem faced by an agent that learns behavior through trial-and-error\ninteractions with a dynamic environment. The work described here has a\nresemblance to work in psychology, but differs considerably in the details and\nin the use of the word ``reinforcement.'' The paper discusses central issues of\nreinforcement learning, including trading off exploration and exploitation,\nestablishing the foundations of the field via Markov decision theory, learning\nfrom delayed reinforcement, constructing empirical models to accelerate\nlearning, making use of generalization and hierarchy, and coping with hidden\nstate. It concludes with a survey of some implemented systems and an assessment\nof the practical utility of current methods for reinforcement learning.",
    "published": "1996-05-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9605103v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "L. P. Kaelbling",
      "M. L. Littman",
      "A. W. Moore"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9605104v1",
    "title": "Adaptive Problem-solving for Large-scale Scheduling Problems: A Case\n  Study",
    "summary": "Although most scheduling problems are NP-hard, domain specific techniques\nperform well in practice but are quite expensive to construct. In adaptive\nproblem-solving solving, domain specific knowledge is acquired automatically\nfor a general problem solver with a flexible control architecture. In this\napproach, a learning system explores a space of possible heuristic methods for\none well-suited to the eccentricities of the given domain and problem\ndistribution. In this article, we discuss an application of the approach to\nscheduling satellite communications. Using problem distributions based on\nactual mission requirements, our approach identifies strategies that not only\ndecrease the amount of CPU time required to produce schedules, but also\nincrease the percentage of problems that are solvable within computational\nresource limitations.",
    "published": "1996-05-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9605104v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "J. Gratch",
      "S. Chien"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9605105v1",
    "title": "A Formal Framework for Speedup Learning from Problems and Solutions",
    "summary": "Speedup learning seeks to improve the computational efficiency of problem\nsolving with experience. In this paper, we develop a formal framework for\nlearning efficient problem solving from random problems and their solutions. We\napply this framework to two different representations of learned knowledge,\nnamely control rules and macro-operators, and prove theorems that identify\nsufficient conditions for learning in each representation. Our proofs are\nconstructive in that they are accompanied with learning algorithms. Our\nframework captures both empirical and explanation-based speedup learning in a\nunified fashion. We illustrate our framework with implementations in two\ndomains: symbolic integration and Eight Puzzle. This work integrates many\nstrands of experimental and theoretical work in machine learning, including\nempirical learning of control rules, macro-operator learning, Explanation-Based\nLearning (EBL), and Probably Approximately Correct (PAC) Learning.",
    "published": "1996-05-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9605105v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "P. Tadepalli",
      "B. K. Natarajan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9605106v1",
    "title": "2Planning for Contingencies: A Decision-based Approach",
    "summary": "A fundamental assumption made by classical AI planners is that there is no\nuncertainty in the world: the planner has full knowledge of the conditions\nunder which the plan will be executed and the outcome of every action is fully\npredictable. These planners cannot therefore construct contingency plans, i.e.,\nplans in which different actions are performed in different circumstances. In\nthis paper we discuss some issues that arise in the representation and\nconstruction of contingency plans and describe Cassandra, a partial-order\ncontingency planner. Cassandra uses explicit decision-steps that enable the\nagent executing the plan to decide which plan branch to follow. The\ndecision-steps in a plan result in subgoals to acquire knowledge, which are\nplanned for in the same way as any other subgoals. Cassandra thus distinguishes\nthe process of gathering information from the process of making decisions. The\nexplicit representation of decisions in Cassandra allows a coherent approach to\nthe problems of contingent planning, and provides a solid base for extensions\nsuch as the use of different decision-making procedures.",
    "published": "1996-05-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9605106v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "L. Pryor",
      "G. Collins"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9606101v1",
    "title": "A Principled Approach Towards Symbolic Geometric Constraint Satisfaction",
    "summary": "An important problem in geometric reasoning is to find the configuration of a\ncollection of geometric bodies so as to satisfy a set of given constraints.\nRecently, it has been suggested that this problem can be solved efficiently by\nsymbolically reasoning about geometry. This approach, called degrees of freedom\nanalysis, employs a set of specialized routines called plan fragments that\nspecify how to change the configuration of a set of bodies to satisfy a new\nconstraint while preserving existing constraints. A potential drawback, which\nlimits the scalability of this approach, is concerned with the difficulty of\nwriting plan fragments. In this paper we address this limitation by showing how\nthese plan fragments can be automatically synthesized using first principles\nabout geometric bodies, actions, and topology.",
    "published": "1996-06-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9606101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "S. Bhansali",
      "G. A. Kramer",
      "T. J. Hoar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9606102v1",
    "title": "On Partially Controlled Multi-Agent Systems",
    "summary": "Motivated by the control theoretic distinction between controllable and\nuncontrollable events, we distinguish between two types of agents within a\nmulti-agent system: controllable agents, which are directly controlled by the\nsystem's designer, and uncontrollable agents, which are not under the\ndesigner's direct control. We refer to such systems as partially controlled\nmulti-agent systems, and we investigate how one might influence the behavior of\nthe uncontrolled agents through appropriate design of the controlled agents. In\nparticular, we wish to understand which problems are naturally described in\nthese terms, what methods can be applied to influence the uncontrollable\nagents, the effectiveness of such methods, and whether similar methods work\nacross different domains. Using a game-theoretic framework, this paper studies\nthe design of partially controlled multi-agent systems in two contexts: in one\ncontext, the uncontrollable agents are expected utility maximizers, while in\nthe other they are reinforcement learners. We suggest different techniques for\ncontrolling agents' behavior in each domain, assess their success, and examine\ntheir relationship.",
    "published": "1996-06-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9606102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "R. I. Brafman",
      "M. Tennenholtz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9608103v1",
    "title": "Spatial Aggregation: Theory and Applications",
    "summary": "Visual thinking plays an important role in scientific reasoning. Based on the\nresearch in automating diverse reasoning tasks about dynamical systems,\nnonlinear controllers, kinematic mechanisms, and fluid motion, we have\nidentified a style of visual thinking, imagistic reasoning. Imagistic reasoning\norganizes computations around image-like, analogue representations so that\nperceptual and symbolic operations can be brought to bear to infer structure\nand behavior. Programs incorporating imagistic reasoning have been shown to\nperform at an expert level in domains that defy current analytic or numerical\nmethods. We have developed a computational paradigm, spatial aggregation, to\nunify the description of a class of imagistic problem solvers. A program\nwritten in this paradigm has the following properties. It takes a continuous\nfield and optional objective functions as input, and produces high-level\ndescriptions of structure, behavior, or control actions. It computes a\nmulti-layer of intermediate representations, called spatial aggregates, by\nforming equivalence classes and adjacency relations. It employs a small set of\ngeneric operators such as aggregation, classification, and localization to\nperform bidirectional mapping between the information-rich field and\nsuccessively more abstract spatial aggregates. It uses a data structure, the\nneighborhood graph, as a common interface to modularize computations. To\nillustrate our theory, we describe the computational structure of three\nimplemented problem solvers -- KAM, MAPS, and HIPAIR --- in terms of the\nspatial aggregation generic operators by mixing and matching a library of\ncommonly used routines.",
    "published": "1996-08-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9608103v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "K. Yip",
      "F. Zhao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9608104v1",
    "title": "A Hierarchy of Tractable Subsets for Computing Stable Models",
    "summary": "Finding the stable models of a knowledge base is a significant computational\nproblem in artificial intelligence. This task is at the computational heart of\ntruth maintenance systems, autoepistemic logic, and default logic.\nUnfortunately, it is NP-hard. In this paper we present a hierarchy of classes\nof knowledge bases, Omega_1,Omega_2,..., with the following properties: first,\nOmega_1 is the class of all stratified knowledge bases; second, if a knowledge\nbase Pi is in Omega_k, then Pi has at most k stable models, and all of them may\nbe found in time O(lnk), where l is the length of the knowledge base and n the\nnumber of atoms in Pi; third, for an arbitrary knowledge base Pi, we can find\nthe minimum k such that Pi belongs to Omega_k in time polynomial in the size of\nPi; and, last, where K is the class of all knowledge bases, it is the case that\nunion{i=1 to infty} Omega_i = K, that is, every knowledge base belongs to some\nclass in the hierarchy.",
    "published": "1996-08-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9608104v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "R. Ben-Eliyahu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9609101v1",
    "title": "Accelerating Partial-Order Planners: Some Techniques for Effective\n  Search Control and Pruning",
    "summary": "We propose some domain-independent techniques for bringing well-founded\npartial-order planners closer to practicality. The first two techniques are\naimed at improving search control while keeping overhead costs low. One is\nbased on a simple adjustment to the default A* heuristic used by UCPOP to\nselect plans for refinement. The other is based on preferring ``zero\ncommitment'' (forced) plan refinements whenever possible, and using LIFO\nprioritization otherwise. A more radical technique is the use of operator\nparameter domains to prune search. These domains are initially computed from\nthe definitions of the operators and the initial and goal conditions, using a\npolynomial-time algorithm that propagates sets of constants through the\noperator graph, starting in the initial conditions. During planning, parameter\ndomains can be used to prune nonviable operator instances and to remove\nspurious clobbering threats. In experiments based on modifications of UCPOP,\nour improved plan and goal selection strategies gave speedups by factors\nranging from 5 to more than 1000 for a variety of problems that are nontrivial\nfor the unmodified version. Crucially, the hardest problems gave the greatest\nimprovements. The pruning technique based on parameter domains often gave\nspeedups by an order of magnitude or more for difficult problems, both with the\ndefault UCPOP search strategy and with our improved strategy. The Lisp code for\nour techniques and for the test problems is provided in on-line appendices.",
    "published": "1996-09-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9609101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "A. Gerevini",
      "L. Schubert"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9609102v1",
    "title": "Cue Phrase Classification Using Machine Learning",
    "summary": "Cue phrases may be used in a discourse sense to explicitly signal discourse\nstructure, but also in a sentential sense to convey semantic rather than\nstructural information. Correctly classifying cue phrases as discourse or\nsentential is critical in natural language processing systems that exploit\ndiscourse structure, e.g., for performing tasks such as anaphora resolution and\nplan recognition. This paper explores the use of machine learning for\nclassifying cue phrases as discourse or sentential. Two machine learning\nprograms (Cgrendel and C4.5) are used to induce classification models from sets\nof pre-classified cue phrases and their features in text and speech. Machine\nlearning is shown to be an effective technique for not only automating the\ngeneration of classification models, but also for improving upon previous\nresults. When compared to manually derived classification models already in the\nliterature, the learned models often perform with higher accuracy and contain\nnew linguistic insights into the data. In addition, the ability to\nautomatically construct classification models makes it easier to comparatively\nanalyze the utility of alternative feature representations of the data.\nFinally, the ease of retraining makes the learning approach more scalable and\nflexible than manual methods.",
    "published": "1996-09-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9609102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "D. J. Litman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9610101v1",
    "title": "Mechanisms for Automated Negotiation in State Oriented Domains",
    "summary": "This paper lays part of the groundwork for a domain theory of negotiation,\nthat is, a way of classifying interactions so that it is clear, given a domain,\nwhich negotiation mechanisms and strategies are appropriate. We define State\nOriented Domains, a general category of interaction. Necessary and sufficient\nconditions for cooperation are outlined. We use the notion of worth in an\naltered definition of utility, thus enabling agreements in a wider class of\njoint-goal reachable situations. An approach is offered for conflict\nresolution, and it is shown that even in a conflict situation, partial\ncooperative steps can be taken by interacting agents (that is, agents in\nfundamental conflict might still agree to cooperate up to a certain point). A\nUnified Negotiation Protocol (UNP) is developed that can be used in all types\nof encounters. It is shown that in certain borderline cooperative situations, a\npartial cooperative agreement (i.e., one that does not achieve all agents'\ngoals) might be preferred by all agents, even though there exists a rational\nagreement that would achieve all their goals. Finally, we analyze cases where\nagents have incomplete information on the goals and worth of other agents.\nFirst we consider the case where agents' goals are private information, and we\nanalyze what goal declaration strategies the agents might adopt to increase\ntheir utility. Then, we consider the situation where the agents' goals (and\ntherefore stand-alone costs) are common knowledge, but the worth they attach to\ntheir goals is private information. We introduce two mechanisms, one 'strict',\nthe other 'tolerant', and analyze their affects on the stability and efficiency\nof negotiation outcomes.",
    "published": "1996-10-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9610101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "G. Zlotkin",
      "J. S. Rosenschein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9610102v1",
    "title": "Learning First-Order Definitions of Functions",
    "summary": "First-order learning involves finding a clause-form definition of a relation\nfrom examples of the relation and relevant background information. In this\npaper, a particular first-order learning system is modified to customize it for\nfinding definitions of functional relations. This restriction leads to faster\nlearning times and, in some cases, to definitions that have higher predictive\naccuracy. Other first-order learning systems might benefit from similar\nspecialization.",
    "published": "1996-10-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9610102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "J. R. Quinlan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9611101v1",
    "title": "MUSE CSP: An Extension to the Constraint Satisfaction Problem",
    "summary": "This paper describes an extension to the constraint satisfaction problem\n(CSP) called MUSE CSP (MUltiply SEgmented Constraint Satisfaction Problem).\nThis extension is especially useful for those problems which segment into\nmultiple sets of partially shared variables. Such problems arise naturally in\nsignal processing applications including computer vision, speech processing,\nand handwriting recognition. For these applications, it is often difficult to\nsegment the data in only one way given the low-level information utilized by\nthe segmentation algorithms. MUSE CSP can be used to compactly represent\nseveral similar instances of the constraint satisfaction problem. If multiple\ninstances of a CSP have some common variables which have the same domains and\nconstraints, then they can be combined into a single instance of a MUSE CSP,\nreducing the work required to apply the constraints. We introduce the concepts\nof MUSE node consistency, MUSE arc consistency, and MUSE path consistency. We\nthen demonstrate how MUSE CSP can be used to compactly represent lexically\nambiguous sentences and the multiple sentence hypotheses that are often\ngenerated by speech recognition algorithms so that grammar constraints can be\nused to provide parses for all syntactically correct sentences. Algorithms for\nMUSE arc and path consistency are provided. Finally, we discuss how to create a\nMUSE CSP from a set of CSPs which are labeled to indicate when the same\nvariable is shared by more than a single CSP.",
    "published": "1996-11-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9611101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "R. A Helzerman",
      "M. P. Harper"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9612101v1",
    "title": "Exploiting Causal Independence in Bayesian Network Inference",
    "summary": "A new method is proposed for exploiting causal independencies in exact\nBayesian network inference. A Bayesian network can be viewed as representing a\nfactorization of a joint probability into the multiplication of a set of\nconditional probabilities. We present a notion of causal independence that\nenables one to further factorize the conditional probabilities into a\ncombination of even smaller factors and consequently obtain a finer-grain\nfactorization of the joint probability. The new formulation of causal\nindependence lets us specify the conditional probability of a variable given\nits parents in terms of an associative and commutative operator, such as\n``or'', ``sum'' or ``max'', on the contribution of each parent. We start with a\nsimple algorithm VE for Bayesian network inference that, given evidence and a\nquery variable, uses the factorization to find the posterior distribution of\nthe query. We show how this algorithm can be extended to exploit causal\nindependence. Empirical studies, based on the CPCS networks for medical\ndiagnosis, show that this method is more efficient than previous methods and\nallows for inference in larger networks than previous algorithms.",
    "published": "1996-12-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9612101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "N. L. Zhang",
      "D. Poole"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9612102v1",
    "title": "Quantitative Results Comparing Three Intelligent Interfaces for\n  Information Capture: A Case Study Adding Name Information into an Electronic\n  Personal Organizer",
    "summary": "Efficiently entering information into a computer is key to enjoying the\nbenefits of computing. This paper describes three intelligent user interfaces:\nhandwriting recognition, adaptive menus, and predictive fillin. In the context\nof adding a personUs name and address to an electronic organizer, tests show\nhandwriting recognition is slower than typing on an on-screen, soft keyboard,\nwhile adaptive menus and predictive fillin can be twice as fast. This paper\nalso presents strategies for applying these three interfaces to other\ninformation collection domains.",
    "published": "1996-12-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9612102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "J. C. Schlimmer",
      "P. C. Wells"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9612103v1",
    "title": "Characterizations of Decomposable Dependency Models",
    "summary": "Decomposable dependency models possess a number of interesting and useful\nproperties. This paper presents new characterizations of decomposable models in\nterms of independence relationships, which are obtained by adding a single\naxiom to the well-known set characterizing dependency models that are\nisomorphic to undirected graphs. We also briefly discuss a potential\napplication of our results to the problem of learning graphical models from\ndata.",
    "published": "1996-12-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9612103v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "L. M. deCampos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9701101v1",
    "title": "Improved Heterogeneous Distance Functions",
    "summary": "Instance-based learning techniques typically handle continuous and linear\ninput values well, but often do not handle nominal input attributes\nappropriately. The Value Difference Metric (VDM) was designed to find\nreasonable distance values between nominal attribute values, but it largely\nignores continuous attributes, requiring discretization to map continuous\nvalues into nominal values. This paper proposes three new heterogeneous\ndistance functions, called the Heterogeneous Value Difference Metric (HVDM),\nthe Interpolated Value Difference Metric (IVDM), and the Windowed Value\nDifference Metric (WVDM). These new distance functions are designed to handle\napplications with nominal attributes, continuous attributes, or both. In\nexperiments on 48 applications the new distance metrics achieve higher\nclassification accuracy on average than three previous distance functions on\nthose datasets that have both nominal and continuous attributes.",
    "published": "1997-01-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9701101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "D. R. Wilson",
      "T. R. Martinez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9701102v1",
    "title": "SCREEN: Learning a Flat Syntactic and Semantic Spoken Language Analysis\n  Using Artificial Neural Networks",
    "summary": "Previous approaches of analyzing spontaneously spoken language often have\nbeen based on encoding syntactic and semantic knowledge manually and\nsymbolically. While there has been some progress using statistical or\nconnectionist language models, many current spoken- language systems still use\na relatively brittle, hand-coded symbolic grammar or symbolic semantic\ncomponent. In contrast, we describe a so-called screening approach for learning\nrobust processing of spontaneously spoken language. A screening approach is a\nflat analysis which uses shallow sequences of category representations for\nanalyzing an utterance at various syntactic, semantic and dialog levels. Rather\nthan using a deeply structured symbolic analysis, we use a flat connectionist\nanalysis. This screening approach aims at supporting speech and language\nprocessing by using (1) data-driven learning and (2) robustness of\nconnectionist networks. In order to test this approach, we have developed the\nSCREEN system which is based on this new robust, learned and flat analysis. In\nthis paper, we focus on a detailed description of SCREEN's architecture, the\nflat syntactic and semantic analysis, the interaction with a speech recognizer,\nand a detailed evaluation analysis of the robustness under the influence of\nnoisy or incomplete input. The main result of this paper is that flat\nrepresentations allow more robust processing of spontaneous spoken language\nthan deeply structured representations. In particular, we show how the\nfault-tolerance and learning capability of connectionist networks can support a\nflat analysis for providing more robust spoken-language processing within an\noverall hybrid symbolic/connectionist framework.",
    "published": "1997-01-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9701102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "S. Wermter",
      "V. Weber"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9703101v1",
    "title": "A Uniform Framework for Concept Definitions in Description Logics",
    "summary": "Most modern formalisms used in Databases and Artificial Intelligence for\ndescribing an application domain are based on the notions of class (or concept)\nand relationship among classes. One interesting feature of such formalisms is\nthe possibility of defining a class, i.e., providing a set of properties that\nprecisely characterize the instances of the class. Many recent articles point\nout that there are several ways of assigning a meaning to a class definition\ncontaining some sort of recursion. In this paper, we argue that, instead of\nchoosing a single style of semantics, we achieve better results by adopting a\nformalism that allows for different semantics to coexist. We demonstrate the\nfeasibility of our argument, by presenting a knowledge representation\nformalism, the description logic muALCQ, with the above characteristics. In\naddition to the constructs for conjunction, disjunction, negation, quantifiers,\nand qualified number restrictions, muALCQ includes special fixpoint constructs\nto express (suitably interpreted) recursive definitions. These constructs\nenable the usual frame-based descriptions to be combined with definitions of\nrecursive data structures such as directed acyclic graphs, lists, streams, etc.\nWe establish several properties of muALCQ, including the decidability and the\ncomputational complexity of reasoning, by formulating a correspondence with a\nparticular modal logic of programs called the modal mu-calculus.",
    "published": "1997-03-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9703101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "G. DeGiacomo",
      "M. Lenzerini"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cond-mat/9703183v1",
    "title": "Finite size scaling of the bayesian perceptron",
    "summary": "We study numerically the properties of the bayesian perceptron through a\ngradient descent on the optimal cost function. The theoretical distribution of\nstabilities is deduced. It predicts that the optimal generalizer lies close to\nthe boundary of the space of (error-free) solutions. The numerical simulations\nare in good agreement with the theoretical distribution. The extrapolation of\nthe generalization error to infinite input space size agrees with the\ntheoretical results. Finite size corrections are negative and exhibit two\ndifferent scaling regimes, depending on the training set size. The variance of\nthe generalization error vanishes for $N \\rightarrow \\infty$ confirming the\nproperty of self-averaging.",
    "published": "1997-03-20T15:54:36Z",
    "link": "http://arxiv.org/pdf/cond-mat/9703183v1.pdf",
    "category": [
      "cond-mat.stat-mech",
      "cond-mat.dis-nn",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "A. Buhot",
      "J. -M. Torres Moreno",
      "M. B. Gordon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9704101v1",
    "title": "Lifeworld Analysis",
    "summary": "We argue that the analysis of agent/environment interactions should be\nextended to include the conventions and invariants maintained by agents\nthroughout their activity. We refer to this thicker notion of environment as a\nlifeworld and present a partial set of formal tools for describing structures\nof lifeworlds and the ways in which they computationally simplify activity. As\none specific example, we apply the tools to the analysis of the Toast system\nand show how versions of the system with very different control structures in\nfact implement a common control structure together with different conventions\nfor encoding task state in the positions or states of objects in the\nenvironment.",
    "published": "1997-04-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9704101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "P. Agre",
      "I. Horswill"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9705101v1",
    "title": "Query DAGs: A Practical Paradigm for Implementing Belief-Network\n  Inference",
    "summary": "We describe a new paradigm for implementing inference in belief networks,\nwhich consists of two steps: (1) compiling a belief network into an arithmetic\nexpression called a Query DAG (Q-DAG); and (2) answering queries using a simple\nevaluation algorithm. Each node of a Q-DAG represents a numeric operation, a\nnumber, or a symbol for evidence. Each leaf node of a Q-DAG represents the\nanswer to a network query, that is, the probability of some event of interest.\nIt appears that Q-DAGs can be generated using any of the standard algorithms\nfor exact inference in belief networks (we show how they can be generated using\nclustering and conditioning algorithms). The time and space complexity of a\nQ-DAG generation algorithm is no worse than the time complexity of the\ninference algorithm on which it is based. The complexity of a Q-DAG evaluation\nalgorithm is linear in the size of the Q-DAG, and such inference amounts to a\nstandard evaluation of the arithmetic expression it represents. The intended\nvalue of Q-DAGs is in reducing the software and hardware resources required to\nutilize belief networks in on-line, real-world applications. The proposed\nframework also facilitates the development of on-line inference on different\nsoftware and hardware platforms due to the simplicity of the Q-DAG evaluation\nalgorithm. Interestingly enough, Q-DAGs were found to serve other purposes:\nsimple techniques for reducing Q-DAGs tend to subsume relatively complex\noptimization techniques for belief-network inference, such as network-pruning\nand computation-caching.",
    "published": "1997-05-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9705101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "A. Darwiche",
      "G. Provan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9705102v1",
    "title": "Connectionist Theory Refinement: Genetically Searching the Space of\n  Network Topologies",
    "summary": "An algorithm that learns from a set of examples should ideally be able to\nexploit the available resources of (a) abundant computing power and (b)\ndomain-specific knowledge to improve its ability to generalize. Connectionist\ntheory-refinement systems, which use background knowledge to select a neural\nnetwork's topology and initial weights, have proven to be effective at\nexploiting domain-specific knowledge; however, most do not exploit available\ncomputing power. This weakness occurs because they lack the ability to refine\nthe topology of the neural networks they produce, thereby limiting\ngeneralization, especially when given impoverished domain theories. We present\nthe REGENT algorithm which uses (a) domain-specific knowledge to help create an\ninitial population of knowledge-based neural networks and (b) genetic operators\nof crossover and mutation (specifically designed for knowledge-based networks)\nto continually search for better network topologies. Experiments on three\nreal-world domains indicate that our new algorithm is able to significantly\nincrease generalization compared to a standard connectionist theory-refinement\nsystem, as well as our previous algorithm for growing knowledge-based networks.",
    "published": "1997-05-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9705102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "D. W. Opitz",
      "J. W. Shavlik"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9706101v1",
    "title": "Flaw Selection Strategies for Partial-Order Planning",
    "summary": "Several recent studies have compared the relative efficiency of alternative\nflaw selection strategies for partial-order causal link (POCL) planning. We\nreview this literature, and present new experimental results that generalize\nthe earlier work and explain some of the discrepancies in it. In particular, we\ndescribe the Least-Cost Flaw Repair (LCFR) strategy developed and analyzed by\nJoslin and Pollack (1994), and compare it with other strategies, including\nGerevini and Schubert's (1996) ZLIFO strategy. LCFR and ZLIFO make very\ndifferent, and apparently conflicting claims about the most effective way to\nreduce search-space size in POCL planning. We resolve this conflict, arguing\nthat much of the benefit that Gerevini and Schubert ascribe to the LIFO\ncomponent of their ZLIFO strategy is better attributed to other causes. We show\nthat for many problems, a strategy that combines least-cost flaw selection with\nthe delay of separable threats will be effective in reducing search-space size,\nand will do so without excessive computational overhead. Although such a\nstrategy thus provides a good default, we also show that certain domain\ncharacteristics may reduce its effectiveness.",
    "published": "1997-06-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9706101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "M. E. Pollack",
      "D. Joslin",
      "M. Paolucci"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9706102v1",
    "title": "A Complete Classification of Tractability in RCC-5",
    "summary": "We investigate the computational properties of the spatial algebra RCC-5\nwhich is a restricted version of the RCC framework for spatial reasoning. The\nsatisfiability problem for RCC-5 is known to be NP-complete but not much is\nknown about its approximately four billion subclasses. We provide a complete\nclassification of satisfiability for all these subclasses into polynomial and\nNP-complete respectively. In the process, we identify all maximal tractable\nsubalgebras which are four in total.",
    "published": "1997-06-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9706102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "P. Jonsson",
      "T. Drakengren"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9707101v1",
    "title": "A New Look at the Easy-Hard-Easy Pattern of Combinatorial Search\n  Difficulty",
    "summary": "The easy-hard-easy pattern in the difficulty of combinatorial search problems\nas constraints are added has been explained as due to a competition between the\ndecrease in number of solutions and increased pruning. We test the generality\nof this explanation by examining one of its predictions: if the number of\nsolutions is held fixed by the choice of problems, then increased pruning\nshould lead to a monotonic decrease in search cost. Instead, we find the\neasy-hard-easy pattern in median search cost even when the number of solutions\nis held constant, for some search methods. This generalizes previous\nobservations of this pattern and shows that the existing theory does not\nexplain the full range of the peak in search cost. In these cases the pattern\nappears to be due to changes in the size of the minimal unsolvable subproblems,\nrather than changing numbers of solutions.",
    "published": "1997-07-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9707101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "D. L. Mammen",
      "T. Hogg"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9707102v1",
    "title": "Eight Maximal Tractable Subclasses of Allen's Algebra with Metric Time",
    "summary": "This paper combines two important directions of research in temporal\nresoning: that of finding maximal tractable subclasses of Allen's interval\nalgebra, and that of reasoning with metric temporal information. Eight new\nmaximal tractable subclasses of Allen's interval algebra are presented, some of\nthem subsuming previously reported tractable algebras. The algebras allow for\nmetric temporal constraints on interval starting or ending points, using the\nrecent framework of Horn DLRs. Two of the algebras can express the notion of\nsequentiality between intervals, being the first such algebras admitting both\nqualitative and metric time.",
    "published": "1997-07-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9707102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "T. Drakengren",
      "P. Jonsson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9707103v1",
    "title": "Defining Relative Likelihood in Partially-Ordered Preferential\n  Structures",
    "summary": "Starting with a likelihood or preference order on worlds, we extend it to a\nlikelihood ordering on sets of worlds in a natural way, and examine the\nresulting logic. Lewis earlier considered such a notion of relative likelihood\nin the context of studying counterfactuals, but he assumed a total preference\norder on worlds. Complications arise when examining partial orders that are not\npresent for total orders. There are subtleties involving the exact approach to\nlifting the order on worlds to an order on sets of worlds. In addition, the\naxiomatization of the logic of relative likelihood in the case of partial\norders gives insight into the connection between relative likelihood and\ndefault reasoning.",
    "published": "1997-07-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9707103v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "J. Y. Halpern"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9709101v1",
    "title": "Towards Flexible Teamwork",
    "summary": "Many AI researchers are today striving to build agent teams for complex,\ndynamic multi-agent domains, with intended applications in arenas such as\neducation, training, entertainment, information integration, and collective\nrobotics. Unfortunately, uncertainties in these complex, dynamic domains\nobstruct coherent teamwork. In particular, team members often encounter\ndiffering, incomplete, and possibly inconsistent views of their environment.\nFurthermore, team members can unexpectedly fail in fulfilling responsibilities\nor discover unexpected opportunities. Highly flexible coordination and\ncommunication is key in addressing such uncertainties. Simply fitting\nindividual agents with precomputed coordination plans will not do, for their\ninflexibility can cause severe failures in teamwork, and their\ndomain-specificity hinders reusability. Our central hypothesis is that the key\nto such flexibility and reusability is providing agents with general models of\nteamwork. Agents exploit such models to autonomously reason about coordination\nand communication, providing requisite flexibility. Furthermore, the models\nenable reuse across domains, both saving implementation effort and enforcing\nconsistency. This article presents one general, implemented model of teamwork,\ncalled STEAM. The basic building block of teamwork in STEAM is joint intentions\n(Cohen & Levesque, 1991b); teamwork in STEAM is based on agents' building up a\n(partial) hierarchy of joint intentions (this hierarchy is seen to parallel\nGrosz & Kraus's partial SharedPlans, 1996). Furthermore, in STEAM, team members\nmonitor the team's and individual members' performance, reorganizing the team\nas necessary. Finally, decision-theoretic communication selectivity in STEAM\nensures reduction in communication overheads of teamwork, with appropriate\nsensitivity to the environmental conditions. This article describes STEAM's\napplication in three different complex domains, and presents detailed empirical\nresults.",
    "published": "1997-09-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9709101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "M. Tambe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9709102v1",
    "title": "Identifying Hierarchical Structure in Sequences: A linear-time algorithm",
    "summary": "SEQUITUR is an algorithm that infers a hierarchical structure from a sequence\nof discrete symbols by replacing repeated phrases with a grammatical rule that\ngenerates the phrase, and continuing this process recursively. The result is a\nhierarchical representation of the original sequence, which offers insights\ninto its lexical structure. The algorithm is driven by two constraints that\nreduce the size of the grammar, and produce structure as a by-product. SEQUITUR\nbreaks new ground by operating incrementally. Moreover, the method's simple\nstructure permits a proof that it operates in space and time that is linear in\nthe size of the input. Our implementation can process 50,000 symbols per second\nand has been applied to an extensive range of real world sequences.",
    "published": "1997-09-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9709102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "C. G. Nevill-Manning",
      "I. H. Witten"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9710101v1",
    "title": "Analysis of Three-Dimensional Protein Images",
    "summary": "A fundamental goal of research in molecular biology is to understand protein\nstructure. Protein crystallography is currently the most successful method for\ndetermining the three-dimensional (3D) conformation of a protein, yet it\nremains labor intensive and relies on an expert's ability to derive and\nevaluate a protein scene model. In this paper, the problem of protein structure\ndetermination is formulated as an exercise in scene analysis. A computational\nmethodology is presented in which a 3D image of a protein is segmented into a\ngraph of critical points. Bayesian and certainty factor approaches are\ndescribed and used to analyze critical point graphs and identify meaningful\nsubstructures, such as alpha-helices and beta-sheets. Results of applying the\nmethodologies to protein images at low and medium resolution are reported. The\nresearch is related to approaches to representation, segmentation and\nclassification in vision, as well as to top-down approaches to protein\nstructure prediction.",
    "published": "1997-10-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9710101v1.pdf",
    "category": [
      "cs.AI",
      "q-bio"
    ],
    "authors": [
      "L. Leherte",
      "J. Glasgow",
      "K. Baxter",
      "E. Steeg",
      "S. Fortier"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9711102v1",
    "title": "Storing and Indexing Plan Derivations through Explanation-based Analysis\n  of Retrieval Failures",
    "summary": "Case-Based Planning (CBP) provides a way of scaling up domain-independent\nplanning to solve large problems in complex domains. It replaces the detailed\nand lengthy search for a solution with the retrieval and adaptation of previous\nplanning experiences. In general, CBP has been demonstrated to improve\nperformance over generative (from-scratch) planning. However, the performance\nimprovements it provides are dependent on adequate judgements as to problem\nsimilarity. In particular, although CBP may substantially reduce planning\neffort overall, it is subject to a mis-retrieval problem. The success of CBP\ndepends on these retrieval errors being relatively rare. This paper describes\nthe design and implementation of a replay framework for the case-based planner\nDERSNLP+EBL. DERSNLP+EBL extends current CBP methodology by incorporating\nexplanation-based learning techniques that allow it to explain and learn from\nthe retrieval failures it encounters. These techniques are used to refine\njudgements about case similarity in response to feedback when a wrong decision\nhas been made. The same failure analysis is used in building the case library,\nthrough the addition of repairing cases. Large problems are split and stored as\nsingle goal subproblems. Multi-goal problems are stored only when these smaller\ncases fail to be merged into a full solution. An empirical evaluation of this\napproach demonstrates the advantage of learning from experienced retrieval\nfailure.",
    "published": "1997-11-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9711102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "L. H. Ihrig",
      "S. Kambhampati"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9711103v1",
    "title": "A Model Approximation Scheme for Planning in Partially Observable\n  Stochastic Domains",
    "summary": "Partially observable Markov decision processes (POMDPs) are a natural model\nfor planning problems where effects of actions are nondeterministic and the\nstate of the world is not completely observable. It is difficult to solve\nPOMDPs exactly. This paper proposes a new approximation scheme. The basic idea\nis to transform a POMDP into another one where additional information is\nprovided by an oracle. The oracle informs the planning agent that the current\nstate of the world is in a certain region. The transformed POMDP is\nconsequently said to be region observable. It is easier to solve than the\noriginal POMDP. We propose to solve the transformed POMDP and use its optimal\npolicy to construct an approximate policy for the original POMDP. By\ncontrolling the amount of additional information that the oracle provides, it\nis possible to find a proper tradeoff between computational time and\napproximation quality. In terms of algorithmic contributions, we study in\ndetails how to exploit region observability in solving the transformed POMDP.\nTo facilitate the study, we also propose a new exact algorithm for general\nPOMDPs. The algorithm is conceptually simple and yet is significantly more\nefficient than all previous exact algorithms.",
    "published": "1997-11-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9711103v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "N. L. Zhang",
      "W. Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9711104v1",
    "title": "Dynamic Non-Bayesian Decision Making",
    "summary": "The model of a non-Bayesian agent who faces a repeated game with incomplete\ninformation against Nature is an appropriate tool for modeling general\nagent-environment interactions. In such a model the environment state\n(controlled by Nature) may change arbitrarily, and the feedback/reward function\nis initially unknown. The agent is not Bayesian, that is he does not form a\nprior probability neither on the state selection strategy of Nature, nor on his\nreward function. A policy for the agent is a function which assigns an action\nto every history of observations and actions. Two basic feedback structures are\nconsidered. In one of them -- the perfect monitoring case -- the agent is able\nto observe the previous environment state as part of his feedback, while in the\nother -- the imperfect monitoring case -- all that is available to the agent is\nthe reward obtained. Both of these settings refer to partially observable\nprocesses, where the current environment state is unknown. Our main result\nrefers to the competitive ratio criterion in the perfect monitoring case. We\nprove the existence of an efficient stochastic policy that ensures that the\ncompetitive ratio is obtained at almost all stages with an arbitrarily high\nprobability, where efficiency is measured in terms of rate of convergence. It\nis further shown that such an optimal policy does not exist in the imperfect\nmonitoring case. Moreover, it is proved that in the perfect monitoring case\nthere does not exist a deterministic policy that satisfies our long run\noptimality criterion. In addition, we discuss the maxmin criterion and prove\nthat a deterministic efficient optimal strategy does exist in the imperfect\nmonitoring case under this criterion. Finally we show that our approach to\nlong-run optimality can be viewed as qualitative, which distinguishes it from\nprevious work in this area.",
    "published": "1997-11-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9711104v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "D. Monderer",
      "M. Tennenholtz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9712101v1",
    "title": "When Gravity Fails: Local Search Topology",
    "summary": "Local search algorithms for combinatorial search problems frequently\nencounter a sequence of states in which it is impossible to improve the value\nof the objective function; moves through these regions, called plateau moves,\ndominate the time spent in local search. We analyze and characterize plateaus\nfor three different classes of randomly generated Boolean Satisfiability\nproblems. We identify several interesting features of plateaus that impact the\nperformance of local search algorithms. We show that local minima tend to be\nsmall but occasionally may be very large. We also show that local minima can be\nescaped without unsatisfying a large number of clauses, but that systematically\nsearching for an escape route may be computationally expensive if the local\nminimum is large. We show that plateaus with exits, called benches, tend to be\nmuch larger than minima, and that some benches have very few exit states which\nlocal search can use to escape. We show that the solutions (i.e., global\nminima) of randomly generated problem instances form clusters, which behave\nsimilarly to local minima. We revisit several enhancements of local search\nalgorithms and explain their performance in light of our results. Finally we\ndiscuss strategies for creating the next generation of local search algorithms.",
    "published": "1997-12-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9712101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "J. Frank",
      "P. Cheeseman",
      "J. Stutz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9712102v1",
    "title": "Bidirectional Heuristic Search Reconsidered",
    "summary": "The assessment of bidirectional heuristic search has been incorrect since it\nwas first published more than a quarter of a century ago. For quite a long\ntime, this search strategy did not achieve the expected results, and there was\na major misunderstanding about the reasons behind it. Although there is still\nwide-spread belief that bidirectional heuristic search is afflicted by the\nproblem of search frontiers passing each other, we demonstrate that this\nconjecture is wrong. Based on this finding, we present both a new generic\napproach to bidirectional heuristic search and a new approach to dynamically\nimproving heuristic values that is feasible in bidirectional search only. These\napproaches are put into perspective with both the traditional and more recently\nproposed approaches in order to facilitate a better overall understanding.\nEmpirical results of experiments with our new approaches show that\nbidirectional heuristic search can be performed very efficiently and also with\nlimited memory. These results suggest that bidirectional heuristic search\nappears to be better for solving certain difficult problems than corresponding\nunidirectional search. This provides some evidence for the usefulness of a\nsearch strategy that was long neglected. In summary, we show that bidirectional\nheuristic search is viable and consequently propose that it be reconsidered.",
    "published": "1997-12-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9712102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "H. Kaindl",
      "G. Kainz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9801101v1",
    "title": "Incremental Recompilation of Knowledge",
    "summary": "Approximating a general formula from above and below by Horn formulas (its\nHorn envelope and Horn core, respectively) was proposed by Selman and Kautz\n(1991, 1996) as a form of ``knowledge compilation,'' supporting rapid\napproximate reasoning; on the negative side, this scheme is static in that it\nsupports no updates, and has certain complexity drawbacks pointed out by\nKavvadias, Papadimitriou and Sideri (1993). On the other hand, the many\nframeworks and schemes proposed in the literature for theory update and\nrevision are plagued by serious complexity-theoretic impediments, even in the\nHorn case, as was pointed out by Eiter and Gottlob (1992), and is further\ndemonstrated in the present paper. More fundamentally, these schemes are not\ninductive, in that they may lose in a single update any positive properties of\nthe represented sets of formulas (small size, Horn structure, etc.). In this\npaper we propose a new scheme, incremental recompilation, which combines Horn\napproximation and model-based updates; this scheme is inductive and very\nefficient, free of the problems facing its constituents. A set of formulas is\nrepresented by an upper and lower Horn approximation. To update, we replace the\nupper Horn formula by the Horn envelope of its minimum-change update, and\nsimilarly the lower one by the Horn core of its update; the key fact which\nenables this scheme is that Horn envelopes and cores are easy to compute when\nthe underlying formula is the result of a minimum-change update of a Horn\nformula by a clause. We conjecture that efficient algorithms are possible for\nmore complex updates.",
    "published": "1998-01-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9801101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "G. Gogic",
      "C. H. Papadimitriou",
      "M. Sideri"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9801102v1",
    "title": "Monotonicity and Persistence in Preferential Logics",
    "summary": "An important characteristic of many logics for Artificial Intelligence is\ntheir nonmonotonicity. This means that adding a formula to the premises can\ninvalidate some of the consequences. There may, however, exist formulae that\ncan always be safely added to the premises without destroying any of the\nconsequences: we say they respect monotonicity. Also, there may be formulae\nthat, when they are a consequence, can not be invalidated when adding any\nformula to the premises: we call them conservative. We study these two classes\nof formulae for preferential logics, and show that they are closely linked to\nthe formulae whose truth-value is preserved along the (preferential) ordering.\nWe will consider some preferential logics for illustration, and prove syntactic\ncharacterization results for them. The results in this paper may improve the\nefficiency of theorem provers for preferential logics.",
    "published": "1998-01-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9801102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "J. Engelfriet"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9803101v1",
    "title": "Synthesizing Customized Planners from Specifications",
    "summary": "Existing plan synthesis approaches in artificial intelligence fall into two\ncategories -- domain independent and domain dependent. The domain independent\napproaches are applicable across a variety of domains, but may not be very\nefficient in any one given domain. The domain dependent approaches need to be\n(re)designed for each domain separately, but can be very efficient in the\ndomain for which they are designed. One enticing alternative to these\napproaches is to automatically synthesize domain independent planners given the\nknowledge about the domain and the theory of planning. In this paper, we\ninvestigate the feasibility of using existing automated software synthesis\ntools to support such synthesis. Specifically, we describe an architecture\ncalled CLAY in which the Kestrel Interactive Development System (KIDS) is used\nto derive a domain-customized planner through a semi-automatic combination of a\ndeclarative theory of planning, and the declarative control knowledge specific\nto a given domain, to semi-automatically combine them to derive\ndomain-customized planners. We discuss what it means to write a declarative\ntheory of planning and control knowledge for KIDS, and illustrate our approach\nby generating a class of domain-specific planners using state space\nrefinements. Our experiments show that the synthesized planners can outperform\nclassical refinement planners (implemented as instantiations of UCP,\nKambhampati & Srivastava, 1995), using the same control knowledge. We will\ncontrast the costs and benefits of the synthesis approach with conventional\nmethods for customizing domain independent planners.",
    "published": "1998-03-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9803101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "B. Srivastava",
      "S. Kambhampati"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9803102v1",
    "title": "Cached Sufficient Statistics for Efficient Machine Learning with Large\n  Datasets",
    "summary": "This paper introduces new algorithms and data structures for quick counting\nfor machine learning datasets. We focus on the counting task of constructing\ncontingency tables, but our approach is also applicable to counting the number\nof records in a dataset that match conjunctive queries. Subject to certain\nassumptions, the costs of these operations can be shown to be independent of\nthe number of records in the dataset and loglinear in the number of non-zero\nentries in the contingency table. We provide a very sparse data structure, the\nADtree, to minimize memory use. We provide analytical worst-case bounds for\nthis structure for several models of data distribution. We empirically\ndemonstrate that tractably-sized data structures can be produced for large\nreal-world datasets by (a) using a sparse tree structure that never allocates\nmemory for counts of zero, (b) never allocating memory for counts that can be\ndeduced from other counts, and (c) not bothering to expand the tree fully near\nits leaves. We show how the ADtree can be used to accelerate Bayes net\nstructure finding algorithms, rule learning algorithms, and feature selection\nalgorithms, and we provide a number of empirical results comparing ADtree\nmethods against traditional direct counting approaches. We also discuss the\npossible uses of ADtrees in other machine learning methods, and discuss the\nmerits of ADtrees in comparison with alternative representations such as\nkd-trees, R-trees and Frequent Sets.",
    "published": "1998-03-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9803102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "A. Moore",
      "M. S. Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9803103v1",
    "title": "Tractability of Theory Patching",
    "summary": "In this paper we consider the problem of `theory patching', in which we are\ngiven a domain theory, some of whose components are indicated to be possibly\nflawed, and a set of labeled training examples for the domain concept. The\ntheory patching problem is to revise only the indicated components of the\ntheory, such that the resulting theory correctly classifies all the training\nexamples. Theory patching is thus a type of theory revision in which revisions\nare made to individual components of the theory. Our concern in this paper is\nto determine for which classes of logical domain theories the theory patching\nproblem is tractable. We consider both propositional and first-order domain\ntheories, and show that the theory patching problem is equivalent to that of\ndetermining what information contained in a theory is `stable' regardless of\nwhat revisions might be performed to the theory. We show that determining\nstability is tractable if the input theory satisfies two conditions: that\nrevisions to each theory component have monotonic effects on the classification\nof examples, and that theory components act independently in the classification\nof examples in the theory. We also show how the concepts introduced can be used\nto determine the soundness and completeness of particular theory patching\nalgorithms.",
    "published": "1998-03-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9803103v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "S. Argamon-Engelson",
      "M. Koppel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9805101v1",
    "title": "Integrative Windowing",
    "summary": "In this paper we re-investigate windowing for rule learning algorithms. We\nshow that, contrary to previous results for decision tree learning, windowing\ncan in fact achieve significant run-time gains in noise-free domains and\nexplain the different behavior of rule learning algorithms by the fact that\nthey learn each rule independently. The main contribution of this paper is\nintegrative windowing, a new type of algorithm that further exploits this\nproperty by integrating good rules into the final theory right after they have\nbeen discovered. Thus it avoids re-learning these rules in subsequent\niterations of the windowing process. Experimental evidence in a variety of\nnoise-free domains shows that integrative windowing can in fact achieve\nsubstantial run-time gains. Furthermore, we discuss the problem of noise in\nwindowing and present an algorithm that is able to achieve run-time gains in a\nset of experiments in a simple domain with artificial noise.",
    "published": "1998-05-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9805101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "J. Frnkranz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9806101v1",
    "title": "Model-Based Diagnosis using Structured System Descriptions",
    "summary": "This paper presents a comprehensive approach for model-based diagnosis which\nincludes proposals for characterizing and computing preferred diagnoses,\nassuming that the system description is augmented with a system structure (a\ndirected graph explicating the interconnections between system components).\nSpecifically, we first introduce the notion of a consequence, which is a\nsyntactically unconstrained propositional sentence that characterizes all\nconsistency-based diagnoses and show that standard characterizations of\ndiagnoses, such as minimal conflicts, correspond to syntactic variations on a\nconsequence. Second, we propose a new syntactic variation on the consequence\nknown as negation normal form (NNF) and discuss its merits compared to standard\nvariations. Third, we introduce a basic algorithm for computing consequences in\nNNF given a structured system description. We show that if the system structure\ndoes not contain cycles, then there is always a linear-size consequence in NNF\nwhich can be computed in linear time. For arbitrary system structures, we show\na precise connection between the complexity of computing consequences and the\ntopology of the underlying system structure. Finally, we present an algorithm\nthat enumerates the preferred diagnoses characterized by a consequence. The\nalgorithm is shown to take linear time in the size of the consequence if the\npreference criterion satisfies some general conditions.",
    "published": "1998-06-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9806101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "A. Darwiche"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9806102v1",
    "title": "A Selective Macro-learning Algorithm and its Application to the NxN\n  Sliding-Tile Puzzle",
    "summary": "One of the most common mechanisms used for speeding up problem solvers is\nmacro-learning. Macros are sequences of basic operators acquired during problem\nsolving. Macros are used by the problem solver as if they were basic operators.\nThe major problem that macro-learning presents is the vast number of macros\nthat are available for acquisition. Macros increase the branching factor of the\nsearch space and can severely degrade problem-solving efficiency. To make macro\nlearning useful, a program must be selective in acquiring and utilizing macros.\nThis paper describes a general method for selective acquisition of macros.\nSolvable training problems are generated in increasing order of difficulty. The\nonly macros acquired are those that take the problem solver out of a local\nminimum to a better state. The utility of the method is demonstrated in several\ndomains, including the domain of NxN sliding-tile puzzles. After learning on\nsmall puzzles, the system is able to efficiently solve puzzles of any size.",
    "published": "1998-06-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9806102v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "L. Finkelstein",
      "S. Markovitch"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9808101v1",
    "title": "The Computational Complexity of Probabilistic Planning",
    "summary": "We examine the computational complexity of testing and finding small plans in\nprobabilistic planning domains with both flat and propositional\nrepresentations. The complexity of plan evaluation and existence varies with\nthe plan type sought; we examine totally ordered plans, acyclic plans, and\nlooping plans, and partially ordered plans under three natural definitions of\nplan value. We show that problems of interest are complete for a variety of\ncomplexity classes: PL, P, NP, co-NP, PP, NP^PP, co-NP^PP, and PSPACE. In the\nprocess of proving that certain planning problems are complete for NP^PP, we\nintroduce a new basic NP^PP-complete problem, E-MAJSAT, which generalizes the\nstandard Boolean satisfiability problem to computations involving probabilistic\nquantities; our results suggest that the development of good heuristics for\nE-MAJSAT could be important for the creation of efficient algorithms for a wide\nvariety of problems.",
    "published": "1998-08-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9808101v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "M. L. Littman",
      "J. Goldsmith",
      "M. Mundhenk"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9808001v1",
    "title": "Chess Pure Strategies are Probably Chaotic",
    "summary": "It is odd that chess grandmasters often disagree in their analysis of\npositions, sometimes even of simple ones, and that a grandmaster can hold his\nown against an powerful analytic machine such as Deep Blue. The fact that there\nmust exist pure winning strategies for chess is used to construct a control\nstrategy function. It is then shown that chess strategy is equivalent to an\nautonomous system of differential equations, and conjectured that the system is\nchaotic. If true the conjecture would explain the forenamed peculiarities and\nwould also imply that there cannot exist a static evaluator for chess.",
    "published": "1998-08-21T19:13:51Z",
    "link": "http://arxiv.org/pdf/cs/9808001v1.pdf",
    "category": [
      "cs.CC",
      "cs.AI",
      "F.2.0; I.2.0"
    ],
    "authors": [
      "M. Chaves"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9808005v1",
    "title": "First-Order Conditional Logic Revisited",
    "summary": "Conditional logics play an important role in recent attempts to formulate\ntheories of default reasoning. This paper investigates first-order conditional\nlogic. We show that, as for first-order probabilistic logic, it is important\nnot to confound statistical conditionals over the domain (such as ``most birds\nfly''), and subjective conditionals over possible worlds (such as ``I believe\nthat Tweety is unlikely to fly''). We then address the issue of ascribing\nsemantics to first-order conditional logic. As in the propositional case, there\nare many possible semantics. To study the problem in a coherent way, we use\nplausibility structures. These provide us with a general framework in which\nmany of the standard approaches can be embedded. We show that while these\nstandard approaches are all the same at the propositional level, they are\nsignificantly different in the context of a first-order language. Furthermore,\nwe show that plausibilities provide the most natural extension of conditional\nlogic to the first-order case: We provide a sound and complete axiomatization\nthat contains only the KLM properties and standard axioms of first-order modal\nlogic. We show that most of the other approaches have additional properties,\nwhich result in an inappropriate treatment of an infinitary version of the\nlottery paradox.",
    "published": "1998-08-28T00:16:49Z",
    "link": "http://arxiv.org/pdf/cs/9808005v1.pdf",
    "category": [
      "cs.AI",
      "cs.LO",
      "I.2.4; F.4.1"
    ],
    "authors": [
      "Nir Friedman",
      "Joseph Y. Halpern",
      "Daphne Koller"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9808006v2",
    "title": "Set-Theoretic Completeness for Epistemic and Conditional Logic",
    "summary": "The standard approach to logic in the literature in philosophy and\nmathematics, which has also been adopted in computer science, is to define a\nlanguage (the syntax), an appropriate class of models together with an\ninterpretation of formulas in the language (the semantics), a collection of\naxioms and rules of inference characterizing reasoning (the proof theory), and\nthen relate the proof theory to the semantics via soundness and completeness\nresults. Here we consider an approach that is more common in the economics\nliterature, which works purely at the semantic, set-theoretic level. We provide\nset-theoretic completeness results for a number of epistemic and conditional\nlogics, and contrast the expressive power of the syntactic and set-theoretic\napproaches",
    "published": "1998-08-28T00:39:47Z",
    "link": "http://arxiv.org/pdf/cs/9808006v2.pdf",
    "category": [
      "cs.AI",
      "cs.LO",
      "I.2.4; F.4.1"
    ],
    "authors": [
      "Joseph Y. Halpern"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9808007v1",
    "title": "Plausibility Measures and Default Reasoning",
    "summary": "We introduce a new approach to modeling uncertainty based on plausibility\nmeasures. This approach is easily seen to generalize other approaches to\nmodeling uncertainty, such as probability measures, belief functions, and\npossibility measures. We focus on one application of plausibility measures in\nthis paper: default reasoning. In recent years, a number of different semantics\nfor defaults have been proposed, such as preferential structures,\n$\\epsilon$-semantics, possibilistic structures, and $\\kappa$-rankings, that\nhave been shown to be characterized by the same set of axioms, known as the KLM\nproperties. While this was viewed as a surprise, we show here that it is almost\ninevitable. In the framework of plausibility measures, we can give a necessary\ncondition for the KLM axioms to be sound, and an additional condition necessary\nand sufficient to ensure that the KLM axioms are complete. This additional\ncondition is so weak that it is almost always met whenever the axioms are\nsound. In particular, it is easily seen to hold for all the proposals made in\nthe literature.",
    "published": "1998-08-29T00:12:30Z",
    "link": "http://arxiv.org/pdf/cs/9808007v1.pdf",
    "category": [
      "cs.AI",
      "cs.LO",
      "I.2.4; F.4.1"
    ],
    "authors": [
      "Nir Friedman",
      "Joseph Y. Halpern"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9809013v1",
    "title": "Reasoning about Noisy Sensors and Effectors in the Situation Calculus",
    "summary": "Agents interacting with an incompletely known world need to be able to reason\nabout the effects of their actions, and to gain further information about that\nworld they need to use sensors of some sort. Unfortunately, both the effects of\nactions and the information returned from sensors are subject to error. To cope\nwith such uncertainties, the agent can maintain probabilistic beliefs about the\nstate of the world. With probabilistic beliefs the agent will be able to\nquantify the likelihood of the various outcomes of its actions and is better\nable to utilize the information gathered from its error-prone actions and\nsensors. In this paper, we present a model in which we can reason about an\nagent's probabilistic degrees of belief and the manner in which these beliefs\nchange as various actions are executed. We build on a general logical theory of\naction developed by Reiter and others, formalized in the situation calculus. We\npropose a simple axiomatization that captures an agent's state of belief and\nthe manner in which these beliefs change when actions are executed. Our model\ndisplays a number of intuitively reasonable properties.",
    "published": "1998-09-09T22:28:32Z",
    "link": "http://arxiv.org/pdf/cs/9809013v1.pdf",
    "category": [
      "cs.AI",
      "cs.LO",
      "I.2.4, F.4.1"
    ],
    "authors": [
      "Fahiem Bacchus",
      "Joseph Y. Halpern",
      "Hector J. Levesque"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9809032v1",
    "title": "Stable models and an alternative logic programming paradigm",
    "summary": "In this paper we reexamine the place and role of stable model semantics in\nlogic programming and contrast it with a least Herbrand model approach to Horn\nprograms. We demonstrate that inherent features of stable model semantics\nnaturally lead to a logic programming system that offers an interesting\nalternative to more traditional logic programming styles of Horn logic\nprogramming, stratified logic programming and logic programming with\nwell-founded semantics. The proposed approach is based on the interpretation of\nprogram clauses as constraints. In this setting programs do not describe a\nsingle intended model, but a family of stable models. These stable models\nencode solutions to the constraint satisfaction problem described by the\nprogram. Our approach imposes restrictions on the syntax of logic programs. In\nparticular, function symbols are eliminated from the language. We argue that\nthe resulting logic programming system is well-attuned to problems in the class\nNP, has a well-defined domain of applications, and an emerging methodology of\nprogramming. We point out that what makes the whole approach viable is recent\nprogress in implementations of algorithms to compute stable models of\npropositional logic programs.",
    "published": "1998-09-18T20:34:59Z",
    "link": "http://arxiv.org/pdf/cs/9809032v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "I.2.3, I.2.4"
    ],
    "authors": [
      "Victor W. Marek",
      "Miroslaw Truszczynski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9809034v1",
    "title": "Semantics and Conversations for an Agent Communication Language",
    "summary": "We address the issues of semantics and conversations for agent communication\nlanguages and the Knowledge Query Manipulation Language (KQML) in particular.\nBased on ideas from speech act theory, we present a semantic description for\nKQML that associates ``cognitive'' states of the agent with the use of the\nlanguage's primitives (performatives). We have used this approach to describe\nthe semantics for the whole set of reserved KQML performatives. Building on the\nsemantics, we devise the conversation policies, i.e., a formal description of\nhow KQML performatives may be combined into KQML exchanges (conversations),\nusing a Definite Clause Grammar. Our research offers methods for a speech act\ntheory-based semantic description of a language of communication acts and for\nthe specification of the protocols associated with these acts. Languages of\ncommunication acts address the issue of communication among software\napplications at a level of abstraction that is useful to the emerging software\nagents paradigm.",
    "published": "1998-09-18T21:41:18Z",
    "link": "http://arxiv.org/pdf/cs/9809034v1.pdf",
    "category": [
      "cs.MA",
      "cs.AI",
      "I.2.11"
    ],
    "authors": [
      "Yannis Labrou",
      "Tim Finin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9809108v1",
    "title": "Learning Nested Agent Models in an Information Economy",
    "summary": "We present our approach to the problem of how an agent, within an economic\nMulti-Agent System, can determine when it should behave strategically (i.e.\nlearn and use models of other agents), and when it should act as a simple\nprice-taker. We provide a framework for the incremental implementation of\nmodeling capabilities in agents, and a description of the forms of knowledge\nrequired. The agents were implemented and different populations simulated in\norder to learn more about their behavior and the merits of using and learning\nagent models. Our results show, among other lessons, how savvy buyers can avoid\nbeing ``cheated'' by sellers, how price volatility can be used to\nquantitatively predict the benefits of deeper models, and how specific types of\nagent populations influence system behavior.",
    "published": "1998-09-26T17:43:36Z",
    "link": "http://arxiv.org/pdf/cs/9809108v1.pdf",
    "category": [
      "cs.MA",
      "cs.AI",
      "I 2.11"
    ],
    "authors": [
      "Jose M. Vidal",
      "Edmund H. Durfee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9809110v1",
    "title": "Similarity-Based Models of Word Cooccurrence Probabilities",
    "summary": "In many applications of natural language processing (NLP) it is necessary to\ndetermine the likelihood of a given word combination. For example, a speech\nrecognizer may need to determine which of the two word combinations ``eat a\npeach'' and ``eat a beach'' is more likely. Statistical NLP methods determine\nthe likelihood of a word combination from its frequency in a training corpus.\nHowever, the nature of language is such that many word combinations are\ninfrequent and do not occur in any given corpus. In this work we propose a\nmethod for estimating the probability of such previously unseen word\ncombinations using available information on ``most similar'' words.\n  We describe probabilistic word association models based on distributional\nword similarity, and apply them to two tasks, language modeling and pseudo-word\ndisambiguation. In the language modeling task, a similarity-based model is used\nto improve probability estimates for unseen bigrams in a back-off language\nmodel. The similarity-based method yields a 20% perplexity improvement in the\nprediction of unseen bigrams and statistically significant reductions in\nspeech-recognition error.\n  We also compare four similarity-based estimation methods against back-off and\nmaximum-likelihood estimation methods on a pseudo-word sense disambiguation\ntask in which we controlled for both unigram and bigram frequency to avoid\ngiving too much weight to easy-to-disambiguate high-frequency configurations.\nThe similarity-based methods perform up to 40% better on this particular task.",
    "published": "1998-09-27T18:42:51Z",
    "link": "http://arxiv.org/pdf/cs/9809110v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7;I.2.6"
    ],
    "authors": [
      "Ido Dagan",
      "Lillian Lee",
      "Fernando C. N. Pereira"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9809121v1",
    "title": "Using Local Optimality Criteria for Efficient Information Retrieval with\n  Redundant Information Filters",
    "summary": "We consider information retrieval when the data, for instance multimedia, is\ncoputationally expensive to fetch. Our approach uses \"information filters\" to\nconsiderably narrow the universe of possiblities before retrieval. We are\nespecially interested in redundant information filters that save time over more\ngeneral but more costly filters. Efficient retrieval requires that decision\nmust be made about the necessity, order, and concurrent processing of proposed\nfilters (an \"execution plan\"). We develop simple polynomial-time local criteria\nfor optimal execution plans, and show that most forms of concurrency are\nsuboptimal with information filters. Although the general problem of finding an\noptimal execution plan is likely exponential in the number of filters, we show\nexperimentally that our local optimality criteria, used in a polynomial-time\nalgorithm, nearly always find the global optimum with 15 filters or less, a\nsufficient number of filters for most applications. Our methods do not require\nspecial hardware and avoid the high processor idleness that is characteristic\nof massive parallelism solutions to this problem. We apply our ideas to an\nimportant application, information retrieval of cpationed data using\nnatural-language understanding, a problem for which the natural-language\nprocessing can be the bottleneck if not implemented well.",
    "published": "1998-09-29T21:55:20Z",
    "link": "http://arxiv.org/pdf/cs/9809121v1.pdf",
    "category": [
      "cs.IR",
      "cs.AI",
      "H.3.3"
    ],
    "authors": [
      "Neil C. Rowe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9810005v1",
    "title": "Anytime Coalition Structure Generation with Worst Case Guarantees",
    "summary": "Coalition formation is a key topic in multiagent systems. One would prefer a\ncoalition structure that maximizes the sum of the values of the coalitions, but\noften the number of coalition structures is too large to allow exhaustive\nsearch for the optimal one. But then, can the coalition structure found via a\npartial search be guaranteed to be within a bound from optimum? We show that\nnone of the previous coalition structure generation algorithms can establish\nany bound because they search fewer nodes than a threshold that we show\nnecessary for establishing a bound. We present an algorithm that establishes a\ntight bound within this minimal amount of search, and show that any other\nalgorithm would have to search strictly more. The fraction of nodes needed to\nbe searched approaches zero as the number of agents grows. If additional time\nremains, our anytime algorithm searches further, and establishes a\nprogressively lower tight bound. Surprisingly, just searching one more node\ndrops the bound in half. As desired, our algorithm lowers the bound rapidly\nearly on, and exhibits diminishing returns to computation. It also drastically\noutperforms its obvious contenders. Finally, we show how to distribute the\ndesired search across self-interested manipulative agents.",
    "published": "1998-10-05T16:08:41Z",
    "link": "http://arxiv.org/pdf/cs/9810005v1.pdf",
    "category": [
      "cs.MA",
      "cs.AI",
      "I.2.11"
    ],
    "authors": [
      "Tuomas Sandholm",
      "Kate Larson",
      "Martin Andersson",
      "Onn Shehory",
      "Fernando Tohme"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cond-mat/9810144v2",
    "title": "Relaxation in graph coloring and satisfiability problems",
    "summary": "Using T=0 Monte Carlo simulation, we study the relaxation of graph coloring\n(K-COL) and satisfiability (K-SAT), two hard problems that have recently been\nshown to possess a phase transition in solvability as a parameter is varied. A\nchange from exponentially fast to power law relaxation, and a transition to\nfreezing behavior are found. These changes take place for smaller values of the\nparameter than the solvability transition. Results for the coloring problem for\ncolorable and clustered graphs and for the fraction of persistent spins for\nsatisfiability are also presented.",
    "published": "1998-10-13T11:27:32Z",
    "link": "http://arxiv.org/pdf/cond-mat/9810144v2.pdf",
    "category": [
      "cond-mat.dis-nn",
      "cs.AI"
    ],
    "authors": [
      "Pontus Svenson",
      "Mats G. Nordahl"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9810016v1",
    "title": "SYNERGY: A Linear Planner Based on Genetic Programming",
    "summary": "In this paper we describe SYNERGY, which is a highly parallelizable, linear\nplanning system that is based on the genetic programming paradigm. Rather than\nreasoning about the world it is planning for, SYNERGY uses artificial\nselection, recombination and fitness measure to generate linear plans that\nsolve conjunctive goals. We ran SYNERGY on several domains (e.g., the briefcase\nproblem and a few variants of the robot navigation problem), and the\nexperimental results show that our planner is capable of handling problem\ninstances that are one to two orders of magnitude larger than the ones solved\nby UCPOP. In order to facilitate the search reduction and to enhance the\nexpressive power of SYNERGY, we also propose two major extensions to our\nplanning system: a formalism for using hierarchical planning operators, and a\nframework for planning in dynamic environments.",
    "published": "1998-10-16T22:11:35Z",
    "link": "http://arxiv.org/pdf/cs/9810016v1.pdf",
    "category": [
      "cs.AI",
      "I.2.8"
    ],
    "authors": [
      "Ion Muslea"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9810018v1",
    "title": "A Proof Theoretic View of Constraint Programming",
    "summary": "We provide here a proof theoretic account of constraint programming that\nattempts to capture the essential ingredients of this programming style. We\nexemplify it by presenting proof rules for linear constraints over interval\ndomains, and illustrate their use by analyzing the constraint propagation\nprocess for the {\\tt SEND + MORE = MONEY} puzzle. We also show how this\napproach allows one to build new constraint solvers.",
    "published": "1998-10-20T11:23:05Z",
    "link": "http://arxiv.org/pdf/cs/9810018v1.pdf",
    "category": [
      "cs.AI",
      "cs.PL",
      "F.4.1;I.2.3;D.1.0"
    ],
    "authors": [
      "Krzysztof R. Apt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9810020v1",
    "title": "Computational Geometry Column 33",
    "summary": "Several recent SIGGRAPH papers on surface simplification are described.",
    "published": "1998-10-22T20:44:35Z",
    "link": "http://arxiv.org/pdf/cs/9810020v1.pdf",
    "category": [
      "cs.CG",
      "cs.AI",
      "cs.GR",
      "F.2.2;I.3"
    ],
    "authors": [
      "Joseph O'Rourke"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9811024v1",
    "title": "The Essence of Constraint Propagation",
    "summary": "We show that several constraint propagation algorithms (also called (local)\nconsistency, consistency enforcing, Waltz, filtering or narrowing algorithms)\nare instances of algorithms that deal with chaotic iteration. To this end we\npropose a simple abstract framework that allows us to classify and compare\nthese algorithms and to establish in a uniform way their basic properties.",
    "published": "1998-11-13T13:04:02Z",
    "link": "http://arxiv.org/pdf/cs/9811024v1.pdf",
    "category": [
      "cs.AI",
      "I.1.2; I.2.2"
    ],
    "authors": [
      "Krzysztof R. Apt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9811029v1",
    "title": "A Human - machine interface for teleoperation of arm manipulators in a\n  complex environment",
    "summary": "This paper discusses the feasibility of using configuration space (C-space)\nas a means of visualization and control in operator-guided real-time motion of\na robot arm manipulator. The motivation is to improve performance of the human\noperator in tasks involving the manipulator motion in an environment with\nobstacles. Unlike some other motion planning tasks, operators are known to make\nexpensive mistakes in such tasks, even in a simpler two-dimensional case. They\nhave difficulty learning better procedures and their performance improves very\nlittle with practice. Using an example of a two-dimensional arm manipulator, we\nshow that translating the problem into C-space improves the operator\nperformance rather remarkably, on the order of magnitude compared to the usual\nwork space control. An interface that makes the transfer possible is described,\nand an example of its use in a virtual environment is shown.",
    "published": "1998-11-20T21:06:07Z",
    "link": "http://arxiv.org/pdf/cs/9811029v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "I.2.9"
    ],
    "authors": [
      "I. Ivanisevic",
      "V. Lumelsky"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9812004v1",
    "title": "Name Strategy: Its Existence and Implications",
    "summary": "It is argued that colour name strategy, object name strategy, and chunking\nstrategy in memory are all aspects of the same general phenomena, called\nstereotyping. It is pointed out that the Berlin-Kay universal partial ordering\nof colours and the frequency of traffic accidents classified by colour are\nsurprisingly similar. Some consequences of the existence of a name strategy for\nthe philosophy of language and mathematics are discussed. It is argued that\nreal valued quantities occur {\\it ab initio}. The implication of real valued\ntruth quantities is that the {\\bf Continuum Hypothesis} of pure mathematics is\nside-stepped. The existence of name strategy shows that thought/sememes and\ntalk/phonemes can be separate, and this vindicates the assumption of thought\noccurring before talk used in psycholinguistic speech production models.",
    "published": "1998-12-04T12:28:19Z",
    "link": "http://arxiv.org/pdf/cs/9812004v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "math.HO",
      "I.2.6;J.4;I.2.7"
    ],
    "authors": [
      "Mark D. Roberts"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9812010v1",
    "title": "Towards a computational theory of human daydreaming",
    "summary": "This paper examines the phenomenon of daydreaming: spontaneously recalling or\nimagining personal or vicarious experiences in the past or future. The\nfollowing important roles of daydreaming in human cognition are postulated:\nplan preparation and rehearsal, learning from failures and successes, support\nfor processes of creativity, emotion regulation, and motivation.\n  A computational theory of daydreaming and its implementation as the program\nDAYDREAMER are presented. DAYDREAMER consists of 1) a scenario generator based\non relaxed planning, 2) a dynamic episodic memory of experiences used by the\nscenario generator, 3) a collection of personal goals and control goals which\nguide the scenario generator, 4) an emotion component in which daydreams\ninitiate, and are initiated by, emotional states arising from goal outcomes,\nand 5) domain knowledge of interpersonal relations and common everyday\noccurrences.\n  The role of emotions and control goals in daydreaming is discussed. Four\ncontrol goals commonly used in guiding daydreaming are presented:\nrationalization, failure/success reversal, revenge, and preparation. The role\nof episodic memory in daydreaming is considered, including how daydreamed\ninformation is incorporated into memory and later used. An initial version of\nDAYDREAMER which produces several daydreams (in English) is currently running.",
    "published": "1998-12-10T16:29:07Z",
    "link": "http://arxiv.org/pdf/cs/9812010v1.pdf",
    "category": [
      "cs.AI",
      "I.2.0"
    ],
    "authors": [
      "Erik T. Mueller",
      "Michael G. Dyer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9812017v1",
    "title": "A reusable iterative optimization software library to solve\n  combinatorial problems with approximate reasoning",
    "summary": "Real world combinatorial optimization problems such as scheduling are\ntypically too complex to solve with exact methods. Additionally, the problems\noften have to observe vaguely specified constraints of different importance,\nthe available data may be uncertain, and compromises between antagonistic\ncriteria may be necessary. We present a combination of approximate reasoning\nbased constraints and iterative optimization based heuristics that help to\nmodel and solve such problems in a framework of C++ software libraries called\nStarFLIP++. While initially developed to schedule continuous caster units in\nsteel plants, we present in this paper results from reusing the library\ncomponents in a shift scheduling system for the workforce of an industrial\nproduction plant.",
    "published": "1998-12-15T21:45:15Z",
    "link": "http://arxiv.org/pdf/cs/9812017v1.pdf",
    "category": [
      "cs.AI",
      "I.2.8; I.2.1; J.6; I.2.4; F.2.2"
    ],
    "authors": [
      "Andreas Raggl",
      "Wolfgang Slany"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9812022v1",
    "title": "Hypertree Decompositions and Tractable Queries",
    "summary": "Several important decision problems on conjunctive queries (CQs) are\nNP-complete in general but become tractable, and actually highly\nparallelizable, if restricted to acyclic or nearly acyclic queries. Examples\nare the evaluation of Boolean CQs and query containment. These problems were\nshown tractable for conjunctive queries of bounded treewidth and of bounded\ndegree of cyclicity. The so far most general concept of nearly acyclic queries\nwas the notion of queries of bounded query-width introduced by Chekuri and\nRajaraman (1997). While CQs of bounded query width are tractable, it remained\nunclear whether such queries are efficiently recognizable. Chekuri and\nRajaraman stated as an open problem whether for each constant k it can be\ndetermined in polynomial time if a query has query width less than or equal to\nk. We give a negative answer by proving this problem NP-complete (specifically,\nfor k=4). In order to circumvent this difficulty, we introduce the new concept\nof hypertree decomposition of a query and the corresponding notion of hypertree\nwidth. We prove: (a) for each k, the class of queries with query width bounded\nby k is properly contained in the class of queries whose hypertree width is\nbounded by k; (b) unlike query width, constant hypertree-width is efficiently\nrecognizable; (c) Boolean queries of constant hypertree width can be\nefficiently evaluated.",
    "published": "1998-12-28T12:30:50Z",
    "link": "http://arxiv.org/pdf/cs/9812022v1.pdf",
    "category": [
      "cs.DB",
      "cs.AI",
      "F.2.2; H.2.4; I.2.8; G.2.2"
    ],
    "authors": [
      "G. Gottlob",
      "N. Leone",
      "F. Scarcello"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9901001v1",
    "title": "TDLeaf(lambda): Combining Temporal Difference Learning with Game-Tree\n  Search",
    "summary": "In this paper we present TDLeaf(lambda), a variation on the TD(lambda)\nalgorithm that enables it to be used in conjunction with minimax search. We\npresent some experiments in both chess and backgammon which demonstrate its\nutility and provide comparisons with TD(lambda) and another less radical\nvariant, TD-directed(lambda). In particular, our chess program, ``KnightCap,''\nused TDLeaf(lambda) to learn its evaluation function while playing on the Free\nInternet Chess Server (FICS, fics.onenet.net). It improved from a 1650 rating\nto a 2100 rating in just 308 games. We discuss some of the reasons for this\nsuccess and the relationship between our results and Tesauro's results in\nbackgammon.",
    "published": "1999-01-05T00:56:54Z",
    "link": "http://arxiv.org/pdf/cs/9901001v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "I.2.6"
    ],
    "authors": [
      "Jonathan Baxter",
      "Andrew Tridgell",
      "Lex Weaver"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9901002v1",
    "title": "KnightCap: A chess program that learns by combining TD(lambda) with\n  game-tree search",
    "summary": "In this paper we present TDLeaf(lambda), a variation on the TD(lambda)\nalgorithm that enables it to be used in conjunction with game-tree search. We\npresent some experiments in which our chess program ``KnightCap'' used\nTDLeaf(lambda) to learn its evaluation function while playing on the Free\nInternet Chess Server (FICS, fics.onenet.net). The main success we report is\nthat KnightCap improved from a 1650 rating to a 2150 rating in just 308 games\nand 3 days of play. As a reference, a rating of 1650 corresponds to about level\nB human play (on a scale from E (1000) to A (1800)), while 2150 is human master\nlevel. We discuss some of the reasons for this success, principle among them\nbeing the use of on-line, rather than self-play.",
    "published": "1999-01-10T03:21:23Z",
    "link": "http://arxiv.org/pdf/cs/9901002v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "I.2.6"
    ],
    "authors": [
      "Jonathan Baxter",
      "Andrew Tridgell",
      "Lex Weaver"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9901003v1",
    "title": "Fixpoint 3-valued semantics for autoepistemic logic",
    "summary": "The paper presents a constructive fixpoint semantics for autoepistemic logic\n(AEL). This fixpoint characterizes a unique but possibly three-valued belief\nset of an autoepistemic theory. It may be three-valued in the sense that for a\nsubclass of formulas F, the fixpoint may not specify whether F is believed or\nnot. The paper presents a constructive 3-valued semantics for autoepistemic\nlogic (AEL). We introduce a derivation operator and define the semantics as its\nleast fixpoint. The semantics is 3-valued in the sense that, for some formulas,\nthe least fixpoint does not specify whether they are believed or not. We show\nthat complete fixpoints of the derivation operator correspond to Moore's stable\nexpansions. In the case of modal representations of logic programs our least\nfixpoint semantics expresses well-founded semantics or 3-valued Fitting-Kunen\nsemantics (depending on the embedding used). We show that, computationally, our\nsemantics is simpler than the semantics proposed by Moore (assuming that the\npolynomial hierarchy does not collapse).",
    "published": "1999-01-12T18:44:40Z",
    "link": "http://arxiv.org/pdf/cs/9901003v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "I.2.4, F.4.1, I.2.3"
    ],
    "authors": [
      "M. Denecker",
      "V. Marek",
      "M. Truszczynski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9901012v1",
    "title": "Extremal problems in logic programming and stable model computation",
    "summary": "We study the following problem: given a class of logic programs C, determine\nthe maximum number of stable models of a program from C. We establish the\nmaximum for the class of all logic programs with at most n clauses, and for the\nclass of all logic programs of size at most n. We also characterize the\nprograms for which the maxima are attained. We obtain similar results for the\nclass of all disjunctive logic programs with at most n clauses, each of length\nat most m, and for the class of all disjunctive logic programs of size at most\nn. Our results on logic programs have direct implication for the design of\nalgorithms to compute stable models. Several such algorithms, similar in spirit\nto the Davis-Putnam procedure, are described in the paper. Our results imply\nthat there is an algorithm that finds all stable models of a program with n\nclauses after considering the search space of size O(3^{n/3}) in the worst\ncase. Our results also provide some insights into the question of\nrepresentability of families of sets as families of stable models of logic\nprograms.",
    "published": "1999-01-25T14:44:20Z",
    "link": "http://arxiv.org/pdf/cs/9901012v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "I.2.3;I.2.4;F.4.1"
    ],
    "authors": [
      "Pawel Cholewinski",
      "Miroslaw Truszczynski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9901014v1",
    "title": "Minimum Description Length Induction, Bayesianism, and Kolmogorov\n  Complexity",
    "summary": "The relationship between the Bayesian approach and the minimum description\nlength approach is established. We sharpen and clarify the general modeling\nprinciples MDL and MML, abstracted as the ideal MDL principle and defined from\nBayes's rule by means of Kolmogorov complexity. The basic condition under which\nthe ideal principle should be applied is encapsulated as the Fundamental\nInequality, which in broad terms states that the principle is valid when the\ndata are random, relative to every contemplated hypothesis and also these\nhypotheses are random relative to the (universal) prior. Basically, the ideal\nprinciple states that the prior probability associated with the hypothesis\nshould be given by the algorithmic universal probability, and the sum of the\nlog universal probability of the model plus the log of the probability of the\ndata given the model should be minimized. If we restrict the model class to the\nfinite sets then application of the ideal principle turns into Kolmogorov's\nminimal sufficient statistic. In general we show that data compression is\nalmost always the best strategy, both in hypothesis identification and\nprediction.",
    "published": "1999-01-27T17:48:14Z",
    "link": "http://arxiv.org/pdf/cs/9901014v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CC",
      "cs.IT",
      "cs.LO",
      "math.IT",
      "math.PR",
      "physics.data-an",
      "E.4,F.2,H.3,I.2,I.5,I.7"
    ],
    "authors": [
      "Paul Vitanyi",
      "Ming Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9901016v1",
    "title": "Representation Theory for Default Logic",
    "summary": "Default logic can be regarded as a mechanism to represent families of belief\nsets of a reasoning agent. As such, it is inherently second-order. In this\npaper, we study the problem of representability of a family of theories as the\nset of extensions of a default theory. We give a complete solution to the\nrepresentability by means of normal default theories. We obtain partial results\non representability by arbitrary default theories. We construct examples of\ndenumerable families of non-including theories that are not representable. We\nalso study the concept of equivalence between default theories.",
    "published": "1999-01-28T21:57:15Z",
    "link": "http://arxiv.org/pdf/cs/9901016v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "I.2.4, F.4.1, I.2.3"
    ],
    "authors": [
      "Victor Marek",
      "Jan Treur",
      "Miroslaw Truszczynski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9902006v1",
    "title": "A Discipline of Evolutionary Programming",
    "summary": "Genetic fitness optimization using small populations or small population\nupdates across generations generally suffers from randomly diverging\nevolutions. We propose a notion of highly probable fitness optimization through\nfeasible evolutionary computing runs on small size populations. Based on\nrapidly mixing Markov chains, the approach pertains to most types of\nevolutionary genetic algorithms, genetic programming and the like. We establish\nthat for systems having associated rapidly mixing Markov chains and appropriate\nstationary distributions the new method finds optimal programs (individuals)\nwith probability almost 1. To make the method useful would require a structured\ndesign methodology where the development of the program and the guarantee of\nthe rapidly mixing property go hand in hand. We analyze a simple example to\nshow that the method is implementable. More significant examples require\ntheoretical advances, for example with respect to the Metropolis filter.",
    "published": "1999-02-02T16:17:16Z",
    "link": "http://arxiv.org/pdf/cs/9902006v1.pdf",
    "category": [
      "cs.NE",
      "cs.AI",
      "cs.CC",
      "cs.DS",
      "cs.LG",
      "cs.MA",
      "I.2,E.1,F.1"
    ],
    "authors": [
      "Paul Vitanyi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9902015v1",
    "title": "Resource Discovery in Trilogy",
    "summary": "Trilogy is a collaborative project whose key aim is the development of an\nintegrated virtual laboratory to support research training within each\ninstitution and collaborative projects between the partners. In this paper, the\narchitecture and underpinning platform of the system is described with\nparticular emphasis being placed on the structure and the integration of the\ndistributed database. A key element is the ontology that provides the\nmulti-agent system with a conceptualisation specification of the domain; this\nontology is explained, accompanied by a discussion how such a system is\nintegrated and used within the virtual laboratory. Although in this paper,\nTelecommunications and in particular Broadband networks are used as exemplars,\nthe underlying system principles are applicable to any domain where a\ncombination of experimental and literature-based resources are required.",
    "published": "1999-02-08T21:23:39Z",
    "link": "http://arxiv.org/pdf/cs/9902015v1.pdf",
    "category": [
      "cs.DL",
      "cs.AI",
      "cs.MA",
      "H.3.4;I.2.0"
    ],
    "authors": [
      "Franck Chevalier",
      "David Harle",
      "Geoffrey Smith"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9903002v1",
    "title": "An Algebraic Programming Style for Numerical Software and its\n  Optimization",
    "summary": "The abstract mathematical theory of partial differential equations (PDEs) is\nformulated in terms of manifolds, scalar fields, tensors, and the like, but\nthese algebraic structures are hardly recognizable in actual PDE solvers. The\ngeneral aim of the Sophus programming style is to bridge the gap between theory\nand practice in the domain of PDE solvers. Its main ingredients are a library\nof abstract datatypes corresponding to the algebraic structures used in the\nmathematical theory and an algebraic expression style similar to the expression\nstyle used in the mathematical theory. Because of its emphasis on abstract\ndatatypes, Sophus is most naturally combined with object-oriented languages or\nother languages supporting abstract datatypes. The resulting source code\npatterns are beyond the scope of current compiler optimizations, but are\nsufficiently specific for a dedicated source-to-source optimizer. The limited,\ndomain-specific, character of Sophus is the key to success here. This kind of\noptimization has been tested on computationally intensive Sophus style code\nwith promising results. The general approach may be useful for other styles and\nin other application domains as well.",
    "published": "1999-03-01T11:03:47Z",
    "link": "http://arxiv.org/pdf/cs/9903002v1.pdf",
    "category": [
      "cs.SE",
      "cs.AI",
      "cs.CE",
      "cs.MS",
      "D.1.5; D.2.2; J.2"
    ],
    "authors": [
      "T. B. Dinesh",
      "M. Haveraaen",
      "J. Heering"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9903011v1",
    "title": "A complete anytime algorithm for balanced number partitioning",
    "summary": "Given a set of numbers, the balanced partioning problem is to divide them\ninto two subsets, so that the sum of the numbers in each subset are as nearly\nequal as possible, subject to the constraint that the cardinalities of the\nsubsets be within one of each other. We combine the balanced largest\ndifferencing method (BLDM) and Korf's complete Karmarkar-Karp algorithm to get\na new algorithm that optimally solves the balanced partitioning problem. For\nnumbers with twelve significant digits or less, the algorithm can optimally\nsolve balanced partioning problems of arbitrary size in practice. For numbers\nwith greater precision, it first returns the BLDM solution, then continues to\nfind better solutions as time allows.",
    "published": "1999-03-11T22:38:01Z",
    "link": "http://arxiv.org/pdf/cs/9903011v1.pdf",
    "category": [
      "cs.DS",
      "cond-mat.dis-nn",
      "cs.AI",
      "F.2.2"
    ],
    "authors": [
      "Stephan Mertens"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9903016v1",
    "title": "Modeling Belief in Dynamic Systems, Part II: Revision and Update",
    "summary": "The study of belief change has been an active area in philosophy and AI. In\nrecent years two special cases of belief change, belief revision and belief\nupdate, have been studied in detail. In a companion paper (Friedman & Halpern,\n1997), we introduce a new framework to model belief change. This framework\ncombines temporal and epistemic modalities with a notion of plausibility,\nallowing us to examine the change of beliefs over time. In this paper, we show\nhow belief revision and belief update can be captured in our framework. This\nallows us to compare the assumptions made by each method, and to better\nunderstand the principles underlying them. In particular, it shows that Katsuno\nand Mendelzon's notion of belief update (Katsuno & Mendelzon, 1991a) depends on\nseveral strong assumptions that may limit its applicability in artificial\nintelligence. Finally, our analysis allow us to identify a notion of minimal\nchange that underlies a broad range of belief change operations including\nrevision and update.",
    "published": "1999-03-24T00:22:01Z",
    "link": "http://arxiv.org/pdf/cs/9903016v1.pdf",
    "category": [
      "cs.AI",
      "I.2"
    ],
    "authors": [
      "N Friedman",
      "J. Y. Halpern"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9904004v1",
    "title": "Mixing Metaphors",
    "summary": "Mixed metaphors have been neglected in recent metaphor research. This paper\nsuggests that such neglect is short-sighted. Though mixing is a more complex\nphenomenon than straight metaphors, the same kinds of reasoning and knowledge\nstructures are required. This paper provides an analysis of both parallel and\nserial mixed metaphors within the framework of an AI system which is already\ncapable of reasoning about straight metaphorical manifestations and argues that\nthe processes underlying mixing are central to metaphorical meaning. Therefore,\nany theory of metaphors must be able to account for mixing.",
    "published": "1999-04-12T11:37:49Z",
    "link": "http://arxiv.org/pdf/cs/9904004v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "I.2.0; I.2.7"
    ],
    "authors": [
      "Mark Lee",
      "John Barnden"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9905008v1",
    "title": "Inducing a Semantically Annotated Lexicon via EM-Based Clustering",
    "summary": "We present a technique for automatic induction of slot annotations for\nsubcategorization frames, based on induction of hidden classes in the EM\nframework of statistical estimation. The models are empirically evalutated by a\ngeneral decision test. Induction of slot labeling for subcategorization frames\nis accomplished by a further application of EM, and applied experimentally on\nframe observations derived from parsing large corpora. We outline an\ninterpretation of the learned representations as theoretical-linguistic\ndecompositional lexical entries.",
    "published": "1999-05-19T14:52:33Z",
    "link": "http://arxiv.org/pdf/cs/9905008v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.6; I.2.7; I.5.3"
    ],
    "authors": [
      "Mats Rooth",
      "Stefan Riezler",
      "Detlef Prescher",
      "Glenn Carroll",
      "Franz Beil"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9906002v1",
    "title": "The Symbol Grounding Problem",
    "summary": "How can the semantic interpretation of a formal symbol system be made\nintrinsic to the system, rather than just parasitic on the meanings in our\nheads? How can the meanings of the meaningless symbol tokens, manipulated\nsolely on the basis of their (arbitrary) shapes, be grounded in anything but\nother meaningless symbols? The problem is analogous to trying to learn Chinese\nfrom a Chinese/Chinese dictionary alone. A candidate solution is sketched:\nSymbolic representations must be grounded bottom-up in nonsymbolic\nrepresentations of two kinds: (1) \"iconic representations,\" which are analogs\nof the proximal sensory projections of distal objects and events, and (2)\n\"categorical representations,\" which are learned and innate feature-detectors\nthat pick out the invariant features of object and event categories from their\nsensory projections. Elementary symbols are the names of these object and event\ncategories, assigned on the basis of their (nonsymbolic) categorical\nrepresentations. Higher-order (3) \"symbolic representations,\" grounded in these\nelementary symbols, consist of symbol strings describing category membership\nrelations (e.g., \"An X is a Y that is Z\").",
    "published": "1999-06-01T19:57:24Z",
    "link": "http://arxiv.org/pdf/cs/9906002v1.pdf",
    "category": [
      "cs.AI",
      "I.2.0"
    ],
    "authors": [
      "Stevan Harnad"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9906006v2",
    "title": "Learning Efficient Disambiguation",
    "summary": "This dissertation analyses the computational properties of current\nperformance-models of natural language parsing, in particular Data Oriented\nParsing (DOP), points out some of their major shortcomings and suggests\nsuitable solutions. It provides proofs that various problems of probabilistic\ndisambiguation are NP-Complete under instances of these performance-models, and\nit argues that none of these models accounts for attractive efficiency\nproperties of human language processing in limited domains, e.g. that frequent\ninputs are usually processed faster than infrequent ones. The central\nhypothesis of this dissertation is that these shortcomings can be eliminated by\nspecializing the performance-models to the limited domains. The dissertation\naddresses \"grammar and model specialization\" and presents a new framework, the\nAmbiguity-Reduction Specialization (ARS) framework, that formulates the\nnecessary and sufficient conditions for successful specialization. The\nframework is instantiated into specialization algorithms and applied to\nspecializing DOP. Novelties of these learning algorithms are 1) they limit the\nhypotheses-space to include only \"safe\" models, 2) are expressed as constrained\noptimization formulae that minimize the entropy of the training tree-bank given\nthe specialized grammar, under the constraint that the size of the specialized\nmodel does not exceed a predefined maximum, and 3) they enable integrating the\nspecialized model with the original one in a complementary manner. The\ndissertation provides experiments with initial implementations and compares the\nresulting Specialized DOP (SDOP) models to the original DOP models with\nencouraging results.",
    "published": "1999-06-02T15:50:26Z",
    "link": "http://arxiv.org/pdf/cs/9906006v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "I.2.6, I.2.7, J.5, F.2"
    ],
    "authors": [
      "Khalil Sima'an"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9906010v1",
    "title": "Predicate Logic with Definitions",
    "summary": "Predicate Logic with Definitions (PLD or D-logic) is a modification of\nfirst-order logic intended mostly for practical formalization of mathematics.\nThe main syntactic constructs of D-logic are terms, formulas and definitions. A\ndefinition is a definition of variables, a definition of constants, or a\ncomposite definition (D-logic has also abbreviation definitions called\nabbreviations). Definitions can be used inside terms and formulas. This\npossibility alleviates introducing new quantifier-like names. Composite\ndefinitions allow constructing new definitions from existing ones.",
    "published": "1999-06-07T20:16:55Z",
    "link": "http://arxiv.org/pdf/cs/9906010v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "F.4.1; I.2.4"
    ],
    "authors": [
      "Victor Makarov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9906016v1",
    "title": "Automatically Selecting Useful Phrases for Dialogue Act Tagging",
    "summary": "We present an empirical investigation of various ways to automatically\nidentify phrases in a tagged corpus that are useful for dialogue act tagging.\nWe found that a new method (which measures a phrase's deviation from an\noptimally-predictive phrase), enhanced with a lexical filtering mechanism,\nproduces significantly better cues than manually-selected cue phrases, the\nexhaustive set of phrases in a training corpus, and phrases chosen by\ntraditional metrics, like mutual information and information gain.",
    "published": "1999-06-18T03:25:03Z",
    "link": "http://arxiv.org/pdf/cs/9906016v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "I.2.7; I.2.6"
    ],
    "authors": [
      "Ken Samuel",
      "Sandra Carberry",
      "K. Vijay-Shanker"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9906019v2",
    "title": "Resolving Part-of-Speech Ambiguity in the Greek Language Using Learning\n  Techniques",
    "summary": "This article investigates the use of Transformation-Based Error-Driven\nlearning for resolving part-of-speech ambiguity in the Greek language. The aim\nis not only to study the performance, but also to examine its dependence on\ndifferent thematic domains. Results are presented here for two different test\ncases: a corpus on \"management succession events\" and a general-theme corpus.\nThe two experiments show that the performance of this method does not depend on\nthe thematic domain of the corpus, and its accuracy for the Greek language is\naround 95%.",
    "published": "1999-06-22T07:41:24Z",
    "link": "http://arxiv.org/pdf/cs/9906019v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "I.2.6 ; I.2.7"
    ],
    "authors": [
      "G. Petasis",
      "G. Paliouras",
      "V. Karkaletsis",
      "C. D. Spyropoulos",
      "I. Androutsopoulos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9906029v2",
    "title": "Events in Property Patterns",
    "summary": "A pattern-based approach to the presentation, codification and reuse of\nproperty specifications for finite-state verification was proposed by Dwyer and\nhis collegues. The patterns enable non-experts to read and write formal\nspecifications for realistic systems and facilitate easy conversion of\nspecifications between formalisms, such as LTL, CTL, QRE. In this paper, we\nextend the pattern system with events - changes of values of variables in the\ncontext of LTL.",
    "published": "1999-06-28T17:06:51Z",
    "link": "http://arxiv.org/pdf/cs/9906029v2.pdf",
    "category": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.SC",
      "D.2.4;F.3.1;F.4.1;I.2.4;D.2.1"
    ],
    "authors": [
      "M. Chechik",
      "D. Paun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9907026v1",
    "title": "Mixing representation levels: The hybrid approach to automatic text\n  generation",
    "summary": "Natural language generation systems (NLG) map non-linguistic representations\ninto strings of words through a number of steps using intermediate\nrepresentations of various levels of abstraction. Template based systems, by\ncontrast, tend to use only one representation level, i.e. fixed strings, which\nare combined, possibly in a sophisticated way, to generate the final text.\n  In some circumstances, it may be profitable to combine NLG and template based\ntechniques. The issue of combining generation techniques can be seen in more\nabstract terms as the issue of mixing levels of representation of different\ndegrees of linguistic abstraction. This paper aims at defining a reference\narchitecture for systems using mixed representations. We argue that mixed\nrepresentations can be used without abandoning a linguistically grounded\napproach to language generation.",
    "published": "1999-07-16T15:43:45Z",
    "link": "http://arxiv.org/pdf/cs/9907026v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "authors": [
      "Emanuele Pianta",
      "Lucia M. Tovena"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9907032v2",
    "title": "Clausal Temporal Resolution",
    "summary": "In this article, we examine how clausal resolution can be applied to a\nspecific, but widely used, non-classical logic, namely discrete linear temporal\nlogic. Thus, we first define a normal form for temporal formulae and show how\narbitrary temporal formulae can be translated into the normal form, while\npreserving satisfiability. We then introduce novel resolution rules that can be\napplied to formulae in this normal form, provide a range of examples and\nexamine the correctness and complexity of this approach is examined and. This\nclausal resolution approach. Finally, we describe related work and future\ndevelopments concerning this work.",
    "published": "1999-07-21T15:48:06Z",
    "link": "http://arxiv.org/pdf/cs/9907032v2.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "I.2.3;F.4.1"
    ],
    "authors": [
      "Michael Fisher",
      "Clare Dixon",
      "Martin Peim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9908004v1",
    "title": "Extending the Stable Model Semantics with More Expressive Rules",
    "summary": "The rules associated with propositional logic programs and the stable model\nsemantics are not expressive enough to let one write concise programs. This\nproblem is alleviated by introducing some new types of propositional rules.\nTogether with a decision procedure that has been used as a base for an\nefficient implementation, the new rules supplant the standard ones in practical\napplications of the stable model semantics.",
    "published": "1999-08-06T06:01:43Z",
    "link": "http://arxiv.org/pdf/cs/9908004v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "I.2.3; I.2.8; F.4.1"
    ],
    "authors": [
      "Patrik Simons"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9908013v1",
    "title": "Collective Intelligence for Control of Distributed Dynamical Systems",
    "summary": "We consider the El Farol bar problem, also known as the minority game (W. B.\nArthur, ``The American Economic Review'', 84(2): 406--411 (1994), D. Challet\nand Y.C. Zhang, ``Physica A'', 256:514 (1998)). We view it as an instance of\nthe general problem of how to configure the nodal elements of a distributed\ndynamical system so that they do not ``work at cross purposes'', in that their\ncollective dynamics avoids frustration and thereby achieves a provided global\ngoal. We summarize a mathematical theory for such configuration applicable when\n(as in the bar problem) the global goal can be expressed as minimizing a global\nenergy function and the nodes can be expressed as minimizers of local free\nenergy functions. We show that a system designed with that theory performs\nnearly optimally for the bar problem.",
    "published": "1999-08-17T21:32:41Z",
    "link": "http://arxiv.org/pdf/cs/9908013v1.pdf",
    "category": [
      "cs.LG",
      "adap-org",
      "cond-mat",
      "cs.AI",
      "cs.DC",
      "cs.MA",
      "nlin.AO",
      "I.2.6 ; I.2.11"
    ],
    "authors": [
      "David H. Wolpert",
      "Kevin R. Wheeler",
      "Kagan Tumer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9908015v1",
    "title": "Representing Scholarly Claims in Internet Digital Libraries: A Knowledge\n  Modelling Approach",
    "summary": "This paper is concerned with tracking and interpreting scholarly documents in\ndistributed research communities. We argue that current approaches to document\ndescription, and current technological infrastructures particularly over the\nWorld Wide Web, provide poor support for these tasks. We describe the design of\na digital library server which will enable authors to submit a summary of the\ncontributions they claim their documents makes, and its relations to the\nliterature. We describe a knowledge-based Web environment to support the\nemergence of such a community-constructed semantic hypertext, and the services\nit could provide to assist the interpretation of an idea or document in the\ncontext of its literature. The discussion considers in detail how the approach\naddresses usability issues associated with knowledge structuring environments.",
    "published": "1999-08-19T09:51:29Z",
    "link": "http://arxiv.org/pdf/cs/9908015v1.pdf",
    "category": [
      "cs.DL",
      "cs.AI",
      "cs.HC",
      "cs.IR",
      "H.3.7; H.1.2; H5.2; H.5.4; I.2.4; I.7.4"
    ],
    "authors": [
      "Simon Buckingham Shum",
      "Enrico Motta",
      "John Domingue"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9909003v1",
    "title": "Iterative Deepening Branch and Bound",
    "summary": "In tree search problem the best-first search algorithm needs too much of\nspace . To remove such drawbacks of these algorithms the IDA* was developed\nwhich is both space and time cost efficient. But again IDA* can give an optimal\nsolution for real valued problems like Flow shop scheduling, Travelling\nSalesman and 0/1 Knapsack due to their real valued cost estimates. Thus further\nmodifications are done on it and the Iterative Deepening Branch and Bound\nSearch Algorithms is developed which meets the requirements. We have tried\nusing this algorithm for the Flow Shop Scheduling Problem and have found that\nit is quite effective.",
    "published": "1999-09-03T10:31:46Z",
    "link": "http://arxiv.org/pdf/cs/9909003v1.pdf",
    "category": [
      "cs.AI",
      "I.2.8"
    ],
    "authors": [
      "S. Mohanty",
      "R. N. Behera"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9909009v1",
    "title": "The Rough Guide to Constraint Propagation",
    "summary": "We provide here a simple, yet very general framework that allows us to\nexplain several constraint propagation algorithms in a systematic way. In\nparticular, using the notions commutativity and semi-commutativity, we show how\nthe well-known AC-3, PC-2, DAC and DPC algorithms are instances of a single\ngeneric algorithm. The work reported here extends and simplifies that of Apt,\ncs.AI/9811024.",
    "published": "1999-09-08T13:50:01Z",
    "link": "http://arxiv.org/pdf/cs/9909009v1.pdf",
    "category": [
      "cs.AI",
      "cs.PL",
      "D.3.3; I.1.2; I.2.2"
    ],
    "authors": [
      "Krzysztof R. Apt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9909010v1",
    "title": "Automatic Generation of Constraint Propagation Algorithms for Small\n  Finite Domains",
    "summary": "We study here constraint satisfaction problems that are based on predefined,\nexplicitly given finite constraints. To solve them we propose a notion of rule\nconsistency that can be expressed in terms of rules derived from the explicit\nrepresentation of the initial constraints.\n  This notion of local consistency is weaker than arc consistency for\nconstraints of arbitrary arity but coincides with it when all domains are unary\nor binary. For Boolean constraints rule consistency coincides with the closure\nunder the well-known propagation rules for Boolean constraints.\n  By generalizing the format of the rules we obtain a characterization of arc\nconsistency in terms of so-called inclusion rules. The advantage of rule\nconsistency and this rule based characterization of the arc consistency is that\nthe algorithms that enforce both notions can be automatically generated, as CHR\nrules. So these algorithms could be integrated into constraint logic\nprogramming systems such as Eclipse.\n  We illustrate the usefulness of this approach to constraint propagation by\ndiscussing the implementations of both algorithms and their use on various\nexamples, including Boolean constraints, three valued logic of Kleene,\nconstraints dealing with Waltz's language for describing polyhedreal scenes,\nand Allen's qualitative approach to temporal logic.",
    "published": "1999-09-08T14:18:47Z",
    "link": "http://arxiv.org/pdf/cs/9909010v1.pdf",
    "category": [
      "cs.AI",
      "cs.PL",
      "D.#.2; I.2.2; I.2.3"
    ],
    "authors": [
      "Krzysztof R. Apt",
      "Eric Monfroy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9909014v1",
    "title": "Reasoning About Common Knowledge with Infinitely Many Agents",
    "summary": "Complete axiomatizations and exponential-time decision procedures are\nprovided for reasoning about knowledge and common knowledge when there are\ninfinitely many agents. The results show that reasoning about knowledge and\ncommon knowledge with infinitely many agents is no harder than when there are\nfinitely many agents, provided that we can check the cardinality of certain set\ndifferences G - G', where G and G' are sets of agents. Since our complexity\nresults are independent of the cardinality of the sets G involved, they\nrepresent improvements over the previous results even with the sets of agents\ninvolved are finite. Moreover, our results make clear the extent to which\nissues of complexity and completeness depend on how the sets of agents involved\nare represented.",
    "published": "1999-09-21T20:43:46Z",
    "link": "http://arxiv.org/pdf/cs/9909014v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "F.4.1; I.2.4"
    ],
    "authors": [
      "Joseph Y. Halpern",
      "Richard A. Shore"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9909019v1",
    "title": "Knowledge in Multi-Agent Systems: Initial Configurations and Broadcast",
    "summary": "The semantic framework for the modal logic of knowledge due to Halpern and\nMoses provides a way to ascribe knowledge to agents in distributed and\nmulti-agent systems. In this paper we study two special cases of this\nframework: full systems and hypercubes. Both model static situations in which\nno agent has any information about another agent's state. Full systems and\nhypercubes are an appropriate model for the initial configurations of many\nsystems of interest. We establish a correspondence between full systems and\nhypercube systems and certain classes of Kripke frames. We show that these\nclasses of systems correspond to the same logic. Moreover, this logic is also\nthe same as that generated by the larger class of weakly directed frames. We\nprovide a sound and complete axiomatization, S5WDn, of this logic. Finally, we\nshow that under certain natural assumptions, in a model where knowledge evolves\nover time, S5WDn characterizes the properties of knowledge not just at the\ninitial configuration, but also at all later configurations. In particular,\nthis holds for homogeneous broadcast systems, which capture settings in which\nagents are initially ignorant of each others local states, operate\nsynchronously, have perfect recall and can communicate only by broadcasting.",
    "published": "1999-09-30T17:03:47Z",
    "link": "http://arxiv.org/pdf/cs/9909019v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "F.4.1; I.2.4"
    ],
    "authors": [
      "A. R. Lomuscio",
      "R. van der Meyden",
      "M. D. Ryan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9910015v3",
    "title": "PIPE: Personalizing Recommendations via Partial Evaluation",
    "summary": "It is shown that personalization of web content can be advantageously viewed\nas a form of partial evaluation --- a technique well known in the programming\nlanguages community. The basic idea is to model a recommendation space as a\nprogram, then partially evaluate this program with respect to user preferences\n(and features) to obtain specialized content. This technique supports both\ncontent-based and collaborative approaches, and is applicable to a range of\napplications that require automatic information integration from multiple web\nsources. The effectiveness of this methodology is illustrated by two example\napplications --- (i) personalizing content for visitors to the Blacksburg\nElectronic Village (http://www.bev.net), and (ii) locating and selecting\nscientific software on the Internet. The scalability of this technique is\ndemonstrated by its ability to interface with online web ontologies that index\nthousands of web pages.",
    "published": "1999-10-18T15:47:29Z",
    "link": "http://arxiv.org/pdf/cs/9910015v3.pdf",
    "category": [
      "cs.IR",
      "cs.AI",
      "H.4.2"
    ],
    "authors": [
      "Naren Ramakrishnan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9910016v1",
    "title": "Probabilistic Agent Programs",
    "summary": "Agents are small programs that autonomously take actions based on changes in\ntheir environment or ``state.'' Over the last few years, there have been an\nincreasing number of efforts to build agents that can interact and/or\ncollaborate with other agents. In one of these efforts, Eiter, Subrahmanian amd\nPick (AIJ, 108(1-2), pages 179-255) have shown how agents may be built on top\nof legacy code. However, their framework assumes that agent states are\ncompletely determined, and there is no uncertainty in an agent's state. Thus,\ntheir framework allows an agent developer to specify how his agents will react\nwhen the agent is 100% sure about what is true/false in the world state. In\nthis paper, we propose the concept of a \\emph{probabilistic agent program} and\nshow how, given an arbitrary program written in any imperative language, we may\nbuild a declarative ``probabilistic'' agent program on top of it which supports\ndecision making in the presence of uncertainty. We provide two alternative\nsemantics for probabilistic agent programs. We show that the second semantics,\nthough more epistemically appealing, is more complex to compute. We provide\nsound and complete algorithms to compute the semantics of \\emph{positive} agent\nprograms.",
    "published": "1999-10-21T09:35:38Z",
    "link": "http://arxiv.org/pdf/cs/9910016v1.pdf",
    "category": [
      "cs.AI",
      "D.1.6"
    ],
    "authors": [
      "Juergen Dix",
      "Mirco Nanni",
      "VS Subrahmanian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9911012v2",
    "title": "Cox's Theorem Revisited",
    "summary": "The assumptions needed to prove Cox's Theorem are discussed and examined.\nVarious sets of assumptions under which a Cox-style theorem can be proved are\nprovided, although all are rather strong and, arguably, not natural.",
    "published": "1999-11-27T17:57:17Z",
    "link": "http://arxiv.org/pdf/cs/9911012v2.pdf",
    "category": [
      "cs.AI",
      "I.2.3; I.2.7"
    ],
    "authors": [
      "Joseph Y. Halpern"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9912008v2",
    "title": "New Error Bounds for Solomonoff Prediction",
    "summary": "Solomonoff sequence prediction is a scheme to predict digits of binary\nstrings without knowing the underlying probability distribution. We call a\nprediction scheme informed when it knows the true probability distribution of\nthe sequence. Several new relations between universal Solomonoff sequence\nprediction and informed prediction and general probabilistic prediction schemes\nwill be proved. Among others, they show that the number of errors in Solomonoff\nprediction is finite for computable distributions, if finite in the informed\ncase. Deterministic variants will also be studied. The most interesting result\nis that the deterministic variant of Solomonoff prediction is optimal compared\nto any other probabilistic or deterministic prediction scheme apart from\nadditive square root corrections only. This makes it well suited even for\ndifficult prediction problems, where it does not suffice when the number of\nerrors is minimal to within some factor greater than one. Solomonoff's original\nbound and the ones presented here complement each other in a useful way.",
    "published": "1999-12-13T08:33:43Z",
    "link": "http://arxiv.org/pdf/cs/9912008v2.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "I.2.6; F.1.3; E.4; F.2"
    ],
    "authors": [
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0001002v1",
    "title": "Minimum Description Length and Compositionality",
    "summary": "We present a non-vacuous definition of compositionality. It is based on the\nidea of combining the minimum description length principle with the original\ndefinition of compositionality (that is, that the meaning of the whole is a\nfunction of the meaning of the parts).\n  The new definition is intuitive and allows us to distinguish between\ncompositional and non-compositional semantics, and between idiomatic and\nnon-idiomatic expressions. It is not ad hoc, since it does not make any\nreferences to non-intrinsic properties of meaning functions (like being a\npolynomial). Moreover, it allows us to compare different meaning functions with\nrespect to how compositional they are. It bridges linguistic and corpus-based,\nstatistical approaches to natural language understanding.",
    "published": "2000-01-04T21:46:29Z",
    "link": "http://arxiv.org/pdf/cs/0001002v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "authors": [
      "Wlodek Zadrozny"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0001015v1",
    "title": "Multi-Agent Only Knowing",
    "summary": "Levesque introduced a notion of ``only knowing'', with the goal of capturing\ncertain types of nonmonotonic reasoning. Levesque's logic dealt with only the\ncase of a single agent. Recently, both Halpern and Lakemeyer independently\nattempted to extend Levesque's logic to the multi-agent case. Although there\nare a number of similarities in their approaches, there are some significant\ndifferences. In this paper, we reexamine the notion of only knowing, going back\nto first principles. In the process, we simplify Levesque's completeness proof,\nand point out some problems with the earlier definitions. This leads us to\nreconsider what the properties of only knowing ought to be. We provide an axiom\nsystem that captures our desiderata, and show that it has a semantics that\ncorresponds to it. The axiom system has an added feature of interest: it\nincludes a modal operator for satisfiability, and thus provides a complete\naxiomatization for satisfiability in the logic K45.",
    "published": "2000-01-19T22:13:38Z",
    "link": "http://arxiv.org/pdf/cs/0001015v1.pdf",
    "category": [
      "cs.AI",
      "cs.LO",
      "I.2.4, F.4.1"
    ],
    "authors": [
      "Joseph Y. Halpern",
      "Gerhard Lakemeyer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0002001v2",
    "title": "Computing large and small stable models",
    "summary": "In this paper, we focus on the problem of existence and computing of small\nand large stable models. We show that for every fixed integer k, there is a\nlinear-time algorithm to decide the problem LSM (large stable models problem):\ndoes a logic program P have a stable model of size at least |P|-k. In contrast,\nwe show that the problem SSM (small stable models problem) to decide whether a\nlogic program P has a stable model of size at most k is much harder. We present\ntwo algorithms for this problem but their running time is given by polynomials\nof order depending on k. We show that the problem SSM is fixed-parameter\nintractable by demonstrating that it is W[2]-hard. This result implies that it\nis unlikely, an algorithm exists to compute stable models of size at most k\nthat would run in time O(n^c), where c is a constant independent of k. We also\nprovide an upper bound on the fixed-parameter complexity of the problem SSM by\nshowing that it belongs to the class W[3].",
    "published": "2000-02-03T21:15:34Z",
    "link": "http://arxiv.org/pdf/cs/0002001v2.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "I.2.3;I.2.4"
    ],
    "authors": [
      "Miroslaw Truszczynski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0002002v1",
    "title": "Uniform semantic treatment of default and autoepistemic logics",
    "summary": "We revisit the issue of connections between two leading formalisms in\nnonmonotonic reasoning: autoepistemic logic and default logic. For each logic\nwe develop a comprehensive semantic framework based on the notion of a belief\npair. The set of all belief pairs together with the so called knowledge\nordering forms a complete lattice. For each logic, we introduce several\nsemantics by means of fixpoints of operators on the lattice of belief pairs.\nOur results elucidate an underlying isomorphism of the respective semantic\nconstructions. In particular, we show that the interpretation of defaults as\nmodal formulas proposed by Konolige allows us to represent all semantics for\ndefault logic in terms of the corresponding semantics for autoepistemic logic.\nThus, our results conclusively establish that default logic can indeed be\nviewed as a fragment of autoepistemic logic. However, as we also demonstrate,\nthe semantics of Moore and Reiter are given by different operators and occupy\ndifferent locations in their corresponding families of semantics. This result\nexplains the source of the longstanding difficulty to formally relate these two\nsemantics. In the paper, we also discuss approximating skeptical reasoning with\nautoepistemic and default logics and establish constructive principles behind\nsuch approximations.",
    "published": "2000-02-03T21:44:57Z",
    "link": "http://arxiv.org/pdf/cs/0002002v1.pdf",
    "category": [
      "cs.AI",
      "I.2.3; I.2.4"
    ],
    "authors": [
      "Marc Denecker",
      "Victor W. Marek",
      "Miroslaw Truszczynski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0002003v1",
    "title": "On the accuracy and running time of GSAT",
    "summary": "Randomized algorithms for deciding satisfiability were shown to be effective\nin solving problems with thousands of variables. However, these algorithms are\nnot complete. That is, they provide no guarantee that a satisfying assignment,\nif one exists, will be found. Thus, when studying randomized algorithms, there\nare two important characteristics that need to be considered: the running time\nand, even more importantly, the accuracy --- a measure of likelihood that a\nsatisfying assignment will be found, provided one exists. In fact, we argue\nthat without a reference to the accuracy, the notion of the running time for\nrandomized algorithms is not well-defined. In this paper, we introduce a formal\nnotion of accuracy. We use it to define a concept of the running time. We use\nboth notions to study the random walk strategy GSAT algorithm. We investigate\nthe dependence of accuracy on properties of input formulas such as\nclause-to-variable ratio and the number of satisfying assignments. We\ndemonstrate that the running time of GSAT grows exponentially in the number of\nvariables of the input formula for randomly generated 3-CNF formulas and for\nthe formulas encoding 3- and 4-colorability of graphs.",
    "published": "2000-02-04T12:53:57Z",
    "link": "http://arxiv.org/pdf/cs/0002003v1.pdf",
    "category": [
      "cs.AI",
      "I.2.8"
    ],
    "authors": [
      "Deborah East",
      "Miroslaw Truszczynski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0002009v1",
    "title": "Syntactic Autonomy: Why There is no Autonomy without Symbols and How\n  Self-Organization Might Evolve Them",
    "summary": "Two different types of agency are discussed based on dynamically coherent and\nincoherent couplings with an environment respectively. I propose that until a\nprivate syntax (syntactic autonomy) is discovered by dynamically coherent\nagents, there are no significant or interesting types of closure or autonomy.\nWhen syntactic autonomy is established, then, because of a process of\ndescription-based selected self-organization, open-ended evolution is enabled.\nAt this stage, agents depend, in addition to dynamics, on localized, symbolic\nmemory, thus adding a level of dynamical incoherence to their interaction with\nthe environment. Furthermore, it is the appearance of syntactic autonomy which\nenables much more interesting types of closures amongst agents which share the\nsame syntax. To investigate how we can study the emergence of syntax from\ndynamical systems, experiments with cellular automata leading to emergent\ncomputation to solve non-trivial tasks are discussed. RNA editing is also\nmentioned as a process that may have been used to obtain a primordial\nbiological code necessary open-ended evolution.",
    "published": "2000-02-16T18:09:20Z",
    "link": "http://arxiv.org/pdf/cs/0002009v1.pdf",
    "category": [
      "cs.AI",
      "A.m"
    ],
    "authors": [
      "Luis M. Rocha"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0002015v1",
    "title": "Genetic Algorithms for Extension Search in Default Logic",
    "summary": "A default theory can be characterized by its sets of plausible conclusions,\ncalled its extensions. But, due to the theoretical complexity of Default Logic\n(Sigma_2p-complete), the problem of finding such an extension is very difficult\nif one wants to deal with non trivial knowledge bases. Based on the principle\nof natural selection, Genetic Algorithms have been quite successfully applied\nto combinatorial problems and seem useful for problems with huge search spaces\nand when no tractable algorithm is available. The purpose of this paper is to\nshow that techniques issued from Genetic Algorithms can be used in order to\nbuild an efficient default reasoning system. After providing a formal\ndescription of the components required for an extension search based on Genetic\nAlgorithms principles, we exhibit some experimental results.",
    "published": "2000-02-24T16:09:04Z",
    "link": "http://arxiv.org/pdf/cs/0002015v1.pdf",
    "category": [
      "cs.AI",
      "cs.LO",
      "F.4.1"
    ],
    "authors": [
      "P. Nicolas",
      "F. Saubion",
      "I. Stephan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0002014v1",
    "title": "Safe cooperative robot dynamics on graphs",
    "summary": "This paper initiates the use of vector fields to design, optimize, and\nimplement reactive schedules for safe cooperative robot patterns on planar\ngraphs. We consider Automated Guided Vehicles (AGV's) operating upon a\npredefined network of pathways. In contrast to the case of locally Euclidean\nconfiguration spaces, regularization of collisions is no longer a local\nprocedure, and issues concerning the global topology of configuration spaces\nmust be addressed. The focus of the present inquiry is the achievement of safe,\nefficient, cooperative patterns in the simplest nontrivial example (a pair of\nrobots on a Y-network) by means of a state-event heirarchical controller.",
    "published": "2000-02-24T18:13:33Z",
    "link": "http://arxiv.org/pdf/cs/0002014v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "I.2.9"
    ],
    "authors": [
      "Robert Ghrist",
      "Daniel Koditschek"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0002016v3",
    "title": "SLT-Resolution for the Well-Founded Semantics",
    "summary": "Global SLS-resolution and SLG-resolution are two representative mechanisms\nfor top-down evaluation of the well-founded semantics of general logic\nprograms. Global SLS-resolution is linear for query evaluation but suffers from\ninfinite loops and redundant computations. In contrast, SLG-resolution resolves\ninfinite loops and redundant computations by means of tabling, but it is not\nlinear. The principal disadvantage of a non-linear approach is that it cannot\nbe implemented using a simple, efficient stack-based memory structure nor can\nit be easily extended to handle some strictly sequential operators such as cuts\nin Prolog.\n  In this paper, we present a linear tabling method, called SLT-resolution, for\ntop-down evaluation of the well-founded semantics. SLT-resolution is a\nsubstantial extension of SLDNF-resolution with tabling. Its main features\ninclude: (1) It resolves infinite loops and redundant computations while\npreserving the linearity. (2) It is terminating, and sound and complete w.r.t.\nthe well-founded semantics for programs with the bounded-term-size property\nwith non-floundering queries. Its time complexity is comparable with\nSLG-resolution and polynomial for function-free logic programs. (3) Because of\nits linearity for query evaluation, SLT-resolution bridges the gap between the\nwell-founded semantics and standard Prolog implementation techniques. It can be\nimplemented by an extension to any existing Prolog abstract machines such as\nWAM or ATOAM.",
    "published": "2000-02-27T19:20:05Z",
    "link": "http://arxiv.org/pdf/cs/0002016v3.pdf",
    "category": [
      "cs.AI",
      "cs.PL",
      "D.3.1; F.4.1; I.2.3"
    ],
    "authors": [
      "Yi-Dong Shen",
      "Li-Yan Yuan",
      "Jia-Huai You"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003003v1",
    "title": "Prospects for in-depth story understanding by computer",
    "summary": "While much research on the hard problem of in-depth story understanding by\ncomputer was performed starting in the 1970s, interest shifted in the 1990s to\ninformation extraction and word sense disambiguation. Now that a degree of\nsuccess has been achieved on these easier problems, I propose it is time to\nreturn to in-depth story understanding. In this paper I examine the shift away\nfrom story understanding, discuss some of the major problems in building a\nstory understanding system, present some possible solutions involving a set of\ninteracting understanding agents, and provide pointers to useful tools and\nresources for building story understanding systems.",
    "published": "2000-03-01T18:01:06Z",
    "link": "http://arxiv.org/pdf/cs/0003003v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "I.2.7"
    ],
    "authors": [
      "Erik T. Mueller"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003004v1",
    "title": "A database and lexicon of scripts for ThoughtTreasure",
    "summary": "Since scripts were proposed in the 1970's as an inferencing mechanism for AI\nand natural language processing programs, there have been few attempts to build\na database of scripts. This paper describes a database and lexicon of scripts\nthat has been added to the ThoughtTreasure commonsense platform. The database\nprovides the following information about scripts: sequence of events, roles,\nprops, entry conditions, results, goals, emotions, places, duration, frequency,\nand cost. English and French words and phrases are linked to script concepts.",
    "published": "2000-03-01T18:07:02Z",
    "link": "http://arxiv.org/pdf/cs/0003004v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "I.2.7; I.2.4"
    ],
    "authors": [
      "Erik T. Mueller"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003007v1",
    "title": "Computing Circumscriptive Databases by Integer Programming: Revisited\n  (Extended Abstract)",
    "summary": "In this paper, we consider a method of computing minimal models in\ncircumscription using integer programming in propositional logic and\nfirst-order logic with domain closure axioms and unique name axioms. This kind\nof treatment is very important since this enable to apply various technique\ndeveloped in operations research to nonmonotonic reasoning.\n  Nerode et al. (1995) are the first to propose a method of computing\ncircumscription using integer programming. They claimed their method was\ncorrect for circumscription with fixed predicate, but we show that their method\ndoes not correctly reflect their claim. We show a correct method of computing\nall the minimal models not only with fixed predicates but also with varied\npredicates and we extend our method to compute prioritized circumscription as\nwell.",
    "published": "2000-03-05T09:57:49Z",
    "link": "http://arxiv.org/pdf/cs/0003007v1.pdf",
    "category": [
      "cs.AI",
      "cs.LO",
      "I.2.3"
    ],
    "authors": [
      "Ken Satoh",
      "Hidenori Okamoto"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003008v1",
    "title": "Consistency Management of Normal Logic Program by Top-down Abductive\n  Proof Procedure",
    "summary": "This paper presents a method of computing a revision of a function-free\nnormal logic program. If an added rule is inconsistent with a program, that is,\nif it leads to a situation such that no stable model exists for a new program,\nthen deletion and addition of rules are performed to avoid inconsistency. We\nspecify a revision by translating a normal logic program into an abductive\nlogic program with abducibles to represent deletion and addition of rules. To\ncompute such deletion and addition, we propose an adaptation of our top-down\nabductive proof procedure to compute a relevant abducibles to an added rule. We\ncompute a minimally revised program, by choosing a minimal set of abducibles\namong all the sets of abducibles computed by a top-down proof procedure.",
    "published": "2000-03-05T10:29:03Z",
    "link": "http://arxiv.org/pdf/cs/0003008v1.pdf",
    "category": [
      "cs.AI",
      "I.2.3"
    ],
    "authors": [
      "Ken Satoh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003009v1",
    "title": "Conditional indifference and conditional preservation",
    "summary": "The idea of preserving conditional beliefs emerged recently as a new paradigm\napt to guide the revision of epistemic states. Conditionals are substantially\ndifferent from propositional beliefs and need specific treatment. In this\npaper, we present a new approach to conditionals, capturing particularly well\ntheir dynamic part as revision policies. We thoroughly axiomatize a principle\nof conditional preservation as an indifference property with respect to\nconditional structures of worlds. This principle is developed in a\nsemi-quantitative setting, so as to reveal its fundamental meaning for belief\nrevision in quantitative as well as in qualitative frameworks. In fact, it is\nshown to cover other proposed approaches to conditional preservation.",
    "published": "2000-03-06T12:08:06Z",
    "link": "http://arxiv.org/pdf/cs/0003009v1.pdf",
    "category": [
      "cs.AI",
      "cs.LO",
      "I.2.0; I.2.3; I.2.6"
    ],
    "authors": [
      "Gabriele Kern-Isberner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003011v2",
    "title": "Automatic Belief Revision in SNePS",
    "summary": "SNePS is a logic- and network- based knowledge representation, reasoning, and\nacting system, based on a monotonic, paraconsistent, first-order term logic,\nwith compositional intensional semantics. It has an ATMS-style facility for\nbelief contraction, and an acting component, including a well-defined syntax\nand semantics for primitive and composite acts, as well as for ``rules'' that\nallow for acting in support of reasoning and reasoning in support of acting.\nSNePS has been designed to support natural language competent cognitive agents.\n  When the current version of SNePS detects an explicit contradiction, it\ninteracts with the user, providing information that helps the user decide what\nto remove from the knowledge base in order to remove the contradiction. The\nforthcoming SNePS 2.6 will also do automatic belief contraction if the\ninformation in the knowledge base warrents it.",
    "published": "2000-03-06T16:55:16Z",
    "link": "http://arxiv.org/pdf/cs/0003011v2.pdf",
    "category": [
      "cs.AI",
      "cs.LO",
      "I.2.3; I.2.4"
    ],
    "authors": [
      "Stuart C. Shapiro",
      "Frances L. Johnson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003012v1",
    "title": "Defeasible Reasoning in OSCAR",
    "summary": "This is a system description for the OSCAR defeasible reasoner.",
    "published": "2000-03-06T22:23:00Z",
    "link": "http://arxiv.org/pdf/cs/0003012v1.pdf",
    "category": [
      "cs.AI",
      "F.4.1"
    ],
    "authors": [
      "John L. Pollock"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003013v1",
    "title": "A flexible framework for defeasible logics",
    "summary": "Logics for knowledge representation suffer from over-specialization: while\neach logic may provide an ideal representation formalism for some problems, it\nis less than optimal for others. A solution to this problem is to choose from\nseveral logics and, when necessary, combine the representations. In general,\nsuch an approach results in a very difficult problem of combination. However,\nif we can choose the logics from a uniform framework then the problem of\ncombining them is greatly simplified. In this paper, we develop such a\nframework for defeasible logics. It supports all defeasible logics that satisfy\na strong negation principle. We use logic meta-programs as the basis for the\nframework.",
    "published": "2000-03-07T01:24:26Z",
    "link": "http://arxiv.org/pdf/cs/0003013v1.pdf",
    "category": [
      "cs.AI",
      "cs.LO",
      "I.2.3; D.1.6"
    ],
    "authors": [
      "G. Antoniou",
      "D. Billigton",
      "G. Governatori",
      "M. J. Maher"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003014v2",
    "title": "Applying Maxi-adjustment to Adaptive Information Filtering Agents",
    "summary": "Learning and adaptation is a fundamental property of intelligent agents. In\nthe context of adaptive information filtering, a filtering agent's beliefs\nabout a user's information needs have to be revised regularly with reference to\nthe user's most current information preferences. This learning and adaptation\nprocess is essential for maintaining the agent's filtering performance. The AGM\nbelief revision paradigm provides a rigorous foundation for modelling rational\nand minimal changes to an agent's beliefs. In particular, the maxi-adjustment\nmethod, which follows the AGM rationale of belief change, offers a sound and\nrobust computational mechanism to develop adaptive agents so that learning\nautonomy of these agents can be enhanced. This paper describes how the\nmaxi-adjustment method is applied to develop the learning components of\nadaptive information filtering agents, and discusses possible difficulties of\napplying such a framework to these agents.",
    "published": "2000-03-07T02:12:55Z",
    "link": "http://arxiv.org/pdf/cs/0003014v2.pdf",
    "category": [
      "cs.AI",
      "cs.MA",
      "I.2.3;I.2.11;H.3.3"
    ],
    "authors": [
      "Raymond Lau",
      "Arthur H. M. ter Hofstede",
      "Peter D. Bruza"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003016v1",
    "title": "Abductive and Consistency-Based Diagnosis Revisited: a Modeling\n  Perspective",
    "summary": "Diagnostic reasoning has been characterized logically as consistency-based\nreasoning or abductive reasoning. Previous analyses in the literature have\nshown, on the one hand, that choosing the (in general more restrictive)\nabductive definition may be appropriate or not, depending on the content of the\nknowledge base [Console&Torasso91], and, on the other hand, that, depending on\nthe choice of the definition the same knowledge should be expressed in\ndifferent form [Poole94].\n  Since in Model-Based Diagnosis a major problem is finding the right way of\nabstracting the behavior of the system to be modeled, this paper discusses the\nrelation between modeling, and in particular abstraction in the model, and the\nnotion of diagnosis.",
    "published": "2000-03-07T11:39:53Z",
    "link": "http://arxiv.org/pdf/cs/0003016v1.pdf",
    "category": [
      "cs.AI",
      "I.2.3; I.2.4"
    ],
    "authors": [
      "Daniele Theseider Dupre'"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003017v2",
    "title": "The lexicographic closure as a revision process",
    "summary": "The connections between nonmonotonic reasoning and belief revision are\nwell-known. A central problem in the area of nonmonotonic reasoning is the\nproblem of default entailment, i.e., when should an item of default information\nrepresenting \"if A is true then, normally, B is true\" be said to follow from a\ngiven set of items of such information. Many answers to this question have been\nproposed but, surprisingly, virtually none have attempted any explicit\nconnection to belief revision. The aim of this paper is to give an example of\nhow such a connection can be made by showing how the lexicographic closure of a\nset of defaults may be conceptualised as a process of iterated revision by sets\nof sentences. Specifically we use the revision process of Nayak.",
    "published": "2000-03-07T11:44:35Z",
    "link": "http://arxiv.org/pdf/cs/0003017v2.pdf",
    "category": [
      "cs.AI",
      "cs.LO",
      "I.2.3"
    ],
    "authors": [
      "Richard Booth"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003015v2",
    "title": "On the semantics of merging",
    "summary": "Intelligent agents are often faced with the problem of trying to merge\npossibly conflicting pieces of information obtained from different sources into\na consistent view of the world. We propose a framework for the modelling of\nsuch merging operations with roots in the work of Spohn (1988, 1991). Unlike\nmost approaches we focus on the merging of epistemic states, not knowledge\nbases. We construct a number of plausible merging operations and measure them\nagainst various properties that merging operations ought to satisfy. Finally,\nwe discuss the connection between merging and the use of infobases Meyer (1999)\nand Meyer et al. (2000).",
    "published": "2000-03-07T12:26:34Z",
    "link": "http://arxiv.org/pdf/cs/0003015v2.pdf",
    "category": [
      "cs.AI",
      "cs.LO",
      "I.2.3; I.2.4; I.2.11"
    ],
    "authors": [
      "Thomas Meyer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003018v1",
    "title": "Description of GADEL",
    "summary": "This article describes the first implementation of the GADEL system : a\nGenetic Algorithm for Default Logic. The goal of GADEL is to compute extensions\nin Reiter's default logic. It accepts every kind of finite propositional\ndefault theories and is based on evolutionary principles of Genetic Algorithms.\nIts first experimental results on certain instances of the problem show that\nthis new approach of the problem can be successful.",
    "published": "2000-03-07T14:46:23Z",
    "link": "http://arxiv.org/pdf/cs/0003018v1.pdf",
    "category": [
      "cs.AI",
      "cs.LO",
      "F.4.1"
    ],
    "authors": [
      "I. Stephan",
      "F. Saubion",
      "P. Nicolas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003019v1",
    "title": "Extending Classical Logic with Inductive Definitions",
    "summary": "The goal of this paper is to extend classical logic with a generalized notion\nof inductive definition supporting positive and negative induction, to\ninvestigate the properties of this logic, its relationships to other logics in\nthe area of non-monotonic reasoning, logic programming and deductive databases,\nand to show its application for knowledge representation by giving a typology\nof definitional knowledge.",
    "published": "2000-03-07T15:44:08Z",
    "link": "http://arxiv.org/pdf/cs/0003019v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "I.2.3;I.2.4;F.4.1"
    ],
    "authors": [
      "Marc Denecker"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003020v2",
    "title": "ACLP: Integrating Abduction and Constraint Solving",
    "summary": "ACLP is a system which combines abductive reasoning and constraint solving by\nintegrating the frameworks of Abductive Logic Programming (ALP) and Constraint\nLogic Programming (CLP). It forms a general high-level knowledge representation\nenvironment for abductive problems in Artificial Intelligence and other areas.\nIn ACLP, the task of abduction is supported and enhanced by its non-trivial\nintegration with constraint solving facilitating its application to complex\nproblems. The ACLP system is currently implemented on top of the CLP language\nof ECLiPSe as a meta-interpreter exploiting its underlying constraint solver\nfor finite domains. It has been applied to the problems of planning and\nscheduling in order to test its computational effectiveness compared with the\ndirect use of the (lower level) constraint solving framework of CLP on which it\nis built. These experiments provide evidence that the abductive framework of\nACLP does not compromise significantly the computational efficiency of the\nsolutions. Other experiments show the natural ability of ACLP to accommodate\neasily and in a robust way new or changing requirements of the original\nproblem.",
    "published": "2000-03-07T22:47:13Z",
    "link": "http://arxiv.org/pdf/cs/0003020v2.pdf",
    "category": [
      "cs.AI",
      "I.2.4;F.4.1"
    ],
    "authors": [
      "Antonis Kakas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003021v1",
    "title": "Relevance Sensitive Non-Monotonic Inference on Belief Sequences",
    "summary": "We present a method for relevance sensitive non-monotonic inference from\nbelief sequences which incorporates insights pertaining to prioritized\ninference and relevance sensitive, inconsistency tolerant belief revision.\n  Our model uses a finite, logically open sequence of propositional formulas as\na representation for beliefs and defines a notion of inference from\nmaxiconsistent subsets of formulas guided by two orderings: a temporal\nsequencing and an ordering based on relevance relations between the conclusion\nand formulas in the sequence. The relevance relations are ternary (using\ncontext as a parameter) as opposed to standard binary axiomatizations. The\ninference operation thus defined easily handles iterated revision by\nmaintaining a revision history, blocks the derivation of inconsistent answers\nfrom a possibly inconsistent sequence and maintains the distinction between\nexplicit and implicit beliefs. In doing so, it provides a finitely presented\nformalism and a plausible model of reasoning for automated agents.",
    "published": "2000-03-08T03:03:36Z",
    "link": "http://arxiv.org/pdf/cs/0003021v1.pdf",
    "category": [
      "cs.AI",
      "I.2.3"
    ],
    "authors": [
      "Samir Chopra",
      "Konstantinos Georgatos",
      "Rohit Parikh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003024v1",
    "title": "A Compiler for Ordered Logic Programs",
    "summary": "This paper describes a system, called PLP, for compiling ordered logic\nprograms into standard logic programs under the answer set semantics. In an\nordered logic program, rules are named by unique terms, and preferences among\nrules are given by a set of dedicated atoms. An ordered logic program is\ntransformed into a second, regular, extended logic program wherein the\npreferences are respected, in that the answer sets obtained in the transformed\ntheory correspond with the preferred answer sets of the original theory. Since\nthe result of the translation is an extended logic program, existing logic\nprogramming systems can be used as underlying reasoning engine. In particular,\nPLP is conceived as a front-end to the logic programming systems dlv and\nsmodels.",
    "published": "2000-03-08T10:15:51Z",
    "link": "http://arxiv.org/pdf/cs/0003024v1.pdf",
    "category": [
      "cs.AI",
      "I.2.3"
    ],
    "authors": [
      "James P. Delgrande",
      "Torsten Schaub",
      "Hans Tompits"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003023v1",
    "title": "Probabilistic Default Reasoning with Conditional Constraints",
    "summary": "We propose a combination of probabilistic reasoning from conditional\nconstraints with approaches to default reasoning from conditional knowledge\nbases. In detail, we generalize the notions of Pearl's entailment in system Z,\nLehmann's lexicographic entailment, and Geffner's conditional entailment to\nconditional constraints. We give some examples that show that the new notions\nof z-, lexicographic, and conditional entailment have similar properties like\ntheir classical counterparts. Moreover, we show that the new notions of z-,\nlexicographic, and conditional entailment are proper generalizations of both\ntheir classical counterparts and the classical notion of logical entailment for\nconditional constraints.",
    "published": "2000-03-08T11:05:45Z",
    "link": "http://arxiv.org/pdf/cs/0003023v1.pdf",
    "category": [
      "cs.AI",
      "I.2.3; I.2.4"
    ],
    "authors": [
      "Thomas Lukasiewicz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003027v1",
    "title": "SLDNFA-system",
    "summary": "The SLDNFA-system results from the LP+ project at the K.U.Leuven, which\ninvestigates logics and proof procedures for these logics for declarative\nknowledge representation. Within this project inductive definition logic\n(ID-logic) is used as representation logic. Different solvers are being\ndeveloped for this logic and one of these is SLDNFA. A prototype of the system\nis available and used for investigating how to solve efficiently problems\nrepresented in ID-logic.",
    "published": "2000-03-08T13:22:44Z",
    "link": "http://arxiv.org/pdf/cs/0003027v1.pdf",
    "category": [
      "cs.AI",
      "F.4.1;I.2.3;I.2.4"
    ],
    "authors": [
      "Bert Van Nuffelen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003025v1",
    "title": "Logic Programming for Describing and Solving Planning Problems",
    "summary": "A logic programming paradigm which expresses solutions to problems as stable\nmodels has recently been promoted as a declarative approach to solving various\ncombinatorial and search problems, including planning problems. In this\nparadigm, all program rules are considered as constraints and solutions are\nstable models of the rule set. This is a rather radical departure from the\nstandard paradigm of logic programming. In this paper we revisit abductive\nlogic programming and argue that it allows a programming style which is as\ndeclarative as programming based on stable models. However, within abductive\nlogic programming, one has two kinds of rules. On the one hand predicate\ndefinitions (which may depend on the abducibles) which are nothing else than\nstandard logic programs (with their non-monotonic semantics when containing\nwith negation); on the other hand rules which constrain the models for the\nabducibles. In this sense abductive logic programming is a smooth extension of\nthe standard paradigm of logic programming, not a radical departure.",
    "published": "2000-03-08T14:00:35Z",
    "link": "http://arxiv.org/pdf/cs/0003025v1.pdf",
    "category": [
      "cs.AI",
      "cs.LO",
      "D.1.6; D.3.1; F.4.1; I.2.3"
    ],
    "authors": [
      "Maurice Bruynooghe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003028v1",
    "title": "Logic Programs with Compiled Preferences",
    "summary": "We describe an approach for compiling preferences into logic programs under\nthe answer set semantics. An ordered logic program is an extended logic program\nin which rules are named by unique terms, and in which preferences among rules\nare given by a set of dedicated atoms. An ordered logic program is transformed\ninto a second, regular, extended logic program wherein the preferences are\nrespected, in that the answer sets obtained in the transformed theory\ncorrespond with the preferred answer sets of the original theory. Our approach\nallows both the specification of static orderings (as found in most previous\nwork), in which preferences are external to a logic program, as well as\norderings on sets of rules. In large part then, we are interested in describing\na general methodology for uniformly incorporating preference information in a\nlogic program. Since the result of our translation is an extended logic\nprogram, we can make use of existing implementations, such as dlv and smodels.\nTo this end, we have developed a compiler, available on the web, as a front-end\nfor these programming systems.",
    "published": "2000-03-08T14:09:56Z",
    "link": "http://arxiv.org/pdf/cs/0003028v1.pdf",
    "category": [
      "cs.AI",
      "I.2.3"
    ],
    "authors": [
      "James P. Delgrande",
      "Torsten Schaub",
      "Hans Tompits"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003029v1",
    "title": "Fuzzy Approaches to Abductive Inference",
    "summary": "This paper proposes two kinds of fuzzy abductive inference in the framework\nof fuzzy rule base. The abductive inference processes described here depend on\nthe semantic of the rule. We distinguish two classes of interpretation of a\nfuzzy rule, certainty generation rules and possible generation rules. In this\npaper we present the architecture of abductive inference in the first class of\ninterpretation. We give two kinds of problem that we can resolve by using the\nproposed models of inference.",
    "published": "2000-03-08T14:56:58Z",
    "link": "http://arxiv.org/pdf/cs/0003029v1.pdf",
    "category": [
      "cs.AI",
      "Artificial intelligence and nonmonotonic reasoning and belief\n  revision"
    ],
    "authors": [
      "Nedra Mellouli",
      "Bernadette Bouchon-Meunier"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003030v1",
    "title": "Problem solving in ID-logic with aggregates: some experiments",
    "summary": "The goal of the LP+ project at the K.U.Leuven is to design an expressive\nlogic, suitable for declarative knowledge representation, and to develop\nintelligent systems based on Logic Programming technology for solving\ncomputational problems using the declarative specifications. The ID-logic is an\nintegration of typed classical logic and a definition logic. Different\nabductive solvers for this language are being developed. This paper is a report\nof the integration of high order aggregates into ID-logic and the consequences\non the solver SLDNFA.",
    "published": "2000-03-08T15:39:14Z",
    "link": "http://arxiv.org/pdf/cs/0003030v1.pdf",
    "category": [
      "cs.AI",
      "F.4.1;I.2.4;I.2.3"
    ],
    "authors": [
      "Bert Van Nuffelen",
      "Marc Denecker"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003031v1",
    "title": "Optimal Belief Revision",
    "summary": "We propose a new approach to belief revision that provides a way to change\nknowledge bases with a minimum of effort. We call this way of revising belief\nstates optimal belief revision. Our revision method gives special attention to\nthe fact that most belief revision processes are directed to a specific\ninformational objective. This approach to belief change is founded on notions\nsuch as optimal context and accessibility. For the sentential model of belief\nstates we provide both a formal description of contexts as sub-theories\ndetermined by three parameters and a method to construct contexts. Next, we\nintroduce an accessibility ordering for belief sets, which we then use for\nselecting the best (optimal) contexts with respect to the processing effort\ninvolved in the revision. Then, for finitely axiomatizable knowledge bases, we\ncharacterize a finite accessibility ranking from which the accessibility\nordering for the entire base is generated and show how to determine the ranking\nof an arbitrary sentence in the language. Finally, we define the adjustment of\nthe accessibility ranking of a revised base of a belief set.",
    "published": "2000-03-08T15:54:50Z",
    "link": "http://arxiv.org/pdf/cs/0003031v1.pdf",
    "category": [
      "cs.AI",
      "I.2.3"
    ],
    "authors": [
      "Carmen Vodislav",
      "Robert E. Mercer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003022v1",
    "title": "Hypothetical revision and matter-of-fact supposition",
    "summary": "The paper studies the notion of supposition encoded in non-Archimedean\nconditional probability (and revealed in the acceptance of the so-called\nindicative conditionals). The notion of qualitative change of view that thus\narises is axiomatized and compared with standard notions like AGM and UPDATE.\nApplications in the following fields are discussed: (1) theory of games and\ndecisions, (2) causal models, (3) non-monotonic logic.",
    "published": "2000-03-08T16:06:58Z",
    "link": "http://arxiv.org/pdf/cs/0003022v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "I.2.4; I.2.6; I.2.7; I.2.11"
    ],
    "authors": [
      "Horacio Arlo-Costa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003032v1",
    "title": "cc-Golog: Towards More Realistic Logic-Based Robot Controllers",
    "summary": "High-level robot controllers in realistic domains typically deal with\nprocesses which operate concurrently, change the world continuously, and where\nthe execution of actions is event-driven as in ``charge the batteries as soon\nas the voltage level is low''. While non-logic-based robot control languages\nare well suited to express such scenarios, they fare poorly when it comes to\nprojecting, in a conspicuous way, how the world evolves when actions are\nexecuted. On the other hand, a logic-based control language like \\congolog,\nbased on the situation calculus, is well-suited for the latter. However, it has\nproblems expressing event-driven behavior. In this paper, we show how these\nproblems can be overcome by first extending the situation calculus to support\ncontinuous change and event-driven behavior and then presenting \\ccgolog, a\nvariant of \\congolog which is based on the extended situation calculus. One\nbenefit of \\ccgolog is that it narrows the gap in expressiveness compared to\nnon-logic-based control languages while preserving a semantically well-founded\nprojection mechanism.",
    "published": "2000-03-08T16:14:08Z",
    "link": "http://arxiv.org/pdf/cs/0003032v1.pdf",
    "category": [
      "cs.AI",
      "I.2.3;I.2.8"
    ],
    "authors": [
      "Henrik Grosskreutz",
      "Gerhard Lakemeyer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003034v2",
    "title": "E-RES: A System for Reasoning about Actions, Events and Observations",
    "summary": "E-RES is a system that implements the Language E, a logic for reasoning about\nnarratives of action occurrences and observations. E's semantics is\nmodel-theoretic, but this implementation is based on a sound and complete\nreformulation of E in terms of argumentation, and uses general computational\ntechniques of argumentation frameworks. The system derives sceptical\nnon-monotonic consequences of a given reformulated theory which exactly\ncorrespond to consequences entailed by E's model-theory. The computation relies\non a complimentary ability of the system to derive credulous non-monotonic\nconsequences together with a set of supporting assumptions which is sufficient\nfor the (credulous) conclusion to hold. E-RES allows theories to contain\ngeneral action laws, statements about action occurrences, observations and\nstatements of ramifications (or universal laws). It is able to derive\nconsequences both forward and backward in time. This paper gives a short\noverview of the theoretical basis of E-RES and illustrates its use on a variety\nof examples. Currently, E-RES is being extended so that the system can be used\nfor planning.",
    "published": "2000-03-08T16:18:52Z",
    "link": "http://arxiv.org/pdf/cs/0003034v2.pdf",
    "category": [
      "cs.AI",
      "I.2.4; F.4.1"
    ],
    "authors": [
      "Antonis Kakas",
      "Rob Miller",
      "Francesca Toni"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003035v1",
    "title": "Declarative Representation of Revision Strategies",
    "summary": "In this paper we introduce a nonmonotonic framework for belief revision in\nwhich reasoning about the reliability of different pieces of information based\non meta-knowledge about the information is possible, and where revision\nstrategies can be described declaratively. The approach is based on a\nPoole-style system for default reasoning in which entrenchment information is\nrepresented in the logical language. A notion of inference based on the least\nfixed point of a monotone operator is used to make sure that all theories\npossess a consistent set of conclusions.",
    "published": "2000-03-08T16:22:03Z",
    "link": "http://arxiv.org/pdf/cs/0003035v1.pdf",
    "category": [
      "cs.AI",
      "cs.LO",
      "I.2.3"
    ],
    "authors": [
      "Gerhard Brewka"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003037v1",
    "title": "QUIP - A Tool for Computing Nonmonotonic Reasoning Tasks",
    "summary": "In this paper, we outline the prototype of an automated inference tool,\ncalled QUIP, which provides a uniform implementation for several nonmonotonic\nreasoning formalisms. The theoretical basis of QUIP is derived from well-known\nresults about the computational complexity of nonmonotonic logics and exploits\na representation of the different reasoning tasks in terms of quantified\nboolean formulae.",
    "published": "2000-03-08T17:18:08Z",
    "link": "http://arxiv.org/pdf/cs/0003037v1.pdf",
    "category": [
      "cs.AI",
      "I.2.3"
    ],
    "authors": [
      "Uwe Egly",
      "Thomas Eiter",
      "Hans Tompits",
      "Stefan Woltran"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003036v1",
    "title": "DLV - A System for Declarative Problem Solving",
    "summary": "DLV is an efficient logic programming and non-monotonic reasoning (LPNMR)\nsystem with advanced knowledge representation mechanisms and interfaces to\nclassic relational database systems.\n  Its core language is disjunctive datalog (function-free disjunctive logic\nprogramming) under the Answer Set Semantics with integrity constraints, both\ndefault and strong (or explicit) negation, and queries. Integer arithmetics and\nvarious built-in predicates are also supported.\n  In addition DLV has several frontends, namely brave and cautious reasoning,\nabductive diagnosis, consistency-based diagnosis, a subset of SQL3, planning\nwith action languages, and logic programming with inheritance.",
    "published": "2000-03-08T18:17:33Z",
    "link": "http://arxiv.org/pdf/cs/0003036v1.pdf",
    "category": [
      "cs.AI",
      "cs.LO",
      "D.1.6; D.3.2; I.2.4; F.4.1"
    ],
    "authors": [
      "Thomas Eiter",
      "Wolfgang Faber",
      "Christoph Koch",
      "Nicola Leone",
      "Gerald Pfeifer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003038v1",
    "title": "A Splitting Set Theorem for Epistemic Specifications",
    "summary": "Over the past decade a considerable amount of research has been done to\nexpand logic programming languages to handle incomplete information. One such\nlanguage is the language of epistemic specifications. As is usual with logic\nprogramming languages, the problem of answering queries is intractable in the\ngeneral case. For extended disjunctive logic programs, an idea that has proven\nuseful in simplifying the investigation of answer sets is the use of splitting\nsets. In this paper we will present an extended definition of splitting sets\nthat will be applicable to epistemic specifications. Furthermore, an extension\nof the splitting set theorem will be presented. Also, a characterization of\nstratified epistemic specifications will be given in terms of splitting sets.\nThis characterization leads us to an algorithmic method of computing world\nviews of a subclass of epistemic logic programs.",
    "published": "2000-03-08T20:40:31Z",
    "link": "http://arxiv.org/pdf/cs/0003038v1.pdf",
    "category": [
      "cs.AI",
      "F.4.1; I.2.3"
    ],
    "authors": [
      "Richard Watson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003040v1",
    "title": "Implementing Integrity Constraints in an Existing Belief Revision System",
    "summary": "SNePS is a mature knowledge representation, reasoning, and acting system that\nhas long contained a belief revision subsystem, called SNeBR. SNeBR is\ntriggered when an explicit contradiction is introduced into the SNePS belief\nspace, either because of a user's new assertion, or because of a user's query.\nSNeBR then makes the user decide what belief to remove from the belief space in\norder to restore consistency, although it provides information to help the user\nin making that decision. We have recently added automatic belief revision to\nSNeBR, by which, under certain circumstances, SNeBR decides by itself which\nbelief to remove, and then informs the user of the decision and its\nconsequences. We have used the well-known belief revision integrity constraints\nas a guide in designing automatic belief revision, taking into account,\nhowever, that SNePS's belief space is not deductively closed, and that it would\nbe infeasible to form the deductive closure in order to decide what belief to\nremove. This paper briefly describes SNeBR both before and after this revision,\ndiscusses how we adapted the integrity constraints for this purpose, and gives\nan example of the new SNeBR in action.",
    "published": "2000-03-08T20:42:29Z",
    "link": "http://arxiv.org/pdf/cs/0003040v1.pdf",
    "category": [
      "cs.AI",
      "cs.LO",
      "I.2.3;I.2.4"
    ],
    "authors": [
      "Frances L. Johnson",
      "Stuart C. Shapiro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003039v1",
    "title": "DES: a Challenge Problem for Nonmonotonic Reasoning Systems",
    "summary": "The US Data Encryption Standard, DES for short, is put forward as an\ninteresting benchmark problem for nonmonotonic reasoning systems because (i) it\nprovides a set of test cases of industrial relevance which shares features of\nrandomly generated problems and real-world problems, (ii) the representation of\nDES using normal logic programs with the stable model semantics is simple and\neasy to understand, and (iii) this subclass of logic programs can be seen as an\ninteresting special case for many other formalizations of nonmonotonic\nreasoning. In this paper we present two encodings of DES as logic programs: a\ndirect one out of the standard specifications and an optimized one extending\nthe work of Massacci and Marraro. The computational properties of the encodings\nare studied by using them for DES key search with the Smodels system as the\nimplementation of the stable model semantics. Results indicate that the\nencodings and Smodels are quite competitive: they outperform state-of-the-art\nSAT-checkers working with an optimized encoding of DES into SAT and are\ncomparable with a SAT-checker that is customized and tuned for the optimized\nSAT encoding.",
    "published": "2000-03-08T21:49:57Z",
    "link": "http://arxiv.org/pdf/cs/0003039v1.pdf",
    "category": [
      "cs.AI",
      "I.2.3; I.2.4"
    ],
    "authors": [
      "Maarit Hietalahti",
      "Fabio Massacci",
      "Ilkka Niemela"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003033v1",
    "title": "Smodels: A System for Answer Set Programming",
    "summary": "The Smodels system implements the stable model semantics for normal logic\nprograms. It handles a subclass of programs which contain no function symbols\nand are domain-restricted but supports extensions including built-in functions\nas well as cardinality and weight constraints. On top of this core engine more\ninvolved systems can be built. As an example, we have implemented total and\npartial stable model computation for disjunctive logic programs. An interesting\napplication method is based on answer set programming, i.e., encoding an\napplication problem as a set of rules so that its solutions are captured by the\nstable models of the rules. Smodels has been applied to a number of areas\nincluding planning, model checking, reachability analysis, product\nconfiguration, dynamic constraint satisfaction, and feature interaction.",
    "published": "2000-03-08T23:25:51Z",
    "link": "http://arxiv.org/pdf/cs/0003033v1.pdf",
    "category": [
      "cs.AI",
      "I.2.3; I.2.4"
    ],
    "authors": [
      "Ilkka Niemela",
      "Patrik Simons",
      "Tommi Syrjanen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003041v1",
    "title": "Coherence, Belief Expansion and Bayesian Networks",
    "summary": "We construct a probabilistic coherence measure for information sets which\ndetermines a partial coherence ordering. This measure is applied in\nconstructing a criterion for expanding our beliefs in the face of new\ninformation. A number of idealizations are being made which can be relaxed by\nan appeal to Bayesian Networks.",
    "published": "2000-03-08T23:34:52Z",
    "link": "http://arxiv.org/pdf/cs/0003041v1.pdf",
    "category": [
      "cs.AI",
      "cs.LO",
      "F.4.0; G.3"
    ],
    "authors": [
      "Luc Bovens",
      "Stephan Hartmann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003042v1",
    "title": "Fages' Theorem and Answer Set Programming",
    "summary": "We generalize a theorem by Francois Fages that describes the relationship\nbetween the completion semantics and the answer set semantics for logic\nprograms with negation as failure. The study of this relationship is important\nin connection with the emergence of answer set programming. Whenever the two\nsemantics are equivalent, answer sets can be computed by a satisfiability\nsolver, and the use of answer set solvers such as smodels and dlv is\nunnecessary. A logic programming representation of the blocks world due to\nIlkka Niemelae is discussed as an example.",
    "published": "2000-03-09T00:28:21Z",
    "link": "http://arxiv.org/pdf/cs/0003042v1.pdf",
    "category": [
      "cs.AI",
      "I.2.4"
    ],
    "authors": [
      "Yuliya Babovich",
      "Esra Erdem",
      "Vladimir Lifschitz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003044v1",
    "title": "On the tractable counting of theory models and its application to belief\n  revision and truth maintenance",
    "summary": "We introduced decomposable negation normal form (DNNF) recently as a\ntractable form of propositional theories, and provided a number of powerful\nlogical operations that can be performed on it in polynomial time. We also\npresented an algorithm for compiling any conjunctive normal form (CNF) into\nDNNF and provided a structure-based guarantee on its space and time complexity.\nWe present in this paper a linear-time algorithm for converting an ordered\nbinary decision diagram (OBDD) representation of a propositional theory into an\nequivalent DNNF, showing that DNNFs scale as well as OBDDs. We also identify a\nsubclass of DNNF which we call deterministic DNNF, d-DNNF, and show that the\nprevious complexity guarantees on compiling DNNF continue to hold for this\nstricter subclass, which has stronger properties. In particular, we present a\nnew operation on d-DNNF which allows us to count its models under the\nassertion, retraction and flipping of every literal by traversing the d-DNNF\ntwice. That is, after such traversal, we can test in constant-time: the\nentailment of any literal by the d-DNNF, and the consistency of the d-DNNF\nunder the retraction or flipping of any literal. We demonstrate the\nsignificance of these new operations by showing how they allow us to implement\nlinear-time, complete truth maintenance systems and linear-time, complete\nbelief revision systems for two important classes of propositional theories.",
    "published": "2000-03-09T08:58:15Z",
    "link": "http://arxiv.org/pdf/cs/0003044v1.pdf",
    "category": [
      "cs.AI",
      "I.2.3"
    ],
    "authors": [
      "Adnan Darwiche"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003046v1",
    "title": "Linear Tabulated Resolution Based on Prolog Control Strategy",
    "summary": "Infinite loops and redundant computations are long recognized open problems\nin Prolog. Two ways have been explored to resolve these problems: loop checking\nand tabling. Loop checking can cut infinite loops, but it cannot be both sound\nand complete even for function-free logic programs. Tabling seems to be an\neffective way to resolve infinite loops and redundant computations. However,\nexisting tabulated resolutions, such as OLDT-resolution, SLG- resolution, and\nTabulated SLS-resolution, are non-linear because they rely on the\nsolution-lookup mode in formulating tabling. The principal disadvantage of\nnon-linear resolutions is that they cannot be implemented using a simple\nstack-based memory structure like that in Prolog. Moreover, some strictly\nsequential operators such as cuts may not be handled as easily as in Prolog.\n  In this paper, we propose a hybrid method to resolve infinite loops and\nredundant computations. We combine the ideas of loop checking and tabling to\nestablish a linear tabulated resolution called TP-resolution. TP-resolution has\ntwo distinctive features: (1) It makes linear tabulated derivations in the same\nway as Prolog except that infinite loops are broken and redundant computations\nare reduced. It handles cuts as effectively as Prolog. (2) It is sound and\ncomplete for positive logic programs with the bounded-term-size property. The\nunderlying algorithm can be implemented by an extension to any existing Prolog\nabstract machines such as WAM or ATOAM.",
    "published": "2000-03-09T17:11:39Z",
    "link": "http://arxiv.org/pdf/cs/0003046v1.pdf",
    "category": [
      "cs.AI",
      "cs.LO",
      "F.4.1; I.2.3"
    ],
    "authors": [
      "Yi-Dong Shen",
      "Li-Yan Yuan",
      "Jia-Huai You",
      "Neng-Fa Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003047v1",
    "title": "BDD-based reasoning in the fluent calculus - first results",
    "summary": "The paper reports on first preliminary results and insights gained in a\nproject aiming at implementing the fluent calculus using methods and techniques\nbased on binary decision diagrams. After reporting on an initial experiment\nshowing promising results we discuss our findings concerning various techniques\nand heuristics used to speed up the reasoning process.",
    "published": "2000-03-09T17:18:12Z",
    "link": "http://arxiv.org/pdf/cs/0003047v1.pdf",
    "category": [
      "cs.AI",
      "I.2.8; I.2.3; F.4.1"
    ],
    "authors": [
      "Steffen Hoelldobler",
      "Hans-Peter Stoerr"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003048v1",
    "title": "PAL: Pertinence Action Language",
    "summary": "The current document contains a brief description of a system for Reasoning\nabout Actions and Change called PAL (Pertinence Action Language) which makes\nuse of several reasoning properties extracted from a Temporal Expert Systems\ntool called Medtool.",
    "published": "2000-03-09T19:50:50Z",
    "link": "http://arxiv.org/pdf/cs/0003048v1.pdf",
    "category": [
      "cs.AI",
      "cs.LO",
      "I.2.4; F.4.1"
    ],
    "authors": [
      "Pedro Cabalar",
      "Manuel Cabarcos",
      "Ramon P. Otero"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003049v1",
    "title": "Planning with Incomplete Information",
    "summary": "Planning is a natural domain of application for frameworks of reasoning about\nactions and change. In this paper we study how one such framework, the Language\nE, can form the basis for planning under (possibly) incomplete information. We\ndefine two types of plans: weak and safe plans, and propose a planner, called\nthe E-Planner, which is often able to extend an initial weak plan into a safe\nplan even though the (explicit) information available is incomplete, e.g. for\ncases where the initial state is not completely known. The E-Planner is based\nupon a reformulation of the Language E in argumentation terms and a natural\nproof theory resulting from the reformulation. It uses an extension of this\nproof theory by means of abduction for the generation of plans and adopts\nargumentation-based techniques for extending weak plans into safe plans. We\nprovide representative examples illustrating the behaviour of the E-Planner, in\nparticular for cases where the status of fluents is incompletely known.",
    "published": "2000-03-09T22:30:27Z",
    "link": "http://arxiv.org/pdf/cs/0003049v1.pdf",
    "category": [
      "cs.AI",
      "I.2.3;I.2.4;I.2.8"
    ],
    "authors": [
      "Antonis Kakas",
      "Rob Miller",
      "Francesca Toni"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003050v1",
    "title": "A tableau methodology for deontic conditional logics",
    "summary": "In this paper we present a theorem proving methodology for a restricted but\nsignificant fragment of the conditional language made up of (boolean\ncombinations of) conditional statements with unnested antecedents. The method\nis based on the possible world semantics for conditional logics. The KEM label\nformalism, designed to account for the semantics of normal modal logics, is\neasily adapted to the semantics of conditional logics by simply indexing labels\nwith formulas. The inference rules are provided by the propositional system KE+\n- a tableau-like analytic proof system devised to be used both as a refutation\nand a direct method of proof - enlarged with suitable elimination rules for the\nconditional connective. The theorem proving methodology we are going to present\ncan be viewed as a first step towards developing an appropriate algorithmic\nframework for several conditional logics for (defeasible) conditional\nobligation.",
    "published": "2000-03-10T07:30:32Z",
    "link": "http://arxiv.org/pdf/cs/0003050v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "F.4.1; I.2.3; I.2.4"
    ],
    "authors": [
      "Alberto Artosi",
      "Guido Governatori"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003051v1",
    "title": "Local Diagnosis",
    "summary": "In an earlier work, we have presented operations of belief change which only\naffect the relevant part of a belief base. In this paper, we propose the\napplication of the same strategy to the problem of model-based diangosis. We\nfirst isolate the subset of the system description which is relevant for a\ngiven observation and then solve the diagnosis problem for this subset.",
    "published": "2000-03-10T22:54:55Z",
    "link": "http://arxiv.org/pdf/cs/0003051v1.pdf",
    "category": [
      "cs.AI",
      "I.2.4"
    ],
    "authors": [
      "Renata Wassermann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003052v3",
    "title": "A Consistency-Based Model for Belief Change: Preliminary Report",
    "summary": "We present a general, consistency-based framework for belief change.\nInformally, in revising K by A, we begin with A and incorporate as much of K as\nconsistently possible. Formally, a knowledge base K and sentence A are\nexpressed, via renaming propositions in K, in separate languages. Using a\nmaximization process, we assume the languages are the same insofar as\nconsistently possible. Lastly, we express the resultant knowledge base in a\nsingle language. There may be more than one way in which A can be so extended\nby K: in choice revision, one such ``extension'' represents the revised state;\nalternately revision consists of the intersection of all such extensions.\n  The most general formulation of our approach is flexible enough to express\nother approaches to revision and update, the merging of knowledge bases, and\nthe incorporation of static and dynamic integrity constraints. Our framework\ndiffers from work based on ordinal conditional functions, notably with respect\nto iterated revision. We argue that the approach is well-suited for\nimplementation: the choice revision operator gives better complexity results\nthan general revision; the approach can be expressed in terms of a finite\nknowledge base; and the scope of a revision can be restricted to just those\npropositions mentioned in the sentence for revision A.",
    "published": "2000-03-11T06:29:02Z",
    "link": "http://arxiv.org/pdf/cs/0003052v3.pdf",
    "category": [
      "cs.AI",
      "I.2.4"
    ],
    "authors": [
      "James Delgrande",
      "Torsten Schaub"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003056v1",
    "title": "A note on the Declarative reading(s) of Logic Programming",
    "summary": "This paper analyses the declarative readings of logic programming. Logic\nprogramming - and negation as failure - has no unique declarative reading. One\ncommon view is that logic programming is a logic for default reasoning, a\nsub-formalism of default logic or autoepistemic logic. In this view, negation\nas failure is a modal operator. In an alternative view, a logic program is\ninterpreted as a definition. In this view, negation as failure is classical\nobjective negation. From a commonsense point of view, there is definitely a\ndifference between these views. Surprisingly though, both types of declarative\nreadings lead to grosso modo the same model semantics. This note investigates\nthe causes for this.",
    "published": "2000-03-13T16:21:41Z",
    "link": "http://arxiv.org/pdf/cs/0003056v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "I.2.3;I.2.4;F.4.1"
    ],
    "authors": [
      "Marc Denecker"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003057v1",
    "title": "XNMR: A tool for knowledge bases exploration",
    "summary": "XNMR is a system designed to explore the results of combining the\nwell-founded semantics system XSB with the stable-models evaluator SMODELS. Its\nmain goal is to work as a tool for fast and interactive exploration of\nknowledge bases.",
    "published": "2000-03-13T23:18:12Z",
    "link": "http://arxiv.org/pdf/cs/0003057v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "D.1.6"
    ],
    "authors": [
      "L. Castro",
      "D. Warren"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003059v1",
    "title": "SATEN: An Object-Oriented Web-Based Revision and Extraction Engine",
    "summary": "SATEN is an object-oriented web-based extraction and belief revision engine.\nIt runs on any computer via a Java 1.1 enabled browser such as Netscape 4.\nSATEN performs belief revision based on the AGM approach. The extraction and\nbelief revision reasoning engines operate on a user specified ranking of\ninformation. One of the features of SATEN is that it can be used to integrate\nmutually inconsistent commensuate rankings into a consistent ranking.",
    "published": "2000-03-14T04:58:18Z",
    "link": "http://arxiv.org/pdf/cs/0003059v1.pdf",
    "category": [
      "cs.AI",
      "I.2.3"
    ],
    "authors": [
      "Mary-Anne Williams",
      "Aidan Sims"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003061v1",
    "title": "dcs: An Implementation of DATALOG with Constraints",
    "summary": "Answer-set programming (ASP) has emerged recently as a viable programming\nparadigm. We describe here an ASP system, DATALOG with constraints or DC, based\non non-monotonic logic. Informally, DC theories consist of propositional\nclauses (constraints) and of Horn rules. The semantics is a simple and natural\nextension of the semantics of the propositional logic. However, thanks to the\npresence of Horn rules in the system, modeling of transitive closure becomes\nstraightforward. We describe the syntax, use and implementation of DC and\nprovide experimental results.",
    "published": "2000-03-14T18:06:38Z",
    "link": "http://arxiv.org/pdf/cs/0003061v1.pdf",
    "category": [
      "cs.AI",
      "I.2.3;I.2.4;I.2.8;F.4.1;F.2.2"
    ],
    "authors": [
      "Deborah East",
      "Miroslaw Truszczynski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003067v1",
    "title": "Detecting Unsolvable Queries for Definite Logic Programs",
    "summary": "In solving a query, the SLD proof procedure for definite programs sometimes\nsearches an infinite space for a non existing solution. For example, querying a\nplanner for an unreachable goal state. Such programs motivate the development\nof methods to prove the absence of a solution. Considering the definite program\nand the query ``<- Q'' as clauses of a first order theory, one can apply model\ngenerators which search for a finite interpretation in which the program\nclauses as well as the clause ``false <- Q'' are true. This paper develops a\nnew approach which exploits the fact that all clauses are definite. It is based\non a goal directed abductive search in the space of finite pre-interpretations\nfor a pre-interpretation such that ``Q'' is false in the least model of the\nprogram based on it. Several methods for efficiently searching the space of\npre-interpretations are presented. Experimental results confirm that our\napproach find solutions with less search than with the use of a first order\nmodel generator.",
    "published": "2000-03-17T10:59:03Z",
    "link": "http://arxiv.org/pdf/cs/0003067v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "D.1.6; F.3.1; F.4.1"
    ],
    "authors": [
      "Maurice Bruynooghe",
      "Henk Vandecasteele",
      "D. Andre de Waal",
      "Marc Denecker"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003073v1",
    "title": "Proceedings of the 8th International Workshop on Non-Monotonic\n  Reasoning, NMR'2000",
    "summary": "The papers gathered in this collection were presented at the 8th\nInternational Workshop on Nonmonotonic Reasoning, NMR2000. The series was\nstarted by John McCarthy in 1978. The first international NMR workshop was held\nat Mohonk Mountain House, New Paltz, New York in June, 1984, and was organized\nby Ray Reiter and Bonnie Webber.\n  In the last 10 years the area of nonmonotonic reasoning has seen a number of\nimportant developments. Significant theoretical advances were made in the\nunderstanding of general abstract principles underlying nonmonotonicity. Key\nresults on the expressibility and computational complexity of nonmonotonic\nlogics were established. The role of nonmonotonic reasoning in belief revision,\nabduction, reasoning about action, planing and uncertainty was further\nclarified. Several successful NMR systems were built and used in applications\nsuch as planning, scheduling, logic programming and constraint satisfaction.\n  The papers in the proceedings reflect these recent advances in the field.\nThey are grouped into sections corresponding to special sessions as they were\nheld at the workshop:\n  1. General NMR track\n  2. Abductive reasonig\n  3. Belief revision: theory and practice\n  4. Representing action and planning\n  5. Systems descriptions and demonstrations\n  6. Uncertainty frameworks in NMR",
    "published": "2000-03-22T15:33:20Z",
    "link": "http://arxiv.org/pdf/cs/0003073v1.pdf",
    "category": [
      "cs.AI",
      "cs.LO",
      "I2.2;I2.3;I2.4;I2.8;F4.1"
    ],
    "authors": [
      "Chitta Baral",
      "Miroslaw Truszczynski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003076v2",
    "title": "Constraint Programming viewed as Rule-based Programming",
    "summary": "We study here a natural situation when constraint programming can be entirely\nreduced to rule-based programming. To this end we explain first how one can\ncompute on constraint satisfaction problems using rules represented by simple\nfirst-order formulas. Then we consider constraint satisfaction problems that\nare based on predefined, explicitly given constraints. To solve them we first\nderive rules from these explicitly given constraints and limit the computation\nprocess to a repeated application of these rules, combined with labeling.We\nconsider here two types of rules. The first type, that we call equality rules,\nleads to a new notion of local consistency, called {\\em rule consistency} that\nturns out to be weaker than arc consistency for constraints of arbitrary arity\n(called hyper-arc consistency in \\cite{MS98b}). For Boolean constraints rule\nconsistency coincides with the closure under the well-known propagation rules\nfor Boolean constraints. The second type of rules, that we call membership\nrules, yields a rule-based characterization of arc consistency. To show\nfeasibility of this rule-based approach to constraint programming we show how\nboth types of rules can be automatically generated, as {\\tt CHR} rules of\n\\cite{fruhwirth-constraint-95}. This yields an implementation of this approach\nto programming by means of constraint logic programming. We illustrate the\nusefulness of this approach to constraint programming by discussing various\nexamples, including Boolean constraints, two typical examples of many valued\nlogics, constraints dealing with Waltz's language for describing polyhedral\nscenes, and Allen's qualitative approach to temporal logic.",
    "published": "2000-03-24T16:12:22Z",
    "link": "http://arxiv.org/pdf/cs/0003076v2.pdf",
    "category": [
      "cs.AI",
      "cs.PL",
      "D.3.3;I.2.2;I.2.3"
    ],
    "authors": [
      "Krzysztof R. Apt",
      "Eric Monfroy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003077v1",
    "title": "DATALOG with constraints - an answer-set programming system",
    "summary": "Answer-set programming (ASP) has emerged recently as a viable programming\nparadigm well attuned to search problems in AI, constraint satisfaction and\ncombinatorics. Propositional logic is, arguably, the simplest ASP system with\nan intuitive semantics supporting direct modeling of problem constraints.\nHowever, for some applications, especially those requiring that transitive\nclosure be computed, it requires additional variables and results in large\ntheories. Consequently, it may not be a practical computational tool for such\nproblems. On the other hand, ASP systems based on nonmonotonic logics, such as\nstable logic programming, can handle transitive closure computation efficiently\nand, in general, yield very concise theories as problem representations. Their\nsemantics is, however, more complex. Searching for the middle ground, in this\npaper we introduce a new nonmonotonic logic, DATALOG with constraints or DC.\nInformally, DC theories consist of propositional clauses (constraints) and of\nHorn rules. The semantics is a simple and natural extension of the semantics of\nthe propositional logic. However, thanks to the presence of Horn rules in the\nsystem, modeling of transitive closure becomes straightforward. We describe the\nsyntax and semantics of DC, and study its properties. We discuss an\nimplementation of DC and present results of experimental study of the\neffectiveness of DC, comparing it with CSAT, a satisfiability checker and\nSMODELS implementation of stable logic programming. Our results show that DC is\ncompetitive with the other two approaches, in case of many search problems,\noften yielding much more efficient solutions.",
    "published": "2000-03-24T19:09:59Z",
    "link": "http://arxiv.org/pdf/cs/0003077v1.pdf",
    "category": [
      "cs.AI",
      "D.1.6;F.2.2;F.4.2;I.2.8;I.6.5"
    ],
    "authors": [
      "Deborah East",
      "Miroslaw Truszczynski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003080v1",
    "title": "Some Remarks on Boolean Constraint Propagation",
    "summary": "We study here the well-known propagation rules for Boolean constraints. First\nwe propose a simple notion of completeness for sets of such rules and establish\na completeness result. Then we show an equivalence in an appropriate sense\nbetween Boolean constraint propagation and unit propagation, a form of\nresolution for propositional logic.\n  Subsequently we characterize one set of such rules by means of the notion of\nhyper-arc consistency introduced in (Mohr and Masini 1988). Also, we clarify\nthe status of a similar, though different, set of rules introduced in (Simonis\n1989a) and more fully in (Codognet and Diaz 1996).",
    "published": "2000-03-28T11:49:37Z",
    "link": "http://arxiv.org/pdf/cs/0003080v1.pdf",
    "category": [
      "cs.AI",
      "D.3.2;D.3.3"
    ],
    "authors": [
      "Krzysztof R. Apt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003082v1",
    "title": "Representation results for defeasible logic",
    "summary": "The importance of transformations and normal forms in logic programming, and\ngenerally in computer science, is well documented. This paper investigates\ntransformations and normal forms in the context of Defeasible Logic, a simple\nbut efficient formalism for nonmonotonic reasoning based on rules and\npriorities. The transformations described in this paper have two main benefits:\non one hand they can be used as a theoretical tool that leads to a deeper\nunderstanding of the formalism, and on the other hand they have been used in\nthe development of an efficient implementation of defeasible logic.",
    "published": "2000-03-30T02:23:21Z",
    "link": "http://arxiv.org/pdf/cs/0003082v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "F.4.1; I.2.3; I.2.4"
    ],
    "authors": [
      "G. Antoniou",
      "D. Billington",
      "G. Governatori",
      "M. J. Maher"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0004001v1",
    "title": "A Theory of Universal Artificial Intelligence based on Algorithmic\n  Complexity",
    "summary": "Decision theory formally solves the problem of rational agents in uncertain\nworlds if the true environmental prior probability distribution is known.\nSolomonoff's theory of universal induction formally solves the problem of\nsequence prediction for unknown prior distribution. We combine both ideas and\nget a parameterless theory of universal Artificial Intelligence. We give strong\narguments that the resulting AIXI model is the most intelligent unbiased agent\npossible. We outline for a number of problem classes, including sequence\nprediction, strategic games, function minimization, reinforcement and\nsupervised learning, how the AIXI model can formally solve them. The major\ndrawback of the AIXI model is that it is uncomputable. To overcome this\nproblem, we construct a modified algorithm AIXI-tl, which is still effectively\nmore intelligent than any other time t and space l bounded agent. The\ncomputation time of AIXI-tl is of the order tx2^l. Other discussed topics are\nformal definitions of intelligence order relations, the horizon problem and\nrelations of the AIXI theory to other AI approaches.",
    "published": "2000-04-03T06:16:16Z",
    "link": "http://arxiv.org/pdf/cs/0004001v1.pdf",
    "category": [
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "I.2; F.1.3; E.4"
    ],
    "authors": [
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0004002v1",
    "title": "Programming in Alma-0, or Imperative and Declarative Programming\n  Reconciled",
    "summary": "In (Apt et al, TOPLAS 1998) we introduced the imperative programming language\nAlma-0 that supports declarative programming. In this paper we illustrate the\nhybrid programming style of Alma-0 by means of various examples that complement\nthose presented in (Apt et al, TOPLAS 1998). The presented Alma-0 programs\nillustrate the versatility of the language and show that ``don't know''\nnondeterminism can be naturally combined with assignment.",
    "published": "2000-04-05T16:04:26Z",
    "link": "http://arxiv.org/pdf/cs/0004002v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "cs.PL",
      "D.3.2;F.3.2;F.3.3;I.2.8;I.5.5"
    ],
    "authors": [
      "Krzysztof R. Apt",
      "Andrea Schaerf"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0004003v2",
    "title": "Searching for Spaceships",
    "summary": "We describe software that searches for spaceships in Conway's Game of Life\nand related two-dimensional cellular automata. Our program searches through a\nstate space related to the de Bruijn graph of the automaton, using a method\nthat combines features of breadth first and iterative deepening search, and\nincludes fast bit-parallel graph reachability and path enumeration algorithms\nfor finding the successors of each state. Successful results include a new 2c/7\nspaceship in Life, found by searching a space with 2^126 states.",
    "published": "2000-04-10T20:55:55Z",
    "link": "http://arxiv.org/pdf/cs/0004003v2.pdf",
    "category": [
      "cs.AI",
      "nlin.CG",
      "I.2.8; F.1.1"
    ],
    "authors": [
      "David Eppstein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0004005v1",
    "title": "Exact Phase Transitions in Random Constraint Satisfaction Problems",
    "summary": "In this paper we propose a new type of random CSP model, called Model RB,\nwhich is a revision to the standard Model B. It is proved that phase\ntransitions from a region where almost all problems are satisfiable to a region\nwhere almost all problems are unsatisfiable do exist for Model RB as the number\nof variables approaches infinity. Moreover, the critical values at which the\nphase transitions occur are also known exactly. By relating the hardness of\nModel RB to Model B, it is shown that there exist a lot of hard instances in\nModel RB.",
    "published": "2000-04-16T07:13:09Z",
    "link": "http://arxiv.org/pdf/cs/0004005v1.pdf",
    "category": [
      "cs.AI",
      "cs.CC",
      "cs.DM",
      "I.2.8; G.3"
    ],
    "authors": [
      "Ke Xu",
      "Wei Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0005008v1",
    "title": "A Denotational Semantics for First-Order Logic",
    "summary": "In Apt and Bezem [AB99] (see cs.LO/9811017) we provided a computational\ninterpretation of first-order formulas over arbitrary interpretations. Here we\ncomplement this work by introducing a denotational semantics for first-order\nlogic. Additionally, by allowing an assignment of a non-ground term to a\nvariable we introduce in this framework logical variables.\n  The semantics combines a number of well-known ideas from the areas of\nsemantics of imperative programming languages and logic programming. In the\nresulting computational view conjunction corresponds to sequential composition,\ndisjunction to ``don't know'' nondeterminism, existential quantification to\ndeclaration of a local variable, and negation to the ``negation as finite\nfailure'' rule. The soundness result shows correctness of the semantics with\nrespect to the notion of truth. The proof resembles in some aspects the proof\nof the soundness of the SLDNF-resolution.",
    "published": "2000-05-08T12:23:07Z",
    "link": "http://arxiv.org/pdf/cs/0005008v1.pdf",
    "category": [
      "cs.PL",
      "cs.AI",
      "F.3.2; D.3.2"
    ],
    "authors": [
      "Krzysztof R. Apt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0005009v1",
    "title": "PSPACE Reasoning for Graded Modal Logics",
    "summary": "We present a PSPACE algorithm that decides satisfiability of the graded modal\nlogic Gr(K_R)---a natural extension of propositional modal logic K_R by\ncounting expressions---which plays an important role in the area of knowledge\nrepresentation. The algorithm employs a tableaux approach and is the first\nknown algorithm which meets the lower bound for the complexity of the problem.\nThus, we exactly fix the complexity of the problem and refute an\nExpTime-hardness conjecture. We extend the results to the logic Gr(K_(R \\cap\nI)), which augments Gr(K_R) with inverse relations and intersection of\naccessibility relations. This establishes a kind of ``theoretical benchmark''\nthat all algorithmic approaches can be measured against.",
    "published": "2000-05-08T14:51:58Z",
    "link": "http://arxiv.org/pdf/cs/0005009v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "cs.CC",
      "cs.DS",
      "F.4.1"
    ],
    "authors": [
      "Stephan Tobies"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0005010v1",
    "title": "Extending and Implementing the Stable Model Semantics",
    "summary": "An algorithm for computing the stable model semantics of logic programs is\ndeveloped. It is shown that one can extend the semantics and the algorithm to\nhandle new and more expressive types of rules. Emphasis is placed on the use of\nefficient implementation techniques. In particular, an implementation of\nlookahead that safely avoids testing every literal for failure and that makes\nthe use of lookahead feasible is presented. In addition, a good heuristic is\nderived from the principle that the search space should be minimized.\n  Due to the lack of competitive algorithms and implementations for the\ncomputation of stable models, the system is compared with three satisfiability\nsolvers. This shows that the heuristic can be improved by breaking ties, but\nleaves open the question of how to break them. It also demonstrates that the\nmore expressive rules of the stable model semantics make the semantics clearly\npreferable over propositional logic when a problem has a more compact logic\nprogram representation. Conjunctive normal form representations are never more\ncompact than logic program ones.",
    "published": "2000-05-08T18:26:54Z",
    "link": "http://arxiv.org/pdf/cs/0005010v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "I.2.3; I.2.8; F.4.1"
    ],
    "authors": [
      "Patrik Simons"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0005011v1",
    "title": "An Average Analysis of Backtracking on Random Constraint Satisfaction\n  Problems",
    "summary": "In this paper we propose a random CSP model, called Model GB, which is a\nnatural generalization of standard Model B. It is proved that Model GB in which\neach constraint is easy to satisfy exhibits non-trivial behaviour (not\ntrivially satisfiable or unsatisfiable) as the number of variables approaches\ninfinity. A detailed analysis to obtain an asymptotic estimate (good to 1+o(1))\nof the average number of nodes in a search tree used by the backtracking\nalgorithm on Model GB is also presented. It is shown that the average number of\nnodes required for finding all solutions or proving that no solution exists\ngrows exponentially with the number of variables. So this model might be an\ninteresting distribution for studying the nature of hard instances and\nevaluating the performance of CSP algorithms. In addition, we further\ninvestigate the behaviour of the average number of nodes as r (the ratio of\nconstraints to variables) varies. The results indicate that as r increases,\nrandom CSP instances get easier and easier to solve, and the base for the\naverage number of nodes that is exponential in r tends to 1 as r approaches\ninfinity. Therefore, although the average number of nodes used by the\nbacktracking algorithm on random CSP is exponential, many CSP instances will be\nvery easy to solve when r is sufficiently large.",
    "published": "2000-05-09T02:12:58Z",
    "link": "http://arxiv.org/pdf/cs/0005011v1.pdf",
    "category": [
      "cs.CC",
      "cs.AI",
      "F.2.2; I.2.8"
    ],
    "authors": [
      "Ke Xu",
      "Wei Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0005012v1",
    "title": "Reasoning with Axioms: Theory and Pratice",
    "summary": "When reasoning in description, modal or temporal logics it is often useful to\nconsider axioms representing universal truths in the domain of discourse.\nReasoning with respect to an arbitrary set of axioms is hard, even for\nrelatively inexpressive logics, and it is essential to deal with such axioms in\nan efficient manner if implemented systems are to be effective in real\napplications. This is particularly relevant to Description Logics, where\nsubsumption reasoning with respect to a terminology is a fundamental problem.\nTwo optimisation techniques that have proved to be particularly effective in\ndealing with terminologies are lazy unfolding and absorption. In this paper we\nseek to improve our theoretical understanding of these important techniques. We\ndefine a formal framework that allows the techniques to be precisely described,\nestablish conditions under which they can be safely applied, and prove that,\nprovided these conditions are respected, subsumption testing algorithms will\nstill function correctly. These results are used to show that the procedures\nused in the FaCT system are correct and, moreover, to show how efficiency can\nbe significantly improved, while still retaining the guarantee of correctness,\nby relaxing the safety conditions for absorption.",
    "published": "2000-05-09T07:17:29Z",
    "link": "http://arxiv.org/pdf/cs/0005012v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "F.4.1, I.2.3, I.2.4"
    ],
    "authors": [
      "Ian Horrocks",
      "Stephan Tobies"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0005013v1",
    "title": "Practical Reasoning for Very Expressive Description Logics",
    "summary": "Description Logics (DLs) are a family of knowledge representation formalisms\nmainly characterised by constructors to build complex concepts and roles from\natomic ones. Expressive role constructors are important in many applications,\nbut can be computationally problematical. We present an algorithm that decides\nsatisfiability of the DL ALC extended with transitive and inverse roles and\nfunctional restrictions with respect to general concept inclusion axioms and\nrole hierarchies; early experiments indicate that this algorithm is well-suited\nfor implementation. Additionally, we show that ALC extended with just\ntransitive and inverse roles is still in PSPACE. We investigate the limits of\ndecidability for this family of DLs, showing that relaxing the constraints\nplaced on the kinds of roles used in number restrictions leads to the\nundecidability of all inference problems. Finally, we describe a number of\noptimisation techniques that are crucial in obtaining implementations of the\ndecision procedures, which, despite the worst-case complexity of the problem,\nexhibit good performance with real-life problems.",
    "published": "2000-05-09T13:02:40Z",
    "link": "http://arxiv.org/pdf/cs/0005013v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "F.4.1, I.2.3, I.2.4"
    ],
    "authors": [
      "Ian Horrocks",
      "Ulrike Sattler",
      "Stephan Tobies"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0005014v1",
    "title": "Practical Reasoning for Expressive Description Logics",
    "summary": "Description Logics (DLs) are a family of knowledge representation formalisms\nmainly characterised by constructors to build complex concepts and roles from\natomic ones. Expressive role constructors are important in many applications,\nbut can be computationally problematical. We present an algorithm that decides\nsatisfiability of the DL ALC extended with transitive and inverse roles, role\nhierarchies, and qualifying number restrictions. Early experiments indicate\nthat this algorithm is well-suited for implementation. Additionally, we show\nthat ALC extended with just transitive and inverse roles is still in PSPACE.\nFinally, we investigate the limits of decidability for this family of DLs.",
    "published": "2000-05-10T08:19:41Z",
    "link": "http://arxiv.org/pdf/cs/0005014v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "F.4.1, I.2.3, I.2.4"
    ],
    "authors": [
      "Ian Horrocks",
      "Ulrike Sattler",
      "Stephan Tobies"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0005017v1",
    "title": "Reasoning with Individuals for the Description Logic SHIQ",
    "summary": "While there has been a great deal of work on the development of reasoning\nalgorithms for expressive description logics, in most cases only Tbox reasoning\nis considered. In this paper we present an algorithm for combined Tbox and Abox\nreasoning in the SHIQ description logic. This algorithm is of particular\ninterest as it can be used to decide the problem of (database) conjunctive\nquery containment w.r.t. a schema. Moreover, the realisation of an efficient\nimplementation should be relatively straightforward as it can be based on an\nexisting highly optimised implementation of the Tbox algorithm in the FaCT\nsystem.",
    "published": "2000-05-11T08:16:21Z",
    "link": "http://arxiv.org/pdf/cs/0005017v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "F.4.1, I.2.3, I.2.4"
    ],
    "authors": [
      "Ian Horrock",
      "Ulrike Sattler",
      "Stephan Tobies"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0005020v1",
    "title": "Centroid-based summarization of multiple documents: sentence extraction,\n  utility-based evaluation, and user studies",
    "summary": "We present a multi-document summarizer, called MEAD, which generates\nsummaries using cluster centroids produced by a topic detection and tracking\nsystem. We also describe two new techniques, based on sentence utility and\nsubsumption, which we have applied to the evaluation of both single and\nmultiple document summaries. Finally, we describe two user studies that test\nour models of multi-document summarization.",
    "published": "2000-05-12T17:24:06Z",
    "link": "http://arxiv.org/pdf/cs/0005020v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.DL",
      "cs.HC",
      "cs.IR",
      "H.3.1; H.3.4; H.3.7; H.5.2; I.2.7"
    ],
    "authors": [
      "Dragomir R. Radev",
      "Hongyan Jing",
      "Malgorzata Budzikowska"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0005021v1",
    "title": "Modeling the Uncertainty in Complex Engineering Systems",
    "summary": "Existing procedures for model validation have been deemed inadequate for many\nengineering systems. The reason of this inadequacy is due to the high degree of\ncomplexity of the mechanisms that govern these systems. It is proposed in this\npaper to shift the attention from modeling the engineering system itself to\nmodeling the uncertainty that underlies its behavior. A mathematical framework\nfor modeling the uncertainty in complex engineering systems is developed. This\nframework uses the results of computational learning theory. It is based on the\npremise that a system model is a learning machine.",
    "published": "2000-05-14T14:35:20Z",
    "link": "http://arxiv.org/pdf/cs/0005021v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "I.2.6;I.6.4;J.2;G.3"
    ],
    "authors": [
      "A. Guergachi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0005024v2",
    "title": "The SAT Phase Transition",
    "summary": "Phase transition is an important feature of SAT problem. For random k-SAT\nmodel, it is proved that as r (ratio of clauses to variables) increases, the\nstructure of solutions will undergo a sudden change like satisfiability phase\ntransition when r reaches a threshold point. This phenomenon shows that the\nsatisfying truth assignments suddenly shift from being relatively different\nfrom each other to being very similar to each other.",
    "published": "2000-05-22T04:45:53Z",
    "link": "http://arxiv.org/pdf/cs/0005024v2.pdf",
    "category": [
      "cs.AI",
      "cs.CC",
      "F.2.m; I.2.8"
    ],
    "authors": [
      "Ke Xu",
      "Wei Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/physics/0005062v1",
    "title": "Applying MDL to Learning Best Model Granularity",
    "summary": "The Minimum Description Length (MDL) principle is solidly based on a provably\nideal method of inference using Kolmogorov complexity. We test how the theory\nbehaves in practice on a general problem in model selection: that of learning\nthe best model granularity. The performance of a model depends critically on\nthe granularity, for example the choice of precision of the parameters. Too\nhigh precision generally involves modeling of accidental noise and too low\nprecision may lead to confusion of models that should be distinguished. This\nprecision is often determined ad hoc. In MDL the best model is the one that\nmost compresses a two-part code of the data set: this embodies ``Occam's\nRazor.'' In two quite different experimental settings the theoretical value\ndetermined using MDL coincides with the best value found experimentally. In the\nfirst experiment the task is to recognize isolated handwritten characters in\none subject's handwriting, irrespective of size and orientation. Based on a new\nmodification of elastic matching, using multiple prototypes per character, the\noptimal prediction rate is predicted for the learned parameter (length of\nsampling interval) considered most likely by MDL, which is shown to coincide\nwith the best value found experimentally. In the second experiment the task is\nto model a robot arm with two degrees of freedom using a three layer\nfeed-forward neural network where we need to determine the number of nodes in\nthe hidden layer giving best modeling performance. The optimal model (the one\nthat extrapolizes best on unseen examples) is predicted for the number of nodes\nin the hidden layer considered most likely by MDL, which again is found to\ncoincide with the best value found experimentally.",
    "published": "2000-05-23T14:50:07Z",
    "link": "http://arxiv.org/pdf/physics/0005062v1.pdf",
    "category": [
      "physics.data-an",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Qiong Gao",
      "Ming Li",
      "Paul Vitanyi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0005030v1",
    "title": "Axiomatizing Causal Reasoning",
    "summary": "Causal models defined in terms of a collection of equations, as defined by\nPearl, are axiomatized here. Axiomatizations are provided for three\nsuccessively more general classes of causal models: (1) the class of recursive\ntheories (those without feedback), (2) the class of theories where the\nsolutions to the equations are unique, (3) arbitrary theories (where the\nequations may not have solutions and, if they do, they are not necessarily\nunique). It is shown that to reason about causality in the most general third\nclass, we must extend the language used by Galles and Pearl. In addition, the\ncomplexity of the decision procedures is characterized for all the languages\nand classes of models considered.",
    "published": "2000-05-30T18:56:46Z",
    "link": "http://arxiv.org/pdf/cs/0005030v1.pdf",
    "category": [
      "cs.AI",
      "cs.LO",
      "I.2.4; F.4.1"
    ],
    "authors": [
      "Joseph Y. Halpern"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0005031v3",
    "title": "Conditional Plausibility Measures and Bayesian Networks",
    "summary": "A general notion of algebraic conditional plausibility measures is defined.\nProbability measures, ranking functions, possibility measures, and (under the\nappropriate definitions) sets of probability measures can all be viewed as\ndefining algebraic conditional plausibility measures. It is shown that\nalgebraic conditional plausibility measures can be represented using Bayesian\nnetworks.",
    "published": "2000-05-30T19:05:21Z",
    "link": "http://arxiv.org/pdf/cs/0005031v3.pdf",
    "category": [
      "cs.AI",
      "I.2.4"
    ],
    "authors": [
      "Joseph Y. Halpern"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0006009v1",
    "title": "Knowledge and common knowledge in a distributed environment",
    "summary": "Reasoning about knowledge seems to play a fundamental role in distributed\nsystems. Indeed, such reasoning is a central part of the informal intuitive\narguments used in the design of distributed protocols. Communication in a\ndistributed system can be viewed as the act of transforming the system's state\nof knowledge. This paper presents a general framework for formalizing and\nreasoning about knowledge in distributed systems. We argue that states of\nknowledge of groups of processors are useful concepts for the design and\nanalysis of distributed protocols. In particular, distributed knowledge\ncorresponds to knowledge that is ``distributed'' among the members of the\ngroup, while common knowledge corresponds to a fact being ``publicly known''.\nThe relationship between common knowledge and a variety of desirable actions in\na distributed system is illustrated. Furthermore, it is shown that, formally\nspeaking, in practical systems common knowledge cannot be attained. A number of\nweaker variants of common knowledge that are attainable in many cases of\ninterest are introduced and investigated.",
    "published": "2000-06-02T18:43:33Z",
    "link": "http://arxiv.org/pdf/cs/0006009v1.pdf",
    "category": [
      "cs.DC",
      "cs.AI",
      "C.2.2, C.2.4, D.2.4, I.2.4, F.3.1, F.3.1"
    ],
    "authors": [
      "Joseph Y. Halpern",
      "Yoram Moses"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0006013v1",
    "title": "An evaluation of Naive Bayesian anti-spam filtering",
    "summary": "It has recently been argued that a Naive Bayesian classifier can be used to\nfilter unsolicited bulk e-mail (\"spam\"). We conduct a thorough evaluation of\nthis proposal on a corpus that we make publicly available, contributing towards\nstandard benchmarks. At the same time we investigate the effect of\nattribute-set size, training-corpus size, lemmatization, and stop-lists on the\nfilter's performance, issues that had not been previously explored. After\nintroducing appropriate cost-sensitive evaluation measures, we reach the\nconclusion that additional safety nets are needed for the Naive Bayesian\nanti-spam filter to be viable in practice.",
    "published": "2000-06-07T11:10:50Z",
    "link": "http://arxiv.org/pdf/cs/0006013v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "H.4.3; I.2.6; I.2.7; I.5.4; K.4.1"
    ],
    "authors": [
      "Ion Androutsopoulos",
      "John Koutsias",
      "Konstantinos V. Chandrinos",
      "George Paliouras",
      "Constantine D. Spyropoulos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0006031v1",
    "title": "Verifying Termination of General Logic Programs with Concrete Queries",
    "summary": "We introduce a method of verifying termination of logic programs with respect\nto concrete queries (instead of abstract query patterns). A necessary and\nsufficient condition is established and an algorithm for automatic verification\nis developed. In contrast to existing query pattern-based approaches, our\nmethod has the following features: (1) It applies to all general logic programs\nwith non-floundering queries. (2) It is very easy to automate because it does\nnot need to search for a level mapping or a model, nor does it need to compute\nan interargument relation based on additional mode or type information. (3) It\nbridges termination analysis with loop checking, the two problems that have\nbeen studied separately in the past despite their close technical relation with\neach other.",
    "published": "2000-06-21T17:30:30Z",
    "link": "http://arxiv.org/pdf/cs/0006031v1.pdf",
    "category": [
      "cs.AI",
      "cs.LO",
      "D.3.1; F.4.1; I.2.3"
    ],
    "authors": [
      "Yi-Dong Shen",
      "Li-Yan Yuan",
      "Jia-Huai You"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0006041v1",
    "title": "Using a Diathesis Model for Semantic Parsing",
    "summary": "This paper presents a semantic parsing approach for unrestricted texts.\nSemantic parsing is one of the major bottlenecks of Natural Language\nUnderstanding (NLU) systems and usually requires building expensive resources\nnot easily portable to other domains. Our approach obtains a case-role\nanalysis, in which the semantic roles of the verb are identified. In order to\ncover all the possible syntactic realisations of a verb, our system combines\ntheir argument structure with a set of general semantic labelled diatheses\nmodels. Combining them, the system builds a set of syntactic-semantic patterns\nwith their own role-case representation. Once the patterns are build, we use an\napproximate tree pattern-matching algorithm to identify the most reliable\npattern for a sentence. The pattern matching is performed between the\nsyntactic-semantic patterns and the feature-structure tree representing the\nmorphological, syntactical and semantic information of the analysed sentence.\nFor sentences assigned to the correct model, the semantic parsing system we are\npresenting identifies correctly more than 73% of possible semantic case-roles.",
    "published": "2000-06-29T07:44:16Z",
    "link": "http://arxiv.org/pdf/cs/0006041v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "I.2.7;I.5"
    ],
    "authors": [
      "Jordi Atserias",
      "Irene Castellon",
      "Montse Civit",
      "German Rigau"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0006042v1",
    "title": "Semantic Parsing based on Verbal Subcategorization",
    "summary": "The aim of this work is to explore new methodologies on Semantic Parsing for\nunrestricted texts. Our approach follows the current trends in Information\nExtraction (IE) and is based on the application of a verbal subcategorization\nlexicon (LEXPIR) by means of complex pattern recognition techniques. LEXPIR is\nframed on the theoretical model of the verbal subcategorization developed in\nthe Pirapides project.",
    "published": "2000-06-29T09:17:45Z",
    "link": "http://arxiv.org/pdf/cs/0006042v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "I.2.7;I.5"
    ],
    "authors": [
      "Jordi Atserias",
      "Irene Castellon",
      "Montse Civit",
      "German Rigau"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0006043v1",
    "title": "Constraint compiling into rules formalism constraint compiling into\n  rules formalism for dynamic CSPs computing",
    "summary": "In this paper we present a rule based formalism for filtering variables\ndomains of constraints. This formalism is well adapted for solving dynamic CSP.\nWe take diagnosis as an instance problem to illustrate the use of these rules.\nA diagnosis problem is seen like finding all the minimal sets of constraints to\nbe relaxed in the constraint network that models the device to be diagnosed",
    "published": "2000-06-30T10:25:06Z",
    "link": "http://arxiv.org/pdf/cs/0006043v1.pdf",
    "category": [
      "cs.AI",
      "F.4.1"
    ],
    "authors": [
      "S. Piechowiak",
      "J. Rodriguez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0007001v1",
    "title": "Constraint Exploration and Envelope of Simulation Trajectories",
    "summary": "The implicit theory that a simulation represents is precisely not in the\nindividual choices but rather in the 'envelope' of possible trajectories - what\nis important is the shape of the whole envelope. Typically a huge amount of\ncomputation is required when experimenting with factors bearing on the dynamics\nof a simulation to tease out what affects the shape of this envelope. In this\npaper we present a methodology aimed at systematically exploring this envelope.\nWe propose a method for searching for tendencies and proving their necessity\nrelative to a range of parameterisations of the model and agents' choices, and\nto the logic of the simulation language. The exploration consists of a forward\nchaining generation of the trajectories associated to and constrained by such a\nrange of parameterisations and choices. Additionally, we propose a\ncomputational procedure that helps implement this exploration by translating a\nMulti Agent System simulation into a constraint-based search over possible\ntrajectories by 'compiling' the simulation rules into a more specific form,\nnamely by partitioning the simulation rules using appropriate modularity in the\nsimulation. An example of this procedure is exhibited.\n  Keywords: Constraint Search, Constraint Logic Programming, Proof, Emergence,\nTendencies",
    "published": "2000-07-03T10:10:09Z",
    "link": "http://arxiv.org/pdf/cs/0007001v1.pdf",
    "category": [
      "cs.PL",
      "cs.AI",
      "cs.LO",
      "D.3.3; F.3.1; F.4.1"
    ],
    "authors": [
      "Oswaldo Teran",
      "Bruce Edmonds",
      "Steve Wallis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0007002v2",
    "title": "Interval Constraint Solving for Camera Control and Motion Planning",
    "summary": "Many problems in robust control and motion planning can be reduced to either\nfind a sound approximation of the solution space determined by a set of\nnonlinear inequalities, or to the ``guaranteed tuning problem'' as defined by\nJaulin and Walter, which amounts to finding a value for some tuning parameter\nsuch that a set of inequalities be verified for all the possible values of some\nperturbation vector. A classical approach to solve these problems, which\nsatisfies the strong soundness requirement, involves some quantifier\nelimination procedure such as Collins' Cylindrical Algebraic Decomposition\nsymbolic method. Sound numerical methods using interval arithmetic and local\nconsistency enforcement to prune the search space are presented in this paper\nas much faster alternatives for both soundly solving systems of nonlinear\ninequalities, and addressing the guaranteed tuning problem whenever the\nperturbation vector has dimension one. The use of these methods in camera\ncontrol is investigated, and experiments with the prototype of a declarative\nmodeller to express camera motion using a cinematic language are reported and\ncommented.",
    "published": "2000-07-03T17:03:39Z",
    "link": "http://arxiv.org/pdf/cs/0007002v2.pdf",
    "category": [
      "cs.AI",
      "cs.NA",
      "math.NA",
      "D.3.3;D.2.2;G.1.0;H.5.1"
    ],
    "authors": [
      "Frederic Benhamou",
      "Frederic Goualard",
      "Eric Languenou",
      "Marc Christie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0007004v1",
    "title": "Brainstorm/J: a Java Framework for Intelligent Agents",
    "summary": "Despite the effort of many researchers in the area of multi-agent systems\n(MAS) for designing and programming agents, a few years ago the research\ncommunity began to take into account that common features among different MAS\nexists. Based on these common features, several tools have tackled the problem\nof agent development on specific application domains or specific types of\nagents. As a consequence, their scope is restricted to a subset of the huge\napplication domain of MAS. In this paper we propose a generic infrastructure\nfor programming agents whose name is Brainstorm/J. The infrastructure has been\nimplemented as an object oriented framework. As a consequence, our approach\nsupports a broader scope of MAS applications than previous efforts, being\nflexible and reusable.",
    "published": "2000-07-04T16:31:40Z",
    "link": "http://arxiv.org/pdf/cs/0007004v1.pdf",
    "category": [
      "cs.AI",
      "I.2.11"
    ],
    "authors": [
      "Alejandro Zunino",
      "Analia Amandi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0007010v1",
    "title": "Boosting Applied to Word Sense Disambiguation",
    "summary": "In this paper Schapire and Singer's AdaBoost.MH boosting algorithm is applied\nto the Word Sense Disambiguation (WSD) problem. Initial experiments on a set of\n15 selected polysemous words show that the boosting approach surpasses Naive\nBayes and Exemplar-based approaches, which represent state-of-the-art accuracy\non supervised WSD. In order to make boosting practical for a real learning\ndomain of thousands of words, several ways of accelerating the algorithm by\nreducing the feature space are studied. The best variant, which we call\nLazyBoosting, is tested on the largest sense-tagged corpus available containing\n192,800 examples of the 191 most frequent and ambiguous English words. Again,\nboosting compares favourably to the other benchmark algorithms.",
    "published": "2000-07-07T14:10:05Z",
    "link": "http://arxiv.org/pdf/cs/0007010v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "I.2.7;I.2.6"
    ],
    "authors": [
      "Gerard Escudero",
      "Lluis Marquez",
      "German Rigau"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0007011v1",
    "title": "Naive Bayes and Exemplar-Based approaches to Word Sense Disambiguation\n  Revisited",
    "summary": "This paper describes an experimental comparison between two standard\nsupervised learning methods, namely Naive Bayes and Exemplar-based\nclassification, on the Word Sense Disambiguation (WSD) problem. The aim of the\nwork is twofold. Firstly, it attempts to contribute to clarify some confusing\ninformation about the comparison between both methods appearing in the related\nliterature. In doing so, several directions have been explored, including:\ntesting several modifications of the basic learning algorithms and varying the\nfeature space. Secondly, an improvement of both algorithms is proposed, in\norder to deal with large attribute sets. This modification, which basically\nconsists in using only the positive information appearing in the examples,\nallows to improve greatly the efficiency of the methods, with no loss in\naccuracy. The experiments have been performed on the largest sense-tagged\ncorpus available containing the most frequent and ambiguous English words.\nResults show that the Exemplar-based approach to WSD is generally superior to\nthe Bayesian approach, especially when a specific metric for dealing with\nsymbolic attributes is used.",
    "published": "2000-07-07T15:00:44Z",
    "link": "http://arxiv.org/pdf/cs/0007011v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "I.2.7;I.2.6"
    ],
    "authors": [
      "Gerard Escudero",
      "Lluis Marquez",
      "German Rigau"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0007012v1",
    "title": "Using Learning-based Filters to Detect Rule-based Filtering Obsolescence",
    "summary": "For years, Caisse des Depots et Consignations has produced information\nfiltering applications. To be operational, these applications require high\nfiltering performances which are achieved by using rule-based filters. With\nthis technique, an administrator has to tune a set of rules for each topic.\nHowever, filters become obsolescent over time. The decrease of their\nperformances is due to diachronic polysemy of terms that involves a loss of\nprecision and to diachronic polymorphism of concepts that involves a loss of\nrecall.\n  To help the administrator to maintain his filters, we have developed a method\nwhich automatically detects filtering obsolescence. It consists in making a\nlearning-based control filter using a set of documents which have already been\ncategorised as relevant or not relevant by the rule-based filter. The idea is\nto supervise this filter by processing a differential comparison of its\noutcomes with those of the control one.\n  This method has many advantages. It is simple to implement since the training\nset used by the learning is supplied by the rule-based filter. Thus, both the\nmaking and the use of the control filter are fully automatic. With automatic\ndetection of obsolescence, learning-based filtering finds a rich application\nwhich offers interesting prospects.",
    "published": "2000-07-07T15:13:09Z",
    "link": "http://arxiv.org/pdf/cs/0007012v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "H.3.3; I.2.6"
    ],
    "authors": [
      "Francis Wolinski",
      "Frantz Vichot",
      "Mathieu Stricker"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0007016v1",
    "title": "Two Steps Feature Selection and Neural Network Classification for the\n  TREC-8 Routing",
    "summary": "For the TREC-8 routing, one specific filter is built for each topic. Each\nfilter is a classifier trained to recognize the documents that are relevant to\nthe topic. When presented with a document, each classifier estimates the\nprobability for the document to be relevant to the topic for which it has been\ntrained. Since the procedure for building a filter is topic-independent, the\nsystem is fully automatic.\n  By making use of a sample of documents that have previously been evaluated as\nrelevant or not relevant to a particular topic, a term selection is performed,\nand a neural network is trained. Each document is represented by a vector of\nfrequencies of a list of selected terms. This list depends on the topic to be\nfiltered; it is constructed in two steps. The first step defines the\ncharacteristic words used in the relevant documents of the corpus; the second\none chooses, among the previous list, the most discriminant ones. The length of\nthe vector is optimized automatically for each topic. At the end of the term\nselection, a vector of typically 25 words is defined for the topic, so that\neach document which has to be processed is represented by a vector of term\nfrequencies.\n  This vector is subsequently input to a classifier that is trained from the\nsame sample. After training, the classifier estimates for each document of a\ntest set its probability of being relevant; for submission to TREC, the top\n1000 documents are ranked in order of decreasing relevance.",
    "published": "2000-07-11T13:21:03Z",
    "link": "http://arxiv.org/pdf/cs/0007016v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "H.3.3; K.3.2"
    ],
    "authors": [
      "Mathieu Stricker",
      "Frantz Vichot",
      "Gerard Dreyfus",
      "Francis Wolinski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0007020v2",
    "title": "Polynomial-time Computation via Local Inference Relations",
    "summary": "We consider the concept of a local set of inference rules. A local rule set\ncan be automatically transformed into a rule set for which bottom-up evaluation\nterminates in polynomial time. The local-rule-set transformation gives\npolynomial-time evaluation strategies for a large variety of rule sets that\ncannot be given terminating evaluation strategies by any other known automatic\ntechnique. This paper discusses three new results. First, it is shown that\nevery polynomial-time predicate can be defined by an (unstratified) local rule\nset. Second, a new machine-recognizable subclass of the local rule sets is\nidentified. Finally we show that locality, as a property of rule sets, is\nundecidable in general.",
    "published": "2000-07-13T17:19:43Z",
    "link": "http://arxiv.org/pdf/cs/0007020v2.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "cs.PL",
      "I.2.2; I.2.3; I.2.4; F.4.m"
    ],
    "authors": [
      "Robert Givan",
      "David McAllester"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0007026v1",
    "title": "Integrating E-Commerce and Data Mining: Architecture and Challenges",
    "summary": "We show that the e-commerce domain can provide all the right ingredients for\nsuccessful data mining and claim that it is a killer domain for data mining. We\ndescribe an integrated architecture, based on our expe-rience at Blue Martini\nSoftware, for supporting this integration. The architecture can dramatically\nreduce the pre-processing, cleaning, and data understanding effort often\ndocumented to take 80% of the time in knowledge discovery projects. We\nemphasize the need for data collection at the application server layer (not the\nweb server) in order to support logging of data and metadata that is essential\nto the discovery process. We describe the data transformation bridges required\nfrom the transaction processing systems and customer event streams (e.g.,\nclickstreams) to the data warehouse. We detail the mining workbench, which\nneeds to provide multiple views of the data through reporting, data mining\nalgorithms, visualization, and OLAP. We con-clude with a set of challenges.",
    "published": "2000-07-14T00:33:12Z",
    "link": "http://arxiv.org/pdf/cs/0007026v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.DB",
      "I.2.6;H.2.8"
    ],
    "authors": [
      "Suhail Ansari",
      "Ron Kohavi",
      "Llew Mason",
      "Zijian Zheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0007032v1",
    "title": "Knowledge on Treelike Spaces",
    "summary": "This paper presents a bimodal logic for reasoning about knowledge during\nknowledge acquisition. One of the modalities represents (effort during)\nnon-deterministic time and the other represents knowledge. The semantics of\nthis logic are tree-like spaces which are a generalization of semantics used\nfor modeling branching time and historical necessity. A finite system of axiom\nschemes is shown to be canonically complete for the formentioned spaces. A\ncharacterization of the satisfaction relation implies the small model property\nand decidability for this system.",
    "published": "2000-07-21T09:52:25Z",
    "link": "http://arxiv.org/pdf/cs/0007032v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "F.4.1;I.2.0"
    ],
    "authors": [
      "Konstantinos Georgatos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0007033v1",
    "title": "To Preference via Entrenchment",
    "summary": "We introduce a simple generalization of Gardenfors and Makinson's epistemic\nentrenchment called partial entrenchment. We show that preferential inference\ncan be generated as the sceptical counterpart of an inference mechanism defined\ndirectly on partial entrenchment.",
    "published": "2000-07-21T10:16:47Z",
    "link": "http://arxiv.org/pdf/cs/0007033v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "F.4.1;I.2.3"
    ],
    "authors": [
      "Konstantinos Georgatos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0007038v1",
    "title": "Modal Logics for Topological Spaces",
    "summary": "In this thesis we shall present two logical systems, MP and MP, for the\npurpose of reasoning about knowledge and effort. These logical systems will be\ninterpreted in a spatial context and therefore, the abstract concepts of\nknowledge and effort will be defined by concrete mathematical concepts.",
    "published": "2000-07-26T18:41:17Z",
    "link": "http://arxiv.org/pdf/cs/0007038v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "F.4.1"
    ],
    "authors": [
      "Konstantinos Georgatos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0007039v1",
    "title": "Ordering-based Representations of Rational Inference",
    "summary": "Rational inference relations were introduced by Lehmann and Magidor as the\nideal systems for drawing conclusions from a conditional base. However, there\nhas been no simple characterization of these relations, other than its original\nrepresentation by preferential models. In this paper, we shall characterize\nthem with a class of total preorders of formulas by improving and extending\nGardenfors and Makinson's results for expectation inference relations. A second\nrepresentation is application-oriented and is obtained by considering a class\nof consequence operators that grade sets of defaults according to our reliance\non them. The finitary fragment of this class of consequence operators has been\nemployed by recent default logic formalisms based on maxiconsistency.",
    "published": "2000-07-26T18:58:09Z",
    "link": "http://arxiv.org/pdf/cs/0007039v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "F.4.1;I.2.3"
    ],
    "authors": [
      "Konstantinos Georgatos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0007040v1",
    "title": "Entrenchment Relations: A Uniform Approach to Nonmonotonicity",
    "summary": "We show that Gabbay's nonmonotonic consequence relations can be reduced to a\nnew family of relations, called entrenchment relations. Entrenchment relations\nprovide a direct generalization of epistemic entrenchment and expectation\nordering introduced by Gardenfors and Makinson for the study of belief revision\nand expectation inference, respectively.",
    "published": "2000-07-26T19:20:35Z",
    "link": "http://arxiv.org/pdf/cs/0007040v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "F.4.1;I.2.3"
    ],
    "authors": [
      "Konstantinos Georgatos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0008008v2",
    "title": "On the Average Similarity Degree between Solutions of Random k-SAT and\n  Random CSPs",
    "summary": "To study the structure of solutions for random k-SAT and random CSPs, this\npaper introduces the concept of average similarity degree to characterize how\nsolutions are similar to each other. It is proved that under certain\nconditions, as r (i.e. the ratio of constraints to variables) increases, the\nlimit of average similarity degree when the number of variables approaches\ninfinity exhibits phase transitions at a threshold point, shifting from a\nsmaller value to a larger value abruptly. For random k-SAT this phenomenon will\noccur when k>4 . It is further shown that this threshold point is also a\nsingular point with respect to r in the asymptotic estimate of the second\nmoment of the number of solutions. Finally, we discuss how this work is helpful\nto understand the hardness of solving random instances and a possible\napplication of it to the design of search algorithms.",
    "published": "2000-08-11T08:10:25Z",
    "link": "http://arxiv.org/pdf/cs/0008008v2.pdf",
    "category": [
      "cs.AI",
      "cs.CC",
      "cs.DM",
      "F.2.2; I.2.8"
    ],
    "authors": [
      "Ke Xu",
      "Wei Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0008016v1",
    "title": "Processing Self Corrections in a speech to speech system",
    "summary": "Speech repairs occur often in spontaneous spoken dialogues. The ability to\ndetect and correct those repairs is necessary for any spoken language system.\nWe present a framework to detect and correct speech repairs where all relevant\nlevels of information, i.e., acoustics, lexis, syntax and semantics can be\nintegrated. The basic idea is to reduce the search space for repairs as soon as\npossible by cascading filters that involve more and more features. At first an\nacoustic module generates hypotheses about the existence of a repair. Second a\nstochastic model suggests a correction for every hypothesis. Well scored\ncorrections are inserted as new paths in the word lattice. Finally a lattice\nparser decides on accepting the rep air.",
    "published": "2000-08-21T10:54:11Z",
    "link": "http://arxiv.org/pdf/cs/0008016v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "I 2.7"
    ],
    "authors": [
      "Joerg Spilker",
      "Martin Klarner",
      "Guenther Goerz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0008020v1",
    "title": "Explaining away ambiguity: Learning verb selectional preference with\n  Bayesian networks",
    "summary": "This paper presents a Bayesian model for unsupervised learning of verb\nselectional preferences. For each verb the model creates a Bayesian network\nwhose architecture is determined by the lexical hierarchy of Wordnet and whose\nparameters are estimated from a list of verb-object pairs found from a corpus.\n``Explaining away'', a well-known property of Bayesian networks, helps the\nmodel deal in a natural fashion with word sense ambiguity in the training data.\nOn a word sense disambiguation test our model performed better than other state\nof the art systems for unsupervised learning of selectional preferences.\nComputational complexity problems, ways of improving this approach and methods\nfor implementing ``explaining away'' in other graphical frameworks are\ndiscussed.",
    "published": "2000-08-22T15:01:21Z",
    "link": "http://arxiv.org/pdf/cs/0008020v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "authors": [
      "Massimiliano Ciaramita",
      "Mark Johnson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0009012v1",
    "title": "Modeling Ambiguity in a Multi-Agent System",
    "summary": "This paper investigates the formal pragmatics of ambiguous expressions by\nmodeling ambiguity in a multi-agent system. Such a framework allows us to give\na more refined notion of the kind of information that is conveyed by ambiguous\nexpressions. We analyze how ambiguity affects the knowledge of the dialog\nparticipants and, especially, what they know about each other after an\nambiguous sentence has been uttered. The agents communicate with each other by\nmeans of a TELL-function, whose application is constrained by an implementation\nof some of Grice's maxims. The information states of the multi-agent system\nitself are represented as a Kripke structures and TELL is an update function on\nthose structures. This framework enables us to distinguish between the\ninformation conveyed by ambiguous sentences vs. the information conveyed by\ndisjunctions, and between semantic ambiguity vs. perceived ambiguity.",
    "published": "2000-09-19T15:43:18Z",
    "link": "http://arxiv.org/pdf/cs/0009012v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.MA",
      "F.4.1; I.2.7"
    ],
    "authors": [
      "Christof Monz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0009016v1",
    "title": "Contextual Inference in Computational Semantics",
    "summary": "In this paper, an application of automated theorem proving techniques to\ncomputational semantics is considered. In order to compute the presuppositions\nof a natural language discourse, several inference tasks arise. Instead of\ntreating these inferences independently of each other, we show how integrating\ntechniques from formal approaches to context into deduction can help to compute\npresuppositions more efficiently. Contexts are represented as Discourse\nRepresentation Structures and the way they are nested is made explicit. In\naddition, a tableau calculus is present which keeps track of contextual\ninformation, and thereby allows to avoid carrying out redundant inference steps\nas it happens in approaches that neglect explicit nesting of contexts.",
    "published": "2000-09-20T13:41:06Z",
    "link": "http://arxiv.org/pdf/cs/0009016v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "F.4.1; I.2.7"
    ],
    "authors": [
      "Christof Monz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0009017v1",
    "title": "A Tableau Calculus for Pronoun Resolution",
    "summary": "We present a tableau calculus for reasoning in fragments of natural language.\nWe focus on the problem of pronoun resolution and the way in which it\ncomplicates automated theorem proving for natural language processing. A method\nfor explicitly manipulating contextual information during deduction is\nproposed, where pronouns are resolved against this context during deduction. As\na result, pronoun resolution and deduction can be interleaved in such a way\nthat pronouns are only resolved if this is licensed by a deduction rule; this\nhelps us to avoid the combinatorial complexity of total pronoun disambiguation.",
    "published": "2000-09-21T14:49:19Z",
    "link": "http://arxiv.org/pdf/cs/0009017v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "F.4.1; I.2.7"
    ],
    "authors": [
      "Christof Monz",
      "Maarten de Rijke"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0009018v1",
    "title": "A Resolution Calculus for Dynamic Semantics",
    "summary": "This paper applies resolution theorem proving to natural language semantics.\nThe aim is to circumvent the computational complexity triggered by natural\nlanguage ambiguities like pronoun binding, by interleaving pronoun binding with\nresolution deduction. Therefore disambiguation is only applied to expression\nthat actually occur during derivations.",
    "published": "2000-09-21T15:21:01Z",
    "link": "http://arxiv.org/pdf/cs/0009018v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "F.4.1; I.2.7"
    ],
    "authors": [
      "Christof Monz",
      "Maarten de Rijke"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0009019v1",
    "title": "Computing Presuppositions by Contextual Reasoning",
    "summary": "This paper describes how automated deduction methods for natural language\nprocessing can be applied more efficiently by encoding context in a more\nelaborate way. Our work is based on formal approaches to context, and we\nprovide a tableau calculus for contextual reasoning. This is explained by\nconsidering an example from the problem area of presupposition projection.",
    "published": "2000-09-21T15:32:17Z",
    "link": "http://arxiv.org/pdf/cs/0009019v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "F.4.1; I.2.7"
    ],
    "authors": [
      "Christof Monz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0009022v1",
    "title": "A Comparison between Supervised Learning Algorithms for Word Sense\n  Disambiguation",
    "summary": "This paper describes a set of comparative experiments, including cross-corpus\nevaluation, between five alternative algorithms for supervised Word Sense\nDisambiguation (WSD), namely Naive Bayes, Exemplar-based learning, SNoW,\nDecision Lists, and Boosting. Two main conclusions can be drawn: 1) The\nLazyBoosting algorithm outperforms the other four state-of-the-art algorithms\nin terms of accuracy and ability to tune to new domains; 2) The domain\ndependence of WSD systems seems very strong and suggests that some kind of\nadaptation or tuning is required for cross-corpus application.",
    "published": "2000-09-22T15:02:26Z",
    "link": "http://arxiv.org/pdf/cs/0009022v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "I.2.7;I.2.6"
    ],
    "authors": [
      "Gerard Escudero",
      "Lluis Marquez",
      "German Rigau"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0009027v1",
    "title": "A Classification Approach to Word Prediction",
    "summary": "The eventual goal of a language model is to accurately predict the value of a\nmissing word given its context. We present an approach to word prediction that\nis based on learning a representation for each word as a function of words and\nlinguistics predicates in its context. This approach raises a few new questions\nthat we address. First, in order to learn good word representations it is\nnecessary to use an expressive representation of the context. We present a way\nthat uses external knowledge to generate expressive context representations,\nalong with a learning method capable of handling the large number of features\ngenerated this way that can, potentially, contribute to each prediction.\nSecond, since the number of words ``competing'' for each prediction is large,\nthere is a need to ``focus the attention'' on a smaller subset of these. We\nexhibit the contribution of a ``focus of attention'' mechanism to the\nperformance of the word predictor. Finally, we describe a large scale\nexperimental study in which the approach presented is shown to yield\nsignificant improvements in word prediction tasks.",
    "published": "2000-09-28T14:25:51Z",
    "link": "http://arxiv.org/pdf/cs/0009027v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.6;I.2.7"
    ],
    "authors": [
      "Yair Even-Zohar",
      "Dan Roth"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0010022v1",
    "title": "Noise-Tolerant Learning, the Parity Problem, and the Statistical Query\n  Model",
    "summary": "We describe a slightly sub-exponential time algorithm for learning parity\nfunctions in the presence of random classification noise. This results in a\npolynomial-time algorithm for the case of parity functions that depend on only\nthe first O(log n log log n) bits of input. This is the first known instance of\nan efficient noise-tolerant algorithm for a concept class that is provably not\nlearnable in the Statistical Query model of Kearns. Thus, we demonstrate that\nthe set of problems learnable in the statistical query model is a strict subset\nof those problems learnable in the presence of noise in the PAC model.\n  In coding-theory terms, what we give is a poly(n)-time algorithm for decoding\nlinear k by n codes in the presence of random noise for the case of k = c log n\nloglog n for some c > 0. (The case of k = O(log n) is trivial since one can\njust individually check each of the 2^k possible messages and choose the one\nthat yields the closest codeword.)\n  A natural extension of the statistical query model is to allow queries about\nstatistical properties that involve t-tuples of examples (as opposed to single\nexamples). The second result of this paper is to show that any class of\nfunctions learnable (strongly or weakly) with t-wise queries for t = O(log n)\nis also weakly learnable with standard unary queries. Hence this natural\nextension to the statistical query model does not increase the set of weakly\nlearnable functions.",
    "published": "2000-10-15T20:14:08Z",
    "link": "http://arxiv.org/pdf/cs/0010022v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.DS",
      "I.2.6"
    ],
    "authors": [
      "Avrim Blum",
      "Adam Kalai",
      "Hal Wasserman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0010023v1",
    "title": "Oracle Complexity and Nontransitivity in Pattern Recognition",
    "summary": "Different mathematical models of recognition processes are known. In the\npresent paper we consider a pattern recognition algorithm as an oracle\ncomputation on a Turing machine. Such point of view seems to be useful in\npattern recognition as well as in recursion theory. Use of recursion theory in\npattern recognition shows connection between a recognition algorithm comparison\nproblem and complexity problems of oracle computation. That is because in many\ncases we can take into account only the number of sign computations or in other\nwords volume of oracle information needed. Therefore, the problem of\nrecognition algorithm preference can be formulated as a complexity optimization\nproblem of oracle computation. Furthermore, introducing a certain \"natural\"\npreference relation on a set of recognizing algorithms, we discover it to be\nnontransitive. This relates to the well known nontransitivity paradox in\nprobability theory.\n  Keywords: Pattern Recognition, Recursion Theory, Nontransitivity, Preference\nRelation",
    "published": "2000-10-16T07:42:23Z",
    "link": "http://arxiv.org/pdf/cs/0010023v1.pdf",
    "category": [
      "cs.CC",
      "cs.AI",
      "cs.CV",
      "cs.DS",
      "F.2.2; F.4.1; I.2.10; I.5.2"
    ],
    "authors": [
      "Vadim Bulitko"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0010032v2",
    "title": "Super Logic Programs",
    "summary": "The Autoepistemic Logic of Knowledge and Belief (AELB) is a powerful\nnonmonotic formalism introduced by Teodor Przymusinski in 1994. In this paper,\nwe specialize it to a class of theories called `super logic programs'. We argue\nthat these programs form a natural generalization of standard logic programs.\nIn particular, they allow disjunctions and default negation of arbibrary\npositive objective formulas.\n  Our main results are two new and powerful characterizations of the static\nsemant ics of these programs, one syntactic, and one model-theoretic. The\nsyntactic fixed point characterization is much simpler than the fixed point\nconstruction of the static semantics for arbitrary AELB theories. The\nmodel-theoretic characterization via Kripke models allows one to construct\nfinite representations of the inherently infinite static expansions.\n  Both characterizations can be used as the basis of algorithms for query\nanswering under the static semantics. We describe a query-answering interpreter\nfor super programs which we developed based on the model-theoretic\ncharacterization and which is available on the web.",
    "published": "2000-10-25T13:32:51Z",
    "link": "http://arxiv.org/pdf/cs/0010032v2.pdf",
    "category": [
      "cs.AI",
      "cs.LO",
      "F.4.1; I.2.3; I.2.4"
    ],
    "authors": [
      "Stefan Brass",
      "Juergen Dix",
      "Teodor C. Przymusinski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0010037v1",
    "title": "On the relationship between fuzzy logic and four-valued relevance logic",
    "summary": "In fuzzy propositional logic, to a proposition a partial truth in [0,1] is\nassigned. It is well known that under certain circumstances, fuzzy logic\ncollapses to classical logic. In this paper, we will show that under dual\nconditions, fuzzy logic collapses to four-valued (relevance) logic, where\npropositions have truth-value true, false, unknown, or contradiction. As a\nconsequence, fuzzy entailment may be considered as ``in between'' four-valued\n(relevance) entailment and classical entailment.",
    "published": "2000-10-31T14:14:26Z",
    "link": "http://arxiv.org/pdf/cs/0010037v1.pdf",
    "category": [
      "cs.AI",
      "F.4.1;I.2.3;I.2.4"
    ],
    "authors": [
      "Umberto Straccia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0011007v1",
    "title": "Tree-gram Parsing: Lexical Dependencies and Structural Relations",
    "summary": "This paper explores the kinds of probabilistic relations that are important\nin syntactic disambiguation. It proposes that two widely used kinds of\nrelations, lexical dependencies and structural relations, have complementary\ndisambiguation capabilities. It presents a new model based on structural\nrelations, the Tree-gram model, and reports experiments showing that structural\nrelations should benefit from enrichment by lexical dependencies.",
    "published": "2000-11-06T13:56:42Z",
    "link": "http://arxiv.org/pdf/cs/0011007v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "I.2; K.3.2; J.5"
    ],
    "authors": [
      "Khalil Sima'an"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0011008v1",
    "title": "A Lambda-Calculus with letrec, case, constructors and non-determinism",
    "summary": "A non-deterministic call-by-need lambda-calculus \\calc with case,\nconstructors, letrec and a (non-deterministic) erratic choice, based on\nrewriting rules is investigated. A standard reduction is defined as a variant\nof left-most outermost reduction. The semantics is defined by contextual\nequivalence of expressions instead of using $\\alpha\\beta(\\eta)$-equivalence. It\nis shown that several program transformations are correct, for example all\n(deterministic) rules of the calculus, and in addition the rules for garbage\ncollection, removing indirections and unique copy.\n  This shows that the combination of a context lemma and a meta-rewriting on\nreductions using complete sets of commuting (forking, resp.) diagrams is a\nuseful and successful method for providing a semantics of a functional\nprogramming language and proving correctness of program transformations.",
    "published": "2000-11-06T14:52:33Z",
    "link": "http://arxiv.org/pdf/cs/0011008v1.pdf",
    "category": [
      "cs.PL",
      "cs.AI",
      "cs.SC",
      "F.4.1;D.3.2;I.2.2"
    ],
    "authors": [
      "Manfred Schmidt-Schau",
      "Michael Huber"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0011012v3",
    "title": "Causes and Explanations: A Structural-Model Approach, Part I: Causes",
    "summary": "We propose a new definition of actual cause, using structural equations to\nmodel counterfactuals. We show that the definition yields a plausible and\nelegant account of causation that handles well examples which have caused\nproblems for other definitions and resolves major difficulties in the\ntraditional account.",
    "published": "2000-11-07T23:21:38Z",
    "link": "http://arxiv.org/pdf/cs/0011012v3.pdf",
    "category": [
      "cs.AI",
      "I.2.4"
    ],
    "authors": [
      "Joseph Y. Halpern",
      "Judea Pearl"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0011030v1",
    "title": "Logic Programming Approaches for Representing and Solving Constraint\n  Satisfaction Problems: A Comparison",
    "summary": "Many logic programming based approaches can be used to describe and solve\ncombinatorial search problems. On the one hand there is constraint logic\nprogramming which computes a solution as an answer substitution to a query\ncontaining the variables of the constraint satisfaction problem. On the other\nhand there are systems based on stable model semantics, abductive systems, and\nfirst order logic model generators which compute solutions as models of some\ntheory. This paper compares these different approaches from the point of view\nof knowledge representation (how declarative are the programs) and from the\npoint of view of performance (how good are they at solving typical problems).",
    "published": "2000-11-21T13:56:21Z",
    "link": "http://arxiv.org/pdf/cs/0011030v1.pdf",
    "category": [
      "cs.AI",
      "I.2.3; I.2.4"
    ],
    "authors": [
      "Nikolay Pelov",
      "Emmanuel De Mot",
      "Marc Denecker"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0011042v1",
    "title": "Order-consistent programs are cautiously monotonic",
    "summary": "Some normal logic programs under the answer set (stable model) semantics lack\nthe appealing property of \"cautious monotonicity.\" That is, augmenting a\nprogram with one of its consequences may cause it to lose another of its\nconsequences. The syntactic condition of \"order-consistency\" was shown by Fages\nto guarantee existence of an answer set. This note establishes that\norder-consistent programs are not only consistent, but cautiously monotonic.\n  From this it follows that they are also \"cumulative.\" That is, augmenting an\norder-consistent with some of its consequences does not alter its consequences.\nIn fact, as we show, its answer sets remain unchanged.",
    "published": "2000-11-27T19:21:10Z",
    "link": "http://arxiv.org/pdf/cs/0011042v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "F.4.1;I.2.3"
    ],
    "authors": [
      "Hudson Turner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/quant-ph/0011122v2",
    "title": "Algorithmic Theories of Everything",
    "summary": "The probability distribution P from which the history of our universe is\nsampled represents a theory of everything or TOE. We assume P is formally\ndescribable. Since most (uncountably many) distributions are not, this imposes\na strong inductive bias. We show that P(x) is small for any universe x lacking\na short description, and study the spectrum of TOEs spanned by two Ps, one\nreflecting the most compact constructive descriptions, the other the fastest\nway of computing everything. The former derives from generalizations of\ntraditional computability, Solomonoff's algorithmic probability, Kolmogorov\ncomplexity, and objects more random than Chaitin's Omega, the latter from\nLevin's universal search and a natural resource-oriented postulate: the\ncumulative prior probability of all x incomputable within time t by this\noptimal algorithm should be 1/t. Between both Ps we find a universal\ncumulatively enumerable measure that dominates traditional enumerable measures;\nany such CEM must assign low probability to any universe lacking a short\nenumerating program. We derive P-specific consequences for evolving observers,\ninductive reasoning, quantum physics, philosophy, and the expected duration of\nour universe.",
    "published": "2000-11-30T14:23:55Z",
    "link": "http://arxiv.org/pdf/quant-ph/0011122v2.pdf",
    "category": [
      "quant-ph",
      "cs.AI",
      "cs.CC",
      "cs.LG",
      "hep-th",
      "math-ph",
      "math.MP",
      "physics.comp-ph"
    ],
    "authors": [
      "Juergen Schmidhuber"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0012004v1",
    "title": "Improving Performance of heavily loaded agents",
    "summary": "With the increase in agent-based applications, there are now agent systems\nthat support \\emph{concurrent} client accesses. The ability to process large\nvolumes of simultaneous requests is critical in many such applications. In such\na setting, the traditional approach of serving these requests one at a time via\nqueues (e.g. \\textsf{FIFO} queues, priority queues) is insufficient.\nAlternative models are essential to improve the performance of such\n\\emph{heavily loaded} agents. In this paper, we propose a set of\n\\emph{cost-based algorithms} to \\emph{optimize} and \\emph{merge} multiple\nrequests submitted to an agent. In order to merge a set of requests, one first\nneeds to identify commonalities among such requests. First, we provide an\n\\emph{application independent framework} within which an agent developer may\nspecify relationships (called \\emph{invariants}) between requests. Second, we\nprovide two algorithms (and various accompanying heuristics) which allow an\nagent to automatically rewrite requests so as to avoid redundant work---these\nalgorithms take invariants associated with the agent into account. Our\nalgorithms are independent of any specific agent framework. For an\nimplementation, we implemented both these algorithms on top of the \\impact\nagent development platform, and on top of a (non-\\impact) geographic database\nagent. Based on these implementations, we conducted experiments and show that\nour algorithms are considerably more efficient than methods that use the $A^*$\nalgorithm.",
    "published": "2000-12-11T10:17:36Z",
    "link": "http://arxiv.org/pdf/cs/0012004v1.pdf",
    "category": [
      "cs.MA",
      "cs.AI",
      "I.2.12;I.2.3;D.2.12;H.2.4"
    ],
    "authors": [
      "Fatma Ozcan",
      "VS Subrahmanian",
      "Juergen Dix"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0012010v1",
    "title": "The Role of Commutativity in Constraint Propagation Algorithms",
    "summary": "Constraint propagation algorithms form an important part of most of the\nconstraint programming systems. We provide here a simple, yet very general\nframework that allows us to explain several constraint propagation algorithms\nin a systematic way. In this framework we proceed in two steps. First, we\nintroduce a generic iteration algorithm on partial orderings and prove its\ncorrectness in an abstract setting. Then we instantiate this algorithm with\nspecific partial orderings and functions to obtain specific constraint\npropagation algorithms.\n  In particular, using the notions commutativity and semi-commutativity, we\nshow that the {\\tt AC-3}, {\\tt PC-2}, {\\tt DAC} and {\\tt DPC} algorithms for\nachieving (directional) arc consistency and (directional) path consistency are\ninstances of a single generic algorithm. The work reported here extends and\nsimplifies that of Apt \\citeyear{Apt99b}.",
    "published": "2000-12-15T14:04:28Z",
    "link": "http://arxiv.org/pdf/cs/0012010v1.pdf",
    "category": [
      "cs.PF",
      "cs.AI",
      "D.3.3;I.1.2;I.1.3"
    ],
    "authors": [
      "Krzysztof R. Apt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0012011v1",
    "title": "Towards a Universal Theory of Artificial Intelligence based on\n  Algorithmic Probability and Sequential Decision Theory",
    "summary": "Decision theory formally solves the problem of rational agents in uncertain\nworlds if the true environmental probability distribution is known.\nSolomonoff's theory of universal induction formally solves the problem of\nsequence prediction for unknown distribution. We unify both theories and give\nstrong arguments that the resulting universal AIXI model behaves optimal in any\ncomputable environment. The major drawback of the AIXI model is that it is\nuncomputable. To overcome this problem, we construct a modified algorithm\nAIXI^tl, which is still superior to any other time t and space l bounded agent.\nThe computation time of AIXI^tl is of the order t x 2^l.",
    "published": "2000-12-16T09:38:13Z",
    "link": "http://arxiv.org/pdf/cs/0012011v1.pdf",
    "category": [
      "cs.AI",
      "cs.CC",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "I.2; I.2.3; I.2.6; I.2.8; F.1.3; F.2"
    ],
    "authors": [
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0012020v1",
    "title": "Creativity and Delusions: A Neurocomputational Approach",
    "summary": "Thinking is one of the most interesting mental processes. Its complexity is\nsometimes simplified and its different manifestations are classified into\nnormal and abnormal, like the delusional and disorganized thought or the\ncreative one. The boundaries between these facets of thinking are fuzzy causing\ndifficulties in medical, academic, and philosophical discussions. Considering\nthe dopaminergic signal-to-noise neuronal modulation in the central nervous\nsystem, and the existence of semantic maps in human brain, a self-organizing\nneural network model was developed to unify the different thought processes\ninto a single neurocomputational substrate. Simulations were performed varying\nthe dopaminergic modulation and observing the different patterns that emerged\nat the semantic map. Assuming that the thought process is the total pattern\nelicited at the output layer of the neural network, the model shows how the\nnormal and abnormal thinking are generated and that there are no borders\nbetween their different manifestations. Actually, a continuum of different\nqualitative reasoning, ranging from delusion to disorganization of thought, and\npassing through the normal and the creative thinking, seems to be more\nplausible. The model is far from explaining the complexities of human thinking\nbut, at least, it seems to be a good metaphorical and unifying view of the many\nfacets of this phenomenon usually studied in separated settings.",
    "published": "2000-12-22T12:00:07Z",
    "link": "http://arxiv.org/pdf/cs/0012020v1.pdf",
    "category": [
      "cs.NE",
      "cs.AI",
      "I.5.1"
    ],
    "authors": [
      "Daniele Quintella Mendes",
      "Luis Alfredo Vidal de Carvalho"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0101014v1",
    "title": "On the problem of computing the well-founded semantics",
    "summary": "The well-founded semantics is one of the most widely studied and used\nsemantics of logic programs with negation. In the case of finite propositional\nprograms, it can be computed in polynomial time, more specifically, in\nO(|At(P)|size(P)) steps, where size(P) denotes the total number of occurrences\nof atoms in a logic program P. This bound is achieved by an algorithm\nintroduced by Van Gelder and known as the alternating-fixpoint algorithm.\nImproving on the alternating-fixpoint algorithm turned out to be difficult. In\nthis paper we study extensions and modifications of the alternating-fixpoint\napproach. We then restrict our attention to the class of programs whose rules\nhave no more than one positive occurrence of an atom in their bodies. For\nprograms in that class we propose a new implementation of the\nalternating-fixpoint method in which false atoms are computed in a top-down\nfashion. We show that our algorithm is faster than other known algorithms and\nthat for a wide class of programs it is linear and so, asymptotically optimal.",
    "published": "2001-01-17T13:33:12Z",
    "link": "http://arxiv.org/pdf/cs/0101014v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "cs.DS",
      "I.2.3; F.2.2"
    ],
    "authors": [
      "Zbigniew Lonc",
      "Miroslaw Truszczynski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0101019v2",
    "title": "General Loss Bounds for Universal Sequence Prediction",
    "summary": "The Bayesian framework is ideally suited for induction problems. The\nprobability of observing $x_t$ at time $t$, given past observations\n$x_1...x_{t-1}$ can be computed with Bayes' rule if the true distribution $\\mu$\nof the sequences $x_1x_2x_3...$ is known. The problem, however, is that in many\ncases one does not even have a reasonable estimate of the true distribution. In\norder to overcome this problem a universal distribution $\\xi$ is defined as a\nweighted sum of distributions $\\mu_i\\inM$, where $M$ is any countable set of\ndistributions including $\\mu$. This is a generalization of Solomonoff\ninduction, in which $M$ is the set of all enumerable semi-measures. Systems\nwhich predict $y_t$, given $x_1...x_{t-1}$ and which receive loss $l_{x_t y_t}$\nif $x_t$ is the true next symbol of the sequence are considered. It is proven\nthat using the universal $\\xi$ as a prior is nearly as good as using the\nunknown true distribution $\\mu$. Furthermore, games of chance, defined as a\nsequence of bets, observations, and rewards are studied. The time needed to\nreach the winning zone is bounded in terms of the relative entropy of $\\mu$ and\n$\\xi$. Extensions to arbitrary alphabets, partial and delayed prediction, and\nmore active systems are discussed.",
    "published": "2001-01-21T17:19:37Z",
    "link": "http://arxiv.org/pdf/cs/0101019v2.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "math.ST",
      "stat.TH",
      "I.2; I.2.6; I.2.8; F.1.3"
    ],
    "authors": [
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0101036v1",
    "title": "The Generalized Universal Law of Generalization",
    "summary": "It has been argued by Shepard that there is a robust psychological law that\nrelates the distance between a pair of items in psychological space and the\nprobability that they will be confused with each other. Specifically, the\nprobability of confusion is a negative exponential function of the distance\nbetween the pair of items. In experimental contexts, distance is typically\ndefined in terms of a multidimensional Euclidean space-but this assumption\nseems unlikely to hold for complex stimuli. We show that, nonetheless, the\nUniversal Law of Generalization can be derived in the more complex setting of\narbitrary stimuli, using a much more universal measure of distance. This\nuniversal distance is defined as the length of the shortest program that\ntransforms the representations of the two items of interest into one another:\nthe algorithmic information distance. It is universal in the sense that it\nminorizes every computable distance: it is the smallest computable distance. We\nshow that the universal law of generalization holds with probability going to\none-provided the confusion probabilities are computable. We also give a\nmathematically more appealing form",
    "published": "2001-01-29T17:54:50Z",
    "link": "http://arxiv.org/pdf/cs/0101036v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "math.PR",
      "physics.soc-ph",
      "J.4"
    ],
    "authors": [
      "Nick Chater",
      "Paul Vitanyi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0102014v1",
    "title": "On the predictability of Rainfall in Kerala- An application of ABF\n  Neural Network",
    "summary": "Rainfall in Kerala State, the southern part of Indian Peninsula in particular\nis caused by the two monsoons and the two cyclones every year. In general,\nclimate and rainfall are highly nonlinear phenomena in nature giving rise to\nwhat is known as the `butterfly effect'. We however attempt to train an ABF\nneural network on the time series rainfall data and show for the first time\nthat in spite of the fluctuations resulting from the nonlinearity in the\nsystem, the trends in the rainfall pattern in this corner of the globe have\nremained unaffected over the past 87 years from 1893 to 1980. We also\nsuccessfully filter out the chaotic part of the system and illustrate that its\neffects are marginal over long term predictions.",
    "published": "2001-02-18T19:17:18Z",
    "link": "http://arxiv.org/pdf/cs/0102014v1.pdf",
    "category": [
      "cs.NE",
      "cs.AI",
      "A0"
    ],
    "authors": [
      "Ninan Sajeeth Philip",
      "K. Babu Joseph"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0102018v1",
    "title": "An effective Procedure for Speeding up Algorithms",
    "summary": "The provably asymptotically fastest algorithm within a factor of 5 for\nformally described problems will be constructed. The main idea is to enumerate\nall programs provably equivalent to the original problem by enumerating all\nproofs. The algorithm could be interpreted as a generalization and improvement\nof Levin search, which is, within a multiplicative constant, the fastest\nalgorithm for inverting functions. Blum's speed-up theorem is avoided by taking\ninto account only programs for which a correctness proof exists. Furthermore,\nit is shown that the fastest program that computes a certain function is also\none of the shortest programs provably computing this function. To quantify this\nstatement, the definition of Kolmogorov complexity is extended, and two new\nnatural measures for the complexity of a function are defined.",
    "published": "2001-02-21T20:52:28Z",
    "link": "http://arxiv.org/pdf/cs/0102018v1.pdf",
    "category": [
      "cs.CC",
      "cs.AI",
      "cs.LG",
      "F.2.3"
    ],
    "authors": [
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0102027v3",
    "title": "Gene Expression Programming: a New Adaptive Algorithm for Solving\n  Problems",
    "summary": "Gene expression programming, a genotype/phenotype genetic algorithm (linear\nand ramified), is presented here for the first time as a new technique for the\ncreation of computer programs. Gene expression programming uses character\nlinear chromosomes composed of genes structurally organized in a head and a\ntail. The chromosomes function as a genome and are subjected to modification by\nmeans of mutation, transposition, root transposition, gene transposition, gene\nrecombination, and one- and two-point recombination. The chromosomes encode\nexpression trees which are the object of selection. The creation of these\nseparate entities (genome and expression tree) with distinct functions allows\nthe algorithm to perform with high efficiency that greatly surpasses existing\nadaptive techniques. The suite of problems chosen to illustrate the power and\nversatility of gene expression programming includes symbolic regression,\nsequence induction with and without constant creation, block stacking, cellular\nautomata rules for the density-classification problem, and two problems of\nboolean concept learning: the 11-multiplexer and the GP rule problem.",
    "published": "2001-02-25T19:29:55Z",
    "link": "http://arxiv.org/pdf/cs/0102027v3.pdf",
    "category": [
      "cs.AI",
      "cs.NE",
      "I.2.2"
    ],
    "authors": [
      "Candida Ferreira"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0103002v1",
    "title": "Quantitative Neural Network Model of the Tip-of-the-Tongue Phenomenon\n  Based on Synthesized Memory-Psycholinguistic-Metacognitive Approach",
    "summary": "A new three-stage computer artificial neural network model of the\ntip-of-the-tongue phenomenon is proposed. Each word's node is build from some\ninterconnected learned auto-associative two-layer neural networks each of which\nrepresents separate word's semantic, lexical, or phonological components. The\nmodel synthesizes memory, psycholinguistic, and metamemory approaches, bridges\nspeech errors and naming chronometry research traditions, and can explain\nquantitatively many tip-of-the-tongue effects.",
    "published": "2001-03-02T00:20:01Z",
    "link": "http://arxiv.org/pdf/cs/0103002v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "q-bio.NC",
      "q-bio.QM",
      "I.2.7"
    ],
    "authors": [
      "Petro M. Gopych"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0103015v1",
    "title": "Fitness Uniform Selection to Preserve Genetic Diversity",
    "summary": "In evolutionary algorithms, the fitness of a population increases with time\nby mutating and recombining individuals and by a biased selection of more fit\nindividuals. The right selection pressure is critical in ensuring sufficient\noptimization progress on the one hand and in preserving genetic diversity to be\nable to escape from local optima on the other. We propose a new selection\nscheme, which is uniform in the fitness values. It generates selection pressure\ntowards sparsely populated fitness regions, not necessarily towards higher\nfitness, as is the case for all other selection schemes. We show that the new\nselection scheme can be much more effective than standard selection schemes.",
    "published": "2001-03-14T18:40:32Z",
    "link": "http://arxiv.org/pdf/cs/0103015v1.pdf",
    "category": [
      "cs.AI",
      "cs.DC",
      "cs.LG",
      "q-bio",
      "I.2; I.2.6; I.2.8; F.2"
    ],
    "authors": [
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0103020v1",
    "title": "Belief Revision: A Critique",
    "summary": "We examine carefully the rationale underlying the approaches to belief change\ntaken in the literature, and highlight what we view as methodological problems.\nWe argue that to study belief change carefully, we must be quite explicit about\nthe ``ontology'' or scenario underlying the belief change process. This is\nsomething that has been missing in previous work, with its focus on postulates.\nOur analysis shows that we must pay particular attention to two issues that\nhave often been taken for granted: The first is how we model the agent's\nepistemic state. (Do we use a set of beliefs, or a richer structure, such as an\nordering on worlds? And if we use a set of beliefs, in what language are these\nbeliefs are expressed?) We show that even postulates that have been called\n``beyond controversy'' are unreasonable when the agent's beliefs include\nbeliefs about her own epistemic state as well as the external world. The second\nis the status of observations. (Are observations known to be true, or just\nbelieved? In the latter case, how firm is the belief?) Issues regarding the\nstatus of observations arise particularly when we consider iterated belief\nrevision, and we must confront the possibility of revising by p and then by\nnot-p.",
    "published": "2001-03-27T20:33:51Z",
    "link": "http://arxiv.org/pdf/cs/0103020v1.pdf",
    "category": [
      "cs.AI",
      "cs.LO",
      "I.2.4, F.4.1"
    ],
    "authors": [
      "Nir Friedman",
      "Joseph Y. Halpern"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0104017v1",
    "title": "Local Search Techniques for Constrained Portfolio Selection Problems",
    "summary": "We consider the problem of selecting a portfolio of assets that provides the\ninvestor a suitable balance of expected return and risk. With respect to the\nseminal mean-variance model of Markowitz, we consider additional constraints on\nthe cardinality of the portfolio and on the quantity of individual shares. Such\nconstraints better capture the real-world trading system, but make the problem\nmore difficult to be solved with exact methods. We explore the use of local\nsearch techniques, mainly tabu search, for the portfolio selection problem. We\ncompare and combine previous work on portfolio selection that makes use of the\nlocal search approach and we propose new algorithms that combine different\nneighborhood relations. In addition, we show how the use of randomization and\nof a simple form of adaptiveness simplifies the setting of a large number of\ncritical parameters. Finally, we show how our techniques perform on public\nbenchmarks.",
    "published": "2001-04-18T13:42:49Z",
    "link": "http://arxiv.org/pdf/cs/0104017v1.pdf",
    "category": [
      "cs.CE",
      "cs.AI",
      "J.1; I.2.8"
    ],
    "authors": [
      "Andrea Schaerf"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0104020v1",
    "title": "Coaxing Confidences from an Old Friend: Probabilistic Classifications\n  from Transformation Rule Lists",
    "summary": "Transformation-based learning has been successfully employed to solve many\nnatural language processing problems. It has many positive features, but one\ndrawback is that it does not provide estimates of class membership\nprobabilities.\n  In this paper, we present a novel method for obtaining class membership\nprobabilities from a transformation-based rule list classifier. Three\nexperiments are presented which measure the modeling accuracy and cross-entropy\nof the probabilistic classifier on unseen data and the degree to which the\noutput probabilities from the classifier can be used to estimate confidences in\nits classification decisions.\n  The results of these experiments show that, for the task of text chunking,\nthe estimates produced by this technique are more informative than those\ngenerated by a state-of-the-art decision tree.",
    "published": "2001-04-27T23:16:21Z",
    "link": "http://arxiv.org/pdf/cs/0104020v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "authors": [
      "Radu Florian",
      "John C. Henderson",
      "Grace Ngai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0105003v1",
    "title": "Rule Writing or Annotation: Cost-efficient Resource Usage for Base Noun\n  Phrase Chunking",
    "summary": "This paper presents a comprehensive empirical comparison between two\napproaches for developing a base noun phrase chunker: human rule writing and\nactive learning using interactive real-time human annotation. Several novel\nvariations on active learning are investigated, and underlying cost models for\ncross-modal machine learning comparison are presented and explored. Results\nshow that it is more efficient and more successful by several measures to train\na system using active learning annotation rather than hand-crafted rule writing\nat a comparable level of human labor investment.",
    "published": "2001-05-02T08:39:32Z",
    "link": "http://arxiv.org/pdf/cs/0105003v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "authors": [
      "Grace Ngai",
      "David Yarowsky"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0105015v1",
    "title": "The alldifferent Constraint: A Survey",
    "summary": "The constraint of difference is known to the constraint programming community\nsince Lauriere introduced Alice in 1978. Since then, several solving strategies\nhave been designed for this constraint. In this paper we give both a practical\noverview and an abstract comparison of these different strategies.",
    "published": "2001-05-08T13:13:04Z",
    "link": "http://arxiv.org/pdf/cs/0105015v1.pdf",
    "category": [
      "cs.PL",
      "cs.AI",
      "D.3.3"
    ],
    "authors": [
      "W. J. van Hoeve"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0105017v1",
    "title": "Optimization Over Zonotopes and Training Support Vector Machines",
    "summary": "We make a connection between classical polytopes called zonotopes and Support\nVector Machine (SVM) classifiers. We combine this connection with the ellipsoid\nmethod to give some new theoretical results on training SVMs. We also describe\nsome special properties of soft margin C-SVMs as parameter C goes to infinity.",
    "published": "2001-05-08T21:07:43Z",
    "link": "http://arxiv.org/pdf/cs/0105017v1.pdf",
    "category": [
      "cs.CG",
      "cs.AI",
      "F.2.2; G.1.6; I.2.6; I.5.1"
    ],
    "authors": [
      "Marshall Bern",
      "David Eppstein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0105021v1",
    "title": "Solving Composed First-Order Constraints from Discrete-Time Robust\n  Control",
    "summary": "This paper deals with a problem from discrete-time robust control which\nrequires the solution of constraints over the reals that contain both universal\nand existential quantifiers. For solving this problem we formulate it as a\nprogram in a (fictitious) constraint logic programming language with explicit\nquantifier notation. This allows us to clarify the special structure of the\nproblem, and to extend an algorithm for computing approximate solution sets of\nfirst-order constraints over the reals to exploit this structure. As a result\nwe can deal with inputs that are clearly out of reach for current symbolic\nsolvers.",
    "published": "2001-05-11T08:28:33Z",
    "link": "http://arxiv.org/pdf/cs/0105021v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "cs.CE",
      "F.4.1;I.2.8"
    ],
    "authors": [
      "Stefan Ratschan",
      "Luc Jaulin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0105022v1",
    "title": "Multi-Channel Parallel Adaptation Theory for Rule Discovery",
    "summary": "In this paper, we introduce a new machine learning theory based on\nmulti-channel parallel adaptation for rule discovery. This theory is\ndistinguished from the familiar parallel-distributed adaptation theory of\nneural networks in terms of channel-based convergence to the target rules. We\nshow how to realize this theory in a learning system named CFRule. CFRule is a\nparallel weight-based model, but it departs from traditional neural computing\nin that its internal knowledge is comprehensible. Furthermore, when the model\nconverges upon training, each channel converges to a target rule. The model\nadaptation rule is derived by multi-level parallel weight optimization based on\ngradient descent. Since, however, gradient descent only guarantees local\noptimization, a multi-channel regression-based optimization strategy is\ndeveloped to effectively deal with this problem. Formally, we prove that the\nCFRule model can explicitly and precisely encode any given rule set. Also, we\nprove a property related to asynchronous parallel convergence, which is a\ncritical element of the multi-channel parallel adaptation theory for rule\nlearning. Thanks to the quantizability nature of the CFRule model, rules can be\nextracted completely and soundly via a threshold-based mechanism. Finally, the\npractical application of the theory is demonstrated in DNA promoter recognition\nand hepatitis prognosis prediction.",
    "published": "2001-05-11T14:17:42Z",
    "link": "http://arxiv.org/pdf/cs/0105022v1.pdf",
    "category": [
      "cs.AI",
      "I2.6"
    ],
    "authors": [
      "Li Min Fu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0105025v1",
    "title": "Market-Based Reinforcement Learning in Partially Observable Worlds",
    "summary": "Unlike traditional reinforcement learning (RL), market-based RL is in\nprinciple applicable to worlds described by partially observable Markov\nDecision Processes (POMDPs), where an agent needs to learn short-term memories\nof relevant previous events in order to execute optimal actions. Most previous\nwork, however, has focused on reactive settings (MDPs) instead of POMDPs. Here\nwe reimplement a recent approach to market-based RL and for the first time\nevaluate it in a toy POMDP setting.",
    "published": "2001-05-15T19:07:28Z",
    "link": "http://arxiv.org/pdf/cs/0105025v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "cs.NE",
      "I.2"
    ],
    "authors": [
      "Ivo Kwee",
      "Marcus Hutter",
      "Juergen Schmidhuber"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9404001v1",
    "title": "An Alternative Conception of Tree-Adjoining Derivation",
    "summary": "The precise formulation of derivation for tree-adjoining grammars has\nimportant ramifications for a wide variety of uses of the formalism, from\nsyntactic analysis to semantic interpretation and statistical language\nmodeling. We argue that the definition of tree-adjoining derivation must be\nreformulated in order to manifest the proper linguistic dependencies in\nderivations. The particular proposal is both precisely characterizable through\na definition of TAG derivations as equivalence classes of ordered derivation\ntrees, and computationally operational, by virtue of a compilation to linear\nindexed grammars together with an efficient algorithm for recognition and\nparsing according to the compiled grammar.",
    "published": "1994-04-04T02:59:51Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9404001v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Yves Schabes",
      "Stuart M. Shieber"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9404002v1",
    "title": "Lessons from a Restricted Turing Test",
    "summary": "We report on the recent Loebner prize competition inspired by Turing's test\nof intelligent behavior. The presentation covers the structure of the\ncompetition and the outcome of its first instantiation in an actual event, and\nan analysis of the purpose, design, and appropriateness of such a competition.\nWe argue that the competition has no clear purpose, that its design prevents\nany useful outcome, and that such a competition is inappropriate given the\ncurrent level of technology. We then speculate as to suitable alternatives to\nthe Loebner prize.",
    "published": "1994-04-04T03:05:08Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9404002v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Stuart M. Shieber"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9404003v2",
    "title": "Restricting the Weak-Generative Capacity of Synchronous Tree-Adjoining\n  Grammars",
    "summary": "The formalism of synchronous tree-adjoining grammars, a variant of standard\ntree-adjoining grammars (TAG), was intended to allow the use of TAGs for\nlanguage transduction in addition to language specification. In previous work,\nthe definition of the transduction relation defined by a synchronous TAG was\ngiven by appeal to an iterative rewriting process. The rewriting definition of\nderivation is problematic in that it greatly extends the expressivity of the\nformalism and makes the design of parsing algorithms difficult if not\nimpossible. We introduce a simple, natural definition of synchronous\ntree-adjoining derivation, based on isomorphisms between standard\ntree-adjoining derivations, that avoids the expressivity and implementability\nproblems of the original rewriting definition. The decrease in expressivity,\nwhich would otherwise make the method unusable, is offset by the incorporation\nof an alternative definition of standard tree-adjoining derivation, previously\nproposed for completely separate reasons, thereby making it practical to\nentertain using the natural definition of synchronous derivation. Nonetheless,\nsome remaining problematic cases call for yet more flexibility in the\ndefinition; the isomorphism requirement may have to be relaxed. It remains for\nfuture research to tune the exact requirements on the allowable mappings.",
    "published": "1994-04-04T03:07:42Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9404003v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Stuart M. Shieber"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9404004v1",
    "title": "An Empirically Motivated Reinterpretation of Dependency Grammar",
    "summary": "Dependency grammar is usually interpreted as equivalent to a strict form of\nX--bar theory that forbids the stacking of nodes of the same bar level (e.g.,\nN' immediately dominating N' with the same head). But adequate accounts of\n_one_--anaphora and of the semantics of multiple modifiers require such\nstacking and accordingly argue against dependency grammar. Dependency grammar\ncan be salvaged by reinterpreting its claims about phrase structure, so that\nmodifiers map onto binary--branching X--bar trees rather than ``flat'' ones.",
    "published": "1994-04-06T17:44:41Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9404004v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Michael A. Covington"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9404005v1",
    "title": "Memoization in Constraint Logic Programming",
    "summary": "This paper shows how to apply memoization (caching of subgoals and associated\nanswer substitutions) in a constraint logic programming setting. The research\nis is motivated by the desire to apply constraint logic programming (CLP) to\nproblems in natural language processing that involve (constraint) interleaving\nor coroutining, such as GB and HPSG parsing.",
    "published": "1994-04-11T17:22:40Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9404005v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Mark Johnson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9404006v1",
    "title": "SPANISH 1992 (S92): corpus-based analysis of present-day Spanish for\n  medical purposes",
    "summary": "S92 research was begun in 1987 to analyze word frequencies in present-day\nSpanish for making speech pathology evaluation tools. 500 2,000-word samples of\nchildren, adolescents and adults' language were input between 1988-1991,\ncalculations done in 1992; statistical and Lewandowski analyses were carried\nout in 1993.",
    "published": "1994-04-15T05:13:26Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9404006v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "R. M. CHANDLER-BURNS"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9404007v1",
    "title": "Constraint-Based Categorial Grammar",
    "summary": "We propose a generalization of Categorial Grammar in which lexical categories\nare defined by means of recursive constraints. In particular, the introduction\nof relational constraints allows one to capture the effects of (recursive)\nlexical rules in a computationally attractive manner. We illustrate the\nlinguistic merits of the new approach by showing how it accounts for the syntax\nof Dutch cross-serial dependencies and the position and scope of adjuncts in\nsuch constructions. Delayed evaluation is used to process grammars containing\nrecursive constraints.",
    "published": "1994-04-19T10:58:10Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9404007v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Gosse Bouma",
      "Gertjan van Noord"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9404008v1",
    "title": "Principles and Implementation of Deductive Parsing",
    "summary": "We present a system for generating parsers based directly on the metaphor of\nparsing as deduction. Parsing algorithms can be represented directly as\ndeduction systems, and a single deduction engine can interpret such deduction\nsystems so as to implement the corresponding parser. The method generalizes\neasily to parsers for augmented phrase structure formalisms, such as\ndefinite-clause grammars and other logic grammar formalisms, and has been used\nfor rapid prototyping of parsing algorithms for a variety of formalisms\nincluding variants of tree-adjoining grammars, categorial grammars, and\nlexicalized context-free grammars.",
    "published": "1994-04-26T21:00:49Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9404008v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Stuart M. Shieber",
      "Yves Schabes",
      "Fernando C. N. Pereira"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9404009v3",
    "title": "A Deductive Account of Quantification in LFG",
    "summary": "The relationship between Lexical-Functional Grammar (LFG) functional\nstructures (f-structures) for sentences and their semantic interpretations can\nbe expressed directly in a fragment of linear logic in a way that explains\ncorrectly the constrained interactions between quantifier scope ambiguity and\nbound anaphora. The use of a deductive framework to account for the\ncompositional properties of quantifying expressions in natural language\nobviates the need for additional mechanisms, such as Cooper storage, to\nrepresent the different scopes that a quantifier might take. Instead, the\nsemantic contribution of a quantifier is recorded as an ordinary logical\nformula, one whose use in a proof will establish the scope of the quantifier.\nThe properties of linear logic ensure that each quantifier is scoped exactly\nonce. Our analysis of quantifier scope can be seen as a recasting of Pereira's\nanalysis (Pereira, 1991), which was expressed in higher-order intuitionistic\nlogic. But our use of LFG and linear logic provides a much more direct and\ncomputationally more flexible interpretation mechanism for at least the same\nrange of phenomena. We have developed a preliminary Prolog implementation of\nthe linear deductions described in this work.",
    "published": "1994-04-27T15:26:24Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9404009v3.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Mary Dalrymple",
      "John Lamping",
      "Fernando Pereira",
      "Vijay Saraswat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9404010v2",
    "title": "Intensional Verbs Without Type-Raising or Lexical Ambiguity",
    "summary": "We present an analysis of the semantic interpretation of intensional verbs\nsuch as seek that allows them to take direct objects of either individual or\nquantifier type, producing both de dicto and de re readings in the quantifier\ncase, all without needing to stipulate type-raising or quantifying-in rules.\nThis simple account follows directly from our use of logical deduction in\nlinear logic to express the relationship between syntactic structures and\nmeanings. While our analysis resembles current categorial approaches in\nimportant ways, it differs from them in allowing the greater type flexibility\nof categorial semantics while maintaining a precise connection to syntax. As a\nresult, we are able to provide derivations for certain readings of sentences\nwith intensional verbs and complex direct objects that are not derivable in\ncurrent purely categorial accounts of the syntax-semantics interface. The\nanalysis forms a part of our ongoing work on semantic interpretation within the\nframework of Lexical-Functional Grammar.",
    "published": "1994-04-27T22:44:56Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9404010v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Mary Dalrymple",
      "John Lamping",
      "Fernando Pereira",
      "Vijay Saraswat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9404011v2",
    "title": "Adjuncts and the Processing of Lexical Rules",
    "summary": "The standard HPSG analysis of Germanic verb clusters can not explain the\nobserved narrow-scope readings of adjuncts in such verb clusters. We present an\nextension of the HPSG analysis that accounts for the systematic ambiguity of\nthe scope of adjuncts in verb cluster constructions, by treating adjuncts as\nmembers of the subcat list. The extension uses powerful recursive lexical\nrules, implemented as complex constraints. We show how `delayed evaluation'\ntechniques from constraint-logic programming can be used to process such\nlexical rules.",
    "published": "1994-04-28T09:59:15Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9404011v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Gertjan van Noord",
      "Gosse Bouma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405001v1",
    "title": "Similarity-Based Estimation of Word Cooccurrence Probabilities",
    "summary": "In many applications of natural language processing it is necessary to\ndetermine the likelihood of a given word combination. For example, a speech\nrecognizer may need to determine which of the two word combinations ``eat a\npeach'' and ``eat a beach'' is more likely. Statistical NLP methods determine\nthe likelihood of a word combination according to its frequency in a training\ncorpus. However, the nature of language is such that many word combinations are\ninfrequent and do not occur in a given corpus. In this work we propose a method\nfor estimating the probability of such previously unseen word combinations\nusing available information on ``most similar'' words. We describe a\nprobabilistic word association model based on distributional word similarity,\nand apply it to improving probability estimates for unseen word bigrams in a\nvariant of Katz's back-off model. The similarity-based method yields a 20%\nperplexity improvement in the prediction of unseen bigrams and statistically\nsignificant reductions in speech-recognition error.",
    "published": "1994-05-02T14:54:10Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405001v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Ido Dagan",
      "Fernando Pereira",
      "Lillian Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405002v1",
    "title": "Temporal Relations: Reference or Discourse Coherence?",
    "summary": "The temporal relations that hold between events described by successive\nutterances are often left implicit or underspecified. We address the role of\ntwo phenomena with respect to the recovery of these relations: (1) the\nreferential properties of tense, and (2) the role of temporal constraints\nimposed by coherence relations. We account for several facets of the\nidentification of temporal relations through an integration of these.",
    "published": "1994-05-02T20:37:25Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405002v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Andrew Kehler"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405003v1",
    "title": "Some Bibliographical References on Intonation and Intonational Meaning",
    "summary": "A by-no-means-complete collection of references for those interested in\nintonational meaning, with other miscellaneous references on intonation\nincluded. Additional references are welcome, and should be sent to\njulia@research.att.com.",
    "published": "1994-05-02T23:14:24Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405003v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Julia Hirschberg"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405004v1",
    "title": "Syntactic-Head-Driven Generation",
    "summary": "The previously proposed semantic-head-driven generation methods run into\nproblems if none of the daughter constituents in the syntacto-semantic rule\nschemata of a grammar fits the definition of a semantic head given in Shieber\net al. 1990. This is the case for the semantic analysis rules of certain\nconstraint-based semantic representations, e.g. Underspecified Discourse\nRepresentation Structures (UDRSs) (Frank/Reyle 1992). Since head-driven\ngeneration in general has its merits, we simply return to a syntactic\ndefinition of `head' and demonstrate the feasibility of syntactic-head-driven\ngeneration. In addition to its generality, a syntactic-head-driven algorithm\nprovides a basis for a logically well-defined treatment of the movement of\n(syntactic) heads, for which only ad-hoc solutions existed, so far.",
    "published": "1994-05-03T13:14:43Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405004v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Esther Koenig"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405009v2",
    "title": "Natural Language Parsing as Statistical Pattern Recognition",
    "summary": "Traditional natural language parsers are based on rewrite rule systems\ndeveloped in an arduous, time-consuming manner by grammarians. A majority of\nthe grammarian's efforts are devoted to the disambiguation process, first\nhypothesizing rules which dictate constituent categories and relationships\namong words in ambiguous sentences, and then seeking exceptions and corrections\nto these rules.\n  In this work, I propose an automatic method for acquiring a statistical\nparser from a set of parsed sentences which takes advantage of some initial\nlinguistic input, but avoids the pitfalls of the iterative and seemingly\nendless grammar development process. Based on distributionally-derived and\nlinguistically-based features of language, this parser acquires a set of\nstatistical decision trees which assign a probability distribution on the space\nof parse trees given the input sentence. These decision trees take advantage of\nsignificant amount of contextual information, potentially including all of the\nlexical information in the sentence, to produce highly accurate statistical\nmodels of the disambiguation process. By basing the disambiguation criteria\nselection on entropy reduction rather than human intuition, this parser\ndevelopment method is able to consider more sentences than a human grammarian\ncan when making individual disambiguation rules.\n  In experiments between a parser, acquired using this statistical framework,\nand a grammarian's rule-based parser, developed over a ten-year period, both\nusing the same training material and test sentences, the decision tree parser\nsignificantly outperformed the grammar-based parser on the accuracy measure\nwhich the grammarian was trying to maximize, achieving an accuracy of 78%\ncompared to the grammar-based parser's 69%.",
    "published": "1994-05-03T14:30:10Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405009v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "David M. Magerman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405005v1",
    "title": "Pearl: A Probabilistic Chart Parser",
    "summary": "This paper describes a natural language parsing algorithm for unrestricted\ntext which uses a probability-based scoring function to select the \"best\" parse\nof a sentence. The parser, Pearl, is a time-asynchronous bottom-up chart parser\nwith Earley-type top-down prediction which pursues the highest-scoring theory\nin the chart, where the score of a theory represents the extent to which the\ncontext of the sentence predicts that interpretation. This parser differs from\nprevious attempts at stochastic parsers in that it uses a richer form of\nconditional probabilities based on context to predict likelihood. Pearl also\nprovides a framework for incorporating the results of previous work in\npart-of-speech assignment, unknown word models, and other probabilistic models\nof linguistic features into one parsing tool, interleaving these techniques\ninstead of using the traditional pipeline architecture. In preliminary tests,\nPearl has been successful at resolving part-of-speech and word (in speech\nprocessing) ambiguity, determining categories for unknown words, and selecting\ncorrect parses first using a very loosely fitting covering grammar.",
    "published": "1994-05-03T14:43:09Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405005v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "David M. Magerman",
      "Mitchell P. Marcus"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405006v1",
    "title": "Efficiency, Robustness, and Accuracy in Picky Chart Parsing",
    "summary": "This paper describes Picky, a probabilistic agenda-based chart parsing\nalgorithm which uses a technique called {\\em probabilistic prediction} to\npredict which grammar rules are likely to lead to an acceptable parse of the\ninput. Using a suboptimal search method, Picky significantly reduces the number\nof edges produced by CKY-like chart parsing algorithms, while maintaining the\nrobustness of pure bottom-up parsers and the accuracy of existing probabilistic\nparsers. Experiments using Picky demonstrate how probabilistic modelling can\nimpact upon the efficiency, robustness and accuracy of a parser.",
    "published": "1994-05-03T14:51:01Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405006v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "David M. Magerman",
      "Carl Weir"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405007v1",
    "title": "Towards History-based Grammars: Using Richer Models for Probabilistic\n  Parsing",
    "summary": "We describe a generative probabilistic model of natural language, which we\ncall HBG, that takes advantage of detailed linguistic information to resolve\nambiguity. HBG incorporates lexical, syntactic, semantic, and structural\ninformation from the parse tree into the disambiguation process in a novel way.\nWe use a corpus of bracketed sentences, called a Treebank, in combination with\ndecision tree building to tease out the relevant aspects of a parse tree that\nwill determine the correct parse of a sentence. This stands in contrast to the\nusual approach of further grammar tailoring via the usual linguistic\nintrospection in the hope of generating the correct parse. In head-to-head\ntests against one of the best existing robust probabilistic parsing models,\nwhich we call P-CFG, the HBG model significantly outperforms P-CFG, increasing\nthe parsing accuracy rate from 60% to 75%, a 37% reduction in error.",
    "published": "1994-05-03T15:01:24Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405007v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Ezra Black",
      "Fred Jelinek",
      "John Lafferty",
      "David M. Magerman",
      "Robert Mercer",
      "Salim Roukos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405008v2",
    "title": "A Stochastic Finite-State Word-Segmentation Algorithm for Chinese",
    "summary": "We present a stochastic finite-state model for segmenting Chinese text into\ndictionary entries and productively derived words, and providing pronunciations\nfor these words; the method incorporates a class-based model in its treatment\nof personal names. We also evaluate the system's performance, taking into\naccount the fact that people often do not agree on a single segmentation.",
    "published": "1994-05-03T16:00:06Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405008v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Richard Sproat",
      "Chilin Shih",
      "William Gale",
      "Nancy Chang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405010v1",
    "title": "Common Topics and Coherent Situations: Interpreting Ellipsis in the\n  Context of Discourse Inference",
    "summary": "It is claimed that a variety of facts concerning ellipsis, event reference,\nand interclausal coherence can be explained by two features of the linguistic\nform in question: (1) whether the form leaves behind an empty constituent in\nthe syntax, and (2) whether the form is anaphoric in the semantics. It is\nproposed that these features interact with one of two types of discourse\ninference, namely {\\it Common Topic} inference and {\\it Coherent Situation}\ninference. The differing ways in which these types of inference utilize\nsyntactic and semantic representations predicts phenomena for which it is\notherwise difficult to account.",
    "published": "1994-05-03T18:22:50Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405010v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Andrew Kehler"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405011v2",
    "title": "A Plan-Based Model for Response Generation in Collaborative\n  Task-Oriented Dialogues",
    "summary": "This paper presents a plan-based architecture for response generation in\ncollaborative consultation dialogues, with emphasis on cases in which the\nsystem (consultant) and user (executing agent) disagree. Our work contributes\nto an overall system for collaborative problem-solving by providing a\nplan-based framework that captures the {\\em Propose-Evaluate-Modify} cycle of\ncollaboration, and by allowing the system to initiate subdialogues to negotiate\nproposed additions to the shared plan and to provide support for its claims. In\naddition, our system handles in a unified manner the negotiation of proposed\ndomain actions, proposed problem-solving actions, and beliefs proposed by\ndiscourse actions. Furthermore, it captures cooperative responses within the\ncollaborative framework and accounts for why questions are sometimes never\nanswered.",
    "published": "1994-05-05T15:32:16Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405011v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Jennifer Chu-Carroll",
      "Sandra Carberry"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405012v1",
    "title": "Integration Of Visual Inter-word Constraints And Linguistic Knowledge In\n  Degraded Text Recognition",
    "summary": "Degraded text recognition is a difficult task. Given a noisy text image, a\nword recognizer can be applied to generate several candidates for each word\nimage. High-level knowledge sources can then be used to select a decision from\nthe candidate set for each word image. In this paper, we propose that visual\ninter-word constraints can be used to facilitate candidate selection. Visual\ninter-word constraints provide a way to link word images inside the text page,\nand to interpret them systematically.",
    "published": "1994-05-06T18:02:14Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405012v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Tao Hong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405013v2",
    "title": "Collaboration on reference to objects that are not mutually known",
    "summary": "In conversation, a person sometimes has to refer to an object that is not\npreviously known to the other participant. We present a plan-based model of how\nagents collaborate on reference of this sort. In making a reference, an agent\nuses the most salient attributes of the referent. In understanding a reference,\nan agent determines his confidence in its adequacy as a means of identifying\nthe referent. To collaborate, the agents use judgment, suggestion, and\nelaboration moves to refashion an inadequate referring expression.",
    "published": "1994-05-06T18:44:10Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405013v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Philip G. Edmonds"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405014v1",
    "title": "Classifying Cue Phrases in Text and Speech Using Machine Learning",
    "summary": "Cue phrases may be used in a discourse sense to explicitly signal discourse\nstructure, but also in a sentential sense to convey semantic rather than\nstructural information. This paper explores the use of machine learning for\nclassifying cue phrases as discourse or sentential. Two machine learning\nprograms (Cgrendel and C4.5) are used to induce classification rules from sets\nof pre-classified cue phrases and their features. Machine learning is shown to\nbe an effective technique for not only automating the generation of\nclassification rules, but also for improving upon previous results.",
    "published": "1994-05-09T17:00:00Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405014v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Diane J. Litman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405015v1",
    "title": "Intention-based Segmentation: Human Reliability and Correlation with\n  Linguistic Cues",
    "summary": "Certain spans of utterances in a discourse, referred to here as segments, are\nwidely assumed to form coherent units. Further, the segmental structure of\ndiscourse has been claimed to constrain and be constrained by many phenomena.\nHowever, there is weak consensus on the nature of segments and the criteria for\nrecognizing or generating them. We present quantitative results of a two part\nstudy using a corpus of spontaneous, narrative monologues. The first part\nevaluates the statistical reliability of human segmentation of our corpus,\nwhere speaker intention is the segmentation criterion. We then use the\nsubjects' segmentations to evaluate the correlation of discourse segmentation\nwith three linguistic cues (referential noun phrases, cue words, and pauses),\nusing information retrieval metrics.",
    "published": "1994-05-09T17:10:00Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405015v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Rebecca J. Passonneau",
      "Diane J. Litman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405016v1",
    "title": "Precise n-gram Probabilities from Stochastic Context-free Grammars",
    "summary": "We present an algorithm for computing n-gram probabilities from stochastic\ncontext-free grammars, a procedure that can alleviate some of the standard\nproblems associated with n-grams (estimation from sparse data, lack of\nlinguistic structure, among others). The method operates via the computation of\nsubstring expectations, which in turn is accomplished by solving systems of\nlinear equations derived from the grammar. We discuss efficient implementation\nof the algorithm and report our practical experience with it.",
    "published": "1994-05-10T05:11:29Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405016v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Andreas Stolcke",
      "Jonathan Segal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405017v1",
    "title": "Best-first Model Merging for Hidden Markov Model Induction",
    "summary": "This report describes a new technique for inducing the structure of Hidden\nMarkov Models from data which is based on the general `model merging' strategy\n(Omohundro 1992). The process begins with a maximum likelihood HMM that\ndirectly encodes the training data. Successively more general models are\nproduced by merging HMM states. A Bayesian posterior probability criterion is\nused to determine which states to merge and when to stop generalizing. The\nprocedure may be considered a heuristic search for the HMM structure with the\nhighest posterior probability. We discuss a variety of possible priors for\nHMMs, as well as a number of approximations which improve the computational\nefficiency of the algorithm. We studied three applications to evaluate the\nprocedure. The first compares the merging algorithm with the standard\nBaum-Welch approach in inducing simple finite-state languages from small,\npositive-only training samples. We found that the merging procedure is more\nrobust and accurate, particularly with a small amount of training data. The\nsecond application uses labelled speech data from the TIMIT database to build\ncompact, multiple-pronunciation word models that can be used in speech\nrecognition. Finally, we describe how the algorithm was incorporated in an\noperational speech understanding system, where it is combined with neural\nnetwork acoustic likelihood estimators to improve performance over\nsingle-pronunciation word models.",
    "published": "1994-05-10T05:44:47Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405017v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Andreas Stolcke",
      "Stephen M. Omohundro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405018v1",
    "title": "Memory-Based Lexical Acquisition and Processing",
    "summary": "Current approaches to computational lexicology in language technology are\nknowledge-based (competence-oriented) and try to abstract away from specific\nformalisms, domains, and applications. This results in severe complexity,\nacquisition and reusability bottlenecks. As an alternative, we propose a\nparticular performance-oriented approach to Natural Language Processing based\non automatic memory-based learning of linguistic (lexical) tasks. The\nconsequences of the approach for computational lexicology are discussed, and\nthe application of the approach on a number of lexical acquisition and\ndisambiguation tasks in phonology, morphology and syntax is described.",
    "published": "1994-05-16T14:03:45Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405018v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Walter Daelemans"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405019v4",
    "title": "Determination of referential property and number of nouns in Japanese\n  sentences for machine translation into English",
    "summary": "When translating Japanese nouns into English, we face the problem of articles\nand numbers which the Japanese language does not have, but which are necessary\nfor the English composition. To solve this difficult problem we classified the\nreferential property and the number of nouns into three types respectively.\nThis paper shows that the referential property and the number of nouns in a\nsentence can be estimated fairly reliably by the words in the sentence. Many\nrules for the estimation were written in forms similar to rewriting rules in\nexpert systems. We obtained the correct recognition scores of 85.5\\% and 89.0\\%\nin the estimation of the referential property and the number respectively for\nthe sentences which were used for the construction of our rules. We tested\nthese rules for some other texts, and obtained the scores of 68.9\\% and 85.6\\%\nrespectively.",
    "published": "1994-05-19T07:21:07Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405019v4.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Masaki Murata",
      "Makoto Nagao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405020v2",
    "title": "Capturing CFLs with Tree Adjoining Grammars",
    "summary": "We define a decidable class of TAGs that is strongly equivalent to CFGs and\nis cubic-time parsable. This class serves to lexicalize CFGs in the same manner\nas the LCFGs of Schabes and Waters but with considerably less restriction on\nthe form of the grammars. The class provides a normal form for TAGs that\ngenerate local sets in much the same way that regular grammars provide a normal\nform for CFGs that generate regular sets.",
    "published": "1994-05-24T02:26:10Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405020v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "James Rogers"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405021v1",
    "title": "Generating Precondition Expressions in Instructional Text",
    "summary": "This study employs a knowledge intensive corpus analysis to identify the\nelements of the communicative context which can be used to determine the\nappropriate lexical and grammatical form of instructional texts. \\ig, an\ninstructional text generation system based on this analysis, is presented,\nparticularly with reference to its expression of precondition relations.",
    "published": "1994-05-24T08:30:05Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405021v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Keith Vander Linden"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405022v1",
    "title": "Grammar Specialization through Entropy Thresholds",
    "summary": "Explanation-based generalization is used to extract a specialized grammar\nfrom the original one using a training corpus of parse trees. This allows very\nmuch faster parsing and gives a lower error rate, at the price of a small loss\nin coverage. Previously, it has been necessary to specify the tree-cutting\ncriteria (or operationality criteria) manually; here they are derived\nautomatically from the training set and the desired coverage of the specialized\ngrammar. This is done by assigning an entropy value to each node in the parse\ntrees and cutting in the nodes with sufficiently high entropy values.",
    "published": "1994-05-25T13:54:35Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405022v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Christer Samuelsson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405023v1",
    "title": "An Integrated Heuristic Scheme for Partial Parse Evaluation",
    "summary": "GLR* is a recently developed robust version of the Generalized LR Parser,\nthat can parse almost ANY input sentence by ignoring unrecognizable parts of\nthe sentence. On a given input sentence, the parser returns a collection of\nparses that correspond to maximal, or close to maximal, parsable subsets of the\noriginal input. This paper describes recent work on developing an integrated\nheuristic scheme for selecting the parse that is deemed ``best'' from such a\ncollection. We describe the heuristic measures used and their combination\nscheme. Preliminary results from experiments conducted on parsing speech\nrecognized spontaneous speech are also reported.",
    "published": "1994-05-26T00:29:52Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405023v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Alon Lavie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405024v1",
    "title": "Abductive Equivalential Translation and its application to Natural\n  Language Database Interfacing",
    "summary": "The thesis describes a logical formalization of natural-language database\ninterfacing. We assume the existence of a ``natural language engine'' capable\nof mediating between surface linguistic string and their representations as\n``literal'' logical forms: the focus of interest will be the question of\nrelating ``literal'' logical forms to representations in terms of primitives\nmeaningful to the underlying database engine. We begin by describing the nature\nof the problem, and show how a variety of interface functionalities can be\nconsidered as instances of a type of formal inference task which we call\n``Abductive Equivalential Translation'' (AET); functionalities which can be\nreduced to this form include answering questions, responding to commands,\nreasoning about the completeness of answers, answering meta-questions of type\n``Do you know...'', and generating assertions and questions. In each case, a\n``linguistic domain theory'' (LDT) $\\Gamma$ and an input formula $F$ are given,\nand the goal is to construct a formula with certain properties which is\nequivalent to $F$, given $\\Gamma$ and a set of permitted assumptions. If the\nLDT is of a certain specified type, whose formulas are either conditional\nequivalences or Horn-clauses, we show that the AET problem can be reduced to a\ngoal-directed inference method. We present an abstract description of this\nmethod, and sketch its realization in Prolog. The relationship between AET and\nseveral problems previously discussed in the literature is discussed. In\nparticular, we show how AET can provide a simple and elegant solution to the\nso-called ``Doctor on Board'' problem, and in effect allows a\n``relativization'' of the Closed World Assumption. The ideas in the thesis have\nall been implemented concretely within the SRI CLARE project, using a real\nprojects and payments database. The LDT for the example database is described\nin detail, and examples of the types of functionality that can be achieved\nwithin the example domain are presented.",
    "published": "1994-05-26T09:52:45Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405024v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Manny Rayner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405025v1",
    "title": "An Optimal Tabular Parsing Algorithm",
    "summary": "In this paper we relate a number of parsing algorithms which have been\ndeveloped in very different areas of parsing theory, and which include\ndeterministic algorithms, tabular algorithms, and a parallel algorithm. We show\nthat these algorithms are based on the same underlying ideas. By relating\nexisting ideas, we hope to provide an opportunity to improve some algorithms\nbased on features of others. A second purpose of this paper is to answer a\nquestion which has come up in the area of tabular parsing, namely how to obtain\na parsing algorithm with the property that the table will contain as little\nentries as possible, but without the possibility that two entries represent the\nsame subderivation.",
    "published": "1994-05-26T14:18:11Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405025v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Mark-Jan Nederhof"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405026v1",
    "title": "An Extended Theory of Head-Driven Parsing",
    "summary": "We show that more head-driven parsing algorithms can be formulated than those\noccurring in the existing literature. These algorithms are inspired by a family\nof left-to-right parsing algorithms from a recent publication. We further\nintroduce a more advanced notion of ``head-driven parsing'' which allows more\ndetailed specification of the processing order of non-head elements in the\nright-hand side. We develop a parsing algorithm for this strategy, based on LR\nparsing techniques.",
    "published": "1994-05-26T15:02:32Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405026v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Mark-Jan Nederhof",
      "Giorgio Satta"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405027v1",
    "title": "Acquiring Receptive Morphology: A Connectionist Model",
    "summary": "This paper describes a modular connectionist model of the acquisition of\nreceptive inflectional morphology. The model takes inputs in the form of phones\none at a time and outputs the associated roots and inflections. Simulations\nusing artificial language stimuli demonstrate the capacity of the model to\nlearn suffixation, prefixation, infixation, circumfixation, mutation, template,\nand deletion rules. Separate network modules responsible for syllables enable\nto the network to learn simple reduplication rules as well. The model also\nembodies constraints against association-line crossing.",
    "published": "1994-05-27T19:22:29Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405027v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Michael Gasser"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405028v1",
    "title": "Semantics of Complex Sentences in Japanese",
    "summary": "The important part of semantics of complex sentence is captured as relations\namong semantic roles in subordinate and main clause respectively. However if\nthere can be relations between every pair of semantic roles, the amount of\ncomputation to identify the relations that hold in the given sentence is\nextremely large. In this paper, for semantics of Japanese complex sentence, we\nintroduce new pragmatic roles called `observer' and `motivated' respectively to\nbridge semantic roles of subordinate and those of main clauses. By these new\nroles constraints on the relations among semantic/pragmatic roles are known to\nbe almost local within subordinate or main clause. In other words, as for the\nsemantics of the whole complex sentence, the only role we should deal with is a\nmotivated.",
    "published": "1994-05-28T08:34:39Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405028v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Hiroshi Nakagawa",
      "Shin'ichiro Nishizawa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405030v1",
    "title": "Priority Union and Generalization in Discourse Grammars",
    "summary": "We describe an implementation in Carpenter's typed feature formalism, ALE, of\na discourse grammar of the kind proposed by Scha, Polanyi, et al. We examine\ntheir method for resolving parallelism-dependent anaphora and show that there\nis a coherent feature-structural rendition of this type of grammar which uses\nthe operations of priority union and generalization. We describe an\naugmentation of the ALE system to encompass these operations and we show that\nan appropriate choice of definition for priority union gives the desired\nmultiple output for examples of VP-ellipsis which exhibit a strict/sloppy\nambiguity.",
    "published": "1994-05-30T13:24:38Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405030v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Claire Grover",
      "Chris Brew",
      "Suresh Manandhar",
      "Marc Moens"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405031v1",
    "title": "An Attributive Logic of Set Descriptions and Set Operations",
    "summary": "This paper provides a model theoretic semantics to feature terms augmented\nwith set descriptions. We provide constraints to specify HPSG style set\ndescriptions, fixed cardinality set descriptions, set-membership constraints,\nrestricted universal role quantifications, set union, intersection, subset and\ndisjointness. A sound, complete and terminating consistency checking procedure\nis provided to determine the consistency of any given term in the logic. It is\nshown that determining consistency of terms is a NP-complete problem.",
    "published": "1994-05-30T14:20:17Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405031v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Suresh Manandhar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405029v1",
    "title": "Structural Tags, Annealing and Automatic Word Classification",
    "summary": "This paper describes an automatic word classification system which uses a\nlocally optimal annealing algorithm and average class mutual information. A new\nword-class representation, the structural tag is introduced and its advantages\nfor use in statistical language modelling are presented. A summary of some\nresults with the one million word LOB corpus is given; the algorithm is also\nshown to discover the vowel-consonant distinction and displays an ability to\ncluster words syntactically in a Latin corpus. Finally, a comparison is made\nbetween the current classification system and several leading alternative\nsystems, which shows that the current system performs respectably well.",
    "published": "1994-05-30T14:22:00Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405029v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "John McMahon",
      "F. J. Smith"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405032v1",
    "title": "Modularity in a Connectionist Model of Morphology Acquisition",
    "summary": "This paper describes a modular connectionist model of the acquisition of\nreceptive inflectional morphology. The model takes inputs in the form of phones\none at a time and outputs the associated roots and inflections. In its simplest\nversion, the network consists of separate simple recurrent subnetworks for root\nand inflection identification; both networks take the phone sequence as inputs.\nIt is shown that the performance of the two separate modular networks is\nsuperior to a single network responsible for both root and inflection\nidentification. In a more elaborate version of the model, the network learns to\nuse separate hidden-layer modules to solve the separate tasks of root and\ninflection identification.",
    "published": "1994-05-30T20:54:14Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405032v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Michael Gasser"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405033v1",
    "title": "Relating Complexity to Practical Performance in Parsing with\n  Wide-Coverage Unification Grammars",
    "summary": "The paper demonstrates that exponential complexities with respect to grammar\nsize and input length have little impact on the performance of three\nunification-based parsing algorithms, using a wide-coverage grammar. The\nresults imply that the study and optimisation of unification-based parsing must\nrely on empirical data until complexity theory can more accurately predict the\npractical behaviour of such parsers.",
    "published": "1994-05-31T11:37:32Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405033v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "John Carroll"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405035v1",
    "title": "Dual-Coding Theory and Connectionist Lexical Selection",
    "summary": "We introduce the bilingual dual-coding theory as a model for bilingual mental\nrepresentation. Based on this model, lexical selection neural networks are\nimplemented for a connectionist transfer project in machine translation. This\nlexical selection approach has two advantages. First, it is learnable. Little\nhuman effort on knowledge engineering is required. Secondly, it is\npsycholinguistically well-founded.",
    "published": "1994-05-31T22:31:04Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405035v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Ye-Yi Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9405034v1",
    "title": "Extracting Noun Phrases from Large-Scale Texts: A Hybrid Approach and\n  Its Automatic Evaluation",
    "summary": "To acquire noun phrases from running texts is useful for many applications,\nsuch as word grouping,terminology indexing, etc. The reported literatures adopt\npure probabilistic approach, or pure rule-based noun phrases grammar to tackle\nthis problem. In this paper, we apply a probabilistic chunker to deciding the\nimplicit boundaries of constituents and utilize the linguistic knowledge to\nextract the noun phrases by a finite state mechanism. The test texts are\nSUSANNE Corpus and the results are evaluated by comparing the parse field of\nSUSANNE Corpus automatically. The results of this preliminary experiment are\nencouraging.",
    "published": "1994-06-01T02:25:41Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9405034v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Kuang-hua Chen",
      "Hsin-Hsi Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406001v1",
    "title": "Intentions and Information in Discourse",
    "summary": "This paper is about the flow of inference between communicative intentions,\ndiscourse structure and the domain during discourse processing. We augment a\ntheory of discourse interpretation with a theory of distinct mental attitudes\nand reasoning about them, in order to provide an account of how the attitudes\ninteract with reasoning about discourse structure.",
    "published": "1994-06-01T09:58:55Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406001v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Nicholas Asher",
      "Alex Lascarides"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406002v1",
    "title": "Speech Dialogue with Facial Displays: Multimodal Human-Computer\n  Conversation",
    "summary": "Human face-to-face conversation is an ideal model for human-computer\ndialogue. One of the major features of face-to-face communication is its\nmultiplicity of communication channels that act on multiple modalities. To\nrealize a natural multimodal dialogue, it is necessary to study how humans\nperceive information and determine the information to which humans are\nsensitive. A face is an independent communication channel that conveys\nemotional and conversational signals, encoded as facial expressions. We have\ndeveloped an experimental system that integrates speech dialogue and facial\nanimation, to investigate the effect of introducing communicative facial\nexpressions as a new modality in human-computer conversation. Our experiments\nhave shown that facial expressions are helpful, especially upon first contact\nwith the system. We have also discovered that featuring facial expressions at\nan early stage improves subsequent interaction.",
    "published": "1994-06-01T11:22:59Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406002v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Katashi Nagao",
      "Akikazu Takeuchi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406003v1",
    "title": "A Learning Approach to Natural Language Understanding",
    "summary": "In this paper we propose a learning paradigm for the problem of understanding\nspoken language. The basis of the work is in a formalization of the\nunderstanding problem as a communication problem. This results in the\ndefinition of a stochastic model of the production of speech or text starting\nfrom the meaning of a sentence. The resulting understanding algorithm consists\nin a Viterbi maximization procedure, analogous to that commonly used for\nrecognizing speech. The algorithm was implemented for building",
    "published": "1994-06-01T16:45:34Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406003v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Roberto Pieraccini",
      "Esther Levin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406004v1",
    "title": "Towards a Principled Representation of Discourse Plans",
    "summary": "We argue that discourse plans must capture the intended causal and\ndecompositional relations between communicative actions. We present a planning\nalgorithm, DPOCL, that builds plan structures that properly capture these\nrelations, and show how these structures are used to solve the problems that\nplagued previous discourse planners, and allow a system to participate\neffectively and flexibly in an ongoing dialogue.",
    "published": "1994-06-01T18:05:29Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406004v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "R. Michael Young",
      "Johanna D. Moore",
      "Martha E. Pollack"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406005v1",
    "title": "Word-Sense Disambiguation Using Decomposable Models",
    "summary": "Most probabilistic classifiers used for word-sense disambiguation have either\nbeen based on only one contextual feature or have used a model that is simply\nassumed to characterize the interdependencies among multiple contextual\nfeatures. In this paper, a different approach to formulating a probabilistic\nmodel is presented along with a case study of the performance of models\nproduced in this manner for the disambiguation of the noun \"interest\". We\ndescribe a method for formulating probabilistic models that use multiple\ncontextual features for word-sense disambiguation, without requiring untested\nassumptions regarding the form of the model. Using this approach, the joint\ndistribution of all variables is described by only the most systematic variable\ninteractions, thereby limiting the number of parameters to be estimated,\nsupporting computational efficiency, and providing an understanding of the\ndata.",
    "published": "1994-06-01T19:09:36Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406005v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Rebecca Bruce",
      "Janyce Wiebe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406006v2",
    "title": "Detecting and Correcting Speech Repairs",
    "summary": "Interactive spoken dialog provides many new challenges for spoken language\nsystems. One of the most critical is the prevalence of speech repairs. This\npaper presents an algorithm that detects and corrects speech repairs based on\nfinding the repair pattern. The repair pattern is built by finding word matches\nand word replacements, and identifying fragments and editing terms. Rather than\nusing a set of prebuilt templates, we build the pattern on the fly. In a fair\ntest, our method, when combined with a statistical model to filter possible\nrepairs, was successful at detecting and correcting 80\\% of the repairs,\nwithout using prosodic information or a parser.",
    "published": "1994-06-01T20:03:48Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406006v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Peter Heeman",
      "James Allen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406008v1",
    "title": "Parsing Turkish with the Lexical Functional Grammar Formalism",
    "summary": "This paper describes our work on parsing Turkish using the lexical-functional\ngrammar formalism. This work represents the first significant effort for\nparsing Turkish. Our implementation is based on Tomita's parser developed at\nCarnegie-Mellon University Center for Machine Translation. The grammar covers a\nsubstantial subset of Turkish including simple and complex sentences, and deals\nwith a reasonable amount of word order freeness. The complex agglutinative\nmorphology of Turkish lexical structures is handled using a separate two-level\nmorphological analyzer. After a discussion of key relevant issues regarding\nTurkish grammar, we discuss aspects of our system and present results from our\nimplementation. Our initial results suggest that our system can parse about\n82\\% of the sentences directly and almost all the remaining with very minor\npre-editing.",
    "published": "1994-06-02T05:18:43Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406008v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Zelal Gungordu",
      "Kemal Oflazer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406009v1",
    "title": "Multiset-Valued Linear Index Grammars: Imposing Dominance Constraints on\n  Derivations",
    "summary": "This paper defines multiset-valued linear index grammar and unordered vector\ngrammar with dominance links. The former models certain uses of multiset-valued\nfeature structures in unification-based formalisms, while the latter is\nmotivated by word order variation and by ``quasi-trees'', a generalization of\ntrees. The two formalisms are weakly equivalent, and an important subset is at\nmost context-sensitive and polynomially parsable.",
    "published": "1994-06-02T09:40:10Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406009v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Owen Rambow"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406007v1",
    "title": "Aligning a Parallel English-Chinese Corpus Statistically with Lexical\n  Criteria",
    "summary": "We describe our experience with automatic alignment of sentences in parallel\nEnglish-Chinese texts. Our report concerns three related topics:\n  (1) progress on the HKUST English-Chinese Parallel Bilingual Corpus;\n  (2) experiments addressing the applicability of Gale & Church's length-based\nstatistical method to the task of alignment involving a non-Indo-European\nlanguage; and\n  (3) an improved statistical method that also incorporates domain-specific\nlexical cues.",
    "published": "1994-06-02T11:55:14Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406007v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Dekai Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406010v1",
    "title": "Some Advances in Transformation-Based Part of Speech Tagging",
    "summary": "Most recent research in trainable part of speech taggers has explored\nstochastic tagging. While these taggers obtain high accuracy, linguistic\ninformation is captured indirectly, typically in tens of thousands of lexical\nand contextual probabilities. In [Brill92], a trainable rule-based tagger was\ndescribed that obtained performance comparable to that of stochastic taggers,\nbut captured relevant linguistic information in a small number of simple\nnon-stochastic rules. In this paper, we describe a number of extensions to this\nrule-based tagger. First, we describe a method for expressing lexical relations\nin tagging that are not captured by stochastic taggers. Next, we show a\nrule-based approach to tagging unknown words. Finally, we show how the tagger\ncan be extended into a k-best tagger, where multiple tags can be assigned to\nwords in some cases of uncertainty.",
    "published": "1994-06-02T20:34:18Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406010v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Eric Brill"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406011v1",
    "title": "Exploring the Statistical Derivation of Transformational Rule Sequences\n  for Part-of-Speech Tagging",
    "summary": "Eric Brill has recently proposed a simple and powerful corpus-based language\nmodeling approach that can be applied to various tasks including part-of-speech\ntagging and building phrase structure trees. The method learns a series of\nsymbolic transformational rules, which can then be applied in sequence to a\ntest corpus to produce predictions. The learning process only requires counting\nmatches for a given set of rule templates, allowing the method to survey a very\nlarge space of possible contextual factors. This paper analyses Brill's\napproach as an interesting variation on existing decision tree methods, based\non experiments involving part-of-speech tagging for both English and ancient\nGreek corpora. In particular, the analysis throws light on why the new\nmechanism seems surprisingly resistant to overtraining. A fast, incremental\nimplementation and a mechanism for recording the dependencies that underlie the\nresulting rule sequence are also described.",
    "published": "1994-06-03T18:46:15Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406011v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Lance A. Ramshaw",
      "Mitchell P. Marcus"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406012v1",
    "title": "Self-Organizing Machine Translation: Example-Driven Induction of\n  Transfer Functions",
    "summary": "With the advent of faster computers, the notion of doing machine translation\nfrom a huge stored database of translation examples is no longer unreasonable.\nThis paper describes an attempt to merge the Example-Based Machine Translation\n(EBMT) approach with psycholinguistic principles. A new formalism for context-\nfree grammars, called *marker-normal form*, is demonstrated and used to\ndescribe language data in a way compatible with psycholinguistic theories. By\nembedding this formalism in a standard multivariate optimization framework, a\nsystem can be built that infers correct transfer functions for a set of\nbilingual sentence pairs and then uses those functions to translate novel\nsentences. The validity of this line of reasoning has been tested in the\ndevelopment of a system called METLA-1. This system has been used to infer\nEnglish->French and English->Urdu transfer functions from small corpora. The\nresults of those experiments are examined, both in engineering terms as well as\nin more linguistic terms. In general, the results of these experiments were\npsycho- logically and linguistically well-grounded while still achieving a\nrespectable level of success when compared against a similar prototype using\nHidden Markov Models.",
    "published": "1994-06-03T20:55:37Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406012v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Patrick Juola"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406013v1",
    "title": "Graded Unification: A Framework for Interactive Processing",
    "summary": "An extension to classical unification, called {\\em graded unification} is\npresented. It is capable of combining contradictory information. An interactive\nprocessing paradigm and parser based on this new operator are also presented.",
    "published": "1994-06-05T17:00:57Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406013v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Albert Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406014v1",
    "title": "A Hybrid Reasoning Model for Indirect Answers",
    "summary": "This paper presents our implemented computational model for interpreting and\ngenerating indirect answers to Yes-No questions. Its main features are 1) a\ndiscourse-plan-based approach to implicature, 2) a reversible architecture for\ngeneration and interpretation, 3) a hybrid reasoning model that employs both\nplan inference and logical inference, and 4) use of stimulus conditions to\nmodel a speaker's motivation for providing appropriate, unrequested\ninformation. The model handles a wider range of types of indirect answers than\nprevious computational models and has several significant advantages.",
    "published": "1994-06-07T17:56:03Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406014v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Nancy Green",
      "Sandra Carberry"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406015v1",
    "title": "Statistical Augmentation of a Chinese Machine-Readable Dictionary",
    "summary": "We describe a method of using statistically-collected Chinese character\ngroups from a corpus to augment a Chinese dictionary. The method is\nparticularly useful for extracting domain-specific and regional words not\nreadily available in machine-readable dictionaries. Output was evaluated both\nusing human evaluators and against a previously available dictionary. We also\nevaluated performance improvement in automatic Chinese tokenization. Results\nshow that our method outputs legitimate words, acronymic constructions, idioms,\nnames and titles, as well as technical compounds, many of which were lacking\nfrom the original dictionary.",
    "published": "1994-06-07T18:17:15Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406015v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Pascale Fung",
      "Dekai Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406016v1",
    "title": "Corpus-Driven Knowledge Acquisition for Discourse Analysis",
    "summary": "The availability of large on-line text corpora provides a natural and\npromising bridge between the worlds of natural language processing (NLP) and\nmachine learning (ML). In recent years, the NLP community has been aggressively\ninvestigating statistical techniques to drive part-of-speech taggers, but\napplication-specific text corpora can be used to drive knowledge acquisition at\nmuch higher levels as well. In this paper we will show how ML techniques can be\nused to support knowledge acquisition for information extraction systems. It is\noften very difficult to specify an explicit domain model for many information\nextraction applications, and it is always labor intensive to implement\nhand-coded heuristics for each new domain. We have discovered that it is\nnevertheless possible to use ML algorithms in order to capture knowledge that\nis only implicitly present in a representative text corpus. Our work addresses\nissues traditionally associated with discourse analysis and intersentential\ninference generation, and demonstrates the utility of ML algorithms at this\nhigher level of language analysis. The benefits of our work address the\nportability and scalability of information extraction (IE) technologies. When\nhand-coded heuristics are used to manage discourse analysis in an information\nextraction system, months of programming effort are easily needed to port a\nsuccessful IE system to a new domain. We will show how ML algorithms can reduce\nthis",
    "published": "1994-06-07T20:11:38Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406016v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Stephen Soderland",
      "Wendy Lehnert"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406017v1",
    "title": "An Automatic Method of Finding Topic Boundaries",
    "summary": "This article outlines a new method of locating discourse boundaries based on\nlexical cohesion and a graphical technique called dotplotting. The application\nof dotplotting to discourse segmentation can be performed either manually, by\nexamining a graph, or automatically, using an optimization algorithm. The\nresults of two experiments involving automatically locating boundaries between\na series of concatenated documents are presented. Areas of application and\nfuture directions for this work are also outlined.",
    "published": "1994-06-07T20:40:42Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406017v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Jeffrey C. Reynar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406018v3",
    "title": "TDL--- A Type Description Language for Constraint-Based Grammars",
    "summary": "This paper presents \\tdl, a typed feature-based representation language and\ninference system. Type definitions in \\tdl\\ consist of type and feature\nconstraints over the boolean connectives. \\tdl\\ supports open- and closed-world\nreasoning over types and allows for partitions and incompatible types. Working\nwith partially as well as with fully expanded types is possible. Efficient\nreasoning in \\tdl\\ is accomplished through specialized modules.",
    "published": "1994-06-08T12:16:37Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406018v3.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Hans-Ulrich Krieger",
      "Ulrich Schfer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406019v3",
    "title": "A Complete and Recursive Feature Theory",
    "summary": "Various feature descriptions are being employed in logic programming\nlanguages and constrained-based grammar formalisms. The common notational\nprimitive of these descriptions are functional attributes called features. The\ndescriptions considered in this paper are the possibly quantified first-order\nformulae obtained from a signature of binary and unary predicates called\nfeatures and sorts, respectively. We establish a first-order theory FT by means\nof three axiom schemes, show its completeness, and construct three elementarily\nequivalent models. One of the models consists of so-called feature graphs, a\ndata structure common in computational linguistics. The other two models\nconsist of so-called feature trees, a record-like data structure generalizing\nthe trees corresponding to first-order terms. Our completeness proof exhibits a\nterminating simplification system deciding validity and satisfiability of\npossibly quantified feature descriptions.",
    "published": "1994-06-10T09:17:05Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406019v3.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Rolf Backofen",
      "Gert Smolka"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406020v1",
    "title": "DPOCL: A Principled Approach to Discourse Planning",
    "summary": "Research in discourse processing has identified two representational\nrequirements for discourse planning systems. First, discourse plans must\nadequately represent the intentional structure of the utterances they produce\nin order to enable a computational discourse agent to respond effectively to\ncommunicative failures \\cite{MooreParisCL}. Second, discourse plans must\nrepresent the informational structure of utterances. In addition to these\nrepresentational requirements, we argue that discourse planners should be\nformally characterizable in terms of soundness and completeness.",
    "published": "1994-06-10T18:51:07Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406020v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "R. Michael Young",
      "Johanna D. Moore"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406021v1",
    "title": "A symbolic description of punning riddles and its computer\n  implementation",
    "summary": "Riddles based on simple puns can be classified according to the patterns of\nword, syllable or phrase similarity they depend upon. We have devised a formal\nmodel of the semantic and syntactic regularities underlying some of the simpler\ntypes of punning riddle. We have also implemented this preliminary theory in a\ncomputer program which can generate riddles from a lexicon containing general\ndata about words and phrases; that is, the lexicon content is not customised to\nproduce jokes. Informal evaluation of the program's results by a set of human\njudges suggest that the riddles produced by this program are of comparable\nquality to those in general circulation among school children.",
    "published": "1994-06-13T13:54:19Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406021v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Kim Binsted",
      "Graeme Ritchie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406022v1",
    "title": "An implemented model of punning riddles",
    "summary": "In this paper, we discuss a model of simple question-answer punning,\nimplemented in a program, JAPE, which generates riddles from humour-independent\nlexical entries. The model uses two main types of structure: schemata, which\ndetermine the relationships between key words in a joke, and templates, which\nproduce the surface form of the joke. JAPE succeeds in generating pieces of\ntext that are recognizably jokes, but some of them are not very good jokes. We\nmention some potential improvements and extensions, including post-production\nheuristics for ordering the jokes according to quality.",
    "published": "1994-06-13T14:44:38Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406022v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Kim Binsted",
      "Graeme Ritchie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406023v1",
    "title": "A Spanish Tagset for the CRATER Project",
    "summary": "This working paper describes the Spanish tagset to be used in the context of\nCRATER, a CEC funded project aiming at the creation of a multilingual (English,\nFrench, Spanish) aligned corpus using the International Telecommunications\nUnion corpus. In this respect, each version of the corpus will be (or is\ncurrently) tagged. Xerox PARC tagger will be adapted to Spanish in order to\nperform the tagging of the Spanish version. This tagset has been devised as the\nideal one for Spanish, and has been posted to several lists in order to get\nfeedback to it.",
    "published": "1994-06-14T13:00:38Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406023v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Fernando Snchez Len"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406024v1",
    "title": "Learning Fault-tolerant Speech Parsing with SCREEN",
    "summary": "This paper describes a new approach and a system SCREEN for fault-tolerant\nspeech parsing. SCREEEN stands for Symbolic Connectionist Robust EnterprisE for\nNatural language. Speech parsing describes the syntactic and semantic analysis\nof spontaneous spoken language. The general approach is based on incremental\nimmediate flat analysis, learning of syntactic and semantic speech parsing,\nparallel integration of current hypotheses, and the consideration of various\nforms of speech related errors. The goal for this approach is to explore the\nparallel interactions between various knowledge sources for learning\nincremental fault-tolerant speech parsing. This approach is examined in a\nsystem SCREEN using various hybrid connectionist techniques. Hybrid\nconnectionist techniques are examined because of their promising properties of\ninherent fault tolerance, learning, gradedness and parallel constraint\nintegration. The input for SCREEN is hypotheses about recognized words of a\nspoken utterance potentially analyzed by a speech system, the output is\nhypotheses about the flat syntactic and semantic analysis of the utterance. In\nthis paper we focus on the general approach, the overall architecture, and\nexamples for learning flat syntactic speech parsing. Different from most other\nspeech language architectures SCREEN emphasizes an interactive rather than an\nautonomous position, learning rather than encoding, flat analysis rather than\nin-depth analysis, and fault-tolerant processing of phonetic, syntactic and\nsemantic knowledge.",
    "published": "1994-06-16T14:09:22Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406024v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Stefan Wermter",
      "Volker Weber"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406025v1",
    "title": "Emergent Parsing and Generation with Generalized Chart",
    "summary": "A new, flexible inference method for Horn logic program is proposed, which is\na drastic generalization of chart parsing, partial instantiations of clauses in\na program roughly corresponding to arcs in a chart. Chart-like parsing and\nsemantic-head-driven generation emerge from this method. With a parsimonious\ninstantiation scheme for ambiguity packing, the parsing complexity reduces to\nthat of standard chart-based algorithms.",
    "published": "1994-06-16T16:17:40Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406025v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "HASIDA Koiti"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406026v1",
    "title": "The Very Idea of Dynamic Semantics",
    "summary": "\"Natural languages are programming languages for minds.\" Can we or should we\ntake this slogan seriously? If so, how? Can answers be found by looking at the\nvarious \"dynamic\" treatments of natural language developed over the last decade\nor so, mostly in response to problems associated with donkey anaphora? In\nDynamic Logic of Programs, the meaning of a program is a binary relation on the\nset of states of some abstract machine. This relation is meant to model aspects\nof the effects of the execution of the program, in particular its input-output\nbehavior. What, if anything, are the dynamic aspects of various proposed\ndynamic semantics for natural languages supposed to model? Is there anything\ndynamic to be modeled? If not, what is all the full about? We shall try to\nanswer some, at least, of these questions and provide materials for answers to\nothers.",
    "published": "1994-06-17T01:26:29Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406026v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "David Israel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406027v1",
    "title": "Analyzing and Improving Statistical Language Models for Speech\n  Recognition",
    "summary": "In many current speech recognizers, a statistical language model is used to\nindicate how likely it is that a certain word will be spoken next, given the\nwords recognized so far. How can statistical language models be improved so\nthat more complex speech recognition tasks can be tackled? Since the knowledge\nof the weaknesses of any theory often makes improving the theory easier, the\ncentral idea of this thesis is to analyze the weaknesses of existing\nstatistical language models in order to subsequently improve them. To that end,\nwe formally define a weakness of a statistical language model in terms of the\nlogarithm of the total probability, LTP, a term closely related to the standard\nperplexity measure used to evaluate statistical language models. We apply our\ndefinition of a weakness to a frequently used statistical language model,\ncalled a bi-pos model. This results, for example, in a new modeling of unknown\nwords which improves the performance of the model by 14% to 21%. Moreover, one\nof the identified weaknesses has prompted the development of our generalized\nN-pos language model, which is also outlined in this thesis. It can incorporate\nlinguistic knowledge even if it extends over many words and this is not\nfeasible in a traditional N-pos model. This leads to a discussion of\nwhatknowledge should be added to statistical language models in general and we\ngive criteria for selecting potentially useful knowledge. These results show\nthe usefulness of both our definition of a weakness and of performing an\nanalysis of weaknesses of statistical language models in general.",
    "published": "1994-06-17T12:33:20Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406027v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Joerg P. Ueberla"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406028v2",
    "title": "Resolution of Syntactic Ambiguity: the Case of New Subjects",
    "summary": "I review evidence for the claim that syntactic ambiguities are resolved on\nthe basis of the meaning of the competing analyses, not their structure. I\nidentify a collection of ambiguities that do not yet have a meaning-based\naccount and propose one which is based on the interaction of discourse and\ngrammatical function. I provide evidence for my proposal by examining\nstatistical properties of the Penn Treebank of syntactically annotated text.",
    "published": "1994-06-20T19:13:30Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406028v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Michael Niv"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406029v1",
    "title": "A Computational Model of Syntactic Processing: Ambiguity Resolution from\n  Interpretation",
    "summary": "Syntactic ambiguity abounds in natural language, yet humans have no\ndifficulty coping with it. In fact, the process of ambiguity resolution is\nalmost always unconscious. But it is not infallible, however, as example 1\ndemonstrates.\n  1. The horse raced past the barn fell.\n  This sentence is perfectly grammatical, as is evident when it appears in the\nfollowing context:\n  2. Two horses were being shown off to a prospective buyer. One was raced past\na meadow. and the other was raced past a barn. ...\n  Grammatical yet unprocessable sentences such as 1 are called `garden-path\nsentences.' Their existence provides an opportunity to investigate the human\nsentence processing mechanism by studying how and when it fails. The aim of\nthis thesis is to construct a computational model of language understanding\nwhich can predict processing difficulty. The data to be modeled are known\nexamples of garden path and non-garden path sentences, and other results from\npsycholinguistics.\n  It is widely believed that there are two distinct loci of computation in\nsentence processing: syntactic parsing and semantic interpretation. One\nlongstanding controversy is which of these two modules bears responsibility for\nthe immediate resolution of ambiguity. My claim is that it is the latter, and\nthat the syntactic processing module is a very simple device which blindly and\nfaithfully constructs all possible analyses for the sentence up to the current\npoint of processing. The interpretive module serves as a filter, occasionally\ndiscarding certain of these analyses which it deems less appropriate for the\nongoing discourse than their competitors.\n  This document is divided into three parts. The first is introductory, and\nreviews a selection of proposals from the sentence processing literature. The\nsecond part explores a body of data which has been adduced in support of a\ntheory of structural preferences --- one that is inconsistent with the present\nclaim. I show how the current proposal can be specified to account for the\navailable data, and moreover to predict where structural preference theories\nwill go wrong. The third part is a theoretical investigation of how well the\nproposed architecture can be realized using current conceptions of linguistic\ncompetence. In it, I present a parsing algorithm and a meaning-based ambiguity\nresolution method.",
    "published": "1994-06-20T19:57:34Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406029v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Michael Niv"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406030v2",
    "title": "The complexity of normal form rewrite sequences for Associativity",
    "summary": "The complexity of a particular term-rewrite system is considered: the rule of\nassociativity (x*y)*z --> x*(y*z). Algorithms and exact calculations are given\nfor the longest and shortest sequences of applications of --> that result in\nnormal form (NF). The shortest NF sequence for a term x is always n-drm(x),\nwhere n is the number of occurrences of * in x and drm(x) is the depth of the\nrightmost leaf of x. The longest NF sequence for any term is of length\nn(n-1)/2.",
    "published": "1994-06-20T20:29:54Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406030v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Michael Niv"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406031v1",
    "title": "A Psycholinguistically Motivated Parser for CCG",
    "summary": "Considering the speed in which humans resolve syntactic ambiguity, and the\noverwhelming evidence that syntactic ambiguity is resolved through selection of\nthe analysis whose interpretation is the most `sensible', one comes to the\nconclusion that interpretation, hence parsing take place incrementally, just\nabout every word. Considerations of parsimony in the theory of the syntactic\nprocessor lead one to explore the simplest of parsers: one which represents\nonly analyses as defined by the grammar and no other information.\n  Toward this aim of a simple, incremental parser I explore the proposal that\nthe competence grammar is a Combinatory Categorial Grammar (CCG). I address the\nproblem of the proliferating analyses that stem from CCG's associativity of\nderivation. My solution involves maintaining only the maximally incremental\nanalysis and, when necessary, computing the maximally right-branching analysis.\nI use results from the study of rewrite systems to show that this computation\nis efficient.",
    "published": "1994-06-20T22:18:26Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406031v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Michael Niv"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406032v1",
    "title": "Anytime Algorithms for Speech Parsing?",
    "summary": "This paper discusses to which extent the concept of ``anytime algorithms''\ncan be applied to parsing algorithms with feature unification. We first try to\ngive a more precise definition of what an anytime algorithm is. We arque that\nparsing algorithms have to be classified as contract algorithms as opposed to\n(truly) interruptible algorithms. With the restriction that the transaction\nbeing active at the time an interrupt is issued has to be completed before the\ninterrupt can be executed, it is possible to provide a parser with limited\nanytime behavior, which is in fact being realized in our research prototype.",
    "published": "1994-06-21T13:21:13Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406032v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Guenther Goerz",
      "Marcus Kesseler"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406033v3",
    "title": "Verb Semantics and Lexical Selection",
    "summary": "This paper will focus on the semantic representation of verbs in computer\nsystems and its impact on lexical selection problems in machine translation\n(MT). Two groups of English and Chinese verbs are examined to show that lexical\nselection must be based on interpretation of the sentence as well as selection\nrestrictions placed on the verb arguments. A novel representation scheme is\nsuggested, and is compared to representations with selection restrictions used\nin transfer-based MT. We see our approach as closely aligned with\nknowledge-based MT approaches (KBMT), and as a separate component that could be\nincorporated into existing systems. Examples and experimental results will show\nthat, using this scheme, inexact matches can achieve correct lexical selection.",
    "published": "1994-06-22T01:51:05Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406033v3.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Zhibiao Wu",
      "Martha Palmer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406034v1",
    "title": "Decision Lists for Lexical Ambiguity Resolution: Application to Accent\n  Restoration in Spanish and French",
    "summary": "This paper presents a statistical decision procedure for lexical ambiguity\nresolution. The algorithm exploits both local syntactic patterns and more\ndistant collocational evidence, generating an efficient, effective, and highly\nperspicuous recipe for resolving a given ambiguity. By identifying and\nutilizing only the single best disambiguating evidence in a target context, the\nalgorithm avoids the problematic complex modeling of statistical dependencies.\nAlthough directly applicable to a wide class of ambiguities, the algorithm is\ndescribed and evaluated in a realistic case study, the problem of restoring\nmissing accents in Spanish and French text.",
    "published": "1994-06-23T03:34:55Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406034v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "David Yarowsky"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406035v3",
    "title": "DISCO---An HPSG-based NLP System and its Application for Appointment\n  Scheduling (Project Note)",
    "summary": "The natural language system DISCO is described. It combines o a powerful and\nflexible grammar development system; o linguistic competence for German\nincluding morphology, syntax and semantics; o new methods for linguistic\nperformance modelling on the basis of high-level competence grammars; o new\nmethods for modelling multi-agent dialogue competence; o an interesting sample\napplication for appointment scheduling and calendar management.",
    "published": "1994-06-23T09:13:36Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406035v3.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Hans Uszkoreit",
      "Rolf Backofen",
      "Stephan Busemann",
      "Abdel Kader Diagne",
      "Elizabeth A. Hinkelman",
      "Walter Kasper",
      "Bernd Kiefer",
      "Hans-Ulrich Krieger",
      "Klaus Netter",
      "Guenter Neumann",
      "Stephan Oepen",
      "Stephen P. Spackman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406036v1",
    "title": "Text Analysis Tools in Spoken Language Processing",
    "summary": "This submission contains the postscript of the final version of the slides\nused in our ACL-94 tutorial.",
    "published": "1994-06-23T22:00:15Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406036v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Michael Riley",
      "Richard Sproat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406037v1",
    "title": "Multi-Paragraph Segmentation of Expository Text",
    "summary": "This paper describes TextTiling, an algorithm for partitioning expository\ntexts into coherent multi-paragraph discourse units which reflect the subtopic\nstructure of the texts. The algorithm uses domain-independent lexical frequency\nand distribution information to recognize the interactions of multiple\nsimultaneous themes. Two fully-implemented versions of the algorithm are\ndescribed and shown to produce segmentation that corresponds well to human\njudgments of the major subtopic boundaries of thirteen lengthy texts.",
    "published": "1994-06-23T23:30:11Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406037v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Marti A. Hearst"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406038v1",
    "title": "An Empirical Model of Acknowledgment for Spoken-Language Systems",
    "summary": "We refine and extend prior views of the description, purposes, and\ncontexts-of-use of acknowledgment acts through empirical examination of the use\nof acknowledgments in task-based conversation. We distinguish three broad\nclasses of acknowledgments (other-->ackn, self-->other-->ackn, and self+ackn)\nand present a catalogue of 13 patterns within these classes that account for\nthe specific uses of acknowledgment in the corpus.",
    "published": "1994-06-27T04:20:02Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406038v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "David G. Novick",
      "Stephen Sutton"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406039v1",
    "title": "Three studies of grammar-based surface-syntactic parsing of unrestricted\n  English text. A summary and orientation",
    "summary": "The dissertation addresses the design of parsing grammars for automatic\nsurface-syntactic analysis of unconstrained English text. It consists of a\nsummary and three articles. {\\it Morphological disambiguation} documents a\ngrammar for morphological (or part-of-speech) disambiguation of English, done\nwithin the Constraint Grammar framework proposed by Fred Karlsson. The\ndisambiguator seeks to discard those of the alternative morphological analyses\nproposed by the lexical analyser that are contextually illegitimate. The 1,100\nconstraints express some 23 general, essentially syntactic statements as\nrestrictions on the linear order of morphological tags. The error rate of the\nmorphological disambiguator is about ten times smaller than that of another\nstate-of-the-art probabilistic disambiguator, given that both are allowed to\nleave some of the hardest ambiguities unresolved. This accuracy suggests the\nviability of the grammar-based approach to natural language parsing, thus also\ncontributing to the more general debate concerning the viability of\nprobabilistic vs.\\ linguistic techniques. {\\it Experiments with heuristics}\naddresses the question of how to resolve those ambiguities that survive the\nmorphological disambiguator. Two approaches are presented and empirically\nevaluated: (i) heuristic disambiguation constraints and (ii) techniques for\nlearning from the fully disambiguated part of the corpus and then applying this\ninformation to resolving remaining ambiguities.",
    "published": "1994-06-27T09:24:50Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406039v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Atro Voutilainen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9406040v1",
    "title": "Learning unification-based grammars using the Spoken English Corpus",
    "summary": "This paper describes a grammar learning system that combines model-based and\ndata-driven learning within a single framework. Our results from learning\ngrammars using the Spoken English Corpus (SEC) suggest that combined\nmodel-based and data-driven learning can produce a more plausible grammar than\nis the case when using either learning style isolation.",
    "published": "1994-06-28T14:59:23Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9406040v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Miles Osborne",
      "Derek Bridge"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407001v1",
    "title": "Morphology with a Null-Interface",
    "summary": "We present an integrated architecture for word-level and sentence-level\nprocessing in a unification-based paradigm. The core of the system is a CLP\nimplementation of a unification engine for feature structures supporting\nrelational values. In this framework an HPSG-style grammar is implemented.\nWord-level processing uses X2MorF, a morphological component based on an\nextended version of two-level morphology. This component is tightly integrated\nwith the grammar as a relation. The advantage of this approach is that\nmorphology and syntax are kept logically autonomous while at the same time\nminimizing interface problems.",
    "published": "1994-07-04T10:55:16Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407001v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Harald Trost",
      "Johannes Matiasek"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407002v1",
    "title": "Syntactic Analysis by Local Grammars Automata: an Efficient Algorithm",
    "summary": "Local grammars can be represented in a very convenient way by automata. This\npaper describes and illustrates an efficient algorithm for the application of\nlocal grammars put in this form to lemmatized texts.",
    "published": "1994-07-04T21:37:12Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407002v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Mehryar Mohri"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407003v1",
    "title": "Compact Representations by Finite-State Transducers",
    "summary": "Finite-state transducers give efficient representations of many Natural\nLanguage phenomena. They allow to account for complex lexicon restrictions\nencountered, without involving the use of a large set of complex rules\ndifficult to analyze. We here show that these representations can be made very\ncompact, indicate how to perform the corresponding minimization, and point out\ninteresting linguistic side-effects of this operation.",
    "published": "1994-07-04T23:18:21Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407003v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Mehryar Mohri"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407004v1",
    "title": "Japanese word sense disambiguation based on examples of synonyms",
    "summary": "(This is not the abstract): The language is Japanese. If your printer does\nnot have fonts for Japases characters, the characters in figures will not be\nprinted out correctly. Dissertation for Bachelor's degree at Kyoto\nUniversity(Nagao lab.),March 1994.",
    "published": "1994-07-05T08:11:49Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407004v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Mitsutaka Matsumoto"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407006v1",
    "title": "Interleaving Syntax and Semantics in an Efficient Bottom-Up Parser",
    "summary": "We describe an efficient bottom-up parser that interleaves syntactic and\nsemantic structure building. Two techniques are presented for reducing search\nby reducing local ambiguity: Limited left-context constraints are used to\nreduce local syntactic ambiguity, and deferred sortal-constraint application is\nused to reduce local semantic ambiguity. We experimentally evaluate these\ntechniques, and show dramatic reductions in both number of chart-edges and\ntotal parsing time. The robust processing capabilities of the parser are\ndemonstrated in its use in improving the accuracy of a speech recognizer.",
    "published": "1994-07-05T22:11:40Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407006v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "John Dowding",
      "Robert Moore",
      "Francois Andry",
      "Douglas Moran"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407007v1",
    "title": "GEMINI: A Natural Language System for Spoken-Language Understanding",
    "summary": "Gemini is a natural language understanding system developed for spoken\nlanguage applications. The paper describes the architecture of Gemini, paying\nparticular attention to resolving the tension between robustness and\novergeneration. Gemini features a broad-coverage unification-based grammar of\nEnglish, fully interleaved syntactic and semantic processing in an all-paths,\nbottom-up parser, and an utterance-level parser to find interpretations of\nsentences that might not be analyzable as complete sentences. Gemini also\nincludes novel components for recognizing and correcting grammatical\ndisfluencies, and for doing parse preferences. This paper presents a\ncomponent-by-component view of Gemini, providing detailed relevant measurements\nof size, efficiency, and performance.",
    "published": "1994-07-05T22:25:51Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407007v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "John Dowding",
      "Jean Mark Gawron",
      "Doug Appelt",
      "John Bear",
      "Lynn Cherny",
      "Robert Moore",
      "Douglas Moran"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407005v1",
    "title": "A Corrective Training Algorithm for Adaptive Learning in Bag Generation",
    "summary": "The sampling problem in training corpus is one of the major sources of errors\nin corpus-based applications. This paper proposes a corrective training\nalgorithm to best-fit the run-time context domain in the application of bag\ngeneration. It shows which objects to be adjusted and how to adjust their\nprobabilities. The resulting techniques are greatly simplified and the\nexperimental results demonstrate the promising effects of the training\nalgorithm from generic domain to specific domain. In general, these techniques\ncan be easily extended to various language models and corpus-based\napplications.",
    "published": "1994-07-06T06:49:10Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407005v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Hsin-Hsi Chen",
      "Yue-Shi Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407008v1",
    "title": "Tricolor DAGs for Machine Translation",
    "summary": "Machine translation (MT) has recently been formulated in terms of\nconstraint-based knowledge representation and unification theories, but it is\nbecoming more and more evident that it is not possible to design a practical MT\nsystem without an adequate method of handling mismatches between semantic\nrepresentations in the source and target languages. In this paper, we introduce\nthe idea of ``information-based'' MT, which is considerably more flexible than\ninterlingual MT or the conventional transfer-based MT.",
    "published": "1994-07-06T09:42:23Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407008v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Koichi Takeda"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407009v1",
    "title": "Estimating Performance of Pipelined Spoken Language Translation Systems",
    "summary": "Most spoken language translation systems developed to date rely on a\npipelined architecture, in which the main stages are speech recognition,\nlinguistic analysis, transfer, generation and speech synthesis. When making\nprojections of error rates for systems of this kind, it is natural to assume\nthat the error rates for the individual components are independent, making the\nsystem accuracy the product of the component accuracies.\n  The paper reports experiments carried out using the SRI-SICS-Telia Research\nSpoken Language Translator and a 1000-utterance sample of unseen data. The\nresults suggest that the naive performance model leads to serious overestimates\nof system error rates, since there are in fact strong dependencies between the\ncomponents. Predicting the system error rate on the independence assumption by\nsimple multiplication resulted in a 16\\% proportional overestimate for all\nutterances, and a 19\\% overestimate when only utterances of length 1-10 words\nwere considered.",
    "published": "1994-07-12T16:14:52Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407009v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Manny Rayner",
      "David Carter",
      "Patti Price",
      "Bertil Lyberg"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407010v1",
    "title": "Combining Knowledge Sources to Reorder N-Best Speech Hypothesis Lists",
    "summary": "A simple and general method is described that can combine different knowledge\nsources to reorder N-best lists of hypotheses produced by a speech recognizer.\nThe method is automatically trainable, acquiring information from both positive\nand negative examples. Experiments are described in which it was tested on a\n1000-utterance sample of unseen ATIS data.",
    "published": "1994-07-12T16:39:05Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407010v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Manny Rayner",
      "David Carter",
      "Vassilios Digalakis",
      "Patti Price"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407011v1",
    "title": "Discourse Obligations in Dialogue Processing",
    "summary": "We show that in modeling social interaction, particularly dialogue, the\nattitude of obligation can be a useful adjunct to the popularly considered\nattitudes of belief, goal, and intention and their mutual and shared\ncounterparts. In particular, we show how discourse obligations can be used to\naccount in a natural manner for the connection between a question and its\nanswer in dialogue and how obligations can be used along with other parts of\nthe discourse context to extend the coverage of a dialogue system.",
    "published": "1994-07-14T07:29:37Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407011v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "David R. Traum",
      "James F. Allen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407012v1",
    "title": "Phoneme Recognition Using Acoustic Events",
    "summary": "This paper presents a new approach to phoneme recognition using nonsequential\nsub--phoneme units. These units are called acoustic events and are\nphonologically meaningful as well as recognizable from speech signals. Acoustic\nevents form a phonologically incomplete representation as compared to\ndistinctive features. This problem may partly be overcome by incorporating\nphonological constraints. Currently, 24 binary events describing manner and\nplace of articulation, vowel quality and voicing are used to recognize all\nGerman phonemes. Phoneme recognition in this paradigm consists of two steps:\nAfter the acoustic events have been determined from the speech signal, a\nphonological parser is used to generate syllable and phoneme hypotheses from\nthe event lattice. Results obtained on a speaker--dependent corpus are\npresented.",
    "published": "1994-07-15T08:48:15Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407012v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Kai Huebener",
      "Julie Carson-Berndsen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407013v1",
    "title": "The Acquisition of a Lexicon from Paired Phoneme Sequences and Semantic\n  Representations",
    "summary": "We present an algorithm that acquires words (pairings of phonological forms\nand semantic representations) from larger utterances of unsegmented phoneme\nsequences and semantic representations. The algorithm maintains from utterance\nto utterance only a single coherent dictionary, and learns in the presence of\nhomonymy, synonymy, and noise. Test results over a corpus of utterances\ngenerated from the Childes database of mother-child interactions are presented.",
    "published": "1994-07-15T23:41:27Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407013v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Carl de Marcken"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407014v1",
    "title": "Abstract Machine for Typed Feature Structures",
    "summary": "This paper describes a first step towards the definition of an abstract\nmachine for linguistic formalisms that are based on typed feature structures,\nsuch as HPSG. The core design of the abstract machine is given in detail,\nincluding the compilation process from a high-level specification language to\nthe abstract machine language and the implementation of the abstract\ninstructions. We thus apply methods that were proved useful in computer science\nto the study of natural languages: a grammar specified using the formalism is\nendowed with an operational semantics. Currently, our machine supports the\nunification of simple feature structures, unification of sequences of such\nstructures, cyclic structures and disjunction.",
    "published": "1994-07-17T06:33:35Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407014v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Shuly Wintner",
      "Nissim Francez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407015v1",
    "title": "Specifying Intonation from Context for Speech Synthesis",
    "summary": "This paper presents a theory and a computational implementation for\ngenerating prosodically appropriate synthetic speech in response to database\nqueries. Proper distinctions of contrast and emphasis are expressed in an\nintonation contour that is synthesized by rule under the control of a grammar,\na discourse model, and a knowledge base. The theory is based on Combinatory\nCategorial Grammar, a formalism which easily integrates the notions of\nsyntactic constituency, semantics, prosodic phrasing and information structure.\nResults from our current implementation demonstrate the system's ability to\ngenerate a variety of intonational possibilities for a given sentence depending\non the discourse context.",
    "published": "1994-07-18T22:46:45Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407015v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Scott Prevost",
      "Mark Steedman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407016v2",
    "title": "The Role of Cognitive Modeling in Achieving Communicative Intentions",
    "summary": "A discourse planner for (task-oriented) dialogue must be able to make choices\nabout whether relevant, but optional information (for example, the \"satellites\"\nin an RST-based planner) should be communicated. We claim that effective text\nplanners must explicitly model aspects of the Hearer's cognitive state, such as\nwhat the hearer is attending to and what inferences the hearer can draw, in\norder to make these choices. We argue that a mere representation of the\nHearer's knowledge is inadequate. We support this claim by (1) an analysis of\nnaturally occurring dialogue, and (2) by simulating the generation of\ndiscourses in a situation in which we can vary the cognitive parameters of the\nhearer. Our results show that modeling cognitive state can lead to more\neffective discourses (measured with respect to a simple task).",
    "published": "1994-07-19T09:15:17Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407016v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Marilyn Walker",
      "Owen Rambow"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407017v1",
    "title": "Generating Context-Appropriate Word Orders in Turkish",
    "summary": "Turkish has considerably freer word order than English. The interpretations\nof different word orders in Turkish rely on information that describes how a\nsentence relates to its discourse context. To capture the syntactic features of\na free word order language, I present an adaptation of Combinatory Categorial\nGrammars called {}-CCGs (set-CCGs). In {}-CCGs, a verb's subcategorization\nrequirements are relaxed so that it requires a set of arguments without\nspecifying their linear order. I integrate a level of information structure,\nrepresenting pragmatic functions such as topic and focus, with {}-CCGs to allow\ncertain pragmatic distinctions in meaning to influence the word order of a\nsentence in a compositional way. Finally, I discuss how this strategy is used\nwithin an implemented generation system which produces Turkish sentences with\ncontext-appropriate word orders in a simple database query task.",
    "published": "1994-07-20T18:36:11Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407017v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Beryl Hoffman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407018v2",
    "title": "Generating Multilingual Documents from a Knowledge Base: The TECHDOC\n  Project",
    "summary": "TECHDOC is an implemented system demonstrating the feasibility of generating\nmultilingual technical documents on the basis of a language-independent\nknowledge base. Its application domain is user and maintenance instructions,\nwhich are produced from underlying plan structures representing the activities,\nthe participating objects with their properties, relations, and so on. This\npaper gives a brief outline of the system architecture and discusses some\nrecent developments in the project: the addition of actual event simulation in\nthe KB, steps towards a document authoring tool, and a multimodal user\ninterface. (slightly corrected version of a paper to appear in: COLING 94,\nProceedings)",
    "published": "1994-07-21T15:55:20Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407018v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Dietmar Rsner",
      "Manfred Stede"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407019v1",
    "title": "Tracking Point of View in Narrative",
    "summary": "Third-person fictional narrative text is composed not only of passages that\nobjectively narrate events, but also of passages that present characters'\nthoughts, perceptions, and inner states. Such passages take a character's\n``psychological point of view''. A language understander must determine the\ncurrent psychological point of view in order to distinguish the beliefs of the\ncharacters from the facts of the story, to correctly attribute beliefs and\nother attitudes to their sources, and to understand the discourse relations\namong sentences. Tracking the psychological point of view is not a trivial\nproblem, because many sentences are not explicitly marked for point of view,\nand whether the point of view of a sentence is objective or that of a character\n(and if the latter, which character it is) often depends on the context in\nwhich the sentence appears. Tracking the psychological point of view is the\nproblem addressed in this work. The approach is to seek, by extensive\nexaminations of naturally-occurring narrative, regularities in the ways that\nauthors manipulate point of view, and to develop an algorithm that tracks point\nof view on the basis of the regularities found. This paper presents this\nalgorithm, gives demonstrations of an implemented system, and describes the\nresults of some preliminary empirical studies, which lend support to the\nalgorithm.",
    "published": "1994-07-22T17:11:55Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407019v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Janyce M. Wiebe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407020v2",
    "title": "A Sequential Algorithm for Training Text Classifiers",
    "summary": "The ability to cheaply train text classifiers is critical to their use in\ninformation retrieval, content analysis, natural language processing, and other\ntasks involving data which is partly or fully textual. An algorithm for\nsequential sampling during machine learning of statistical classifiers was\ndeveloped and tested on a newswire text categorization task. This method, which\nwe call uncertainty sampling, reduced by as much as 500-fold the amount of\ntraining data that would have to be manually classified to achieve a given\nlevel of effectiveness.",
    "published": "1994-07-24T13:38:00Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407020v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "David D. Lewis",
      "William A. Gale"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407021v1",
    "title": "K-vec: A New Approach for Aligning Parallel Texts",
    "summary": "Various methods have been proposed for aligning texts in two or more\nlanguages such as the Canadian Parliamentary Debates(Hansards). Some of these\nmethods generate a bilingual lexicon as a by-product. We present an alternative\nalignment strategy which we call K-vec, that starts by estimating the lexicon.\nFor example, it discovers that the English word \"fisheries\" is similar to the\nFrench \"pe^ches\" by noting that the distribution of \"fisheries\" in the English\ntext is similar to the distribution of \"pe^ches\" in the French. K-vec does not\ndepend on sentence boundaries.",
    "published": "1994-07-25T08:57:38Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407021v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Pascale Fung",
      "Kenneth Church"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407022v1",
    "title": "Comparative Discourse Analysis of Parallel Texts",
    "summary": "A quantitative representation of discourse structure can be computed by\nmeasuring lexical cohesion relations among adjacent blocks of text. These\nrepresentations have been proposed to deal with sub-topic text segmentation. In\na parallel corpus, similar representations can be derived for versions of a\ntext in various languages. These can be used for parallel segmentation and as\nan alternative measure of text-translation similarity.",
    "published": "1994-07-26T12:45:04Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407022v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Pim van der Eijk"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407023v1",
    "title": "Multi-Tape Two-Level Morphology: A Case Study in Semitic Non-linear\n  Morphology",
    "summary": "This paper presents an implemented multi-tape two-level model capable of\ndescribing Semitic non-linear morphology. The computational framework behind\nthe current work is motivated by Kay (1987); the formalism presented here is an\nextension to the formalism reported by Pulman and Hepple (1993). The objectives\nof the current work are: to stay as close as possible, in spirit, to standard\ntwo-level morphology, to stay close to the linguistic description of Semitic\nstems, and to present a model which can be used with ease by the Semitist. The\npaper illustrates that if finite-state transducers (FSTs) in a standard\ntwo-level morphology model are replaced with multi-tape auxiliary versions\n(AFSTs), one can account for Semitic root-and-pattern morphology using high\nlevel notation.",
    "published": "1994-07-26T15:42:28Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407023v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "George Kiraz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407024v1",
    "title": "PRINCIPAR---An Efficient, Broad-coverage, Principle-based Parser",
    "summary": "We present an efficient, broad-coverage, principle-based parser for English.\nThe parser has been implemented in C++ and runs on SUN Sparcstations with\nX-windows. It contains a lexicon with over 90,000 entries, constructed\nautomatically by applying a set of extraction and conversion rules to entries\nfrom machine readable dictionaries.",
    "published": "1994-07-27T21:07:17Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407024v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Dekang Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407025v1",
    "title": "Recovering From Parser Failures: A Hybrid Statistical/Symbolic Approach",
    "summary": "We describe an implementation of a hybrid statistical/symbolic approach to\nrepairing parser failures in a speech-to-speech translation system. We describe\na module which takes as input a fragmented parse and returns a repaired meaning\nrepresentation. It negotiates with the speaker about what the complete meaning\nof the utterance is by generating hypotheses about how to fit the fragments of\nthe partial parse together into a coherent meaning representation. By drawing\nupon both statistical and symbolic information, it constrains its repair\nhypotheses to those which are both likely and meaningful. Because it updates\nits statistical model during use, it improves its performance over time.",
    "published": "1994-07-28T22:19:36Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407025v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Carolyn Penstein Rose'",
      "Alex Waibel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407026v1",
    "title": "Tagging and Morphological Disambiguation of Turkish Text",
    "summary": "Automatic text tagging is an important component in higher level analysis of\ntext corpora, and its output can be used in many natural language processing\napplications. In languages like Turkish or Finnish, with agglutinative\nmorphology, morphological disambiguation is a very crucial process in tagging,\nas the structures of many lexical forms are morphologically ambiguous. This\npaper describes a POS tagger for Turkish text based on a full-scale two-level\nspecification of Turkish morphology that is based on a lexicon of about 24,000\nroot words. This is augmented with a multi-word and idiomatic construct\nrecognizer, and most importantly morphological disambiguator based on local\nneighborhood constraints, heuristics and limited amount of statistical\ninformation. The tagger also has functionality for statistics compilation and\nfine tuning of the morphological analyzer, such as logging erroneous\nmorphological parses, commonly used roots, etc. Preliminary results indicate\nthat the tagger can tag about 98-99\\% of the texts accurately with very minimal\nuser intervention. Furthermore for sentences morphologically disambiguated with\nthe tagger, an LFG parser developed for Turkish, generates, on the average,\n50\\% less ambiguous parses and parses almost 2.5 times faster. The tagging\nfunctionality is not specific to Turkish, and can be applied to any language\nwith a proper morphological analysis interface.",
    "published": "1994-07-29T06:08:49Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407026v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Kemal Oflazer",
      "Ilker Kuruoz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407027v1",
    "title": "Parsing as Tree Traversal",
    "summary": "This paper presents a unified approach to parsing, in which top-down,\nbottom-up and left-corner parsers are related to preorder, postorder and\ninorder tree traversals. It is shown that the simplest bottom-up and\nleft-corner parsers are left recursive and must be converted using an extended\nGreibach normal form. With further partial execution, the bottom-up and\nleft-corner parsers collapse together as in the BUP parser of Matsumoto.",
    "published": "1994-07-29T14:05:09Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407027v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Dale Gerdemann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407028v1",
    "title": "Automated Postediting of Documents",
    "summary": "Large amounts of low- to medium-quality English texts are now being produced\nby machine translation (MT) systems, optical character readers (OCR), and\nnon-native speakers of English. Most of this text must be postedited by hand\nbefore it sees the light of day. Improving text quality is tedious work, but\nits automation has not received much research attention. Anyone who has\npostedited a technical report or thesis written by a non-native speaker of\nEnglish knows the potential of an automated postediting system. For the case of\nMT-generated text, we argue for the construction of postediting modules that\nare portable across MT systems, as an alternative to hardcoding improvements\ninside any one system. As an example, we have built a complete self-contained\npostediting module for the task of article selection (a, an, the) for English\nnoun phrases. This is a notoriously difficult problem for Japanese-English MT.\nOur system contains over 200,000 rules derived automatically from online text\nresources. We report on learning algorithms, accuracy, and comparisons with\nhuman performance.",
    "published": "1994-07-29T19:24:18Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407028v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Kevin Knight",
      "Ishwar Chander"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407029v1",
    "title": "Building a Large-Scale Knowledge Base for Machine Translation",
    "summary": "Knowledge-based machine translation (KBMT) systems have achieved excellent\nresults in constrained domains, but have not yet scaled up to newspaper text.\nThe reason is that knowledge resources (lexicons, grammar rules, world models)\nmust be painstakingly handcrafted from scratch. One of the hypotheses being\ntested in the PANGLOSS machine translation project is whether or not these\nresources can be semi-automatically acquired on a very large scale. This paper\nfocuses on the construction of a large ontology (or knowledge base, or world\nmodel) for supporting KBMT. It contains representations for some 70,000\ncommonly encountered objects, processes, qualities, and relations. The ontology\nwas constructed by merging various online dictionaries, semantic networks, and\nbilingual resources, through semi-automatic methods. Some of these methods\n(e.g., conceptual matching of semantic taxonomies) are broadly applicable to\nproblems of importing/exporting knowledge from one KB to another. Other methods\n(e.g., bilingual matching) allow a knowledge engineer to build up an index to a\nKB in a second language, such as Spanish or Japanese.",
    "published": "1994-07-29T19:24:34Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407029v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Kevin Knight",
      "Steve K. Luk"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9407030v1",
    "title": "Computing FIRST and FOLLOW Functions for Feature-Theoretic Grammars",
    "summary": "This paper describes an algorithm for the computation of FIRST and FOLLOW\nsets for use with feature-theoretic grammars in which the value of the sets\nconsists of pairs of feature-theoretic categories. The algorithm preserves as\nmuch information from the grammars as possible, using negative restriction to\ndefine equivalence classes. Addition of a simple data structure leads to an\norder of magnitude improvement in execution time over a naive implementation.",
    "published": "1994-07-30T16:47:36Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9407030v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Arturo Trujillo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9408001v2",
    "title": "The Correct and Efficient Implementation of Appropriateness\n  Specifications for Typed Feature Structures",
    "summary": "In this paper, we argue that type inferencing incorrectly implements\nappropriateness specifications for typed feature structures, promote a\ncombination of type resolution and unfilling as a correct and efficient\nalternative, and consider the expressive limits of this alternative approach.\nThroughout, we use feature cooccurence restrictions as illustration and\nlinguistic motivation.",
    "published": "1994-08-01T14:19:39Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9408001v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Dale Gerdemann",
      "Paul John King"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9408002v1",
    "title": "Computational Analyses of Arabic Morphology",
    "summary": "This paper demonstrates how a (multi-tape) two-level formalism can be used to\nwrite two-level grammars for Arabic non-linear morphology using a high level,\nbut computationally tractable, notation. Three illustrative grammars are\nprovided based on CV-, moraic- and affixational analyses. These are\ncomplemented by a proposal for handling the hitherto computationally untreated\nproblem of the broken plural. It will be shown that the best grammars for\ndescribing Arabic non-linear morphology are moraic in the case of templatic\nstems, and affixational in the case of a-templatic stems. The paper will\ndemonstrate how the broken plural can be derived under two-level theory via the\n`implicit' derivation of the singular.",
    "published": "1994-08-01T15:41:59Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9408002v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "George A. Kiraz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9408003v1",
    "title": "Typed Feature Structures as Descriptions",
    "summary": "A description is an entity that can be interpreted as true or false of an\nobject, and using feature structures as descriptions accrues several\ncomputational benefits. In this paper, I create an explicit interpretation of a\ntyped feature structure used as a description, define the notion of a\nsatisfiable feature structure, and create a simple and effective algorithm to\ndecide if a feature structure is satisfiable.",
    "published": "1994-08-02T08:59:21Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9408003v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Paul John King"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9408004v1",
    "title": "Parsing with Principles and Probabilities",
    "summary": "This paper is an attempt to bring together two approaches to language\nanalysis. The possible use of probabilistic information in principle-based\ngrammars and parsers is considered, including discussion on some theoretical\nand computational problems that arise. Finally a partial implementation of\nthese ideas is presented, along with some preliminary results from testing on a\nsmall set of sentences.",
    "published": "1994-08-02T10:02:45Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9408004v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Andrew Fordham",
      "Matthew Crocker"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9408005v1",
    "title": "A Modular and Flexible Architecture for an Integrated Corpus Query\n  System",
    "summary": "The paper describes the architecture of an integrated and extensible corpus\nquery system developed at the University of Stuttgart and gives examples of\nsome of the modules realized within this architecture. The modules form the\ncore of a corpus workbench. Within the proposed architecture, information\nrequired for the evaluation of queries may be derived from different knowledge\nsources (the corpus text, databases, on-line thesauri) and by different means:\neither through direct lookup in a database or by calling external tools which\nmay infer the necessary information at the time of query evaluation. The\ninformation available and the method of information access can be stated\ndeclaratively and individually for each corpus, leading to a flexible,\nextensible and modular corpus workbench.",
    "published": "1994-08-02T13:41:45Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9408005v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Oliver Christ"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9408006v1",
    "title": "LHIP: Extended DCGs for Configurable Robust Parsing",
    "summary": "We present LHIP, a system for incremental grammar development using an\nextended DCG formalism. The system uses a robust island-based parsing method\ncontrolled by user-defined performance thresholds.",
    "published": "1994-08-03T10:34:26Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9408006v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Afzal Ballim",
      "Graham Russell"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9408007v1",
    "title": "Emergent Linguistic Rules from Inducing Decision Trees: Disambiguating\n  Discourse Clue Words",
    "summary": "We apply decision tree induction to the problem of discourse clue word sense\ndisambiguation with a genetic algorithm. The automatic partitioning of the\ntraining set which is intrinsic to decision tree induction gives rise to\nlinguistically viable rules.",
    "published": "1994-08-13T20:38:54Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9408007v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Eric V. Siegel",
      "Kathleen R. McKeown"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9408008v1",
    "title": "Statistical versus symbolic parsing for captioned-information retrieval",
    "summary": "We discuss implementation issues of MARIE-1, a mostly symbolic parser fully\nimplemented, and MARIE-2, a more statistical parser partially implemented. They\naddress a corpus of 100,000 picture captions. We argue that the mixed approach\nof MARIE-2 should be better for this corpus because its algorithms (not data)\nare simpler.",
    "published": "1994-08-15T19:08:41Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9408008v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Neil C. Rowe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9408009v1",
    "title": "Tagging accurately -- Don't guess if you know",
    "summary": "We discuss combining knowledge-based (or rule-based) and statistical\npart-of-speech taggers. We use two mature taggers, ENGCG and Xerox Tagger, to\nindependently tag the same text and combine the results to produce a fully\ndisambiguated text. In a 27000 word test sample taken from a previously unseen\ncorpus we achieve 98.5% accuracy. This paper presents the data in detail. We\ndescribe the problems we encountered in the course of combining the two taggers\nand discuss the problem of evaluating taggers.",
    "published": "1994-08-16T10:22:05Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9408009v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Pasi Tapanainen",
      "Atro Voutilainen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9408010v1",
    "title": "On Using Selectional Restriction in Language Models for Speech\n  Recognition",
    "summary": "In this paper, we investigate the use of selectional restriction -- the\nconstraints a predicate imposes on its arguments -- in a language model for\nspeech recognition. We use an un-tagged corpus, followed by a public domain\ntagger and a very simple finite state machine to obtain verb-object pairs from\nunrestricted English text. We then measure the impact the knowledge of the verb\nhas on the prediction of the direct object in terms of the perplexity of a\ncluster-based language model. The results show that even though a clustered\nbigram is more useful than a verb-object model, the combination of the two\nleads to an improvement over the clustered bigram model.",
    "published": "1994-08-19T12:21:46Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9408010v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Joerg P. Ueberla"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9408011v1",
    "title": "Distributional Clustering of English Words",
    "summary": "We describe and experimentally evaluate a method for automatically clustering\nwords according to their distribution in particular syntactic contexts.\nDeterministic annealing is used to find lowest distortion sets of clusters. As\nthe annealing parameter increases, existing clusters become unstable and\nsubdivide, yielding a hierarchical ``soft'' clustering of the data. Clusters\nare used as the basis for class models of word coocurrence, and the models\nevaluated with respect to held-out test data.",
    "published": "1994-08-22T16:26:21Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9408011v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Fernando Pereira",
      "Naftali Tishby",
      "Lillian Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9408013v1",
    "title": "Training and Scaling Preference Functions for Disambiguation",
    "summary": "We present an automatic method for weighting the contributions of preference\nfunctions used in disambiguation. Initial scaling factors are derived as the\nsolution to a least-squares minimization problem, and improvements are then\nmade by hill-climbing. The method is applied to disambiguating sentences in the\nATIS (Air Travel Information System) corpus, and the performance of the\nresulting scaling factors is compared with hand-tuned factors. We then focus on\none class of preference function, those based on semantic lexical collocations.\nExperimental results are presented showing that such functions vary\nconsiderably in selecting correct analyses. In particular we define a function\nthat performs significantly better than ones based on mutual information and\nlikelihood ratios of lexical associations.",
    "published": "1994-08-24T00:11:32Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9408013v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Hiyan Alshawi",
      "David Carter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9408014v1",
    "title": "Qualitative and Quantitative Models of Speech Translation",
    "summary": "This paper compares a qualitative reasoning model of translation with a\nquantitative statistical model. We consider these models within the context of\ntwo hypothetical speech translation systems, starting with a logic-based design\nand pointing out which of its characteristics are best preserved or eliminated\nin moving to the second, quantitative design. The quantitative language and\ntranslation models are based on relations between lexical heads of phrases.\nStatistical parameters for structural dependency, lexical transfer, and linear\norder are used to select a set of implicit relations between words in a source\nutterance, a corresponding set of relations between target language words, and\nthe most likely translation of the original utterance.",
    "published": "1994-08-24T00:14:29Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9408014v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Hiyan Alshawi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9408012v1",
    "title": "Approximate N-Gram Markov Model for Natural Language Generation",
    "summary": "This paper proposes an Approximate n-gram Markov Model for bag generation.\nDirected word association pairs with distances are used to approximate\n(n-1)-gram and n-gram training tables. This model has parameters of word\nassociation model, and merits of both word association model and Markov Model.\nThe training knowledge for bag generation can be also applied to lexical\nselection in machine translation design.",
    "published": "1994-08-24T07:31:47Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9408012v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Hsin-Hsi Chen",
      "Yue-Shi Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9408015v1",
    "title": "Experimentally Evaluating Communicative Strategies: The Effect of the\n  Task",
    "summary": "Effective problem solving among multiple agents requires a better\nunderstanding of the role of communication in collaboration. In this paper we\nshow that there are communicative strategies that greatly improve the\nperformance of resource-bounded agents, but that these strategies are highly\nsensitive to the task requirements, situation parameters and agents' resource\nlimitations. We base our argument on two sources of evidence: (1) an analysis\nof a corpus of 55 problem solving dialogues, and (2) experimental simulations\nof collaborative problem solving dialogues in an experimental world,\nDesign-World, where we parameterize task requirements, agents' resources and\ncommunicative strategies.",
    "published": "1994-08-24T16:43:13Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9408015v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Marilyn A. Walker"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9408016v1",
    "title": "On Implementing an HPSG theory -- Aspects of the logical architecture,\n  the formalization, and the implementation of head-driven phrase structure\n  grammars",
    "summary": "The paper presents some aspects involved in the formalization and\nimplementation of HPSG theories. As basis, the logical setups of Carpenter\n(1992) and King (1989, 1994) are briefly compared regarding their usefulness as\nbasis for HPSGII (Pollard and Sag 1994). The possibilities for expressing HPSG\ntheories in the HPSGII architecture and in various computational systems (ALE,\nTroll, CUF, and TFS) are discussed. Beside a formal characterization of the\npossibilities, the paper investigates the specific choices for constraints with\ncertain linguistic motivations, i.e. the lexicon, structure licencing, and\ngrammatical principles. An ALE implementation of a theory for German proposed\nby Hinrichs and Nakazawa (1994) is used as example and the ALE grammar is\nincluded in the appendix.",
    "published": "1994-08-31T15:21:26Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9408016v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Walt Detmar Meurers"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9408017v1",
    "title": "Reaping the Benefits of Interactive Syntax and Semantics",
    "summary": "Semantic feedback is an important source of information that a parser could\nuse to deal with local ambiguities in syntax. However, it is difficult to\ndevise a systematic communication mechanism for interactive syntax and\nsemantics. In this article, I propose a variant of left-corner parsing to\ndefine the points at which syntax and semantics should interact, an account of\ngrammatical relations and thematic roles to define the content of the\ncommunication, and a conflict resolution strategy based on independent\npreferences from syntax and semantics. The resulting interactive model has been\nimplemented in a program called COMPERE and shown to account for a wide variety\nof psycholinguistic data on structural and lexical ambiguities.",
    "published": "1994-08-31T16:13:21Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9408017v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Kavi Mahesh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9408019v1",
    "title": "Building a Parser That can Afford to Interact with Semantics",
    "summary": "Natural language understanding programs get bogged down by the multiplicity\nof possible syntactic structures while processing real world texts that human\nunderstanders do not have much difficulty with. In this work, I analyze the\nrelationships between parsing strategies, the degree of local ambiguity\nencountered by them, and semantic feedback to syntax, and propose a parsing\nalgorithm called {\\em Head-Signaled Left Corner Parsing} (HSLC) that minimizes\nlocal ambiguities while supporting interactive syntactic and semantic analysis.\nSuch a parser has been implemented in a sentence understanding program called\nCOMPERE.",
    "published": "1994-08-31T16:28:26Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9408019v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Kavi Mahesh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9408018v1",
    "title": "Uniform Representations for Syntax-Semantics Arbitration",
    "summary": "Psychological investigations have led to considerable insight into the\nworking of the human language comprehension system. In this article, we look at\na set of principles derived from psychological findings to argue for a\nparticular organization of linguistic knowledge along with a particular\nprocessing strategy and present a computational model of sentence processing\nbased on those principles. Many studies have shown that human sentence\ncomprehension is an incremental and interactive process in which semantic and\nother higher-level information interacts with syntactic information to make\ninformed commitments as early as possible at a local ambiguity. Early\ncommitments may be made by using top-down guidance from knowledge of different\ntypes, each of which must be applicable independently of others. Further\nevidence from studies of error recovery and delayed decisions points toward an\narbitration mechanism for combining syntactic and semantic information in\nresolving ambiguities. In order to account for all of the above, we propose\nthat all types of linguistic knowledge must be represented in a common form but\nmust be separable so that they can be applied independently of each other and\nintegrated at processing time by the arbitrator. We present such a uniform\nrepresentation and a computational model called COMPERE based on the\nrepresentation and the processing strategy.",
    "published": "1994-08-31T17:05:14Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9408018v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Kavi Mahesh",
      "Kurt P. Eiselt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9408020v1",
    "title": "Having Your Cake and Eating It Too: Autonomy and Interaction in a Model\n  of Sentence Processing",
    "summary": "Is the human language understander a collection of modular processes\noperating with relative autonomy, or is it a single integrated process? This\nongoing debate has polarized the language processing community, with two\nfundamentally different types of model posited, and with each camp concluding\nthat the other is wrong. One camp puts forth a model with separate processors\nand distinct knowledge sources to explain one body of data, and the other\nproposes a model with a single processor and a homogeneous, monolithic\nknowledge source to explain the other body of data. In this paper we argue that\na hybrid approach which combines a unified processor with separate knowledge\nsources provides an explanation of both bodies of data, and we demonstrate the\nfeasibility of this approach with the computational model called COMPERE. We\nbelieve that this approach brings the language processing community\nsignificantly closer to offering human-like language processing systems.",
    "published": "1994-08-31T17:59:18Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9408020v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Kurt P. Eiselt",
      "Kavi Mahesh",
      "Jennifer K. Holbrook"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9408021v1",
    "title": "A Unified Process Model of Syntactic and Semantic Error Recovery in\n  Sentence Understanding",
    "summary": "The development of models of human sentence processing has traditionally\nfollowed one of two paths. Either the model posited a sequence of processing\nmodules, each with its own task-specific knowledge (e.g., syntax and\nsemantics), or it posited a single processor utilizing different types of\nknowledge inextricably integrated into a monolithic knowledge base. Our\nprevious work in modeling the sentence processor resulted in a model in which\ndifferent processing modules used separate knowledge sources but operated in\nparallel to arrive at the interpretation of a sentence. One highlight of this\nmodel is that it offered an explanation of how the sentence processor might\nrecover from an error in choosing the meaning of an ambiguous word. Recent\nexperimental work by Laurie Stowe strongly suggests that the human sentence\nprocessor deals with syntactic error recovery using a mechanism very much like\nthat proposed by our model of semantic error recovery. Another way to interpret\nStowe's finding is this: the human sentence processor consists of a single\nunified processing module utilizing multiple independent knowledge sources in\nparallel. A sentence processor built upon this architecture should at times\nexhibit behavior associated with modular approaches, and at other times act\nlike an integrated system. In this paper we explore some of these ideas via a\nprototype computational model of sentence processing called COMPERE, and\npropose a set of psychological experiments for testing our theories.",
    "published": "1994-08-31T21:20:43Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9408021v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Jennifer K. Holbrook",
      "Kurt P. Eiselt",
      "Kavi Mahesh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9409001v1",
    "title": "Integrating Knowledge Bases and Statistics in MT",
    "summary": "We summarize recent machine translation (MT) research at the Information\nSciences Institute of USC, and we describe its application to the development\nof a Japanese-English newspaper MT system. Our work aims at scaling up\ngrammar-based, knowledge-based MT techniques. This scale-up involves the use of\nstatistical methods, both in acquiring effective knowledge resources and in\nmaking reasonable linguistic choices in the face of knowledge gaps.",
    "published": "1994-09-05T21:21:29Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9409001v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Kevin Knight",
      "Ishwar Chander",
      "Matthew Haines",
      "Vasileios Hatzivassiloglou",
      "Eduard Hovy",
      "Masayo Iida",
      "Steve K. Luk",
      "Akitoshi Okumura",
      "Richard Whitney",
      "Kenji Yamada"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9409002v2",
    "title": "Conceptual Association for Compound Noun Analysis",
    "summary": "This paper describes research toward the automatic interpretation of compound\nnouns using corpus statistics. An initial study aimed at syntactic\ndisambiguation is presented. The approach presented bases associations upon\nthesaurus categories. Association data is gathered from unambiguous cases\nextracted from a corpus and is then applied to the analysis of ambiguous\ncompound nouns. While the work presented is still in progress, a first attempt\nto syntactically analyse a test set of 244 examples shows 75% correctness.\nFuture work is aimed at improving this accuracy and extending the technique to\nassign semantic role information, thus producing a complete interpretation.",
    "published": "1994-09-06T18:59:21Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9409002v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Mark Lauer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9409003v1",
    "title": "A Probabilistic Model of Compound Nouns",
    "summary": "Compound nouns such as example noun compound are becoming more common in\nnatural language and pose a number of difficult problems for NLP systems,\nnotably increasing the complexity of parsing. In this paper we develop a\nprobabilistic model for syntactically analysing such compounds. The model\npredicts compound noun structures based on knowledge of affinities between\nnouns, which can be acquired from a corpus. Problems inherent in this\ncorpus-based approach are addressed: data sparseness is overcome by the use of\nsemantically motivated word classes and sense ambiguity is explicitly handled\nin the model. An implementation based on this model is described in Lauer\n(1994) and correctly parses 77% of the test set.",
    "published": "1994-09-06T22:11:36Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9409003v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Mark Lauer",
      "Mark Dras"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9409004v1",
    "title": "An Experiment on Learning Appropriate Selectional Restrictions from a\n  Parsed Corpus",
    "summary": "We present a methodology to extract Selectional Restrictions at a variable\nlevel of abstraction from phrasally analyzed corpora. The method relays in the\nuse of a wide-coverage noun taxonomy and a statistical measure of the\nco-occurrence of linguistic items. Some experimental results about the\nperformance of the method are provided.",
    "published": "1994-09-07T14:15:39Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9409004v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Francesc Ribas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9409005v1",
    "title": "Focusing for Pronoun Resolution in English Discourse: An Implementation",
    "summary": "Anaphora resolution is one of the most active research areas in natural\nlanguage processing. This study examines focusing as a tool for the resolution\nof pronouns which are a kind of anaphora. Focusing is a discourse phenomenon\nlike anaphora. Candy Sidner formalized focusing in her 1979 MIT PhD thesis and\ndevised several algorithms to resolve definite anaphora including pronouns. She\npresented her theory in a computational framework but did not generally\nimplement the algorithms. Her algorithms related to focusing and pronoun\nresolution are implemented in this thesis. This implementation provides a\nbetter comprehension of the theory both from a conceptual and a computational\npoint of view. The resulting program is tested on different discourse segments,\nand evaluation and analysis of the experiments are presented together with the\nstatistical results.",
    "published": "1994-09-07T14:26:08Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9409005v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Ebru Ersan",
      "Varol Akman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9409006v1",
    "title": "Situated Modeling of Epistemic Puzzles",
    "summary": "Situation theory is a mathematical theory of meaning introduced by Jon\nBarwise and John Perry. It has evoked great theoretical and practical interest\nand motivated the framework of a few `computational' systems. PROSIT is the\npioneering work in this direction. Unfortunately, there is a lack of real-life\napplications on these systems and this study is a preliminary attempt to remedy\nthis deficiency. Here, we examine how much PROSIT reflects situation-theoretic\nconcepts and solve a group of epistemic puzzles using the constructs provided\nby this programming language.",
    "published": "1994-09-07T14:37:03Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9409006v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Murat Ersan",
      "Varol Akman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9409007v1",
    "title": "Treating `Free Word Order' in Machine Translation",
    "summary": "In `free word order' languages, every sentence is embedded in its specific\ncontext. Among others, the order of constituents is determined by the\ncategories `theme', `rheme' and `contrastive focus'. This paper shows how to\nrecognise and to translate these categories automatically on a sentential\nbasis, so that sentence embedding can be achieved without having to refer to\nthe context. Modifier classes, which are traditionally neglected in linguistic\ndescription, are fully covered by the proposed method. (Coling 94, Kyoto, Vol.\nI, pages 69-75)",
    "published": "1994-09-08T10:10:18Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9409007v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Ralf Steinberger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9409008v1",
    "title": "Parsing of Spoken Language under Time Constraints",
    "summary": "Spoken language applications in natural dialogue settings place serious\nrequirements on the choice of processing architecture. Especially under adverse\nphonetic and acoustic conditions parsing procedures have to be developed which\ndo not only analyse the incoming speech in a time-synchroneous and incremental\nmanner, but which are able to schedule their resources according to the varying\nconditions of the recognition process. Depending on the actual degree of local\nambiguity the parser has to select among the available constraints in order to\nnarrow down the search space with as little effort as possible.\n  A parsing approach based on constraint satisfaction techniques is discussed.\nIt provides important characteristics of the desired real-time behaviour and\nattempts to mimic some of the attention focussing capabilities of the human\nspeech comprehension mechanism.",
    "published": "1994-09-09T09:12:45Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9409008v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Wolfgang Menzel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9409009v1",
    "title": "Linguistics Computation, Automatic Model Generation, and Intensions",
    "summary": "Techniques are presented for defining models of computational linguistics\ntheories. The methods of generalized diagrams that were developed by this\nauthor for modeling artificial intelligence planning and reasoning are shown to\nbe applicable to models of computation of linguistics theories. It is shown\nthat for extensional and intensional interpretations, models can be generated\nautomatically which assign meaning to computations of linguistics theories for\nnatural languages.\n  Keywords: Computational Linguistics, Reasoning Models, G-diagrams For Models,\nDynamic Model Implementation, Linguistics and Logics For Artificial\nIntelligence",
    "published": "1994-09-09T17:04:26Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9409009v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Cyrus F. Nourani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9409010v1",
    "title": "Inducing Probabilistic Grammars by Bayesian Model Merging",
    "summary": "We describe a framework for inducing probabilistic grammars from corpora of\npositive samples. First, samples are {\\em incorporated} by adding ad-hoc rules\nto a working grammar; subsequently, elements of the model (such as states or\nnonterminals) are {\\em merged} to achieve generalization and a more compact\nrepresentation. The choice of what to merge and when to stop is governed by the\nBayesian posterior probability of the grammar given the data, which formalizes\na trade-off between a close fit to the data and a default preference for\nsimpler models (`Occam's Razor'). The general scheme is illustrated using three\ntypes of probabilistic grammars: Hidden Markov models, class-based $n$-grams,\nand stochastic context-free grammars.",
    "published": "1994-09-13T08:34:58Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9409010v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Andreas Stolcke",
      "Stephen M. Omohundro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9409011v1",
    "title": "Aligning Noisy Parallel Corpora Across Language Groups : Word Pair\n  Feature Matching by Dynamic Time Warping",
    "summary": "We propose a new algorithm called DK-vec for aligning pairs of\nAsian/Indo-European noisy parallel texts without sentence boundaries. DK-vec\nimproves on previous alignment algorithms in that it handles better the\nnon-linear nature of noisy corpora. The algorithm uses frequency, position and\nrecency information as features for pattern matching. Dynamic Time Warping is\nused as the matching technique between word pairs. This algorithm produces a\nsmall bilingual lexicon which provides anchor points for alignment.",
    "published": "1994-09-22T09:53:36Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9409011v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Pascale Fung",
      "Kathleen McKeown"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9409012v1",
    "title": "Towards an Automatic Dictation System for Translators: the TransTalk\n  Project",
    "summary": "Professional translators often dictate their translations orally and have\nthem typed afterwards. The TransTalk project aims at automating the second part\nof this process. Its originality as a dictation system lies in the fact that\nboth the acoustic signal produced by the translator and the source text under\ntranslation are made available to the system. Probable translations of the\nsource text can be predicted and these predictions used to help the speech\nrecognition system in its lexical choices. We present the results of the first\nprototype, which show a marked improvement in the performance of the speech\nrecognition task when translation predictions are taken into account.",
    "published": "1994-09-28T15:43:30Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9409012v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Marc Dymetman",
      "Julie Brousseau",
      "George Foster",
      "Pierre Isabelle",
      "Yves Normandin",
      "Pierre Plamondon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410001v1",
    "title": "Improving Language Models by Clustering Training Sentences",
    "summary": "Many of the kinds of language model used in speech understanding suffer from\nimperfect modeling of intra-sentential contextual influences. I argue that this\nproblem can be addressed by clustering the sentences in a training corpus\nautomatically into subcorpora on the criterion of entropy reduction, and\ncalculating separate language model parameters for each cluster. This kind of\nclustering offers a way to represent important contextual effects and can\ntherefore significantly improve the performance of a model. It also offers a\nreasonably automatic means to gather evidence on whether a more complex,\ncontext-sensitive model using the same general kind of linguistic information\nis likely to reward the effort that would be required to develop it: if\nclustering improves the performance of a model, this proves the existence of\nfurther context dependencies, not exploited by the unclustered model. As\nevidence for these claims, I present results showing that clustering improves\nsome models but not others for the ATIS domain. These results are consistent\nwith other findings for such models, suggesting that the existence or otherwise\nof an improvement brought about by clustering is indeed a good pointer to\nwhether it is worth developing further the unclustered model.",
    "published": "1994-10-04T15:21:05Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410001v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "David Carter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410002v1",
    "title": "Lexikoneintraege fuer deutsche Adverbien (Dictionary Entries for German\n  Adverbs)",
    "summary": "Modifiers in general, and adverbs in particular, are neglected categories in\nlinguistics, and consequently, their treatment in Natural Language Processing\nposes problems. In this article, we present the dictionary information for\nGerman adverbs which is necessary to deal with word order, degree modifier\nscope and other problems in NLP. We also give evidence for the claim that a\nclassification according to position classes differs from any semantic\nclassification.",
    "published": "1994-10-04T18:10:41Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410002v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Ralf Steinberger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410003v1",
    "title": "Principle Based Semantics for HPSG",
    "summary": "The paper presents a constraint based semantic formalism for HPSG. The\nadvantages of the formlism are shown with respect to a grammar for a fragment\nof German that deals with (i) quantifier scope ambiguities triggered by\nscrambling and/or movement and (ii) ambiguities that arise from the\ncollective/distributive distinction of plural NPs. The syntax-semantics\ninterface directly implements syntactic conditions on quantifier scoping and\ndistributivity. The construction of semantic representations is guided by\ngeneral principles governing the interaction between syntax and semantics. Each\nof these principles acts as a constraint to narrow down the set of possible\ninterpretations of a sentence. Meanings of ambiguous sentences are represented\nby single partial representations (so-called U(nderspecified) D(iscourse)\nR(epresentation) S(tructure)s) to which further constraints can be added\nmonotonically to gain more information about the content of a sentence. There\nis no need to build up a large number of alternative representations of the\nsentence which are then filtered by subsequent discourse and world knowledge.\nThe advantage of UDRSs is not only that they allow for monotonic incremental\ninterpretation but also that they are equipped with truth conditions and a\nproof theory that allows for inferences to be drawn directly on structures\nwhere quantifier scope is not resolved.",
    "published": "1994-10-05T16:15:48Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410003v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "A. Frank",
      "U. Reyle"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410004v2",
    "title": "Spelling Correction in Agglutinative Languages",
    "summary": "This paper presents an approach to spelling correction in agglutinative\nlanguages that is based on two-level morphology and a dynamic programming based\nsearch algorithm. Spelling correction in agglutinative languages is\nsignificantly different than in languages like English. The concept of a word\nin such languages is much wider that the entries found in a dictionary, owing\nto {}~productive word formation by derivational and inflectional affixations.\nAfter an overview of certain issues and relevant mathematical preliminaries, we\nformally present the problem and our solution. We then present results from our\nexperiments with spelling correction in Turkish, a Ural--Altaic agglutinative\nlanguage. Our results indicate that we can find the intended correct word in\n95\\% of the cases and offer it as the first candidate in 74\\% of the cases,\nwhen the edit distance is 1.",
    "published": "1994-10-06T07:41:44Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410004v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Kemal Oflazer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410006v2",
    "title": "Evaluating Discourse Processing Algorithms",
    "summary": "In order to take steps towards establishing a methodology for evaluating\nNatural Language systems, we conducted a case study. We attempt to evaluate two\ndifferent approaches to anaphoric processing in discourse by comparing the\naccuracy and coverage of two published algorithms for finding the co-specifiers\nof pronouns in naturally occurring texts and dialogues. We present the\nquantitative results of hand-simulating these algorithms, but this analysis\nnaturally gives rise to both a qualitative evaluation and recommendations for\nperforming such evaluations in general. We illustrate the general difficulties\nencountered with quantitative evaluation. These are problems with: (a) allowing\nfor underlying assumptions, (b) determining how to handle underspecifications,\nand (c) evaluating the contribution of false positives and error chaining.",
    "published": "1994-10-10T21:58:11Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410006v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Marilyn A. Walker"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410005v1",
    "title": "A Centering Approach to Pronouns",
    "summary": "In this paper we present a formalization of the centering approach to\nmodeling attentional structure in discourse and use it as the basis for an\nalgorithm to track discourse context and bind pronouns. As described in Grosz,\nJoshi and Weinstein (1986), the process of centering attention on entities in\nthe discourse gives rise to the intersentential transitional states of\ncontinuing, retaining and shifting. We propose an extension to these states\nwhich handles some additional cases of multiple ambiguous pronouns. The\nalgorithm has been implemented in an HPSG natural language system which serves\nas the interface to a database query application.",
    "published": "1994-10-10T21:59:49Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410005v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Susan E. Brennan",
      "Marilyn Walker Friedman",
      "Carl J. Pollard"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410007v1",
    "title": "A Formal Look at Dependency Grammars and Phrase-Structure Grammars, with\n  Special Consideration of Word-Order Phenomena",
    "summary": "The central role of the lexicon in Meaning-Text Theory (MTT) and other\ndependency-based linguistic theories cannot be replicated in linguistic\ntheories based on context-free grammars (CFGs). We describe Tree Adjoining\nGrammar (TAG) as a system that arises naturally in the process of lexicalizing\nCFGs. A TAG grammar can therefore be compared directly to an Meaning-Text Model\n(MTM). We illustrate this point by discussing the computational complexity of\ncertain non-projective constructions, and suggest a way of incorporating\nlocality of word-order definitions into the Surface-Syntactic Component of MTT.",
    "published": "1994-10-18T20:03:47Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410007v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Owen Rambow",
      "Aravind Joshi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410009v1",
    "title": "Lexical Functions and Machine Translation",
    "summary": "This paper discusses the lexicographical concept of lexical functions and\ntheir potential exploitation in the development of a machine translation\nlexicon designed to handle collocations.",
    "published": "1994-10-20T14:28:24Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410009v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Dirk Heylen",
      "Kerry G. Maxwell",
      "Marc Verhagen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410008v1",
    "title": "Recognizing Text Genres with Simple Metrics Using Discriminant Analysis",
    "summary": "A simple method for categorizing texts into predetermined text genre\ncategories using the statistical standard technique of discriminant analysis is\ndemonstrated with application to the Brown corpus. Discriminant analysis makes\nit possible use a large number of parameters that may be specific for a certain\ncorpus or information stream, and combine them into a small number of\nfunctions, with the parameters weighted on basis of how useful they are for\ndiscriminating text genres. An application to information retrieval is\ndiscussed.",
    "published": "1994-10-20T17:19:00Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410008v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Jussi Karlgren",
      "Douglass Cutting"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410010v1",
    "title": "XTAG system - A Wide Coverage Grammar for English",
    "summary": "This paper presents the XTAG system, a grammar development tool based on the\nTree Adjoining Grammar (TAG) formalism that includes a wide-coverage syntactic\ngrammar for English. The various components of the system are discussed and\npreliminary evaluation results from the parsing of various corpora are given.\nResults from the comparison of XTAG against the IBM statistical parser and the\nAlvey Natural Language Tool parser are also given.",
    "published": "1994-10-20T20:06:51Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410010v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Christy Doran",
      "Dania Egedi",
      "Beth Ann Hockey",
      "B. Srinivas",
      "Martin Zaidel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410012v2",
    "title": "Does Baum-Welch Re-estimation Help Taggers?",
    "summary": "In part of speech tagging by Hidden Markov Model, a statistical model is used\nto assign grammatical categories to words in a text. Early work in the field\nrelied on a corpus which had been tagged by a human annotator to train the\nmodel. More recently, Cutting {\\it et al.} (1992) suggest that training can be\nachieved with a minimal lexicon and a limited amount of {\\em a priori}\ninformation about probabilities, by using Baum-Welch re-estimation to\nautomatically refine the model. In this paper, I report two experiments\ndesigned to determine how much manual training information is needed. The first\nexperiment suggests that initial biasing of either lexical or transition\nprobabilities is essential to achieve a good accuracy. The second experiment\nreveals that there are three distinct patterns of Baum-Welch re-estimation. In\ntwo of the patterns, the re-estimation ultimately reduces the accuracy of the\ntagging rather than improving it. The pattern which is applicable can be\npredicted from the quality of the initial model and the similarity between the\ntagged training corpus (if any) and the corpus to be tagged. Heuristics for\ndeciding how to use re-estimation in an effective manner are given. The\nconclusions are broadly in agreement with those of Merialdo (1994), but give\ngreater detail about the contributions of different parts of the model.",
    "published": "1994-10-21T13:19:05Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410012v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "David Elworthy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410013v1",
    "title": "Automatic Error Detection in Part of Speech Tagging",
    "summary": "A technique for detecting errors made by Hidden Markov Model taggers is\ndescribed, based on comparing observable values of the tagging process with a\nthreshold. The resulting approach allows the accuracy of the tagger to be\nimproved by accepting a lower efficiency, defined as the proportion of words\nwhich are tagged. Empirical observations are presented which demonstrate the\nvalidity of the technique and suggest how to choose an appropriate threshold.",
    "published": "1994-10-21T13:22:36Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410013v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "David Elworthy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410011v1",
    "title": "Dilemma - An Instant Lexicographer",
    "summary": "Dilemma is intended to enhance quality and increase productivity of expert\nhuman translators by presenting to the writer relevant lexical information\nmechanically extracted from comparable existing translations, thus replacing -\nor compensating for the absence of - a lexicographer and stand-by terminologist\nrather than the translator. Using statistics and crude surface analysis and a\nminimum of prior information, Dilemma identifies instances and suggests their\ncounterparts in parallel source and target texts, on all levels down to\nindividual words. Dilemma forms part of a tool kit for translation where focus\nis on text structure and over-all consistency in large text volumes rather than\non framing sentences, on interaction between many actors in a large project\nrather than on retrieval of machine-stored data and on decision making rather\nthan on application of given rules. In particular, the system has been tuned to\nthe needs of the ongoing translation of European Community legislation into the\nlanguages of candidate member countries. The system has been demonstrated to\nand used by professional translators with promising results.",
    "published": "1994-10-21T13:26:46Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410011v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Hans Karlgren",
      "Jussi Karlgren",
      "Magnus Nordstrm",
      "Paul Pettersson",
      "Bengt Wahroln"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410014v1",
    "title": "A Freely Available Syntactic Lexicon for English",
    "summary": "This paper presents a syntactic lexicon for English that was originally\nderived from the Oxford Advanced Learner's Dictionary and the Oxford Dictionary\nof Current Idiomatic English, and then modified and augmented by hand. There\nare more than 37,000 syntactic entries from all 8 parts of speech. An X-windows\nbased tool is available for maintaining the lexicon and performing searches. C\nand Lisp hooks are also available so that the lexicon can be easily utilized by\nparsers and other programs.",
    "published": "1994-10-21T14:23:31Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410014v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Dania Egedi",
      "Patrick Martin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410015v1",
    "title": "Lexicalization and Grammar Development",
    "summary": "In this paper we present a fully lexicalized grammar formalism as a\nparticularly attractive framework for the specification of natural language\ngrammars. We discuss in detail Feature-based, Lexicalized Tree Adjoining\nGrammars (FB-LTAGs), a representative of the class of lexicalized grammars. We\nillustrate the advantages of lexicalized grammars in various contexts of\nnatural language processing, ranging from wide-coverage grammar development to\nparsing and machine translation. We also present a method for compact and\nefficient representation of lexicalized trees.",
    "published": "1994-10-21T15:08:12Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410015v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "B. Srinivas",
      "Dania Egedi",
      "Christy Doran",
      "Tilman Becker"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410016v2",
    "title": "Dutch Cross Serial Dependencies in HPSG",
    "summary": "We present an analysis of Dutch cross serial dependencies in Head-driven\nPhrase Structure Grammar. Arguably, our analysis differs from other analyses in\nthat we do not refer to `additional' mechanisms (e.g., sequence union, head\nwrapping): just standard structure sharing, an immediate dominance schema and a\nlinear precedence rule.",
    "published": "1994-10-21T19:43:24Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410016v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Gerrit Rentier"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410017v1",
    "title": "Concurrent Lexicalized Dependency Parsing: The ParseTalk Model",
    "summary": "A grammar model for concurrent, object-oriented natural language parsing is\nintroduced. Complete lexical distribution of grammatical knowledge is achieved\nbuilding upon the head-oriented notions of valency and dependency, while\ninheritance mechanisms are used to capture lexical generalizations. The\nunderlying concurrent computation model relies upon the actor paradigm. We\nconsider message passing protocols for establishing dependency relations and\nambiguity handling.",
    "published": "1994-10-24T08:25:45Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410017v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Norbert Broeker",
      "Udo Hahn",
      "Susanne Schacht"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410018v1",
    "title": "Part-of-Speech Tagging with Neural Networks",
    "summary": "Text corpora which are tagged with part-of-speech information are useful in\nmany areas of linguistic research. In this paper, a new part-of-speech tagging\nmethod based on neural networks (Net- Tagger) is presented and its performance\nis compared to that of a HMM-tagger and a trigram-based tagger. It is shown\nthat the Net- Tagger performs as well as the trigram-based tagger and better\nthan the HMM-tagger.",
    "published": "1994-10-24T08:37:44Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410018v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Helmut Schmid"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410019v1",
    "title": "Concurrent Lexicalized Dependency Parsing: A Behavioral View on\n  ParseTalk Events",
    "summary": "The behavioral specification of an object-oriented grammar model is\nconsidered. The model is based on full lexicalization, head-orientation via\nvalency constraints and dependency relations, inheritance as a means for\nnon-redundant lexicon specification, and concurrency of computation. The\ncomputation model relies upon the actor paradigm, with concurrency entering\nthrough asynchronous message passing between actors. In particular, we here\nelaborate on principles of how the global behavior of a lexically distributed\ngrammar and its corresponding parser can be specified in terms of event type\nnetworks and event networks, resp.",
    "published": "1994-10-24T08:43:53Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410019v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Susanne Schacht",
      "Udo Hahn",
      "Norbert Broeker"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410021v1",
    "title": "Reference Resolution Using Semantic Patterns in Japanese Newspaper\n  Articles",
    "summary": "Reference resolution is one of the important tasks in natural language\nprocessing. In this paper, the author first determines the referents and their\nlocations of \"dousha\", literally meaning \"the same company\", which appear in\nJapanese newspaper articles. Secondly, three heuristic methods, two of which\nuse semantic information in text such as company names and their patterns, are\nproposed and tested on how accurately they identify the correct referents. The\nproposed methods based on semantic patterns show high accuracy for reference\nresolution of \"dousha\" (more than 90\\%). This suggests that semantic\npattern-matching methods are effective for reference resolution in newspaper\narticles.",
    "published": "1994-10-24T09:59:37Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410021v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Takahiro Wakao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410020v1",
    "title": "Construction of a Bilingual Dictionary Intermediated by a Third Language",
    "summary": "When using a third language to construct a bilingual dictionary, it is\nnecessary to discriminate equivalencies from inappropriate words derived as a\nresult of ambiguity in the third language. We propose a method to treat this by\nutilizing the structures of dictionaries to measure the nearness of the\nmeanings of words. The resulting dictionary is a word-to-word bilingual\ndictionary of nouns and can be used to refine the entries and equivalencies in\npublished bilingual dictionaries.",
    "published": "1994-10-24T12:41:10Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410020v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Kumiko TANAKA",
      "Kyoji UMEMURA"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410022v2",
    "title": "Automated tone transcription",
    "summary": "In this paper I report on an investigation into the problem of assigning\ntones to pitch contours. The proposed model is intended to serve as a tool for\nphonologists working on instrumentally obtained pitch data from tone languages.\nMotivation and exemplification for the model is provided by data taken from my\nfieldwork on Bamileke Dschang (Cameroon). Following recent work by Liberman and\nothers, I provide a parametrised F_0 prediction function P which generates F_0\nvalues from a tone sequence, and I explore the asymptotic behaviour of\ndownstep. Next, I observe that transcribing a sequence X of pitch (i.e. F_0)\nvalues amounts to finding a tone sequence T such that P(T) {}~= X. This is a\ncombinatorial optimisation problem, for which two non-deterministic search\ntechniques are provided: a genetic algorithm and a simulated annealing\nalgorithm. Finally, two implementations---one for each technique---are\ndescribed and then compared using both artificial and real data for sequences\nof up to 20 tones. These programs can be adapted to other tone languages by\nadjusting the F_0 prediction function.",
    "published": "1994-10-24T15:20:32Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410022v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Steven Bird"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410023v1",
    "title": "Korean to English Translation Using Synchronous TAGs",
    "summary": "It is often argued that accurate machine translation requires reference to\ncontextual knowledge for the correct treatment of linguistic phenomena such as\ndropped arguments and accurate lexical selection. One of the historical\narguments in favor of the interlingua approach has been that, since it revolves\naround a deep semantic representation, it is better able to handle the types of\nlinguistic phenomena that are seen as requiring a knowledge-based approach. In\nthis paper we present an alternative approach, exemplified by a prototype\nsystem for machine translation of English and Korean which is implemented in\nSynchronous TAGs. This approach is essentially transfer based, and uses\nsemantic feature unification for accurate lexical selection of polysemous\nverbs. The same semantic features, when combined with a discourse model which\nstores previously mentioned entities, can also be used for the recovery of\ntopicalized arguments. In this paper we concentrate on the translation of\nKorean to English.",
    "published": "1994-10-24T19:02:19Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410023v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Dania Egedi",
      "Martha Palmer",
      "Hyun S. Park",
      "Aravind K. Joshi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410024v1",
    "title": "A Freely Available Wide Coverage Morphological Analyzer for English",
    "summary": "This paper presents a morphological lexicon for English that handles more\nthan 317000 inflected forms derived from over 90000 stems. The lexicon is\navailable in two formats. The first can be used by an implementation of a\ntwo-level processor for morphological analysis. The second, derived from the\nfirst one for efficiency reasons, consists of a disk-based database using a\nUNIX hash table facility. We also built an X Window tool to facilitate the\nmaintenance and browsing of the lexicon. The package is ready to be integrated\ninto an natural language application such as a parser through hooks written in\nLisp and C.",
    "published": "1994-10-24T19:55:23Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410024v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Daniel Karp",
      "Yves Schabes",
      "Martin Zaidel",
      "Dania Egedi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410026v1",
    "title": "A Rule-Based Approach To Prepositional Phrase Attachment Disambiguation",
    "summary": "In this paper, we describe a new corpus-based approach to prepositional\nphrase attachment disambiguation, and present results comparing performance of\nthis algorithm with other corpus-based approaches to this problem.",
    "published": "1994-10-25T06:24:54Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410026v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Eric Brill",
      "Philip Resnik"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410025v1",
    "title": "Syntactic Analysis Of Natural Language Using Linguistic Rules And\n  Corpus-based Patterns",
    "summary": "We are concerned with the syntactic annotation of unrestricted text. We\ncombine a rule-based analysis with subsequent exploitation of empirical data.\nThe rule-based surface syntactic analyser leaves some amount of ambiguity in\nthe output that is resolved using empirical patterns. We have implemented a\nsystem for generating and applying corpus-based patterns. Some patterns\ndescribe the main constituents in the sentence and some the local context of\nthe each syntactic function. There are several (partly) reduntant patterns, and\nthe ``pattern'' parser selects analysis of the sentence that matches the\nstrictest possible pattern(s). The system is applied to an experimental corpus.\nWe present the results and discuss possible refinements of the method from a\nlinguistic point of view.",
    "published": "1994-10-25T14:42:31Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410025v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Pasi Tapanainen",
      "Timo Jrvinen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410027v1",
    "title": "Probabilistic Tagging with Feature Structures",
    "summary": "The described tagger is based on a hidden Markov model and uses tags composed\nof features such as part-of-speech, gender, etc. The contextual probability of\na tag (state transition probability) is deduced from the contextual\nprobabilities of its feature-value-pairs. This approach is advantageous when\nthe available training corpus is small and the tag set large, which can be the\ncase with morphologically rich languages.",
    "published": "1994-10-25T18:49:27Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410027v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Andre Kempe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410028v1",
    "title": "Minimal Change and Bounded Incremental Parsing",
    "summary": "Ideally, the time that an incremental algorithm uses to process a change\nshould be a function of the size of the change rather than, say, the size of\nthe entire current input. Based on a formalization of ``the set of things\nchanged'' by an incremental modification, this paper investigates how and to\nwhat extent it is possible to give such a guarantee for a chart-based parsing\nframework and discusses the general utility of a minimality notion in\nincremental processing.",
    "published": "1994-10-25T20:43:11Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410028v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Mats Wirn"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410029v1",
    "title": "Disambiguation of Super Parts of Speech (or Supertags): Almost Parsing",
    "summary": "In a lexicalized grammar formalism such as Lexicalized Tree-Adjoining Grammar\n(LTAG), each lexical item is associated with at least one elementary structure\n(supertag) that localizes syntactic and semantic dependencies. Thus a parser\nfor a lexicalized grammar must search a large set of supertags to choose the\nright ones to combine for the parse of the sentence. We present techniques for\ndisambiguating supertags using local information such as lexical preference and\nlocal lexical dependencies. The similarity between LTAG and Dependency grammars\nis exploited in the dependency model of supertag disambiguation. The\nperformance results for various models of supertag disambiguation such as\nunigram, trigram and dependency-based models are presented.",
    "published": "1994-10-26T17:21:53Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410029v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Aravind K. Joshi",
      "B. Srinivas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410030v1",
    "title": "Feature-Based TAG in place of multi-component adjunction: Computational\n  Implications",
    "summary": "Using feature-based Tree Adjoining Grammar (TAG), this paper presents\nlinguistically motivated analyses of constructions claimed to require\nmulti-component adjunction. These feature-based TAG analyses permit parsing of\nthese constructions using an existing unification-based Earley-style TAG\nparser, thus obviating the need for a multi-component TAG parser without\nsacrificing linguistic coverage for English.",
    "published": "1994-10-26T17:33:45Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410030v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "B. A. Hockey",
      "B. Srinivas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410031v1",
    "title": "Towards a More User-friendly Correction",
    "summary": "We first present our view of detection and correction of syntactic errors. We\nthen introduce a new correction method, based on heuristic criteria used to\ndecide which correction should be preferred. Weighting of these criteria leads\nto a flexible and parametrable system, which can adapt itself to the user. A\npartitioning of the trees based on linguistic criteria: agreement rules, rather\nthan computational criteria is then necessary. We end by proposing extensions\nto lexical correction and to some syntactic errors. Our aim is an adaptable and\nuser-friendly system capable of automatic correction for some applications.",
    "published": "1994-10-27T16:12:55Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410031v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Damien Genthial",
      "Jacques Courtin",
      "Jacques Menezo Equipe Trilan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410032v1",
    "title": "Planning Argumentative Texts",
    "summary": "This paper presents \\proverb\\, a text planner for argumentative texts.\n\\proverb\\'s main feature is that it combines global hierarchical planning and\nunplanned organization of text with respect to local derivation relations in a\ncomplementary way. The former splits the task of presenting a particular proof\ninto subtasks of presenting subproofs. The latter simulates how the next\nintermediate conclusion to be presented is chosen under the guidance of the\nlocal focus.",
    "published": "1994-10-28T10:20:12Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410032v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Xiaorong Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410033v1",
    "title": "Default Handling in Incremental Generation",
    "summary": "Natural language generation must work with insufficient input.\nUnderspecifications can be caused by shortcomings of the component providing\nthe input or by the preliminary state of incrementally given input. The paper\naims to escape from such dead-end situations by making assumptions. We discuss\nglobal aspects of default handling. Two problem classes for defaults in the\nincremental syntactic generator VM-GEN are presented to substantiate our\ndiscussion.",
    "published": "1994-10-30T14:37:06Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410033v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Karin Harbusch",
      "Gen-ichiro Kikui",
      "Anne Kilger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9410034v1",
    "title": "A Comparison of Two Smoothing Methods for Word Bigram Models",
    "summary": "A COMPARISON OF TWO SMOOTHING METHODS FOR WORD BIGRAM MODELS\n  Linda Bauman Peto\n  Department of Computer Science\n  University of Toronto Abstract Word bigram models estimated from text corpora\nrequire smoothing methods to estimate the probabilities of unseen bigrams. The\ndeleted estimation method uses the formula:\n  Pr(i|j) = lambda f_i + (1-lambda)f_i|j, where f_i and f_i|j are the relative\nfrequency of i and the conditional relative frequency of i given j,\nrespectively, and lambda is an optimized parameter. MacKay (1994) proposes a\nBayesian approach using Dirichlet priors, which yields a different formula:\n  Pr(i|j) = (alpha/F_j + alpha) m_i + (1 - alpha/F_j + alpha) f_i|j where F_j\nis the count of j and alpha and m_i are optimized parameters. This thesis\ndescribes an experiment in which the two methods were trained on a\ntwo-million-word corpus taken from the Canadian _Hansard_ and compared on the\nbasis of the experimental perplexity that they assigned to a shared test\ncorpus. The methods proved to be about equally accurate, with MacKay's method\nusing fewer resources.",
    "published": "1994-10-31T19:55:57Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9410034v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Linda Bauman Peto"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411001v1",
    "title": "Sublanguage Terms: Dictionaries, Usage, and Automatic Classification",
    "summary": "The use of terms from natural and social scientific titles and abstracts is\nstudied from the perspective of sublanguages and their specialized\ndictionaries. Different notions of sublanguage distinctiveness are explored.\nObjective methods for separating hard and soft sciences are suggested based on\nmeasures of sublanguage use, dictionary characteristics, and sublanguage\ndistinctiveness. Abstracts were automatically classified with a high degree of\naccuracy by using a formula that considers the degree of uniqueness of terms in\neach sublanguage. This may prove useful for text filtering or information\nretrieval systems.",
    "published": "1994-11-01T14:35:06Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411001v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Robert M. Losee",
      "Stephanie W. Haas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411002v1",
    "title": "CLARE: A Contextual Reasoning and Cooperative Response Framework for the\n  Core Language Engine",
    "summary": "This report describes the research, design and implementation work carried\nout in building the CLARE system at SRI International, Cambridge, England.\nCLARE was designed as a natural language processing system with facilities for\nreasoning and understanding in context and for generating cooperative\nresponses. The project involved both further development of SRI's Core Language\nEngine (Alshawi, 1992, MIT Press) natural language processor and the design and\nimplementation of new components for reasoning and response generation. The\nCLARE system has advanced the state of the art in a wide variety of areas, both\nthrough the use of novel techniques developed on the project, and by extending\nthe coverage or scale of known techniques. The language components are\napplication-independent and provide interfaces for the development of new types\nof application.",
    "published": "1994-11-01T15:36:02Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411002v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Hiyan Alshawi",
      "David Carter",
      "Richard Crouch",
      "Steve Pulman",
      "Manny Rayner",
      "Arnold Smith"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411003v3",
    "title": "Adnominal adjectives, code-switching and lexicalized TAG",
    "summary": "In codeswitching contexts, the language of a syntactic head determines the\ndistribution of its complements. Mahootian 1993 derives this generalization by\nrepresenting heads as the anchors of elementary trees in a lexicalized TAG.\nHowever, not all codeswitching sequences are amenable to a head-complement\nanalysis. For instance, adnominal adjectives can occupy positions not available\nto them in their own language, and the TAG derivation of such sequences must\nuse unanchored auxiliary trees. palabras heavy-duty `heavy-duty words'\n(Spanish-English; Poplack 1980:584) taste lousy sana `very lousy taste'\n(English-Swahili; Myers-Scotton 1993:29, (10)) Given the null hypothesis that\ncodeswitching and monolingual sequences are derived in an identical manner,\nsequences like those above provide evidence that pure lexicalized TAGs are\ninadequate for the description of natural language.",
    "published": "1994-11-02T19:26:11Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411003v3.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Shahrzad Mahootian",
      "Beatrice Santorini"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411004v1",
    "title": "Determining Determiner Sequencing: A Syntactic Analysis for English",
    "summary": "Previous work on English determiners has primarily concentrated on their\nsemantics or scoping properties rather than their complex ordering behavior.\nThe little work that has been done on determiner ordering generally splits\ndeterminers into three subcategories. However, this small number of categories\ndoes not capture the finer distinctions necessary to correctly order\ndeterminers. This paper presents a syntactic account of determiner sequencing\nbased on eight independently identified semantic features. Complex determiners,\nsuch as genitives, partitives, and determiner modifying adverbials, are also\npresented. This work has been implemented as part of XTAG, a wide-coverage\ngrammar for English based in the Feature-Based, Lexicalized Tree Adjoining\nGrammar (FB-LTAG) formalism.",
    "published": "1994-11-03T13:40:44Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411004v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Beth Ann Hockey",
      "Dania Egedi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411005v1",
    "title": "Constraining Lexical Selection Across Languages Using TAGs",
    "summary": "Lexical selection in Machine Translation consists of several related\ncomponents. Two that have received a lot of attention are lexical mapping from\nan underlying concept or lexical item, and choosing the correct\nsubcategorization frame based on argument structure. Because most MT\napplications are small or relatively domain specific, a third component of\nlexical selection is generally overlooked - distinguishing between lexical\nitems that are closely related conceptually. While some MT systems have\nproposed using a 'world knowledge' module to decide which word is more\nappropriate based on various pragmatic or stylistic constraints, we are\ninterested in seeing how much we can accomplish using a combination of syntax\nand lexical semantics. By using separate ontologies for each language\nimplemented in FB-LTAGs, we are able to elegantly model the more specific and\nlanguage dependent syntactic and semantic distinctions necessary to further\nfilter the choice of the lexical item.",
    "published": "1994-11-03T13:56:55Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411005v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Dania Egedi",
      "Martha Palmer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411006v1",
    "title": "Status of the XTAG System",
    "summary": "XTAG is an ongoing project to develop a wide-coverage grammar for English,\nbased on the Feature-based Lexicalized Tree Adjoining Grammar (FB-LTAG)\nformalism. The XTAG system integrates a morphological analyzer, an N-best\npart-of-speech tagger, an Early-style parser and an X-window interface, along\nwith a wide-coverage grammar for English developed using the system. This\nsystem serves as a linguist's workbench for developing FB-LTAG specifications.\nThis paper presents a description of and recent improvements to the various\ncomponents of the XTAG system. It also presents the recent performance of the\nwide-coverage grammar on various corpora and compares it against the\nperformance of other wide-coverage and domain-specific grammars.",
    "published": "1994-11-03T14:07:31Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411006v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Christy Doran",
      "Dania Egedi",
      "Beth Ann Hockey",
      "B. Srinivas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411007v1",
    "title": "The Linguistic Relevance of Quasi-Trees",
    "summary": "We discuss two constructions (long scrambling and ECM verbs) which challenge\nmost syntactic theories (including traditional TAG approaches) since they seem\nto require exceptional mechanisms and postulates. We argue that these\nconstructions should in fact be analyzed in a similar manner, namely as\ninvolving a verb which selects for a ``defective'' complement. These\ncomplements are defective in that they lack certain Case-assigning abilities\n(represented as functional heads). The constructions differ in how many such\nabilities are lacking. Following the previous analysis of scrambling of Rambow\n(1994), we propose a TAG analysis based on quasi-trees.",
    "published": "1994-11-03T16:40:25Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411007v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Anthony Kroch",
      "Owen Rambow"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411008v1",
    "title": "Parsing Free Word-Order Languages in Polynomial Time",
    "summary": "We present a parsing algorithm with polynomial time complexity for a large\nsubset of V-TAG languages. V-TAG, a variant of multi-component TAG, can handle\nfree-word order phenomena which are beyond the class LCFRS (which includes\nregular TAG). Our algorithm is based on a CYK-style parser for TAGs.",
    "published": "1994-11-03T17:39:35Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411008v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Tilman Becker",
      "Owen Rambow"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411009v1",
    "title": "Bootstrapping A Wide-Coverage CCG from FB-LTAG",
    "summary": "A number of researchers have noted the similarities between LTAGs and CCGs.\nObserving this resemblance, we felt that we could make use of the wide-coverage\ngrammar developed in the XTAG project to build a wide-coverage CCG. To our\nknowledge there have been no attempts to construct a large-scale CCG parser\nwith the lexicon to support it. In this paper, we describe such a system, built\nby adapting various XTAG components to CCG. We find that, despite the\nsimilarities between the formalisms, certain parts of the grammatical workload\nare distributed differently. In addition, the flexibility of CCG derivations\nallows the translated grammar to handle a number of ``non-constituent''\nconstructions which the XTAG grammar cannot.",
    "published": "1994-11-03T18:33:10Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411009v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Christine Doran",
      "B. Srinivas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411010v1",
    "title": "The \"Whiteboard\" Architecture: a way to integrate heterogeneous\n  components of NLP systems",
    "summary": "We present a new software architecture for NLP systems made of heterogeneous\ncomponents, and demonstrate an architectural prototype we have built at ATR in\nthe context of Speech Translation.",
    "published": "1994-11-04T13:16:25Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411010v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Christian Boitet",
      "Mark Seligman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411012v1",
    "title": "From Regular to Context Free to Mildly Context Sensitive Tree Rewriting\n  Systems: The Path of Child Language Acquisition",
    "summary": "Current syntactic theory limits the range of grammatical variation so\nseverely that the logical problem of grammar learning is trivial. Yet, children\nexhibit characteristic stages in syntactic development at least through their\nsixth year. Rather than positing maturational delays, I suggest that\nacquisition difficulties are the result of limitations in manipulating\ngrammatical representations. I argue that the genesis of complex sentences\nreflects increasing generative capacity in the systems generating structural\ndescriptions: conjoined clauses demand only a regular tree rewriting system;\nsentential embedding uses a context-free tree substitution grammar;\nmodification requires TAG, a mildly context-sensitive system.",
    "published": "1994-11-04T20:56:44Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411012v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Robert Frank"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411011v1",
    "title": "Acquiring Knowledge from Encyclopedic Texts",
    "summary": "A computational model for the acquisition of knowledge from encyclopedic\ntexts is described. The model has been implemented in a program, called SNOWY,\nthat reads unedited texts from {\\em The World Book Encyclopedia}, and acquires\nnew concepts and conceptual relations about topics dealing with the dietary\nhabits of animals, their classifications and habitats. The program is also able\nto answer an ample set of questions about the knowledge that it has acquired.\nThis paper describes the essential components of this model, namely semantic\ninterpretation, inferences and representation, and ends with an evaluation of\nthe performance of the program, a sample of the questions that it is able to\nanswer, and its relation to other programs of similar nature.",
    "published": "1994-11-04T23:08:09Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411011v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Fernando Gomez",
      "Richard Hull",
      "Carlos Segami"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411013v1",
    "title": "Phoneme-level speech and natural language intergration for agglutinative\n  languages",
    "summary": "A new tightly coupled speech and natural language integration model is\npresented for a TDNN-based large vocabulary continuous speech recognition\nsystem. Unlike the popular n-best techniques developed for integrating mainly\nHMM-based speech and natural language systems in word level, which is obviously\ninadequate for the morphologically complex agglutinative languages, our model\nconstructs a spoken language system based on the phoneme-level integration. The\nTDNN-CYK spoken language architecture is designed and implemented using the\nTDNN-based diphone recognition module integrated with the table-driven\nphonological/morphological co-analysis. Our integration model provides a\nseamless integration of speech and natural language for connectionist speech\nrecognition systems especially for morphologically complex languages such as\nKorean. Our experiment results show that the speaker-dependent continuous\nEojeol (word) recognition can be integrated with the morphological analysis\nwith over 80\\% morphological analysis success rate directly from the speech\ninput for the middle-level vocabularies.",
    "published": "1994-11-05T06:22:31Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411013v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Geunbae Lee Jong-Hyeok Lee Kyunghee Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411014v2",
    "title": "Automatically Identifying Morphological Relations in = Machine-Readable\n  Dictionaries",
    "summary": "We describe an automated method for identifying classes of morphologically\nrelated words in an on-line dictionary, and for linking individual senses in\nthe derived form to one or more senses in the base form by means of\nmorphological relation attributes. We also present an algorithm for computing a\nscore reflecting the system=92s certainty in these derivational links; this\ncomputation relies on the content of semantic relations associated with each\nsense, which are extracted automatically by parsing each sense definition and\nsubjecting the parse structure to automated semantic analysis. By processing\nthe entire set of headwords in the dictionary in this fashion we create a large\nset of directed derivational graphs, which can then be accessed by other\ncomponents in our broad-coverage NLP system. Spurious or unlikely derivations\nare not discarded, but are rather added to the dictionary and assigned a\nnegative score; this allows the system to handle non-standard uses of these\nforms.",
    "published": "1994-11-08T00:39:33Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411014v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Joseph Pentheroudakis",
      "Lucy Vanderwende",
      "Microsoft Corporation"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411015v2",
    "title": "Parsing Using Linearly Ordered Phonological Rules",
    "summary": "A generate and test algorithm is described which parses a surface form into\none or more lexical entries using linearly ordered phonological rules. This\nalgorithm avoids the exponential expansion of search space which a naive\nparsing algorithm would face by encoding into the form being parsed the\nambiguities which arise during parsing. The algorithm has been implemented and\ntested on real language data, and its speed compares favorably with that of a\nKIMMO-type parser.",
    "published": "1994-11-08T16:05:00Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411015v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Michael Maxwell"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411016v1",
    "title": "Extending DRT with a Focusing Mechanism for Pronominal Anaphora and\n  Ellipsis Resolution",
    "summary": "Cormack (1992) proposed a framework for pronominal anaphora resolution. Her\nproposal integrates focusing theory (Sidner et al.) and DRT (Kamp and Reyle).\nWe analyzed this methodology and adjusted it to the processing of Portuguese\ntexts. The scope of the framework was widened to cover sentences containing\nrestrictive relative clauses and subject ellipsis. Tests were conceived and\napplied to probe the adequacy of proposed modifications when dealing with\nprocessing of current texts.",
    "published": "1994-11-09T17:53:57Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411016v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Jose Abracos",
      "Jose Gabriel Lopes"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411017v1",
    "title": "Comlex Syntax: Building a Computational Lexicon",
    "summary": "We describe the design of Comlex Syntax, a computational lexicon providing\ndetailed syntactic information for approximately 38,000 English headwords. We\nconsider the types of errors which arise in creating such a lexicon, and how\nsuch errors can be measured and controlled.",
    "published": "1994-11-10T16:18:07Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411017v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Ralph Grishman",
      "Catherine Macleod",
      "Adam Meyers"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411018v1",
    "title": "Interlanguage Signs and Lexical Transfer Errors",
    "summary": "A theory of interlanguage (IL) lexicons is outlined, with emphasis on IL\nlexical entries, based on the HPSG notion of lexical sign. This theory accounts\nfor idiosyncratic or lexical transfer of syntactic subcategorisation and idioms\nfrom the first language to the IL. It also accounts for developmental stages in\nIL lexical grammar, and grammatical variation in the use of the same lexical\nitem. The theory offers a tool for robust parsing of lexical transfer errors\nand diagnosis of such errors.",
    "published": "1994-11-11T11:43:45Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411018v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Atle Ro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411019v2",
    "title": "Focus on ``only\" and ``Not\"",
    "summary": "Krifka [1993] has suggested that focus should be seen as a means of providing\nmaterial for a range of semantic and pragmatic functions to work on, rather\nthan as a specific semantic or pragmatic function itself. The current paper\ndescribes an implementation of this general idea, and applies it to the\ninterpretation of {\\em only} and {\\em not}.",
    "published": "1994-11-11T13:54:16Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411019v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Allan Ramsay"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411020v1",
    "title": "Extraction in Dutch with Lexical Rules",
    "summary": "Unbounded dependencies are often modelled by ``traces'' (and ``gap\nthreading'') in unification-based grammars. Pollard and Sag, however, suggest\nan analysis of extraction based on lexical rules, which excludes the notion of\ntraces (P&S 1994, Chapter 9). In parsing, it suggests a trade of indeterminism\nfor lexical ambiguity. This paper provides a short introduction to this\napproach to extraction with lexical rules, and illustrates the linguistic power\nof the approach by applying it to particularly idiosyncratic Dutch extraction\ndata.",
    "published": "1994-11-14T12:19:42Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411020v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Gerrit Rentier"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411021v1",
    "title": "Free-ordered CUG on Chemical Abstract Machine",
    "summary": "We propose a paradigm for concurrent natural language generation. In order to\nrepresent grammar rules distributively, we adopt categorial unification grammar\n(CUG) where each category owns its functional type. We augment typed lambda\ncalculus with several new combinators, to make the order of lambda-conversions\nfree for partial / local processing. The concurrent calculus is modeled with\nChemical Abstract Machine. We show an example of a Japanese causative auxiliary\nverb that requires a drastic rearrangement of case domination.",
    "published": "1994-11-16T10:42:25Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411021v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Satoshi Tojo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411022v2",
    "title": "Adaptive Sentence Boundary Disambiguation",
    "summary": "Labeling of sentence boundaries is a necessary prerequisite for many natural\nlanguage processing tasks, including part-of-speech tagging and sentence\nalignment. End-of-sentence punctuation marks are ambiguous; to disambiguate\nthem most systems use brittle, special-purpose regular expression grammars and\nexception rules. As an alternative, we have developed an efficient, trainable\nalgorithm that uses a lexicon with part-of-speech probabilities and a\nfeed-forward neural network. After training for less than one minute, the\nmethod correctly labels over 98.5\\% of sentence boundaries in a corpus of over\n27,000 sentence-boundary marks. We show the method to be efficient and easily\nadaptable to different text genres, including single-case texts.",
    "published": "1994-11-16T23:31:30Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411022v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "David D. Palmer",
      "Marti A. Hearst"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411023v1",
    "title": "Abstract Generation based on Rhetorical Structure Extraction",
    "summary": "We have developed an automatic abstract generation system for Japanese\nexpository writings based on rhetorical structure extraction. The system first\nextracts the rhetorical structure, the compound of the rhetorical relations\nbetween sentences, and then cuts out less important parts in the extracted\nstructure to generate an abstract of the desired length.\n  Evaluation of the generated abstract showed that it contains at maximum 74\\%\nof the most important sentences of the original text. The system is now\nutilized as a text browser for a prototypical interactive document retrieval\nsystem.",
    "published": "1994-11-17T11:55:17Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411023v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Kenji Ono",
      "Kazuo Sumita",
      "Seiji Miike Research",
      "Development Center",
      "Toshiba Corporation Komukai-Toshiba-cho 1",
      " Saiwai-ku",
      " Kawasaki",
      " 210",
      " Japan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411024v1",
    "title": "Reverse Queries in DATR",
    "summary": "DATR is a declarative representation language for lexical information and as\nsuch, in principle, neutral with respect to particular processing strategies.\nPrevious DATR compiler/interpreter systems support only one access strategy\nthat closely resembles the set of inference rules of the procedural semantics\nof DATR (Evans & Gazdar 1989a). In this paper we present an alternative access\nstrategy (reverse query strategy) for a non-trivial subset of DATR.",
    "published": "1994-11-17T15:24:39Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411024v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Hagen Langer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411025v1",
    "title": "Multi-Dimensional Inheritance",
    "summary": "In this paper, we present an alternative approach to multiple inheritance for\ntyped feature structures. In our approach, a feature structure can be\nassociated with several types coming from different hierarchies (dimensions).\nIn case of multiple inheritance, a type has supertypes from different\nhierarchies. We contrast this approach with approaches based on a single type\nhierarchy where a feature structure has only one unique most general type, and\nmultiple inheritance involves computation of greatest lower bounds in the\nhierarchy. The proposed approach supports current linguistic analyses in\nconstraint-based formalisms like HPSG, inheritance in the lexicon, and\nknowledge representation for NLP systems. Finally, we show that\nmulti-dimensional inheritance hierarchies can be compiled into a Prolog term\nrepresentation, which allows to compute the conjunction of two types\nefficiently by Prolog term unification.",
    "published": "1994-11-17T20:00:23Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411025v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Gregor Erbach"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411026v2",
    "title": "Manipulating Human-oriented Dictionaries with very simple tools",
    "summary": "This paper presents a methodology for building and manipulating\nhuman-oriented dictionaries. This methodology has been applied in the\nconstruction of a French-English-Malay dictionary which has been obtained by\n\"crossing\" semi-automatically two bilingual dictionaries. We use only Microsoft\nWord, a specialized language for writing transcriptors and a small but powerful\ndictionary tool.",
    "published": "1994-11-18T08:05:20Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411026v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Jean Gaschler",
      "Mathieu Lafourcade"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411027v3",
    "title": "Classifier Assignment by Corpus-based Approach",
    "summary": "This paper presents an algorithm for selecting an appropriate classifier word\nfor a noun. In Thai language, it frequently happens that there is fluctuation\nin the choice of classifier for a given concrete noun, both from the point of\nview of the whole spe ech community and individual speakers. Basically, there\nis no exect rule for classifier selection. As far as we can do in the\nrule-based approach is to give a default rule to pick up a corresponding\nclassifier of each noun. Registration of classifier for each noun is limited to\nthe type of unit classifier because other types are open due to the meaning of\nrepresentation. We propose a corpus-based method (Biber, 1993; Nagao, 1993;\nSmadja, 1993) which generates Noun Classifier Associations (NCA) to overcome\nthe problems in classifier assignment and semantic construction of noun phrase.\nThe NCA is created statistically from a large corpus and recomposed under\nconcept hierarchy constraints and frequency of occurrences.",
    "published": "1994-11-21T04:44:15Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411027v3.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Virach Sornlertlamvanich",
      "Wantanee Pantachat",
      "Surapant Meknavin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411028v1",
    "title": "The Speech-Language Interface in the Spoken Language Translator",
    "summary": "The Spoken Language Translator is a prototype for practically useful systems\ncapable of translating continuous spoken language within restricted domains.\nThe prototype system translates air travel (ATIS) queries from spoken English\nto spoken Swedish and to French. It is constructed, with as few modifications\nas possible, from existing pieces of speech and language processing software.\nThe speech recognizer and language understander are connected by a fairly\nconventional pipelined N-best interface. This paper focuses on the ways in\nwhich the language processor makes intelligent use of the sentence hypotheses\ndelivered by the recognizer. These ways include (1) producing modified\nhypotheses to reflect the possible presence of repairs in the uttered word\nsequence; (2) fast parsing with a version of the grammar automatically\nspecialized to the more frequent constructions in the training corpus; and (3)\nallowing syntactic and semantic factors to interact with acoustic ones in the\nchoice of a meaning structure for translation, so that the acoustically\npreferred hypothesis is not always selected even if it is within linguistic\ncoverage.",
    "published": "1994-11-23T18:09:54Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411028v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "David Carter",
      "Manny Rayner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411029v1",
    "title": "An Efficient Probabilistic Context-Free Parsing Algorithm that Computes\n  Prefix Probabilities",
    "summary": "We describe an extension of Earley's parser for stochastic context-free\ngrammars that computes the following quantities given a stochastic context-free\ngrammar and an input string: a) probabilities of successive prefixes being\ngenerated by the grammar; b) probabilities of substrings being generated by the\nnonterminals, including the entire string being generated by the grammar; c)\nmost likely (Viterbi) parse of the string; d) posterior expected number of\napplications of each grammar production, as required for reestimating rule\nprobabilities. (a) and (b) are computed incrementally in a single left-to-right\npass over the input. Our algorithm compares favorably to standard bottom-up\nparsing methods for SCFGs in that it works efficiently on sparse grammars by\nmaking use of Earley's top-down control structure. It can process any\ncontext-free rule format without conversion to some normal form, and combines\ncomputations for (a) through (d) in a single algorithm. Finally, the algorithm\nhas simple extensions for processing partially bracketed inputs, and for\nfinding partial parses and their likelihoods on ungrammatical inputs.",
    "published": "1994-11-28T09:39:49Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411029v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Andreas Stolcke"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411030v2",
    "title": "Complexity of Scrambling: A New Twist to the Competence - Performance\n  Distinction",
    "summary": "In this paper we discuss the following issue: How do we decide whether a\ncertain property of language is a competence property or a performance\nproperty? Our claim is that the answer to this question is not given a-priori.\nThe answer depends on the formal devices (formal grammars and machines)\navailable to us for describing language. We discuss this issue in the context\nof the complexity of processing of center embedding (of relative clauses in\nEnglish) and scrambling (in German, for example) from arbitrary depths of\nembedding.",
    "published": "1994-11-29T13:57:25Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411030v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Aravind K Joshi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411031v2",
    "title": "Automatic Generation of Technical Documentation",
    "summary": "Natural-language generation (NLG) techniques can be used to automatically\nproduce technical documentation from a domain knowledge base and linguistic and\ncontextual models. We discuss this application of NLG technology from both a\ntechnical and a usefulness (costs and benefits) perspective. This discussion is\nbased largely on our experiences with the IDAS documentation-generation\nproject, and the reactions various interested people from industry have had to\nIDAS. We hope that this summary of our experiences with IDAS and the lessons we\nhave learned from it will be beneficial for other researchers who wish to build\ntechnical-documentation generation systems.",
    "published": "1994-11-29T17:42:52Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411031v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Ehud Reiter",
      "Chris Mellish",
      "John Levine"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9411032v1",
    "title": "Has a Consensus NL Generation Architecture Appeared, and is it\n  Psycholinguistically Plausible?",
    "summary": "I survey some recent applications-oriented NL generation systems, and claim\nthat despite very different theoretical backgrounds, these systems have a\nremarkably similar architecture in terms of the modules they divide the\ngeneration process into, the computations these modules perform, and the way\nthe modules interact with each other. I also compare this `consensus\narchitecture' among applied NLG systems with psycholinguistic knowledge about\nhow humans speak, and argue that at least some aspects of the consensus\narchitecture seem to be in agreement with what is known about human language\nproduction, despite the fact that psycholinguistic plausibility was not in\ngeneral a goal of the developers of the surveyed systems.",
    "published": "1994-11-30T18:44:10Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9411032v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Ehud Reiter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9412001v1",
    "title": "Dependency Grammar and the Parsing of Chinese Sentences",
    "summary": "Dependency Grammar has been used by linguists as the basis of the syntactic\ncomponents of their grammar formalisms. It has also been used in natural\nlanguage parsing. In China, attempts have been made to use this grammar\nformalism to parse Chinese sentences using corpus-based techniques. This paper\nreviews the properties of Dependency Grammar as embodied in four axioms for the\nwell-formedness conditions for dependency structures. It is shown that allowing\nmultiple governors as done by some followers of this formalism is unnecessary.\nThe practice of augmenting Dependency Grammar with functional labels is also\ndiscussed in the light of building functional structures when the sentence is\nparsed. This will also facilitate semantic interpretation.",
    "published": "1994-12-01T07:19:12Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9412001v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Bong Yeung Tom Lai",
      "Changning Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9412002v1",
    "title": "N-Gram Cluster Identification During Empirical Knowledge Representation\n  Generation",
    "summary": "This paper presents an overview of current research concerning knowledge\nextraction from technical texts. In particular, the use of empirical techniques\nduring the identification and generation of a semantic representation is\nconsidered. A key step is the discovery of useful n-grams and correlations\nbetween clusters of these n-grams.",
    "published": "1994-12-05T05:40:54Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9412002v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Robin Collier"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9412003v1",
    "title": "An Extended Clustering Algorithm for Statistical Language Models",
    "summary": "Statistical language models frequently suffer from a lack of training data.\nThis problem can be alleviated by clustering, because it reduces the number of\nfree parameters that need to be trained. However, clustered models have the\nfollowing drawback: if there is ``enough'' data to train an unclustered model,\nthen the clustered variant may perform worse. On currently used language\nmodeling corpora, e.g. the Wall Street Journal corpus, how do the performances\nof a clustered and an unclustered model compare? While trying to address this\nquestion, we develop the following two ideas. First, to get a clustering\nalgorithm with potentially high performance, an existing algorithm is extended\nto deal with higher order N-grams. Second, to make it possible to cluster large\namounts of training data more efficiently, a heuristic to speed up the\nalgorithm is presented. The resulting clustering algorithm can be used to\ncluster trigrams on the Wall Street Journal corpus and the language models it\nproduces can compete with existing back-off models. Especially when there is\nonly little training data available, the clustered models clearly outperform\nthe back-off models.",
    "published": "1994-12-06T12:07:53Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9412003v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Joerg P. Ueberla"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9412004v1",
    "title": "Knowledge Representation for Lexical Semantics: Is Standard First Order\n  Logic Enough?",
    "summary": "Natural language understanding applications such as interactive planning and\nface-to-face translation require extensive inferencing. Many of these\ninferences are based on the meaning of particular open class words. Providing a\nrepresentation that can support such lexically-based inferences is a primary\nconcern of lexical semantics. The representation language of first order logic\nhas well-understood semantics and a multitude of inferencing systems have been\nimplemented for it. Thus it is a prime candidate to serve as a lexical\nsemantics representation. However, we argue that FOL, although a good starting\npoint, needs to be extended before it can efficiently and concisely support all\nthe lexically-based inferences needed.",
    "published": "1994-12-10T16:53:27Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9412004v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Marc Light",
      "Lenhart Schubert"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9412005v1",
    "title": "Segmenting speech without a lexicon: The roles of phonotactics and\n  speech source",
    "summary": "Infants face the difficult problem of segmenting continuous speech into words\nwithout the benefit of a fully developed lexicon. Several sources of\ninformation in speech might help infants solve this problem, including prosody,\nsemantic correlations and phonotactics. Research to date has focused on\ndetermining to which of these sources infants might be sensitive, but little\nwork has been done to determine the potential usefulness of each source. The\ncomputer simulations reported here are a first attempt to measure the\nusefulness of distributional and phonotactic information in segmenting phoneme\nsequences. The algorithms hypothesize different segmentations of the input into\nwords and select the best hypothesis according to the Minimum Description\nLength principle. Our results indicate that while there is some useful\ninformation in both phoneme distributions and phonotactic rules, the\ncombination of both sources is most useful.",
    "published": "1994-12-15T16:08:16Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9412005v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Timothy Andrew Cartwright",
      "Michael R. Brent"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9412006v1",
    "title": "Robust stochastic parsing using the inside-outside algorithm",
    "summary": "The paper describes a parser of sequences of (English) part-of-speech labels\nwhich utilises a probabilistic grammar trained using the inside-outside\nalgorithm. The initial (meta)grammar is defined by a linguist and further rules\ncompatible with metagrammatical constraints are automatically generated. During\ntraining, rules with very low probability are rejected yielding a wide-coverage\nparser capable of ranking alternative analyses. A series of corpus-based\nexperiments describe the parser's performance.",
    "published": "1994-12-19T21:10:57Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9412006v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      " Briscoe",
      " Ted",
      " Waegner",
      " Nick"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9412007v1",
    "title": "Coupling Phonology and Phonetics in a Constraint-Based Gestural Model",
    "summary": "An implemented approach which couples a constraint-based phonology component\nwith an articulatory speech synthesizer is proposed. Articulatory gestures\nensure a tight connection between both components, as they comprise both\nphysical-phonetic and phonological aspects. The phonological modelling of e.g.\nsyllabification and phonological processes such as German final devoicing is\nexpressed in the constraint logic programming language CUF. Extending CUF by\narithmetic constraints allows the simultaneous description of both phonology\nand phonetics. Thus declarative lexicalist theories of grammar such as HPSG may\nbe enriched up to the level of detailed phonetic realisation. Initial acoustic\ndemonstrations show that our approach is in principle capable of synthesizing\nfull utterances in a linguistically motivated fashion.",
    "published": "1994-12-23T12:15:04Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9412007v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Markus Walther",
      "Bernd J. Kroeger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9412008v1",
    "title": "Analysis of Japanese Compound Nouns using Collocational Information",
    "summary": "Analyzing compound nouns is one of the crucial issues for natural language\nprocessing systems, in particular for those systems that aim at a wide coverage\nof domains. In this paper, we propose a method to analyze structures of\nJapanese compound nouns by using both word collocations statistics and a\nthesaurus. An experiment is conducted with 160,000 word collocations to analyze\ncompound nouns of with an average length of 4.9 characters. The accuracy of\nthis method is about 80%.",
    "published": "1994-12-25T05:35:35Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9412008v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Kobayasi Yosiyuki",
      "Takunaga Takenobu",
      "Tanaka Hozumi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9501001v1",
    "title": "Using default inheritance to describe LTAG",
    "summary": "We present the results of an investigation into how the set of elementary\ntrees of a Lexicalized Tree Adjoining Grammar can be represented in the lexical\nknowledge representation language DATR (Evans & Gazdar 1989a,b). The LTAG under\nconsideration is based on the one described in Abeille et al. (1990). Our\napproach is similar to that of Vijay-Shanker & Schabes (1992) in that we\nformulate an inheritance hierarchy that efficiently encodes the elementary\ntrees. However, rather than creating a new representation formalism for this\ntask, we employ techniques of established utility in other lexically-oriented\nframeworks. In particular, we show how DATR's default mechanism can be used to\neliminate the need for a non-immediate dominance relation in the descriptions\nof the surface LTAG entries. This allows us to embed the tree structures in the\nfeature theory in a manner reminiscent of HPSG subcategorisation frames, and\nhence express lexical rules as relations over feature structures.",
    "published": "1995-01-09T16:28:46Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9501001v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Roger Evans",
      "Gerald Gazdar",
      "David Weir"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9501002v1",
    "title": "NL Understanding with a Grammar of Constructions",
    "summary": "We present an approach to natural language understanding based on a\ncomputable grammar of constructions. A \"construction\" consists of a set of\nfeatures of form and a description of meaning in a context. A grammar is a set\nof constructions. This kind of grammar is the key element of Mincal, an\nimplemented natural language, speech-enabled interface to an on-line calendar\nsystem. The system consists of a NL grammar, a parser, an on-line calendar, a\ndomain knowledge base (about dates, times and meetings), an application\nknowledge base (about the calendar), a speech recognizer, a speech generator,\nand the interfaces between those modules. We claim that this architecture\nshould work in general for spoken interfaces in small domains. In this paper we\npresent two novel aspects of the architecture: (a) the use of constructions,\nintegrating descriptions of form, meaning and context into one whole; and (b)\nthe separation of domain knowledge from application knowledge. We describe the\ndata structures for encoding constructions, the structure of the knowledge\nbases, and the interactions of the key modules of the system.",
    "published": "1995-01-17T19:48:31Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9501002v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Wlodek Zadrozny",
      "Marcin Szummer",
      "Stanislaw Jarecki",
      "David E. Johnson",
      "Leora Morgenstern"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9501003v1",
    "title": "An HPSG Parser Based on Description Logics",
    "summary": "In this paper I present a parser based on Description Logics (DL) for a\nGerman HPSG -style fragment. The specified parser relies mainly on the\ninferential capabilities of the underlying DL system. Given a preferential\ndefault extension for DL disambiguation is achieved by choosing the parse\ncontaining a qualitatively minimal number of exceptions.",
    "published": "1995-01-18T13:35:20Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9501003v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "J. Joachim Quantz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9501004v1",
    "title": "Lexical Knowledge Representation in an Intelligent Dictionary Help\n  System",
    "summary": "The frame-based knowledge representation model adopted in IDHS (Intelligent\nDictionary Help System) is described in this paper. It is used to represent the\nlexical knowledge acquired automatically from a conventional dictionary.\nMoreover, the enrichment processes that have been performed on the Dictionary\nKnowledge Base and the dynamic exploitation of this knowledge - both based on\nthe exploitation of the properties of lexical semantic relations - are also\ndescribed.",
    "published": "1995-01-30T10:58:03Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9501004v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "E. Agirre",
      "X. Arregi",
      "X. Artola",
      "A. Diaz de Ilarraza",
      "K. Sarasola"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9501005v1",
    "title": "A Tool for Collecting Domain Dependent Sortal Constraints From Corpora",
    "summary": "In this paper, we describe a tool designed to generate semi-automatically the\nsortal constraints specific to a domain to be used in a natural language (NL)\nunderstanding system. This tool is evaluated using the SRI Gemini NL\nunderstanding system in the ATIS domain.",
    "published": "1995-01-31T13:27:52Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9501005v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Francois Andry",
      "Mark Gawron",
      "John Dowding",
      "Robert Moore"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502001v1",
    "title": "Interlingual Lexical Organisation for Multilingual Lexical Databases in\n  NADIA",
    "summary": "We propose a lexical organisation for multilingual lexical databases (MLDB).\nThis organisation is based on acceptions (word-senses). We detail this lexical\norganisation and show a mock-up built to experiment with it. We also present\nour current work in defining and prototyping a specialised system for the\nmanagement of acception-based MLDB. Keywords: multilingual lexical database,\nacception, linguistic structure.",
    "published": "1995-02-02T13:09:03Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502001v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Gilles Serasset"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502002v1",
    "title": "Learning Unification-Based Natural Language Grammars",
    "summary": "When parsing unrestricted language, wide-covering grammars often\nundergenerate. Undergeneration can be tackled either by sentence correction, or\nby grammar correction. This thesis concentrates upon automatic grammar\ncorrection (or machine learning of grammar) as a solution to the problem of\nundergeneration. Broadly speaking, grammar correction approaches can be\nclassified as being either {\\it data-driven}, or {\\it model-based}. Data-driven\nlearners use data-intensive methods to acquire grammar. They typically use\ngrammar formalisms unsuited to the needs of practical text processing and\ncannot guarantee that the resulting grammar is adequate for subsequent semantic\ninterpretation. That is, data-driven learners acquire grammars that generate\nstrings that humans would judge to be grammatically ill-formed (they {\\it\novergenerate}) and fail to assign linguistically plausible parses. Model-based\nlearners are knowledge-intensive and are reliant for success upon the\ncompleteness of a {\\it model of grammaticality}. But in practice, the model\nwill be incomplete. Given that in this thesis we deal with undergeneration by\nlearning, we hypothesise that the combined use of data-driven and model-based\nlearning would allow data-driven learning to compensate for model-based\nlearning's incompleteness, whilst model-based learning would compensate for\ndata-driven learning's unsoundness. We describe a system that we have used to\ntest the hypothesis empirically. The system combines data-driven and\nmodel-based learning to acquire unification-based grammars that are more\nsuitable for practical text parsing. Using the Spoken English Corpus as data,\nand by quantitatively measuring undergeneration, overgeneration and parse\nplausibility, we show that this hypothesis is correct.",
    "published": "1995-02-03T12:17:28Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502002v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Miles Osborne"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502004v1",
    "title": "Bottom-Up Earley Deduction",
    "summary": "We propose a bottom-up variant of Earley deduction. Bottom-up deduction is\npreferable to top-down deduction because it allows incremental processing (even\nfor head-driven grammars), it is data-driven, no subsumption check is needed,\nand preference values attached to lexical items can be used to guide best-first\nsearch. We discuss the scanning step for bottom-up Earley deduction and\nindexing schemes that help avoid useless deduction steps.",
    "published": "1995-02-05T16:59:05Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502004v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Gregor Erbach"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502003v1",
    "title": "ProFIT: Prolog with Features, Inheritance and Templates",
    "summary": "ProFIT is an extension of Standard Prolog with Features, Inheritance and\nTemplates. ProFIT allows the programmer or grammar developer to declare an\ninheritance hierarchy, features and templates. Sorted feature terms can be used\nin ProFIT programs together with Prolog terms to provide a clearer description\nlanguage for linguistic structures. ProFIT compiles all sorted feature terms\ninto a Prolog term representation, so that the built-in Prolog term unification\ncan be used for the unification of sorted feature structures, and no special\nunification algorithm is needed. ProFIT programs are compiled into Prolog\nprograms, so that no meta-interpreter is needed for their execution. ProFIT\nthus provides a direct step from grammars developed with sorted feature terms\nto Prolog programs usable for practical NLP systems.",
    "published": "1995-02-05T17:22:23Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502003v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Gregor Erbach"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502005v1",
    "title": "Off-line Optimization for Earley-style HPSG Processing",
    "summary": "A novel approach to HPSG based natural language processing is described that\nuses an off-line compiler to automatically prime a declarative grammar for\ngeneration or parsing, and inputs the primed grammar to an advanced\nEarley-style processor. This way we provide an elegant solution to the problems\nwith empty heads and efficient bidirectional processing which is illustrated\nfor the special case of HPSG generation. Extensive testing with a large HPSG\ngrammar revealed some important constraints on the form of the grammar.",
    "published": "1995-02-07T11:22:16Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502005v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Guido Minnen",
      "Dale Gerdemann",
      "Thilo Goetz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502006v1",
    "title": "Rapid Development of Morphological Descriptions for Full Language\n  Processing Systems",
    "summary": "I describe a compiler and development environment for feature-augmented\ntwo-level morphology rules integrated into a full NLP system. The compiler is\noptimized for a class of languages including many or most European ones, and\nfor rapid development and debugging of descriptions of new languages. The key\ndesign decision is to compose morphophonological and morphosyntactic\ninformation, but not the lexicon, when compiling the description. This results\nin typical compilation times of about a minute, and has allowed a reasonably\nfull, feature-based description of French inflectional morphology to be\ndeveloped in about a month by a linguist new to the system.",
    "published": "1995-02-08T10:26:31Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502006v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "David Carter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502007v1",
    "title": "Utilization of a Lexicon for Spelling Correction in Modern Greek",
    "summary": "In this paper we present an interactive spelling correction system for Modern\nGreek. The entire system is based on a morphological lexicon. Emphasis is given\nto the development of the lexicon, especially as far as storage economy, speed\nefficiency and dictionary coverage is concerned. Extensive research was\nconducted from both the computer engineering and linguisting fields, in order\nto describe inflectional morphology as economically as possible.",
    "published": "1995-02-09T15:05:14Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502007v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "A. Vagelatos",
      "T. Triantopoulou",
      "C. Tsalidis",
      "D. Christodoulakis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502009v1",
    "title": "On Learning More Appropriate Selectional Restrictions",
    "summary": "We present some variations affecting the association measure and thresholding\non a technique for learning Selectional Restrictions from on-line corpora. It\nuses a wide-coverage noun taxonomy and a statistical measure to generalize the\nappropriate semantic classes. Evaluation measures for the Selectional\nRestrictions learning task are discussed. Finally, an experimental evaluation\nof these variations is reported.",
    "published": "1995-02-09T19:10:33Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502009v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Francesc Ribas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502008v1",
    "title": "A Robust and Efficient Three-Layered Dialogue Component for a\n  Speech-to-Speech Translation System",
    "summary": "We present the dialogue component of the speech-to-speech translation system\nVERBMOBIL. In contrast to conventional dialogue systems it mediates the\ndialogue while processing maximally 50% of the dialogue in depth. Special\nrequirements like robustness and efficiency lead to a 3-layered hybrid\narchitecture for the dialogue module, using statistics, an automaton and a\nplanner. A dialogue memory is constructed incrementally.",
    "published": "1995-02-10T12:18:02Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502008v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Jan Alexandersson",
      "Elisabeth Maier",
      "Norbert Reithinger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502010v1",
    "title": "NPtool, a detector of English noun phrases",
    "summary": "NPtool is a fast and accurate system for extracting noun phrases from English\ntexts for the purposes of e.g. information retrieval, translation unit\ndiscovery, and corpus studies. After a general introduction, the system\narchitecture is presented in outline. Then follows an examination of a recently\nwritten Constraint Syntax. An evaluation report concludes the paper.",
    "published": "1995-02-13T13:16:51Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502010v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Atro Voutilainen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502012v2",
    "title": "A syntax-based part-of-speech analyser",
    "summary": "There are two main methodologies for constructing the knowledge base of a\nnatural language analyser: the linguistic and the data-driven. Recent\nstate-of-the-art part-of-speech taggers are based on the data-driven approach.\nBecause of the known feasibility of the linguistic rule-based approach at\nrelated levels of description, the success of the data-driven approach in\npart-of-speech analysis may appear surprising. In this paper, a case is made\nfor the syntactic nature of part-of-speech tagging. A new tagger of English\nthat uses only linguistic distributional rules is outlined and empirically\nevaluated. Tested against a benchmark corpus of 38,000 words of previously\nunseen text, this syntax-based system reaches an accuracy of above 99%.\nCompared to the 95-97% accuracy of its best competitors, this result suggests\nthe feasibility of the linguistic approach also in part-of-speech analysis.",
    "published": "1995-02-13T13:17:20Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502012v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Atro Voutilainen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502011v1",
    "title": "Specifying a shallow grammatical representation for parsing purposes",
    "summary": "Is it possible to specify a grammatical representation (descriptors and their\napplication guidelines) to such a degree that it can be consistently applied by\ndifferent grammarians e.g. for producing a benchmark corpus for parser\nevaluation? Arguments for and against have been given, but very little\nempirical evidence. In this article we report on a double-blind experiment with\na surface-oriented morphosyntactic grammatical representation used in a\nlarge-scale English parser. We argue that a consistently applicable\nrepresentation for morphology and also shallow syntax can be specified. A\ngrammatical representation with a near-100% coverage of running text can be\nspecified with a reasonable effort, especially if the representation is based\non structural distinctions (i.e. it is structurally resolvable).",
    "published": "1995-02-13T13:17:41Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502011v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Atro Voutilainen",
      "Timo Jarvinen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502013v1",
    "title": "Ambiguity resolution in a reductionistic parser",
    "summary": "We are concerned with dependency-oriented morphosyntactic parsing of running\ntext. While a parsing grammar should avoid introducing structurally\nunresolvable distinctions in order to optimise on the accuracy of the parser,\nit also is beneficial for the grammarian to have as expressive a structural\nrepresentation available as possible. In a reductionistic parsing system this\npolicy may result in considerable ambiguity in the input; however, even massive\nambiguity can be tackled efficiently with an accurate parsing description and\neffective parsing technology.",
    "published": "1995-02-13T13:51:24Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502013v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Atro Voutilainen",
      "Pasi Tapanainen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502014v1",
    "title": "Ellipsis and Quantification: a substitutional approach",
    "summary": "The paper describes a substitutional approach to ellipsis resolution giving\ncomparable results to Dalrymple, Shieber and Pereira (1991), but without the\nneed for order-sensitive interleaving of quantifier scoping and ellipsis\nresolution. It is argued that the order-independence results from viewing\nsemantic interpretation as building a description of a semantic composition,\ninstead of the more common view of interpretation as actually performing the\ncomposition",
    "published": "1995-02-13T16:40:05Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502014v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Richard Crouch"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502015v1",
    "title": "The Semantics of Resource Sharing in Lexical-Functional Grammar",
    "summary": "We argue that the resource sharing that is commonly manifest in semantic\naccounts of coordination is instead appropriately handled in terms of\nstructure-sharing in LFG f-structures. We provide an extension to the previous\naccount of LFG semantics (Dalrymple et al., 1993b) according to which\ndependencies between f-structures are viewed as resources; as a result a\none-to-one correspondence between uses of f-structures and meanings is\nmaintained. The resulting system is sufficiently restricted in cases where\nother approaches overgenerate; the very property of resource-sensitivity for\nwhich resource sharing appears to be problematic actually provides explanatory\nadvantages over systems that more freely replicate resources during derivation.",
    "published": "1995-02-13T20:03:17Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502015v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Andrew Kehler",
      "Mary Dalrymple",
      "John Lamping",
      "Vijay Saraswat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502020v1",
    "title": "Formalization and Parsing of Typed Unification-Based ID/LP Grammars",
    "summary": "This paper defines unification based ID/LP grammars based on typed feature\nstructures as nonterminals and proposes a variant of Earley's algorithm to\ndecide whether a given input sentence is a member of the language generated by\na particular typed unification ID/LP grammar. A solution to the problem of the\nnonlocal flow of information in unification ID/LP grammars as discussed in\nSeiffert (1991) is incorporated into the algorithm. At the same time, it tries\nto connect this technical work with linguistics by presenting an example of the\nproblem resulting from HPSG approaches to linguistics (Hinrichs and Nakasawa\n1994, Richter and Sailer 1995) and with computational linguistics by drawing\nconnections from this approach to systems implementing HPSG, especially the\nTROLL system, Gerdemann et al. (forthcoming).",
    "published": "1995-02-14T11:15:24Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502020v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Frank Morawietz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502016v2",
    "title": "Higher-order Linear Logic Programming of Categorial Deduction",
    "summary": "We show how categorial deduction can be implemented in higher-order (linear)\nlogic programming, thereby realising parsing as deduction for the associative\nand non-associative Lambek calculi. This provides a method of solution to the\nparsing problem of Lambek categorial grammar applicable to a variety of its\nextensions.",
    "published": "1995-02-14T13:26:18Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502016v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Glyn Morrill"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502017v2",
    "title": "Deterministic Consistency Checking of LP Constraints",
    "summary": "We provide a constraint based computational model of linear precedence as\nemployed in the HPSG grammar formalism. An extended feature logic which adds a\nwide range of constraints involving precedence is described. A sound, complete\nand terminating deterministic constraint solving procedure is given.\nDeterministic computational model is achieved by weakening the logic such that\nit is sufficient for linguistic applications involving word-order.",
    "published": "1995-02-14T16:53:49Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502017v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Suresh Manandhar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502018v3",
    "title": "Algorithms for Analysing the Temporal Structure of Discourse",
    "summary": "We describe a method for analysing the temporal structure of a discourse\nwhich takes into account the effects of tense, aspect, temporal adverbials and\nrhetorical structure and which minimises unnecessary ambiguity in the temporal\nstructure. It is part of a discourse grammar implemented in Carpenter's ALE\nformalism. The method for building up the temporal structure of the discourse\ncombines constraints and preferences: we use constraints to reduce the number\nof possible structures, exploiting the HPSG type hierarchy and unification for\nthis purpose; and we apply preferences to choose between the remaining options\nusing a temporal centering mechanism. We end by recommending that an\nunderspecified representation of the structure using these techniques be used\nto avoid generating the temporal/rhetorical structure until higher-level\ninformation can be used to disambiguate.",
    "published": "1995-02-15T17:54:20Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502018v3.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Janet Hitzeman",
      "Marc Moens",
      "Claire Grover"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502019v1",
    "title": "Integrating \"Free\" Word Order Syntax and Information Structure",
    "summary": "This paper describes a combinatory categorial formalism called Multiset-CCG\nthat can capture the syntax and interpretation of ``free'' word order in\nlanguages such as Turkish. The formalism compositionally derives the\npredicate-argument structure and the information structure (e.g. topic, focus)\nof a sentence in parallel, and uniformly handles word order variation among the\narguments and adjuncts within a clause, as well as in complex clauses and\nacross clause boundaries.",
    "published": "1995-02-15T21:38:21Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502019v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Beryl Hoffman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502021v1",
    "title": "A Tractable Extension of Linear Indexed Grammars",
    "summary": "It has been shown that Linear Indexed Grammars can be processed in polynomial\ntime by exploiting constraints which make possible the extensive use of\nstructure-sharing. This paper describes a formalism that is more powerful than\nLinear Indexed Grammar, but which can also be processed in polynomial time\nusing similar techniques. The formalism, which we refer to as Partially Linear\nPATR manipulates feature structures rather than stacks.",
    "published": "1995-02-17T09:30:27Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502021v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Bill Keller",
      "David Weir"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502022v1",
    "title": "Stochastic HPSG",
    "summary": "In this paper we provide a probabilistic interpretation for typed feature\nstructures very similar to those used by Pollard and Sag. We begin with a\nversion of the interpretation which lacks a treatment of re-entrant feature\nstructures, then provide an extended interpretation which allows them. We\nsketch algorithms allowing the numerical parameters of our probabilistic\ninterpretations of HPSG to be estimated from corpora.",
    "published": "1995-02-17T10:02:35Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502022v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Chris Brew"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502023v1",
    "title": "Splitting the Reference Time: Temporal Anaphora and Quantification in\n  DRT",
    "summary": "This paper presents an analysis of temporal anaphora in sentences which\ncontain quantification over events, within the framework of Discourse\nRepresentation Theory. The analysis in (Partee 1984) of quantified sentences,\nintroduced by a temporal connective, gives the wrong truth-conditions when the\ntemporal connective in the subordinate clause is \"before\" or \"after\". This\nproblem has been previously analyzed in (de Swart 1991) as an instance of the\nproportion problem, and given a solution from a Generalized Quantifier\napproach. By using a careful distinction between the different notions of\nreference time, based on (Kamp and Reyle 1993), we propose a solution to this\nproblem, within the framework of DRT. We show some applications of this\nsolution to additional temporal anaphora phenomena in quantified sentences.",
    "published": "1995-02-18T15:03:04Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502023v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Rani Nelken",
      "Nissim Francez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502024v2",
    "title": "A Robust Parser Based on Syntactic Information",
    "summary": "In this paper, we propose a robust parser which can parse extragrammatical\nsentences. This parser can recover them using only syntactic information. It\ncan be easily modified and extended because it utilize only syntactic\ninformation.",
    "published": "1995-02-21T01:57:32Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502024v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Kong Joo Lee",
      "Cheol Jung Kweon",
      "Jungyun Seo",
      "Gil Chang Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502025v1",
    "title": "Principle Based Semantics for HPSG",
    "summary": "The paper presents a constraint based semantic formalism for HPSG. The\nsyntax-semantics interface directly implements syntactic conditions on\nquantifier scoping and distributivity. The construction of semantic\nrepresentations is guided by general principles governing the interaction\nbetween syntax and semantics. Each of these principles acts as a constraint to\nnarrow down the set of possible interpretations of a sentence. Meanings of\nambiguous sentences are represented by single partial representations\n(so-called U(nderspecified) D(iscourse) R(epresentation) S(tructure)s) to which\nfurther constraints can be added monotonically to gain more information about\nthe content of a sentence. There is no need to build up a large number of\nalternative representations of the sentence which are then filtered by\nsubsequent discourse and world knowledge. The advantage of UDRSs is not only\nthat they allow for monotonic incremental interpretation but also that they are\nequipped with truth conditions and a proof theory that allows for inferences to\nbe drawn directly on structures where quantifier scope is not resolved.",
    "published": "1995-02-21T13:32:27Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502025v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Anette Frank",
      "Uwe Reyle"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502026v2",
    "title": "On Reasoning with Ambiguities",
    "summary": "The paper adresses the problem of reasoning with ambiguities. Semantic\nrepresentations are presented that leave scope relations between quantifiers\nand/or other operators unspecified. Truth conditions are provided for these\nrepresentations and different consequence relations are judged on the basis of\nintuitive correctness. Finally inference patterns are presented that operate\ndirectly on these underspecified structures, i.e. do not rely on any\ntranslation into the set of their disambiguations.",
    "published": "1995-02-21T13:36:36Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502026v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Uwe Reyle"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502027v1",
    "title": "Towards an Account of Extraposition in HPSG",
    "summary": "This paper investigates the syntax of extraposition in the HPSG framework. We\npresent English and German data (partly taken from corpora), and provide an\nanalysis using lexical rules and a nonlocal dependency. The condition for\nbinding this dependency is formulated relative to the antecedent of the\nextraposed phrase, which entails that no fixed site for extraposition exists.\nOur analysis accounts for the interaction of extraposition with fronting and\ncoordination, and predicts constraints on multiple extraposition.",
    "published": "1995-02-21T18:04:25Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502027v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Frank Keller"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502028v1",
    "title": "Lexical Acquisition via Constraint Solving",
    "summary": "This paper describes a method to automatically acquire the syntactic and\nsemantic classifications of unknown words. Our method reduces the search space\nof the lexical acquisition problem by utilizing both the left and the right\ncontext of the unknown word. Link Grammar provides a convenient framework in\nwhich to implement our method.",
    "published": "1995-02-22T22:31:11Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502028v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Ted Pedersen",
      "Weidong Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502030v1",
    "title": "Bi-directional memory-based dialog translation: The KEMDT approach",
    "summary": "A bi-directional Korean/English dialog translation system is designed and\nimplemented using the memory-based translation technique. The system KEMDT\n(Korean/English Memory-based Dialog Translation system) can perform Korean to\nEnglish, and English to Korean translation using unified memory network and\nextended marker passing algorithm. We resolve the word order variation and\nfrequent word omission problems in Korean by classifying the concept sequence\nelement in four different types and extending the marker-\npassing-based-translation algorithm. Unlike the previous memory-based\ntranslation systems, the KEMDT system develops the bilingual memory network and\nthe unified bi-directional marker passing translation algorithm. For efficient\nlanguage specific processing, we separate the morphological processors from the\nmemory-based translator. The KEMDT technology provides a hierarchical memory\nnetwork and an efficient marker-based control for the recent example-based MT\nparadigm.",
    "published": "1995-02-23T07:58:41Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502030v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Geunbae Lee",
      "Hanmin Jung",
      "Jong-Hyeok Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502031v1",
    "title": "Cooperative Error Handling and Shallow Processing",
    "summary": "This paper is concerned with the detection and correction of sub-sentential\nEnglish text errors. Previous spelling programs, unless restricted to a very\nsmall set of words, have operated as post-processors. And to date, grammar\ncheckers and other programs which deal with ill-formed input usually step\ndirectly from spelling considerations to a full-scale parse, assuming a\ncomplete sentence. Work described below is aimed at evaluating the\neffectiveness of shallow (sub-sentential) processing and the feasibility of\ncooperative error checking, through building and testing appropriately an\nerror-processing system. A system under construction is outlined which\nincorporates morphological checks (using new two-level error rules) over a\ndirected letter graph, tag positional trigrams and partial parsing. Intended\ntesting is discussed.",
    "published": "1995-02-23T11:19:11Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502031v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Tanya Bowden"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502032v1",
    "title": "An NLP Approach to a Specific Type of Texts: Car Accident Reports",
    "summary": "The work reported here is the result of a study done within a larger project\non the ``Semantics of Natural Languages'' viewed from the field of Artificial\nIntelligence and Computational Linguistics. In this project, we have chosen a\ncorpus of insurance claim reports. These texts deal with a relatively\ncircumscribed domain, that of road traffic, thereby limiting the\nextra-linguistic knowledge necessary to understand them. Moreover, these texts\npresent a number of very specific characteristics, insofar as they are written\nin a quasi-institutional setting which imposes many constraints on their\nproduction. We first determine what these constraints are in order to then show\nhow they provide the writer with the means to create as succint a text as\npossible, and in a symmetric way, how they provide the reader with the means to\ninterpret the text and to distinguish between its factual and argumentative\naspects.",
    "published": "1995-02-23T17:47:57Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502032v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Dominique Estival",
      "Francoise Gayral"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502029v1",
    "title": "Topic Identification in Discourse",
    "summary": "This paper proposes a corpus-based language model for topic identification.\nWe analyze the association of noun-noun and noun-verb pairs in LOB Corpus. The\nword association norms are based on three factors: 1) word importance, 2) pair\nco-occurrence, and 3) distance. They are trained on the paragraph and sentence\nlevels for noun-noun and noun-verb pairs, respectively. Under the topic\ncoherence postulation, the nouns that have the strongest connectivities with\nthe other nouns and verbs in the discourse form the preferred topic set. The\ncollocational semantics then is used to identify the topics from paragraphs and\nto discuss the topic shift phenomenon among paragraphs.",
    "published": "1995-02-23T19:14:36Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502029v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Kuang-hua Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502034v1",
    "title": "Grouping Words Using Statistical Context",
    "summary": "This paper (cmp-lg/yymmnnn) has been accepted for publication in the student\nsession of EACL-95. It outlines ongoing work using statistical and unsupervised\nneural network methods for clustering words in untagged corpora. Such\napproaches are of interest when attempting to understand the development of\nhuman intuitive categorization of language as well as for trying to improve\ncomputational methods in natural language understanding. Some preliminary\nresults using a simple statistical approach are described, along with work\nusing an unsupervised neural network to distinguish between the sense classes\ninto which words fall.",
    "published": "1995-02-24T13:25:14Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502034v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Christopher C. Huckle"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502035v1",
    "title": "Incorporating \"Unconscious Reanalysis\" into an Incremental, Monotonic\n  Parser",
    "summary": "This paper describes an implementation based on a recent model in the\npsycholinguistic literature. We define a parsing operation which allows the\nreanalysis of dependencies within an incremental and monotonic processing\narchitecture, and discuss search strategies for its application in a\nhead-initial language (English) and a head-final language (Japanese).",
    "published": "1995-02-24T16:41:14Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502035v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Patrick Sturt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502033v1",
    "title": "An Algorithm to Co-Ordinate Anaphora Resolution and PPS Disambiguation\n  Process",
    "summary": "This paper concerns both anaphora resolution and prepositional phrase (PP)\nattachment that are the most frequent ambiguities in natural language\nprocessing. Several methods have been proposed to deal with each phenomenon\nseparately, however none of proposed systems has considered the way of dealing\nboth phenomena. We tackle this issue, proposing an algorithm to co-ordinate the\ntreatment of these two problems efficiently, i.e., the aim is also to exploit\nat each step all the results that each component can provide.",
    "published": "1995-02-24T19:34:10Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502033v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Saliha Azzam"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502036v1",
    "title": "Literal Movement Grammars",
    "summary": "Literal movement grammars (LMGs) provide a general account of extraposition\nphenomena through an attribute mechanism allowing top-down displacement of\nsyntactical information. LMGs provide a simple and efficient treatment of\ncomplex linguistic phenomena such as cross-serial dependencies in German and\nDutch---separating the treatment of natural language into a parsing phase\nclosely resembling traditional context-free treatment, and a disambiguation\nphase which can be carried out using matching, as opposed to full unification\nemployed in most current grammar formalisms of linguistical relevance.",
    "published": "1995-02-27T11:08:13Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502036v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Annius V. Groenink"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502037v1",
    "title": "A State-Transition Grammar for Data-Oriented Parsing",
    "summary": "This paper presents a grammar formalism designed for use in data-oriented\napproaches to language processing. The formalism is best described as a\nright-linear indexed grammar extended in linguistically interesting ways. The\npaper goes on to investigate how a corpus pre-parsed with this formalism may be\nprocessed to provide a probabilistic language model for use in the parsing of\nfresh texts.",
    "published": "1995-02-27T15:18:23Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502037v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "David Tugwell"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502038v1",
    "title": "Implementation and evaluation of a German HMM for POS disambiguation",
    "summary": "A German language model for the Xerox HMM tagger is presented. This model's\nperformance is compared with two other German taggers with partial parameter\nre-estimation and full adaption of parameters from pre-tagged corpora. The\nambiguity types resolved by this model are analysed and compared to ambiguity\ntypes of English and French. Finally, the model's error types are described. I\nargue that although the overall performance of these models for German is\ncomparable to results for English and French, a more exact analysis\ndemonstrates important differences in the types of disambiguation involved for\nGerman.",
    "published": "1995-02-27T18:15:04Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502038v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Helmut Feldweg"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9502039v2",
    "title": "Multilingual Sentence Categorization according to Language",
    "summary": "In this paper, we describe an approach to sentence categorization which has\nthe originality to be based on natural properties of languages with no training\nset dependency. The implementation is fast, small, robust and textual errors\ntolerant. Tested for french, english, spanish and german discrimination, the\nsystem gives very interesting results, achieving in one test 99.4% correct\nassignments on real sentences.\n  The resolution power is based on grammatical words (not the most common\nwords) and alphabet. Having the grammatical words and the alphabet of each\nlanguage at its disposal, the system computes for each of them its likelihood\nto be selected. The name of the language having the optimum likelihood will tag\nthe sentence --- but non resolved ambiguities will be maintained. We will\ndiscuss the reasons which lead us to use these linguistic facts and present\nseveral directions to improve the system's classification performance.\n  Categorization sentences with linguistic properties shows that difficult\nproblems have sometimes simple solutions.",
    "published": "1995-02-28T18:02:43Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9502039v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Emmanuel Giguet"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9503001v1",
    "title": "Using a Corpus for Teaching Turkish Morphology",
    "summary": "This paper reports on the preliminary phase of our ongoing research towards\ndeveloping an intelligent tutoring environment for Turkish grammar. One of the\ncomponents of this environment is a corpus search tool which, among other\naspects of the language, will be used to present the learner sample sentences\nalong with their morphological analyses. Following a brief introduction to the\nTurkish language and its morphology, the paper describes the morphological\nanalysis and ambiguity resolution used to construct the corpus used in the\nsearch tool. Finally, implementation issues and details involving the user\ninterface of the tool are discussed.",
    "published": "1995-03-01T09:48:07Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9503001v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "H. Altay Guvenir",
      "Kemal Oflazer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9503002v1",
    "title": "Computational dialectology in Irish Gaelic",
    "summary": "Dialect groupings can be discovered objectively and automatically by cluster\nanalysis of phonetic transcriptions such as those found in a linguistic atlas.\nThe first step in the analysis, the computation of linguistic distance between\neach pair of sites, can be computed as Levenshtein distance between phonetic\nstrings. This correlates closely with the much more laborious technique of\ndetermining and counting isoglosses, and is more accurate than the more\nfamiliar metric of computing Hamming distance based on whether vocabulary\nentries match. In the actual clustering step, traditional agglomerative\nclustering works better than the top-down technique of partitioning around\nmedoids. When agglomerative clustering of phonetic string comparison distances\nis applied to Gaelic, reasonable dialect boundaries are obtained, corresponding\nto national and (within Ireland) provincial boundaries.",
    "published": "1995-03-01T14:34:45Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9503002v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Brett Kessler"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9503003v1",
    "title": "Tagging French -- comparing a statistical and a constraint-based method",
    "summary": "In this paper we compare two competing approaches to part-of-speech tagging,\nstatistical and constraint-based disambiguation, using French as our test\nlanguage. We imposed a time limit on our experiment: the amount of time spent\non the design of our constraint system was about the same as the time we used\nto train and test the easy-to-implement statistical model. We describe the two\nsystems and compare the results. The accuracy of the statistical method is\nreasonably good, comparable to taggers for English. But the constraint-based\ntagger seems to be superior even with the limited time we allowed ourselves for\nrule development.",
    "published": "1995-03-02T16:38:49Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9503003v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Jean-Pierre Chanod",
      "Pasi Tapanainen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9503004v2",
    "title": "Creating a tagset, lexicon and guesser for a French tagger",
    "summary": "We earlier described two taggers for French, a statistical one and a\nconstraint-based one. The two taggers have the same tokeniser and morphological\nanalyser. In this paper, we describe aspects of this work concerned with the\ndefinition of the tagset, the building of the lexicon, derived from an existing\ntwo-level morphological analyser, and the definition of a lexical transducer\nfor guessing unknown words.",
    "published": "1995-03-02T18:53:30Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9503004v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Jean-Pierre Chanod",
      "Pasi Tapanainen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9503005v1",
    "title": "A specification language for Lexical Functional Grammars",
    "summary": "This paper defines a language L for specifying LFG grammars. This enables\nconstraints on LFG's composite ontology (c-structures synchronised with\nf-structures) to be stated directly; no appeal to the LFG construction\nalgorithm is needed. We use L to specify schemata annotated rules and the LFG\nuniqueness, completeness and coherence principles. Broader issues raised by\nthis work are noted and discussed.",
    "published": "1995-03-03T12:33:04Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9503005v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Patrick Blackburn",
      "Claire Gardent"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9503006v1",
    "title": "ParseTalk about Sentence- and Text-Level Anaphora",
    "summary": "We provide a unified account of sentence-level and text-level anaphora within\nthe framework of a dependency-based grammar model. Criteria for anaphora\nresolution within sentence boundaries rephrase major concepts from GB's binding\ntheory, while those for text-level anaphora incorporate an adapted version of a\nGrosz-Sidner-style focus model.",
    "published": "1995-03-03T16:53:53Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9503006v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Michael Strube",
      "Udo Hahn"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9503007v1",
    "title": "The Semantics of Motion",
    "summary": "In this paper we present a semantic study of motion complexes (ie. of a\nmotion verb followed by a spatial preposition). We focus on the spatial and the\ntemporal intrinsic semantic properties of the motion verbs, on the one hand,\nand of the spatial prepositions, on the other hand. Then, we address the\nproblem of combining these basic semantics in order to formally and\nautomatically derive the spatiotemporal semantics of a motion complex from the\nspatiotemporal properties of its components.",
    "published": "1995-03-07T16:30:01Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9503007v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Pierre Sablayrolles"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9503008v1",
    "title": "Ellipsis and Higher-Order Unification",
    "summary": "We present a new method for characterizing the interpretive possibilities\ngenerated by elliptical constructions in natural language. Unlike previous\nanalyses, which postulate ambiguity of interpretation or derivation in the full\nclause source of the ellipsis, our analysis requires no such hidden ambiguity.\nFurther, the analysis follows relatively directly from an abstract statement of\nthe ellipsis interpretation problem. It predicts correctly a wide range of\ninteractions between ellipsis and other semantic phenomena such as quantifier\nscope and bound anaphora. Finally, although the analysis itself is stated\nnonprocedurally, it admits of a direct computational method for generating\ninterpretations.",
    "published": "1995-03-08T18:02:11Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9503008v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Mary Dalrymple",
      "Stuart M. Shieber",
      "Fernando C. N. Pereira"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9503009v1",
    "title": "Distributional Part-of-Speech Tagging",
    "summary": "This paper presents an algorithm for tagging words whose part-of-speech\nproperties are unknown. Unlike previous work, the algorithm categorizes word\ntokens in context instead of word types. The algorithm is evaluated on the\nBrown Corpus.",
    "published": "1995-03-08T18:36:40Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9503009v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Hinrich Schuetze"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9503010v1",
    "title": "Corpus-based Method for Automatic Identification of Support Verbs for\n  Nominalizations",
    "summary": "Nominalization is a highly productive phenomena in most languages. The\nprocess of nominalization ejects a verb from its syntactic role into a nominal\nposition. The original verb is often replaced by a semantically emptied support\nverb (e.g., \"make a proposal\"). The choice of a support verb for a given\nnominalization is unpredictable, causing a problem for language learners as\nwell as for natural language processing systems. We present here a method of\ndiscovering support verbs from an untagged corpus via low-level syntactic\nprocessing and comparison of arguments attached to verbal forms and potential\nnominalized forms. The result of the process is a list of potential support\nverbs for the nominalized form of a given predicate.",
    "published": "1995-03-09T12:23:50Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9503010v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Gregory Grefenstette",
      "Simone Teufel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9503012v1",
    "title": "A Note on Zipf's Law, Natural Languages, and Noncoding DNA regions",
    "summary": "In Phys. Rev. Letters (73:2, 5 Dec. 94), Mantegna et al. conclude on the\nbasis of Zipf rank frequency data that noncoding DNA sequence regions are more\nlike natural languages than coding regions. We argue on the contrary that an\nempirical fit to Zipf's ``law'' cannot be used as a criterion for similarity to\nnatural languages. Although DNA is a presumably an ``organized system of\nsigns'' in Mandelbrot's (1961) sense, an observation of statistical features of\nthe sort presented in the Mantegna et al. paper does not shed light on the\nsimilarity between DNA's ``grammar'' and natural language grammars, just as the\nobservation of exact Zipf-like behavior cannot distinguish between the\nunderlying processes of tossing an $M$ sided die or a finite-state branching\nprocess.",
    "published": "1995-03-09T20:08:39Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9503012v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL",
      "q-bio"
    ],
    "authors": [
      "Partha Niyogi",
      "Robert C. Berwick"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9503011v1",
    "title": "Improving Statistical Language Model Performance with Automatically\n  Generated Word Hierarchies",
    "summary": "An automatic word classification system has been designed which processes\nword unigram and bigram frequency statistics extracted from a corpus of natural\nlanguage utterances. The system implements a binary top-down form of word\nclustering which employs an average class mutual information metric. Resulting\nclassifications are hierarchical, allowing variable class granularity. Words\nare represented as structural tags --- unique $n$-bit numbers the most\nsignificant bit-patterns of which incorporate class information. Access to a\nstructural tag immediately provides access to all classification levels for the\ncorresponding word. The classification system has successfully revealed some of\nthe structure of English, from the phonemic to the semantic level. The system\nhas been compared --- directly and indirectly --- with other recent word\nclassification systems. Class based interpolated language models have been\nconstructed to exploit the extra information supplied by the classifications\nand some experiments have shown that the new models improve model performance.",
    "published": "1995-03-09T21:07:06Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9503011v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "John McMahon",
      "F. J. Smith"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9503013v2",
    "title": "Incremental Interpretation: Applications, Theory, and Relationship to\n  Dynamic Semantics",
    "summary": "Why should computers interpret language incrementally? In recent years\npsycholinguistic evidence for incremental interpretation has become more and\nmore compelling, suggesting that humans perform semantic interpretation before\nconstituent boundaries, possibly word by word. However, possible computational\napplications have received less attention. In this paper we consider various\npotential applications, in particular graphical interaction and dialogue. We\nthen review the theoretical and computational tools available for mapping from\nfragments of sentences to fully scoped semantic representations. Finally, we\ntease apart the relationship between dynamic semantics and incremental\ninterpretation.",
    "published": "1995-03-13T20:17:33Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9503013v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "David Milward",
      "Robin Cooper"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9503014v1",
    "title": "Non-Constituent Coordination: Theory and Practice",
    "summary": "Despite the large amount of theoretical work done on non-constituent\ncoordination during the last two decades, many computational systems still\ntreat coordination using adapted parsing strategies, in a similar fashion to\nthe SYSCONJ system developed for ATNs. This paper reviews the theoretical\nliterature, and shows why many of the theoretical accounts actually have worse\ncoverage than accounts based on processing. Finally, it shows how processing\naccounts can be described formally and declaratively in terms of Dynamic\nGrammars.",
    "published": "1995-03-14T10:59:42Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9503014v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "David Milward"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9503015v1",
    "title": "Incremental Interpretation of Categorial Grammar",
    "summary": "The paper describes a parser for Categorial Grammar which provides fully word\nby word incremental interpretation. The parser does not require fragments of\nsentences to form constituents, and thereby avoids problems of spurious\nambiguity. The paper includes a brief discussion of the relationship between\nbasic Categorial Grammar and other formalisms such as HPSG, Dependency Grammar\nand the Lambek Calculus. It also includes a discussion of some of the issues\nwhich arise when parsing lexicalised grammars, and the possibilities for using\nstatistical techniques for tuning to particular languages.",
    "published": "1995-03-14T11:30:53Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9503015v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "David Milward"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9503016v2",
    "title": "Natural Language Interfaces to Databases - An Introduction",
    "summary": "This paper is an introduction to natural language interfaces to databases\n(NLIDBs). A brief overview of the history of NLIDBs is first given. Some\nadvantages and disadvantages of NLIDBs are then discussed, comparing NLIDBs to\nformal query languages, form-based interfaces, and graphical interfaces. An\nintroduction to some of the linguistic problems NLIDBs have to confront\nfollows, for the benefit of readers less familiar with computational\nlinguistics. The discussion then moves on to NLIDB architectures, portability\nissues, restricted natural language input systems (including menu-based\nNLIDBs), and NLIDBs with reasoning capabilities. Some less explored areas of\nNLIDB research are then presented, namely database updates, meta-knowledge\nquestions, temporal questions, and multi-modal NLIDBs. The paper ends with\nreflections on the current state of the art.",
    "published": "1995-03-14T19:58:54Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9503016v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "I. Androutsopoulos",
      "G. D. Ritchie",
      "P. Thanisch"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9503017v1",
    "title": "Redundancy in Collaborative Dialogue",
    "summary": "In dialogues in which both agents are autonomous, each agent deliberates\nwhether to accept or reject the contributions of the current speaker. A speaker\ncannot simply assume that a proposal or an assertion will be accepted. However,\nan examination of a corpus of naturally-occurring problem-solving dialogues\nshows that agents often do not explicitly indicate acceptance or rejection.\nRather the speaker must infer whether the hearer understands and accepts the\ncurrent contribution based on indirect evidence provided by the hearer's next\ndialogue contribution. In this paper, I propose a model of the role of\ninformationally redundant utterances in providing evidence to support\ninferences about mutual understanding and acceptance. The model (1) requires a\ntheory of mutual belief that supports mutual beliefs of various strengths; (2)\nexplains the function of a class of informationally redundant utterances that\ncannot be explained by other accounts; and (3) contributes to a theory of\ndialogue by showing how mutual beliefs can be inferred in the absence of the\nmaster-slave assumption.",
    "published": "1995-03-16T21:27:48Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9503017v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Marilyn A. Walker"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9503018v1",
    "title": "Discourse and Deliberation: Testing a Collaborative Strategy",
    "summary": "A discourse strategy is a strategy for communicating with another agent.\nDesigning effective dialogue systems requires designing agents that can choose\namong discourse strategies. We claim that the design of effective strategies\nmust take cognitive factors into account, propose a new method for testing the\nhypothesized factors, and present experimental results on an effective strategy\nfor supporting deliberation. The proposed method of computational dialogue\nsimulation provides a new empirical basis for computational linguistics.",
    "published": "1995-03-16T23:46:51Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9503018v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Marilyn A. Walker"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9503020v1",
    "title": "Different Issues in the Design of a Lemmatizer/Tagger for Basque",
    "summary": "This paper presents relevant issues that have been considered in the design\nof a general purpose lemmatizer/tagger for Basque (EUSLEM). The\nlemmatizer/tagger is conceived as a basic tool necessary for other linguistic\napplications. It uses the lexical data base and the morphological analyzer\npreviously developed and implemented. Due to the characteristics of the\nlanguage, the tagset here proposed in structured in for levels, so that each\nlevel is a refinement of the previous one in the sense that it adds more\ndetailed information. We will focus on the problems found in designing this\ntagset and on the strategies for morphological disambiguation that will be\nused.",
    "published": "1995-03-20T12:06:42Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9503020v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "I. Aduriz",
      "I. Alegria",
      "J. M. Arriola",
      "X. Artola",
      "Diaz de Illarraza A.",
      "N. Ezeiza",
      "K. Gojenola",
      "M. Maritxalar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9503019v1",
    "title": "SATZ - An Adaptive Sentence Segmentation System",
    "summary": "This paper provides a detailed description of the sentence segmentation\nsystem first introduced in cmp-lg/9411022. It provides results of systematic\nexperiments involving sentence boundary determination, including context size,\nlexicon size, and single-case texts. Also included are the results of\nsuccessfully adapting the system to German and French. The source code for the\nsystem is available as a compressed tar file at\nftp://cs-tr.CS.Berkeley.EDU/pub/cstr/satz.tar.Z .",
    "published": "1995-03-20T20:11:05Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9503019v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "David D. Palmer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9503021v1",
    "title": "A Note on the Complexity of Restricted Attribute-Value Grammars",
    "summary": "The recognition problem for attribute-value grammars (AVGs) was shown to be\nundecidable by Johnson in 1988. Therefore, the general form of AVGs is of no\npractical use. In this paper we study a very restricted form of AVG, for which\nthe recognition problem is decidable (though still NP-complete), the R-AVG. We\nshow that the R-AVG formalism captures all of the context free languages and\nmore, and introduce a variation on the so-called `off-line parsability\nconstraint', the `honest parsability constraint', which lets different types of\nR-AVG coincide precisely with well-known time complexity classes.",
    "published": "1995-03-21T13:32:21Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9503021v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Leen Torenvliet",
      "Marten Trautwein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9503022v1",
    "title": "Assessing Complexity Results in Feature Theories",
    "summary": "In this paper, we assess the complexity results of formalisms that describe\nthe feature theories used in computational linguistics. We show that from these\ncomplexity results no immediate conclusions can be drawn about the complexity\nof the recognition problem of unification grammars using these feature\ntheories. On the one hand, the complexity of feature theories does not provide\nan upper bound for the complexity of such unification grammars.\n  On the other hand, the complexity of feature theories need not provide a\nlower bound. Therefore, we argue for formalisms that describe actual\nunification grammars instead of feature theories. Thus the complexity results\nof these formalisms judge upon the hardness of unification grammars in\ncomputational linguistics.",
    "published": "1995-03-21T13:58:01Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9503022v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Marten Trautwein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9503023v1",
    "title": "A fast partial parse of natural language sentences using a connectionist\n  method",
    "summary": "The pattern matching capabilities of neural networks can be used to locate\nsyntactic constituents of natural language. This paper describes a fully\nautomated hybrid system, using neural nets operating within a grammatic\nframework. It addresses the representation of language for connectionist\nprocessing, and describes methods of constraining the problem size. The\nfunction of the network is briefly explained, and results are given.",
    "published": "1995-03-22T11:29:41Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9503023v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Caroline Lyon",
      "Bob Dickerson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9503024v1",
    "title": "From compositional to systematic semantics",
    "summary": "We prove a theorem stating that any semantics can be encoded as a\ncompositional semantics, which means that, essentially, the standard definition\nof compositionality is formally vacuous. We then show that when compositional\nsemantics is required to be \"systematic\" (that is, the meaning function cannot\nbe arbitrary, but must belong to some class), it is possible to distinguish\nbetween compositional and non-compositional semantics. As a result, we believe\nthat the paper clarifies the concept of compositionality and opens a\npossibility of making systematic formal comparisons of different systems of\ngrammars.",
    "published": "1995-03-24T19:03:09Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9503024v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Wlodek Zadrozny"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9503025v1",
    "title": "Co-occurrence Vectors from Corpora vs. Distance Vectors from\n  Dictionaries",
    "summary": "A comparison was made of vectors derived by using ordinary co-occurrence\nstatistics from large text corpora and of vectors derived by measuring the\ninter-word distances in dictionary definitions. The precision of word sense\ndisambiguation by using co-occurrence vectors from the 1987 Wall Street Journal\n(20M total words) was higher than that by using distance vectors from the\nCollins English Dictionary (60K head words + 1.6M definition words). However,\nother experimental results suggest that distance vectors contain some different\nsemantic information from co-occurrence vectors.",
    "published": "1995-04-01T09:26:12Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9503025v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Yoshiki Niwa",
      "Yoshihiko Nitta"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9504001v2",
    "title": "Automatic processing proper names in texts",
    "summary": "This paper shows first the problems raised by proper names in natural\nlanguage processing. Second, it introduces the knowledge representation\nstructure we use based on conceptual graphs. Then it explains the techniques\nwhich are used to process known and unknown proper names. At last, it gives the\nperformance of the system and the further works we intend to deal with.",
    "published": "1995-04-03T12:58:51Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9504001v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Francis Wolinski",
      "Frantz Vichot",
      "Bruno Dillet"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9504002v2",
    "title": "Tagset Design and Inflected Languages",
    "summary": "An experiment designed to explore the relationship between tagging accuracy\nand the nature of the tagset is described, using corpora in English, French and\nSwedish. In particular, the question of internal versus external criteria for\ntagset design is considered, with the general conclusion that external\n(linguistic) criteria should be followed. Some problems associated with tagging\nunknown words in inflected languages are briefly considered.",
    "published": "1995-04-03T15:47:58Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9504002v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "David Elworthy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9504004v1",
    "title": "A Computational Treatment of HPSG Lexical Rules as Covariation in\n  Lexical Entries",
    "summary": "We describe a compiler which translates a set of HPSG lexical rules and their\ninteraction into definite relations used to constrain lexical entries. The\ncompiler ensures automatic transfer of properties unchanged by a lexical rule.\nThus an operational semantics for the full lexical rule mechanism as used in\nHPSG linguistics is provided. Program transformation techniques are used to\nadvance the resulting encoding. The final output constitutes a computational\ncounterpart of the linguistic generalizations captured by lexical rules and\nallows ``on the fly'' application.",
    "published": "1995-04-04T18:00:36Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9504004v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Walt Detmar Meurers",
      "Guido Minnen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9504003v1",
    "title": "Collaborating on Referring Expressions",
    "summary": "This paper presents a computational model of how conversational participants\ncollaborate in order to make a referring action successful. The model is based\non the view of language as goal-directed behavior. We propose that the content\nof a referring expression can be accounted for by the planning paradigm. Not\nonly does this approach allow the processes of building referring expressions\nand identifying their referents to be captured by plan construction and plan\ninference, it also allows us to account for how participants clarify a\nreferring expression by using meta-actions that reason about and manipulate the\nplan derivation that corresponds to the referring expression. To account for\nhow clarification goals arise and how inferred clarification plans affect the\nagent, we propose that the agents are in a certain state of mind, and that this\nstate includes an intention to achieve the goal of referring and a plan that\nthe agents are currently considering. It is this mental state that sanctions\nthe adoption of goals and the acceptance of inferred plans, and so acts as a\nlink between understanding and generation.",
    "published": "1995-04-04T20:59:06Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9504003v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Peter A. Heeman",
      "Graeme Hirst"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9504005v1",
    "title": "Constraint Logic Programming for Natural Language Processing",
    "summary": "This paper proposes an evaluation of the adequacy of the constraint logic\nprogramming paradigm for natural language processing. Theoretical aspects of\nthis question have been discussed in several works. We adopt here a pragmatic\npoint of view and our argumentation relies on concrete solutions. Using actual\ncontraints (in the CLP sense) is neither easy nor direct. However, CLP can\nimprove parsing techniques in several aspects such as concision, control,\nefficiency or direct representation of linguistic formalism. This discussion is\nillustrated by several examples and the presentation of an HPSG parser.",
    "published": "1995-04-05T14:16:33Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9504005v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Philippe Blache",
      "Nabil Hathout"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9504006v1",
    "title": "Cues and control in Expert-Client Dialogues",
    "summary": "We conducted an empirical analysis into the relation between control and\ndiscourse structure. We applied control criteria to four dialogues and\nidentified 3 levels of discourse structure. We investigated the mechanism for\nchanging control between these structures and found that utterance type and not\ncue words predicted shifts of control. Participants used certain types of\nsignals when discourse goals were proceeding successfully but resorted to\ninterruptions when they were not.",
    "published": "1995-04-05T18:36:59Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9504006v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Steve Whittaker",
      "Phil Stenton"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9504007v1",
    "title": "Mixed Initiative in Dialogue: An Investigation into Discourse\n  Segmentation",
    "summary": "Conversation between two people is usually of mixed-initiative, with control\nover the conversation being transferred from one person to another. We apply a\nset of rules for the transfer of control to 4 sets of dialogues consisting of a\ntotal of 1862 turns. The application of the control rules lets us derive\ndomain-independent discourse structures. The derived structures indicate that\ninitiative plays a role in the structuring of discourse. In order to explore\nthe relationship of control and initiative to discourse processes like\ncentering, we analyze the distribution of four different classes of anaphora\nfor two data sets. This distribution indicates that some control segments are\nhierarchically related to others. The analysis suggests that discourse\nparticipants often mutually agree to a change of topic. We also compared\ninitiative in Task Oriented and Advice Giving dialogues and found that both\nallocation of control and the manner in which control is transferred is\nradically different for the two dialogue types. These differences can be\nexplained in terms of collaborative planning principles.",
    "published": "1995-04-05T18:38:17Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9504007v1.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Marilyn Walker",
      "Steve Whittaker"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9504008v2",
    "title": "SKOPE: A connectionist/symbolic architecture of spoken Korean processing",
    "summary": "Spoken language processing requires speech and natural language integration.\nMoreover, spoken Korean calls for unique processing methodology due to its\nlinguistic characteristics. This paper presents SKOPE, a connectionist/symbolic\nspoken Korean processing engine, which emphasizes that: 1) connectionist and\nsymbolic techniques must be selectively applied according to their relative\nstrength and weakness, and 2) the linguistic characteristics of Korean must be\nfully considered for phoneme recognition, speech and language integration, and\nmorphological/syntactic processing. The design and implementation of SKOPE\ndemonstrates how connectionist/symbolic hybrid architectures can be constructed\nfor spoken agglutinative language processing. Also SKOPE presents many novel\nideas for speech and language processing. The phoneme recognition,\nmorphological analysis, and syntactic analysis experiments show that SKOPE is a\nviable approach for the spoken Korean processing.",
    "published": "1995-04-07T14:39:09Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9504008v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL"
    ],
    "authors": [
      "Geunbae Lee",
      "Jong-Hyeok Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/quant-ph/9802028v1",
    "title": "Analogue Quantum Computers for Data Analysis",
    "summary": "Analogue computers use continuous properties of physical system for modeling.\nIn the paper is described possibility of modeling by analogue quantum computers\nfor some model of data analysis. It is analogue associative memory and a formal\nneural network. A particularity of the models is combination of continuous\ninternal processes with discrete set of output states. The modeling of the\nsystem by classical analogue computers was offered long times ago, but now it\nis not very effectively in comparison with modern digital computers. The\napplication of quantum analogue modelling looks quite possible for modern level\nof technology and it may be more effective than digital one, because number of\nelement may be about Avogadro number (N=6.0E23).",
    "published": "1998-02-11T16:25:41Z",
    "link": "http://arxiv.org/pdf/quant-ph/9802028v1.pdf",
    "category": [
      "quant-ph",
      "cs.CV"
    ],
    "authors": [
      "Alexander Yu. Vlasov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9810003v1",
    "title": "A Linear Shift Invariant Multiscale Transform",
    "summary": "This paper presents a multiscale decomposition algorithm. Unlike standard\nwavelet transforms, the proposed operator is both linear and shift invariant.\nThe central idea is to obtain shift invariance by averaging the aligned wavelet\ntransform projections over all circular shifts of the signal. It is shown how\nthe same transform can be obtained by a linear filter bank.",
    "published": "1998-10-02T03:34:38Z",
    "link": "http://arxiv.org/pdf/cs/9810003v1.pdf",
    "category": [
      "cs.CV",
      "I.4.3"
    ],
    "authors": [
      "Andreas Siebert"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9810017v1",
    "title": "General Theory of Image Normalization",
    "summary": "We give a systematic, abstract formulation of the image normalization method\nas applied to a general group of image transformations, and then illustrate the\nabstract analysis by applying it to the hierarchy of viewing transformations of\na planar object.",
    "published": "1998-10-19T20:46:16Z",
    "link": "http://arxiv.org/pdf/cs/9810017v1.pdf",
    "category": [
      "cs.CV",
      "I.2.10, I.4.7, I.4.8"
    ],
    "authors": [
      "Stephen L. Adler"
    ]
  },
  {
    "id": "http://arxiv.org/abs/math-ph/9903036v2",
    "title": "Numerically Invariant Signature Curves",
    "summary": "Corrected versions of the numerically invariant expressions for the affine\nand Euclidean signature of a planar curve proposed by E.Calabi et. al are\npresented. The new formulas are valid for fine but otherwise arbitrary\npartitions of the curve. We also give numerically invariant expressions for the\nfour differential invariants parametrizing the three dimensional version of the\nEuclidean signature curve, namely the curvature, the torsion and their\nderivatives with respect to arc length.",
    "published": "1999-03-18T22:41:39Z",
    "link": "http://arxiv.org/pdf/math-ph/9903036v2.pdf",
    "category": [
      "math-ph",
      "cs.CV",
      "math.MP"
    ],
    "authors": [
      "Mireille Boutin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9905013v1",
    "title": "Robust Combining of Disparate Classifiers through Order Statistics",
    "summary": "Integrating the outputs of multiple classifiers via combiners or\nmeta-learners has led to substantial improvements in several difficult pattern\nrecognition problems. In the typical setting investigated till now, each\nclassifier is trained on data taken or resampled from a common data set, or\n(almost) randomly selected subsets thereof, and thus experiences similar\nquality of training data. However, in certain situations where data is acquired\nand analyzed on-line at several geographically distributed locations, the\nquality of data may vary substantially, leading to large discrepancies in\nperformance of individual classifiers. In this article we introduce and\ninvestigate a family of classifiers based on order statistics, for robust\nhandling of such cases. Based on a mathematical modeling of how the decision\nboundaries are affected by order statistic combiners, we derive expressions for\nthe reductions in error expected when such combiners are used. We show\nanalytically that the selection of the median, the maximum and in general, the\n$i^{th}$ order statistic improves classification performance. Furthermore, we\nintroduce the trim and spread combiners, both based on linear combinations of\nthe ordered classifier outputs, and show that they are quite beneficial in\npresence of outliers or uneven classifier performance. Experimental results on\nseveral public domain data sets corroborate these findings.",
    "published": "1999-05-20T20:37:02Z",
    "link": "http://arxiv.org/pdf/cs/9905013v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV",
      "cs.NE",
      "I.5.1 ; G.3"
    ],
    "authors": [
      "Kagan Tumer",
      "Joydeep Ghosh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/math/9905165v1",
    "title": "Perception games, the image understanding and interpretational geometry",
    "summary": "The interactive game theoretical approach to the description of perception\nprocesses is proposed. The subject is treated formally in terms of a new class\nof the verbalizable interactive games which are called the perception games. An\napplication of the previously elaborated formalism of dialogues and\nverbalizable interactive games to the visual perception allows to combine the\nlinguistic (such as formal grammars), psycholinguistic and (interactive) game\ntheoretical methods for analysis of the image understanding by a human that may\nbe also useful for the elaboration of computer vision systems. By the way the\ninteractive game theoretical aspects of interpretational geometries are\nclarified.",
    "published": "1999-05-26T13:19:34Z",
    "link": "http://arxiv.org/pdf/math/9905165v1.pdf",
    "category": [
      "math.HO",
      "cs.CV",
      "90D20 (Primary) 90D80, 49N55, 93C41, 93B52, 51D05, 68U07 (Secondary)"
    ],
    "authors": [
      "Denis V. Juriev"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9908017v1",
    "title": "A Differential Invariant for Zooming",
    "summary": "This paper presents an invariant under scaling and linear brightness change.\nThe invariant is based on differentials and therefore is a local feature.\nRotationally invariant 2-d differential Gaussian operators up to third order\nare proposed for the implementation of the invariant. The performance is\nanalyzed by simulating a camera zoom-out.",
    "published": "1999-08-26T17:18:49Z",
    "link": "http://arxiv.org/pdf/cs/9908017v1.pdf",
    "category": [
      "cs.CV",
      "I.4.7"
    ],
    "authors": [
      "Andreas Siebert"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0001024v1",
    "title": "A Parallel Algorithm for Dilated Contour Extraction from Bilevel Images",
    "summary": "We describe a simple, but efficient algorithm for the generation of dilated\ncontours from bilevel images. The initial part of the contour extraction is\nexplained to be a good candidate for parallel computer code generation. The\nremainder of the algorithm is of linear nature.",
    "published": "2000-01-25T16:09:37Z",
    "link": "http://arxiv.org/pdf/cs/0001024v1.pdf",
    "category": [
      "cs.CV",
      "I.2.10, D.1.3, G.1.2"
    ],
    "authors": [
      "B. R. Schlei",
      "L. Prasad"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0001025v1",
    "title": "Computational Geometry Column 38",
    "summary": "Recent results on curve reconstruction are described.",
    "published": "2000-01-28T14:23:18Z",
    "link": "http://arxiv.org/pdf/cs/0001025v1.pdf",
    "category": [
      "cs.CG",
      "cs.CV",
      "F.2.2; I.5.3"
    ],
    "authors": [
      "Joseph O'Rourke"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003065v1",
    "title": "Image Compression with Iterated Function Systems, Finite Automata and\n  Zerotrees: Grand Unification",
    "summary": "Fractal image compression, Culik's image compression and zerotree prediction\ncoding of wavelet image decomposition coefficients succeed only because typical\nimages being compressed possess a significant degree of self-similarity.\nBesides the common concept, these methods turn out to be even more tightly\nrelated, to the point of algorithmical reducibility of one technique to\nanother. The goal of the present paper is to demonstrate these relations.\n  The paper offers a plain-term interpretation of Culik's image compression, in\nregular image processing terms, without resorting to finite state machines and\nsimilar lofty language. The interpretation is shown to be algorithmically\nrelated to an IFS fractal image compression method: an IFS can be exactly\ntransformed into Culik's image code. Using this transformation, we will prove\nthat in a self-similar (part of an) image any zero wavelet coefficient is the\nroot of a zerotree, or its branch.\n  The paper discusses the zerotree coding of (wavelet/projection) coefficients\nas a common predictor/corrector, applied vertically through different layers of\na multiresolutional decomposition, rather than within the same view. This\ninterpretation leads to an insight into the evolution of image compression\ntechniques: from a causal single-layer prediction, to non-causal same-view\npredictions (wavelet decomposition among others) and to a causal cross-layer\nprediction (zero-trees, Culik's method).",
    "published": "2000-03-15T19:31:51Z",
    "link": "http://arxiv.org/pdf/cs/0003065v1.pdf",
    "category": [
      "cs.CV",
      "I.4.2; I.4.10; G.1.2"
    ],
    "authors": [
      "Oleg Kiselyov",
      "Paul Fisher"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003079v1",
    "title": "Differential Invariants under Gamma Correction",
    "summary": "This paper presents invariants under gamma correction and similarity\ntransformations. The invariants are local features based on differentials which\nare implemented using derivatives of the Gaussian. The use of the proposed\ninvariant representation is shown to yield improved correlation results in a\ntemplate matching scenario.",
    "published": "2000-03-26T23:18:43Z",
    "link": "http://arxiv.org/pdf/cs/0003079v1.pdf",
    "category": [
      "cs.CV",
      "I.4.7"
    ],
    "authors": [
      "Andreas Siebert"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0004012v1",
    "title": "Assisted Video Sequences Indexing : Motion Analysis Based on Interest\n  Points",
    "summary": "This work deals with content-based video indexing. Our viewpoint is\nsemi-automatic analysis of compressed video. We consider the possible\napplications of motion analysis and moving object detection : assisting moving\nobject indexing, summarising videos, and allowing image and motion queries. We\npropose an approach based on interest points. As first results, we test and\ncompare the stability of different types of interest point detectors in\ncompressed sequences.",
    "published": "2000-04-21T17:32:29Z",
    "link": "http://arxiv.org/pdf/cs/0004012v1.pdf",
    "category": [
      "cs.CV",
      "I.4.8; I.4.9"
    ],
    "authors": [
      "Emmanuel Etievent",
      "Frank Lebourgeois",
      "Jean-Michel Jolion"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0005001v1",
    "title": "Robustness of Regional Matching Scheme over Global Matching Scheme",
    "summary": "The paper has established and verified the theory prevailing widely among\nimage and pattern recognition specialists that the bottom-up indirect regional\nmatching process is the more stable and the more robust than the global\nmatching process against concentrated types of noise represented by clutter,\noutlier or occlusion in the imagery. We have demonstrated this by analyzing the\neffect of concentrated noise on a typical decision making process of a\nsimplified two candidate voting model where our theorem establishes the lower\nbounds to a critical breakdown point of election (or decision) result by the\nbottom-up matching process are greater than the exact bound of the global\nmatching process implying that the former regional process is capable of\naccommodating a higher level of noise than the latter global process before the\nresult of decision overturns. We present a convincing experimental verification\nsupporting not only the theory by a white-black flag recognition problem in the\npresence of localized noise but also the validity of the conjecture by a facial\nrecognition problem that the theorem remains valid for other decision making\nprocesses involving an important dimension-reducing transform such as principal\ncomponent analysis or a Gabor transform.",
    "published": "2000-05-03T08:49:28Z",
    "link": "http://arxiv.org/pdf/cs/0005001v1.pdf",
    "category": [
      "cs.CV",
      "I.2.10; I.5.2; H.1"
    ],
    "authors": [
      "Liang Chen",
      "Naoyuki Tokuda"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0005027v1",
    "title": "A Bayesian Reflection on Surfaces",
    "summary": "The topic of this paper is a novel Bayesian continuous-basis field\nrepresentation and inference framework. Within this paper several problems are\nsolved: The maximally informative inference of continuous-basis fields, that is\nwhere the basis for the field is itself a continuous object and not\nrepresentable in a finite manner; the tradeoff between accuracy of\nrepresentation in terms of information learned, and memory or storage capacity\nin bits; the approximation of probability distributions so that a maximal\namount of information about the object being inferred is preserved; an\ninformation theoretic justification for multigrid methodology. The maximally\ninformative field inference framework is described in full generality and\ndenoted the Generalized Kalman Filter. The Generalized Kalman Filter allows the\nupdate of field knowledge from previous knowledge at any scale, and new data,\nto new knowledge at any other scale. An application example instance, the\ninference of continuous surfaces from measurements (for example, camera image\ndata), is presented.",
    "published": "2000-05-26T20:24:48Z",
    "link": "http://arxiv.org/pdf/cs/0005027v1.pdf",
    "category": [
      "cs.CV",
      "cs.DS",
      "cs.LG",
      "math.PR",
      "nlin.AO",
      "physics.data-an",
      "G.3;I.2.4;I.2.6;I.2.10;I.4.1;I.4.4;I.4.5;I.4.10"
    ],
    "authors": [
      "David R. Wolf"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0006001v1",
    "title": "Boosting the Differences: A fast Bayesian classifier neural network",
    "summary": "A Bayesian classifier that up-weights the differences in the attribute values\nis discussed. Using four popular datasets from the UCI repository, some\ninteresting features of the network are illustrated. The network is suitable\nfor classification problems.",
    "published": "2000-05-31T23:37:48Z",
    "link": "http://arxiv.org/pdf/cs/0006001v1.pdf",
    "category": [
      "cs.CV",
      "I1.2;F.1.1;F1.2;C1.3"
    ],
    "authors": [
      "Ninan Sajeeth Philip",
      "K. Babu Joseph"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0006002v1",
    "title": "Distorted English Alphabet Identification : An application of Difference\n  Boosting Algorithm",
    "summary": "The difference-boosting algorithm is used on letters dataset from the UCI\nrepository to classify distorted raster images of English alphabets. In\ncontrast to rather complex networks, the difference-boosting is found to\nproduce comparable or better classification efficiency on this complex problem.",
    "published": "2000-05-31T23:52:31Z",
    "link": "http://arxiv.org/pdf/cs/0006002v1.pdf",
    "category": [
      "cs.CV",
      "I1.2;F.1.1;F1.2;C1.3"
    ],
    "authors": [
      "Ninan Sajeeth Philip",
      "K. Babu Joseph"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0006040v1",
    "title": "Correlation over Decomposed Signals: A Non-Linear Approach to Fast and\n  Effective Sequences Comparison",
    "summary": "A novel non-linear approach to fast and effective comparison of sequences is\npresented, compared to the traditional cross-correlation operator, and\nillustrated with respect to DNA sequences.",
    "published": "2000-06-28T18:34:14Z",
    "link": "http://arxiv.org/pdf/cs/0006040v1.pdf",
    "category": [
      "cs.CV",
      "cs.DS",
      "q-bio",
      "I.5.4; F.2.2; I.5.4; J.3"
    ],
    "authors": [
      "Luciano da Fontoura Costa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0006047v1",
    "title": "Geometric Morphology of Granular Materials",
    "summary": "We present a new method to transform the spectral pixel information of a\nmicrograph into an affine geometric description, which allows us to analyze the\nmorphology of granular materials. We use spectral and pulse-coupled neural\nnetwork based segmentation techniques to generate blobs, and a newly developed\nalgorithm to extract dilated contours. A constrained Delaunay tesselation of\nthe contour points results in a triangular mesh. This mesh is the basic\ningredient of the Chodal Axis Transform, which provides a morphological\ndecomposition of shapes. Such decomposition allows for grain separation and the\nefficient computation of the statistical features of granular materials.",
    "published": "2000-06-30T22:17:42Z",
    "link": "http://arxiv.org/pdf/cs/0006047v1.pdf",
    "category": [
      "cs.CV",
      "I.2.10;I.4.6;I.4.10"
    ],
    "authors": [
      "B. R. Schlei",
      "L. Prasad",
      "A. N. Skourikhine"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0010014v1",
    "title": "On a cepstrum-based speech detector robust to white noise",
    "summary": "We study effects of additive white noise on the cepstral representation of\nspeech signals. Distribution of each individual cepstrum coefficient of speech\nis shown to depend strongly on noise and to overlap significantly with the\ncepstrum distribution of noise. Based on these studies, we suggest a scalar\nquantity, V, equal to the sum of weighted cepstral coefficients, which is able\nto classify frames containing speech against noise-like frames. The\ndistributions of V for speech and noise frames are reasonably well separated\nabove SNR = 5 dB, demonstrating the feasibility of robust speech detector based\non V.",
    "published": "2000-10-10T17:33:02Z",
    "link": "http://arxiv.org/pdf/cs/0010014v1.pdf",
    "category": [
      "cs.CL",
      "cs.CV",
      "cs.HC",
      "I.2.7; I.2.1; I.2.10; H.5.5"
    ],
    "authors": [
      "Sergei Skorik",
      "Frederic Berthommier"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0101010v2",
    "title": "An Even Faster and More Unifying Algorithm for Comparing Trees via\n  Unbalanced Bipartite Matchings",
    "summary": "A widely used method for determining the similarity of two labeled trees is\nto compute a maximum agreement subtree of the two trees. Previous work on this\nsimilarity measure is only concerned with the comparison of labeled trees of\ntwo special kinds, namely, uniformly labeled trees (i.e., trees with all their\nnodes labeled by the same symbol) and evolutionary trees (i.e., leaf-labeled\ntrees with distinct symbols for distinct leaves). This paper presents an\nalgorithm for comparing trees that are labeled in an arbitrary manner. In\naddition to this generality, this algorithm is faster than the previous\nalgorithms.\n  Another contribution of this paper is on maximum weight bipartite matchings.\nWe show how to speed up the best known matching algorithms when the input\ngraphs are node-unbalanced or weight-unbalanced. Based on these enhancements,\nwe obtain an efficient algorithm for a new matching problem called the\nhierarchical bipartite matching problem, which is at the core of our maximum\nagreement subtree algorithm.",
    "published": "2001-01-14T03:31:56Z",
    "link": "http://arxiv.org/pdf/cs/0101010v2.pdf",
    "category": [
      "cs.CV",
      "cs.DS",
      "F.2.2; I.5; J.3"
    ],
    "authors": [
      "Ming-Yang Kao",
      "Tak-Wah Lam",
      "Wing-Kin Sung",
      "Hing-Fung Ting"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0105026v1",
    "title": "Toward Natural Gesture/Speech Control of a Large Display",
    "summary": "In recent years because of the advances in computer vision research, free\nhand gestures have been explored as means of human-computer interaction (HCI).\nTogether with improved speech processing technology it is an important step\ntoward natural multimodal HCI. However, inclusion of non-predefined continuous\ngestures into a multimodal framework is a challenging problem. In this paper,\nwe propose a structured approach for studying patterns of multimodal language\nin the context of a 2D-display control. We consider systematic analysis of\ngestures from observable kinematical primitives to their semantics as pertinent\nto a linguistic structure. Proposed semantic classification of co-verbal\ngestures distinguishes six categories based on their spatio-temporal deixis. We\ndiscuss evolution of a computational framework for gesture and speech\nintegration which was used to develop an interactive testbed (iMAP). The\ntestbed enabled elicitation of adequate, non-sequential, multimodal patterns in\na narrative mode of HCI. Conducted user studies illustrate significance of\naccounting for the temporal alignment of gesture and speech parts in semantic\nmapping. Furthermore, co-occurrence analysis of gesture/speech production\nsuggests syntactic organization of gestures at the lexical level.",
    "published": "2001-05-17T15:41:29Z",
    "link": "http://arxiv.org/pdf/cs/0105026v1.pdf",
    "category": [
      "cs.CV",
      "cs.HC",
      "H.5.2; I.5.4; I.2.7"
    ],
    "authors": [
      "S. Kettebekov",
      "R. Sharma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0109116v1",
    "title": "Digital Color Imaging",
    "summary": "This paper surveys current technology and research in the area of digital\ncolor imaging. In order to establish the background and lay down terminology,\nfundamental concepts of color perception and measurement are first presented\nus-ing vector-space notation and terminology. Present-day color recording and\nreproduction systems are reviewed along with the common mathematical models\nused for representing these devices. Algorithms for processing color images for\ndisplay and communication are surveyed, and a forecast of research trends is\nattempted. An extensive bibliography is provided.",
    "published": "2001-09-26T22:14:40Z",
    "link": "http://arxiv.org/pdf/cs/0109116v1.pdf",
    "category": [
      "cs.CV",
      "cs.GR",
      "A.1;I.4,I.3.3,I.2.10;I.3.7;B.4.2"
    ],
    "authors": [
      "Gaurav Sharma",
      "H. Joel Trussell"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0111054v3",
    "title": "The similarity metric",
    "summary": "A new class of distances appropriate for measuring similarity relations\nbetween sequences, say one type of similarity per distance, is studied. We\npropose a new ``normalized information distance'', based on the noncomputable\nnotion of Kolmogorov complexity, and show that it is in this class and it\nminorizes every computable distance in the class (that is, it is universal in\nthat it discovers all computable similarities). We demonstrate that it is a\nmetric and call it the {\\em similarity metric}. This theory forms the\nfoundation for a new practical tool. To evidence generality and robustness we\ngive two distinctive applications in widely divergent areas using standard\ncompression programs like gzip and GenCompress. First, we compare whole\nmitochondrial genomes and infer their evolutionary history. This results in a\nfirst completely automatic computed whole mitochondrial phylogeny tree.\nSecondly, we fully automatically compute the language tree of 52 different\nlanguages.",
    "published": "2001-11-20T15:25:47Z",
    "link": "http://arxiv.org/pdf/cs/0111054v3.pdf",
    "category": [
      "cs.CC",
      "cond-mat.stat-mech",
      "cs.CE",
      "cs.CV",
      "math.CO",
      "math.MG",
      "math.ST",
      "physics.data-an",
      "q-bio.GN",
      "stat.TH",
      "J.3, E.4"
    ],
    "authors": [
      "Ming Li",
      "Xin Chen",
      "Xin Li",
      "Bin Ma",
      "Paul Vitanyi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0201019v1",
    "title": "Structure from Motion: Theoretical Foundations of a Novel Approach Using\n  Custom Built Invariants",
    "summary": "We rephrase the problem of 3D reconstruction from images in terms of\nintersections of projections of orbits of custom built Lie groups actions. We\nthen use an algorithmic method based on moving frames \"a la Fels-Olver\" to\nobtain a fundamental set of invariants of these groups actions. The invariants\nare used to define a set of equations to be solved by the points of the 3D\nobject, providing a new technique for recovering 3D structure from motion.",
    "published": "2002-01-22T21:00:35Z",
    "link": "http://arxiv.org/pdf/cs/0201019v1.pdf",
    "category": [
      "cs.CV",
      "math.DG",
      "I.4.8;I.2.10"
    ],
    "authors": [
      "Pierre-Louis Bazin",
      "Mireille Boutin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0202009v1",
    "title": "Non-negative sparse coding",
    "summary": "Non-negative sparse coding is a method for decomposing multivariate data into\nnon-negative sparse components. In this paper we briefly describe the\nmotivation behind this type of data representation and its relation to standard\nsparse coding and non-negative matrix factorization. We then give a simple yet\nefficient multiplicative algorithm for finding the optimal values of the hidden\ncomponents. In addition, we show how the basis vectors can be learned from the\nobserved data. Simulations demonstrate the effectiveness of the proposed\nmethod.",
    "published": "2002-02-11T11:04:08Z",
    "link": "http://arxiv.org/pdf/cs/0202009v1.pdf",
    "category": [
      "cs.NE",
      "cs.CV",
      "I.4.2"
    ],
    "authors": [
      "Patrik O. Hoyer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0202020v3",
    "title": "The Mysterious Optimality of Naive Bayes: Estimation of the Probability\n  in the System of \"Classifiers\"",
    "summary": "Bayes Classifiers are widely used currently for recognition, identification\nand knowledge discovery. The fields of application are, for example, image\nprocessing, medicine, chemistry (QSAR). But by mysterious way the Naive Bayes\nClassifier usually gives a very nice and good presentation of a recognition. It\ncan not be improved considerably by more complex models of Bayes Classifier. We\ndemonstrate here a very nice and simple proof of the Naive Bayes Classifier\noptimality, that can explain this interesting fact.The derivation in the\ncurrent paper is based on arXiv:cs/0202020v1",
    "published": "2002-02-17T14:55:47Z",
    "link": "http://arxiv.org/pdf/cs/0202020v3.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "E.5; E.4; E.2; H.1.1; F.1.1; F.1.3"
    ],
    "authors": [
      "Oleg Kupervasser",
      "Alexsander Vardy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0208005v1",
    "title": "Probabilistic Search for Object Segmentation and Recognition",
    "summary": "The problem of searching for a model-based scene interpretation is analyzed\nwithin a probabilistic framework. Object models are formulated as generative\nmodels for range data of the scene. A new statistical criterion, the truncated\nobject probability, is introduced to infer an optimal sequence of object\nhypotheses to be evaluated for their match to the data. The truncated\nprobability is partly determined by prior knowledge of the objects and partly\nlearned from data. Some experiments on sequence quality and object segmentation\nand recognition from stereo data are presented. The article recovers classic\nconcepts from object recognition (grouping, geometric hashing, alignment) from\nthe probabilistic perspective and adds insight into the optimal ordering of\nobject hypotheses for evaluation. Moreover, it introduces point-relation\ndensities, a key component of the truncated probability, as statistical models\nof local surface shape.",
    "published": "2002-08-05T10:57:09Z",
    "link": "http://arxiv.org/pdf/cs/0208005v1.pdf",
    "category": [
      "cs.CV",
      "I.2.10; I.4.6; I.4.7; I.4.8; I.5.4"
    ],
    "authors": [
      "Ulrich Hillenbrand",
      "Gerd Hirzinger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0210009v1",
    "title": "On the Cell-based Complexity of Recognition of Bounded Configurations by\n  Finite Dynamic Cellular Automata",
    "summary": "This paper studies complexity of recognition of classes of bounded\nconfigurations by a generalization of conventional cellular automata (CA) --\nfinite dynamic cellular automata (FDCA). Inspired by the CA-based models of\nbiological and computer vision, this study attempts to derive the properties of\na complexity measure and of the classes of input configurations that make it\nbeneficial to realize the recognition via a two-layered automaton as compared\nto a one-layered automaton. A formalized model of an image pattern recognition\ntask is utilized to demonstrate that the derived conditions can be satisfied\nfor a non-empty set of practical problems.",
    "published": "2002-10-11T19:55:16Z",
    "link": "http://arxiv.org/pdf/cs/0210009v1.pdf",
    "category": [
      "cs.CC",
      "cs.CV",
      "F.1.3; F.2.2; F.2.3; I.4.3; I.5.1; I.5.4; I.5.5"
    ],
    "authors": [
      "Maxim Makatchev"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0211005v1",
    "title": "Prosody Based Co-analysis for Continuous Recognition of Coverbal\n  Gestures",
    "summary": "Although speech and gesture recognition has been studied extensively, all the\nsuccessful attempts of combining them in the unified framework were\nsemantically motivated, e.g., keyword-gesture cooccurrence. Such formulations\ninherited the complexity of natural language processing. This paper presents a\nBayesian formulation that uses a phenomenon of gesture and speech articulation\nfor improving accuracy of automatic recognition of continuous coverbal\ngestures. The prosodic features from the speech signal were coanalyzed with the\nvisual signal to learn the prior probability of co-occurrence of the prominent\nspoken segments with the particular kinematical phases of gestures. It was\nfound that the above co-analysis helps in detecting and disambiguating visually\nsmall gestures, which subsequently improves the rate of continuous gesture\nrecognition. The efficacy of the proposed approach was demonstrated on a large\ndatabase collected from the weather channel broadcast. This formulation opens\nnew avenues for bottom-up frameworks of multimodal integration.",
    "published": "2002-11-05T19:27:32Z",
    "link": "http://arxiv.org/pdf/cs/0211005v1.pdf",
    "category": [
      "cs.CV",
      "cs.HC",
      "H.5.2; I.5.4"
    ],
    "authors": [
      "Sanshzar Kettebekov",
      "Mohammed Yeasin",
      "Rajeev Sharma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0212028v1",
    "title": "Technical Note: Bias and the Quantification of Stability",
    "summary": "Research on bias in machine learning algorithms has generally been concerned\nwith the impact of bias on predictive accuracy. We believe that there are other\nfactors that should also play a role in the evaluation of bias. One such factor\nis the stability of the algorithm; in other words, the repeatability of the\nresults. If we obtain two sets of data from the same phenomenon, with the same\nunderlying probability distribution, then we would like our learning algorithm\nto induce approximately the same concepts from both sets of data. This paper\nintroduces a method for quantifying stability, based on a measure of the\nagreement between concepts. We also discuss the relationships among stability,\npredictive accuracy, and bias.",
    "published": "2002-12-11T15:50:41Z",
    "link": "http://arxiv.org/pdf/cs/0212028v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV",
      "I.2.6; I.5.2"
    ],
    "authors": [
      "Peter D. Turney"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0212029v1",
    "title": "A Theory of Cross-Validation Error",
    "summary": "This paper presents a theory of error in cross-validation testing of\nalgorithms for predicting real-valued attributes. The theory justifies the\nclaim that predicting real-valued attributes requires balancing the conflicting\ndemands of simplicity and accuracy. Furthermore, the theory indicates precisely\nhow these conflicting demands must be balanced, in order to minimize\ncross-validation error. A general theory is presented, then it is developed in\ndetail for linear regression and instance-based learning.",
    "published": "2002-12-11T16:08:36Z",
    "link": "http://arxiv.org/pdf/cs/0212029v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV",
      "I.2.6; I.5.2"
    ],
    "authors": [
      "Peter D. Turney"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0212030v1",
    "title": "Theoretical Analyses of Cross-Validation Error and Voting in\n  Instance-Based Learning",
    "summary": "This paper begins with a general theory of error in cross-validation testing\nof algorithms for supervised learning from examples. It is assumed that the\nexamples are described by attribute-value pairs, where the values are symbolic.\nCross-validation requires a set of training examples and a set of testing\nexamples. The value of the attribute that is to be predicted is known to the\nlearner in the training set, but unknown in the testing set. The theory\ndemonstrates that cross-validation error has two components: error on the\ntraining set (inaccuracy) and sensitivity to noise (instability). This general\ntheory is then applied to voting in instance-based learning. Given an example\nin the testing set, a typical instance-based learning algorithm predicts the\ndesignated attribute by voting among the k nearest neighbors (the k most\nsimilar examples) to the testing example in the training set. Voting is\nintended to increase the stability (resistance to noise) of instance-based\nlearning, but a theoretical analysis shows that there are circumstances in\nwhich voting can be destabilizing. The theory suggests ways to minimize\ncross-validation error, by insuring that voting is stable and does not\nadversely affect accuracy.",
    "published": "2002-12-11T17:36:00Z",
    "link": "http://arxiv.org/pdf/cs/0212030v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV",
      "I.2.6; I.5.2"
    ],
    "authors": [
      "Peter D. Turney"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0212031v1",
    "title": "Contextual Normalization Applied to Aircraft Gas Turbine Engine\n  Diagnosis",
    "summary": "Diagnosing faults in aircraft gas turbine engines is a complex problem. It\ninvolves several tasks, including rapid and accurate interpretation of patterns\nin engine sensor data. We have investigated contextual normalization for the\ndevelopment of a software tool to help engine repair technicians with\ninterpretation of sensor data. Contextual normalization is a new strategy for\nemploying machine learning. It handles variation in data that is due to\ncontextual factors, rather than the health of the engine. It does this by\nnormalizing the data in a context-sensitive manner. This learning strategy was\ndeveloped and tested using 242 observations of an aircraft gas turbine engine\nin a test cell, where each observation consists of roughly 12,000 numbers,\ngathered over a 12 second interval. There were eight classes of observations:\nseven deliberately implanted classes of faults and a healthy class. We compared\ntwo approaches to implementing our learning strategy: linear regression and\ninstance-based learning. We have three main results. (1) For the given problem,\ninstance-based learning works better than linear regression. (2) For this\nproblem, contextual normalization works better than other common forms of\nnormalization. (3) The algorithms described here can be the basis for a useful\nsoftware tool for assisting technicians with the interpretation of sensor data.",
    "published": "2002-12-11T18:30:59Z",
    "link": "http://arxiv.org/pdf/cs/0212031v1.pdf",
    "category": [
      "cs.LG",
      "cs.CE",
      "cs.CV",
      "I.2.6; I.5.4; J.2"
    ],
    "authors": [
      "Peter D. Turney",
      "Michael Halasz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0212034v1",
    "title": "Types of Cost in Inductive Concept Learning",
    "summary": "Inductive concept learning is the task of learning to assign cases to a\ndiscrete set of classes. In real-world applications of concept learning, there\nare many different types of cost involved. The majority of the machine learning\nliterature ignores all types of cost (unless accuracy is interpreted as a type\nof cost measure). A few papers have investigated the cost of misclassification\nerrors. Very few papers have examined the many other types of cost. In this\npaper, we attempt to create a taxonomy of the different types of cost that are\ninvolved in inductive concept learning. This taxonomy may help to organize the\nliterature on cost-sensitive learning. We hope that it will inspire researchers\nto investigate all types of cost in inductive concept learning in more depth.",
    "published": "2002-12-11T19:42:14Z",
    "link": "http://arxiv.org/pdf/cs/0212034v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV",
      "I.2.6; I.5.2"
    ],
    "authors": [
      "Peter D. Turney"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0212037v1",
    "title": "The Management of Context-Sensitive Features: A Review of Strategies",
    "summary": "In this paper, we review five heuristic strategies for handling\ncontext-sensitive features in supervised machine learning from examples. We\ndiscuss two methods for recovering lost (implicit) contextual information. We\nmention some evidence that hybrid strategies can have a synergetic effect. We\nthen show how the work of several machine learning researchers fits into this\nframework. While we do not claim that these strategies exhaust the\npossibilities, it appears that the framework includes all of the techniques\nthat can be found in the published literature on contextsensitive learning.",
    "published": "2002-12-12T18:14:38Z",
    "link": "http://arxiv.org/pdf/cs/0212037v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV",
      "I.2.6; I.5.2"
    ],
    "authors": [
      "Peter D. Turney"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0212038v1",
    "title": "The Identification of Context-Sensitive Features: A Formal Definition of\n  Context for Concept Learning",
    "summary": "A large body of research in machine learning is concerned with supervised\nlearning from examples. The examples are typically represented as vectors in a\nmulti-dimensional feature space (also known as attribute-value descriptions). A\nteacher partitions a set of training examples into a finite number of classes.\nThe task of the learning algorithm is to induce a concept from the training\nexamples. In this paper, we formally distinguish three types of features:\nprimary, contextual, and irrelevant features. We also formally define what it\nmeans for one feature to be context-sensitive to another feature.\nContext-sensitive features complicate the task of the learner and potentially\nimpair the learner's performance. Our formal definitions make it possible for a\nlearner to automatically identify context-sensitive features. After\ncontext-sensitive features have been identified, there are several strategies\nthat the learner can employ for managing the features; however, a discussion of\nthese strategies is outside of the scope of this paper. The formal definitions\npresented here correct a flaw in previously proposed definitions. We discuss\nthe relationship between our work and a formal definition of relevance.",
    "published": "2002-12-12T18:29:02Z",
    "link": "http://arxiv.org/pdf/cs/0212038v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV",
      "I.2.6; I.5.2"
    ],
    "authors": [
      "Peter D. Turney"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0212040v1",
    "title": "Data Engineering for the Analysis of Semiconductor Manufacturing Data",
    "summary": "We have analyzed manufacturing data from several different semiconductor\nmanufacturing plants, using decision tree induction software called Q-YIELD.\nThe software generates rules for predicting when a given product should be\nrejected. The rules are intended to help the process engineers improve the\nyield of the product, by helping them to discover the causes of rejection.\nExperience with Q-YIELD has taught us the importance of data engineering --\npreprocessing the data to enable or facilitate decision tree induction. This\npaper discusses some of the data engineering problems we have encountered with\nsemiconductor manufacturing data. The paper deals with two broad classes of\nproblems: engineering the features in a feature vector representation and\nengineering the definition of the target concept (the classes). Manufacturing\nprocess data present special problems for feature engineering, since the data\nhave multiple levels of granularity (detail, resolution). Engineering the\ntarget concept is important, due to our focus on understanding the past, as\nopposed to the more common focus in machine learning on predicting the future.",
    "published": "2002-12-12T19:11:11Z",
    "link": "http://arxiv.org/pdf/cs/0212040v1.pdf",
    "category": [
      "cs.LG",
      "cs.CE",
      "cs.CV",
      "I.2.6; I.5.2; I.5.4; J.2"
    ],
    "authors": [
      "Peter D. Turney"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0212041v1",
    "title": "Robust Classification with Context-Sensitive Features",
    "summary": "This paper addresses the problem of classifying observations when features\nare context-sensitive, especially when the testing set involves a context that\nis different from the training set. The paper begins with a precise definition\nof the problem, then general strategies are presented for enhancing the\nperformance of classification algorithms on this type of problem. These\nstrategies are tested on three domains. The first domain is the diagnosis of\ngas turbine engines. The problem is to diagnose a faulty engine in one context,\nsuch as warm weather, when the fault has previously been seen only in another\ncontext, such as cold weather. The second domain is speech recognition. The\ncontext is given by the identity of the speaker. The problem is to recognize\nwords spoken by a new speaker, not represented in the training set. The third\ndomain is medical prognosis. The problem is to predict whether a patient with\nhepatitis will live or die. The context is the age of the patient. For all\nthree domains, exploiting context results in substantially more accurate\nclassification.",
    "published": "2002-12-12T19:26:52Z",
    "link": "http://arxiv.org/pdf/cs/0212041v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV",
      "I.2.6; I.5.2; I.5.4"
    ],
    "authors": [
      "Peter D. Turney"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0212035v1",
    "title": "Exploiting Context When Learning to Classify",
    "summary": "This paper addresses the problem of classifying observations when features\nare context-sensitive, specifically when the testing set involves a context\nthat is different from the training set. The paper begins with a precise\ndefinition of the problem, then general strategies are presented for enhancing\nthe performance of classification algorithms on this type of problem. These\nstrategies are tested on two domains. The first domain is the diagnosis of gas\nturbine engines. The problem is to diagnose a faulty engine in one context,\nsuch as warm weather, when the fault has previously been seen only in another\ncontext, such as cold weather. The second domain is speech recognition. The\nproblem is to recognize words spoken by a new speaker, not represented in the\ntraining set. For both domains, exploiting context results in substantially\nmore accurate classification.",
    "published": "2002-12-12T19:40:50Z",
    "link": "http://arxiv.org/pdf/cs/0212035v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV",
      "I.2.6; I.5.2; I.5.4"
    ],
    "authors": [
      "Peter D. Turney"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0301001v1",
    "title": "Least squares fitting of circles and lines",
    "summary": "We study theoretical and computational aspects of the least squares fit (LSF)\nof circles and circular arcs. First we discuss the existence and uniqueness of\nLSF and various parametrization schemes. Then we evaluate several popular\ncircle fitting algorithms and propose a new one that surpasses the existing\nmethods in reliability. We also discuss and compare direct (algebraic) circle\nfits.",
    "published": "2003-01-01T19:58:03Z",
    "link": "http://arxiv.org/pdf/cs/0301001v1.pdf",
    "category": [
      "cs.CV",
      "I.4.8; I.5.1; I.2.10; G.1.2; G.3"
    ],
    "authors": [
      "N. Chernov",
      "C. Lesort"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0302023v1",
    "title": "Segmentation, Indexing, and Visualization of Extended Instructional\n  Videos",
    "summary": "We present a new method for segmenting, and a new user interface for indexing\nand visualizing, the semantic content of extended instructional videos. Given a\nseries of key frames from the video, we generate a condensed view of the data\nby clustering frames according to media type and visual similarities. Using\nvarious visual filters, key frames are first assigned a media type (board,\nclass, computer, illustration, podium, and sheet). Key frames of media type\nboard and sheet are then clustered based on contents via an algorithm with\nnear-linear cost. A novel user interface, the result of two user studies,\ndisplays related topics using icons linked topologically, allowing users to\nquickly locate semantically related portions of the video. We analyze the\naccuracy of the segmentation tool on 17 instructional videos, each of which is\nfrom 75 to 150 minutes in duration (a total of 40 hours); the classification\naccuracy exceeds 96%.",
    "published": "2003-02-16T22:08:01Z",
    "link": "http://arxiv.org/pdf/cs/0302023v1.pdf",
    "category": [
      "cs.IR",
      "cs.CV",
      "H.3.1;H.3.3;I.4.8;I.5.3"
    ],
    "authors": [
      "Alexander Haubold",
      "John R. Kender"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0302024v2",
    "title": "Analysis and Interface for Instructional Video",
    "summary": "We present a new method for segmenting, and a new user interface for indexing\nand visualizing, the semantic content of extended instructional videos. Using\nvarious visual filters, key frames are first assigned a media type (board,\nclass, computer, illustration, podium, and sheet). Key frames of media type\nboard and sheet are then clustered based on contents via an algorithm with\nnear-linear cost. A novel user interface, the result of two user studies,\ndisplays related topics using icons linked topologically, allowing users to\nquickly locate semantically related portions of the video. We analyze the\naccuracy of the segmentation tool on 17 instructional videos, each of which is\nfrom 75 to 150 minutes in duration (a total of 40 hours); it exceeds 96%.",
    "published": "2003-02-16T22:13:42Z",
    "link": "http://arxiv.org/pdf/cs/0302024v2.pdf",
    "category": [
      "cs.IR",
      "cs.CV",
      "H.3.1;H.3.3;I.4.8;I.5.3"
    ],
    "authors": [
      "Alexander Haubold",
      "John R. Kender"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0303015v1",
    "title": "Statistical efficiency of curve fitting algorithms",
    "summary": "We study the problem of fitting parametrized curves to noisy data. Under\ncertain assumptions (known as Cartesian and radial functional models), we\nderive asymptotic expressions for the bias and the covariance matrix of the\nparameter estimates. We also extend Kanatani's version of the Cramer-Rao lower\nbound, which he proved for unbiased estimates only, to more general estimates\nthat include many popular algorithms (most notably, the orthogonal least\nsquares and algebraic fits). We then show that the gradient-weighted algebraic\nfit is statistically efficient and describe all other statistically efficient\nalgebraic fits.",
    "published": "2003-03-18T21:30:36Z",
    "link": "http://arxiv.org/pdf/cs/0303015v1.pdf",
    "category": [
      "cs.CV",
      "I.4.8;I.5.1;I.2.10;G.3;G.1.2"
    ],
    "authors": [
      "N. Chernov",
      "C. Lesort"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0303024v1",
    "title": "Differential Methods in Catadioptric Sensor Design with Applications to\n  Panoramic Imaging",
    "summary": "We discuss design techniques for catadioptric sensors that realize given\nprojections. In general, these problems do not have solutions, but approximate\nsolutions may often be found that are visually acceptable. There are several\nmethods to approach this problem, but here we focus on what we call the\n``vector field approach''. An application is given where a true panoramic\nmirror is derived, i.e. a mirror that yields a cylindrical projection to the\nviewer without any digital unwarping.",
    "published": "2003-03-24T02:36:21Z",
    "link": "http://arxiv.org/pdf/cs/0303024v1.pdf",
    "category": [
      "cs.CV",
      "cs.RO",
      "I.2.9"
    ],
    "authors": [
      "R. Andrew Hicks"
    ]
  },
  {
    "id": "http://arxiv.org/abs/math/0304192v1",
    "title": "On reconstructing n-point configurations from the distribution of\n  distances or areas",
    "summary": "One way to characterize configurations of points up to congruence is by\nconsidering the distribution of all mutual distances between points. This paper\ndeals with the question if point configurations are uniquely determined by this\ndistribution. After giving some counterexamples, we prove that this is the case\nfor the vast majority of configurations. In the second part of the paper, the\ndistribution of areas of sub-triangles is used for characterizing point\nconfigurations. Again it turns out that most configurations are reconstructible\nfrom the distribution of areas, though there are counterexamples.",
    "published": "2003-04-15T10:01:26Z",
    "link": "http://arxiv.org/pdf/math/0304192v1.pdf",
    "category": [
      "math.AC",
      "cs.CV",
      "cs.SC",
      "13A50;13-04;68T45"
    ],
    "authors": [
      "Mireille Boutin",
      "Gregor Kemper"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0305048v1",
    "title": "2D Electrophoresis Gel Image and Diagnosis of a Disease",
    "summary": "The process of diagnosing a disease from the 2D gel electrophoresis image is\na challenging problem. This is due to technical difficulties of generating\nreproducible images with a normalized form and the effect of negative stain. In\nthis paper, we will discuss a new concept of interpreting the 2D images and\novercoming the aforementioned technical difficulties using mathematical\ntransformation. The method makes use of 2D gel images of proteins in serums and\nwe explain a way of representing the images into vectors in order to apply\nmachine-learning methods, such as the support vector machine.",
    "published": "2003-05-28T13:48:34Z",
    "link": "http://arxiv.org/pdf/cs/0305048v1.pdf",
    "category": [
      "cs.CC",
      "cs.CV",
      "q-bio.QM",
      "I.5; J.3; I.4.1; I.4.3"
    ],
    "authors": [
      "Gene Kim",
      "MyungHo Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cond-mat/0305681v4",
    "title": "Seven clusters in genomic triplet distributions",
    "summary": "In several recent papers new gene-detection algorithms were proposed for\ndetecting protein-coding regions without requiring learning dataset of already\nknown genes. The fact that unsupervised gene-detection is possible closely\nconnected to existence of a cluster structure in oligomer frequency\ndistributions. In this paper we study cluster structure of several genomes in\nthe space of their triplet frequencies, using pure data exploration strategy.\nSeveral complete genomic sequences were analyzed, using visualization of tables\nof triplet frequencies in a sliding window. The distribution of 64-dimensional\nvectors of triplet frequencies displays a well-detectable cluster structure.\nThe structure was found to consist of seven clusters, corresponding to\nprotein-coding information in three possible phases in one of the two\ncomplementary strands and in the non-coding regions with high accuracy (higher\nthan 90% on the nucleotide level). Visualizing and understanding the structure\nallows to analyze effectively performance of different gene-prediction tools.\nSince the method does not require extraction of ORFs, it can be applied even\nfor unassembled genomes. The information content of the triplet distributions\nand the validity of the mean-field models are analysed.",
    "published": "2003-05-29T11:36:34Z",
    "link": "http://arxiv.org/pdf/cond-mat/0305681v4.pdf",
    "category": [
      "cond-mat.dis-nn",
      "cs.CV",
      "physics.bio-ph",
      "physics.data-an",
      "q-bio.GN"
    ],
    "authors": [
      "A. N. Gorban",
      "A. Yu. Zinovyev",
      "T. G. Popova"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0307038v1",
    "title": "Manifold Learning with Geodesic Minimal Spanning Trees",
    "summary": "In the manifold learning problem one seeks to discover a smooth low\ndimensional surface, i.e., a manifold embedded in a higher dimensional linear\nvector space, based on a set of measured sample points on the surface. In this\npaper we consider the closely related problem of estimating the manifold's\nintrinsic dimension and the intrinsic entropy of the sample points.\nSpecifically, we view the sample points as realizations of an unknown\nmultivariate density supported on an unknown smooth manifold. We present a\nnovel geometrical probability approach, called the\ngeodesic-minimal-spanning-tree (GMST), to obtaining asymptotically consistent\nestimates of the manifold dimension and the R\\'{e}nyi $\\alpha$-entropy of the\nsample density on the manifold. The GMST approach is striking in its simplicity\nand does not require reconstructing the manifold or estimating the multivariate\ndensity of the samples. The GMST method simply constructs a minimal spanning\ntree (MST) sequence using a geodesic edge matrix and uses the overall lengths\nof the MSTs to simultaneously estimate manifold dimension and entropy. We\nillustrate the GMST approach for dimension and entropy estimation of a human\nface dataset.",
    "published": "2003-07-16T23:50:53Z",
    "link": "http://arxiv.org/pdf/cs/0307038v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG",
      "G.3;F.2.2"
    ],
    "authors": [
      "Jose Costa",
      "Alfred Hero"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0307045v1",
    "title": "Flexible Camera Calibration Using a New Analytical Radial Undistortion\n  Formula with Application to Mobile Robot Localization",
    "summary": "Most algorithms in 3D computer vision rely on the pinhole camera model\nbecause of its simplicity, whereas virtually all imaging devices introduce\ncertain amount of nonlinear distortion, where the radial distortion is the most\nsevere part. Common approach to radial distortion is by the means of polynomial\napproximation, which introduces distortion-specific parameters into the camera\nmodel and requires estimation of these distortion parameters. The task of\nestimating radial distortion is to find a radial distortion model that allows\neasy undistortion as well as satisfactory accuracy. This paper presents a new\nradial distortion model with an easy analytical undistortion formula, which\nalso belongs to the polynomial approximation category. Experimental results are\npresented to show that with this radial distortion model, satisfactory accuracy\nis achieved. An application of the new radial distortion model is non-iterative\nyellow line alignment with a calibrated camera on ODIS, a robot built in our\nCSOIS.",
    "published": "2003-07-20T02:35:38Z",
    "link": "http://arxiv.org/pdf/cs/0307045v1.pdf",
    "category": [
      "cs.CV",
      "I.4.1"
    ],
    "authors": [
      "Lili Ma",
      "YangQuan Chen",
      "Kevin L. Moore"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0307046v1",
    "title": "A New Analytical Radial Distortion Model for Camera Calibration",
    "summary": "Common approach to radial distortion is by the means of polynomial\napproximation, which introduces distortion-specific parameters into the camera\nmodel and requires estimation of these distortion parameters. The task of\nestimating radial distortion is to find a radial distortion model that allows\neasy undistortion as well as satisfactory accuracy. This paper presents a new\nradial distortion model with an easy analytical undistortion formula, which\nalso belongs to the polynomial approximation category. Experimental results are\npresented to show that with this radial distortion model, satisfactory accuracy\nis achieved.",
    "published": "2003-07-20T05:18:59Z",
    "link": "http://arxiv.org/pdf/cs/0307046v1.pdf",
    "category": [
      "cs.CV",
      "I.4.1"
    ],
    "authors": [
      "Lili Ma",
      "YangQuan Chen",
      "Kevin L. Moore"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0307047v1",
    "title": "Rational Radial Distortion Models with Analytical Undistortion Formulae",
    "summary": "The common approach to radial distortion is by the means of polynomial\napproximation, which introduces distortion-specific parameters into the camera\nmodel and requires estimation of these distortion parameters. The task of\nestimating radial distortion is to find a radial distortion model that allows\neasy undistortion as well as satisfactory accuracy. This paper presents a new\nclass of rational radial distortion models with easy analytical undistortion\nformulae. Experimental results are presented to show that with this class of\nrational radial distortion models, satisfactory and comparable accuracy is\nachieved.",
    "published": "2003-07-20T05:54:42Z",
    "link": "http://arxiv.org/pdf/cs/0307047v1.pdf",
    "category": [
      "cs.CV",
      "I.4.1"
    ],
    "authors": [
      "Lili Ma",
      "YangQuan Chen",
      "Kevin L. Moore"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0307051v1",
    "title": "An Analytical Piecewise Radial Distortion Model for Precision Camera\n  Calibration",
    "summary": "The common approach to radial distortion is by the means of polynomial\napproximation, which introduces distortion-specific parameters into the camera\nmodel and requires estimation of these distortion parameters. The task of\nestimating radial distortion is to find a radial distortion model that allows\neasy undistortion as well as satisfactory accuracy. This paper presents a new\npiecewise radial distortion model with easy analytical undistortion formula.\nThe motivation for seeking a piecewise radial distortion model is that, when a\ncamera is resulted in a low quality during manufacturing, the nonlinear radial\ndistortion can be complex. Using low order polynomials to approximate the\nradial distortion might not be precise enough. On the other hand, higher order\npolynomials suffer from the inverse problem. With the new piecewise radial\ndistortion function, more flexibility is obtained and the radial undistortion\ncan be performed analytically. Experimental results are presented to show that\nwith this new piecewise radial distortion model, better performance is achieved\nthan that using the single function. Furthermore, a comparable performance with\nthe conventional polynomial model using 2 coefficients can also be\naccomplished.",
    "published": "2003-07-21T16:30:11Z",
    "link": "http://arxiv.org/pdf/cs/0307051v1.pdf",
    "category": [
      "cs.CV",
      "I.4.1"
    ],
    "authors": [
      "Lili Ma",
      "YangQuan Chen",
      "Kevin L. Moore"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0307072v1",
    "title": "Camera Calibration: a USU Implementation",
    "summary": "The task of camera calibration is to estimate the intrinsic and extrinsic\nparameters of a camera model. Though there are some restricted techniques to\ninfer the 3-D information about the scene from uncalibrated cameras, effective\ncamera calibration procedures will open up the possibility of using a wide\nrange of existing algorithms for 3-D reconstruction and recognition.\n  The applications of camera calibration include vision-based metrology, robust\nvisual platooning and visual docking of mobile robots where the depth\ninformation is important.",
    "published": "2003-07-31T19:33:48Z",
    "link": "http://arxiv.org/pdf/cs/0307072v1.pdf",
    "category": [
      "cs.CV",
      "I.4.1"
    ],
    "authors": [
      "Lili Ma",
      "YangQuan Chen",
      "Kevin L. Moore"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0308003v1",
    "title": "A Family of Simplified Geometric Distortion Models for Camera\n  Calibration",
    "summary": "The commonly used radial distortion model for camera calibration is in fact\nan assumption or a restriction. In practice, camera distortion could happen in\na general geometrical manner that is not limited to the radial sense. This\npaper proposes a simplified geometrical distortion modeling method by using two\ndifferent radial distortion functions in the two image axes. A family of\nsimplified geometric distortion models is proposed, which are either simple\npolynomials or the rational functions of polynomials. Analytical geometric\nundistortion is possible using two of the distortion functions discussed in\nthis paper and their performance can be improved by applying a piecewise\nfitting idea. Our experimental results show that the geometrical distortion\nmodels always perform better than their radial distortion counterparts.\nFurthermore, the proposed geometric modeling method is more appropriate for\ncameras whose distortion is not perfectly radially symmetric around the center\nof distortion.",
    "published": "2003-08-02T01:39:38Z",
    "link": "http://arxiv.org/pdf/cs/0308003v1.pdf",
    "category": [
      "cs.CV",
      "I.4.1"
    ],
    "authors": [
      "Lili Ma",
      "YangQuan Chen",
      "Kevin L. Moore"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0308009v3",
    "title": "The Generalized Riemann or Henstock Integral Underpinning Multivariate\n  Data Analysis: Application to Faint Structure Finding in Price Processes",
    "summary": "Practical data analysis involves many implicit or explicit assumptions about\nthe good behavior of the data, and excludes consideration of various\npotentially pathological or limit cases. In this work, we present a new general\ntheory of data, and of data processing, to bypass some of these assumptions.\nThe new framework presented is focused on integration, and has direct\napplicability to expectation, distance, correlation, and aggregation. In a case\nstudy, we seek to reveal faint structure in financial data. Our new foundation\nfor data encoding and handling offers increased justification for our\nconclusions.",
    "published": "2003-08-05T09:31:38Z",
    "link": "http://arxiv.org/pdf/cs/0308009v3.pdf",
    "category": [
      "cs.CE",
      "cs.CV",
      "G.3; I.5.3"
    ],
    "authors": [
      "Pat Muldowney",
      "Fionn Murtagh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0308023v1",
    "title": "On the complexity of curve fitting algorithms",
    "summary": "We study a popular algorithm for fitting polynomial curves to scattered data\nbased on the least squares with gradient weights. We show that sometimes this\nalgorithm admits a substantial reduction of complexity, and, furthermore, find\nprecise conditions under which this is possible. It turns out that this is,\nindeed, possible when one fits circles but not ellipses or hyperbolas.",
    "published": "2003-08-15T15:37:43Z",
    "link": "http://arxiv.org/pdf/cs/0308023v1.pdf",
    "category": [
      "cs.CC",
      "cs.CV",
      "I.4.8; I.5.1; G.3"
    ],
    "authors": [
      "N. Chernov",
      "C. Lesort",
      "N. Simanyi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0308034v1",
    "title": "Fingerprint based bio-starter and bio-access",
    "summary": "In the paper will be presented a safety and security system based on\nfingerprint technology. The results suggest a new scenario where the new cars\ncan use a fingerprint sensor integrated in car handle to allow access and in\nthe dashboard as starter button.",
    "published": "2003-08-21T10:47:27Z",
    "link": "http://arxiv.org/pdf/cs/0308034v1.pdf",
    "category": [
      "cs.CV",
      "I.2.10, I.4, I.5"
    ],
    "authors": [
      "G. Iovane",
      "P. Giordano",
      "C. Iovane",
      "F. Rotulo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0308035v1",
    "title": "IS (Iris Security)",
    "summary": "In the paper will be presented a safety system based on iridology. The\nresults suggest a new scenario where the security problem in supervised and\nunsupervised areas can be treat with the present system and the iris image\nrecognition.",
    "published": "2003-08-21T10:52:53Z",
    "link": "http://arxiv.org/pdf/cs/0308035v1.pdf",
    "category": [
      "cs.CV",
      "I.5, I.5"
    ],
    "authors": [
      "G. Iovane",
      "F. S. Tortoriello"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0308037v1",
    "title": "Distributed and Parallel Net Imaging",
    "summary": "A very complex vision system is developed to detect luminosity variations\nconnected with the discovery of new planets in the Universe. The traditional\nimaging system can not manage a so large load. A private net is implemented to\nperform an automatic vision and decision architecture. It lets to carry out an\non-line discrimination of interesting events by using two levels of triggers.\nThis system can even manage many Tbytes of data per day. The architecture\navails itself of a distributed parallel network system based on a maximum of\n256 standard workstations with Microsoft Window as OS.",
    "published": "2003-08-22T10:31:53Z",
    "link": "http://arxiv.org/pdf/cs/0308037v1.pdf",
    "category": [
      "cs.CV",
      "astro-ph",
      "cs.DC",
      "I.4,I.5"
    ],
    "authors": [
      "G. Iovane"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0308038v1",
    "title": "Image Analysis in Astronomy for very large vision machine",
    "summary": "It is developed a very complex system (hardware/software) to detect\nluminosity variations connected with the discovery of new planets outside the\nSolar System. Traditional imaging approaches are very demanding in terms of\ncomputing time; then, the implementation of an automatic vision and decision\nsoftware architecture is presented. It allows to perform an on-line\ndiscrimination of interesting events by using two levels of triggers. A\nfundamental challenge was to work with very large CCD camera (even 16k*16k\npixels) in line with very large telescopes. Then, the architecture can use a\ndistributed parallel network system based on a maximum of 256 standard\nworkstations.",
    "published": "2003-08-22T18:47:33Z",
    "link": "http://arxiv.org/pdf/cs/0308038v1.pdf",
    "category": [
      "cs.CV",
      "astro-ph",
      "cs.DC",
      "I.4,I.5"
    ],
    "authors": [
      "G. Iovane"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0309041v2",
    "title": "Fast Verification of Convexity of Piecewise-linear Surfaces",
    "summary": "We show that a realization of a closed connected PL-manifold of dimension n-1\nin n-dimensional Euclidean space (n>2) is the boundary of a convex polyhedron\n(finite or infinite) if and only if the interior of each (n-3)-face has a\npoint, which has a neighborhood lying on the boundary of an n-dimensional\nconvex body. No initial assumptions about the topology or orientability of the\ninput surface are made. The theorem is derived from a refinement and\ngeneralization of Van Heijenoort's theorem on locally convex manifolds to\nspherical spaces. Our convexity criterion for PL-manifolds implies an easy\npolynomial-time algorithm for checking convexity of a given PL-surface in\nn-dimensional Euclidean or spherical space, n>2. The algorithm is worst case\noptimal with respect to both the number of operations and the algebraic degree.\nThe algorithm works under significantly weaker assumptions and is easier to\nimplement than convexity verification algorithms suggested by Mehlhorn et al\n(1996-1999), and Devillers et al.(1998). A paradigm of approximate convexity is\nsuggested and a simplified algorithm of smaller degree and complexity is\nsuggested for approximate floating point convexity verification.",
    "published": "2003-09-23T06:47:28Z",
    "link": "http://arxiv.org/pdf/cs/0309041v2.pdf",
    "category": [
      "cs.CG",
      "cs.CV",
      "Primary: G.4, F.2.2; Secondary: 1.4.7, 1.4.8"
    ],
    "authors": [
      "Konstantin Rybnikov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/math/0311004v1",
    "title": "Which Point Configurations are Determined by the Distribution of their\n  Pairwise Distances?",
    "summary": "In a previous paper we showed that, for any $n \\ge m+2$, most sets of $n$\npoints in $\\RR^m$ are determined (up to rotations, reflections, translations\nand relabeling of the points) by the distribution of their pairwise distances.\nBut there are some exceptional point configurations which are not\nreconstructible from the distribution of distances in the above sense. In this\npaper, we present a reconstructibility test with running time $O(n^{11})$. The\ncases of orientation preserving rigid motions (rotations and translations) and\nscalings are also discussed.",
    "published": "2003-11-02T01:16:12Z",
    "link": "http://arxiv.org/pdf/math/0311004v1.pdf",
    "category": [
      "math.MG",
      "cs.CV",
      "math.AC",
      "math.AG",
      "68U;14L"
    ],
    "authors": [
      "Mireille Boutin",
      "Gregor Kemper"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0311012v1",
    "title": "A rigorous definition of axial lines: ridges on isovist fields",
    "summary": "We suggest that 'axial lines' defined by (Hillier and Hanson, 1984) as lines\nof uninterrupted movement within urban streetscapes or buildings, appear as\nridges in isovist fields (Benedikt, 1979). These are formed from the maximum\ndiametric lengths of the individual isovists, sometimes called viewsheds, that\nmake up these fields (Batty and Rana, 2004). We present an image processing\ntechnique for the identification of lines from ridges, discuss current\nstrengths and weaknesses of the method, and show how it can be implemented\neasily and effectively.",
    "published": "2003-11-12T19:15:41Z",
    "link": "http://arxiv.org/pdf/cs/0311012v1.pdf",
    "category": [
      "cs.CV",
      "cs.CG",
      "I2.10; I.4.10"
    ],
    "authors": [
      "Rui Carvalho",
      "Michael Batty"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0312044v2",
    "title": "Clustering by compression",
    "summary": "We present a new method for clustering based on compression. The method\ndoesn't use subject-specific features or background knowledge, and works as\nfollows: First, we determine a universal similarity distance, the normalized\ncompression distance or NCD, computed from the lengths of compressed data files\n(singly and in pairwise concatenation). Second, we apply a hierarchical\nclustering method. The NCD is universal in that it is not restricted to a\nspecific application area, and works across application area boundaries. A\ntheoretical precursor, the normalized information distance, co-developed by one\nof the authors, is provably optimal but uses the non-computable notion of\nKolmogorov complexity. We propose precise notions of similarity metric, normal\ncompressor, and show that the NCD based on a normal compressor is a similarity\nmetric that approximates universality. To extract a hierarchy of clusters from\nthe distance matrix, we determine a dendrogram (binary tree) by a new quartet\nmethod and a fast heuristic to implement it. The method is implemented and\navailable as public software, and is robust under choice of different\ncompressors. To substantiate our claims of universality and robustness, we\nreport evidence of successful application in areas as diverse as genomics,\nvirology, languages, literature, music, handwritten digits, astronomy, and\ncombinations of objects from completely different domains, using statistical,\ndictionary, and block sorting compressors. In genomics we presented new\nevidence for major questions in Mammalian evolution, based on\nwhole-mitochondrial genomic analysis: the Eutherian orders and the Marsupionta\nhypothesis against the Theria hypothesis.",
    "published": "2003-12-19T18:41:29Z",
    "link": "http://arxiv.org/pdf/cs/0312044v2.pdf",
    "category": [
      "cs.CV",
      "cond-mat.stat-mech",
      "cs.AI",
      "physics.data-an",
      "q-bio.GN",
      "q-bio.QM",
      "E4, H.3.3, H.5.5, I.2.6, I.2.10, I.5.3, J.3,J.5"
    ],
    "authors": [
      "Rudi Cilibrasi",
      "Paul Vitanyi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0401004v2",
    "title": "Cyborg Systems as Platforms for Computer-Vision Algorithm-Development\n  for Astrobiology",
    "summary": "Employing the allegorical imagery from the film \"The Matrix\", we motivate and\ndiscuss our `Cyborg Astrobiologist' research program. In this research program,\nwe are using a wearable computer and video camcorder in order to test and train\na computer-vision system to be a field-geologist and field-astrobiologist.",
    "published": "2004-01-02T12:39:15Z",
    "link": "http://arxiv.org/pdf/cs/0401004v2.pdf",
    "category": [
      "cs.CV",
      "astro-ph",
      "cs.AI",
      "I.4.0; I.4.6; I.4.8; I.4.9; I.5.4; I.5.5; J.2; I.2.5; I.2.10"
    ],
    "authors": [
      "Patrick C. McGuire",
      "J. A. Rodriguez-Manfredi",
      "E. Sebastian-Martinez",
      "J. Gomez-Elvira",
      "E. Diaz-Martinez",
      "J. Ormo",
      "K. Neuffer",
      "A. Giaquinta",
      "F. Camps-Martinez",
      "A. Lepinette-Malvitte",
      "J. Perez-Mercader",
      "H. Ritter",
      "M. Oesker",
      "J. Ontrup",
      "J. Walter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0401017v2",
    "title": "Better Foreground Segmentation Through Graph Cuts",
    "summary": "For many tracking and surveillance applications, background subtraction\nprovides an effective means of segmenting objects moving in front of a static\nbackground. Researchers have traditionally used combinations of morphological\noperations to remove the noise inherent in the background-subtracted result.\nSuch techniques can effectively isolate foreground objects, but tend to lose\nfidelity around the borders of the segmentation, especially for noisy input.\nThis paper explores the use of a minimum graph cut algorithm to segment the\nforeground, resulting in qualitatively and quantitiatively cleaner\nsegmentations. Experiments on both artificial and real data show that the\ngraph-based method reduces the error around segmented foreground objects. A\nMATLAB code implementation is available at\nhttp://www.cs.smith.edu/~nhowe/research/code/#fgseg",
    "published": "2004-01-21T20:06:51Z",
    "link": "http://arxiv.org/pdf/cs/0401017v2.pdf",
    "category": [
      "cs.CV",
      "I.4.6"
    ],
    "authors": [
      "Nicholas R. Howe",
      "Alexandra Deschamps"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0401018v1",
    "title": "Factor Temporal Prognosis of Tick-Borne Encephalitis Foci Functioning on\n  the South of Russian Far East",
    "summary": "A method of temporal factor prognosis of TE (tick-borne encephalitis)\ninfection has been developed. The high precision of the prognosis results for a\nnumber of geographical regions of Primorsky Krai has been achieved. The method\ncan be applied not only to epidemiological research but also to others.",
    "published": "2004-01-22T05:53:30Z",
    "link": "http://arxiv.org/pdf/cs/0401018v1.pdf",
    "category": [
      "cs.CV",
      "B.1.3"
    ],
    "authors": [
      "E. I. Bolotin",
      "G. Sh. Tsitsiashvili",
      "I. V. Golycheva"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0402021v1",
    "title": "A Numerical Example on the Principles of Stochastic Discrimination",
    "summary": "Studies on ensemble methods for classification suffer from the difficulty of\nmodeling the complementary strengths of the components. Kleinberg's theory of\nstochastic discrimination (SD) addresses this rigorously via mathematical\nnotions of enrichment, uniformity, and projectability of an ensemble. We\nexplain these concepts via a very simple numerical example that captures the\nbasic principles of the SD theory and method. We focus on a fundamental\nsymmetry in point set covering that is the key observation leading to the\nfoundation of the theory. We believe a better understanding of the SD method\nwill lead to developments of better tools for analyzing other ensemble methods.",
    "published": "2004-02-11T15:45:14Z",
    "link": "http://arxiv.org/pdf/cs/0402021v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG",
      "I.5.0"
    ],
    "authors": [
      "Tin Kam Ho"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0402020v1",
    "title": "Geometrical Complexity of Classification Problems",
    "summary": "Despite encouraging recent progresses in ensemble approaches, classification\nmethods seem to have reached a plateau in development. Further advances depend\non a better understanding of geometrical and topological characteristics of\npoint sets in high-dimensional spaces, the preservation of such characteristics\nunder feature transformations and sampling processes, and their interaction\nwith geometrical models used in classifiers. We discuss an attempt to measure\nsuch properties from data sets and relate them to classifier accuracies.",
    "published": "2004-02-11T16:34:16Z",
    "link": "http://arxiv.org/pdf/cs/0402020v1.pdf",
    "category": [
      "cs.CV",
      "I.5.0"
    ],
    "authors": [
      "Tin Kam Ho"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0404042v2",
    "title": "Extraction of topological features from communication network\n  topological patterns using self-organizing feature maps",
    "summary": "Different classes of communication network topologies and their\nrepresentation in the form of adjacency matrix and its eigenvalues are\npresented. A self-organizing feature map neural network is used to map\ndifferent classes of communication network topological patterns. The neural\nnetwork simulation results are reported.",
    "published": "2004-04-21T16:05:27Z",
    "link": "http://arxiv.org/pdf/cs/0404042v2.pdf",
    "category": [
      "cs.NE",
      "cs.CV",
      "C.2; I.5"
    ],
    "authors": [
      "W. Ali",
      "R. J. Mondragon",
      "F. Alavi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0404046v1",
    "title": "Visualising the structure of architectural open spaces based on shape\n  analysis",
    "summary": "This paper proposes the application of some well known two-dimensional\ngeometrical shape descriptors for the visualisation of the structure of\narchitectural open spaces. The paper demonstrates the use of visibility\nmeasures such as distance to obstacles and amount of visible space to calculate\nshape descriptors such as convexity and skeleton of the open space. The aim of\nthe paper is to indicate a simple, objective and quantifiable approach to\nunderstand the structure of open spaces otherwise impossible due to the complex\nconstruction of built structures.",
    "published": "2004-04-22T13:42:48Z",
    "link": "http://arxiv.org/pdf/cs/0404046v1.pdf",
    "category": [
      "cs.CV",
      "cs.CG",
      "cs.DS",
      "I.3.5;I.4.8;I.5.2"
    ],
    "authors": [
      "Sanjay Rana",
      "Mike Batty"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0405029v2",
    "title": "A New Computational Framework For 2D Shape-Enclosing Contours",
    "summary": "In this paper, a new framework for one-dimensional contour extraction from\ndiscrete two-dimensional data sets is presented. Contour extraction is\nimportant in many scientific fields such as digital image processing, computer\nvision, pattern recognition, etc. This novel framework includes (but is not\nlimited to) algorithms for dilated contour extraction, contour displacement,\nshape skeleton extraction, contour continuation, shape feature based contour\nrefinement and contour simplification. Many of the new techniques depend\nstrongly on the application of a Delaunay tessellation. In order to demonstrate\nthe versatility of this novel toolbox approach, the contour extraction\ntechniques presented here are applied to scientific problems in material\nscience, biology and heavy ion physics.",
    "published": "2004-05-07T03:25:03Z",
    "link": "http://arxiv.org/pdf/cs/0405029v2.pdf",
    "category": [
      "cs.CV",
      "cs.CG",
      "G.1.2"
    ],
    "authors": [
      "B. R. Schlei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0405093v2",
    "title": "Computerized Face Detection and Recognition",
    "summary": "This publication presents methods for face detection, analysis and\nrecognition: fast normalized cross-correlation (fast correlation coefficient)\nbetween multiple templates based face pre-detection method, method for\ndetection of exact face contour based on snakes and Generalized Gradient Vector\nFlow field, method for combining recognition algorithms based on Cumulative\nMatch Characteristics in order to increase recognition speed and accuracy, and\nface recognition method based on Principal Component Analysis of the Wavelet\nPacket Decomposition allowing to use PCA - based recognition method with large\nnumber of training images. For all the methods are presented experimental\nresults and comparisons of speed and accuracy with large face databases.",
    "published": "2004-05-25T11:36:34Z",
    "link": "http://arxiv.org/pdf/cs/0405093v2.pdf",
    "category": [
      "cs.CV",
      "I.4.8; I.5"
    ],
    "authors": [
      "Vytautas Perlibakas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0405095v1",
    "title": "Blind Detection and Compensation of Camera Lens Geometric Distortions",
    "summary": "This paper presents a blind detection and compensation technique for camera\nlens geometric distortions. The lens distortion introduces higher-order\ncorrelations in the frequency domain and in turn it can be detected using\nhigher-order spectral analysis tools without assuming any specific calibration\ntarget. The existing blind lens distortion removal method only considered a\nsingle-coefficient radial distortion model. In this paper, two coefficients are\nconsidered to model approximately the geometric distortion. All the models\nconsidered have analytical closed-form inverse formulae.",
    "published": "2004-05-25T22:40:42Z",
    "link": "http://arxiv.org/pdf/cs/0405095v1.pdf",
    "category": [
      "cs.CV",
      "I 4.1"
    ],
    "authors": [
      "Lili Ma",
      "YangQuan Chen",
      "Kevin L. Moore"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0406008v1",
    "title": "Image compression by rectangular wavelet transform",
    "summary": "We study image compression by a separable wavelet basis\n$\\big\\{\\psi(2^{k_1}x-i)\\psi(2^{k_2}y-j),$ $\\phi(x-i)\\psi(2^{k_2}y-j),$\n$\\psi(2^{k_1}(x-i)\\phi(y-j),$ $\\phi(x-i)\\phi(y-i)\\big\\},$ where $k_1, k_2 \\in\n\\mathbb{Z}_+$; $i,j\\in\\mathbb{Z}$; and $\\phi,\\psi$ are elements of a standard\nbiorthogonal wavelet basis in $L_2(\\mathbb{R})$. Because $k_1\\ne k_2$, the\nsupports of the basis elements are rectangles, and the corresponding transform\nis known as the {\\em rectangular wavelet transform}. We prove that if\none-dimensional wavelet basis has $M$ dual vanishing moments then the rate of\napproximation by $N$ coefficients of rectangular wavelet transform is\n$\\mathcal{O}(N^{-M}\\log^C N)$ for functions with mixed derivative of order $M$\nin each direction.\n  The square wavelet transform yields the approximation rate is\n$\\mathcal{O}(N^{-M/2})$ for functions with all derivatives of the total order\n$M$. Thus, the rectangular wavelet transform can outperform the square one if\nan image has a mixed derivative. We provide experimental comparison of image\ncompression which shows that rectangular wavelet transform outperform the\nsquare one.",
    "published": "2004-06-04T12:28:06Z",
    "link": "http://arxiv.org/pdf/cs/0406008v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Vyacheslav Zavadsky"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0406017v2",
    "title": "Using Self-Organising Mappings to Learn the Structure of Data Manifolds",
    "summary": "In this paper it is shown how to map a data manifold into a simpler form by\nprogressively discarding small degrees of freedom. This is the key to\nself-organising data fusion, where the raw data is embedded in a very\nhigh-dimensional space (e.g. the pixel values of one or more images), and the\nrequirement is to isolate the important degrees of freedom which lie on a\nlow-dimensional manifold. A useful advantage of the approach used in this paper\nis that the computations are arranged as a feed-forward processing chain, where\nall the details of the processing in each stage of the chain are learnt by\nself-organisation. This approach is demonstrated using hierarchically\ncorrelated data, which causes the processing chain to split the data into\nseparate processing channels, and then to progressively merge these channels\nwherever they are correlated with each other. This is the key to\nself-organising data fusion.",
    "published": "2004-06-08T14:45:45Z",
    "link": "http://arxiv.org/pdf/cs/0406017v2.pdf",
    "category": [
      "cs.NE",
      "cs.CV",
      "I.2.6; I.5.1"
    ],
    "authors": [
      "Stephen Luttrell"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0406043v2",
    "title": "The Computational Complexity of Orientation Search Problems in\n  Cryo-Electron Microscopy",
    "summary": "In this report we study the problem of determining three-dimensional\norientations for noisy projections of randomly oriented identical particles.\nThe problem is of central importance in the tomographic reconstruction of the\ndensity map of macromolecular complexes from electron microscope images and it\nhas been studied intensively for more than 30 years.\n  We analyze the computational complexity of the orientation problem and show\nthat while several variants of the problem are $NP$-hard, inapproximable and\nfixed-parameter intractable, some restrictions are polynomial-time approximable\nwithin a constant factor or even solvable in logarithmic space. The orientation\nsearch problem is formalized as a constrained line arrangement problem that is\nof independent interest. The negative complexity results give a partial\njustification for the heuristic methods used in orientation search, and the\npositive complexity results on the orientation search have some positive\nimplications also to the problem of finding functionally analogous genes.\n  A preliminary version ``The Computational Complexity of Orientation Search in\nCryo-Electron Microscopy'' appeared in Proc. ICCS 2004, LNCS 3036, pp.\n231--238. Springer-Verlag 2004.",
    "published": "2004-06-23T14:28:17Z",
    "link": "http://arxiv.org/pdf/cs/0406043v2.pdf",
    "category": [
      "cs.DS",
      "cs.CG",
      "cs.CV",
      "F.2.2; I.4.5; J.3"
    ],
    "authors": [
      "Taneli Mielikinen",
      "Janne Ravantti",
      "Esko Ukkonen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0406047v1",
    "title": "Self-organizing neural networks in classification and image recognition",
    "summary": "Self-organizing neural networks are used for brick finding in OPERA\nexperiment. Self-organizing neural networks and wavelet analysis used for\nrecognition and extraction of car numbers from images.",
    "published": "2004-06-24T13:14:58Z",
    "link": "http://arxiv.org/pdf/cs/0406047v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "G. A. Ososkov",
      "S. G. Dmitrievskiy",
      "A. V. Stadnik"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0407047v3",
    "title": "Channel-Independent and Sensor-Independent Stimulus Representations",
    "summary": "This paper shows how a machine, which observes stimuli through an\nuncharacterized, uncalibrated channel and sensor, can glean machine-independent\ninformation (i.e., channel- and sensor-independent information) about the\nstimuli. First, we demonstrate that a machine defines a specific coordinate\nsystem on the stimulus state space, with the nature of that coordinate system\ndepending on the device's channel and sensor. Thus, machines with different\nchannels and sensors \"see\" the same stimulus trajectory through state space,\nbut in different machine-specific coordinate systems. For a large variety of\nphysical stimuli, statistical properties of that trajectory endow the stimulus\nconfiguration space with differential geometric structure (a metric and\nparallel transfer procedure), which can then be used to represent relative\nstimulus configurations in a coordinate-system-independent manner (and,\ntherefore, in a channel- and sensor-independent manner). The resulting\ndescription is an \"inner\" property of the stimulus time series in the sense\nthat it does not depend on extrinsic factors like the observer's choice of a\ncoordinate system in which the stimulus is viewed (i.e., the observer's choice\nof channel and sensor). This methodology is illustrated with analytic examples\nand with a numerically simulated experiment. In an intelligent sensory device,\nthis kind of representation \"engine\" could function as a \"front-end\" that\npasses channel/sensor-independent stimulus representations to a pattern\nrecognition module. After a pattern recognizer has been trained in one of these\ndevices, it could be used without change in other devices having different\nchannels and sensors.",
    "published": "2004-07-19T17:13:34Z",
    "link": "http://arxiv.org/pdf/cs/0407047v3.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "I.5; I.5.4.m; I.5.2.b; I.2.10.f; I.2.4.j; I.2.7.g; I.5.4.b; I.2;\n  I.2.0.b"
    ],
    "authors": [
      "David N. Levin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0408012v1",
    "title": "Three-Dimensional Face Orientation and Gaze Detection from a Single\n  Image",
    "summary": "Gaze detection and head orientation are an important part of many advanced\nhuman-machine interaction applications. Many systems have been proposed for\ngaze detection. Typically, they require some form of user cooperation and\ncalibration. Additionally, they may require multiple cameras and/or restricted\nhead positions. We present a new approach for inference of both face\norientation and gaze direction from a single image with no restrictions on the\nhead position. Our algorithm is based on a face and eye model, deduced from\nanthropometric data. This approach allows us to use a single camera and\nrequires no cooperation from the user. Using a single image avoids the\ncomplexities associated with of a multi-camera system. Evaluation tests show\nthat our system is accurate, fast and can be used in a variety of applications,\nincluding ones where the user is unaware of the system.",
    "published": "2004-08-04T18:12:52Z",
    "link": "http://arxiv.org/pdf/cs/0408012v1.pdf",
    "category": [
      "cs.CV",
      "cs.HC"
    ],
    "authors": [
      "J. Y. Kaminski",
      "M. Teicher",
      "D. Knaan",
      "A. Shavit"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0408049v1",
    "title": "Using Stochastic Encoders to Discover Structure in Data",
    "summary": "In this paper a stochastic generalisation of the standard Linde-Buzo-Gray\n(LBG) approach to vector quantiser (VQ) design is presented, in which the\nencoder is implemented as the sampling of a vector of code indices from a\nprobability distribution derived from the input vector, and the decoder is\nimplemented as a superposition of reconstruction vectors. This stochastic VQ\n(SVQ) is optimised using a minimum mean Euclidean reconstruction distortion\ncriterion, as in the LBG case. Numerical simulations are used to demonstrate\nhow this leads to self-organisation of the SVQ, where different stochastically\nsampled code indices become associated with different input subspaces.",
    "published": "2004-08-21T19:40:24Z",
    "link": "http://arxiv.org/pdf/cs/0408049v1.pdf",
    "category": [
      "cs.NE",
      "cs.CV",
      "I.2.6; I.5.1"
    ],
    "authors": [
      "Stephen Luttrell"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0408050v1",
    "title": "Invariant Stochastic Encoders",
    "summary": "The theory of stochastic vector quantisers (SVQ) has been extended to allow\nthe quantiser to develop invariances, so that only \"large\" degrees of freedom\nin the input vector are represented in the code. This has been applied to the\nproblem of encoding data vectors which are a superposition of a \"large\" jammer\nand a \"small\" signal, so that only the jammer is represented in the code. This\nallows the jammer to be subtracted from the total input vector (i.e. the jammer\nis nulled), leaving a residual that contains only the underlying signal. The\nmain advantage of this approach to jammer nulling is that little prior\nknowledge of the jammer is assumed, because these properties are automatically\ndiscovered by the SVQ as it is trained on examples of input vectors.",
    "published": "2004-08-21T23:06:45Z",
    "link": "http://arxiv.org/pdf/cs/0408050v1.pdf",
    "category": [
      "cs.NE",
      "cs.CV",
      "I.2.6; I.5.1"
    ],
    "authors": [
      "Stephen Luttrell"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0409003v1",
    "title": "ScheduleNanny: Using GPS to Learn the User's Significant Locations,\n  Travel Times and Schedule",
    "summary": "As computing technology becomes more pervasive, personal devices such as the\nPDA, cell-phone, and notebook should use context to determine how to act.\nLocation is one form of context that can be used in many ways. We present a\nmultiple-device system that collects and clusters GPS data into significant\nlocations. These locations are then used to determine travel times and a\nprobabilistic model of the user's schedule, which is used to intelligently\nalert the user. We evaluate our system and suggest how it should be integrated\nwith a variety of applications.",
    "published": "2004-09-02T15:28:53Z",
    "link": "http://arxiv.org/pdf/cs/0409003v1.pdf",
    "category": [
      "cs.AI",
      "cs.CV",
      "cs.HC",
      "F.2.2; I.5.3; H.5.3; H.5.m"
    ],
    "authors": [
      "Parth Bhawalkar",
      "Victor Bigio",
      "Adam Davis",
      "Karthik Narayanaswami",
      "Femi Olumoko"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0409031v1",
    "title": "Field Geology with a Wearable Computer: First Results of the Cyborg\n  Astrobiologist System",
    "summary": "We present results from the first geological field tests of the `Cyborg\nAstrobiologist', which is a wearable computer and video camcorder system that\nwe are using to test and train a computer-vision system towards having some of\nthe autonomous decision-making capabilities of a field-geologist. The Cyborg\nAstrobiologist platform has thus far been used for testing and development of\nthese algorithms and systems: robotic acquisition of quasi-mosaics of images,\nreal-time image segmentation, and real-time determination of interesting points\nin the image mosaics. The hardware and software systems function reliably, and\nthe computer-vision algorithms are adequate for the first field tests. In\naddition to the proof-of-concept aspect of these field tests, the main result\nof these field tests is the enumeration of those issues that we can improve in\nthe future, including: dealing with structural shadow and microtexture, and\nalso, controlling the camera's zoom lens in an intelligent manner. Nonetheless,\ndespite these and other technical inadequacies, this Cyborg Astrobiologist\nsystem, consisting of a camera-equipped wearable-computer and its\ncomputer-vision algorithms, has demonstrated its ability of finding genuinely\ninteresting points in real-time in the geological scenery, and then gathering\nmore information about these interest points in an automated manner.",
    "published": "2004-09-15T15:38:59Z",
    "link": "http://arxiv.org/pdf/cs/0409031v1.pdf",
    "category": [
      "cs.CV",
      "astro-ph",
      "cs.RO",
      "I.4.8; I.4.6; I.4.0; I.2.9; I.2.10; J.2.; I.5.5; I.5.4; I.4.9"
    ],
    "authors": [
      "Patrick C. McGuire",
      "Javier Gomez-Elvira",
      "Jose Antonio Rodriguez-Manfredi",
      "Eduardo Sebastian-Martinez",
      "Jens Ormo",
      "Enrique Diaz-Martinez",
      "Helge Ritter",
      "Markus Oesker",
      "Robert Haschke",
      "Joerg Ontrup"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0410017v1",
    "title": "Automated Pattern Detection--An Algorithm for Constructing Optimally\n  Synchronizing Multi-Regular Language Filters",
    "summary": "In the computational-mechanics structural analysis of one-dimensional\ncellular automata the following automata-theoretic analogue of the\n\\emph{change-point problem} from time series analysis arises: \\emph{Given a\nstring $\\sigma$ and a collection $\\{\\mc{D}_i\\}$ of finite automata, identify\nthe regions of $\\sigma$ that belong to each $\\mc{D}_i$ and, in particular, the\nboundaries separating them.} We present two methods for solving this\n\\emph{multi-regular language filtering problem}. The first, although providing\nthe ideal solution, requires a stack, has a worst-case compute time that grows\nquadratically in $\\sigma$'s length and conditions its output at any point on\narbitrarily long windows of future input. The second method is to\nalgorithmically construct a transducer that approximates the first algorithm.\nIn contrast to the stack-based algorithm, however, the transducer requires only\na finite amount of memory, runs in linear time, and gives immediate output for\neach letter read; it is, moreover, the best possible finite-state approximation\nwith these three features.",
    "published": "2004-10-07T17:20:56Z",
    "link": "http://arxiv.org/pdf/cs/0410017v1.pdf",
    "category": [
      "cs.CV",
      "cond-mat.stat-mech",
      "cs.CL",
      "cs.DS",
      "cs.IR",
      "cs.LG",
      "nlin.AO",
      "nlin.CG",
      "nlin.PS",
      "physics.comp-ph",
      "q-bio.GN"
    ],
    "authors": [
      "Carl S. McTague",
      "James P. Crutchfield"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0410020v1",
    "title": "Adaptive Cluster Expansion (ACE): A Hierarchical Bayesian Network",
    "summary": "Using the maximum entropy method, we derive the \"adaptive cluster expansion\"\n(ACE), which can be trained to estimate probability density functions in high\ndimensional spaces. The main advantage of ACE over other Bayesian networks is\nits ability to capture high order statistics after short training times, which\nit achieves by making use of a hierarchical vector quantisation of the input\ndata. We derive a scheme for representing the state of an ACE network as a\n\"probability image\", which allows us to identify statistically anomalous\nregions in an otherwise statistically homogeneous image, for instance. Finally,\nwe present some probability images that we obtained after training ACE on some\nBrodatz texture images - these demonstrate the ability of ACE to detect subtle\ntextural anomalies.",
    "published": "2004-10-10T18:30:03Z",
    "link": "http://arxiv.org/pdf/cs/0410020v1.pdf",
    "category": [
      "cs.NE",
      "cs.CV",
      "I.2.6; I.5.1"
    ],
    "authors": [
      "Stephen Luttrell"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0410036v2",
    "title": "Self-Organised Factorial Encoding of a Toroidal Manifold",
    "summary": "It is shown analytically how a neural network can be used optimally to encode\ninput data that is derived from a toroidal manifold. The case of a 2-layer\nnetwork is considered, where the output is assumed to be a set of discrete\nneural firing events. The network objective function measures the average\nEuclidean error that occurs when the network attempts to reconstruct its input\nfrom its output. This optimisation problem is solved analytically for a\ntoroidal input manifold, and two types of solution are obtained: a joint\nencoder in which the network acts as a soft vector quantiser, and a factorial\nencoder in which the network acts as a pair of soft vector quantisers (one for\neach of the circular subspaces of the torus). The factorial encoder is favoured\nfor small network sizes when the number of observed firing events is large.\nSuch self-organised factorial encoding may be used to restrict the size of\nnetwork that is required to perform a given encoding task, and will decompose\nan input manifold into its constituent submanifolds.",
    "published": "2004-10-15T20:25:24Z",
    "link": "http://arxiv.org/pdf/cs/0410036v2.pdf",
    "category": [
      "cs.LG",
      "cs.CV",
      "I.2.6; I.5.1"
    ],
    "authors": [
      "Stephen Luttrell"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0410042v1",
    "title": "Neural Architectures for Robot Intelligence",
    "summary": "We argue that the direct experimental approaches to elucidate the\narchitecture of higher brains may benefit from insights gained from exploring\nthe possibilities and limits of artificial control architectures for robot\nsystems. We present some of our recent work that has been motivated by that\nview and that is centered around the study of various aspects of hand actions\nsince these are intimately linked with many higher cognitive abilities. As\nexamples, we report on the development of a modular system for the recognition\nof continuous hand postures based on neural nets, the use of vision and tactile\nsensing for guiding prehensile movements of a multifingered hand, and the\nrecognition and use of hand gestures for robot teaching.\n  Regarding the issue of learning, we propose to view real-world learning from\nthe perspective of data mining and to focus more strongly on the imitation of\nobserved actions instead of purely reinforcement-based exploration. As a\nconcrete example of such an effort we report on the status of an ongoing\nproject in our lab in which a robot equipped with an attention system with a\nneurally inspired architecture is taught actions by using hand gestures in\nconjunction with speech commands. We point out some of the lessons learnt from\nthis system, and discuss how systems of this kind can contribute to the study\nof issues at the junction between natural and artificial cognitive systems.",
    "published": "2004-10-18T10:50:28Z",
    "link": "http://arxiv.org/pdf/cs/0410042v1.pdf",
    "category": [
      "cs.RO",
      "cs.CV",
      "cs.HC",
      "cs.LG",
      "cs.NE",
      "q-bio.NC",
      "I.2.9; I.2.10; I.2.6; H.1.2; H.2.8; I.5.4"
    ],
    "authors": [
      "H. Ritter",
      "J. J. Steil",
      "C. Noelker",
      "F. Roethling",
      "P. C. McGuire"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0410071v1",
    "title": "The Cyborg Astrobiologist: First Field Experience",
    "summary": "We present results from the first geological field tests of the `Cyborg\nAstrobiologist', which is a wearable computer and video camcorder system that\nwe are using to test and train a computer-vision system towards having some of\nthe autonomous decision-making capabilities of a field-geologist and\nfield-astrobiologist. The Cyborg Astrobiologist platform has thus far been used\nfor testing and development of these algorithms and systems: robotic\nacquisition of quasi-mosaics of images, real-time image segmentation, and\nreal-time determination of interesting points in the image mosaics. The\nhardware and software systems function reliably, and the computer-vision\nalgorithms are adequate for the first field tests. In addition to the\nproof-of-concept aspect of these field tests, the main result of these field\ntests is the enumeration of those issues that we can improve in the future,\nincluding: first, detection and accounting for shadows caused by 3D jagged\nedges in the outcrop; second, reincorporation of more sophisticated\ntexture-analysis algorithms into the system; third, creation of hardware and\nsoftware capabilities to control the camera's zoom lens in an intelligent\nmanner; and fourth, development of algorithms for interpretation of complex\ngeological scenery. Nonetheless, despite these technical inadequacies, this\nCyborg Astrobiologist system, consisting of a camera-equipped wearable-computer\nand its computer-vision algorithms, has demonstrated its ability of finding\ngenuinely interesting points in real-time in the geological scenery, and then\ngathering more information about these interest points in an automated manner.",
    "published": "2004-10-27T09:14:01Z",
    "link": "http://arxiv.org/pdf/cs/0410071v1.pdf",
    "category": [
      "cs.CV",
      "astro-ph",
      "cs.AI",
      "cs.CE",
      "cs.HC",
      "cs.RO",
      "cs.SE",
      "q-bio.NC",
      "I.4.8; I.4.6; I.4.0; I.2.9; I.2.10; J.2.; I.5.5; I.5.4; I.4.9"
    ],
    "authors": [
      "Patrick C. McGuire",
      "Jens Ormo",
      "Enrique Diaz-Martinez",
      "Jose Antonio Rodriguez-Manfredi",
      "Javier Gomez-Elvira",
      "Helge Ritter",
      "Markus Oesker",
      "Joerg Ontrup"
    ]
  },
  {
    "id": "http://arxiv.org/abs/q-bio/0411030v1",
    "title": "Statistical Mechanics Characterization of Neuronal Mosaics",
    "summary": "The spatial distribution of neuronal cells is an important requirement for\nachieving proper neuronal function in several parts of the nervous system of\nmost animals. For instance, specific distribution of photoreceptors and related\nneuronal cells, particularly the ganglion cells, in mammal's retina is required\nin order to properly sample the projected scene. This work presents how two\nconcepts from the areas of statistical mechanics and complex systems, namely\nthe \\emph{lacunarity} and the \\emph{multiscale entropy} (i.e. the entropy\ncalculated over progressively diffused representations of the cell mosaic),\nhave allowed effective characterization of the spatial distribution of retinal\ncells.",
    "published": "2004-11-14T12:36:23Z",
    "link": "http://arxiv.org/pdf/q-bio/0411030v1.pdf",
    "category": [
      "q-bio.NC",
      "cond-mat.dis-nn",
      "cs.CV",
      "physics.bio-ph",
      "q-bio.QM"
    ],
    "authors": [
      "Luciano da Fontoura Costa",
      "Fernando Rocha",
      "Silene Maria Araujo de Lima"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0412069v1",
    "title": "Swarming around Shellfish Larvae",
    "summary": "The collection of wild larvae seed as a source of raw material is a major sub\nindustry of shellfish aquaculture. To predict when, where and in what\nquantities wild seed will be available, it is necessary to track the appearance\nand growth of planktonic larvae. One of the most difficult groups to identify,\nparticularly at the species level are the Bivalvia. This difficulty arises from\nthe fact that fundamentally all bivalve larvae have a similar shape and colour.\nIdentification based on gross morphological appearance is limited by the\ntime-consuming nature of the microscopic examination and by the limited\navailability of expertise in this field. Molecular and immunological methods\nare also being studied. We describe the application of computational pattern\nrecognition methods to the automated identification and size analysis of\nscallop larvae. For identification, the shape features used are binary\ninvariant moments; that is, the features are invariant to shift (position\nwithin the image), scale (induced either by growth or differential image\nmagnification) and rotation. Images of a sample of scallop and non-scallop\nlarvae covering a range of maturities have been analysed. In order to overcome\nthe automatic identification, as well as to allow the system to receive new\nunknown samples at any moment, a self-organized and unsupervised ant-like\nclustering algorithm based on Swarm Intelligence is proposed, followed by\nsimple k-NNR nearest neighbour classification on the final map. Results achieve\na full recognition rate of 100% under several situations (k =1 or 3).",
    "published": "2004-12-17T13:30:30Z",
    "link": "http://arxiv.org/pdf/cs/0412069v1.pdf",
    "category": [
      "cs.AI",
      "cs.CV",
      "I.5; I.5.3; I.4; I.2.11"
    ],
    "authors": [
      "Vitorino Ramos",
      "Jonathan Campbell",
      "John Slater",
      "John Gillespie",
      "Ivan F. Bendezu",
      "Fionn Murtagh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0412076v1",
    "title": "Clustering Techniques for Marbles Classification",
    "summary": "Automatic marbles classification based on their visual appearance is an\nimportant industrial issue. However, there is no definitive solution to the\nproblem mainly due to the presence of randomly distributed high number of\ndifferent colours and its subjective evaluation by the human expert. In this\npaper we present a study of segmentation techniques, we evaluate they overall\nperformance using a training set and standard quality measures and finally we\napply different clustering techniques to automatically classify the marbles.\nKEYWORDS: Segmentation, Clustering, Quadtrees, Learning Vector Quantization\n(LVQ), Simulated Annealing (SA).",
    "published": "2004-12-17T15:55:46Z",
    "link": "http://arxiv.org/pdf/cs/0412076v1.pdf",
    "category": [
      "cs.AI",
      "cs.CV",
      "I.2; I.5"
    ],
    "authors": [
      "J. R. Caldas-Pinto",
      "Pedro Pina",
      "Vitorino Ramos",
      "Mario Ramalho"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0412083v1",
    "title": "Line and Word Matching in Old Documents",
    "summary": "This paper is concerned with the problem of establishing an index based on\nword matching. It is assumed that the book was digitised as better as possible\nand some pre-processing techniques were already applied as line orientation\ncorrection and some noise removal. However two main factor are responsible for\nbeing not possible to apply ordinary optical character recognition techniques\n(OCR): the presence of antique fonts and the degraded state of many characters\ndue to unrecoverable original time degradation. In this paper we make a short\nintroduction to word segmentation that involves finding the lines that\ncharacterise a word. After we discuss different approaches for word matching\nand how they can be combined to obtain an ordered list for candidate words for\nthe matching. This discussion will be illustrated by examples.",
    "published": "2004-12-17T16:58:52Z",
    "link": "http://arxiv.org/pdf/cs/0412083v1.pdf",
    "category": [
      "cs.AI",
      "cs.CV",
      "I.2; I.5"
    ],
    "authors": [
      "A. Marcolino",
      "Vitorino Ramos",
      "Mario Ramalho",
      "J. R. Caldas Pinto"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0412086v1",
    "title": "Artificial Ant Colonies in Digital Image Habitats - A Mass Behaviour\n  Effect Study on Pattern Recognition",
    "summary": "Some recent studies have pointed that, the self-organization of neurons into\nbrain-like structures, and the self-organization of ants into a swarm are\nsimilar in many respects. If possible to implement, these features could lead\nto important developments in pattern recognition systems, where perceptive\ncapabilities can emerge and evolve from the interaction of many simple local\nrules. The principle of the method is inspired by the work of Chialvo and\nMillonas who developed the first numerical simulation in which swarm cognitive\nmap formation could be explained. From this point, an extended model is\npresented in order to deal with digital image habitats, in which artificial\nants could be able to react to the environment and perceive it. Evolution of\npheromone fields point that artificial ant colonies could react and adapt\nappropriately to any type of digital habitat. KEYWORDS: Swarm Intelligence,\nSelf-Organization, Stigmergy, Artificial Ant Systems, Pattern Recognition and\nPerception, Image Segmentation, Gestalt Perception Theory, Distributed\nComputation.",
    "published": "2004-12-17T17:19:03Z",
    "link": "http://arxiv.org/pdf/cs/0412086v1.pdf",
    "category": [
      "cs.AI",
      "cs.CV",
      "I.2; I.5; I.5.3; I.4; I.2.11"
    ],
    "authors": [
      "Vitorino Ramos",
      "Filipe Almeida"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0412087v1",
    "title": "Image Colour Segmentation by Genetic Algorithms",
    "summary": "Segmentation of a colour image composed of different kinds of texture regions\ncan be a hard problem, namely to compute for an exact texture fields and a\ndecision of the optimum number of segmentation areas in an image when it\ncontains similar and/or unstationary texture fields. In this work, a method is\ndescribed for evolving adaptive procedures for these problems. In many real\nworld applications data clustering constitutes a fundamental issue whenever\nbehavioural or feature domains can be mapped into topological domains. We\nformulate the segmentation problem upon such images as an optimisation problem\nand adopt evolutionary strategy of Genetic Algorithms for the clustering of\nsmall regions in colour feature space. The present approach uses k-Means\nunsupervised clustering methods into Genetic Algorithms, namely for guiding\nthis last Evolutionary Algorithm in his search for finding the optimal or\nsub-optimal data partition, task that as we know, requires a non-trivial search\nbecause of its intrinsic NP-complete nature. To solve this task, the\nappropriate genetic coding is also discussed, since this is a key aspect in the\nimplementation. Our purpose is to demonstrate the efficiency of Genetic\nAlgorithms to automatic and unsupervised texture segmentation. Some examples in\nColour Maps, Ornamental Stones and in Human Skin Mark segmentation are\npresented and overall results discussed. KEYWORDS: Genetic Algorithms, Colour\nImage Segmentation, Classification, Clustering.",
    "published": "2004-12-17T17:29:27Z",
    "link": "http://arxiv.org/pdf/cs/0412087v1.pdf",
    "category": [
      "cs.AI",
      "cs.CV",
      "I.2; I.5"
    ],
    "authors": [
      "Vitorino Ramos",
      "Fernando Muge"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0412088v1",
    "title": "On Image Filtering, Noise and Morphological Size Intensity Diagrams",
    "summary": "In the absence of a pure noise-free image it is hard to define what noise is,\nin any original noisy image, and as a consequence also where it is, and in what\namount. In fact, the definition of noise depends largely on our own aim in the\nwhole image analysis process, and (perhaps more important) in our\nself-perception of noise. For instance, when we perceive noise as disconnected\nand small it is normal to use MM-ASF filters to treat it. There is two\nevidences of this. First, in many instances there is no ideal and pure\nnoise-free image to compare our filtering process (nothing but our\nself-perception of its pure image); second, and related with this first point,\nMM transformations that we chose are only based on our self - and perhaps -\nfuzzy notion. The present proposal combines the results of two MM filtering\ntransformations (FT1, FT2) and makes use of some measures and quantitative\nrelations on their Size/Intensity Diagrams to find the most appropriate noise\nremoval process. Results can also be used for finding the most appropriate stop\ncriteria, and the right sequence of MM operators combination on Alternating\nSequential Filters (ASF), if these measures are applied, for instance, on a\nGenetic Algorithm's target function.",
    "published": "2004-12-17T18:58:31Z",
    "link": "http://arxiv.org/pdf/cs/0412088v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "I.5; I.2"
    ],
    "authors": [
      "Vitorino Ramos",
      "Fernando Muge"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0412066v1",
    "title": "From Feature Extraction to Classification: A multidisciplinary Approach\n  applied to Portuguese Granites",
    "summary": "The purpose of this paper is to present a complete methodology based on a\nmultidisciplinary approach, that goes from the extraction of features till the\nclassification of a set of different portuguese granites. The set of tools to\nextract the features that characterise polished surfaces of the granites is\nmainly based on mathematical morphology. The classification methodology is\nbased on a genetic algorithm capable of search the input feature space used by\nthe nearest neighbour rule classifier. Results show that is adequate to perform\nfeature reduction and simultaneous improve the recognition rate. Moreover, the\npresent methodology represents a robust strategy to understand the proper\nnature of the images treated, and their discriminant features. KEYWORDS:\nPortuguese grey granites, feature extraction, mathematical morphology, feature\nreduction, genetic algorithms, nearest neighbour rule classifiers (k-NNR).",
    "published": "2004-12-17T19:04:35Z",
    "link": "http://arxiv.org/pdf/cs/0412066v1.pdf",
    "category": [
      "cs.AI",
      "cs.CV",
      "I.2; I.5"
    ],
    "authors": [
      "Vitorino Ramos",
      "Pedro Pina",
      "Fernando Muge"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0412070v1",
    "title": "Less is More - Genetic Optimisation of Nearest Neighbour Classifiers",
    "summary": "The present paper deals with optimisation of Nearest Neighbour rule\nClassifiers via Genetic Algorithms. The methodology consists on implement a\nGenetic Algorithm capable of search the input feature space used by the NNR\nclassifier. Results show that is adequate to perform feature reduction and\nsimultaneous improve the Recognition Rate. Some practical examples prove that\nis possible to Recognise Portuguese Granites in 100%, with only 3 morphological\nfeatures (from an original set of 117 features), which is well suited for real\ntime applications. Moreover, the present method represents a robust strategy to\nunderstand the proper nature of the images treated, and their discriminant\nfeatures. KEYWORDS: Feature Reduction, Genetic Algorithms, Nearest Neighbour\nRule Classifiers (k-NNR).",
    "published": "2004-12-17T19:09:43Z",
    "link": "http://arxiv.org/pdf/cs/0412070v1.pdf",
    "category": [
      "cs.AI",
      "cs.CV",
      "I.2; I.5"
    ],
    "authors": [
      "Vitorino Ramos",
      "Fernando Muge"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0412110v1",
    "title": "Q-valued neural network as a system of fast identification and pattern\n  recognition",
    "summary": "An effective neural network algorithm of the perceptron type is proposed. The\nalgorithm allows us to identify strongly distorted input vector reliably. It is\nshown that its reliability and processing speed are orders of magnitude higher\nthan that of full connected neural networks. The processing speed of our\nalgorithm exceeds the one of the stack fast-access retrieval algorithm that is\nmodified for working when there are noises in the input channel.",
    "published": "2004-12-24T13:48:44Z",
    "link": "http://arxiv.org/pdf/cs/0412110v1.pdf",
    "category": [
      "cs.NE",
      "cs.CV"
    ],
    "authors": [
      "D. I. Alieva",
      "B. V. Kryzhanovsky",
      "V. M. Kryzhanovsky",
      "A. B. Fonarev"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0502017v1",
    "title": "Estimating mutual information and multi--information in large networks",
    "summary": "We address the practical problems of estimating the information relations\nthat characterize large networks. Building on methods developed for analysis of\nthe neural code, we show that reliable estimates of mutual information can be\nobtained with manageable computational effort. The same methods allow\nestimation of higher order, multi--information terms. These ideas are\nillustrated by analyses of gene expression, financial markets, and consumer\npreferences. In each case, information theoretic measures correlate with\nindependent, intuitive measures of the underlying structures in the system.",
    "published": "2005-02-03T21:11:54Z",
    "link": "http://arxiv.org/pdf/cs/0502017v1.pdf",
    "category": [
      "cs.IT",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "math.IT"
    ],
    "authors": [
      "Noam Slonim",
      "Gurinder S. Atwal",
      "Gasper Tkacik",
      "William Bialek"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0502095v2",
    "title": "Gradient Vector Flow Models for Boundary Extraction in 2D Images",
    "summary": "The Gradient Vector Flow (GVF) is a vector diffusion approach based on\nPartial Differential Equations (PDEs). This method has been applied together\nwith snake models for boundary extraction medical images segmentation. The key\nidea is to use a diffusion-reaction PDE to generate a new external force field\nthat makes snake models less sensitivity to initialization as well as improves\nthe snake's ability to move into boundary concavities. In this paper, we\nfirstly review basic results about convergence and numerical analysis of usual\nGVF schemes. We point out that GVF presents numerical problems due to\ndiscontinuities image intensity. This point is considered from a practical\nviewpoint from which the GVF parameters must follow a relationship in order to\nimprove numerical convergence. Besides, we present an analytical analysis of\nthe GVF dependency from the parameters values. Also, we observe that the method\ncan be used for multiply connected domains by just imposing the suitable\nboundary condition. In the experimental results we verify these theoretical\npoints and demonstrate the utility of GVF on a segmentation approach that we\nhave developed based on snakes.",
    "published": "2005-02-28T15:09:08Z",
    "link": "http://arxiv.org/pdf/cs/0502095v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Gilson A. Giraldi",
      "Leandro S. Marturelli",
      "Paulo S. Rodrigues"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0503001v1",
    "title": "Top-Down Unsupervised Image Segmentation (it sounds like oxymoron, but\n  actually it is not)",
    "summary": "Pattern recognition is generally assumed as an interaction of two inversely\ndirected image-processing streams: the bottom-up information details gathering\nand localization (segmentation) stream, and the top-down information features\naggregation, association and interpretation (recognition) stream. Inspired by\nrecent evidence from biological vision research and by the insights of\nKolmogorov Complexity theory, we propose a new, just top-down evolving,\nprocedure of initial image segmentation. We claim that traditional top-down\ncognitive reasoning, which is supposed to guide the segmentation process to its\nfinal result, is not at all a part of the image information content evaluation.\nAnd that initial image segmentation is certainly an unsupervised process. We\npresent some illustrative examples, which support our claims.",
    "published": "2005-03-01T05:17:33Z",
    "link": "http://arxiv.org/pdf/cs/0503001v1.pdf",
    "category": [
      "cs.CV",
      "cs.IR"
    ],
    "authors": [
      "Emanuel Diamant"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0503053v1",
    "title": "A hybrid MLP-PNN architecture for fast image superresolution",
    "summary": "Image superresolution methods process an input image sequence of a scene to\nobtain a still image with increased resolution. Classical approaches to this\nproblem involve complex iterative minimization procedures, typically with high\ncomputational costs. In this paper is proposed a novel algorithm for\nsuper-resolution that enables a substantial decrease in computer load. First, a\nprobabilistic neural network architecture is used to perform a scattered-point\ninterpolation of the image sequence data. The network kernel function is\noptimally determined for this problem by a multi-layer perceptron trained on\nsynthetic data. Network parameters dependence on sequence noise level is\nquantitatively analyzed. This super-sampled image is spatially filtered to\ncorrect finite pixel size effects, to yield the final high-resolution estimate.\nResults on a real outdoor sequence are presented, showing the quality of the\nproposed method.",
    "published": "2005-03-22T11:45:59Z",
    "link": "http://arxiv.org/pdf/cs/0503053v1.pdf",
    "category": [
      "cs.CV",
      "cs.MM",
      "I.4.5; I.2.6; I.5.1"
    ],
    "authors": [
      "Carlos Miravet",
      "Francisco B. Rodriguez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0503056v1",
    "title": "Semi-automatic vectorization of linear networks on rasterized\n  cartographic maps",
    "summary": "A system for semi-automatic vectorization of linear networks (roads, rivers,\netc.) on rasterized cartographic maps is presented. In this system, human\nintervention is limited to a graphic, interactive selection of the color\nattributes of the information to be obtained. Using this data, the system\nperforms a preliminary extraction of the linear network, which is subsequently\ncompleted, refined and vectorized by means of an automatic procedure. Results\non maps of different sources and scales are included.\n  -----\n  Se presenta un sistema semi-automatico de vectorizacion de redes de objetos\nlineales (carreteras, rios, etc.) en mapas cartograficos digitalizados. En este\nsistema, la intervencion humana queda reducida a la seleccion grafica\ninteractiva de los atributos de color de la informacion a obtener. Con estos\ndatos, el sistema realiza una extraccion preliminar de la red lineal, que se\ncompleta, refina y vectoriza mediante un procedimiento automatico. Se presentan\nresultados de la aplicacion del sistema sobre imagenes digitalizadas de mapas\nde distinta procedencia y escala.",
    "published": "2005-03-22T20:16:52Z",
    "link": "http://arxiv.org/pdf/cs/0503056v1.pdf",
    "category": [
      "cs.CV",
      "cs.MM",
      "I.4.6"
    ],
    "authors": [
      "Carlos Miravet",
      "Enrique Coiras",
      "Javier Santamaria"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0503076v1",
    "title": "Geometric Models of Rolling-Shutter Cameras",
    "summary": "Cameras with rolling shutters are becoming more common as low-power, low-cost\nCMOS sensors are being used more frequently in cameras. The rolling shutter\nmeans that not all scanlines are exposed over the same time interval. The\neffects of a rolling shutter are noticeable when either the camera or objects\nin the scene are moving and can lead to systematic biases in projection\nestimation. We develop a general projection equation for a rolling shutter\ncamera and show how it is affected by different types of camera motion. In the\ncase of fronto-parallel motion, we show how that camera can be modeled as an\nX-slit camera. We also develop approximate projection equations for a non-zero\nangular velocity about the optical axis and approximate the projection equation\nfor a constant velocity screw motion. We demonstrate how the rolling shutter\neffects the projective geometry of the camera and in turn the\nstructure-from-motion.",
    "published": "2005-03-29T00:00:17Z",
    "link": "http://arxiv.org/pdf/cs/0503076v1.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Marci Meingast",
      "Christopher Geyer",
      "Shankar Sastry"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0504031v1",
    "title": "Convexity Analysis of Snake Models Based on Hamiltonian Formulation",
    "summary": "This paper presents a convexity analysis for the dynamic snake model based on\nthe Potential Energy functional and the Hamiltonian formulation of the\nclassical mechanics. First we see the snake model as a dynamical system whose\nsingular points are the borders we seek. Next we show that a necessary\ncondition for a singular point to be an attractor is that the energy functional\nis strictly convex in a neighborhood of it, that means, if the singular point\nis a local minimum of the potential energy. As a consequence of this analysis,\na local expression relating the dynamic parameters and the rate of convergence\narises. Such results link the convexity analysis of the potential energy and\nthe dynamic snake model and point forward to the necessity of a physical\nquantity whose convexity analysis is related to the dynamic and which\nincorporate the velocity space. Such a quantity is exactly the (conservative)\nHamiltonian of the system.",
    "published": "2005-04-08T16:41:52Z",
    "link": "http://arxiv.org/pdf/cs/0504031v1.pdf",
    "category": [
      "cs.CV",
      "cs.GR",
      "I.4; I.4.6;I.4.8"
    ],
    "authors": [
      "Gilson Antonio Giraldi",
      "Antonio Alberto Fernandes de Oliveira"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0504037v2",
    "title": "Bayesian Restoration of Digital Images Employing Markov Chain Monte\n  Carlo a Review",
    "summary": "A review of Bayesian restoration of digital images based on Monte Carlo\ntechniques is presented. The topics covered include Likelihood, Prior and\nPosterior distributions, Poisson, Binay symmetric channel, and Gaussian channel\nmodels of Likelihood distribution,Ising and Potts spin models of Prior\ndistribution, restoration of an image through Posterior maximization,\nstatistical estimation of a true image from Posterior ensembles, Markov Chain\nMonte Carlo methods and cluster algorithms.",
    "published": "2005-04-11T12:41:19Z",
    "link": "http://arxiv.org/pdf/cs/0504037v2.pdf",
    "category": [
      "cs.CV",
      "cond-mat.stat-mech",
      "physics.comp-ph"
    ],
    "authors": [
      "K. P. N. Murthy",
      "M. Janani",
      "B. Shenbga Priya"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0505006v1",
    "title": "Searching for image information content, its discovery, extraction, and\n  representation",
    "summary": "Image information content is known to be a complicated and controvercial\nproblem. This paper posits a new image information content definition.\nFollowing the theory of Solomonoff-Kolmogorov-Chaitin's complexity, we define\nimage information content as a set of descriptions of imafe data structures.\nThree levels of such description can be generally distinguished: 1)the global\nlevel, where the coarse structure of the entire scene is initially outlined; 2)\nthe intermediate level, where structures of separate, non-overlapping image\nregions usually associated with individual scene objects are deliniated; and 3)\nthe low-level description, where local image structures observed in a limited\nand restricted field of view are resolved. A technique for creating such image\ninformation content descriptors is developed. Its algorithm is presented and\nelucidated with some examples, which demonstrate the effectiveness of the\nproposed approach.",
    "published": "2005-05-02T03:17:02Z",
    "link": "http://arxiv.org/pdf/cs/0505006v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Emanuel Diamant"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0505058v1",
    "title": "The Cyborg Astrobiologist: Scouting Red Beds for Uncommon Features with\n  Geological Significance",
    "summary": "The `Cyborg Astrobiologist' (CA) has undergone a second geological field\ntrial, at a red sandstone site in northern Guadalajara, Spain, near Riba de\nSantiuste. The Cyborg Astrobiologist is a wearable computer and video camera\nsystem that has demonstrated a capability to find uncommon interest points in\ngeological imagery in real-time in the field. The first (of three) geological\nstructures that we studied was an outcrop of nearly homogeneous sandstone,\nwhich exhibits oxidized-iron impurities in red and and an absence of these iron\nimpurities in white. The white areas in these ``red beds'' have turned white\nbecause the iron has been removed by chemical reduction, perhaps by a\nbiological agent. The computer vision system found in one instance several\n(iron-free) white spots to be uncommon and therefore interesting, as well as\nseveral small and dark nodules. The second geological structure contained\nwhite, textured mineral deposits on the surface of the sandstone, which were\nfound by the CA to be interesting. The third geological structure was a 50 cm\nthick paleosol layer, with fossilized root structures of some plants, which\nwere found by the CA to be interesting. A quasi-blind comparison of the Cyborg\nAstrobiologist's interest points for these images with the interest points\ndetermined afterwards by a human geologist shows that the Cyborg Astrobiologist\nconcurred with the human geologist 68% of the time (true positive rate), with a\n32% false positive rate and a 32% false negative rate.\n  (abstract has been abridged).",
    "published": "2005-05-23T09:55:37Z",
    "link": "http://arxiv.org/pdf/cs/0505058v1.pdf",
    "category": [
      "cs.CV",
      "astro-ph",
      "cs.AI",
      "cs.CE",
      "cs.HC",
      "cs.RO",
      "cs.SE",
      "physics.ins-det",
      "q-bio.NC",
      "I.2.10; I.4.6; I.4.8; I.4.9; I.2.9; I.5.4; I.5.5; J.2; J.3; D.2;\n  D.1.7; D.4.7"
    ],
    "authors": [
      "Patrick C. McGuire",
      "Enrique Diaz-Martinez",
      "Jens Ormo",
      "Javier Gomez-Elvira",
      "Jose A. Rodriguez-Manfredi",
      "Eduardo Sebastian-Martinez",
      "Helge Ritter",
      "Robert Haschke",
      "Markus Oesker",
      "Joerg Ontrup"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0505064v1",
    "title": "Multi-Modal Human-Machine Communication for Instructing Robot Grasping\n  Tasks",
    "summary": "A major challenge for the realization of intelligent robots is to supply them\nwith cognitive abilities in order to allow ordinary users to program them\neasily and intuitively. One way of such programming is teaching work tasks by\ninteractive demonstration. To make this effective and convenient for the user,\nthe machine must be capable to establish a common focus of attention and be\nable to use and integrate spoken instructions, visual perceptions, and\nnon-verbal clues like gestural commands. We report progress in building a\nhybrid architecture that combines statistical methods, neural networks, and\nfinite state machines into an integrated system for instructing grasping tasks\nby man-machine interaction. The system combines the GRAVIS-robot for visual\nattention and gestural instruction with an intelligent interface for speech\nrecognition and linguistic interpretation, and an modality fusion module to\nallow multi-modal task-oriented man-machine communication with respect to\ndextrous robot manipulation of objects.",
    "published": "2005-05-24T14:53:49Z",
    "link": "http://arxiv.org/pdf/cs/0505064v1.pdf",
    "category": [
      "cs.HC",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.RO",
      "H.1.2; I.2.9; I.2.10; I.2.7; H.5.2; H.5.1; I.2.6; I.4.8; I.4.7;\n  I.4.6"
    ],
    "authors": [
      "P. C. McGuire",
      "J. Fritsch",
      "J. J. Steil",
      "F. Roethling",
      "G. A. Fink",
      "S. Wachsmuth",
      "G. Sagerer",
      "H. Ritter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0505084v2",
    "title": "An explicit formula for the number of tunnels in digital objects",
    "summary": "An important concept in digital geometry for computer imagery is that of\ntunnel. In this paper we obtain a formula for the number of tunnels as a\nfunction of the number of the object vertices, pixels, holes, connected\ncomponents, and 2x2 grid squares. It can be used to test for tunnel-freedom a\ndigital object, in particular a digital curve.",
    "published": "2005-05-31T00:44:16Z",
    "link": "http://arxiv.org/pdf/cs/0505084v2.pdf",
    "category": [
      "cs.DM",
      "cs.CG",
      "cs.CV",
      "G.2.1; F.2.2; I.4.6; I.5.1"
    ],
    "authors": [
      "Valentin Brimkov",
      "Angelo Maimone",
      "Giorgio Nordo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0506019v4",
    "title": "An Efficient Approximation Algorithm for Point Pattern Matching Under\n  Noise",
    "summary": "Point pattern matching problems are of fundamental importance in various\nareas including computer vision and structural bioinformatics. In this paper,\nwe study one of the more general problems, known as LCP (largest common point\nset problem): Let $\\PP$ and $\\QQ$ be two point sets in $\\mathbb{R}^3$, and let\n$\\epsilon \\geq 0$ be a tolerance parameter, the problem is to find a rigid\nmotion $\\mu$ that maximizes the cardinality of subset $\\II$ of $Q$, such that\nthe Hausdorff distance $\\distance(\\PP,\\mu(\\II)) \\leq \\epsilon$. We denote the\nsize of the optimal solution to the above problem by $\\LCP(P,Q)$. The problem\nis called exact-LCP for $\\epsilon=0$, and \\tolerant-LCP when $\\epsilon>0$ and\nthe minimum interpoint distance is greater than $2\\epsilon$. A\n$\\beta$-distance-approximation algorithm for tolerant-LCP finds a subset $I\n\\subseteq \\QQ$ such that $|I|\\geq \\LCP(P,Q)$ and $\\distance(\\PP,\\mu(\\II)) \\leq\n\\beta \\epsilon$ for some $\\beta \\ge 1$.\n  This paper has three main contributions. (1) We introduce a new algorithm,\ncalled {\\DA}, which gives the fastest known deterministic\n4-distance-approximation algorithm for \\tolerant-LCP. (2) For the exact-LCP,\nwhen the matched set is required to be large, we give a simple sampling\nstrategy that improves the running times of all known deterministic algorithms,\nyielding the fastest known deterministic algorithm for this problem. (3) We use\nexpander graphs to speed-up the \\DA algorithm for \\tolerant-LCP when the size\nof the matched set is required to be large, at the expense of approximation in\nthe matched set size. Our algorithms also work when the transformation $\\mu$ is\nallowed to be scaling transformation.",
    "published": "2005-06-07T17:41:53Z",
    "link": "http://arxiv.org/pdf/cs/0506019v4.pdf",
    "category": [
      "cs.CV",
      "cs.CG"
    ],
    "authors": [
      "Vicky Choi",
      "Navin Goyal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0506089v1",
    "title": "Field geology with a wearable computer: 1st results of the Cyborg\n  Astrobiologist System",
    "summary": "We present results from the first geological field tests of the `Cyborg\nAstrobiologist', which is a wearable computer and video camcorder system that\nwe are using to test and train a computer-vision system towards having some of\nthe autonomous decision-making capabilities of a field-geologist. The Cyborg\nAstrobiologist platform has thus far been used for testing and development of\nthese algorithms and systems: robotic acquisition of quasi-mosaics of images,\nreal-time image segmentation, and real-time determination of interesting points\nin the image mosaics. This work is more of a test of the whole system, rather\nthan of any one part of the system. However, beyond the concept of the system\nitself, the uncommon map (despite its simplicity) is the main innovative part\nof the system. The uncommon map helps to determine interest-points in a\ncontext-free manner. Overall, the hardware and software systems function\nreliably, and the computer-vision algorithms are adequate for the first field\ntests. In addition to the proof-of-concept aspect of these field tests, the\nmain result of these field tests is the enumeration of those issues that we can\nimprove in the future, including: dealing with structural shadow and\nmicrotexture, and also, controlling the camera's zoom lens in an intelligent\nmanner. Nonetheless, despite these and other technical inadequacies, this\nCyborg Astrobiologist system, consisting of a camera-equipped wearable-computer\nand its computer-vision algorithms, has demonstrated its ability of finding\ngenuinely interesting points in real-time in the geological scenery, and then\ngathering more information about these interest points in an automated manner.\nWe use these capabilities for autonomous guidance towards geological\npoints-of-interest.",
    "published": "2005-06-24T10:25:22Z",
    "link": "http://arxiv.org/pdf/cs/0506089v1.pdf",
    "category": [
      "cs.CV",
      "astro-ph",
      "cs.AI",
      "cs.CE",
      "cs.HC",
      "cs.RO"
    ],
    "authors": [
      "Patrick C. McGuire",
      "Javier Gomez-Elvira",
      "Jose Antonio Rodriguez-Manfredi",
      "Eduardo Sebastian-Martinez",
      "Jens Ormo",
      "Enrique Diaz-Martinez",
      "Markus Oesker",
      "Robert Haschke",
      "Joerg Ontrup",
      "Helge Ritter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0507039v1",
    "title": "Distributed Regression in Sensor Networks: Training Distributively with\n  Alternating Projections",
    "summary": "Wireless sensor networks (WSNs) have attracted considerable attention in\nrecent years and motivate a host of new challenges for distributed signal\nprocessing. The problem of distributed or decentralized estimation has often\nbeen considered in the context of parametric models. However, the success of\nparametric methods is limited by the appropriateness of the strong statistical\nassumptions made by the models. In this paper, a more flexible nonparametric\nmodel for distributed regression is considered that is applicable in a variety\nof WSN applications including field estimation. Here, starting with the\nstandard regularized kernel least-squares estimator, a message-passing\nalgorithm for distributed estimation in WSNs is derived. The algorithm can be\nviewed as an instantiation of the successive orthogonal projection (SOP)\nalgorithm. Various practical aspects of the algorithm are discussed and several\nnumerical simulations validate the potential of the approach.",
    "published": "2005-07-18T00:45:12Z",
    "link": "http://arxiv.org/pdf/cs/0507039v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.DC",
      "cs.IT",
      "math.IT"
    ],
    "authors": [
      "Joel B. Predd",
      "Sanjeev R. Kulkarni",
      "H. Vincent Poor"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0507040v1",
    "title": "Pattern Recognition for Conditionally Independent Data",
    "summary": "In this work we consider the task of relaxing the i.i.d assumption in pattern\nrecognition (or classification), aiming to make existing learning algorithms\napplicable to a wider range of tasks. Pattern recognition is guessing a\ndiscrete label of some object based on a set of given examples (pairs of\nobjects and labels). We consider the case of deterministically defined labels.\nTraditionally, this task is studied under the assumption that examples are\nindependent and identically distributed. However, it turns out that many\nresults of pattern recognition theory carry over a weaker assumption. Namely,\nunder the assumption of conditional independence and identical distribution of\nobjects, while the only assumption on the distribution of labels is that the\nrate of occurrence of each label should be above some positive threshold.\n  We find a broad class of learning algorithms for which estimations of the\nprobability of a classification error achieved under the classical i.i.d.\nassumption can be generalised to the similar estimates for the case of\nconditionally i.i.d. examples.",
    "published": "2005-07-18T08:10:10Z",
    "link": "http://arxiv.org/pdf/cs/0507040v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Daniil Ryabko"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0507058v1",
    "title": "Paving the Way for Image Understanding: A New Kind of Image\n  Decomposition is Desired",
    "summary": "In this paper we present an unconventional image segmentation approach which\nis devised to meet the requirements of image understanding and pattern\nrecognition tasks. Generally image understanding assumes interplay of two\nsub-processes: image information content discovery and image information\ncontent interpretation. Despite of its widespread use, the notion of \"image\ninformation content\" is still ill defined, intuitive, and ambiguous. Most\noften, it is used in the Shannon's sense, which means information content\nassessment averaged over the whole signal ensemble. Humans, however,rarely\nresort to such estimates. They are very effective in decomposing images into\ntheir meaningful constituents and focusing attention to the perceptually\nrelevant image parts. We posit that following the latest findings in human\nattention vision studies and the concepts of Kolmogorov's complexity theory an\nunorthodox segmentation approach can be proposed that provides effective image\ndecomposition to information preserving image fragments well suited for\nsubsequent image interpretation. We provide some illustrative examples,\ndemonstrating effectiveness of this approach.",
    "published": "2005-07-22T12:18:44Z",
    "link": "http://arxiv.org/pdf/cs/0507058v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Emanuel Diamant"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0508007v4",
    "title": "Regularity of Position Sequences",
    "summary": "A person is given a numbered sequence of positions on a sheet of paper. The\nperson is asked, \"Which will be the next (or the next after that) position?\"\nEveryone has an opinion as to how he or she would proceed. There are regular\nsequences for which there is general agreement on how to continue. However,\nthere are less regular sequences for which this assessment is less certain.\nThere are sequences for which every continuation is perceived to be arbitrary.\nI would like to present a mathematical model that reflects these opinions and\nperceptions with the aid of a valuation function. It is necessary to apply a\nrich set of invariant features of position sequences to ensure the quality of\nthis model. All other properties of the model are arbitrary.",
    "published": "2005-08-01T18:55:57Z",
    "link": "http://arxiv.org/pdf/cs/0508007v4.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "q-bio.NC",
      "I.5.1; I.6.8; J.4"
    ],
    "authors": [
      "Manfred Harringer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/math/0508171v2",
    "title": "Matrices of Forests and the Analysis of Digraphs",
    "summary": "The matrices of spanning rooted forests are studied as a tool for analysing\nthe structure of digraphs and measuring their characteristics. The problems of\nrevealing the basis bicomponents, measuring vertex proximity, and ranking from\npreference relations / sports competitions are considered. It is shown that the\nvertex accessibility measure based on spanning forests has a number of\ndesirable properties. An interpretation for the normalized matrix of\nout-forests in terms of information dissemination is given.\n  Keywords: Laplacian matrix, spanning forest, matrix-forest theorem, proximity\nmeasure, bicomponent, ranking, incomplete tournament, paired comparisons",
    "published": "2005-08-09T20:11:27Z",
    "link": "http://arxiv.org/pdf/math/0508171v2.pdf",
    "category": [
      "math.CO",
      "cs.CV",
      "cs.NI",
      "05C50; 05C05; 15A51"
    ],
    "authors": [
      "Pavel Chebotarev",
      "Rafig Agaev"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0508099v1",
    "title": "Search Process and Probabilistic Bifix Approach",
    "summary": "An analytical approach to a search process is a mathematical prerequisite for\ndigital synchronization acquisition analysis and optimization. A search is\nperformed for an arbitrary set of sequences within random but not equiprobable\nL-ary data. This paper derives in detail an expression for probability\ndistribution function, from which other statistical parameters - expected value\nand variance - can be obtained. The probabilistic nature of (cross-) bifix\nindicators is shown and application examples are outlined, ranging beyond the\nusual telecommunication field.",
    "published": "2005-08-23T08:51:45Z",
    "link": "http://arxiv.org/pdf/cs/0508099v1.pdf",
    "category": [
      "cs.IT",
      "cs.CV",
      "math.IT"
    ],
    "authors": [
      "Dragana Bajic",
      "Cedomir Stefanovic",
      "Dejan Vukobratovic"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0509022v1",
    "title": "Achievable Rates for Pattern Recognition",
    "summary": "Biological and machine pattern recognition systems face a common challenge:\nGiven sensory data about an unknown object, classify the object by comparing\nthe sensory data with a library of internal representations stored in memory.\nIn many cases of interest, the number of patterns to be discriminated and the\nrichness of the raw data force recognition systems to internally represent\nmemory and sensory information in a compressed format. However, these\nrepresentations must preserve enough information to accommodate the variability\nand complexity of the environment, or else recognition will be unreliable.\nThus, there is an intrinsic tradeoff between the amount of resources devoted to\ndata representation and the complexity of the environment in which a\nrecognition system may reliably operate.\n  In this paper we describe a general mathematical model for pattern\nrecognition systems subject to resource constraints, and show how the\naforementioned resource-complexity tradeoff can be characterized in terms of\nthree rates related to number of bits available for representing memory and\nsensory data, and the number of patterns populating a given statistical\nenvironment. We prove single-letter information theoretic bounds governing the\nachievable rates, and illustrate the theory by analyzing the elementary cases\nwhere the pattern data is either binary or Gaussian.",
    "published": "2005-09-08T06:30:34Z",
    "link": "http://arxiv.org/pdf/cs/0509022v1.pdf",
    "category": [
      "cs.IT",
      "cs.CV",
      "math.IT"
    ],
    "authors": [
      "M. Brandon Westover",
      "Joseph A. O'Sullivan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0509081v1",
    "title": "Automatic Face Recognition System Based on Local Fourier-Bessel Features",
    "summary": "We present an automatic face verification system inspired by known properties\nof biological systems. In the proposed algorithm the whole image is converted\nfrom the spatial to polar frequency domain by a Fourier-Bessel Transform (FBT).\nUsing the whole image is compared to the case where only face image regions\n(local analysis) are considered. The resulting representations are embedded in\na dissimilarity space, where each image is represented by its distance to all\nthe other images, and a Pseudo-Fisher discriminator is built. Verification test\nresults on the FERET database showed that the local-based algorithm outperforms\nthe global-FBT version. The local-FBT algorithm performed as state-of-the-art\nmethods under different testing conditions, indicating that the proposed system\nis highly robust for expression, age, and illumination variations. We also\nevaluated the performance of the proposed system under strong occlusion\nconditions and found that it is highly robust for up to 50% of face occlusion.\nFinally, we automated completely the verification system by implementing face\nand eye detection algorithms. Under this condition, the local approach was only\nslightly superior to the global approach.",
    "published": "2005-09-27T15:25:36Z",
    "link": "http://arxiv.org/pdf/cs/0509081v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yossi Zana",
      "Roberto M. Cesar-Jr",
      "Regis de A. Barbosa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0509082v1",
    "title": "Face Recognition Based on Polar Frequency Features",
    "summary": "A novel biologically motivated face recognition algorithm based on polar\nfrequency is presented. Polar frequency descriptors are extracted from face\nimages by Fourier-Bessel transform (FBT). Next, the Euclidean distance between\nall images is computed and each image is now represented by its dissimilarity\nto the other images. A Pseudo-Fisher Linear Discriminant was built on this\ndissimilarity space. The performance of Discrete Fourier transform (DFT)\ndescriptors, and a combination of both feature types was also evaluated. The\nalgorithms were tested on a 40- and 1196-subjects face database (ORL and FERET,\nrespectively). With 5 images per subject in the training and test datasets,\nerror rate on the ORL database was 3.8, 1.25 and 0.2% for the FBT, DFT, and the\ncombined classifier, respectively, as compared to 2.6% achieved by the best\nprevious algorithm. The most informative polar frequency features were\nconcentrated at low-to-medium angular frequencies coupled to low radial\nfrequencies. On the FERET database, where an affine normalization\npre-processing was applied, the FBT algorithm outperformed only the PCA in a\nrank recognition test. However, it achieved performance comparable to\nstate-of-the-art methods when evaluated by verification tests. These results\nindicate the high informative value of the polar frequency content of face\nimages in relation to recognition and verification tasks, and that the\nCartesian frequency content can complement information about the subjects'\nidentity, but possibly only when the images are not pre-normalized. Possible\nimplications for human face recognition are discussed.",
    "published": "2005-09-27T15:50:27Z",
    "link": "http://arxiv.org/pdf/cs/0509082v1.pdf",
    "category": [
      "cs.CV",
      "I.4; I.5"
    ],
    "authors": [
      "Yossi Zana",
      "Roberto M. Cesar-JR"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0509083v1",
    "title": "Face Verification in Polar Frequency Domain: a Biologically Motivated\n  Approach",
    "summary": "We present a novel local-based face verification system whose components are\nanalogous to those of biological systems. In the proposed system, after global\nregistration and normalization, three eye regions are converted from the\nspatial to polar frequency domain by a Fourier-Bessel Transform. The resulting\nrepresentations are embedded in a dissimilarity space, where each image is\nrepresented by its distance to all the other images. In this dissimilarity\nspace a Pseudo-Fisher discriminator is built. ROC and equal error rate\nverification test results on the FERET database showed that the system\nperformed at least as state-of-the-art methods and better than a system based\non polar Fourier features. The local-based system is especially robust to\nfacial expression and age variations, but sensitive to registration errors.",
    "published": "2005-09-27T16:06:22Z",
    "link": "http://arxiv.org/pdf/cs/0509083v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yossi Zana",
      "Roberto M. Cesar-Jr",
      "Rogerio S. Feris",
      "Matthew Turk"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0510001v2",
    "title": "Retinal Vessel Segmentation Using the 2-D Morlet Wavelet and Supervised\n  Classification",
    "summary": "We present a method for automated segmentation of the vasculature in retinal\nimages. The method produces segmentations by classifying each image pixel as\nvessel or non-vessel, based on the pixel's feature vector. Feature vectors are\ncomposed of the pixel's intensity and continuous two-dimensional Morlet wavelet\ntransform responses taken at multiple scales. The Morlet wavelet is capable of\ntuning to specific frequencies, thus allowing noise filtering and vessel\nenhancement in a single step. We use a Bayesian classifier with\nclass-conditional probability density functions (likelihoods) described as\nGaussian mixtures, yielding a fast classification, while being able to model\ncomplex decision surfaces and compare its performance with the linear minimum\nsquared error classifier. The probability distributions are estimated based on\na training set of labeled pixels obtained from manual segmentations. The\nmethod's performance is evaluated on publicly available DRIVE and STARE\ndatabases of manually labeled non-mydriatic images. On the DRIVE database, it\nachieves an area under the receiver operating characteristic (ROC) curve of\n0.9598, being slightly superior than that presented by the method of Staal et\nal.",
    "published": "2005-09-30T22:27:45Z",
    "link": "http://arxiv.org/pdf/cs/0510001v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Joo V. B. Soares",
      "Jorge J. G. Leandro",
      "Roberto M. Cesar Jr.",
      "Herbert F. Jelinek",
      "Michael J. Cree"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0510008v1",
    "title": "Accurate and robust image superresolution by neural processing of local\n  image representations",
    "summary": "Image superresolution involves the processing of an image sequence to\ngenerate a still image with higher resolution. Classical approaches, such as\nbayesian MAP methods, require iterative minimization procedures, with high\ncomputational costs. Recently, the authors proposed a method to tackle this\nproblem, based on the use of a hybrid MLP-PNN architecture. In this paper, we\npresent a novel superresolution method, based on an evolution of this concept,\nto incorporate the use of local image models. A neural processing stage\nreceives as input the value of model coefficients on local windows. The data\ndimensionality is firstly reduced by application of PCA. An MLP, trained on\nsynthetic sequences with various amounts of noise, estimates the\nhigh-resolution image data. The effect of varying the dimension of the network\ninput space is examined, showing a complex, structured behavior. Quantitative\nresults are presented showing the accuracy and robustness of the proposed\nmethod.",
    "published": "2005-10-03T19:42:55Z",
    "link": "http://arxiv.org/pdf/cs/0510008v1.pdf",
    "category": [
      "cs.CV",
      "cs.NE",
      "I.4.5; I.2.6; I.5.1"
    ],
    "authors": [
      "Carlos Miravet",
      "Francisco B. Rodriguez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0510026v1",
    "title": "A decision support system for ship identification based on the curvature\n  scale space representation",
    "summary": "In this paper, a decision support system for ship identification is\npresented. The system receives as input a silhouette of the vessel to be\nidentified, previously extracted from a side view of the object. This view\ncould have been acquired with imaging sensors operating at different spectral\nranges (CCD, FLIR, image intensifier). The input silhouette is preprocessed and\ncompared to those stored in a database, retrieving a small number of potential\nmatches ranked by their similarity to the target silhouette. This set of\npotential matches is presented to the system operator, who makes the final ship\nidentification. This system makes use of an evolved version of the Curvature\nScale Space (CSS) representation. In the proposed approach, it is curvature\nextrema, instead of zero crossings, that are tracked during silhouette\nevolution, hence improving robustness and enabling to cope successfully with\ncases where the standard CCS representation is found to be unstable. Also, the\nuse of local curvature was replaced with the more robust concept of lobe\nconcavity, with significant additional gains in performance. Experimental\nresults on actual operational imagery prove the excellent performance and\nrobustness of the developed method.",
    "published": "2005-10-11T08:43:04Z",
    "link": "http://arxiv.org/pdf/cs/0510026v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Alvaro Enriquez de Luna",
      "Carlos Miravet",
      "Deitze Otaduy",
      "Carlos Dorronsoro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0510056v1",
    "title": "First-Order Modeling and Stability Analysis of Illusory Contours",
    "summary": "In visual cognition, illusions help elucidate certain intriguing latent\nperceptual functions of the human vision system, and their proper mathematical\nmodeling and computational simulation are therefore deeply beneficial to both\nbiological and computer vision. Inspired by existent prior works, the current\npaper proposes a first-order energy-based model for analyzing and simulating\nillusory contours. The lower complexity of the proposed model facilitates\nrigorous mathematical analysis on the detailed geometric structures of illusory\ncontours. After being asymptotically approximated by classical active contours,\nthe proposed model is then robustly computed using the celebrated level-set\nmethod of Osher and Sethian (J. Comput. Phys., 79:12-49, 1988) with a natural\nsupervising scheme. Potential cognitive implications of the mathematical\nresults are addressed, and generic computational examples are demonstrated and\ndiscussed.",
    "published": "2005-10-19T20:44:04Z",
    "link": "http://arxiv.org/pdf/cs/0510056v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "I.4.6; I.4.8"
    ],
    "authors": [
      "Yoon-Mo Jung",
      "Jianhong Shen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0511032v1",
    "title": "Spatiotemporal sensistivity and visual attention for efficient rendering\n  of dynamic environments",
    "summary": "We present a method to accelerate global illumination computation in dynamic\nenvironments by taking advantage of limitations of the human visual system. A\nmodel of visual attention is used to locate regions of interest in a scene and\nto modulate spatiotemporal sensitivity. The method is applied in the form of a\nspatiotemporal error tolerance map. Perceptual acceleration combined with good\nsampling protocols provide a global illumination solution feasible for use in\nanimation. Results indicate an order of magnitude improvement in computational\nspeed. The method is adaptable and can also be used in image-based rendering,\ngeometry level of detail selection, realistic image synthesis, video telephony\nand video compression.",
    "published": "2005-11-08T14:40:47Z",
    "link": "http://arxiv.org/pdf/cs/0511032v1.pdf",
    "category": [
      "cs.GR",
      "cs.CV"
    ],
    "authors": [
      "Yang Li Hector Yee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0511064v1",
    "title": "The consistency principle for a digitization procedure. An algorithm for\n  building normal digital spaces of continuous n-dimensional objects",
    "summary": "This paper considers conditions, which allow to preserve important\ntopological and geometric properties in the process of digitization. For this\npurpose, we introduce a triplet {C,M,D} consisting of a continuous object C, an\nintermediate model M, which is a collection of subregions whose union is C, a\ndigital model D, which is the intersection graph of M, and apply the\nconsistency principle and criteria of similarity to M in order to make its\nmathematical structure consistent with the natural structure of D.\nSpecifically, this paper introduces a locally centered lump collection of\nsubregions and shows that for any locally centered lump cover of an\nn-dimensional continuous manifold, the digital model of the manifold is a\ndigital normal n-dimensional space. In addition, we give examples of locally\ncentered lump tilings of two-manifolds. We propose an algorithm for\nconstructing normal digital models of continuous objects.",
    "published": "2005-11-16T20:33:16Z",
    "link": "http://arxiv.org/pdf/cs/0511064v1.pdf",
    "category": [
      "cs.CV",
      "cs.DM",
      "I.3.5; I.5.1; G.2.2"
    ],
    "authors": [
      "Alexander V. Evako"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0512084v1",
    "title": "Understanding physics from interconnected data",
    "summary": "Metal melting on release after explosion is a physical system far from\nquilibrium. A complete physical model of this system does not exist, because\nmany interrelated effects have to be considered. General methodology needs to\nbe developed so as to describe and understand physical phenomena involved.\n  The high noise of the data, moving blur of images, the high degree of\nuncertainty due to the different types of sensors, and the information\nentangled and hidden inside the noisy images makes reasoning about the physical\nprocesses very difficult. Major problems include proper information extraction\nand the problem of reconstruction, as well as prediction of the missing data.\nIn this paper, several techniques addressing the first problem are given,\nbuilding the basis for tackling the second problem.",
    "published": "2005-12-21T20:23:38Z",
    "link": "http://arxiv.org/pdf/cs/0512084v1.pdf",
    "category": [
      "cs.CV",
      "I.4.6; I.4.7; I.5.4"
    ],
    "authors": [
      "Nikita Sakhanenko",
      "Hanna Makaruk"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0601102v1",
    "title": "Geometric symmetry in the quadratic Fisher discriminant operating on\n  image pixels",
    "summary": "This article examines the design of Quadratic Fisher Discriminants (QFDs)\nthat operate directly on image pixels, when image ensembles are taken to\ncomprise all rotated and reflected versions of distinct sample images. A\nprocedure based on group theory is devised to identify and discard QFD\ncoefficients made redundant by symmetry, for arbitrary sampling lattices. This\nprocedure introduces the concept of a degeneracy matrix. Tensor representations\nare established for the square lattice point group (8-fold symmetry) and\nhexagonal lattice point group (12-fold symmetry). The analysis is largely\napplicable to the symmetrisation of any quadratic filter, and generalises to\nhigher order polynomial (Volterra) filters. Experiments on square lattice\nsampled synthetic aperture radar (SAR) imagery verify that symmetrisation of\nQFDs can improve their generalisation and discrimination ability.",
    "published": "2006-01-24T05:03:23Z",
    "link": "http://arxiv.org/pdf/cs/0601102v1.pdf",
    "category": [
      "cs.IT",
      "cs.CV",
      "math.IT"
    ],
    "authors": [
      "Robert S. Caprari"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0601105v3",
    "title": "The Perceptron Algorithm: Image and Signal Decomposition, Compression,\n  and Analysis by Iterative Gaussian Blurring",
    "summary": "A novel algorithm for tunable compression to within the precision of\nreproduction targets, or storage, is proposed. The new algorithm is termed the\n`Perceptron Algorithm', which utilises simple existing concepts in a novel way,\nhas multiple immediate commercial application aspects as well as it opens up a\nmultitude of fronts in computational science and technology. The aims of this\npaper are to present the concepts underlying the algorithm, observations by its\napplication to some example cases, and the identification of a multitude of\npotential areas of applications such as: image compression by orders of\nmagnitude, signal compression including sound as well, image analysis in a\nmultilayered detailed analysis, pattern recognition and matching and rapid\ndatabase searching (e.g. face recognition), motion analysis, biomedical\napplications e.g. in MRI and CAT scan image analysis and compression, as well\nas hints on the link of these ideas to the way how biological memory might work\nleading to new points of view in neural computation. Commercial applications of\nimmediate interest are the compression of images at the source (e.g.\nphotographic equipment, scanners, satellite imaging systems), DVD film\ncompression, pay-per-view downloads acceleration and many others identified in\nthe present paper at its conclusion and future work section.",
    "published": "2006-01-24T17:23:17Z",
    "link": "http://arxiv.org/pdf/cs/0601105v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Vassilios S. Vassiliadis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0601106v1",
    "title": "The `Face on Mars': a photographic approach for the search of signs of\n  past civilizations from a macroscopic point of view, factoring long-term\n  erosion in image reconstruction",
    "summary": "This short article presents an alternative view of high resolution imaging\nfrom various sources with the aim of the discovery of potential sites of\narchaeological importance, or sites that exhibit `anomalies' such that they may\nmerit closer inspection and analysis. It is conjectured, and to a certain\nextent demonstrated here, that it is possible for advanced civilizations to\nfactor in erosion by natural processes into a large scale design so that main\nfeatures be preserved even with the passage of millions of years. Alternatively\nviewed, even without such intent embedded in a design left for posterity, it is\npossible that a gigantic construction may naturally decay in such a way that\neven cataclysmic (massive) events may leave sufficient information intact with\nthe passage of time, provided one changes the point of view from high\nresolution images to enhanced blurred renderings of the sites in question.",
    "published": "2006-01-24T18:12:00Z",
    "link": "http://arxiv.org/pdf/cs/0601106v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Vassilios S. Vassiliadis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0601108v4",
    "title": "Fast Lexically Constrained Viterbi Algorithm (FLCVA): Simultaneous\n  Optimization of Speed and Memory",
    "summary": "Lexical constraints on the input of speech and on-line handwriting systems\nimprove the performance of such systems. A significant gain in speed can be\nachieved by integrating in a digraph structure the different Hidden Markov\nModels (HMM) corresponding to the words of the relevant lexicon. This\nintegration avoids redundant computations by sharing intermediate results\nbetween HMM's corresponding to different words of the lexicon. In this paper,\nwe introduce a token passing method to perform simultaneously the computation\nof the a posteriori probabilities of all the words of the lexicon. The coding\nscheme that we introduce for the tokens is optimal in the information theory\nsense. The tokens use the minimum possible number of bits. Overall, we optimize\nsimultaneously the execution speed and the memory requirement of the\nrecognition systems.",
    "published": "2006-01-25T17:50:13Z",
    "link": "http://arxiv.org/pdf/cs/0601108v4.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.DS",
      "G.2.2; I.5.5; E.2"
    ],
    "authors": [
      "Alain Lifchitz",
      "Frederic Maire",
      "Dominique Revuz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0602044v1",
    "title": "Multilevel Thresholding for Image Segmentation through a Fast\n  Statistical Recursive Algorithm",
    "summary": "A novel algorithm is proposed for segmenting an image into multiple levels\nusing its mean and variance. Starting from the extreme pixel values at both\nends of the histogram plot, the algorithm is applied recursively on sub-ranges\ncomputed from the previous step, so as to find a threshold level and a new\nsub-range for the next step, until no significant improvement in image quality\ncan be achieved. The method makes use of the fact that a number of\ndistributions tend towards Dirac delta function, peaking at the mean, in the\nlimiting condition of vanishing variance. The procedure naturally provides for\nvariable size segmentation with bigger blocks near the extreme pixel values and\nfiner divisions around the mean or other chosen value for better visualization.\nExperiments on a variety of images show that the new algorithm effectively\nsegments the image in computationally very less time.",
    "published": "2006-02-12T18:22:41Z",
    "link": "http://arxiv.org/pdf/cs/0602044v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Siddharth Arora",
      "Jayadev Acharya",
      "Amit Verma",
      "Prasanta K. Panigrahi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0602065v1",
    "title": "Similarity of Objects and the Meaning of Words",
    "summary": "We survey the emerging area of compression-based, parameter-free, similarity\ndistance measures useful in data-mining, pattern recognition, learning and\nautomatic semantics extraction. Given a family of distances on a set of\nobjects, a distance is universal up to a certain precision for that family if\nit minorizes every distance in the family between every two objects in the set,\nup to the stated precision (we do not require the universal distance to be an\nelement of the family). We consider similarity distances for two types of\nobjects: literal objects that as such contain all of their meaning, like\ngenomes or books, and names for objects. The latter may have literal\nembodyments like the first type, but may also be abstract like ``red'' or\n``christianity.'' For the first type we consider a family of computable\ndistance measures corresponding to parameters expressing similarity according\nto particular featuresdistances generated by web users corresponding to\nparticular semantic relations between the (names for) the designated objects.\nFor both families we give universal similarity distance measures, incorporating\nall particular distance measures in the family. In the first case the universal\ndistance is based on compression and in the second case it is based on Google\npage counts related to search terms. In both cases experiments on a massive\nscale give evidence of the viability of the approaches. between pairs of\nliteral objects. For the second type we consider similarity",
    "published": "2006-02-17T16:15:07Z",
    "link": "http://arxiv.org/pdf/cs/0602065v1.pdf",
    "category": [
      "cs.CV",
      "cs.IR",
      "I.5; E.4; H.5; I.2.6; I.2.7; I.6"
    ],
    "authors": [
      "Rudi Cilibrasi",
      "Paul Vitanyi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0602083v1",
    "title": "A third level trigger programmable on FPGA for the gamma/hadron\n  separation in a Cherenkov telescope using pseudo-Zernike moments and the SVM\n  classifier",
    "summary": "We studied the application of the Pseudo-Zernike features as image parameters\n(instead of the Hillas parameters) for the discrimination between the images\nproduced by atmospheric electromagnetic showers caused by gamma-rays and the\nones produced by atmospheric electromagnetic showers caused by hadrons in the\nMAGIC Experiment. We used a Support Vector Machine as classification algorithm\nwith the computed Pseudo-Zernike features as classification parameters. We\nimplemented on a FPGA board a kernel function of the SVM and the Pseudo-Zernike\nfeatures to build a third level trigger for the gamma-hadron separation task of\nthe MAGIC Experiment.",
    "published": "2006-02-24T17:29:08Z",
    "link": "http://arxiv.org/pdf/cs/0602083v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "I.5.2; C.3"
    ],
    "authors": [
      "Marco Frailis",
      "Oriana Mansutti",
      "Praveen Boinee",
      "Giuseppe Cabras",
      "Alessandro De Angelis",
      "Barbara De Lotto",
      "Alberto Forti",
      "Mauro Dell'Orso",
      "Riccardo Paoletti",
      "Angelo Scribano",
      "Nicola Turini",
      "Mose' Mariotti",
      "Luigi Peruzzo",
      "Antonio Saggion"
    ]
  },
  {
    "id": "http://arxiv.org/abs/physics/0603002v2",
    "title": "Functional dissipation microarrays for classification",
    "summary": "In this article, we describe a new method of extracting information from\nsignals, called functional dissipation, that proves to be very effective for\nenhancing classification of high resolution, texture-rich data. Our algorithm\nbypasses to some extent the need to have very specialized feature extraction\ntechniques, and can potentially be used as an intermediate, feature enhancement\nstep in any classification scheme.\n  Functional dissipation is based on signal transforms, but uses the transforms\nrecursively to uncover new features. We generate a variety of masking functions\nand `extract' features with several generalized matching pursuit iterations. In\neach iteration, the recursive process modifies several coefficients of the\ntransformed signal with the largest absolute values according to the specific\nmasking function; in this way the greedy pursuit is turned into a slow,\ncontrolled, dissipation of the structure of the signal that, for some masking\nfunctions, enhances separation among classes.\n  Our case study in this paper is the classification of crystallization\npatterns of amino acids solutions affected by the addition of small quantities\nof proteins.",
    "published": "2006-02-28T21:12:45Z",
    "link": "http://arxiv.org/pdf/physics/0603002v2.pdf",
    "category": [
      "physics.data-an",
      "cs.CV"
    ],
    "authors": [
      "D. Napoletani",
      "D. C. Struppa",
      "T. Sauer",
      "V. Morozov",
      "N. Vsevolodov",
      "C. Bailey"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0603041v1",
    "title": "Locally Adaptive Block Thresholding Method with Continuity Constraint",
    "summary": "We present an algorithm that enables one to perform locally adaptive block\nthresholding, while maintaining image continuity. Images are divided into\nsub-images based some standard image attributes and thresholding technique is\nemployed over the sub-images. The present algorithm makes use of the thresholds\nof neighboring sub-images to calculate a range of values. The image continuity\nis taken care by choosing the threshold of the sub-image under consideration to\nlie within the above range. After examining the average range values for\nvarious sub-image sizes of a variety of images, it was found that the range of\nacceptable threshold values is substantially high, justifying our assumption of\nexploiting the freedom of range for bringing out local details.",
    "published": "2006-03-09T17:14:00Z",
    "link": "http://arxiv.org/pdf/cs/0603041v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "S. Hemachander",
      "Amit Verma",
      "Siddharth Arora",
      "Prasanta K. Panigrahi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0603086v1",
    "title": "Matching Edges in Images ; Application to Face Recognition",
    "summary": "This communication describes a representation of images as a set of edges\ncharacterized by their position and orientation. This representation allows the\ncomparison of two images and the computation of their similarity. The first\nstep in this computation of similarity is the seach of a geometrical basis of\nthe two dimensional space where the two images are represented simultaneously\nafter transformation of one of them. Presently, this simultaneous\nrepresentation takes into account a shift and a scaling ; it may be extended to\nrotations or other global geometrical transformations. An elementary\nprobabilistic computation shows that a sufficient but not excessive number of\ntrials (a few tens) ensures that the exhibition of this common basis is\nguaranteed in spite of possible errors in the detection of edges. When this\nfirst step is performed, the search of similarity between the two images\nreduces to counting the coincidence of edges in the two images. The approach\nmay be applied to many problems of pattern matching ; it was checked on face\nrecognition.",
    "published": "2006-03-22T14:51:53Z",
    "link": "http://arxiv.org/pdf/cs/0603086v1.pdf",
    "category": [
      "cs.CV",
      "I.5.1; I.5.2"
    ],
    "authors": [
      "Joel Le Roux",
      "Philippe Chaurand",
      "Mickael Urrutia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0603116v2",
    "title": "Fourier Analysis and Holographic Representations of 1D and 2D Signals",
    "summary": "In this paper, we focus on Fourier analysis and holographic transforms for\nsignal representation. For instance, in the case of image processing, the\nholographic representation has the property that an arbitrary portion of the\ntransformed image enables reconstruction of the whole image with details\nmissing. We focus on holographic representation defined through the Fourier\nTransforms. Thus, We firstly review some results in Fourier transform and\nFourier series. Next, we review the Discrete Holographic Fourier Transform\n(DHFT) for image representation. Then, we describe the contributions of our\nwork. We show a simple scheme for progressive transmission based on the DHFT.\nNext, we propose the Continuous Holographic Fourier Transform (CHFT) and\ndiscuss some theoretical aspects of it for 1D signals. Finally, some testes are\npresented in the experimental results",
    "published": "2006-03-29T19:07:52Z",
    "link": "http://arxiv.org/pdf/cs/0603116v2.pdf",
    "category": [
      "cs.CV",
      "I.4.10"
    ],
    "authors": [
      "G. A. Giraldi",
      "B. F. Moutinho",
      "D. M. L. de Carvalho",
      "J. C. de Oliveira"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0604004v1",
    "title": "The Poincare conjecture for digital spaces. Properties of digital\n  n-dimensional disks and spheres",
    "summary": "Motivated by the Poincare conjecture, we study properties of digital\nn-dimensional spheres and disks, which are digital models of their continuous\ncounterparts. We introduce homeomorphic transformations of digital manifolds,\nwhich retain the connectedness, the dimension, the Euler characteristics and\nthe homology groups of manifolds. We find conditions where an n-dimensional\ndigital manifold is the n-dimensional digital sphere and discuss the link\nbetween continuous closed n-manifolds and their digital models.",
    "published": "2006-04-02T19:55:04Z",
    "link": "http://arxiv.org/pdf/cs/0604004v1.pdf",
    "category": [
      "cs.DM",
      "cs.CV",
      "math.AT"
    ],
    "authors": [
      "Alexander V. Evako"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0604011v2",
    "title": "Semi-Supervised Learning -- A Statistical Physics Approach",
    "summary": "We present a novel approach to semi-supervised learning which is based on\nstatistical physics. Most of the former work in the field of semi-supervised\nlearning classifies the points by minimizing a certain energy function, which\ncorresponds to a minimal k-way cut solution. In contrast to these methods, we\nestimate the distribution of classifications, instead of the sole minimal k-way\ncut, which yields more accurate and robust results. Our approach may be applied\nto all energy functions used for semi-supervised learning. The method is based\non sampling using a Multicanonical Markov chain Monte-Carlo algorithm, and has\na straightforward probabilistic interpretation, which allows for soft\nassignments of points to classes, and also to cope with yet unseen class types.\nThe suggested approach is demonstrated on a toy data set and on two real-life\ndata sets of gene expression.",
    "published": "2006-04-05T18:07:31Z",
    "link": "http://arxiv.org/pdf/cs/0604011v2.pdf",
    "category": [
      "cs.LG",
      "cond-mat.stat-mech",
      "cs.CV"
    ],
    "authors": [
      "Gad Getz",
      "Noam Shental",
      "Eytan Domany"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0604062v1",
    "title": "Biologically Inspired Hierarchical Model for Feature Extraction and\n  Localization",
    "summary": "Feature extraction and matching are among central problems of computer\nvision. It is inefficent to search features over all locations and scales.\nNeurophysiological evidence shows that to locate objects in a digital image the\nhuman visual system employs visual attention to a specific object while\nignoring others. The brain also has a mechanism to search from coarse to fine.\nIn this paper, we present a feature extractor and an associated hierarchical\nsearching model to simulate such processes. With the hierarchical\nrepresentation of the object, coarse scanning is done through the matching of\nthe larger scale and precise localization is conducted through the matching of\nthe smaller scale. Experimental results justify the proposed model in its\neffectiveness and efficiency to localize features.",
    "published": "2006-04-14T04:40:29Z",
    "link": "http://arxiv.org/pdf/cs/0604062v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Liang Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0604094v1",
    "title": "A Fast and Accurate Nonlinear Spectral Method for Image Recognition and\n  Registration",
    "summary": "This article addresses the problem of two- and higher dimensional pattern\nmatching, i.e. the identification of instances of a template within a larger\nsignal space, which is a form of registration. Unlike traditional correlation,\nwe aim at obtaining more selective matchings by considering more strict\ncomparisons of gray-level intensity. In order to achieve fast matching, a\nnonlinear thresholded version of the fast Fourier transform is applied to a\ngray-level decomposition of the original 2D image. The potential of the method\nis substantiated with respect to real data involving the selective\nidentification of neuronal cell bodies in gray-level images.",
    "published": "2006-04-24T16:38:01Z",
    "link": "http://arxiv.org/pdf/cs/0604094v1.pdf",
    "category": [
      "cs.DC",
      "cond-mat.stat-mech",
      "cs.CG",
      "cs.CV"
    ],
    "authors": [
      "Luciano da Fontoura Costa",
      "Erik Bollt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0605025v1",
    "title": "Face Recognition using Principal Component Analysis and Log-Gabor\n  Filters",
    "summary": "In this article we propose a novel face recognition method based on Principal\nComponent Analysis (PCA) and Log-Gabor filters. The main advantages of the\nproposed method are its simple implementation, training, and very high\nrecognition accuracy. For recognition experiments we used 5151 face images of\n1311 persons from different sets of the FERET and AR databases that allow to\nanalyze how recognition accuracy is affected by the change of facial\nexpressions, illumination, and aging. Recognition experiments with the FERET\ndatabase (containing photographs of 1196 persons) showed that our method can\nachieve maximal 97-98% first one recognition rate and 0.3-0.4% Equal Error\nRate. The experiments also showed that the accuracy of our method is less\naffected by eye location errors and used image normalization method than of\ntraditional PCA -based recognition method.",
    "published": "2006-05-07T13:30:09Z",
    "link": "http://arxiv.org/pdf/cs/0605025v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Vytautas Perlibakas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0605027v1",
    "title": "Recognition of expression variant faces using masked log-Gabor features\n  and Principal Component Analysis",
    "summary": "In this article we propose a method for the recognition of faces with\ndifferent facial expressions. For recognition we extract feature vectors by\nusing log-Gabor filters of multiple orientations and scales. Using sliding\nwindow algorithm and variances -based masking these features are extracted at\nimage regions that are less affected by the changes of facial expressions.\nExtracted features are passed to the Principal Component Analysis (PCA) -based\nrecognition method. The results of face recognition experiments using\nexpression variant faces showed that the proposed method could achieve higher\nrecognition accuracy than many other methods. For development and testing we\nused facial images from the AR and FERET databases. Using facial photographs of\nmore than one thousand persons from the FERET database the proposed method\nachieved 96.6-98.9% first one recognition rate and 0.2-0.6% Equal Error Rate\n(EER).",
    "published": "2006-05-07T15:02:53Z",
    "link": "http://arxiv.org/pdf/cs/0605027v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Vytautas Perlibakas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0605103v8",
    "title": "A Better Alternative to Piecewise Linear Time Series Segmentation",
    "summary": "Time series are difficult to monitor, summarize and predict. Segmentation\norganizes time series into few intervals having uniform characteristics\n(flatness, linearity, modality, monotonicity and so on). For scalability, we\nrequire fast linear time algorithms. The popular piecewise linear model can\ndetermine where the data goes up or down and at what rate. Unfortunately, when\nthe data does not follow a linear model, the computation of the local slope\ncreates overfitting. We propose an adaptive time series model where the\npolynomial degree of each interval vary (constant, linear and so on). Given a\nnumber of regressors, the cost of each interval is its polynomial degree:\nconstant intervals cost 1 regressor, linear intervals cost 2 regressors, and so\non. Our goal is to minimize the Euclidean (l_2) error for a given model\ncomplexity. Experimentally, we investigate the model where intervals can be\neither constant or linear. Over synthetic random walks, historical stock market\nprices, and electrocardiograms, the adaptive model provides a more accurate\nsegmentation than the piecewise linear model without increasing the\ncross-validation error or the running time, while providing a richer vocabulary\nto applications. Implementation issues, such as numerical stability and\nreal-world performance, are discussed.",
    "published": "2006-05-24T04:42:53Z",
    "link": "http://arxiv.org/pdf/cs/0605103v8.pdf",
    "category": [
      "cs.DB",
      "cs.CV",
      "H.2.8"
    ],
    "authors": [
      "Daniel Lemire"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0605131v2",
    "title": "Notes on Geometric Measure Theory Applications to Image Processing;\n  De-noising, Segmentation, Pattern, Texture, Lines, Gestalt and Occlusion",
    "summary": "Regularization functionals that lower level set boundary length when used\nwith L^1 fidelity functionals on signal de-noising on images create artifacts.\nThese are (i) rounding of corners, (ii) shrinking of radii, (iii) shrinking of\ncusps, and (iv) non-smoothing of staircasing. Regularity functionals based upon\ntotal curvature of level set boundaries do not create artifacts (i) and (ii).\nAn adjusted fidelity term based on the flat norm on the current (a\ndistributional graph) representing the density of curvature of level sets\nboundaries can minimize (iii) by weighting the position of a cusp. A regularity\nterm to eliminate staircasing can be based upon the mass of the current\nrepresenting the graph of an image function or its second derivatives.\nDensities on the Grassmann bundle of the Grassmann bundle of the ambient space\nof the graph can be used to identify patterns, textures, occlusion and lines.",
    "published": "2006-05-29T13:27:38Z",
    "link": "http://arxiv.org/pdf/cs/0605131v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Simon P Morgan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0606048v1",
    "title": "A New Quartet Tree Heuristic for Hierarchical Clustering",
    "summary": "We consider the problem of constructing an an optimal-weight tree from the\n3*(n choose 4) weighted quartet topologies on n objects, where optimality means\nthat the summed weight of the embedded quartet topologiesis optimal (so it can\nbe the case that the optimal tree embeds all quartets as non-optimal\ntopologies). We present a heuristic for reconstructing the optimal-weight tree,\nand a canonical manner to derive the quartet-topology weights from a given\ndistance matrix. The method repeatedly transforms a bifurcating tree, with all\nobjects involved as leaves, achieving a monotonic approximation to the exact\nsingle globally optimal tree. This contrasts to other heuristic search methods\nfrom biological phylogeny, like DNAML or quartet puzzling, which, repeatedly,\nincrementally construct a solution from a random order of objects, and\nsubsequently add agreement values.",
    "published": "2006-06-11T16:05:51Z",
    "link": "http://arxiv.org/pdf/cs/0606048v1.pdf",
    "category": [
      "cs.DS",
      "cs.CV",
      "cs.DM",
      "math.ST",
      "physics.data-an",
      "q-bio.QM",
      "stat.TH",
      "F.2.2; G.1.6"
    ],
    "authors": [
      "Rudi Cilibrasi",
      "Paul M. B. Vitanyi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0606060v1",
    "title": "Complex Networks: New Concepts and Tools for Real-Time Imaging and\n  Vision",
    "summary": "This article discusses how concepts and methods of complex networks can be\napplied to real-time imaging and computer vision. After a brief introduction of\ncomplex networks basic concepts, their use as means to represent and\ncharacterize images, as well as for modeling visual saliency, are briefly\ndescribed. The possibility to apply complex networks in order to model and\nsimulate the performance of parallel and distributed computing systems for\nperformance of visual methods is also proposed.",
    "published": "2006-06-13T12:53:45Z",
    "link": "http://arxiv.org/pdf/cs/0606060v1.pdf",
    "category": [
      "cs.CV",
      "cs.DC",
      "physics.soc-ph"
    ],
    "authors": [
      "Luciano da Fontoura Costa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/math/0606643v3",
    "title": "Entropy And Vision",
    "summary": "In vector quantization the number of vectors used to construct the codebook\nis always an undefined problem, there is always a compromise between the number\nof vectors and the quantity of information lost during the compression. In this\ntext we present a minimum of Entropy principle that gives solution to this\ncompromise and represents an Entropy point of view of signal compression in\ngeneral. Also we present a new adaptive Object Quantization technique that is\nthe same for the compression and the perception.",
    "published": "2006-06-26T13:03:11Z",
    "link": "http://arxiv.org/pdf/math/0606643v3.pdf",
    "category": [
      "math.PR",
      "cs.CV",
      "cs.DB",
      "cs.DM",
      "cs.LG",
      "math.CO",
      "I.2.10 Vision and Scene Understanding"
    ],
    "authors": [
      "Rami Kanhouche"
    ]
  },
  {
    "id": "http://arxiv.org/abs/math/0607243v1",
    "title": "An active curve approach for tomographic reconstruction of binary\n  radially symmetric objects",
    "summary": "This paper deals with a method of tomographic reconstruction of radially\nsymmetric objects from a single radiograph, in order to study the behavior of\nshocked material. The usual tomographic reconstruction algorithms such as\ngeneralized inverse or filtered back-projection cannot be applied here because\ndata are very noisy and the inverse problem associated to single view\ntomographic reconstruction is highly unstable. In order to improve the\nreconstruction, we propose here to add some a priori assumptions on the looked\nafter object. One of these assumptions is that the object is binary and\nconsequently, the object may be described by the curves that separate the two\nmaterials. We present a model that lives in BV space and leads to a non local\nHamilton-Jacobi equation, via a level set strategy. Numerical experiments are\nperformed (using level sets methods) on synthetic objects.",
    "published": "2006-07-10T17:08:49Z",
    "link": "http://arxiv.org/pdf/math/0607243v1.pdf",
    "category": [
      "math.OC",
      "cs.CV"
    ],
    "authors": [
      "Isabelle Abraham",
      "Romain Abraham",
      "Maitine Bergounioux"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0608009v1",
    "title": "Stability in multidimensional Size Theory",
    "summary": "This paper proves that in Size Theory the comparison of multidimensional size\nfunctions can be reduced to the 1-dimensional case by a suitable change of\nvariables. Indeed, we show that a foliation in half-planes can be given, such\nthat the restriction of a multidimensional size function to each of these\nhalf-planes turns out to be a classical size function in two scalar variables.\nThis leads to the definition of a new distance between multidimensional size\nfunctions, and to the proof of their stability with respect to that distance.",
    "published": "2006-08-02T08:49:57Z",
    "link": "http://arxiv.org/pdf/cs/0608009v1.pdf",
    "category": [
      "cs.CG",
      "cs.CV",
      "I.3.5; I.5.1"
    ],
    "authors": [
      "Andrea Cerri",
      "Patrizio Frosini",
      "Claudia Landi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0608073v1",
    "title": "Parametrical Neural Networks and Some Other Similar Architectures",
    "summary": "A review of works on associative neural networks accomplished during last\nfour years in the Institute of Optical Neural Technologies RAS is given. The\npresentation is based on description of parametrical neural networks (PNN). For\ntoday PNN have record recognizing characteristics (storage capacity, noise\nimmunity and speed of operation). Presentation of basic ideas and principles is\naccentuated.",
    "published": "2006-08-18T08:28:23Z",
    "link": "http://arxiv.org/pdf/cs/0608073v1.pdf",
    "category": [
      "cs.CV",
      "cs.NE"
    ],
    "authors": [
      "Leonid B. Litinskii"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0608093v1",
    "title": "Connection between continuous and digital n-manifolds and the Poincare\n  conjecture",
    "summary": "We introduce LCL covers of closed n-dimensional manifolds by n-dimensional\ndisks and study their properties. We show that any LCL cover of an\nn-dimensional sphere can be converted to the minimal LCL cover, which consists\nof 2n+2 disks. We prove that an LCL collection of n-disks is a cover of a\ncontinuous n-sphere if and only if the intersection graph of this collection is\na digital n-sphere. Using a link between LCL covers of closed continuous\nn-manifolds and digital n-manifolds, we find conditions where a continuous\nclosed three-dimensional manifold is the three-dimensional sphere. We discuss a\nconnection between the classification problems for closed continuous\nthree-dimensional manifolds and digital three-manifolds.",
    "published": "2006-08-24T17:45:45Z",
    "link": "http://arxiv.org/pdf/cs/0608093v1.pdf",
    "category": [
      "cs.DM",
      "cs.CV",
      "math.AT"
    ],
    "authors": [
      "Alexander Evako"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0608115v1",
    "title": "Neural Network Clustering Based on Distances Between Objects",
    "summary": "We present an algorithm of clustering of many-dimensional objects, where only\nthe distances between objects are used. Centers of classes are found with the\naid of neuron-like procedure with lateral inhibition. The result of clustering\ndoes not depend on starting conditions. Our algorithm makes it possible to give\nan idea about classes that really exist in the empirical data. The results of\ncomputer simulations are presented.",
    "published": "2006-08-29T13:24:37Z",
    "link": "http://arxiv.org/pdf/cs/0608115v1.pdf",
    "category": [
      "cs.CV",
      "cs.NE"
    ],
    "authors": [
      "Leonid B. Litinskii",
      "Dmitry E. Romanov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0609003v1",
    "title": "In Quest of Image Semantics: Are We Looking for It Under the Right\n  Lamppost?",
    "summary": "In the last years we witness a dramatic growth of research focused on\nsemantic image understanding. Indeed, without understanding image content\nsuccessful accomplishment of any image-processing task is simply incredible. Up\nto the recent times, the ultimate need for such understanding has been met by\nthe knowledge that a domain expert or a vision system supervisor have\ncontributed to every image-processing application. The advent of the Internet\nhas drastically changed this situation. Internet sources of visual information\nare diffused and dispersed over the whole Web, so the duty of information\ncontent discovery and evaluation must be relegated now to an image\nunderstanding agent (a machine or a computer program) capable to perform image\ncontent assessment at a remote image location. Development of Content Based\nImage Retrieval (CBIR) techniques was a right move in a right direction,\nlaunched about ten years ago. Unfortunately, very little progress has been made\nsince then. The reason for this can be seen in a rank of long lasting\nmisconceptions that CBIR designers are continuing to adhere to. I hope, my\narguments will help them to change their minds.",
    "published": "2006-09-02T11:50:29Z",
    "link": "http://arxiv.org/pdf/cs/0609003v1.pdf",
    "category": [
      "cs.CV",
      "cs.IR"
    ],
    "authors": [
      "Emanuel Diamant"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0609010v1",
    "title": "An effective edge--directed frequency filter for removal of aliasing in\n  upsampled images",
    "summary": "Raster images can have a range of various distortions connected to their\nraster structure. Upsampling them might in effect substantially yield the\nraster structure of the original image, known as aliasing. The upsampling\nitself may introduce aliasing into the upsampled image as well. The presented\nmethod attempts to remove the aliasing using frequency filters based on the\ndiscrete fast Fourier transform, and applied directionally in certain regions\nplaced along the edges in the image.\n  As opposed to some anisotropic smoothing methods, the presented algorithm\naims to selectively reduce only the aliasing, preserving the sharpness of image\ndetails.\n  The method can be used as a post--processing filter along with various\nupsampling algorithms. It was experimentally shown that the method can improve\nthe visual quality of the upsampled images.",
    "published": "2006-09-04T13:04:57Z",
    "link": "http://arxiv.org/pdf/cs/0609010v1.pdf",
    "category": [
      "cs.CV",
      "I.4.3"
    ],
    "authors": [
      "Artur Rataj"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0609071v2",
    "title": "A kernel method for canonical correlation analysis",
    "summary": "Canonical correlation analysis is a technique to extract common features from\na pair of multivariate data. In complex situations, however, it does not\nextract useful features because of its linearity. On the other hand, kernel\nmethod used in support vector machine is an efficient approach to improve such\na linear method. In this paper, we investigate the effectiveness of applying\nkernel method to canonical correlation analysis.",
    "published": "2006-09-13T03:44:08Z",
    "link": "http://arxiv.org/pdf/cs/0609071v2.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Shotaro Akaho"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0609100v1",
    "title": "Total Variation Minimization and Graph Cuts for Moving Objects\n  Segmentation",
    "summary": "In this paper, we are interested in the application to video segmentation of\nthe discrete shape optimization problem involving the shape weighted perimeter\nand an additional term depending on a parameter. Based on recent works and in\nparticular the one of Darbon and Sigelle, we justify the equivalence of the\nshape optimization problem and a weighted total variation regularization. For\nsolving this problem, we adapt the projection algorithm proposed recently for\nsolving the basic TV regularization problem. Another solution to the shape\noptimization investigated here is the graph cut technique. Both methods have\nthe advantage to lead to a global minimum. Since we can distinguish moving\nobjects from static elements of a scene by analyzing norm of the optical flow\nvectors, we choose the optical flow norm as initial data. In order to have the\ncontour as close as possible to an edge in the image, we use a classical edge\ndetector function as the weight of the weighted total variation. This model has\nbeen used in one of our former works. We also apply the same methods to a video\nsegmentation model used by Jehan-Besson, Barlaud and Aubert. In this case, only\nstandard perimeter is incorporated in the shape functional. We also propose\nanother way for finding moving objects by using an a contrario detection of\nobjects on the image obtained by solving the Rudin-Osher-Fatemi Total Variation\nregularization problem.We can notice the segmentation can be associated to a\nlevel set in the former methods.",
    "published": "2006-09-18T06:40:44Z",
    "link": "http://arxiv.org/pdf/cs/0609100v1.pdf",
    "category": [
      "cs.CV",
      "I.4.6; G.3"
    ],
    "authors": [
      "Florent Ranchin",
      "Antonin Chambolle",
      "Franoise Dibos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0609164v1",
    "title": "Conditional Expressions for Blind Deconvolution: Multi-point form",
    "summary": "We present conditional expression (CE) for finding blurs convolved in given\nimages. The CE is given in terms of the zero-values of the blurs evaluated at\nmulti-point. The CE can detect multiple blur all at once. We illustrate the\nmultiple blur-detection by using a test image.",
    "published": "2006-09-29T13:48:35Z",
    "link": "http://arxiv.org/pdf/cs/0609164v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "S. Aogaki",
      "I. Moritani",
      "T. Sugai",
      "F. Takeutchi",
      "F. M. Toyama"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0609165v1",
    "title": "Simple method to eliminate blur based on Lane and Bates algorithm",
    "summary": "A simple search method for finding a blur convolved in a given image is\npresented. The method can be easily extended to a large blur. The method has\nbeen experimentally tested with a model blurred image.",
    "published": "2006-09-29T13:50:12Z",
    "link": "http://arxiv.org/pdf/cs/0609165v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "S. Aogaki",
      "I. Moritani",
      "T. Sugai",
      "F. Takeutchi",
      "F. M. Toyama"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0610002v1",
    "title": "Conditional Expressions for Blind Deconvolution: Derivative form",
    "summary": "We developed novel conditional expressions (CEs) for Lane and Bates' blind\ndeconvolution. The CEs are given in term of the derivatives of the zero-values\nof the z-transform of given images. The CEs make it possible to automatically\ndetect multiple blur convolved in the given images all at once without\nperforming any analysis of the zero-sheets of the given images. We illustrate\nthe multiple blur-detection by the CEs for a model image",
    "published": "2006-09-30T08:05:02Z",
    "link": "http://arxiv.org/pdf/cs/0610002v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "S. Aogaki",
      "I. Moritani",
      "T. Sugai",
      "F. Takeutchi",
      "F. M. Toyama"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0610033v1",
    "title": "A kernel for time series based on global alignments",
    "summary": "We propose in this paper a new family of kernels to handle times series,\nnotably speech data, within the framework of kernel methods which includes\npopular algorithms such as the Support Vector Machine. These kernels elaborate\non the well known Dynamic Time Warping (DTW) family of distances by considering\nthe same set of elementary operations, namely substitutions and repetitions of\ntokens, to map a sequence onto another. Associating to each of these operations\na given score, DTW algorithms use dynamic programming techniques to compute an\noptimal sequence of operations with high overall score. In this paper we\nconsider instead the score spanned by all possible alignments, take a smoothed\nversion of their maximum and derive a kernel out of this formulation. We prove\nthat this kernel is positive definite under favorable conditions and show how\nit can be tuned effectively for practical applications as we report encouraging\nresults on a speech recognition task.",
    "published": "2006-10-06T04:45:32Z",
    "link": "http://arxiv.org/pdf/cs/0610033v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Marco Cuturi",
      "Jean-Philippe Vert",
      "Oystein Birkenes",
      "Tomoko Matsui"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0610059v2",
    "title": "Camera motion estimation through planar deformation determination",
    "summary": "In this paper, we propose a global method for estimating the motion of a\ncamera which films a static scene. Our approach is direct, fast and robust, and\ndeals with adjacent frames of a sequence. It is based on a quadratic\napproximation of the deformation between two images, in the case of a scene\nwith constant depth in the camera coordinate system. This condition is very\nrestrictive but we show that provided translation and depth inverse variations\nare small enough, the error on optical flow involved by the approximation of\ndepths by a constant is small. In this context, we propose a new model of\ncamera motion, that allows to separate the image deformation in a similarity\nand a ``purely'' projective application, due to change of optical axis\ndirection. This model leads to a quadratic approximation of image deformation\nthat we estimate with an M-estimator; we can immediatly deduce camera motion\nparameters.",
    "published": "2006-10-11T09:31:52Z",
    "link": "http://arxiv.org/pdf/cs/0610059v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Claire Jonchery",
      "Franoise Dibos",
      "Georges Koepfler"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0611115v1",
    "title": "A higher-order active contour model of a `gas of circles' and its\n  application to tree crown extraction",
    "summary": "Many image processing problems involve identifying the region in the image\ndomain occupied by a given entity in the scene. Automatic solution of these\nproblems requires models that incorporate significant prior knowledge about the\nshape of the region. Many methods for including such knowledge run into\ndifficulties when the topology of the region is unknown a priori, for example\nwhen the entity is composed of an unknown number of similar objects.\nHigher-order active contours (HOACs) represent one method for the modelling of\nnon-trivial prior knowledge about shape without necessarily constraining region\ntopology, via the inclusion of non-local interactions between region boundary\npoints in the energy defining the model. The case of an unknown number of\ncircular objects arises in a number of domains, e.g. medical, biological,\nnanotechnological, and remote sensing imagery. Regions composed of an a priori\nunknown number of circles may be referred to as a `gas of circles'. In this\nreport, we present a HOAC model of a `gas of circles'. In order to guarantee\nstable circles, we conduct a stability analysis via a functional Taylor\nexpansion of the HOAC energy around a circular shape. This analysis fixes one\nof the model parameters in terms of the others and constrains the rest. In\nconjunction with a suitable likelihood energy, we apply the model to the\nextraction of tree crowns from aerial imagery, and show that the new model\noutperforms other techniques.",
    "published": "2006-11-22T13:44:11Z",
    "link": "http://arxiv.org/pdf/cs/0611115v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Peter Horvath",
      "Ian Jermyn",
      "Zoltan Kato",
      "Josiane Zerubia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/q-bio/0612013v1",
    "title": "Clustering fetal heart rate tracings by compression",
    "summary": "Fetal heart rate (FHR) monitoring, before and during labor, is a very\nimportant medical practice in the detection of fetuses in danger. We clustered\nFHR tracings by compression in order to identify abnormal ones. We use a\nrecently introduced approach based on algorithmic information theory, a\ntheoretical, rigorous and well-studied notion of information content in\nindividual objects. The new method can mine patterns in completely different\nareas, there are no domain-specific parameters to set, and it does not require\nspecific background knowledge. At the highest level the FHR tracings were\nclustered according to an unanticipated feature, namely the technology used in\nsignal acquisition. At the lower levels all tracings with abnormal or\nsuspicious patterns were clustered together, independent of the technology\nused. Moreover, FHR tracings with future poor neonatal outcomes were included\nin the cluster with other suspicious patterns.",
    "published": "2006-12-07T16:45:15Z",
    "link": "http://arxiv.org/pdf/q-bio/0612013v1.pdf",
    "category": [
      "q-bio.TO",
      "cs.CV",
      "cs.IR",
      "q-bio.QM"
    ],
    "authors": [
      "C. Costa Santos",
      "J. Bernardes",
      "P. Vitanyi",
      "L. Antunes"
    ]
  },
  {
    "id": "http://arxiv.org/abs/physics/0701081v1",
    "title": "Spatio-Temporal Electromagnetic Field Shapes and their Logical\n  Processing",
    "summary": "This paper is on the spatio-temporal signals with the topologically modulated\nelectromagnetic fields. The carrier of the digital information is the\ntopological scheme composed of the separatrices-manifolds and equilibrium\npositions of the field. The signals and developed hardware for their processing\nin the space-time domain are considered",
    "published": "2007-01-07T16:07:15Z",
    "link": "http://arxiv.org/pdf/physics/0701081v1.pdf",
    "category": [
      "physics.comp-ph",
      "cs.CV",
      "physics.gen-ph"
    ],
    "authors": [
      "G. A. Kouzaev"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0701057v1",
    "title": "Cooperative Optimization for Energy Minimization: A Case Study of Stereo\n  Matching",
    "summary": "Often times, individuals working together as a team can solve hard problems\nbeyond the capability of any individual in the team. Cooperative optimization\nis a newly proposed general method for attacking hard optimization problems\ninspired by cooperation principles in team playing. It has an established\ntheoretical foundation and has demonstrated outstanding performances in solving\nreal-world optimization problems. With some general settings, a cooperative\noptimization algorithm has a unique equilibrium and converges to it with an\nexponential rate regardless initial conditions and insensitive to\nperturbations. It also possesses a number of global optimality conditions for\nidentifying global optima so that it can terminate its search process\nefficiently. This paper offers a general description of cooperative\noptimization, addresses a number of design issues, and presents a case study to\ndemonstrate its power.",
    "published": "2007-01-09T01:03:25Z",
    "link": "http://arxiv.org/pdf/cs/0701057v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Xiaofei Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0701127v3",
    "title": "A novel set of rotationally and translationally invariant features for\n  images based on the non-commutative bispectrum",
    "summary": "We propose a new set of rotationally and translationally invariant features\nfor image or pattern recognition and classification. The new features are cubic\npolynomials in the pixel intensities and provide a richer representation of the\noriginal image than most existing systems of invariants. Our construction is\nbased on the generalization of the concept of bispectrum to the\nthree-dimensional rotation group SO(3), and a projection of the image onto the\nsphere.",
    "published": "2007-01-20T15:45:03Z",
    "link": "http://arxiv.org/pdf/cs/0701127v3.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "I.4.7; I.2.10; I.5.4"
    ],
    "authors": [
      "Risi Kondor"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0701150v1",
    "title": "Contains and Inside relationships within combinatorial Pyramids",
    "summary": "Irregular pyramids are made of a stack of successively reduced graphs\nembedded in the plane. Such pyramids are used within the segmentation framework\nto encode a hierarchy of partitions. The different graph models used within the\nirregular pyramid framework encode different types of relationships between\nregions. This paper compares different graph models used within the irregular\npyramid framework according to a set of relationships between regions. We also\ndefine a new algorithm based on a pyramid of combinatorial maps which allows to\ndetermine if one region contains the other using only local calculus.",
    "published": "2007-01-24T15:13:06Z",
    "link": "http://arxiv.org/pdf/cs/0701150v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Luc Brun",
      "Walter G. Kropatsch"
    ]
  },
  {
    "id": "http://arxiv.org/abs/math/0701791v2",
    "title": "Linear versus Non-linear Acquisition of Step-Functions",
    "summary": "We address in this paper the following two closely related problems:\n  1. How to represent functions with singularities (up to a prescribed\naccuracy) in a compact way?\n  2. How to reconstruct such functions from a small number of measurements?\n  The stress is on a comparison of linear and non-linear approaches. As a model\ncase we use piecewise-constant functions on [0,1], in particular, the Heaviside\njump function. Considered as a curve in the Hilbert space, it is completely\ncharacterized by the fact that any two its disjoint chords are orthogonal. We\nreinterpret this fact in a context of step-functions in one or two variables.\n  Next we study the limitations on representability and reconstruction of\npiecewise-constant functions by linear and semi-linear methods. Our main tools\nin this problem are Kolmogorov's n-width and entropy, as well as Temlyakov's\n(N,m)-width.\n  On the positive side, we show that a very accurate non-linear reconstruction\nis possible. It goes through a solution of certain specific non-linear systems\nof algebraic equations. We discuss the form of these systems and methods of\ntheir solution, stressing their relation to Moment Theory and Complex Analysis.\n  Finally, we informally discuss two problems in Computer Imaging which are\nparallel to the problems 1 and 2 above: compression of still images and\nvideo-sequences on one side, and image reconstruction from indirect measurement\n(for example, in Computer Tomography), on the other.",
    "published": "2007-01-27T09:26:16Z",
    "link": "http://arxiv.org/pdf/math/0701791v2.pdf",
    "category": [
      "math.CA",
      "cs.CV",
      "41A46 (Primary); 94A08 (Secondary)"
    ],
    "authors": [
      "Boris Ettinger",
      "Niv Sarig",
      "Yosef Yomdin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0702082v1",
    "title": "Invariant template matching in systems with spatiotemporal coding: a\n  vote for instability",
    "summary": "We consider the design of a pattern recognition that matches templates to\nimages, both of which are spatially sampled and encoded as temporal sequences.\nThe image is subject to a combination of various perturbations. These include\nones that can be modeled as parameterized uncertainties such as image blur,\nluminance, translation, and rotation as well as unmodeled ones. Biological and\nneural systems require that these perturbations be processed through a minimal\nnumber of channels by simple adaptation mechanisms. We found that the most\nsuitable mathematical framework to meet this requirement is that of weakly\nattracting sets. This framework provides us with a normative and unifying\nsolution to the pattern recognition problem. We analyze the consequences of its\nexplicit implementation in neural systems. Several properties inherent to the\nsystems designed in accordance with our normative mathematical argument\ncoincide with known empirical facts. This is illustrated in mental rotation,\nvisual search and blur/intensity adaptation. We demonstrate how our results can\nbe applied to a range of practical problems in template matching and pattern\nrecognition.",
    "published": "2007-02-14T07:01:56Z",
    "link": "http://arxiv.org/pdf/cs/0702082v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "G.1.6; G.1.7; I.2.0; I.2.8; I.2.10; I.4.4; I.5.0; I.5.2"
    ],
    "authors": [
      "Ivan Tyukin",
      "Tatiana Tyukina",
      "Cees van Leeuwen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0703053v1",
    "title": "Extraction of cartographic objects in high resolution satellite images\n  for object model generation",
    "summary": "The aim of this study is to detect man-made cartographic objects in\nhigh-resolution satellite images. New generation satellites offer a sub-metric\nspatial resolution, in which it is possible (and necessary) to develop methods\nat object level rather than at pixel level, and to exploit structural features\nof objects. With this aim, a method to generate structural object models from\nmanually segmented images has been developed. To generate the model from\nnon-segmented images, extraction of the objects from the sample images is\nrequired. A hybrid method of extraction (both in terms of input sources and\nsegmentation algorithms) is proposed: A region based segmentation is applied on\na 10 meter resolution multi-spectral image. The result is used as marker in a\n\"marker-controlled watershed method using edges\" on a 2.5 meter resolution\npanchromatic image. Very promising results have been obtained even on images\nwhere the limits of the target objects are not apparent.",
    "published": "2007-03-12T15:57:23Z",
    "link": "http://arxiv.org/pdf/cs/0703053v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Guray Erus",
      "Nicolas Lomnie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0703088v1",
    "title": "Plot 94 in ambiance X-Window",
    "summary": "<PLOT > is a collection of routines to draw surfaces, contours and so on. In\nthis work we are presenting a version, that functions over work stations with\nthe operative system UNIX, that count with the graphic ambiance X-WINDOW with\nthe tools XLIB and OSF/MOTIF. This implant was realized for the work stations\nDEC 5000-200, DEC IPX, and DEC ALFA of the CINVESTAV (Center of Investigation\nand Advanced Studies). Also implanted in SILICON GRAPHICS of the CENAC\n(National Center of Calculation of the Polytechnic National Institute",
    "published": "2007-03-16T00:18:11Z",
    "link": "http://arxiv.org/pdf/cs/0703088v1.pdf",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "Ignacio Vega-Paez",
      "Carlos Alberto Hernandez-Hernandez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0703101v1",
    "title": "A Note on Approximate Nearest Neighbor Methods",
    "summary": "A number of authors have described randomized algorithms for solving the\nepsilon-approximate nearest neighbor problem. In this note I point out that the\nepsilon-approximate nearest neighbor property often fails to be a useful\napproximation property, since epsilon-approximate solutions fail to satisfy the\nnecessary preconditions for using nearest neighbors for classification and\nrelated tasks.",
    "published": "2007-03-21T20:47:33Z",
    "link": "http://arxiv.org/pdf/cs/0703101v1.pdf",
    "category": [
      "cs.IR",
      "cs.CC",
      "cs.CV"
    ],
    "authors": [
      "Thomas M. Breuel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0704.1267v1",
    "title": "Text Line Segmentation of Historical Documents: a Survey",
    "summary": "There is a huge amount of historical documents in libraries and in various\nNational Archives that have not been exploited electronically. Although\nautomatic reading of complete pages remains, in most cases, a long-term\nobjective, tasks such as word spotting, text/image alignment, authentication\nand extraction of specific fields are in use today. For all these tasks, a\nmajor step is document segmentation into text lines. Because of the low quality\nand the complexity of these documents (background noise, artifacts due to\naging, interfering lines),automatic text line segmentation remains an open\nresearch field. The objective of this paper is to present a survey of existing\nmethods, developed during the last decade, and dedicated to documents of\nhistorical interest.",
    "published": "2007-04-10T16:26:42Z",
    "link": "http://arxiv.org/pdf/0704.1267v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Laurence Likforman-Sulem",
      "Abderrazak Zahour",
      "Bruno Taconet"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0704.3635v1",
    "title": "Rough Sets Computations to Impute Missing Data",
    "summary": "Many techniques for handling missing data have been proposed in the\nliterature. Most of these techniques are overly complex. This paper explores an\nimputation technique based on rough set computations. In this paper,\ncharacteristic relations are introduced to describe incompletely specified\ndecision tables.It is shown that the basic rough set idea of lower and upper\napproximations for incompletely specified decision tables may be defined in a\nvariety of different ways. Empirical results obtained using real data are given\nand they provide a valuable and promising insight to the problem of missing\ndata. Missing data were predicted with an accuracy of up to 99%.",
    "published": "2007-04-26T22:22:45Z",
    "link": "http://arxiv.org/pdf/0704.3635v1.pdf",
    "category": [
      "cs.CV",
      "cs.IR"
    ],
    "authors": [
      "Fulufhelo Vincent Nelwamondo",
      "Tshilidzi Marwala"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.0199v2",
    "title": "The Parameter-Less Self-Organizing Map algorithm",
    "summary": "The Parameter-Less Self-Organizing Map (PLSOM) is a new neural network\nalgorithm based on the Self-Organizing Map (SOM). It eliminates the need for a\nlearning rate and annealing schemes for learning rate and neighbourhood size.\nWe discuss the relative performance of the PLSOM and the SOM and demonstrate\nsome tasks in which the SOM fails but the PLSOM performs satisfactory. Finally\nwe discuss some example applications of the PLSOM and present a proof of\nordering under certain limited conditions.",
    "published": "2007-05-02T04:04:51Z",
    "link": "http://arxiv.org/pdf/0705.0199v2.pdf",
    "category": [
      "cs.NE",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Erik Berglund",
      "Joaquin Sitte"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.0214v1",
    "title": "Riemannian level-set methods for tensor-valued data",
    "summary": "We present a novel approach for the derivation of PDE modeling\ncurvature-driven flows for matrix-valued data. This approach is based on the\nRiemannian geometry of the manifold of Symmetric Positive Definite Matrices\nPos(n).",
    "published": "2007-05-02T07:32:58Z",
    "link": "http://arxiv.org/pdf/0705.0214v1.pdf",
    "category": [
      "cs.CV",
      "I.4.3"
    ],
    "authors": [
      "Mourad Zerai",
      "Maher Moakher"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.0449v1",
    "title": "Multiresolution Approximation of Polygonal Curves in Linear Complexity",
    "summary": "We propose a new algorithm to the problem of polygonal curve approximation\nbased on a multiresolution approach. This algorithm is suboptimal but still\nmaintains some optimality between successive levels of resolution using dynamic\nprogramming. We show theoretically and experimentally that this algorithm has a\nlinear complexity in time and space. We experimentally compare the outcomes of\nour algorithm to the optimal \"full search\" dynamic programming solution and\nfinally to classical merge and split approaches. The experimental evaluations\nconfirm the theoretical derivations and show that the proposed approach\nevaluated on 2D coastal maps either show a lower time complexity or provide\npolygonal approximations closer to the input discrete curves.",
    "published": "2007-05-03T12:47:31Z",
    "link": "http://arxiv.org/pdf/0705.0449v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Pierre-Franois Marteau",
      "Gilbas Mnier"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.0781v1",
    "title": "Medical Image Segmentation and Localization using Deformable Templates",
    "summary": "This paper presents deformable templates as a tool for segmentation and\nlocalization of biological structures in medical images. Structures are\nrepresented by a prototype template, combined with a parametric warp mapping\nused to deform the original shape. The localization procedure is achieved using\na multi-stage, multi-resolution algorithm de-signed to reduce computational\ncomplexity and time. The algorithm initially identifies regions in the image\nmost likely to contain the desired objects and then examines these regions at\nprogressively increasing resolutions. The final stage of the algorithm involves\nwarping the prototype template to match the localized objects. The algorithm is\npresented along with the results of four example applications using MRI, x-ray\nand ultrasound images.",
    "published": "2007-05-06T06:02:46Z",
    "link": "http://arxiv.org/pdf/0705.0781v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jonathan M. Spiller",
      "T. Marwala"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.0828v1",
    "title": "Enhancement of Noisy Planar Nuclear Medicine Images using Mean Field\n  Annealing",
    "summary": "Nuclear medicine (NM) images inherently suffer from large amounts of noise\nand blur. The purpose of this research is to reduce the noise and blur while\nmaintaining image integrity for improved diagnosis. The proposed solution is to\nincrease image quality after the standard pre- and post-processing undertaken\nby a gamma camera system. Mean Field Annealing (MFA) is the image processing\ntechnique used in this research. It is a computational iterative technique that\nmakes use of the Point Spread Function (PSF) and the noise associated with the\nNM image. MFA is applied to NM images with the objective of reducing noise\nwhile not compromising edge integrity. Using a sharpening filter as a\npost-processing technique (after MFA) yields image enhancement of planar NM\nimages.",
    "published": "2007-05-06T23:08:04Z",
    "link": "http://arxiv.org/pdf/0705.0828v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "D. L. Falk",
      "D. M. Rubin",
      "T. Marwala"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.0952v1",
    "title": "An Independent Evaluation of Subspace Face Recognition Algorithms",
    "summary": "This paper explores a comparative study of both the linear and kernel\nimplementations of three of the most popular Appearance-based Face Recognition\nprojection classes, these being the methodologies of Principal Component\nAnalysis, Linear Discriminant Analysis and Independent Component Analysis. The\nexperimental procedure provides a platform of equal working conditions and\nexamines the ten algorithms in the categories of expression, illumination,\nocclusion and temporal delay. The results are then evaluated based on a\nsequential combination of assessment tools that facilitate both intuitive and\nstatistical decisiveness among the intra and interclass comparisons. The best\ncategorical algorithms are then incorporated into a hybrid methodology, where\nthe advantageous effects of fusion strategies are considered.",
    "published": "2007-05-07T19:19:55Z",
    "link": "http://arxiv.org/pdf/0705.0952v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Dhiresh R. Surajpal",
      "Tshilidzi Marwala"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.1674v1",
    "title": "Evolutionary Optimisation Methods for Template Based Image Registration",
    "summary": "This paper investigates the use of evolutionary optimisation techniques to\nregister a template with a scene image. An error function is created to measure\nthe correspondence of the template to the image. The problem presented here is\nto optimise the horizontal, vertical and scaling parameters that register the\ntemplate with the scene. The Genetic Algorithm, Simulated Annealing and\nParticle Swarm Optimisations are compared to a Nelder-Mead Simplex optimisation\nwith starting points chosen in a pre-processing stage. The paper investigates\nthe precision and accuracy of each method and shows that all four methods\nperform favourably for image registration. SA is the most precise, GA is the\nmost accurate. PSO is a good mix of both and the Simplex method returns local\nminima the most. A pre-processing stage should be investigated for the\nevolutionary methods in order to improve performance. Discrete versions of the\noptimisation methods should be investigated to further improve computational\nperformance.",
    "published": "2007-05-11T15:51:36Z",
    "link": "http://arxiv.org/pdf/0705.1674v1.pdf",
    "category": [
      "cs.CE",
      "cs.CV"
    ],
    "authors": [
      "Lukasz A Machowski",
      "Tshilidzi Marwala"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.2011v1",
    "title": "Multi-Dimensional Recurrent Neural Networks",
    "summary": "Recurrent neural networks (RNNs) have proved effective at one dimensional\nsequence learning tasks, such as speech and online handwriting recognition.\nSome of the properties that make RNNs suitable for such tasks, for example\nrobustness to input warping, and the ability to access contextual information,\nare also desirable in multidimensional domains. However, there has so far been\nno direct way of applying RNNs to data with more than one spatio-temporal\ndimension. This paper introduces multi-dimensional recurrent neural networks\n(MDRNNs), thereby extending the potential applicability of RNNs to vision,\nvideo processing, medical imaging and many other areas, while avoiding the\nscaling problems that have plagued other multi-dimensional models. Experimental\nresults are provided for two image segmentation tasks.",
    "published": "2007-05-14T19:49:56Z",
    "link": "http://arxiv.org/pdf/0705.2011v1.pdf",
    "category": [
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Alex Graves",
      "Santiago Fernandez",
      "Juergen Schmidhuber"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.2854v1",
    "title": "Scanning and Sequential Decision Making for Multi-Dimensional Data -\n  Part II: the Noisy Case",
    "summary": "We consider the problem of sequential decision making on random fields\ncorrupted by noise. In this scenario, the decision maker observes a noisy\nversion of the data, yet judged with respect to the clean data. In particular,\nwe first consider the problem of sequentially scanning and filtering noisy\nrandom fields. In this case, the sequential filter is given the freedom to\nchoose the path over which it traverses the random field (e.g., noisy image or\nvideo sequence), thus it is natural to ask what is the best achievable\nperformance and how sensitive this performance is to the choice of the scan. We\nformally define the problem of scanning and filtering, derive a bound on the\nbest achievable performance and quantify the excess loss occurring when\nnon-optimal scanners are used, compared to optimal scanning and filtering.\n  We then discuss the problem of sequential scanning and prediction of noisy\nrandom fields. This setting is a natural model for applications such as\nrestoration and coding of noisy images. We formally define the problem of\nscanning and prediction of a noisy multidimensional array and relate the\noptimal performance to the clean scandictability defined by Merhav and\nWeissman. Moreover, bounds on the excess loss due to sub-optimal scans are\nderived, and a universal prediction algorithm is suggested.\n  This paper is the second part of a two-part paper. The first paper dealt with\nsequential decision making on noiseless data arrays, namely, when the decision\nmaker is judged with respect to the same data array it observes.",
    "published": "2007-05-20T09:14:06Z",
    "link": "http://arxiv.org/pdf/0705.2854v1.pdf",
    "category": [
      "cs.IT",
      "cs.CV",
      "math.IT"
    ],
    "authors": [
      "Asaf Cohen",
      "Tsachy Weissman",
      "Neri Merhav"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.3593v2",
    "title": "MI image registration using prior knowledge",
    "summary": "Subtraction of aligned images is a means to assess changes in a wide variety\nof clinical applications. In this paper we explore the information theoretical\norigin of Mutual Information (MI), which is based on Shannon's entropy.However,\nthe interpretation of standard MI registration as a communication channel\nsuggests that MI is too restrictive a criterion. In this paper the concept of\nMutual Information (MI) is extended to (Normalized) Focussed Mutual Information\n(FMI) to incorporate prior knowledge to overcome some shortcomings of MI. We\nuse this to develop new methodologies to successfully address specific\nregistration problems, the follow-up of dental restorations, cephalometry, and\nthe monitoring of implants.",
    "published": "2007-05-24T14:41:11Z",
    "link": "http://arxiv.org/pdf/0705.3593v2.pdf",
    "category": [
      "cs.CV",
      "I.4.3"
    ],
    "authors": [
      "W. Jacquet",
      "P. de Groen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.3669v1",
    "title": "Structural Health Monitoring Using Neural Network Based Vibrational\n  System Identification",
    "summary": "Composite fabrication technologies now provide the means for producing\nhigh-strength, low-weight panels, plates, spars and other structural components\nwhich use embedded fiber optic sensors and piezoelectric transducers. These\nmaterials, often referred to as smart structures, make it possible to sense\ninternal characteristics, such as delaminations or structural degradation. In\nthis effort we use neural network based techniques for modeling and analyzing\ndynamic structural information for recognizing structural defects. This yields\nan adaptable system which gives a measure of structural integrity for composite\nstructures.",
    "published": "2007-05-24T21:48:18Z",
    "link": "http://arxiv.org/pdf/0705.3669v1.pdf",
    "category": [
      "cs.NE",
      "cs.CV",
      "cs.SD"
    ],
    "authors": [
      "Donald A. Sofge"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.3693v4",
    "title": "Morphing Ensemble Kalman Filters",
    "summary": "A new type of ensemble filter is proposed, which combines an ensemble Kalman\nfilter (EnKF) with the ideas of morphing and registration from image\nprocessing. This results in filters suitable for nonlinear problems whose\nsolutions exhibit moving coherent features, such as thin interfaces in wildfire\nmodeling. The ensemble members are represented as the composition of one common\nstate with a spatial transformation, called registration mapping, plus a\nresidual. A fully automatic registration method is used that requires only\ngridded data, so the features in the model state do not need to be identified\nby the user. The morphing EnKF operates on a transformed state consisting of\nthe registration mapping and the residual. Essentially, the morphing EnKF uses\nintermediate states obtained by morphing instead of linear combinations of the\nstates.",
    "published": "2007-05-25T05:46:33Z",
    "link": "http://arxiv.org/pdf/0705.3693v4.pdf",
    "category": [
      "math.DS",
      "cs.CV",
      "math.ST",
      "physics.ao-ph",
      "stat.ME",
      "stat.TH",
      "65P99, 62F15, 94A08"
    ],
    "authors": [
      "Jonathan D. Beezley",
      "Jan Mandel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.4654v1",
    "title": "Local Area Damage Detection in Composite Structures Using Piezoelectric\n  Transducers",
    "summary": "An integrated and automated smart structures approach for structural health\nmonitoring is presented, utilizing an array of piezoelectric transducers\nattached to or embedded within the structure for both actuation and sensing.\nThe system actively interrogates the structure via broadband excitation of\nmultiple actuators across a desired frequency range. The structure's vibration\nsignature is then characterized by computing the transfer functions between\neach actuator/sensor pair, and compared to the baseline signature. Experimental\nresults applying the system to local area damage detection in a MD Explorer\nrotorcraft composite flexbeam are presented.",
    "published": "2007-05-31T17:19:17Z",
    "link": "http://arxiv.org/pdf/0705.4654v1.pdf",
    "category": [
      "cs.SD",
      "cs.CV"
    ],
    "authors": [
      "Peter F. Lichtenwalner",
      "Donald A. Sofge"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0706.0300v1",
    "title": "Automatic Detection of Pulmonary Embolism using Computational\n  Intelligence",
    "summary": "This article describes the implementation of a system designed to\nautomatically detect the presence of pulmonary embolism in lung scans. These\nimages are firstly segmented, before alignment and feature extraction using\nPCA. The neural network was trained using the Hybrid Monte Carlo method,\nresulting in a committee of 250 neural networks and good results are obtained.",
    "published": "2007-06-03T05:17:38Z",
    "link": "http://arxiv.org/pdf/0706.0300v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Simon Scurrell",
      "Tshilidzi Marwala",
      "David Rubin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0706.0465v1",
    "title": "Virtual Sensor Based Fault Detection and Classification on a Plasma Etch\n  Reactor",
    "summary": "The SEMATECH sponsored J-88-E project teaming Texas Instruments with\nNeuroDyne (et al.) focused on Fault Detection and Classification (FDC) on a Lam\n9600 aluminum plasma etch reactor, used in the process of semiconductor\nfabrication. Fault classification was accomplished by implementing a series of\nvirtual sensor models which used data from real sensors (Lam Station sensors,\nOptical Emission Spectroscopy, and RF Monitoring) to predict recipe setpoints\nand wafer state characteristics. Fault detection and classification were\nperformed by comparing predicted recipe and wafer state values with expected\nvalues. Models utilized include linear PLS, Polynomial PLS, and Neural Network\nPLS. Prediction of recipe setpoints based upon sensor data provides a\ncapability for cross-checking that the machine is maintaining the desired\nsetpoints. Wafer state characteristics such as Line Width Reduction and\nRemaining Oxide were estimated on-line using these same process sensors (Lam,\nOES, RFM). Wafer-to-wafer measurement of these characteristics in a production\nsetting (where typically this information may be only sparsely available, if at\nall, after batch processing runs with numerous wafers have been completed)\nwould provide important information to the operator that the process is or is\nnot producing wafers within acceptable bounds of product quality. Production\nyield is increased, and correspondingly per unit cost is reduced, by providing\nthe operator with the opportunity to adjust the process or machine before\netching more wafers.",
    "published": "2007-06-04T15:55:27Z",
    "link": "http://arxiv.org/pdf/0706.0465v1.pdf",
    "category": [
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "D. A. Sofge"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0706.1926v1",
    "title": "Towards understanding and modelling office daily life",
    "summary": "Measuring and modeling human behavior is a very complex task. In this paper\nwe present our initial thoughts on modeling and automatic recognition of some\nhuman activities in an office. We argue that to successfully model human\nactivities, we need to consider both individual behavior and group dynamics. To\ndemonstrate these theoretical approaches, we introduce an experimental system\nfor analyzing everyday activity in our office.",
    "published": "2007-06-13T15:15:00Z",
    "link": "http://arxiv.org/pdf/0706.1926v1.pdf",
    "category": [
      "cs.CV",
      "cs.CY",
      "I.4.8; I.5.3"
    ],
    "authors": [
      "Michele Bezzi",
      "Robin Groenevelt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.0802v1",
    "title": "Very fast watermarking by reversible contrast mapping",
    "summary": "Reversible contrast mapping (RCM) is a simple integer transform that applies\nto pairs of pixels. For some pairs of pixels, RCM is invertible, even if the\nleast significant bits (LSBs) of the transformed pixels are lost. The data\nspace occupied by the LSBs is suitable for data hiding. The embedded\ninformation bit-rates of the proposed spatial domain reversible watermarking\nscheme are close to the highest bit-rates reported so far. The scheme does not\nneed additional data compression, and, in terms of mathematical complexity, it\nappears to be the lowest complexity one proposed up to now. A very fast lookup\ntable implementation is proposed. Robustness against cropping can be ensured as\nwell.",
    "published": "2007-07-05T15:11:24Z",
    "link": "http://arxiv.org/pdf/0707.0802v1.pdf",
    "category": [
      "cs.MM",
      "cs.CR",
      "cs.CV",
      "cs.IT",
      "math.IT"
    ],
    "authors": [
      "Dinu Coltuc",
      "Jean-Marc Chassery"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.0808v1",
    "title": "The Cyborg Astrobiologist: Porting from a wearable computer to the\n  Astrobiology Phone-cam",
    "summary": "We have used a simple camera phone to significantly improve an `exploration\nsystem' for astrobiology and geology. This camera phone will make it much\neasier to develop and test computer-vision algorithms for future planetary\nexploration. We envision that the `Astrobiology Phone-cam' exploration system\ncan be fruitfully used in other problem domains as well.",
    "published": "2007-07-05T15:19:37Z",
    "link": "http://arxiv.org/pdf/0707.0808v1.pdf",
    "category": [
      "cs.CV",
      "astro-ph",
      "cs.AI",
      "cs.CE",
      "cs.HC",
      "cs.NI",
      "cs.RO",
      "cs.SE"
    ],
    "authors": [
      "Alexandra Bartolo",
      "Patrick C. McGuire",
      "Kenneth P. Camilleri",
      "Christopher Spiteri",
      "Jonathan C. Borg",
      "Philip J. Farrugia",
      "Jens Ormo",
      "Javier Gomez-Elvira",
      "Jose Antonio Rodriguez-Manfredi",
      "Enrique Diaz-Martinez",
      "Helge Ritter",
      "Robert Haschke",
      "Markus Oesker",
      "Joerg Ontrup"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0708.0927v1",
    "title": "Modeling Visual Information Processing in Brain: A Computer Vision Point\n  of View and Approach",
    "summary": "We live in the Information Age, and information has become a critically\nimportant component of our life. The success of the Internet made huge amounts\nof it easily available and accessible to everyone. To keep the flow of this\ninformation manageable, means for its faultless circulation and effective\nhandling have become urgently required. Considerable research efforts are\ndedicated today to address this necessity, but they are seriously hampered by\nthe lack of a common agreement about \"What is information?\" In particular, what\nis \"visual information\" - human's primary input from the surrounding world. The\nproblem is further aggravated by a long-lasting stance borrowed from the\nbiological vision research that assumes human-like information processing as an\nenigmatic mix of perceptual and cognitive vision faculties. I am trying to find\na remedy for this bizarre situation. Relying on a new definition of\n\"information\", which can be derived from Kolmogorov's compexity theory and\nChaitin's notion of algorithmic information, I propose a unifying framework for\nvisual information processing, which explicitly accounts for the perceptual and\ncognitive image processing peculiarities. I believe that this framework will be\nuseful to overcome the difficulties that are impeding our attempts to develop\nthe right model of human-like intelligent image processing.",
    "published": "2007-08-07T11:16:15Z",
    "link": "http://arxiv.org/pdf/0708.0927v1.pdf",
    "category": [
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Emanuel Diamant"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0708.2438v1",
    "title": "On Ullman's theorem in computer vision",
    "summary": "Both in the plane and in space, we invert the nonlinear Ullman transformation\nfor 3 points and 3 orthographic cameras. While Ullman's theorem assures a\nunique reconstruction modulo a reflection for 3 cameras and 4 points, we find a\nlocally unique reconstruction for 3 cameras and 3 points. Explicit\nreconstruction formulas allow to decide whether picture data of three cameras\nseeing three points can be realized as a point-camera configuration.",
    "published": "2007-08-17T21:36:08Z",
    "link": "http://arxiv.org/pdf/0708.2438v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "I.2.10"
    ],
    "authors": [
      "Oliver Knill",
      "Jose Ramirez-Herran"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0708.2442v1",
    "title": "Space and camera path reconstruction for omni-directional vision",
    "summary": "In this paper, we address the inverse problem of reconstructing a scene as\nwell as the camera motion from the image sequence taken by an omni-directional\ncamera. Our structure from motion results give sharp conditions under which the\nreconstruction is unique. For example, if there are three points in general\nposition and three omni-directional cameras in general position, a unique\nreconstruction is possible up to a similarity. We then look at the\nreconstruction problem with m cameras and n points, where n and m can be large\nand the over-determined system is solved by least square methods. The\nreconstruction is robust and generalizes to the case of a dynamic environment\nwhere landmarks can move during the movie capture. Possible applications of the\nresult are computer assisted scene reconstruction, 3D scanning, autonomous\nrobot navigation, medical tomography and city reconstructions.",
    "published": "2007-08-17T21:53:41Z",
    "link": "http://arxiv.org/pdf/0708.2442v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Oliver Knill",
      "Jose Ramirez-Herran"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0708.2432v1",
    "title": "A structure from motion inequality",
    "summary": "We state an elementary inequality for the structure from motion problem for m\ncameras and n points. This structure from motion inequality relates space\ndimension, camera parameter dimension, the number of cameras and number points\nand global symmetry properties and provides a rigorous criterion for which\nreconstruction is not possible with probability 1. Mathematically the\ninequality is based on Frobenius theorem which is a geometric incarnation of\nthe fundamental theorem of linear algebra. The paper also provides a general\nmathematical formalism for the structure from motion problem. It includes the\nsituation the points can move while the camera takes the pictures.",
    "published": "2007-08-18T14:36:28Z",
    "link": "http://arxiv.org/pdf/0708.2432v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "I.2.10"
    ],
    "authors": [
      "Oliver Knill",
      "Jose Ramirez-Herran"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0708.2974v1",
    "title": "The Fuzzy Vault for fingerprints is Vulnerable to Brute Force Attack",
    "summary": "The \\textit{fuzzy vault} approach is one of the best studied and well\naccepted ideas for binding cryptographic security into biometric\nauthentication. The vault has been implemented in connection with fingerprint\ndata by Uludag and Jain. We show that this instance of the vault is vulnerable\nto brute force attack. An interceptor of the vault data can recover both secret\nand template data using only generally affordable computational resources. Some\npossible alternatives are then discussed and it is suggested that cryptographic\nsecurity may be preferable to the one - way function approach to biometric\nsecurity.",
    "published": "2007-08-22T08:28:02Z",
    "link": "http://arxiv.org/pdf/0708.2974v1.pdf",
    "category": [
      "cs.CV",
      "cs.CR",
      "D.4.6"
    ],
    "authors": [
      "Preda Mihailescu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0709.1771v1",
    "title": "Variational local structure estimation for image super-resolution",
    "summary": "Super-resolution is an important but difficult problem in image/video\nprocessing. If a video sequence or some training set other than the given\nlow-resolution image is available, this kind of extra information can greatly\naid in the reconstruction of the high-resolution image. The problem is\nsubstantially more difficult with only a single low-resolution image on hand.\nThe image reconstruction methods designed primarily for denoising is\ninsufficient for super-resolution problem in the sense that it tends to\noversmooth images with essentially no noise. We propose a new adaptive linear\ninterpolation method based on variational method and inspired by local linear\nembedding (LLE). The experimental result shows that our method avoids the\nproblem of oversmoothing and preserves image structures well.",
    "published": "2007-09-12T08:41:36Z",
    "link": "http://arxiv.org/pdf/0709.1771v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Heng Lian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0709.1920v2",
    "title": "Bandwidth selection for kernel estimation in mixed multi-dimensional\n  spaces",
    "summary": "Kernel estimation techniques, such as mean shift, suffer from one major\ndrawback: the kernel bandwidth selection. The bandwidth can be fixed for all\nthe data set or can vary at each points. Automatic bandwidth selection becomes\na real challenge in case of multidimensional heterogeneous features. This paper\npresents a solution to this problem. It is an extension of \\cite{Comaniciu03a}\nwhich was based on the fundamental property of normal distributions regarding\nthe bias of the normalized density gradient. The selection is done iteratively\nfor each type of features, by looking for the stability of local bandwidth\nestimates across a predefined range of bandwidths. A pseudo balloon mean shift\nfiltering and partitioning are introduced. The validity of the method is\ndemonstrated in the context of color image segmentation based on a\n5-dimensional space.",
    "published": "2007-09-12T16:02:25Z",
    "link": "http://arxiv.org/pdf/0709.1920v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Aurelie Bugeau",
      "Patrick Prez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0709.3013v2",
    "title": "Supervised learning on graphs of spatio-temporal similarity in satellite\n  image sequences",
    "summary": "High resolution satellite image sequences are multidimensional signals\ncomposed of spatio-temporal patterns associated to numerous and various\nphenomena. Bayesian methods have been previously proposed in (Heas and Datcu,\n2005) to code the information contained in satellite image sequences in a graph\nrepresentation using Bayesian methods. Based on such a representation, this\npaper further presents a supervised learning methodology of semantics\nassociated to spatio-temporal patterns occurring in satellite image sequences.\nIt enables the recognition and the probabilistic retrieval of similar events.\nIndeed, graphs are attached to statistical models for spatio-temporal\nprocesses, which at their turn describe physical changes in the observed scene.\nTherefore, we adjust a parametric model evaluating similarity types between\ngraph patterns in order to represent user-specific semantics attached to\nspatio-temporal phenomena. The learning step is performed by the incremental\ndefinition of similarity types via user-provided spatio-temporal pattern\nexamples attached to positive or/and negative semantics. From these examples,\nprobabilities are inferred using a Bayesian network and a Dirichlet model. This\nenables to links user interest to a specific similarity model between graph\npatterns. According to the current state of learning, semantic posterior\nprobabilities are updated for all possible graph patterns so that similar\nspatio-temporal phenomena can be recognized and retrieved from the image\nsequence. Few experiments performed on a multi-spectral SPOT image sequence\nillustrate the proposed spatio-temporal recognition method.",
    "published": "2007-09-19T13:18:18Z",
    "link": "http://arxiv.org/pdf/0709.3013v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Patrick Has",
      "Mihai Datcu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0710.0043v2",
    "title": "Graph rigidity, Cyclic Belief Propagation and Point Pattern Matching",
    "summary": "A recent paper \\cite{CaeCaeSchBar06} proposed a provably optimal, polynomial\ntime method for performing near-isometric point pattern matching by means of\nexact probabilistic inference in a chordal graphical model. Their fundamental\nresult is that the chordal graph in question is shown to be globally rigid,\nimplying that exact inference provides the same matching solution as exact\ninference in a complete graphical model. This implies that the algorithm is\noptimal when there is no noise in the point patterns. In this paper, we present\na new graph which is also globally rigid but has an advantage over the graph\nproposed in \\cite{CaeCaeSchBar06}: its maximal clique size is smaller,\nrendering inference significantly more efficient. However, our graph is not\nchordal and thus standard Junction Tree algorithms cannot be directly applied.\nNevertheless, we show that loopy belief propagation in such a graph converges\nto the optimal solution. This allows us to retain the optimality guarantee in\nthe noiseless case, while substantially reducing both memory requirements and\nprocessing time. Our experimental results show that the accuracy of the\nproposed solution is indistinguishable from that of \\cite{CaeCaeSchBar06} when\nthere is noise in the point patterns.",
    "published": "2007-09-29T06:19:09Z",
    "link": "http://arxiv.org/pdf/0710.0043v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Julian J. McAuley",
      "Tiberio S. Caetano",
      "Marconi S. Barbosa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0710.0243v1",
    "title": "High-Order Nonparametric Belief-Propagation for Fast Image Inpainting",
    "summary": "In this paper, we use belief-propagation techniques to develop fast\nalgorithms for image inpainting. Unlike traditional gradient-based approaches,\nwhich may require many iterations to converge, our techniques achieve\ncompetitive results after only a few iterations. On the other hand, while\nbelief-propagation techniques are often unable to deal with high-order models\ndue to the explosion in the size of messages, we avoid this problem by\napproximating our high-order prior model using a Gaussian mixture. By using\nsuch an approximation, we are able to inpaint images quickly while at the same\ntime retaining good visual results.",
    "published": "2007-10-01T09:18:36Z",
    "link": "http://arxiv.org/pdf/0710.0243v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Julian John McAuley",
      "Tiberio S. Caetano"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0710.0410v1",
    "title": "The Theory of Unified Relativity for a Biovielectroluminescence\n  Phenomenon via Fly's Visual and Imaging System",
    "summary": "The elucidation upon fly's neuronal patterns as a link to computer graphics\nand memory cards I/O's, is investigated for the phenomenon by propounding a\nunified theory of Einstein's two known relativities. It is conclusive that\nflies could contribute a certain amount of neuromatrices indicating an imagery\nfunction of a visual-computational system into computer graphics and storage\nsystems. The visual system involves the time aspect, whereas flies possess\nfaster pulses compared to humans' visual ability due to the E-field state on an\nactive fly's eye surface. This behaviour can be tested on a dissected fly\nspecimen at its ommatidia. Electro-optical contacts and electrodes are wired\nthrough the flesh forming organic emitter layer to stimulate light emission,\nthereby to a computer circuit. The next step is applying a threshold voltage\nwith secondary voltages to the circuit denoting an array of essential\nelectrodes for bit switch. As a result, circuit's dormant pulses versus active\npulses at the specimen's area are recorded. The outcome matrix possesses a\nconstruction of RGB and time radicals expressing the time problem in\nconsumption, allocating time into computational algorithms, enhancing the\ntechnology far beyond. The obtained formulation generates consumed distance\ncons(x), denoting circuital travel between data source/sink for pixel data and\nbendable wavelengths. Once 'image logic' is in place, incorporating this point\nof graphical acceleration permits one to enhance graphics and optimize\nimmensely central processing, data transmissions between memory and computer\nvisual system. The phenomenon can be mainly used in 360-deg. display/viewing,\n3D scanning techniques, military and medicine, a robust and cheap substitution\nfor e.g. pre-motion pattern analysis, real-time rendering and LCDs.",
    "published": "2007-10-01T23:55:50Z",
    "link": "http://arxiv.org/pdf/0710.0410v1.pdf",
    "category": [
      "cs.CE",
      "cs.CV",
      "I.2.10; I.4; I.5; J.0; J.2; J.3"
    ],
    "authors": [
      "Philip B. Alipour"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0710.0736v1",
    "title": "Colour image segmentation by the vector-valued Allen-Cahn phase-field\n  model: a multigrid solution",
    "summary": "We propose a new method for the numerical solution of a PDE-driven model for\ncolour image segmentation and give numerical examples of the results. The\nmethod combines the vector-valued Allen-Cahn phase field equation with initial\ndata fitting terms. This method is known to be closely related to the\nMumford-Shah problem and the level set segmentation by Chan and Vese. Our\nnumerical solution is performed using a multigrid splitting of a finite element\nspace, thereby producing an efficient and robust method for the segmentation of\nlarge images.",
    "published": "2007-10-03T08:51:44Z",
    "link": "http://arxiv.org/pdf/0710.0736v1.pdf",
    "category": [
      "cs.CV",
      "cs.NA",
      "I.4.6; G.1.8"
    ],
    "authors": [
      "David A Kay",
      "Alessandro Tomasi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0710.1870v1",
    "title": "Lossless Representation of Graphs using Distributions",
    "summary": "We consider complete graphs with edge weights and/or node weights taking\nvalues in some set. In the first part of this paper, we show that a large\nnumber of graphs are completely determined, up to isomorphism, by the\ndistribution of their sub-triangles. In the second part, we propose graph\nrepresentations in terms of one-dimensional distributions (e.g., distribution\nof the node weights, sum of adjacent weights, etc.). For the case when the\nweights of the graph are real-valued vectors, we show that all graphs, except\nfor a set of measure zero, are uniquely determined, up to isomorphism, from\nthese distributions. The motivating application for this paper is the problem\nof browsing through large sets of graphs.",
    "published": "2007-10-09T20:01:59Z",
    "link": "http://arxiv.org/pdf/0710.1870v1.pdf",
    "category": [
      "math.CO",
      "cs.CV"
    ],
    "authors": [
      "Mireille Boutin",
      "Gregor Kemper"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0710.2037v2",
    "title": "An Affinity Propagation Based method for Vector Quantization Codebook\n  Design",
    "summary": "In this paper, we firstly modify a parameter in affinity propagation (AP) to\nimprove its convergence ability, and then, we apply it to vector quantization\n(VQ) codebook design problem. In order to improve the quality of the resulted\ncodebook, we combine the improved AP (IAP) with the conventional LBG algorithm\nto generate an effective algorithm call IAP-LBG. According to the experimental\nresults, the proposed method not only enhances the convergence abilities but\nalso is capable of providing higher-quality codebooks than conventional LBG\nmethod.",
    "published": "2007-10-10T15:12:20Z",
    "link": "http://arxiv.org/pdf/0710.2037v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Wu Jiang",
      "Fei Ding",
      "Qiao-liang Xiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0710.2231v1",
    "title": "Comparison and Combination of State-of-the-art Techniques for\n  Handwritten Character Recognition: Topping the MNIST Benchmark",
    "summary": "Although the recognition of isolated handwritten digits has been a research\ntopic for many years, it continues to be of interest for the research community\nand for commercial applications. We show that despite the maturity of the\nfield, different approaches still deliver results that vary enough to allow\nimprovements by using their combination. We do so by choosing four\nwell-motivated state-of-the-art recognition systems for which results on the\nstandard MNIST benchmark are available. When comparing the errors made, we\nobserve that the errors made differ between all four systems, suggesting the\nuse of classifier combination. We then determine the error rate of a\nhypothetical system that combines the output of the four systems. The result\nobtained in this manner is an error rate of 0.35% on the MNIST data, the best\nresult published so far. We furthermore discuss the statistical significance of\nthe combined result and of the results of the individual classifiers.",
    "published": "2007-10-11T12:22:27Z",
    "link": "http://arxiv.org/pdf/0710.2231v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Daniel Keysers"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0710.3185v1",
    "title": "Fuzzy Modeling of Electrical Impedance Tomography Image of the Lungs",
    "summary": "Electrical Impedance Tomography (EIT) is a functional imaging method that is\nbeing developed for bedside use in critical care medicine. Aiming at improving\nthe chest anatomical resolution of EIT images we developed a fuzzy model based\non EIT high temporal resolution and the functional information contained in the\npulmonary perfusion and ventilation signals. EIT data from an experimental\nanimal model were collected during normal ventilation and apnea while an\ninjection of hypertonic saline was used as a reference . The fuzzy model was\nelaborated in three parts: a modeling of the heart, a pulmonary map from\nventilation images and, a pulmonary map from perfusion images. Image\nsegmentation was performed using a threshold method and a ventilation/perfusion\nmap was generated. EIT images treated by the fuzzy model were compared with the\nhypertonic saline injection method and CT-scan images, presenting good results\nin both qualitative (the image obtained by the model was very similar to that\nof the CT-scan) and quantitative (the ROC curve provided an area equal to 0.93)\npoint of view. Undoubtedly, these results represent an important step in the\nEIT images area, since they open the possibility of developing EIT-based\nbedside clinical methods, which are not available nowadays. These achievements\ncould serve as the base to develop EIT diagnosis system for some\nlife-threatening diseases commonly found in critical care medicine.",
    "published": "2007-10-16T22:13:11Z",
    "link": "http://arxiv.org/pdf/0710.3185v1.pdf",
    "category": [
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Harki Tanaka",
      "Neli Regina Siqueira Ortega",
      "Mauricio Stanzione Galizia",
      "Joao Batista Borges Sobrinho",
      "Marcelo Britto Passos Amato"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0710.5002v1",
    "title": "The entropy of keys derived from laser speckle",
    "summary": "Laser speckle has been proposed in a number of papers as a high-entropy\nsource of unpredictable bits for use in security applications. Bit strings\nderived from speckle can be used for a variety of security purposes such as\nidentification, authentication, anti-counterfeiting, secure key storage, random\nnumber generation and tamper protection. The choice of laser speckle as a\nsource of random keys is quite natural, given the chaotic properties of\nspeckle. However, this same chaotic behaviour also causes reproducibility\nproblems. Cryptographic protocols require either zero noise or very low noise\nin their inputs; hence the issue of error rates is critical to applications of\nlaser speckle in cryptography. Most of the literature uses an error reduction\nmethod based on Gabor filtering. Though the method is successful, it has not\nbeen thoroughly analysed.\n  In this paper we present a statistical analysis of Gabor-filtered speckle\npatterns. We introduce a model in which perturbations are described as random\nphase changes in the source plane. Using this model we compute the second and\nfourth order statistics of Gabor coefficients. We determine the mutual\ninformation between perturbed and unperturbed Gabor coefficients and the bit\nerror rate in the derived bit string. The mutual information provides an\nabsolute upper bound on the number of secure bits that can be reproducibly\nextracted from noisy measurements.",
    "published": "2007-10-26T06:56:23Z",
    "link": "http://arxiv.org/pdf/0710.5002v1.pdf",
    "category": [
      "cs.CR",
      "cs.CV"
    ],
    "authors": [
      "B. Skoric"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0710.5547v1",
    "title": "Code Similarity on High Level Programs",
    "summary": "This paper presents a new approach for code similarity on High Level\nprograms. Our technique is based on Fast Dynamic Time Warping, that builds a\nwarp path or points relation with local restrictions. The source code is\nrepresented into Time Series using the operators inside programming languages\nthat makes possible the comparison. This makes possible subsequence detection\nthat represent similar code instructions. In contrast with other code\nsimilarity algorithms, we do not make features extraction. The experiments show\nthat two source codes are similar when their respective Time Series are\nsimilar.",
    "published": "2007-10-29T22:39:21Z",
    "link": "http://arxiv.org/pdf/0710.5547v1.pdf",
    "category": [
      "cs.CV",
      "cs.DS",
      "I.5.2"
    ],
    "authors": [
      "M. Miron Bernal",
      "H. Coyote Estrada",
      "J. Figueroa Nazuno"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0711.0784v1",
    "title": "Addendum to Research MMMCV; A Man/Microbio/Megabio/Computer Vision",
    "summary": "In October 2007, a Research Proposal for the University of Sydney, Australia,\nthe author suggested that biovie-physical phenomenon as `electrodynamic\ndependant biological vision', is governed by relativistic quantum laws and\nbiovision. The phenomenon on the basis of `biovielectroluminescence', satisfies\nman/microbio/megabio/computer vision (MMMCV), as a robust candidate for\nphysical and visual sciences. The general aim of this addendum is to present a\nrefined text of Sections 1-3 of that proposal and highlighting the contents of\nits Appendix in form of a `Mechanisms' Section. We then briefly remind in an\narticle aimed for December 2007, by appending two more equations into Section\n3, a theoretical II-time scenario as a time model well-proposed for the\nphenomenon. The time model within the core of the proposal, plays a significant\nrole in emphasizing the principle points on Objectives no. 1-8, Sub-hypothesis\n3.1.2, mentioned in Article [arXiv:0710.0410]. It also expresses the time\nconcept in terms of causing quantized energy f(|E|) of time |t|, emit in regard\nto shortening the probability of particle loci as predictable patterns of\nparticle's un-occurred motion, a solution to Heisenberg's uncertainty principle\n(HUP) into a simplistic manner. We conclude that, practical frames via a time\nalgorithm to this model, fixates such predictable patterns of motion of scenery\nbodies onto recordable observation points of a MMMCV system. It even\nsuppresses/predicts superposition phenomena coming from a human subject and/or\nother bio-subjects for any decision making event, e.g., brainwave quantum\npatterns based on vision. Maintaining the existential probability of Riemann\nsurfaces of II-time scenarios in the context of biovielectroluminescence, makes\nmotion-prediction a possibility.",
    "published": "2007-11-06T19:41:22Z",
    "link": "http://arxiv.org/pdf/0711.0784v1.pdf",
    "category": [
      "cs.CV",
      "cs.CE",
      "I.2.10; I.4; I.5; J.0; J.2; J.3"
    ],
    "authors": [
      "Philip B. Alipour"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0711.2104v3",
    "title": "On the Information Rates of the Plenoptic Function",
    "summary": "The {\\it plenoptic function} (Adelson and Bergen, 91) describes the visual\ninformation available to an observer at any point in space and time. Samples of\nthe plenoptic function (POF) are seen in video and in general visual content,\nand represent large amounts of information. In this paper we propose a\nstochastic model to study the compression limits of the plenoptic function. In\nthe proposed framework, we isolate the two fundamental sources of information\nin the POF: the one representing the camera motion and the other representing\nthe information complexity of the \"reality\" being acquired and transmitted. The\nsources of information are combined, generating a stochastic process that we\nstudy in detail. We first propose a model for ensembles of realities that do\nnot change over time. The proposed model is simple in that it enables us to\nderive precise coding bounds in the information-theoretic sense that are sharp\nin a number of cases of practical interest. For this simple case of static\nrealities and camera motion, our results indicate that coding practice is in\naccordance with optimal coding from an information-theoretic standpoint. The\nmodel is further extended to account for visual realities that change over\ntime. We derive bounds on the lossless and lossy information rates for this\ndynamic reality model, stating conditions under which the bounds are tight.\nExamples with synthetic sources suggest that in the presence of scene dynamics,\nsimple hybrid coding using motion/displacement estimation with DPCM performs\nconsiderably suboptimally relative to the true rate-distortion bound.",
    "published": "2007-11-14T02:54:22Z",
    "link": "http://arxiv.org/pdf/0711.2104v3.pdf",
    "category": [
      "cs.IT",
      "cs.CV",
      "math.IT",
      "math.PR"
    ],
    "authors": [
      "Arthur Cunha",
      "Minh Do",
      "Martin Vetterli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0711.2914v1",
    "title": "Image Classification Using SVMs: One-against-One Vs One-against-All",
    "summary": "Support Vector Machines (SVMs) are a relatively new supervised classification\ntechnique to the land cover mapping community. They have their roots in\nStatistical Learning Theory and have gained prominence because they are robust,\naccurate and are effective even when using a small training sample. By their\nnature SVMs are essentially binary classifiers, however, they can be adopted to\nhandle the multiple classification tasks common in remote sensing studies. The\ntwo approaches commonly used are the One-Against-One (1A1) and One-Against-All\n(1AA) techniques. In this paper, these approaches are evaluated in as far as\ntheir impact and implication for land cover mapping. The main finding from this\nresearch is that whereas the 1AA technique is more predisposed to yielding\nunclassified and mixed pixels, the resulting classification accuracy is not\nsignificantly different from 1A1 approach. It is the authors conclusion\ntherefore that ultimately the choice of technique adopted boils down to\npersonal preference and the uniqueness of the dataset at hand.",
    "published": "2007-11-19T12:25:00Z",
    "link": "http://arxiv.org/pdf/0711.2914v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Gidudu Anthony",
      "Hulley Gregg",
      "Marwala Tshilidzi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0711.4508v2",
    "title": "Representation and Measure of Structural Information",
    "summary": "We introduce a uniform representation of general objects that captures the\nregularities with respect to their structure. It allows a representation of a\ngeneral class of objects including geometric patterns and images in a sparse,\nmodular, hierarchical, and recursive manner. The representation can exploit any\ncomputable regularity in objects to compactly describe them, while also being\ncapable of representing random objects as raw data. A set of rules uniformly\ndictates the interpretation of the representation into raw signal, which makes\nit possible to ask what pattern a given raw signal contains. Also, it allows\nsimple separation of the information that we wish to ignore from that which we\nmeasure, by using a set of maps to delineate the a priori parts of the objects,\nleaving only the information in the structure.\n  Using the representation, we introduce a measure of information in general\nobjects relative to structures defined by the set of maps. We point out that\nthe common prescription of encoding objects by strings to use Kolmogorov\ncomplexity is meaningless when, as often is the case, the encoding is not\nspecified in any way other than that it exists. Noting this, we define the\nmeasure directly in terms of the structures of the spaces in which the objects\nreside. As a result, the measure is defined relative to a set of maps that\ncharacterize the structures. It turns out that the measure is equivalent to\nKolmogorov complexity when it is defined relative to the maps characterizing\nthe structure of natural numbers. Thus, the formulation gives the larger class\nof objects a meaningful measure of information that generalizes Kolmogorov\ncomplexity.",
    "published": "2007-11-28T18:41:30Z",
    "link": "http://arxiv.org/pdf/0711.4508v2.pdf",
    "category": [
      "cs.CC",
      "cs.CV",
      "cs.IT",
      "math.IT",
      "F.1.1; H.1.1; I.2.10"
    ],
    "authors": [
      "Hiroshi Ishikawa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0712.0131v1",
    "title": "Learning Similarity for Character Recognition and 3D Object Recognition",
    "summary": "I describe an approach to similarity motivated by Bayesian methods. This\nyields a similarity function that is learnable using a standard Bayesian\nmethods. The relationship of the approach to variable kernel and variable\nmetric methods is discussed. The approach is related to variable kernel\nExperimental results on character recognition and 3D object recognition are\npresented..",
    "published": "2007-12-02T10:02:01Z",
    "link": "http://arxiv.org/pdf/0712.0131v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Thomas M. Breuel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0712.0136v1",
    "title": "Learning View Generalization Functions",
    "summary": "Learning object models from views in 3D visual object recognition is usually\nformulated either as a function approximation problem of a function describing\nthe view-manifold of an object, or as that of learning a class-conditional\ndensity. This paper describes an alternative framework for learning in visual\nobject recognition, that of learning the view-generalization function. Using\nthe view-generalization function, an observer can perform Bayes-optimal 3D\nobject recognition given one or more 2D training views directly, without the\nneed for a separate model acquisition step. The paper shows that view\ngeneralization functions can be computationally practical by restating two\nwidely-used methods, the eigenspace and linear combination of views approaches,\nin a view generalization framework. The paper relates the approach to recent\nmethods for object recognition based on non-uniform blurring. The paper\npresents results both on simulated 3D ``paperclip'' objects and real-world\nimages from the COIL-100 database showing that useful view-generalization\nfunctions can be realistically be learned from a comparatively small number of\ntraining examples.",
    "published": "2007-12-02T10:54:40Z",
    "link": "http://arxiv.org/pdf/0712.0136v1.pdf",
    "category": [
      "cs.CV",
      "I.4.8; I.2.10"
    ],
    "authors": [
      "Thomas M. Breuel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0712.0137v1",
    "title": "View Based Methods can achieve Bayes-Optimal 3D Recognition",
    "summary": "This paper proves that visual object recognition systems using only 2D\nEuclidean similarity measurements to compare object views against previously\nseen views can achieve the same recognition performance as observers having\naccess to all coordinate information and able of using arbitrary 3D models\ninternally. Furthermore, it demonstrates that such systems do not require more\ntraining views than Bayes-optimal 3D model-based systems. For building computer\nvision systems, these results imply that using view-based or appearance-based\ntechniques with carefully constructed combination of evidence mechanisms may\nnot be at a disadvantage relative to 3D model-based systems. For computational\napproaches to human vision, they show that it is impossible to distinguish\nview-based and 3D model-based techniques for 3D object recognition solely by\ncomparing the performance achievable by human and 3D model-based systems.}",
    "published": "2007-12-02T11:02:37Z",
    "link": "http://arxiv.org/pdf/0712.0137v1.pdf",
    "category": [
      "cs.CV",
      "I.4.8; I.5"
    ],
    "authors": [
      "Thomas M. Breuel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0712.0932v1",
    "title": "Dimensionality Reduction and Reconstruction using Mirroring Neural\n  Networks and Object Recognition based on Reduced Dimension Characteristic\n  Vector",
    "summary": "In this paper, we present a Mirroring Neural Network architecture to perform\nnon-linear dimensionality reduction and Object Recognition using a reduced\nlowdimensional characteristic vector. In addition to dimensionality reduction,\nthe network also reconstructs (mirrors) the original high-dimensional input\nvector from the reduced low-dimensional data. The Mirroring Neural Network\narchitecture has more number of processing elements (adalines) in the outer\nlayers and the least number of elements in the central layer to form a\nconverging-diverging shape in its configuration. Since this network is able to\nreconstruct the original image from the output of the innermost layer (which\ncontains all the information about the input pattern), these outputs can be\nused as object signature to classify patterns. The network is trained to\nminimize the discrepancy between actual output and the input by back\npropagating the mean squared error from the output layer to the input layer.\nAfter successfully training the network, it can reduce the dimension of input\nvectors and mirror the patterns fed to it. The Mirroring Neural Network\narchitecture gave very good results on various test patterns.",
    "published": "2007-12-06T14:11:07Z",
    "link": "http://arxiv.org/pdf/0712.0932v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.NE"
    ],
    "authors": [
      "Dasika Ratna Deepthi",
      "Sujeet Kuchibhotla",
      "K. Eswaran"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0712.1878v1",
    "title": "Hierarchy construction schemes within the Scale set framework",
    "summary": "Segmentation algorithms based on an energy minimisation framework often\ndepend on a scale parameter which balances a fit to data and a regularising\nterm. Irregular pyramids are defined as a stack of graphs successively reduced.\nWithin this framework, the scale is often defined implicitly as the height in\nthe pyramid. However, each level of an irregular pyramid can not usually be\nreadily associated to the global optimum of an energy or a global criterion on\nthe base level graph. This last drawback is addressed by the scale set\nframework designed by Guigues. The methods designed by this author allow to\nbuild a hierarchy and to design cuts within this hierarchy which globally\nminimise an energy. This paper studies the influence of the construction scheme\nof the initial hierarchy on the resulting optimal cuts. We propose one\nsequential and one parallel method with two variations within both. Our\nsequential methods provide partitions near the global optima while parallel\nmethods require less execution times than the sequential method of Guigues even\non sequential machines.",
    "published": "2007-12-12T07:45:08Z",
    "link": "http://arxiv.org/pdf/0712.1878v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jean Hugues Pruvot",
      "Luc Brun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0712.2870v1",
    "title": "The source coding game with a cheating switcher",
    "summary": "Motivated by the lossy compression of an active-vision video stream, we\nconsider the problem of finding the rate-distortion function of an arbitrarily\nvarying source (AVS) composed of a finite number of subsources with known\ndistributions. Berger's paper `The Source Coding Game', \\emph{IEEE Trans.\nInform. Theory}, 1971, solves this problem under the condition that the\nadversary is allowed only strictly causal access to the subsource realizations.\nWe consider the case when the adversary has access to the subsource\nrealizations non-causally. Using the type-covering lemma, this new\nrate-distortion function is determined to be the maximum of the IID\nrate-distortion function over a set of source distributions attainable by the\nadversary. We then extend the results to allow for partial or noisy\nobservations of subsource realizations. We further explore the model by\nattempting to find the rate-distortion function when the adversary is actually\nhelpful.\n  Finally, a bound is developed on the uniform continuity of the IID\nrate-distortion function for finite-alphabet sources. The bound is used to give\na sufficient number of distributions that need to be sampled to compute the\nrate-distortion function of an AVS to within a certain accuracy. The bound is\nalso used to give a rate of convergence for the estimate of the rate-distortion\nfunction for an unknown IID finite-alphabet source .",
    "published": "2007-12-18T03:31:32Z",
    "link": "http://arxiv.org/pdf/0712.2870v1.pdf",
    "category": [
      "cs.IT",
      "cs.CV",
      "math.IT"
    ],
    "authors": [
      "Hari Palaiyanur",
      "Cheng Chang",
      "Anant Sahai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0712.2923v1",
    "title": "A Class of LULU Operators on Multi-Dimensional Arrays",
    "summary": "The LULU operators for sequences are extended to multi-dimensional arrays via\nthe morphological concept of connection in a way which preserves their\nessential properties, e.g. they are separators and form a four element fully\nordered semi-group. The power of the operators is demonstrated by deriving a\ntotal variation preserving discrete pulse decomposition of images.",
    "published": "2007-12-18T10:43:23Z",
    "link": "http://arxiv.org/pdf/0712.2923v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Roumen Anguelov",
      "Inger Plaskitt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0712.3587v1",
    "title": "Pattern Recognition System Design with Linear Encoding for Discrete\n  Patterns",
    "summary": "In this paper, designs and analyses of compressive recognition systems are\ndiscussed, and also a method of establishing a dual connection between designs\nof good communication codes and designs of recognition systems is presented.\nPattern recognition systems based on compressed patterns and compressed sensor\nmeasurements can be designed using low-density matrices. We examine truncation\nencoding where a subset of the patterns and measurements are stored perfectly\nwhile the rest is discarded. We also examine the use of LDPC parity check\nmatrices for compressing measurements and patterns. We show how more general\nensembles of good linear codes can be used as the basis for pattern recognition\nsystem design, yielding system design strategies for more general noise models.",
    "published": "2007-12-20T22:46:29Z",
    "link": "http://arxiv.org/pdf/0712.3587v1.pdf",
    "category": [
      "cs.IT",
      "cs.CV",
      "math.IT"
    ],
    "authors": [
      "Po-Hsiang Lai",
      "Joseph A. O'Sullivan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0712.4015v1",
    "title": "A Fast Hierarchical Multilevel Image Segmentation Method using Unbiased\n  Estimators",
    "summary": "This paper proposes a novel method for segmentation of images by hierarchical\nmultilevel thresholding. The method is global, agglomerative in nature and\ndisregards pixel locations. It involves the optimization of the ratio of the\nunbiased estimators of within class to between class variances. We obtain a\nrecursive relation at each step for the variances which expedites the process.\nThe efficacy of the method is shown in a comparison with some well-known\nmethods.",
    "published": "2007-12-24T17:11:56Z",
    "link": "http://arxiv.org/pdf/0712.4015v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Sreechakra Goparaju",
      "Jayadev Acharya",
      "Ajoy K. Ray",
      "Jaideva C. Goswami"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0712.4183v1",
    "title": "Probabilistic Visual Secret Sharing Schemes for Gray-scale images and\n  Color images",
    "summary": "Visual secrete sharing (VSS) is an encryption technique that utilizes human\nvisual system in the recovering of the secret image and it does not require any\ncomplex calculation. Pixel expansion has been a major issue of VSS schemes. A\nnumber of probabilistic VSS schemes with minimum pixel expansion have been\nproposed for binary secret images. This paper presents a general probabilistic\n(k, n)-VSS scheme for gray-scale images and another scheme for color images.\nWith our schemes, the pixel expansion can be set to a user-defined value. When\nthis value is 1, there is no pixel expansion at all. The quality of\nreconstructed secret images, measured by Average Relative Difference, is\nequivalent to Relative Difference of existing deterministic schemes. Previous\nprobabilistic VSS schemes for black-and-white images with respect to pixel\nexpansion can be viewed as special cases of the schemes proposed here",
    "published": "2007-12-27T03:27:10Z",
    "link": "http://arxiv.org/pdf/0712.4183v1.pdf",
    "category": [
      "cs.CR",
      "cs.CV"
    ],
    "authors": [
      "Dao-Shun Wang",
      "Feng Yi",
      "Xiaobo Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0801.3654v2",
    "title": "A path following algorithm for the graph matching problem",
    "summary": "We propose a convex-concave programming approach for the labeled weighted\ngraph matching problem. The convex-concave programming formulation is obtained\nby rewriting the weighted graph matching problem as a least-square problem on\nthe set of permutation matrices and relaxing it to two different optimization\nproblems: a quadratic convex and a quadratic concave optimization problem on\nthe set of doubly stochastic matrices. The concave relaxation has the same\nglobal minimum as the initial graph matching problem, but the search for its\nglobal minimum is also a hard combinatorial problem. We therefore construct an\napproximation of the concave problem solution by following a solution path of a\nconvex-concave problem obtained by linear interpolation of the convex and\nconcave formulations, starting from the convex relaxation. This method allows\nto easily integrate the information on graph label similarities into the\noptimization problem, and therefore to perform labeled weighted graph matching.\nThe algorithm is compared with some of the best performing graph matching\nmethods on four datasets: simulated graphs, QAPLib, retina vessel images and\nhandwritten chinese characters. In all cases, the results are competitive with\nthe state-of-the-art.",
    "published": "2008-01-23T20:20:32Z",
    "link": "http://arxiv.org/pdf/0801.3654v2.pdf",
    "category": [
      "cs.CV",
      "cs.DM"
    ],
    "authors": [
      "Mikhail Zaslavskiy",
      "Francis Bach",
      "Jean-Philippe Vert"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0801.4807v1",
    "title": "Automatic Text Area Segmentation in Natural Images",
    "summary": "We present a hierarchical method for segmenting text areas in natural images.\nThe method assumes that the text is written with a contrasting color on a more\nor less uniform background. But no assumption is made regarding the language or\ncharacter set used to write the text. In particular, the text can contain\nsimple graphics or symbols. The key feature of our approach is that we first\nconcentrate on finding the background of the text, before testing whether there\nis actually text on the background. Since uniform areas are easy to find in\nnatural images, and since text backgrounds define areas which contain \"holes\"\n(where the text is written) we thus look for uniform areas containing \"holes\"\nand label them as text backgrounds candidates. Each candidate area is then\nfurther tested for the presence of text within its convex hull. We tested our\nmethod on a database of 65 images including English and Urdu text. The method\ncorrectly segmented all the text areas in 63 of these images, and in only 4 of\nthese were areas that do not contain text also segmented.",
    "published": "2008-01-31T01:46:32Z",
    "link": "http://arxiv.org/pdf/0801.4807v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Syed Ali Raza Jafri",
      "Mireille Boutin",
      "Edward J. Delp"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0802.1258v1",
    "title": "Bayesian Nonlinear Principal Component Analysis Using Random Fields",
    "summary": "We propose a novel model for nonlinear dimension reduction motivated by the\nprobabilistic formulation of principal component analysis. Nonlinearity is\nachieved by specifying different transformation matrices at different locations\nof the latent space and smoothing the transformation using a Markov random\nfield type prior. The computation is made feasible by the recent advances in\nsampling from von Mises-Fisher distributions.",
    "published": "2008-02-09T12:22:47Z",
    "link": "http://arxiv.org/pdf/0802.1258v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Heng Lian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0802.1412v1",
    "title": "Extreme Learning Machine for land cover classification",
    "summary": "This paper explores the potential of extreme learning machine based\nsupervised classification algorithm for land cover classification. In\ncomparison to a backpropagation neural network, which requires setting of\nseveral user-defined parameters and may produce local minima, extreme learning\nmachine require setting of one parameter and produce a unique solution. ETM+\nmultispectral data set (England) was used to judge the suitability of extreme\nlearning machine for remote sensing classifications. A back propagation neural\nnetwork was used to compare its performance in term of classification accuracy\nand computational cost. Results suggest that the extreme learning machine\nperform equally well to back propagation neural network in term of\nclassification accuracy with this data set. The computational cost using\nextreme learning machine is very small in comparison to back propagation neural\nnetwork.",
    "published": "2008-02-11T11:12:06Z",
    "link": "http://arxiv.org/pdf/0802.1412v1.pdf",
    "category": [
      "cs.NE",
      "cs.CV"
    ],
    "authors": [
      "Mahesh Pal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0802.2138v1",
    "title": "Support Vector classifiers for Land Cover Classification",
    "summary": "Support vector machines represent a promising development in machine learning\nresearch that is not widely used within the remote sensing community. This\npaper reports the results of Multispectral(Landsat-7 ETM+) and Hyperspectral\nDAIS)data in which multi-class SVMs are compared with maximum likelihood and\nartificial neural network methods in terms of classification accuracy. Our\nresults show that the SVM achieves a higher level of classification accuracy\nthan either the maximum likelihood or the neural classifier, and that the\nsupport vector machine can be used with small training datasets and\nhigh-dimensional data.",
    "published": "2008-02-15T04:53:33Z",
    "link": "http://arxiv.org/pdf/0802.2138v1.pdf",
    "category": [
      "cs.NE",
      "cs.CV"
    ],
    "authors": [
      "Mahesh Pal",
      "Paul M. Mather"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0802.2411v1",
    "title": "Multiclass Approaches for Support Vector Machine Based Land Cover\n  Classification",
    "summary": "SVMs were initially developed to perform binary classification; though,\napplications of binary classification are very limited. Most of the practical\napplications involve multiclass classification, especially in remote sensing\nland cover classification. A number of methods have been proposed to implement\nSVMs to produce multiclass classification. A number of methods to generate\nmulticlass SVMs from binary SVMs have been proposed by researchers and is still\na continuing research topic. This paper compares the performance of six\nmulti-class approaches to solve classification problem with remote sensing data\nin term of classification accuracy and computational cost. One vs. one, one vs.\nrest, Directed Acyclic Graph (DAG), and Error Corrected Output Coding (ECOC)\nbased multiclass approaches creates many binary classifiers and combines their\nresults to determine the class label of a test pixel. Another catogery of multi\nclass approach modify the binary class objective function and allows\nsimultaneous computation of multiclass classification by solving a single\noptimisation problem. Results from this study conclude the usefulness of One\nvs. One multi class approach in term of accuracy and computational cost over\nother multi class approaches.",
    "published": "2008-02-18T03:47:45Z",
    "link": "http://arxiv.org/pdf/0802.2411v1.pdf",
    "category": [
      "cs.NE",
      "cs.CV"
    ],
    "authors": [
      "Mahesh Pal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0802.3285v1",
    "title": "Some Aspects of Testing Process for Transport Streams in Digital Video\n  Broadcasting",
    "summary": "This paper presents some aspects related to the DVB (Digital Video\nBroadcasting) investigation. The basic aspects of DVB are presented, with an\nemphasis on DVB-T version of standard. The main purpose of this research is to\nanalyze the way that the transmission of the transport streams is realized in\ncase of the Terrestrial Digital Video Broadcasting (DVB-T). To accomplish this,\nfirst, Digital Video Broadcasting standard is presented, and then the main\naspects of DVB testing and analysis of the transport streams are investigated.\nThe paper presents also the results obtained using two programs designed for\nDVB analysis: Mosalina and TSA.",
    "published": "2008-02-22T10:48:44Z",
    "link": "http://arxiv.org/pdf/0802.3285v1.pdf",
    "category": [
      "cs.CV",
      "cs.MM"
    ],
    "authors": [
      "Radu Arsinte",
      "Ciprian Ilioaei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0802.3288v1",
    "title": "Implementing a Test Strategy for an Advanced Video Acquisition and\n  Processing Architecture",
    "summary": "This paper presents some aspects related to test process of an advanced video\nsystem used in remote IP surveillance. The system is based on a Pentium\ncompatible architecture using the industrial standard PC104+. First the overall\narchitecture of the system is presented, involving both hardware or software\naspects. The acquisition board which is developed in a special, nonstandard\narchitecture, is also briefly presented. The main purpose of this research was\nto set a coherent set of procedures in order to test all the aspects of the\nvideo acquisition board. To accomplish this, it was necessary to set-up a\nprocedure in two steps: stand alone video board test (functional test) and an\nin-system test procedure verifying the compatibility with both OS: Linux and\nWindows. The paper presents also the results obtained using this procedure.",
    "published": "2008-02-22T10:54:59Z",
    "link": "http://arxiv.org/pdf/0802.3288v1.pdf",
    "category": [
      "cs.CV",
      "cs.MM"
    ],
    "authors": [
      "Radu Arsinte"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0802.3528v1",
    "title": "Wavelet and Curvelet Moments for Image Classification: Application to\n  Aggregate Mixture Grading",
    "summary": "We show the potential for classifying images of mixtures of aggregate, based\nthemselves on varying, albeit well-defined, sizes and shapes, in order to\nprovide a far more effective approach compared to the classification of\nindividual sizes and shapes. While a dominant (additive, stationary) Gaussian\nnoise component in image data will ensure that wavelet coefficients are of\nGaussian distribution, long tailed distributions (symptomatic, for example, of\nextreme values) may well hold in practice for wavelet coefficients. Energy (2nd\norder moment) has often been used for image characterization for image\ncontent-based retrieval, and higher order moments may be important also, not\nleast for capturing long tailed distributional behavior. In this work, we\nassess 2nd, 3rd and 4th order moments of multiresolution transform -- wavelet\nand curvelet transform -- coefficients as features. As analysis methodology,\ntaking account of image types, multiresolution transforms, and moments of\ncoefficients in the scales or bands, we use correspondence analysis as well as\nk-nearest neighbors supervised classification.",
    "published": "2008-02-24T18:25:51Z",
    "link": "http://arxiv.org/pdf/0802.3528v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Fionn Murtagh",
      "Jean-Luc Starck"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0803.0146v1",
    "title": "Polynomial time algorithms for bi-criteria, multi-objective and ratio\n  problems in clustering and imaging. Part I: Normalized cut and ratio regions",
    "summary": "Partitioning and grouping of similar objects plays a fundamental role in\nimage segmentation and in clustering problems. In such problems a typical goal\nis to group together similar objects, or pixels in the case of image\nprocessing. At the same time another goal is to have each group distinctly\ndissimilar from the rest and possibly to have the group size fairly large.\nThese goals are often combined as a ratio optimization problem. One example of\nsuch problem is the normalized cut problem, another is the ratio regions\nproblem. We devise here the first polynomial time algorithms solving these\nproblems optimally. The algorithms are efficient and combinatorial. This\ncontrasts with the heuristic approaches used in the image segmentation\nliterature that formulate those problems as nonlinear optimization problems,\nwhich are then relaxed and solved with spectral techniques in real numbers.\nThese approaches not only fail to deliver an optimal solution, but they are\nalso computationally expensive. The algorithms presented here use as a\nsubroutine a minimum $s,t-cut procedure on a related graph which is of\npolynomial size. The output consists of the optimal solution to the respective\nratio problem, as well as a sequence of nested solution with respect to any\nrelative weighting of the objectives of the numerator and denominator.\n  An extension of the results here to bi-criteria and multi-criteria objective\nfunctions is presented in part II.",
    "published": "2008-03-02T21:30:58Z",
    "link": "http://arxiv.org/pdf/0803.0146v1.pdf",
    "category": [
      "cs.CV",
      "cs.DM"
    ],
    "authors": [
      "Dorit S. Hochbaum"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0803.0194v1",
    "title": "Acquisition Accuracy Evaluation in Visual Inspection Systems - a\n  Practical Approach",
    "summary": "This paper draws a proposal of a set of parameters and methods for accuracy\nevaluation of visual inspection systems. The case of a monochrome board is\ntreated, but practically all conclusions and methods may be extended for colour\nacquisition. Basically, the proposed parameters are grouped in five sets as\nfollows:Internal noise;Video ADC cuantisation parameters;Analogue processing\nsection parameters;Dominant frequencies;Synchronisation (lock-in) accuracy. On\nbasis of this set of parameters was developed a software environment, in\nconjunction with a test signal generator that allows the \"test\" images. The\npaper also presents conclusions of evaluation for two types of video\nacquisition boards",
    "published": "2008-03-03T08:57:10Z",
    "link": "http://arxiv.org/pdf/0803.0194v1.pdf",
    "category": [
      "cs.CV",
      "cs.MM"
    ],
    "authors": [
      "Radu Arsinte",
      "Costin Miron"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0803.1586v1",
    "title": "Spatio-activity based object detection",
    "summary": "We present the SAMMI lightweight object detection method which has a high\nlevel of accuracy and robustness, and which is able to operate in an\nenvironment with a large number of cameras. Background modeling is based on DCT\ncoefficients provided by cameras. Foreground detection uses similarity in\ntemporal characteristics of adjacent blocks of pixels, which is a\ncomputationally inexpensive way to make use of object coherence. Scene model\nupdating uses the approximated median method for improved performance.\nEvaluation at pixel level and application level shows that SAMMI object\ndetection performs better and faster than the conventional Mixture of Gaussians\nmethod.",
    "published": "2008-03-11T13:40:42Z",
    "link": "http://arxiv.org/pdf/0803.1586v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jarrad Springett",
      "Jeroen Vendrig"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0803.2363v1",
    "title": "lambda-Connectedness Determination for Image Segmentation",
    "summary": "Image segmentation is to separate an image into distinct homogeneous regions\nbelonging to different objects. It is an essential step in image analysis and\ncomputer vision. This paper compares some segmentation technologies and\nattempts to find an automated way to better determine the parameters for image\nsegmentation, especially the connectivity value of $\\lambda$ in\n$\\lambda$-connected segmentation.\n  Based on the theories on the maximum entropy method and Otsu's minimum\nvariance method, we propose:(1)maximum entropy connectedness determination: a\nmethod that uses maximum entropy to determine the best $\\lambda$ value in\n$\\lambda$-connected segmentation, and (2) minimum variance connectedness\ndetermination: a method that uses the principle of minimum variance to\ndetermine $\\lambda$ value. Applying these optimization techniques in real\nimages, the experimental results have shown great promise in the development of\nthe new methods. In the end, we extend the above method to more general case in\norder to compare it with the famous Mumford-Shah method that uses variational\nprinciple and geometric measure.",
    "published": "2008-03-16T17:18:19Z",
    "link": "http://arxiv.org/pdf/0803.2363v1.pdf",
    "category": [
      "cs.CV",
      "cs.DM",
      "I.4.6"
    ],
    "authors": [
      "Li Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0803.2695v1",
    "title": "KohonAnts: A Self-Organizing Ant Algorithm for Clustering and Pattern\n  Classification",
    "summary": "In this paper we introduce a new ant-based method that takes advantage of the\ncooperative self-organization of Ant Colony Systems to create a naturally\ninspired clustering and pattern recognition method. The approach considers each\ndata item as an ant, which moves inside a grid changing the cells it goes\nthrough, in a fashion similar to Kohonen's Self-Organizing Maps. The resulting\nalgorithm is conceptually more simple, takes less free parameters than other\nant-based clustering algorithms, and, after some parameter tuning, yields very\ngood results on some benchmark problems.",
    "published": "2008-03-18T18:27:14Z",
    "link": "http://arxiv.org/pdf/0803.2695v1.pdf",
    "category": [
      "cs.NE",
      "cs.CV"
    ],
    "authors": [
      "C. Fernandes",
      "A. M. Mora",
      "J. J. Merelo",
      "V. Ramos",
      "J. L. J. Laredo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0803.2812v2",
    "title": "Using Spatially Varying Pixels Exposures and Bayer-covered Photosensors\n  for High Dynamic Range Imaging",
    "summary": "The method of a linear high dynamic range imaging using solid-state\nphotosensors with Bayer colour filters array is provided in this paper. Using\ninformation from neighbour pixels, it is possible to reconstruct linear images\nwith wide dynamic range from the oversaturated images. Bayer colour filters\narray is considered as an array of neutral filters in a quasimonochromatic\nlight. If the camera's response function to the desirable light source is known\nthen one can calculate correction coefficients to reconstruct oversaturated\nimages. Reconstructed images are linearized in order to provide a linear high\ndynamic range images for optical-digital imaging systems. The calibration\nprocedure for obtaining the camera's response function to the desired light\nsource is described. Experimental results of the reconstruction of the images\nfrom the oversaturated images are presented for red, green, and blue\nquasimonochromatic light sources. Quantitative analysis of the accuracy of the\nreconstructed images is provided.",
    "published": "2008-03-19T14:55:15Z",
    "link": "http://arxiv.org/pdf/0803.2812v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Mikhail V. Konnik"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.1046v1",
    "title": "Discrete schemes for Gaussian curvature and their convergence",
    "summary": "In this paper, several discrete schemes for Gaussian curvature are surveyed.\nThe convergence property of a modified discrete scheme for the Gaussian\ncurvature is considered. Furthermore, a new discrete scheme for Gaussian\ncurvature is resented. We prove that the new scheme converges at the regular\nvertex with valence not less than 5. By constructing a counterexample, we also\nshow that it is impossible for building a discrete scheme for Gaussian\ncurvature which converges over the regular vertex with valence 4. Finally,\nasymptotic errors of several discrete scheme for Gaussian curvature are\ncompared.",
    "published": "2008-04-07T14:47:03Z",
    "link": "http://arxiv.org/pdf/0804.1046v1.pdf",
    "category": [
      "cs.CV",
      "cs.CG",
      "cs.GR",
      "cs.NA"
    ],
    "authors": [
      "Zhiqiang Xu",
      "Guoliang Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.1448v1",
    "title": "Fast k Nearest Neighbor Search using GPU",
    "summary": "The recent improvements of graphics processing units (GPU) offer to the\ncomputer vision community a powerful processing platform. Indeed, a lot of\nhighly-parallelizable computer vision problems can be significantly accelerated\nusing GPU architecture. Among these algorithms, the k nearest neighbor search\n(KNN) is a well-known problem linked with many applications such as\nclassification, estimation of statistical properties, etc. The main drawback of\nthis task lies in its computation burden, as it grows polynomially with the\ndata size. In this paper, we show that the use of the NVIDIA CUDA API\naccelerates the search for the KNN up to a factor of 120.",
    "published": "2008-04-09T10:06:15Z",
    "link": "http://arxiv.org/pdf/0804.1448v1.pdf",
    "category": [
      "cs.CV",
      "cs.DC"
    ],
    "authors": [
      "Vincent Garcia",
      "Eric Debreuve",
      "Michel Barlaud"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.1982v2",
    "title": "Linear Time Recognition Algorithms for Topological Invariants in 3D",
    "summary": "In this paper, we design linear time algorithms to recognize and determine\ntopological invariants such as the genus and homology groups in 3D. These\nproperties can be used to identify patterns in 3D image recognition. This has\ntremendous amount of applications in 3D medical image analysis. Our method is\nbased on cubical images with direct adjacency, also called (6,26)-connectivity\nimages in discrete geometry. According to the fact that there are only six\ntypes of local surface points in 3D and a discrete version of the well-known\nGauss-Bonnett Theorem in differential geometry, we first determine the genus of\na closed 2D-connected component (a closed digital surface). Then, we use\nAlexander duality to obtain the homology groups of a 3D object in 3D space.",
    "published": "2008-04-12T03:13:33Z",
    "link": "http://arxiv.org/pdf/0804.1982v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Li Chen",
      "Yongwu Rong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.2346v1",
    "title": "Theory and Applications of Two-dimensional, Null-boundary,\n  Nine-Neighborhood, Cellular Automata Linear rules",
    "summary": "This paper deals with the theory and application of 2-Dimensional,\nnine-neighborhood, null- boundary, uniform as well as hybrid Cellular Automata\n(2D CA) linear rules in image processing. These rules are classified into nine\ngroups depending upon the number of neighboring cells influences the cell under\nconsideration. All the Uniform rules have been found to be rendering multiple\ncopies of a given image depending on the groups to which they belong where as\nHybrid rules are also shown to be characterizing the phenomena of zooming in,\nzooming out, thickening and thinning of a given image. Further, using hybrid CA\nrules a new searching algorithm is developed called Sweepers algorithm which is\nfound to be applicable to simulate many inter disciplinary research areas like\nmigration of organisms towards a single point destination, Single Attractor and\nMultiple Attractor Cellular Automata Theory, Pattern Classification and\nClustering Problem, Image compression, Encryption and Decryption problems,\nDensity Classification problem etc.",
    "published": "2008-04-15T10:17:35Z",
    "link": "http://arxiv.org/pdf/0804.2346v1.pdf",
    "category": [
      "cs.DM",
      "cs.CC",
      "cs.CV"
    ],
    "authors": [
      "Pabitra Pal Choudhury",
      "Birendra Kumar Nayak",
      "Sudhakar Sahoo",
      "Sunil Pankaj Rath"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.3234v2",
    "title": "Technical Report - Automatic Contour Extraction from 2D Neuron Images",
    "summary": "This work describes a novel methodology for automatic contour extraction from\n2D images of 3D neurons (e.g. camera lucida images and other types of 2D\nmicroscopy). Most contour-based shape analysis methods can not be used to\ncharacterize such cells because of overlaps between neuronal processes. The\nproposed framework is specifically aimed at the problem of contour following\neven in presence of multiple overlaps. First, the input image is preprocessed\nin order to obtain an 8-connected skeleton with one-pixel-wide branches, as\nwell as a set of critical regions (i.e., bifurcations and crossings). Next, for\neach subtree, the tracking stage iteratively labels all valid pixel of\nbranches, up to a critical region, where it determines the suitable direction\nto proceed. Finally, the labeled skeleton segments are followed in order to\nyield the parametric contour of the neuronal shape under analysis. The reported\nsystem was successfully tested with respect to several images and the results\nfrom a set of three neuron images are presented here, each pertaining to a\ndifferent class, i.e. alpha, delta and epsilon ganglion cells, containing a\ntotal of 34 crossings. The algorithms successfully got across all these\noverlaps. The method has also been found to exhibit robustness even for images\nwith close parallel segments. The proposed method is robust and may be\nimplemented in an efficient manner. The introduction of this approach should\npave the way for more systematic application of contour-based shape analysis\nmethods in neuronal morphology.",
    "published": "2008-04-21T04:03:48Z",
    "link": "http://arxiv.org/pdf/0804.3234v2.pdf",
    "category": [
      "cs.CV",
      "q-bio.NC",
      "I.4.7; I.4.10"
    ],
    "authors": [
      "J. J. G. Leandro",
      "R. M. Cesar Jr",
      "L. da F. Costa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.3361v2",
    "title": "A New Approach to Automated Epileptic Diagnosis Using EEG and\n  Probabilistic Neural Network",
    "summary": "Epilepsy is one of the most common neurological disorders that greatly impair\npatient' daily lives. Traditional epileptic diagnosis relies on tedious visual\nscreening by neurologists from lengthy EEG recording that requires the presence\nof seizure (ictal) activities. Nowadays, there are many systems helping the\nneurologists to quickly find interesting segments of the lengthy signal by\nautomatic seizure detection. However, we notice that it is very difficult, if\nnot impossible, to obtain long-term EEG data with seizure activities for\nepilepsy patients in areas lack of medical resources and trained neurologists.\nTherefore, we propose to study automated epileptic diagnosis using interictal\nEEG data that is much easier to collect than ictal data. The authors are not\naware of any report on automated EEG diagnostic system that can accurately\ndistinguish patients' interictal EEG from the EEG of normal people. The\nresearch presented in this paper, therefore, aims to develop an automated\ndiagnostic system that can use interictal EEG data to diagnose whether the\nperson is epileptic. Such a system should also detect seizure activities for\nfurther investigation by doctors and potential patient monitoring. To develop\nsuch a system, we extract four classes of features from the EEG data and build\na Probabilistic Neural Network (PNN) fed with these features. Leave-one-out\ncross-validation (LOO-CV) on a widely used epileptic-normal data set reflects\nan impressive 99.5% accuracy of our system on distinguishing normal people's\nEEG from patient's interictal EEG. We also find our system can be used in\npatient monitoring (seizure detection) and seizure focus localization, with\n96.7% and 77.5% accuracy respectively on the data set.",
    "published": "2008-04-21T17:07:59Z",
    "link": "http://arxiv.org/pdf/0804.3361v2.pdf",
    "category": [
      "cs.AI",
      "cs.CV",
      "I.5.4; I.2.1"
    ],
    "authors": [
      "Forrest Sheng Bao",
      "Donald Yu-Chun Lie",
      "Yuanlin Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.3500v1",
    "title": "Natural pseudo-distance and optimal matching between reduced size\n  functions",
    "summary": "This paper studies the properties of a new lower bound for the natural\npseudo-distance. The natural pseudo-distance is a dissimilarity measure between\nshapes, where a shape is viewed as a topological space endowed with a\nreal-valued continuous function. Measuring dissimilarity amounts to minimizing\nthe change in the functions due to the application of homeomorphisms between\ntopological spaces, with respect to the $L_\\infty$-norm. In order to obtain the\nlower bound, a suitable metric between size functions, called matching\ndistance, is introduced. It compares size functions by solving an optimal\nmatching problem between countable point sets. The matching distance is shown\nto be resistant to perturbations, implying that it is always smaller than the\nnatural pseudo-distance. We also prove that the lower bound so obtained is\nsharp and cannot be improved by any other distance between size functions.",
    "published": "2008-04-22T11:25:11Z",
    "link": "http://arxiv.org/pdf/0804.3500v1.pdf",
    "category": [
      "cs.CG",
      "cs.CV"
    ],
    "authors": [
      "M. d'Amico",
      "P. Frosini",
      "C. Landi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0805.1854v2",
    "title": "A New Algorithm for Interactive Structural Image Segmentation",
    "summary": "This paper proposes a novel algorithm for the problem of structural image\nsegmentation through an interactive model-based approach. Interaction is\nexpressed in the model creation, which is done according to user traces drawn\nover a given input image. Both model and input are then represented by means of\nattributed relational graphs derived on the fly. Appearance features are taken\ninto account as object attributes and structural properties are expressed as\nrelational attributes. To cope with possible topological differences between\nboth graphs, a new structure called the deformation graph is introduced. The\nsegmentation process corresponds to finding a labelling of the input graph that\nminimizes the deformations introduced in the model when it is updated with\ninput information. This approach has shown to be faster than other segmentation\nmethods, with competitive output quality. Therefore, the method solves the\nproblem of multiple label segmentation in an efficient way. Encouraging results\non both natural and target-specific color images, as well as examples showing\nthe reusability of the model, are presented and discussed.",
    "published": "2008-05-13T13:39:19Z",
    "link": "http://arxiv.org/pdf/0805.1854v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Alexandre Noma",
      "Ana B. V. Graciano",
      "Luis Augusto Consularo",
      "Roberto M. Cesar-Jr",
      "Isabelle Bloch"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0805.2324v1",
    "title": "A multilateral filtering method applied to airplane runway image",
    "summary": "By considering the features of the airport runway image filtering, an\nimproved bilateral filtering method was proposed which can remove noise with\nedge preserving. Firstly the steerable filtering decomposition is used to\ncalculate the sub-band parameters of 4 orients, and the texture feature matrix\nis then obtained from the sub-band local median energy. The texture similar,\nthe spatial closer and the color similar functions are used to filter the\nimage.The effect of the weighting function parameters is qualitatively analyzed\nalso. In contrast with the standard bilateral filter and the simulation results\nfor the real airport runway image show that the multilateral filtering is more\neffective than the standard bilateral filtering.",
    "published": "2008-05-15T13:15:08Z",
    "link": "http://arxiv.org/pdf/0805.2324v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhang Yu",
      "Shi Zhong-ke",
      "Wang Run-quan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0805.2690v1",
    "title": "Increasing Linear Dynamic Range of Commercial Digital Photocamera Used\n  in Imaging Systems with Optical Coding",
    "summary": "Methods of increasing linear optical dynamic range of commercial photocamera\nfor optical-digital imaging systems are described. Use of such methods allows\nto use commercial photocameras for optical measurements. Experimental results\nare reported.",
    "published": "2008-05-17T17:15:26Z",
    "link": "http://arxiv.org/pdf/0805.2690v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "M. V. Konnik",
      "E. A. Manykin",
      "S. N. Starikov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0805.3217v1",
    "title": "Statistical region-based active contours with exponential family\n  observations",
    "summary": "In this paper, we focus on statistical region-based active contour models\nwhere image features (e.g. intensity) are random variables whose distribution\nbelongs to some parametric family (e.g. exponential) rather than confining\nourselves to the special Gaussian case. Using shape derivation tools, our\neffort focuses on constructing a general expression for the derivative of the\nenergy (with respect to a domain) and derive the corresponding evolution speed.\nA general result is stated within the framework of multi-parameter exponential\nfamily. More particularly, when using Maximum Likelihood estimators, the\nevolution speed has a closed-form expression that depends simply on the\nprobability density function, while complicating additive terms appear when\nusing other estimators, e.g. moments method. Experimental results on both\nsynthesized and real images demonstrate the applicability of our approach.",
    "published": "2008-05-21T07:54:07Z",
    "link": "http://arxiv.org/pdf/0805.3217v1.pdf",
    "category": [
      "cs.CV",
      "I.4.6"
    ],
    "authors": [
      "Franois Lecellier",
      "Stphanie Jehan-Besson",
      "Jalal Fadili",
      "Gilles Aubert",
      "Marinette Revenu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0805.3218v1",
    "title": "Region-based active contour with noise and shape priors",
    "summary": "In this paper, we propose to combine formally noise and shape priors in\nregion-based active contours. On the one hand, we use the general framework of\nexponential family as a prior model for noise. On the other hand, translation\nand scale invariant Legendre moments are considered to incorporate the shape\nprior (e.g. fidelity to a reference shape). The combination of the two prior\nterms in the active contour functional yields the final evolution equation\nwhose evolution speed is rigorously derived using shape derivative tools.\nExperimental results on both synthetic images and real life cardiac echography\ndata clearly demonstrate the robustness to initialization and noise,\nflexibility and large potential applicability of our segmentation algorithm.",
    "published": "2008-05-21T08:06:01Z",
    "link": "http://arxiv.org/pdf/0805.3218v1.pdf",
    "category": [
      "cs.CV",
      "I.4.6"
    ],
    "authors": [
      "Franois Lecellier",
      "Stphanie Jehan-Besson",
      "Jalal Fadili",
      "Gilles Aubert",
      "Marinette Revenu",
      "Eric Saloux"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0805.3964v2",
    "title": "DimReduction - Interactive Graphic Environment for Dimensionality\n  Reduction",
    "summary": "Feature selection is a pattern recognition approach to choose important\nvariables according to some criteria to distinguish or explain certain\nphenomena. There are many genomic and proteomic applications which rely on\nfeature selection to answer questions such as: selecting signature genes which\nare informative about some biological state, e.g. normal tissues and several\ntypes of cancer; or defining a network of prediction or inference among\nelements such as genes, proteins, external stimuli and other elements of\ninterest. In these applications, a recurrent problem is the lack of samples to\nperform an adequate estimate of the joint probabilities between element states.\nA myriad of feature selection algorithms and criterion functions are proposed,\nalthough it is difficult to point the best solution in general. The intent of\nthis work is to provide an open-source multiplataform graphical environment to\napply, test and compare many feature selection approaches suitable to be used\nin bioinformatics problems.",
    "published": "2008-05-26T14:16:06Z",
    "link": "http://arxiv.org/pdf/0805.3964v2.pdf",
    "category": [
      "cs.CV",
      "I.5.2"
    ],
    "authors": [
      "Fabricio Martins Lopes",
      "David Correa Martins-Jr",
      "Roberto M. Cesar-Jr"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0806.0689v1",
    "title": "Directional Cross Diamond Search Algorithm for Fast Block Motion\n  Estimation",
    "summary": "In block-matching motion estimation (BMME), the search patterns have a\nsignificant impact on the algorithm's performance, both the search speed and\nthe search quality. The search pattern should be designed to fit the motion\nvector probability (MVP) distribution characteristics of the real-world\nsequences. In this paper, we build a directional model of MVP distribution to\ndescribe the directional-center-biased characteristic of the MVP distribution\nand the directional characteristics of the conditional MVP distribution more\nexactly based on the detailed statistical data of motion vectors of eighteen\npopular sequences. Three directional search patterns are firstly designed by\nutilizing the directional characteristics and they are the smallest search\npatterns among the popular ones. A new algorithm is proposed using the\nhorizontal cross search pattern as the initial step and the horizontal/vertical\ndiamond search pattern as the subsequent step for the fast BMME, which is\ncalled the directional cross diamond search (DCDS) algorithm. The DCDS\nalgorithm can obtain the motion vector with fewer search points than CDS, DS or\nHEXBS while maintaining the similar or even better search quality. The gain on\nspeedup of DCDS over CDS or DS can be up to 54.9%. The simulation results show\nthat DCDS is efficient, effective and robust, and it can always give the faster\nsearch speed on different sequences than other fast block-matching algorithm in\ncommon use.",
    "published": "2008-06-04T05:05:19Z",
    "link": "http://arxiv.org/pdf/0806.0689v1.pdf",
    "category": [
      "cs.CV",
      "I.4.2"
    ],
    "authors": [
      "Hongjun Jia",
      "Li Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0806.0870v1",
    "title": "The Euler-Poincare theory of Metamorphosis",
    "summary": "In the pattern matching approach to imaging science, the process of\n``metamorphosis'' is template matching with dynamical templates. Here, we\nrecast the metamorphosis equations of into the Euler-Poincare variational\nframework of and show that the metamorphosis equations contain the equations\nfor a perfect complex fluid \\cite{Ho2002}. This result connects the ideas\nunderlying the process of metamorphosis in image matching to the physical\nconcept of order parameter in the theory of complex fluids. After developing\nthe general theory, we reinterpret various examples, including point set, image\nand density metamorphosis. We finally discuss the issue of matching measures\nwith metamorphosis, for which we provide existence theorems for the initial and\nboundary value problems.",
    "published": "2008-06-04T22:58:41Z",
    "link": "http://arxiv.org/pdf/0806.0870v1.pdf",
    "category": [
      "cs.CV",
      "nlin.CD"
    ],
    "authors": [
      "Darryl D. Holm",
      "Alain Trouve",
      "Laurent Younes"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0806.0899v1",
    "title": "A Nonparametric Approach to 3D Shape Analysis from Digital Camera Images\n  - I. in Memory of W.P. Dayawansa",
    "summary": "In this article, for the first time, one develops a nonparametric methodology\nfor an analysis of shapes of configurations of landmarks on real 3D objects\nfrom regular camera photographs, thus making 3D shape analysis very accessible.\nA fundamental result in computer vision by Faugeras (1992), Hartley, Gupta and\nChang (1992) is that generically, a finite 3D configuration of points can be\nretrieved up to a projective transformation, from corresponding configurations\nin a pair of camera images. Consequently, the projective shape of a 3D\nconfiguration can be retrieved from two of its planar views. Given the inherent\nregistration errors, the 3D projective shape can be estimated from a sample of\nphotos of the scene containing that configuration. Projective shapes are here\nregarded as points on projective shape manifolds. Using large sample and\nnonparametric bootstrap methodology for extrinsic means on manifolds, one gives\nconfidence regions and tests for the mean projective shape of a 3D\nconfiguration from its 2D camera images.",
    "published": "2008-06-05T04:26:49Z",
    "link": "http://arxiv.org/pdf/0806.0899v1.pdf",
    "category": [
      "stat.ME",
      "cs.CV",
      "math.ST",
      "stat.TH"
    ],
    "authors": [
      "V. Patrangenaru",
      "X. Liu",
      "S. Sugathadasa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0806.1446v1",
    "title": "Fast Wavelet-Based Visual Classification",
    "summary": "We investigate a biologically motivated approach to fast visual\nclassification, directly inspired by the recent work of Serre et al.\nSpecifically, trading-off biological accuracy for computational efficiency, we\nexplore using wavelet and grouplet-like transforms to parallel the tuning of\nvisual cortex V1 and V2 cells, alternated with max operations to achieve scale\nand translation invariance. A feature selection procedure is applied during\nlearning to accelerate recognition. We introduce a simple attention-like\nfeedback mechanism, significantly improving recognition and robustness in\nmultiple-object scenes. In experiments, the proposed algorithm achieves or\nexceeds state-of-the-art success rate on object recognition, texture and\nsatellite image classification, language identification and sound\nclassification.",
    "published": "2008-06-08T10:15:04Z",
    "link": "http://arxiv.org/pdf/0806.1446v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Guoshen Yu",
      "Jean-Jacques Slotine"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0806.1796v1",
    "title": "Evaluation for Uncertain Image Classification and Segmentation",
    "summary": "Each year, numerous segmentation and classification algorithms are invented\nor reused to solve problems where machine vision is needed. Generally, the\nefficiency of these algorithms is compared against the results given by one or\nmany human experts. However, in many situations, the location of the real\nboundaries of the objects as well as their classes are not known with certainty\nby the human experts. Furthermore, only one aspect of the segmentation and\nclassification problem is generally evaluated. In this paper we present a new\nevaluation method for classification and segmentation of image, where we take\ninto account both the classification and segmentation results as well as the\nlevel of certainty given by the experts. As a concrete example of our method,\nwe evaluate an automatic seabed characterization algorithm based on sonar\nimages.",
    "published": "2008-06-11T07:02:45Z",
    "link": "http://arxiv.org/pdf/0806.1796v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "I.4; I.5"
    ],
    "authors": [
      "Arnaud Martin",
      "Hicham Laanaya",
      "Andreas Arnold-Bos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0806.1798v1",
    "title": "Human expert fusion for image classification",
    "summary": "In image classification, merging the opinion of several human experts is very\nimportant for different tasks such as the evaluation or the training. Indeed,\nthe ground truth is rarely known before the scene imaging. We propose here\ndifferent models in order to fuse the informations given by two or more\nexperts. The considered unit for the classification, a small tile of the image,\ncan contain one or more kind of the considered classes given by the experts. A\nsecond problem that we have to take into account, is the amount of certainty of\nthe expert has for each pixel of the tile. In order to solve these problems we\ndefine five models in the context of the Dempster-Shafer Theory and in the\ncontext of the Dezert-Smarandache Theory and we study the possible decisions\nwith these models.",
    "published": "2008-06-11T07:09:15Z",
    "link": "http://arxiv.org/pdf/0806.1798v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "I.4; I.5"
    ],
    "authors": [
      "Arnaud Martin",
      "Christophe Osswald"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0806.1984v1",
    "title": "Classification of curves in 2D and 3D via affine integral signatures",
    "summary": "We propose a robust classification algorithm for curves in 2D and 3D, under\nthe special and full groups of affine transformations. To each plane or spatial\ncurve we assign a plane signature curve. Curves, equivalent under an affine\ntransformation, have the same signature. The signatures introduced in this\npaper are based on integral invariants, which behave much better on noisy\nimages than classically known differential invariants. The comparison with\nother types of invariants is given in the introduction. Though the integral\ninvariants for planar curves were known before, the affine integral invariants\nfor spatial curves are proposed here for the first time. Using the inductive\nvariation of the moving frame method we compute affine invariants in terms of\nEuclidean invariants. We present two types of signatures, the global signature\nand the local signature. Both signatures are independent of parameterization\n(curve sampling). The global signature depends on the choice of the initial\npoint and does not allow us to compare fragments of curves, and is therefore\nsensitive to occlusions. The local signature, although is slightly more\nsensitive to noise, is independent of the choice of the initial point and is\nnot sensitive to occlusions in an image. It helps establish local equivalence\nof curves. The robustness of these invariants and signatures in their\napplication to the problem of classification of noisy spatial curves extracted\nfrom a 3D object is analyzed.",
    "published": "2008-06-12T01:12:25Z",
    "link": "http://arxiv.org/pdf/0806.1984v1.pdf",
    "category": [
      "cs.CV",
      "I.4"
    ],
    "authors": [
      "S. Feng",
      "I. A. Kogan",
      "H. Krim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0806.2006v2",
    "title": "Fusion de classifieurs pour la classification d'images sonar",
    "summary": "In this paper, we present some high level information fusion approaches for\nnumeric and symbolic data. We study the interest of such method particularly\nfor classifier fusion. A comparative study is made in a context of sea bed\ncharacterization from sonar images. The classi- fication of kind of sediment is\na difficult problem because of the data complexity. We compare high level\ninformation fusion and give the obtained performance.",
    "published": "2008-06-12T06:42:07Z",
    "link": "http://arxiv.org/pdf/0806.2006v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Arnaud Martin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0806.2007v1",
    "title": "Experts Fusion and Multilayer Perceptron Based on Belief Learning for\n  Sonar Image Classification",
    "summary": "The sonar images provide a rapid view of the seabed in order to characterize\nit. However, in such as uncertain environment, real seabed is unknown and the\nonly information we can obtain, is the interpretation of different human\nexperts, sometimes in conflict. In this paper, we propose to manage this\nconflict in order to provide a robust reality for the learning step of\nclassification algorithms. The classification is conducted by a multilayer\nperceptron, taking into account the uncertainty of the reality in the learning\nstage. The results of this seabed characterization are presented on real sonar\nimages.",
    "published": "2008-06-12T06:44:55Z",
    "link": "http://arxiv.org/pdf/0806.2007v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "I.4; I.5"
    ],
    "authors": [
      "Arnaud Martin",
      "Christophe Osswald"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0806.2008v1",
    "title": "Generalized proportional conflict redistribution rule applied to Sonar\n  imagery and Radar targets classification",
    "summary": "In this chapter, we present two applications in information fusion in order\nto evaluate the generalized proportional conflict redistribution rule presented\nin the chapter \\cite{Martin06a}. Most of the time the combination rules are\nevaluated only on simple examples. We study here different combination rules\nand compare them in terms of decision on real data. Indeed, in real\napplications, we need a reliable decision and it is the final results that\nmatter. Two applications are presented here: a fusion of human experts opinions\non the kind of underwater sediments depict on sonar image and a classifier\nfusion for radar targets recognition.",
    "published": "2008-06-12T06:47:26Z",
    "link": "http://arxiv.org/pdf/0806.2008v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "I.4; I.5"
    ],
    "authors": [
      "Arnaud Martin",
      "Christophe Osswald"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0806.2890v1",
    "title": "Learning Graph Matching",
    "summary": "As a fundamental problem in pattern recognition, graph matching has\napplications in a variety of fields, from computer vision to computational\nbiology. In graph matching, patterns are modeled as graphs and pattern\nrecognition amounts to finding a correspondence between the nodes of different\ngraphs. Many formulations of this problem can be cast in general as a quadratic\nassignment problem, where a linear term in the objective function encodes node\ncompatibility and a quadratic term encodes edge compatibility. The main\nresearch focus in this theme is about designing efficient algorithms for\napproximately solving the quadratic assignment problem, since it is NP-hard. In\nthis paper we turn our attention to a different question: how to estimate\ncompatibility functions such that the solution of the resulting graph matching\nproblem best matches the expected solution that a human would manually provide.\nWe present a method for learning graph matching: the training examples are\npairs of graphs and the `labels' are matches between them. Our experimental\nresults reveal that learning can substantially improve the performance of\nstandard graph matching algorithms. In particular, we find that simple linear\nassignment with such a learning scheme outperforms Graduated Assignment with\nbistochastic normalisation, a state-of-the-art quadratic assignment relaxation\nalgorithm.",
    "published": "2008-06-17T23:28:08Z",
    "link": "http://arxiv.org/pdf/0806.2890v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Tiberio S. Caetano",
      "Julian J. McAuley",
      "Li Cheng",
      "Quoc V. Le",
      "Alex J. Smola"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0806.3887v1",
    "title": "Conceptualization of seeded region growing by pixels aggregation. Part\n  2: how to localize a final partition invariant about the seeded region\n  initialisation order",
    "summary": "In the previous paper, we have conceptualized the localization and the\norganization of seeded region growing by pixels aggregation (SRGPA) but we do\nnot give the issue when there is a collision between two distinct regions\nduring the growing process. In this paper, we propose two implementations to\nmanage two classical growing processes: one without a boundary region region to\ndivide the other regions and another with. Unfortunately, as noticed by Mehnert\nand Jakway (1997), this partition depends on the seeded region initialisation\norder (SRIO). We propose a growing process, invariant about SRIO such as the\nboundary region is the set of ambiguous pixels.",
    "published": "2008-06-24T13:34:15Z",
    "link": "http://arxiv.org/pdf/0806.3887v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Vincent Tariel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0806.3885v1",
    "title": "Conceptualization of seeded region growing by pixels aggregation. Part\n  1: the framework",
    "summary": "Adams and Bishop have proposed in 1994 a novel region growing algorithm\ncalled seeded region growing by pixels aggregation (SRGPA). This paper\nintroduces a framework to implement an algorithm using SRGPA. This framework is\nbuilt around two concepts: localization and organization of applied action.\nThis conceptualization gives a quick implementation of algorithms, a direct\ntranslation between the mathematical idea and the numerical implementation, and\nan improvement of algorithms efficiency.",
    "published": "2008-06-24T13:43:06Z",
    "link": "http://arxiv.org/pdf/0806.3885v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Vincent Tariel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0806.3928v1",
    "title": "Conceptualization of seeded region growing by pixels aggregation. Part\n  3: a wide range of algorithms",
    "summary": "In the two previous papers of this serie, we have created a library, called\nPopulation, dedicated to seeded region growing by pixels aggregation and we\nhave proposed different growing processes to get a partition with or without a\nboundary region to divide the other regions or to get a partition invariant\nabout the seeded region initialisation order. Using this work, we implement\nsome algorithms belonging to the field of SRGPA using this library and these\ngrowing processes.",
    "published": "2008-06-24T17:02:47Z",
    "link": "http://arxiv.org/pdf/0806.3928v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Vincent Tariel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0806.3939v2",
    "title": "Conceptualization of seeded region growing by pixels aggregation. Part\n  4: Simple, generic and robust extraction of grains in granular materials\n  obtained by X-ray tomography",
    "summary": "This paper proposes a simple, generic and robust method to extract the grains\nfrom experimental tridimensionnal images of granular materials obtained by\nX-ray tomography. This extraction has two steps: segmentation and splitting.\nFor the segmentation step, if there is a sufficient contrast between the\ndifferent components, a classical threshold procedure followed by a succession\nof morphological filters can be applied. If not, and if the boundary needs to\nbe localized precisely, a watershed transformation controlled by labels is\napplied. The basement of this transformation is to localize a label included in\nthe component and another label in the component complementary. A \"soft\"\nthreshold following by an opening is applied on the initial image to localize a\nlabel in a component. For any segmentation procedure, the visualisation shows a\nproblem: some groups of two grains, close one to each other, become connected.\nSo if a classical cluster procedure is applied on the segmented binary image,\nthese numerical connected grains are considered as a single grain. To overcome\nthis problem, we applied a procedure introduced by L. Vincent in 1993. This\ngrains extraction is tested for various complexes porous media and granular\nmaterial, to predict various properties (diffusion, electrical conductivity,\ndeformation field) in a good agreement with experiment data.",
    "published": "2008-06-24T17:40:25Z",
    "link": "http://arxiv.org/pdf/0806.3939v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Vincent Tariel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0807.2043v1",
    "title": "Intrusion Detection Using Cost-Sensitive Classification",
    "summary": "Intrusion Detection is an invaluable part of computer networks defense. An\nimportant consideration is the fact that raising false alarms carries a\nsignificantly lower cost than not detecting at- tacks. For this reason, we\nexamine how cost-sensitive classification methods can be used in Intrusion\nDetection systems. The performance of the approach is evaluated under different\nexperimental conditions, cost matrices and different classification models, in\nterms of expected cost, as well as detection and false alarm rates. We find\nthat even under unfavourable conditions, cost-sensitive classification can\nimprove performance significantly, if only slightly.",
    "published": "2008-07-13T16:54:13Z",
    "link": "http://arxiv.org/pdf/0807.2043v1.pdf",
    "category": [
      "cs.CR",
      "cs.CV",
      "cs.NI"
    ],
    "authors": [
      "Aikaterini Mitrokotsa",
      "Christos Dimitrakakis",
      "Christos Douligeris"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0807.2047v3",
    "title": "The Five Points Pose Problem : A New and Accurate Solution Adapted to\n  any Geometric Configuration",
    "summary": "The goal of this paper is to estimate directly the rotation and translation\nbetween two stereoscopic images with the help of five homologous points. The\nmethodology presented does not mix the rotation and translation parameters,\nwhich is comparably an important advantage over the methods using the\nwell-known essential matrix. This results in correct behavior and accuracy for\nsituations otherwise known as quite unfavorable, such as planar scenes, or\npanoramic sets of images (with a null base length), while providing quite\ncomparable results for more \"standard\" cases. The resolution of the algebraic\npolynomials resulting from the modeling of the coplanarity constraint is made\nwith the help of powerful algebraic solver tools (the Groebner bases and the\nRational Univariate Representation).",
    "published": "2008-07-13T18:37:06Z",
    "link": "http://arxiv.org/pdf/0807.2047v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Mahzad Kalantari",
      "Franck Jung",
      "JeanPierre Guedon",
      "Nicolas Paparoditis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0807.2928v1",
    "title": "Visual Grouping by Neural Oscillators",
    "summary": "Distributed synchronization is known to occur at several scales in the brain,\nand has been suggested as playing a key functional role in perceptual grouping.\nState-of-the-art visual grouping algorithms, however, seem to give\ncomparatively little attention to neural synchronization analogies. Based on\nthe framework of concurrent synchronization of dynamic systems, simple networks\nof neural oscillators coupled with diffusive connections are proposed to solve\nvisual grouping problems. Multi-layer algorithms and feedback mechanisms are\nalso studied. The same algorithm is shown to achieve promising results on\nseveral classical visual grouping problems, including point clustering, contour\nintegration and image segmentation.",
    "published": "2008-07-18T11:23:27Z",
    "link": "http://arxiv.org/pdf/0807.2928v1.pdf",
    "category": [
      "cs.CV",
      "cs.NE"
    ],
    "authors": [
      "Guoshen Yu",
      "Jean-Jacques Slotine"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0807.4478v1",
    "title": "An Image-Based Sensor System for Autonomous Rendez-Vous with\n  Uncooperative Satellites",
    "summary": "In this paper are described the image processing algorithms developed by\nSENER, Ingenieria y Sistemas to cope with the problem of image-based,\nautonomous rendez-vous (RV) with an orbiting satellite. The methods developed\nhave a direct application in the OLEV (Orbital Life Extension Extension\nVehicle) mission. OLEV is a commercial mission under development by a\nconsortium formed by Swedish Space Corporation, Kayser-Threde and SENER, aimed\nto extend the operational life of geostationary telecommunication satellites by\nsupplying them control, navigation and guidance services. OLEV is planned to\nuse a set of cameras to determine the angular position and distance to the\nclient satellite during the complete phases of rendez-vous and docking, thus\nenabling the operation with satellites not equipped with any specific\nnavigational aid to provide support during the approach. The ability to operate\nwith un-equipped client satellites significantly expands the range of\napplicability of the system under development, compared to other competing\nvideo technologies already tested in previous spatial missions, such as the\nones described here below.",
    "published": "2008-07-28T15:46:02Z",
    "link": "http://arxiv.org/pdf/0807.4478v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "I.4.3; I.4.8"
    ],
    "authors": [
      "Carlos Miravet",
      "Luis Pascual",
      "Eloise Krouch",
      "Juan Manuel del Cura"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0807.4701v1",
    "title": "An image processing analysis of skin textures",
    "summary": "Colour and coarseness of skin are visually different. When image processing\nis involved in the skin analysis, it is important to quantitatively evaluate\nsuch differences using texture features. In this paper, we discuss a texture\nanalysis and measurements based on a statistical approach to the pattern\nrecognition. Grain size and anisotropy are evaluated with proper diagrams. The\npossibility to determine the presence of pattern defects is also discussed.",
    "published": "2008-07-29T16:28:44Z",
    "link": "http://arxiv.org/pdf/0807.4701v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "A. Sparavigna",
      "R. Marazzato"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0808.0056v1",
    "title": "I'm sorry to say, but your understanding of image processing\n  fundamentals is absolutely wrong",
    "summary": "The ongoing discussion whether modern vision systems have to be viewed as\nvisually-enabled cognitive systems or cognitively-enabled vision systems is\ngroundless, because perceptual and cognitive faculties of vision are separate\ncomponents of human (and consequently, artificial) information processing\nsystem modeling.",
    "published": "2008-08-01T04:45:17Z",
    "link": "http://arxiv.org/pdf/0808.0056v1.pdf",
    "category": [
      "cs.AI",
      "cs.CV",
      "cs.IR",
      "cs.RO",
      "q-bio.NC"
    ],
    "authors": [
      "Emanuel Diamant"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0808.0374v1",
    "title": "A 8 bits Pipeline Analog to Digital Converter Design for High Speed\n  Camera Application",
    "summary": "- This paper describes a pipeline analog-to-digital converter is implemented\nfor high speed camera. In the pipeline ADC design, prime factor is designing\noperational amplifier with high gain so ADC have been high speed. The other\nadvantage of pipeline is simple on concept, easy to implement in layout and\nhave flexibility to increase speed. We made design and simulation using Mentor\nGraphics Software with 0.6 \\mu m CMOS technology with a total power dissipation\nof 75.47 mW. Circuit techniques used include a precise comparator, operational\namplifier and clock management. A switched capacitor is used to sample and\nmultiplying at each stage. Simulation a worst case DNL and INL of 0.75 LSB. The\ndesign operates at 5 V dc. The ADC achieves a SNDR of 44.86 dB. keywords:\npipeline, switched capacitor, clock management",
    "published": "2008-08-04T03:23:20Z",
    "link": "http://arxiv.org/pdf/0808.0374v1.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Eri Prasetyo",
      "Hamzah Afandi",
      "Nurul Huda Dominique Ginhac",
      "Michel Paindavoine"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0808.0387v1",
    "title": "Design and Implementation a 8 bits Pipeline Analog to Digital Converter\n  in the Technology 0.6 m CMOS Process",
    "summary": "This paper describes a 8 bits, 20 Msamples/s pipeline analog-to-digital\nconverter implemented in 0.6 \\mu m CMOS technology with a total power\ndissipation of 75.47 mW. Circuit techniques used include a precise comparator,\noperational amplifier and clock management. A switched capacitor is used to\nsample and multiplying at each stage. Simulation a worst case DNL and INL of\n0.75 LSB. The design operate at 5 V dc. The ADC achieves a SNDR of 44.86 dB.\nkeywords : pipeline, switched capacitor, clock management",
    "published": "2008-08-04T07:19:57Z",
    "link": "http://arxiv.org/pdf/0808.0387v1.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Eri Prasetyo",
      "Dominique Ginhac",
      "Michel Paindavoine"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0808.2227v1",
    "title": "Higher Order Moments Generation by Mellin Transform for Compound Models\n  of Clutter",
    "summary": "The compound models of clutter statistics are found suitable to describe the\nnonstationary nature of radar backscattering from high-resolution observations.\nIn this letter, we show that the properties of Mellin transform can be utilized\nto generate higher order moments of simple and compound models of clutter\nstatistics in a compact manner.",
    "published": "2008-08-16T01:34:48Z",
    "link": "http://arxiv.org/pdf/0808.2227v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "C Bhattacharya"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0809.1802v1",
    "title": "Automatic Identification and Data Extraction from 2-Dimensional Plots in\n  Digital Documents",
    "summary": "Most search engines index the textual content of documents in digital\nlibraries. However, scholarly articles frequently report important findings in\nfigures for visual impact and the contents of these figures are not indexed.\nThese contents are often invaluable to the researcher in various fields, for\nthe purposes of direct comparison with their own work. Therefore, searching for\nfigures and extracting figure data are important problems. To the best of our\nknowledge, there exists no tool to automatically extract data from figures in\ndigital documents. If we can extract data from these images automatically and\nstore them in a database, an end-user can query and combine data from multiple\ndigital documents simultaneously and efficiently. We propose a framework based\non image analysis and machine learning to extract information from 2-D plot\nimages and store them in a database. The proposed algorithm identifies a 2-D\nplot and extracts the axis labels, legend and the data points from the 2-D\nplot. We also segregate overlapping shapes that correspond to different data\npoints. We demonstrate performance of individual algorithms, using a\ncombination of generated and real-life images.",
    "published": "2008-09-10T14:43:37Z",
    "link": "http://arxiv.org/pdf/0809.1802v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "William Brouwer",
      "Saurabh Kataria",
      "Sujatha Das",
      "Prasenjit Mitra",
      "C. L. Giles"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0809.3083v1",
    "title": "Supervised Dictionary Learning",
    "summary": "It is now well established that sparse signal models are well suited to\nrestoration tasks and can effectively be learned from audio, image, and video\ndata. Recent research has been aimed at learning discriminative sparse models\ninstead of purely reconstructive ones. This paper proposes a new step in that\ndirection, with a novel sparse representation for signals belonging to\ndifferent classes in terms of a shared dictionary and multiple class-decision\nfunctions. The linear variant of the proposed model admits a simple\nprobabilistic interpretation, while its most general variant admits an\ninterpretation in terms of kernels. An optimization framework for learning all\nthe components of the proposed model is presented, along with experimental\nresults on standard handwritten digit and texture classification tasks.",
    "published": "2008-09-18T07:16:34Z",
    "link": "http://arxiv.org/pdf/0809.3083v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Julien Mairal",
      "Francis Bach",
      "Jean Ponce",
      "Guillermo Sapiro",
      "Andrew Zisserman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0809.3352v1",
    "title": "Generalized Prediction Intervals for Arbitrary Distributed\n  High-Dimensional Data",
    "summary": "This paper generalizes the traditional statistical concept of prediction\nintervals for arbitrary probability density functions in high-dimensional\nfeature spaces by introducing significance level distributions, which provides\ninterval-independent probabilities for continuous random variables. The\nadvantage of the transformation of a probability density function into a\nsignificance level distribution is that it enables one-class classification or\noutlier detection in a direct manner.",
    "published": "2008-09-19T11:02:39Z",
    "link": "http://arxiv.org/pdf/0809.3352v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Steffen Kuehn"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0809.3618v1",
    "title": "Robust Near-Isometric Matching via Structured Learning of Graphical\n  Models",
    "summary": "Models for near-rigid shape matching are typically based on distance-related\nfeatures, in order to infer matches that are consistent with the isometric\nassumption. However, real shapes from image datasets, even when expected to be\nrelated by \"almost isometric\" transformations, are actually subject not only to\nnoise but also, to some limited degree, to variations in appearance and scale.\nIn this paper, we introduce a graphical model that parameterises appearance,\ndistance, and angle features and we learn all of the involved parameters via\nstructured prediction. The outcome is a model for near-rigid shape matching\nwhich is robust in the sense that it is able to capture the possibly limited\nbut still important scale and appearance variations. Our experimental results\nreveal substantial improvements upon recent successful models, while\nmaintaining similar running times.",
    "published": "2008-09-21T23:23:26Z",
    "link": "http://arxiv.org/pdf/0809.3618v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Julian J. McAuley",
      "Tiberio S. Caetano",
      "Alexander J. Smola"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0809.3690v1",
    "title": "Modeling and Control with Local Linearizing Nadaraya Watson Regression",
    "summary": "Black box models of technical systems are purely descriptive. They do not\nexplain why a system works the way it does. Thus, black box models are\ninsufficient for some problems. But there are numerous applications, for\nexample, in control engineering, for which a black box model is absolutely\nsufficient. In this article, we describe a general stochastic framework with\nwhich such models can be built easily and fully automated by observation.\nFurthermore, we give a practical example and show how this framework can be\nused to model and control a motorcar powertrain.",
    "published": "2008-09-22T12:08:24Z",
    "link": "http://arxiv.org/pdf/0809.3690v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Steffen Khn",
      "Clemens Ghmann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0809.4501v1",
    "title": "Audio Classification from Time-Frequency Texture",
    "summary": "Time-frequency representations of audio signals often resemble texture\nimages. This paper derives a simple audio classification algorithm based on\ntreating sound spectrograms as texture images. The algorithm is inspired by an\nearlier visual classification scheme particularly efficient at classifying\ntextures. While solely based on time-frequency texture features, the algorithm\nachieves surprisingly good performance in musical instrument classification\nexperiments.",
    "published": "2008-09-25T20:54:29Z",
    "link": "http://arxiv.org/pdf/0809.4501v1.pdf",
    "category": [
      "cs.CV",
      "cs.SD"
    ],
    "authors": [
      "Guoshen Yu",
      "Jean-Jacques Slotine"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0810.2311v2",
    "title": "Non-Negative Matrix Factorization, Convexity and Isometry",
    "summary": "In this paper we explore avenues for improving the reliability of\ndimensionality reduction methods such as Non-Negative Matrix Factorization\n(NMF) as interpretive exploratory data analysis tools. We first explore the\ndifficulties of the optimization problem underlying NMF, showing for the first\ntime that non-trivial NMF solutions always exist and that the optimization\nproblem is actually convex, by using the theory of Completely Positive\nFactorization. We subsequently explore four novel approaches to finding\nglobally-optimal NMF solutions using various ideas from convex optimization. We\nthen develop a new method, isometric NMF (isoNMF), which preserves\nnon-negativity while also providing an isometric embedding, simultaneously\nachieving two properties which are helpful for interpretation. Though it\nresults in a more difficult optimization problem, we show experimentally that\nthe resulting method is scalable and even achieves more compact spectra than\nstandard NMF.",
    "published": "2008-10-13T20:43:24Z",
    "link": "http://arxiv.org/pdf/0810.2311v2.pdf",
    "category": [
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Nikolaos Vasiloglou",
      "Alexander G. Gray",
      "David V. Anderson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0810.2434v1",
    "title": "Faster and better: a machine learning approach to corner detection",
    "summary": "The repeatability and efficiency of a corner detector determines how likely\nit is to be useful in a real-world application. The repeatability is importand\nbecause the same scene viewed from different positions should yield features\nwhich correspond to the same real-world 3D locations [Schmid et al 2000]. The\nefficiency is important because this determines whether the detector combined\nwith further processing can operate at frame rate.\n  Three advances are described in this paper. First, we present a new heuristic\nfor feature detection, and using machine learning we derive a feature detector\nfrom this which can fully process live PAL video using less than 5% of the\navailable processing time. By comparison, most other detectors cannot even\noperate at frame rate (Harris detector 115%, SIFT 195%). Second, we generalize\nthe detector, allowing it to be optimized for repeatability, with little loss\nof efficiency. Third, we carry out a rigorous comparison of corner detectors\nbased on the above repeatability criterion applied to 3D scenes. We show that\ndespite being principally constructed for speed, on these stringent tests, our\nheuristic detector significantly outperforms existing feature detectors.\nFinally, the comparison demonstrates that using machine learning produces\nsignificant improvements in repeatability, yielding a detector that is both\nvery fast and very high quality.",
    "published": "2008-10-14T14:22:05Z",
    "link": "http://arxiv.org/pdf/0810.2434v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Edward Rosten",
      "Reid Porter",
      "Tom Drummond"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0810.3418v1",
    "title": "Detecting the Most Unusual Part of a Digital Image",
    "summary": "The purpose of this paper is to introduce an algorithm that can detect the\nmost unusual part of a digital image. The most unusual part of a given shape is\ndefined as a part of the image that has the maximal distance to all non\nintersecting shapes with the same form.\n  The method can be used to scan image databases with no clear model of the\ninteresting part or large image databases, as for example medical databases.",
    "published": "2008-10-19T18:04:51Z",
    "link": "http://arxiv.org/pdf/0810.3418v1.pdf",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "K. Koroutchev",
      "E. Korutcheva"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0810.3579v1",
    "title": "Hierarchical Bag of Paths for Kernel Based Shape Classification",
    "summary": "Graph kernels methods are based on an implicit embedding of graphs within a\nvector space of large dimension. This implicit embedding allows to apply to\ngraphs methods which where until recently solely reserved to numerical data.\nWithin the shape classification framework, graphs are often produced by a\nskeletonization step which is sensitive to noise. We propose in this paper to\nintegrate the robustness to structural noise by using a kernel based on a bag\nof path where each path is associated to a hierarchy encoding successive\nsimplifications of the path. Several experiments prove the robustness and the\nflexibility of our approach compared to alternative shape classification\nmethods.",
    "published": "2008-10-20T15:13:18Z",
    "link": "http://arxiv.org/pdf/0810.3579v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Franois-Xavier Dup",
      "Luc Brun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0810.3851v1",
    "title": "Astronomical imaging: The theory of everything",
    "summary": "We are developing automated systems to provide homogeneous calibration\nmeta-data for heterogeneous imaging data, using the pixel content of the image\nalone where necessary. Standardized and complete calibration meta-data permit\ngenerative modeling: A good model of the sky through wavelength and time--that\nis, a model of the positions, motions, spectra, and variability of all stellar\nsources, plus an intensity map of all cosmological sources--could synthesize or\ngenerate any astronomical image ever taken at any time with any equipment in\nany configuration. We argue that the best-fit or highest likelihood model of\nthe data is also the best possible astronomical catalog constructed from those\ndata. A generative model or catalog of this form is the best possible platform\nfor automated discovery, because it is capable of identifying informative\nfailures of the model in new data at the pixel level, or as statistical\nanomalies in the joint distribution of residuals from many images. It is also,\nin some sense, an astronomer's \"theory of everything\".",
    "published": "2008-10-21T14:47:38Z",
    "link": "http://arxiv.org/pdf/0810.3851v1.pdf",
    "category": [
      "astro-ph",
      "cs.CV",
      "physics.data-an"
    ],
    "authors": [
      "David W. Hogg",
      "Dustin Lang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0810.4401v2",
    "title": "Efficient Exact Inference in Planar Ising Models",
    "summary": "We give polynomial-time algorithms for the exact computation of lowest-energy\n(ground) states, worst margin violators, log partition functions, and marginal\nedge probabilities in certain binary undirected graphical models. Our approach\nprovides an interesting alternative to the well-known graph cut paradigm in\nthat it does not impose any submodularity constraints; instead we require\nplanarity to establish a correspondence with perfect matchings (dimer\ncoverings) in an expanded dual graph. We implement a unified framework while\ndelegating complex but well-understood subproblems (planar embedding,\nmaximum-weight perfect matching) to established algorithms for which efficient\nimplementations are freely available. Unlike graph cut methods, we can perform\npenalized maximum-likelihood as well as maximum-margin parameter estimation in\nthe associated conditional random fields (CRFs), and employ marginal posterior\nprobabilities as well as maximum a posteriori (MAP) states for prediction.\nMaximum-margin CRF parameter estimation on image denoising and segmentation\nproblems shows our approach to be efficient and effective. A C++ implementation\nis available from http://nic.schraudolph.org/isinf/",
    "published": "2008-10-24T08:49:09Z",
    "link": "http://arxiv.org/pdf/0810.4401v2.pdf",
    "category": [
      "cs.LG",
      "cs.CV",
      "stat.ML"
    ],
    "authors": [
      "Nicol N. Schraudolph",
      "Dmitry Kamenetsky"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0810.4426v2",
    "title": "Camera distortion self-calibration using the plumb-line constraint and\n  minimal Hough entropy",
    "summary": "In this paper we present a simple and robust method for self-correction of\ncamera distortion using single images of scenes which contain straight lines.\nSince the most common distortion can be modelled as radial distortion, we\nillustrate the method using the Harris radial distortion model, but the method\nis applicable to any distortion model. The method is based on transforming the\nedgels of the distorted image to a 1-D angular Hough space, and optimizing the\ndistortion correction parameters which minimize the entropy of the\ncorresponding normalized histogram. Properly corrected imagery will have fewer\ncurved lines, and therefore less spread in Hough space. Since the method does\nnot rely on any image structure beyond the existence of edgels sharing some\ncommon orientations and does not use edge fitting, it is applicable to a wide\nvariety of image types. For instance, it can be applied equally well to images\nof texture with weak but dominant orientations, or images with strong vanishing\npoints. Finally, the method is performed on both synthetic and real data\nrevealing that it is particularly robust to noise.",
    "published": "2008-10-24T10:50:59Z",
    "link": "http://arxiv.org/pdf/0810.4426v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Edward Rosten",
      "Rohan Loveland"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0810.4617v2",
    "title": "Graph-based classification of multiple observation sets",
    "summary": "We consider the problem of classification of an object given multiple\nobservations that possibly include different transformations. The possible\ntransformations of the object generally span a low-dimensional manifold in the\noriginal signal space. We propose to take advantage of this manifold structure\nfor the effective classification of the object represented by the observation\nset. In particular, we design a low complexity solution that is able to exploit\nthe properties of the data manifolds with a graph-based algorithm. Hence, we\nformulate the computation of the unknown label matrix as a smoothing process on\nthe manifold under the constraint that all observations represent an object of\none single class. It results into a discrete optimization problem, which can be\nsolved by an efficient and low complexity algorithm. We demonstrate the\nperformance of the proposed graph-based algorithm in the classification of sets\nof multiple images. Moreover, we show its high potential in video-based face\nrecognition, where it outperforms state-of-the-art solutions that fall short of\nexploiting the manifold structure of the face image data sets.",
    "published": "2008-10-25T16:02:32Z",
    "link": "http://arxiv.org/pdf/0810.4617v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Effrosyni Kokiopoulou",
      "Pascal Frossard"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0810.5325v1",
    "title": "3D Face Recognition with Sparse Spherical Representations",
    "summary": "This paper addresses the problem of 3D face recognition using simultaneous\nsparse approximations on the sphere. The 3D face point clouds are first aligned\nwith a novel and fully automated registration process. They are then\nrepresented as signals on the 2D sphere in order to preserve depth and geometry\ninformation. Next, we implement a dimensionality reduction process with\nsimultaneous sparse approximations and subspace projection. It permits to\nrepresent each 3D face by only a few spherical functions that are able to\ncapture the salient facial characteristics, and hence to preserve the\ndiscriminant facial information. We eventually perform recognition by effective\nmatching in the reduced space, where Linear Discriminant Analysis can be\nfurther activated for improved recognition performance. The 3D face recognition\nalgorithm is evaluated on the FRGC v.1.0 data set, where it is shown to\noutperform classical state-of-the-art solutions that work with depth images.",
    "published": "2008-10-29T17:43:54Z",
    "link": "http://arxiv.org/pdf/0810.5325v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "R. Sala Llonch",
      "E. Kokiopoulou",
      "I. Tosic",
      "P. Frossard"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cmp-lg/9712002v2",
    "title": "Machine Learning of User Profiles: Representational Issues",
    "summary": "As more information becomes available electronically, tools for finding\ninformation of interest to users becomes increasingly important. The goal of\nthe research described here is to build a system for generating comprehensible\nuser profiles that accurately capture user interest with minimum user\ninteraction. The research described here focuses on the importance of a\nsuitable generalization hierarchy and representation for learning profiles\nwhich are predictively accurate and comprehensible. In our experiments we\nevaluated both traditional features based on weighted term vectors as well as\nsubject features corresponding to categories which could be drawn from a\nthesaurus. Our experiments, conducted in the context of a content-based\nprofiling system for on-line newspapers on the World Wide Web (the IDD News\nBrowser), demonstrate the importance of a generalization hierarchy and the\npromise of combining natural language processing techniques with machine\nlearning (ML) to address an information retrieval (IR) problem.",
    "published": "1997-12-09T15:42:46Z",
    "link": "http://arxiv.org/pdf/cmp-lg/9712002v2.pdf",
    "category": [
      "cmp-lg",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Eric Bloedorn",
      "Inderjeet Mani",
      "T. Richard MacMillan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9809111v1",
    "title": "Evolution of Neural Networks to Play the Game of Dots-and-Boxes",
    "summary": "Dots-and-Boxes is a child's game which remains analytically unsolved. We\nimplement and evolve artificial neural networks to play this game, evaluating\nthem against simple heuristic players. Our networks do not evaluate or predict\nthe final outcome of the game, but rather recommend moves at each stage.\nSuperior generalisation of play by co-evolved populations is found, and a\ncomparison made with networks trained by back-propagation using simple\nheuristics as an oracle.",
    "published": "1998-09-28T03:48:22Z",
    "link": "http://arxiv.org/pdf/cs/9809111v1.pdf",
    "category": [
      "cs.NE",
      "cs.LG",
      "I.2.6"
    ],
    "authors": [
      "Lex Weaver",
      "Terry Bossomaier"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9809122v1",
    "title": "Practical algorithms for on-line sampling",
    "summary": "One of the core applications of machine learning to knowledge discovery\nconsists on building a function (a hypothesis) from a given amount of data (for\ninstance a decision tree or a neural network) such that we can use it\nafterwards to predict new instances of the data. In this paper, we focus on a\nparticular situation where we assume that the hypothesis we want to use for\nprediction is very simple, and thus, the hypotheses class is of feasible size.\nWe study the problem of how to determine which of the hypotheses in the class\nis almost the best one. We present two on-line sampling algorithms for\nselecting hypotheses, give theoretical bounds on the number of necessary\nexamples, and analize them exprimentally. We compare them with the simple batch\nsampling approach commonly used and show that in most of the situations our\nalgorithms use much fewer number of examples.",
    "published": "1998-09-30T03:44:08Z",
    "link": "http://arxiv.org/pdf/cs/9809122v1.pdf",
    "category": [
      "cs.LG",
      "cs.DS",
      "I.2.6;H.2.8"
    ],
    "authors": [
      "Carlos Domingo",
      "Ricard Gavalda",
      "Osamu Watanabe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9811003v1",
    "title": "A Winnow-Based Approach to Context-Sensitive Spelling Correction",
    "summary": "A large class of machine-learning problems in natural language require the\ncharacterization of linguistic context. Two characteristic properties of such\nproblems are that their feature space is of very high dimensionality, and their\ntarget concepts refer to only a small subset of the features in the space.\nUnder such conditions, multiplicative weight-update algorithms such as Winnow\nhave been shown to have exceptionally good theoretical properties. We present\nan algorithm combining variants of Winnow and weighted-majority voting, and\napply it to a problem in the aforementioned class: context-sensitive spelling\ncorrection. This is the task of fixing spelling errors that happen to result in\nvalid words, such as substituting \"to\" for \"too\", \"casual\" for \"causal\", etc.\nWe evaluate our algorithm, WinSpell, by comparing it against BaySpell, a\nstatistics-based method representing the state of the art for this task. We\nfind: (1) When run with a full (unpruned) set of features, WinSpell achieves\naccuracies significantly higher than BaySpell was able to achieve in either the\npruned or unpruned condition; (2) When compared with other systems in the\nliterature, WinSpell exhibits the highest performance; (3) The primary reason\nthat WinSpell outperforms BaySpell is that WinSpell learns a better linear\nseparator; (4) When run on a test set drawn from a different corpus than the\ntraining set was drawn from, WinSpell is better able than BaySpell to adapt,\nusing a strategy we will present that combines supervised learning on the\ntraining set with unsupervised learning on the (noisy) test set.",
    "published": "1998-10-31T19:33:50Z",
    "link": "http://arxiv.org/pdf/cs/9811003v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL",
      "I.2.6; I.2.7"
    ],
    "authors": [
      "Andrew R. Golding",
      "Dan Roth"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9811006v1",
    "title": "Machine Learning of Generic and User-Focused Summarization",
    "summary": "A key problem in text summarization is finding a salience function which\ndetermines what information in the source should be included in the summary.\nThis paper describes the use of machine learning on a training corpus of\ndocuments and their abstracts to discover salience functions which describe\nwhat combination of features is optimal for a given summarization task. The\nmethod addresses both \"generic\" and user-focused summaries.",
    "published": "1998-11-02T18:57:23Z",
    "link": "http://arxiv.org/pdf/cs/9811006v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG",
      "I.2.6; I.2.7"
    ],
    "authors": [
      "Inderjeet Mani",
      "Eric Bloedorn"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9811010v1",
    "title": "Learning to Resolve Natural Language Ambiguities: A Unified Approach",
    "summary": "We analyze a few of the commonly used statistics based and machine learning\nalgorithms for natural language disambiguation tasks and observe that they can\nbe re-cast as learning linear separators in the feature space. Each of the\nmethods makes a priori assumptions, which it employs, given the data, when\nsearching for its hypothesis. Nevertheless, as we show, it searches a space\nthat is as rich as the space of all linear separators. We use this to build an\nargument for a data driven approach which merely searches for a good linear\nseparator in the feature space, without further assumptions on the domain or a\nspecific problem.\n  We present such an approach - a sparse network of linear separators,\nutilizing the Winnow learning algorithm - and show how to use it in a variety\nof ambiguity resolution problems. The learning approach presented is\nattribute-efficient and, therefore, appropriate for domains having very large\nnumber of attributes.\n  In particular, we present an extensive experimental comparison of our\napproach with other methods on several well studied lexical disambiguation\ntasks such as context-sensitive spelling correction, prepositional phrase\nattachment and part of speech tagging. In all cases we show that our approach\neither outperforms other methods tried for these tasks or performs comparably\nto the best.",
    "published": "1998-11-03T21:14:32Z",
    "link": "http://arxiv.org/pdf/cs/9811010v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG",
      "I.2.6 I.2.7"
    ],
    "authors": [
      "Dan Roth"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9812021v1",
    "title": "Forgetting Exceptions is Harmful in Language Learning",
    "summary": "We show that in language learning, contrary to received wisdom, keeping\nexceptional training instances in memory can be beneficial for generalization\naccuracy. We investigate this phenomenon empirically on a selection of\nbenchmark natural language processing tasks: grapheme-to-phoneme conversion,\npart-of-speech tagging, prepositional-phrase attachment, and base noun phrase\nchunking. In a first series of experiments we combine memory-based learning\nwith training set editing techniques, in which instances are edited based on\ntheir typicality and class prediction strength. Results show that editing\nexceptional instances (with low typicality or low class prediction strength)\ntends to harm generalization accuracy. In a second series of experiments we\ncompare memory-based learning and decision-tree learning methods on the same\nselection of tasks, and find that decision-tree learning often performs worse\nthan memory-based learning. Moreover, the decrease in performance can be linked\nto the degree of abstraction from exceptions (i.e., pruning or eagerness). We\nprovide explanations for both results in terms of the properties of the natural\nlanguage processing tasks and the learning algorithms.",
    "published": "1998-12-22T16:33:19Z",
    "link": "http://arxiv.org/pdf/cs/9812021v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG",
      "I.2.6; I.2.7"
    ],
    "authors": [
      "Walter Daelemans",
      "Antal van den Bosch",
      "Jakub Zavrel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9902026v1",
    "title": "Probabilistic Inductive Inference:a Survey",
    "summary": "Inductive inference is a recursion-theoretic theory of learning, first\ndeveloped by E. M. Gold (1967). This paper surveys developments in\nprobabilistic inductive inference. We mainly focus on finite inference of\nrecursive functions, since this simple paradigm has produced the most\ninteresting (and most complex) results.",
    "published": "1999-02-15T01:52:45Z",
    "link": "http://arxiv.org/pdf/cs/9902026v1.pdf",
    "category": [
      "cs.LG",
      "cs.CC",
      "cs.LO",
      "math.LO",
      "F.1.1., F.4.1., I.2.3., I.2.6"
    ],
    "authors": [
      "Andris Ambainis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9905004v1",
    "title": "Using Collective Intelligence to Route Internet Traffic",
    "summary": "A COllective INtelligence (COIN) is a set of interacting reinforcement\nlearning (RL) algorithms designed in an automated fashion so that their\ncollective behavior optimizes a global utility function. We summarize the\ntheory of COINs, then present experiments using that theory to design COINs to\ncontrol internet traffic routing. These experiments indicate that COINs\noutperform all previously investigated RL-based, shortest path routing\nalgorithms.",
    "published": "1999-05-10T20:52:23Z",
    "link": "http://arxiv.org/pdf/cs/9905004v1.pdf",
    "category": [
      "cs.LG",
      "adap-org",
      "cond-mat.stat-mech",
      "cs.DC",
      "cs.NI",
      "nlin.AO",
      "I.2.6; I.2.11"
    ],
    "authors": [
      "David H. Wolpert",
      "Kagan Tumer",
      "Jeremy Frank"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9905005v1",
    "title": "General Principles of Learning-Based Multi-Agent Systems",
    "summary": "We consider the problem of how to design large decentralized multi-agent\nsystems (MAS's) in an automated fashion, with little or no hand-tuning. Our\napproach has each agent run a reinforcement learning algorithm. This converts\nthe problem into one of how to automatically set/update the reward functions\nfor each of the agents so that the global goal is achieved. In particular we do\nnot want the agents to ``work at cross-purposes'' as far as the global goal is\nconcerned. We use the term artificial COllective INtelligence (COIN) to refer\nto systems that embody solutions to this problem. In this paper we present a\nsummary of a mathematical framework for COINs. We then investigate the\nreal-world applicability of the core concepts of that framework via two\ncomputer experiments: we show that our COINs perform near optimally in a\ndifficult variant of Arthur's bar problem (and in particular avoid the tragedy\nof the commons for that problem), and we also illustrate optimal performance\nfor our COINs in the leader-follower problem.",
    "published": "1999-05-10T22:20:40Z",
    "link": "http://arxiv.org/pdf/cs/9905005v1.pdf",
    "category": [
      "cs.MA",
      "adap-org",
      "cond-mat.stat-mech",
      "cs.DC",
      "cs.LG",
      "nlin.AO",
      "I.2.6 ; I.2.11"
    ],
    "authors": [
      "David H. Wolpert",
      "Kevin R. Wheeler",
      "Kagan Tumer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9905007v1",
    "title": "An Efficient, Probabilistically Sound Algorithm for Segmentation and\n  Word Discovery",
    "summary": "This paper presents a model-based, unsupervised algorithm for recovering word\nboundaries in a natural-language text from which they have been deleted. The\nalgorithm is derived from a probability model of the source that generated the\ntext. The fundamental structure of the model is specified abstractly so that\nthe detailed component models of phonology, word-order, and word frequency can\nbe replaced in a modular fashion. The model yields a language-independent,\nprior probability distribution on all possible sequences of all possible words\nover a given alphabet, based on the assumption that the input was generated by\nconcatenating words from a fixed but unknown lexicon. The model is unusual in\nthat it treats the generation of a complete corpus, regardless of length, as a\nsingle event in the probability space. Accordingly, the algorithm does not\nestimate a probability distribution on words; instead, it attempts to calculate\nthe prior probabilities of various word sequences that could underlie the\nobserved text. Experiments on phonemic transcripts of spontaneous speech by\nparents to young children suggest that this algorithm is more effective than\nother proposed algorithms, at least when utterance boundaries are given and the\ntext includes a substantial number of short utterances.\n  Keywords: Bayesian grammar induction, probability models, minimum description\nlength (MDL), unsupervised learning, cognitive modeling, language acquisition,\nsegmentation",
    "published": "1999-05-12T14:25:40Z",
    "link": "http://arxiv.org/pdf/cs/9905007v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG",
      "I.2.0;I.2.6;I.2.7"
    ],
    "authors": [
      "Michael R. Brent"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9905009v1",
    "title": "Inside-Outside Estimation of a Lexicalized PCFG for German",
    "summary": "The paper describes an extensive experiment in inside-outside estimation of a\nlexicalized probabilistic context free grammar for German verb-final clauses.\nGrammar and formalism features which make the experiment feasible are\ndescribed. Successive models are evaluated on precision and recall of phrase\nmarkup.",
    "published": "1999-05-19T14:47:21Z",
    "link": "http://arxiv.org/pdf/cs/9905009v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG",
      "I.2.6; I.2.7"
    ],
    "authors": [
      "Franz Beil",
      "Glenn Carroll",
      "Detlef Prescher",
      "Stefan Riezler",
      "Mats Rooth"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9905010v1",
    "title": "Statistical Inference and Probabilistic Modelling for Constraint-Based\n  NLP",
    "summary": "We present a probabilistic model for constraint-based grammars and a method\nfor estimating the parameters of such models from incomplete, i.e., unparsed\ndata. Whereas methods exist to estimate the parameters of probabilistic\ncontext-free grammars from incomplete data (Baum 1970), so far for\nprobabilistic grammars involving context-dependencies only parameter estimation\ntechniques from complete, i.e., fully parsed data have been presented (Abney\n1997). However, complete-data estimation requires labor-intensive, error-prone,\nand grammar-specific hand-annotating of large language corpora. We present a\nlog-linear probability model for constraint logic programming, and a general\nalgorithm to estimate the parameters of such models from incomplete data by\nextending the estimation algorithm of Della-Pietra, Della-Pietra, and Lafferty\n(1997) to incomplete data settings.",
    "published": "1999-05-19T16:03:05Z",
    "link": "http://arxiv.org/pdf/cs/9905010v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG",
      "I.2.6; I.2.7"
    ],
    "authors": [
      "Stefan Riezler"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9905011v1",
    "title": "Ensembles of Radial Basis Function Networks for Spectroscopic Detection\n  of Cervical Pre-Cancer",
    "summary": "The mortality related to cervical cancer can be substantially reduced through\nearly detection and treatment. However, current detection techniques, such as\nPap smear and colposcopy, fail to achieve a concurrently high sensitivity and\nspecificity.\n  In vivo fluorescence spectroscopy is a technique which quickly,\nnon-invasively and quantitatively probes the biochemical and morphological\nchanges that occur in pre-cancerous tissue.\n  A multivariate statistical algorithm was used to extract clinically useful\ninformation from tissue spectra acquired from 361 cervical sites from 95\npatients at 337, 380 and 460 nm excitation wavelengths. The multivariate\nstatistical analysis was also employed to reduce the number of fluorescence\nexcitation-emission wavelength pairs required to discriminate healthy tissue\nsamples from pre-cancerous tissue samples. The use of connectionist methods\nsuch as multi layered perceptrons, radial basis function networks, and\nensembles of such networks was investigated. RBF ensemble algorithms based on\nfluorescence spectra potentially provide automated, and near real-time\nimplementation of pre-cancer detection in the hands of non-experts. The results\nare more reliable, direct and accurate than those achieved by either human\nexperts or multivariate statistical algorithms.",
    "published": "1999-05-20T18:28:15Z",
    "link": "http://arxiv.org/pdf/cs/9905011v1.pdf",
    "category": [
      "cs.NE",
      "cs.LG",
      "q-bio",
      "I.5.1 ; J.3"
    ],
    "authors": [
      "Kagan Tumer",
      "Nirmala Ramanujam",
      "Joydeep Ghosh",
      "Rebecca Richards-Kortum"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9905012v1",
    "title": "Linear and Order Statistics Combiners for Pattern Classification",
    "summary": "Several researchers have experimentally shown that substantial improvements\ncan be obtained in difficult pattern recognition problems by combining or\nintegrating the outputs of multiple classifiers. This chapter provides an\nanalytical framework to quantify the improvements in classification results due\nto combining. The results apply to both linear combiners and order statistics\ncombiners. We first show that to a first order approximation, the error rate\nobtained over and above the Bayes error rate, is directly proportional to the\nvariance of the actual decision boundaries around the Bayes optimum boundary.\nCombining classifiers in output space reduces this variance, and hence reduces\nthe \"added\" error. If N unbiased classifiers are combined by simple averaging,\nthe added error rate can be reduced by a factor of N if the individual errors\nin approximating the decision boundaries are uncorrelated. Expressions are then\nderived for linear combiners which are biased or correlated, and the effect of\noutput correlations on ensemble performance is quantified. For order statistics\nbased non-linear combiners, we derive expressions that indicate how much the\nmedian, the maximum and in general the ith order statistic can improve\nclassifier performance. The analysis presented here facilitates the\nunderstanding of the relationships among error rates, classifier boundary\ndistributions, and combining in output space. Experimental results on several\npublic domain data sets are provided to illustrate the benefits of combining\nand to support the analytical results.",
    "published": "1999-05-20T20:15:13Z",
    "link": "http://arxiv.org/pdf/cs/9905012v1.pdf",
    "category": [
      "cs.NE",
      "cs.LG",
      "I.5.1 ; I.2.6"
    ],
    "authors": [
      "Kagan Tumer",
      "Joydeep Ghosh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9905014v1",
    "title": "Hierarchical Reinforcement Learning with the MAXQ Value Function\n  Decomposition",
    "summary": "This paper presents the MAXQ approach to hierarchical reinforcement learning\nbased on decomposing the target Markov decision process (MDP) into a hierarchy\nof smaller MDPs and decomposing the value function of the target MDP into an\nadditive combination of the value functions of the smaller MDPs. The paper\ndefines the MAXQ hierarchy, proves formal results on its representational\npower, and establishes five conditions for the safe use of state abstractions.\nThe paper presents an online model-free learning algorithm, MAXQ-Q, and proves\nthat it converges wih probability 1 to a kind of locally-optimal policy known\nas a recursively optimal policy, even in the presence of the five kinds of\nstate abstraction. The paper evaluates the MAXQ representation and MAXQ-Q\nthrough a series of experiments in three domains and shows experimentally that\nMAXQ-Q (with state abstractions) converges to a recursively optimal policy much\nfaster than flat Q learning. The fact that MAXQ learns a representation of the\nvalue function has an important benefit: it makes it possible to compute and\nexecute an improved, non-hierarchical policy via a procedure similar to the\npolicy improvement step of policy iteration. The paper demonstrates the\neffectiveness of this non-hierarchical execution experimentally. Finally, the\npaper concludes with a comparison to related work and a discussion of the\ndesign tradeoffs in hierarchical reinforcement learning.",
    "published": "1999-05-21T14:26:07Z",
    "link": "http://arxiv.org/pdf/cs/9905014v1.pdf",
    "category": [
      "cs.LG",
      "I.2.6"
    ],
    "authors": [
      "Thomas G. Dietterich"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9905015v1",
    "title": "State Abstraction in MAXQ Hierarchical Reinforcement Learning",
    "summary": "Many researchers have explored methods for hierarchical reinforcement\nlearning (RL) with temporal abstractions, in which abstract actions are defined\nthat can perform many primitive actions before terminating. However, little is\nknown about learning with state abstractions, in which aspects of the state\nspace are ignored. In previous work, we developed the MAXQ method for\nhierarchical RL. In this paper, we define five conditions under which state\nabstraction can be combined with the MAXQ value function decomposition. We\nprove that the MAXQ-Q learning algorithm converges under these conditions and\nshow experimentally that state abstraction is important for the successful\napplication of MAXQ-Q learning.",
    "published": "1999-05-21T14:49:39Z",
    "link": "http://arxiv.org/pdf/cs/9905015v1.pdf",
    "category": [
      "cs.LG",
      "I.2.6"
    ],
    "authors": [
      "Thomas G. Dietterich"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9906004v1",
    "title": "Cascaded Grammatical Relation Assignment",
    "summary": "In this paper we discuss cascaded Memory-Based grammatical relations\nassignment. In the first stages of the cascade, we find chunks of several types\n(NP,VP,ADJP,ADVP,PP) and label them with their adverbial function (e.g. local,\ntemporal). In the last stage, we assign grammatical relations to pairs of\nchunks. We studied the effect of adding several levels to this cascaded\nclassifier and we found that even the less performing chunkers enhanced the\nperformance of the relation finder.",
    "published": "1999-06-02T13:41:51Z",
    "link": "http://arxiv.org/pdf/cs/9906004v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG",
      "I.6.2;I.7.1"
    ],
    "authors": [
      "Sabine Buchholz",
      "Jorn Veenstra",
      "Walter Daelemans"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9906005v1",
    "title": "Memory-Based Shallow Parsing",
    "summary": "We present a memory-based learning (MBL) approach to shallow parsing in which\nPOS tagging, chunking, and identification of syntactic relations are formulated\nas memory-based modules. The experiments reported in this paper show\ncompetitive results, the F-value for the Wall Street Journal (WSJ) treebank is:\n93.8% for NP chunking, 94.7% for VP chunking, 77.1% for subject detection and\n79.0% for object detection.",
    "published": "1999-06-02T13:48:48Z",
    "link": "http://arxiv.org/pdf/cs/9906005v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG",
      "I.6.2;I.7.1"
    ],
    "authors": [
      "Walter Daelemans",
      "Sabine Buchholz",
      "Jorn Veenstra"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9907004v2",
    "title": "MAP Lexicon is useful for segmentation and word discovery in\n  child-directed speech",
    "summary": "Because of rather fundamental changes to the underlying model proposed in the\npaper, it has been withdrawn from the archive.",
    "published": "1999-07-06T01:44:00Z",
    "link": "http://arxiv.org/pdf/cs/9907004v2.pdf",
    "category": [
      "cs.CL",
      "cs.LG",
      "I.2.6; I.2.7"
    ],
    "authors": [
      "Anand Venkataraman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9908014v1",
    "title": "An Introduction to Collective Intelligence",
    "summary": "This paper surveys the emerging science of how to design a ``COllective\nINtelligence'' (COIN). A COIN is a large multi-agent system where:\n  (i) There is little to no centralized communication or control; and\n  (ii) There is a provided world utility function that rates the possible\nhistories of the full system.\n  In particular, we are interested in COINs in which each agent runs a\nreinforcement learning (RL) algorithm. Rather than use a conventional modeling\napproach (e.g., model the system dynamics, and hand-tune agents to cooperate),\nwe aim to solve the COIN design problem implicitly, via the ``adaptive''\ncharacter of the RL algorithms of each of the agents. This approach introduces\nan entirely new, profound design problem: Assuming the RL algorithms are able\nto achieve high rewards, what reward functions for the individual agents will,\nwhen pursued by those agents, result in high world utility? In other words,\nwhat reward functions will best ensure that we do not have phenomena like the\ntragedy of the commons, Braess's paradox, or the liquidity trap?\n  Although still very young, research specifically concentrating on the COIN\ndesign problem has already resulted in successes in artificial domains, in\nparticular in packet-routing, the leader-follower problem, and in variants of\nArthur's El Farol bar problem. It is expected that as it matures and draws upon\nother disciplines related to COINs, this research will greatly expand the range\nof tasks addressable by human engineers. Moreover, in addition to drawing on\nthem, such a fully developed scie nce of COIN design may provide much insight\ninto other already established scientific fields, such as economics, game\ntheory, and population biology.",
    "published": "1999-08-17T22:49:19Z",
    "link": "http://arxiv.org/pdf/cs/9908014v1.pdf",
    "category": [
      "cs.LG",
      "adap-org",
      "cond-mat",
      "cs.DC",
      "cs.MA",
      "nlin.AO",
      "I.2.6 ; I.2.11"
    ],
    "authors": [
      "David H. Wolpert",
      "Kagan Tumer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9910011v1",
    "title": "A statistical model for word discovery in child directed speech",
    "summary": "A statistical model for segmentation and word discovery in child directed\nspeech is presented. An incremental unsupervised learning algorithm to infer\nword boundaries based on this model is described and results of empirical tests\nshowing that the algorithm is competitive with other models that have been used\nfor similar tasks are also presented.",
    "published": "1999-10-13T03:25:33Z",
    "link": "http://arxiv.org/pdf/cs/9910011v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG",
      "I.2.6; I.2.7"
    ],
    "authors": [
      "Anand Venkataraman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9912016v1",
    "title": "HMM Specialization with Selective Lexicalization",
    "summary": "We present a technique which complements Hidden Markov Models by\nincorporating some lexicalized states representing syntactically uncommon\nwords. Our approach examines the distribution of transitions, selects the\nuncommon words, and makes lexicalized states for the words. We performed a\npart-of-speech tagging experiment on the Brown corpus to evaluate the resultant\nlanguage model and discovered that this technique improved the tagging accuracy\nby 0.21% at the 95% level of confidence.",
    "published": "1999-12-23T01:07:33Z",
    "link": "http://arxiv.org/pdf/cs/9912016v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG",
      "I.2.6; I.2.7"
    ],
    "authors": [
      "Jin-Dong Kim",
      "Sang-Zoo Lee",
      "Hae-Chang Rim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0001004v1",
    "title": "Multiplicative Algorithm for Orthgonal Groups and Independent Component\n  Analysis",
    "summary": "The multiplicative Newton-like method developed by the author et al. is\nextended to the situation where the dynamics is restricted to the orthogonal\ngroup. A general framework is constructed without specifying the cost function.\nThough the restriction to the orthogonal groups makes the problem somewhat\ncomplicated, an explicit expression for the amount of individual jumps is\nobtained. This algorithm is exactly second-order-convergent. The global\ninstability inherent in the Newton method is remedied by a\nLevenberg-Marquardt-type variation. The method thus constructed can readily be\napplied to the independent component analysis. Its remarkable performance is\nillustrated by a numerical simulation.",
    "published": "2000-01-07T06:20:53Z",
    "link": "http://arxiv.org/pdf/cs/0001004v1.pdf",
    "category": [
      "cs.LG",
      "G.1.6"
    ],
    "authors": [
      "Toshinao Akuzawa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0001008v3",
    "title": "Predicting the expected behavior of agents that learn about agents: the\n  CLRI framework",
    "summary": "We describe a framework and equations used to model and predict the behavior\nof multi-agent systems (MASs) with learning agents. A difference equation is\nused for calculating the progression of an agent's error in its decision\nfunction, thereby telling us how the agent is expected to fare in the MAS. The\nequation relies on parameters which capture the agent's learning abilities,\nsuch as its change rate, learning rate and retention rate, as well as relevant\naspects of the MAS such as the impact that agents have on each other. We\nvalidate the framework with experimental results using reinforcement learning\nagents in a market system, as well as with other experimental results gathered\nfrom the AI literature. Finally, we use PAC-theory to show how to calculate\nbounds on the values of the learning parameters.",
    "published": "2000-01-12T20:57:59Z",
    "link": "http://arxiv.org/pdf/cs/0001008v3.pdf",
    "category": [
      "cs.MA",
      "cs.LG",
      "I.2.11"
    ],
    "authors": [
      "Jose M. Vidal",
      "Edmund H. Durfee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0001027v1",
    "title": "Pattern Discovery and Computational Mechanics",
    "summary": "Computational mechanics is a method for discovering, describing and\nquantifying patterns, using tools from statistical physics. It constructs\noptimal, minimal models of stochastic processes and their underlying causal\nstructures. These models tell us about the intrinsic computation embedded\nwithin a process---how it stores and transforms information. Here we summarize\nthe mathematics of computational mechanics, especially recent optimality and\nuniqueness results. We also expound the principles and motivations underlying\ncomputational mechanics, emphasizing its connections to the minimum description\nlength principle, PAC theory, and other aspects of machine learning.",
    "published": "2000-01-29T01:23:54Z",
    "link": "http://arxiv.org/pdf/cs/0001027v1.pdf",
    "category": [
      "cs.LG",
      "cs.NE",
      "I.2.6; F.1.3; G.3; H.1.1"
    ],
    "authors": [
      "Cosma Rohilla Shalizi",
      "James P. Crutchfield"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0002006v1",
    "title": "Multiplicative Nonholonomic/Newton -like Algorithm",
    "summary": "We construct new algorithms from scratch, which use the fourth order cumulant\nof stochastic variables for the cost function. The multiplicative updating rule\nhere constructed is natural from the homogeneous nature of the Lie group and\nhas numerous merits for the rigorous treatment of the dynamics. As one\nconsequence, the second order convergence is shown. For the cost function,\nfunctions invariant under the componentwise scaling are choosen. By identifying\npoints which can be transformed to each other by the scaling, we assume that\nthe dynamics is in a coset space. In our method, a point can move toward any\ndirection in this coset. Thus, no prewhitening is required.",
    "published": "2000-02-09T06:44:28Z",
    "link": "http://arxiv.org/pdf/cs/0002006v1.pdf",
    "category": [
      "cs.LG",
      "G.1.6"
    ],
    "authors": [
      "Toshinao Akuzawa",
      "Noboru Murata"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0003072v1",
    "title": "MOO: A Methodology for Online Optimization through Mining the Offline\n  Optimum",
    "summary": "Ports, warehouses and courier services have to decide online how an arriving\ntask is to be served in order that cost is minimized (or profit maximized).\nThese operators have a wealth of historical data on task assignments; can these\ndata be mined for knowledge or rules that can help the decision-making?\n  MOO is a novel application of data mining to online optimization. The idea is\nto mine (logged) expert decisions or the offline optimum for rules that can be\nused for online decisions. It requires little knowledge about the task\ndistribution and cost structure, and is applicable to a wide range of problems.\n  This paper presents a feasibility study of the methodology for the well-known\nk-server problem. Experiments with synthetic data show that optimization can be\nrecast as classification of the optimum decisions; the resulting heuristic can\nachieve the optimum for strong request patterns, consistently outperforms other\nheuristics for weak patterns, and is robust despite changes in cost model.",
    "published": "2000-03-22T12:49:38Z",
    "link": "http://arxiv.org/pdf/cs/0003072v1.pdf",
    "category": [
      "cs.DS",
      "cs.LG",
      "F.2.2;H.2.8;F.1.2"
    ],
    "authors": [
      "Jason W. H. Lee",
      "Y. C. Tay",
      "Anthony K. H. Tung"
    ]
  },
  {
    "id": "http://arxiv.org/abs/physics/0004057v1",
    "title": "The information bottleneck method",
    "summary": "We define the relevant information in a signal $x\\in X$ as being the\ninformation that this signal provides about another signal $y\\in \\Y$. Examples\ninclude the information that face images provide about the names of the people\nportrayed, or the information that speech sounds provide about the words\nspoken. Understanding the signal $x$ requires more than just predicting $y$, it\nalso requires specifying which features of $\\X$ play a role in the prediction.\nWe formalize this problem as that of finding a short code for $\\X$ that\npreserves the maximum information about $\\Y$. That is, we squeeze the\ninformation that $\\X$ provides about $\\Y$ through a `bottleneck' formed by a\nlimited set of codewords $\\tX$. This constrained optimization problem can be\nseen as a generalization of rate distortion theory in which the distortion\nmeasure $d(x,\\x)$ emerges from the joint statistics of $\\X$ and $\\Y$. This\napproach yields an exact set of self consistent equations for the coding rules\n$X \\to \\tX$ and $\\tX \\to \\Y$. Solutions to these equations can be found by a\nconvergent re-estimation method that generalizes the Blahut-Arimoto algorithm.\nOur variational principle provides a surprisingly rich framework for discussing\na variety of problems in signal processing and learning, as will be described\nin detail elsewhere.",
    "published": "2000-04-24T15:22:30Z",
    "link": "http://arxiv.org/pdf/physics/0004057v1.pdf",
    "category": [
      "physics.data-an",
      "cond-mat.dis-nn",
      "cs.LG",
      "nlin.AO"
    ],
    "authors": [
      "Naftali Tishby",
      "Fernando C. Pereira",
      "William Bialek"
    ]
  },
  {
    "id": "http://arxiv.org/abs/nlin/0006025v1",
    "title": "Information Bottlenecks, Causal States, and Statistical Relevance Bases:\n  How to Represent Relevant Information in Memoryless Transduction",
    "summary": "Discovering relevant, but possibly hidden, variables is a key step in\nconstructing useful and predictive theories about the natural world. This brief\nnote explains the connections between three approaches to this problem: the\nrecently introduced information-bottleneck method, the computational mechanics\napproach to inferring optimal models, and Salmon's statistical relevance basis.",
    "published": "2000-06-16T17:01:39Z",
    "link": "http://arxiv.org/pdf/nlin/0006025v1.pdf",
    "category": [
      "nlin.AO",
      "cond-mat.dis-nn",
      "cs.LG",
      "physics.data-an"
    ],
    "authors": [
      "Cosma Rohilla Shalizi",
      "James P. Crutchfield"
    ]
  },
  {
    "id": "http://arxiv.org/abs/math/0006233v3",
    "title": "Algorithmic Statistics",
    "summary": "While Kolmogorov complexity is the accepted absolute measure of information\ncontent of an individual finite object, a similarly absolute notion is needed\nfor the relation between an individual data sample and an individual model\nsummarizing the information in the data, for example, a finite set (or\nprobability distribution) where the data sample typically came from. The\nstatistical theory based on such relations between individual objects can be\ncalled algorithmic statistics, in contrast to classical statistical theory that\ndeals with relations between probabilistic ensembles. We develop the\nalgorithmic theory of statistic, sufficient statistic, and minimal sufficient\nstatistic. This theory is based on two-part codes consisting of the code for\nthe statistic (the model summarizing the regularity, the meaningful\ninformation, in the data) and the model-to-data code. In contrast to the\nsituation in probabilistic statistical theory, the algorithmic relation of\n(minimal) sufficiency is an absolute relation between the individual model and\nthe individual data sample. We distinguish implicit and explicit descriptions\nof the models. We give characterizations of algorithmic (Kolmogorov) minimal\nsufficient statistic for all data samples for both description modes--in the\nexplicit mode under some constraints. We also strengthen and elaborate earlier\nresults on the ``Kolmogorov structure function'' and ``absolutely\nnon-stochastic objects''--those rare objects for which the simplest models that\nsummarize their relevant information (minimal sufficient statistics) are at\nleast as complex as the objects themselves. We demonstrate a close relation\nbetween the probabilistic notions and the algorithmic ones.",
    "published": "2000-06-30T17:19:06Z",
    "link": "http://arxiv.org/pdf/math/0006233v3.pdf",
    "category": [
      "math.ST",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "math.PR",
      "physics.data-an",
      "stat.TH",
      "62B05, 62B10, 68Q32, 68Q30, 60AXX, 68T04"
    ],
    "authors": [
      "Peter Gacs",
      "John Tromp",
      "Paul Vitanyi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/physics/0007070v3",
    "title": "Predictability, complexity and learning",
    "summary": "We define {\\em predictive information} $I_{\\rm pred} (T)$ as the mutual\ninformation between the past and the future of a time series. Three\nqualitatively different behaviors are found in the limit of large observation\ntimes $T$: $I_{\\rm pred} (T)$ can remain finite, grow logarithmically, or grow\nas a fractional power law. If the time series allows us to learn a model with a\nfinite number of parameters, then $I_{\\rm pred} (T)$ grows logarithmically with\na coefficient that counts the dimensionality of the model space. In contrast,\npower--law growth is associated, for example, with the learning of infinite\nparameter (or nonparametric) models such as continuous functions with\nsmoothness constraints. There are connections between the predictive\ninformation and measures of complexity that have been defined both in learning\ntheory and in the analysis of physical systems through statistical mechanics\nand dynamical systems theory. Further, in the same way that entropy provides\nthe unique measure of available information consistent with some simple and\nplausible conditions, we argue that the divergent part of $I_{\\rm pred} (T)$\nprovides the unique measure for the complexity of dynamics underlying a time\nseries. Finally, we discuss how these ideas may be useful in different problems\nin physics, statistics, and biology.",
    "published": "2000-07-20T00:45:11Z",
    "link": "http://arxiv.org/pdf/physics/0007070v3.pdf",
    "category": [
      "physics.data-an",
      "cond-mat.dis-nn",
      "cond-mat.other",
      "cs.LG",
      "nlin.AO",
      "q-bio.OT"
    ],
    "authors": [
      "William Bialek",
      "Ilya Nemenman",
      "Naftali Tishby"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0008009v1",
    "title": "Data Mining to Measure and Improve the Success of Web Sites",
    "summary": "For many companies, competitiveness in e-commerce requires a successful\npresence on the web. Web sites are used to establish the company's image, to\npromote and sell goods and to provide customer support. The success of a web\nsite affects and reflects directly the success of the company in the electronic\nmarket. In this study, we propose a methodology to improve the ``success'' of\nweb sites, based on the exploitation of navigation pattern discovery. In\nparticular, we present a theory, in which success is modelled on the basis of\nthe navigation behaviour of the site's users. We then exploit WUM, a navigation\npattern discovery miner, to study how the success of a site is reflected in the\nusers' behaviour. With WUM we measure the success of a site's components and\nobtain concrete indications of how the site should be improved. We report on\nour first experiments with an online catalog, the success of which we have\nstudied. Our mining analysis has shown very promising results, on the basis of\nwhich the site is currently undergoing concrete improvements.",
    "published": "2000-08-15T15:20:18Z",
    "link": "http://arxiv.org/pdf/cs/0008009v1.pdf",
    "category": [
      "cs.LG",
      "cs.DB",
      "I.2.6; H.2.8"
    ],
    "authors": [
      "Myra Spiliopoulou",
      "Carsten Pohle"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0008019v1",
    "title": "An Experimental Comparison of Naive Bayesian and Keyword-Based Anti-Spam\n  Filtering with Personal E-mail Messages",
    "summary": "The growing problem of unsolicited bulk e-mail, also known as \"spam\", has\ngenerated a need for reliable anti-spam e-mail filters. Filters of this type\nhave so far been based mostly on manually constructed keyword patterns. An\nalternative approach has recently been proposed, whereby a Naive Bayesian\nclassifier is trained automatically to detect spam messages. We test this\napproach on a large collection of personal e-mail messages, which we make\npublicly available in \"encrypted\" form contributing towards standard\nbenchmarks. We introduce appropriate cost-sensitive measures, investigating at\nthe same time the effect of attribute-set size, training-corpus size,\nlemmatization, and stop lists, issues that have not been explored in previous\nexperiments. Finally, the Naive Bayesian filter is compared, in terms of\nperformance, to a filter that uses keyword patterns, and which is part of a\nwidely used e-mail reader.",
    "published": "2000-08-22T11:20:14Z",
    "link": "http://arxiv.org/pdf/cs/0008019v1.pdf",
    "category": [
      "cs.CL",
      "cs.IR",
      "cs.LG",
      "H.4.3; I.2.6; I.2.7; I.5.4; K.4.1"
    ],
    "authors": [
      "Ion Androutsopoulos",
      "John Koutsias",
      "Konstantinos V. Chandrinos",
      "Constantine D. Spyropoulos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0008022v1",
    "title": "A Learning Approach to Shallow Parsing",
    "summary": "A SNoW based learning approach to shallow parsing tasks is presented and\nstudied experimentally. The approach learns to identify syntactic patterns by\ncombining simple predictors to produce a coherent inference. Two instantiations\nof this approach are studied and experimental results for Noun-Phrases (NP) and\nSubject-Verb (SV) phrases that compare favorably with the best published\nresults are presented. In doing that, we compare two ways of modeling the\nproblem of learning to recognize patterns and suggest that shallow parsing\npatterns are better learned using open/close predictors than using\ninside/outside predictors.",
    "published": "2000-08-22T21:37:50Z",
    "link": "http://arxiv.org/pdf/cs/0008022v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL",
      "I.2.6; I.2.7"
    ],
    "authors": [
      "Marcia Muoz",
      "Vasin Punyakanok",
      "Dan Roth",
      "Dav Zimak"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0009001v3",
    "title": "Complexity analysis for algorithmically simple strings",
    "summary": "Given a reference computer, Kolmogorov complexity is a well defined function\non all binary strings. In the standard approach, however, only the asymptotic\nproperties of such functions are considered because they do not depend on the\nreference computer. We argue that this approach can be more useful if it is\nrefined to include an important practical case of simple binary strings.\nKolmogorov complexity calculus may be developed for this case if we restrict\nthe class of available reference computers. The interesting problem is to\ndefine a class of computers which is restricted in a {\\it natural} way modeling\nthe real-life situation where only a limited class of computers is physically\navailable to us. We give an example of what such a natural restriction might\nlook like mathematically, and show that under such restrictions some error\nterms, even logarithmic in complexity, can disappear from the standard\ncomplexity calculus.\n  Keywords: Kolmogorov complexity; Algorithmic information theory.",
    "published": "2000-09-05T18:54:58Z",
    "link": "http://arxiv.org/pdf/cs/0009001v3.pdf",
    "category": [
      "cs.LG",
      "E.4; F.2; I.2"
    ],
    "authors": [
      "Andrei N. Soklakov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/physics/0009032v1",
    "title": "Information theory and learning: a physical approach",
    "summary": "We try to establish a unified information theoretic approach to learning and\nto explore some of its applications. First, we define {\\em predictive\ninformation} as the mutual information between the past and the future of a\ntime series, discuss its behavior as a function of the length of the series,\nand explain how other quantities of interest studied previously in learning\ntheory - as well as in dynamical systems and statistical mechanics - emerge\nfrom this universally definable concept. We then prove that predictive\ninformation provides the {\\em unique measure for the complexity} of dynamics\nunderlying the time series and show that there are classes of models\ncharacterized by {\\em power-law growth of the predictive information} that are\nqualitatively more complex than any of the systems that have been investigated\nbefore. Further, we investigate numerically the learning of a nonparametric\nprobability density, which is an example of a problem with power-law\ncomplexity, and show that the proper Bayesian formulation of this problem\nprovides for the `Occam' factors that punish overly complex models and thus\nallow one {\\em to learn not only a solution within a specific model class, but\nalso the class itself} using the data only and with very few a priori\nassumptions. We study a possible {\\em information theoretic method} that\nregularizes the learning of an undersampled discrete variable, and show that\nlearning in such a setup goes through stages of very different complexities.\nFinally, we discuss how all of these ideas may be useful in various problems in\nphysics, statistics, and, most importantly, biology.",
    "published": "2000-09-08T23:30:26Z",
    "link": "http://arxiv.org/pdf/physics/0009032v1.pdf",
    "category": [
      "physics.data-an",
      "cond-mat.dis-nn",
      "cs.LG",
      "nlin.AO"
    ],
    "authors": [
      "Ilya Nemenman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cond-mat/0009165v2",
    "title": "Occam factors and model-independent Bayesian learning of continuous\n  distributions",
    "summary": "Learning of a smooth but nonparametric probability density can be regularized\nusing methods of Quantum Field Theory. We implement a field theoretic prior\nnumerically, test its efficacy, and show that the data and the phase space\nfactors arising from the integration over the model space determine the free\nparameter of the theory (\"smoothness scale\") self-consistently. This persists\neven for distributions that are atypical in the prior and is a step towards a\nmodel-independent theory for learning continuous distributions. Finally, we\npoint out that a wrong parameterization of a model family may sometimes be\nadvantageous for small data sets.",
    "published": "2000-09-11T22:51:53Z",
    "link": "http://arxiv.org/pdf/cond-mat/0009165v2.pdf",
    "category": [
      "cond-mat",
      "cs.LG",
      "nlin.AO",
      "physics.data-an"
    ],
    "authors": [
      "Ilya Nemenman",
      "William Bialek"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0009007v1",
    "title": "Robust Classification for Imprecise Environments",
    "summary": "In real-world environments it usually is difficult to specify target\noperating conditions precisely, for example, target misclassification costs.\nThis uncertainty makes building robust classification systems problematic. We\nshow that it is possible to build a hybrid classifier that will perform at\nleast as well as the best available classifier for any target conditions. In\nsome cases, the performance of the hybrid actually can surpass that of the best\nknown classifier. This robust performance extends across a wide variety of\ncomparison frameworks, including the optimization of metrics such as accuracy,\nexpected cost, lift, precision, recall, and workforce utilization. The hybrid\nalso is efficient to build, to store, and to update. The hybrid is based on a\nmethod for the comparison of classifier performance that is robust to imprecise\nclass distributions and misclassification costs. The ROC convex hull (ROCCH)\nmethod combines techniques from ROC analysis, decision analysis and\ncomputational geometry, and adapts them to the particulars of analyzing learned\nclassifiers. The method is efficient and incremental, minimizes the management\nof classifier performance data, and allows for clear visual comparisons and\nsensitivity analyses. Finally, we point to empirical evidence that a robust\nhybrid classifier indeed is needed for many real-world problems.",
    "published": "2000-09-13T21:09:47Z",
    "link": "http://arxiv.org/pdf/cs/0009007v1.pdf",
    "category": [
      "cs.LG",
      "I.2.6"
    ],
    "authors": [
      "Foster Provost",
      "Tom Fawcett"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0009009v1",
    "title": "Learning to Filter Spam E-Mail: A Comparison of a Naive Bayesian and a\n  Memory-Based Approach",
    "summary": "We investigate the performance of two machine learning algorithms in the\ncontext of anti-spam filtering. The increasing volume of unsolicited bulk\ne-mail (spam) has generated a need for reliable anti-spam filters. Filters of\nthis type have so far been based mostly on keyword patterns that are\nconstructed by hand and perform poorly. The Naive Bayesian classifier has\nrecently been suggested as an effective method to construct automatically\nanti-spam filters with superior performance. We investigate thoroughly the\nperformance of the Naive Bayesian filter on a publicly available corpus,\ncontributing towards standard benchmarks. At the same time, we compare the\nperformance of the Naive Bayesian filter to an alternative memory-based\nlearning approach, after introducing suitable cost-sensitive evaluation\nmeasures. Both methods achieve very accurate spam filtering, outperforming\nclearly the keyword-based filter of a widely used e-mail reader.",
    "published": "2000-09-18T14:05:13Z",
    "link": "http://arxiv.org/pdf/cs/0009009v1.pdf",
    "category": [
      "cs.CL",
      "cs.IR",
      "cs.LG",
      "H.4.3; I.2.6; I.2.7; I.5.4; K.4.1"
    ],
    "authors": [
      "Ion Androutsopoulos",
      "Georgios Paliouras",
      "Vangelis Karkaletsis",
      "Georgios Sakkis",
      "Constantine D. Spyropoulos",
      "Panagiotis Stamatopoulos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0010001v1",
    "title": "Design of an Electro-Hydraulic System Using Neuro-Fuzzy Techniques",
    "summary": "Increasing demands in performance and quality make drive systems fundamental\nparts in the progressive automation of industrial processes. Their conventional\nmodels become inappropriate and have limited scope if one requires a precise\nand fast performance. So, it is important to incorporate learning capabilities\ninto drive systems in such a way that they improve their accuracy in realtime,\nbecoming more autonomous agents with some degree of intelligence. To\ninvestigate this challenge, this chapter presents the development of a learning\ncontrol system that uses neuro-fuzzy techniques in the design of a tracking\ncontroller to an experimental electro-hydraulic actuator. We begin the chapter\nby presenting the neuro-fuzzy modeling process of the actuator. This part\nsurveys the learning algorithm, describes the laboratorial system, and presents\nthe modeling steps as the choice of actuator representative variables, the\nacquisition of training and testing data sets, and the acquisition of the\nneuro-fuzzy inverse-model of the actuator. In the second part of the chapter,\nwe use the extracted neuro-fuzzy model and its learning capabilities to design\nthe actuator position controller based on the feedback-error-learning\ntechnique. Through a set of experimental results, we show the generalization\nproperties of the controller, its learning capability in actualizing in\nrealtime the initial neuro-fuzzy inverse-model, and its compensation action\nimproving the electro-hydraulics tracking performance.",
    "published": "2000-09-30T11:47:42Z",
    "link": "http://arxiv.org/pdf/cs/0010001v1.pdf",
    "category": [
      "cs.RO",
      "cs.LG",
      "C.3; C.4; F.1.1; I.2.6; I.2.9; I.6.5; J.2, J.7"
    ],
    "authors": [
      "P. J. Costa Branco",
      "J. A. Dente"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0010002v1",
    "title": "Noise Effects in Fuzzy Modelling Systems",
    "summary": "Noise is source of ambiguity for fuzzy systems. Although being an important\naspect, the effects of noise in fuzzy modeling have been little investigated.\nThis paper presents a set of tests using three well-known fuzzy modeling\nalgorithms. These evaluate perturbations in the extracted rule-bases caused by\nnoise polluting the learning data, and the corresponding deformations in each\nlearned functional relation. We present results to show: 1) how these fuzzy\nmodeling systems deal with noise; 2) how the established fuzzy model structure\ninfluences noise sensitivity of each algorithm; and 3) whose characteristics of\nthe learning algorithms are relevant to noise attenuation.",
    "published": "2000-09-30T14:37:23Z",
    "link": "http://arxiv.org/pdf/cs/0010002v1.pdf",
    "category": [
      "cs.NE",
      "cs.LG",
      "I.2.6; I.5.1; I.5.2"
    ],
    "authors": [
      "P. J. Costa Branco",
      "J. A. Dente"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0010003v1",
    "title": "Torque Ripple Minimization in a Switched Reluctance Drive by Neuro-Fuzzy\n  Compensation",
    "summary": "Simple power electronic drive circuit and fault tolerance of converter are\nspecific advantages of SRM drives, but excessive torque ripple has limited its\nuse to special applications. It is well known that controlling the current\nshape adequately can minimize the torque ripple. This paper presents a new\nmethod for shaping the motor currents to minimize the torque ripple, using a\nneuro-fuzzy compensator. In the proposed method, a compensating signal is added\nto the output of a PI controller, in a current-regulated speed control loop.\nNumerical results are presented in this paper, with an analysis of the effects\nof changing the form of the membership function of the neuro-fuzzy compensator.",
    "published": "2000-09-30T15:31:16Z",
    "link": "http://arxiv.org/pdf/cs/0010003v1.pdf",
    "category": [
      "cs.RO",
      "cs.LG",
      "I.2.9; I.2.6"
    ],
    "authors": [
      "L. Henriques",
      "L. Rolim",
      "W. Suemitsu",
      "P. J. Costa Branco",
      "J. A. Dente"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0010004v1",
    "title": "A Fuzzy Relational Identification Algorithm and Its Application to\n  Predict The Behaviour of a Motor Drive System",
    "summary": "Fuzzy relational identification builds a relational model describing systems\nbehaviour by a nonlinear mapping between its variables. In this paper, we\npropose a new fuzzy relational algorithm based on simplified max-min relational\nequation. The algorithm presents an adaptation method applied to gravity-center\nof each fuzzy set based on error integral value between measured and predicted\nsystem output, and uses the concept of time-variant universe of discourses. The\nidentification algorithm also includes a method to attenuate noise influence in\nextracted system relational model using a fuzzy filtering mechanism. The\nalgorithm is applied to one-step forward prediction of a simulated and\nexperimental motor drive system. The identified model has its input-output\nvariables (stator-reference current and motor speed signal) treated as fuzzy\nsets, whereas the relations existing between them are described by means of a\nmatrix R defining the relational model extracted by the algorithm. The results\nshow the good potentialities of the algorithm in predict the behaviour of the\nsystem and attenuate through the fuzzy filtering method possible noise\ndistortions in the relational model.",
    "published": "2000-09-30T15:42:55Z",
    "link": "http://arxiv.org/pdf/cs/0010004v1.pdf",
    "category": [
      "cs.RO",
      "cs.LG",
      "I.2.9; I.2.6"
    ],
    "authors": [
      "P. J. Costa Branco",
      "J. A. Dente"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0010006v1",
    "title": "Applications of Data Mining to Electronic Commerce",
    "summary": "Electronic commerce is emerging as the killer domain for data mining\ntechnology.\n  The following are five desiderata for success. Seldom are they they all\npresent in one data mining application.\n  1. Data with rich descriptions. For example, wide customer records with many\npotentially useful fields allow data mining algorithms to search beyond obvious\ncorrelations.\n  2. A large volume of data. The large model spaces corresponding to rich data\ndemand many training instances to build reliable models.\n  3. Controlled and reliable data collection. Manual data entry and integration\nfrom legacy systems both are notoriously problematic; fully automated\ncollection is considerably better.\n  4. The ability to evaluate results. Substantial, demonstrable return on\ninvestment can be very convincing.\n  5. Ease of integration with existing processes. Even if pilot studies show\npotential benefit, deploying automated solutions to previously manual processes\nis rife with pitfalls. Building a system to take advantage of the mined\nknowledge can be a substantial undertaking. Furthermore, one often must deal\nwith social and political issues involved in the automation of a previously\nmanual business process.",
    "published": "2000-10-02T12:16:17Z",
    "link": "http://arxiv.org/pdf/cs/0010006v1.pdf",
    "category": [
      "cs.LG",
      "cs.DB",
      "I.2.6;H.2.8"
    ],
    "authors": [
      "Ron Kohavi",
      "Foster Provost"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0010010v1",
    "title": "Fault Detection using Immune-Based Systems and Formal Language\n  Algorithms",
    "summary": "This paper describes two approaches for fault detection: an immune-based\nmechanism and a formal language algorithm. The first one is based on the\nfeature of immune systems in distinguish any foreign cell from the body own\ncell. The formal language approach assumes the system as a linguistic source\ncapable of generating a certain language, characterised by a grammar. Each\nalgorithm has particular characteristics, which are analysed in the paper,\nnamely in what cases they can be used with advantage. To test their\npracticality, both approaches were applied on the problem of fault detection in\nan induction motor.",
    "published": "2000-10-03T17:54:38Z",
    "link": "http://arxiv.org/pdf/cs/0010010v1.pdf",
    "category": [
      "cs.CE",
      "cs.LG",
      "I.2.6; I.2.7"
    ],
    "authors": [
      "J. F. Martins",
      "P. J. Costa Branco",
      "A. J. Pires",
      "J. A. Dente"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0011032v1",
    "title": "Top-down induction of clustering trees",
    "summary": "An approach to clustering is presented that adapts the basic top-down\ninduction of decision trees method towards clustering. To this aim, it employs\nthe principles of instance based learning. The resulting methodology is\nimplemented in the TIC (Top down Induction of Clustering trees) system for\nfirst order clustering. The TIC system employs the first order logical decision\ntree representation of the inductive logic programming system Tilde. Various\nexperiments with TIC are presented, in both propositional and relational\ndomains.",
    "published": "2000-11-21T21:51:01Z",
    "link": "http://arxiv.org/pdf/cs/0011032v1.pdf",
    "category": [
      "cs.LG",
      "I.2.6"
    ],
    "authors": [
      "Hendrik Blockeel",
      "Luc De Raedt",
      "Jan Ramon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0011033v1",
    "title": "Web Mining Research: A Survey",
    "summary": "With the huge amount of information available online, the World Wide Web is a\nfertile area for data mining research. The Web mining research is at the cross\nroad of research from several research communities, such as database,\ninformation retrieval, and within AI, especially the sub-areas of machine\nlearning and natural language processing. However, there is a lot of confusions\nwhen comparing research efforts from different point of views. In this paper,\nwe survey the research in the area of Web mining, point out some confusions\nregarded the usage of the term Web mining and suggest three Web mining\ncategories. Then we situate some of the research with respect to these three\ncategories. We also explore the connection between the Web mining categories\nand the related agent paradigm. For the survey, we focus on representation\nissues, on the process, on the learning algorithm, and on the application of\nthe recent works as the criteria. We conclude the paper with some research\nissues.",
    "published": "2000-11-22T09:41:53Z",
    "link": "http://arxiv.org/pdf/cs/0011033v1.pdf",
    "category": [
      "cs.LG",
      "cs.DB",
      "I.2.6; H.2.8"
    ],
    "authors": [
      "Raymond Kosala",
      "Hendrik Blockeel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0011038v1",
    "title": "Provably Fast and Accurate Recovery of Evolutionary Trees through\n  Harmonic Greedy Triplets",
    "summary": "We give a greedy learning algorithm for reconstructing an evolutionary tree\nbased on a certain harmonic average on triplets of terminal taxa. After the\npairwise distances between terminal taxa are estimated from sequence data, the\nalgorithm runs in O(n^2) time using O(n) work space, where n is the number of\nterminal taxa. These time and space complexities are optimal in the sense that\nthe size of an input distance matrix is n^2 and the size of an output tree is\nn. Moreover, in the Jukes-Cantor model of evolution, the algorithm recovers the\ncorrect tree topology with high probability using sample sequences of length\npolynomial in (1) n, (2) the logarithm of the error probability, and (3) the\ninverses of two small parameters.",
    "published": "2000-11-23T14:48:53Z",
    "link": "http://arxiv.org/pdf/cs/0011038v1.pdf",
    "category": [
      "cs.DS",
      "cs.LG",
      "E.1; F.2.2; G.2.1; G.2.2; G.2.3; G.3; G.4; J.3"
    ],
    "authors": [
      "Miklos Csuros",
      "Ming-Yang Kao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0011044v1",
    "title": "Scaling Up Inductive Logic Programming by Learning from Interpretations",
    "summary": "When comparing inductive logic programming (ILP) and attribute-value learning\ntechniques, there is a trade-off between expressive power and efficiency.\nInductive logic programming techniques are typically more expressive but also\nless efficient. Therefore, the data sets handled by current inductive logic\nprogramming systems are small according to general standards within the data\nmining community. The main source of inefficiency lies in the assumption that\nseveral examples may be related to each other, so they cannot be handled\nindependently.\n  Within the learning from interpretations framework for inductive logic\nprogramming this assumption is unnecessary, which allows to scale up existing\nILP algorithms. In this paper we explain this learning setting in the context\nof relational databases. We relate the setting to propositional data mining and\nto the classical ILP setting, and show that learning from interpretations\ncorresponds to learning from multiple relations and thus extends the\nexpressiveness of propositional learning, while maintaining its efficiency to a\nlarge extent (which is not the case in the classical ILP setting).\n  As a case study, we present two alternative implementations of the ILP system\nTilde (Top-down Induction of Logical DEcision trees): Tilde-classic, which\nloads all data in main memory, and Tilde-LDS, which loads the examples one by\none. We experimentally compare the implementations, showing Tilde-LDS can\nhandle large data sets (in the order of 100,000 examples or 100 MB) and indeed\nscales up linearly in the number of examples.",
    "published": "2000-11-29T12:14:50Z",
    "link": "http://arxiv.org/pdf/cs/0011044v1.pdf",
    "category": [
      "cs.LG",
      "I.2.6 ; I.2.3"
    ],
    "authors": [
      "Hendrik Blockeel",
      "Luc De Raedt",
      "Nico Jacobs",
      "Bart Demoen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/math/0012163v2",
    "title": "Learning Complexity Dimensions for a Continuous-Time Control System",
    "summary": "This paper takes a computational learning theory approach to a problem of\nlinear systems identification. It is assumed that input signals have only a\nfinite number k of frequency components, and systems to be identified have\ndimension no greater than n. The main result establishes that the sample\ncomplexity needed for identification scales polynomially with n and\nlogarithmically with k.",
    "published": "2000-12-18T10:35:00Z",
    "link": "http://arxiv.org/pdf/math/0012163v2.pdf",
    "category": [
      "math.OC",
      "cs.LG",
      "93C05"
    ],
    "authors": [
      "Pirkko Kuusela",
      "Daniel Ocone",
      "Eduardo D. Sontag"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0102015v1",
    "title": "Non-convex cost functionals in boosting algorithms and methods for panel\n  selection",
    "summary": "In this document we propose a new improvement for boosting techniques as\nproposed in Friedman '99 by the use of non-convex cost functional. The idea is\nto introduce a correlation term to better deal with forecasting of additive\ntime series. The problem is discussed in a theoretical way to prove the\nexistence of minimizing sequence, and in a numerical way to propose a new\n\"ArgMin\" algorithm. The model has been used to perform the touristic presence\nforecast for the winter season 1999/2000 in Trentino (italian Alps).",
    "published": "2001-02-20T13:08:15Z",
    "link": "http://arxiv.org/pdf/cs/0102015v1.pdf",
    "category": [
      "cs.NE",
      "cs.LG",
      "cs.NA",
      "math.NA",
      "I.2.6;G.1.2;G.3;I.6.5"
    ],
    "authors": [
      "Marco Visentin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0103003v1",
    "title": "Learning Policies with External Memory",
    "summary": "In order for an agent to perform well in partially observable domains, it is\nusually necessary for actions to depend on the history of observations. In this\npaper, we explore a {\\it stigmergic} approach, in which the agent's actions\ninclude the ability to set and clear bits in an external memory, and the\nexternal memory is included as part of the input to the agent. In this case, we\nneed to learn a reactive policy in a highly non-Markovian domain. We explore\ntwo algorithms: SARSA(\\lambda), which has had empirical success in partially\nobservable domains, and VAPS, a new algorithm due to Baird and Moore, with\nconvergence guarantees in partially observable domains. We compare the\nperformance of these two algorithms on benchmark problems.",
    "published": "2001-03-02T01:55:46Z",
    "link": "http://arxiv.org/pdf/cs/0103003v1.pdf",
    "category": [
      "cs.LG",
      "I.2.8;I.2.6;I.2.11;I.2;I.2.3"
    ],
    "authors": [
      "Leonid Peshkin",
      "Nicolas Meuleau",
      "Leslie Kaelbling"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0104005v1",
    "title": "Bootstrapping Structure using Similarity",
    "summary": "In this paper a new similarity-based learning algorithm, inspired by string\nedit-distance (Wagner and Fischer, 1974), is applied to the problem of\nbootstrapping structure from scratch. The algorithm takes a corpus of\nunannotated sentences as input and returns a corpus of bracketed sentences. The\nmethod works on pairs of unstructured sentences or sentences partially\nbracketed by the algorithm that have one or more words in common. It finds\nparts of sentences that are interchangeable (i.e. the parts of the sentences\nthat are different in both sentences). These parts are taken as possible\nconstituents of the same type. While this corresponds to the basic\nbootstrapping step of the algorithm, further structure may be learned from\ncomparison with other (similar) sentences.\n  We used this method for bootstrapping structure from the flat sentences of\nthe Penn Treebank ATIS corpus, and compared the resulting structured sentences\nto the structured sentences in the ATIS corpus. Similarly, the algorithm was\ntested on the OVIS corpus. We obtained 86.04 % non-crossing brackets precision\non the ATIS corpus and 89.39 % non-crossing brackets precision on the OVIS\ncorpus.",
    "published": "2001-04-03T14:09:12Z",
    "link": "http://arxiv.org/pdf/cs/0104005v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL",
      "I.2, I.2.6, I.2.7"
    ],
    "authors": [
      "Menno van Zaanen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0104006v1",
    "title": "ABL: Alignment-Based Learning",
    "summary": "This paper introduces a new type of grammar learning algorithm, inspired by\nstring edit distance (Wagner and Fischer, 1974). The algorithm takes a corpus\nof flat sentences as input and returns a corpus of labelled, bracketed\nsentences. The method works on pairs of unstructured sentences that have one or\nmore words in common. When two sentences are divided into parts that are the\nsame in both sentences and parts that are different, this information is used\nto find parts that are interchangeable. These parts are taken as possible\nconstituents of the same type. After this alignment learning step, the\nselection learning step selects the most probable constituents from all\npossible constituents.\n  This method was used to bootstrap structure on the ATIS corpus (Marcus et\nal., 1993) and on the OVIS (Openbaar Vervoer Informatie Systeem (OVIS) stands\nfor Public Transport Information System.) corpus (Bonnema et al., 1997). While\nthe results are encouraging (we obtained up to 89.25 % non-crossing brackets\nprecision), this paper will point out some of the shortcomings of our approach\nand will suggest possible solutions.",
    "published": "2001-04-03T14:20:26Z",
    "link": "http://arxiv.org/pdf/cs/0104006v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL",
      "I.2; I.2.6; I.2.7"
    ],
    "authors": [
      "Menno van Zaanen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0104007v1",
    "title": "Bootstrapping Syntax and Recursion using Alignment-Based Learning",
    "summary": "This paper introduces a new type of unsupervised learning algorithm, based on\nthe alignment of sentences and Harris's (1951) notion of interchangeability.\nThe algorithm is applied to an untagged, unstructured corpus of natural\nlanguage sentences, resulting in a labelled, bracketed version of the corpus.\nFirstly, the algorithm aligns all sentences in the corpus in pairs, resulting\nin a partition of the sentences consisting of parts of the sentences that are\nsimilar in both sentences and parts that are dissimilar. This information is\nused to find (possibly overlapping) constituents. Next, the algorithm selects\n(non-overlapping) constituents. Several instances of the algorithm are applied\nto the ATIS corpus (Marcus et al., 1993) and the OVIS (Openbaar Vervoer\nInformatie Systeem (OVIS) stands for Public Transport Information System.)\ncorpus (Bonnema et al., 1997). Apart from the promising numerical results, the\nmost striking result is that even the simplest algorithm based on alignment\nlearns recursion.",
    "published": "2001-04-03T15:03:16Z",
    "link": "http://arxiv.org/pdf/cs/0104007v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL",
      "I.2; I.2.6; I.2.7"
    ],
    "authors": [
      "Menno van Zaanen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0105027v1",
    "title": "Bounds on sample size for policy evaluation in Markov environments",
    "summary": "Reinforcement learning means finding the optimal course of action in\nMarkovian environments without knowledge of the environment's dynamics.\nStochastic optimization algorithms used in the field rely on estimates of the\nvalue of a policy. Typically, the value of a policy is estimated from results\nof simulating that very policy in the environment. This approach requires a\nlarge amount of simulation as different points in the policy space are\nconsidered. In this paper, we develop value estimators that utilize data\ngathered when using one policy to estimate the value of using another policy,\nresulting in much more data-efficient algorithms. We consider the question of\naccumulating a sufficient experience and give PAC-style bounds.",
    "published": "2001-05-17T18:33:56Z",
    "link": "http://arxiv.org/pdf/cs/0105027v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CC",
      "G.2;G.1.6;I.2;I.2.6"
    ],
    "authors": [
      "Leonid Peshkin",
      "Sayan Mukherjee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0105032v1",
    "title": "Learning to Cooperate via Policy Search",
    "summary": "Cooperative games are those in which both agents share the same payoff\nstructure. Value-based reinforcement-learning algorithms, such as variants of\nQ-learning, have been applied to learning cooperative games, but they only\napply when the game state is completely observable to both agents. Policy\nsearch methods are a reasonable alternative to value-based methods for\npartially observable environments. In this paper, we provide a gradient-based\ndistributed policy-search method for cooperative games and compare the notion\nof local optimum to that of Nash equilibrium. We demonstrate the effectiveness\nof this method experimentally in a small, partially observable simulated soccer\ndomain.",
    "published": "2001-05-25T02:52:07Z",
    "link": "http://arxiv.org/pdf/cs/0105032v1.pdf",
    "category": [
      "cs.LG",
      "cs.MA",
      "I.2;I.2.9;I.2.11"
    ],
    "authors": [
      "Leonid Peshkin",
      "Kee-Eung Kim",
      "Nicolas Meuleau",
      "Leslie Pack Kaelbling"
    ]
  },
  {
    "id": "http://arxiv.org/abs/math/0105235v3",
    "title": "Mathematics of learning",
    "summary": "We study the convergence properties of a pair of learning algorithms\n(learning with and without memory). This leads us to study the dominant\neigenvalue of a class of random matrices. This turns out to be related to the\nroots of the derivative of random polynomials (generated by picking their roots\nuniformly at random in the interval [0, 1], although our results extend to\nother distributions). This, in turn, requires the study of the statistical\nbehavior of the harmonic mean of random variables as above, which leads us to\ndelicate question of the rate of convergence to stable laws and tail estimates\nfor stable laws. The reader can find the proofs of most of the results\nannounced here in the paper entitled \"Harmonic mean, random polynomials, and\nrandom matrices\", by the same authors.",
    "published": "2001-05-29T02:20:17Z",
    "link": "http://arxiv.org/pdf/math/0105235v3.pdf",
    "category": [
      "math.PR",
      "cs.LG",
      "math.CO",
      "math.DS",
      "60E07, 60F15, 60J20, 91E40, 26C10"
    ],
    "authors": [
      "Natalia Komarova",
      "Igor Rivin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/math/0105236v2",
    "title": "Harmonic mean, random polynomials and stochastic matrices",
    "summary": "Motivated by a problem in learning theory, we are led to study the dominant\neigenvalue of a class of random matrices. This turns out to be related to the\nroots of the derivative of random polynomials (generated by picking their roots\nuniformly at random in the interval [0, 1], although our results extend to\nother distributions). This, in turn, requires the study of the statistical\nbehavior of the harmonic mean of random variables as above, and that, in turn,\nleads us to delicate question of the rate of convergence to stable laws and\ntail estimates for stable laws.",
    "published": "2001-05-29T02:25:23Z",
    "link": "http://arxiv.org/pdf/math/0105236v2.pdf",
    "category": [
      "math.PR",
      "cs.LG",
      "math.CA",
      "math.CO",
      "math.DS",
      "60E07, 60F15, 60J20, 91E40, 26C10"
    ],
    "authors": [
      "Natalia Komarova",
      "Igor Rivin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0106016v1",
    "title": "File mapping Rule-based DBMS and Natural Language Processing",
    "summary": "This paper describes the system of storage, extract and processing of\ninformation structured similarly to the natural language. For recursive\ninference the system uses the rules having the same representation, as the\ndata. The environment of storage of information is provided with the File\nMapping (SHM) mechanism of operating system. In the paper the main principles\nof construction of dynamic data structure and language for record of the\ninference rules are stated; the features of available implementation are\nconsidered and the description of the application realizing semantic\ninformation retrieval on the natural language is given.",
    "published": "2001-06-10T14:56:51Z",
    "link": "http://arxiv.org/pdf/cs/0106016v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.DB",
      "cs.IR",
      "cs.LG",
      "cs.PL",
      "D.3.2; H.2.4"
    ],
    "authors": [
      "Vjacheslav M. Novikov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0106036v1",
    "title": "Convergence and Error Bounds for Universal Prediction of Nonbinary\n  Sequences",
    "summary": "Solomonoff's uncomputable universal prediction scheme $\\xi$ allows to predict\nthe next symbol $x_k$ of a sequence $x_1...x_{k-1}$ for any Turing computable,\nbut otherwise unknown, probabilistic environment $\\mu$. This scheme will be\ngeneralized to arbitrary environmental classes, which, among others, allows the\nconstruction of computable universal prediction schemes $\\xi$. Convergence of\n$\\xi$ to $\\mu$ in a conditional mean squared sense and with $\\mu$ probability 1\nis proven. It is shown that the average number of prediction errors made by the\nuniversal $\\xi$ scheme rapidly converges to those made by the best possible\ninformed $\\mu$ scheme. The schemes, theorems and proofs are given for general\nfinite alphabet, which results in additional complications as compared to the\nbinary case. Several extensions of the presented theory and results are\noutlined. They include general loss functions and bounds, games of chance,\ninfinite alphabet, partial and delayed prediction, classification, and more\nactive systems.",
    "published": "2001-06-15T09:12:51Z",
    "link": "http://arxiv.org/pdf/cs/0106036v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CC",
      "math.PR",
      "F.2.3"
    ],
    "authors": [
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0106044v1",
    "title": "A Sequential Model for Multi-Class Classification",
    "summary": "Many classification problems require decisions among a large number of\ncompeting classes. These tasks, however, are not handled well by general\npurpose learning methods and are usually addressed in an ad-hoc fashion. We\nsuggest a general approach -- a sequential learning model that utilizes\nclassifiers to sequentially restrict the number of competing classes while\nmaintaining, with high probability, the presence of the true outcome in the\ncandidates set. Some theoretical and computational properties of the model are\ndiscussed and we argue that these are important in NLP-like domains. The\nadvantages of the model are illustrated in an experiment in part-of-speech\ntagging.",
    "published": "2001-06-20T19:01:41Z",
    "link": "http://arxiv.org/pdf/cs/0106044v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "I.2.6;I.2.67"
    ],
    "authors": [
      "Yair Even-Zohar",
      "Dan Roth"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0107032v1",
    "title": "Coupled Clustering: a Method for Detecting Structural Correspondence",
    "summary": "This paper proposes a new paradigm and computational framework for\nidentification of correspondences between sub-structures of distinct composite\nsystems. For this, we define and investigate a variant of traditional data\nclustering, termed coupled clustering, which simultaneously identifies\ncorresponding clusters within two data sets. The presented method is\ndemonstrated and evaluated for detecting topical correspondences in textual\ncorpora.",
    "published": "2001-07-23T11:06:45Z",
    "link": "http://arxiv.org/pdf/cs/0107032v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL",
      "cs.IR",
      "H.3.3; I.2.6; I.2.7; I.5.3; I.5.4"
    ],
    "authors": [
      "Zvika Marx",
      "Ido Dagan",
      "Joachim Buhmann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0107033v1",
    "title": "Yet another zeta function and learning",
    "summary": "We study the convergence speed of the batch learning algorithm, and compare\nits speed to that of the memoryless learning algorithm and of learning with\nmemory (as analyzed in joint work with N. Komarova). We obtain precise results\nand show in particular that the batch learning algorithm is never worse than\nthe memoryless learning algorithm (at least asymptotically). Its performance\nvis-a-vis learning with full memory is less clearcut, and depends on\ncertainprobabilistic assumptions. These results necessitate theintroduction of\nthe moment zeta function of a probability distribution and the study of some of\nits properties.",
    "published": "2001-07-25T15:50:43Z",
    "link": "http://arxiv.org/pdf/cs/0107033v1.pdf",
    "category": [
      "cs.LG",
      "cs.DM",
      "math.PR",
      "I.2.6; G.3"
    ],
    "authors": [
      "Igor Rivin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0108018v1",
    "title": "Bipartite graph partitioning and data clustering",
    "summary": "Many data types arising from data mining applications can be modeled as\nbipartite graphs, examples include terms and documents in a text corpus,\ncustomers and purchasing items in market basket analysis and reviewers and\nmovies in a movie recommender system. In this paper, we propose a new data\nclustering method based on partitioning the underlying bipartite graph. The\npartition is constructed by minimizing a normalized sum of edge weights between\nunmatched pairs of vertices of the bipartite graph. We show that an approximate\nsolution to the minimization problem can be obtained by computing a partial\nsingular value decomposition (SVD) of the associated edge weight matrix of the\nbipartite graph. We point out the connection of our clustering algorithm to\ncorrespondence analysis used in multivariate analysis. We also briefly discuss\nthe issue of assigning data objects to multiple clusters. In the experimental\nresults, we apply our clustering algorithm to the problem of document\nclustering to illustrate its effectiveness and efficiency.",
    "published": "2001-08-27T13:07:44Z",
    "link": "http://arxiv.org/pdf/cs/0108018v1.pdf",
    "category": [
      "cs.IR",
      "cs.LG",
      "H.3.3; G.1.3; G.2.2"
    ],
    "authors": [
      "H. Zha",
      "X. He",
      "C. Ding",
      "M. Gu",
      "H. Simon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0109034v1",
    "title": "Relevant Knowledge First - Reinforcement Learning and Forgetting in\n  Knowledge Based Configuration",
    "summary": "In order to solve complex configuration tasks in technical domains, various\nknowledge based methods have been developed. However their applicability is\noften unsuccessful due to their low efficiency. One of the reasons for this is\nthat (parts of the) problems have to be solved again and again, instead of\nbeing \"learnt\" from preceding processes. However, learning processes bring with\nthem the problem of conservatism, for in technical domains innovation is a\ndeciding factor in competition. On the other hand a certain amount of\nconservatism is often desired since uncontrolled innovation as a rule is also\ndetrimental. This paper proposes the heuristic RKF (Relevant Knowledge First)\nfor making decisions in configuration processes based on the so-called\nrelevance of objects in a knowledge base. The underlying relevance-function has\ntwo components, one based on reinforcement learning and the other based on\nforgetting (fading). Relevance of an object increases with its successful use\nand decreases with age when it is not used. RKF has been developed to speed up\nthe configuration process and to improve the quality of the solutions relative\nto the reward value that is given by users.",
    "published": "2001-09-19T08:07:38Z",
    "link": "http://arxiv.org/pdf/cs/0109034v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "H.4.2; I.2.0; I.2.1; I.2.6; I.2.8"
    ],
    "authors": [
      "Ingo Kreuz",
      "Dieter Roller"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0110036v1",
    "title": "Efficient algorithms for decision tree cross-validation",
    "summary": "Cross-validation is a useful and generally applicable technique often\nemployed in machine learning, including decision tree induction. An important\ndisadvantage of straightforward implementation of the technique is its\ncomputational overhead. In this paper we show that, for decision trees, the\ncomputational overhead of cross-validation can be reduced significantly by\nintegrating the cross-validation with the normal decision tree induction\nprocess. We discuss how existing decision tree algorithms can be adapted to\nthis aim, and provide an analysis of the speedups these adaptations may yield.\nThe analysis is supported by experimental results.",
    "published": "2001-10-17T15:45:23Z",
    "link": "http://arxiv.org/pdf/cs/0110036v1.pdf",
    "category": [
      "cs.LG",
      "I.2.6"
    ],
    "authors": [
      "Hendrik Blockeel",
      "Jan Struyf"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0110053v1",
    "title": "Machine Learning in Automated Text Categorization",
    "summary": "The automated categorization (or classification) of texts into predefined\ncategories has witnessed a booming interest in the last ten years, due to the\nincreased availability of documents in digital form and the ensuing need to\norganize them. In the research community the dominant approach to this problem\nis based on machine learning techniques: a general inductive process\nautomatically builds a classifier by learning, from a set of preclassified\ndocuments, the characteristics of the categories. The advantages of this\napproach over the knowledge engineering approach (consisting in the manual\ndefinition of a classifier by domain experts) are a very good effectiveness,\nconsiderable savings in terms of expert manpower, and straightforward\nportability to different domains. This survey discusses the main approaches to\ntext categorization that fall within the machine learning paradigm. We will\ndiscuss in detail issues pertaining to three different problems, namely\ndocument representation, classifier construction, and classifier evaluation.",
    "published": "2001-10-26T09:27:48Z",
    "link": "http://arxiv.org/pdf/cs/0110053v1.pdf",
    "category": [
      "cs.IR",
      "cs.LG",
      "H.3.1;H.3.3;I.2.3"
    ],
    "authors": [
      "Fabrizio Sebastiani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0111003v1",
    "title": "The Use of Classifiers in Sequential Inference",
    "summary": "We study the problem of combining the outcomes of several different\nclassifiers in a way that provides a coherent inference that satisfies some\nconstraints. In particular, we develop two general approaches for an important\nsubproblem-identifying phrase structure. The first is a Markovian approach that\nextends standard HMMs to allow the use of a rich observation structure and of\ngeneral classifiers to model state-observation dependencies. The second is an\nextension of constraint satisfaction formalisms. We develop efficient\ncombination algorithms under both models and study them experimentally in the\ncontext of shallow parsing.",
    "published": "2001-11-01T03:02:19Z",
    "link": "http://arxiv.org/pdf/cs/0111003v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL",
      "I.2.6, I.2.7"
    ],
    "authors": [
      "Vasin Punyakanok",
      "Dan Roth"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0201005v2",
    "title": "Sharpening Occam's Razor",
    "summary": "We provide a new representation-independent formulation of Occam's razor\ntheorem, based on Kolmogorov complexity. This new formulation allows us to:\n  (i) Obtain better sample complexity than both length-based and VC-based\nversions of Occam's razor theorem, in many applications.\n  (ii) Achieve a sharper reverse of Occam's razor theorem than previous work.\n  Specifically, we weaken the assumptions made in an earlier publication, and\nextend the reverse to superpolynomial running times.",
    "published": "2002-01-08T16:44:10Z",
    "link": "http://arxiv.org/pdf/cs/0201005v2.pdf",
    "category": [
      "cs.LG",
      "cond-mat.dis-nn",
      "cs.AI",
      "cs.CC",
      "math.PR",
      "physics.data-an",
      "F.2, E.4, I.2"
    ],
    "authors": [
      "Ming Li",
      "John Tromp",
      "Paul Vitanyi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0201009v1",
    "title": "The performance of the batch learner algorithm",
    "summary": "We analyze completely the convergence speed of the \\emph{batch learning\nalgorithm}, and compare its speed to that of the memoryless learning algorithm\nand of learning with memory. We show that the batch learning algorithm is never\nworse than the memoryless learning algorithm (at least asymptotically). Its\nperformance \\emph{vis-a-vis} learning with full memory is less clearcut, and\ndepends on certain probabilistic assumptions.",
    "published": "2002-01-14T18:38:55Z",
    "link": "http://arxiv.org/pdf/cs/0201009v1.pdf",
    "category": [
      "cs.LG",
      "cs.DM",
      "I2.6"
    ],
    "authors": [
      "Igor Rivin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0201014v1",
    "title": "The Dynamics of AdaBoost Weights Tells You What's Hard to Classify",
    "summary": "The dynamical evolution of weights in the Adaboost algorithm contains useful\ninformation about the role that the associated data points play in the built of\nthe Adaboost model. In particular, the dynamics induces a bipartition of the\ndata set into two (easy/hard) classes. Easy points are ininfluential in the\nmaking of the model, while the varying relevance of hard points can be gauged\nin terms of an entropy value associated to their evolution. Smooth\napproximations of entropy highlight regions where classification is most\nuncertain. Promising results are obtained when methods proposed are applied in\nthe Optimal Sampling framework.",
    "published": "2002-01-17T13:42:23Z",
    "link": "http://arxiv.org/pdf/cs/0201014v1.pdf",
    "category": [
      "cs.LG",
      "cs.DS",
      "I.5.1"
    ],
    "authors": [
      "Bruno Caprile",
      "Cesare Furlanello",
      "Stefano Merler"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0201021v1",
    "title": "Learning to Play Games in Extensive Form by Valuation",
    "summary": "A valuation for a player in a game in extensive form is an assignment of\nnumeric values to the players moves. The valuation reflects the desirability\nmoves. We assume a myopic player, who chooses a move with the highest\nvaluation. Valuations can also be revised, and hopefully improved, after each\nplay of the game. Here, a very simple valuation revision is considered, in\nwhich the moves made in a play are assigned the payoff obtained in the play. We\nshow that by adopting such a learning process a player who has a winning\nstrategy in a win-lose game can almost surely guarantee a win in a repeated\ngame. When a player has more than two payoffs, a more elaborate learning\nprocedure is required. We consider one that associates with each move the\naverage payoff in the rounds in which this move was made. When all players\nadopt this learning procedure, with some perturbations, then, with probability\n1, strategies that are close to subgame perfect equilibrium are played after\nsome time. A single player who adopts this procedure can guarantee only her\nindividually rational payoff.",
    "published": "2002-01-23T11:58:17Z",
    "link": "http://arxiv.org/pdf/cs/0201021v1.pdf",
    "category": [
      "cs.LG",
      "cs.GT",
      "I.2.1; I.2.6; I.2.8"
    ],
    "authors": [
      "Philippe Jehiel",
      "Dov Samet"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cond-mat/0202383v1",
    "title": "Extended Comment on Language Trees and Zipping",
    "summary": "This is the extended version of a Comment submitted to Physical Review\nLetters. I first point out the inappropriateness of publishing a Letter\nunrelated to physics. Next, I give experimental results showing that the\ntechnique used in the Letter is 3 times worse and 17 times slower than a simple\nbaseline. And finally, I review the literature, showing that the ideas of the\nLetter are not novel. I conclude by suggesting that Physical Review Letters\nshould not publish Letters unrelated to physics.",
    "published": "2002-02-21T18:25:29Z",
    "link": "http://arxiv.org/pdf/cond-mat/0202383v1.pdf",
    "category": [
      "cond-mat.stat-mech",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Joshua Goodman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0203010v1",
    "title": "On Learning by Exchanging Advice",
    "summary": "One of the main questions concerning learning in Multi-Agent Systems is:\n(How) can agents benefit from mutual interaction during the learning process?.\nThis paper describes the study of an interactive advice-exchange mechanism as a\npossible way to improve agents' learning performance. The advice-exchange\ntechnique, discussed here, uses supervised learning (backpropagation), where\nreinforcement is not directly coming from the environment but is based on\nadvice given by peers with better performance score (higher confidence), to\nenhance the performance of a heterogeneous group of Learning Agents (LAs). The\nLAs are facing similar problems, in an environment where only reinforcement\ninformation is available. Each LA applies a different, well known, learning\ntechnique: Random Walk (hill-climbing), Simulated Annealing, Evolutionary\nAlgorithms and Q-Learning. The problem used for evaluation is a simplified\ntraffic-control simulation. Initial results indicate that advice-exchange can\nimprove learning speed, although bad advice and/or blind reliance can disturb\nthe learning performance.",
    "published": "2002-03-07T10:16:25Z",
    "link": "http://arxiv.org/pdf/cs/0203010v1.pdf",
    "category": [
      "cs.LG",
      "cs.MA",
      "I.2.6; I.2.11"
    ],
    "authors": [
      "L. Nunes",
      "E. Oliveira"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0203011v1",
    "title": "Capturing Knowledge of User Preferences: ontologies on recommender\n  systems",
    "summary": "Tools for filtering the World Wide Web exist, but they are hampered by the\ndifficulty of capturing user preferences in such a dynamic environment. We\nexplore the acquisition of user profiles by unobtrusive monitoring of browsing\nbehaviour and application of supervised machine-learning techniques coupled\nwith an ontological representation to extract user preferences. A multi-class\napproach to paper classification is used, allowing the paper topic taxonomy to\nbe utilised during profile construction. The Quickstep recommender system is\npresented and two empirical studies evaluate it in a real work setting,\nmeasuring the effectiveness of using a hierarchical topic ontology compared\nwith an extendable flat list.",
    "published": "2002-03-08T15:58:23Z",
    "link": "http://arxiv.org/pdf/cs/0203011v1.pdf",
    "category": [
      "cs.LG",
      "cs.MA",
      "I.2.6;I.2.11"
    ],
    "authors": [
      "S. E. Middleton",
      "D. C. De Roure",
      "N. R. Shadbolt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0203012v1",
    "title": "Interface agents: A review of the field",
    "summary": "This paper reviews the origins of interface agents, discusses challenges that\nexist within the interface agent field and presents a survey of current\nattempts to find solutions to these challenges. A history of agent systems from\ntheir birth in the 1960's to the current day is described, along with the\nissues they try to address. A taxonomy of interface agent systems is presented,\nand today's agent systems categorized accordingly. Lastly, an analysis of the\nmachine learning and user modelling techniques used by today's agents is\npresented.",
    "published": "2002-03-09T01:28:33Z",
    "link": "http://arxiv.org/pdf/cs/0203012v1.pdf",
    "category": [
      "cs.MA",
      "cs.LG",
      "I.2.11;I.2.6"
    ],
    "authors": [
      "Stuart E. Middleton"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0204012v1",
    "title": "Exploiting Synergy Between Ontologies and Recommender Systems",
    "summary": "Recommender systems learn about user preferences over time, automatically\nfinding things of similar interest. This reduces the burden of creating\nexplicit queries. Recommender systems do, however, suffer from cold-start\nproblems where no initial information is available early on upon which to base\nrecommendations. Semantic knowledge structures, such as ontologies, can provide\nvaluable domain knowledge and user information. However, acquiring such\nknowledge and keeping it up to date is not a trivial task and user interests\nare particularly difficult to acquire and maintain. This paper investigates the\nsynergy between a web-based research paper recommender system and an ontology\ncontaining information automatically extracted from departmental databases\navailable on the web. The ontology is used to address the recommender systems\ncold-start problem. The recommender system addresses the ontology's\ninterest-acquisition problem. An empirical evaluation of this approach is\nconducted and the performance of the integrated systems measured.",
    "published": "2002-04-08T10:56:26Z",
    "link": "http://arxiv.org/pdf/cs/0204012v1.pdf",
    "category": [
      "cs.LG",
      "cs.MA",
      "K.3.2;I.2.11"
    ],
    "authors": [
      "Stuart E. Middleton",
      "Harith Alani",
      "David C. De Roure"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0204040v1",
    "title": "Self-Optimizing and Pareto-Optimal Policies in General Environments\n  based on Bayes-Mixtures",
    "summary": "The problem of making sequential decisions in unknown probabilistic\nenvironments is studied. In cycle $t$ action $y_t$ results in perception $x_t$\nand reward $r_t$, where all quantities in general may depend on the complete\nhistory. The perception $x_t$ and reward $r_t$ are sampled from the (reactive)\nenvironmental probability distribution $\\mu$. This very general setting\nincludes, but is not limited to, (partial observable, k-th order) Markov\ndecision processes. Sequential decision theory tells us how to act in order to\nmaximize the total expected reward, called value, if $\\mu$ is known.\nReinforcement learning is usually used if $\\mu$ is unknown. In the Bayesian\napproach one defines a mixture distribution $\\xi$ as a weighted sum of\ndistributions $\\nu\\in\\M$, where $\\M$ is any class of distributions including\nthe true environment $\\mu$. We show that the Bayes-optimal policy $p^\\xi$ based\non the mixture $\\xi$ is self-optimizing in the sense that the average value\nconverges asymptotically for all $\\mu\\in\\M$ to the optimal value achieved by\nthe (infeasible) Bayes-optimal policy $p^\\mu$ which knows $\\mu$ in advance. We\nshow that the necessary condition that $\\M$ admits self-optimizing policies at\nall, is also sufficient. No other structural assumptions are made on $\\M$. As\nan example application, we discuss ergodic Markov decision processes, which\nallow for self-optimizing policies. Furthermore, we show that $p^\\xi$ is\nPareto-optimal in the sense that there is no other policy yielding higher or\nequal value in {\\em all} environments $\\nu\\in\\M$ and a strictly higher value in\nat least one.",
    "published": "2002-04-17T10:46:00Z",
    "link": "http://arxiv.org/pdf/cs/0204040v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "math.OC",
      "math.PR",
      "I.2"
    ],
    "authors": [
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0204043v1",
    "title": "Learning from Scarce Experience",
    "summary": "Searching the space of policies directly for the optimal policy has been one\npopular method for solving partially observable reinforcement learning\nproblems. Typically, with each change of the target policy, its value is\nestimated from the results of following that very policy. This requires a large\nnumber of interactions with the environment as different polices are\nconsidered. We present a family of algorithms based on likelihood ratio\nestimation that use data gathered when executing one policy (or collection of\npolicies) to estimate the value of a different policy. The algorithms combine\nestimation and optimization stages. The former utilizes experience to build a\nnon-parametric representation of an optimized function. The latter performs\noptimization on this estimate. We show positive empirical results and provide\nthe sample complexity bound.",
    "published": "2002-04-20T05:02:53Z",
    "link": "http://arxiv.org/pdf/cs/0204043v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "cs.NE",
      "cs.RO",
      "I.2; I.2.8; I.2.11; I.2.6; G.1.6"
    ],
    "authors": [
      "Leonid Peshkin",
      "Christian R. Shelton"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0204052v1",
    "title": "Required sample size for learning sparse Bayesian networks with many\n  variables",
    "summary": "Learning joint probability distributions on n random variables requires\nexponential sample size in the generic case. Here we consider the case that a\ntemporal (or causal) order of the variables is known and that the (unknown)\ngraph of causal dependencies has bounded in-degree Delta. Then the joint\nmeasure is uniquely determined by the probabilities of all (2 Delta+1)-tuples.\nUpper bounds on the sample size required for estimating their probabilities can\nbe given in terms of the VC-dimension of the set of corresponding cylinder\nsets. The sample size grows less than linearly with n.",
    "published": "2002-04-26T14:33:29Z",
    "link": "http://arxiv.org/pdf/cs/0204052v1.pdf",
    "category": [
      "cs.LG",
      "math.PR",
      "I.2.6"
    ],
    "authors": [
      "Pawel Wocjan",
      "Dominik Janzing",
      "Thomas Beth"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0205025v1",
    "title": "Bootstrapping Structure into Language: Alignment-Based Learning",
    "summary": "This thesis introduces a new unsupervised learning framework, called\nAlignment-Based Learning, which is based on the alignment of sentences and\nHarris's (1951) notion of substitutability. Instances of the framework can be\napplied to an untagged, unstructured corpus of natural language sentences,\nresulting in a labelled, bracketed version of that corpus.\n  Firstly, the framework aligns all sentences in the corpus in pairs, resulting\nin a partition of the sentences consisting of parts of the sentences that are\nequal in both sentences and parts that are unequal. Unequal parts of sentences\ncan be seen as being substitutable for each other, since substituting one\nunequal part for the other results in another valid sentence. The unequal parts\nof the sentences are thus considered to be possible (possibly overlapping)\nconstituents, called hypotheses.\n  Secondly, the selection learning phase considers all hypotheses found by the\nalignment learning phase and selects the best of these. The hypotheses are\nselected based on the order in which they were found, or based on a\nprobabilistic function.\n  The framework can be extended with a grammar extraction phase. This extended\nframework is called parseABL. Instead of returning a structured version of the\nunstructured input corpus, like the ABL system, this system also returns a\nstochastic context-free or tree substitution grammar.\n  Different instances of the framework have been tested on the English ATIS\ncorpus, the Dutch OVIS corpus and the Wall Street Journal corpus. One of the\ninteresting results, apart from the encouraging numerical results, is that all\ninstances can (and do) learn recursive structures.",
    "published": "2002-05-16T12:35:00Z",
    "link": "http://arxiv.org/pdf/cs/0205025v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL",
      "I.2; I.2.6; I.2.7"
    ],
    "authors": [
      "Menno M. van Zaanen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0205070v1",
    "title": "Thumbs up? Sentiment Classification using Machine Learning Techniques",
    "summary": "We consider the problem of classifying documents not by topic, but by overall\nsentiment, e.g., determining whether a review is positive or negative. Using\nmovie reviews as data, we find that standard machine learning techniques\ndefinitively outperform human-produced baselines. However, the three machine\nlearning methods we employed (Naive Bayes, maximum entropy classification, and\nsupport vector machines) do not perform as well on sentiment classification as\non traditional topic-based categorization. We conclude by examining factors\nthat make the sentiment classification problem more challenging.",
    "published": "2002-05-28T02:01:55Z",
    "link": "http://arxiv.org/pdf/cs/0205070v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG",
      "I.2.7; I.2.6"
    ],
    "authors": [
      "Bo Pang",
      "Lillian Lee",
      "Shivakumar Vaithyanathan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0205072v1",
    "title": "Unsupervised Learning of Morphology without Morphemes",
    "summary": "The first morphological learner based upon the theory of Whole Word\nMorphology Ford et al. (1997) is outlined, and preliminary evaluation results\nare presented. The program, Whole Word Morphologizer, takes a POS-tagged\nlexicon as input, induces morphological relationships without attempting to\ndiscover or identify morphemes, and is then able to generate new words beyond\nthe learning sample. The accuracy (precision) of the generated new words is as\nhigh as 80% using the pure Whole Word theory, and 92% after a post-hoc\nadjustment is added to the routine.",
    "published": "2002-05-29T17:48:48Z",
    "link": "http://arxiv.org/pdf/cs/0205072v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG",
      "I.2.6"
    ],
    "authors": [
      "Sylvain Neuvel",
      "Sean A. Fulop"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0206006v1",
    "title": "Robust Feature Selection by Mutual Information Distributions",
    "summary": "Mutual information is widely used in artificial intelligence, in a\ndescriptive way, to measure the stochastic dependence of discrete random\nvariables. In order to address questions such as the reliability of the\nempirical value, one must consider sample-to-population inferential approaches.\nThis paper deals with the distribution of mutual information, as obtained in a\nBayesian framework by a second-order Dirichlet prior distribution. The exact\nanalytical expression for the mean and an analytical approximation of the\nvariance are reported. Asymptotic approximations of the distribution are\nproposed. The results are applied to the problem of selecting features for\nincremental learning and classification of the naive Bayes classifier. A fast,\nnewly defined method is shown to outperform the traditional approach based on\nempirical mutual information on a number of real data sets. Finally, a\ntheoretical development is reported that allows one to efficiently extend the\nabove methods to incomplete samples in an easy and effective way.",
    "published": "2002-06-03T16:00:55Z",
    "link": "http://arxiv.org/pdf/cs/0206006v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "I.2"
    ],
    "authors": [
      "Marco Zaffalon",
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0206017v1",
    "title": "The Prioritized Inductive Logic Programs",
    "summary": "The limit behavior of inductive logic programs has not been explored, but\nwhen considering incremental or online inductive learning algorithms which\nusually run ongoingly, such behavior of the programs should be taken into\naccount. An example is given to show that some inductive learning algorithm may\nnot be correct in the long run if the limit behavior is not considered. An\ninductive logic program is convergent if given an increasing sequence of\nexample sets, the program produces a corresponding sequence of the Horn logic\nprograms which has the set-theoretic limit, and is limit-correct if the limit\nof the produced sequence of the Horn logic programs is correct with respect to\nthe limit of the sequence of the example sets. It is shown that the GOLEM\nsystem is not limit-correct. Finally, a limit-correct inductive logic system,\ncalled the prioritized GOLEM system, is proposed as a solution.",
    "published": "2002-06-10T16:02:36Z",
    "link": "http://arxiv.org/pdf/cs/0206017v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "I.2.3; I.2.6"
    ],
    "authors": [
      "Shilong Ma",
      "Yuefei Sui",
      "Ke Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0207097v2",
    "title": "Optimal Ordered Problem Solver",
    "summary": "We present a novel, general, optimally fast, incremental way of searching for\na universal algorithm that solves each task in a sequence of tasks. The Optimal\nOrdered Problem Solver (OOPS) continually organizes and exploits previously\nfound solutions to earlier tasks, efficiently searching not only the space of\ndomain-specific algorithms, but also the space of search algorithms.\nEssentially we extend the principles of optimal nonincremental universal search\nto build an incremental universal learner that is able to improve itself\nthrough experience. In illustrative experiments, our self-improver becomes the\nfirst general system that learns to solve all n disk Towers of Hanoi tasks\n(solution size 2^n-1) for n up to 30, profiting from previously solved, simpler\ntasks involving samples of a simple context free language.",
    "published": "2002-07-31T14:33:11Z",
    "link": "http://arxiv.org/pdf/cs/0207097v2.pdf",
    "category": [
      "cs.AI",
      "cs.CC",
      "cs.LG",
      "I.2.2;I.2.6;I.2.8"
    ],
    "authors": [
      "Juergen Schmidhuber"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0210025v3",
    "title": "An Algorithm for Pattern Discovery in Time Series",
    "summary": "We present a new algorithm for discovering patterns in time series and other\nsequential data. We exhibit a reliable procedure for building the minimal set\nof hidden, Markovian states that is statistically capable of producing the\nbehavior exhibited in the data -- the underlying process's causal states.\nUnlike conventional methods for fitting hidden Markov models (HMMs) to data,\nour algorithm makes no assumptions about the process's causal architecture (the\nnumber of hidden states and their transition structure), but rather infers it\nfrom the data. It starts with assumptions of minimal structure and introduces\ncomplexity only when the data demand it. Moreover, the causal states it infers\nhave important predictive optimality properties that conventional HMM states\nlack. We introduce the algorithm, review the theory behind it, prove its\nasymptotic reliability, use large deviation theory to estimate its rate of\nconvergence, and compare it to other algorithms which also construct HMMs from\ndata. We also illustrate its behavior on an example process, and report\nselected numerical results from an implementation.",
    "published": "2002-10-29T00:33:26Z",
    "link": "http://arxiv.org/pdf/cs/0210025v3.pdf",
    "category": [
      "cs.LG",
      "cs.CL",
      "I.2.6;H.1.1;E.4"
    ],
    "authors": [
      "Cosma Rohilla Shalizi",
      "Kristina Lisa Shalizi",
      "James P. Crutchfield"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0211003v1",
    "title": "Evaluation of the Performance of the Markov Blanket Bayesian Classifier\n  Algorithm",
    "summary": "The Markov Blanket Bayesian Classifier is a recently-proposed algorithm for\nconstruction of probabilistic classifiers. This paper presents an empirical\ncomparison of the MBBC algorithm with three other Bayesian classifiers: Naive\nBayes, Tree-Augmented Naive Bayes and a general Bayesian network. All of these\nare implemented using the K2 framework of Cooper and Herskovits. The\nclassifiers are compared in terms of their performance (using simple accuracy\nmeasures and ROC curves) and speed, on a range of standard benchmark data sets.\nIt is concluded that MBBC is competitive in terms of speed and accuracy with\nthe other algorithms considered.",
    "published": "2002-11-01T18:09:56Z",
    "link": "http://arxiv.org/pdf/cs/0211003v1.pdf",
    "category": [
      "cs.LG",
      "I.2.6"
    ],
    "authors": [
      "Michael G. Madden"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0211006v1",
    "title": "Maximing the Margin in the Input Space",
    "summary": "We propose a novel criterion for support vector machine learning: maximizing\nthe margin in the input space, not in the feature (Hilbert) space. This\ncriterion is a discriminative version of the principal curve proposed by Hastie\net al. The criterion is appropriate in particular when the input space is\nalready a well-designed feature space with rather small dimensionality. The\ndefinition of the margin is generalized in order to represent prior knowledge.\nThe derived algorithm consists of two alternating steps to estimate the dual\nparameters. Firstly, the parameters are initialized by the original SVM. Then\none set of parameters is updated by Newton-like procedure, and the other set is\nupdated by solving a quadratic programming problem. The algorithm converges in\na few steps to a local optimum under mild conditions and it preserves the\nsparsity of support vectors. Although the complexity to calculate temporal\nvariables increases the complexity to solve the quadratic programming problem\nfor each step does not change. It is also shown that the original SVM can be\nseen as a special case. We further derive a simplified algorithm which enables\nus to use the existing code for the original SVM.",
    "published": "2002-11-07T06:44:54Z",
    "link": "http://arxiv.org/pdf/cs/0211006v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "I.2.6; I.5.1"
    ],
    "authors": [
      "Shotaro Akaho"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0211007v1",
    "title": "Approximating Incomplete Kernel Matrices by the em Algorithm",
    "summary": "In biological data, it is often the case that observed data are available\nonly for a subset of samples. When a kernel matrix is derived from such data,\nwe have to leave the entries for unavailable samples as missing. In this paper,\nwe make use of a parametric model of kernel matrices, and estimate missing\nentries by fitting the model to existing entries. The parametric model is\ncreated as a set of spectral variants of a complete kernel matrix derived from\nanother information source. For model fitting, we adopt the em algorithm based\non the information geometry of positive definite matrices. We will report\npromising results on bacteria clustering experiments using two marker\nsequences: 16S and gyrB.",
    "published": "2002-11-07T07:21:58Z",
    "link": "http://arxiv.org/pdf/cs/0211007v1.pdf",
    "category": [
      "cs.LG",
      "I2.6; I5.2"
    ],
    "authors": [
      "Koji Tsuda",
      "Shotaro Akaho",
      "Kiyoshi Asai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0212008v1",
    "title": "Principal Manifolds and Nonlinear Dimension Reduction via Local Tangent\n  Space Alignment",
    "summary": "Nonlinear manifold learning from unorganized data points is a very\nchallenging unsupervised learning and data visualization problem with a great\nvariety of applications. In this paper we present a new algorithm for manifold\nlearning and nonlinear dimension reduction. Based on a set of unorganized data\npoints sampled with noise from the manifold, we represent the local geometry of\nthe manifold using tangent spaces learned by fitting an affine subspace in a\nneighborhood of each data point. Those tangent spaces are aligned to give the\ninternal global coordinates of the data points with respect to the underlying\nmanifold by way of a partial eigendecomposition of the neighborhood connection\nmatrix. We present a careful error analysis of our algorithm and show that the\nreconstruction errors are of second-order accuracy. We illustrate our algorithm\nusing curves and surfaces both in\n  2D/3D and higher dimensional Euclidean spaces, and 64-by-64 pixel face images\nwith various pose and lighting conditions. We also address several theoretical\nand algorithmic issues for further research and improvements.",
    "published": "2002-12-07T18:51:12Z",
    "link": "http://arxiv.org/pdf/cs/0212008v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "I.5.1;I5.3"
    ],
    "authors": [
      "Zhenyue Zhang",
      "Hongyuan Zha"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0212011v1",
    "title": "Mining the Web for Lexical Knowledge to Improve Keyphrase Extraction:\n  Learning from Labeled and Unlabeled Data",
    "summary": "Keyphrases are useful for a variety of purposes, including summarizing,\nindexing, labeling, categorizing, clustering, highlighting, browsing, and\nsearching. The task of automatic keyphrase extraction is to select keyphrases\nfrom within the text of a given document. Automatic keyphrase extraction makes\nit feasible to generate keyphrases for the huge number of documents that do not\nhave manually assigned keyphrases. Good performance on this task has been\nobtained by approaching it as a supervised learning problem. An input document\nis treated as a set of candidate phrases that must be classified as either\nkeyphrases or non-keyphrases. To classify a candidate phrase as a keyphrase,\nthe most important features (attributes) appear to be the frequency and\nlocation of the candidate phrase in the document. Recent work has demonstrated\nthat it is also useful to know the frequency of the candidate phrase as a\nmanually assigned keyphrase for other documents in the same domain as the given\ndocument (e.g., the domain of computer science). Unfortunately, this\nkeyphrase-frequency feature is domain-specific (the learning process must be\nrepeated for each new domain) and training-intensive (good performance requires\na relatively large number of training documents in the given domain, with\nmanually assigned keyphrases). The aim of the work described here is to remove\nthese limitations. In this paper, I introduce new features that are derived by\nmining lexical knowledge from a very large collection of unlabeled data,\nconsisting of approximately 350 million Web pages without manually assigned\nkeyphrases. I present experiments that show that the new features result in\nimproved keyphrase extraction, although they are neither domain-specific nor\ntraining-intensive.",
    "published": "2002-12-08T18:52:33Z",
    "link": "http://arxiv.org/pdf/cs/0212011v1.pdf",
    "category": [
      "cs.LG",
      "cs.IR",
      "H.3.1; H.3.3; I.2.6; I.2.7"
    ],
    "authors": [
      "Peter D. Turney"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0212012v1",
    "title": "Unsupervised Learning of Semantic Orientation from a\n  Hundred-Billion-Word Corpus",
    "summary": "The evaluative character of a word is called its semantic orientation. A\npositive semantic orientation implies desirability (e.g., \"honest\", \"intrepid\")\nand a negative semantic orientation implies undesirability (e.g., \"disturbing\",\n\"superfluous\"). This paper introduces a simple algorithm for unsupervised\nlearning of semantic orientation from extremely large corpora. The method\ninvolves issuing queries to a Web search engine and using pointwise mutual\ninformation to analyse the results. The algorithm is empirically evaluated\nusing a training corpus of approximately one hundred billion words -- the\nsubset of the Web that is indexed by the chosen search engine. Tested with\n3,596 words (1,614 positive and 1,982 negative), the algorithm attains an\naccuracy of 80%. The 3,596 test words include adjectives, adverbs, nouns, and\nverbs. The accuracy is comparable with the results achieved by Hatzivassiloglou\nand McKeown (1997), using a complex four-stage supervised learning algorithm\nthat is restricted to determining the semantic orientation of adjectives.",
    "published": "2002-12-08T19:06:08Z",
    "link": "http://arxiv.org/pdf/cs/0212012v1.pdf",
    "category": [
      "cs.LG",
      "cs.IR",
      "H.3.1; H.3.3; I.2.6; I.2.7"
    ],
    "authors": [
      "Peter D. Turney",
      "Michael L. Littman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0212013v1",
    "title": "Learning to Extract Keyphrases from Text",
    "summary": "Many academic journals ask their authors to provide a list of about five to\nfifteen key words, to appear on the first page of each article. Since these key\nwords are often phrases of two or more words, we prefer to call them\nkeyphrases. There is a surprisingly wide variety of tasks for which keyphrases\nare useful, as we discuss in this paper. Recent commercial software, such as\nMicrosoft's Word 97 and Verity's Search 97, includes algorithms that\nautomatically extract keyphrases from documents. In this paper, we approach the\nproblem of automatically extracting keyphrases from text as a supervised\nlearning task. We treat a document as a set of phrases, which the learning\nalgorithm must learn to classify as positive or negative examples of\nkeyphrases. Our first set of experiments applies the C4.5 decision tree\ninduction algorithm to this learning task. The second set of experiments\napplies the GenEx algorithm to the task. We developed the GenEx algorithm\nspecifically for this task. The third set of experiments examines the\nperformance of GenEx on the task of metadata generation, relative to the\nperformance of Microsoft's Word 97. The fourth and final set of experiments\ninvestigates the performance of GenEx on the task of highlighting, relative to\nVerity's Search 97. The experimental results support the claim that a\nspecialized learning algorithm (GenEx) can generate better keyphrases than a\ngeneral-purpose learning algorithm (C4.5) and the non-learning algorithms that\nare used in commercial software (Word 97 and Search 97).",
    "published": "2002-12-08T19:27:56Z",
    "link": "http://arxiv.org/pdf/cs/0212013v1.pdf",
    "category": [
      "cs.LG",
      "cs.IR",
      "H.3.1; H.3.3; I.2.6; I.2.7"
    ],
    "authors": [
      "Peter D. Turney"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0212014v1",
    "title": "Extraction of Keyphrases from Text: Evaluation of Four Algorithms",
    "summary": "This report presents an empirical evaluation of four algorithms for\nautomatically extracting keywords and keyphrases from documents. The four\nalgorithms are compared using five different collections of documents. For each\ndocument, we have a target set of keyphrases, which were generated by hand. The\ntarget keyphrases were generated for human readers; they were not tailored for\nany of the four keyphrase extraction algorithms. Each of the algorithms was\nevaluated by the degree to which the algorithm's keyphrases matched the\nmanually generated keyphrases. The four algorithms were (1) the AutoSummarize\nfeature in Microsoft's Word 97, (2) an algorithm based on Eric Brill's\npart-of-speech tagger, (3) the Summarize feature in Verity's Search 97, and (4)\nNRC's Extractor algorithm. For all five document collections, NRC's Extractor\nyields the best match with the manually generated keyphrases.",
    "published": "2002-12-08T19:40:42Z",
    "link": "http://arxiv.org/pdf/cs/0212014v1.pdf",
    "category": [
      "cs.LG",
      "cs.IR",
      "H.3.1; H.3.3; I.2.6; I.2.7"
    ],
    "authors": [
      "Peter D. Turney"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0212020v1",
    "title": "Learning Algorithms for Keyphrase Extraction",
    "summary": "Many academic journals ask their authors to provide a list of about five to\nfifteen keywords, to appear on the first page of each article. Since these key\nwords are often phrases of two or more words, we prefer to call them\nkeyphrases. There is a wide variety of tasks for which keyphrases are useful,\nas we discuss in this paper. We approach the problem of automatically\nextracting keyphrases from text as a supervised learning task. We treat a\ndocument as a set of phrases, which the learning algorithm must learn to\nclassify as positive or negative examples of keyphrases. Our first set of\nexperiments applies the C4.5 decision tree induction algorithm to this learning\ntask. We evaluate the performance of nine different configurations of C4.5. The\nsecond set of experiments applies the GenEx algorithm to the task. We developed\nthe GenEx algorithm specifically for automatically extracting keyphrases from\ntext. The experimental results support the claim that a custom-designed\nalgorithm (GenEx), incorporating specialized procedural domain knowledge, can\ngenerate better keyphrases than a generalpurpose algorithm (C4.5). Subjective\nhuman evaluation of the keyphrases generated by Extractor suggests that about\n80% of the keyphrases are acceptable to human readers. This level of\nperformance should be satisfactory for a wide variety of applications.",
    "published": "2002-12-10T15:30:56Z",
    "link": "http://arxiv.org/pdf/cs/0212020v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL",
      "cs.IR",
      "H.3.1; H.3.3; I.2.6; I.2.7"
    ],
    "authors": [
      "Peter D. Turney"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0212023v1",
    "title": "How to Shift Bias: Lessons from the Baldwin Effect",
    "summary": "An inductive learning algorithm takes a set of data as input and generates a\nhypothesis as output. A set of data is typically consistent with an infinite\nnumber of hypotheses; therefore, there must be factors other than the data that\ndetermine the output of the learning algorithm. In machine learning, these\nother factors are called the bias of the learner. Classical learning algorithms\nhave a fixed bias, implicit in their design. Recently developed learning\nalgorithms dynamically adjust their bias as they search for a hypothesis.\nAlgorithms that shift bias in this manner are not as well understood as\nclassical algorithms. In this paper, we show that the Baldwin effect has\nimplications for the design and analysis of bias shifting algorithms. The\nBaldwin effect was proposed in 1896, to explain how phenomena that might appear\nto require Lamarckian evolution (inheritance of acquired characteristics) can\narise from purely Darwinian evolution. Hinton and Nowlan presented a\ncomputational model of the Baldwin effect in 1987. We explore a variation on\ntheir model, which we constructed explicitly to illustrate the lessons that the\nBaldwin effect has for research in bias shifting algorithms. The main lesson is\nthat it appears that a good strategy for shift of bias in a learning algorithm\nis to begin with a weak bias and gradually shift to a strong bias.",
    "published": "2002-12-10T18:19:54Z",
    "link": "http://arxiv.org/pdf/cs/0212023v1.pdf",
    "category": [
      "cs.LG",
      "cs.NE",
      "I.2.6; I.2.8"
    ],
    "authors": [
      "Peter D. Turney"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0212024v1",
    "title": "Unsupervised Language Acquisition: Theory and Practice",
    "summary": "In this thesis I present various algorithms for the unsupervised machine\nlearning of aspects of natural languages using a variety of statistical models.\nThe scientific object of the work is to examine the validity of the so-called\nArgument from the Poverty of the Stimulus advanced in favour of the proposition\nthat humans have language-specific innate knowledge. I start by examining an a\npriori argument based on Gold's theorem, that purports to prove that natural\nlanguages cannot be learned, and some formal issues related to the choice of\nstatistical grammars rather than symbolic grammars. I present three novel\nalgorithms for learning various parts of natural languages: first, an algorithm\nfor the induction of syntactic categories from unlabelled text using\ndistributional information, that can deal with ambiguous and rare words;\nsecondly, a set of algorithms for learning morphological processes in a variety\nof languages, including languages such as Arabic with non-concatenative\nmorphology; thirdly an algorithm for the unsupervised induction of a\ncontext-free grammar from tagged text. I carefully examine the interaction\nbetween the various components, and show how these algorithms can form the\nbasis for a empiricist model of language acquisition. I therefore conclude that\nthe Argument from the Poverty of the Stimulus is unsupported by the evidence.",
    "published": "2002-12-10T21:59:15Z",
    "link": "http://arxiv.org/pdf/cs/0212024v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG",
      "I.2.6; I.2.7"
    ],
    "authors": [
      "Alexander Clark"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0212032v1",
    "title": "Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised\n  Classification of Reviews",
    "summary": "This paper presents a simple unsupervised learning algorithm for classifying\nreviews as recommended (thumbs up) or not recommended (thumbs down). The\nclassification of a review is predicted by the average semantic orientation of\nthe phrases in the review that contain adjectives or adverbs. A phrase has a\npositive semantic orientation when it has good associations (e.g., \"subtle\nnuances\") and a negative semantic orientation when it has bad associations\n(e.g., \"very cavalier\"). In this paper, the semantic orientation of a phrase is\ncalculated as the mutual information between the given phrase and the word\n\"excellent\" minus the mutual information between the given phrase and the word\n\"poor\". A review is classified as recommended if the average semantic\norientation of its phrases is positive. The algorithm achieves an average\naccuracy of 74% when evaluated on 410 reviews from Epinions, sampled from four\ndifferent domains (reviews of automobiles, banks, movies, and travel\ndestinations). The accuracy ranges from 84% for automobile reviews to 66% for\nmovie reviews.",
    "published": "2002-12-11T18:57:42Z",
    "link": "http://arxiv.org/pdf/cs/0212032v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL",
      "cs.IR",
      "I.2.6; I.2.7; H.3.1; H.3.3"
    ],
    "authors": [
      "Peter D. Turney"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0212033v1",
    "title": "Mining the Web for Synonyms: PMI-IR versus LSA on TOEFL",
    "summary": "This paper presents a simple unsupervised learning algorithm for recognizing\nsynonyms, based on statistical data acquired by querying a Web search engine.\nThe algorithm, called PMI-IR, uses Pointwise Mutual Information (PMI) and\nInformation Retrieval (IR) to measure the similarity of pairs of words. PMI-IR\nis empirically evaluated using 80 synonym test questions from the Test of\nEnglish as a Foreign Language (TOEFL) and 50 synonym test questions from a\ncollection of tests for students of English as a Second Language (ESL). On both\ntests, the algorithm obtains a score of 74%. PMI-IR is contrasted with Latent\nSemantic Analysis (LSA), which achieves a score of 64% on the same 80 TOEFL\nquestions. The paper discusses potential applications of the new unsupervised\nlearning algorithm and some implications of the results for LSA and LSI (Latent\nSemantic Indexing).",
    "published": "2002-12-11T19:17:06Z",
    "link": "http://arxiv.org/pdf/cs/0212033v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL",
      "cs.IR",
      "I.2.6; I.2.7; H.3.1; H.3.3"
    ],
    "authors": [
      "Peter D. Turney"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0212036v1",
    "title": "Myths and Legends of the Baldwin Effect",
    "summary": "This position paper argues that the Baldwin effect is widely misunderstood by\nthe evolutionary computation community. The misunderstandings appear to fall\ninto two general categories. Firstly, it is commonly believed that the Baldwin\neffect is concerned with the synergy that results when there is an evolving\npopulation of learning individuals. This is only half of the story. The full\nstory is more complicated and more interesting. The Baldwin effect is concerned\nwith the costs and benefits of lifetime learning by individuals in an evolving\npopulation. Several researchers have focussed exclusively on the benefits, but\nthere is much to be gained from attention to the costs. This paper explains the\ntwo sides of the story and enumerates ten of the costs and benefits of lifetime\nlearning by individuals in an evolving population. Secondly, there is a cluster\nof misunderstandings about the relationship between the Baldwin effect and\nLamarckian inheritance of acquired characteristics. The Baldwin effect is not\nLamarckian. A Lamarckian algorithm is not better for most evolutionary\ncomputing problems than a Baldwinian algorithm. Finally, Lamarckian inheritance\nis not a better model of memetic (cultural) evolution than the Baldwin effect.",
    "published": "2002-12-11T21:34:18Z",
    "link": "http://arxiv.org/pdf/cs/0212036v1.pdf",
    "category": [
      "cs.LG",
      "cs.NE",
      "I.2.6; I.2.8"
    ],
    "authors": [
      "Peter D. Turney"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0212039v1",
    "title": "Low Size-Complexity Inductive Logic Programming: The East-West Challenge\n  Considered as a Problem in Cost-Sensitive Classification",
    "summary": "The Inductive Logic Programming community has considered proof-complexity and\nmodel-complexity, but, until recently, size-complexity has received little\nattention. Recently a challenge was issued \"to the international computing\ncommunity\" to discover low size-complexity Prolog programs for classifying\ntrains. The challenge was based on a problem first proposed by Ryszard\nMichalski, 20 years ago. We interpreted the challenge as a problem in\ncost-sensitive classification and we applied a recently developed\ncost-sensitive classifier to the competition. Our algorithm was relatively\nsuccessful (we won a prize). This paper presents our algorithm and analyzes the\nresults of the competition.",
    "published": "2002-12-12T18:51:06Z",
    "link": "http://arxiv.org/pdf/cs/0212039v1.pdf",
    "category": [
      "cs.LG",
      "cs.NE",
      "I.2.6; I.2.8"
    ],
    "authors": [
      "Peter D. Turney"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0301007v1",
    "title": "Kalman filter control in the reinforcement learning framework",
    "summary": "There is a growing interest in using Kalman-filter models in brain modelling.\nIn turn, it is of considerable importance to make Kalman-filters amenable for\nreinforcement learning. In the usual formulation of optimal control it is\ncomputed off-line by solving a backward recursion. In this technical note we\nshow that slight modification of the linear-quadratic-Gaussian Kalman-filter\nmodel allows the on-line estimation of optimal control and makes the bridge to\nreinforcement learning. Moreover, the learning rule for value estimation\nassumes a Hebbian form weighted by the error of the value estimation.",
    "published": "2003-01-09T15:08:47Z",
    "link": "http://arxiv.org/pdf/cs/0301007v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "I.2.6; I.2.8"
    ],
    "authors": [
      "Istvan Szita",
      "Andras Lorincz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0301014v1",
    "title": "Convergence and Loss Bounds for Bayesian Sequence Prediction",
    "summary": "The probability of observing $x_t$ at time $t$, given past observations\n$x_1...x_{t-1}$ can be computed with Bayes' rule if the true generating\ndistribution $\\mu$ of the sequences $x_1x_2x_3...$ is known. If $\\mu$ is\nunknown, but known to belong to a class $M$ one can base ones prediction on the\nBayes mix $\\xi$ defined as a weighted sum of distributions $\\nu\\in M$. Various\nconvergence results of the mixture posterior $\\xi_t$ to the true posterior\n$\\mu_t$ are presented. In particular a new (elementary) derivation of the\nconvergence $\\xi_t/\\mu_t\\to 1$ is provided, which additionally gives the rate\nof convergence. A general sequence predictor is allowed to choose an action\n$y_t$ based on $x_1...x_{t-1}$ and receives loss $\\ell_{x_t y_t}$ if $x_t$ is\nthe next symbol of the sequence. No assumptions are made on the structure of\n$\\ell$ (apart from being bounded) and $M$. The Bayes-optimal prediction scheme\n$\\Lambda_\\xi$ based on mixture $\\xi$ and the Bayes-optimal informed prediction\nscheme $\\Lambda_\\mu$ are defined and the total loss $L_\\xi$ of $\\Lambda_\\xi$ is\nbounded in terms of the total loss $L_\\mu$ of $\\Lambda_\\mu$. It is shown that\n$L_\\xi$ is bounded for bounded $L_\\mu$ and $L_\\xi/L_\\mu\\to 1$ for $L_\\mu\\to\n\\infty$. Convergence of the instantaneous losses are also proven.",
    "published": "2003-01-16T16:36:15Z",
    "link": "http://arxiv.org/pdf/cs/0301014v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "math.PR",
      "E.4;I.2.6;G.3"
    ],
    "authors": [
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0302012v2",
    "title": "The New AI: General & Sound & Relevant for Physics",
    "summary": "Most traditional artificial intelligence (AI) systems of the past 50 years\nare either very limited, or based on heuristics, or both. The new millennium,\nhowever, has brought substantial progress in the field of theoretically optimal\nand practically feasible algorithms for prediction, search, inductive inference\nbased on Occam's razor, problem solving, decision making, and reinforcement\nlearning in environments of a very general type. Since inductive inference is\nat the heart of all inductive sciences, some of the results are relevant not\nonly for AI and computer science but also for physics, provoking nontraditional\npredictions based on Zuse's thesis of the computer-generated universe.",
    "published": "2003-02-10T14:17:33Z",
    "link": "http://arxiv.org/pdf/cs/0302012v2.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "quant-ph",
      "I.2"
    ],
    "authors": [
      "Juergen Schmidhuber"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0302015v1",
    "title": "Unsupervised Learning in a Framework of Information Compression by\n  Multiple Alignment, Unification and Search",
    "summary": "This paper describes a novel approach to unsupervised learning that has been\ndeveloped within a framework of \"information compression by multiple alignment,\nunification and search\" (ICMAUS), designed to integrate learning with other AI\nfunctions such as parsing and production of language, fuzzy pattern\nrecognition, probabilistic and exact forms of reasoning, and others.",
    "published": "2003-02-12T09:39:00Z",
    "link": "http://arxiv.org/pdf/cs/0302015v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "I.2.4; I.2.6; I.2.7"
    ],
    "authors": [
      "J. G. Wolff"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0303025v1",
    "title": "Algorithmic Clustering of Music",
    "summary": "We present a fully automatic method for music classification, based only on\ncompression of strings that represent the music pieces. The method uses no\nbackground knowledge about music whatsoever: it is completely general and can,\nwithout change, be used in different areas like linguistic classification and\ngenomics. It is based on an ideal theory of the information content in\nindividual objects (Kolmogorov complexity), information distance, and a\nuniversal similarity metric. Experiments show that the method distinguishes\nreasonably well between various musical genres and can even cluster pieces by\ncomposer.",
    "published": "2003-03-24T16:01:46Z",
    "link": "http://arxiv.org/pdf/cs/0303025v1.pdf",
    "category": [
      "cs.SD",
      "cs.LG",
      "physics.data-an",
      "E.4, H.3.1, I.5.3, F.1.3, J.5"
    ],
    "authors": [
      "Rudi Cilibrasi",
      "Paul Vitanyi",
      "Ronald de Wolf"
    ]
  },
  {
    "id": "http://arxiv.org/abs/math/0305121v1",
    "title": "Robust Estimators under the Imprecise Dirichlet Model",
    "summary": "Walley's Imprecise Dirichlet Model (IDM) for categorical data overcomes\nseveral fundamental problems which other approaches to uncertainty suffer from.\nYet, to be useful in practice, one needs efficient ways for computing the\nimprecise=robust sets or intervals. The main objective of this work is to\nderive exact, conservative, and approximate, robust and credible interval\nestimates under the IDM for a large class of statistical estimators, including\nthe entropy and mutual information.",
    "published": "2003-05-08T17:11:45Z",
    "link": "http://arxiv.org/pdf/math/0305121v1.pdf",
    "category": [
      "math.PR",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "math.ST",
      "stat.TH"
    ],
    "authors": [
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0305052v1",
    "title": "On the Existence and Convergence Computable Universal Priors",
    "summary": "Solomonoff unified Occam's razor and Epicurus' principle of multiple\nexplanations to one elegant, formal, universal theory of inductive inference,\nwhich initiated the field of algorithmic information theory. His central result\nis that the posterior of his universal semimeasure M converges rapidly to the\ntrue sequence generating posterior mu, if the latter is computable. Hence, M is\neligible as a universal predictor in case of unknown mu. We investigate the\nexistence and convergence of computable universal (semi)measures for a\nhierarchy of computability classes: finitely computable, estimable, enumerable,\nand approximable. For instance, M is known to be enumerable, but not finitely\ncomputable, and to dominate all enumerable semimeasures. We define seven\nclasses of (semi)measures based on these four computability concepts. Each\nclass may or may not contain a (semi)measure which dominates all elements of\nanother class. The analysis of these 49 cases can be reduced to four basic\ncases, two of them being new. The results hold for discrete and continuous\nsemimeasures. We also investigate more closely the types of convergence,\npossibly implied by universality: in difference and in ratio, with probability\n1, in mean sum, and for Martin-Loef random sequences. We introduce a\ngeneralized concept of randomness for individual sequences and use it to\nexhibit difficulties regarding these issues.",
    "published": "2003-05-29T11:11:01Z",
    "link": "http://arxiv.org/pdf/cs/0305052v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CC",
      "math.ST",
      "stat.TH",
      "G.3; I.2"
    ],
    "authors": [
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0306036v1",
    "title": "Sequence Prediction based on Monotone Complexity",
    "summary": "This paper studies sequence prediction based on the monotone Kolmogorov\ncomplexity Km=-log m, i.e. based on universal deterministic/one-part MDL. m is\nextremely close to Solomonoff's prior M, the latter being an excellent\npredictor in deterministic as well as probabilistic environments, where\nperformance is measured in terms of convergence of posteriors or losses.\nDespite this closeness to M, it is difficult to assess the prediction quality\nof m, since little is known about the closeness of their posteriors, which are\nthe important quantities for prediction. We show that for deterministic\ncomputable environments, the \"posterior\" and losses of m converge, but rapid\nconvergence could only be shown on-sequence; the off-sequence behavior is\nunclear. In probabilistic environments, neither the posterior nor the losses\nconverge, in general.",
    "published": "2003-06-07T19:21:20Z",
    "link": "http://arxiv.org/pdf/cs/0306036v1.pdf",
    "category": [
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "math.ST",
      "stat.TH",
      "I.2"
    ],
    "authors": [
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0306091v2",
    "title": "Universal Sequential Decisions in Unknown Environments",
    "summary": "We give a brief introduction to the AIXI model, which unifies and overcomes\nthe limitations of sequential decision theory and universal Solomonoff\ninduction. While the former theory is suited for active agents in known\nenvironments, the latter is suited for passive prediction of unknown\nenvironments.",
    "published": "2003-06-16T13:15:29Z",
    "link": "http://arxiv.org/pdf/cs/0306091v2.pdf",
    "category": [
      "cs.AI",
      "cs.CC",
      "cs.LG",
      "I.2; G.3"
    ],
    "authors": [
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0306120v2",
    "title": "Reinforcement Learning with Linear Function Approximation and LQ control\n  Converges",
    "summary": "Reinforcement learning is commonly used with function approximation. However,\nvery few positive results are known about the convergence of function\napproximation based RL control algorithms. In this paper we show that TD(0) and\nSarsa(0) with linear function approximation is convergent for a simple class of\nproblems, where the system is linear and the costs are quadratic (the LQ\ncontrol problem). Furthermore, we show that for systems with Gaussian noise and\nnon-completely observable states (the LQG problem), the mentioned RL algorithms\nare still convergent, if they are combined with Kalman filtering.",
    "published": "2003-06-22T08:00:09Z",
    "link": "http://arxiv.org/pdf/cs/0306120v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "I.2.6; I.2.8"
    ],
    "authors": [
      "Istvan Szita",
      "Andras Lorincz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0306126v1",
    "title": "Bayesian Treatment of Incomplete Discrete Data applied to Mutual\n  Information and Feature Selection",
    "summary": "Given the joint chances of a pair of random variables one can compute\nquantities of interest, like the mutual information. The Bayesian treatment of\nunknown chances involves computing, from a second order prior distribution and\nthe data likelihood, a posterior distribution of the chances. A common\ntreatment of incomplete data is to assume ignorability and determine the\nchances by the expectation maximization (EM) algorithm. The two different\nmethods above are well established but typically separated. This paper joins\nthe two approaches in the case of Dirichlet priors, and derives efficient\napproximations for the mean, mode and the (co)variance of the chances and the\nmutual information. Furthermore, we prove the unimodality of the posterior\ndistribution, whence the important property of convergence of EM to the global\nmaximum in the chosen framework. These results are applied to the problem of\nselecting features for incremental learning and naive Bayes classification. A\nfast filter based on the distribution of mutual information is shown to\noutperform the traditional filter based on empirical mutual information on a\nnumber of incomplete real data sets.",
    "published": "2003-06-24T09:50:29Z",
    "link": "http://arxiv.org/pdf/cs/0306126v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "math.PR",
      "G.3; G.1.2; I.2"
    ],
    "authors": [
      "Marcus Hutter",
      "Marco Zaffalon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/nlin/0306055v2",
    "title": "A Model for Prejudiced Learning in Noisy Environments",
    "summary": "Based on the heuristics that maintaining presumptions can be beneficial in\nuncertain environments, we propose a set of basic axioms for learning systems\nto incorporate the concept of prejudice. The simplest, memoryless model of a\ndeterministic learning rule obeying the axioms is constructed, and shown to be\nequivalent to the logistic map. The system's performance is analysed in an\nenvironment in which it is subject to external randomness, weighing learning\ndefectiveness against stability gained. The corresponding random dynamical\nsystem with inhomogeneous, additive noise is studied, and shown to exhibit the\nphenomena of noise induced stability and stochastic bifurcations. The overall\nresults allow for the interpretation that prejudice in uncertain environments\nentails a considerable portion of stubbornness as a secondary phenomenon.",
    "published": "2003-06-26T10:12:58Z",
    "link": "http://arxiv.org/pdf/nlin/0306055v2.pdf",
    "category": [
      "nlin.AO",
      "cs.LG"
    ],
    "authors": [
      "Andreas U. Schmidt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0307002v1",
    "title": "AWESOME: A General Multiagent Learning Algorithm that Converges in\n  Self-Play and Learns a Best Response Against Stationary Opponents",
    "summary": "A satisfactory multiagent learning algorithm should, {\\em at a minimum},\nlearn to play optimally against stationary opponents and converge to a Nash\nequilibrium in self-play. The algorithm that has come closest, WoLF-IGA, has\nbeen proven to have these two properties in 2-player 2-action repeated\ngames--assuming that the opponent's (mixed) strategy is observable. In this\npaper we present AWESOME, the first algorithm that is guaranteed to have these\ntwo properties in {\\em all} repeated (finite) games. It requires only that the\nother players' actual actions (not their strategies) can be observed at each\nstep. It also learns to play optimally against opponents that {\\em eventually\nbecome} stationary. The basic idea behind AWESOME ({\\em Adapt When Everybody is\nStationary, Otherwise Move to Equilibrium}) is to try to adapt to the others'\nstrategies when they appear stationary, but otherwise to retreat to a\nprecomputed equilibrium strategy. The techniques used to prove the properties\nof AWESOME are fundamentally different from those used for previous algorithms,\nand may help in analyzing other multiagent learning algorithms also.",
    "published": "2003-07-01T23:22:44Z",
    "link": "http://arxiv.org/pdf/cs/0307002v1.pdf",
    "category": [
      "cs.GT",
      "cs.LG",
      "cs.MA",
      "I.2.11"
    ],
    "authors": [
      "Vincent Conitzer",
      "Tuomas Sandholm"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0307006v1",
    "title": "BL-WoLF: A Framework For Loss-Bounded Learnability In Zero-Sum Games",
    "summary": "We present BL-WoLF, a framework for learnability in repeated zero-sum games\nwhere the cost of learning is measured by the losses the learning agent accrues\n(rather than the number of rounds). The game is adversarially chosen from some\nfamily that the learner knows. The opponent knows the game and the learner's\nlearning strategy. The learner tries to either not accrue losses, or to quickly\nlearn about the game so as to avoid future losses (this is consistent with the\nWin or Learn Fast (WoLF) principle; BL stands for ``bounded loss''). Our\nframework allows for both probabilistic and approximate learning. The resultant\nnotion of {\\em BL-WoLF}-learnability can be applied to any class of games, and\nallows us to measure the inherent disadvantage to a player that does not know\nwhich game in the class it is in. We present {\\em guaranteed\nBL-WoLF-learnability} results for families of games with deterministic payoffs\nand families of games with stochastic payoffs. We demonstrate that these\nfamilies are {\\em guaranteed approximately BL-WoLF-learnable} with lower cost.\nWe then demonstrate families of games (both stochastic and deterministic) that\nare not guaranteed BL-WoLF-learnable. We show that those families,\nnevertheless, are {\\em BL-WoLF-learnable}. To prove these results, we use a key\nlemma which we derive.",
    "published": "2003-07-03T15:44:36Z",
    "link": "http://arxiv.org/pdf/cs/0307006v1.pdf",
    "category": [
      "cs.GT",
      "cs.LG",
      "cs.MA",
      "I.2.11"
    ],
    "authors": [
      "Vincent Conitzer",
      "Tuomas Sandholm"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0307055v1",
    "title": "Learning Analogies and Semantic Relations",
    "summary": "We present an algorithm for learning from unlabeled text, based on the Vector\nSpace Model (VSM) of information retrieval, that can solve verbal analogy\nquestions of the kind found in the Scholastic Aptitude Test (SAT). A verbal\nanalogy has the form A:B::C:D, meaning \"A is to B as C is to D\"; for example,\nmason:stone::carpenter:wood. SAT analogy questions provide a word pair, A:B,\nand the problem is to select the most analogous word pair, C:D, from a set of\nfive choices. The VSM algorithm correctly answers 47% of a collection of 374\ncollege-level analogy questions (random guessing would yield 20% correct). We\nmotivate this research by relating it to work in cognitive science and\nlinguistics, and by applying it to a difficult problem in natural language\nprocessing, determining semantic relations in noun-modifier pairs. The problem\nis to classify a noun-modifier pair, such as \"laser printer\", according to the\nsemantic relation between the noun (printer) and the modifier (laser). We use a\nsupervised nearest-neighbour algorithm that assigns a class to a given\nnoun-modifier pair by finding the most analogous noun-modifier pair in the\ntraining data. With 30 classes of semantic relations, on a collection of 600\nlabeled noun-modifier pairs, the learning algorithm attains an F value of 26.5%\n(random guessing: 3.3%). With 5 classes of semantic relations, the F value is\n43.2% (random: 20%). The performance is state-of-the-art for these challenging\nproblems.",
    "published": "2003-07-24T21:09:43Z",
    "link": "http://arxiv.org/pdf/cs/0307055v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL",
      "cs.IR",
      "H.3.1; I.2.6; I.2.7"
    ],
    "authors": [
      "Peter D. Turney",
      "Michael L. Littman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0308025v1",
    "title": "Controlled hierarchical filtering: Model of neocortical sensory\n  processing",
    "summary": "A model of sensory information processing is presented. The model assumes\nthat learning of internal (hidden) generative models, which can predict the\nfuture and evaluate the precision of that prediction, is of central importance\nfor information extraction. Furthermore, the model makes a bridge to\ngoal-oriented systems and builds upon the structural similarity between the\narchitecture of a robust controller and that of the hippocampal entorhinal\nloop. This generative control architecture is mapped to the neocortex and to\nthe hippocampal entorhinal loop. Implicit memory phenomena; priming and\nprototype learning are emerging features of the model. Mathematical theorems\nensure stability and attractive learning properties of the architecture.\nConnections to reinforcement learning are also established: both the control\nnetwork, and the network with a hidden model converge to (near) optimal policy\nunder suitable conditions. Falsifying predictions, including the role of the\nfeedback connections between neocortical areas are made.",
    "published": "2003-08-16T07:31:57Z",
    "link": "http://arxiv.org/pdf/cs/0308025v1.pdf",
    "category": [
      "cs.NE",
      "cs.AI",
      "cs.LG",
      "q-bio.NC",
      "C.1.3; F.1.1.; I.2.0; I.2.6; I.2.10; I.4.3.; I.4.10; I.5.1"
    ],
    "authors": [
      "Andras Lorincz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0308033v1",
    "title": "Coherent Keyphrase Extraction via Web Mining",
    "summary": "Keyphrases are useful for a variety of purposes, including summarizing,\nindexing, labeling, categorizing, clustering, highlighting, browsing, and\nsearching. The task of automatic keyphrase extraction is to select keyphrases\nfrom within the text of a given document. Automatic keyphrase extraction makes\nit feasible to generate keyphrases for the huge number of documents that do not\nhave manually assigned keyphrases. A limitation of previous keyphrase\nextraction algorithms is that the selected keyphrases are occasionally\nincoherent. That is, the majority of the output keyphrases may fit together\nwell, but there may be a minority that appear to be outliers, with no clear\nsemantic relation to the majority or to each other. This paper presents\nenhancements to the Kea keyphrase extraction algorithm that are designed to\nincrease the coherence of the extracted keyphrases. The approach is to use the\ndegree of statistical association among candidate keyphrases as evidence that\nthey may be semantically related. The statistical association is measured using\nweb mining. Experiments demonstrate that the enhancements improve the quality\nof the extracted keyphrases. Furthermore, the enhancements are not\ndomain-specific: the algorithm generalizes well when it is trained on one\ndomain (computer science documents) and tested on another (physics documents).",
    "published": "2003-08-20T20:42:19Z",
    "link": "http://arxiv.org/pdf/cs/0308033v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL",
      "cs.IR",
      "H.3.1; H.3.3; I.2.6; I.2.7"
    ],
    "authors": [
      "Peter D. Turney"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0309015v1",
    "title": "Reliable and Efficient Inference of Bayesian Networks from Sparse Data\n  by Statistical Learning Theory",
    "summary": "To learn (statistical) dependencies among random variables requires\nexponentially large sample size in the number of observed random variables if\nany arbitrary joint probability distribution can occur.\n  We consider the case that sparse data strongly suggest that the probabilities\ncan be described by a simple Bayesian network, i.e., by a graph with small\nin-degree \\Delta. Then this simple law will also explain further data with high\nconfidence. This is shown by calculating bounds on the VC dimension of the set\nof those probability measures that correspond to simple graphs. This allows to\nselect networks by structural risk minimization and gives reliability bounds on\nthe error of the estimated joint measure without (in contrast to a previous\npaper) any prior assumptions on the set of possible joint measures.\n  The complexity for searching the optimal Bayesian networks of in-degree\n\\Delta increases only polynomially in the number of random varibales for\nconstant \\Delta and the optimal joint measure associated with a given graph can\nbe found by convex optimization.",
    "published": "2003-09-10T13:56:41Z",
    "link": "http://arxiv.org/pdf/cs/0309015v1.pdf",
    "category": [
      "cs.LG",
      "K.3.2"
    ],
    "authors": [
      "Dominik Janzing",
      "Daniel Herrmann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0309016v1",
    "title": "Using Simulated Annealing to Calculate the Trembles of Trembling Hand\n  Perfection",
    "summary": "Within the literature on non-cooperative game theory, there have been a\nnumber of attempts to propose logorithms which will compute Nash equilibria.\nRather than derive a new algorithm, this paper shows that the family of\nalgorithms known as Markov chain Monte Carlo (MCMC) can be used to calculate\nNash equilibria. MCMC is a type of Monte Carlo simulation that relies on Markov\nchains to ensure its regularity conditions. MCMC has been widely used\nthroughout the statistics and optimization literature, where variants of this\nalgorithm are known as simulated annealing. This paper shows that there is\ninteresting connection between the trembles that underlie the functioning of\nthis algorithm and the type of Nash refinement known as trembling hand\nperfection.",
    "published": "2003-09-10T15:11:44Z",
    "link": "http://arxiv.org/pdf/cs/0309016v1.pdf",
    "category": [
      "cs.GT",
      "cs.CC",
      "cs.DS",
      "cs.LG",
      "cs.NE",
      "q-bio.PE",
      "F.1.1;F.2.2;G.3;I.2.1;J.4"
    ],
    "authors": [
      "Stuart McDonald",
      "Liam Wagner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0309034v1",
    "title": "Measuring Praise and Criticism: Inference of Semantic Orientation from\n  Association",
    "summary": "The evaluative character of a word is called its semantic orientation.\nPositive semantic orientation indicates praise (e.g., \"honest\", \"intrepid\") and\nnegative semantic orientation indicates criticism (e.g., \"disturbing\",\n\"superfluous\"). Semantic orientation varies in both direction (positive or\nnegative) and degree (mild to strong). An automated system for measuring\nsemantic orientation would have application in text classification, text\nfiltering, tracking opinions in online discussions, analysis of survey\nresponses, and automated chat systems (chatbots). This paper introduces a\nmethod for inferring the semantic orientation of a word from its statistical\nassociation with a set of positive and negative paradigm words. Two instances\nof this approach are evaluated, based on two different statistical measures of\nword association: pointwise mutual information (PMI) and latent semantic\nanalysis (LSA). The method is experimentally tested with 3,596 words (including\nadjectives, adverbs, nouns, and verbs) that have been manually labeled positive\n(1,614 words) and negative (1,982 words). The method attains an accuracy of\n82.8% on the full test set, but the accuracy rises above 95% when the algorithm\nis allowed to abstain from classifying mild words.",
    "published": "2003-09-19T16:30:55Z",
    "link": "http://arxiv.org/pdf/cs/0309034v1.pdf",
    "category": [
      "cs.CL",
      "cs.IR",
      "cs.LG",
      "H.3.1; H.3.3; I.2.6; I.2.7"
    ],
    "authors": [
      "Peter D. Turney",
      "Michael L. Littman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0309035v1",
    "title": "Combining Independent Modules to Solve Multiple-choice Synonym and\n  Analogy Problems",
    "summary": "Existing statistical approaches to natural language problems are very coarse\napproximations to the true complexity of language processing. As such, no\nsingle technique will be best for all problem instances. Many researchers are\nexamining ensemble methods that combine the output of successful, separately\ndeveloped modules to create more accurate solutions. This paper examines three\nmerging rules for combining probability distributions: the well known mixture\nrule, the logarithmic rule, and a novel product rule. These rules were applied\nwith state-of-the-art results to two problems commonly used to assess human\nmastery of lexical semantics -- synonym questions and analogy questions. All\nthree merging rules result in ensembles that are more accurate than any of\ntheir component modules. The differences among the three rules are not\nstatistically significant, but it is suggestive that the popular mixture rule\nis not the best rule for either of the two problems.",
    "published": "2003-09-19T20:13:07Z",
    "link": "http://arxiv.org/pdf/cs/0309035v1.pdf",
    "category": [
      "cs.CL",
      "cs.IR",
      "cs.LG",
      "I.2.6; I.2.7; H.3.1; J.5"
    ],
    "authors": [
      "Peter D. Turney",
      "Michael L. Littman",
      "Jeffrey Bigham",
      "Victor Shnayder"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0311014v1",
    "title": "Optimality of Universal Bayesian Sequence Prediction for General Loss\n  and Alphabet",
    "summary": "Various optimality properties of universal sequence predictors based on\nBayes-mixtures in general, and Solomonoff's prediction scheme in particular,\nwill be studied. The probability of observing $x_t$ at time $t$, given past\nobservations $x_1...x_{t-1}$ can be computed with the chain rule if the true\ngenerating distribution $\\mu$ of the sequences $x_1x_2x_3...$ is known. If\n$\\mu$ is unknown, but known to belong to a countable or continuous class $\\M$\none can base ones prediction on the Bayes-mixture $\\xi$ defined as a\n$w_\\nu$-weighted sum or integral of distributions $\\nu\\in\\M$. The cumulative\nexpected loss of the Bayes-optimal universal prediction scheme based on $\\xi$\nis shown to be close to the loss of the Bayes-optimal, but infeasible\nprediction scheme based on $\\mu$. We show that the bounds are tight and that no\nother predictor can lead to significantly smaller bounds. Furthermore, for\nvarious performance measures, we show Pareto-optimality of $\\xi$ and give an\nOccam's razor argument that the choice $w_\\nu\\sim 2^{-K(\\nu)}$ for the weights\nis optimal, where $K(\\nu)$ is the length of the shortest program describing\n$\\nu$. The results are applied to games of chance, defined as a sequence of\nbets, observations, and rewards. The prediction schemes (and bounds) are\ncompared to the popular predictors based on expert advice. Extensions to\ninfinite alphabets, partial, delayed and probabilistic prediction,\nclassification, and more active systems are briefly discussed.",
    "published": "2003-11-13T12:02:04Z",
    "link": "http://arxiv.org/pdf/cs/0311014v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "math.PR",
      "E.4;I.2.6;G.3"
    ],
    "authors": [
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0311042v1",
    "title": "Toward Attribute Efficient Learning Algorithms",
    "summary": "We make progress on two important problems regarding attribute efficient\nlearnability.\n  First, we give an algorithm for learning decision lists of length $k$ over\n$n$ variables using $2^{\\tilde{O}(k^{1/3})} \\log n$ examples and time\n$n^{\\tilde{O}(k^{1/3})}$. This is the first algorithm for learning decision\nlists that has both subexponential sample complexity and subexponential running\ntime in the relevant parameters. Our approach establishes a relationship\nbetween attribute efficient learning and polynomial threshold functions and is\nbased on a new construction of low degree, low weight polynomial threshold\nfunctions for decision lists. For a wide range of parameters our construction\nmatches a 1994 lower bound due to Beigel for the ODDMAXBIT predicate and gives\nan essentially optimal tradeoff between polynomial threshold function degree\nand weight.\n  Second, we give an algorithm for learning an unknown parity function on $k$\nout of $n$ variables using $O(n^{1-1/k})$ examples in time polynomial in $n$.\nFor $k=o(\\log n)$ this yields a polynomial time algorithm with sample\ncomplexity $o(n)$. This is the first polynomial time algorithm for learning\nparity on a superconstant number of variables with sublinear sample complexity.",
    "published": "2003-11-27T05:34:04Z",
    "link": "http://arxiv.org/pdf/cs/0311042v1.pdf",
    "category": [
      "cs.LG",
      "I.2.6"
    ],
    "authors": [
      "Adam R. Klivans",
      "Rocco A. Servedio"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0312003v1",
    "title": "Hybrid LQG-Neural Controller for Inverted Pendulum System",
    "summary": "The paper presents a hybrid system controller, incorporating a neural and an\nLQG controller. The neural controller has been optimized by genetic algorithms\ndirectly on the inverted pendulum system. The failure free optimization process\nstipulated a relatively small region of the asymptotic stability of the neural\ncontroller, which is concentrated around the regulation point. The presented\nhybrid controller combines benefits of a genetically optimized neural\ncontroller and an LQG controller in a single system controller. High quality of\nthe regulation process is achieved through utilization of the neural\ncontroller, while stability of the system during transient processes and a wide\nrange of operation are assured through application of the LQG controller. The\nhybrid controller has been validated by applying it to a simulation model of an\ninherently unstable system of inverted pendulum.",
    "published": "2003-11-30T00:19:19Z",
    "link": "http://arxiv.org/pdf/cs/0312003v1.pdf",
    "category": [
      "cs.NE",
      "cs.LG",
      "I.2.6;C.1.3;I.5.1"
    ],
    "authors": [
      "E. S. Sazonov",
      "P. Klinkhachorn",
      "R. L. Klein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0312004v1",
    "title": "Improving spam filtering by combining Naive Bayes with simple k-nearest\n  neighbor searches",
    "summary": "Using naive Bayes for email classification has become very popular within the\nlast few months. They are quite easy to implement and very efficient. In this\npaper we want to present empirical results of email classification using a\ncombination of naive Bayes and k-nearest neighbor searches. Using this\ntechnique we show that the accuracy of a Bayes filter can be improved slightly\nfor a high number of features and significantly for a small number of features.",
    "published": "2003-11-30T20:41:18Z",
    "link": "http://arxiv.org/pdf/cs/0312004v1.pdf",
    "category": [
      "cs.LG",
      "I.2.6"
    ],
    "authors": [
      "Daniel Etzold"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0312009v1",
    "title": "Failure-Free Genetic Algorithm Optimization of a System Controller Using\n  SAFE/LEARNING Controllers in Tandem",
    "summary": "The paper presents a method for failure free genetic algorithm optimization\nof a system controller. Genetic algorithms present a powerful tool that\nfacilitates producing near-optimal system controllers. Applied to such methods\nof computational intelligence as neural networks or fuzzy logic, these methods\nare capable of combining the non-linear mapping capabilities of the latter with\nlearning the system behavior directly, that is, without a prior model. At the\nsame time, genetic algorithms routinely produce solutions that lead to the\nfailure of the controlled system. Such solutions are generally unacceptable for\napplications where safe operation must be guaranteed. We present here a method\nof design, which allows failure-free application of genetic algorithms through\nutilization of SAFE and LEARNING controllers in tandem, where the SAFE\ncontroller recovers the system from dangerous states while the LEARNING\ncontroller learns its behavior. The method has been validated by applying it to\nan inherently unstable system of inverted pendulum.",
    "published": "2003-12-03T22:29:01Z",
    "link": "http://arxiv.org/pdf/cs/0312009v1.pdf",
    "category": [
      "cs.NE",
      "cs.LG",
      "I.2.6;C.1.3;I.5.1"
    ],
    "authors": [
      "E. S. Sazonov",
      "D. Del Gobbo",
      "P. Klinkhachorn",
      "R. L. Klein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0312018v1",
    "title": "Mapping Subsets of Scholarly Information",
    "summary": "We illustrate the use of machine learning techniques to analyze, structure,\nmaintain, and evolve a large online corpus of academic literature. An emerging\nfield of research can be identified as part of an existing corpus, permitting\nthe implementation of a more coherent community structure for its\npractitioners.",
    "published": "2003-12-11T20:07:39Z",
    "link": "http://arxiv.org/pdf/cs/0312018v1.pdf",
    "category": [
      "cs.IR",
      "cs.LG",
      "H.3.1; H.3.6; I.2.6"
    ],
    "authors": [
      "Paul Ginsparg",
      "Paul Houle",
      "Thorsten Joachims",
      "Jae-Hoon Sul"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0312058v1",
    "title": "Acquiring Lexical Paraphrases from a Single Corpus",
    "summary": "This paper studies the potential of identifying lexical paraphrases within a\nsingle corpus, focusing on the extraction of verb paraphrases. Most previous\napproaches detect individual paraphrase instances within a pair (or set) of\ncomparable corpora, each of them containing roughly the same information, and\nrely on the substantial level of correspondence of such corpora. We present a\nnovel method that successfully detects isolated paraphrase instances within a\nsingle corpus without relying on any a-priori structure and information. A\ncomparison suggests that an instance-based approach may be combined with a\nvector based approach in order to assess better the paraphrase likelihood for\nmany verb pairs.",
    "published": "2003-12-25T16:45:20Z",
    "link": "http://arxiv.org/pdf/cs/0312058v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "I.7"
    ],
    "authors": [
      "Oren Glickman",
      "Ido Dagan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0312060v1",
    "title": "Part-of-Speech Tagging with Minimal Lexicalization",
    "summary": "We use a Dynamic Bayesian Network to represent compactly a variety of\nsublexical and contextual features relevant to Part-of-Speech (PoS) tagging.\nThe outcome is a flexible tagger (LegoTag) with state-of-the-art performance\n(3.6% error on a benchmark corpus). We explore the effect of eliminating\nredundancy and radically reducing the size of feature vocabularies. We find\nthat a small but linguistically motivated set of suffixes results in improved\ncross-corpora generalization. We also show that a minimal lexicon limited to\nfunction words is sufficient to ensure reasonable performance.",
    "published": "2003-12-27T21:21:48Z",
    "link": "http://arxiv.org/pdf/cs/0312060v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG",
      "I.2.7"
    ],
    "authors": [
      "Virginia Savova",
      "Leonid Peshkin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0401005v1",
    "title": "About Unitary Rating Score Constructing",
    "summary": "It is offered to pool test points of different subjects and different aspects\nof the same subject together in order to get the unitary rating score, by the\nway of nonlinear transformation of indicator points in accordance with Zipf's\ndistribution. It is proposed to use the well-studied distribution of\nIntellectuality Quotient IQ as the reference distribution for latent variable\n\"progress in studies\".",
    "published": "2004-01-08T07:50:51Z",
    "link": "http://arxiv.org/pdf/cs/0401005v1.pdf",
    "category": [
      "cs.LG",
      "1.2.6"
    ],
    "authors": [
      "Kromer Victor"
    ]
  },
  {
    "id": "http://arxiv.org/abs/q-bio/0401033v1",
    "title": "Parametric Inference for Biological Sequence Analysis",
    "summary": "One of the major successes in computational biology has been the unification,\nusing the graphical model formalism, of a multitude of algorithms for\nannotating and comparing biological sequences. Graphical models that have been\napplied towards these problems include hidden Markov models for annotation,\ntree models for phylogenetics, and pair hidden Markov models for alignment. A\nsingle algorithm, the sum-product algorithm, solves many of the inference\nproblems associated with different statistical models. This paper introduces\nthe \\emph{polytope propagation algorithm} for computing the Newton polytope of\nan observation from a graphical model. This algorithm is a geometric version of\nthe sum-product algorithm and is used to analyze the parametric behavior of\nmaximum a posteriori inference calculations for graphical models.",
    "published": "2004-01-26T03:50:03Z",
    "link": "http://arxiv.org/pdf/q-bio/0401033v1.pdf",
    "category": [
      "q-bio.GN",
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "authors": [
      "Lior Pachter",
      "Bernd Sturmfels"
    ]
  },
  {
    "id": "http://arxiv.org/abs/q-bio/0402029v2",
    "title": "Fluctuation-dissipation theorem and models of learning",
    "summary": "Advances in statistical learning theory have resulted in a multitude of\ndifferent designs of learning machines. But which ones are implemented by\nbrains and other biological information processors? We analyze how various\nabstract Bayesian learners perform on different data and argue that it is\ndifficult to determine which learning-theoretic computation is performed by a\nparticular organism using just its performance in learning a stationary target\n(learning curve). Basing on the fluctuation-dissipation relation in statistical\nphysics, we then discuss a different experimental setup that might be able to\nsolve the problem.",
    "published": "2004-02-12T22:36:01Z",
    "link": "http://arxiv.org/pdf/q-bio/0402029v2.pdf",
    "category": [
      "q-bio.NC",
      "cs.LG",
      "nlin.AO",
      "physics.data-an"
    ],
    "authors": [
      "Ilya Nemenman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0402032v1",
    "title": "Fitness inheritance in the Bayesian optimization algorithm",
    "summary": "This paper describes how fitness inheritance can be used to estimate fitness\nfor a proportion of newly sampled candidate solutions in the Bayesian\noptimization algorithm (BOA). The goal of estimating fitness for some candidate\nsolutions is to reduce the number of fitness evaluations for problems where\nfitness evaluation is expensive. Bayesian networks used in BOA to model\npromising solutions and generate the new ones are extended to allow not only\nfor modeling and sampling candidate solutions, but also for estimating their\nfitness. The results indicate that fitness inheritance is a promising concept\nin BOA, because population-sizing requirements for building appropriate models\nof promising solutions lead to good fitness estimates even if only a small\nproportion of candidate solutions is evaluated using the actual fitness\nfunction. This can lead to a reduction of the number of actual fitness\nevaluations by a factor of 30 or more.",
    "published": "2004-02-15T07:40:45Z",
    "link": "http://arxiv.org/pdf/cs/0402032v1.pdf",
    "category": [
      "cs.NE",
      "cs.AI",
      "cs.LG",
      "G.1.6; G.3; I.2.6; I.2.8"
    ],
    "authors": [
      "Martin Pelikan",
      "Kumara Sastry"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0403025v1",
    "title": "Distribution of Mutual Information from Complete and Incomplete Data",
    "summary": "Mutual information is widely used, in a descriptive way, to measure the\nstochastic dependence of categorical random variables. In order to address\nquestions such as the reliability of the descriptive value, one must consider\nsample-to-population inferential approaches. This paper deals with the\nposterior distribution of mutual information, as obtained in a Bayesian\nframework by a second-order Dirichlet prior distribution. The exact analytical\nexpression for the mean, and analytical approximations for the variance,\nskewness and kurtosis are derived. These approximations have a guaranteed\naccuracy level of the order O(1/n^3), where n is the sample size. Leading order\napproximations for the mean and the variance are derived in the case of\nincomplete samples. The derived analytical expressions allow the distribution\nof mutual information to be approximated reliably and quickly. In fact, the\nderived expressions can be computed with the same order of complexity needed\nfor descriptive mutual information. This makes the distribution of mutual\ninformation become a concrete alternative to descriptive mutual information in\nmany applications which would benefit from moving to the inductive side. Some\nof these prospective applications are discussed, and one of them, namely\nfeature selection, is shown to perform significantly better when inductive\nmutual information is used.",
    "published": "2004-03-15T16:33:55Z",
    "link": "http://arxiv.org/pdf/cs/0403025v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT",
      "math.ST",
      "stat.TH",
      "I.2"
    ],
    "authors": [
      "Marcus Hutter",
      "Marco Zaffalon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0403031v2",
    "title": "Concept of E-machine: How does a \"dynamical\" brain learn to process\n  \"symbolic\" information? Part I",
    "summary": "The human brain has many remarkable information processing characteristics\nthat deeply puzzle scientists and engineers. Among the most important and the\nmost intriguing of these characteristics are the brain's broad universality as\na learning system and its mysterious ability to dynamically change\n(reconfigure) its behavior depending on a combinatorial number of different\ncontexts.\n  This paper discusses a class of hypothetically brain-like dynamically\nreconfigurable associative learning systems that shed light on the possible\nnature of these brain's properties. The systems are arranged on the general\nprinciple referred to as the concept of E-machine.\n  The paper addresses the following questions:\n  1. How can \"dynamical\" neural networks function as universal programmable\n\"symbolic\" machines?\n  2. What kind of a universal programmable symbolic machine can form\narbitrarily complex software in the process of programming similar to the\nprocess of biological associative learning?\n  3. How can a universal learning machine dynamically reconfigure its software\ndepending on a combinatorial number of possible contexts?",
    "published": "2004-03-19T17:13:55Z",
    "link": "http://arxiv.org/pdf/cs/0403031v2.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "I.2.0"
    ],
    "authors": [
      "Victor Eliashberg"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0403038v1",
    "title": "Tournament versus Fitness Uniform Selection",
    "summary": "In evolutionary algorithms a critical parameter that must be tuned is that of\nselection pressure. If it is set too low then the rate of convergence towards\nthe optimum is likely to be slow. Alternatively if the selection pressure is\nset too high the system is likely to become stuck in a local optimum due to a\nloss of diversity in the population. The recent Fitness Uniform Selection\nScheme (FUSS) is a conceptually simple but somewhat radical approach to\naddressing this problem - rather than biasing the selection towards higher\nfitness, FUSS biases selection towards sparsely populated fitness levels. In\nthis paper we compare the relative performance of FUSS with the well known\ntournament selection scheme on a range of problems.",
    "published": "2004-03-23T15:17:53Z",
    "link": "http://arxiv.org/pdf/cs/0403038v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "I.2; I.2.6; I.2.8; F.2"
    ],
    "authors": [
      "Shane Legg",
      "Marcus Hutter",
      "Akshat Kumar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0404032v1",
    "title": "When Do Differences Matter? On-Line Feature Extraction Through Cognitive\n  Economy",
    "summary": "For an intelligent agent to be truly autonomous, it must be able to adapt its\nrepresentation to the requirements of its task as it interacts with the world.\nMost current approaches to on-line feature extraction are ad hoc; in contrast,\nthis paper presents an algorithm that bases judgments of state compatibility\nand state-space abstraction on principled criteria derived from the\npsychological principle of cognitive economy. The algorithm incorporates an\nactive form of Q-learning, and partitions continuous state-spaces by merging\nand splitting Voronoi regions. The experiments illustrate a new methodology for\ntesting and comparing representations by means of learning curves. Results from\nthe puck-on-a-hill task demonstrate the algorithm's ability to learn effective\nrepresentations, superior to those produced by some other, well-known, methods.",
    "published": "2004-04-15T02:59:10Z",
    "link": "http://arxiv.org/pdf/cs/0404032v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "I.2.6; I.2.4; I.2.8"
    ],
    "authors": [
      "David J. Finton"
    ]
  },
  {
    "id": "http://arxiv.org/abs/nlin/0404032v1",
    "title": "Metrics for more than two points at once",
    "summary": "The conventional definition of a topological metric over a space specifies\nproperties that must be obeyed by any measure of \"how separated\" two points in\nthat space are. Here it is shown how to extend that definition, and in\nparticular the triangle inequality, to concern arbitrary numbers of points.\nSuch a measure of how separated the points within a collection are can be\nbootstrapped, to measure \"how separated\" from each other are two (or more)\ncollections. The measure presented here also allows fractional membership of an\nelement in a collection. This means it directly concerns measures of ``how\nspread out\" a probability distribution over a space is. When such a measure is\nbootstrapped to compare two collections, it allows us to measure how separated\ntwo probability distributions are, or more generally, how separated a\ndistribution of distributions is.",
    "published": "2004-04-16T02:31:43Z",
    "link": "http://arxiv.org/pdf/nlin/0404032v1.pdf",
    "category": [
      "nlin.AO",
      "cond-mat.other",
      "cs.LG",
      "math.GM"
    ],
    "authors": [
      "David H. Wolpert"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0404057v1",
    "title": "Convergence of Discrete MDL for Sequential Prediction",
    "summary": "We study the properties of the Minimum Description Length principle for\nsequence prediction, considering a two-part MDL estimator which is chosen from\na countable class of models. This applies in particular to the important case\nof universal sequence prediction, where the model class corresponds to all\nalgorithms for some fixed universal Turing machine (this correspondence is by\nenumerable semimeasures, hence the resulting models are stochastic). We prove\nconvergence theorems similar to Solomonoff's theorem of universal induction,\nwhich also holds for general Bayes mixtures. The bound characterizing the\nconvergence speed for MDL predictions is exponentially larger as compared to\nBayes mixtures. We observe that there are at least three different ways of\nusing MDL for prediction. One of these has worse prediction properties, for\nwhich predictions only converge if the MDL estimator stabilizes. We establish\nsufficient conditions for this to occur. Finally, some immediate consequences\nfor complexity relations and randomness criteria are proven.",
    "published": "2004-04-28T15:58:35Z",
    "link": "http://arxiv.org/pdf/cs/0404057v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.TH",
      "I.2.6; E.4; G.3"
    ],
    "authors": [
      "Jan Poland",
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0405043v2",
    "title": "Prediction with Expert Advice by Following the Perturbed Leader for\n  General Weights",
    "summary": "When applying aggregating strategies to Prediction with Expert Advice, the\nlearning rate must be adaptively tuned. The natural choice of\nsqrt(complexity/current loss) renders the analysis of Weighted Majority\nderivatives quite complicated. In particular, for arbitrary weights there have\nbeen no results proven so far. The analysis of the alternative \"Follow the\nPerturbed Leader\" (FPL) algorithm from Kalai (2003} (based on Hannan's\nalgorithm) is easier. We derive loss bounds for adaptive learning rate and both\nfinite expert classes with uniform weights and countable expert classes with\narbitrary weights. For the former setup, our loss bounds match the best known\nresults so far, while for the latter our results are (to our knowledge) new.",
    "published": "2004-05-12T16:41:01Z",
    "link": "http://arxiv.org/pdf/cs/0405043v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "I.2.6; G.3"
    ],
    "authors": [
      "Marcus Hutter",
      "Jan Poland"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0405104v1",
    "title": "Knowledge Reduction and Discovery based on Demarcation Information",
    "summary": "Knowledge reduction, includes attribute reduction and value reduction, is an\nimportant topic in rough set literature. It is also closely relevant to other\nfields, such as machine learning and data mining. In this paper, an algorithm\ncalled TWI-SQUEEZE is proposed. It can find a reduct, or an irreducible\nattribute subset after two scans. Its soundness and computational complexity\nare given, which show that it is the fastest algorithm at present. A measure of\nvariety is brought forward, of which algorithm TWI-SQUEEZE can be regarded as\nan application. The author also argues the rightness of this measure as a\nmeasure of information, which can make it a unified measure for\n\"differentiation, a concept appeared in cognitive psychology literature. Value\nreduction is another important aspect of knowledge reduction. It is interesting\nthat using the same algorithm we can execute a complete value reduction\nefficiently. The complete knowledge reduction, which results in an irreducible\ntable, can therefore be accomplished after four scans of table. The byproducts\nof reduction are two classifiers of different styles. In this paper, various\ncases and models will be discussed to prove the efficiency and effectiveness of\nthe algorithm. Some topics, such as how to integrate user preference to find a\nlocal optimal attribute subset will also be discussed.",
    "published": "2004-05-27T11:26:18Z",
    "link": "http://arxiv.org/pdf/cs/0405104v1.pdf",
    "category": [
      "cs.LG",
      "cs.DB",
      "cs.IT",
      "math.IT",
      "H.2.8;I.2.6; H.1.1;I.5.2"
    ],
    "authors": [
      "Yuguo He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/math/0406077v1",
    "title": "A tutorial introduction to the minimum description length principle",
    "summary": "This tutorial provides an overview of and introduction to Rissanen's Minimum\nDescription Length (MDL) Principle. The first chapter provides a conceptual,\nentirely non-technical introduction to the subject. It serves as a basis for\nthe technical introduction given in the second chapter, in which all the ideas\nof the first chapter are made mathematically precise. The main ideas are\ndiscussed in great conceptual and technical detail. This tutorial is an\nextended version of the first two chapters of the collection \"Advances in\nMinimum Description Length: Theory and Application\" (edited by P.Grunwald, I.J.\nMyung and M. Pitt, to be published by the MIT Press, Spring 2005).",
    "published": "2004-06-04T09:11:18Z",
    "link": "http://arxiv.org/pdf/math/0406077v1.pdf",
    "category": [
      "math.ST",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "stat.TH",
      "6201; 6801; 68T05; 68T10; 9401"
    ],
    "authors": [
      "Peter Grunwald"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0406011v1",
    "title": "Blind Construction of Optimal Nonlinear Recursive Predictors for\n  Discrete Sequences",
    "summary": "We present a new method for nonlinear prediction of discrete random sequences\nunder minimal structural assumptions. We give a mathematical construction for\noptimal predictors of such processes, in the form of hidden Markov models. We\nthen describe an algorithm, CSSR (Causal-State Splitting Reconstruction), which\napproximates the ideal predictor from data. We discuss the reliability of CSSR,\nits data requirements, and its performance in simulations. Finally, we compare\nour approach to existing methods using variable-length Markov models and\ncross-validated hidden Markov models, and show theoretically and experimentally\nthat our method delivers results superior to the former and at least comparable\nto the latter.",
    "published": "2004-06-06T18:57:05Z",
    "link": "http://arxiv.org/pdf/cs/0406011v1.pdf",
    "category": [
      "cs.LG",
      "math.ST",
      "nlin.CD",
      "physics.data-an",
      "stat.TH",
      "I.2.6"
    ],
    "authors": [
      "Cosma Rohilla Shalizi",
      "Kristina Lisa Shalizi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/math/0406221v1",
    "title": "Suboptimal behaviour of Bayes and MDL in classification under\n  misspecification",
    "summary": "We show that forms of Bayesian and MDL inference that are often applied to\nclassification problems can be *inconsistent*. This means there exists a\nlearning problem such that for all amounts of data the generalization errors of\nthe MDL classifier and the Bayes classifier relative to the Bayesian posterior\nboth remain bounded away from the smallest achievable generalization error.",
    "published": "2004-06-10T16:36:54Z",
    "link": "http://arxiv.org/pdf/math/0406221v1.pdf",
    "category": [
      "math.ST",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "stat.TH",
      "62A01; 68T05; 68T10"
    ],
    "authors": [
      "Peter Grunwald",
      "John Langford"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0407016v1",
    "title": "Learning for Adaptive Real-time Search",
    "summary": "Real-time heuristic search is a popular model of acting and learning in\nintelligent autonomous agents. Learning real-time search agents improve their\nperformance over time by acquiring and refining a value function guiding the\napplication of their actions. As computing the perfect value function is\ntypically intractable, a heuristic approximation is acquired instead. Most\nstudies of learning in real-time search (and reinforcement learning) assume\nthat a simple value-function-greedy policy is used to select actions. This is\nin contrast to practice, where high-performance is usually attained by\ninterleaving planning and acting via a lookahead search of a non-trivial depth.\nIn this paper, we take a step toward bridging this gap and propose a novel\nalgorithm that (i) learns a heuristic function to be used specifically with a\nlookahead-based policy, (ii) selects the lookahead depth adaptively in each\nstate, (iii) gives the user control over the trade-off between exploration and\nexploitation. We extensively evaluate the algorithm in the sliding tile puzzle\ntestbed comparing it to the classical LRTA* and the more recent weighted LRTA*,\nbounded LRTA*, and FALCONS. Improvements of 5 to 30 folds in convergence speed\nare observed.",
    "published": "2004-07-06T22:18:25Z",
    "link": "http://arxiv.org/pdf/cs/0407016v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Vadim Bulitko"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0407039v1",
    "title": "On the Convergence Speed of MDL Predictions for Bernoulli Sequences",
    "summary": "We consider the Minimum Description Length principle for online sequence\nprediction. If the underlying model class is discrete, then the total expected\nsquare loss is a particularly interesting performance measure: (a) this\nquantity is bounded, implying convergence with probability one, and (b) it\nadditionally specifies a `rate of convergence'. Generally, for MDL only\nexponential loss bounds hold, as opposed to the linear bounds for a Bayes\nmixture. We show that this is even the case if the model class contains only\nBernoulli distributions. We derive a new upper bound on the prediction error\nfor countable Bernoulli classes. This implies a small bound (comparable to the\none for Bayes mixtures) for certain important model classes. The results apply\nto many Machine Learning tasks including classification and hypothesis testing.\nWe provide arguments that our theorems generalize to countable classes of\ni.i.d. models.",
    "published": "2004-07-16T10:36:49Z",
    "link": "http://arxiv.org/pdf/cs/0407039v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT",
      "math.PR",
      "I.2.6; E.4; G.3"
    ],
    "authors": [
      "Jan Poland",
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0407057v1",
    "title": "Universal Convergence of Semimeasures on Individual Random Sequences",
    "summary": "Solomonoff's central result on induction is that the posterior of a universal\nsemimeasure M converges rapidly and with probability 1 to the true sequence\ngenerating posterior mu, if the latter is computable. Hence, M is eligible as a\nuniversal sequence predictor in case of unknown mu. Despite some nearby results\nand proofs in the literature, the stronger result of convergence for all\n(Martin-Loef) random sequences remained open. Such a convergence result would\nbe particularly interesting and natural, since randomness can be defined in\nterms of M itself. We show that there are universal semimeasures M which do not\nconverge for all random sequences, i.e. we give a partial negative answer to\nthe open problem. We also provide a positive answer for some non-universal\nsemimeasures. We define the incomputable measure D as a mixture over all\ncomputable measures and the enumerable semimeasure W as a mixture over all\nenumerable nearly-measures. We show that W converges to D and D to mu on all\nrandom sequences. The Hellinger distance measuring closeness of two\ndistributions plays a central role.",
    "published": "2004-07-23T12:43:28Z",
    "link": "http://arxiv.org/pdf/cs/0407057v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CC",
      "cs.IT",
      "math.IT",
      "math.PR",
      "I.2.6; E.4; G.3; F.1.3"
    ],
    "authors": [
      "Marcus Hutter",
      "Andrej Muchnik"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0407065v1",
    "title": "Word Sense Disambiguation by Web Mining for Word Co-occurrence\n  Probabilities",
    "summary": "This paper describes the National Research Council (NRC) Word Sense\nDisambiguation (WSD) system, as applied to the English Lexical Sample (ELS)\ntask in Senseval-3. The NRC system approaches WSD as a classical supervised\nmachine learning problem, using familiar tools such as the Weka machine\nlearning software and Brill's rule-based part-of-speech tagger. Head words are\nrepresented as feature vectors with several hundred features. Approximately\nhalf of the features are syntactic and the other half are semantic. The main\nnovelty in the system is the method for generating the semantic features, based\non word \\hbox{co-occurrence} probabilities. The probabilities are estimated\nusing the Waterloo MultiText System with a corpus of about one terabyte of\nunlabeled text, collected by a web crawler.",
    "published": "2004-07-29T19:46:01Z",
    "link": "http://arxiv.org/pdf/cs/0407065v1.pdf",
    "category": [
      "cs.CL",
      "cs.IR",
      "cs.LG",
      "H.3.1; H.3.3; I.2.6; I.2.7; J.5"
    ],
    "authors": [
      "Peter D. Turney"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0408001v1",
    "title": "Semantic Linking - a Context-Based Approach to Interactivity in\n  Hypermedia",
    "summary": "The semantic Web initiates new, high level access schemes to online content\nand applications. One area of superior need for a redefined content exploration\nis given by on-line educational applications and their concepts of\ninteractivity in the framework of open hypermedia systems. In the present paper\nwe discuss aspects and opportunities of gaining interactivity schemes from\nsemantic notions of components. A transition from standard educational\nannotation to semantic statements of hyperlinks is discussed. Further on we\nintroduce the concept of semantic link contexts as an approach to manage a\ncoherent rhetoric of linking. A practical implementation is introduced, as\nwell. Our semantic hyperlink implementation is based on the more general\nMultimedia Information Repository MIR, an open hypermedia system supporting the\nstandards XML, Corba and JNDI.",
    "published": "2004-07-31T14:04:04Z",
    "link": "http://arxiv.org/pdf/cs/0408001v1.pdf",
    "category": [
      "cs.IR",
      "cs.LG",
      "H.5.4; H.2.4; H.3.4; H.5.1; C.2.4; K.3.1"
    ],
    "authors": [
      "Michael Engelhardt",
      "Thomas C. Schmidt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0408004v1",
    "title": "Hypermedia Learning Objects System - On the Way to a Semantic\n  Educational Web",
    "summary": "While eLearning systems become more and more popular in daily education,\navailable applications lack opportunities to structure, annotate and manage\ntheir contents in a high-level fashion. General efforts to improve these\ndeficits are taken by initiatives to define rich meta data sets and a\nsemanticWeb layer. In the present paper we introduce Hylos, an online learning\nsystem. Hylos is based on a cellular eLearning Object (ELO) information model\nencapsulating meta data conforming to the LOM standard. Content management is\nprovisioned on this semantic meta data level and allows for variable,\ndynamically adaptable access structures. Context aware multifunctional links\npermit a systematic navigation depending on the learners and didactic needs,\nthereby exploring the capabilities of the semantic web. Hylos is built upon the\nmore general Multimedia Information Repository (MIR) and the MIR adaptive\ncontext linking environment (MIRaCLE), its linking extension. MIR is an open\nsystem supporting the standards XML, Corba and JNDI. Hylos benefits from\nmanageable information structures, sophisticated access logic and high-level\nauthoring tools like the ELO editor responsible for the semi-manual creation of\nmeta data and WYSIWYG like content editing.",
    "published": "2004-07-31T22:16:37Z",
    "link": "http://arxiv.org/pdf/cs/0408004v1.pdf",
    "category": [
      "cs.IR",
      "cs.LG",
      "H.5.4; H.2.4; H.3.4; H.5.1; C.2.4; K.3.1"
    ],
    "authors": [
      "Michael Engelhardt",
      "Andreas Krpti",
      "Torsten Rack",
      "Ivette Schmidt",
      "Thomas C. Schmidt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0408007v1",
    "title": "Online convex optimization in the bandit setting: gradient descent\n  without a gradient",
    "summary": "We consider a the general online convex optimization framework introduced by\nZinkevich. In this setting, there is a sequence of convex functions. Each\nperiod, we must choose a signle point (from some feasible set) and pay a cost\nequal to the value of the next function on our chosen point. Zinkevich shows\nthat, if the each function is revealed after the choice is made, then one can\nachieve vanishingly small regret relative the best single decision chosen in\nhindsight.\n  We extend this to the bandit setting where we do not find out the entire\nfunctions but rather just their value at our chosen point. We show how to get\nvanishingly small regret in this setting.\n  Our approach uses a simple approximation of the gradient that is computed\nfrom evaluating a function at a single (random) point. We show that this\nestimate is sufficient to mimic Zinkevich's gradient descent online analysis,\nwith access to the gradient (only being able to evaluate the function at a\nsingle point).",
    "published": "2004-08-02T21:24:41Z",
    "link": "http://arxiv.org/pdf/cs/0408007v1.pdf",
    "category": [
      "cs.LG",
      "cs.CC"
    ],
    "authors": [
      "Abraham D. Flaxman",
      "Adam Tauman Kalai",
      "H. Brendan McMahan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/math/0408146v1",
    "title": "Learning a Machine for the Decision in a Partially Observable Markov\n  Universe",
    "summary": "In this paper, we are interested in optimal decisions in a partially\nobservable Markov universe. Our viewpoint departs from the dynamic programming\nviewpoint: we are directly approximating an optimal strategic tree depending on\nthe observation. This approximation is made by means of a parameterized\nprobabilistic law. In this paper, a particular family of hidden Markov models,\nwith input and output, is considered as a learning framework. A method for\noptimizing the parameters of these HMMs is proposed and applied. This\noptimization method is based on the cross-entropic principle.",
    "published": "2004-08-11T06:38:50Z",
    "link": "http://arxiv.org/pdf/math/0408146v1.pdf",
    "category": [
      "math.GM",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Frederic Dambreville"
    ]
  },
  {
    "id": "http://arxiv.org/abs/nlin/0408039v2",
    "title": "Stability and Diversity in Collective Adaptation",
    "summary": "We derive a class of macroscopic differential equations that describe\ncollective adaptation, starting from a discrete-time stochastic microscopic\nmodel. The behavior of each agent is a dynamic balance between adaptation that\nlocally achieves the best action and memory loss that leads to randomized\nbehavior. We show that, although individual agents interact with their\nenvironment and other agents in a purely self-interested way, macroscopic\nbehavior can be interpreted as game dynamics. Application to several familiar,\nexplicit game interactions shows that the adaptation dynamics exhibits a\ndiversity of collective behaviors. The simplicity of the assumptions underlying\nthe macroscopic equations suggests that these behaviors should be expected\nbroadly in collective adaptation. We also analyze the adaptation dynamics from\nan information-theoretic viewpoint and discuss self-organization induced by\ninformation flux between agents, giving a novel view of collective adaptation.",
    "published": "2004-08-20T05:17:14Z",
    "link": "http://arxiv.org/pdf/nlin/0408039v2.pdf",
    "category": [
      "nlin.AO",
      "cs.LG",
      "math.DS",
      "nlin.CD",
      "stat.ML"
    ],
    "authors": [
      "Yuzuru Sato",
      "Eizo Akiyama",
      "James P. Crutchfield"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0408048v1",
    "title": "Journal of New Democratic Methods: An Introduction",
    "summary": "This paper describes a new breed of academic journals that use statistical\nmachine learning techniques to make them more democratic. In particular, not\nonly can anyone submit an article, but anyone can also become a reviewer.\nMachine learning is used to decide which reviewers accurately represent the\nviews of the journal's readers and thus deserve to have their opinions carry\nmore weight. The paper concentrates on describing a specific experimental\nprototype of a democratic journal called the Journal of New Democratic Methods\n(JNDM). The paper also mentions the wider implications that machine learning\nand the techniques used in the JNDM may have for representative democracy in\ngeneral.",
    "published": "2004-08-21T16:57:34Z",
    "link": "http://arxiv.org/pdf/cs/0408048v1.pdf",
    "category": [
      "cs.CY",
      "cs.LG",
      "I.2.6; J.1; K.4.3"
    ],
    "authors": [
      "John David Funge"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0408058v1",
    "title": "Non-negative matrix factorization with sparseness constraints",
    "summary": "Non-negative matrix factorization (NMF) is a recently developed technique for\nfinding parts-based, linear representations of non-negative data. Although it\nhas successfully been applied in several applications, it does not always\nresult in parts-based representations. In this paper, we show how explicitly\nincorporating the notion of `sparseness' improves the found decompositions.\nAdditionally, we provide complete MATLAB code both for standard NMF and for our\nextension. Our hope is that this will further the application of these methods\nto solving novel data-analysis problems.",
    "published": "2004-08-25T20:25:43Z",
    "link": "http://arxiv.org/pdf/cs/0408058v1.pdf",
    "category": [
      "cs.LG",
      "cs.NE"
    ],
    "authors": [
      "Patrik O. Hoyer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0410004v1",
    "title": "Applying Policy Iteration for Training Recurrent Neural Networks",
    "summary": "Recurrent neural networks are often used for learning time-series data. Based\non a few assumptions we model this learning task as a minimization problem of a\nnonlinear least-squares cost function. The special structure of the cost\nfunction allows us to build a connection to reinforcement learning. We exploit\nthis connection and derive a convergent, policy iteration-based algorithm.\nFurthermore, we argue that RNN training can be fit naturally into the\nreinforcement learning framework.",
    "published": "2004-10-02T07:19:49Z",
    "link": "http://arxiv.org/pdf/cs/0410004v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "authors": [
      "I. Szita",
      "A. Lorincz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0410015v1",
    "title": "L1 regularization is better than L2 for learning and predicting chaotic\n  systems",
    "summary": "Emergent behaviors are in the focus of recent research interest. It is then\nof considerable importance to investigate what optimizations suit the learning\nand prediction of chaotic systems, the putative candidates for emergence. We\nhave compared L1 and L2 regularizations on predicting chaotic time series using\nlinear recurrent neural networks. The internal representation and the weights\nof the networks were optimized in a unifying framework. Computational tests on\ndifferent problems indicate considerable advantages for the L1 regularization:\nIt had considerably better learning time and better interpolating capabilities.\nWe shall argue that optimization viewed as a maximum likelihood estimation\njustifies our results, because L1 regularization fits heavy-tailed\ndistributions -- an apparently general feature of emergent systems -- better.",
    "published": "2004-10-07T10:57:08Z",
    "link": "http://arxiv.org/pdf/cs/0410015v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Z. Szabo",
      "A. Lorincz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/quant-ph/0411140v2",
    "title": "Improved Bounds on Quantum Learning Algorithms",
    "summary": "In this article we give several new results on the complexity of algorithms\nthat learn Boolean functions from quantum queries and quantum examples.\n  Hunziker et al. conjectured that for any class C of Boolean functions, the\nnumber of quantum black-box queries which are required to exactly identify an\nunknown function from C is $O(\\frac{\\log |C|}{\\sqrt{{\\hat{\\gamma}}^{C}}})$,\nwhere $\\hat{\\gamma}^{C}$ is a combinatorial parameter of the class C. We\nessentially resolve this conjecture in the affirmative by giving a quantum\nalgorithm that, for any class C, identifies any unknown function from C using\n$O(\\frac{\\log |C| \\log \\log |C|}{\\sqrt{{\\hat{\\gamma}}^{C}}})$ quantum black-box\nqueries.\n  We consider a range of natural problems intermediate between the exact\nlearning problem (in which the learner must obtain all bits of information\nabout the black-box function) and the usual problem of computing a predicate\n(in which the learner must obtain only one bit of information about the\nblack-box function). We give positive and negative results on when the quantum\nand classical query complexities of these intermediate problems are\npolynomially related to each other.\n  Finally, we improve the known lower bounds on the number of quantum examples\n(as opposed to quantum black-box queries) required for $(\\epsilon,\\delta)$-PAC\nlearning any concept class of Vapnik-Chervonenkis dimension d over the domain\n$\\{0,1\\}^n$ from $\\Omega(\\frac{d}{n})$ to $\\Omega(\\frac{1}{\\epsilon}\\log\n\\frac{1}{\\delta}+d+\\frac{\\sqrt{d}}{\\epsilon})$. This new lower bound comes\ncloser to matching known upper bounds for classical PAC learning.",
    "published": "2004-11-18T20:14:16Z",
    "link": "http://arxiv.org/pdf/quant-ph/0411140v2.pdf",
    "category": [
      "quant-ph",
      "cs.LG"
    ],
    "authors": [
      "Alp Atici",
      "Rocco A. Servedio"
    ]
  },
  {
    "id": "http://arxiv.org/abs/math/0411515v1",
    "title": "Fast Non-Parametric Bayesian Inference on Infinite Trees",
    "summary": "Given i.i.d. data from an unknown distribution, we consider the problem of\npredicting future items. An adaptive way to estimate the probability density is\nto recursively subdivide the domain to an appropriate data-dependent\ngranularity. A Bayesian would assign a data-independent prior probability to\n\"subdivide\", which leads to a prior over infinite(ly many) trees. We derive an\nexact, fast, and simple inference algorithm for such a prior, for the data\nevidence, the predictive distribution, the effective model dimension, and other\nquantities.",
    "published": "2004-11-23T16:39:07Z",
    "link": "http://arxiv.org/pdf/math/0411515v1.pdf",
    "category": [
      "math.ST",
      "cs.LG",
      "math.PR",
      "stat.TH",
      "62G07; 60B10; 68W99"
    ],
    "authors": [
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0411099v1",
    "title": "A Note on the PAC Bayesian Theorem",
    "summary": "We prove general exponential moment inequalities for averages of [0,1]-valued\niid random variables and use them to tighten the PAC Bayesian Theorem. The\nlogarithmic dependence on the sample count in the enumerator of the PAC\nBayesian bound is halved.",
    "published": "2004-11-30T08:36:59Z",
    "link": "http://arxiv.org/pdf/cs/0411099v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "I.5.1"
    ],
    "authors": [
      "Andreas Maurer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0412003v1",
    "title": "Mining Heterogeneous Multivariate Time-Series for Learning Meaningful\n  Patterns: Application to Home Health Telecare",
    "summary": "For the last years, time-series mining has become a challenging issue for\nresearchers. An important application lies in most monitoring purposes, which\nrequire analyzing large sets of time-series for learning usual patterns. Any\ndeviation from this learned profile is then considered as an unexpected\nsituation. Moreover, complex applications may involve the temporal study of\nseveral heterogeneous parameters. In that paper, we propose a method for mining\nheterogeneous multivariate time-series for learning meaningful patterns. The\nproposed approach allows for mixed time-series -- containing both pattern and\nnon-pattern data -- such as for imprecise matches, outliers, stretching and\nglobal translating of patterns instances in time. We present the early results\nof our approach in the context of monitoring the health status of a person at\nhome. The purpose is to build a behavioral profile of a person by analyzing the\ntime variations of several quantitative or qualitative parameters recorded\nthrough a provision of sensors installed in the home.",
    "published": "2004-12-01T16:32:49Z",
    "link": "http://arxiv.org/pdf/cs/0412003v1.pdf",
    "category": [
      "cs.LG",
      "G.3"
    ],
    "authors": [
      "Florence Duchene",
      "Catherine Garbay",
      "Vincent Rialle"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0412024v1",
    "title": "Human-Level Performance on Word Analogy Questions by Latent Relational\n  Analysis",
    "summary": "This paper introduces Latent Relational Analysis (LRA), a method for\nmeasuring relational similarity. LRA has potential applications in many areas,\nincluding information extraction, word sense disambiguation, machine\ntranslation, and information retrieval. Relational similarity is correspondence\nbetween relations, in contrast with attributional similarity, which is\ncorrespondence between attributes. When two words have a high degree of\nattributional similarity, we call them synonyms. When two pairs of words have a\nhigh degree of relational similarity, we say that their relations are\nanalogous. For example, the word pair mason/stone is analogous to the pair\ncarpenter/wood. Past work on semantic similarity measures has mainly been\nconcerned with attributional similarity. Recently the Vector Space Model (VSM)\nof information retrieval has been adapted to the task of measuring relational\nsimilarity, achieving a score of 47% on a collection of 374 college-level\nmultiple-choice word analogy questions. In the VSM approach, the relation\nbetween a pair of words is characterized by a vector of frequencies of\npredefined patterns in a large corpus. LRA extends the VSM approach in three\nways: (1) the patterns are derived automatically from the corpus (they are not\npredefined), (2) the Singular Value Decomposition (SVD) is used to smooth the\nfrequency data (it is also used this way in Latent Semantic Analysis), and (3)\nautomatically generated synonyms are used to explore reformulations of the word\npairs. LRA achieves 56% on the 374 analogy questions, statistically equivalent\nto the average human score of 57%. On the related problem of classifying\nnoun-modifier relations, LRA achieves similar gains over the VSM, while using a\nsmaller corpus.",
    "published": "2004-12-06T21:50:18Z",
    "link": "http://arxiv.org/pdf/cs/0412024v1.pdf",
    "category": [
      "cs.CL",
      "cs.IR",
      "cs.LG",
      "H.3.1; I.2.6; I.2.7"
    ],
    "authors": [
      "Peter D. Turney"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0412098v3",
    "title": "The Google Similarity Distance",
    "summary": "Words and phrases acquire meaning from the way they are used in society, from\ntheir relative semantics to other words and phrases. For computers the\nequivalent of `society' is `database,' and the equivalent of `use' is `way to\nsearch the database.' We present a new theory of similarity between words and\nphrases based on information distance and Kolmogorov complexity. To fix\nthoughts we use the world-wide-web as database, and Google as search engine.\nThe method is also applicable to other search engines and databases. This\ntheory is then applied to construct a method to automatically extract\nsimilarity, the Google similarity distance, of words and phrases from the\nworld-wide-web using Google page counts. The world-wide-web is the largest\ndatabase on earth, and the context information entered by millions of\nindependent users averages out to provide automatic semantics of useful\nquality. We give applications in hierarchical clustering, classification, and\nlanguage translation. We give examples to distinguish between colors and\nnumbers, cluster names of paintings by 17th century Dutch masters and names of\nbooks by English novelists, the ability to understand emergencies, and primes,\nand we demonstrate the ability to do a simple automatic English-Spanish\ntranslation. Finally, we use the WordNet database as an objective baseline\nagainst which to judge the performance of our method. We conduct a massive\nrandomized trial in binary classification using support vector machines to\nlearn categories based on our Google distance, resulting in an a mean agreement\nof 87% with the expert crafted WordNet categories.",
    "published": "2004-12-21T16:05:36Z",
    "link": "http://arxiv.org/pdf/cs/0412098v3.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.DB",
      "cs.IR",
      "cs.LG",
      "I.2.4; I.2.7"
    ],
    "authors": [
      "Rudi Cilibrasi",
      "Paul M. B. Vitanyi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0412106v1",
    "title": "Online Learning of Aggregate Knowledge about Non-linear Preferences\n  Applied to Negotiating Prices and Bundles",
    "summary": "In this paper, we consider a form of multi-issue negotiation where a shop\nnegotiates both the contents and the price of bundles of goods with his\ncustomers. We present some key insights about, as well as a procedure for,\nlocating mutually beneficial alternatives to the bundle currently under\nnegotiation. The essence of our approach lies in combining aggregate\n(anonymous) knowledge of customer preferences with current data about the\nongoing negotiation process. The developed procedure either works with already\nobtained aggregate knowledge or, in the absence of such knowledge, learns the\nrelevant information online. We conduct computer experiments with simulated\ncustomers that have_nonlinear_ preferences. We show how, for various types of\ncustomers, with distinct negotiation heuristics, our procedure (with and\nwithout the necessary aggregate knowledge) increases the speed with which deals\nare reached, as well as the number and the Pareto efficiency of the deals\nreached compared to a benchmark.",
    "published": "2004-12-23T15:21:40Z",
    "link": "http://arxiv.org/pdf/cs/0412106v1.pdf",
    "category": [
      "cs.MA",
      "cs.GT",
      "cs.LG"
    ],
    "authors": [
      "Koye Somefun",
      "Tomas Klos",
      "Han La Poutr"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0501018v1",
    "title": "Combining Independent Modules in Lexical Multiple-Choice Problems",
    "summary": "Existing statistical approaches to natural language problems are very coarse\napproximations to the true complexity of language processing. As such, no\nsingle technique will be best for all problem instances. Many researchers are\nexamining ensemble methods that combine the output of multiple modules to\ncreate more accurate solutions. This paper examines three merging rules for\ncombining probability distributions: the familiar mixture rule, the logarithmic\nrule, and a novel product rule. These rules were applied with state-of-the-art\nresults to two problems used to assess human mastery of lexical semantics --\nsynonym questions and analogy questions. All three merging rules result in\nensembles that are more accurate than any of their component modules. The\ndifferences among the three rules are not statistically significant, but it is\nsuggestive that the popular mixture rule is not the best rule for either of the\ntwo problems.",
    "published": "2005-01-10T21:03:14Z",
    "link": "http://arxiv.org/pdf/cs/0501018v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL",
      "cs.IR",
      "I.2.6; I.2.7; H.3.1; J.5"
    ],
    "authors": [
      "Peter D. Turney",
      "Michael L. Littman",
      "Jeffrey Bigham",
      "Victor Shnayder"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0501028v1",
    "title": "An Empirical Study of MDL Model Selection with Infinite Parametric\n  Complexity",
    "summary": "Parametric complexity is a central concept in MDL model selection. In\npractice it often turns out to be infinite, even for quite simple models such\nas the Poisson and Geometric families. In such cases, MDL model selection as\nbased on NML and Bayesian inference based on Jeffreys' prior can not be used.\nSeveral ways to resolve this problem have been proposed. We conduct experiments\nto compare and evaluate their behaviour on small sample sizes.\n  We find interestingly poor behaviour for the plug-in predictive code; a\nrestricted NML model performs quite well but it is questionable if the results\nvalidate its theoretical motivation. The Bayesian model with the improper\nJeffreys' prior is the most dependable.",
    "published": "2005-01-14T15:50:28Z",
    "link": "http://arxiv.org/pdf/cs/0501028v1.pdf",
    "category": [
      "cs.LG",
      "cs.IT",
      "math.IT",
      "E.3; G.4"
    ],
    "authors": [
      "Steven de Rooij",
      "Peter Grunwald"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0501063v1",
    "title": "Bandit Problems with Side Observations",
    "summary": "An extension of the traditional two-armed bandit problem is considered, in\nwhich the decision maker has access to some side information before deciding\nwhich arm to pull. At each time t, before making a selection, the decision\nmaker is able to observe a random variable X_t that provides some information\non the rewards to be obtained. The focus is on finding uniformly good rules\n(that minimize the growth rate of the inferior sampling time) and on\nquantifying how much the additional information helps. Various settings are\nconsidered and for each setting, lower bounds on the achievable inferior\nsampling time are developed and asymptotically optimal adaptive schemes\nachieving these lower bounds are constructed.",
    "published": "2005-01-22T22:07:18Z",
    "link": "http://arxiv.org/pdf/cs/0501063v1.pdf",
    "category": [
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "authors": [
      "Chih-Chun Wang",
      "Sanjeev R. Kulkarni",
      "H. Vincent Poor"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0502004v1",
    "title": "Asymptotic Log-loss of Prequential Maximum Likelihood Codes",
    "summary": "We analyze the Dawid-Rissanen prequential maximum likelihood codes relative\nto one-parameter exponential family models M. If data are i.i.d. according to\nan (essentially) arbitrary P, then the redundancy grows at rate c/2 ln n. We\nshow that c=v1/v2, where v1 is the variance of P, and v2 is the variance of the\ndistribution m* in M that is closest to P in KL divergence. This shows that\nprequential codes behave quite differently from other important universal codes\nsuch as the 2-part MDL, Shtarkov and Bayes codes, for which c=1. This behavior\nis undesirable in an MDL model selection setting.",
    "published": "2005-02-01T13:42:49Z",
    "link": "http://arxiv.org/pdf/cs/0502004v1.pdf",
    "category": [
      "cs.LG",
      "cs.IT",
      "math.IT",
      "E.4"
    ],
    "authors": [
      "Peter Grunwald",
      "Steven de Rooij"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0502016v1",
    "title": "Stability Analysis for Regularized Least Squares Regression",
    "summary": "We discuss stability for a class of learning algorithms with respect to noisy\nlabels. The algorithms we consider are for regression, and they involve the\nminimization of regularized risk functionals, such as L(f) := 1/N sum_i\n(f(x_i)-y_i)^2+ lambda ||f||_H^2. We shall call the algorithm `stable' if, when\ny_i is a noisy version of f*(x_i) for some function f* in H, the output of the\nalgorithm converges to f* as the regularization term and noise simultaneously\nvanish. We consider two flavors of this problem, one where a data set of N\npoints remains fixed, and the other where N -> infinity. For the case where N\n-> infinity, we give conditions for convergence to f_E (the function which is\nthe expectation of y(x) for each x), as lambda -> 0. For the fixed N case, we\ndescribe the limiting 'non-noisy', 'non-regularized' function f*, and give\nconditions for convergence. In the process, we develop a set of tools for\ndealing with functionals such as L(f), which are applicable to many other\nproblems in learning theory.",
    "published": "2005-02-03T19:54:02Z",
    "link": "http://arxiv.org/pdf/cs/0502016v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Cynthia Rudin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0502067v1",
    "title": "Master Algorithms for Active Experts Problems based on Increasing Loss\n  Values",
    "summary": "We specify an experts algorithm with the following characteristics: (a) it\nuses only feedback from the actions actually chosen (bandit setup), (b) it can\nbe applied with countably infinite expert classes, and (c) it copes with losses\nthat may grow in time appropriately slowly. We prove loss bounds against an\nadaptive adversary. From this, we obtain master algorithms for \"active experts\nproblems\", which means that the master's actions may influence the behavior of\nthe adversary. Our algorithm can significantly outperform standard experts\nalgorithms on such problems. Finally, we combine it with a universal expert\nclass. This results in a (computationally infeasible) universal master\nalgorithm which performs - in a certain sense - almost as well as any\ncomputable strategy, for any online problem.",
    "published": "2005-02-15T14:59:49Z",
    "link": "http://arxiv.org/pdf/cs/0502067v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "I.2.6; G.3"
    ],
    "authors": [
      "Jan Poland",
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/math/0502315v1",
    "title": "Strong Asymptotic Assertions for Discrete MDL in Regression and\n  Classification",
    "summary": "We study the properties of the MDL (or maximum penalized complexity)\nestimator for Regression and Classification, where the underlying model class\nis countable. We show in particular a finite bound on the Hellinger losses\nunder the only assumption that there is a \"true\" model contained in the class.\nThis implies almost sure convergence of the predictive distribution to the true\none at a fast rate. It corresponds to Solomonoff's central theorem of universal\ninduction, however with a bound that is exponentially larger.",
    "published": "2005-02-15T16:26:36Z",
    "link": "http://arxiv.org/pdf/math/0502315v1.pdf",
    "category": [
      "math.ST",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "math.PR",
      "stat.TH"
    ],
    "authors": [
      "Jan Poland",
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0502074v2",
    "title": "On sample complexity for computational pattern recognition",
    "summary": "In statistical setting of the pattern recognition problem the number of\nexamples required to approximate an unknown labelling function is linear in the\nVC dimension of the target learning class. In this work we consider the\nquestion whether such bounds exist if we restrict our attention to computable\npattern recognition methods, assuming that the unknown labelling function is\nalso computable. We find that in this case the number of examples required for\na computable method to approximate the labelling function not only is not\nlinear, but grows faster (in the VC dimension of the class) than any computable\nfunction. No time or space constraints are put on the predictors or target\nfunctions; the only resource we consider is the training examples.\n  The task of pattern recognition is considered in conjunction with another\nlearning problem -- data compression. An impossibility result for the task of\ndata compression allows us to estimate the sample complexity for pattern\nrecognition.",
    "published": "2005-02-17T14:58:28Z",
    "link": "http://arxiv.org/pdf/cs/0502074v2.pdf",
    "category": [
      "cs.LG",
      "cs.CC"
    ],
    "authors": [
      "Daniil Ryabko"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0502076v2",
    "title": "Learning nonsingular phylogenies and hidden Markov models",
    "summary": "In this paper we study the problem of learning phylogenies and hidden Markov\nmodels. We call a Markov model nonsingular if all transition matrices have\ndeterminants bounded away from 0 (and 1). We highlight the role of the\nnonsingularity condition for the learning problem. Learning hidden Markov\nmodels without the nonsingularity condition is at least as hard as learning\nparity with noise, a well-known learning problem conjectured to be\ncomputationally hard. On the other hand, we give a polynomial-time algorithm\nfor learning nonsingular phylogenies and hidden Markov models.",
    "published": "2005-02-18T01:31:53Z",
    "link": "http://arxiv.org/pdf/cs/0502076v2.pdf",
    "category": [
      "cs.LG",
      "cs.CE",
      "math.PR",
      "math.ST",
      "q-bio.PE",
      "stat.TH",
      "60J10, 60J20, 68T05, 92B10 (Primary)"
    ],
    "authors": [
      "Elchanan Mossel",
      "Sbastien Roch"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0502086v1",
    "title": "The Self-Organization of Speech Sounds",
    "summary": "The speech code is a vehicle of language: it defines a set of forms used by a\ncommunity to carry information. Such a code is necessary to support the\nlinguistic interactions that allow humans to communicate. How then may a speech\ncode be formed prior to the existence of linguistic interactions? Moreover, the\nhuman speech code is discrete and compositional, shared by all the individuals\nof a community but different across communities, and phoneme inventories are\ncharacterized by statistical regularities. How can a speech code with these\nproperties form? We try to approach these questions in the paper, using the\n\"methodology of the artificial\". We build a society of artificial agents, and\ndetail a mechanism that shows the formation of a discrete speech code without\npre-supposing the existence of linguistic capacities or of coordinated\ninteractions. The mechanism is based on a low-level model of sensory-motor\ninteractions. We show that the integration of certain very simple and non\nlanguage-specific neural devices leads to the formation of a speech code that\nhas properties similar to the human speech code. This result relies on the\nself-organizing properties of a generic coupling between perception and\nproduction within agents, and on the interactions between agents. The\nartificial system helps us to develop better intuitions on how speech might\nhave appeared, by showing how self-organization might have helped natural\nselection to find speech.",
    "published": "2005-02-22T09:51:16Z",
    "link": "http://arxiv.org/pdf/cs/0502086v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.NE",
      "cs.RO",
      "math.DS"
    ],
    "authors": [
      "Pierre-Yves Oudeyer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0503026v1",
    "title": "On Generalized Computable Universal Priors and their Convergence",
    "summary": "Solomonoff unified Occam's razor and Epicurus' principle of multiple\nexplanations to one elegant, formal, universal theory of inductive inference,\nwhich initiated the field of algorithmic information theory. His central result\nis that the posterior of the universal semimeasure M converges rapidly to the\ntrue sequence generating posterior mu, if the latter is computable. Hence, M is\neligible as a universal predictor in case of unknown mu. The first part of the\npaper investigates the existence and convergence of computable universal\n(semi)measures for a hierarchy of computability classes: recursive, estimable,\nenumerable, and approximable. For instance, M is known to be enumerable, but\nnot estimable, and to dominate all enumerable semimeasures. We present proofs\nfor discrete and continuous semimeasures. The second part investigates more\nclosely the types of convergence, possibly implied by universality: in\ndifference and in ratio, with probability 1, in mean sum, and for Martin-Loef\nrandom sequences. We introduce a generalized concept of randomness for\nindividual sequences and use it to exhibit difficulties regarding these issues.\nIn particular, we show that convergence fails (holds) on generalized-random\nsequences in gappy (dense) Bernoulli classes.",
    "published": "2005-03-11T12:38:30Z",
    "link": "http://arxiv.org/pdf/cs/0503026v1.pdf",
    "category": [
      "cs.LG",
      "cs.CC",
      "math.PR",
      "I.2.6; E.4; G.3"
    ],
    "authors": [
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0503071v2",
    "title": "Consistency in Models for Distributed Learning under Communication\n  Constraints",
    "summary": "Motivated by sensor networks and other distributed settings, several models\nfor distributed learning are presented. The models differ from classical works\nin statistical pattern recognition by allocating observations of an independent\nand identically distributed (i.i.d.) sampling process amongst members of a\nnetwork of simple learning agents. The agents are limited in their ability to\ncommunicate to a central fusion center and thus, the amount of information\navailable for use in classification or regression is constrained. For several\nbasic communication models in both the binary classification and regression\nframeworks, we question the existence of agent decision rules and fusion rules\nthat result in a universally consistent ensemble. The answers to this question\npresent new issues to consider with regard to universal consistency. Insofar as\nthese models present a useful picture of distributed scenarios, this paper\naddresses the issue of whether or not the guarantees provided by Stone's\nTheorem in centralized environments hold in distributed settings.",
    "published": "2005-03-26T05:13:51Z",
    "link": "http://arxiv.org/pdf/cs/0503071v2.pdf",
    "category": [
      "cs.IT",
      "cs.LG",
      "math.IT",
      "G.3; I.2.6; I.2.11; I.5.1"
    ],
    "authors": [
      "Joel B. Predd",
      "Sanjeev R. Kulkarni",
      "H. Vincent Poor"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0503072v1",
    "title": "Distributed Learning in Wireless Sensor Networks",
    "summary": "The problem of distributed or decentralized detection and estimation in\napplications such as wireless sensor networks has often been considered in the\nframework of parametric models, in which strong assumptions are made about a\nstatistical description of nature. In certain applications, such assumptions\nare warranted and systems designed from these models show promise. However, in\nother scenarios, prior knowledge is at best vague and translating such\nknowledge into a statistical model is undesirable. Applications such as these\npave the way for a nonparametric study of distributed detection and estimation.\nIn this paper, we review recent work of the authors in which some elementary\nmodels for distributed learning are considered. These models are in the spirit\nof classical work in nonparametric statistics and are applicable to wireless\nsensor networks.",
    "published": "2005-03-26T05:42:06Z",
    "link": "http://arxiv.org/pdf/cs/0503072v1.pdf",
    "category": [
      "cs.IT",
      "cs.LG",
      "math.IT",
      "C.2.1; I.2.6; G3"
    ],
    "authors": [
      "Joel B. Predd",
      "Sanjeev R. Kulkarni",
      "H. Vincent Poor"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0504001v1",
    "title": "Probabilistic and Team PFIN-type Learning: General Properties",
    "summary": "We consider the probability hierarchy for Popperian FINite learning and study\nthe general properties of this hierarchy. We prove that the probability\nhierarchy is decidable, i.e. there exists an algorithm that receives p_1 and\np_2 and answers whether PFIN-type learning with the probability of success p_1\nis equivalent to PFIN-type learning with the probability of success p_2.\n  To prove our result, we analyze the topological structure of the probability\nhierarchy. We prove that it is well-ordered in descending ordering and\norder-equivalent to ordinal epsilon_0. This shows that the structure of the\nhierarchy is very complicated.\n  Using similar methods, we also prove that, for PFIN-type learning, team\nlearning and probabilistic learning are of the same power.",
    "published": "2005-03-31T23:04:28Z",
    "link": "http://arxiv.org/pdf/cs/0504001v1.pdf",
    "category": [
      "cs.LG",
      "F.1.1, I.2.6"
    ],
    "authors": [
      "Andris Ambainis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0504042v1",
    "title": "The Bayesian Decision Tree Technique with a Sweeping Strategy",
    "summary": "The uncertainty of classification outcomes is of crucial importance for many\nsafety critical applications including, for example, medical diagnostics. In\nsuch applications the uncertainty of classification can be reliably estimated\nwithin a Bayesian model averaging technique that allows the use of prior\ninformation. Decision Tree (DT) classification models used within such a\ntechnique gives experts additional information by making this classification\nscheme observable. The use of the Markov Chain Monte Carlo (MCMC) methodology\nof stochastic sampling makes the Bayesian DT technique feasible to perform.\nHowever, in practice, the MCMC technique may become stuck in a particular DT\nwhich is far away from a region with a maximal posterior. Sampling such DTs\ncauses bias in the posterior estimates, and as a result the evaluation of\nclassification uncertainty may be incorrect. In a particular case, the negative\neffect of such sampling may be reduced by giving additional prior information\non the shape of DTs. In this paper we describe a new approach based on sweeping\nthe DTs without additional priors on the favorite shape of DTs. The\nperformances of Bayesian DT techniques with the standard and sweeping\nstrategies are compared on a synthetic data as well as on real datasets.\nQuantitatively evaluating the uncertainty in terms of entropy of class\nposterior probabilities, we found that the sweeping strategy is superior to the\nstandard strategy.",
    "published": "2005-04-11T17:45:09Z",
    "link": "http://arxiv.org/pdf/cs/0504042v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "V. Schetinin",
      "J. E. Fieldsend",
      "D. Partridge",
      "W. J. Krzanowski",
      "R. M. Everson",
      "T. C. Bailey",
      "A. Hernandez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0504043v1",
    "title": "Experimental Comparison of Classification Uncertainty for Randomised and\n  Bayesian Decision Tree Ensembles",
    "summary": "In this paper we experimentally compare the classification uncertainty of the\nrandomised Decision Tree (DT) ensemble technique and the Bayesian DT technique\nwith a restarting strategy on a synthetic dataset as well as on some datasets\ncommonly used in the machine learning community. For quantitative evaluation of\nclassification uncertainty, we use an Uncertainty Envelope dealing with the\nclass posterior distribution and a given confidence probability. Counting the\nclassifier outcomes, this technique produces feasible evaluations of the\nclassification uncertainty. Using this technique in our experiments, we found\nthat the Bayesian DT technique is superior to the randomised DT ensemble\ntechnique.",
    "published": "2005-04-11T17:53:35Z",
    "link": "http://arxiv.org/pdf/cs/0504043v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "V. Schetinin",
      "D. Partridge",
      "W. J. Krzanowski",
      "R. M. Everson",
      "J. E. Fieldsend",
      "T. C. Bailey",
      "A. Hernandez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0504052v1",
    "title": "Learning Multi-Class Neural-Network Models from Electroencephalograms",
    "summary": "We describe a new algorithm for learning multi-class neural-network models\nfrom large-scale clinical electroencephalograms (EEGs). This algorithm trains\nhidden neurons separately to classify all the pairs of classes. To find best\npairwise classifiers, our algorithm searches for input variables which are\nrelevant to the classification problem. Despite patient variability and heavily\noverlapping classes, a 16-class model learnt from EEGs of 65 sleeping newborns\ncorrectly classified 80.8% of the training and 80.1% of the testing examples.\nAdditionally, the neural-network model provides a probabilistic interpretation\nof decisions.",
    "published": "2005-04-13T13:22:49Z",
    "link": "http://arxiv.org/pdf/cs/0504052v1.pdf",
    "category": [
      "cs.NE",
      "cs.LG"
    ],
    "authors": [
      "Vitaly Schetinin",
      "Joachim Schult",
      "Burkhart Scheidt",
      "Valery Kuriakin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0504054v1",
    "title": "Learning from Web: Review of Approaches",
    "summary": "Knowledge discovery is defined as non-trivial extraction of implicit,\npreviously unknown and potentially useful information from given data.\nKnowledge extraction from web documents deals with unstructured, free-format\ndocuments whose number is enormous and rapidly growing. The artificial neural\nnetworks are well suitable to solve a problem of knowledge discovery from web\ndocuments because trained networks are able more accurately and easily to\nclassify the learning and testing examples those represent the text mining\ndomain. However, the neural networks that consist of large number of weighted\nconnections and activation units often generate the incomprehensible and\nhard-to-understand models of text classification. This problem may be also\naddressed to most powerful recurrent neural networks that employ the feedback\nlinks from hidden or output units to their input units. Due to feedback links,\nrecurrent neural networks are able take into account of a context in document.\nTo be useful for data mining, self-organizing neural network techniques of\nknowledge extraction have been explored and developed. Self-organization\nprinciples were used to create an adequate neural-network structure and reduce\na dimensionality of features used to describe text documents. The use of these\nprinciples seems interesting because ones are able to reduce a neural-network\nredundancy and considerably facilitate the knowledge representation.",
    "published": "2005-04-13T13:40:38Z",
    "link": "http://arxiv.org/pdf/cs/0504054v1.pdf",
    "category": [
      "cs.NE",
      "cs.LG"
    ],
    "authors": [
      "Vitaly Schetinin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0504063v1",
    "title": "Selection in Scale-Free Small World",
    "summary": "In this paper we compare the performance characteristics of our selection\nbased learning algorithm for Web crawlers with the characteristics of the\nreinforcement learning algorithm. The task of the crawlers is to find new\ninformation on the Web. The selection algorithm, called weblog update, modifies\nthe starting URL lists of our crawlers based on the found URLs containing new\ninformation. The reinforcement learning algorithm modifies the URL orderings of\nthe crawlers based on the received reinforcements for submitted documents. We\nperformed simulations based on data collected from the Web. The collected\nportion of the Web is typical and exhibits scale-free small world (SFSW)\nstructure. We have found that on this SFSW, the weblog update algorithm\nperforms better than the reinforcement learning algorithm. It finds the new\ninformation faster than the reinforcement learning algorithm and has better new\ninformation/all submitted documents ratio. We believe that the advantages of\nthe selection algorithm over reinforcement learning algorithm is due to the\nsmall world property of the Web.",
    "published": "2005-04-14T07:57:01Z",
    "link": "http://arxiv.org/pdf/cs/0504063v1.pdf",
    "category": [
      "cs.LG",
      "cs.IR",
      "H.3.3"
    ],
    "authors": [
      "Zs. Palotai",
      "Cs. Farkas",
      "A. Lorincz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0504069v1",
    "title": "A Neural-Network Technique to Learn Concepts from Electroencephalograms",
    "summary": "A new technique is presented developed to learn multi-class concepts from\nclinical electroencephalograms. A desired concept is represented as a neuronal\ncomputational model consisting of the input, hidden, and output neurons. In\nthis model the hidden neurons learn independently to classify the\nelectroencephalogram segments presented by spectral and statistical features.\nThis technique has been applied to the electroencephalogram data recorded from\n65 sleeping healthy newborns in order to learn a brain maturation concept of\nnewborns aged between 35 and 51 weeks. The 39399 and 19670 segments from these\ndata have been used for learning and testing the concept, respectively. As a\nresult, the concept has correctly classified 80.1% of the testing segments or\n87.7% of the 65 records.",
    "published": "2005-04-14T10:47:38Z",
    "link": "http://arxiv.org/pdf/cs/0504069v1.pdf",
    "category": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Vitaly Schetinin",
      "Joachim Schult"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0504070v1",
    "title": "The Combined Technique for Detection of Artifacts in Clinical\n  Electroencephalograms of Sleeping Newborns",
    "summary": "In this paper we describe a new method combining the polynomial neural\nnetwork and decision tree techniques in order to derive comprehensible\nclassification rules from clinical electroencephalograms (EEGs) recorded from\nsleeping newborns. These EEGs are heavily corrupted by cardiac, eye movement,\nmuscle and noise artifacts and as a consequence some EEG features are\nirrelevant to classification problems. Combining the polynomial network and\ndecision tree techniques, we discover comprehensible classification rules\nwhilst also attempting to keep their classification error down. This technique\nis shown to outperform a number of commonly used machine learning technique\napplied to automatically recognize artifacts in the sleep EEGs.",
    "published": "2005-04-14T10:49:55Z",
    "link": "http://arxiv.org/pdf/cs/0504070v1.pdf",
    "category": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Vitaly Schetinin",
      "Joachim Schult"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0504078v1",
    "title": "Adaptive Online Prediction by Following the Perturbed Leader",
    "summary": "When applying aggregating strategies to Prediction with Expert Advice, the\nlearning rate must be adaptively tuned. The natural choice of\nsqrt(complexity/current loss) renders the analysis of Weighted Majority\nderivatives quite complicated. In particular, for arbitrary weights there have\nbeen no results proven so far. The analysis of the alternative \"Follow the\nPerturbed Leader\" (FPL) algorithm from Kalai & Vempala (2003) (based on\nHannan's algorithm) is easier. We derive loss bounds for adaptive learning rate\nand both finite expert classes with uniform weights and countable expert\nclasses with arbitrary weights. For the former setup, our loss bounds match the\nbest known results so far, while for the latter our results are new.",
    "published": "2005-04-16T16:48:49Z",
    "link": "http://arxiv.org/pdf/cs/0504078v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "I.2.6; G.3"
    ],
    "authors": [
      "Marcus Hutter",
      "Jan Poland"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0504086v1",
    "title": "Componentwise Least Squares Support Vector Machines",
    "summary": "This chapter describes componentwise Least Squares Support Vector Machines\n(LS-SVMs) for the estimation of additive models consisting of a sum of\nnonlinear components. The primal-dual derivations characterizing LS-SVMs for\nthe estimation of the additive model result in a single set of linear equations\nwith size growing in the number of data-points. The derivation is elaborated\nfor the classification as well as the regression case. Furthermore, different\ntechniques are proposed to discover structure in the data by looking for sparse\ncomponents in the model based on dedicated regularization schemes on the one\nhand and fusion of the componentwise LS-SVMs training with a validation\ncriterion on the other hand. (keywords: LS-SVMs, additive models,\nregularization, structure detection)",
    "published": "2005-04-19T15:01:25Z",
    "link": "http://arxiv.org/pdf/cs/0504086v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "I.2.6"
    ],
    "authors": [
      "Kristiaan Pelckmans",
      "Ivan Goethals",
      "Jos De Brabanter",
      "Johan A. K. Suykens",
      "Bart De Moor"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0505028v3",
    "title": "A linear memory algorithm for Baum-Welch training",
    "summary": "Background: Baum-Welch training is an expectation-maximisation algorithm for\ntraining the emission and transition probabilities of hidden Markov models in a\nfully automated way.\n  Methods and results: We introduce a linear space algorithm for Baum-Welch\ntraining. For a hidden Markov model with M states, T free transition and E free\nemission parameters, and an input sequence of length L, our new algorithm\nrequires O(M) memory and O(L M T_max (T + E)) time for one Baum-Welch\niteration, where T_max is the maximum number of states that any state is\nconnected to. The most memory efficient algorithm until now was the\ncheckpointing algorithm with O(log(L) M) memory and O(log(L) L M T_max) time\nrequirement. Our novel algorithm thus renders the memory requirement completely\nindependent of the length of the training sequences. More generally, for an\nn-hidden Markov model and n input sequences of length L, the memory requirement\nof O(log(L) L^(n-1) M) is reduced to O(L^(n-1) M) memory while the running time\nis changed from O(log(L) L^n M T_max + L^n (T + E)) to O(L^n M T_max (T + E)).\n  Conclusions: For the large class of hidden Markov models used for example in\ngene prediction, whose number of states does not scale with the length of the\ninput sequence, our novel algorithm can thus be both faster and more\nmemory-efficient than any of the existing algorithms.",
    "published": "2005-05-11T16:45:58Z",
    "link": "http://arxiv.org/pdf/cs/0505028v3.pdf",
    "category": [
      "cs.LG",
      "cs.DS",
      "q-bio.QM",
      "I.2.6; G.3"
    ],
    "authors": [
      "Istvan Miklos",
      "Irmtraud M. Meyer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0505083v1",
    "title": "Defensive forecasting",
    "summary": "We consider how to make probability forecasts of binary labels. Our main\nmathematical result is that for any continuous gambling strategy used for\ndetecting disagreement between the forecasts and the actual labels, there\nexists a forecasting strategy whose forecasts are ideal as far as this gambling\nstrategy is concerned. A forecasting strategy obtained in this way from a\ngambling strategy demonstrating a strong law of large numbers is simplified and\nstudied empirically.",
    "published": "2005-05-30T21:12:00Z",
    "link": "http://arxiv.org/pdf/cs/0505083v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "I.2.6; I.5.1"
    ],
    "authors": [
      "Vladimir Vovk",
      "Akimichi Takemura",
      "Glenn Shafer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0506004v4",
    "title": "Non-asymptotic calibration and resolution",
    "summary": "We analyze a new algorithm for probability forecasting of binary observations\non the basis of the available data, without making any assumptions about the\nway the observations are generated. The algorithm is shown to be well\ncalibrated and to have good resolution for long enough sequences of\nobservations and for a suitable choice of its parameter, a kernel on the\nCartesian product of the forecast space $[0,1]$ and the data space. Our main\nresults are non-asymptotic: we establish explicit inequalities, shown to be\ntight, for the performance of the algorithm.",
    "published": "2005-06-01T14:03:20Z",
    "link": "http://arxiv.org/pdf/cs/0506004v4.pdf",
    "category": [
      "cs.LG",
      "I.2.6; I.5.1"
    ],
    "authors": [
      "Vladimir Vovk"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0506007v2",
    "title": "Defensive forecasting for linear protocols",
    "summary": "We consider a general class of forecasting protocols, called \"linear\nprotocols\", and discuss several important special cases, including multi-class\nforecasting. Forecasting is formalized as a game between three players:\nReality, whose role is to generate observations; Forecaster, whose goal is to\npredict the observations; and Skeptic, who tries to make money on any lack of\nagreement between Forecaster's predictions and the actual observations. Our\nmain mathematical result is that for any continuous strategy for Skeptic in a\nlinear protocol there exists a strategy for Forecaster that does not allow\nSkeptic's capital to grow. This result is a meta-theorem that allows one to\ntransform any continuous law of probability in a linear protocol into a\nforecasting strategy whose predictions are guaranteed to satisfy this law. We\napply this meta-theorem to a weak law of large numbers in Hilbert spaces to\nobtain a version of the K29 prediction algorithm for linear protocols and show\nthat this version also satisfies the attractive properties of proper\ncalibration and resolution under a suitable choice of its kernel parameter,\nwith no assumptions about the way the data is generated.",
    "published": "2005-06-02T13:26:43Z",
    "link": "http://arxiv.org/pdf/cs/0506007v2.pdf",
    "category": [
      "cs.LG",
      "I.2.6; I.5.1"
    ],
    "authors": [
      "Vladimir Vovk",
      "Ilia Nouretdinov",
      "Akimichi Takemura",
      "Glenn Shafer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0506022v1",
    "title": "Asymptotics of Discrete MDL for Online Prediction",
    "summary": "Minimum Description Length (MDL) is an important principle for induction and\nprediction, with strong relations to optimal Bayesian learning. This paper\ndeals with learning non-i.i.d. processes by means of two-part MDL, where the\nunderlying model class is countable. We consider the online learning framework,\ni.e. observations come in one by one, and the predictor is allowed to update\nhis state of mind after each time step. We identify two ways of predicting by\nMDL for this setup, namely a static} and a dynamic one. (A third variant,\nhybrid MDL, will turn out inferior.) We will prove that under the only\nassumption that the data is generated by a distribution contained in the model\nclass, the MDL predictions converge to the true values almost surely. This is\naccomplished by proving finite bounds on the quadratic, the Hellinger, and the\nKullback-Leibler loss of the MDL learner, which are however exponentially worse\nthan for Bayesian prediction. We demonstrate that these bounds are sharp, even\nfor model classes containing only Bernoulli distributions. We show how these\nbounds imply regret bounds for arbitrary loss functions. Our results apply to a\nwide range of setups, namely sequence prediction, pattern classification,\nregression, and universal induction in the sense of Algorithmic Information\nTheory among others.",
    "published": "2005-06-08T09:07:23Z",
    "link": "http://arxiv.org/pdf/cs/0506022v1.pdf",
    "category": [
      "cs.IT",
      "cs.LG",
      "math.IT",
      "math.ST",
      "stat.TH",
      "I.2.6; E.4; G.3"
    ],
    "authors": [
      "Jan Poland",
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0506041v3",
    "title": "Competitive on-line learning with a convex loss function",
    "summary": "We consider the problem of sequential decision making under uncertainty in\nwhich the loss caused by a decision depends on the following binary\nobservation. In competitive on-line learning, the goal is to design decision\nalgorithms that are almost as good as the best decision rules in a wide\nbenchmark class, without making any assumptions about the way the observations\nare generated. However, standard algorithms in this area can only deal with\nfinite-dimensional (often countable) benchmark classes. In this paper we give\nsimilar results for decision rules ranging over an arbitrary reproducing kernel\nHilbert space. For example, it is shown that for a wide class of loss functions\n(including the standard square, absolute, and log loss functions) the average\nloss of the master algorithm, over the first $N$ observations, does not exceed\nthe average loss of the best decision rule with a bounded norm plus\n$O(N^{-1/2})$. Our proof technique is very different from the standard ones and\nis based on recent results about defensive forecasting. Given the probabilities\nproduced by a defensive forecasting algorithm, which are known to be well\ncalibrated and to have good resolution in the long run, we use the expected\nloss minimization principle to find a suitable decision.",
    "published": "2005-06-11T18:11:22Z",
    "link": "http://arxiv.org/pdf/cs/0506041v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "I.2.6; I.5.1"
    ],
    "authors": [
      "Vladimir Vovk"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0506057v2",
    "title": "About one 3-parameter Model of Testing",
    "summary": "This article offers a 3-parameter model of testing, with 1) the difference\nbetween the ability level of the examinee and item difficulty; 2) the examinee\ndiscrimination and 3) the item discrimination as model parameters.",
    "published": "2005-06-14T04:00:38Z",
    "link": "http://arxiv.org/pdf/cs/0506057v2.pdf",
    "category": [
      "cs.LG",
      "I.2.6; K.3.2"
    ],
    "authors": [
      "Kromer Victor"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0506075v1",
    "title": "Seeing stars: Exploiting class relationships for sentiment\n  categorization with respect to rating scales",
    "summary": "We address the rating-inference problem, wherein rather than simply decide\nwhether a review is \"thumbs up\" or \"thumbs down\", as in previous sentiment\nanalysis work, one must determine an author's evaluation with respect to a\nmulti-point scale (e.g., one to five \"stars\"). This task represents an\ninteresting twist on standard multi-class text categorization because there are\nseveral different degrees of similarity between class labels; for example,\n\"three stars\" is intuitively closer to \"four stars\" than to \"one star\". We\nfirst evaluate human performance at the task. Then, we apply a meta-algorithm,\nbased on a metric labeling formulation of the problem, that alters a given\nn-ary classifier's output in an explicit attempt to ensure that similar items\nreceive similar labels. We show that the meta-algorithm can provide significant\nimprovements over both multi-class and regression versions of SVMs when we\nemploy a novel similarity measure appropriate to the problem.",
    "published": "2005-06-17T20:10:43Z",
    "link": "http://arxiv.org/pdf/cs/0506075v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG",
      "I.2.7; I.2.6"
    ],
    "authors": [
      "Bo Pang",
      "Lillian Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0506085v1",
    "title": "On the Job Training",
    "summary": "We propose a new framework for building and evaluating machine learning\nalgorithms. We argue that many real-world problems require an agent which must\nquickly learn to respond to demands, yet can continue to perform and respond to\nnew training throughout its useful life. We give a framework for how such\nagents can be built, describe several metrics for evaluating them, and show\nthat subtle changes in system construction can significantly affect agent\nperformance.",
    "published": "2005-06-22T21:21:13Z",
    "link": "http://arxiv.org/pdf/cs/0506085v1.pdf",
    "category": [
      "cs.LG",
      "K.3.2"
    ],
    "authors": [
      "Jason E. Holt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0506095v1",
    "title": "Deriving a Stationary Dynamic Bayesian Network from a Logic Program with\n  Recursive Loops",
    "summary": "Recursive loops in a logic program present a challenging problem to the PLP\nframework. On the one hand, they loop forever so that the PLP backward-chaining\ninferences would never stop. On the other hand, they generate cyclic\ninfluences, which are disallowed in Bayesian networks. Therefore, in existing\nPLP approaches logic programs with recursive loops are considered to be\nproblematic and thus are excluded. In this paper, we propose an approach that\nmakes use of recursive loops to build a stationary dynamic Bayesian network.\nOur work stems from an observation that recursive loops in a logic program\nimply a time sequence and thus can be used to model a stationary dynamic\nBayesian network without using explicit time parameters. We introduce a\nBayesian knowledge base with logic clauses of the form $A \\leftarrow\nA_1,...,A_l, true, Context, Types$, which naturally represents the knowledge\nthat the $A_i$s have direct influences on $A$ in the context $Context$ under\nthe type constraints $Types$. We then use the well-founded model of a logic\nprogram to define the direct influence relation and apply SLG-resolution to\ncompute the space of random variables together with their parental connections.\nWe introduce a novel notion of influence clauses, based on which a declarative\nsemantics for a Bayesian knowledge base is established and algorithms for\nbuilding a two-slice dynamic Bayesian network from a logic program are\ndeveloped.",
    "published": "2005-06-27T04:07:34Z",
    "link": "http://arxiv.org/pdf/cs/0506095v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "cs.LO"
    ],
    "authors": [
      "Y. D. Shen",
      "Q. Yang",
      "J. H. You",
      "L. Y. Yuan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0506101v1",
    "title": "Efficient Multiclass Implementations of L1-Regularized Maximum Entropy",
    "summary": "This paper discusses the application of L1-regularized maximum entropy\nmodeling or SL1-Max [9] to multiclass categorization problems. A new\nmodification to the SL1-Max fast sequential learning algorithm is proposed to\nhandle conditional distributions. Furthermore, unlike most previous studies,\nthe present research goes beyond a single type of conditional distribution. It\ndescribes and compares a variety of modeling assumptions about the class\ndistribution (independent or exclusive) and various types of joint or\nconditional distributions. It results in a new methodology for combining binary\nregularized classifiers to achieve multiclass categorization. In this context,\nMaximum Entropy can be considered as a generic and efficient regularized\nclassification tool that matches or outperforms the state-of-the art\nrepresented by AdaBoost and SVMs.",
    "published": "2005-06-29T20:26:33Z",
    "link": "http://arxiv.org/pdf/cs/0506101v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Patrick Haffner",
      "Steven Phillips",
      "Rob Schapire"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0507033v2",
    "title": "Multiresolution Kernels",
    "summary": "We present in this work a new methodology to design kernels on data which is\nstructured with smaller components, such as text, images or sequences. This\nmethodology is a template procedure which can be applied on most kernels on\nmeasures and takes advantage of a more detailed \"bag of components\"\nrepresentation of the objects. To obtain such a detailed description, we\nconsider possible decompositions of the original bag into a collection of\nnested bags, following a prior knowledge on the objects' structure. We then\nconsider these smaller bags to compare two objects both in a detailed\nperspective, stressing local matches between the smaller bags, and in a global\nor coarse perspective, by considering the entire bag. This multiresolution\napproach is likely to be best suited for tasks where the coarse approach is not\nprecise enough, and where a more subtle mixture of both local and global\nsimilarities is necessary to compare objects. The approach presented here would\nnot be computationally tractable without a factorization trick that we\nintroduce before presenting promising results on an image retrieval task.",
    "published": "2005-07-13T05:45:28Z",
    "link": "http://arxiv.org/pdf/cs/0507033v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Marco Cuturi",
      "Kenji Fukumizu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0507041v1",
    "title": "Monotone Conditional Complexity Bounds on Future Prediction Errors",
    "summary": "We bound the future loss when predicting any (computably) stochastic sequence\nonline. Solomonoff finitely bounded the total deviation of his universal\npredictor M from the true distribution m by the algorithmic complexity of m.\nHere we assume we are at a time t>1 and already observed x=x_1...x_t. We bound\nthe future prediction performance on x_{t+1}x_{t+2}... by a new variant of\nalgorithmic complexity of m given x, plus the complexity of the randomness\ndeficiency of x. The new complexity is monotone in its condition in the sense\nthat this complexity can only decrease if the condition is prolonged. We also\nbriefly discuss potential generalizations to Bayesian model classes and to\nclassification problems.",
    "published": "2005-07-18T12:34:53Z",
    "link": "http://arxiv.org/pdf/cs/0507041v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT",
      "I.2.6; E.4; G.3; F.1.3"
    ],
    "authors": [
      "Alexey Chernov",
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0507044v1",
    "title": "Defensive Universal Learning with Experts",
    "summary": "This paper shows how universal learning can be achieved with expert advice.\nTo this aim, we specify an experts algorithm with the following\ncharacteristics: (a) it uses only feedback from the actions actually chosen\n(bandit setup), (b) it can be applied with countably infinite expert classes,\nand (c) it copes with losses that may grow in time appropriately slowly. We\nprove loss bounds against an adaptive adversary. From this, we obtain a master\nalgorithm for \"reactive\" experts problems, which means that the master's\nactions may influence the behavior of the adversary. Our algorithm can\nsignificantly outperform standard experts algorithms on such problems. Finally,\nwe combine it with a universal expert class. The resulting universal learner\nperforms -- in a certain sense -- almost as well as any computable strategy,\nfor any online decision problem. We also specify the (worst-case) convergence\nspeed, which is very slow.",
    "published": "2005-07-18T14:33:56Z",
    "link": "http://arxiv.org/pdf/cs/0507044v1.pdf",
    "category": [
      "cs.LG",
      "I.2.6; G.3"
    ],
    "authors": [
      "Jan Poland",
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0507062v1",
    "title": "FPL Analysis for Adaptive Bandits",
    "summary": "A main problem of \"Follow the Perturbed Leader\" strategies for online\ndecision problems is that regret bounds are typically proven against oblivious\nadversary. In partial observation cases, it was not clear how to obtain\nperformance guarantees against adaptive adversary, without worsening the\nbounds. We propose a conceptually simple argument to resolve this problem.\nUsing this, a regret bound of O(t^(2/3)) for FPL in the adversarial multi-armed\nbandit problem is shown. This bound holds for the common FPL variant using only\nthe observations from designated exploration rounds. Using all observations\nallows for the stronger bound of O(t^(1/2)), matching the best bound known so\nfar (and essentially the known lower bound) for adversarial bandits.\nSurprisingly, this variant does not even need explicit exploration, it is\nself-stabilizing. However the sampling probabilities have to be either\nexternally provided or approximated to sufficient accuracy, using O(t^2 log t)\nsamples in each step.",
    "published": "2005-07-26T05:00:27Z",
    "link": "http://arxiv.org/pdf/cs/0507062v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Jan Poland"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0508027v1",
    "title": "Expectation maximization as message passing",
    "summary": "Based on prior work by Eckford, it is shown how expectation maximization (EM)\nmay be viewed, and used, as a message passing algorithm in factor graphs.",
    "published": "2005-08-03T16:09:00Z",
    "link": "http://arxiv.org/pdf/cs/0508027v1.pdf",
    "category": [
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "authors": [
      "J. Dauwels",
      "S. Korl",
      "H. -A. Loeliger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0508043v1",
    "title": "Sequential Predictions based on Algorithmic Complexity",
    "summary": "This paper studies sequence prediction based on the monotone Kolmogorov\ncomplexity Km=-log m, i.e. based on universal deterministic/one-part MDL. m is\nextremely close to Solomonoff's universal prior M, the latter being an\nexcellent predictor in deterministic as well as probabilistic environments,\nwhere performance is measured in terms of convergence of posteriors or losses.\nDespite this closeness to M, it is difficult to assess the prediction quality\nof m, since little is known about the closeness of their posteriors, which are\nthe important quantities for prediction. We show that for deterministic\ncomputable environments, the \"posterior\" and losses of m converge, but rapid\nconvergence could only be shown on-sequence; the off-sequence convergence can\nbe slow. In probabilistic environments, neither the posterior nor the losses\nconverge, in general.",
    "published": "2005-08-05T10:16:16Z",
    "link": "http://arxiv.org/pdf/cs/0508043v1.pdf",
    "category": [
      "cs.IT",
      "cs.LG",
      "math.IT",
      "G.3; G.1.2; I.2.6; E.4"
    ],
    "authors": [
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0508053v1",
    "title": "Measuring Semantic Similarity by Latent Relational Analysis",
    "summary": "This paper introduces Latent Relational Analysis (LRA), a method for\nmeasuring semantic similarity. LRA measures similarity in the semantic\nrelations between two pairs of words. When two pairs have a high degree of\nrelational similarity, they are analogous. For example, the pair cat:meow is\nanalogous to the pair dog:bark. There is evidence from cognitive science that\nrelational similarity is fundamental to many cognitive and linguistic tasks\n(e.g., analogical reasoning). In the Vector Space Model (VSM) approach to\nmeasuring relational similarity, the similarity between two pairs is calculated\nby the cosine of the angle between the vectors that represent the two pairs.\nThe elements in the vectors are based on the frequencies of manually\nconstructed patterns in a large corpus. LRA extends the VSM approach in three\nways: (1) patterns are derived automatically from the corpus, (2) Singular\nValue Decomposition is used to smooth the frequency data, and (3) synonyms are\nused to reformulate word pairs. This paper describes the LRA algorithm and\nexperimentally compares LRA to VSM on two tasks, answering college-level\nmultiple-choice word analogy questions and classifying semantic relations in\nnoun-modifier expressions. LRA achieves state-of-the-art results, reaching\nhuman-level performance on the analogy questions and significantly exceeding\nVSM performance on both tasks.",
    "published": "2005-08-10T19:35:57Z",
    "link": "http://arxiv.org/pdf/cs/0508053v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL",
      "cs.IR",
      "H.3.1; I.2.6; I.2.7"
    ],
    "authors": [
      "Peter D. Turney"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0508073v1",
    "title": "Universal Learning of Repeated Matrix Games",
    "summary": "We study and compare the learning dynamics of two universal learning\nalgorithms, one based on Bayesian learning and the other on prediction with\nexpert advice. Both approaches have strong asymptotic performance guarantees.\nWhen confronted with the task of finding good long-term strategies in repeated\n2x2 matrix games, they behave quite differently.",
    "published": "2005-08-16T16:27:25Z",
    "link": "http://arxiv.org/pdf/cs/0508073v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Jan Poland",
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/math/0508319v1",
    "title": "Combinations and Mixtures of Optimal Policies in Unichain Markov\n  Decision Processes are Optimal",
    "summary": "We show that combinations of optimal (stationary) policies in unichain Markov\ndecision processes are optimal. That is, let M be a unichain Markov decision\nprocess with state space S, action space A and policies \\pi_j^*: S -> A (1\\leq\nj\\leq n) with optimal average infinite horizon reward. Then any combination \\pi\nof these policies, where for each state i in S there is a j such that\n\\pi(i)=\\pi_j^*(i), is optimal as well. Furthermore, we prove that any mixture\nof optimal policies, where at each visit in a state i an arbitrary action\n\\pi_j^*(i) of an optimal policy is chosen, yields optimal average reward, too.",
    "published": "2005-08-17T10:13:04Z",
    "link": "http://arxiv.org/pdf/math/0508319v1.pdf",
    "category": [
      "math.CO",
      "cs.DM",
      "cs.LG",
      "math.OC",
      "math.PR",
      "90C40"
    ],
    "authors": [
      "Ronald Ortner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0508103v1",
    "title": "Corpus-based Learning of Analogies and Semantic Relations",
    "summary": "We present an algorithm for learning from unlabeled text, based on the Vector\nSpace Model (VSM) of information retrieval, that can solve verbal analogy\nquestions of the kind found in the SAT college entrance exam. A verbal analogy\nhas the form A:B::C:D, meaning \"A is to B as C is to D\"; for example,\nmason:stone::carpenter:wood. SAT analogy questions provide a word pair, A:B,\nand the problem is to select the most analogous word pair, C:D, from a set of\nfive choices. The VSM algorithm correctly answers 47% of a collection of 374\ncollege-level analogy questions (random guessing would yield 20% correct; the\naverage college-bound senior high school student answers about 57% correctly).\nWe motivate this research by applying it to a difficult problem in natural\nlanguage processing, determining semantic relations in noun-modifier pairs. The\nproblem is to classify a noun-modifier pair, such as \"laser printer\", according\nto the semantic relation between the noun (printer) and the modifier (laser).\nWe use a supervised nearest-neighbour algorithm that assigns a class to a given\nnoun-modifier pair by finding the most analogous noun-modifier pair in the\ntraining data. With 30 classes of semantic relations, on a collection of 600\nlabeled noun-modifier pairs, the learning algorithm attains an F value of 26.5%\n(random guessing: 3.3%). With 5 classes of semantic relations, the F value is\n43.2% (random: 20%). The performance is state-of-the-art for both verbal\nanalogies and noun-modifier relations.",
    "published": "2005-08-23T20:21:56Z",
    "link": "http://arxiv.org/pdf/cs/0508103v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL",
      "cs.IR",
      "H.3.1; I.2.6; I.2.7"
    ],
    "authors": [
      "Peter D. Turney",
      "Michael L. Littman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0509055v1",
    "title": "Learning Optimal Augmented Bayes Networks",
    "summary": "Naive Bayes is a simple Bayesian classifier with strong independence\nassumptions among the attributes. This classifier, desipte its strong\nindependence assumptions, often performs well in practice. It is believed that\nrelaxing the independence assumptions of a naive Bayes classifier may improve\nthe classification accuracy of the resulting structure. While finding an\noptimal unconstrained Bayesian Network (for most any reasonable scoring\nmeasure) is an NP-hard problem, it is possible to learn in polynomial time\noptimal networks obeying various structural restrictions. Several authors have\nexamined the possibilities of adding augmenting arcs between attributes of a\nNaive Bayes classifier. Friedman, Geiger and Goldszmidt define the TAN\nstructure in which the augmenting arcs form a tree on the attributes, and\npresent a polynomial time algorithm that learns an optimal TAN with respect to\nMDL score. Keogh and Pazzani define Augmented Bayes Networks in which the\naugmenting arcs form a forest on the attributes (a collection of trees, hence a\nrelaxation of the stuctural restriction of TAN), and present heuristic search\nmethods for learning good, though not optimal, augmenting arc sets. The\nauthors, however, evaluate the learned structure only in terms of observed\nmisclassification error and not against a scoring metric, such as MDL. In this\npaper, we present a simple, polynomial time greedy algorithm for learning an\noptimal Augmented Bayes Network with respect to MDL score.",
    "published": "2005-09-19T04:57:26Z",
    "link": "http://arxiv.org/pdf/cs/0509055v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Vikas Hamine",
      "Paul Helman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0510038v4",
    "title": "Learning Unions of $(1)$-Dimensional Rectangles",
    "summary": "We consider the problem of learning unions of rectangles over the domain\n$[b]^n$, in the uniform distribution membership query learning setting, where\nboth b and n are \"large\". We obtain poly$(n, \\log b)$-time algorithms for the\nfollowing classes:\n  - poly$(n \\log b)$-way Majority of $O(\\frac{\\log(n \\log b)} {\\log \\log(n \\log\nb)})$-dimensional rectangles.\n  - Union of poly$(\\log(n \\log b))$ many $O(\\frac{\\log^2 (n \\log b)} {(\\log\n\\log(n \\log b) \\log \\log \\log (n \\log b))^2})$-dimensional rectangles.\n  - poly$(n \\log b)$-way Majority of poly$(n \\log b)$-Or of disjoint\n$O(\\frac{\\log(n \\log b)} {\\log \\log(n \\log b)})$-dimensional rectangles.\n  Our main algorithmic tool is an extension of Jackson's boosting- and\nFourier-based Harmonic Sieve algorithm [Jackson 1997] to the domain $[b]^n$,\nbuilding on work of [Akavia, Goldwasser, Safra 2003]. Other ingredients used to\nobtain the results stated above are techniques from exact learning [Beimel,\nKushilevitz 1998] and ideas from recent work on learning augmented $AC^{0}$\ncircuits [Jackson, Klivans, Servedio 2002] and on representing Boolean\nfunctions as thresholds of parities [Klivans, Servedio 2001].",
    "published": "2005-10-14T19:26:34Z",
    "link": "http://arxiv.org/pdf/cs/0510038v4.pdf",
    "category": [
      "cs.LG",
      "F.2.2; I.2.6"
    ],
    "authors": [
      "Alp Atici",
      "Rocco A. Servedio"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0510080v1",
    "title": "When Ignorance is Bliss",
    "summary": "It is commonly-accepted wisdom that more information is better, and that\ninformation should never be ignored. Here we argue, using both a Bayesian and a\nnon-Bayesian analysis, that in some situations you are better off ignoring\ninformation if your uncertainty is represented by a set of probability\nmeasures. These include situations in which the information is relevant for the\nprediction task at hand. In the non-Bayesian analysis, we show how ignoring\ninformation avoids dilation, the phenomenon that additional pieces of\ninformation sometimes lead to an increase in uncertainty. In the Bayesian\nanalysis, we show that for small sample sizes and certain prediction tasks, the\nBayesian posterior based on a noninformative prior yields worse predictions\nthan simply ignoring the given information.",
    "published": "2005-10-25T22:14:33Z",
    "link": "http://arxiv.org/pdf/cs/0510080v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "I.2.4"
    ],
    "authors": [
      "Peter D. Grunwald",
      "Joseph Y. Halpern"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0511011v1",
    "title": "The Impact of Social Networks on Multi-Agent Recommender Systems",
    "summary": "Awerbuch et al.'s approach to distributed recommender systems (DRSs) is to\nhave agents sample products at random while randomly querying one another for\nthe best item they have found; we improve upon this by adding a communication\nnetwork. Agents can only communicate with their immediate neighbors in the\nnetwork, but neighboring agents may or may not represent users with common\ninterests. We define two network structures: in the ``mailing-list model,''\nagents representing similar users form cliques, while in the ``word-of-mouth\nmodel'' the agents are distributed randomly in a scale-free network (SFN). In\nboth models, agents tell their neighbors about satisfactory products as they\nare found. In the word-of-mouth model, knowledge of items propagates only\nthrough interested agents, and the SFN parameters affect the system's\nperformance. We include a summary of our new results on the character and\nparameters of random subgraphs of SFNs, in particular SFNs with power-law\ndegree distributions down to minimum degree 1. These networks are not as\nresilient as Cohen et al. originally suggested. In the case of the widely-cited\n``Internet resilience'' result, high failure rates actually lead to the\norphaning of half of the surviving nodes after 60% of the network has failed\nand the complete disintegration of the network at 90%. We show that given an\nappropriate network, the communication network reduces the number of sampled\nitems, the number of messages sent, and the amount of ``spam.'' We conclude\nthat in many cases DRSs will be useful for sharing information in a multi-agent\nlearning system.",
    "published": "2005-11-02T23:44:34Z",
    "link": "http://arxiv.org/pdf/cs/0511011v1.pdf",
    "category": [
      "cs.LG",
      "cs.CC",
      "cs.MA",
      "I.2.6; I.2.11"
    ],
    "authors": [
      "Hamilton Link",
      "Jared Saia",
      "Terran Lane",
      "Randall A. LaViolette"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cond-mat/0511159v2",
    "title": "Learning by message-passing in networks of discrete synapses",
    "summary": "We show that a message-passing process allows to store in binary \"material\"\nsynapses a number of random patterns which almost saturates the information\ntheoretic bounds. We apply the learning algorithm to networks characterized by\na wide range of different connection topologies and of size comparable with\nthat of biological systems (e.g. $n\\simeq10^{5}-10^{6}$). The algorithm can be\nturned into an on-line --fault tolerant-- learning protocol of potential\ninterest in modeling aspects of synaptic plasticity and in building\nneuromorphic devices.",
    "published": "2005-11-07T13:48:01Z",
    "link": "http://arxiv.org/pdf/cond-mat/0511159v2.pdf",
    "category": [
      "cond-mat.dis-nn",
      "cs.LG",
      "q-bio.NC"
    ],
    "authors": [
      "Alfredo Braunstein",
      "Riccardo Zecchina"
    ]
  },
  {
    "id": "http://arxiv.org/abs/nlin/0511015v1",
    "title": "Combinatorial Approach to Object Analysis",
    "summary": "We present a perceptional mathematical model for image and signal analysis. A\nresemblance measure is defined, and submitted to an innovating combinatorial\noptimization algorithm. Numerical Simulations are also presented",
    "published": "2005-11-09T14:41:00Z",
    "link": "http://arxiv.org/pdf/nlin/0511015v1.pdf",
    "category": [
      "nlin.AO",
      "cs.LG"
    ],
    "authors": [
      "Rami Kanhouche"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0511058v2",
    "title": "On-line regression competitive with reproducing kernel Hilbert spaces",
    "summary": "We consider the problem of on-line prediction of real-valued labels, assumed\nbounded in absolute value by a known constant, of new objects from known\nlabeled objects. The prediction algorithm's performance is measured by the\nsquared deviation of the predictions from the actual labels. No stochastic\nassumptions are made about the way the labels and objects are generated.\nInstead, we are given a benchmark class of prediction rules some of which are\nhoped to produce good predictions. We show that for a wide range of\ninfinite-dimensional benchmark classes one can construct a prediction algorithm\nwhose cumulative loss over the first N examples does not exceed the cumulative\nloss of any prediction rule in the class plus O(sqrt(N)); the main differences\nfrom the known results are that we do not impose any upper bound on the norm of\nthe considered prediction rules and that we achieve an optimal leading term in\nthe excess loss of our algorithm. If the benchmark class is \"universal\" (dense\nin the class of continuous functions on each compact set), this provides an\non-line non-stochastic analogue of universally consistent prediction in\nnon-parametric statistics. We use two proof techniques: one is based on the\nAggregating Algorithm and the other on the recently developed method of\ndefensive forecasting.",
    "published": "2005-11-15T17:13:50Z",
    "link": "http://arxiv.org/pdf/cs/0511058v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Vladimir Vovk"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0511075v1",
    "title": "Identifying Interaction Sites in \"Recalcitrant\" Proteins: Predicted\n  Protein and Rna Binding Sites in Rev Proteins of Hiv-1 and Eiav Agree with\n  Experimental Data",
    "summary": "Protein-protein and protein nucleic acid interactions are vitally important\nfor a wide range of biological processes, including regulation of gene\nexpression, protein synthesis, and replication and assembly of many viruses. We\nhave developed machine learning approaches for predicting which amino acids of\na protein participate in its interactions with other proteins and/or nucleic\nacids, using only the protein sequence as input. In this paper, we describe an\napplication of classifiers trained on datasets of well-characterized\nprotein-protein and protein-RNA complexes for which experimental structures are\navailable. We apply these classifiers to the problem of predicting protein and\nRNA binding sites in the sequence of a clinically important protein for which\nthe structure is not known: the regulatory protein Rev, essential for the\nreplication of HIV-1 and other lentiviruses. We compare our predictions with\npublished biochemical, genetic and partial structural information for HIV-1 and\nEIAV Rev and with our own published experimental mapping of RNA binding sites\nin EIAV Rev. The predicted and experimentally determined binding sites are in\nvery good agreement. The ability to predict reliably the residues of a protein\nthat directly contribute to specific binding events - without the requirement\nfor structural information regarding either the protein or complexes in which\nit participates - can potentially generate new disease intervention strategies.",
    "published": "2005-11-21T01:47:53Z",
    "link": "http://arxiv.org/pdf/cs/0511075v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "J.3"
    ],
    "authors": [
      "Michael Terribilini",
      "Jae-Hyung Lee",
      "Changhui Yan",
      "Robert L. Jernigan",
      "Susan Carpenter",
      "Vasant Honavar",
      "Drena Dobbs"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0511087v1",
    "title": "Robust Inference of Trees",
    "summary": "This paper is concerned with the reliable inference of optimal\ntree-approximations to the dependency structure of an unknown distribution\ngenerating data. The traditional approach to the problem measures the\ndependency strength between random variables by the index called mutual\ninformation. In this paper reliability is achieved by Walley's imprecise\nDirichlet model, which generalizes Bayesian learning with Dirichlet priors.\nAdopting the imprecise Dirichlet model results in posterior interval\nexpectation for mutual information, and in a set of plausible trees consistent\nwith the data. Reliable inference about the actual tree is achieved by focusing\non the substructure common to all the plausible trees. We develop an exact\nalgorithm that infers the substructure in time O(m^4), m being the number of\nrandom variables. The new algorithm is applied to a set of data sampled from a\nknown distribution. The method is shown to reliably infer edges of the actual\ntree even when the data are very scarce, unlike the traditional approach.\nFinally, we provide lower and upper credibility limits for mutual information\nunder the imprecise Dirichlet model. These enable the previous developments to\nbe extended to a full inferential method for trees.",
    "published": "2005-11-25T10:59:35Z",
    "link": "http://arxiv.org/pdf/cs/0511087v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "authors": [
      "Marco Zaffalon",
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0511088v1",
    "title": "Bounds on Query Convergence",
    "summary": "The problem of finding an optimum using noisy evaluations of a smooth cost\nfunction arises in many contexts, including economics, business, medicine,\nexperiment design, and foraging theory. We derive an asymptotic bound E[ (x_t -\nx*)^2 ] >= O(1/sqrt(t)) on the rate of convergence of a sequence (x_0, x_1,\n>...) generated by an unbiased feedback process observing noisy evaluations of\nan unknown quadratic function maximised at x*. The bound is tight, as the proof\nleads to a simple algorithm which meets it. We further establish a bound on the\ntotal regret, E[ sum_{i=1..t} (x_i - x*)^2 ] >= O(sqrt(t)) These bounds may\nimpose practical limitations on an agent's performance, as O(eps^-4) queries\nare made before the queries converge to x* with eps accuracy.",
    "published": "2005-11-25T15:57:56Z",
    "link": "http://arxiv.org/pdf/cs/0511088v1.pdf",
    "category": [
      "cs.LG",
      "G.1.6"
    ],
    "authors": [
      "Barak A. Pearlmutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0511105v1",
    "title": "The Signed Distance Function: A New Tool for Binary Classification",
    "summary": "From a geometric perspective most nonlinear binary classification algorithms,\nincluding state of the art versions of Support Vector Machine (SVM) and Radial\nBasis Function Network (RBFN) classifiers, and are based on the idea of\nreconstructing indicator functions. We propose instead to use reconstruction of\nthe signed distance function (SDF) as a basis for binary classification. We\ndiscuss properties of the signed distance function that can be exploited in\nclassification algorithms. We develop simple versions of such classifiers and\ntest them on several linear and nonlinear problems. On linear tests accuracy of\nthe new algorithm exceeds that of standard SVM methods, with an average of 50%\nfewer misclassifications. Performance of the new methods also matches or\nexceeds that of standard methods on several nonlinear problems including\nclassification of benchmark diagnostic micro-array data sets.",
    "published": "2005-11-30T14:15:17Z",
    "link": "http://arxiv.org/pdf/cs/0511105v1.pdf",
    "category": [
      "cs.LG",
      "cs.CG"
    ],
    "authors": [
      "Erik M. Boczko",
      "Todd R. Young"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0511108v1",
    "title": "Parameter Estimation of Hidden Diffusion Processes: Particle Filter vs.\n  Modified Baum-Welch Algorithm",
    "summary": "We propose a new method for the estimation of parameters of hidden diffusion\nprocesses. Based on parametrization of the transition matrix, the Baum-Welch\nalgorithm is improved. The algorithm is compared to the particle filter in\napplication to the noisy periodic systems. It is shown that the modified\nBaum-Welch algorithm is capable of estimating the system parameters with better\naccuracy than particle filters.",
    "published": "2005-11-30T20:23:19Z",
    "link": "http://arxiv.org/pdf/cs/0511108v1.pdf",
    "category": [
      "cs.DS",
      "cs.LG",
      "F.2.1; J.2"
    ],
    "authors": [
      "A. Benabdallah",
      "G. Radons"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0512015v3",
    "title": "Joint fixed-rate universal lossy coding and identification of\n  continuous-alphabet memoryless sources",
    "summary": "The problem of joint universal source coding and identification is considered\nin the setting of fixed-rate lossy coding of continuous-alphabet memoryless\nsources. For a wide class of bounded distortion measures, it is shown that any\ncompactly parametrized family of $\\R^d$-valued i.i.d. sources with absolutely\ncontinuous distributions satisfying appropriate smoothness and\nVapnik--Chervonenkis learnability conditions, admits a joint scheme for\nuniversal lossy block coding and parameter estimation, such that when the block\nlength $n$ tends to infinity, the overhead per-letter rate and the distortion\nredundancies converge to zero as $O(n^{-1}\\log n)$ and $O(\\sqrt{n^{-1}\\log\nn})$, respectively. Moreover, the active source can be determined at the\ndecoder up to a ball of radius $O(\\sqrt{n^{-1} \\log n})$ in variational\ndistance, asymptotically almost surely. The system has finite memory length\nequal to the block length, and can be thought of as blockwise application of a\ntime-invariant nonlinear filter with initial conditions determined from the\nprevious block. Comparisons are presented with several existing schemes for\nuniversal vector quantization, which do not include parameter estimation\nexplicitly, and an extension to unbounded distortion measures is outlined.\nFinally, finite mixture classes and exponential families are given as explicit\nexamples of parametric sources admitting joint universal compression and\nmodeling schemes of the kind studied here.",
    "published": "2005-12-03T19:21:33Z",
    "link": "http://arxiv.org/pdf/cs/0512015v3.pdf",
    "category": [
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "authors": [
      "Maxim Raginsky"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0512018v2",
    "title": "DAMNED: A Distributed and Multithreaded Neural Event-Driven simulation\n  framework",
    "summary": "In a Spiking Neural Networks (SNN), spike emissions are sparsely and\nirregularly distributed both in time and in the network architecture. Since a\ncurrent feature of SNNs is a low average activity, efficient implementations of\nSNNs are usually based on an Event-Driven Simulation (EDS). On the other hand,\nsimulations of large scale neural networks can take advantage of distributing\nthe neurons on a set of processors (either workstation cluster or parallel\ncomputer). This article presents DAMNED, a large scale SNN simulation framework\nable to gather the benefits of EDS and parallel computing. Two levels of\nparallelism are combined: Distributed mapping of the neural topology, at the\nnetwork level, and local multithreaded allocation of resources for simultaneous\nprocessing of events, at the neuron level. Based on the causality of events, a\ndistributed solution is proposed for solving the complex problem of scheduling\nwithout synchronization barrier.",
    "published": "2005-12-05T06:57:39Z",
    "link": "http://arxiv.org/pdf/cs/0512018v2.pdf",
    "category": [
      "cs.NE",
      "cs.LG"
    ],
    "authors": [
      "Anthony Mouraud",
      "Didier Puzenat",
      "Hlne Paugam-Moisy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0512050v1",
    "title": "Preference Learning in Terminology Extraction: A ROC-based approach",
    "summary": "A key data preparation step in Text Mining, Term Extraction selects the\nterms, or collocation of words, attached to specific concepts. In this paper,\nthe task of extracting relevant collocations is achieved through a supervised\nlearning algorithm, exploiting a few collocations manually labelled as\nrelevant/irrelevant. The candidate terms are described along 13 standard\nstatistical criteria measures. From these examples, an evolutionary learning\nalgorithm termed Roger, based on the optimization of the Area under the ROC\ncurve criterion, extracts an order on the candidate terms. The robustness of\nthe approach is demonstrated on two real-world domain applications, considering\ndifferent domains (biology and human resources) and different languages\n(English and French).",
    "published": "2005-12-13T13:25:57Z",
    "link": "http://arxiv.org/pdf/cs/0512050v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Jrme Az",
      "Mathieu Roche",
      "Yves Kodratoff",
      "Michle Sebag"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0512053v1",
    "title": "Online Learning and Resource-Bounded Dimension: Winnow Yields New Lower\n  Bounds for Hard Sets",
    "summary": "We establish a relationship between the online mistake-bound model of\nlearning and resource-bounded dimension. This connection is combined with the\nWinnow algorithm to obtain new results about the density of hard sets under\nadaptive reductions. This improves previous work of Fu (1995) and Lutz and Zhao\n(2000), and solves one of Lutz and Mayordomo's \"Twelve Problems in\nResource-Bounded Measure\" (1999).",
    "published": "2005-12-13T22:01:09Z",
    "link": "http://arxiv.org/pdf/cs/0512053v1.pdf",
    "category": [
      "cs.CC",
      "cs.LG"
    ],
    "authors": [
      "John M. Hitchcock"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0512059v2",
    "title": "Competing with wild prediction rules",
    "summary": "We consider the problem of on-line prediction competitive with a benchmark\nclass of continuous but highly irregular prediction rules. It is known that if\nthe benchmark class is a reproducing kernel Hilbert space, there exists a\nprediction algorithm whose average loss over the first N examples does not\nexceed the average loss of any prediction rule in the class plus a \"regret\nterm\" of O(N^(-1/2)). The elements of some natural benchmark classes, however,\nare so irregular that these classes are not Hilbert spaces. In this paper we\ndevelop Banach-space methods to construct a prediction algorithm with a regret\nterm of O(N^(-1/p)), where p is in [2,infty) and p-2 reflects the degree to\nwhich the benchmark class fails to be a Hilbert space.",
    "published": "2005-12-14T20:03:30Z",
    "link": "http://arxiv.org/pdf/cs/0512059v2.pdf",
    "category": [
      "cs.LG",
      "I.2.6"
    ],
    "authors": [
      "Vladimir Vovk"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0512063v1",
    "title": "Complex Random Vectors and ICA Models: Identifiability, Uniqueness and\n  Separability",
    "summary": "In this paper the conditions for identifiability, separability and uniqueness\nof linear complex valued independent component analysis (ICA) models are\nestablished. These results extend the well-known conditions for solving\nreal-valued ICA problems to complex-valued models. Relevant properties of\ncomplex random vectors are described in order to extend the Darmois-Skitovich\ntheorem for complex-valued models. This theorem is used to construct a proof of\na theorem for each of the above ICA model concepts. Both circular and\nnoncircular complex random vectors are covered. Examples clarifying the above\nconcepts are presented.",
    "published": "2005-12-15T14:51:36Z",
    "link": "http://arxiv.org/pdf/cs/0512063v1.pdf",
    "category": [
      "cs.IT",
      "cs.CE",
      "cs.IR",
      "cs.LG",
      "math.IT"
    ],
    "authors": [
      "Jan Eriksson",
      "Visa Koivunen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0601044v1",
    "title": "Genetic Programming, Validation Sets, and Parsimony Pressure",
    "summary": "Fitness functions based on test cases are very common in Genetic Programming\n(GP). This process can be assimilated to a learning task, with the inference of\nmodels from a limited number of samples. This paper is an investigation on two\nmethods to improve generalization in GP-based learning: 1) the selection of the\nbest-of-run individuals using a three data sets methodology, and 2) the\napplication of parsimony pressure in order to reduce the complexity of the\nsolutions. Results using GP in a binary classification setup show that while\nthe accuracy on the test sets is preserved, with less variances compared to\nbaseline results, the mean tree size obtained with the tested methods is\nsignificantly reduced.",
    "published": "2006-01-11T15:39:16Z",
    "link": "http://arxiv.org/pdf/cs/0601044v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Christian Gagn",
      "Marc Schoenauer",
      "Marc Parizeau",
      "Marco Tomassini"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0601074v2",
    "title": "Joint universal lossy coding and identification of i.i.d. vector sources",
    "summary": "The problem of joint universal source coding and modeling, addressed by\nRissanen in the context of lossless codes, is generalized to fixed-rate lossy\ncoding of continuous-alphabet memoryless sources. We show that, for bounded\ndistortion measures, any compactly parametrized family of i.i.d. real vector\nsources with absolutely continuous marginals (satisfying appropriate smoothness\nand Vapnik--Chervonenkis learnability conditions) admits a joint scheme for\nuniversal lossy block coding and parameter estimation, and give nonasymptotic\nestimates of convergence rates for distortion redundancies and variational\ndistances between the active source and the estimated source. We also present\nexplicit examples of parametric sources admitting such joint universal\ncompression and modeling schemes.",
    "published": "2006-01-17T00:08:05Z",
    "link": "http://arxiv.org/pdf/cs/0601074v2.pdf",
    "category": [
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "authors": [
      "Maxim Raginsky"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0601087v1",
    "title": "Processing of Test Matrices with Guessing Correction",
    "summary": "It is suggested to insert into test matrix 1s for correct responses, 0s for\nresponse refusals, and negative corrective elements for incorrect responses.\nWith the classical test theory approach test scores of examinees and items are\ncalculated traditionally as sums of matrix elements, organized in rows and\ncolumns. Correlation coefficients are estimated using correction coefficients.\nIn item response theory approach examinee and item logits are estimated using\nmaximum likelihood method and probabilities of all matrix elements.",
    "published": "2006-01-20T05:40:44Z",
    "link": "http://arxiv.org/pdf/cs/0601087v1.pdf",
    "category": [
      "cs.LG",
      "I.2.6; K.3.2"
    ],
    "authors": [
      "Kromer Victor"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0601089v1",
    "title": "Distributed Kernel Regression: An Algorithm for Training Collaboratively",
    "summary": "This paper addresses the problem of distributed learning under communication\nconstraints, motivated by distributed signal processing in wireless sensor\nnetworks and data mining with distributed databases. After formalizing a\ngeneral model for distributed learning, an algorithm for collaboratively\ntraining regularized kernel least-squares regression estimators is derived.\nNoting that the algorithm can be viewed as an application of successive\northogonal projection algorithms, its convergence properties are investigated\nand the statistical behavior of the estimator is discussed in a simplified\ntheoretical setting.",
    "published": "2006-01-20T17:46:45Z",
    "link": "http://arxiv.org/pdf/cs/0601089v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.IT",
      "math.IT"
    ],
    "authors": [
      "Joel B. Predd",
      "Sanjeev R. Kulkarni",
      "H. Vincent Poor"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0601115v2",
    "title": "Decision Making with Side Information and Unbounded Loss Functions",
    "summary": "We consider the problem of decision-making with side information and\nunbounded loss functions. Inspired by probably approximately correct learning\nmodel, we use a slightly different model that incorporates the notion of side\ninformation in a more generic form to make it applicable to a broader class of\napplications including parameter estimation and system identification. We\naddress sufficient conditions for consistent decision-making with exponential\nconvergence behavior. In this regard, besides a certain condition on the growth\nfunction of the class of loss functions, it suffices that the class of loss\nfunctions be dominated by a measurable function whose exponential Orlicz\nexpectation is uniformly bounded over the probabilistic model. Decay exponent,\ndecay constant, and sample complexity are discussed. Example applications to\nmethod of moments, maximum likelihood estimation, and system identification are\nillustrated, as well.",
    "published": "2006-01-27T16:52:09Z",
    "link": "http://arxiv.org/pdf/cs/0601115v2.pdf",
    "category": [
      "cs.LG",
      "cs.IT",
      "math.IT"
    ],
    "authors": [
      "Majid Fozunbal",
      "Ton Kalker"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cond-mat/0602183v1",
    "title": "Nonlinear parametric model for Granger causality of time series",
    "summary": "We generalize a previously proposed approach for nonlinear Granger causality\nof time series, based on radial basis function. The proposed model is not\nconstrained to be additive in variables from the two time series and can\napproximate any function of these variables, still being suitable to evaluate\ncausality. Usefulness of this measure of causality is shown in a physiological\nexample and in the study of the feed-back loop in a model of excitatory and\ninhibitory neurons.",
    "published": "2006-02-07T18:29:35Z",
    "link": "http://arxiv.org/pdf/cond-mat/0602183v1.pdf",
    "category": [
      "cond-mat.dis-nn",
      "cond-mat.stat-mech",
      "cs.LG",
      "physics.med-ph",
      "q-bio.QM"
    ],
    "authors": [
      "Daniele Marinazzo",
      "Mario Pellicoro",
      "Sebastiano Stramaglia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0602053v1",
    "title": "How to Beat the Adaptive Multi-Armed Bandit",
    "summary": "The multi-armed bandit is a concise model for the problem of iterated\ndecision-making under uncertainty. In each round, a gambler must pull one of\n$K$ arms of a slot machine, without any foreknowledge of their payouts, except\nthat they are uniformly bounded. A standard objective is to minimize the\ngambler's regret, defined as the gambler's total payout minus the largest\npayout which would have been achieved by any fixed arm, in hindsight. Note that\nthe gambler is only told the payout for the arm actually chosen, not for the\nunchosen arms.\n  Almost all previous work on this problem assumed the payouts to be\nnon-adaptive, in the sense that the distribution of the payout of arm $j$ in\nround $i$ is completely independent of the choices made by the gambler on\nrounds $1, \\dots, i-1$. In the more general model of adaptive payouts, the\npayouts in round $i$ may depend arbitrarily on the history of past choices made\nby the algorithm.\n  We present a new algorithm for this problem, and prove nearly optimal\nguarantees for the regret against both non-adaptive and adaptive adversaries.\nAfter $T$ rounds, our algorithm has regret $O(\\sqrt{T})$ with high probability\n(the tail probability decays exponentially). This dependence on $T$ is best\npossible, and matches that of the full-information version of the problem, in\nwhich the gambler is told the payouts for all $K$ arms after each round.\n  Previously, even for non-adaptive payouts, the best high-probability bounds\nknown were $O(T^{2/3})$, due to Auer, Cesa-Bianchi, Freund and Schapire. The\nexpected regret of their algorithm is $O(T^{1/2}) for non-adaptive payouts, but\nas we show, $\\Omega(T^{2/3})$ for adaptive payouts.",
    "published": "2006-02-14T23:57:01Z",
    "link": "http://arxiv.org/pdf/cs/0602053v1.pdf",
    "category": [
      "cs.DS",
      "cs.LG"
    ],
    "authors": [
      "Varsha Dani",
      "Thomas P. Hayes"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0602062v1",
    "title": "Learning rational stochastic languages",
    "summary": "Given a finite set of words w1,...,wn independently drawn according to a\nfixed unknown distribution law P called a stochastic language, an usual goal in\nGrammatical Inference is to infer an estimate of P in some class of\nprobabilistic models, such as Probabilistic Automata (PA). Here, we study the\nclass of rational stochastic languages, which consists in stochastic languages\nthat can be generated by Multiplicity Automata (MA) and which strictly includes\nthe class of stochastic languages generated by PA. Rational stochastic\nlanguages have minimal normal representation which may be very concise, and\nwhose parameters can be efficiently estimated from stochastic samples. We\ndesign an efficient inference algorithm DEES which aims at building a minimal\nnormal representation of the target. Despite the fact that no recursively\nenumerable class of MA computes exactly the set of rational stochastic\nlanguages over Q, we show that DEES strongly identifies tis set in the limit.\nWe study the intermediary MA output by DEES and show that they compute rational\nseries which converge absolutely to one and which can be used to provide\nstochastic languages which closely estimate the target.",
    "published": "2006-02-17T08:57:44Z",
    "link": "http://arxiv.org/pdf/cs/0602062v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Franois Denis",
      "Yann Esposito",
      "Amaury Habrard"
    ]
  },
  {
    "id": "http://arxiv.org/abs/math/0602505v1",
    "title": "MDL Convergence Speed for Bernoulli Sequences",
    "summary": "The Minimum Description Length principle for online sequence\nestimation/prediction in a proper learning setup is studied. If the underlying\nmodel class is discrete, then the total expected square loss is a particularly\ninteresting performance measure: (a) this quantity is finitely bounded,\nimplying convergence with probability one, and (b) it additionally specifies\nthe convergence speed. For MDL, in general one can only have loss bounds which\nare finite but exponentially larger than those for Bayes mixtures. We show that\nthis is even the case if the model class contains only Bernoulli distributions.\nWe derive a new upper bound on the prediction error for countable Bernoulli\nclasses. This implies a small bound (comparable to the one for Bayes mixtures)\nfor certain important model classes. We discuss the application to Machine\nLearning tasks such as classification and hypothesis testing, and\ngeneralization to countable classes of i.i.d. models.",
    "published": "2006-02-22T16:29:05Z",
    "link": "http://arxiv.org/pdf/math/0602505v1.pdf",
    "category": [
      "math.ST",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "math.PR",
      "stat.TH"
    ],
    "authors": [
      "Jan Poland",
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0602092v1",
    "title": "Inconsistent parameter estimation in Markov random fields: Benefits in\n  the computation-limited setting",
    "summary": "Consider the problem of joint parameter estimation and prediction in a Markov\nrandom field: i.e., the model parameters are estimated on the basis of an\ninitial set of data, and then the fitted model is used to perform prediction\n(e.g., smoothing, denoising, interpolation) on a new noisy observation. Working\nunder the restriction of limited computation, we analyze a joint method in\nwhich the \\emph{same convex variational relaxation} is used to construct an\nM-estimator for fitting parameters, and to perform approximate marginalization\nfor the prediction step. The key result of this paper is that in the\ncomputation-limited setting, using an inconsistent parameter estimator (i.e.,\nan estimator that returns the ``wrong'' model even in the infinite data limit)\ncan be provably beneficial, since the resulting errors can partially compensate\nfor errors made by using an approximate prediction technique. En route to this\nresult, we analyze the asymptotic properties of M-estimators based on convex\nvariational relaxations, and establish a Lipschitz stability property that\nholds for a broad class of variational methods. We show that joint\nestimation/prediction based on the reweighted sum-product algorithm\nsubstantially outperforms a commonly used heuristic based on ordinary\nsum-product.",
    "published": "2006-02-27T05:22:15Z",
    "link": "http://arxiv.org/pdf/cs/0602092v1.pdf",
    "category": [
      "cs.LG",
      "cs.IT",
      "math.IT",
      "math.ST",
      "stat.TH"
    ],
    "authors": [
      "Martin J. Wainwright"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0602093v1",
    "title": "Rational stochastic languages",
    "summary": "The goal of the present paper is to provide a systematic and comprehensive\nstudy of rational stochastic languages over a semiring K \\in {Q, Q +, R, R+}. A\nrational stochastic language is a probability distribution over a free monoid\n\\Sigma^* which is rational over K, that is which can be generated by a\nmultiplicity automata with parameters in K. We study the relations between the\nclasses of rational stochastic languages S rat K (\\Sigma). We define the notion\nof residual of a stochastic language and we use it to investigate properties of\nseveral subclasses of rational stochastic languages. Lastly, we study the\nrepresentation of rational stochastic languages by means of multiplicity\nautomata.",
    "published": "2006-02-27T10:08:26Z",
    "link": "http://arxiv.org/pdf/cs/0602093v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Franois Denis",
      "Yann Esposito"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0603023v1",
    "title": "Metric State Space Reinforcement Learning for a Vision-Capable Mobile\n  Robot",
    "summary": "We address the problem of autonomously learning controllers for\nvision-capable mobile robots. We extend McCallum's (1995) Nearest-Sequence\nMemory algorithm to allow for general metrics over state-action trajectories.\nWe demonstrate the feasibility of our approach by successfully running our\nalgorithm on a real mobile robot. The algorithm is novel and unique in that it\n(a) explores the environment and learns directly on a mobile robot without\nusing a hand-made computer model as an intermediate step, (b) does not require\nmanual discretization of the sensor input space, (c) works in piecewise\ncontinuous perceptual spaces, and (d) copes with partial observability.\nTogether this allows learning from much less experience compared to previous\nmethods.",
    "published": "2006-03-07T08:44:29Z",
    "link": "http://arxiv.org/pdf/cs/0603023v1.pdf",
    "category": [
      "cs.RO",
      "cs.LG"
    ],
    "authors": [
      "Viktor Zhumatiy",
      "Faustino Gomez",
      "Marcus Hutter",
      "Juergen Schmidhuber"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0603090v2",
    "title": "Topological Grammars for Data Approximation",
    "summary": "A method of {\\it topological grammars} is proposed for multidimensional data\napproximation. For data with complex topology we define a {\\it principal cubic\ncomplex} of low dimension and given complexity that gives the best\napproximation for the dataset. This complex is a generalization of linear and\nnon-linear principal manifolds and includes them as particular cases. The\nproblem of optimal principal complex construction is transformed into a series\nof minimization problems for quadratic functionals. These quadratic functionals\nhave a physically transparent interpretation in terms of elastic energy. For\nthe energy computation, the whole complex is represented as a system of nodes\nand springs. Topologically, the principal complex is a product of\none-dimensional continuums (represented by graphs), and the grammars describe\nhow these continuums transform during the process of optimal complex\nconstruction. This factorization of the whole process onto one-dimensional\ntransformations using minimization of quadratic energy functionals allow us to\nconstruct efficient algorithms.",
    "published": "2006-03-22T22:52:23Z",
    "link": "http://arxiv.org/pdf/cs/0603090v2.pdf",
    "category": [
      "cs.NE",
      "cs.LG"
    ],
    "authors": [
      "A. N. Gorban",
      "N. R. Sumner",
      "A. Y. Zinovyev"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0603110v1",
    "title": "Asymptotic Learnability of Reinforcement Problems with Arbitrary\n  Dependence",
    "summary": "We address the problem of reinforcement learning in which observations may\nexhibit an arbitrary form of stochastic dependence on past observations and\nactions. The task for an agent is to attain the best possible asymptotic reward\nwhere the true generating environment is unknown but belongs to a known\ncountable family of environments. We find some sufficient conditions on the\nclass of environments under which an agent exists which attains the best\nasymptotic reward for any environment in the class. We analyze how tight these\nconditions are and how they relate to different probabilistic assumptions known\nin reinforcement learning and related fields, such as Markov Decision Processes\nand mixing conditions.",
    "published": "2006-03-28T16:22:42Z",
    "link": "http://arxiv.org/pdf/cs/0603110v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Daniil Ryabko",
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0604010v2",
    "title": "Nearly optimal exploration-exploitation decision thresholds",
    "summary": "While in general trading off exploration and exploitation in reinforcement\nlearning is hard, under some formulations relatively simple solutions exist. In\nthis paper, we first derive upper bounds for the utility of selecting different\nactions in the multi-armed bandit setting. Unlike the common statistical upper\nconfidence bounds, these explicitly link the planning horizon, uncertainty and\nthe need for exploration explicit. The resulting algorithm can be seen as a\ngeneralisation of the classical Thompson sampling algorithm. We experimentally\ntest these algorithms, as well as $\\epsilon$-greedy and the value of perfect\ninformation heuristics. Finally, we also introduce the idea of bagging for\nreinforcement learning. By employing a version of online bootstrapping, we can\nefficiently sample from an approximate posterior distribution.",
    "published": "2006-04-05T10:29:48Z",
    "link": "http://arxiv.org/pdf/cs/0604010v2.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Christos Dimitrakakis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0604015v1",
    "title": "Revealing the Autonomous System Taxonomy: The Machine Learning Approach",
    "summary": "Although the Internet AS-level topology has been extensively studied over the\npast few years, little is known about the details of the AS taxonomy. An AS\n\"node\" can represent a wide variety of organizations, e.g., large ISP, or small\nprivate business, university, with vastly different network characteristics,\nexternal connectivity patterns, network growth tendencies, and other properties\nthat we can hardly neglect while working on veracious Internet representations\nin simulation environments. In this paper, we introduce a radically new\napproach based on machine learning techniques to map all the ASes in the\nInternet into a natural AS taxonomy. We successfully classify 95.3% of ASes\nwith expected accuracy of 78.1%. We release to the community the AS-level\ntopology dataset augmented with: 1) the AS taxonomy information and 2) the set\nof AS attributes we used to classify ASes. We believe that this dataset will\nserve as an invaluable addition to further understanding of the structure and\nevolution of the Internet.",
    "published": "2006-04-06T00:08:24Z",
    "link": "http://arxiv.org/pdf/cs/0604015v1.pdf",
    "category": [
      "cs.NI",
      "cs.LG"
    ],
    "authors": [
      "Xenofontas Dimitropoulos",
      "Dmitri Krioukov",
      "George Riley",
      "kc claffy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/math/0604233v1",
    "title": "Generalization error bounds in semi-supervised classification under the\n  cluster assumption",
    "summary": "We consider semi-supervised classification when part of the available data is\nunlabeled. These unlabeled data can be useful for the classification problem\nwhen we make an assumption relating the behavior of the regression function to\nthat of the marginal distribution. Seeger (2000) proposed the well-known\n\"cluster assumption\" as a reasonable one. We propose a mathematical formulation\nof this assumption and a method based on density level sets estimation that\ntakes advantage of it to achieve fast rates of convergence both in the number\nof unlabeled examples and the number of labeled examples.",
    "published": "2006-04-11T05:41:15Z",
    "link": "http://arxiv.org/pdf/math/0604233v1.pdf",
    "category": [
      "math.ST",
      "cs.LG",
      "stat.TH"
    ],
    "authors": [
      "Philippe Rigollet"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0604046v1",
    "title": "Concerning the differentiability of the energy function in vector\n  quantization algorithms",
    "summary": "The adaptation rule for Vector Quantization algorithms, and consequently the\nconvergence of the generated sequence, depends on the existence and properties\nof a function called the energy function, defined on a topological manifold.\nOur aim is to investigate the conditions of existence of such a function for a\nclass of algorithms examplified by the initial ''K-means'' and Kohonen\nalgorithms. The results presented here supplement previous studies and show\nthat the energy function is not always a potential but at least the uniform\nlimit of a series of potential functions which we call a pseudo-potential. Our\nwork also shows that a large number of existing vector quantization algorithms\ndevelopped by the Artificial Neural Networks community fall into this category.\nThe framework we define opens the way to study the convergence of all the\ncorresponding adaptation rules at once, and a theorem gives promising insights\nin that direction. We also demonstrate that the ''K-means'' energy function is\na pseudo-potential but not a potential in general. Consequently, the energy\nfunction associated to the ''Neural-Gas'' is not a potential in general.",
    "published": "2006-04-11T14:00:22Z",
    "link": "http://arxiv.org/pdf/cs/0604046v1.pdf",
    "category": [
      "cs.LG",
      "cs.NE"
    ],
    "authors": [
      "Dominique Lepetz",
      "Max Nemoz-Gaillard",
      "Michael Aupetit"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0604102v1",
    "title": "HCI and Educational Metrics as Tools for VLE Evaluation",
    "summary": "The general set of HCI and Educational principles are considered and a\nclassification system constructed. A frequency analysis of principles is used\nto obtain the most significant set. Metrics are devised to provide objective\nmeasures of these principles and a consistent testing regime devised. These\nprinciples are used to analyse Blackboard and Moodle.",
    "published": "2006-04-25T19:32:03Z",
    "link": "http://arxiv.org/pdf/cs/0604102v1.pdf",
    "category": [
      "cs.HC",
      "cs.LG"
    ],
    "authors": [
      "Vita Hinze-Hoare"
    ]
  },
  {
    "id": "http://arxiv.org/abs/astro-ph/0605042v1",
    "title": "How accurate are the time delay estimates in gravitational lensing?",
    "summary": "We present a novel approach to estimate the time delay between light curves\nof multiple images in a gravitationally lensed system, based on Kernel methods\nin the context of machine learning. We perform various experiments with\nartificially generated irregularly-sampled data sets to study the effect of the\nvarious levels of noise and the presence of gaps of various size in the\nmonitoring data. We compare the performance of our method with various other\npopular methods of estimating the time delay and conclude, from experiments\nwith artificial data, that our method is least vulnerable to missing data and\nirregular sampling, within reasonable bounds of Gaussian noise. Thereafter, we\nuse our method to determine the time delays between the two images of quasar\nQ0957+561 from radio monitoring data at 4 cm and 6 cm, and conclude that if\nonly the observations at epochs common to both wavelengths are used, the time\ndelay gives consistent estimates, which can be combined to yield 408\\pm 12\ndays. The full 6 cm dataset, which covers a longer monitoring period, yields a\nvalue which is 10% larger, but this can be attributed to differences in\nsampling and missing data.",
    "published": "2006-05-01T20:42:03Z",
    "link": "http://arxiv.org/pdf/astro-ph/0605042v1.pdf",
    "category": [
      "astro-ph",
      "cs.LG"
    ],
    "authors": [
      "Juan C. Cuevas-Tello",
      "Peter Tino",
      "Somak Raychaudhury"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0605009v1",
    "title": "On the Foundations of Universal Sequence Prediction",
    "summary": "Solomonoff completed the Bayesian framework by providing a rigorous, unique,\nformal, and universal choice for the model class and the prior. We discuss in\nbreadth how and in which sense universal (non-i.i.d.) sequence prediction\nsolves various (philosophical) problems of traditional Bayesian sequence\nprediction. We show that Solomonoff's model possesses many desirable\nproperties: Fast convergence and strong bounds, and in contrast to most\nclassical continuous prior densities has no zero p(oste)rior problem, i.e. can\nconfirm universal hypotheses, is reparametrization and regrouping invariant,\nand avoids the old-evidence and updating problem. It even performs well\n(actually better) in non-computable environments.",
    "published": "2006-05-03T07:47:21Z",
    "link": "http://arxiv.org/pdf/cs/0605009v1.pdf",
    "category": [
      "cs.LG",
      "cs.IT",
      "math.IT",
      "math.ST",
      "stat.TH"
    ],
    "authors": [
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0605024v1",
    "title": "A Formal Measure of Machine Intelligence",
    "summary": "A fundamental problem in artificial intelligence is that nobody really knows\nwhat intelligence is. The problem is especially acute when we need to consider\nartificial systems which are significantly different to humans. In this paper\nwe approach this problem in the following way: We take a number of well known\ninformal definitions of human intelligence that have been given by experts, and\nextract their essential features. These are then mathematically formalised to\nproduce a general measure of intelligence for arbitrary machines. We believe\nthat this measure formally captures the concept of machine intelligence in the\nbroadest reasonable sense.",
    "published": "2006-05-06T16:56:43Z",
    "link": "http://arxiv.org/pdf/cs/0605024v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Shane Legg",
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0605035v1",
    "title": "Query Chains: Learning to Rank from Implicit Feedback",
    "summary": "This paper presents a novel approach for using clickthrough data to learn\nranked retrieval functions for web search results. We observe that users\nsearching the web often perform a sequence, or chain, of queries with a similar\ninformation need. Using query chains, we generate new types of preference\njudgments from search engine logs, thus taking advantage of user intelligence\nin reformulating queries. To validate our method we perform a controlled user\nstudy comparing generated preference judgments to explicit relevance judgments.\nWe also implemented a real-world search engine to test our approach, using a\nmodified ranking SVM to learn an improved ranking function from preference\ndata. Our results demonstrate significant improvements in the ranking given by\nthe search engine. The learned rankings outperform both a static ranking\nfunction, as well as one trained without considering query chains.",
    "published": "2006-05-08T22:05:24Z",
    "link": "http://arxiv.org/pdf/cs/0605035v1.pdf",
    "category": [
      "cs.LG",
      "cs.IR",
      "H.3.3"
    ],
    "authors": [
      "Filip Radlinski",
      "Thorsten Joachims"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0605036v1",
    "title": "Evaluating the Robustness of Learning from Implicit Feedback",
    "summary": "This paper evaluates the robustness of learning from implicit feedback in web\nsearch. In particular, we create a model of user behavior by drawing upon user\nstudies in laboratory and real-world settings. The model is used to understand\nthe effect of user behavior on the performance of a learning algorithm for\nranked retrieval. We explore a wide range of possible user behaviors and find\nthat learning from implicit feedback can be surprisingly robust. This\ncomplements previous results that demonstrated our algorithm's effectiveness in\na real-world search engine application.",
    "published": "2006-05-08T23:38:13Z",
    "link": "http://arxiv.org/pdf/cs/0605036v1.pdf",
    "category": [
      "cs.LG",
      "cs.IR",
      "H.3.3"
    ],
    "authors": [
      "Filip Radlinski",
      "Thorsten Joachims"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0605037v1",
    "title": "Minimally Invasive Randomization for Collecting Unbiased Preferences\n  from Clickthrough Logs",
    "summary": "Clickthrough data is a particularly inexpensive and plentiful resource to\nobtain implicit relevance feedback for improving and personalizing search\nengines. However, it is well known that the probability of a user clicking on a\nresult is strongly biased toward documents presented higher in the result set\nirrespective of relevance. We introduce a simple method to modify the\npresentation of search results that provably gives relevance judgments that are\nunaffected by presentation bias under reasonable assumptions. We validate this\nproperty of the training data in interactive real world experiments. Finally,\nwe show that using these unbiased relevance judgments learning methods can be\nguaranteed to converge to an ideal ranking given sufficient data.",
    "published": "2006-05-09T01:53:22Z",
    "link": "http://arxiv.org/pdf/cs/0605037v1.pdf",
    "category": [
      "cs.IR",
      "cs.LG",
      "H.3.3"
    ],
    "authors": [
      "Filip Radlinski",
      "Thorsten Joachims"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0605040v1",
    "title": "General Discounting versus Average Reward",
    "summary": "Consider an agent interacting with an environment in cycles. In every\ninteraction cycle the agent is rewarded for its performance. We compare the\naverage reward U from cycle 1 to m (average value) with the future discounted\nreward V from cycle k to infinity (discounted value). We consider essentially\narbitrary (non-geometric) discount sequences and arbitrary reward sequences\n(non-MDP environments). We show that asymptotically U for m->infinity and V for\nk->infinity are equal, provided both limits exist. Further, if the effective\nhorizon grows linearly with k or faster, then existence of the limit of U\nimplies that the limit of V exists. Conversely, if the effective horizon grows\nlinearly with k or slower, then existence of the limit of V implies that the\nlimit of U exists.",
    "published": "2006-05-09T10:39:03Z",
    "link": "http://arxiv.org/pdf/cs/0605040v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Marcus Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9809036v1",
    "title": "Document Archiving, Replication and Migration Container for Mobile Web\n  Users",
    "summary": "With the increasing use of mobile workstations for a wide variety of tasks\nand associated information needs, and with many variations of available\nnetworks, access to data becomes a prime consideration. This paper discusses\nissues of workstation mobility and proposes a solution wherein the data\nstructures are accessed in an encapsulated form - through the Portable File\nSystem (PFS) wrapper. The paper discusses an implementation of the Portable\nFile System, highlighting the architecture and commenting upon performance of\nan experimental system. Although investigations have been focused upon mobile\naccess of WWW documents, this technique could be applied to any mobile data\naccess situation.",
    "published": "1998-09-20T12:48:43Z",
    "link": "http://arxiv.org/pdf/cs/9809036v1.pdf",
    "category": [
      "cs.MA",
      "cs.MM",
      "H.3.2; H.5.3; H.5.4"
    ],
    "authors": [
      "P. Stanski",
      "S. Giles",
      "A. Zaslavsky"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9809104v1",
    "title": "Adaptive Multicast of Multi-Layered Video: Rate-Based and Credit-Based\n  Approaches",
    "summary": "Network architectures that can efficiently transport high quality, multicast\nvideo are rapidly becoming a basic requirement of emerging multimedia\napplications. The main problem complicating multicast video transport is\nvariation in network bandwidth constraints. An attractive solution to this\nproblem is to use an adaptive, multi-layered video encoding mechanism. In this\npaper, we consider two such mechanisms for the support of video multicast; one\nis a rate-based mechanism that relies on explicit rate congestion feedback from\nthe network, and the other is a credit-based mechanism that relies on\nhop-by-hop congestion feedback. The responsiveness, bandwidth utilization,\nscalability and fairness of the two mechanisms are evaluated through\nsimulations. Results suggest that while the two mechanisms exhibit performance\ntrade-offs, both are capable of providing a high quality video service in the\npresence of varying bandwidth constraints.",
    "published": "1998-09-24T18:12:21Z",
    "link": "http://arxiv.org/pdf/cs/9809104v1.pdf",
    "category": [
      "cs.NI",
      "cs.MM",
      "C.2.1"
    ],
    "authors": [
      "Brett J. Vickers",
      "Celio Albuquerque",
      "Tatsuya Suda"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0002004v1",
    "title": "Stochastic Model Checking for Multimedia",
    "summary": "Modern distributed systems include a class of applications in which\nnon-functional requirements are important. In particular, these applications\ninclude multimedia facilities where real time constraints are crucial to their\ncorrect functioning. In order to specify such systems it is necessary to\ndescribe that events occur at times given by probability distributions and\nstochastic automata have emerged as a useful technique by which such systems\ncan be specified and verified.\n  However, stochastic descriptions are very general, in particular they allow\nthe use of general probability distribution functions, and therefore their\nverification can be complex. In the last few years, model checking has emerged\nas a useful verification tool for large systems.\n  In this paper we describe two model checking algorithms for stochastic\nautomata. These algorithms consider how properties written in a simple\nprobabilistic real-time logic can be checked against a given stochastic\nautomaton.",
    "published": "2000-02-04T18:42:13Z",
    "link": "http://arxiv.org/pdf/cs/0002004v1.pdf",
    "category": [
      "cs.MM",
      "cs.LO",
      "F.3.1; F.4.1; G.3"
    ],
    "authors": [
      "Jeremy Bryans",
      "Howard Bowman",
      "John Derrick"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0007007v1",
    "title": "Data sonification and sound visualization",
    "summary": "This article describes a collaborative project between researchers in the\nMathematics and Computer Science Division at Argonne National Laboratory and\nthe Computer Music Project of the University of Illinois at Urbana-Champaign.\nThe project focuses on the use of sound for the exploration and analysis of\ncomplex data sets in scientific computing. The article addresses digital sound\nsynthesis in the context of DIASS (Digital Instrument for Additive Sound\nSynthesis) and sound visualization in a virtual-reality environment by means of\nM4CAVE. It describes the procedures and preliminary results of some experiments\nin scientific sonification and sound visualization.",
    "published": "2000-07-05T21:26:48Z",
    "link": "http://arxiv.org/pdf/cs/0007007v1.pdf",
    "category": [
      "cs.SD",
      "cs.HC",
      "cs.MM",
      "H.5.5"
    ],
    "authors": [
      "Hans G. Kaper",
      "Sever Tipei",
      "Elizabeth Wiebel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0012021v1",
    "title": "A Benchmark for Image Retrieval using Distributed Systems over the\n  Internet: BIRDS-I",
    "summary": "The performance of CBIR algorithms is usually measured on an isolated\nworkstation. In a real-world environment the algorithms would only constitute a\nminor component among the many interacting components. The Internet\ndramati-cally changes many of the usual assumptions about measuring CBIR\nperformance. Any CBIR benchmark should be designed from a networked systems\nstandpoint. These benchmarks typically introduce communication overhead because\nthe real systems they model are distributed applications. We present our\nimplementation of a client/server benchmark called BIRDS-I to measure image\nretrieval performance over the Internet. It has been designed with the trend\ntoward the use of small personalized wireless systems in mind. Web-based CBIR\nimplies the use of heteroge-neous image sets, imposing certain constraints on\nhow the images are organized and the type of performance metrics applicable.\nBIRDS-I only requires controlled human intervention for the compilation of the\nimage collection and none for the generation of ground truth in the measurement\nof retrieval accuracy. Benchmark image collections need to be evolved\nincrementally toward the storage of millions of images and that scaleup can\nonly be achieved through the use of computer-aided compilation. Finally, our\nscoring metric introduces a tightly optimized image-ranking window.",
    "published": "2000-12-22T23:38:37Z",
    "link": "http://arxiv.org/pdf/cs/0012021v1.pdf",
    "category": [
      "cs.IR",
      "cs.MM",
      "D.2.8;H.2.8;H.3.1;H.3.4;H.3.5"
    ],
    "authors": [
      "Neil J. Gunther",
      "Giordano B. Beretta"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0109041v2",
    "title": "Open Access beyond cable: The case of Interactive TV",
    "summary": "In this paper we analyze the development of interactive TV in the U.S. and\nWestern Europe. We argue that despite the nascent character of the market there\nare important regulatory issues at stake, as exemplified by the AOL/TW merger\nand the British Interactive Broadcasting case. Absent rules that provide for\nnon-discriminatory access to network components (including terminal equipment\nspecifications), dominant platform operators are likely to leverage ownership\nof delivery infrastructure into market power over interactive TV services.\nWhile integration between platform operator, service provider and terminal\nvendor may facilitate the introduction of services in the short-term, the\nlasting result will be a collection of fragmented \"walled gardens\" offering\nlimited content and applications. Would interactive TV develop under such\nmodel, the exciting opportunities for broad-based innovation and extended\naccess to multiple information, entertainment and educational services opened\nby the new generation of broadcasting technologies will be foregone",
    "published": "2001-09-20T23:48:11Z",
    "link": "http://arxiv.org/pdf/cs/0109041v2.pdf",
    "category": [
      "cs.MM",
      "K.4.1"
    ],
    "authors": [
      "Hernan Galperin",
      "Francois Bar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0112024v1",
    "title": "Media Objects in Time - A Multimedia Streaming System",
    "summary": "The widespread availability of networked multimedia potentials embedded in an\ninfrastructure of qualitative superior kind gives rise to new approaches in the\nareas of teleteaching and internet presentation: The distribution of\nprofessionally styled multimedia streams has fallen in the realm of\npossibility. This paper presents a prototype - both model and runtime\nenvironment - of a time directed media system treating any kind of\npresentational contribution as reusable media object components. The plug-in\nfree runtime system is based on a database and allows for a flexible support of\nstatic media types as well as for easy extensions by streaming media servers.\nThe prototypic implementation includes a preliminary Web Authoring platform.",
    "published": "2001-12-28T20:19:09Z",
    "link": "http://arxiv.org/pdf/cs/0112024v1.pdf",
    "category": [
      "cs.NI",
      "cs.MM",
      "H.5.4; H.2.4; H.4.3; C.3"
    ],
    "authors": [
      "B. Feustel",
      "T. C. Schmidt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0210021v1",
    "title": "Reconciling MPEG-7 and MPEG-21 Semantics through a Common Event-Aware\n  Metadata Model",
    "summary": "The \"event\" concept appears repeatedly when developing metadata models for\nthe description and management of multimedia content. During the typical life\ncycle of multimedia content, events occur at many different levels - from the\nevents which happen during content creation (directing, acting, camera panning\nand zooming) to the events which happen to the physical form (acquisition,\nrelocation, damage of film or video) to the digital conversion, reformatting,\nediting and repackaging events, to the events which are depicted in the actual\ncontent (political, news, sporting) to the usage, ownership and copyright\nagreement events and even the metadata attribution events. Support is required\nwithin both MPEG-7 and MPEG-21 for the clear and unambiguous description of all\nof these event types which may occur at widely different levels of nesting and\ngranularity. In this paper we first describe an event-aware model (the ABC\nmodel) which is capable of modeling and yet clearly differentiating between all\nof these, often recursive and overlapping events. We then illustrate how this\nmodel can be used as the foundation to facilitate semantic interoperability\nbetween MPEG-7 and MPEG-21. By expressing the semantics of both MPEG-7 and\nMPEG-21 metadata terms in RDF Schema (and some DAML+OIL extensions) and\nattaching the MPEG-7 and MPEG-21 class and property hierarchies to the\nappropriate top-level classes and properties of the ABC model, we are\nessentially able to define a single distributed machine-understandable\nontology, which will enable interoperability of data and services across the\nentire multimedia content delivery chain.",
    "published": "2002-10-22T02:16:57Z",
    "link": "http://arxiv.org/pdf/cs/0210021v1.pdf",
    "category": [
      "cs.MM",
      "cs.DL",
      "H.2.1;H.3.1;H.3.7;H.5.1"
    ],
    "authors": [
      "Jane Hunter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0306116v2",
    "title": "Global Platform for Rich Media Conferencing and Collaboration",
    "summary": "The Virtual Rooms Videoconferencing Service (VRVS) provides a worldwide\nvideoconferencing service and collaborative environment to the research and\neducation communities. This system provides a low cost, bandwidth-efficient,\nextensible means for videoconferencing and remote collaboration over networks\nwithin the High Energy and Nuclear Physics communities (HENP). VRVS has become\na standard part of the toolset used daily by a large sector of HENP, and it is\nused increasingly for other DoE/NSF-supported programs. The current features\nincluded multi-protocol, multi-OS support for all significant video enabled\nclients including: H.323, Mbone, QuickTime, MPEG2, Java Media Framework, and\nother clients. The current architecture makes VRVS a distributed, highly\nfunctional, and efficient software-only system for multipoint audio, video and\nweb conferencing and collaboration over global IP networks. VRVS has developed\nthe VRVS-AG Reflector and a specialized Web interface that enables end users to\nconnect to any Access Grid (AG) session, in any of the AG \"virtual venues\" from\nanywhere worldwide. The VRVS system has now been running for the last five and\nhalf years, offering to the HENP community a working and reliable tool for\ncollaboration within groups and among physicists dispersed world-wide. The goal\nof this ongoing effort is to develop the next generation collaborative systems\nrunning over next generation networks. The new developments area integrate\nemerging standards, include all security aspects, and will extend the range of\nVRVS video technologies supported to cover the latest high end standards\nquality. We will focus the discussion on the new capability provides by the\nlatest version V3.0 and its future evolution.",
    "published": "2003-06-19T22:57:42Z",
    "link": "http://arxiv.org/pdf/cs/0306116v2.pdf",
    "category": [
      "cs.MM",
      "cs.NI",
      "H.5.3"
    ],
    "authors": [
      "Harvey B. Newman",
      "Philippe Galvez",
      "Gregory Denis",
      "David Collados",
      "Kun Wei",
      "David Adamczyk"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0312050v1",
    "title": "A Flexible Pragmatics-driven Language Generator for Animated Agents",
    "summary": "This paper describes the NECA MNLG; a fully implemented Multimodal Natural\nLanguage Generation module. The MNLG is deployed as part of the NECA system\nwhich generates dialogues between animated agents. The generation module\nsupports the seamless integration of full grammar rules, templates and canned\ntext. The generator takes input which allows for the specification of\nsyntactic, semantic and pragmatic constraints on the output.",
    "published": "2003-12-22T16:23:34Z",
    "link": "http://arxiv.org/pdf/cs/0312050v1.pdf",
    "category": [
      "cs.CL",
      "cs.MM",
      "I.2.7"
    ],
    "authors": [
      "Paul Piwek"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0408063v1",
    "title": "Analysis and Visualization of Index Words from Audio Transcripts of\n  Instructional Videos",
    "summary": "We introduce new techniques for extracting, analyzing, and visualizing\ntextual contents from instructional videos of low production quality. Using\nAutomatic Speech Recognition, approximate transcripts (H75% Word Error Rate)\nare obtained from the originally highly compressed videos of university\ncourses, each comprising between 10 to 30 lectures. Text material in the form\nof books or papers that accompany the course are then used to filter meaningful\nphrases from the seemingly incoherent transcripts. The resulting index into the\ntranscripts is tied together and visualized in 3 experimental graphs that help\nin understanding the overall course structure and provide a tool for localizing\ncertain topics for indexing. We specifically discuss a Transcript Index Map,\nwhich graphically lays out key phrases for a course, a Textbook Chapter to\nTranscript Match, and finally a Lecture Transcript Similarity graph, which\nclusters semantically similar lectures. We test our methods and tools on 7 full\ncourses with 230 hours of video and 273 transcripts. We are able to extract up\nto 98 unique key terms for a given transcript and up to 347 unique key terms\nfor an entire course. The accuracy of the Textbook Chapter to Transcript Match\nexceeds 70% on average. The methods used can be applied to genres of video in\nwhich there are recurrent thematic words (news, sports, meetings,...)",
    "published": "2004-08-27T20:45:32Z",
    "link": "http://arxiv.org/pdf/cs/0408063v1.pdf",
    "category": [
      "cs.IR",
      "cs.MM",
      "H.3.1;H.3.3;I.2.10"
    ],
    "authors": [
      "Alexander Haubold",
      "John R. Kender"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0409059v1",
    "title": "From Digital Television to Internet?",
    "summary": "This paper provides a general technical overview of the Multimedia Home\nPlatform (MHP) specifications. MHP is a generic interface between digital\napplications and user machines, whether they happen to be set top boxes,\ndigital TV sets or Multimedia PC's. MHP extends the DVB open standards.\nAddressed are MHP architexture, System core and MHP Profiles.",
    "published": "2004-09-30T19:08:55Z",
    "link": "http://arxiv.org/pdf/cs/0409059v1.pdf",
    "category": [
      "cs.MM",
      "cs.CY"
    ],
    "authors": [
      "Vita Hinze-Hoare"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0410022v1",
    "title": "RRL: A Rich Representation Language for the Description of Agent\n  Behaviour in NECA",
    "summary": "In this paper, we describe the Rich Representation Language (RRL) which is\nused in the NECA system. The NECA system generates interactions between two or\nmore animated characters. The RRL is an XML compliant framework for\nrepresenting the information that is exchanged at the interfaces between the\nvarious NECA system modules. The full XML Schemas for the RRL are available at\nhttp://www.ai.univie.ac.at/NECA/RRL",
    "published": "2004-10-11T12:34:02Z",
    "link": "http://arxiv.org/pdf/cs/0410022v1.pdf",
    "category": [
      "cs.MM",
      "cs.MA",
      "H5.1, H5.2"
    ],
    "authors": [
      "P. Piwek",
      "B. Krenn",
      "M. Schroeder",
      "M. Grice",
      "S. Baumann",
      "H. Pirker"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0412017v1",
    "title": "An Analysis of the Skype Peer-to-Peer Internet Telephony Protocol",
    "summary": "Skype is a peer-to-peer VoIP client developed by KaZaa in 2003. Skype claims\nthat it can work almost seamlessly across NATs and firewalls and has better\nvoice quality than the MSN and Yahoo IM applications. It encrypts calls\nend-to-end, and stores user information in a decentralized fashion. Skype also\nsupports instant messaging and conferencing. This report analyzes key Skype\nfunctions such as login, NAT and firewall traversal, call establishment, media\ntransfer, codecs, and conferencing under three different network setups.\nAnalysis is performed by careful study of Skype network traffic.",
    "published": "2004-12-05T03:56:57Z",
    "link": "http://arxiv.org/pdf/cs/0412017v1.pdf",
    "category": [
      "cs.NI",
      "cs.MM",
      "C.2.2"
    ],
    "authors": [
      "Salman A. Baset",
      "Henning Schulzrinne"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0412073v1",
    "title": "Self-Organizing the Abstract: Canvas as a Swarm Habitat for Collective\n  Memory, Perception and Cooperative Distributed Creativity",
    "summary": "Past experiences under the designation of \"Swarm Paintings\" conducted in\n2001, not only confirmed the possibility of realizing an artificial art (thus\nnon-human), as introduced into the process the questioning of creative\nmigration, specifically from the computer monitors to the canvas via a robotic\nharm. In more recent self-organized based research we seek to develop and\nprofound the initial ideas by using a swarm of autonomous robots (ARTsBOT\nproject 2002-03), that \"live\" avoiding the purpose of being merely a simple\nperpetrator of order streams coming from an external computer, but instead,\nthat actually co-evolve within the canvas space, acting (that is, laying ink)\naccording to simple inner threshold stimulus response functions, reacting\nsimultaneously to the chromatic stimulus present in the canvas environment done\nby the passage of their team-mates, as well as by the distributed feedback,\naffecting their future collective behaviour. In parallel, and in what respects\nto certain types of collective systems, we seek to confirm, in a physically\nembedded way, that the emergence of order (even as a concept) seems to be found\nat a lower level of complexity, based on simple and basic interchange of\ninformation, and on the local dynamic of parts, who, by self-organizing\nmechanisms tend to form an lived whole, innovative and adapting, allowing for\nemergent open-ended creative and distributed production. KEYWORDS: ArtSBots\nProject, Swarm Intelligence, Stigmergy, UnManned Art, Symbiotic Art, Swarm\nPaintings, Robot Paintings, Non-Human Art, Painting Emergence and Cooperation,\nArt and Complexity, ArtBots: The Robot Talent Show.",
    "published": "2004-12-17T15:36:05Z",
    "link": "http://arxiv.org/pdf/cs/0412073v1.pdf",
    "category": [
      "cs.MM",
      "cs.AI",
      "I.2.11"
    ],
    "authors": [
      "Vitorino Ramos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0412077v1",
    "title": "On the Implicit and on the Artificial - Morphogenesis and Emergent\n  Aesthetics in Autonomous Collective Systems",
    "summary": "Imagine a \"machine\" where there is no pre-commitment to any particular\nrepresentational scheme: the desired behaviour is distributed and roughly\nspecified simultaneously among many parts, but there is minimal specification\nof the mechanism required to generate that behaviour, i.e. the global behaviour\nevolves from the many relations of multiple simple behaviours. A machine that\nlives to and from/with Synergy. An artificial super-organism that avoids\nspecific constraints and emerges within multiple low-level implicit\nbio-inspired mechanisms. KEYWORDS: Complex Science, ArtSBots Project, Swarm\nIntelligence, Stigmergy, UnManned Art, Symbiotic Art, Swarm Paintings, Robot\nPaintings, Non-Human Art, Painting Emergence and Cooperation, Art and\nComplexity, ArtBots: The Robot Talent Show.",
    "published": "2004-12-17T16:15:08Z",
    "link": "http://arxiv.org/pdf/cs/0412077v1.pdf",
    "category": [
      "cs.AI",
      "cs.MM",
      "I.2; I.6"
    ],
    "authors": [
      "Vitorino Ramos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0412079v1",
    "title": "The MC2 Project [Machines of Collective Conscience]: A possible walk, up\n  to Life-like Complexity and Behaviour, from bottom, basic and simple\n  bio-inspired heuristics - a walk, up into the morphogenesis of information",
    "summary": "Synergy (from the Greek word synergos), broadly defined, refers to combined\nor co-operative effects produced by two or more elements (parts or\nindividuals). The definition is often associated with the holistic conviction\nquote that \"the whole is greater than the sum of its parts\" (Aristotle, in\nMetaphysics), or the whole cannot exceed the sum of the energies invested in\neach of its parts (e.g. first law of thermodynamics) even if it is more\naccurate to say that the functional effects produced by wholes are different\nfrom what the parts can produce alone. Synergy is a ubiquitous phenomena in\nnature and human societies alike. One well know example is provided by the\nemergence of self-organization in social insects, via direct or indirect\ninteractions. The latter types are more subtle and defined as stigmergy to\nexplain task coordination and regulation in the context of nest reconstruction\nin termites. An example, could be provided by two individuals, who interact\nindirectly when one of them modifies the environment and the other responds to\nthe new environment at a later time. In other words, stigmergy could be defined\nas a particular case of environmental or spatial synergy. The system is purely\nholistic, and their properties are intrinsically emergent and autocatalytic. On\nthe present work we present a \"machine\" where there is no precommitment to any\nparticular representational scheme: the desired behaviour is distributed and\nroughly specified simultaneously among many parts, but there is minimal\nspecification of the mechanism required to generate that behaviour, i.e. the\nglobal behaviour evolves from the many relations of multiple simple behaviours.",
    "published": "2004-12-17T16:28:26Z",
    "link": "http://arxiv.org/pdf/cs/0412079v1.pdf",
    "category": [
      "cs.AI",
      "cs.MM",
      "I.2.11"
    ],
    "authors": [
      "Vitorino Ramos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0501012v6",
    "title": "Fedora: An Architecture for Complex Objects and their Relationships",
    "summary": "The Fedora architecture is an extensible framework for the storage,\nmanagement, and dissemination of complex objects and the relationships among\nthem. Fedora accommodates the aggregation of local and distributed content into\ndigital objects and the association of services with objects. This al-lows an\nobject to have several accessible representations, some of them dy-namically\nproduced. The architecture includes a generic RDF-based relation-ship model\nthat represents relationships among objects and their components. Queries\nagainst these relationships are supported by an RDF triple store. The\narchitecture is implemented as a web service, with all aspects of the complex\nobject architecture and related management functions exposed through REST and\nSOAP interfaces. The implementation is available as open-source soft-ware,\nproviding the foundation for a variety of end-user applications for digital\nlibraries, archives, institutional repositories, and learning object systems.",
    "published": "2005-01-07T17:57:05Z",
    "link": "http://arxiv.org/pdf/cs/0501012v6.pdf",
    "category": [
      "cs.DL",
      "cs.MM",
      "H.3.7"
    ],
    "authors": [
      "Carl Lagoze",
      "Sandy Payette",
      "Edwin Shin",
      "Chris Wilper"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0501013v2",
    "title": "On the security of the Yen-Guo's domino signal encryption algorithm\n  (DSEA)",
    "summary": "Recently, a new domino signal encryption algorithm (DSEA) was proposed for\ndigital signal transmission, especially for digital images and videos. This\npaper analyzes the security of DSEA, and points out the following weaknesses:\n1) its security against the brute-force attack was overestimated; 2) it is not\nsufficiently secure against ciphertext-only attacks, and only one ciphertext is\nenough to get some information about the plaintext and to break the value of a\nsub-key; 3) it is insecure against known/chosen-plaintext attacks, in the sense\nthat the secret key can be recovered from a number of continuous bytes of only\none known/chosen plaintext and the corresponding ciphertext. Experimental\nresults are given to show the performance of the proposed attacks, and some\ncountermeasures are discussed to improve DSEA.",
    "published": "2005-01-08T15:35:13Z",
    "link": "http://arxiv.org/pdf/cs/0501013v2.pdf",
    "category": [
      "cs.CR",
      "cs.MM",
      "nlin.CD"
    ],
    "authors": [
      "Chengqing Li",
      "Shujun Li",
      "Der-Chyuan Lou",
      "Dan Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0501014v3",
    "title": "On the Design of Perceptual MPEG-Video Encryption Algorithms",
    "summary": "In this paper, some existing perceptual encryption algorithms of MPEG videos\nare reviewed and some problems, especially security defects of two recently\nproposed MPEG-video perceptual encryption schemes, are pointed out. Then, a\nsimpler and more effective design is suggested, which selectively encrypts\nfixed-length codewords (FLC) in MPEG-video bitstreams under the control of\nthree perceptibility factors. The proposed design is actually an encryption\nconfiguration that can work with any stream cipher or block cipher. Compared\nwith the previously-proposed schemes, the new design provides more useful\nfeatures, such as strict size-preservation, on-the-fly encryption and multiple\nperceptibility, which make it possible to support more applications with\ndifferent requirements. In addition, four different measures are suggested to\nprovide better security against known/chosen-plaintext attacks.",
    "published": "2005-01-08T15:55:30Z",
    "link": "http://arxiv.org/pdf/cs/0501014v3.pdf",
    "category": [
      "cs.MM",
      "cs.CR"
    ],
    "authors": [
      "Shujun Li",
      "Guanrong Chen",
      "Albert Cheung",
      "Bharat Bhargava",
      "Kwok-Tung Lo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0501044v1",
    "title": "Augmented Segmentation and Visualization for Presentation Videos",
    "summary": "We investigate methods of segmenting, visualizing, and indexing presentation\nvideos by separately considering audio and visual data. The audio track is\nsegmented by speaker, and augmented with key phrases which are extracted using\nan Automatic Speech Recognizer (ASR). The video track is segmented by visual\ndissimilarities and augmented by representative key frames. An interactive user\ninterface combines a visual representation of audio, video, text, and key\nframes, and allows the user to navigate a presentation video. We also explore\nclustering and labeling of speaker data and present preliminary results.",
    "published": "2005-01-20T17:12:05Z",
    "link": "http://arxiv.org/pdf/cs/0501044v1.pdf",
    "category": [
      "cs.MM",
      "cs.IR",
      "H.2.4;H.3.1"
    ],
    "authors": [
      "Alexander Haubold",
      "John R. Kender"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0503027v2",
    "title": "Authentication with Distortion Criteria",
    "summary": "In a variety of applications, there is a need to authenticate content that\nhas experienced legitimate editing in addition to potential tampering attacks.\nWe develop one formulation of this problem based on a strict notion of\nsecurity, and characterize and interpret the associated information-theoretic\nperformance limits. The results can be viewed as a natural generalization of\nclassical approaches to traditional authentication. Additional insights into\nthe structure of such systems and their behavior are obtained by further\nspecializing the results to Bernoulli and Gaussian cases. The associated\nsystems are shown to be substantially better in terms of performance and/or\nsecurity than commonly advocated approaches based on data hiding and digital\nwatermarking. Finally, the formulation is extended to obtain efficient layered\nauthentication system constructions.",
    "published": "2005-03-12T21:13:21Z",
    "link": "http://arxiv.org/pdf/cs/0503027v2.pdf",
    "category": [
      "cs.IT",
      "cs.CR",
      "cs.MM",
      "math.IT"
    ],
    "authors": [
      "Emin Martinian",
      "Gregory W. Wornell",
      "Brian Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0504105v1",
    "title": "Wikis in Tuple Spaces",
    "summary": "We consider storing the pages of a wiki in a tuple space and the effects this\nmight have on the wiki experience. In particular, wiki pages are stored in\ntuples with a few identifying values such as title, author, revision date,\ncontent, etc. and pages are retrieved by sending the tuple space templates,\nsuch as one that gives the title but nothing else, leaving the tuple space to\nresolve to a single tuple. We use a tuple space wiki to avoid deadlocks,\ninfinite loops, and wasted efforts when page edit contention arises and examine\nhow a tuple space wiki changes the wiki experience.",
    "published": "2005-04-27T23:04:35Z",
    "link": "http://arxiv.org/pdf/cs/0504105v1.pdf",
    "category": [
      "cs.DC",
      "cs.MM"
    ],
    "authors": [
      "G Gordon Worley III"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0504106v1",
    "title": "A Distributed Multimedia Communication System and its Applications to\n  E-Learning",
    "summary": "In this paper we report on a multimedia communication system including a\nVCoIP (Video Conferencing over IP) software with a distributed architecture and\nits applications for teaching scenarios. It is a simple, ready-to-use scheme\nfor distributed presenting, recording and streaming multimedia content. We also\nintroduce and investigate concepts and experiments to IPv6 user and session\nmobility, with the special focus on real-time video group communication.",
    "published": "2005-04-28T13:40:09Z",
    "link": "http://arxiv.org/pdf/cs/0504106v1.pdf",
    "category": [
      "cs.MM",
      "cs.NI",
      "C.2.2; C.2.4; H.4.3"
    ],
    "authors": [
      "Hans L. Cycon",
      "Thomas C. Schmidt",
      "Matthias Waehlisch",
      "Mark Palkow",
      "Henrik Regensburg"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0506070v1",
    "title": "Data Visualization on Shared Usage Multi-Screen Environment",
    "summary": "The modern multimedia technologies based on the whole palette of hardware and\nsoftware facilities of real-time high-speed information processing, in a\ncombination with effective facilities of the remote access to information\nresources, allow us to visualize diverse types of information. Data\nvisualization facilities &#8211; is the face of the Automated Control System on\nwhom often judge about their efficiency. They take a special place, providing\nvisualization of the diverse information necessary for decision-making by a\nfinal control link - the person allocated by certain powers.",
    "published": "2005-06-16T10:15:05Z",
    "link": "http://arxiv.org/pdf/cs/0506070v1.pdf",
    "category": [
      "cs.MM",
      "D.1.1; H.5.1"
    ],
    "authors": [
      "Ph. D. Yuriy A. Chashkov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0506076v1",
    "title": "Alternative security architecture for IP Telephony based on digital\n  watermarking",
    "summary": "Problems with securing IP Telephony systems, insufficient standardization and\nlack of security mechanisms emerged the need for new approaches and solutions.\nIn this paper a new, alternative security architecture for voice-systems is\npresented. It is based on digital watermarking: a new, flexible and powerful\ntechnology that is increasingly gaining more and more attention. Besides known\napplications e.g. to solve copyright protection problems, we propose to use\ndigital watermarking to secure not only transmitted audio but also signaling\nprotocol that IP Telephony is based on.",
    "published": "2005-06-18T21:41:13Z",
    "link": "http://arxiv.org/pdf/cs/0506076v1.pdf",
    "category": [
      "cs.CR",
      "cs.MM",
      "C.2.0; K.4.6"
    ],
    "authors": [
      "Wojciech Mazurczyk",
      "Zbigniew Kotulski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0508066v1",
    "title": "Can Small Museums Develop Compelling, Educational and Accessible Web\n  Resources? The Case of Accademia Carrara",
    "summary": "Due to the lack of budget, competence, personnel and time, small museums are\noften unable to develop compelling, educational and accessible web resources\nfor their permanent collections or temporary exhibitions. In an attempt to\nprove that investing in these types of resources can be very fruitful even for\nsmall institutions, we will illustrate the case of Accademia Carrara, a museum\nin Bergamo, northern Italy, which, for a current temporary exhibition on\nCezanne and Renoir's masterpieces from the Paul Guillaume collection, developed\na series of multimedia applications, including an accessible website, rich in\ncontent and educational material [www.cezannerenoir.it].",
    "published": "2005-08-13T14:46:16Z",
    "link": "http://arxiv.org/pdf/cs/0508066v1.pdf",
    "category": [
      "cs.MM",
      "cs.CY",
      "cs.DL",
      "cs.IR",
      "H.3.5; H.3.7; H.4.3; H.5.1; H.5.2; H.5.3; H.5.4; K.3.1; K.4.0"
    ],
    "authors": [
      "Silvia Filippini-Fantoni",
      "Jonathan P. Bowen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0509036v2",
    "title": "Security Problems with Improper Implementations of Improved FEA-M",
    "summary": "This paper reports security problems with improper implementations of an\nimproved version of FEA-M (fast encryption algorithm for multimedia). It is\nfound that an implementation-dependent differential chosen-plaintext attack or\nits chosen-ciphertext counterpart can reveal the secret key of the\ncryptosystem, if the involved (pseudo-)random process can be tampered (for\nexample, through a public time service). The implementation-dependent\ndifferential attack is very efficient in complexity and needs only $O(n^2)$\nchosen plaintext or ciphertext bits. In addition, this paper also points out a\nminor security problem with the selection of the session key. In real\nimplementations of the cryptosystem, these security problems should be\ncarefully avoided, or the cryptosystem has to be further enhanced to work under\nsuch weak implementations.",
    "published": "2005-09-13T10:35:52Z",
    "link": "http://arxiv.org/pdf/cs/0509036v2.pdf",
    "category": [
      "cs.CR",
      "cs.MM"
    ],
    "authors": [
      "Shujun Li",
      "Kwok-Tung Lo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0509035v2",
    "title": "Cryptanalysis of an MPEG-Video Encryption Scheme Based on Secret Huffman\n  Tables",
    "summary": "This paper studies the security of a recently-proposed MPEG-video encryption\nscheme based on secret Huffman tables. Our cryptanalysis shows that: 1) the key\nspace of the encryption scheme is not sufficiently large against\ndivide-and-conquer (DAC) attack and known-plaintext attack; 2) it is possible\nto decrypt a cipher-video with a partially-known key, thus dramatically\nreducing the complexity of the DAC brute-force attack in some cases; 3) its\nsecurity against the chosen-plaintext attack is very weak. Some experimental\nresults are included to support the cryptanalytic results with a brief discuss\non how to improve this MPEG-video encryption scheme.",
    "published": "2005-09-13T10:44:31Z",
    "link": "http://arxiv.org/pdf/cs/0509035v2.pdf",
    "category": [
      "cs.MM",
      "cs.CR"
    ],
    "authors": [
      "Shujun Li",
      "Guanrong Chen",
      "Albert Cheung",
      "Kwok-Tung Lo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/quant-ph/0510031v1",
    "title": "Image compression and entanglement",
    "summary": "The pixel values of an image can be casted into a real ket of a Hilbert space\nusing an appropriate block structured addressing. The resulting state can then\nbe rewritten in terms of its matrix product state representation in such a way\nthat quantum entanglement corresponds to classical correlations between\ndifferent coarse-grained textures. A truncation of the MPS representation is\ntantamount to a compression of the original image. The resulting algorithm can\nbe improved adding a discrete Fourier transform preprocessing and a further\nentropic lossless compression.",
    "published": "2005-10-04T14:54:22Z",
    "link": "http://arxiv.org/pdf/quant-ph/0510031v1.pdf",
    "category": [
      "quant-ph",
      "cs.MM"
    ],
    "authors": [
      "Jose I. Latorre"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0602042v1",
    "title": "New security and control protocol for VoIP based on steganography and\n  digital watermarking",
    "summary": "In this paper new security and control protocol for Voice over Internet\nProtocol (VoIP) service is presented. It is the alternative for the IETF's\n(Internet Engineering Task Force) RTCP (Real-Time Control Protocol) for\nreal-time application's traffic. Additionally this solution offers\nauthentication and integrity, it is capable of exchanging and verifying QoS and\nsecurity parameters. It is based on digital watermarking and steganography that\nis why it does not consume additional bandwidth and the data transmitted is\ninseparably bound to the voice content.",
    "published": "2006-02-10T22:49:53Z",
    "link": "http://arxiv.org/pdf/cs/0602042v1.pdf",
    "category": [
      "cs.CR",
      "cs.MM",
      "C.2.0; K.4.6"
    ],
    "authors": [
      "Wojciech Mazurczyk",
      "Zbigniew Kotulski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0603130v1",
    "title": "Digital watermarking in the singular vector domain",
    "summary": "Many current watermarking algorithms insert data in the spatial or transform\ndomains like the discrete cosine, the discrete Fourier, and the discrete\nwavelet transforms. In this paper, we present a data-hiding algorithm that\nexploits the singular value decomposition (SVD) representation of the data. We\ncompute the SVD of the host image and the watermark and embed the watermark in\nthe singular vectors of the host image. The proposed method leads to an\nimperceptible scheme for digital images, both in grey scale and color and is\nquite robust against attacks like noise and JPEG compression.",
    "published": "2006-03-31T19:36:03Z",
    "link": "http://arxiv.org/pdf/cs/0603130v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Rashmi Agarwal",
      "M. S. Santhanam"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0605002v3",
    "title": "A Hybrid Quantum Encoding Algorithm of Vector Quantization for Image\n  Compression",
    "summary": "Many classical encoding algorithms of Vector Quantization (VQ) of image\ncompression that can obtain global optimal solution have computational\ncomplexity O(N). A pure quantum VQ encoding algorithm with probability of\nsuccess near 100% has been proposed, that performs operations 45sqrt(N) times\napproximately. In this paper, a hybrid quantum VQ encoding algorithm between\nclassical method and quantum algorithm is presented. The number of its\noperations is less than sqrt(N) for most images, and it is more efficient than\nthe pure quantum algorithm.\n  Key Words: Vector Quantization, Grover's Algorithm, Image Compression,\nQuantum Algorithm",
    "published": "2006-04-30T13:35:54Z",
    "link": "http://arxiv.org/pdf/cs/0605002v3.pdf",
    "category": [
      "cs.MM",
      "cs.DS",
      "H.5.1; F.2.1; F.2.2; F.1.2"
    ],
    "authors": [
      "Chao-Yang Pang",
      "Zheng-Wei Zhou",
      "Guang-Can Guo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0606034v2",
    "title": "A constructive and unifying framework for zero-bit watermarking",
    "summary": "In the watermark detection scenario, also known as zero-bit watermarking, a\nwatermark, carrying no hidden message, is inserted in content. The watermark\ndetector checks for the presence of this particular weak signal in content. The\narticle looks at this problem from a classical detection theory point of view,\nbut with side information enabled at the embedding side. This means that the\nwatermark signal is a function of the host content. Our study is twofold. The\nfirst step is to design the best embedding function for a given detection\nfunction, and the best detection function for a given embedding function. This\nyields two conditions, which are mixed into one `fundamental' partial\ndifferential equation. It appears that many famous watermarking schemes are\nindeed solution to this `fundamental' equation. This study thus gives birth to\na constructive framework unifying solutions, so far perceived as very\ndifferent.",
    "published": "2006-06-08T13:28:07Z",
    "link": "http://arxiv.org/pdf/cs/0606034v2.pdf",
    "category": [
      "cs.MM",
      "cs.CR"
    ],
    "authors": [
      "Teddy Furon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0607077v1",
    "title": "Fault-Tolerant Real-Time Streaming with FEC thanks to Capillary\n  Multi-Path Routing",
    "summary": "Erasure resilient FEC codes in off-line packetized streaming rely on time\ndiversity. This requires unrestricted buffering time at the receiver. In\nreal-time streaming the playback buffering time must be very short. Path\ndiversity is an orthogonal strategy. However, the large number of long paths\nincreases the number of underlying links and consecutively the overall link\nfailure rate. This may increase the overall requirement in redundant FEC\npackets for combating the link failures. We introduce the Redundancy Overall\nRequirement (ROR) metric, a routing coefficient specifying the total number of\nFEC packets required for compensation of all underlying link failures. We\npresent a capillary routing algorithm for constructing layer by layer steadily\ndiversifying multi-path routing patterns. By measuring the ROR coefficients of\na dozen of routing layers on hundreds of network samples, we show that the\nnumber of required FEC packets decreases substantially when the path diversity\nis increased by the capillary routing construction algorithm.",
    "published": "2006-07-17T08:10:28Z",
    "link": "http://arxiv.org/pdf/cs/0607077v1.pdf",
    "category": [
      "cs.NI",
      "cs.MM"
    ],
    "authors": [
      "Emin Gabrielyan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0607087v1",
    "title": "Un filtre temporel crdibiliste pour la reconnaissance d'actions\n  humaines dans les vidos",
    "summary": "In the context of human action recognition in video sequences, a temporal\nbelief filter is presented. It allows to cope with human action disparity and\nlow quality videos. The whole system of action recognition is based on the\nTransferable Belief Model (TBM) proposed by P. Smets. The TBM allows to\nexplicitly model the doubt between actions. Furthermore, the TBM emphasizes the\nconflict which is exploited for action recognition. The filtering performance\nis assessed on real video sequences acquired by a moving camera and under\nseveral unknown view angles.",
    "published": "2006-07-18T08:16:37Z",
    "link": "http://arxiv.org/pdf/cs/0607087v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Emmanuel Ramasso",
      "Michle Rombaut",
      "Denis Pellerin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0608024v1",
    "title": "Cryptanalysis of an Encryption Scheme Based on Blind Source Separation",
    "summary": "Recently Lin et al. proposed a method of using the underdetermined BSS (blind\nsource separation) problem to realize image and speech encryption. In this\npaper, we give a cryptanalysis of this BSS-based encryption and point out that\nit is not secure against known/chosen-plaintext attack and chosen-ciphertext\nattack. In addition, there exist some other security defects: low sensitivity\nto part of the key and the plaintext, a ciphertext-only differential attack,\ndivide-and-conquer (DAC) attack on part of the key. We also discuss the role of\nBSS in Lin et al.'s efforts towards cryptographically secure ciphers.",
    "published": "2006-08-04T11:32:44Z",
    "link": "http://arxiv.org/pdf/cs/0608024v1.pdf",
    "category": [
      "cs.CR",
      "cs.MM"
    ],
    "authors": [
      "Shujun Li",
      "Chengqing Li",
      "Kwok-Tung Lo",
      "Guanrong Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0608119v1",
    "title": "Security Analysis of A Chaos-based Image Encryption Algorithm",
    "summary": "The security of Fridrich Image Encryption Algorithm against brute-force\nattack, statistical attack, known-plaintext attack and select-plaintext attack\nis analyzed by investigating the properties of the involved chaotic maps and\ndiffusion functions. Based on the given analyses, some means are proposed to\nstrengthen the overall performance of the focused cryptosystem.",
    "published": "2006-08-30T03:22:06Z",
    "link": "http://arxiv.org/pdf/cs/0608119v1.pdf",
    "category": [
      "cs.MM",
      "cs.CR"
    ],
    "authors": [
      "Shiguo Lian",
      "Jinsheng Sun",
      "Zhiquan Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0609131v1",
    "title": "A Fast Block Matching Algorithm for Video Motion Estimation Based on\n  Particle Swarm Optimization and Motion Prejudgment",
    "summary": "In this paper, we propose a fast 2-D block-based motion estimation algorithm\ncalled Particle Swarm Optimization - Zero-motion Prejudgment(PSO-ZMP) which\nconsists of three sequential routines: 1)Zero-motion prejudgment. The routine\naims at finding static macroblocks(MB) which do not need to perform remaining\nsearch thus reduces the computational cost; 2)Predictive image coding and 3)PSO\nmatching routine. Simulation results obtained show that the proposed PSO-ZMP\nalgorithm achieves over 10 times of computation less than Diamond Search(DS)\nand 5 times less than the recent proposed Adaptive Rood Pattern\nSearching(ARPS). Meanwhile the PSNR performances using PSO-ZMP are very close\nto that using DS and ARPS in some less-motioned sequences. While in some\nsequences containing dense and complex motion contents, the PSNR performances\nof PSO-ZMP are several dB lower than that using DS and ARPS but in an\nacceptable degree.",
    "published": "2006-09-24T09:55:57Z",
    "link": "http://arxiv.org/pdf/cs/0609131v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Ran Ren",
      "Madan mohan Manokar",
      "Yaogang Shi",
      "Baoyu Zheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0609158v1",
    "title": "A Fast Image Encryption Scheme based on Chaotic Standard Map",
    "summary": "In recent years, a variety of effective chaos-based image encryption schemes\nhave been proposed. The typical structure of these schemes has the permutation\nand the diffusion stages performed alternatively. The confusion and diffusion\neffect is solely contributed by the permutation and the diffusion stage,\nrespectively. As a result, more overall rounds than necessary are required to\nachieve a certain level of security. In this paper, we suggest to introduce\ncertain diffusion effect in the confusion stage by simple sequential\nadd-and-shift operations. The purpose is to reduce the workload of the\ntime-consuming diffusion part so that fewer overall rounds and hence a shorter\nencryption time is needed. Simulation results show that at a similar\nperformance level, the proposed cryptosystem needs less than one-third the\nencryption time of an existing cryptosystem. The effective acceleration of the\nencryption speed is thus achieved.",
    "published": "2006-09-29T07:36:29Z",
    "link": "http://arxiv.org/pdf/cs/0609158v1.pdf",
    "category": [
      "cs.CR",
      "cs.MM"
    ],
    "authors": [
      "Kwok-Wo Wong",
      "Bernie Sin-Hung Kwok",
      "Wing-Shing Law"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0610133v4",
    "title": "P2P IPTV Measurement: A Comparison Study",
    "summary": "With the success of P2P file sharing, new emerging P2P applications arise on\nthe Internet for streaming content like voice (VoIP) or live video (IPTV).\nNowadays, there are lots of works measuring P2P file sharing or P2P telephony\nsystems, but there is still no comprehensive study about P2P IPTV, whereas it\nshould be massively used in the future. During the last FIFA world cup, we\nmeasured network traffic generated by P2P IPTV applications like PPlive,\nPPstream, TVants and Sopcast. In this paper we analyze some of our results\nduring the same games for the applications. We focus on traffic statistics and\nchurn of peers within these P2P networks. Our objectives are threefold: we\npoint out the traffic generated to understand the impact they will have on the\nnetwork, we try to infer the mechanisms of such applications and highlight\ndifferences, and we give some insights about the users' behavior.",
    "published": "2006-10-23T13:55:28Z",
    "link": "http://arxiv.org/pdf/cs/0610133v4.pdf",
    "category": [
      "cs.NI",
      "cs.MM"
    ],
    "authors": [
      "Thomas Silverston",
      "Olivier Fourmaux"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0612054v1",
    "title": "Lightweight security mechanism for PSTN-VoIP cooperation",
    "summary": "In this paper we describe a new, lightweight security mechanism for PSTN-VoIP\ncooperation that is based on two information hiding techniques: digital\nwatermarking and steganography. Proposed scheme is especially suitable for\nPSTN-IP-PSTN (toll-by-passing) scenario which nowadays is very popular\napplication of IP Telephony systems. With the use of this mechanism we\nauthenticate end-to-end transmitted voice between PSTN users. Additionally we\nimprove IP part traffic security (both media stream and VoIP signalling\nmessages). Exemplary scenario is presented for SIP signalling protocol along\nwith SIP-T extension and H.248/Megaco protocol.",
    "published": "2006-12-08T22:05:21Z",
    "link": "http://arxiv.org/pdf/cs/0612054v1.pdf",
    "category": [
      "cs.CR",
      "cs.MM",
      "K.6.5; D.4.6; K.4.2"
    ],
    "authors": [
      "Wojciech Mazurczyk",
      "Zbigniew Kotulski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0612138v1",
    "title": "Accommodating Sample Size Effect on Similarity Measures in Speaker\n  Clustering",
    "summary": "We investigate the symmetric Kullback-Leibler (KL2) distance in speaker\nclustering and its unreported effects for differently-sized feature matrices.\nSpeaker data is represented as Mel Frequency Cepstral Coefficient (MFCC)\nvectors, and features are compared using the KL2 metric to form clusters of\nspeech segments for each speaker. We make two observations with respect to\nclustering based on KL2: 1.) The accuracy of clustering is strongly dependent\non the absolute lengths of the speech segments and their extracted feature\nvectors. 2.) The accuracy of the similarity measure strongly degrades with the\nlength of the shorter of the two speech segments. These effects of length can\nbe attributed to the measure of covariance used in KL2. We demonstrate an\nempirical correction of this sample-size effect that increases clustering\naccuracy. We draw parallels to two Vector Quantization-based (VQ) similarity\nmeasures, one which exhibits an equivalent effect of sample size, and the\nsecond being less influenced by it.",
    "published": "2006-12-28T06:39:55Z",
    "link": "http://arxiv.org/pdf/cs/0612138v1.pdf",
    "category": [
      "cs.SD",
      "cs.MM",
      "H.3.3; H.5.1; H.5.5"
    ],
    "authors": [
      "Alexander Haubold",
      "John R. Kender"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0612139v1",
    "title": "Alignment of Speech to Highly Imperfect Text Transcriptions",
    "summary": "We introduce a novel and inexpensive approach for the temporal alignment of\nspeech to highly imperfect transcripts from automatic speech recognition (ASR).\nTranscripts are generated for extended lecture and presentation videos, which\nin some cases feature more than 30 speakers with different accents, resulting\nin highly varying transcription qualities. In our approach we detect a subset\nof phonemes in the speech track, and align them to the sequence of phonemes\nextracted from the transcript. We report on the results for 4 speech-transcript\nsets ranging from 22 to 108 minutes. The alignment performance is promising,\nshowing a correct matching of phonemes within 10, 20, 30 second error margins\nfor more than 60%, 75%, 90% of text, respectively, on average.",
    "published": "2006-12-28T06:45:43Z",
    "link": "http://arxiv.org/pdf/cs/0612139v1.pdf",
    "category": [
      "cs.SD",
      "cs.MM",
      "H.3.1; H.5.1; H.5.5"
    ],
    "authors": [
      "Alexander Haubold",
      "John R. Kender"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0703091v1",
    "title": "Multimodal Meaning Representation for Generic Dialogue Systems\n  Architectures",
    "summary": "An unified language for the communicative acts between agents is essential\nfor the design of multi-agents architectures. Whatever the type of interaction\n(linguistic, multimodal, including particular aspects such as force feedback),\nwhatever the type of application (command dialogue, request dialogue, database\nquerying), the concepts are common and we need a generic meta-model. In order\nto tend towards task-independent systems, we need to clarify the modules\nparameterization procedures. In this paper, we focus on the characteristics of\na meta-model designed to represent meaning in linguistic and multimodal\napplications. This meta-model is called MMIL for MultiModal Interface Language,\nand has first been specified in the framework of the IST MIAMM European\nproject. What we want to test here is how relevant is MMIL for a completely\ndifferent context (a different task, a different interaction type, a different\nlinguistic domain). We detail the exploitation of MMIL in the framework of the\nIST OZONE European project, and we draw the conclusions on the role of MMIL in\nthe parameterization of task-independent dialogue managers.",
    "published": "2007-03-16T15:37:47Z",
    "link": "http://arxiv.org/pdf/cs/0703091v1.pdf",
    "category": [
      "cs.AI",
      "cs.MM"
    ],
    "authors": [
      "Frdric Landragin",
      "Alexandre Denis",
      "Annalisa Ricci",
      "Laurent Romary"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0704.3228v2",
    "title": "Characterization of P2P IPTV Traffic: Scaling Analysis",
    "summary": "P2P IPTV applications arise on the Internet and will be massively used in the\nfuture. It is expected that P2P IPTV will contribute to increase the overall\nInternet traffic. In this context, it is important to measure the impact of P2P\nIPTV on the networks and to characterize this traffic. Dur- ing the 2006 FIFA\nWorld Cup, we performed an extensive measurement campaign. We measured network\ntraffic generated by broadcasting soc- cer games by the most popular P2P IPTV\napplications, namely PPLive, PPStream, SOPCast and TVAnts. From the collected\ndata, we charac- terized the P2P IPTV traffic structure at different time\nscales by using wavelet based transform method. To the best of our knowledge,\nthis is the first work, which presents a complete multiscale analysis of the\nP2P IPTV traffic. Our results show that the scaling properties of the TCP\ntraffic present periodic behavior whereas the UDP traffic is stationary and\nlead to long- range depedency characteristics. For all the applications, the\ndownload traffic has different characteristics than the upload traffic. The\nsignaling traffic has a significant impact on the download traffic but it has\nnegligible impact on the upload. Both sides of the traffic and its granularity\nhas to be taken into account to design accurate P2P IPTV traffic models.",
    "published": "2007-04-24T16:18:13Z",
    "link": "http://arxiv.org/pdf/0704.3228v2.pdf",
    "category": [
      "cs.NI",
      "cs.MM"
    ],
    "authors": [
      "Thomas Silverston",
      "Olivier Fourmaux",
      "Kave Salamatian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.1925v1",
    "title": "Double Sided Watermark Embedding and Detection with Perceptual Analysis",
    "summary": "In our previous work, we introduced a double-sided technique that utilizes\nbut not reject the host interference. Due to its nice property of utilizing but\nnot rejecting the host interference, it has a big advantage over the host\ninterference schemes in that the perceptual analysis can be easily implemented\nfor our scheme to achieve the locally bounded maximum embedding strength. Thus,\nin this work, we detail how to implement the perceptual analysis in our\ndouble-sided schemes since the perceptual analysis is very important for\nimproving the fidelity of watermarked contents. Through the extensive\nperformance comparisons, we can further validate the performance advantage of\nour double-sided schemes.",
    "published": "2007-05-14T12:23:43Z",
    "link": "http://arxiv.org/pdf/0705.1925v1.pdf",
    "category": [
      "cs.MM",
      "cs.CR"
    ],
    "authors": [
      "Jidong Zhong",
      "Shangteng Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0706.0427v1",
    "title": "Watermark Embedding and Detection",
    "summary": "The embedder and the detector (or decoder) are the two most important\ncomponents of the digital watermarking systems. Thus in this work, we discuss\nhow to design a better embedder and detector (or decoder). I first give a\nsummary of the prospective applications of watermarking technology and major\nwatermarking schemes in the literature. My review on the literature closely\ncenters upon how the side information is exploited at both embedders and\ndetectors. In Chapter 3, I explore the optimum detector or decoder according to\na particular probability distribution of the host signals. We found that the\nperformance of both multiplicative and additive spread spectrum schemes depends\non the shape parameter of the host signals. For spread spectrum schemes, the\nperformance of the detector or the decoder is reduced by the host interference.\nThus I present a new host-interference rejection technique for the\nmultiplicative spread spectrum schemes. Its embedding rule is tailored to the\noptimum detection or decoding rule. Though the host interference rejection\nschemes enjoy a big performance gain over the traditional spread spectrum\nschemes, their drawbacks that it is difficult for them to be implemented with\nthe perceptual analysis to achieve the maximum allowable embedding level\ndiscourage their use in real scenarios. Thus, in the last chapters of this\nwork, I introduce a double-sided technique to tackle this drawback. It differs\nfrom the host interference rejection schemes in that it utilizes but does not\nreject the host interference at its embedder. The perceptual analysis can be\neasily implemented in our scheme to achieve the maximum allowable level of\nembedding strength.",
    "published": "2007-06-02T05:37:34Z",
    "link": "http://arxiv.org/pdf/0706.0427v1.pdf",
    "category": [
      "cs.MM",
      "cs.CR"
    ],
    "authors": [
      "Jidong Zhong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0706.1141v1",
    "title": "Multimedia Content Distribution in Hybrid Wireless Networks using\n  Weighted Clustering",
    "summary": "Fixed infrastructured networks naturally support centralized approaches for\ngroup management and information provisioning. Contrary to infrastructured\nnetworks, in multi-hop ad-hoc networks each node acts as a router as well as\nsender and receiver. Some applications, however, requires hierarchical\narrangements that-for practical reasons-has to be done locally and\nself-organized. An additional challenge is to deal with mobility that causes\npermanent network partitioning and re-organizations. Technically, these\nproblems can be tackled by providing additional uplinks to a backbone network,\nwhich can be used to access resources in the Internet as well as to inter-link\nmultiple ad-hoc network partitions, creating a hybrid wireless network. In this\npaper, we present a prototypically implemented hybrid wireless network system\noptimized for multimedia content distribution. To efficiently manage the ad-hoc\ncommunicating devices a weighted clustering algorithm is introduced. The\nproposed localized algorithm deals with mobility, but does not require\ngeographical information or distances.",
    "published": "2007-06-08T09:31:46Z",
    "link": "http://arxiv.org/pdf/0706.1141v1.pdf",
    "category": [
      "cs.MM",
      "cs.NI"
    ],
    "authors": [
      "Adrian Andronache",
      "Matthias R. Brust",
      "Steffen Rothkugel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0706.3076v1",
    "title": "On the Performance of Joint Fingerprint Embedding and Decryption Scheme",
    "summary": "Till now, few work has been done to analyze the performances of joint\nfingerprint embedding and decryption schemes. In this paper, the security of\nthe joint fingerprint embedding and decryption scheme proposed by Kundur et al.\nis analyzed and improved. The analyses include the security against\nunauthorized customer, the security against authorized customer, the\nrelationship between security and robustness, the relationship between\nsecu-rity and imperceptibility and the perceptual security. Based these\nanalyses, some means are proposed to strengthen the system, such as multi-key\nencryp-tion and DC coefficient encryption. The method can be used to analyze\nother JFD schemes. It is expected to provide valuable information to design JFD\nschemes.",
    "published": "2007-06-21T02:44:44Z",
    "link": "http://arxiv.org/pdf/0706.3076v1.pdf",
    "category": [
      "cs.MM",
      "cs.CR",
      "C.2.0; D.2.11; D.4.6"
    ],
    "authors": [
      "Shiguo Lian",
      "Zhongxuan Liu",
      "Zhen Ren",
      "Haila Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.0397v1",
    "title": "Robust Audio Watermarking Against the D/A and A/D conversions",
    "summary": "Audio watermarking has played an important role in multimedia security. In\nmany applications using audio watermarking, D/A and A/D conversions (denoted by\nDA/AD in this paper) are often involved. In previous works, however, the\nrobustness issue of audio watermarking against the DA/AD conversions has not\ndrawn sufficient attention yet. In our extensive investigation, it has been\nfound that the degradation of a watermarked audio signal caused by the DA/AD\nconversions manifests itself mainly in terms of wave magnitude distortion and\nlinear temporal scaling, making the watermark extraction failed. Accordingly, a\nDWT-based audio watermarking algorithm robust against the DA/AD conversions is\nproposed in this paper. To resist the magnitude distortion, the relative energy\nrelationships among different groups of the DWT coefficients in the\nlow-frequency sub-band are utilized in watermark embedding by adaptively\ncontrolling the embedding strength. Furthermore, the resynchronization is\ndesigned to cope with the linear temporal scaling. The time-frequency\nlocalization characteristics of DWT are exploited to save the computational\nload in the resynchronization. Consequently, the proposed audio watermarking\nalgorithm is robust against the DA/AD conversions, other common audio\nprocessing manipulations, and the attacks in StirMark Benchmark for Audio,\nwhich has been verified by experiments.",
    "published": "2007-07-03T11:49:03Z",
    "link": "http://arxiv.org/pdf/0707.0397v1.pdf",
    "category": [
      "cs.CR",
      "cs.MM",
      "K.4.4"
    ],
    "authors": [
      "Shijun Xiang",
      "Jiwu Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.2836v3",
    "title": "Multimedia Capacity Analysis of the IEEE 802.11e Contention-based\n  Infrastructure Basic Service Set",
    "summary": "We first propose a simple mathematical analysis framework for the Enhanced\nDistributed Channel Access (EDCA) function of the recently ratified IEEE\n802.11e standard. Our analysis considers the fact that the distributed random\naccess systems exhibit cyclic behavior. The proposed model is valid for\narbitrary assignments of AC-specific Arbitration Interframe Space (AIFS) values\nand Contention Window (CW) sizes and is the first that considers an arbitrary\ndistribution of active Access Categories (ACs) at the stations. Validating the\ntheoretical results via extensive simulations, we show that the proposed\nanalysis accurately captures the EDCA saturation performance. Next, we propose\na framework for multimedia capacity analysis of the EDCA function. We calculate\nan accurate station- and AC-specific queue utilization ratio by appropriately\nweighing the service time predictions of the cycle time model for different\nnumber of active stations. Based on the calculated queue utilization ratio, we\ndesign a simple model-based admission control scheme. We show that the proposed\ncall admission control algorithm maintains satisfactory user-perceived quality\nfor coexisting voice and video connections in an infrastructure BSS and does\nnot present over- or under-admission problems of previously proposed models in\nthe literature.",
    "published": "2007-07-19T05:16:53Z",
    "link": "http://arxiv.org/pdf/0707.2836v3.pdf",
    "category": [
      "cs.IT",
      "cs.MM",
      "math.IT"
    ],
    "authors": [
      "Inanc Inan",
      "Feyza Keceli",
      "Ender Ayanoglu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.3670v1",
    "title": "Understanding the Characteristics of Internet Short Video Sharing:\n  YouTube as a Case Study",
    "summary": "Established in 2005, YouTube has become the most successful Internet site\nproviding a new generation of short video sharing service. Today, YouTube alone\ncomprises approximately 20% of all HTTP traffic, or nearly 10% of all traffic\non the Internet. Understanding the features of YouTube and similar video\nsharing sites is thus crucial to their sustainable development and to network\ntraffic engineering. In this paper, using traces crawled in a 3-month period,\nwe present an in-depth and systematic measurement study on the characteristics\nof YouTube videos. We find that YouTube videos have noticeably different\nstatistics compared to traditional streaming videos, ranging from length and\naccess pattern, to their active life span, ratings, and comments. The series of\ndatasets also allows us to identify the growth trend of this fast evolving\nInternet site in various aspects, which has seldom been explored before. We\nalso look closely at the social networking aspect of YouTube, as this is a key\ndriving force toward its success. In particular, we find that the links to\nrelated videos generated by uploaders' choices form a small-world network. This\nsuggests that the videos have strong correlations with each other, and creates\nopportunities for developing novel caching or peer-to-peer distribution schemes\nto efficiently deliver videos to end users.",
    "published": "2007-07-25T05:39:44Z",
    "link": "http://arxiv.org/pdf/0707.3670v1.pdf",
    "category": [
      "cs.NI",
      "cs.MM"
    ],
    "authors": [
      "Xu Cheng",
      "Cameron Dale",
      "Jiangchuan Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.4524v1",
    "title": "Image Authentication Based on Neural Networks",
    "summary": "Neural network has been attracting more and more researchers since the past\ndecades. The properties, such as parameter sensitivity, random similarity,\nlearning ability, etc., make it suitable for information protection, such as\ndata encryption, data authentication, intrusion detection, etc. In this paper,\nby investigating neural networks' properties, the low-cost authentication\nmethod based on neural networks is proposed and used to authenticate images or\nvideos. The authentication method can detect whether the images or videos are\nmodified maliciously. Firstly, this chapter introduces neural networks'\nproperties, such as parameter sensitivity, random similarity, diffusion\nproperty, confusion property, one-way property, etc. Secondly, the chapter\ngives an introduction to neural network based protection methods. Thirdly, an\nimage or video authentication scheme based on neural networks is presented, and\nits performances, including security, robustness and efficiency, are analyzed.\nFinally, conclusions are drawn, and some open issues in this field are\npresented.",
    "published": "2007-07-31T02:27:10Z",
    "link": "http://arxiv.org/pdf/0707.4524v1.pdf",
    "category": [
      "cs.MM",
      "cs.NE",
      "C.1.3; E.3.x; F.1.1"
    ],
    "authors": [
      "Shiguo Lian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0708.0598v2",
    "title": "An Application of Chromatic Prototypes",
    "summary": "This paper has been withdrawn.",
    "published": "2007-08-04T02:38:19Z",
    "link": "http://arxiv.org/pdf/0708.0598v2.pdf",
    "category": [
      "cs.HC",
      "cs.MM"
    ],
    "authors": [
      "Matthew McCool"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0710.4180v1",
    "title": "A quick search method for audio signals based on a piecewise linear\n  representation of feature trajectories",
    "summary": "This paper presents a new method for a quick similarity-based search through\nlong unlabeled audio streams to detect and locate audio clips provided by\nusers. The method involves feature-dimension reduction based on a piecewise\nlinear representation of a sequential feature trajectory extracted from a long\naudio stream. Two techniques enable us to obtain a piecewise linear\nrepresentation: the dynamic segmentation of feature trajectories and the\nsegment-based Karhunen-L\\'{o}eve (KL) transform. The proposed search method\nguarantees the same search results as the search method without the proposed\nfeature-dimension reduction method in principle. Experiment results indicate\nsignificant improvements in search speed. For example the proposed method\nreduced the total search time to approximately 1/12 that of previous methods\nand detected queries in approximately 0.3 seconds from a 200-hour audio\ndatabase.",
    "published": "2007-10-23T03:06:53Z",
    "link": "http://arxiv.org/pdf/0710.4180v1.pdf",
    "category": [
      "cs.MM",
      "cs.DB"
    ],
    "authors": [
      "Akisato Kimura",
      "Kunio Kashino",
      "Takayuki Kurozumi",
      "Hiroshi Murase"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0710.4658v1",
    "title": "Compositional Memory Systems for Multimedia Communicating Tasks",
    "summary": "Conventional cache models are not suited for real-time parallel processing\nbecause tasks may flush each other's data out of the cache in an unpredictable\nmanner. In this way the system is not compositional so the overall performance\nis difficult to predict and the integration of new tasks expensive. This paper\nproposes a new method that imposes compositionality to the system?s performance\nand makes different memory hierarchy optimizations possible for multimedia\ncommunicating tasks when running on embedded multiprocessor architectures. The\nmethod is based on a cache allocation strategy that assigns sets of the unified\ncache exclusively to tasks and to the communication buffers. We also\nanalytically formulate the problem and describe a method to compute the cache\npartitioning ratio for optimizing the throughput and the consumed power. When\napplied to a multiprocessor with memory hierarchy our technique delivers also\nperformance gain. Compared to the shared cache case, for an application\nconsisting of two jpeg decoders and one edge detection algorithm 5 times less\nmisses are experienced and for an mpeg2 decoder 6.5 times less misses are\nexperienced.",
    "published": "2007-10-25T08:35:10Z",
    "link": "http://arxiv.org/pdf/0710.4658v1.pdf",
    "category": [
      "cs.AR",
      "cs.MM"
    ],
    "authors": [
      "A. M. Molnos",
      "M. J. M. Heijligers",
      "S. D. Cotofana",
      "J. T. J. Van Eijndhoven"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0710.4667v1",
    "title": "Integration, Verification and Layout of a Complex Multimedia SOC",
    "summary": "We present our experience of designing a single-chip controller for advanced\ndigital still camera from specification all the way to mass production. The\nprocess involves collaboration with camera system designer, IP vendors, EDA\nvendors, silicon wafer foundry, package and testing houses, and camera maker.\nWe also co-work with academic research groups to develop a JPEG codec IP and\nmemory BIST and SOC testing methodology. In this presentation, we cover the\nproblems encountered, our solutions, and lessons learned.",
    "published": "2007-10-25T08:44:47Z",
    "link": "http://arxiv.org/pdf/0710.4667v1.pdf",
    "category": [
      "cs.AR",
      "cs.MM"
    ],
    "authors": [
      "Chien-Liang Chen",
      "Jiing-Yuan Lin",
      "Youn-Long Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0710.4819v1",
    "title": "A High Quality/Low Computational Cost Technique for Block Matching\n  Motion Estimation",
    "summary": "Motion estimation is the most critical process in video coding systems. First\nof all, it has a definitive impact on the rate-distortion performance given by\nthe video encoder. Secondly, it is the most computationally intensive process\nwithin the encoding loop. For these reasons, the design of high-performance\nlow-cost motion estimators is a crucial task in the video compression field. An\nadaptive cost block matching (ACBM) motion estimation technique is presented in\nthis paper, featuring an excellent tradeoff between the quality of the\nreconstructed video sequences and the computational effort. Simulation results\ndemonstrate that the ACBM algorithm achieves a slight better rate-distortion\nperformance than the one given by the well-known full search algorithm block\nmatching algorithm with reductions of up to 95% in the computational load.",
    "published": "2007-10-25T12:03:15Z",
    "link": "http://arxiv.org/pdf/0710.4819v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "S. Lopez",
      "G. M. Callico",
      "J. F. Lopez",
      "R. Sarmiento"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0710.4821v1",
    "title": "Multimedia Applications of Multiprocessor Systems-on-Chips",
    "summary": "This paper surveys the characteristics of multimedia systems. Multimedia\napplications today are dominated by compression and decompression, but\nmultimedia devices must also implement many other functions such as security\nand file management. We introduce some basic concepts of multimedia algorithms\nand the larger set of functions that multimedia systems-on-chips must\nimplement.",
    "published": "2007-10-25T12:04:15Z",
    "link": "http://arxiv.org/pdf/0710.4821v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Wayne Wolf"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0710.4823v1",
    "title": "A Coprocessor for Accelerating Visual Information Processing",
    "summary": "Visual information processing will play an increasingly important role in\nfuture electronics systems. In many applications, e.g. video surveillance\ncameras, data throughput of microprocessors is not sufficient and power\nconsumption is too high. Instruction profiling on a typical test algorithm has\nshown that pixel address calculations are the dominant operations to be\noptimized. Therefore AddressLib, a structured scheme for pixel addressing was\ndeveloped, that can be accelerated by AddressEngine, a coprocessor for visual\ninformation processing. In this paper, the architectural design of\nAddressEngine is described, which in the first step supports a subset of the\nAddressLib. Dataflow and memory organization are optimized during architectural\ndesign. AddressEngine was implemented in a FPGA and was tested with MPEG-7\nGlobal Motion Estimation algorithm. Results on processing speed and circuit\ncomplexity are given and compared to a pure software implementation. The next\nstep will be the support for the full AddressLib, including segment addressing.\nAn outlook on further investigations on dynamic reconfiguration capabilities is\ngiven.",
    "published": "2007-10-25T12:04:42Z",
    "link": "http://arxiv.org/pdf/0710.4823v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "W. Stechele",
      "L. Alvado Carcel",
      "S. Herrmann",
      "J. Lidon Simon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0710.4846v1",
    "title": "An Integrated Design and Verification Methodology for Reconfigurable\n  Multimedia Systems",
    "summary": "Recently a lot of multimedia applications are emerging on portable\nappliances. They require both the flexibility of upgradeable devices\n(traditionally software based) and a powerful computing engine (typically\nhardware). In this context, programmable HW and dynamic reconfiguration allow\nnovel approaches to the migration of algorithms from SW to HW. Thus, in the\nframe of the Symbad project, we propose an industrial design flow for\nreconfigurable SoC's. The goal of Symbad consists of developing a system level\ndesign platform for hardware and software SoC systems including formal and\nsemi-formal verification techniques.",
    "published": "2007-10-25T12:24:16Z",
    "link": "http://arxiv.org/pdf/0710.4846v1.pdf",
    "category": [
      "cs.MM",
      "cs.LO"
    ],
    "authors": [
      "M. Borgatti",
      "A. Capello",
      "U. Rossi",
      "J. -L. Lambert",
      "I. Moussa",
      "F. Fummi",
      "G. Pravadelli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0710.5465v1",
    "title": "Cryptanalysis of an image encryption scheme based on a new total\n  shuffling algorithm",
    "summary": "Chaotic systems have been broadly exploited through the last two decades to\nbuild encryption methods. Recently, two new image encryption schemes have been\nproposed, where the encryption process involves a permutation operation and an\nXOR-like transformation of the shuffled pixels, which are controlled by three\nchaotic systems. This paper discusses some defects of the schemes and how to\nbreak them with a chosen-plaintext attack.",
    "published": "2007-10-29T16:00:56Z",
    "link": "http://arxiv.org/pdf/0710.5465v1.pdf",
    "category": [
      "nlin.CD",
      "cs.CR",
      "cs.MM"
    ],
    "authors": [
      "David Arroyo",
      "Chengqing Li",
      "Shujun Li",
      "Gonzalo Alvarez",
      "Wolfgang A. Halang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0711.3500v1",
    "title": "Secure Fractal Image Coding",
    "summary": "In recent work, various fractal image coding methods are reported, which\nadopt the self-similarity of images to compress the size of images. However,\ntill now, no solutions for the security of fractal encoded images have been\nprovided. In this paper, a secure fractal image coding scheme is proposed and\nevaluated, which encrypts some of the fractal parameters during fractal\nencoding, and thus, produces the encrypted and encoded image. The encrypted\nimage can only be recovered by the correct key. To keep secure and efficient,\nonly the suitable parameters are selected and encrypted through in-vestigating\nthe properties of various fractal parameters, including parameter space,\nparameter distribu-tion and parameter sensitivity. The encryption process does\nnot change the file format, keeps secure in perception, and costs little time\nor computational resources. These properties make it suitable for secure image\nencoding or transmission.",
    "published": "2007-11-22T03:53:29Z",
    "link": "http://arxiv.org/pdf/0711.3500v1.pdf",
    "category": [
      "cs.MM",
      "cs.CR",
      "C.2.0; D.2.11; D.4.6"
    ],
    "authors": [
      "Shiguo Lian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0712.3964v2",
    "title": "Cryptanalysis of an Image Encryption Scheme Based on a Compound Chaotic\n  Sequence",
    "summary": "Recently, an image encryption scheme based on a compound chaotic sequence was\nproposed. In this paper, the security of the scheme is studied and the\nfollowing problems are found: (1) a differential chosen-plaintext attack can\nbreak the scheme with only three chosen plain-images; (2) there is a number of\nweak keys and some equivalent keys for encryption; (3) the scheme is not\nsensitive to the changes of plain-images; and (4) the compound chaotic sequence\ndoes not work as a good random number resource.",
    "published": "2007-12-24T04:02:35Z",
    "link": "http://arxiv.org/pdf/0712.3964v2.pdf",
    "category": [
      "cs.CR",
      "cs.MM"
    ],
    "authors": [
      "Chengqing Li",
      "Shujun Li",
      "Guanrong Chen",
      "Wolfgang A. Halang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0801.0625v1",
    "title": "On the Robustness of the Delay-Based Fingerprint Embedding Scheme",
    "summary": "The delay-based fingerprint embedding was recently proposed to support more\nusers in secure media distribution scenario. In this embedding scheme, some\nusers are assigned the same fingerprint code with only different embedding\ndelay. The algorithm's robustness against collusion attacks is investigated.\nHowever, its robustness against common desynchronization attacks, e.g.,\ncropping and time shifting, is not considered. In this paper, desynchronization\nattacks are used to break the delay-based fingerprint embedding algorithm. To\nimprove the robustness, two means are proposed to keep the embedded fingerprint\ncodes synchronized, i.e., adding a synchronization fingerprint and adopting the\nrelative delay to detect users. Analyses and experiments are given to show the\nimprovements.",
    "published": "2008-01-04T03:15:56Z",
    "link": "http://arxiv.org/pdf/0801.0625v1.pdf",
    "category": [
      "cs.MM",
      "cs.SD",
      "D.2.11; H.5.1; H.5.5"
    ],
    "authors": [
      "Shiguo Lian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0802.3253v1",
    "title": "On the Capacity and Design of Limited Feedback Multiuser MIMO Uplinks",
    "summary": "The theory of multiple-input multiple-output (MIMO) technology has been\nwell-developed to increase fading channel capacity over single-input\nsingle-output (SISO) systems. This capacity gain can often be leveraged by\nutilizing channel state information at the transmitter and the receiver. Users\nmake use of this channel state information for transmit signal adaptation. In\nthis correspondence, we derive the capacity region for the MIMO multiple access\nchannel (MIMO MAC) when partial channel state information is available at the\ntransmitters, where we assume a synchronous MIMO multiuser uplink. The partial\nchannel state information feedback has a cardinality constraint and is fed back\nfrom the basestation to the users using a limited rate feedback channel. Using\nthis feedback information, we propose a finite codebook design method to\nmaximize sum-rate. In this correspondence, the codebook is a set of transmit\nsignal covariance matrices. We also derive the capacity region and codebook\ndesign methods in the case that the covariance matrix is rank-one (i.e.,\nbeamforming). This is motivated by the fact that beamforming is optimal in\ncertain conditions. The simulation results show that when the number of\nfeedback bits increases, the capacity also increases. Even with a small number\nof feedback bits, the performance of the proposed system is close to an optimal\nsolution with the full feedback.",
    "published": "2008-02-22T04:56:57Z",
    "link": "http://arxiv.org/pdf/0802.3253v1.pdf",
    "category": [
      "cs.IT",
      "cs.MM",
      "math.IT",
      "H.1.1"
    ],
    "authors": [
      "Il Han Kim",
      "David J. Love"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0803.0405v1",
    "title": "Multi-dimensional sparse time series: feature extraction",
    "summary": "We show an analysis of multi-dimensional time series via entropy and\nstatistical linguistic techniques. We define three markers encoding the\nbehavior of the series, after it has been translated into a multi-dimensional\nsymbolic sequence. The leading component and the trend of the series with\nrespect to a mobile window analysis result from the entropy analysis and label\nthe dynamical evolution of the series. The diversification formalizes the\ndifferentiation in the use of recurrent patterns, from a Zipf law point of\nview. These markers are the starting point of further analysis such as\nclassification or clustering of large database of multi-dimensional time\nseries, prediction of future behavior and attribution of new data. We also\npresent an application to economic data. We deal with measurements of money\ninvestments of some business companies in advertising market for different\nmedia sources.",
    "published": "2008-03-04T10:27:59Z",
    "link": "http://arxiv.org/pdf/0803.0405v1.pdf",
    "category": [
      "cs.MM",
      "cs.IR"
    ],
    "authors": [
      "Marco Franciosi",
      "Giulia Menconi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.0134v1",
    "title": "SecMon: End-to-End Quality and Security Monitoring System",
    "summary": "The Voice over Internet Protocol (VoIP) is becoming a more available and\npopular way of communicating for Internet users. This also applies to\nPeer-to-Peer (P2P) systems and merging these two have already proven to be\nsuccessful (e.g. Skype). Even the existing standards of VoIP provide an\nassurance of security and Quality of Service (QoS), however, these features are\nusually optional and supported by limited number of implementations. As a\nresult, the lack of mandatory and widely applicable QoS and security guaranties\nmakes the contemporary VoIP systems vulnerable to attacks and network\ndisturbances. In this paper we are facing these issues and propose the SecMon\nsystem, which simultaneously provides a lightweight security mechanism and\nimproves quality parameters of the call. SecMon is intended specially for VoIP\nservice over P2P networks and its main advantage is that it provides\nauthentication, data integrity services, adaptive QoS and (D)DoS attack\ndetection. Moreover, the SecMon approach represents a low-bandwidth consumption\nsolution that is transparent to the users and possesses a self-organizing\ncapability. The above-mentioned features are accomplished mainly by utilizing\ntwo information hiding techniques: digital audio watermarking and network\nsteganography. These techniques are used to create covert channels that serve\nas transport channels for lightweight QoS measurement's results. Furthermore,\nthese metrics are aggregated in a reputation system that enables best route\npath selection in the P2P network. The reputation system helps also to mitigate\n(D)DoS attacks, maximize performance and increase transmission efficiency in\nthe network.",
    "published": "2008-04-01T10:46:26Z",
    "link": "http://arxiv.org/pdf/0804.0134v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Tomasz Ciszkowski",
      "Charlott Eliasson",
      "Markus Fiedler",
      "Zbigniew Kotulski",
      "Radu Lupu",
      "Wojciech Mazurczyk"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.4865v1",
    "title": "Characterizing Video Responses in Social Networks",
    "summary": "Video sharing sites, such as YouTube, use video responses to enhance the\nsocial interactions among their users. The video response feature allows users\nto interact and converse through video, by creating a video sequence that\nbegins with an opening video and followed by video responses from other users.\nOur characterization is over 3.4 million videos and 400,000 video responses\ncollected from YouTube during a 7-day period. We first analyze the\ncharacteristics of the video responses, such as popularity, duration, and\ngeography. We then examine the social networks that emerge from the video\nresponse interactions.",
    "published": "2008-04-30T16:39:32Z",
    "link": "http://arxiv.org/pdf/0804.4865v1.pdf",
    "category": [
      "cs.MM",
      "cs.CY",
      "cs.HC",
      "J.4; H.3.5"
    ],
    "authors": [
      "Fabricio Benevenuto",
      "Fernando Duarte",
      "Tiago Rodrigues",
      "Virgilio Almeida",
      "Jussara Almeida",
      "Keith Ross"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0805.2938v2",
    "title": "Steganography of VoIP Streams",
    "summary": "The paper concerns available steganographic techniques that can be used for\ncreating covert channels for VoIP (Voice over Internet Protocol) streams. Apart\nfrom characterizing existing steganographic methods we provide new insights by\npresenting two new techniques. The first one is network steganography solution\nwhich exploits free/unused protocols' fields and is known for IP, UDP or TCP\nprotocols but has never been applied to RTP (Real-Time Transport Protocol) and\nRTCP (Real-Time Control Protocol) which are characteristic for VoIP. The second\nmethod, called LACK (Lost Audio Packets Steganography), provides hybrid\nstorage-timing covert channel by utilizing delayed audio packets. The results\nof the experiment, that was performed to estimate a total amount of data that\ncan be covertly transferred during typical VoIP conversation phase, regardless\nof steganalysis, are also included in this paper.",
    "published": "2008-05-19T20:46:38Z",
    "link": "http://arxiv.org/pdf/0805.2938v2.pdf",
    "category": [
      "cs.MM",
      "cs.CR"
    ],
    "authors": [
      "Wojciech Mazurczyk",
      "Krzysztof Szczypiorski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0805.3538v1",
    "title": "Covert Channels in SIP for VoIP signalling",
    "summary": "In this paper, we evaluate available steganographic techniques for SIP\n(Session Initiation Protocol) that can be used for creating covert channels\nduring signaling phase of VoIP (Voice over IP) call. Apart from characterizing\nexisting steganographic methods we provide new insights by introducing new\ntechniques. We also estimate amount of data that can be transferred in\nsignalling messages for typical IP telephony call.",
    "published": "2008-05-22T20:43:38Z",
    "link": "http://arxiv.org/pdf/0805.3538v1.pdf",
    "category": [
      "cs.MM",
      "cs.CR"
    ],
    "authors": [
      "Wojciech Mazurczyk",
      "Krzysztof Szczypiorski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0806.1543v1",
    "title": "On the Superdistribution of Digital Goods",
    "summary": "Business models involving buyers of digital goods in the distribution process\nare called superdistribution schemes. We review the state-of-the art of\nresearch and application of superdistribution and propose systematic approach\nto market mechanisms using super-distribution and technical system\narchitectures supporting it. The limiting conditions on such markets are of\neconomic, legal, technical, and psychological nature.",
    "published": "2008-06-09T22:03:40Z",
    "link": "http://arxiv.org/pdf/0806.1543v1.pdf",
    "category": [
      "cs.MM",
      "cs.CR",
      "cs.CY"
    ],
    "authors": [
      "Andreas U. Schmidt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0806.4293v1",
    "title": "Scalar Quantization for Audio Data Coding",
    "summary": "This paper is concerned with scalar quantization of transform coefficients in\nan audio codec. The generalized Gaussian distribution (GGD) is used as an\napproximation of one-dimensional probability density function for transform\ncoefficients obtained by modulated lapped transform (MLT) or modified cosine\ntransform (MDCT) filterbank. The rationale of the model is provided in\ncomparison with theoretically achievable rate-distortion function. The\nrate-distortion function computed for the random sequence obtained from a real\nsequence of samples from a large database is compared with that computed for\nrandom sequence obtained by a GGD random generator. A simple algorithm of\nconstructing the Extended Zero Zone (EZZ) quantizer is proposed. Simulation\nresults show that the EZZ quantizer yields a negligible loss in terms of coding\nefficiency compared to optimal scalar quantizers. Furthermore, we describe an\nadaptive version of the EZZ quantizer which works efficiently with low bitrate\nrequirements for transmitting side information",
    "published": "2008-06-26T12:19:27Z",
    "link": "http://arxiv.org/pdf/0806.4293v1.pdf",
    "category": [
      "cs.MM",
      "cs.IT",
      "math.IT"
    ],
    "authors": [
      "Boris D. Kudryashov",
      "Anton V. Porov",
      "Eunmi L. Oh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0807.2328v1",
    "title": "Avatar Mobility in Networked Virtual Environments: Measurements,\n  Analysis, and Implications",
    "summary": "We collected mobility traces of 84,208 avatars spanning 22 regions over two\nmonths in Second Life, a popular networked virtual environment. We analyzed the\ntraces to characterize the dynamics of the avatars mobility and behavior, both\ntemporally and spatially. We discuss the implications of the our findings to\nthe design of peer-to-peer networked virtual environments, interest management,\nmobility modeling of avatars, server load balancing and zone partitioning,\nclient-side caching, and prefetching.",
    "published": "2008-07-15T09:51:46Z",
    "link": "http://arxiv.org/pdf/0807.2328v1.pdf",
    "category": [
      "cs.NI",
      "cs.MM",
      "H.5.1; C.2.4"
    ],
    "authors": [
      "Huiguang Liang",
      "Ian Tay",
      "Ming Feng Neo",
      "Wei Tsang Ooi",
      "Mehul Motani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0808.0309v1",
    "title": "A Reliable SVD based Watermarking Schem",
    "summary": "We propose a novel scheme for watermarking of digital images based on\nsingular value decomposition (SVD), which makes use of the fact that the SVD\nsubspace preserves significant amount of information of an image, as compared\nto its singular value matrix, Zhang and Li (2005). The principal components of\nthe watermark are embedded in the original image, leaving the detector with a\ncomplimentary set of singular vectors for watermark extraction. The above step\ninvariably ensures that watermark extraction from the embedded watermark image,\nusing a modified matrix, is not possible, thereby removing a major drawback of\nan earlier proposed algorithm by Liu and Tan (2002).",
    "published": "2008-08-03T10:17:03Z",
    "link": "http://arxiv.org/pdf/0808.0309v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Chirag Jain",
      "Siddharth Arora",
      "Prasanta K. Panigrahi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0809.0524v1",
    "title": "Computer Art in the Former Soviet Bloc",
    "summary": "Documents early computer art in the Soviet bloc and describes Marxist art\ntheory.",
    "published": "2008-09-02T21:48:28Z",
    "link": "http://arxiv.org/pdf/0809.0524v1.pdf",
    "category": [
      "cs.MM",
      "cs.CY",
      "J.5"
    ],
    "authors": [
      "Eric Engle"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0809.3485v1",
    "title": "A First Step to Convolutive Sparse Representation",
    "summary": "In this paper an extension of the sparse decomposition problem is considered\nand an algorithm for solving it is presented. In this extension, it is known\nthat one of the shifted versions of a signal s (not necessarily the original\nsignal itself) has a sparse representation on an overcomplete dictionary, and\nwe are looking for the sparsest representation among the representations of all\nthe shifted versions of s. Then, the proposed algorithm finds simultaneously\nthe amount of the required shift, and the sparse representation. Experimental\nresults emphasize on the performance of our algorithm.",
    "published": "2008-09-20T05:52:47Z",
    "link": "http://arxiv.org/pdf/0809.3485v1.pdf",
    "category": [
      "cs.MM",
      "cs.OH"
    ],
    "authors": [
      "Hamed Firouzi",
      "Massoud Babaie-Zadeh",
      "Aria Ghasemian",
      "Christian Jutten"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0809.5154v1",
    "title": "An Export Architecture for a Multimedia Authoring Environment",
    "summary": "In this paper, we propose an export architecture that provides a clear\nseparation of authoring services from publication services. We illustrate this\narchitecture with the LimSee3 authoring tool and several standard publication\nformats: Timesheets, SMIL, and XHTML.",
    "published": "2008-09-30T09:56:35Z",
    "link": "http://arxiv.org/pdf/0809.5154v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Jan Mikc",
      "Ccile Roisin",
      "Bao Le Duc"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0810.2063v1",
    "title": "Initial Offset Placement in p2p Live Streaming Systems",
    "summary": "Initial offset placement in p2p streaming systems is studied in this paper.\nProportional placement (PP) scheme is proposed. In this scheme, peer places the\ninitial offset as the offset reported by other reference peer with a shift\nproportional to the buffer width or offset lag of this reference peer. This\nwill introduce a stable placement that supports larger buffer width for peers\nand small buffer width for tracker. Real deployed placement method in PPLive is\nstudied through measurement. It shows that, instead of based on offset lag, the\nplacement is based on buffer width of the reference peer to facilitate the\ninitial chunk fetching. We will prove that, such a PP scheme may not be stable\nunder arbitrary buffer occupation in the reference peer. The required average\nbuffer width then is derived. A simple good peer selection mechanism to check\nthe buffer occupation of reference peer is proposed for a stable PP scheme\nbased on buffer width",
    "published": "2008-10-12T00:15:27Z",
    "link": "http://arxiv.org/pdf/0810.2063v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Chunxi Li",
      "Changjia Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0811.0582v1",
    "title": "Optimization of automatically generated multi-core code for the LTE\n  RACH-PD algorithm",
    "summary": "Embedded real-time applications in communication systems require high\nprocessing power. Manual scheduling devel-oped for single-processor\napplications is not suited to multi-core architectures. The Algorithm\nArchitecture Matching (AAM) methodology optimizes static application\nimplementation on multi-core architectures. The Random Access Channel Preamble\nDetection (RACH-PD) is an algorithm for non-synchronized access of Long Term\nEvolu-tion (LTE) wireless networks. LTE aims to improve the spectral efficiency\nof the next generation cellular system. This paper de-scribes a complete\nmethodology for implementing the RACH-PD. AAM prototyping is applied to the\nRACH-PD which is modelled as a Synchronous DataFlow graph (SDF). An efficient\nimplemen-tation of the algorithm onto a multi-core DSP, the TI C6487, is then\nexplained. Benchmarks for the solution are given.",
    "published": "2008-11-04T19:36:16Z",
    "link": "http://arxiv.org/pdf/0811.0582v1.pdf",
    "category": [
      "cs.MM",
      "cs.DC"
    ],
    "authors": [
      "Maxime Pelcat",
      "Slaheddine Aridhi",
      "Jean Franois Nezan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0811.1959v1",
    "title": "Characterization and collection of information from heterogeneous\n  multimedia sources with users' parameters for decision support",
    "summary": "No single information source can be good enough to satisfy the divergent and\ndynamic needs of users all the time. Integrating information from divergent\nsources can be a solution to deficiencies in information content. We present\nhow Information from multimedia document can be collected based on associating\na generic database to a federated database. Information collected in this way\nis brought into relevance by integrating the parameters of usage and user's\nparameter for decision making. We identified seven different classifications of\nmultimedia document.",
    "published": "2008-11-12T20:10:00Z",
    "link": "http://arxiv.org/pdf/0811.1959v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Charles A. B. Robert"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0811.2868v1",
    "title": "Approximate Sparse Decomposition Based on Smoothed L0-Norm",
    "summary": "In this paper, we propose a method to address the problem of source\nestimation for Sparse Component Analysis (SCA) in the presence of additive\nnoise. Our method is a generalization of a recently proposed method (SL0),\nwhich has the advantage of directly minimizing the L0-norm instead of L1-norm,\nwhile being very fast. SL0 is based on minimization of the smoothed L0-norm\nsubject to As=x. In order to better estimate the source vector for noisy\nmixtures, we suggest then to remove the constraint As=x, by relaxing exact\nequality to an approximation (we call our method Smoothed L0-norm Denoising or\nSL0DN). The final result can then be obtained by minimization of a proper\nlinear combination of the smoothed L0-norm and a cost function for the\napproximation. Experimental results emphasize on the significant enhancement of\nthe modified method in noisy cases.",
    "published": "2008-11-18T09:14:18Z",
    "link": "http://arxiv.org/pdf/0811.2868v1.pdf",
    "category": [
      "cs.MM",
      "cs.IT",
      "math.IT"
    ],
    "authors": [
      "Hamed Firouzi",
      "Masoud Farivar",
      "Massoud Babaie-Zadeh",
      "Christian Jutten"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0811.4138v1",
    "title": "LACK - a VoIP Steganographic Method",
    "summary": "The paper presents a new steganographic method called LACK (Lost Audio\nPaCKets Steganography) which is intended mainly for VoIP. The method is\npresented in a broader context of network steganography and of VoIP\nsteganography in particular. The analytical results presented in the paper\nconcern the influence of LACK's hidden data insertion procedure on the method's\nimpact on quality of voice transmission and its resistance to steganalysis.",
    "published": "2008-11-25T17:25:13Z",
    "link": "http://arxiv.org/pdf/0811.4138v1.pdf",
    "category": [
      "cs.CR",
      "cs.MM"
    ],
    "authors": [
      "Wojciech Mazurczyk",
      "Jozef Lubacz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0811.4697v1",
    "title": "Informed stego-systems in active warden context: statistical\n  undetectability and capacity",
    "summary": "Several authors have studied stego-systems based on Costa scheme, but just a\nfew ones gave both theoretical and experimental justifications of these schemes\nperformance in an active warden context. We provide in this paper a\nsteganographic and comparative study of three informed stego-systems in active\nwarden context: scalar Costa scheme, trellis-coded quantization and spread\ntransform scalar Costa scheme. By leading on analytical formulations and on\nexperimental evaluations, we show the advantages and limits of each scheme in\nterm of statistical undetectability and capacity in the case of active warden.\nSuch as the undetectability is given by the distance between the stego-signal\nand the cover distance. It is measured by the Kullback-Leibler distance.",
    "published": "2008-11-28T12:04:51Z",
    "link": "http://arxiv.org/pdf/0811.4697v1.pdf",
    "category": [
      "cs.IT",
      "cs.MM",
      "math.IT"
    ],
    "authors": [
      "Sofiane Braci",
      "Claude Delpha",
      "Rmy Boyer",
      "Gatan Le Guelvouit"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0811.4702v1",
    "title": "Information-theoretic resolution of perceptual WSS watermarking of non\n  i.i.d. Gaussian signals",
    "summary": "The theoretical foundations of data hiding have been revealed by formulating\nthe problem as message communication over a noisy channel. We revisit the\nproblem in light of a more general characterization of the watermark channel\nand of weighted distortion measures. Considering spread spectrum based\ninformation hiding, we release the usual assumption of an i.i.d. cover signal.\nThe game-theoretic resolution of the problem reveals a generalized\ncharacterization of optimum attacks. The paper then derives closed-form\nexpressions for the different parameters exhibiting a practical embedding and\nextraction technique.",
    "published": "2008-11-28T12:41:23Z",
    "link": "http://arxiv.org/pdf/0811.4702v1.pdf",
    "category": [
      "cs.IT",
      "cs.MM",
      "math.IT"
    ],
    "authors": [
      "Stphane Pateux",
      "Gatan Le Guelvouit",
      "Christine Guillemot"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0811.4700v1",
    "title": "Trellis-coded quantization for public-key steganography",
    "summary": "This paper deals with public-key steganography in the presence of a passive\nwarden. The aim is to hide secret messages within cover-documents without\nmaking the warden suspicious, and without any preliminar secret key sharing.\nWhereas a practical attempt has been already done to provide a solution to this\nproblem, it suffers of poor flexibility (since embedding and decoding steps\nhighly depend on cover-signals statistics) and of little capacity compared to\nrecent data hiding techniques. Using the same framework, this paper explores\nthe use of trellis-coded quantization techniques (TCQ and turbo TCQ) to design\na more efficient public-key scheme. Experiments on audio signals show great\nimprovements considering Cachin's security criterion.",
    "published": "2008-11-28T16:07:33Z",
    "link": "http://arxiv.org/pdf/0811.4700v1.pdf",
    "category": [
      "cs.MM",
      "cs.IT",
      "math.IT"
    ],
    "authors": [
      "Gatan Le Guelvouit"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0811.4483v1",
    "title": "Wide spread spectrum watermarking with side information and interference\n  cancellation",
    "summary": "Nowadays, a popular method used for additive watermarking is wide spread\nspectrum. It consists in adding a spread signal into the host document. This\nsignal is obtained by the sum of a set of carrier vectors, which are modulated\nby the bits to be embedded. To extract these embedded bits, weighted\ncorrelations between the watermarked document and the carriers are computed.\nUnfortunately, even without any attack, the obtained set of bits can be\ncorrupted due to the interference with the host signal (host interference) and\nalso due to the interference with the others carriers (inter-symbols\ninterference (ISI) due to the non-orthogonality of the carriers). Some recent\nwatermarking algorithms deal with host interference using side informed\nmethods, but inter-symbols interference problem is still open. In this paper,\nwe deal with interference cancellation methods, and we propose to consider ISI\nas side information and to integrate it into the host signal. This leads to a\ngreat improvement of extraction performance in term of signal-to-noise ratio\nand/or watermark robustness.",
    "published": "2008-11-28T16:28:59Z",
    "link": "http://arxiv.org/pdf/0811.4483v1.pdf",
    "category": [
      "cs.MM",
      "cs.IT",
      "math.IT"
    ],
    "authors": [
      "Gatan Le Guelvouit",
      "Stphane Pateux"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0811.4681v1",
    "title": "The Good, the Bad, and the Ugly: three different approaches to break\n  their watermarking system",
    "summary": "The Good is Blondie, a wandering gunman with a strong personal sense of\nhonor. The Bad is Angel Eyes, a sadistic hitman who always hits his mark. The\nUgly is Tuco, a Mexican bandit who's always only looking out for himself.\nAgainst the backdrop of the BOWS contest, they search for a watermark in gold\nburied in three images. Each knows only a portion of the gold's exact location,\nso for the moment they're dependent on each other. However, none are\nparticularly inclined to share...",
    "published": "2008-11-28T16:31:12Z",
    "link": "http://arxiv.org/pdf/0811.4681v1.pdf",
    "category": [
      "cs.GR",
      "cs.MM"
    ],
    "authors": [
      "Gatan Le Guelvouit",
      "Teddy Furon",
      "Franois Cayre"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0811.4672v1",
    "title": "Fast and Quality-Guaranteed Data Streaming in Resource-Constrained\n  Sensor Networks",
    "summary": "In many emerging applications, data streams are monitored in a network\nenvironment. Due to limited communication bandwidth and other resource\nconstraints, a critical and practical demand is to online compress data streams\ncontinuously with quality guarantee. Although many data compression and digital\nsignal processing methods have been developed to reduce data volume, their\nsuper-linear time and more-than-constant space complexity prevents them from\nbeing applied directly on data streams, particularly over resource-constrained\nsensor networks. In this paper, we tackle the problem of online quality\nguaranteed compression of data streams using fast linear approximation (i.e.,\nusing line segments to approximate a time series). Technically, we address two\nversions of the problem which explore quality guarantees in different forms. We\ndevelop online algorithms with linear time complexity and constant cost in\nspace. Our algorithms are optimal in the sense they generate the minimum number\nof segments that approximate a time series with the required quality guarantee.\nTo meet the resource constraints in sensor networks, we also develop a fast\nalgorithm which creates connecting segments with very simple computation. The\nlow cost nature of our methods leads to a unique edge on the applications of\nmassive and fast streaming environment, low bandwidth networks, and heavily\nconstrained nodes in computational power. We implement and evaluate our methods\nin the application of an acoustic wireless sensor network.",
    "published": "2008-11-28T20:59:55Z",
    "link": "http://arxiv.org/pdf/0811.4672v1.pdf",
    "category": [
      "cs.DS",
      "cs.MM",
      "C.3; G.1.2"
    ],
    "authors": [
      "Emad Soroush",
      "Kui Wu",
      "Jian Pei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0812.0759v1",
    "title": "A new Contrast Based Image Fusion using Wavelet Packets",
    "summary": "Image Fusion, a technique which combines complimentary information from\ndifferent images of the same scene so that the fused image is more suitable for\nsegmentation, feature extraction, object recognition and Human Visual System.\nIn this paper, a simple yet efficient algorithm is presented based on contrast\nusing wavelet packet decomposition. First, all the source images are decomposed\ninto low and high frequency sub-bands and then fusion of high frequency\nsub-bands is done by the means of Directive Contrast. Now, inverse wavelet\npacket transform is performed to reconstruct the fused image. The performance\nof the algorithm is carried out by the comparison made between proposed and\nexisting algorithm.",
    "published": "2008-12-03T17:29:19Z",
    "link": "http://arxiv.org/pdf/0812.0759v1.pdf",
    "category": [
      "cs.IT",
      "cs.MM",
      "math.IT"
    ],
    "authors": [
      "R. Balasubramanian",
      "Gaurav Bhatnagar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0812.1244v1",
    "title": "Decomposition Principles and Online Learning in Cross-Layer Optimization\n  for Delay-Sensitive Applications",
    "summary": "In this paper, we propose a general cross-layer optimization framework in\nwhich we explicitly consider both the heterogeneous and dynamically changing\ncharacteristics of delay-sensitive applications and the underlying time-varying\nnetwork conditions. We consider both the independently decodable data units\n(DUs, e.g. packets) and the interdependent DUs whose dependencies are captured\nby a directed acyclic graph (DAG). We first formulate the cross-layer design as\na non-linear constrained optimization problem by assuming complete knowledge of\nthe application characteristics and the underlying network conditions. The\nconstrained cross-layer optimization is decomposed into several cross-layer\noptimization subproblems for each DU and two master problems. The proposed\ndecomposition method determines the necessary message exchanges between layers\nfor achieving the optimal cross-layer solution. However, the attributes (e.g.\ndistortion impact, delay deadline etc) of future DUs as well as the network\nconditions are often unknown in the considered real-time applications. The\nimpact of current cross-layer actions on the future DUs can be characterized by\na state-value function in the Markov decision process (MDP) framework. Based on\nthe dynamic programming solution to the MDP, we develop a low-complexity\ncross-layer optimization algorithm using online learning for each DU\ntransmission. This online algorithm can be implemented in real-time in order to\ncope with unknown source characteristics, network dynamics and resource\nconstraints. Our numerical results demonstrate the efficiency of the proposed\nonline algorithm.",
    "published": "2008-12-05T23:14:41Z",
    "link": "http://arxiv.org/pdf/0812.1244v1.pdf",
    "category": [
      "cs.MM",
      "cs.LG"
    ],
    "authors": [
      "Fangwen Fu",
      "Mihaela van der Schaar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0812.2405v1",
    "title": "A New Trend in Optimization on Multi Overcomplete Dictionary toward\n  Inpainting",
    "summary": "Recently, great attention was intended toward overcomplete dictionaries and\nthe sparse representations they can provide. In a wide variety of signal\nprocessing problems, sparsity serves a crucial property leading to high\nperformance. Inpainting, the process of reconstructing lost or deteriorated\nparts of images or videos, is an interesting application which can be handled\nby suitably decomposition of an image through combination of overcomplete\ndictionaries. This paper addresses a novel technique of such a decomposition\nand investigate that through inpainting of images. Simulations are presented to\ndemonstrate the validation of our approach.",
    "published": "2008-12-12T15:56:42Z",
    "link": "http://arxiv.org/pdf/0812.2405v1.pdf",
    "category": [
      "cs.MM",
      "cs.AI"
    ],
    "authors": [
      "SeyyedMajid Valiollahzadeh",
      "Mohammad Nazari",
      "Massoud Babaie-Zadeh",
      "Christian Jutten"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0812.2411v1",
    "title": "Probabilistic SVM/GMM Classifier for Speaker-Independent Vowel\n  Recognition in Continues Speech",
    "summary": "In this paper, we discuss the issues in automatic recognition of vowels in\nPersian language. The present work focuses on new statistical method of\nrecognition of vowels as a basic unit of syllables. First we describe a vowel\ndetection system then briefly discuss how the detected vowels can feed to\nrecognition unit. According to pattern recognition, Support Vector Machines\n(SVM) as a discriminative classifier and Gaussian mixture model (GMM) as a\ngenerative model classifier are two most popular techniques. Current\nstate-ofthe- art systems try to combine them together for achieving more power\nof classification and improving the performance of the recognition systems. The\nmain idea of the study is to combine probabilistic SVM and traditional GMM\npattern classification with some characteristic of speech like band-pass energy\nto achieve better classification rate. This idea has been analytically\nformulated and tested on a FarsDat based vowel recognition system. The results\nshow inconceivable increases in recognition accuracy. The tests have been\ncarried out by various proposed vowel recognition algorithms and the results\nhave been compared.",
    "published": "2008-12-12T16:08:04Z",
    "link": "http://arxiv.org/pdf/0812.2411v1.pdf",
    "category": [
      "cs.MM",
      "cs.AI"
    ],
    "authors": [
      "Mohammad Nazari",
      "Abolghasem Sayadiyan",
      "SeyedMajid Valiollahzadeh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0812.2529v1",
    "title": "Kalinahia: Considering Quality of Service to Design and Execute\n  Distributed Multimedia Applications",
    "summary": "One of the current challenges of Information Systems is to ensure\nsemi-structured data transmission, such as multimedia data, in a distributed\nand pervasive environment. Information Sytems must then guarantee users a\nquality of service ensuring data accessibility whatever the hardware and\nnetwork conditions may be. They must also guarantee information coherence and\nparticularly intelligibility that imposes a personalization of the service.\nWithin this framework, we propose a design method based on original models of\nmultimedia applications and quality of service. We also define a supervision\nplatform Kalinahia using a user centered heuristic allowing us to define at any\nmoment which configuration of software components constitutes the best answers\nto users' wishes in terms of service.",
    "published": "2008-12-13T07:46:52Z",
    "link": "http://arxiv.org/pdf/0812.2529v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Sophie Laplace",
      "Marc Dalmau",
      "Philippe Roose"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0812.2988v1",
    "title": "The Korrontea Data Modeling",
    "summary": "Needs of multimedia systems evolved due to the evolution of their\narchitecture which is now distributed into heterogeneous contexts. A critical\nissue lies in the fact that they handle, process, and transmit multimedia data.\nThis data integrates several properties which should be considered since it\nholds a considerable part of its semantics, for instance the lips\nsynchronization in a video. In this paper, we focus on the definition of a\nmodel as a basic abstraction for describing and modeling media in multimedia\nsystems by taking into account their properties. This model will be used in\nsoftware architecture in order to handle data in efficient way. The provided\nmodel is an interesting solution for the integration of media into\napplications; we propose to consider and to handle them in a uniform way. This\nmodel is proposed with synchronization policies to ensure synchronous transport\nof media. Therefore, we use it in a component model that we develop for the\ndesign and deployment of distributed multimedia systems.",
    "published": "2008-12-16T07:46:49Z",
    "link": "http://arxiv.org/pdf/0812.2988v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Emmanuel Bouix",
      "Philippe Roose",
      "Marc Dalmau"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0812.2989v1",
    "title": "Heterogeneous component interactions: Sensors integration into\n  multimedia applications",
    "summary": "Resource-constrained embedded and mobile devices are becoming increasingly\ncommon. Since few years, some mobile and ubiquitous devices such as wireless\nsensor, able to be aware of their physical environment, appeared. Such devices\nenable proposing applications which adapt to user's need according the context\nevolution. It implies the collaboration of sensors and software components\nwhich differ on their nature and their communication mechanisms. This paper\nproposes a unified component model in order to easily design applications based\non software components and sensors without taking care of their nature. Then it\npresents a state of the art of communication problems linked to heterogeneous\ncomponents and proposes an interaction mechanism which ensures information\nexchanges between wireless sensors and software components.",
    "published": "2008-12-16T07:47:22Z",
    "link": "http://arxiv.org/pdf/0812.2989v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Christine Louberry",
      "Philippe Roose",
      "Marc Dalmau"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0901.0065v1",
    "title": "Exact Histogram Specification Optimized for Structural Similarity",
    "summary": "An exact histogram specification (EHS) method modifies its input image to\nhave a specified histogram. Applications of EHS include image (contrast)\nenhancement (e.g., by histogram equalization) and histogram watermarking.\nPerforming EHS on an image, however, reduces its visual quality. Starting from\nthe output of a generic EHS method, we maximize the structural similarity index\n(SSIM) between the original image (before EHS) and the result of EHS\niteratively. Essential in this process is the computationally simple and\naccurate formula we derive for SSIM gradient. As it is based on gradient\nascent, the proposed EHS always converges. Experimental results confirm that\nwhile obtaining the histogram exactly as specified, the proposed method\ninvariably outperforms the existing methods in terms of visual quality of the\nresult. The computational complexity of the proposed method is shown to be of\nthe same order as that of the existing methods.\n  Index terms: histogram modification, histogram equalization, optimization for\nperceptual visual quality, structural similarity gradient ascent, histogram\nwatermarking, contrast enhancement.",
    "published": "2008-12-31T06:13:39Z",
    "link": "http://arxiv.org/pdf/0901.0065v1.pdf",
    "category": [
      "cs.CV",
      "cs.MM"
    ],
    "authors": [
      "Alireza Avanaki"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0901.1407v1",
    "title": "Condition for Energy Efficient Watermarking with Random Vector Model\n  without WSS Assumption",
    "summary": "Energy efficient watermarking preserves the watermark energy after linear\nattack as much as possible. We consider in this letter non-stationary signal\nmodels and derive conditions for energy efficient watermarking under random\nvector model without WSS assumption. We find that the covariance matrix of the\nenergy efficient watermark should be proportional to host covariance matrix to\nbest resist the optimal linear removal attacks. In WSS process our result\nreduces to the well known power spectrum condition. Intuitive geometric\ninterpretation of the results are also discussed which in turn also provide\nmore simpler proof of the main results.",
    "published": "2009-01-11T02:25:17Z",
    "link": "http://arxiv.org/pdf/0901.1407v1.pdf",
    "category": [
      "cs.MM",
      "cs.CR"
    ],
    "authors": [
      "Bin Yan",
      "Zheming Lu",
      "Yinjing Guo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0902.0221v2",
    "title": "Over-enhancement Reduction in Local Histogram Equalization using its\n  Degrees of Freedom",
    "summary": "A well-known issue of local (adaptive) histogram equalization (LHE) is\nover-enhancement (i.e., generation of spurious details) in homogenous areas of\nthe image. In this paper, we show that the LHE problem has many solutions due\nto the ambiguity in ranking pixels with the same intensity. The LHE solution\nspace can be searched for the images having the maximum PSNR or structural\nsimilarity (SSIM) with the input image. As compared to the results of the prior\nart, these solutions are more similar to the input image while offering the\nsame local contrast.\n  Index Terms: histogram modification or specification, contrast enhancement",
    "published": "2009-02-02T10:41:53Z",
    "link": "http://arxiv.org/pdf/0902.0221v2.pdf",
    "category": [
      "cs.CV",
      "cs.MM"
    ],
    "authors": [
      "Alireza Avanaki"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0902.1394v2",
    "title": "Fundamental delay bounds in peer-to-peer chunk-based real-time streaming\n  systems",
    "summary": "This paper addresses the following foundational question: what is the maximum\ntheoretical delay performance achievable by an overlay peer-to-peer streaming\nsystem where the streamed content is subdivided into chunks? As shown in this\npaper, when posed for chunk-based systems, and as a consequence of the\nstore-and-forward way in which chunks are delivered across the network, this\nquestion has a fundamentally different answer with respect to the case of\nsystems where the streamed content is distributed through one or more flows\n(sub-streams). To circumvent the complexity emerging when directly dealing with\ndelay, we express performance in term of a convenient metric, called \"stream\ndiffusion metric\". We show that it is directly related to the end-to-end\nminimum delay achievable in a P2P streaming network. In a homogeneous scenario,\nwe derive a performance bound for such metric, and we show how this bound\nrelates to two fundamental parameters: the upload bandwidth available at each\nnode, and the number of neighbors a node may deliver chunks to. In this bound,\nk-step Fibonacci sequences do emerge, and appear to set the fundamental laws\nthat characterize the optimal operation of chunk-based systems.",
    "published": "2009-02-09T10:05:48Z",
    "link": "http://arxiv.org/pdf/0902.1394v2.pdf",
    "category": [
      "cs.PF",
      "cs.MM"
    ],
    "authors": [
      "Giuseppe Bianchi",
      "Nicola Blefari Melazzi",
      "Lorenzo Bracciale",
      "Francesca Lo Piccolo",
      "Stefano Salsano"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0902.2187v1",
    "title": "A Standalone Markerless 3D Tracker for Handheld Augmented Reality",
    "summary": "This paper presents an implementation of a markerless tracking technique\ntargeted to the Windows Mobile Pocket PC platform. The primary aim of this work\nis to allow the development of standalone augmented reality applications for\nhandheld devices based on natural feature tracking. In order to achieve this\ngoal, a subset of two computer vision libraries was ported to the Pocket PC\nplatform. They were also adapted to use fixed point math, with the purpose of\nimproving the overall performance of the routines. The port of these libraries\nopens up the possibility of having other computer vision tasks being executed\non mobile platforms. A model based tracking approach that relies on edge\ninformation was adopted. Since it does not require a high processing power, it\nis suitable for constrained devices such as handhelds. The OpenGL ES graphics\nlibrary was used to perform computer vision tasks, taking advantage of existing\ngraphics hardware acceleration. An augmented reality application was created\nusing the implemented technique and evaluations were done regarding tracking\nperformance and accuracy",
    "published": "2009-02-12T18:25:13Z",
    "link": "http://arxiv.org/pdf/0902.2187v1.pdf",
    "category": [
      "cs.CV",
      "cs.GR",
      "cs.MM"
    ],
    "authors": [
      "Joao Paulo Lima",
      "Veronica Teichrieb",
      "Judith Kelner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0902.2953v1",
    "title": "ImageSpace: An Environment for Image Ontology Management",
    "summary": "More and more researchers have realized that ontologies will play a critical\nrole in the development of the Semantic Web, the next generation Web in which\ncontent is not only consumable by humans, but also by software agents. The\ndevelopment of tools to support ontology management including creation,\nvisualization, annotation, database storage, and retrieval is thus extremely\nimportant. We have developed ImageSpace, an image ontology creation and\nannotation tool that features (1) full support for the standard web ontology\nlanguage DAML+OIL; (2) image ontology creation, visualization, image annotation\nand display in one integrated framework; (3) ontology consistency assurance;\nand (4) storing ontologies and annotations in relational databases. It is\nexpected that the availability of such a tool will greatly facilitate the\ncreation of image repositories as islands of the Semantic Web.",
    "published": "2009-02-17T17:28:25Z",
    "link": "http://arxiv.org/pdf/0902.2953v1.pdf",
    "category": [
      "cs.DL",
      "cs.DB",
      "cs.MM",
      "cs.SE"
    ],
    "authors": [
      "Shiyong Lu",
      "Rong Huang",
      "Artem Chebotko",
      "Yu Deng",
      "Farshad Fotouhi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0902.3026v1",
    "title": "OntoELAN: An Ontology-based Linguistic Multimedia Annotator",
    "summary": "Despite its scientific, political, and practical value, comprehensive\ninformation about human languages, in all their variety and complexity, is not\nreadily obtainable and searchable. One reason is that many language data are\ncollected as audio and video recordings which imposes a challenge to document\nindexing and retrieval. Annotation of multimedia data provides an opportunity\nfor making the semantics explicit and facilitates the searching of multimedia\ndocuments. We have developed OntoELAN, an ontology-based linguistic multimedia\nannotator that features: (1) support for loading and displaying ontologies\nspecified in OWL; (2) creation of a language profile, which allows a user to\nchoose a subset of terms from an ontology and conveniently rename them if\nneeded; (3) creation of ontological tiers, which can be annotated with profile\nterms and, therefore, corresponding ontological terms; and (4) saving\nannotations in the XML format as Multimedia Ontology class instances and,\nlinked to them, class instances of other ontologies used in ontological tiers.\nTo our best knowledge, OntoELAN is the first audio/video annotation tool in\nlinguistic domain that provides support for ontology-based annotation.",
    "published": "2009-02-18T00:40:37Z",
    "link": "http://arxiv.org/pdf/0902.3026v1.pdf",
    "category": [
      "cs.DL",
      "cs.DB",
      "cs.MM",
      "cs.SE"
    ],
    "authors": [
      "Artem Chebotko",
      "Yu Deng",
      "Shiyong Lu",
      "Farshad Fotouhi",
      "Anthony Aristar",
      "Hennie Brugman",
      "Alexander Klassmann",
      "Han Sloetjes",
      "Albert Russel",
      "Peter Wittenburg"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0902.3027v1",
    "title": "Ontology-Based Annotation of Multimedia Language Data for the Semantic\n  Web",
    "summary": "There is an increasing interest and effort in preserving and documenting\nendangered languages. Language data are valuable only when they are\nwell-cataloged, indexed and searchable. Many language data, particularly those\nof lesser-spoken languages, are collected as audio and video recordings. While\nmultimedia data provide more channels and dimensions to describe a language's\nfunction, and gives a better presentation of the cultural system associated\nwith the language of that community, they are not text-based or structured (in\nbinary format), and their semantics is implicit in their content. The content\nis thus easy for a human being to understand, but difficult for computers to\ninterpret. Hence, there is a great need for a powerful and user-friendly system\nto annotate multimedia data with text-based, well-structured and searchable\nmetadata. This chapter describes an ontology-based multimedia annotation tool,\nOntoELAN, that enables annotation of language multimedia data with a linguistic\nontology.",
    "published": "2009-02-18T01:16:50Z",
    "link": "http://arxiv.org/pdf/0902.3027v1.pdf",
    "category": [
      "cs.DL",
      "cs.DB",
      "cs.MM"
    ],
    "authors": [
      "Artem Chebotko",
      "Shiyong Lu",
      "Farshad Fotouhi",
      "Anthony Aristar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0902.3979v1",
    "title": "Optimal Control of a Single Queue with Retransmissions: Delay-Dropping\n  Tradeoffs",
    "summary": "A single queue incorporating a retransmission protocol is investigated,\nassuming that the sequence of per effort success probabilities in the Automatic\nRetransmission reQuest (ARQ) chain is a priori defined and no channel state\ninformation at the transmitter is available. A Markov Decision Problem with an\naverage cost criterion is formulated where the possible actions are to either\ncontinue the retransmission process of an erroneous packet at the next time\nslot or to drop the packet and move on to the next packet awaiting for\ntransmission. The cost per slot is a linear combination of the current queue\nlength and a penalty term in case dropping is chosen as action. The\ninvestigation seeks policies that provide the best possible average packet\ndelay-dropping trade-off for Quality of Service guarantees. An optimal\ndeterministic stationary policy is shown to exist, several structural\nproperties of which are obtained. Based on that, a class of suboptimal\n<L,K>-policies is introduced. These suggest that it is almost optimal to use a\nK-truncated ARQ protocol as long as the queue length is lower than L, else send\nall packets in one shot. The work concludes with an evaluation of the optimal\ndelay-dropping tradeoff using dynamic programming and a comparison between the\noptimal and suboptimal policies.",
    "published": "2009-02-23T19:48:51Z",
    "link": "http://arxiv.org/pdf/0902.3979v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Anastasios Giovanidis",
      "Gerhard Wunder",
      "Joerg Buehler"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0903.0207v1",
    "title": "A Systematic Framework for Dynamically Optimizing Multi-User Wireless\n  Video Transmission",
    "summary": "In this paper, we formulate the collaborative multi-user wireless video\ntransmission problem as a multi-user Markov decision process (MUMDP) by\nexplicitly considering the users' heterogeneous video traffic characteristics,\ntime-varying network conditions and the resulting dynamic coupling between the\nwireless users. These environment dynamics are often ignored in existing\nmulti-user video transmission solutions. To comply with the decentralized\nnature of wireless networks, we propose to decompose the MUMDP into local MDPs\nusing Lagrangian relaxation. Unlike in conventional multi-user video\ntransmission solutions stemming from the network utility maximization\nframework, the proposed decomposition enables each wireless user to\nindividually solve its own dynamic cross-layer optimization (i.e. the local\nMDP) and the network coordinator to update the Lagrangian multipliers (i.e.\nresource prices) based on not only current, but also future resource needs of\nall users, such that the long-term video quality of all users is maximized.\nHowever, solving the MUMDP requires statistical knowledge of the experienced\nenvironment dynamics, which is often unavailable before transmission time. To\novercome this obstacle, we then propose a novel online learning algorithm,\nwhich allows the wireless users to update their policies in multiple states\nduring one time slot. This is different from conventional learning solutions,\nwhich often update one state per time slot. The proposed learning algorithm can\nsignificantly improve the learning performance, thereby dramatically improving\nthe video quality experienced by the wireless users over time. Our simulation\nresults demonstrate the efficiency of the proposed MUMDP framework as compared\nto conventional multi-user video transmission solutions.",
    "published": "2009-03-02T04:49:27Z",
    "link": "http://arxiv.org/pdf/0903.0207v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Fangwen Fu",
      "Mihaela van der Schaar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0903.2272v1",
    "title": "A Novel Approach for Compression of Images Captured using Bayer Color\n  Filter Arrays",
    "summary": "We propose a new approach for image compression in digital cameras, where the\ngoal is to achieve better quality at a given rate by using the characteristics\nof a Bayer color filter array. Most digital cameras produce color images by\nusing a single CCD plate, so that each pixel in an image has only one color\ncomponent and therefore an interpolation method is needed to produce a full\ncolor image. After the image processing stage, in order to reduce the memory\nrequirements of the camera, a lossless or lossy compression stage often\nfollows. But in this scheme, before decreasing redundancy through compression,\nredundancy is increased in an interpolation stage. In order to avoid increasing\nthe redundancy before compression, we propose algorithms for image compression\nin which the order of the compression and interpolation stages is reversed. We\nintroduce image transform algorithms, since non interpolated images cannot be\ndirectly compressed with general image coders. The simulation results show that\nour algorithm outperforms conventional methods with various color interpolation\nmethods in a wide range of compression ratios. Our proposed algorithm provides\nnot only better quality but also lower encoding complexity because the amount\nof luminance data used is only half of that in conventional methods.",
    "published": "2009-03-13T07:11:31Z",
    "link": "http://arxiv.org/pdf/0903.2272v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Sang-Yong Lee",
      "Antonio Ortega"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0903.3103v1",
    "title": "Efficiently Learning a Detection Cascade with Sparse Eigenvectors",
    "summary": "In this work, we first show that feature selection methods other than\nboosting can also be used for training an efficient object detector. In\nparticular, we introduce Greedy Sparse Linear Discriminant Analysis (GSLDA)\n\\cite{Moghaddam2007Fast} for its conceptual simplicity and computational\nefficiency; and slightly better detection performance is achieved compared with\n\\cite{Viola2004Robust}. Moreover, we propose a new technique, termed Boosted\nGreedy Sparse Linear Discriminant Analysis (BGSLDA), to efficiently train a\ndetection cascade. BGSLDA exploits the sample re-weighting property of boosting\nand the class-separability criterion of GSLDA.",
    "published": "2009-03-18T08:17:05Z",
    "link": "http://arxiv.org/pdf/0903.3103v1.pdf",
    "category": [
      "cs.MM",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Chunhua Shen",
      "Sakrapee Paisitkriangkrai",
      "Jian Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0903.3995v1",
    "title": "Gradient-based adaptive interpolation in super-resolution image\n  restoration",
    "summary": "This paper presents a super-resolution method based on gradient-based\nadaptive interpolation. In this method, in addition to considering the distance\nbetween the interpolated pixel and the neighboring valid pixel, the\ninterpolation coefficients take the local gradient of the original image into\naccount. The smaller the local gradient of a pixel is, the more influence it\nshould have on the interpolated pixel. And the interpolated high resolution\nimage is finally deblurred by the application of wiener filter. Experimental\nresults show that our proposed method not only substantially improves the\nsubjective and objective quality of restored images, especially enhances edges,\nbut also is robust to the registration error and has low computational\ncomplexity.",
    "published": "2009-03-24T01:33:15Z",
    "link": "http://arxiv.org/pdf/0903.3995v1.pdf",
    "category": [
      "cs.MM",
      "cs.CV"
    ],
    "authors": [
      "Jinyu Chu",
      "Ju Liu",
      "Jianping Qiao",
      "Xiaoling Wang",
      "Yujun Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0903.4113v1",
    "title": "Overlay Structure for Large Scale Content Sharing: Leveraging Geography\n  as the Basis for Routing Locality",
    "summary": "In this paper we place our arguments on two related issues in the design of\ngeneralized structured peer-to-peer overlays. First, we argue that for the\nlarge-scale content-sharing applications, lookup and content transport\nfunctions need to be treated separately. Second, to create a location-based\nrouting overlay suitable for content sharing and other applications, we argue\nthat off-the-shelf geographic coordinates of Internet-connected hosts can be\nused as a basis. We then outline the design principles and present a design for\nthe generalized routing overlay based on adaptive hierarchical partitioning of\nthe geographical space.",
    "published": "2009-03-24T16:16:26Z",
    "link": "http://arxiv.org/pdf/0903.4113v1.pdf",
    "category": [
      "cs.NI",
      "cs.DC",
      "cs.MM"
    ],
    "authors": [
      "Shah Asaduzzaman",
      "Gregor v. Bochmann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0903.4314v1",
    "title": "Virtual Reality",
    "summary": "This paper is focused on the presentation of Virtual Reality principles\ntogether with the main implementation methods and techniques. An overview of\nthe main development directions is included.",
    "published": "2009-03-25T12:16:29Z",
    "link": "http://arxiv.org/pdf/0903.4314v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Dan L. Lacrama",
      "Dorina Fera"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0903.4365v2",
    "title": "CliqueStream: an efficient and fault-resilient live streaming network on\n  a clustered peer-to-peer overlay",
    "summary": "Several overlay-based live multimedia streaming platforms have been proposed\nin the recent peer-to-peer streaming literature. In most of the cases, the\noverlay neighbors are chosen randomly for robustness of the overlay. However,\nthis causes nodes that are distant in terms of proximity in the underlying\nphysical network to become neighbors, and thus data travels unnecessary\ndistances before reaching the destination. For efficiency of bulk data\ntransmission like multimedia streaming, the overlay neighborhood should\nresemble the proximity in the underlying network. In this paper, we exploit the\nproximity and redundancy properties of a recently proposed clique-based\nclustered overlay network, named eQuus, to build efficient as well as robust\noverlays for multimedia stream dissemination. To combine the efficiency of\ncontent pushing over tree structured overlays and the robustness of data-driven\nmesh overlays, higher capacity stable nodes are organized in tree structure to\ncarry the long haul traffic and less stable nodes with intermittent presence\nare organized in localized meshes. The overlay construction and fault-recovery\nprocedures are explained in details. Simulation study demonstrates the good\nlocality properties of the platform. The outage time and control overhead\ninduced by the failure recovery mechanism are minimal as demonstrated by the\nanalysis.",
    "published": "2009-03-25T15:58:47Z",
    "link": "http://arxiv.org/pdf/0903.4365v2.pdf",
    "category": [
      "cs.NI",
      "cs.DC",
      "cs.MM"
    ],
    "authors": [
      "Shah Asaduzzaman",
      "Ying Qiao",
      "Gregor v. Bochmann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0904.2096v1",
    "title": "A Distributed Software Architecture for Collaborative Teleoperation\n  based on a VR Platform and Web Application Interoperability",
    "summary": "Augmented Reality and Virtual Reality can provide to a Human Operator (HO) a\nreal help to complete complex tasks, such as robot teleoperation and\ncooperative teleassistance. Using appropriate augmentations, the HO can\ninteract faster, safer and easier with the remote real world. In this paper, we\npresent an extension of an existing distributed software and network\narchitecture for collaborative teleoperation based on networked human-scaled\nmixed reality and mobile platform. The first teleoperation system was composed\nby a VR application and a Web application. However the 2 systems cannot be used\ntogether and it is impossible to control a distant robot simultaneously. Our\ngoal is to update the teleoperation system to permit a heterogeneous\ncollaborative teleoperation between the 2 platforms. An important feature of\nthis interface is based on different Mobile platforms to control one or many\nrobots.",
    "published": "2009-04-14T11:21:47Z",
    "link": "http://arxiv.org/pdf/0904.2096v1.pdf",
    "category": [
      "cs.HC",
      "cs.GR",
      "cs.MM",
      "cs.RO"
    ],
    "authors": [
      "Christophe Domingues",
      "Samir Otmane",
      "Frdric Davesne",
      "Malik Mallem"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0904.3693v1",
    "title": "The Multimedia Product - between Design and Information, Design and\n  Utility and Design and Entertainment",
    "summary": "The paper investigates the possible coherent and effective alternatives to\nsolve the problems related to the communication needs of any multimedia\nproduct. In essence, the presentation will focus on identifying the issues and\nprinciples governing three types of the design - in fact, the multimedia design\nin a broader sense - namely the information design - precisely aiming at ways\nof organization and presentation of information in a useful and significant\nform, the graphical user interface design, whose sub-domain consists of the\ninformation displayed on the monitor screen and of interactivity between user,\ncomputer and electronic devices, meaning, in fact, everything the user sees,\ntouches, hears and all the elements with which he interacts, the graphic\ndesign, whose main concern is to create an aesthetic layout arrangement (from\nthe visual and perceptive) information.",
    "published": "2009-04-23T13:50:36Z",
    "link": "http://arxiv.org/pdf/0904.3693v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Dieter Penteliuc Cotosman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0904.3694v1",
    "title": "The new multimedia educational technologies, used in open and distance\n  learning",
    "summary": "This paper reviews and refers to the latest telematics technology that has\nturned the open system learning and helped it to become an institutional\nalternative to the face-to-face traditional one. Most technologies, briefly\npresented here, will be implemented in the \"ARTeFACt\" project - telematic\nsystem for vocational education system of open system learning, system which\nwill be officially launched at the end of 2006, in the institutional offer of\nthe Faculty of Arts of the University West of Timisoara. The scientific\ncoordination of the doctoral project \"ARTeFACt\" is done by Mr. Prof. Dr. Eng.\nSavi G. George, representing the Department of Mechatronics Faculty of\nMechanical Engineering from the University \"Politehnica\" of Timisoara, Romania",
    "published": "2009-04-23T13:57:23Z",
    "link": "http://arxiv.org/pdf/0904.3694v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Dieter Penteliuc-Cotosman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0904.4202v4",
    "title": "On-the-fly erasure coding for real-time video applications",
    "summary": "This paper introduces a robust point-to-point transmission scheme: Tetrys,\nthat relies on a novel on-the-fly erasure coding concept which reduces the\ndelay for recovering lost data at the receiver side. In current erasure coding\nschemes, the packets that are not rebuilt at the receiver side are either lost\nor delayed by at least one RTT before transmission to the application. The\npresent contribution aims at demonstrating that Tetrys coding scheme can fill\nthe gap between real-time applications requirements and full reliability.\nIndeed, we show that in several cases, Tetrys can recover lost packets below\none RTT over lossy and best-effort networks. We also show that Tetrys allows to\nenable full reliability without delay compromise and as a result: significantly\nimproves the performance of time constrained applications. For instance, our\nevaluations present that video-conferencing applications obtain a PSNR gain up\nto 7dB compared to classic block-based erasure codes.",
    "published": "2009-04-27T16:09:33Z",
    "link": "http://arxiv.org/pdf/0904.4202v4.pdf",
    "category": [
      "cs.NI",
      "cs.MM"
    ],
    "authors": [
      "Pierre-Ugo Tournoux",
      "Emmanuel Lochin",
      "Jerome Lacan",
      "Amine Bouabdallah",
      "Vincent Roca"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0905.1235v2",
    "title": "The Modular Audio Recognition Framework (MARF) and its Applications:\n  Scientific and Software Engineering Notes",
    "summary": "MARF is an open-source research platform and a collection of\nvoice/sound/speech/text and natural language processing (NLP) algorithms\nwritten in Java and arranged into a modular and extensible framework\nfacilitating addition of new algorithms. MARF can run distributively over the\nnetwork and may act as a library in applications or be used as a source for\nlearning and extension. A few example applications are provided to show how to\nuse the framework. There is an API reference in the Javadoc format as well as\nthis set of accompanying notes with the detailed description of the\narchitectural design, algorithms, and applications. MARF and its applications\nare released under a BSD-style license and is hosted at SourceForge.net. This\ndocument provides the details and the insight on the internals of MARF and some\nof the mentioned applications.",
    "published": "2009-05-08T14:42:03Z",
    "link": "http://arxiv.org/pdf/0905.1235v2.pdf",
    "category": [
      "cs.SD",
      "cs.CL",
      "cs.CV",
      "cs.MM",
      "cs.NE",
      "I.5; I.2.6; D.2.10; D.2.11; D.2.5; D.2.2; I.2.7"
    ],
    "authors": [
      "Serguei A. Mokhov",
      "Stephen Sinclair",
      "Ian Clment",
      "Dimitrios Nicolacopoulos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0905.2459v2",
    "title": "On Design and Implementation of the Distributed Modular Audio\n  Recognition Framework: Requirements and Specification Design Document",
    "summary": "We present the requirements and design specification of the open-source\nDistributed Modular Audio Recognition Framework (DMARF), a distributed\nextension of MARF. The distributed version aggregates a number of distributed\ntechnologies (e.g. Java RMI, CORBA, Web Services) in a pluggable and modular\nmodel along with the provision of advanced distributed systems algorithms. We\noutline the associated challenges incurred during the design and implementation\nas well as overall specification of the project and its advantages and\nlimitations.",
    "published": "2009-05-15T02:52:28Z",
    "link": "http://arxiv.org/pdf/0905.2459v2.pdf",
    "category": [
      "cs.CV",
      "cs.DC",
      "cs.MM",
      "cs.NE",
      "cs.SD",
      "C.2.4; I.5; I.2.6; D.2.10; D.2.11; D.2.5; D.2.2; I.2.7"
    ],
    "authors": [
      "Serguei A. Mokhov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0905.2463v2",
    "title": "Generalized Kernel-based Visual Tracking",
    "summary": "In this work we generalize the plain MS trackers and attempt to overcome\nstandard mean shift trackers' two limitations.\n  It is well known that modeling and maintaining a representation of a target\nobject is an important component of a successful visual tracker.\n  However, little work has been done on building a robust template model for\nkernel-based MS tracking. In contrast to building a template from a single\nframe, we train a robust object representation model from a large amount of\ndata. Tracking is viewed as a binary classification problem, and a\ndiscriminative classification rule is learned to distinguish between the object\nand background. We adopt a support vector machine (SVM) for training. The\ntracker is then implemented by maximizing the classification score. An\niterative optimization scheme very similar to MS is derived for this purpose.",
    "published": "2009-05-15T03:26:52Z",
    "link": "http://arxiv.org/pdf/0905.2463v2.pdf",
    "category": [
      "cs.CV",
      "cs.MM"
    ],
    "authors": [
      "Chunhua Shen",
      "Junae Kim",
      "Hanzi Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0905.4087v1",
    "title": "Structural Solutions for Cross-Layer Optimization of Wireless Multimedia\n  Transmission",
    "summary": "In this paper, we propose a systematic solution to the problem of cross-layer\noptimization for delay-sensitive media transmission over time-varying wireless\nchannels as well as investigate the structures and properties of this solution,\nsuch that it can be easily implemented in various multimedia systems and\napplications. Specifically, we formulate this problem as a finite-horizon\nMarkov decision process (MDP) by explicitly considering the users'\nheterogeneous multimedia traffic characteristics (e.g. delay deadlines,\ndistortion impacts and dependencies etc.), time-varying network conditions as\nwell as, importantly, their ability to adapt their cross-layer transmission\nstrategies in response to these dynamics. Based on the heterogeneous\ncharacteristics of the media packets, we are able to express the transmission\npriorities between packets as a new type of directed acyclic graph (DAG). This\nDAG provides the necessary structure for determining the optimal cross-layer\nactions in each time slot: the root packet in the DAG will always be selected\nfor transmission since it has the highest positive marginal utility; and the\ncomplexity of the proposed cross-layer solution is demonstrated to linearly\nincrease w.r.t. the number of disconnected packet pairs in the DAG and\nexponentially increase w.r.t. the number of packets on which the current\npackets depend on. The simulation results demonstrate that the proposed\nsolution significantly outperforms existing state-of-the-art cross-layer\nsolutions. Moreover, we show that our solution provides the upper bound\nperformance for the cross-layer optimization solutions with delayed feedback\nsuch as the well-known RaDiO framework.",
    "published": "2009-05-25T22:09:58Z",
    "link": "http://arxiv.org/pdf/0905.4087v1.pdf",
    "category": [
      "cs.MM",
      "cs.IT",
      "math.IT"
    ],
    "authors": [
      "Fangwen Fu",
      "Mihaela van der Schaar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0905.4205v1",
    "title": "Development and Optimization of a Multimedia Product",
    "summary": "This article presents a new concept of a multimedia interactive product. It\nis a multiuser versatile platform that can be used for different purposes. The\nfirst implementation of the platform is a multiplayer game called Texas Hold\n'em, which is a very popular community card game. The paper shows the product's\nmultimedia structure where Hardware and Software work together in creating a\nrealistic feeling for the users.",
    "published": "2009-05-26T14:06:05Z",
    "link": "http://arxiv.org/pdf/0905.4205v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Cristian Anghel",
      "Vlad Muia",
      "Miodrag Stoianovici"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0905.4627v2",
    "title": "CoPhIR: a Test Collection for Content-Based Image Retrieval",
    "summary": "The scalability, as well as the effectiveness, of the different Content-based\nImage Retrieval (CBIR) approaches proposed in literature, is today an important\nresearch issue. Given the wealth of images on the Web, CBIR systems must in\nfact leap towards Web-scale datasets. In this paper, we report on our\nexperience in building a test collection of 100 million images, with the\ncorresponding descriptive features, to be used in experimenting new scalable\ntechniques for similarity searching, and comparing their results. In the\ncontext of the SAPIR (Search on Audio-visual content using Peer-to-peer\nInformation Retrieval) European project, we had to experiment our distributed\nsimilarity searching technology on a realistic data set. Therefore, since no\nlarge-scale collection was available for research purposes, we had to tackle\nthe non-trivial process of image crawling and descriptive feature extraction\n(we used five MPEG-7 features) using the European EGEE computer GRID. The\nresult of this effort is CoPhIR, the first CBIR test collection of such scale.\nCoPhIR is now open to the research community for experiments and comparisons,\nand access to the collection was already granted to more than 50 research\ngroups worldwide.",
    "published": "2009-05-28T12:14:07Z",
    "link": "http://arxiv.org/pdf/0905.4627v2.pdf",
    "category": [
      "cs.MM",
      "cs.IR"
    ],
    "authors": [
      "Paolo Bolettieri",
      "Andrea Esuli",
      "Fabrizio Falchi",
      "Claudio Lucchese",
      "Raffaele Perego",
      "Tommaso Piccioli",
      "Fausto Rabitti"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0906.0667v1",
    "title": "Quality assessment of the MPEG-4 scalable video CODEC",
    "summary": "In this paper, the performance of the emerging MPEG-4 SVC CODEC is evaluated.\nIn the first part, a brief introduction on the subject of quality assessment\nand the development of the MPEG-4 SVC CODEC is given. After that, the used test\nmethodologies are described in detail, followed by an explanation of the actual\ntest scenarios. The main part of this work concentrates on the performance\nanalysis of the MPEG-4 SVC CODEC - both objective and subjective.",
    "published": "2009-06-03T09:31:34Z",
    "link": "http://arxiv.org/pdf/0906.0667v1.pdf",
    "category": [
      "cs.MM",
      "cs.CV"
    ],
    "authors": [
      "Florian Niedermeier",
      "Michael Niedermeier",
      "Harald Kosch"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0906.0866v1",
    "title": "Web Publishing of the Files Obtained by Flash",
    "summary": "The aim of this article is to familiarize the user with the Web publishing of\nthe files obtained by Flash. The article contains an overview of Macromedia\nFlash 5, as well as the running of a Playing Flash movie, information on Flash\nand Generator, the publishing of Flash movies, a HTLM publishing for Flash\nPlayer files and publishing by Generator templates.",
    "published": "2009-06-04T09:52:22Z",
    "link": "http://arxiv.org/pdf/0906.0866v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Virgiliu Streian",
      "Adela Ionescu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0906.4415v1",
    "title": "Robust Watermarking in Multiresolution Walsh-Hadamard Transform",
    "summary": "In this paper, a newer version of Walsh-Hadamard Transform namely\nmultiresolution Walsh-Hadamard Transform (MR-WHT) is proposed for images.\nFurther, a robust watermarking scheme is proposed for copyright protection\nusing MRWHT and singular value decomposition. The core idea of the proposed\nscheme is to decompose an image using MR-WHT and then middle singular values of\nhigh frequency sub-band at the coarsest and the finest level are modified with\nthe singular values of the watermark. Finally, a reliable watermark extraction\nscheme is developed for the extraction of the watermark from the distorted\nimage. The experimental results show better visual imperceptibility and\nresiliency of the proposed scheme against intentional or un-intentional variety\nof attacks.",
    "published": "2009-06-24T07:23:51Z",
    "link": "http://arxiv.org/pdf/0906.4415v1.pdf",
    "category": [
      "cs.CR",
      "cs.IT",
      "cs.MM",
      "math.IT"
    ],
    "authors": [
      "Gaurav Bhatnagar",
      "Balasubramanian Raman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0906.4607v1",
    "title": "A Bandwidth Characterization Tool For MPEG-2 File",
    "summary": "This paper proposes the design and development of MPEG 2 Video Decoder to\noffer flexible and effective utilization of bandwidth services. The decoder is\ncapable of decoding the MPEG 2 bit stream on a single host machine. The present\ndecoder is designed to be simple, but yet effectively reconstruct the video\nfrom MPEG 2 bit stream.",
    "published": "2009-06-25T05:40:46Z",
    "link": "http://arxiv.org/pdf/0906.4607v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Sandeep. Kugali",
      "S. S. Manvi",
      "A. V. Sutagundar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0906.4936v1",
    "title": "A New Approach to Manage QoS in Distributed Multimedia Systems",
    "summary": "Dealing with network congestion is a criterion used to enhance quality of\nservice (QoS) in distributed multimedia systems. The existing solutions for the\nproblem of network congestion ignore scalability considerations because they\nmaintain a separate classification for each video stream. In this paper, we\npropose a new method allowing to control QoS provided to clients according to\nthe network congestion, by discarding some frames when needed. The technique\nproposed, called (m,k)-frame, is scalable with little degradation in\napplication performances. (m,k)-frame method is issued from the notion of\n(m,k)-firm realtime constraints which means that among k invocations of a task,\nm invocations must meet their deadline. Our simulation studies show the\nusefulness of (m,k)-frame method to adapt the QoS to the real conditions in a\nmultimedia application, according to the current system load. Notably, the\nsystem must adjust the QoS provided to active clients1 when their number\nvaries, i.e. dynamic arrival of clients.",
    "published": "2009-06-26T13:40:38Z",
    "link": "http://arxiv.org/pdf/0906.4936v1.pdf",
    "category": [
      "cs.MM",
      "cs.PF"
    ],
    "authors": [
      "Bechir Alaya",
      "Claude Duvallet",
      "Bruno Sadeg"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0906.5073v1",
    "title": "TTSS Packet Classification Algorithm to enhance Multimedia Applications\n  in Network Processor based Router",
    "summary": "The objective of this paper is to implement the Trie based Tuple Space\nSearch(TTSS) packet classification algorithm for Network Processor(NP) based\nrouter to enhance multimedia applications. The performance is evaluated using\nIntel IXP2400 NP Simulator. The results demonstrate that, TTSS has better\nperformance than Tuple Space Search algorithm and is well suited to achieve\nhigh speed packet classification to support multimedia applications.",
    "published": "2009-06-27T11:59:15Z",
    "link": "http://arxiv.org/pdf/0906.5073v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "R. Avudaiammal",
      "R. SivaSubramanian",
      "R. Pandian",
      "P. Seethalakshmi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0906.5325v1",
    "title": "Online Reinforcement Learning for Dynamic Multimedia Systems",
    "summary": "In our previous work, we proposed a systematic cross-layer framework for\ndynamic multimedia systems, which allows each layer to make autonomous and\nforesighted decisions that maximize the system's long-term performance, while\nmeeting the application's real-time delay constraints. The proposed solution\nsolved the cross-layer optimization offline, under the assumption that the\nmultimedia system's probabilistic dynamics were known a priori. In practice,\nhowever, these dynamics are unknown a priori and therefore must be learned\nonline. In this paper, we address this problem by allowing the multimedia\nsystem layers to learn, through repeated interactions with each other, to\nautonomously optimize the system's long-term performance at run-time. We\npropose two reinforcement learning algorithms for optimizing the system under\ndifferent design constraints: the first algorithm solves the cross-layer\noptimization in a centralized manner, and the second solves it in a\ndecentralized manner. We analyze both algorithms in terms of their required\ncomputation, memory, and inter-layer communication overheads. After noting that\nthe proposed reinforcement learning algorithms learn too slowly, we introduce a\ncomplementary accelerated learning algorithm that exploits partial knowledge\nabout the system's dynamics in order to dramatically improve the system's\nperformance. In our experiments, we demonstrate that decentralized learning can\nperform as well as centralized learning, while enabling the layers to act\nautonomously. Additionally, we show that existing application-independent\nreinforcement learning algorithms, and existing myopic learning algorithms\ndeployed in multimedia systems, perform significantly worse than our proposed\napplication-aware and foresighted learning methods.",
    "published": "2009-06-29T17:48:40Z",
    "link": "http://arxiv.org/pdf/0906.5325v1.pdf",
    "category": [
      "cs.LG",
      "cs.MM"
    ],
    "authors": [
      "Nicholas Mastronarde",
      "Mihaela van der Schaar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0908.0667v1",
    "title": "Interworking Scheme Using Optimized SIP Mobility for MultiHomed Mobile\n  Nodes in Wireless Heterogeneous Networks",
    "summary": "Nowadays, mobile users wish to use their multi-interface mobile devices to\naccess the Internet through network points of attachment (PoA) based on\nheterogeneous wireless technologies. They also wish to seamlessly change the\nPoAs during their ongoing sessions to improve service quality and/or reduce\nmonetary cost. If appropriately handled, multihomed mobile nodes offer a\npotential solution to this issue. In this sense, the management of multihomed\nmobile nodes in heterogeneous environment is a key research topic. In this\npaper, we present an improvement of SIP mobility (pre-call plus mid-call\nmobility) to support seamless mobility of multihomed mobile nodes in\nheterogeneous wireless networks. Pre-call mobility is extended to associate\nuser identifier (i.e. SIP URI) and interface identifiers (i.e. IP addresses).\nThe multiple addresses of a mobile device are weighted by the user to create a\npriority list in the SIP server so as to guarantee resilient reachability of\nmobile nodes and to avoid unnecessary signaling through wireless links, thus\nsaving radio resources. Then, three variations of mid-call mobility, called\nhard, hybrid and soft procedures, are also proposed. Their main aim is to\nminimize, or even avoid, packet losses during interface switching at the mobile\nnode. The proposed solutions have been implemented in a wireless heterogeneous\ntestbed composed of 802.11 WLAN plus 3.5 cellular network, which are fully\ncontrolled and configurable. The testbed has been used to study the performance\nand the robustness of the three proposed mid-call mobility procedures.",
    "published": "2009-08-05T13:55:36Z",
    "link": "http://arxiv.org/pdf/0908.0667v1.pdf",
    "category": [
      "cs.NI",
      "cs.MM"
    ],
    "authors": [
      "Paolo Dini",
      "Jaume Nin-Guerrero",
      "Josep Mangues-Bafalluy",
      "Lillian Dai",
      "Sateesh Addepalli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0908.3082v1",
    "title": "Component based platform for multimedia applications",
    "summary": "We propose a platform for distributed multimedia applications which\nsimplifies the development process and at the same time ensures application\nportability, flexibility and performance. The platform is implemented using the\nNetscape Portable Runtime (NSPR) and the Cross-Platform Component Object Model\n(XPCOM).",
    "published": "2009-08-21T09:46:07Z",
    "link": "http://arxiv.org/pdf/0908.3082v1.pdf",
    "category": [
      "cs.MM",
      "cs.NI"
    ],
    "authors": [
      "Ovidiu Ratoi",
      "Piroska Haller",
      "Ioan Salomie",
      "Bela Genge"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0908.4062v1",
    "title": "Optimization of Bit Plane Combination for Efficient Digital Image\n  Watermarking",
    "summary": "In view of the frequent multimedia data transfer authentication and\nprotection of images has gained importance in todays world. In this paper we\npropose a new watermarking technique, based on bit plane, which enhances\nrobustness and capacity of the watermark, as well as maintains transparency of\nthe watermark and fidelity of the image. In the proposed technique, higher\nstrength bit plane of digital signature watermark is embedded in to a\nsignificant bit plane of the original image. The combination of bit planes\n(image and watermark) selection is an important issue. Therefore, a mechanism\nis developed for appropriate bit plane selection. Ten different attacks are\nselected to test different alternatives. These attacks are given different\nweightings as appropriate to user requirement. A weighted correlation\ncoefficient for retrieved watermark is estimated for each of the alternatives.\nBased on these estimated values optimal bit plane combination is identified for\na given user requirement. The proposed method is found to be useful for\nauthentication and to prove legal ownership. We observed better results by our\nproposed method in comparison with the previously reported work on pseudorandom\nwatermark embedded in least significant bit (LSB) plane.",
    "published": "2009-08-27T18:52:26Z",
    "link": "http://arxiv.org/pdf/0908.4062v1.pdf",
    "category": [
      "cs.CR",
      "cs.MM"
    ],
    "authors": [
      "Sushma Kejgir",
      "Manesh Kokare"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0908.4074v1",
    "title": "Retrieval of Remote Sensing Images Using Colour and Texture Attribute",
    "summary": "Grouping images into semantically meaningful categories using low-level\nvisual feature is a challenging and important problem in content-based image\nretrieval. The groupings can be used to build effective indices for an image\ndatabase. Digital image analysis techniques are being used widely in remote\nsensing assuming that each terrain surface category is characterized with\nspectral signature observed by remote sensors. Even with the remote sensing\nimages of IRS data, integration of spatial information is expected to assist\nand to improve the image analysis of remote sensing data. In this paper we\npresent a satellite image retrieval based on a mixture of old fashioned ideas\nand state of the art learning tools. We have developed a methodology to\nclassify remote sensing images using HSV color features and Haar wavelet\ntexture features and then grouping them on the basis of particular threshold\nvalue. The experimental results indicate that the use of color and texture\nfeature extraction is very useful for image retrieval.",
    "published": "2009-08-27T19:21:11Z",
    "link": "http://arxiv.org/pdf/0908.4074v1.pdf",
    "category": [
      "cs.IR",
      "cs.MM"
    ],
    "authors": [
      "Priti Maheswary",
      "Namita Srivastava"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0909.0118v1",
    "title": "Dynamic Multimedia Content Retrieval System in Distributed Environment",
    "summary": "WiCoM enables remote management of web resources. Our application Mobile\nreporter is aimed at Journalist, who will be able to capture the events in\nreal-time using their mobile phones and update their web server on the latest\nevent. WiCoM has been developed using J2ME technology on the client side and\nPHP on the server side. The communication between the client and the server is\nestablished through GPRS. Mobile reporter will be able to upload, edit and\nremove both textual as well as multimedia contents in the server.",
    "published": "2009-09-01T08:19:18Z",
    "link": "http://arxiv.org/pdf/0909.0118v1.pdf",
    "category": [
      "cs.MM",
      "cs.IR"
    ],
    "authors": [
      "R. Sivaraman",
      "R. Prabakaran",
      "S. Sujatha"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0909.0245v1",
    "title": "Enhanced Mode Selection Algorithm for H.264 encoder for Application in\n  Low Computational power devices",
    "summary": "The intent of the H.264 AVC project was to create a standard capable of\nproviding good video quality at substantially lower bit rates than previous\nstandards without increasing the complexity of design so much that it would be\nimpractical or excessively expensive to implement. An additional goal was to\nprovide enough flexibility to allow the standard to be applied to a wide\nvariety of applications. To achieve better coding efficiency, H.264 AVC uses\nseveral techniques such as inter mode and intra mode prediction with variable\nsize motion compensation, which adopts Rate Distortion Optimization (RDO). This\nincreases the computational complexity of the encoder especially for devices\nwith lower processing capabilities such as mobile and other handheld devices.\nIn this paper, we propose an algorithm to reduce the number of mode and sub\nmode evaluations in inter mode prediction. Experimental results show that this\nfast intra mode selection algorithm can lessen about 75 percent encoding time\nwith little loss of bit rate and visual quality.",
    "published": "2009-09-01T18:57:06Z",
    "link": "http://arxiv.org/pdf/0909.0245v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Sourabh Rungta",
      "Kshitij Verma",
      "Neeta Tripathi",
      "Anupam Shukla"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0909.2816v1",
    "title": "Efficient Quality-Based Playout Buffer Algorithm",
    "summary": "Playout buffers are used in VoIP systems to compensate for network delay\njitter by making a trade-off between delay and loss. In this work we propose a\nplayout buffer algorithm that makes the trade-off based on maximization of\nconversational speech quality, aiming to keep the computational complexity\nlowest possible. We model the network delay using a Pareto distribution and\nshow that it is a good compromise between providing an appropriate fit to the\nnetwork delay characteristics and yielding a low arithmetical complexity. We\nuse the ITU-T E-Model as the quality model and simplify its delay impairment\nfunction. The proposed playout buffer algorithm finds the optimum playout delay\nusing a closed-form solution that minimizes the sum of the simplified delay\nimpairment factor and the loss-dependent equipment impairment factor of the\nE-model. The simulation results show that our proposed algorithm outperforms\nexisting state-of-the-art algorithms with a reduced complexity for a\nquality-based algorithm.",
    "published": "2009-09-15T14:44:21Z",
    "link": "http://arxiv.org/pdf/0909.2816v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Emine Zerrin Sakir",
      "Christian Feldbauer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0909.3554v1",
    "title": "Robustness of the Digital Image Watermarking Techniques against\n  Brightness and Rotation Attack",
    "summary": "The recent advent in the field of multimedia proposed a many facilities in\ntransport, transmission and manipulation of data. Along with this advancement\nof facilities there are larger threats in authentication of data, its licensed\nuse and protection against illegal use of data. A lot of digital image\nwatermarking techniques have been designed and implemented to stop the illegal\nuse of the digital multimedia images. This paper compares the robustness of\nthree different watermarking schemes against brightness and rotation attacks.\nThe robustness of the watermarked images has been verified on the parameters of\nPSNR (Peak Signal to Noise Ratio), RMSE (Root Mean Square Error) and MAE (Mean\nAbsolute Error).",
    "published": "2009-09-19T03:06:57Z",
    "link": "http://arxiv.org/pdf/0909.3554v1.pdf",
    "category": [
      "cs.MM",
      "cs.CR"
    ],
    "authors": [
      "Harsh K Verma",
      "Abhishek Narain Singh",
      "Raman Kumar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0910.0179v1",
    "title": "Analysis, Design and Simulation of a New System for Internet Multimedia\n  Transmission Guarantee",
    "summary": "QoS is a very important issue for multimedia communication systems. In this\npaper, a new system that reinstalls the relation between the QoS elements\n(RSVP, routing protocol, sender, and receiver) during the multimedia\ntransmission is proposed, then an alternative path is created in case of\noriginal multimedia path failure. The suggested system considers the resulting\nproblems that may be faced within and after the creation of rerouting path.\nFinally, the proposed system is simulated using OPNET 11.5 simulation package.\nSimulation results show that our proposed system outperforms the old one in\nterms of QoS parameters like packet loss and delay jitter.",
    "published": "2009-10-01T14:03:51Z",
    "link": "http://arxiv.org/pdf/0910.0179v1.pdf",
    "category": [
      "cs.MM",
      "cs.NI"
    ],
    "authors": [
      "O. Said",
      "S. Bahgat",
      "M. Ghoniemy",
      "Y. Elawdy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0910.0983v1",
    "title": "On Metric Skyline Processing by PM-tree",
    "summary": "The task of similarity search in multimedia databases is usually accomplished\nby range or k nearest neighbor queries. However, the expressing power of these\n\"single-example\" queries fails when the user's delicate query intent is not\navailable as a single example. Recently, the well-known skyline operator was\nreused in metric similarity search as a \"multi-example\" query type. When\napplied on a multi-dimensional database (i.e., on a multi-attribute table), the\ntraditional skyline operator selects all database objects that are not\ndominated by other objects. The metric skyline query adopts the skyline\noperator such that the multiple attributes are represented by distances\n(similarities) to multiple query examples. Hence, we can view the metric\nskyline as a set of representative database objects which are as similar to all\nthe examples as possible and, simultaneously, are semantically distinct. In\nthis paper we propose a technique of processing the metric skyline query by use\nof PM-tree, while we show that our technique significantly outperforms the\noriginal M-tree based implementation in both time and space costs. In\nexperiments we also evaluate the partial metric skyline processing, where only\na controlled number of skyline objects is retrieved.",
    "published": "2009-10-06T12:09:52Z",
    "link": "http://arxiv.org/pdf/0910.0983v1.pdf",
    "category": [
      "cs.DB",
      "cs.DL",
      "cs.MM",
      "cs.PF"
    ],
    "authors": [
      "Tomas Skopal",
      "Jakub Lokoc"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0910.1468v1",
    "title": "Prefetching of VoD Programs Based On ART1 Requesting Clustering",
    "summary": "In this paper, we propose a novel approach to group users according to the\nVoD user request pattern. We cluster the user requests based on ART1 neural\nnetwork algorithm. The knowledge extracted from the cluster is used to prefetch\nthe multimedia object from each cluster before the users request. We have\ndeveloped an algorithm to cluster users according to the users request patterns\nbased on ART1 neural network algorithm that offers an unsupervised clustering.\nThis approach adapts to changes in user request patterns over period without\nlosing previous information. Each cluster is represented as prototype vector by\ngeneralizing the most frequently used URLs that are accessed by all the cluster\nmembers. The simulation results of our proposed clustering and prefetching\nalgorithm, shows enormous increase in the performance of streaming server. Our\nalgorithm helps the servers agent to learn user preferences and discover the\ninformation about the corresponding sources and other similar interested\nindividuals.",
    "published": "2009-10-08T11:21:21Z",
    "link": "http://arxiv.org/pdf/0910.1468v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "P. Jayarekha",
      "T. R. GopalaKrishnan Nair"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0910.1471v1",
    "title": "Prefix based Chaining Scheme for Streaming Popular Videos using Proxy\n  servers in VoD",
    "summary": "Streaming high quality videos consumes significantly large amount of network\nresources. In this context request to service delay, network traffic,\ncongestion and server overloading are the main parameters to be considered in\nvideo streaming over the internet that effect the quality of service (QoS). In\nthis paper, we propose an efficient architecture as a cluster of proxy servers\nand clients that uses a peer to peer (P2P) approach to cooperatively stream the\nvideo using chaining technique. We consider the following two key issues in the\nproposed architecture (1) Prefix caching technique to accommodate more number\nof videos close to client (2) Cooperative client and proxy chaining to achieve\nthe network efficiency. Our simulation results shows that the proposed approach\nyields a prefix caching close to the optimal solution minimizing WAN bandwidth\nusage on server-proxy path by utilizing the proxy-client and client-client path\nbandwidth, which is much cheaper than the expensive server proxy path\nbandwidth, server load, and client rejection ratio significantly using\nchaining.",
    "published": "2009-10-08T11:26:01Z",
    "link": "http://arxiv.org/pdf/0910.1471v1.pdf",
    "category": [
      "cs.MM",
      "cs.NI"
    ],
    "authors": [
      "M Dakshayini",
      "T R GopalaKrishnan Nair"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0910.4186v1",
    "title": "Media-TCP: A Quality-Centric TCP-Friendly Congestion Control for\n  Multimedia Transmission",
    "summary": "In this paper, we propose a quality-centric congestion control for multimedia\nstreaming over IP networks, which we refer to as media-TCP. Unlike existing\ncongestion control schemes that adapt a user's sending rate merely to the\nnetwork condition, our solution adapts the sending rate to both the network\ncondition and the application characteristics by explicitly considering the\ndistortion impacts, delay deadlines, and interdependencies of different video\npacket classes. Hence, our media-aware solution is able to provide differential\nservices for transmitting various packet classes and thereby, further improves\nthe multimedia streaming quality. We model this problem using a Finite-Horizon\nMarkov Decision Process (FHMDP) and determine the optimal congestion control\npolicy that maximizes the long-term multimedia quality, while adhering to the\nhorizon- TCP-friendliness constraint, which ensures long-term fairness with\nexisting TCP applications. We show that the FHMDP problem can be decomposed\ninto multiple optimal stopping problems, which admit a low-complexity\nthreshold-based solution. Moreover, unlike existing congestion control\napproaches, which focus on maintaining throughput-based fairness among users,\nthe proposed media-TCP aims to achieve quality-based fairness among multimedia\nusers. We also derive sufficient conditions for multiple multimedia users to\nachieve quality-based fairness using media-TCP congestion control. Our\nsimulation results show that the proposed media-TCP achieves more than 3dB\nimprovement in terms of PSNR over the conventional TCP congestion control\napproaches, with the largest improvements observed for real-time streaming\napplications requiring stringent playback delays.",
    "published": "2009-10-21T21:53:25Z",
    "link": "http://arxiv.org/pdf/0910.4186v1.pdf",
    "category": [
      "cs.NI",
      "cs.MM"
    ],
    "authors": [
      "Hsien-Po Shiang",
      "Mihaela van der Schaar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0911.0399v1",
    "title": "A Wavelet-Based Digital Watermarking for Video",
    "summary": "A novel video watermarking system operating in the three dimensional wavelet\ntransform is here presented. Specifically the video sequence is partitioned\ninto spatio temporal units and the single shots are projected onto the 3D\nwavelet domain. First a grayscale watermark image is decomposed into a series\nof bitplanes that are preprocessed with a random location matrix. After that\nthe preprocessed bitplanes are adaptively spread spectrum and added in 3D\nwavelet coefficients of the video shot. Our video watermarking algorithm is\nrobust against the attacks of frame dropping, averaging and swapping.\nFurthermore, it allows blind retrieval of embedded watermark which does not\nneed the original video and the watermark is perceptually invisible. The\nalgorithm design, evaluation, and experimentation of the proposed scheme are\ndescribed in this paper.",
    "published": "2009-11-02T20:07:52Z",
    "link": "http://arxiv.org/pdf/0911.0399v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "A. Essaouabi",
      "F. Regragui",
      "E. Ibnelhaj"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0911.0499v1",
    "title": "An Innovative Scheme For Effectual Fingerprint Data Compression Using\n  Bezier Curve Representations",
    "summary": "Naturally, with the mounting application of biometric systems, there arises a\ndifficulty in storing and handling those acquired biometric data. Fingerprint\nrecognition has been recognized as one of the most mature and established\ntechnique among all the biometrics systems. In recent times, with fingerprint\nrecognition receiving increasingly more attention the amount of fingerprints\ncollected has been constantly creating enormous problems in storage and\ntransmission. Henceforth, the compression of fingerprints has emerged as an\nindispensable step in automated fingerprint recognition systems. Several\nresearchers have presented approaches for fingerprint image compression. In\nthis paper, we propose a novel and efficient scheme for fingerprint image\ncompression. The presented scheme utilizes the Bezier curve representations for\neffective compression of fingerprint images. Initially, the ridges present in\nthe fingerprint image are extracted along with their coordinate values using\nthe approach presented. Subsequently, the control points are determined for all\nthe ridges by visualizing each ridge as a Bezier curve. The control points of\nall the ridges determined are stored and are used to represent the fingerprint\nimage. When needed, the fingerprint image is reconstructed from the stored\ncontrol points using Bezier curves. The quality of the reconstructed\nfingerprint is determined by a formal evaluation. The proposed scheme achieves\nconsiderable memory reduction in storing the fingerprint.",
    "published": "2009-11-03T05:11:40Z",
    "link": "http://arxiv.org/pdf/0911.0499v1.pdf",
    "category": [
      "cs.CV",
      "cs.CR",
      "cs.MM"
    ],
    "authors": [
      "Vani Perumal",
      "Jagannathan Ramaswamy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0911.4642v1",
    "title": "G3 : GENESIS software envrionment update",
    "summary": "GENESIS3 is the new version of the GENESIS software environment for musical\ncreation by means of mass-interaction physics network modeling. It was\ndesigned, and developed from scratch, in hindsight of more than 10 years\nworking on and using the previous version. We take the opportunity of this\nbirth to provide in this article (1) an analysis of the peculiarities in\nGENESIS, aiming at highlighting its core ?software paradigm?; and (2) an update\non the features of the new version as compared to the last.",
    "published": "2009-11-24T15:07:37Z",
    "link": "http://arxiv.org/pdf/0911.4642v1.pdf",
    "category": [
      "cs.SD",
      "cs.HC",
      "cs.MM",
      "cs.SE"
    ],
    "authors": [
      "Nicolas Castagn",
      "Claude Cadoz",
      "Ali Allaoui",
      "Olivier Michel Tache"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0912.1005v1",
    "title": "Performance analysis of Non Linear Filtering Algorithms for underwater\n  images",
    "summary": "Image filtering algorithms are applied on images to remove the different\ntypes of noise that are either present in the image during capturing or\ninjected in to the image during transmission. Underwater images when captured\nusually have Gaussian noise, speckle noise and salt and pepper noise. In this\nwork, five different image filtering algorithms are compared for the three\ndifferent noise types. The performances of the filters are compared using the\nPeak Signal to Noise Ratio (PSNR) and Mean Square Error (MSE). The modified\nspatial median filter gives desirable results in terms of the above two\nparameters for the three different noise. Forty underwater images are taken for\nstudy.",
    "published": "2009-12-05T12:33:09Z",
    "link": "http://arxiv.org/pdf/0912.1005v1.pdf",
    "category": [
      "cs.MM",
      "cs.CV",
      "cs.IR"
    ],
    "authors": [
      "Dr. G. Padmavathi",
      "Dr. P. Subashini",
      "Mr. M. Muthu Kumar",
      "Suresh Kumar Thakur"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0912.1011v1",
    "title": "A Reliable Replication Strategy for VoD System using Markov Chain",
    "summary": "In this paper we have investigated on the reliability of streams for a VoD\nsystem. The objective of the paper is to maximize the availability of streams\nfor the peers in the VoD system. We have achieved this by using data\nreplication technique in the peers. Hence, we proposed a new data replication\ntechnique to optimally store the videos in the peers. The new data replication\ntechnique generates more number of replicas than the existing techniques such\nas random, minimum request and maximize hit. We have also investigated by\napplying the CTMC model for the reliability of replications during the peer\nfailures. Our result shows that the mean lifetime of replicas are more under\nvarious circumstances. We have addressed the practical issues of efficient\nutilization of overall bandwidth and buffer in the VoD system. We achieved\ngreater success playback probability of videos than the existing techniques.",
    "published": "2009-12-05T13:03:17Z",
    "link": "http://arxiv.org/pdf/0912.1011v1.pdf",
    "category": [
      "cs.MM",
      "cs.NI"
    ],
    "authors": [
      "R. Ashok Kumar",
      "K. Ganesan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0912.1017v1",
    "title": "Genetic Programming Framework for Fingerprint Matching",
    "summary": "A fingerprint matching is a very difficult problem. Minutiae based matching\nis the most popular and widely used technique for fingerprint matching. The\nminutiae points considered in automatic identification systems are based\nnormally on termination and bifurcation points. In this paper we propose a new\ntechnique for fingerprint matching using minutiae points and genetic\nprogramming. The goal of this paper is extracting the mathematical formula that\ndefines the minutiae points.",
    "published": "2009-12-05T13:27:10Z",
    "link": "http://arxiv.org/pdf/0912.1017v1.pdf",
    "category": [
      "cs.CR",
      "cs.CV",
      "cs.MM"
    ],
    "authors": [
      "Ismail A. Ismail",
      "Nabawia A. ElRamly",
      "Mohammed A. Abd-ElWahid",
      "Passent M. ElKafrawy",
      "Mohammed M. Nasef"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0912.3050v2",
    "title": "Breaking a modified substitution-diffusion image cipher based on chaotic\n  standard and logistic maps",
    "summary": "Recently, an image encryption scheme based on chaotic standard and logistic\nmaps was proposed by Patidar et al. It was later reported by Rhouma et al. that\nan equivalent secret key can be reconstructed with only one\nknown/chosen-plaintext and the corresponding ciphertext. Patidar et al. soon\nmodified the original scheme and claimed that the modified scheme is secure\nagainst Rhouma et al.'s attack. In this paper, we point out that the modified\nscheme is still insecure against the same known/chosen-plaintext attack. In\naddition, some other security defects existing in both the original and the\nmodified schemes are also reported.",
    "published": "2009-12-16T03:52:35Z",
    "link": "http://arxiv.org/pdf/0912.3050v2.pdf",
    "category": [
      "cs.CR",
      "cs.MM"
    ],
    "authors": [
      "Chengqing Li",
      "Shujun Li",
      "Kwok-Tung Lo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0912.3917v1",
    "title": "Speech Recognition Oriented Vowel Classification Using Temporal Radial\n  Basis Functions",
    "summary": "The recent resurgence of interest in spatio-temporal neural network as speech\nrecognition tool motivates the present investigation. In this paper an approach\nwas developed based on temporal radial basis function \"TRBF\" looking to many\nadvantages: few parameters, speed convergence and time invariance. This\napplication aims to identify vowels taken from natural speech samples from the\nTimit corpus of American speech. We report a recognition accuracy of 98.06\npercent in training and 90.13 in test on a subset of 6 vowel phonemes, with the\npossibility to expend the vowel sets in future.",
    "published": "2009-12-19T18:29:43Z",
    "link": "http://arxiv.org/pdf/0912.3917v1.pdf",
    "category": [
      "cs.CL",
      "cs.MM"
    ],
    "authors": [
      "Mustapha Guezouri",
      "Larbi Mesbahi",
      "Abdelkader Benyettou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0912.4880v1",
    "title": "How Do Interactive Virtual Operas Shift Relationships between Music,\n  Text and Image?",
    "summary": "In this paper we present the new genre of interactive operas implemented on\npersonal computers. They differ from traditional ones not only because they are\nvirtual, but mainly because they offer to composers and listeners new\nperspectives of combinations and interactions between music, text and visual\naspects.",
    "published": "2009-12-24T15:28:33Z",
    "link": "http://arxiv.org/pdf/0912.4880v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Alain Bonardi",
      "Francis Rousseaux"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0912.4881v1",
    "title": "Music-ripping: des pratiques qui provoquent la musicologie",
    "summary": "Out of the scope of the usual positions of computing in the field of music\nand musicology, one notices the emergence of human-computer systems that do\nexist by breaking off. Though these singular systems take effect in the usual\nfields of expansion of music, they do not make any systematic reference to\nknown musicological categories. On the contrary, they make possible experiments\nthat open uses where listening, composition and musical transmission get merged\nin a gesture sometimes named as ?music-ripping?. We will show in which way the\nmusic-ripping practices provoke traditional musicology, whose canonical\ncategories happen to be ineffectual to explain here. To achieve that purpose,\nwe shall need: - to make explicit a minimal set of categories that is\nsufficient to underlie the usual models of computer assisted music;- to do the\nsame for human-computer systems (anti-musicological?) that disturb us; - to\nexamine the possibility conditions of reduction of the second set to the first;\n- to conclude on the nature of music-ripping.",
    "published": "2009-12-24T15:28:53Z",
    "link": "http://arxiv.org/pdf/0912.4881v1.pdf",
    "category": [
      "cs.MM",
      "cs.HC"
    ],
    "authors": [
      "Francis Rousseaux",
      "Alain Bonardi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1001.0440v1",
    "title": "Tutoring System for Dance Learning",
    "summary": "Recent advances in hardware sophistication related to graphics display, audio\nand video devices made available a large number of multimedia and hypermedia\napplications. These multimedia applications need to store and retrieve the\ndifferent forms of media like text, hypertext, graphics, still images,\nanimations, audio and video. Dance is one of the important cultural forms of a\nnation and dance video is one such multimedia types. Archiving and retrieving\nthe required semantics from these dance media collections is a crucial and\ndemanding multimedia application. This paper summarizes the difference dance\nvideo archival techniques and systems. Keywords: Multimedia, Culture Media,\nMetadata archival and retrieval systems, MPEG-7, XML.",
    "published": "2010-01-04T05:24:31Z",
    "link": "http://arxiv.org/pdf/1001.0440v1.pdf",
    "category": [
      "cs.IR",
      "cs.MM",
      "H.3.1; H.5.4; H.2.4"
    ],
    "authors": [
      "Rajkumar Kannan",
      "Frederic Andres",
      "Balakrishnan Ramadoss"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1001.0441v1",
    "title": "Semantic Modeling and Retrieval of Dance Video Annotations",
    "summary": "Dance video is one of the important types of narrative videos with semantic\nrich content. This paper proposes a new meta model, Dance Video Content Model\n(DVCM) to represent the expressive semantics of the dance videos at multiple\ngranularity levels. The DVCM is designed based on the concepts such as video,\nshot, segment, event and object, which are the components of MPEG-7 MDS. This\npaper introduces a new relationship type called Temporal Semantic Relationship\nto infer the semantic relationships between the dance video objects. Inverted\nfile based index is created to reduce the search time of the dance queries. The\neffectiveness of containment queries using precision and recall is depicted.\nKeywords: Dance Video Annotations, Effectiveness Metrics, Metamodeling,\nTemporal Semantic Relationships.",
    "published": "2010-01-04T05:32:05Z",
    "link": "http://arxiv.org/pdf/1001.0441v1.pdf",
    "category": [
      "cs.MM",
      "cs.LO",
      "H.3.1; H.5.4; H.2.4"
    ],
    "authors": [
      "Rajkumar Kannan",
      "Balakrishnan Ramadoss"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1001.0442v1",
    "title": "Modeling and Annotating the Expressive Semantics of Dance Videos",
    "summary": "Dance videos are interesting and semantics-intensive. At the same time, they\nare the complex type of videos compared to all other types such as sports, news\nand movie videos. In fact, dance video is the one which is less explored by the\nresearchers across the globe. Dance videos exhibit rich semantics such as macro\nfeatures and micro features and can be classified into several types. Hence,\nthe conceptual modeling of the expressive semantics of the dance videos is very\ncrucial and complex. This paper presents a generic Dance Video Semantics Model\n(DVSM) in order to represent the semantics of the dance videos at different\ngranularity levels, identified by the components of the accompanying song. This\nmodel incorporates both syntactic and semantic features of the videos and\nintroduces a new entity type called, Agent, to specify the micro features of\nthe dance videos. The instantiations of the model are expressed as graphs. The\nmodel is implemented as a tool using J2SE and JMF to annotate the macro and\nmicro features of the dance videos. Finally examples and evaluation results are\nprovided to depict the effectiveness of the proposed dance video model.\nKeywords: Agents, Dance videos, Macro features, Micro features, Video\nannotation, Video semantics.",
    "published": "2010-01-04T05:41:01Z",
    "link": "http://arxiv.org/pdf/1001.0442v1.pdf",
    "category": [
      "cs.MM",
      "J.5; H.5.4"
    ],
    "authors": [
      "Rajkumar Kannan",
      "Balakrishnan Ramadoss"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1001.0443v1",
    "title": "Discovering Knowledge from Multi-modal Lecture Recordings",
    "summary": "Educational media mining is the process of converting raw media data from\neducational systems to useful information that can be used to design learning\nsystems, answer research questions and allow personalized learning experiences.\nKnowledge discovery encompasses a wide range of techniques ranging from\ndatabase queries to more recent developments in machine learning and language\ntechnology. Educational media mining techniques are now being used in IT\nServices research worldwide. Multi-modal Lecture Recordings is one of the\nimportant types of educational media and this paper explores the research\nchallenges for mining lecture recordings for the efficient personalized\nlearning experiences. Keywords: Educational Media Mining; Lecture Recordings,\nMultimodal Information System, Personalized Learning; Online Course Ware;\nSkills and Competences;",
    "published": "2010-01-04T05:44:57Z",
    "link": "http://arxiv.org/pdf/1001.0443v1.pdf",
    "category": [
      "cs.MM",
      "H.3.1; H.5.4; H.2.4"
    ],
    "authors": [
      "Rajkumar Kannan",
      "Christian Guetl"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1001.1013v1",
    "title": "Distributed Rate Allocation Policies for Multi-Homed Video Streaming\n  over Heterogeneous Access Networks",
    "summary": "We consider the problem of rate allocation among multiple simultaneous video\nstreams sharing multiple heterogeneous access networks. We develop and evaluate\nan analytical framework for optimal rate allocation based on observed available\nbit rate (ABR) and round-trip time (RTT) over each access network and video\ndistortion-rate (DR) characteristics. The rate allocation is formulated as a\nconvex optimization problem that minimizes the total expected distortion of all\nvideo streams. We present a distributed approximation of its solution and\ncompare its performance against H-infinity optimal control and two heuristic\nschemes based on TCP-style additive-increase-multiplicative decrease (AIMD)\nprinciples. The various rate allocation schemes are evaluated in simulations of\nmultiple high-definition (HD) video streams sharing multiple access networks.\nOur results demonstrate that, in comparison with heuristic AIMD-based schemes,\nboth media-aware allocation and H-infinity optimal control benefit from\nproactive congestion avoidance and reduce the average packet loss rate from 45%\nto below 2%. Improvement in average received video quality ranges between 1.5\nto 10.7 dB in PSNR for various background traffic loads and video playout\ndeadlines. Media-aware allocation further exploits its knowledge of the video\nDR characteristics to achieve a more balanced video quality among all streams.",
    "published": "2010-01-07T01:11:44Z",
    "link": "http://arxiv.org/pdf/1001.1013v1.pdf",
    "category": [
      "cs.MM",
      "cs.NI"
    ],
    "authors": [
      "Xiaoqing Zhu",
      "Piyush Agrawal",
      "Jatinder Pal Singh",
      "Tansu Alpcan",
      "Bernd Girod"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1001.1794v1",
    "title": "Designing a Truly Integrated (Onsite and Online) Conference: Concept,\n  Processes, Solutions",
    "summary": "Web conferencing tools have entered the mainstream of business applications.\nUsing web conferencing for IEEE conferences has a good potential of adding\nvalue to both organizers and participants. Authors propose a concept of Truly\nIntegrated Conference (TIC) according to which a multi-point\nworldwide-distributed network of conference online authors/participants will\nenhance the standard (centralized) IEEE conference model, which requires\nattendance of the participants in person at the main conference location. The\nconcept entails seamless integration of the onsite and online conference\nsystems, including data/presentation, video, audio channels. Benefits and\nchallenges of the TIC concept are analyzed. Requirements to the web\nconferencing system capable of supporting the TIC conference are presented and\nreviewed against commercial web conferencing tools. Case study of the IEEE\nToronto International Conference ? Science and Technology for Humanity, which\nwas the first realization of TIC, is presented which analyzes various aspects\n(organizational, technological, and financial) of the integrated conference.",
    "published": "2010-01-12T05:06:16Z",
    "link": "http://arxiv.org/pdf/1001.1794v1.pdf",
    "category": [
      "cs.MM",
      "cs.CY"
    ],
    "authors": [
      "Alexei Botchkarev",
      "Lian Zhao",
      "Hamed Rasouli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1001.1937v2",
    "title": "Avoiding Interruptions - QoE Trade-offs in Block-coded Streaming Media\n  Applications",
    "summary": "We take an analytical approach to study Quality of user Experience (QoE) for\nvideo streaming applications. First, we show that random linear network coding\napplied to blocks of video frames can significantly simplify the packet\nrequests at the network layer and save resources by avoiding duplicate packet\nreception. Network coding allows us to model the receiver's buffer as a queue\nwith Poisson arrivals and deterministic departures. We consider the probability\nof interruption in video playback as well as the number of initially buffered\npackets (initial waiting time) as the QoE metrics. We characterize the optimal\ntrade-off between these metrics by providing upper and lower bounds on the\nminimum initial buffer size, required to achieve certain level of interruption\nprobability for different regimes of the system parameters. Our bounds are\nasymptotically tight as the file size goes to infinity.",
    "published": "2010-01-12T16:13:50Z",
    "link": "http://arxiv.org/pdf/1001.1937v2.pdf",
    "category": [
      "cs.MM",
      "cs.NI"
    ],
    "authors": [
      "Ali Parandehgheibi",
      "Muriel Medard",
      "Srinivas Shakkottai",
      "Asu Ozdaglar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1001.1972v1",
    "title": "A New Image Steganography Based On First Component Alteration Technique",
    "summary": "In this paper, A new image steganography scheme is proposed which is a kind\nof spatial domain technique. In order to hide secret data in cover-image, the\nfirst component alteration technique is used. Techniques used so far focuses\nonly on the two or four bits of a pixel in a image (at the most five bits at\nthe edge of an image) which results in less peak to signal noise ratio and high\nroot mean square error. In this technique, 8 bits of blue components of pixels\nare replaced with secret data bits. Proposed scheme can embed more data than\nprevious schemes and shows better image quality. To prove this scheme, several\nexperiments are performed, and are compared the experimental results with the\nrelated previous works.",
    "published": "2010-01-12T18:30:20Z",
    "link": "http://arxiv.org/pdf/1001.1972v1.pdf",
    "category": [
      "cs.MM",
      "cs.CV"
    ],
    "authors": [
      "Amanpreet Kaur",
      "Renu Dhir",
      "Geeta Sikka"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1001.1974v1",
    "title": "Evaluating Effectiveness of Tamper Proofing on Dynamic Graph Software\n  Watermarks",
    "summary": "For enhancing the protection level of dynamic graph software watermarks and\nfor the purpose of conducting the analysis which evaluates the effect of\nintegrating two software protection techniques such as software watermarking\nand tamper proofing, constant encoding technique along with the enhancement\nthrough the idea of constant splitting is proposed. In this paper Thomborson\ntechnique has been implemented with the scheme of breaking constants which\nenables to encode all constants without having any consideration about their\nvalues with respect to the value of watermark tree. Experimental analysis which\nhave been conducted and provided in this paper concludes that the constant\nencoding process significantly increases the code size, heap space usage, and\nexecution time, while making the tamper proofed code resilient to variety of\nsemantic preserving program transformation attacks.",
    "published": "2010-01-12T18:34:24Z",
    "link": "http://arxiv.org/pdf/1001.1974v1.pdf",
    "category": [
      "cs.MM",
      "cs.CR"
    ],
    "authors": [
      "Malik Sikandar Hayat Khiyal",
      "Aihab Khan",
      "Sehrish Amjad",
      "M. Shahid Khalil"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1001.2280v1",
    "title": "Comparative Evaluation and Analysis of IAX and RSW",
    "summary": "Voice over IP (VoIP) is a technology to transport media over IP networks such\nas the Internet. VoIP has the capability of connecting people over packet\nswitched networks instead of traditional circuit switched networks. Recently,\nthe InterAsterisk Exchange Protocol (IAX) has emerged as a new VoIP which is\ngaining popularity among VoIP products. IAX is known for its simplicity, NAT\nfriendliness, efficiency, and robustness. More recently, the Real time\nSwitching (RSW) control criterion has emerged as a multimedia conferencing\nprotocol. In this paper, we made a comparative evaluation and analysis of IAX\nand RSW using Mean Opinion Score rating (MOS) and found that they both perform\nwell under different network packet delays in ms.",
    "published": "2010-01-13T19:29:02Z",
    "link": "http://arxiv.org/pdf/1001.2280v1.pdf",
    "category": [
      "cs.NI",
      "cs.MM"
    ],
    "authors": [
      "Manjur S Kolhar",
      "Mosleh M. Abu-Alhaj",
      "Omar Abouabdalla",
      "Tat Chee Wan",
      "Ahmad M. Manasrah"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1001.3744v1",
    "title": "Multicast Transmission Prefix and Popularity Aware Interval Caching\n  Based Admission Control Policy",
    "summary": "Admission control is a key component in multimedia servers, which will allow\nthe resources to be used by the client only when they are available. A problem\nfaced by numerous content serving machines is overload, when there are too many\nclients who need to be served, the server tends to slow down. An admission\ncontrol algorithm for a multimedia server is responsible for determining if a\nnew request can be accepted without violating the QoS requirements of the\nexisting requests in the system. By caching and streaming only the data in the\ninterval between two successive requests on the same object, the following\nrequest can be serviced directly from the buffer cache without disk operations\nand within the deadline of the request. An admission control strategy based on\nPopularity-aware interval caching for Prefix [3] scheme extends the interval\ncaching by considering different popularity of multimedia objects. The method\nof Prefix caching with multicast transmission of popular objects utilizes the\nhard disk and network bandwidth efficiently and increases the number of\nrequests being served.",
    "published": "2010-01-21T08:57:27Z",
    "link": "http://arxiv.org/pdf/1001.3744v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "P. Jayarekha",
      "T. R. Gopalakrishnan Nair"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1001.3774v1",
    "title": "Cooperative Proxy Servers Architecture for VoD to Achieve High QoS with\n  Reduced Transmission Time and Cost",
    "summary": "- The aim of this paper is to propose a novel Voice On Demand (VoD)\narchitecture and implementation of an efficient load sharing algorithm to\nachieve Quality of Service (QoS). This scheme reduces the transmission cost\nfrom the Centralized Multimedia Sever (CMS) to Proxy Servers (PS) by sharing\nthe videos among the proxy servers of the Local Proxy Servers Group [LPSG] and\namong the neighboring LPSGs, which are interconnected in a ring fashion. This\nresults in very low request rejection ratio, reduction in transmission time and\ncost, reduction of load on the CMS and high QoS for the users. Simulation\nresults indicate acceptable initial startup latency, reduced transmission cost\nand time, load sharing among the proxy servers, among the LPSGs and between the\nCMS and the PS.",
    "published": "2010-01-21T11:08:42Z",
    "link": "http://arxiv.org/pdf/1001.3774v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "M. Dakshayini",
      "T. R. Gopalakrishan Nair"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1001.4135v1",
    "title": "An Adaptive Dynamic Replacement Approach for a Multicast based\n  Popularity Aware Prefix Cache Memory System",
    "summary": "In this paper we have proposed an adaptive dynamic cache replacement\nalgorithm for a multimedia servers cache system. The goal is to achieve an\neffective utilization of the cache memory which stores the prefix of popular\nvideos. A replacement policy is usually evaluated using hit ratio, the\nfrequency with which any video is requested. Usually discarding the least\nrecently used page is the policy of choice in cache management. The adaptive\ndynamic replacement approach for prefix cache is a self tuning, low overhead\nalgorithm that responds online to changing access patterns. It constantly\nbalances between lru and lfu to improve combined result. It automatically\nadapts to evolving workloads. Since in our algorithm we have considered a\nprefix caching with multicast transmission of popular objects it utilizes the\nhard disk and network bandwidth efficiently and increases the number of\nrequests being served.",
    "published": "2010-01-23T07:20:30Z",
    "link": "http://arxiv.org/pdf/1001.4135v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "P. Jayarekha",
      "T. R. Gopalakrishnan Nair"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1002.1166v1",
    "title": "A Strategy to enable Prefix of Multicast VoD through dynamic buffer\n  allocation",
    "summary": "In this paper we have proposed a dynamic buffer allocation algorithm for the\nprefix, based on the popularity of the videos. More cache blocks are allocated\nfor most popular videos and a few cache blocks are allocated for less popular\nvideos. Buffer utilization is also maximized irrespective of the load on the\nVideo-on-Demand system. Overload can lead the server getting slowed down. By\nstoring the first few seconds of popular video clips, a multimedia local server\ncan shield the users from the delay, throughput, and loss properties of the\npath between the local server and the central server. The key idea of\ncontrolled multicast is used to allow clients to share a segment of a video\nstream even when the requests arrive at different times. This dynamic buffer\nallocation algorithm is simulated and its performance is evaluated based on the\nbuffer utilization by multimedia servers and average buffer allocation for the\nmost popular videos. Our simulation results shows efficient utilization of\nnetwork bandwidth and reduced hard disk utilization hence resulting in increase\nin the number of requests being served.",
    "published": "2010-02-05T09:27:01Z",
    "link": "http://arxiv.org/pdf/1002.1166v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "T. R. GopalaKrishnan nair",
      "P. Jayarekha"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1002.1168v1",
    "title": "Shape-Adaptive Motion Estimation Algorithm for MPEG-4 Video Coding",
    "summary": "This paper presents a gradient based motion estimation algorithm based on\nshape-motion prediction, which takes advantage of the correlation between\nneighboring Binary Alpha Blocks (BABs), to match with the Mpeg-4 shape coding\ncase and speed up the estimation process. The PSNR and computation time\nachieved by the proposed algorithm seem to be better than those obtained by\nmost popular motion estimation techniques.",
    "published": "2010-02-05T09:31:58Z",
    "link": "http://arxiv.org/pdf/1002.1168v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "F. Benboubker",
      "F. Abdi",
      "A. Ahaitouf"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1002.1195v1",
    "title": "Stochastic Model Based Proxy Servers Architecture for VoD to Achieve\n  Reduced Client Waiting Time",
    "summary": "In a video on demand system, the main video repository may be far away from\nthe user and generally has limited streaming capacities. Since a high quality\nvideo's size is huge, it requires high bandwidth for streaming over the\ninternet. In order to achieve a higher video hit ratio, reduced client waiting\ntime, distributed server's architecture can be used, in which multiple local\nservers are placed close to clients and, based on their regional demands video\ncontents are cached dynamically from the main server. As the cost of proxy\nserver is decreasing and demand for reduced waiting time is increasing day by\nday, newer architectures are explored, innovative schemes are arrived at. In\nthis paper we present novel 3 layer architecture, includes main multimedia\nserver, a Tracker and Proxy servers. This architecture targets to optimize the\nclient waiting time. We also propose an efficient prefix caching and load\nsharing algorithm at the proxy server to allocate the cache according to\nregional popularity of the video. The simulation results demonstrate that it\nachieves significantly lower client's waiting time, when compared to the other\nexisting algorithms.",
    "published": "2010-02-05T10:54:05Z",
    "link": "http://arxiv.org/pdf/1002.1195v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "T. R. GopalaKrishnan Nair",
      "M. Dakshayini"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1002.1727v3",
    "title": "An Improved DC Recovery Method from AC Coefficients of DCT-Transformed\n  Images",
    "summary": "Motivated by the work of Uehara et al. [1], an improved method to recover DC\ncoefficients from AC coefficients of DCT-transformed images is investigated in\nthis work, which finds applications in cryptanalysis of selective multimedia\nencryption. The proposed under/over-flow rate minimization (FRM) method employs\nan optimization process to get a statistically more accurate estimation of\nunknown DC coefficients, thus achieving a better recovery performance. It was\nshown by experimental results based on 200 test images that the proposed DC\nrecovery method significantly improves the quality of most recovered images in\nterms of the PSNR values and several state-of-the-art objective image quality\nassessment (IQA) metrics such as SSIM and MS-SSIM.",
    "published": "2010-02-08T22:05:04Z",
    "link": "http://arxiv.org/pdf/1002.1727v3.pdf",
    "category": [
      "cs.MM",
      "cs.CV",
      "I.4.2; E.3"
    ],
    "authors": [
      "Shujun Li",
      "Junaid Jameel Ahmad",
      "Dietmar Saupe",
      "C. -C. Jay Kuo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1002.1951v1",
    "title": "Image Retrieval Techniques based on Image Features, A State of Art\n  approach for CBIR",
    "summary": "The purpose of this Paper is to describe our research on different feature\nextraction and matching techniques in designing a Content Based Image Retrieval\n(CBIR) system. Due to the enormous increase in image database sizes, as well as\nits vast deployment in various applications, the need for CBIR development\narose. Firstly, this paper outlines a description of the primitive feature\nextraction techniques like, texture, colour, and shape. Once these features are\nextracted and used as the basis for a similarity check between images, the\nvarious matching techniques are discussed. Furthermore, the results of its\nperformance are illustrated by a detailed example.",
    "published": "2010-02-09T19:43:44Z",
    "link": "http://arxiv.org/pdf/1002.1951v1.pdf",
    "category": [
      "cs.MM",
      "cs.IR"
    ],
    "authors": [
      "Mr. Kondekar V. H.",
      "Mr. Kolkure V. S.",
      "Prof. Kore S. N"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1002.2184v1",
    "title": "The Fast Haar Wavelet Transform for Signal & Image Processing",
    "summary": "A method for the design of Fast Haar wavelet for signal processing and image\nprocessing has been proposed. In the proposed work, the analysis bank and\nsynthesis bank of Haar wavelet is modified by using polyphase structure.\nFinally, the Fast Haar wavelet was designed and it satisfies alias free and\nperfect reconstruction condition. Computational time and computational\ncomplexity is reduced in Fast Haar wavelet transform.",
    "published": "2010-02-10T19:27:25Z",
    "link": "http://arxiv.org/pdf/1002.2184v1.pdf",
    "category": [
      "cs.MM",
      "cs.CV"
    ],
    "authors": [
      "V. Ashok",
      "T. Balakumaran",
      "C. Gowrishankar",
      "I. L. A. Vennila",
      "A. Nirmal kumar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1002.2191v1",
    "title": "Vision Based Game Development Using Human Computer Interaction",
    "summary": "A Human Computer Interface (HCI) System for playing games is designed here\nfor more natural communication with the machines. The system presented here is\na vision-based system for detection of long voluntary eye blinks and\ninterpretation of blink patterns for communication between man and machine.\nThis system replaces the mouse with the human face as a new way to interact\nwith the computer. Facial features (nose tip and eyes) are detected and tracked\nin realtime to use their actions as mouse events. The coordinates and movement\nof the nose tip in the live video feed are translated to become the coordinates\nand movement of the mouse pointer on the application. The left or right eye\nblinks fire left or right mouse click events. The system works with inexpensive\nUSB cameras and runs at a frame rate of 30 frames per second.",
    "published": "2010-02-10T19:46:07Z",
    "link": "http://arxiv.org/pdf/1002.2191v1.pdf",
    "category": [
      "cs.HC",
      "cs.CV",
      "cs.MM"
    ],
    "authors": [
      "S. Sumathi",
      "S. K. Srivatsa",
      "M. Uma Maheswari"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1002.2193v1",
    "title": "Using Statistical Moment Invariants and Entropy in Image Retrieval",
    "summary": "Although content-based image retrieval (CBIR) is not a new subject, it keeps\nattracting more and more attention, as the amount of images grow tremendously\ndue to internet, inexpensive hardware and automation of image acquisition. One\nof the applications of CBIR is fetching images from a database. This paper\npresents a new method for automatic image retrieval using moment invariants and\nimage entropy, our technique could be used to find semi or perfect matches\nbased on query by example manner, experimental results demonstrate that the\npurposed technique is scalable and efficient.",
    "published": "2010-02-10T19:52:12Z",
    "link": "http://arxiv.org/pdf/1002.2193v1.pdf",
    "category": [
      "cs.MM",
      "cs.IR"
    ],
    "authors": [
      "Ismail I. Amr",
      "Mohamed Amin",
      "Passent El Kafrawy",
      "Amr M. Sauber"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1002.2414v1",
    "title": "Dual Watermarking Scheme with Encryption",
    "summary": "Digital Watermarking is used for copyright protection and authentication. In\nthe proposed system, a Dual Watermarking Scheme based on DWT SVD with chaos\nencryption algorithm, will be developed to improve the robustness and\nprotection along with security. DWT and SVD have been used as a mathematical\ntool to embed watermark in the image. Two watermarks are embedded in the host\nimage. The secondary is embedded into primary watermark and the resultant\nwatermarked image is encrypted using chaos based logistic map. This provides an\nefficient and secure way for image encryption and transmission. The watermarked\nimage is decrypted and a reliable watermark extraction scheme is developed for\nthe extraction of the primary as well as secondary watermark from the distorted\nimage.",
    "published": "2010-02-11T20:05:22Z",
    "link": "http://arxiv.org/pdf/1002.2414v1.pdf",
    "category": [
      "cs.MM",
      "cs.CR"
    ],
    "authors": [
      "R. Dhanalakshmi",
      "K. Thaiyalnayaki"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1002.2416v1",
    "title": "New System for Secure Cover File of Hidden Data in the Image Page within\n  Executable File Using Statistical Steganography Techniques",
    "summary": "A Previously traditional methods were sufficient to protect the information,\nsince it is simplicity in the past does not need complicated methods but with\nthe progress of information technology, it become easy to attack systems, and\ndetection of encryption methods became necessary to find ways parallel with the\ndiffering methods used by hackers, so the embedding methods could be under\nsurveillance from system managers in an organization that requires the high\nlevel of security. This fact requires researches on new hiding methods and\ncover objects which hidden information is embedded in. It is the result from\nthe researches to embed information in executable files, but when will use the\nexecutable file for cover they have many challenges must be taken into\nconsideration which is any changes made to the file will be firstly detected by\nuntie viruses, secondly the functionality of the file is not still functioning.\nIn this paper, a new information hiding system is presented. The aim of the\nproposed system is to hide information (data file) within image page of\nexecution file (EXEfile) to make sure changes made to the file will not be\ndetected by universe and the functionality of the exe.file is still functioning\nafter hiding process. Meanwhile, since the cover file might be used to identify\nhiding information, the proposed system considers overcoming this dilemma by\nusing the execution file as a cover file.",
    "published": "2010-02-11T20:28:15Z",
    "link": "http://arxiv.org/pdf/1002.2416v1.pdf",
    "category": [
      "cs.CR",
      "cs.MM"
    ],
    "authors": [
      "Rafiqul Islam",
      "A. W. Naji",
      "A. A. Zaidan",
      "B. B. Zaidan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1002.3344v1",
    "title": "Iterative exact global histogram specification and SSIM gradient ascent:\n  a proof of convergence, step size and parameter selection",
    "summary": "The SSIM-optimized exact global histogram specification (EGHS) is shown to\nconverge in the sense that the first order approximation of the result's\nquality (i.e., its structural similarity with input) does not decrease in an\niteration, when the step size is small. Each iteration is composed of SSIM\ngradient ascent and basic EGHS with the specified target histogram. Selection\nof step size and other parameters is also discussed.",
    "published": "2010-02-17T18:29:09Z",
    "link": "http://arxiv.org/pdf/1002.3344v1.pdf",
    "category": [
      "cs.CV",
      "cs.MM"
    ],
    "authors": [
      "Alireza Avanaki"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1002.3984v1",
    "title": "Effect of Embedding Watermark on Compression of the Digital Images",
    "summary": "Image Compression plays a very important role in image processing especially\nwhen we are to send the image on the internet. The threat to the information on\nthe internet increases and image is no exception. Generally the image is sent\non the internet as the compressed image to optimally use the bandwidth of the\nnetwork. But as we are on the network, at any intermediate level the image can\nbe changed intentionally or unintentionally. To make sure that the correct\nimage is being delivered at the other end we embed the water mark to the image.\nThe watermarked image is then compressed and sent on the network. When the\nimage is decompressed at the other end we can extract the watermark and make\nsure that the image is the same that was sent by the other end. Though\nwatermarking the image increases the size of the uncompressed image but that\nhas to done to achieve the high degree of robustness i.e. how an image sustains\nthe attacks on it. The present paper is an attempt to make transmission of the\nimages secure from the intermediate attacks by applying the generally used\ncompression transforms.",
    "published": "2010-02-21T18:29:53Z",
    "link": "http://arxiv.org/pdf/1002.3984v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Deepak Aggarwal",
      "Kanwalvir Singh Dhindsa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1002.4049v1",
    "title": "Optimization Digital Image Watermarking Technique for Patent Protection",
    "summary": "The rapid development of multimedia and internet allows for wide distribution\nof digital media data. It becomes much easier to edit, modify and duplicate\ndigital information besides that, digital documents are also easy to copy and\ndistribute, therefore it will be faced by many threats. It is a big security\nand privacy issue. Another problem with digital document and video is that\nundetectable modifications can be made with very simple and widely available\nequipment, which put the digital material for evidential purposes under\nquestion With the large flood of information and the development of the digital\nformat, it become necessary to find appropriate protection because of the\nsignificance, accuracy and sensitivity of the information, therefore multimedia\ntechnology and popularity of internet communications they have great interest\nin using digital watermarks for the purpose of copy protection and content\nauthentication. Digital watermarking is a technique used to embed a known piece\nof digital data within another piece of digital data .A digital data may\nrepresent a digital signature or digital watermark that is embedded in the host\nmedia. The signature or watermark is hidden such that it's perceptually and\nstatistically undetectable. Then this signature or watermark can be extracted\nfrom the host media and used to identify the owner of the media.",
    "published": "2010-02-22T03:19:07Z",
    "link": "http://arxiv.org/pdf/1002.4049v1.pdf",
    "category": [
      "cs.MM",
      "cs.CR"
    ],
    "authors": [
      "Mahmoud Elnajjar",
      "A. A Zaidan",
      "B. B Zaidan",
      "Mohamed Elhadi M. Sharif",
      "Hamdan. O. Alanazi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1002.4303v1",
    "title": "What are suspicious VoIP delays?",
    "summary": "Voice over IP (VoIP) is unquestionably the most popular real-time service in\nIP networks today. Recent studies have shown that it is also a suitable carrier\nfor information hiding. Hidden communication may pose security concerns as it\ncan lead to confidential information leakage. In VoIP, RTP (Real-time Transport\nProtocol) in particular, which provides the means for the successful transport\nof voice packets through IP networks, is suitable for steganographic purposes.\nIt is characterised by a high packet rate compared to other protocols used in\nIP telephony, resulting in a potentially high steganographic bandwidth. The\nmodification of an RTP packet stream provides many opportunities for hidden\ncommunication as the packets may be delayed, reordered or intentionally lost.\nIn this paper, to enable the detection of steganographic exchanges in VoIP, we\nexamined real RTP traffic traces to answer the questions, what do the \"normal\"\ndelays in RTP packet streams look like? and, is it possible to detect the use\nof known RTP steganographic methods based on this knowledge?",
    "published": "2010-02-23T11:22:50Z",
    "link": "http://arxiv.org/pdf/1002.4303v1.pdf",
    "category": [
      "cs.CR",
      "cs.MM"
    ],
    "authors": [
      "Wojciech Mazurczyk",
      "Krzysztof Cabaj",
      "Krzysztof Szczypiorski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1003.2471v1",
    "title": "Structure-Aware Stochastic Control for Transmission Scheduling",
    "summary": "In this paper, we consider the problem of real-time transmission scheduling\nover time-varying channels. We first formulate the transmission scheduling\nproblem as a Markov decision process (MDP) and systematically unravel the\nstructural properties (e.g. concavity in the state-value function and\nmonotonicity in the optimal scheduling policy) exhibited by the optimal\nsolutions. We then propose an online learning algorithm which preserves these\nstructural properties and achieves -optimal solutions for an arbitrarily small\n. The advantages of the proposed online method are that: (i) it does not\nrequire a priori knowledge of the traffic arrival and channel statistics and\n(ii) it adaptively approximates the state-value functions using piece-wise\nlinear functions and has low storage and computation complexity. We also extend\nthe proposed low-complexity online learning solution to the prioritized data\ntransmission. The simulation results demonstrate that the proposed method\nachieves significantly better utility (or delay)-energy trade-offs when\ncomparing to existing state-of-art online optimization methods.",
    "published": "2010-03-12T04:07:41Z",
    "link": "http://arxiv.org/pdf/1003.2471v1.pdf",
    "category": [
      "cs.LG",
      "cs.IT",
      "cs.MM",
      "math.IT"
    ],
    "authors": [
      "Fangwen Fu",
      "Mihaela van der Schaar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1003.3080v1",
    "title": "An Algorithm for Index Multimedia Data (Video) using the Movement\n  Oriented Method for Real-time Online Services",
    "summary": "Multimedia data is a form of data that can represent all types of data\n(images, sound and text). The use of multimedia data for the online application\nrequires a more comprehensive database in the use of storage media, Sorting /\nindexing, search and system / data searching. This is necessary in order to\nhelp providers and users to access multimedia data online. Systems that use of\nthe index image as a reference requires storage media so that the rules and\nrequire special expertise to obtain the desired file. Changes in multimedia\ndata into a series of stories / storyboard in the form of a text will help\nreduce the consumption of media storage, system index / sorting and search\napplications. Oriented Movement is one method that is being developed to change\nthe form of multimedia data into a storyboard.",
    "published": "2010-03-16T05:07:10Z",
    "link": "http://arxiv.org/pdf/1003.3080v1.pdf",
    "category": [
      "cs.MM",
      "cs.IR"
    ],
    "authors": [
      "A. Muslim",
      "A. B. Mutiara",
      "C. M. Karyati",
      "P. Musa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1003.3533v1",
    "title": "Towards Automated Lecture Capture, Navigation and Delivery System for\n  Web-Lecture on Demand",
    "summary": "Institutions all over the world are continuously exploring ways to use ICT in\nimproving teaching and learning effectiveness. The use of course web pages,\ndiscussion groups, bulletin boards, and e-mails have shown considerable impact\non teaching and learning in significant ways, across all disciplines. ELearning\nhas emerged as an alternative to traditional classroom-based education and\ntraining and web lectures can be a powerful addition to traditional lectures.\nThey can even serve as a main content source for learning, provided users can\nquickly navigate and locate relevant pages in a web lecture. A web lecture\nconsists of video and audio of the presenter and slides complemented with\nscreen capturing. In this paper, an automated approach for recording live\nlectures and for browsing available web lectures for on-demand applications by\nend users is presented.",
    "published": "2010-03-18T09:27:16Z",
    "link": "http://arxiv.org/pdf/1003.3533v1.pdf",
    "category": [
      "cs.MM",
      "cs.IR"
    ],
    "authors": [
      "Rajkumar Kannan",
      "Frederic Andres"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1003.4049v1",
    "title": "An Optimal Prefix Replication Strategy for VoD Services",
    "summary": "In this paper we propose scalable proxy servers cluster architecture of\ninterconnected proxy servers for high quality and high availability services.\nWe also propose an optimal regional popularity based video prefix replication\nstrategy and a scene change based replica caching algorithm that utilizes the\nzipf-like video popularity distribution to maximize the availability of videos\ncloser to the client and request-servicing rate thereby reducing the client\nrejection ratio and the response time for the client. The simulation results of\nour proposed architecture and algorithm show the greater achievement in\nmaximizing the availability of videos, client request-servicing rate and in\nreduction of initial start-up latency and client rejection ratio.",
    "published": "2010-03-22T03:31:50Z",
    "link": "http://arxiv.org/pdf/1003.4049v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "M Dakshayini",
      "T R GopalaKrishnan Nair"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1003.4083v1",
    "title": "Voice Recognition Algorithms using Mel Frequency Cepstral Coefficient\n  (MFCC) and Dynamic Time Warping (DTW) Techniques",
    "summary": "Digital processing of speech signal and voice recognition algorithm is very\nimportant for fast and accurate automatic voice recognition technology. The\nvoice is a signal of infinite information. A direct analysis and synthesizing\nthe complex voice signal is due to too much information contained in the\nsignal. Therefore the digital signal processes such as Feature Extraction and\nFeature Matching are introduced to represent the voice signal. Several methods\nsuch as Liner Predictive Predictive Coding (LPC), Hidden Markov Model (HMM),\nArtificial Neural Network (ANN) and etc are evaluated with a view to identify a\nstraight forward and effective method for voice signal. The extraction and\nmatching process is implemented right after the Pre Processing or filtering\nsignal is performed. The non-parametric method for modelling the human auditory\nperception system, Mel Frequency Cepstral Coefficients (MFCCs) are utilize as\nextraction techniques. The non linear sequence alignment known as Dynamic Time\nWarping (DTW) introduced by Sakoe Chiba has been used as features matching\ntechniques. Since it's obvious that the voice signal tends to have different\ntemporal rate, the alignment is important to produce the better\nperformance.This paper present the viability of MFCC to extract features and\nDTW to compare the test patterns.",
    "published": "2010-03-22T06:39:55Z",
    "link": "http://arxiv.org/pdf/1003.4083v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Lindasalwa Muda",
      "Mumtaj Begam",
      "I. Elamvazuthi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1003.4084v1",
    "title": "New Classification Methods for Hiding Information into Two Parts:\n  Multimedia Files and Non Multimedia Files",
    "summary": "With the rapid development of various multimedia technologies, more and more\nmultimedia data are generated and transmitted in the medical, commercial, and\nmilitary fields, which may include some sensitive information which should not\nbe accessed by or can only be partially exposed to the general users.\nTherefore, security and privacy has become an important, Another problem with\ndigital document and video is that undetectable modifications can be made with\nvery simple and widely available equipment, which put the digital material for\nevidential purposes under question .With the large flood of information and the\ndevelopment of the digital format Information hiding considers one of the\ntechniques which used to protect the important information. The main goals for\nthis paper, provides a general overview of the New Classification Methods for\nHiding Information into Two Parts: Multimedia Files and Non Multimedia Files.",
    "published": "2010-03-22T06:42:05Z",
    "link": "http://arxiv.org/pdf/1003.4084v1.pdf",
    "category": [
      "cs.MM",
      "cs.CR"
    ],
    "authors": [
      "Hamdan. O. Alanazi",
      "A. A. Zaidan",
      "B. B. Zaidan",
      "Hamid A. Jalab",
      "Zaidoon Kh. AL-Ani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1003.4086v1",
    "title": "Overview: Main Fundamentals for Steganography",
    "summary": "The rapid development of multimedia and internet allows for wide distribution\nof digital media data. It becomes much easier to edit, modify and duplicate\ndigital information .Besides that, digital documents are also easy to copy and\ndistribute, therefore it will be faced by many threats. It is a big security\nand privacy issue, it become necessary to find appropriate protection because\nof the significance, accuracy and sensitivity of the information. Steganography\nconsiders one of the techniques which used to protect the important\ninformation. The main goals for this paper, to recognize the researchers for\nthe main fundamentals of steganography. In this paper provides a general\noverview of the following subject areas: Steganography types, General\nSteganography system, Characterization of Steganography Systems and\nClassification of Steganography Techniques.",
    "published": "2010-03-22T06:46:04Z",
    "link": "http://arxiv.org/pdf/1003.4086v1.pdf",
    "category": [
      "cs.CR",
      "cs.MM"
    ],
    "authors": [
      "Zaidoon Kh. AL-Ani",
      "A. A. Zaidan",
      "B. B. Zaidan",
      "Hamdan. O. Alanazi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1003.4637v1",
    "title": "Context-Oriented Web Video Tag Recommendation",
    "summary": "Tag recommendation is a common way to enrich the textual annotation of\nmultimedia contents. However, state-of-the-art recommendation methods are built\nupon the pair-wised tag relevance, which hardly capture the context of the web\nvideo, i.e., when who are doing what at where. In this paper we propose the\ncontext-oriented tag recommendation (CtextR) approach, which expands tags for\nweb videos under the context-consistent constraint. Given a web video, CtextR\nfirst collects the multi-form WWW resources describing the same event with the\nvideo, which produce an informative and consistent context; and then, the tag\nrecommendation is conducted based on the obtained context. Experiments on an\n80,031 web video collection show CtextR recommends various relevant tags to web\nvideos. Moreover, the enriched tags improve the performance of web video\ncategorization.",
    "published": "2010-03-24T13:07:08Z",
    "link": "http://arxiv.org/pdf/1003.4637v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Zhineng Chen",
      "Juan Cao",
      "Yicheng Song",
      "Junbo Guo",
      "Yongdong Zhang",
      "Jintao Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1003.5435v1",
    "title": "Image Compression and Watermarking scheme using Scalar Quantization",
    "summary": "This paper presents a new compression technique and image watermarking\nalgorithm based on Contourlet Transform (CT). For image compression, an energy\nbased quantization is used. Scalar quantization is explored for image\nwatermarking. Double filter bank structure is used in CT. The Laplacian Pyramid\n(LP) is used to capture the point discontinuities, and then followed by a\nDirectional Filter Bank (DFB) to link point discontinuities. The coefficients\nof down sampled low pass version of LP decomposed image are re-ordered in a\npre-determined manner and prediction algorithm is used to reduce entropy\n(bits/pixel). In addition, the coefficients of CT are quantized based on the\nenergy in the particular band. The superiority of proposed algorithm to JPEG is\nobserved in terms of reduced blocking artifacts. The results are also compared\nwith wavelet transform (WT). Superiority of CT to WT is observed when the image\ncontains more contours. The watermark image is embedded in the low pass image\nof contourlet decomposition. The watermark can be extracted with minimum error.\nIn terms of PSNR, the visual quality of the watermarked image is exceptional.\nThe proposed algorithm is robust to many image attacks and suitable for\ncopyright protection applications.",
    "published": "2010-03-29T06:51:17Z",
    "link": "http://arxiv.org/pdf/1003.5435v1.pdf",
    "category": [
      "cs.CV",
      "cs.MM"
    ],
    "authors": [
      "Kilari Veera Swamy",
      "B. Chandra Mohan",
      "Y. V. Bhaskar Reddy",
      "S. Srinivas Kumar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1004.0085v1",
    "title": "A stochastic model of human visual attention with a dynamic Bayesian\n  network",
    "summary": "Recent studies in the field of human vision science suggest that the human\nresponses to the stimuli on a visual display are non-deterministic. People may\nattend to different locations on the same visual input at the same time. Based\non this knowledge, we propose a new stochastic model of visual attention by\nintroducing a dynamic Bayesian network to predict the likelihood of where\nhumans typically focus on a video scene. The proposed model is composed of a\ndynamic Bayesian network with 4 layers. Our model provides a framework that\nsimulates and combines the visual saliency response and the cognitive state of\na person to estimate the most probable attended regions. Sample-based inference\nwith Markov chain Monte-Carlo based particle filter and stream processing with\nmulti-core processors enable us to estimate human visual attention in near real\ntime. Experimental results have demonstrated that our model performs\nsignificantly better in predicting human visual attention compared to the\nprevious deterministic models.",
    "published": "2010-04-01T08:51:32Z",
    "link": "http://arxiv.org/pdf/1004.0085v1.pdf",
    "category": [
      "cs.CV",
      "cs.MM",
      "cs.NE",
      "stat.ML",
      "68U10",
      "I.4.8; I.4.10; I.5.1; I.6.8; I.2.10; I.4.4; I.2.9; I.3.1"
    ],
    "authors": [
      "Akisato kimura",
      "Derek Pang",
      "Tatsuto Takeuchi",
      "Kouji Miyazato",
      "Junji Yamato",
      "Kunio Kashino"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1004.0243v1",
    "title": "Psychophysiological Correlations with Gameplay Experience Dimensions",
    "summary": "In this paper, we report a case study using two easy-to-deploy\npsychophysiological measures - electrodermal activity (EDA) and heart rate (HR)\n- and correlating them with a gameplay experience questionnaire (GEQ) in an\nattempt to establish this mixed-methods approach for rapid application in a\ncommercial game development context. Results indicate that there is a\nstatistically significant correlation (p < 0.01) between measures of\npsychophysiological arousal (HR, EDA) and self-reported UX in games (GEQ), with\nsome variation between the EDA and HR measures. Results are consistent across\nthree major commercial First-Person Shooter (FPS) games.",
    "published": "2010-04-01T21:52:36Z",
    "link": "http://arxiv.org/pdf/1004.0243v1.pdf",
    "category": [
      "cs.HC",
      "cs.MM",
      "91E30",
      "K.8.0; J.4"
    ],
    "authors": [
      "Anders Drachen",
      "Lennart E. Nacke",
      "Georgios Yannakakis",
      "Anja Lee Pedersen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1004.0248v1",
    "title": "Affective Ludology, Flow and Immersion in a First- Person Shooter:\n  Measurement of Player Experience",
    "summary": "Gameplay research about experiential phenomena is a challenging undertaking,\ngiven the variety of experiences that gamers encounter when playing and which\ncurrently do not have a formal taxonomy, such as flow, immersion, boredom, and\nfun. These informal terms require a scientific explanation. Ludologists also\nacknowledge the need to understand cognition, emotion, and goal- oriented\nbehavior of players from a psychological perspective by establishing rigorous\nmethodologies. This paper builds upon and extends prior work in an area for\nwhich we would like to coin the term \"affective ludology.\" The area is\nconcerned with the affective measurement of player-game interaction. The\nexperimental study reported here investigated different traits of gameplay\nexperience using subjective (i.e., questionnaires) and objective (i.e.,\npsychophysiological) measures. Participants played three Half-Life 2 game level\ndesign modifications while measures such as electromyography (EMG),\nelectrodermal activity (EDA) were taken and questionnaire responses were\ncollected. A level designed for combat-oriented flow experience demonstrated\nsignificant high-arousal positive affect emotions. This method shows that\nemotional patterns emerge from different level designs, which has great\npotential for providing real-time emotional profiles of gameplay that may be\ngenerated together with self- reported subjective player experience\ndescriptions.",
    "published": "2010-04-01T22:24:47Z",
    "link": "http://arxiv.org/pdf/1004.0248v1.pdf",
    "category": [
      "cs.HC",
      "cs.MM",
      "91-XX; 91E30",
      "K.8.0; H.5.1; J.4; D.2.8"
    ],
    "authors": [
      "Lennart E. Nacke",
      "Craig A. Lindley"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1004.0256v1",
    "title": "From Playability to a Hierarchical Game Usability Model",
    "summary": "This paper presents a brief review of current game usability models. This\nleads to the conception of a high-level game development-centered usability\nmodel that integrates current usability approaches in game industry and game\nresearch.",
    "published": "2010-04-01T23:42:11Z",
    "link": "http://arxiv.org/pdf/1004.0256v1.pdf",
    "category": [
      "cs.HC",
      "cs.MM",
      "97Rxx",
      "K.8.0; H.5.1; J.4"
    ],
    "authors": [
      "Lennart E. Nacke"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1004.0258v1",
    "title": "Trends and Techniques in Visual Gaze Analysis",
    "summary": "Visualizing gaze data is an effective way for the quick interpretation of eye\ntracking results. This paper presents a study investigation benefits and\nlimitations of visual gaze analysis among eye tracking professionals and\nresearchers. The results were used to create a tool for visual gaze analysis\nwithin a Master's project.",
    "published": "2010-04-01T23:48:23Z",
    "link": "http://arxiv.org/pdf/1004.0258v1.pdf",
    "category": [
      "cs.HC",
      "cs.CV",
      "cs.GR",
      "cs.MM",
      "00A66",
      "H.5.1; I.4.8"
    ],
    "authors": [
      "Sophie Stellmach",
      "Lennart E. Nacke",
      "Raimund Dachselt",
      "Craig A. Lindley"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1004.0259v1",
    "title": "Gameplay experience in a gaze interaction game",
    "summary": "Assessing gameplay experience for gaze interaction games is a challenging\ntask. For this study, a gaze interaction Half-Life 2 game modification was\ncreated that allowed eye tracking control. The mod was deployed during an\nexperiment at Dreamhack 2007, where participants had to play with gaze\nnavigation and afterwards rate their gameplay experience. The results show low\ntension and negative affects scores on the gameplay experience questionnaire as\nwell as high positive challenge, immersion and flow ratings. The correlation\nbetween spatial presence and immersion for gaze interaction was high and yields\nfurther investigation. It is concluded that gameplay experience can be\ncorrectly assessed with the methodology presented in this paper.",
    "published": "2010-04-01T23:52:50Z",
    "link": "http://arxiv.org/pdf/1004.0259v1.pdf",
    "category": [
      "cs.HC",
      "cs.MM",
      "91A90",
      "I.4.8; H.5.1; K.8.0"
    ],
    "authors": [
      "Lennart E. Nacke",
      "Sophie Stellmach",
      "Dennis Sasse",
      "Craig A. Lindley"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1004.0762v1",
    "title": "Integrating identity-based cryptography in IMS service authentication",
    "summary": "Nowadays, the IP Multimedia Subsystem (IMS) is a promising research field.\nMany ongoing works related to the security and the performances of its\nemployment are presented to the research community. Although, the security and\ndata privacy aspects are very important in the IMS global objectives, they\nobserve little attention so far. Secure access to multimedia services is based\non SIP and HTTP digest on top of IMS architecture. The standard deploys AKA-MD5\nfor the terminal authentication. The third Generation Partnership Project\n(3GPP) provided Generic Bootstrapping Architecture (GBA) to authenticate the\nsubscriber before accessing multimedia services over HTTP. In this paper, we\npropose a new IMS Service Authentication scheme using Identity Based\ncryptography (IBC). This new scheme will lead to better performances when there\nare simultaneous authentication requests using Identity-based Batch\nVerification. We analyzed the security of our new protocol and we presented a\nperformance evaluation of its cryptographic operations",
    "published": "2010-04-06T03:38:59Z",
    "link": "http://arxiv.org/pdf/1004.0762v1.pdf",
    "category": [
      "cs.CR",
      "cs.MM"
    ],
    "authors": [
      "Mohamed Abid",
      "Songbo Song",
      "Hassnaa Moustafa",
      "Hossam Afifi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1004.1229v1",
    "title": "Feature-Based Adaptive Tolerance Tree (FATT): An Efficient Indexing\n  Technique for Content-Based Image Retrieval Using Wavelet Transform",
    "summary": "This paper introduces a novel indexing and access method, called Feature-\nBased Adaptive Tolerance Tree (FATT), using wavelet transform is proposed to\norganize large image data sets efficiently and to support popular image access\nmechanisms like Content Based Image Retrieval (CBIR).Conventional database\nsystems are designed for managing textual and numerical data and retrieving\nsuch data is often based on simple comparisons of text or numerical values.\nHowever, this method is no longer adequate for images, since the digital\npresentation of images does not convey the reality of images. Retrieval of\nimages become difficult when the database is very large. This paper addresses\nsuch problems and presents a novel indexing technique, Feature Based Adaptive\nTolerance Tree (FATT), which is designed to bring an effective solution\nespecially for indexing large databases. The proposed indexing scheme is then\nused along with a query by image content, in order to achieve the ultimate goal\nfrom the user point of view that is retrieval of all relevant images. FATT\nindexing technique, features of the image is extracted using 2-dimensional\ndiscrete wavelet transform (2DDWT) and index code is generated from the\ndeterminant value of the features. Multiresolution analysis technique using\n2D-DWT can decompose the image into components at different scales, so that the\ncoarest scale components carry the global approximation information while the\nfiner scale components contain the detailed information. Experimental results\nshow that the FATT outperforms M-tree upto 200%, Slim-tree up to 120% and HCT\nupto 89%. FATT indexing technique is adopted to increase the efficiently of\ndata storage and retrieval.",
    "published": "2010-04-08T02:56:58Z",
    "link": "http://arxiv.org/pdf/1004.1229v1.pdf",
    "category": [
      "cs.MM",
      "cs.DB"
    ],
    "authors": [
      "Dr. P. AnandhaKumar",
      "V. Balamurugan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1004.1676v1",
    "title": "A reversible high embedding capacity data hiding technique for hiding\n  secret data in images",
    "summary": "As the multimedia and internet technologies are growing fast, the\ntransmission of digital media plays an important role in communication. The\nvarious digital media like audio, video and images are being transferred\nthrough internet. There are a lot of threats for the digital data that are\ntransferred through internet. Also, a number of security techniques have been\nemployed to protect the data that is transferred through internet. This paper\nproposes a new technique for sending secret messages securely, using\nsteganographic technique. Since the proposed system uses multiple level of\nsecurity for data hiding, where the data is hidden in an image file and the\nstego file is again concealed in another image. Previously, the secret message\nis being encrypted with the encryption algorithm which ensures the achievement\nof high security enabled data transfer through internet.",
    "published": "2010-04-10T03:42:06Z",
    "link": "http://arxiv.org/pdf/1004.1676v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "P. Mohan Kumar",
      "K. L. Shunmuganathan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1004.1682v1",
    "title": "Design And Implementation Of Multilevel Access Control In Medical Image\n  Transmission Using Symmetric Polynomial Based Audio Steganography",
    "summary": "...The steganography scheme makes it possible to hide the medical image in\ndifferent bit locations of host media without inviting suspicion. The Secret\nfile is embedded in a cover media with a key. At the receiving end the key can\nbe derived by all the classes which are higher in the hierarchy using symmetric\npolynomial and the medical image file can be retrieved. The system is\nimplemented and found to be secure, fast and scalable. Simulation results show\nthat the system is dynamic in nature and allows any type of hierarchy. The\nproposed approach performs better even during frequent member joins and leaves.\nThe computation cost is reduced as the same algorithm is used for key\ncomputation and descendant key derivation. Steganographic technique used in\nthis paper does not use the conventional LSB's and uses two bit positions and\nthe hidden data occurs only from a frame which is dictated by the key that is\nused. Hence the quality of stego data is improved.",
    "published": "2010-04-10T04:29:01Z",
    "link": "http://arxiv.org/pdf/1004.1682v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "J. Nafeesa Begum",
      "K. Kumar",
      "V. Sumathy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1004.1757v1",
    "title": "Processor Based Active Queue Management for providing QoS in Multimedia\n  Application",
    "summary": "The objective of this paper is to implement the Active Network based Active\nQueue Management Technique for providing Quality of Service (QoS) using Network\nProcessor(NP) based router to enhance multimedia applications. The performance\nis evaluated using Intel IXP2400 NP Simulator. The results demonstrate that,\nActive Network based Active Queue Management has better performance than RED\nalgorithm in case of congestion and is well suited to achieve high speed packet\nclassification to support multimedia applications with minimum delay and Queue\nloss. Using simulation, we show that the proposed system can provide assurance\nfor prioritized flows with improved network utilization where bandwidth is\nshared among the flows according to the levels of priority. We first analyze\nthe feasibility and optimality of the load distribution schemes and then\npresent separate solutions for non-delay sensitive streams and delay-sensitive\nstreams. Rigorous simulations and experiments have been carried out to evaluate\nthe performance.",
    "published": "2010-04-11T03:44:30Z",
    "link": "http://arxiv.org/pdf/1004.1757v1.pdf",
    "category": [
      "cs.NI",
      "cs.MM"
    ],
    "authors": [
      "N. Saravana Selvam",
      "S. Radhakrishnan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1004.1770v1",
    "title": "Review of Robust Video Watermarking Algorithms",
    "summary": "There has been a remarkable increase in the data exchange over web and the\nwidespread use of digital media. As a result, multimedia data transfers also\nhad a boost up. The mounting interest with reference to digital watermarking\nthroughout the last decade is certainly due to the increase in the need of\ncopyright protection of digital content. This is also enhanced due to\ncommercial prospective. Applications of video watermarking in copy control,\nbroadcast monitoring, fingerprinting, video authentication, copyright\nprotection etc is immensely rising. The main aspects of information hiding are\ncapacity, security and robustness. Capacity deals with the amount of\ninformation that can be hidden. The skill of anyone detecting the information\nis security and robustness refers to the resistance to modification of the\ncover content before concealed information is destroyed. Video watermarking\nalgorithms normally prefers robustness. In a robust algorithm it is not\npossible to eliminate the watermark without rigorous degradation of the cover\ncontent. In this paper, we introduce the notion of Video Watermarking and the\nfeatures required to design a robust watermarked video for a valuable\napplication. We review several algorithms, and introduce frequently used key\ntechniques. The aim of this paper is to focus on the various domains of video\nwatermarking techniques. The majority of the reviewed methods based on video\nwatermarking emphasize on the notion of robustness of the algorithm.",
    "published": "2010-04-11T08:07:40Z",
    "link": "http://arxiv.org/pdf/1004.1770v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Neeta Deshpande",
      "Archana Rajurkar",
      "R Manthalkar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1004.1789v1",
    "title": "SAR Image Segmentation using Vector Quantization Technique on Entropy\n  Images",
    "summary": "The development and application of various remote sensing platforms result in\nthe production of huge amounts of satellite image data. Therefore, there is an\nincreasing need for effective querying and browsing in these image databases.\nIn order to take advantage and make good use of satellite images data, we must\nbe able to extract meaningful information from the imagery. Hence we proposed a\nnew algorithm for SAR image segmentation. In this paper we propose segmentation\nusing vector quantization technique on entropy image. Initially, we obtain\nentropy image and in second step we use Kekre's Fast Codebook Generation (KFCG)\nalgorithm for segmentation of the entropy image. Thereafter, a codebook of size\n128 was generated for the Entropy image. These code vectors were further\nclustered in 8 clusters using same KFCG algorithm and converted into 8 images.\nThese 8 images were displayed as a result. This approach does not lead to over\nsegmentation or under segmentation. We compared these results with well known\nGray Level Co-occurrence Matrix. The proposed algorithm gives better\nsegmentation with less complexity.",
    "published": "2010-04-11T11:05:33Z",
    "link": "http://arxiv.org/pdf/1004.1789v1.pdf",
    "category": [
      "cs.MM",
      "cs.CV"
    ],
    "authors": [
      "H. B. Kekre",
      "Saylee Gharge",
      "Tanuja K. Sarode"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1004.1791v1",
    "title": "Reversible Image data Hiding using Lifting wavelet Transform and\n  Histogram Shifting",
    "summary": "A method of lossless data hiding in images using integer wavelet transform\nand histogram shifting for gray scale images is proposed. The method shifts\npart of the histogram, to create space for embedding the watermark information\nbits. The method embeds watermark while maintaining the visual quality well.\nThe method is completely reversible. The original image and the watermark data\ncan be recovered without any loss.",
    "published": "2010-04-11T11:11:59Z",
    "link": "http://arxiv.org/pdf/1004.1791v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "S. Kurshid Jinna",
      "L. Ganesan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1004.3275v1",
    "title": "C Implementation & comparison of companding & silence audio compression\n  techniques",
    "summary": "Just about all the newest living room audio-video electronics and PC\nmultimedia products being designed today will incorporate some form of\ncompressed digitized-audio processing capability. Audio compression reduces the\nbit rate required to represent an analog audio signal while maintaining the\nperceived audio quality. Discarding inaudible data reduces the storage,\ntransmission and compute requirements of handling high-quality audio files.\nThis paper covers wave audio file format & algorithm of silence compression\nmethod and companding method to compress and decompress wave audio file. Then\nit compares the result of these two methods.",
    "published": "2010-04-19T18:26:09Z",
    "link": "http://arxiv.org/pdf/1004.3275v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Kruti Dangarwala",
      "Jigar Shah"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1004.3523v1",
    "title": "Access-Network Association Policies for Media Streaming in Heterogeneous\n  Environments",
    "summary": "We study the design of media streaming applications in the presence of\nmultiple heterogeneous wireless access methods with different throughputs and\ncosts. Our objective is to analytically characterize the trade-off between the\nusage cost and the Quality of user Experience (QoE), which is represented by\nthe probability of interruption in media playback and the initial waiting time.\nWe model each access network as a server that provides packets to the user\naccording to a Poisson process with a certain rate and cost. Blocks are coded\nusing random linear codes to alleviate the duplicate packet reception problem.\nUsers must take decisions on how many packets to buffer before playout, and\nwhich networks to access during playout. We design, analyze and compare several\ncontrol policies with a threshold structure. We formulate the problem of\nfinding the optimal control policy as an MDP with a probabilistic constraint.\nWe present the HJB equation for this problem by expanding the state space, and\nexploit it as a verification method for optimality of the proposed control law.",
    "published": "2010-04-20T18:32:58Z",
    "link": "http://arxiv.org/pdf/1004.3523v1.pdf",
    "category": [
      "math.OC",
      "cs.MM"
    ],
    "authors": [
      "Ali ParandehGheibi",
      "Muriel Medard",
      "Asuman Ozdaglar",
      "Srinivas Shakkottai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1004.3556v1",
    "title": "Policies and Economics of Digital Multimedia Transmission",
    "summary": "There are different Standards of digital multimedia transmission, for example\nDVB in Europe and ISDB in Japan and DMB in Korea, with different delivery\nsystem (example MPEG-2, MPEG-4).This paper describe an overview of Digital\nMultimedia Transmission (DMT) technologies. The economic aspects of digital\ncontent & software solution industry as a strategic key in the future will be\ndiscussed. The study then focuses on some important policy and technology\nissues, such S-DMB, T-DMB, Digital Video Broadcasting Handheld (DVB-H) and\nconcludes DMT policies for convergence of telecommunications and broadcasting.",
    "published": "2010-04-20T20:14:19Z",
    "link": "http://arxiv.org/pdf/1004.3556v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Mohsen Gerami"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1004.4241v1",
    "title": "Error Concealment in Image Communication Using Edge Map Watermarking and\n  Spatial Smoothing",
    "summary": "We propose a novel error concealment algorithm to be used at the receiver\nside of a lossy image transmission system. Our algorithm involves hiding the\nedge map of the original image at the transmitter within itself using a robust\nwatermarking scheme. At the receiver, wherever a lost block is detected, the\nextracted edge information is used as border constraint for the spatial\nsmoothing employing the intact neighboring blocks in order to conceal errors.\nSimulation results show the superiority of our technique over existing methods\neven in case of high packet loss ratios in the communication network.",
    "published": "2010-04-24T00:29:00Z",
    "link": "http://arxiv.org/pdf/1004.4241v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Shabnam Sodagari",
      "Peyman Hesami",
      "Alireza Nasiri Avanaki"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1004.4457v1",
    "title": "Combination of Subtractive Clustering and Radial Basis Function in\n  Speaker Identification",
    "summary": "Speaker identification is the process of determining which registered speaker\nprovides a given utterance. Speaker identification required to make a claim on\nthe identity of speaker from the Ns trained speaker in its user database. In\nthis study, we propose the combination of clustering algorithm and the\nclassification technique - subtractive and Radial Basis Function (RBF). The\nproposed technique is chosen because RBF is a simpler network structures and\nfaster learning algorithm. RBF finds the input to output map using the local\napproximators which will combine the linear of the approximators and cause the\nlinear combiner have few weights. Besides that, RBF neural network model using\nsubtractive clustering algorithm for selecting the hidden node centers, which\ncan achieve faster training speed. In the meantime, the RBF network was trained\nwith a regularization term so as to minimize the variances of the nodes in the\nhidden layer and perform more accu-rate prediction.",
    "published": "2010-04-26T09:57:23Z",
    "link": "http://arxiv.org/pdf/1004.4457v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Ibrahim A. Albidewi",
      "Yap Teck Ann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1004.4459v1",
    "title": "Visual Infrared Video Fusion for Night Vision using Background\n  Estimation",
    "summary": "Video fusion is a process that combines visual data from different sensors to\nobtain a single composite video preserving the information of the sources. The\navailability of a system, enhancing human ability to perceive the observed\nscenario, is crucial to improve the performance of a surveillance system. The\ninfrared (IR) camera captures thermal image of object in night-time\nenvironment, when only limited visual information can be captured by RGB\ncamera. The fusion of data recorded by an IR sensor and a visible RGB camera\ncan produce information otherwise not obtainable by viewing the sensor outputs\nseparately. In this paper we consider the problem of fusing two video streams\nacquired by an RGB camera and an IR sensor. The pedestrians, distinctly\ncaptured by IR video, are separated and fused with the RGB video. The\nalgorithms implemented involve estimation of the background, followed by\ndetection of object from the IR Video, after necessary denoising. Finally a\nsuitable fusion algorithm is employed to combine the extracted pedestrians with\nthe visual output. The obtained results clearly demonstrate the effectiveness\nof the proposed video fusion scheme, for night vision.",
    "published": "2010-04-26T10:01:53Z",
    "link": "http://arxiv.org/pdf/1004.4459v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Anjali Malviya",
      "S. G. Bhirud"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1004.4464v1",
    "title": "Audio enabled information extraction system for cricket and hockey\n  domains",
    "summary": "The proposed system aims at the retrieval of the summarized information from\nthe documents collected from web based search engine as per the user query\nrelated to cricket and hockey domain. The system is designed in a manner that\nit takes the voice commands as keywords for search. The parts of speech in the\nquery are extracted using the natural language extractor for English. Based on\nthe keywords the search is categorized into 2 types: - 1.Concept wise -\ninformation retrieved to the query is retrieved based on the keywords and the\nconcept words related to it. The retrieved information is summarized using the\nprobabilistic approach and weighted means algorithm.2.Keyword search - extracts\nthe result relevant to the query from the highly ranked document retrieved from\nthe search by the search engine. The relevant search results are retrieved and\nthen keywords are used for summarizing part. During summarization it follows\nthe weighted and probabilistic approaches in order to identify the data\ncomparable to the keywords extracted. The extracted information is then refined\nrepeatedly through the aggregation process to reduce redundancy. Finally the\nresultant data is submitted to the user in the form of audio output.",
    "published": "2010-04-26T10:11:00Z",
    "link": "http://arxiv.org/pdf/1004.4464v1.pdf",
    "category": [
      "cs.IR",
      "cs.MM",
      "cs.SD"
    ],
    "authors": [
      "S. Saraswathi",
      "Narasimha Sravan. V",
      "Sai Vamsi Krishna. B. V",
      "Suresh Reddy. S"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1005.0771v1",
    "title": "Towards Hardware implementation of video applications in new\n  telecommunications devices",
    "summary": "Among the areas, most demanding in terms of calculation is the\ntelecommunication and video applications are now included in several\ntelecommunication devices such as set-top boxes, mobile phones. Embedded videos\napplications in new generations of telecommunication devices need a processing\ncapacity that can not be achieved by the conventional processor, to work around\nthis problem the use of programmable technology has a lot of interest. First,\nField Programmable Gate Arrays (FPGAs) present many performance benefits for\nreal-time image processing applications. The FPGA structure is able to exploit\nspatial and temporal parallelism. In this paper, we present a new method for\nimplementation of the Color Structure Descriptor (CSD) using the FPGA circuit.\nIn fact the (CSD) provides satisfactory image indexing and retrieval results\namong all colorbased descriptors in MPEG-7. But the real time implementation of\nthis descriptor is still having problems. In this paper we propose a method for\nadapting this descriptor for possible implementation under the constraints of\nthe video processing in real time. We have verified the real-time\nimplementation of the (CSD) with an image size of 120*80 pixels.",
    "published": "2010-04-26T19:14:07Z",
    "link": "http://arxiv.org/pdf/1005.0771v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Lamjed Touil",
      "Abdessalem Ben Abdelali",
      "Abdellatif Mtibaa",
      "Elbey Bourennane"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1005.0092v1",
    "title": "Influence of distortions of key frames on video transfer in wireless\n  networks",
    "summary": "In this paper it is shown that for substantial increase of video quality in\nwireless network it is necessary to execute two obligatory points on\nmodernization of the communication scheme. The player on the received part\nshould throw back automatically duplicated RTP packets, server of streaming\nvideo should duplicate the packets containing the information of key frames.\nCoefficients of the mathematical model describing video quality in wireless\nnetwork have been found for WiFi and 3G standards and codecs MPEG-2 and MPEG-4\n(DivX). The special experimental technique which has allowed collecting and\nprocessing the data has been developed for calculation of values of factors.",
    "published": "2010-05-01T17:15:36Z",
    "link": "http://arxiv.org/pdf/1005.0092v1.pdf",
    "category": [
      "cs.NI",
      "cs.MM",
      "H.4.3; C.2.1; C.2.5"
    ],
    "authors": [
      "E. S. Sagatov",
      "A. M. Sukhov",
      "P. Calyam"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1005.1684v12",
    "title": "On Macroscopic Complexity and Perceptual Coding",
    "summary": "The theoretical limits of 'lossy' data compression algorithms are considered.\nThe complexity of an object as seen by a macroscopic observer is the size of\nthe perceptual code which discards all information that can be lost without\naltering the perception of the specified observer. The complexity of this\nmacroscopically observed state is the simplest description of any microstate\ncomprising that macrostate. Inference and pattern recognition based on\nmacrostate rather than microstate complexities will take advantage of the\ncomplexity of the macroscopic observer to ignore irrelevant noise.",
    "published": "2010-05-10T22:41:10Z",
    "link": "http://arxiv.org/pdf/1005.1684v12.pdf",
    "category": [
      "cs.IT",
      "cs.AI",
      "cs.MM",
      "cs.SD",
      "math.IT",
      "I.4.2; I.5.0; I.5.1; I.2.6; I.2.10; H.5.5; E.4"
    ],
    "authors": [
      "John Scoville"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1005.1757v1",
    "title": "Architecture for Cooperative Prefetching in P2P Video-on- Demand System",
    "summary": "Most P2P VoD schemes focused on service architectures and overlays\noptimization without considering segments rarity and the performance of\nprefetching strategies. As a result, they cannot better support VCRoriented\nservice in heterogeneous environment having clients using free VCR controls.\nDespite the remarkable popularity in VoD systems, there exist no prior work\nthat studies the performance gap between different prefetching strategies. In\nthis paper, we analyze and understand the performance of different prefetching\nstrategies. Our analytical characterization brings us not only a better\nunderstanding of several fundamental tradeoffs in prefetching strategies, but\nalso important insights on the design of P2P VoD system. On the basis of this\nanalysis, we finally proposed a cooperative prefetching strategy called\n\"cooching\". In this strategy, the requested segments in VCR interactivities are\nprefetched into session beforehand using the information collected through\ngossips. We evaluate our strategy through extensive simulations. The results\nindicate that the proposed strategy outperforms the existing prefetching\nmechanisms.",
    "published": "2010-05-11T08:42:18Z",
    "link": "http://arxiv.org/pdf/1005.1757v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Ubaid Abbasi",
      "Toufik Ahmed"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1005.2672v1",
    "title": "Proviola: A Tool for Proof Re-animation",
    "summary": "To improve on existing models of interaction with a proof assistant (PA), in\nparticular for storage and replay of proofs, we in- troduce three related\nconcepts, those of: a proof movie, consisting of frames which record both user\ninput and the corresponding PA response; a camera, which films a user's\ninteractive session with a PA as a movie; and a proviola, which replays a movie\nframe-by-frame to a third party. In this paper we describe the movie data\nstructure and we discuss a proto- type implementation of the camera and\nproviola based on the ProofWeb system. ProofWeb uncouples the interaction with\na PA via a web- interface (the client) from the actual PA that resides on the\nserver. Our camera films a movie by \"listening\" to the ProofWeb communication.\nThe first reason for developing movies is to uncouple the reviewing of a formal\nproof from the PA used to develop it: the movie concept enables users to\ndiscuss small code fragments without the need to install the PA or to load a\nwhole library into it. Other advantages include the possibility to develop a\nseparate com- mentary track to discuss or explain the PA interaction. We assert\nthat a combined camera+proviola provides a generic layer between a client\n(user) and a server (PA). Finally we claim that movies are the right type of\ndata to be stored in an encyclopedia of formalized mathematics, based on our\nexperience in filming the Coq standard library.",
    "published": "2010-05-15T12:54:28Z",
    "link": "http://arxiv.org/pdf/1005.2672v1.pdf",
    "category": [
      "cs.LO",
      "cs.DL",
      "cs.HC",
      "cs.MM"
    ],
    "authors": [
      "Carst Tankink",
      "Herman Geuvers",
      "James McKinna",
      "Freek Wiedijk"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1005.4014v1",
    "title": "A Study on Potential of Integrating Multimodal Interaction into Musical\n  Conducting Education",
    "summary": "With the rapid development of computer technology, computer music has begun\nto appear in the laboratory. Many potential utility of computer music is\ngradually increasing. The purpose of this paper is attempted to analyze the\npossibility of integrating multimodal interaction such as vision-based hand\ngesture and speech interaction into musical conducting education. To achieve\nthis purpose, this paper is focus on discuss some related research and the\ntraditional musical conducting education. To do so, six musical conductors had\nbeen interviewed to share their musical conducting learning/ teaching\nexperience. These interviews had been analyzed in this paper to show the\nsyllabus and the focus of musical conducting education for beginners.",
    "published": "2010-05-21T17:18:29Z",
    "link": "http://arxiv.org/pdf/1005.4014v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Gilbert Phuah Leong Siang",
      "Nor Azman Ismail",
      "Pang Yee Yong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1005.4267v1",
    "title": "Content Base Image Retrieval Using Phong Shading",
    "summary": "The digital image data is rapidly expanding in quantity and heterogeneity.\nThe traditional information retrieval techniques does not meet the user's\ndemand, so there is need to develop an efficient system for content based image\nretrieval. Content based image retrieval means retrieval of images from\ndatabase on the basis of visual features of image like as color, texture etc.\nIn our proposed method feature are extracted after applying Phong shading on\ninput image. Phong shading, flattering out the dull surfaces of the image The\nfeatures are extracted using color, texture & edge density methods. Feature\nextracted values are used to find the similarity between input query image and\nthe data base image. It can be measure by the Euclidean distance formula. The\nexperimental result shows that the proposed approach has a better retrieval\nresults with phong shading.",
    "published": "2010-05-24T07:28:24Z",
    "link": "http://arxiv.org/pdf/1005.4267v1.pdf",
    "category": [
      "cs.MM",
      "cs.IR"
    ],
    "authors": [
      "Uday Pratap Singh",
      "Sanjeev Jain",
      "Gulfishan Firdose Ahmed"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1005.4564v1",
    "title": "A basic gesture and motion format for virtual reality multisensory\n  applications",
    "summary": "The question of encoding movements such as those produced by human gestures\nmay become central in the coming years, given the growing importance of\nmovement data exchanges between heterogeneous systems and applications (musical\napplications, 3D motion control, virtual reality interaction, etc.). For the\npast 20 years, various formats have been proposed for encoding movement,\nespecially gestures. Though, these formats, at different degrees, were designed\nin the context of quite specific applications (character animation, motion\ncapture, musical gesture, biomechanical concerns...). The article introduce a\nnew file format, called GMS (for 'Gesture and Motion Signal'), with the aim of\nbeing more low-level and generic, by defining the minimal features a format\ncarrying movement/gesture information needs, rather than by gathering all the\ninformation generally given by the existing formats. The article argues that,\ngiven its growing presence in virtual reality situations, the \"gesture signal\"\nitself must be encoded, and that a specific format is needed. The proposed\nformat features the inner properties of such signals: dimensionality,\nstructural features, types of variables, and spatial and temporal properties.\nThe article first reviews the various situations with multisensory virtual\nobjects in which gesture controls intervene. The proposed format is then\ndeduced, as a mean to encode such versatile and variable \"gestural and animated\nscene\".",
    "published": "2010-05-25T13:16:29Z",
    "link": "http://arxiv.org/pdf/1005.4564v1.pdf",
    "category": [
      "cs.HC",
      "cs.GR",
      "cs.MM",
      "cs.SD"
    ],
    "authors": [
      "Annie Luciani",
      "Matthieu Evrard",
      "Damien Courouss",
      "Nicolas Castagn",
      "Claude Cadoz",
      "Jean-Loup Florens"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1005.5436v1",
    "title": "Client-to-Client Streaming Scheme for VOD Applications",
    "summary": "In this paper, we propose an efficient client-to-client streaming approach to\ncooperatively stream the video using chaining technique with unicast\ncommunication among the clients. This approach considers two major issues of\nVoD 1) Prefix caching scheme to accommodate more number of videos closer to\nclient, so that the request-service delay for the user can be minimized. 2)\nCooperative proxy and client chaining scheme for streaming the videos using\nunicasting. This approach minimizes the client rejection rate and bandwidth\nrequirement on server to proxy and proxy to client path. Our simulation results\nshow that the proposed approach achieves reduced client waiting time and\noptimal prefix caching of videos minimizing server to proxy path bandwidth\nusage by utilizing the client to client bandwidth, which is occasionally used\nwhen compared to busy server to proxy path bandwidth.",
    "published": "2010-05-29T08:00:39Z",
    "link": "http://arxiv.org/pdf/1005.5436v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "M. Dakshayini",
      "T. R. Gopala Krishnan Nair"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1005.5613v1",
    "title": "An Automated Algorithm for Approximation of Temporal Video Data Using\n  Linear B'EZIER Fitting",
    "summary": "This paper presents an efficient method for approximation of temporal video\ndata using linear Bezier fitting. For a given sequence of frames, the proposed\nmethod estimates the intensity variations of each pixel in temporal dimension\nusing linear Bezier fitting in Euclidean space. Fitting of each segment ensures\nupper bound of specified mean squared error. Break and fit criteria is employed\nto minimize the number of segments required to fit the data. The proposed\nmethod is well suitable for lossy compression of temporal video data and\nautomates the fitting process of each pixel. Experimental results show that the\nproposed method yields good results both in terms of objective and subjective\nquality measurement parameters without causing any blocking artifacts.",
    "published": "2010-05-31T08:11:59Z",
    "link": "http://arxiv.org/pdf/1005.5613v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Murtaza Ali Khan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1006.1186v1",
    "title": "A novel technique for image steganography based on Block-DCT and Huffman\n  Encoding",
    "summary": "Image steganography is the art of hiding information into a cover image. This\npaper presents a novel technique for Image steganography based on Block-DCT,\nwhere DCT is used to transform original image (cover image) blocks from spatial\ndomain to frequency domain. Firstly a gray level image of size M x N is divided\ninto no joint 8 x 8 blocks and a two dimensional Discrete Cosine Transform (2-d\nDCT) is performed on each of the P = MN / 64 blocks. Then Huffman encoding is\nalso performed on the secret messages/images before embedding and each bit of\nHuffman code of secret message/image is embedded in the frequency domain by\naltering the least significant bit of each of the DCT coefficients of cover\nimage blocks. The experimental results show that the algorithm has a high\ncapacity and a good invisibility. Moreover PSNR of cover image with stego-image\nshows the better results in comparison with other existing steganography\napproaches. Furthermore, satisfactory security is maintained since the secret\nmessage/image cannot be extracted without knowing decoding rules and Huffman\ntable.",
    "published": "2010-06-07T06:59:18Z",
    "link": "http://arxiv.org/pdf/1006.1186v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "A. Nag",
      "S. Biswas",
      "D. Sarkar",
      "P. P. Sarkar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1007.1233v1",
    "title": "An Alternative Approach of Steganography using Reference Image",
    "summary": "This paper is to create a practical steganographic implementation for 4-bit\nimages.The proposed technique converts 4 bit image into 4 shaded Gray Scale\nimage. This image will be act as reference image to hide the text. Using this\ngrey scale reference image any text can be hidden. Single character of a text\ncan be represented by 8-bit. The 8-bit character can be split into 4X2 bit\ninformation. If the reference image and the data file are transmitted through\nnetwork separately, we can achieve the effect of Steganography. Here the image\nis not at all distorted because said image is only used for referencing. Any\nhuge mount of text material can be hidden using a very small image. Decipher\nthe text is not possible intercepting the image or data file separately. So, it\nis more secure.",
    "published": "2010-07-01T09:40:40Z",
    "link": "http://arxiv.org/pdf/1007.1233v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Samir Kumar Bandyopadhyay",
      "Indra Kanta Maitra"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1007.4134v1",
    "title": "Human Daily Activities Indexing in Videos from Wearable Cameras for\n  Monitoring of Patients with Dementia Diseases",
    "summary": "Our research focuses on analysing human activities according to a known\nbehaviorist scenario, in case of noisy and high dimensional collected data. The\ndata come from the monitoring of patients with dementia diseases by wearable\ncameras. We define a structural model of video recordings based on a Hidden\nMarkov Model. New spatio-temporal features, color features and localization\nfeatures are proposed as observations. First results in recognition of\nactivities are promising.",
    "published": "2010-07-23T13:59:42Z",
    "link": "http://arxiv.org/pdf/1007.4134v1.pdf",
    "category": [
      "cs.MM",
      "stat.ML"
    ],
    "authors": [
      "Svebor Karaman",
      "Jenny Benois-Pineau",
      "Rmi Mgret",
      "Vladislavs Dovgalecs",
      "Jean-Franois Dartigues",
      "Yann Gastel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1007.5136v1",
    "title": "Perceptual Copyright Protection Using Multiresolution Wavelet-Based\n  Watermarking And Fuzzy Logic",
    "summary": "In this paper, an efficiently DWT-based watermarking technique is proposed to\nembed signatures in images to attest the owner identification and discourage\nthe unauthorized copying. This paper deals with a fuzzy inference filter to\nchoose the larger entropy of coefficients to embed watermarks. Unlike most\nprevious watermarking frameworks which embedded watermarks in the larger\ncoefficients of inner coarser subbands, the proposed technique is based on\nutilizing a context model and fuzzy inference filter by embedding watermarks in\nthe larger-entropy coefficients of coarser DWT subbands. The proposed\napproaches allow us to embed adaptive casting degree of watermarks for\ntransparency and robustness to the general image-processing attacks such as\nsmoothing, sharpening, and JPEG compression. The approach has no need the\noriginal host image to extract watermarks. Our schemes have been shown to\nprovide very good results in both image transparency and robustness.",
    "published": "2010-07-29T07:41:51Z",
    "link": "http://arxiv.org/pdf/1007.5136v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Ming-Shing Hsieh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1008.0502v2",
    "title": "Fully automatic extraction of salient objects from videos in near\n  real-time",
    "summary": "Automatic video segmentation plays an important role in a wide range of\ncomputer vision and image processing applications. Recently, various methods\nhave been proposed for this purpose. The problem is that most of these methods\nare far from real-time processing even for low-resolution videos due to the\ncomplex procedures. To this end, we propose a new and quite fast method for\nautomatic video segmentation with the help of 1) efficient optimization of\nMarkov random fields with polynomial time of number of pixels by introducing\ngraph cuts, 2) automatic, computationally efficient but stable derivation of\nsegmentation priors using visual saliency and sequential update mechanism, and\n3) an implementation strategy in the principle of stream processing with\ngraphics processor units (GPUs). Test results indicates that our method\nextracts appropriate regions from videos as precisely as and much faster than\nprevious semi-automatic methods even though any supervisions have not been\nincorporated.",
    "published": "2010-08-03T10:00:07Z",
    "link": "http://arxiv.org/pdf/1008.0502v2.pdf",
    "category": [
      "cs.CV",
      "cs.GR",
      "cs.MM"
    ],
    "authors": [
      "Akamine Kazuma",
      "Ken Fukuchi",
      "Akisato Kimura",
      "Shigeru Takagi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1008.0757v1",
    "title": "Web Video Categorization based on Wikipedia Categories and\n  Content-Duplicated Open Resources",
    "summary": "This paper presents a novel approach for web video categorization by\nleveraging Wikipedia categories (WikiCs) and open resources describing the same\ncontent as the video, i.e., content-duplicated open resources (CDORs). Note\nthat current approaches only col-lect CDORs within one or a few media forms and\nignore CDORs of other forms. We explore all these resources by utilizing WikiCs\nand commercial search engines. Given a web video, its discrimin-ative Wikipedia\nconcepts are first identified and classified. Then a textual query is\nconstructed and from which CDORs are collected. Based on these CDORs, we\npropose to categorize web videos in the space spanned by WikiCs rather than\nthat spanned by raw tags. Experimental results demonstrate the effectiveness of\nboth the proposed CDOR collection method and the WikiC voting catego-rization\nalgorithm. In addition, the categorization model built based on both WikiCs and\nCDORs achieves better performance compared with the models built based on only\none of them as well as state-of-the-art approach.",
    "published": "2010-08-04T12:01:39Z",
    "link": "http://arxiv.org/pdf/1008.0757v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Zhineng Chen",
      "Juan Cao",
      "Yicheng Song",
      "Yongdong Zhang",
      "Jintao Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1008.2824v1",
    "title": "Optimized Image Steganalysis through Feature Selection using MBEGA",
    "summary": "Feature based steganalysis, an emerging branch in information forensics, aims\nat identifying the presence of a covert communication by employing the\nstatistical features of the cover and stego image as clues/evidences. Due to\nthe large volumes of security audit data as well as complex and dynamic\nproperties of steganogram behaviours, optimizing the performance of\nsteganalysers becomes an important open problem. This paper is focussed at fine\ntuning the performance of six promising steganalysers in this field, through\nfeature selection. We propose to employ Markov Blanket-Embedded Genetic\nAlgorithm (MBEGA) for stego sensitive feature selection process. In particular,\nthe embedded Markov blanket based memetic operators add or delete features (or\ngenes) from a genetic algorithm (GA) solution so as to quickly improve the\nsolution and fine-tune the search. Empirical results suggest that MBEGA is\neffective and efficient in eliminating irrelevant and redundant features based\non both Markov blanket and predictive power in classifier model. Observations\nshow that the proposed method is superior in terms of number of selected\nfeatures, classification accuracy and computational cost than their existing\ncounterparts.",
    "published": "2010-08-17T05:57:36Z",
    "link": "http://arxiv.org/pdf/1008.2824v1.pdf",
    "category": [
      "cs.CR",
      "cs.MM"
    ],
    "authors": [
      "S. Geetha",
      "N. Kamaraj"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1008.3741v2",
    "title": "Reliable Multicasting for Device-to-Device Radio Underlaying Cellular\n  Networks",
    "summary": "This paper proposes Leader in Charge (LiC), a reliable multicast architecture\nfor device-to-device (D2D) radio underlaying cellular networks. The\nmulticast-requesting user equipments (UEs) in close proximity form a D2D\ncluster to receive the multicast packets through cooperation. In addition to\nreceiving the multicast packets from the eNB, UEs share what they received from\nthe multicast on short-range links among UEs, namely the D2D links, to exploit\nthe wireless resources a more efficient way. Consequently, we show that\nutilizing the D2D links in cellular networks increases the throughput of a\nmulticast session by means of simulation. We also discuss some practical issues\nfacing the integration of LiC into the current cellular networks. In\nparticular, we propose efficient delay control mechanism to reduce the average\nand maximum delay experienced by LiC users, which is further confirmed by the\nsimulation results.",
    "published": "2010-08-23T03:06:22Z",
    "link": "http://arxiv.org/pdf/1008.3741v2.pdf",
    "category": [
      "cs.MM",
      "cs.NI"
    ],
    "authors": [
      "Wei Yang",
      "Wanlu Sun",
      "Lihua Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1008.4406v1",
    "title": "Structural Solutions to Dynamic Scheduling for Multimedia Transmission\n  in Unknown Wireless Environments",
    "summary": "In this paper, we propose a systematic solution to the problem of scheduling\ndelay-sensitive media data for transmission over time-varying wireless\nchannels. We first formulate the dynamic scheduling problem as a Markov\ndecision process (MDP) that explicitly considers the users' heterogeneous\nmultimedia data characteristics (e.g. delay deadlines, distortion impacts and\ndependencies etc.) and time-varying channel conditions, which are not\nsimultaneously considered in state-of-the-art packet scheduling algorithms.\nThis formulation allows us to perform foresighted decisions to schedule\nmultiple data units for transmission at each time in order to optimize the\nlong-term utilities of the multimedia applications. The heterogeneity of the\nmedia data enables us to express the transmission priorities between the\ndifferent data units as a priority graph, which is a directed acyclic graph\n(DAG). This priority graph provides us with an elegant structure to decompose\nthe multi-data unit foresighted decision at each time into multiple single-data\nunit foresighted decisions which can be performed sequentially, from the high\npriority data units to the low priority data units, thereby significantly\nreducing the computation complexity. When the statistical knowledge of the\nmultimedia data characteristics and channel conditions is unknown a priori, we\ndevelop a low-complexity online learning algorithm to update the value\nfunctions which capture the impact of the current decision on the future\nutility. The simulation results show that the proposed solution significantly\noutperforms existing state-of-the-art scheduling solutions.",
    "published": "2010-08-25T23:06:39Z",
    "link": "http://arxiv.org/pdf/1008.4406v1.pdf",
    "category": [
      "cs.MM",
      "cs.LG",
      "cs.SY"
    ],
    "authors": [
      "Fangwen Fu",
      "Mihaela van der Schaar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1009.1170v1",
    "title": "M-Learning: A New Paradigm of Learning Mathematics in Malaysia",
    "summary": "M-Learning is a new learning paradigm of the new social structure with mobile\nand wireless technologies.Smart school is one of the four flagship applications\nfor Multimedia Super Corridor (MSC) under Malaysian government initiative to\nimprove education standard in the country. With the advances of mobile devices\ntechnologies, mobile learning could help the government in realizing the\ninitiative. This paper discusses the prospect of implementing mobile learning\nfor primary school students. It indicates significant and challenges and\nanalysis of user perceptions on potential mobile applications through a survey\ndone in primary school context. The authors propose the m-Learning for\nmathematics by allowing the extension of technology in the traditional\nclassroom in term of learning and teaching.",
    "published": "2010-09-06T22:33:38Z",
    "link": "http://arxiv.org/pdf/1009.1170v1.pdf",
    "category": [
      "cs.MM",
      "cs.CY",
      "cs.MS",
      "K.3.1"
    ],
    "authors": [
      "Saipunidzam Mahamad",
      "Mohammad Noor Ibrahim",
      "Shakirah Mohd Taib"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1009.1478v1",
    "title": "A Block Based Scheme for Enhancing Low Luminated Images",
    "summary": "In this paper the background detection in images in poor lighting can be done\nby the use of morphological filters. Lately contrast image enhancement\ntechnique is used to detect the background in image which uses Weber's Law. The\nproposed technique is more effective one in which the background detection in\nimage can be done in color images. The given image obtained in this method is\nvery effective one. More enhancement can be obtained while comparing the\nresults. In this technique compressed domain enhancement has been used for\nbetter result.",
    "published": "2010-09-08T08:23:47Z",
    "link": "http://arxiv.org/pdf/1009.1478v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "A. Saradha Devi",
      "S. Suja Priyadharsini",
      "S. Athinarayanan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1009.4642v1",
    "title": "A Gossip-based optimistic replication for efficient delay-sensitive\n  streaming using an interactive middleware support system",
    "summary": "While sharing resources the efficiency is substantially degraded as a result\nof the scarceness of availability of the requested resources in a multiclient\nsupport manner. These resources are often aggravated by many factors like the\ntemporal constraints for availability or node flooding by the requested\nreplicated file chunks. Thus replicated file chunks should be efficiently\ndisseminated in order to enable resource availability on-demand by the mobile\nusers. This work considers a cross layered middleware support system for\nefficient delay-sensitive streaming by using each device's connectivity and\nsocial interactions in a cross layered manner. The collaborative streaming is\nachieved through the epidemically replicated file chunk policy which uses a\ntransition-based approach of a chained model of an infectious disease with\nsusceptible, infected, recovered and death states. The Gossip-based stateful\nmodel enforces the mobile nodes whether to host a file chunk or not or, when no\nlonger a chunk is needed, to purge it. The proposed model is thoroughly\nevaluated through experimental simulation taking measures for the effective\nthroughput Eff as a function of the packet loss parameter in contrast with the\neffectiveness of the replication Gossip-based policy.",
    "published": "2010-09-09T09:14:37Z",
    "link": "http://arxiv.org/pdf/1009.4642v1.pdf",
    "category": [
      "cs.DC",
      "cs.MM"
    ],
    "authors": [
      "Constandinos X. Mavromoustakis",
      "Helen D. Karatza"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1009.2368v1",
    "title": "Network evolution and QOS provisioning for integrated\n  femtocell/macrocell networks",
    "summary": "Integrated femtocell/macrocell networks, comprising a conventional cellular\nnetwork overlaid with femtocells, offer an economically appealing way to\nimprove coverage, quality of service, and access network capacity. The key\nelement to successful femtocells/macrocell integration lies in its\nself-organizing capability. Provisioning of quality of service is the main\ntechnical challenge of the femtocell/macrocell integrated networks, while the\nmain administrative challenge is the choice of the proper evolutionary path\nfrom the existing macrocellular networks to the integrated network. In this\narticle, we introduce three integrated network architectures which, while\nincreasing the access capacity, they also reduce the deployment and operational\ncosts. Then, we discuss a number of technical issues, which are key to making\nsuch integration a reality, and we offer possible approaches to their solution.\nThese issues include efficient frequency and interference management, quality\nof service provisioning of the xDSL-based backhaul networks, and intelligent\nhandover control.",
    "published": "2010-09-13T12:39:02Z",
    "link": "http://arxiv.org/pdf/1009.2368v1.pdf",
    "category": [
      "cs.NI",
      "cs.MM"
    ],
    "authors": [
      "Mostafa Zaman Chowdhury",
      "Yeong Min Jang",
      "Zygmunt J. Haas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1009.3779v1",
    "title": "Handover Control for WCDMA Femtocell Networks",
    "summary": "The ability to seamlessly switch between the macro networks and femtocell\nnetworks is a key driver for femtocell network deployment. The handover\nprocedures for the integrated femtocell/macrocell networks differ from the\nexisting handovers. Some modifications of existing network and protocol\narchitecture for the integration of femtocell networks with the existing\nmacrocell networks are also essential. These modifications change the signal\nflow for handover procedures due to different 2-tier cell (macrocell and\nfemtocell) environment. The handover between two networks should be performed\nwith minimum signaling. A frequent and unnecessary handover is another problem\nfor hierarchical femtocell/macrocell network environment that must be\nminimized. This work studies the details mobility management schemes for small\nand medium scale femtocell network deployment. To do that, firstly we present\ntwo different network architectures for small scale and medium scale WCDMA\nfemtocell deployment. The details handover call flow for these two network\narchitectures and CAC scheme to minimize the unnecessary handovers are proposed\nfor the integrated femtocell/macrocell networks. The numerical analysis for the\nproposed M/M/N/N queuing scheme and the simulation results of the proposed CAC\nscheme demonstrate the handover call control performances for femtocell\nenvironment.",
    "published": "2010-09-20T11:50:21Z",
    "link": "http://arxiv.org/pdf/1009.3779v1.pdf",
    "category": [
      "cs.NI",
      "cs.MM"
    ],
    "authors": [
      "Mostafa Zaman Chowdhury",
      "Yeong Min Jang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1009.3785v1",
    "title": "Improved Iterative Techniques to Compensate for Interpolation\n  Distortions",
    "summary": "In this paper a novel hybrid approach for compensating the distortion of any\ninterpolation has been proposed. In this hybrid method, a modular approach was\nincorporated in an iterative fashion. By using this approach we can get drastic\nimprovement with less computational complexity. The extension of the proposed\napproach to two dimensions was also studied. Both the simulation results and\nmathematical analyses confirmed the superiority of the hybrid method. The\nproposed method was also shown to be robust against additive noise.",
    "published": "2010-09-20T12:15:46Z",
    "link": "http://arxiv.org/pdf/1009.3785v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "A. ParandehGheibi",
      "M. A. Akhaee",
      "A. Ayremlou",
      "M. A. Rahimian",
      "F. Marvasti"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1009.5762v1",
    "title": "Morphological dilation image coding with context weights prediction",
    "summary": "This paper proposes an adaptive morphological dilation image coding with\ncontext weights prediction. The new dilation method is not to use fixed models,\nbut to decide whether a coefficient needs to be dilated or not according to the\ncoefficient's predicted significance degree. It includes two key dilation\ntechnologies: 1) controlling dilation process with context weights to reduce\nthe output of insignificant coefficients, and 2) using variable-length group\ntest coding with context weights to adjust the coding order and cost as few\nbits as possible to present the events with large probability. Moreover, we\nalso propose a novel context weight strategy to predict coefficient's\nsignificance degree more accurately, which serves for two dilation\ntechnologies. Experimental results show that our proposed method outperforms\nthe state of the art image coding algorithms available today.",
    "published": "2010-09-29T03:22:34Z",
    "link": "http://arxiv.org/pdf/1009.5762v1.pdf",
    "category": [
      "cs.IT",
      "cs.MM",
      "math.IT"
    ],
    "authors": [
      "Jiaji Wu",
      "Yan Xing",
      "Anand Paul",
      "Yong Fang",
      "Jechang Jeong",
      "Licheng Jiao",
      "Guangming Shi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1010.1496v1",
    "title": "Profile Based Sub-Image Search in Image Databases",
    "summary": "Sub-image search with high accuracy in natural images still remains a\nchallenging problem. This paper proposes a new feature vector called profile\nfor a keypoint in a bag of visual words model of an image. The profile of a\nkeypoint captures the spatial geometry of all the other keypoints in an image\nwith respect to itself, and is very effective in discriminating true matches\nfrom false matches. Sub-image search using profiles is a single-phase process\nrequiring no geometric validation, yields high precision on natural images, and\nworks well on small visual codebook. The proposed search technique differs from\ntraditional methods that first generate a set of candidates disregarding\nspatial information and then verify them geometrically. Conventional methods\nalso use large codebooks. We achieve a precision of 81% on a combined data set\nof synthetic and real natural images using a codebook size of 500 for top-10\nqueries; that is 31% higher than the conventional candidate generation\napproach.",
    "published": "2010-10-07T17:42:09Z",
    "link": "http://arxiv.org/pdf/1010.1496v1.pdf",
    "category": [
      "cs.CV",
      "cs.IR",
      "cs.MM"
    ],
    "authors": [
      "Vishwakarma Singh",
      "Ambuj K. Singh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1010.2432v1",
    "title": "Transmitting Video-on-Demand Effectively",
    "summary": "Now-a-days internet has become a vast source of entertainment & new services\nare available in quick succession which provides entertainment to the users.\nOne of this service i.e. Video-on-Demand is most hyped service in this context.\nTransferring the video over the network with less error is the main objective\nof the service providers. In this paper we present an algorithm for routing the\nvideo to the user in an effective manner along with a method that ensures less\nerror rate than others.",
    "published": "2010-10-12T16:13:21Z",
    "link": "http://arxiv.org/pdf/1010.2432v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Rachit Mohan Garg",
      "Shipra Kapoor",
      "Kapil Kumar",
      "Mohd. Dilshad Ansari"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1010.3951v1",
    "title": "Alternatives to speech in low bit rate communication systems",
    "summary": "This paper describes a framework and a method with which speech communication\ncan be analyzed. The framework consists of a set of low bit rate, short-range\nacoustic communication systems, such as speech, but that are quite different\nfrom speech. The method is to systematically compare these systems according to\ndifferent objective functions such as data rate, computational overhead,\npsychoacoustic effects and semantics. One goal of this study is to better\nunderstand the nature of human communication. Another goal is to identify\nacoustic communication systems that are more efficient than human speech for\nsome specific purposes.",
    "published": "2010-10-19T15:24:33Z",
    "link": "http://arxiv.org/pdf/1010.3951v1.pdf",
    "category": [
      "cs.MM",
      "cs.SD"
    ],
    "authors": [
      "Cristina Videira Lopes",
      "Pedro M. Q. Aguiar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1010.4007v1",
    "title": "Colour Guided Colour Image Steganography",
    "summary": "Information security has become a cause of concern because of the electronic\neavesdropping. Capacity, robustness and invisibility are important parameters\nin information hiding and are quite difficult to achieve in a single algorithm.\nThis paper proposes a novel steganography technique for digital color image\nwhich achieves the purported targets. The professed methodology employs a\ncomplete random scheme for pixel selection and embedding of data. Of the three\ncolour channels (Red, Green, Blue) in a given colour image, the least two\nsignificant bits of any one of the channels of the color image is used to\nchannelize the embedding capacity of the remaining two channels. We have\ndevised three approaches to achieve various levels of our desired targets. In\nthe first approach, Red is the default guide but it results in localization of\nMSE in the remaining two channels, which makes it slightly vulnerable. In the\nsecond approach, user gets the liberty to select the guiding channel (Red,\nGreen or Blue) to guide the remaining two channels. It will increase the\nrobustness and imperceptibility of the embedded image however the MSE factor\nwill still remain as a drawback. The third approach improves the performance\nfactor as a cyclic methodology is employed and the guiding channel is selected\nin a cyclic fashion. This ensures the uniform distribution of MSE, which gives\nbetter robustness and imperceptibility along with enhanced embedding capacity.\nThe imperceptibility has been enhanced by suitably adapting optimal pixel\nadjustment process (OPAP) on the stego covers.",
    "published": "2010-10-19T19:07:08Z",
    "link": "http://arxiv.org/pdf/1010.4007v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "R. Amirtharajan",
      "Sandeep Kumar Behera",
      "Motamarri Abhilash Swarup",
      "Mohamed Ashfaaq K",
      "John Bosco Balaguru Rayappan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1010.4084v1",
    "title": "Haar Wavelet Based Approach for Image Compression and Quality Assessment\n  of Compressed Image",
    "summary": "With the increasing growth of technology and the entrance into the digital\nage, we have to handle a vast amount of information every time which often\npresents difficulties. So, the digital information must be stored and retrieved\nin an efficient and effective manner, in order for it to be put to practical\nuse. Wavelets provide a mathematical way of encoding information in such a way\nthat it is layered according to level of detail. This layering facilitates\napproximations at various intermediate stages. These approximations can be\nstored using a lot less space than the original data. Here a low complex 2D\nimage compression method using wavelets as the basis functions and the approach\nto measure the quality of the compressed image are presented. The particular\nwavelet chosen and used here is the simplest wavelet form namely the Haar\nWavelet. The 2D discret wavelet transform (DWT) has been applied and the detail\nmatrices from the information matrix of the image have been estimated. The\nreconstructed image is synthesized using the estimated detail matrices and\ninformation matrix provided by the Wavelet transform. The quality of the\ncompressed images has been evaluated using some factors like Compression Ratio\n(CR), Peak Signal to Noise Ratio (PSNR), Mean Opinion Score (MOS), Picture\nQuality Scale (PQS) etc.",
    "published": "2010-10-20T01:52:05Z",
    "link": "http://arxiv.org/pdf/1010.4084v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Kamrul Hasan Talukder",
      "Koichi Harada"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1011.2753v1",
    "title": "Compensating Interpolation Distortion by New Optimized Modular Method",
    "summary": "A modular method was suggested before to recover a band limited signal from\nthe sample and hold and linearly interpolated (or, in general, an\nnth-order-hold) version of the regular samples. In this paper a novel approach\nfor compensating the distortion of any interpolation based on modular method\nhas been proposed. In this method the performance of the modular method is\noptimized by adding only some simply calculated coefficients. This approach\ncauses drastic improvement in terms of SNRs with fewer modules compared to the\nclassical modular method. Simulation results clearly confirm the improvement of\nthe proposed method and also its superior robustness against additive noise.",
    "published": "2010-11-11T20:20:36Z",
    "link": "http://arxiv.org/pdf/1011.2753v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Ali Ayremlou",
      "Mohammad Tofighi",
      "Farokh Marvasti"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1011.2893v1",
    "title": "Web Conferencing Traffic - An Analysis using DimDim as Example",
    "summary": "In this paper, we present an evaluation of the Ethernet traffic for host and\nattendees of the popular opensource web conferencing system DimDim. While\ntraditional Internet-centric approaches such as the MBONE have been used over\nthe past decades, current trends for web-based conference systems make\nexclusive use of application-layer multicast. To allow for network dimensioning\nand QoS provisioning, an understanding of the underlying traffic\ncharacteristics is required. We find in our exemplary evaluations that the host\nof a web conference session produces a large amount of Ethernet traffic,\nlargely due to the required control of the conference session, that is\nheavily-tailed distributed and exhibits additionally long-range dependence. For\ndifferent groups of activities within a web conference session, we find\ndistinctive characteristics of the generated traffic.",
    "published": "2010-11-12T12:11:51Z",
    "link": "http://arxiv.org/pdf/1011.2893v1.pdf",
    "category": [
      "cs.NI",
      "cs.MM"
    ],
    "authors": [
      "Patrick Seeling"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1011.5458v1",
    "title": "Image Inpainting Using Sparsity of the Transform Domain",
    "summary": "In this paper, we propose a new image inpainting method based on the property\nthat much of the image information in the transform domain is sparse. We add a\nredundancy to the original image by mapping the transform coefficients with\nsmall amplitudes to zero and the resultant sparsity pattern is used as the side\ninformation in the recovery stage. If the side information is not available,\nthe receiver has to estimate the sparsity pattern. At the end, the recovery is\ndone by consecutive projecting between two spatial and transform sets.\nExperimental results show that our method works well for both structural and\ntexture images and outperforms other techniques in objective and subjective\nperformance measures.",
    "published": "2010-11-24T18:58:53Z",
    "link": "http://arxiv.org/pdf/1011.5458v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "H. Hosseini",
      "N. B. Marvasti",
      "F. Marvasti"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1012.0223v1",
    "title": "An Effective Method of Image Retrieval using Image Mining Techniques",
    "summary": "The present research scholars are having keen interest in doing their\nresearch activities in the area of Data mining all over the world. Especially,\n[13]Mining Image data is the one of the essential features in this present\nscenario since image data plays vital role in every aspect of the system such\nas business for marketing, hospital for surgery, engineering for construction,\nWeb for publication and so on. The other area in the Image mining system is the\nContent-Based Image Retrieval (CBIR) which performs retrieval based on the\nsimilarity defined in terms of extracted features with more objectiveness. The\ndrawback in CBIR is the features of the query image alone are considered.\nHence, a new technique called Image retrieval based on optimum clusters is\nproposed for improving user interaction with image retrieval systems by fully\nexploiting the similarity information. The index is created by describing the\nimages according to their color characteristics, with compact feature vectors,\nthat represent typical color distributions [12].",
    "published": "2010-12-01T15:34:50Z",
    "link": "http://arxiv.org/pdf/1012.0223v1.pdf",
    "category": [
      "cs.CV",
      "cs.MM"
    ],
    "authors": [
      "A. Kannan",
      "V. Mohan",
      "N. Anbazhagan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1012.0397v2",
    "title": "A proposed Optimized Spline Interpolation",
    "summary": "The goal of this paper is to design compact support basis spline functions\nthat best approximate a given filter (e.g., an ideal Lowpass filter). The\noptimum function is found by minimizing the least square problem ($\\ell$2 norm\nof the difference between the desired and the approximated filters) by means of\nthe calculus of variation; more precisely, the introduced splines give optimal\nfiltering properties with respect to their time support interval. Both\nmathematical analysis and simulation results confirm the superiority of these\nsplines.",
    "published": "2010-12-02T13:02:06Z",
    "link": "http://arxiv.org/pdf/1012.0397v2.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Ramtin Madani",
      "Ali Ayremlou",
      "Arash Amini",
      "Farrokh Marvasti"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1012.1184v1",
    "title": "Image Deblurring and Super-resolution by Adaptive Sparse Domain\n  Selection and Adaptive Regularization",
    "summary": "As a powerful statistical image modeling technique, sparse representation has\nbeen successfully used in various image restoration applications. The success\nof sparse representation owes to the development of l1-norm optimization\ntechniques, and the fact that natural images are intrinsically sparse in some\ndomain. The image restoration quality largely depends on whether the employed\nsparse domain can represent well the underlying image. Considering that the\ncontents can vary significantly across different images or different patches in\na single image, we propose to learn various sets of bases from a pre-collected\ndataset of example image patches, and then for a given patch to be processed,\none set of bases are adaptively selected to characterize the local sparse\ndomain. We further introduce two adaptive regularization terms into the sparse\nrepresentation framework. First, a set of autoregressive (AR) models are\nlearned from the dataset of example image patches. The best fitted AR models to\na given patch are adaptively selected to regularize the image local structures.\nSecond, the image non-local self-similarity is introduced as another\nregularization term. In addition, the sparsity regularization parameter is\nadaptively estimated for better image restoration performance. Extensive\nexperiments on image deblurring and super-resolution validate that by using\nadaptive sparse domain selection and adaptive regularization, the proposed\nmethod achieves much better results than many state-of-the-art algorithms in\nterms of both PSNR and visual perception.",
    "published": "2010-12-06T14:37:14Z",
    "link": "http://arxiv.org/pdf/1012.1184v1.pdf",
    "category": [
      "cs.CV",
      "cs.MM",
      "68U10"
    ],
    "authors": [
      "Weisheng Dong",
      "Lei Zhang",
      "Guangming Shi",
      "Xiaolin Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1012.1882v1",
    "title": "Evaluating Modelling Approaches for Medical Image Annotations",
    "summary": "Information system designers face many challenges w.r.t. selecting\nappropriate semantic technologies and deciding on a modelling approach for\ntheir system. However, there is no clear methodology yet to evaluate\n\"semantically enriched\" information systems. In this paper we present a case\nstudy on different modelling approaches for annotating medical images and\nintroduce a conceptual framework that can be used to analyse the fitness of\ninformation systems and help designers to spot the strengths and weaknesses of\nvarious modelling approaches as well as managing trade-offs between modelling\neffort and their potential benefits.",
    "published": "2010-12-08T21:45:16Z",
    "link": "http://arxiv.org/pdf/1012.1882v1.pdf",
    "category": [
      "cs.MM",
      "J.3"
    ],
    "authors": [
      "Jasmin Opitz",
      "Bijan Parsia",
      "Ulrike Sattler"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1012.2518v1",
    "title": "A Survey on Cross-Layer Design Frameworks for Multimedia Applications\n  over Wireless Networks",
    "summary": "In the last few years, the Internet throughput, usage and reliability have\nincreased almost exponentially. The introduction of broadband wireless mobile\nad hoc networks (MANETs) and cellular networks together with increased\ncomputational power have opened the door for a new breed of applications to be\ncreated, namely real-time multimedia applications. Delivering real-time\nmultimedia traffic over a complex network like the Internet is a particularly\nchallenging task since these applications have strict quality -of-service (QoS)\nrequirements on bandwidth, delay, and delay jitter. Traditional IP-based best\neffort service will not be able to meet these stringent requirements. The\ntime-varying nature of wireless channels and resource constrained wireless\ndevices make the problem even more difficult. To improve perceived media\nquality by end users over wireless Internet, QoS supports can be addressed in\ndifferent layers, including application layer, transport layer and link layer.\nCross layer design is a well-known approach to achieve this adaptation. In\ncross-layer design, the challenges from the physical wireless medium and the\nQoS-demands from the applications are taken into account so that the rate,\npower, and coding at the physical layer can adapted to meet the requirements of\nthe applications given the current channel and network conditions. A number of\npropositions for cross-layer designs exist in the literature. In this paper, an\nextensive review has been made on these cross-layer architectures that combine\nthe application-layer, transport layer and the link layer controls.\nParticularly the issues like channel estimation techniques, adaptive controls\nat the application and link layers for energy efficiency, priority based\nscheduling, transmission rate control at the transport layer, and adaptive\nautomatic repeat request (ARQ) are discussed in detail.",
    "published": "2010-12-12T07:40:07Z",
    "link": "http://arxiv.org/pdf/1012.2518v1.pdf",
    "category": [
      "cs.NI",
      "cs.MM"
    ],
    "authors": [
      "Jaydip Sen",
      "Shomik Bhattacharya"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1012.2965v1",
    "title": "Digital watermarking : An approach based on Hilbert transform",
    "summary": "Most of the well known algorithms for watermarking of digital images involve\ntransformation of the image data to Fourier or singular vector space. In this\npaper, we introduce watermarking in Hilbert transform domain for digital media.\nGenerally, if the image is a matrix of order $m$ by $n$, then the transformed\nspace is also an image of the same order. However, with Hilbert transforms, the\ntransformed space is of order $2m$ by $2n$. This allows for more latitude in\nstoring the watermark in the host image. Based on this idea, we propose an\nalgorithm for embedding and extracting watermark in a host image and\nanalytically obtain a parameter related to this procedure. Using extensive\nsimulations, we show that the algorithm performs well even if the host image is\ncorrupted by various attacks.",
    "published": "2010-12-14T08:50:29Z",
    "link": "http://arxiv.org/pdf/1012.2965v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Rashmi Agarwal",
      "R. Krishnan",
      "M. S. Santhanam",
      "K. Srinivas",
      "K. Venugopalan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1012.5208v1",
    "title": "Texture feature extraction in the spatial-frequency domain for\n  content-based image retrieval",
    "summary": "The advent of large scale multimedia databases has led to great challenges in\ncontent-based image retrieval (CBIR). Even though CBIR is considered an\nemerging field of research, however it constitutes a strong background for new\nmethodologies and systems implementations. Therefore, many research\ncontributions are focusing on techniques enabling higher image retrieval\naccuracy while preserving low level of computational complexity. Image\nretrieval based on texture features is receiving special attention because of\nthe omnipresence of this visual feature in most real-world images. This paper\nhighlights the state-of-the-art and current progress relevant to texture-based\nimage retrieval and spatial-frequency image representations. In particular, it\ngives an overview of statistical methodologies and techniques employed for\ntexture feature extraction using most popular spatial-frequency image\ntransforms, namely discrete wavelets, Gabor wavelets, dual-tree complex wavelet\nand contourlets. Indications are also given about used similarity measurement\nfunctions and most important achieved results.",
    "published": "2010-12-23T14:10:25Z",
    "link": "http://arxiv.org/pdf/1012.5208v1.pdf",
    "category": [
      "cs.CV",
      "cs.IR",
      "cs.MM"
    ],
    "authors": [
      "Nadia Baaziz",
      "Omar Abahmane",
      "Rokia Missaoui"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1012.5573v1",
    "title": "Image Sterilization to Prevent LSB-based Steganographic Transmission",
    "summary": "Sterilization is a very popular word used in biomedical testing (like removal\nof all microorganisms on surface of an article or in fluid using appropriate\nchemical products). Motivated by this biological analogy, we, for the first\ntime, introduce the concept of sterilization of an image, i.e., removing any\nsteganographic information embedded in the image. Experimental results show\nthat our technique succeeded in sterilizing around 76% to 91% of stego pixels\nin an image on average, where data is embedded using LSB-based steganography.",
    "published": "2010-12-27T07:44:21Z",
    "link": "http://arxiv.org/pdf/1012.5573v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Goutam Paul",
      "Imon Mukherjee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1101.0011v1",
    "title": "Packet Scheduling in Switches with Target Outflow Profiles",
    "summary": "The problem of packet scheduling for traffic streams with target outflow\nprofiles traversing input queued switches is formulated in this paper. Target\noutflow profiles specify the desirable inter-departure times of packets leaving\nthe switch from each traffic stream. The goal of the switch scheduler is to\ndynamically select service configurations of the switch, so that actual outflow\nstreams (\"pulled\" through the switch) adhere to their desired target profiles\nas accurately as possible. Dynamic service controls (schedules) are developed\nto minimize deviation of actual outflow streams from their targets and suppress\nstream \"distortion\". Using appropriately selected subsets of service\nconfigurations of the switch, efficient schedules are designed, which deliver\nhigh performance at relatively low complexity. Some of these schedules are\nprovably shown to achieve 100% pull-throughput. Moreover, simulations\ndemonstrate that for even substantial contention of streams through the switch,\ndue to stringent/intense target outflow profiles, the proposed schedules\nachieve closely their target profiles and suppress stream distortion. The\nswitch model investigated here deviates from the classical switching paradigm.\nIn the latter, the goal of packet scheduling is primarily to \"push\" as much\ntraffic load through the switch as possible, while controlling delay to\ntraverse the switch and keeping congestion/backlogs from exploding. In the\nmodel presented here, however, the goal of packet scheduling is to \"pull\"\ntraffic streams through the switch, maintaining desirable (target) outflow\nprofiles.",
    "published": "2010-12-29T21:44:50Z",
    "link": "http://arxiv.org/pdf/1101.0011v1.pdf",
    "category": [
      "cs.NI",
      "cs.MM",
      "cs.SY"
    ],
    "authors": [
      "Aditya Dua",
      "Nicholas Bambos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1101.2219v1",
    "title": "Alchymical Mirror: Real-time Interactive Sound- and Simple\n  Motion-Tracking Set of Jitter/Max/MSP Patches",
    "summary": "This document supplements an experimental Jitter / Max/MSP collection of\nimplementation patches that set its goal to simulate an alchemical process for\na person standing in front of a mirror-like screen while interacting with it.\nThe work involved takes some patience and has three stages to go through. At\nthe final stage the \"alchemist\" in the mirror wearing sharp-colored gloves (for\nmotion tracking) is to extract the final ultimate shining sparkle (FFT-based\nvisualization) in the nexus of the hands. The more the hands are apart, the\nlarge the sparkle should be. Moving hands around should make the sparkle\nfollow. To achieve the desired visual effect and the feedback mechanism, the\nJitter lattice-based intensional programming model is used to work on\n4-dimensional (A+R+G+B) video matrices and sound signals in order to apply some\nwell-known alchemical techniques to the video at real-time to get a mirror\neffect and accompanying transmutation and transformation stages of the video\nbased on the stability of the sound produced for some duration of time in\nreal-time. There is an accompanying video of the result with the interaction\nwith the tool and the corresponding programming patches.",
    "published": "2011-01-05T18:43:30Z",
    "link": "http://arxiv.org/pdf/1101.2219v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Elizaveta Eidelman",
      "Serguei A. Mokhov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1101.5127v1",
    "title": "A Color Image Digital Watermarking Scheme Based on SOFM",
    "summary": "Digital watermarking technique has been presented and widely researched to\nsolve some important issues in the digital world, such as copyright protection,\ncopy protection and content authentication. Several robust watermarking schemes\nbased on vector quantization (VQ) have been presented. In this paper, we\npresent a new digital image watermarking method based on SOFM vector quantizer\nfor color images. This method utilizes the codebook partition technique in\nwhich the watermark bit is embedded into the selected VQ encoded block. The\nmain feature of this scheme is that the watermark exists both in VQ compressed\nimage and in the reconstructed image. The watermark extraction can be performed\nwithout the original image. The watermark is hidden inside the compressed\nimage, so much transmission time and storage space can be saved when the\ncompressed data are transmitted over the Internet. Simulation results\ndemonstrate that the proposed method has robustness against various image\nprocessing operations without sacrificing compression performance and the\ncomputational speed.",
    "published": "2011-01-13T15:01:12Z",
    "link": "http://arxiv.org/pdf/1101.5127v1.pdf",
    "category": [
      "cs.MM",
      "cs.CR"
    ],
    "authors": [
      "J. Anitha",
      "S. Immanuel Alex Pandian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1101.3979v1",
    "title": "Selection of network coding nodes for minimal playback delay in\n  streaming overlays",
    "summary": "Network coding permits to deploy distributed packet delivery algorithms that\nlocally adapt to the network availability in media streaming applications.\nHowever, it may also increase delay and computational complexity if it is not\nimplemented efficiently. We address here the effective placement of nodes that\nimplement randomized network coding in overlay networks, so that the goodput is\nkept high while the delay for decoding stays small in streaming applications.\nWe first estimate the decoding delay at each client, which depends on the\ninnovative rate in the network. This estimation permits to identify the nodes\nthat have to perform coding for a reduced decoding delay. We then propose two\niterative algorithms for selecting the nodes that should perform network\ncoding. The first algorithm relies on the knowledge of the full network\nstatistics. The second algorithm uses only local network statistics at each\nnode. Simulation results show that large performance gains can be achieved with\nthe selection of only a few network coding nodes. Moreover, the second\nalgorithm performs very closely to the central estimation strategy, which\ndemonstrates that the network coding nodes can be selected efficiently in a\ndistributed manner. Our scheme shows large gains in terms of achieved\nthroughput, delay and video quality in realistic overlay networks when compared\nto methods that employ traditional streaming strategies as well as random\nnetwork nodes selection algorithms.",
    "published": "2011-01-20T17:50:26Z",
    "link": "http://arxiv.org/pdf/1101.3979v1.pdf",
    "category": [
      "cs.MM",
      "cs.IT",
      "cs.NI",
      "math.IT"
    ],
    "authors": [
      "Nicolae Cleju",
      "Nikolaos Thomos",
      "Pascal Frossard"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1101.4789v3",
    "title": "Multi-Level Steganography: Improving Hidden Communication in Networks",
    "summary": "The paper presents Multi-Level Steganography (MLS), which defines a new\nconcept for hidden communication in telecommunication networks. In MLS, at\nleast two steganographic methods are utilised simultaneously, in such a way\nthat one method (called the upper-level) serves as a carrier for the second one\n(called the lower-level). Such a relationship between two (or more) information\nhiding solutions has several potential benefits. The most important is that the\nlower-level method steganographic bandwidth can be utilised to make the\nsteganogram unreadable even after the detection of the upper-level method:\ne.g., it can carry a cryptographic key that deciphers the steganogram carried\nby the upper-level one. It can also be used to provide the steganogram with\nintegrity. Another important benefit is that the lower-layer method may be used\nas a signalling channel in which to exchange information that affects the way\nthat the upper-level method functions, thus possibly making the steganographic\ncommunication harder to detect. The prototype of MLS for IP networks was also\ndeveloped, and the experimental results are included in this paper.",
    "published": "2011-01-25T12:26:00Z",
    "link": "http://arxiv.org/pdf/1101.4789v3.pdf",
    "category": [
      "cs.CR",
      "cs.MM"
    ],
    "authors": [
      "Wojciech Fraczek",
      "Wojciech Mazurczyk",
      "Krzysztof Szczypiorski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1101.5755v2",
    "title": "2D Sparse Signal Recovery via 2D Orthogonal Matching Pursuit",
    "summary": "Recovery algorithms play a key role in compressive sampling (CS). Most of\ncurrent CS recovery algorithms are originally designed for one-dimensional (1D)\nsignal, while many practical signals are two-dimensional (2D). By utilizing 2D\nseparable sampling, 2D signal recovery problem can be converted into 1D signal\nrecovery problem so that ordinary 1D recovery algorithms, e.g. orthogonal\nmatching pursuit (OMP), can be applied directly. However, even with 2D\nseparable sampling, the memory usage and complexity at the decoder is still\nhigh. This paper develops a novel recovery algorithm called 2D-OMP, which is an\nextension of 1D-OMP. In the 2D-OMP, each atom in the dictionary is a matrix. At\neach iteration, the decoder projects the sample matrix onto 2D atoms to select\nthe best matched atom, and then renews the weights for all the already selected\natoms via the least squares. We show that 2D-OMP is in fact equivalent to\n1D-OMP, but it reduces recovery complexity and memory usage significantly.\nWhat's more important, by utilizing the same methodology used in this paper,\none can even obtain higher dimensional OMP (say 3D-OMP, etc.) with ease.",
    "published": "2011-01-30T10:02:06Z",
    "link": "http://arxiv.org/pdf/1101.5755v2.pdf",
    "category": [
      "cs.IT",
      "cs.MM",
      "math.IT"
    ],
    "authors": [
      "Yong Fang",
      "Bormin Huang",
      "Jiaji Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1101.5791v1",
    "title": "Using Planetlab to Implement Multicast at the Application Level",
    "summary": "Application-layer multicast implements the multicast functionality at the\napplication layer. The main goal of application-layer multicast is to construct\nand maintain efficient distribution structures between endhosts. In this paper\nwe focus on the implementation of an application-layer multicast network using\nPlanetLab. We observe that the total time required to measure network latency\nover TCP is influenced dramatically by the TCP connection time. We argue that\nend-host distribution is not only influenced by the quality of network links\nbut also by the time required to make connections between nodes. We provide\nseveral solutions to decrease the total end-host distribution time.",
    "published": "2011-01-30T17:49:58Z",
    "link": "http://arxiv.org/pdf/1101.5791v1.pdf",
    "category": [
      "cs.DC",
      "cs.MM"
    ],
    "authors": [
      "Genge Bela",
      "Haller Piroska"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1102.0023v1",
    "title": "On Steganography in Lost Audio Packets",
    "summary": "The paper presents a new hidden data insertion procedure based on estimated\nprobability of the remaining time of the call for steganographic method called\nLACK (Lost Audio PaCKets steganography). LACK provides hidden communication for\nreal-time services like Voice over IP. The analytical results presented in this\npaper concern the influence of LACK's hidden data insertion procedures on the\nmethod's impact on quality of voice transmission and its resistance to\nsteganalysis. The proposed hidden data insertion procedure is also compared to\nprevious steganogram insertion approach based on estimated remaining average\ncall duration.",
    "published": "2011-01-31T21:57:34Z",
    "link": "http://arxiv.org/pdf/1102.0023v1.pdf",
    "category": [
      "cs.CR",
      "cs.MM"
    ],
    "authors": [
      "Wojciech Mazurczyk",
      "Jozef Lubacz",
      "Krzysztof Szczypiorski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1102.1503v1",
    "title": "Peer-to-Peer Multimedia Sharing based on Social Norms",
    "summary": "Empirical data shows that in the absence of incentives, a peer participating\nin a Peer-to-Peer (P2P) network wishes to free-riding. Most solutions for\nproviding incentives in P2P networks are based on direct reciprocity, which are\nnot appropriate for most P2P multimedia sharing networks due to the unique\nfeatures exhibited by such networks: large populations of anonymous agents\ninteracting infrequently, asymmetric interests of peers, network errors, and\nmultiple concurrent transactions. In this paper, we design and rigorously\nanalyze a new family of incentive protocols that utilizes indirect reciprocity\nwhich is based on the design of efficient social norms. In the proposed P2P\nprotocols, the social norms consist of a social strategy, which represents the\nrule prescribing to the peers when they should or should not provide content to\nother peers, and a reputation scheme, which rewards or punishes peers depending\non whether they comply or not with the social strategy. We first define the\nconcept of a sustainable social norm, under which no peer has an incentive to\ndeviate. We then formulate the problem of designing optimal social norms, which\nselects the social norm that maximizes the network performance among all\nsustainable social norms. Hence, we prove that it becomes in the self-interest\nof peers to contribute their content to the network rather than to free-ride.\nWe also investigate the impact of various punishment schemes on the social\nwelfare as well as how should the optimal social norms be designed if\naltruistic and malicious peers are active in the network. Our results show that\noptimal social norms are capable of providing significant improvements in the\nsharing efficiency of multimedia P2P networks.",
    "published": "2011-02-08T04:36:32Z",
    "link": "http://arxiv.org/pdf/1102.1503v1.pdf",
    "category": [
      "cs.MM",
      "cs.SI"
    ],
    "authors": [
      "Yu Zhang",
      "Mihaela van der Schaar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1102.1600v1",
    "title": "A Study on Digital Video Broadcasting to a Handheld Device (DVB-H),\n  Operating in UHF Band",
    "summary": "In this paper, we will understand that the development of the Digital Video\nBroadcasting to a Handheld (DVB-H) standard makes it possible to deliver live\nbroadcast television to a mobile handheld device. Building upon the strengths\nof the Digital Video Broadcasting - Terrestrial (DVB-T) standard in use in\nmillions of homes, DVB-H recognizes the trend towards the personal consumption\nof media.",
    "published": "2011-02-08T13:22:55Z",
    "link": "http://arxiv.org/pdf/1102.1600v1.pdf",
    "category": [
      "cs.NI",
      "cs.MM"
    ],
    "authors": [
      "Farhat Masood"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1102.2604v2",
    "title": "Quasi-Optimal Network Utility Maximization for Scalable Video Streaming",
    "summary": "This paper addresses rate control for transmission of scalable video streams\nvia Network Utility Maximization (NUM) formulation. Due to stringent QoS\nrequirements of video streams and specific characterization of utility\nexperienced by end-users, one has to solve nonconvex and even nonsmooth NUM\nformulation for such streams, where dual methods often prove incompetent.\nConvexification plays an important role in this work as it permits the use of\nexisting dual methods to solve an approximate to the NUM problem iteratively\nand distributively. Hence, to tackle the nonsmoothness and nonconvexity, we aim\nat reformulating the NUM problem through approximation and transformation of\nthe ideal discretely adaptive utility function for scalable video streams. The\nreformulated problem is shown to be a D.C. (Difference of Convex) problem. We\nleveraged Sequential Convex Programming (SCP) approach to replace the nonconvex\nD.C. problem by a sequence of convex problems that aim to approximate the\noriginal D.C. problem. We then solve each convex problem produced by SCP\napproach using existing dual methods. This procedure is the essence of two\ndistributed iterative rate control algorithms proposed in this paper, for which\none can show the convergence to a locally optimal point of the nonconvex D.C.\nproblem and equivalently to a locally optimal point of an approximate to the\noriginal nonconvex problem. Our experimental results show that the proposed\nrate control algorithms converge with tractable convergence behavior.",
    "published": "2011-02-13T15:35:30Z",
    "link": "http://arxiv.org/pdf/1102.2604v2.pdf",
    "category": [
      "cs.MM",
      "cs.NI"
    ],
    "authors": [
      "Mohammad Sadegh Talebi",
      "Ahmad Khonsari",
      "Mohammad Hassan Hajiesmaili",
      "Sina Jafarpour"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1102.3219v1",
    "title": "On the Capacity of p2p Multipoint Video Conference",
    "summary": "In this paper, The structure of video conference is formulated and the\npeer-assisted distribution scheme is constructed to achieve optimal video\ndelivery rate in each sub-conference. The capacity of conference is proposed to\nreferee the video rate that can be supported in every possible scenario. We\nhave proved that, in case of one user watching only one video, 5/6 is a lower\nbound of the capacity which is much larger than 1/2, the achievable rate of\nchained approach in [2]. Almost all proofs in this paper are constructive. They\ncan be applied into real implementation directly with a few modifications.",
    "published": "2011-02-16T02:27:45Z",
    "link": "http://arxiv.org/pdf/1102.3219v1.pdf",
    "category": [
      "cs.NI",
      "cs.MM"
    ],
    "authors": [
      "Zhao Yong-Xiang",
      "Chen Chang-Jia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1102.5437v2",
    "title": "Transmitting important bits and sailing high radio waves: a\n  decentralized cross-layer approach to cooperative video transmission",
    "summary": "We investigate the impact of cooperative relaying on uplink and downlink\nmulti-user (MU) wireless video transmissions. The objective is to maximize the\nlong-term sum of utilities across the video terminals in a decentralized\nfashion, by jointly optimizing the packet scheduling, the resource allocation,\nand the cooperation decisions, under the assumption that some nodes are willing\nto act as cooperative relays. A pricing-based distributed resource allocation\nframework is adopted, where the price reflects the expected future congestion\nin the network. Specifically, we formulate the wireless video transmission\nproblem as an MU Markov decision process (MDP) that explicitly considers the\ncooperation at the physical layer and the medium access control sublayer, the\nvideo users' heterogeneous traffic characteristics, the dynamically varying\nnetwork conditions, and the coupling among the users' transmission strategies\nacross time due to the shared wireless resource. Although MDPs notoriously\nsuffer from the curse of dimensionality, our study shows that, with appropriate\nsimplications and approximations, the complexity of the MU-MDP can be\nsignificantly mitigated. Our simulation results demonstrate that integrating\ncooperative decisions into the MU-MDP optimization can increase the resource\nprice in networks that only support low transmission rates and can decrease the\nprice in networks that support high transmission rates. Additionally, our\nresults show that cooperation allows users with feeble direct signals to\nachieve improvements in video quality on the order of 5-10 dB peak\nsignal-to-noise ratio (PSNR), with less than 0.8 dB quality loss by users with\nstrong direct signals, and with a moderate increase in total network energy\nconsumption that is significantly less than the energy that a distant node\nwould require to achieve an equivalent PSNR without exploiting cooperative\ndiversity.",
    "published": "2011-02-26T19:11:27Z",
    "link": "http://arxiv.org/pdf/1102.5437v2.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Nicholas Mastronarde",
      "Francesco Verde",
      "Donatella Darsena",
      "Anna Scaglione",
      "Mihaela van der Schaar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1102.5699v1",
    "title": "Ontology based approach for video transmission over the network",
    "summary": "With the increase in the bandwidth & the transmission speed over the\ninternet, transmission of multimedia objects like video, audio, images has\nbecome an easier work. In this paper we provide an approach that can be useful\nfor transmission of video objects over the internet without much fuzz. The\napproach provides a ontology based framework that is used to establish an\nautomatic deployment of video transmission system. Further the video is\ncompressed using the structural flow mechanism that uses the wavelet principle\nfor compression of video frames. Finally the video transmission algorithm known\nas RRDBFSF algorithm is provided that makes use of the concept of restrictive\nflooding to avoid redundancy thereby increasing the efficiency.",
    "published": "2011-02-28T16:13:20Z",
    "link": "http://arxiv.org/pdf/1102.5699v1.pdf",
    "category": [
      "cs.MM",
      "cs.NI"
    ],
    "authors": [
      "Rachit Mohan Garg",
      "Yamini Sood",
      "Neha Tyagi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1102.5769v1",
    "title": "Multimedia Database Applications: Issues and Concerns for Classroom\n  Teaching",
    "summary": "The abundance of multimedia data and information is challenging educators to\neffectively search, browse, access, use, and store the data for their classroom\nteaching. However, many educators could still be accustomed to teaching or\nsearching for information using conventional methods, but often the\nconventional methods may not function well with multimedia data. Educators need\nto efficiently interact and manage a variety of digital media files too. The\npurpose of this study is to review current multimedia database applications in\nteaching and learning, and further discuss some of the issues or concerns that\neducators may have while incorporating multimedia data into their classrooms.\nSome strategies and recommendations are also provided in order for educators to\nbe able to use multimedia data more effectively in their teaching environments.",
    "published": "2011-02-28T20:47:08Z",
    "link": "http://arxiv.org/pdf/1102.5769v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Chien Yu",
      "Teri Brandenburg"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1103.0065v1",
    "title": "Interdisciplinary Collaboration through Designing 3D Simulation Case\n  Studies",
    "summary": "Interdisciplinary collaboration is essential for the advance of research. As\ndomain subjects become more and more specialized, researchers need to cross\ndisciplines for insights from peers in other areas to have a broader and deeper\nunderstand of a topic at micro- and macro-levels. We developed a 3D virtual\nlearning environment that served as a platform for faculty to plan curriculum,\nshare educational beliefs, and conduct cross-discipline research for effective\nlearning. Based upon the scripts designed by faculty from five disciplines,\nvirtual doctors, nurses, or patients interact in a 3D virtual hospital. The\nteaching vignettes were then converted to video clips, allowing users to view,\npause, replay, or comment on the videos individually or in groups. Unlike many\nexisting platforms, we anticipated a value-added by adding a social networking\ncapacity to this virtual environment. The focus of this paper is on the\ncost-efficiency and system design of the virtual learning environment.",
    "published": "2011-03-01T02:02:54Z",
    "link": "http://arxiv.org/pdf/1103.0065v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Xin Bai",
      "Dana Fusco"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1103.0540v1",
    "title": "An Algorithm for Repairing Low-Quality Video Enhancement Techniques\n  Based on Trained Filter",
    "summary": "Multifarious image enhancement algorithms have been used in different\napplications. Still, some algorithms or modules are imperfect for practical\nuse. When the image enhancement modules have been fixed or combined by a series\nof algorithms, we need to repair them as a whole part without changing the\ninside. This report aims to find an algorithm based on trained filters to\nrepair low-quality image enhancement modules. A brief review on basic image\nenhancement techniques and pixel classification methods will be presented, and\nthe procedure of trained filters will be described step by step. The\nexperiments and result comparisons for this algorithm will be described in\ndetail.",
    "published": "2011-03-02T20:50:22Z",
    "link": "http://arxiv.org/pdf/1103.0540v1.pdf",
    "category": [
      "cs.CV",
      "cs.MM"
    ],
    "authors": [
      "Lijun Wang",
      "Ling Shao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1103.0829v1",
    "title": "Hiding Secret Information in Movie Clip: A Steganographic Approach",
    "summary": "Establishing hidden communication is an important subject of discussion that\nhas gained increasing importance nowadays with the development of the internet.\nOne of the key methods for establishing hidden communication is steganography.\nModern day steganography mainly deals with hiding information within files like\nimage, text, html, binary files etc. These file contains small irrelevant\ninformation that can be substituted for small secret data. To store a high\ncapacity secret data these carrier files are not very supportive. To overcome\nthe problem of storing the high capacity secret data with the utmost security\nfence, we have proposed a novel methodology for concealing a voluminous data\nwith high levels of security wall by using movie clip as a carrier file.",
    "published": "2011-03-04T05:38:59Z",
    "link": "http://arxiv.org/pdf/1103.0829v1.pdf",
    "category": [
      "cs.MM",
      "cs.CR",
      "F.2.2; I.2.7"
    ],
    "authors": [
      "G. Sahoo",
      "Rajesh Kumar Tiwari"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1103.0837v1",
    "title": "Priority based Interface Selection for Overlaying Heterogeneous Networks",
    "summary": "Offering of different attractive opportunities by different wireless\ntechnologies trends the convergence of heterogeneous networks for the future\nwireless communication system. To make a seamless handover among the\nheterogeneous networks, the optimization of the power consumption, and optimal\nselection of interface are the challenging issues for convergence networks. The\naccess of multi interfaces simultaneously reduces the handover latency and data\nloss in heterogeneous handover. The mobile node (MN) maintains one interface\nconnection while other interface is used for handover process. However, it\ncauses much battery power consumption. In this paper we propose an efficient\ninterface selection scheme including interface selection algorithms, interface\nselection procedures considering battery power consumption and user mobility\nwith other existing parameters for overlaying networks. We also propose a\npriority based network selection scheme according to the service types. MN's\nbattery power level, provision of QoS/QoE in the target network and our\nproposed priority parameters are considered as more important parameters for\nour interface selection algorithm. The performances of the proposed scheme are\nverified using numerical analysis.",
    "published": "2011-03-04T07:40:44Z",
    "link": "http://arxiv.org/pdf/1103.0837v1.pdf",
    "category": [
      "cs.MM",
      "cs.NI"
    ],
    "authors": [
      "Mostafa Zaman Chowdhury",
      "Yeong Min Jang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1103.2756v3",
    "title": "Sparse Transfer Learning for Interactive Video Search Reranking",
    "summary": "Visual reranking is effective to improve the performance of the text-based\nvideo search. However, existing reranking algorithms can only achieve limited\nimprovement because of the well-known semantic gap between low level visual\nfeatures and high level semantic concepts. In this paper, we adopt interactive\nvideo search reranking to bridge the semantic gap by introducing user's\nlabeling effort. We propose a novel dimension reduction tool, termed sparse\ntransfer learning (STL), to effectively and efficiently encode user's labeling\ninformation. STL is particularly designed for interactive video search\nreranking. Technically, it a) considers the pair-wise discriminative\ninformation to maximally separate labeled query relevant samples from labeled\nquery irrelevant ones, b) achieves a sparse representation for the subspace to\nencodes user's intention by applying the elastic net penalty, and c) propagates\nuser's labeling information from labeled samples to unlabeled samples by using\nthe data distribution knowledge. We conducted extensive experiments on the\nTRECVID 2005, 2006 and 2007 benchmark datasets and compared STL with popular\ndimension reduction algorithms. We report superior performance by using the\nproposed STL based interactive video search reranking.",
    "published": "2011-03-14T19:48:20Z",
    "link": "http://arxiv.org/pdf/1103.2756v3.pdf",
    "category": [
      "cs.IR",
      "cs.CV",
      "cs.MM",
      "stat.ML"
    ],
    "authors": [
      "Xinmei Tian",
      "Dacheng Tao",
      "Yong Rui"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1103.3802v1",
    "title": "Stage Staffing Scheme for Copyright Protection in Multimedia",
    "summary": "Copyright protection has become a need in today's world. To achieve a secure\ncopyright protection we embedded some information in images and videos and that\nimage or video is called copyright protected. The embedded information can't be\ndetected by human eye but some attacks and operations can tamper that\ninformation to breach protection. So in order to find a secure technique of\ncopyright protection, we have analyzed image processing techniques i.e. Spatial\nDomain (Least Significant Bit (LSB)), Transform Domain (Discrete Cosine\nTransform (DCT)), Discrete Wavelet Transform (DWT) and there are numerous\nalgorithm for watermarking using them. After having a good understanding of the\nsame we have proposed a novel algorithm named as Stage Staffing Algorithm that\ngenerates results with high effectiveness, additionally we can use self\nextracted-watermark technique to increase the security and automate the process\nof watermark image. The proposed algorithm provides protection in three stages.\nWe have implemented the algorithm and results of the simulations are shown. The\nvarious factors affecting spatial domain watermarking are also discussed.",
    "published": "2011-03-19T18:43:30Z",
    "link": "http://arxiv.org/pdf/1103.3802v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Sumit Kumar",
      "Santosh Kumar",
      "Sukumar Nandi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1103.4271v2",
    "title": "Rendering of 3D Dynamic Virtual Environments",
    "summary": "In this paper we present a framework for the rendering of dynamic 3D virtual\nenvironments which can be integrated in the development of videogames. It\nincludes methods to manage sounds and particle effects, paged static\ngeometries, the support of a physics engine and various input systems. It has\nbeen designed with a modular structure to allow future expansions. We exploited\nsome open-source state-of-the-art components such as OGRE, PhysX,\nParticleUniverse, etc.; all of them have been properly integrated to obtain\npeculiar physical and environmental effects. The stand-alone version of the\napplication is fully compatible with Direct3D and OpenGL APIs and adopts OpenAL\nAPIs to manage audio cards. Concluding, we devised a showcase demo which\nreproduces a dynamic 3D environment, including some particular effects: the\nalternation of day and night infuencing the lighting of the scene, the\nrendering of terrain, water and vegetation, the reproduction of sounds and\natmospheric agents.",
    "published": "2011-03-22T14:16:07Z",
    "link": "http://arxiv.org/pdf/1103.4271v2.pdf",
    "category": [
      "cs.GR",
      "cs.MM",
      "68",
      "H.5.1; I.2.1; I.3.7"
    ],
    "authors": [
      "Salvatore Catanese",
      "Emilio Ferrara",
      "Giacomo Fiumara",
      "Francesco Pagano"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1103.4712v1",
    "title": "Distributed Video Coding: Codec Architecture and Implementation",
    "summary": "Distributed Video Coding (DVC) is a new coding paradigm for video\ncompression, based on Slepian- Wolf (lossless coding) and Wyner-Ziv (lossy\ncoding) information theoretic results. DVC is useful for emerging applications\nsuch as wireless video cameras, wireless low-power surveillance networks and\ndisposable video cameras for medical applications etc. The primary objective of\nDVC is low-complexity video encoding, where bulk of computation is shifted to\nthe decoder, as opposed to low-complexity decoder in conventional video\ncompression standards such as H.264 and MPEG etc. There are couple of early\narchitectures and implementations of DVC from Stanford University[2][3] in\n2002, Berkeley University PRISM (Power-efficient, Robust, hIgh-compression,\nSyndrome-based Multimedia coding)[4][5] in 2002 and European project DISCOVER\n(DIStributed COding for Video SERvices)[6] in 2007. Primarily there are two\ntypes of DVC techniques namely pixel domain and transform domain based.\nTransform domain design will have better rate-distortion (RD) performance as it\nexploits spatial correlation between neighbouring samples and compacts the\nblock energy into as few transform coefficients as possible (aka energy\ncompaction). In this paper, architecture, implementation details and \"C\" model\nresults of our transform domain DVC are presented.",
    "published": "2011-03-24T09:50:26Z",
    "link": "http://arxiv.org/pdf/1103.4712v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Vijay Kumar Kodavalla",
      "Dr. P. G. Krishna Mohan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1104.0809v1",
    "title": "SLDs for Visualizing Multicolor Elevation Contour Lines in Geo-Spatial\n  Web Applications",
    "summary": "This paper addresses the need for geospatial consumers (either humans or\nmachines) to visualize multicolored elevation contour poly lines with respect\ntheir different contour intervals and control the visual portrayal of the data\nwith which they work. The current OpenGIS Web Map Service (WMS) specification\nsupports the ability for an information provider to specify very basic styling\noptions by advertising a preset collection of visual portrayals for each\navailable data set. However, while a WMS currently can provide the user with a\nchoice of style options, the WMS can only tell the user the name of each style.\nIt cannot tell the user what portrayal will look like on the map. More\nimportantly, the user has no way of defining their own styling rules. The\nability for a human or machine client to define these rules requires a styling\nlanguage that the client and server can both understand. Defining this\nlanguage, called the StyledLayerDescriptor (SLD), is the main focus of this\npaper, and it can be used to portray the output of Web Map Servers, Web Feature\nServers and Web Coverage Servers.",
    "published": "2011-04-05T11:06:30Z",
    "link": "http://arxiv.org/pdf/1104.0809v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "B. G. Kodge",
      "P. S. Hiremath"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1104.2681v1",
    "title": "Liquidsoap: a High-Level Programming Language for Multimedia Streaming",
    "summary": "Generating multimedia streams, such as in a netradio, is a task which is\ncomplex and difficult to adapt to every users' needs. We introduce a novel\napproach in order to achieve it, based on a dedicated high-level functional\nprogramming language, called Liquidsoap, for generating, manipulating and\nbroadcasting multimedia streams. Unlike traditional approaches, which are based\non configuration files or static graphical interfaces, it also allows the user\nto build complex and highly customized systems. This language is based on a\nmodel for streams and contains operators and constructions, which make it\nadapted to the generation of streams. The interpreter of the language also\nensures many properties concerning the good execution of the stream generation.",
    "published": "2011-04-14T07:01:54Z",
    "link": "http://arxiv.org/pdf/1104.2681v1.pdf",
    "category": [
      "cs.PL",
      "cs.MM",
      "cs.SD"
    ],
    "authors": [
      "David Baelde",
      "Romain Beauxis",
      "Samuel Mimram"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1104.4959v1",
    "title": "Duplication of Key Frames of Video Streams in Wireless Networks",
    "summary": "In this paper technological solutions for improving the quality of video\ntransfer along wireless networks are investigated. Tools have been developed to\nallow packets to be duplicated with key frames data. In the paper we tested\nvideo streams with duplication of all frames, with duplication of key frames,\nand without duplication. The experiments showed that the best results are\nobtained by duplication of packages which contain key frames. The paper also\nprovides an overview of the coefficients describing the dependence of video\nquality on packet loss and delay variation (network jitter).",
    "published": "2011-04-26T16:29:15Z",
    "link": "http://arxiv.org/pdf/1104.4959v1.pdf",
    "category": [
      "cs.NI",
      "cs.MM"
    ],
    "authors": [
      "Evgeny S. Sagatov",
      "Andrei M. Sukhov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1104.5284v1",
    "title": "Content-Based Spam Filtering on Video Sharing Social Networks",
    "summary": "In this work we are concerned with the detection of spam in video sharing\nsocial networks. Specifically, we investigate how much visual content-based\nanalysis can aid in detecting spam in videos. This is a very challenging task,\nbecause of the high-level semantic concepts involved; of the assorted nature of\nsocial networks, preventing the use of constrained a priori information; and,\nwhat is paramount, of the context dependent nature of spam. Content filtering\nfor social networks is an increasingly demanded task: due to their popularity,\nthe number of abuses also tends to increase, annoying the user base and\ndisrupting their services. We systematically evaluate several approaches for\nprocessing the visual information: using static and dynamic (motionaware)\nfeatures, with and without considering the context, and with or without latent\nsemantic analysis (LSA). Our experiments show that LSA is helpful, but taking\nthe context into consideration is paramount. The whole scheme shows good\nresults, showing the feasibility of the concept.",
    "published": "2011-04-28T03:16:42Z",
    "link": "http://arxiv.org/pdf/1104.5284v1.pdf",
    "category": [
      "cs.CV",
      "cs.MM"
    ],
    "authors": [
      "Antonio da Luz",
      "Eduardo Valle",
      "Arnaldo Araujo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1105.0011v1",
    "title": "Optimized Spline Interpolation",
    "summary": "In this paper, we investigate the problem of designing compact support\ninterpolation kernels for a given class of signals. By using calculus of\nvariations, we simplify the optimization problem from an infinite nonlinear\nproblem to a finite dimensional linear case, and then find the optimum compact\nsupport function that best approximates a given filter in the least square\nsense (l2 norm). The benefit of compact support interpolants is the low\ncomputational complexity in the interpolation process while the optimum compact\nsupport interpolant gaurantees the highest achivable Signal to Noise Ratio\n(SNR). Our simulation results confirm the superior performance of the proposed\nsplines compared to other conventional compact support interpolants such as\ncubic spline.",
    "published": "2011-04-29T20:05:52Z",
    "link": "http://arxiv.org/pdf/1105.0011v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Ramtin Madani",
      "Ali Ayremlou",
      "Arash Amini",
      "Farrokh Marvasti"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1105.0023v1",
    "title": "Survey of Cognitive Radio Techniques in Wireless Network",
    "summary": "In this report, I surveyed the cognitive radio technique in wireless\nnetworks. Researched several kinds of cognitive techniques about their\nadvantages and disadvantages.",
    "published": "2011-04-29T21:34:21Z",
    "link": "http://arxiv.org/pdf/1105.0023v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Lu Lu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1105.0699v1",
    "title": "Robust Sign Language Recognition System Using ToF Depth Cameras",
    "summary": "Sign language recognition is a difficult task, yet required for many\napplications in real-time speed. Using RGB cameras for recognition of sign\nlanguages is not very successful in practical situations and accurate 3D\nimaging requires expensive and complex instruments. With introduction of\nTime-of-Flight (ToF) depth cameras in recent years, it has become easier to\nscan the environment for accurate, yet fast depth images of the objects without\nthe need of any extra calibrating object. In this paper, a robust system for\nsign language recognition using ToF depth cameras is presented for converting\nthe recorded signs to a standard and portable XML sign language named SiGML for\neasy transferring and converting to real-time 3D virtual characters animations.\nFeature extraction using moments and classification using nearest neighbor\nclassifier are used to track hand gestures and significant result of 100% is\nachieved for the proposed approach.",
    "published": "2011-05-03T21:57:18Z",
    "link": "http://arxiv.org/pdf/1105.0699v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Morteza Zahedi",
      "Ali Reza Manashty"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1105.0755v1",
    "title": "Using Logistic Regression to Analyze the Balance of a Game: The Case of\n  StarCraft II",
    "summary": "Recently, the market size of online game has been increasing astonishingly\nfast, and so does the importance of good game design. In online games, usually\na human user competes with others, so the fairness of the game system to all\nusers is of great importance not to lose interests of users on the game.\nFurthermore, the emergence and success of electronic sports (e-sports) and\nprofessional gaming which specially talented gamers compete with others draws\nmore attention on whether they are competing in the fair environment. No matter\nhow fierce the debates are in the game-design community, it is rarely the case\nthat one employs statistical analysis to answer this question seriously. But\nconsidering the fact that we can easily gather large amount of user behavior\ndata on games, it seems potentially beneficial to make use of this data to aid\nmaking decisions on design problems of games. Actually, modern games do not aim\nto perfectly design the game at once: rather, they first release the game, and\nthen monitor users' behavior to better balance the game. In such a scenario,\nstatistical analysis can be particularly helpful. Specifically, we chose to\nanalyze the balance of StarCraft II, which is a very successful\nrecently-released real-time strategy (RTS) game. It is a central icon in\ncurrent e-Sports and professional gaming community: from April 1st to 15th,\nthere were 18 tournaments of StarCraft II. However, there is endless debate on\nwhether the winner of the tournament is actually superior to others, or it is\nlargely due to certain design flaws of the game. In this paper, we aim to\nanswer such a question using traditional statistical tool, logistic regression.",
    "published": "2011-05-04T08:15:20Z",
    "link": "http://arxiv.org/pdf/1105.0755v1.pdf",
    "category": [
      "stat.AP",
      "cs.MM"
    ],
    "authors": [
      "Hyokun Yun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1105.0826v1",
    "title": "Streaming Multimedia Information Using the Features of the DVB-S Card",
    "summary": "This paper presents a study of audio-video streaming using the additional\npossibilities of a DVB-S card. The board used for experiments (Technisat\nSkyStar 2) is one of the most frequently used cards for this purpose. Using the\nmain blocks of the board's software support it is possible the implement a\nreally useful and full functional system for audio-video streaming. The\nstreaming is possible to be implemented either for decoded MPEG stream or for\ntransport stream. In this last case it is possible to view not only a program,\nbut any program from the same multiplex. This allows us to implement",
    "published": "2011-05-04T13:46:31Z",
    "link": "http://arxiv.org/pdf/1105.0826v1.pdf",
    "category": [
      "cs.MM",
      "cs.CV"
    ],
    "authors": [
      "Radu Arsinte",
      "Eugen Lupu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1105.1561v2",
    "title": "Efficient Image Transmission Through Analog Error Correction",
    "summary": "This paper presents a new paradigm for image transmission through analog\nerror correction codes. Conventional schemes rely on digitizing images through\nquantization (which inevitably causes significant bandwidth expansion) and\ntransmitting binary bit-streams through digital error correction codes (which\ndo not automatically differentiate the different levels of significance among\nthe bits). To strike a better overall performance in terms of transmission\nefficiency and quality, we propose to use a single analog error correction code\nin lieu of digital quantization, digital code and digital modulation. The key\nis to get analog coding right. We show that this can be achieved by cleverly\nexploiting an elegant \"butterfly\" property of chaotic systems. Specifically, we\ndemonstrate a tail-biting triple-branch baker's map code and its\nmaximum-likelihood decoding algorithm. Simulations show that the proposed\nanalog code can actually outperform digital turbo code, one of the best codes\nknown to date. The results and findings discussed in this paper speak volume\nfor the promising potential of analog codes, in spite of their rather short\nhistory.",
    "published": "2011-05-09T00:07:56Z",
    "link": "http://arxiv.org/pdf/1105.1561v2.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Yang Liu",
      " Jing",
      " Li",
      "Kai Xie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1105.1948v1",
    "title": "Analytical Classification of Multimedia Index Structures by Using a\n  Partitioning Method-Based Framework",
    "summary": "Due to the advances in hardware technology and increase in production of\nmultimedia data in many applications, during the last decades, multimedia\ndatabases have become increasingly important. Contentbased multimedia retrieval\nis one of an important research area in the field of multimedia databases. Lots\nof research on this field has led to proposition of different kinds of index\nstructures to support fast and efficient similarity search to retrieve\nmultimedia data from these databases. Due to variety and plenty of proposed\nindex structures, we suggest a systematic framework based on partitioning\nmethod used in these structures to classify multimedia index structures, and\nthen we evaluated these structures based on important functional measures. We\nhope this proposed framework will lead to empirical and technical comparison of\nmultimedia index structures and development of more efficient structures at\nfuture.",
    "published": "2011-05-10T13:55:31Z",
    "link": "http://arxiv.org/pdf/1105.1948v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Mohammadreza keyvanpour",
      "Najva Izadpanah"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1105.2344v1",
    "title": "Learning content similarity for music recommendation",
    "summary": "Many tasks in music information retrieval, such as recommendation, and\nplaylist generation for online radio, fall naturally into the query-by-example\nsetting, wherein a user queries the system by providing a song, and the system\nresponds with a list of relevant or similar song recommendations. Such\napplications ultimately depend on the notion of similarity between items to\nproduce high-quality results. Current state-of-the-art systems employ\ncollaborative filter methods to represent musical items, effectively comparing\nitems in terms of their constituent users. While collaborative filter\ntechniques perform well when historical data is available for each item, their\nreliance on historical data impedes performance on novel or unpopular items. To\ncombat this problem, practitioners rely on content-based similarity, which\nnaturally extends to novel items, but is typically out-performed by\ncollaborative filter methods.\n  In this article, we propose a method for optimizing contentbased similarity\nby learning from a sample of collaborative filter data. The optimized\ncontent-based similarity metric can then be applied to answer queries on novel\nand unpopular items, while still maintaining high recommendation accuracy. The\nproposed system yields accurate and efficient representations of audio content,\nand experimental results show significant improvements in accuracy over\ncompeting content-based recommendation techniques.",
    "published": "2011-05-12T00:43:46Z",
    "link": "http://arxiv.org/pdf/1105.2344v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Brian McFee",
      "Luke Barrington",
      "Gert Lanckriet"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1105.2770v2",
    "title": "Improving Performance of Speaker Identification System Using\n  Complementary Information Fusion",
    "summary": "Feature extraction plays an important role as a front-end processing block in\nspeaker identification (SI) process. Most of the SI systems utilize like\nMel-Frequency Cepstral Coefficients (MFCC), Perceptual Linear Prediction (PLP),\nLinear Predictive Cepstral Coefficients (LPCC), as a feature for representing\nspeech signal. Their derivations are based on short term processing of speech\nsignal and they try to capture the vocal tract information ignoring the\ncontribution from the vocal cord. Vocal cord cues are equally important in SI\ncontext, as the information like pitch frequency, phase in the residual signal,\netc could convey important speaker specific attributes and are complementary to\nthe information contained in spectral feature sets. In this paper we propose a\nnovel feature set extracted from the residual signal of LP modeling.\nHigher-order statistical moments are used here to find the nonlinear\nrelationship in residual signal. To get the advantages of complementarity vocal\ncord based decision score is fused with the vocal tract based score. The\nexperimental results on two public databases show that fused mode system\noutperforms single spectral features.",
    "published": "2011-05-13T16:32:44Z",
    "link": "http://arxiv.org/pdf/1105.2770v2.pdf",
    "category": [
      "cs.SD",
      "cs.MM"
    ],
    "authors": [
      "Md. Sahidullah",
      "Sandipan Chakroborty",
      "Goutam Saha"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1105.2795v1",
    "title": "View subspaces for indexing and retrieval of 3D models",
    "summary": "View-based indexing schemes for 3D object retrieval are gaining popularity\nsince they provide good retrieval results. These schemes are coherent with the\ntheory that humans recognize objects based on their 2D appearances. The\nviewbased techniques also allow users to search with various queries such as\nbinary images, range images and even 2D sketches. The previous view-based\ntechniques use classical 2D shape descriptors such as Fourier invariants,\nZernike moments, Scale Invariant Feature Transform-based local features and 2D\nDigital Fourier Transform coefficients. These methods describe each object\nindependent of others. In this work, we explore data driven subspace models,\nsuch as Principal Component Analysis, Independent Component Analysis and\nNonnegative Matrix Factorization to describe the shape information of the\nviews. We treat the depth images obtained from various points of the view\nsphere as 2D intensity images and train a subspace to extract the inherent\nstructure of the views within a database. We also show the benefit of\ncategorizing shapes according to their eigenvalue spread. Both the shape\ncategorization and data-driven feature set conjectures are tested on the PSB\ndatabase and compared with the competitor view-based 3D shape retrieval\nalgorithms",
    "published": "2011-05-13T18:24:10Z",
    "link": "http://arxiv.org/pdf/1105.2795v1.pdf",
    "category": [
      "cs.CV",
      "cs.MM",
      "I.2.10; I.4.8; I.5.4"
    ],
    "authors": [
      "Helin Dutagaci",
      "Afzal Godil",
      "Bulent Sankur",
      "Ycel Yemez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1105.2796v1",
    "title": "Salient Local 3D Features for 3D Shape Retrieval",
    "summary": "In this paper we describe a new formulation for the 3D salient local features\nbased on the voxel grid inspired by the Scale Invariant Feature Transform\n(SIFT). We use it to identify the salient keypoints (invariant points) on a 3D\nvoxelized model and calculate invariant 3D local feature descriptors at these\nkeypoints. We then use the bag of words approach on the 3D local features to\nrepresent the 3D models for shape retrieval. The advantages of the method are\nthat it can be applied to rigid as well as to articulated and deformable 3D\nmodels. Finally, this approach is applied for 3D Shape Retrieval on the McGill\narticulated shape benchmark and then the retrieval results are presented and\ncompared to other methods.",
    "published": "2011-05-13T18:25:15Z",
    "link": "http://arxiv.org/pdf/1105.2796v1.pdf",
    "category": [
      "cs.CV",
      "cs.MM",
      "I.2.10; I.4.8; I.5.4"
    ],
    "authors": [
      "Afzal Godil",
      "Asim Imdad Wagan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1105.2899v2",
    "title": "Fast restoration of natural images corrupted by high-density impulse\n  noise",
    "summary": "In this paper, we suggest a general model for the fixed-valued impulse noise\nand propose a two-stage method for high density noise suppression while\npreserving the image details. In the first stage, we apply an iterative impulse\ndetector, exploiting the image entropy, to identify the corrupted pixels and\nthen employ an Adaptive Iterative Mean filter to restore them. The filter is\nadaptive in terms of the number of iterations, which is different for each\nnoisy pixel, according to the Euclidean distance from the nearest uncorrupted\npixel. Experimental results show that the proposed filter is fast and\noutperforms the best existing techniques in both objective and subjective\nperformance measures.",
    "published": "2011-05-14T13:57:35Z",
    "link": "http://arxiv.org/pdf/1105.2899v2.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Hossein Hosseini",
      "Farokh Marvasti"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1105.4431v1",
    "title": "Service Level Agreement for the QoS Guaranteed Mobile IPTV Services over\n  Mobile WiMAX Networks",
    "summary": "While mobile IPTV services are supported through the mobile WiMAX networks,\nthere must need some guaranteed bandwidth for the IPTV services especially if\nIPTV and non-IPTV services are simultaneously supported by the mobile WiMAX\nnetworks. The quality of an IPTV service definitely depends on the allocated\nbandwidth for that channel. However, due to the high quality IPTV services and\nto support of huge non-IPTV traffic over mobile WiMAX networks, it is not\npossible to guarantee the sufficient amount of the limited mobile WiMAX\nbandwidth for the mobile IPTV services every time. A Service Level Agreement\n(SLA) between the mobile IPTV service provider and mobile WiMAX network\noperator to reserve sufficient bandwidth for the IPTV calls can increase the\nsatisfaction level of the mobile IPTV users. In this paper, we propose a SLA\nnegotiation procedure for mobile IPTV users over mobile WiMAX networks. The\nBandwidth Broker controls the allocated bandwidth for IPTV and non-IPTV users.\nThe proposed dynamically reserved bandwidth for the IPTV services increases the\nIPTV user's satisfaction level. The simulation results state that, our proposed\nscheme is able to provide better user satisfaction level for the IPTV users.",
    "published": "2011-05-23T08:30:58Z",
    "link": "http://arxiv.org/pdf/1105.4431v1.pdf",
    "category": [
      "cs.MM",
      "cs.NI"
    ],
    "authors": [
      "Mostafa Zaman Chowdhury",
      "Bui Minh Trung",
      "Yeong Min Jang",
      "Young-Il Kim",
      "Won Ryu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1105.5553v3",
    "title": "A Frequency-domain Compensation Scheme for IQ-Imbalance in OFDM\n  Receivers",
    "summary": "A pilot pattern across two OFDM symbols with special structure is devised for\nchannel estimation in OFDM systems with IQ imbalance at receiver. Based on this\npilot pattern, a high-efficiency time-domain (TD) least square (LS) channel\nestimator is proposed to significantly suppress channel noise by a factor\nN/(L+1) in comparison with the frequency-domain LS one in [1] where N and L+1\nare the total number of subcarriers and the length of cyclic prefix,\nrespectively. Following this, a low-complexity frequency-domain (FD) Gaussian\nelimination (GE) equalizer is proposed to eliminate IQ distortion by using only\n2N complex multiplications per OFDM symbol. From simulation, the proposed\nscheme TD-LS/FD-GE using only two pilot OFDM symbols achieves the same bit\nerror rate (BER) performance under ideal channel knowledge and no IQ imbalances\nat low and medium signal-to-noise ratio (SNR) regions whereas these\ncompensation schemes including FD-LS/Post-FFT LS, FD-LS/Pre-FFT Corr, and\nSPP/Pre-FFT Corr in [1] require about twenty OFDM training symbols to reach the\nsame performance where A/B denotes compensation scheme with A being channel\nestimator and B being equalizer.",
    "published": "2011-05-27T13:08:30Z",
    "link": "http://arxiv.org/pdf/1105.5553v3.pdf",
    "category": [
      "cs.NI",
      "cs.MM",
      "C.2.1"
    ],
    "authors": [
      "Shu Feng",
      "Wang Mao",
      "Shi Xiajie",
      "Liu Junhao",
      "Sheng Weixin",
      "Xie Renhong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1105.5641v1",
    "title": "High Quality of Service on Video Streaming in P2P Networks using FST-MDC",
    "summary": "Video streaming applications have newly attracted a large number of\nparticipants in a distribution network. Traditional client-server based video\nstreaming solutions sustain precious bandwidth provision rate on the server.\nRecently, several P2P streaming systems have been organized to provide\non-demand and live video streaming services on the wireless network at reduced\nserver cost. Peer-to-Peer (P2P) computing is a new pattern to construct\ndisseminated network applications. Typical error control techniques are not\nvery well matched and on the other hand error prone channels has increased\ngreatly for video transmission e.g., over wireless networks and IP. These two\nfacts united together provided the essential motivation for the development of\na new set of techniques (error concealment) capable of dealing with\ntransmission errors in video systems. In this paper, we propose an flexible\nmultiple description coding method named as Flexible Spatial-Temporal (FST)\nwhich improves error resilience in the sense of frame loss possibilities over\nindependent paths. It introduces combination of both spatial and temporal\nconcealment technique at the receiver and to conceal the lost frames more\neffectively. Experimental results show that, proposed approach attains\nreasonable quality of video performance over P2P wireless network.",
    "published": "2011-05-27T13:34:42Z",
    "link": "http://arxiv.org/pdf/1105.5641v1.pdf",
    "category": [
      "cs.DC",
      "cs.MM"
    ],
    "authors": [
      "Suresh Jaganathan",
      "Jeevan Eranti"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9301112v1",
    "title": "A note on digitized angles",
    "summary": "We study the configurations of pixels that occur when two digitized straight\nlines meet each other.",
    "published": "1990-04-01T00:00:00Z",
    "link": "http://arxiv.org/pdf/cs/9301112v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Donald E. Knuth"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9809035v2",
    "title": "Separation-Sensitive Collision Detection for Convex Objects",
    "summary": "We develop a class of new kinetic data structures for collision detection\nbetween moving convex polytopes; the performance of these structures is\nsensitive to the separation of the polytopes during their motion. For two\nconvex polygons in the plane, let $D$ be the maximum diameter of the polygons,\nand let $s$ be the minimum distance between them during their motion. Our\nseparation certificate changes $O(\\log(D/s))$ times when the relative motion of\nthe two polygons is a translation along a straight line or convex curve,\n$O(\\sqrt{D/s})$ for translation along an algebraic trajectory, and $O(D/s)$ for\nalgebraic rigid motion (translation and rotation). Each certificate update is\nperformed in $O(\\log(D/s))$ time. Variants of these data structures are also\nshown that exhibit \\emph{hysteresis}---after a separation certificate fails,\nthe new certificate cannot fail again until the objects have moved by some\nconstant fraction of their current separation. We can then bound the number of\nevents by the combinatorial size of a certain cover of the motion path by\nballs.",
    "published": "1998-09-18T23:16:06Z",
    "link": "http://arxiv.org/pdf/cs/9809035v2.pdf",
    "category": [
      "cs.CG",
      "cs.GR",
      "F.2.2;I.3.5"
    ],
    "authors": [
      "Jeff Erickson",
      "Leonidas J. Guibas",
      "Jorge Stolfi",
      "Li Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9809119v1",
    "title": "Droems: experimental mathematics, informatics and infinite dimensional\n  geometry",
    "summary": "The article is devoted to a problem of elaboration of the real-time\ninteractive videosystems for accelerated nonverbal cognitive computer and\ntelecommunications. The proposed approach is based on the using of droems\n(dynamically reconstructed objects of experimental mathematics) and\ninterpretational figures as pointers to them. Four paragraphs of the article\nare devoted to (1) an exposition of basic notions of the interpretational\ngeometry, (2) the operator methods in the theory of interactive dynamical\nvideosystems, (3) the general concept of organization of the integrated\ninteractive real-time videocognitive systems, (4) the droems and processes of\ntheir dynamical reconstruction, where the general notions are illustrated by a\nconcrete example related to the infinite dimensional geometry. The exposition\nis presumably heuristic and conceptual (the first and the third paragraphs)\nthough some particular aspects such as content of the second and the fourth\nparagraphs, which allow deeper formalization and detailing in present, are\nexposed on the mathematical level of rigor.",
    "published": "1998-09-29T07:06:31Z",
    "link": "http://arxiv.org/pdf/cs/9809119v1.pdf",
    "category": [
      "cs.HC",
      "cs.GR",
      "math.RT",
      "H.1.2; I.3.8"
    ],
    "authors": [
      "Denis V. Juriev"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9810004v1",
    "title": "The Design of EzWindows: A Graphics API for an Introductory Programming\n  Course",
    "summary": "Teaching object-oriented programming in an introductory programming course\nposes considerable challenges to the instructor. An often advocated approach to\nmeeting this challenge is the use of a simple, object-oriented graphics\nlibrary. We have developed a simple, portable graphics library for teaching\nobject-oriented programming using C++. The library, EzWindows, allows beginning\nprogrammers to design and write programs that use the graphical display found\non all modern desktop computers. In addition to providing simple graphical\nobjects such as windows, geometric shapes, and bitmaps, EzWindows provides\nfacilities for introducing event-based programming using the mouse and timers.\nEzWindows has proven to be extremely popular; it is currently in use at over\n200 universities, colleges, and high schools. This paper describes the\nrationale for EzWindows and its high-level design.",
    "published": "1998-10-03T12:04:29Z",
    "link": "http://arxiv.org/pdf/cs/9810004v1.pdf",
    "category": [
      "cs.CY",
      "cs.GR",
      "K.3.1;K.3.2;I.3.4"
    ],
    "authors": [
      "Bruce R. Childers",
      "James P. Cohoon",
      "Jack W. Davidson",
      "Peter Valle"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9810021v1",
    "title": "Computational Geometry Column 32",
    "summary": "The proof of Dey's new k-set bound is illustrated.",
    "published": "1998-10-22T21:01:36Z",
    "link": "http://arxiv.org/pdf/cs/9810021v1.pdf",
    "category": [
      "cs.CG",
      "cs.GR",
      "F.2.2"
    ],
    "authors": [
      "Joseph O'Rourke"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9909018v1",
    "title": "Geometric compression for progressive transmission",
    "summary": "The compression of geometric structures is a relatively new field of data\ncompression. Since about 1995, several articles have dealt with the coding of\nmeshes, using for most of them the following approach: the vertices of the mesh\nare coded in an order such that it contains partially the topology of the mesh.\nIn the same time, some simple rules attempt to predict the position of the\ncurrent vertex from the positions of its neighbours that have been previously\ncoded. In this article, we describe a compression algorithm whose principle is\ncompletely different: the order of the vertices is used to compress their\ncoordinates, and then the topology of the mesh is reconstructed from the\nvertices. This algorithm, particularly suited for terrain models, achieves\ncompression factors that are slightly greater than those of the currently\navailable algorithms, and moreover, it allows progressive and interactive\ntransmission of the meshes.",
    "published": "1999-09-28T06:56:27Z",
    "link": "http://arxiv.org/pdf/cs/9909018v1.pdf",
    "category": [
      "cs.CG",
      "cs.GR",
      "F.2.2; I.3.5"
    ],
    "authors": [
      "Olivier Devillers",
      "Pierre-Maris Gandoin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9910017v1",
    "title": "Finite-resolution hidden surface removal",
    "summary": "We propose a hybrid image-space/object-space solution to the classical hidden\nsurface removal problem: Given n disjoint triangles in Real^3 and p sample\npoints (``pixels'') in the xy-plane, determine the first triangle directly\nbehind each pixel. Our algorithm constructs the sampled visibility map of the\ntriangles with respect to the pixels, which is the subset of the trapezoids in\na trapezoidal decomposition of the analytic visibility map that contain at\nleast one pixel. The sampled visibility map adapts to local changes in image\ncomplexity, and its complexity is bounded both by the number of pixels and by\nthe complexity of the analytic visibility map. Our algorithm runs in time\nO(n^{1+e} + n^{2/3+e}t^{2/3} + p), where t is the output size and e is any\npositive constant. This is nearly optimal in the worst case and compares\nfavorably with the best output-sensitive algorithms for both ray casting and\nanalytic hidden surface removal. In the special case where the pixels form a\nregular grid, a sweepline variant of our algorithm runs in time O(n^{1+e} +\nn^{2/3+e}t^{2/3} + t log p), which is usually sublinear in the number of\npixels.",
    "published": "1999-10-21T21:51:18Z",
    "link": "http://arxiv.org/pdf/cs/9910017v1.pdf",
    "category": [
      "cs.CG",
      "cs.GR",
      "I.3.7,F.2.2"
    ],
    "authors": [
      "Jeff Erickson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0001017v1",
    "title": "Bezier Curves Intersection Using Relief Perspective",
    "summary": "Presented paper describes the method for finding the intersection of class\nspace rational Bezier curves. The problem curve/curve intersection belongs\namong basic geometric problems and the aim of this article is to describe the\nnew technique to solve the problem using relief perspective and Bezier\nclipping.",
    "published": "2000-01-21T10:02:49Z",
    "link": "http://arxiv.org/pdf/cs/0001017v1.pdf",
    "category": [
      "cs.CG",
      "cs.GR",
      "F.2.2; I.3.5; J.6"
    ],
    "authors": [
      "Radoslav Hlusek"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0005005v1",
    "title": "Connectivity Compression for Irregular Quadrilateral Meshes",
    "summary": "Applications that require Internet access to remote 3D datasets are often\nlimited by the storage costs of 3D models. Several compression methods are\navailable to address these limits for objects represented by triangle meshes.\nMany CAD and VRML models, however, are represented as quadrilateral meshes or\nmixed triangle/quadrilateral meshes, and these models may also require\ncompression. We present an algorithm for encoding the connectivity of such\nquadrilateral meshes, and we demonstrate that by preserving and exploiting the\noriginal quad structure, our approach achieves encodings 30 - 80% smaller than\nan approach based on randomly splitting quads into triangles. We present both a\ncode with a proven worst-case cost of 3 bits per vertex (or 2.75 bits per\nvertex for meshes without valence-two vertices) and entropy-coding results for\ntypical meshes ranging from 0.3 to 0.9 bits per vertex, depending on the\nregularity of the mesh. Our method may be implemented by a rule for a\nparticular splitting of quads into triangles and by using the compression and\ndecompression algorithms introduced in [Rossignac99] and\n[Rossignac&Szymczak99]. We also present extensions to the algorithm to compress\nmeshes with holes and handles and meshes containing triangles and other\npolygons as well as quads.",
    "published": "2000-05-04T18:15:08Z",
    "link": "http://arxiv.org/pdf/cs/0005005v1.pdf",
    "category": [
      "cs.GR",
      "cs.CG",
      "cs.DS",
      "I.3.5; G2.2; E.4; J.6"
    ],
    "authors": [
      "Davis King",
      "Jarek Rossignac",
      "Andrzej Szymczak"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0101021v1",
    "title": "A Fast General Methodology for Information-Theoretically Optimal\n  Encodings of Graphs",
    "summary": "We propose a fast methodology for encoding graphs with\ninformation-theoretically minimum numbers of bits. Specifically, a graph with\nproperty pi is called a pi-graph. If pi satisfies certain properties, then an\nn-node m-edge pi-graph G can be encoded by a binary string X such that (1) G\nand X can be obtained from each other in O(n log n) time, and (2) X has at most\nbeta(n)+o(beta(n)) bits for any continuous super-additive function beta(n) so\nthat there are at most 2^{beta(n)+o(beta(n))} distinct n-node pi-graphs. The\nmethodology is applicable to general classes of graphs; this paper focuses on\nplanar graphs. Examples of such pi include all conjunctions over the following\ngroups of properties: (1) G is a planar graph or a plane graph; (2) G is\ndirected or undirected; (3) G is triangulated, triconnected, biconnected,\nmerely connected, or not required to be connected; (4) the nodes of G are\nlabeled with labels from {1, ..., ell_1} for ell_1 <= n; (5) the edges of G are\nlabeled with labels from {1, ..., ell_2} for ell_2 <= m; and (6) each node\n(respectively, edge) of G has at most ell_3 = O(1) self-loops (respectively,\nell_4 = O(1) multiple edges). Moreover, ell_3 and ell_4 are not required to be\nO(1) for the cases of pi being a plane triangulation. These examples are novel\napplications of small cycle separators of planar graphs and are the only\nnontrivial classes of graphs, other than rooted trees, with known\npolynomial-time information-theoretically optimal coding schemes.",
    "published": "2001-01-23T00:17:50Z",
    "link": "http://arxiv.org/pdf/cs/0101021v1.pdf",
    "category": [
      "cs.DS",
      "cs.GR",
      "E.4; F.2.2"
    ],
    "authors": [
      "Xin He",
      "Ming-Yang Kao",
      "Hsueh-I Lu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0101033v1",
    "title": "Linear-Time Succinct Encodings of Planar Graphs via Canonical Orderings",
    "summary": "Let G be an embedded planar undirected graph that has n vertices, m edges,\nand f faces but has no self-loop or multiple edge. If G is triangulated, we can\nencode it using {4/3}m-1 bits, improving on the best previous bound of about\n1.53m bits. In case exponential time is acceptable, roughly 1.08m bits have\nbeen known to suffice. If G is triconnected, we use at most\n(2.5+2\\log{3})\\min\\{n,f\\}-7 bits, which is at most 2.835m bits and smaller than\nthe best previous bound of 3m bits. Both of our schemes take O(n) time for\nencoding and decoding.",
    "published": "2001-01-27T02:05:33Z",
    "link": "http://arxiv.org/pdf/cs/0101033v1.pdf",
    "category": [
      "cs.DS",
      "cs.GR",
      "E.4; F.2.2"
    ],
    "authors": [
      "Xin He",
      "Ming-Yang Kao",
      "Hsueh-I Lu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0203026v1",
    "title": "Conformal Geometry, Euclidean Space and Geometric Algebra",
    "summary": "Projective geometry provides the preferred framework for most implementations\nof Euclidean space in graphics applications. Translations and rotations are\nboth linear transformations in projective geometry, which helps when it comes\nto programming complicated geometrical operations. But there is a fundamental\nweakness in this approach - the Euclidean distance between points is not\nhandled in a straightforward manner. Here we discuss a solution to this\nproblem, based on conformal geometry. The language of geometric algebra is best\nsuited to exploiting this geometry, as it handles the interior and exterior\nproducts in a single, unified framework. A number of applications are\ndiscussed, including a compact formula for reflecting a line off a general\nspherical surface.",
    "published": "2002-03-22T14:33:34Z",
    "link": "http://arxiv.org/pdf/cs/0203026v1.pdf",
    "category": [
      "cs.CG",
      "cs.GR",
      "math.MG",
      "I.3.5;I.3.6"
    ],
    "authors": [
      "Chris Doran",
      "Anthony Lasenby",
      "Joan Lasenby"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0206029v1",
    "title": "Computer-Generated Photorealistic Hair",
    "summary": "This paper presents an efficient method for generating and rendering\nphotorealistic hair in two dimensional pictures. The method consists of three\nmajor steps. Simulating an artist drawing is used to design the rough hair\nshape. A convolution based filter is then used to generate photorealistic hair\npatches. A refine procedure is finally used to blend the boundaries of the\npatches with surrounding areas. This method can be used to create all types of\nphotorealistic human hair (head hair, facial hair and body hair). It is also\nsuitable for fur and grass generation. Applications of this method include:\nhairstyle designing/editing, damaged hair image restoration, human hair\nanimation, virtual makeover of a human, and landscape creation.",
    "published": "2002-06-20T06:21:15Z",
    "link": "http://arxiv.org/pdf/cs/0206029v1.pdf",
    "category": [
      "cs.GR",
      "I.3.3"
    ],
    "authors": [
      "Alice J. Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0207004v1",
    "title": "Optimally cutting a surface into a disk",
    "summary": "We consider the problem of cutting a set of edges on a polyhedral manifold\nsurface, possibly with boundary, to obtain a single topological disk,\nminimizing either the total number of cut edges or their total length. We show\nthat this problem is NP-hard, even for manifolds without boundary and for\npunctured spheres. We also describe an algorithm with running time n^{O(g+k)},\nwhere n is the combinatorial complexity, g is the genus, and k is the number of\nboundary components of the input surface. Finally, we describe a greedy\nalgorithm that outputs a O(log^2 g)-approximation of the minimum cut graph in\nO(g^2 n log n) time.",
    "published": "2002-07-02T22:03:51Z",
    "link": "http://arxiv.org/pdf/cs/0207004v1.pdf",
    "category": [
      "cs.CG",
      "cs.DS",
      "cs.GR",
      "F.2.2; I.3.5; G.2.m"
    ],
    "authors": [
      "Jeff Erickson",
      "Sariel Har-Peled"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0210018v1",
    "title": "User software for the next generation",
    "summary": "New generations of neutron scattering sources and instrumentation are\nproviding challenges in data handling for user software. Time-of-Flight\ninstruments used at pulsed sources typically produce hundreds or thousands of\nchannels of data for each detector segment. New instruments are being designed\nwith thousands to hundreds of thousands of detector segments. High intensity\nneutron sources make possible parametric studies and texture studies which\nfurther increase data handling requirements. The Integrated Spectral Analysis\nWorkbench (ISAW) software developed at Argonne handles large numbers of spectra\nsimultaneously while providing operations to reduce, sort, combine and export\nthe data. It includes viewers to inspect the data in detail in real time. ISAW\nuses existing software components and packages where feasible and takes\nadvantage of the excellent support for user interface design and network\ncommunication in Java. The included scripting language simplifies repetitive\noperations for analyzing many files related to a given experiment. Recent\nadditions to ISAW include a contour view, a time-slice table view, routines for\nfinding and fitting peaks in data, and support for data from other facilities\nusing the NeXus format. In this paper, I give an overview of features and\nplanned improvements of ISAW. Details of some of the improvements are covered\nin other presentations at this conference.",
    "published": "2002-10-19T01:27:45Z",
    "link": "http://arxiv.org/pdf/cs/0210018v1.pdf",
    "category": [
      "cs.GR",
      "cs.CE",
      "J2;I3.6;I3.3"
    ],
    "authors": [
      "T. G. Worlton",
      "A. Chatterjee",
      "J. P. Hammonds",
      "P. F. Peterson",
      "D. J. Mikkelson",
      "R. L. Mikkelson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0212007v1",
    "title": "Optimized Color Gamuts for Tiled Displays",
    "summary": "We consider the problem of finding a large color space that can be generated\nby all units in multi-projector tiled display systems. Viewing the problem\ngeometrically as one of finding a large parallelepiped within the intersection\nof multiple parallelepipeds, and using colorimetric principles to define a\nvolume-based objective function for comparing feasible solutions, we develop an\nalgorithm for finding the optimal gamut in time O(n^3), where n denotes the\nnumber of projectors in the system. We also discuss more efficient quasiconvex\nprogramming algorithms for alternative objective functions based on maximizing\nthe quality of the color space extrema.",
    "published": "2002-12-06T21:59:17Z",
    "link": "http://arxiv.org/pdf/cs/0212007v1.pdf",
    "category": [
      "cs.CG",
      "cs.GR",
      "F.2.2"
    ],
    "authors": [
      "Marshall Bern",
      "David Eppstein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0212043v1",
    "title": "Computing Conformal Structure of Surfaces",
    "summary": "This paper solves the problem of computing conformal structures of general\n2-manifolds represented as triangle meshes. We compute conformal structures in\nthe following way: first compute homology bases from simplicial complex\nstructures, then construct dual cohomology bases and diffuse them to harmonic\n1-forms. Next, we construct bases of holomorphic differentials. We then obtain\nperiod matrices by integrating holomorphic differentials along homology bases.\nWe also study the global conformal mapping between genus zero surfaces and\nspheres, and between general meshes and planes. Our method of computing\nconformal structures can be applied to tackle fundamental problems in computer\naid design and computer graphics, such as geometry classification and\nidentification, and surface global parametrization.",
    "published": "2002-12-13T05:33:10Z",
    "link": "http://arxiv.org/pdf/cs/0212043v1.pdf",
    "category": [
      "cs.GR",
      "cs.CG",
      "I.3.5;F.2.2;G.2.m"
    ],
    "authors": [
      "Xianfeng Gu",
      "Shing-Tung Yau"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0301002v1",
    "title": "Practical and Robust Stenciled Shadow Volumes for Hardware-Accelerated\n  Rendering",
    "summary": "Twenty-five years ago, Crow published the shadow volume approach for\ndetermining shadowed regions in a scene. A decade ago, Heidmann described a\nhardware-accelerated stencil buffer-based shadow volume algorithm.\n  Unfortunately hardware-accelerated stenciled shadow volume techniques have\nnot been widely adopted by 3D games and applications due in large part to the\nlack of robustness of described techniques. This situation persists despite\nwidely available hardware support. Specifically what has been lacking is a\ntechnique that robustly handles various \"hard\" situations created by near or\nfar plane clipping of shadow volumes.\n  We describe a robust, artifact-free technique for hardware-accelerated\nrendering of stenciled shadow volumes. Assuming existing hardware, we resolve\nthe issues otherwise caused by shadow volume near and far plane clipping\nthrough a combination of (1) placing the conventional far clip plane \"at\ninfinity\", (2) rasterization with infinite shadow volume polygons via\nhomogeneous coordinates, and (3) adopting a zfail stencil-testing scheme. Depth\nclamping, a new rasterization feature provided by NVIDIA's GeForce3, preserves\nexisting depth precision by not requiring the far plane to be placed at\ninfinity. We also propose two-sided stencil testing to improve the efficiency\nof rendering stenciled shadow volumes.",
    "published": "2003-01-06T20:57:51Z",
    "link": "http://arxiv.org/pdf/cs/0301002v1.pdf",
    "category": [
      "cs.GR",
      "cs.CG",
      "I.3.6; I.3.1"
    ],
    "authors": [
      "Cass Everitt",
      "Mark J. Kilgard"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0302013v1",
    "title": "Cg in Two Pages",
    "summary": "Cg is a language for programming GPUs. This paper describes Cg briefly.",
    "published": "2003-02-12T05:16:12Z",
    "link": "http://arxiv.org/pdf/cs/0302013v1.pdf",
    "category": [
      "cs.GR",
      "cs.PL",
      "I.3.6; C.1.3"
    ],
    "authors": [
      "Mark J. Kilgard"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0304011v1",
    "title": "Embedded Reflection Mapping",
    "summary": "Environment maps are used to simulate reflections off curved objects. We\npresent a technique to reflect a user, or a group of users, in a real\nenvironment, onto a virtual object, in a virtual reality application, using the\nlive video feeds from a set of cameras, in real-time. Our setup can be used in\na variety of environments ranging from outdoor or indoor scenes.",
    "published": "2003-04-08T14:17:53Z",
    "link": "http://arxiv.org/pdf/cs/0304011v1.pdf",
    "category": [
      "cs.GR",
      "I.3.7"
    ],
    "authors": [
      "Paul Anderson",
      "Goncalo Carvalho"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0305057v1",
    "title": "The Persint visualization program for the ATLAS experiment",
    "summary": "The Persint program is designed for the three-dimensional representation of\nobjects and for the interfacing and access to a variety of independent\napplications, in a fully interactive way. Facilities are provided for the\nspatial navigation and the definition of the visualization properties, in order\nto interactively set the viewing and viewed points, and to obtain the desired\nperspective. In parallel, applications may be launched through the use of\ndedicated interfaces, such as the interactive reconstruction and display of\nphysics events. Recent developments have focalized on the interfacing to the\nXML ATLAS General Detector Description AGDD, making it a widely used tool for\nXML developers. The graphics capabilities of this program were exploited in the\ncontext of the ATLAS 2002 Muon Testbeam where it was used as an online event\ndisplay, integrated in the online software framework and participating in the\ncommissioning and debug of the detector system.",
    "published": "2003-05-29T22:06:27Z",
    "link": "http://arxiv.org/pdf/cs/0305057v1.pdf",
    "category": [
      "cs.GR",
      "I.3.0"
    ],
    "authors": [
      "D. Pomarede",
      "M. Virchaux"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0306012v1",
    "title": "GraXML - Modular Geometric Modeler",
    "summary": "Many entities managed by HEP Software Frameworks represent spatial\n(3-dimensional) real objects. Effective definition, manipulation and\nvisualization of such objects is an indispensable functionality.\n  GraXML is a modular Geometric Modeling toolkit capable of processing\ngeometric data of various kinds (detector geometry, event geometry) from\ndifferent sources and delivering them in ways suitable for further use.\nGeometric data are first modeled in one of the Generic Models. Those Models are\nthen used to populate powerful Geometric Model based on the Java3D technology.\nWhile Java3D has been originally created just to provide visualization of 3D\nobjects, its light weight and high functionality allow an effective reuse as a\ngeneral geometric component. This is possible also thanks to a large overlap\nbetween graphical and general geometric functionality and modular design of\nJava3D itself. Its graphical functionalities also allow a natural visualization\nof all manipulated elements.\n  All these techniques have been developed primarily (or only) for the Java\nenvironment. It is, however, possible to interface them transparently to\nFrameworks built in other languages, like for example C++.\n  The GraXML toolkit has been tested with data from several sources, as for\nexample ATLAS and ALICE detector description and ATLAS event data. Prototypes\nfor other sources, like Geometry Description Markup Language (GDML) exist too\nand interface to any other source is easy to add.",
    "published": "2003-06-02T09:04:18Z",
    "link": "http://arxiv.org/pdf/cs/0306012v1.pdf",
    "category": [
      "cs.GR",
      "I.2.10; I.3.7"
    ],
    "authors": [
      "Julius Hrivnac"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0306010v1",
    "title": "On multiple connectedness of regions visible due to multiple diffuse\n  reflections",
    "summary": "It is known that the region $V(s)$ of a simple polygon $P$, directly visible\n(illuminable) from an internal point $s$, is simply connected. Aronov et al.\n\\cite{addpp981} established that the region $V_1(s)$ of a simple polygon\nvisible from an internal point $s$ due to at most one diffuse reflection on the\nboundary of the polygon $P$, is also simply connected. In this paper we\nestablish that the region $V_2(s)$, visible from $s$ due to at most two diffuse\nreflections may be multiply connected; we demonstrate the construction of an\n$n$-sided simple polygon with a point $s$ inside it so that and the region of\n$P$ visible from $s$ after at most two diffuse reflections is multiple\nconnected.",
    "published": "2003-06-02T11:40:37Z",
    "link": "http://arxiv.org/pdf/cs/0306010v1.pdf",
    "category": [
      "cs.CG",
      "cs.DM",
      "cs.GR",
      "F2.2, G2.1"
    ],
    "authors": [
      "Sudebkumar Prasant Pal",
      "Dilip Sarkar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0306031v1",
    "title": "The FRED Event Display: an Extensible HepRep Client for GLAST",
    "summary": "A new graphics client prototype for the HepRep protocol is presented. Based\non modern toolkits and high level languages (C++ and Ruby), Fred is an\nexperiment to test applicability of scripting facilities to the high energy\nphysics event display domain. Its flexible structure, extensibility and the use\nof the HepRep protocol are key features for its use in the astroparticle\nexperiment GLAST.",
    "published": "2003-06-06T12:34:53Z",
    "link": "http://arxiv.org/pdf/cs/0306031v1.pdf",
    "category": [
      "cs.GR",
      "I.3.2,I.3.3,I.3.7"
    ],
    "authors": [
      "Marco Frailis",
      "Riccardo Giannitrapani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0306042v1",
    "title": "IGUANA Architecture, Framework and Toolkit for Interactive Graphics",
    "summary": "IGUANA is a generic interactive visualisation framework based on a C++\ncomponent model. It provides powerful user interface and visualisation\nprimitives in a way that is not tied to any particular physics experiment or\ndetector design. The article describes interactive visualisation tools built\nusing IGUANA for the CMS and D0 experiments, as well as generic GEANT4 and\nGEANT3 applications. It covers features of the graphical user interfaces, 3D\nand 2D graphics, high-quality vector graphics output for print media, various\ntextual, tabular and hierarchical data views, and integration with the\napplication through control panels, a command line and different\nmulti-threading models.",
    "published": "2003-06-10T16:15:41Z",
    "link": "http://arxiv.org/pdf/cs/0306042v1.pdf",
    "category": [
      "cs.SE",
      "cs.GR",
      "D.2.11;I.3.8;J.2"
    ],
    "authors": [
      "George Alverson",
      "Giulio Eulisse",
      "Shahzad Muzaffar",
      "Ianna Osborne",
      "Lassi A. Tuura",
      "Lucas Taylor"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0306059v1",
    "title": "The Use of HepRep in GLAST",
    "summary": "HepRep is a generic, hierarchical format for description of graphics\nrepresentables that can be augmented by physics information and relational\nproperties. It was developed for high energy physics event display applications\nand is especially suited to client/server or component frameworks. The GLAST\nexperiment, an international effort led by NASA for a gamma-ray telescope to\nlaunch in 2006, chose HepRep to provide a flexible, extensible and maintainable\nframework for their event display without tying their users to any one graphics\napplication. To support HepRep in their GUADI infrastructure, GLAST developed a\nHepRep filler and builder architecture. The architecture hides the details of\nXML and CORBA in a set of base and helper classes allowing physics experts to\nfocus on what data they want to represent. GLAST has two GAUDI services:\nHepRepSvc, which registers HepRep fillers in a global registry and allows the\nHepRep to be exported to XML, and CorbaSvc, which allows the HepRep to be\npublished through a CORBA interface and which allows the client application to\nfeed commands back to GAUDI (such as start next event, or run some GAUDI\nalgorithm). GLAST's HepRep solution gives users a choice of client\napplications, WIRED (written in Java) or FRED (written in C++ and Ruby), and\nleaves them free to move to any future HepRep-compliant event display.",
    "published": "2003-06-12T20:37:32Z",
    "link": "http://arxiv.org/pdf/cs/0306059v1.pdf",
    "category": [
      "cs.GR",
      "I.3.2; I.3.4; I.3.6"
    ],
    "authors": [
      "J. Perl",
      "R. Giannitrapani",
      "M. Frailis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0306087v1",
    "title": "OO Model of the STAR offline production \"Event Display\" and its\n  implementation based on Qt-ROOT",
    "summary": "The paper presents the \"Event Display\" package for the STAR offline\nproduction as a special visualization tool to debug the reconstruction code.\nThis can be achieved if an author of the algorithm / code may build his/her own\ncustom Event Display alone from the base software blocks and re-used some\nwell-designed, easy to learn user-friendly patterns. For STAR offline\nproduction Event Display ROOT with Qt lower level interface was chosen as the\nbase tools.",
    "published": "2003-06-14T05:42:43Z",
    "link": "http://arxiv.org/pdf/cs/0306087v1.pdf",
    "category": [
      "cs.HC",
      "cs.GR",
      "I.3.7; D.1.5"
    ],
    "authors": [
      "Valeri Fine",
      "Jerome Lauret",
      "Victor Perevoztchikov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0307065v1",
    "title": "Application of interactive parallel visualization for commodity-based\n  clusters using visualization APIs",
    "summary": "We present an efficient and inexpensive to develop application for\ninteractive high-performance parallel visualization. We extend popular APIs\nsuch as Open Inventor and VTK to support commodity-based cluster visualization.\nOur implementation follows a standard master/slave concept: the general idea is\nto have a ``Master'' node, which will intercept a sequential graphical user\ninterface (GUI) and broadcast it to the ``Slave'' nodes. The interactions\nbetween the nodes are implemented using MPI. The parallel remote rendering uses\nChromium. This paper is mainly the report of our implementation experiences. We\npresent in detail the proposed model and key aspects of its implementation.\nAlso, we present performance measurements, we benchmark and quantitatively\ndemonstrate the dependence of the visualization speed on the data size and the\nnetwork bandwidth, and we identify the singularities and draw conclusions on\nChromium's sort-first rendering architecture. The most original part of this\nwork is the combined use of Open Inventor and Chromium.",
    "published": "2003-07-29T13:40:12Z",
    "link": "http://arxiv.org/pdf/cs/0307065v1.pdf",
    "category": [
      "cs.GR",
      "I.3.6; I.3.4"
    ],
    "authors": [
      "Stanimire Tomov",
      "Robert Bennett",
      "Michael McGuigan",
      "Arnold Peskin",
      "Gordon Smith",
      "John Spiletic"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0310002v2",
    "title": "The Graphics Card as a Streaming Computer",
    "summary": "Massive data sets have radically changed our understanding of how to design\nefficient algorithms; the streaming paradigm, whether it in terms of number of\npasses of an external memory algorithm, or the single pass and limited memory\nof a stream algorithm, appears to be the dominant method for coping with large\ndata.\n  A very different kind of massive computation has had the same effect at the\nlevel of the CPU. The most prominent example is that of the computations\nperformed by a graphics card. The operations themselves are very simple, and\nrequire very little memory, but require the ability to perform many\ncomputations extremely fast and in parallel to whatever degree possible. What\nhas resulted is a stream processor that is highly optimized for stream\ncomputations. An intriguing side effect of this is the growing use of a\ngraphics card as a general purpose stream processing engine. In an\never-increasing array of applications, researchers are discovering that\nperforming a computation on a graphics card is far faster than performing it on\na CPU, and so are using a GPU as a stream co-processor.",
    "published": "2003-10-05T06:30:56Z",
    "link": "http://arxiv.org/pdf/cs/0310002v2.pdf",
    "category": [
      "cs.GR",
      "cs.AR",
      "C.1.2;F.1.1;I.3.1"
    ],
    "authors": [
      "Suresh Venkatasubramanian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0310008v1",
    "title": "Poster on MPI application in Computational Fluid Dynamics",
    "summary": "Poster-presentation of the paper \"Message Passing Fluids: molecules as\nprocesses in parallel computational fluids\" held at \"EURO PVMMPI 2003\"\nCongress; the paper is on the proceedings \"Recent Advances in Parallel Virtual\nMachine and Message Passing Interface\", 10th European PVM/MPI User's Group\nMeeting, LNCS 2840, Springer-Verlag, Dongarra-Laforenza-Orlando editors, pp.\n550-554.",
    "published": "2003-10-06T14:20:00Z",
    "link": "http://arxiv.org/pdf/cs/0310008v1.pdf",
    "category": [
      "cs.DC",
      "cs.GR",
      "D.1.3"
    ],
    "authors": [
      "Gianluca Argentini"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0310017v1",
    "title": "Circle and sphere blending with conformal geometric algebra",
    "summary": "Blending schemes based on circles provide smooth `fair' interpolations\nbetween series of points. Here we demonstrate a simple, robust set of\nalgorithms for performing circle blends for a range of cases. An arbitrary\nlevel of G-continuity can be achieved by simple alterations to the underlying\nparameterisation. Our method exploits the computational framework provided by\nconformal geometric algebra. This employs a five-dimensional representation of\npoints in space, in contrast to the four-dimensional representation typically\nused in projective geometry. The advantage of the conformal scheme is that\nstraight lines and circles are treated in a single, unified framework. As a\nfurther illustration of the power of the conformal framework, the basic idea is\nextended to the case of sphere blending to interpolate over a surface.",
    "published": "2003-10-09T15:15:41Z",
    "link": "http://arxiv.org/pdf/cs/0310017v1.pdf",
    "category": [
      "cs.CG",
      "cs.GR",
      "I.3.5"
    ],
    "authors": [
      "Chris Doran"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0311034v1",
    "title": "Visualization of variations in human brain morphology using\n  differentiating reflection functions",
    "summary": "Conventional visualization media such as MRI prints and computer screens are\ninherently two dimensional, making them incapable of displaying true 3D volume\ndata sets. By applying only transparency or intensity projection, and ignoring\nlight-matter interaction, results will likely fail to give optimal results.\nLittle research has been done on using reflectance functions to visually\nseparate the various segments of a MRI volume. We will explore if applying\nspecific reflectance functions to individual anatomical structures can help in\nbuilding an intuitive 2D image from a 3D dataset. We will test our hypothesis\nby visualizing a statistical analysis of the genetic influences on variations\nin human brain morphology because it inherently contains complex and many\ndifferent types of data making it a good candidate for our approach",
    "published": "2003-11-22T18:17:26Z",
    "link": "http://arxiv.org/pdf/cs/0311034v1.pdf",
    "category": [
      "cs.GR",
      "I.4.7;I.4.8;I.4.10;I.3.7"
    ],
    "authors": [
      "Gibby Koldenhof"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0312006v1",
    "title": "Benchmarking and Implementation of Probability-Based Simulations on\n  Programmable Graphics Cards",
    "summary": "The latest Graphics Processing Units (GPUs) are reported to reach up to\n  200 billion floating point operations per second (200 Gflops) and to have\nprice performance of 0.1 cents per M flop. These facts raise great interest in\nthe plausibility of extending the GPUs' use to non-graphics applications, in\nparticular numerical simulations on structured grids (lattice).\n  We review previous work on using GPUs for non-graphics applications,\nimplement probability-based simulations on the GPU, namely the\n  Ising and percolation models, implement vector operation benchmarks for the\nGPU, and finally compare the CPU's and GPU's performance.\n  A general conclusion from the results obtained is that moving computations\nfrom the CPU to the GPU is feasible, yielding good time and price performance,\nfor certain lattice computations.\n  Preliminary results also show that it is feasible to use them in parallel",
    "published": "2003-12-02T15:47:19Z",
    "link": "http://arxiv.org/pdf/cs/0312006v1.pdf",
    "category": [
      "cs.GR",
      "cs.PF",
      "I.6.3; I.3.1; B.8.2"
    ],
    "authors": [
      "S. Tomov",
      "M. McGuigan",
      "R. Bennett",
      "G. Smith",
      "J. Spiletic"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0401023v1",
    "title": "Surface Triangulation -- The Metric Approach",
    "summary": "We embark in a program of studying the problem of better approximating\nsurfaces by triangulations(triangular meshes) by considering the approximating\ntriangulations as finite metric spaces and the target smooth surface as their\nHaussdorff-Gromov limit. This allows us to define in a more natural way the\nrelevant elements, constants and invariants s.a. principal directions and\nprincipal values, Gaussian and Mean curvature, etc. By a \"natural way\" we mean\nan intrinsic, discrete, metric definitions as opposed to approximating or\nparaphrasing the differentiable notions. In this way we hope to circumvent\ncomputational errors and, indeed, conceptual ones, that are often inherent to\nthe classical, \"numerical\" approach. In this first study we consider the\nproblem of determining the Gaussian curvature of a polyhedral surface, by using\nthe {\\em embedding curvature} in the sense of Wald (and Menger). We present two\nmodalities of employing these definitions for the computation of Gaussian\ncurvature.",
    "published": "2004-01-26T21:51:04Z",
    "link": "http://arxiv.org/pdf/cs/0401023v1.pdf",
    "category": [
      "cs.GR",
      "cs.CG",
      "math.MG",
      "G.1.2; I.4.7"
    ],
    "authors": [
      "Emil Saucan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0404022v1",
    "title": "An Algorithm for Transforming Color Images into Tactile Graphics",
    "summary": "This paper presents an algorithm that transforms color visual images, like\nphotographs or paintings, into tactile graphics. In the algorithm, the edges of\nobjects are detected and colors of the objects are estimated. Then, the edges\nand the colors are encoded into lines and textures in the output tactile image.\nDesign of the method is substantiated by various qualities of haptic\nrecognizing of images. Also, means of presentation of the tactile images in\nprintouts are discussed. Example translated images are shown.",
    "published": "2004-04-08T14:07:05Z",
    "link": "http://arxiv.org/pdf/cs/0404022v1.pdf",
    "category": [
      "cs.GR",
      "I.4.0"
    ],
    "authors": [
      "Artur Rataj"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0405036v1",
    "title": "Single-Strip Triangulation of Manifolds with Arbitrary Topology",
    "summary": "Triangle strips have been widely used for efficient rendering. It is\nNP-complete to test whether a given triangulated model can be represented as a\nsingle triangle strip, so many heuristics have been proposed to partition\nmodels into few long strips. In this paper, we present a new algorithm for\ncreating a single triangle loop or strip from a triangulated model. Our method\napplies a dual graph matching algorithm to partition the mesh into cycles, and\nthen merges pairs of cycles by splitting adjacent triangles when necessary. New\nvertices are introduced at midpoints of edges and the new triangles thus formed\nare coplanar with their parent triangles, hence the visual fidelity of the\ngeometry is not changed. We prove that the increase in the number of triangles\ndue to this splitting is 50% in the worst case, however for all models we\ntested the increase was less than 2%. We also prove tight bounds on the number\nof triangles needed for a single-strip representation of a model with holes on\nits boundary. Our strips can be used not only for efficient rendering, but also\nfor other applications including the generation of space filling curves on a\nmanifold of any arbitrary topology.",
    "published": "2004-05-10T14:31:40Z",
    "link": "http://arxiv.org/pdf/cs/0405036v1.pdf",
    "category": [
      "cs.CG",
      "cs.GR",
      "I.3.5; G.2.2"
    ],
    "authors": [
      "M. Gopi",
      "David Eppstein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0405048v1",
    "title": "Interactive visualization of higher dimensional data in a multiview\n  environment",
    "summary": "We develop multiple view visualization of higher dimensional data. Our work\nwas chiefly motivated by the need to extract insight from four dimensional\nQuantum Chromodynamic (QCD) data. We develop visualization where multiple\nviews, generally views of 3D projections or slices of a higher dimensional\ndata, are tightly coupled not only by their specific order but also by a view\nsynchronizing interaction style, and an internally defined interaction\nlanguage. The tight coupling of the different views allows a fast and\nwell-coordinated exploration of the data. In particular, the visualization\nallowed us to easily make consistency checks of the 4D QCD data and to infer\nthe correctness of particle properties calculations. The software developed was\nalso successfully applied in material studies, in particular studies of\nmeteorite properties. Our implementation uses the VTK API. To handle a large\nnumber of views (slices/projections) and to still maintain good resolution, we\nuse IBM T221 display (3840 X 2400 pixels).",
    "published": "2004-05-14T18:18:04Z",
    "link": "http://arxiv.org/pdf/cs/0405048v1.pdf",
    "category": [
      "cs.GR",
      "I.3.6; I.3.8; H.5.2"
    ],
    "authors": [
      "Stanimire Tomov",
      "Michael McGuigan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0410044v5",
    "title": "An Example of Clifford Algebras Calculations with GiNaC",
    "summary": "This example of Clifford algebras calculations uses GiNaC\n(http://www.ginac.de/) library, which includes a support for generic Clifford\nalgebra starting from version~1.3.0. Both symbolic and numeric calculation are\npossible and can be blended with other functions of GiNaC. This calculations\nwas made for the paper math.CV/0410399.\n  Described features of GiNaC are already available at PyGiNaC\n(http://sourceforge.net/projects/pyginac/) and due to course should propagate\ninto other software like GNU Octave (http://www.octave.org/), gTybalt\n(http://www.fis.unipr.it/~stefanw/gtybalt.html), which use GiNaC library as\ntheir back-end.",
    "published": "2004-10-18T17:39:51Z",
    "link": "http://arxiv.org/pdf/cs/0410044v5.pdf",
    "category": [
      "cs.MS",
      "cs.CG",
      "cs.GR",
      "cs.SC"
    ],
    "authors": [
      "Vladimir V. Kisil"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0503054v1",
    "title": "Analytic Definition of Curves and Surfaces by Parabolic Blending",
    "summary": "A procedure for interpolating between specified points of a curve or surface\nis described. The method guarantees slope continuity at all junctions. A\nsurface panel divided into p x q contiguous patches is completely specified by\nthe coordinates of (p+1) x (q+1) points. Each individual patch, however,\ndepends parametrically on the coordinates of 16 points, allowing shape\nflexibility and global conformity.",
    "published": "2005-03-22T16:59:56Z",
    "link": "http://arxiv.org/pdf/cs/0503054v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "A. W. Overhauser"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0504107v2",
    "title": "k-core decomposition: a tool for the visualization of large scale\n  networks",
    "summary": "We use the k-core decomposition to visualize large scale complex networks in\ntwo dimensions. This decomposition, based on a recursive pruning of the least\nconnected vertices, allows to disentangle the hierarchical structure of\nnetworks by progressively focusing on their central cores. By using this\nstrategy we develop a general visualization algorithm that can be used to\ncompare the structural properties of various networks and highlight their\nhierarchical structure. The low computational complexity of the algorithm,\nO(n+e), where 'n' is the size of the network, and 'e' is the number of edges,\nmakes it suitable for the visualization of very large sparse networks. We apply\nthe proposed visualization tool to several real and synthetic graphs, showing\nits utility in finding specific structural fingerprints of computer generated\nand real world networks.",
    "published": "2005-04-28T13:53:36Z",
    "link": "http://arxiv.org/pdf/cs/0504107v2.pdf",
    "category": [
      "cs.NI",
      "cs.GR"
    ],
    "authors": [
      "Jos Ignacio Alvarez-Hamelin",
      "Luca Dall'Asta",
      "Alain Barrat",
      "Alessandro Vespignani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0505043v2",
    "title": "Estimacao Temporal da Deformacao entre Objectos utilizando uma\n  Metodologia Fisica",
    "summary": "In this paper, it is presented a methodology to estimate the deformation\ninvolved between two objects attending to its physical properties. This\nmethodology can be used, for example, in Computational Vision or Computer\nGraphics applications, and consists in physically modeling the objects, by\nmeans of the Finite Elements Method, establishing correspondences between some\nof its data points, by using Modal Matching, and finally, determining the\ndisplacement field, that is the intermediate shapes, through the resolution of\nthe Lagrange Dynamic Equilibrium Equation. As in many of the possible\napplications of the methodology to present, it is necessary to quantify the\nexisting deformation, as well as to estimate only the non rigid component of\nthe involved global deformation. The solutions adopted to satisfy such\nintentions will be also presented.",
    "published": "2005-05-16T02:20:19Z",
    "link": "http://arxiv.org/pdf/cs/0505043v2.pdf",
    "category": [
      "cs.GR",
      "cs.CG"
    ],
    "authors": [
      "Joao Manuel R. S. Tavares",
      "Raquel R. Pinho"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0507012v1",
    "title": "Lattice Gas Cellular Automata for Computational Fluid Animation",
    "summary": "The past two decades showed a rapid growing of physically-based modeling of\nfluids for computer graphics applications. In this area, a common top down\napproach is to model the fluid dynamics by Navier-Stokes equations and apply a\nnumerical techniques such as Finite Differences or Finite Elements for the\nsimulation. In this paper we focus on fluid modeling through Lattice Gas\nCellular Automata (LGCA) for computer graphics applications. LGCA are discrete\nmodels based on point particles that move on a lattice, according to suitable\nand simple rules in order to mimic a fully molecular dynamics. By\nChapman-Enskog expansion, a known multiscale technique in this area, it can be\ndemonstrated that the Navier-Stokes model can be reproduced by the LGCA\ntechnique. Thus, with LGCA we get a fluid model that does not require solution\nof complicated equations. Therefore, we combine the advantage of the low\ncomputational cost of LGCA and its ability to mimic the realistic fluid\ndynamics to develop a new animating framework for computer graphics\napplications. In this work, we discuss the theoretical elements of our proposal\nand show experimental results.",
    "published": "2005-07-05T19:48:09Z",
    "link": "http://arxiv.org/pdf/cs/0507012v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Gilson A. Giraldi",
      "Adilson V. Xavier",
      "Antonio L. Apolinario Jr",
      "Paulo S. Rodrigues"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0508002v1",
    "title": "Methods for Analytical Understanding of Agent-Based Modeling of Complex\n  Systems",
    "summary": "Von Neuman's work on universal machines and the hardware development have\nallowed the simulation of dynamical systems through a large set of interacting\nagents. This is a bottom-up approach which tries to derive global properties of\na complex system through local interaction rules and agent behaviour.\nTraditionally, such systems are modeled and simulated through top-down methods\nbased on differential equations. Agent-Based Modeling has the advantage of\nsimplicity and low computational cost. However, unlike differential equations,\nthere is no standard way to express agent behaviour. Besides, it is not clear\nhow to analytically predict the results obtained by the simulation. In this\npaper we survey some of these methods. For expressing agent behaviour formal\nmethods, like Stochastic Process Algebras have been used. Such approach is\nuseful if the global properties of interest can be expressed as a function of\nstochastic time series. However, if space variables must be considered, we\nshall change the focus. In this case, multiscale techniques, based on\nChapman-Enskog expansion, was used to establish the connection between the\nmicroscopic dynamics and the macroscopic observables. Also, we use data mining\ntechniques,like Principal Component Analysis (PCA), to study agent systems like\nCellular Automata. With the help of these tools we will discuss a simple\nsociety model, a Lattice Gas Automaton for fluid modeling, and knowledge\ndiscovery in CA databases. Besides, we show the capabilities of the NetLogo, a\nsoftware for agent simulation of complex system and show our experience about.",
    "published": "2005-07-30T12:31:00Z",
    "link": "http://arxiv.org/pdf/cs/0508002v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Gilson A. Giraldi",
      "Luis C. da Costa",
      "Adilson V. Xavier",
      "Paulo S. Rodrigues"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0510087v1",
    "title": "MathPSfrag: Creating Publication-Quality Labels in Mathematica Plots",
    "summary": "This article introduces a Mathematica package providing a graphics export\nfunction that automatically replaces Mathematica expressions in a graphic by\nthe corresponding LaTeX constructs and positions them correctly. It thus\nfacilitates the creation of publication-quality Enscapulated PostScript (EPS)\ngraphics.",
    "published": "2005-10-31T09:40:00Z",
    "link": "http://arxiv.org/pdf/cs/0510087v1.pdf",
    "category": [
      "cs.GR",
      "I.3.4"
    ],
    "authors": [
      "J. Grosse"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0512010v1",
    "title": "A geometry of information, I: Nerves, posets and differential forms",
    "summary": "The main theme of this workshop (Dagstuhl seminar 04351) is `Spatial\nRepresentation: Continuous vs. Discrete'. Spatial representation has two\ncontrasting but interacting aspects (i) representation of spaces' and (ii)\nrepresentation by spaces. In this paper, we will examine two aspects that are\ncommon to both interpretations of the theme, namely nerve constructions and\nrefinement. Representations change, data changes, spaces change. We will\nexamine the possibility of a `differential geometry' of spatial representations\nof both types, and in the sequel give an algebra of differential forms that has\nthe potential to handle the dynamical aspect of such a geometry. We will\ndiscuss briefly a conjectured class of spaces, generalising the Cantor set\nwhich would seem ideal as a test-bed for the set of tools we are developing.",
    "published": "2005-12-02T16:18:11Z",
    "link": "http://arxiv.org/pdf/cs/0512010v1.pdf",
    "category": [
      "cs.AI",
      "cs.GR"
    ],
    "authors": [
      "Jonathan Gratus",
      "Timothy Porter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0512070v2",
    "title": "Incremental and Transitive Discrete Rotations",
    "summary": "A discrete rotation algorithm can be apprehended as a parametric application\n$f\\_\\alpha$ from $\\ZZ[i]$ to $\\ZZ[i]$, whose resulting permutation ``looks\nlike'' the map induced by an Euclidean rotation. For this kind of algorithm, to\nbe incremental means to compute successively all the intermediate rotate d\ncopies of an image for angles in-between 0 and a destination angle. The di\nscretized rotation consists in the composition of an Euclidean rotation with a\ndiscretization; the aim of this article is to describe an algorithm whic h\ncomputes incrementally a discretized rotation. The suggested method uses o nly\ninteger arithmetic and does not compute any sine nor any cosine. More pr\necisely, its design relies on the analysis of the discretized rotation as a\nstep function: the precise description of the discontinuities turns to be th e\nkey ingredient that will make the resulting procedure optimally fast and e\nxact. A complete description of the incremental rotation process is provided,\nalso this result may be useful in the specification of a consistent set of\ndefin itions for discrete geometry.",
    "published": "2005-12-16T16:12:12Z",
    "link": "http://arxiv.org/pdf/cs/0512070v2.pdf",
    "category": [
      "cs.DM",
      "cs.GR"
    ],
    "authors": [
      "Bertrand Nouvel",
      "Eric Remila"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0512098v1",
    "title": "Mathematical models of the complex surfaces in simulation and\n  visualization systems",
    "summary": "Modeling, simulation and visualization of three-dimension complex bodies\nwidely use mathematical model of curves and surfaces. The most important curves\nand surfaces for these purposes are curves and surfaces in Hermite and Bezier\nforms, splines and NURBS. Article is devoted to survey this way to use\ngeometrical data in various computer graphics systems and adjacent fields.",
    "published": "2005-12-26T14:45:32Z",
    "link": "http://arxiv.org/pdf/cs/0512098v1.pdf",
    "category": [
      "cs.GR",
      "cs.CG"
    ],
    "authors": [
      "Dmitry P. Paukov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/quant-ph/0602063v2",
    "title": "Topological Quantum Error Correction with Optimal Encoding Rate",
    "summary": "We prove the existence of topological quantum error correcting codes with\nencoding rates $k/n$ asymptotically approaching the maximum possible value.\nExplicit constructions of these topological codes are presented using surfaces\nof arbitrary genus. We find a class of regular toric codes that are optimal.\nFor physical implementations, we present planar topological codes.",
    "published": "2006-02-06T10:43:50Z",
    "link": "http://arxiv.org/pdf/quant-ph/0602063v2.pdf",
    "category": [
      "quant-ph",
      "cond-mat.str-el",
      "cs.GR",
      "hep-th",
      "math-ph",
      "math.AT",
      "math.CO",
      "math.MP"
    ],
    "authors": [
      "H. Bombin",
      "M. A. Martin-Delgado"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0603115v1",
    "title": "Implementation of float-float operators on graphics hardware",
    "summary": "The Graphic Processing Unit (GPU) has evolved into a powerful and flexible\nprocessor. The latest graphic processors provide fully programmable vertex and\npixel processing units that support vector operations up to single\nfloating-point precision. This computational power is now being used for\ngeneral-purpose computations. However, some applications require higher\nprecision than single precision. This paper describes the emulation of a 44-bit\nfloating-point number format and its corresponding operations. An\nimplementation is presented along with performance and accuracy results.",
    "published": "2006-03-29T11:48:29Z",
    "link": "http://arxiv.org/pdf/cs/0603115v1.pdf",
    "category": [
      "cs.AR",
      "cs.GR"
    ],
    "authors": [
      "Guillaume Da Graca",
      "David Defour"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0603132v1",
    "title": "Graphics Turing Test",
    "summary": "We define a Graphics Turing Test to measure graphics performance in a similar\nmanner to the definition of the traditional Turing Test. To pass the test one\nneeds to reach a computational scale, the Graphics Turing Scale, for which\nComputer Generated Imagery becomes comparatively indistinguishable from real\nimages while also being interactive. We derive an estimate for this\ncomputational scale which, although large, is within reach of todays\nsupercomputers. We consider advantages and disadvantages of various computer\nsystems designed to pass the Graphics Turing Test. Finally we discuss\ncommercial applications from the creation of such a system, in particular\nInteractive Cinema.",
    "published": "2006-03-31T19:58:30Z",
    "link": "http://arxiv.org/pdf/cs/0603132v1.pdf",
    "category": [
      "cs.GR",
      "I.3.7"
    ],
    "authors": [
      "Michael McGuigan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0606007v1",
    "title": "A parent-centered radial layout algorithm for interactive graph\n  visualization and animation",
    "summary": "We have developed (1) a graph visualization system that allows users to\nexplore graphs by viewing them as a succession of spanning trees selected\ninteractively, (2) a radial graph layout algorithm, and (3) an animation\nalgorithm that generates meaningful visualizations and smooth transitions\nbetween graphs while minimizing edge crossings during transitions and in static\nlayouts.\n  Our system is similar to the radial layout system of Yee et al. (2001), but\ndiffers primarily in that each node is positioned on a coordinate system\ncentered on its own parent rather than on a single coordinate system for all\nnodes. Our system is thus easy to define recursively and lends itself to\nparallelization. It also guarantees that layouts have many nice properties,\nsuch as: it guarantees certain edges never cross during an animation.\n  We compared the layouts and transitions produced by our algorithms to those\nproduced by Yee et al. Results from several experiments indicate that our\nsystem produces fewer edge crossings during transitions between graph drawings,\nand that the transitions more often involve changes in local scaling rather\nthan structure.\n  These findings suggest the system has promise as an interactive graph\nexploration tool in a variety of settings.",
    "published": "2006-06-01T16:56:55Z",
    "link": "http://arxiv.org/pdf/cs/0606007v1.pdf",
    "category": [
      "cs.HC",
      "cs.CG",
      "cs.GR",
      "I.3.3; H.5.0"
    ],
    "authors": [
      "Andrew Pavlo",
      "Christopher Homan",
      "Jonathan Schull"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0606055v1",
    "title": "Simple Methods For Drawing Rational Surfaces as Four or Six Bezier\n  Patches",
    "summary": "In this paper, we give several simple methods for drawing a whole rational\nsurface (without base points) as several Bezier patches. The first two methods\napply to surfaces specified by triangular control nets and partition the real\nprojective plane RP2 into four and six triangles respectively. The third method\napplies to surfaces specified by rectangular control nets and partitions the\ntorus RP1 X RP1 into four rectangular regions. In all cases, the new control\nnets are obtained by sign flipping and permutation of indices from the original\ncontrol net. The proofs that these formulae are correct involve very little\ncomputations and instead exploit the geometry of the parameter space (RP2 or\nRP1 X RP1). We illustrate our method on some classical examples. We also\npropose a new method for resolving base points using a simple ``blowing up''\ntechnique involving the computation of ``resolved'' control nets.",
    "published": "2006-06-12T22:02:41Z",
    "link": "http://arxiv.org/pdf/cs/0606055v1.pdf",
    "category": [
      "cs.CG",
      "cs.GR"
    ],
    "authors": [
      "Jean Gallier"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0606056v1",
    "title": "Fast and Simple Methods For Computing Control Points",
    "summary": "The purpose of this paper is to present simple and fast methods for computing\ncontrol points for polynomial curves and polynomial surfaces given explicitly\nin terms of polynomials (written as sums of monomials). We give recurrence\nformulae w.r.t. arbitrary affine frames. As a corollary, it is amusing that we\ncan also give closed-form expressions in the case of the frame (r, s) for\ncurves, and the frame ((1, 0, 0), (0, 1, 0), (0, 0, 1) for surfaces. Our\nmethods have the same low polynomial (time and space) complexity as the other\nbest known algorithms, and are very easy to implement.",
    "published": "2006-06-13T00:47:34Z",
    "link": "http://arxiv.org/pdf/cs/0606056v1.pdf",
    "category": [
      "cs.CC",
      "cs.GR"
    ],
    "authors": [
      "Jean Gallier",
      "Weqing Gu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0606061v1",
    "title": "On the Efficiency of Strategies for Subdividing Polynomial Triangular\n  Surface Patches",
    "summary": "In this paper, we investigate the efficiency of various strategies for\nsubdividing polynomial triangular surface patches. We give a simple algorithm\nperforming a regular subdivision in four calls to the standard de Casteljau\nalgorithm (in its subdivision version). A naive version uses twelve calls. We\nalso show that any method for obtaining a regular subdivision using the\nstandard de Casteljau algorithm requires at least 4 calls. Thus, our method is\noptimal. We give another subdivision algorithm using only three calls to the de\nCasteljau algorithm. Instead of being regular, the subdivision pattern is\ndiamond-like. Finally, we present a ``spider-like'' subdivision scheme\nproducing six subtriangles in four calls to the de Casteljau algorithm.",
    "published": "2006-06-13T15:09:24Z",
    "link": "http://arxiv.org/pdf/cs/0606061v1.pdf",
    "category": [
      "cs.CG",
      "cs.GR"
    ],
    "authors": [
      "Jean Gallier"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0606098v1",
    "title": "Outlier Robust ICP for Minimizing Fractional RMSD",
    "summary": "We describe a variation of the iterative closest point (ICP) algorithm for\naligning two point sets under a set of transformations. Our algorithm is\nsuperior to previous algorithms because (1) in determining the optimal\nalignment, it identifies and discards likely outliers in a statistically robust\nmanner, and (2) it is guaranteed to converge to a locally optimal solution. To\nthis end, we formalize a new distance measure, fractional root mean squared\ndistance (frmsd), which incorporates the fraction of inliers into the distance\nfunction. We lay out a specific implementation, but our framework can easily\nincorporate most techniques and heuristics from modern registration algorithms.\nWe experimentally validate our algorithm against previous techniques on 2 and 3\ndimensional data exposed to a variety of outlier types.",
    "published": "2006-06-22T15:35:56Z",
    "link": "http://arxiv.org/pdf/cs/0606098v1.pdf",
    "category": [
      "cs.GR",
      "cs.CG"
    ],
    "authors": [
      "Jeff M. Phillips",
      "Ran Liu",
      "Carlo Tomasi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0607050v2",
    "title": "Interactive Hatching and Stippling by Example",
    "summary": "We describe a system that lets a designer interactively draw patterns of\nstrokes in the picture plane, then guide the synthesis of similar patterns over\nnew picture regions. Synthesis is based on an initial user-assisted analysis\nphase in which the system recognizes distinct types of strokes (hatching and\nstippling) and organizes them according to perceptual grouping criteria. The\nsynthesized strokes are produced by combining properties (eg. length,\norientation, parallelism, proximity) of the stroke groups extracted from the\ninput examples. We illustrate our technique with a drawing application that\nallows the control of attributes and scale-dependent reproduction of the\nsynthesized patterns.",
    "published": "2006-07-11T19:01:41Z",
    "link": "http://arxiv.org/pdf/cs/0607050v2.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Pascal Barla",
      "Simon Breslav",
      "Lee Markosian",
      "Jolle Thollot"
    ]
  },
  {
    "id": "http://arxiv.org/abs/math/0607597v1",
    "title": "A Vortex Method for Bi-phasic Fluids Interacting with Rigid Bodies",
    "summary": "We present an accurate Lagrangian method based on vortex particles,\nlevel-sets, and immersed boundary methods, for animating the interplay between\ntwo fluids and rigid solids. We show that a vortex method is a good choice for\nsimulating bi-phase flow, such as liquid and gas, with a good level of realism.\nVortex particles are localized at the interfaces between the two fluids and\nwithin the regions of high turbulence. We gain local precision and efficiency\nfrom the stable advection permitted by the vorticity formulation. Moreover, our\nnumerical method straightforwardly solves the two-way coupling problem between\nthe fluids and animated rigid solids. This new approach is validated through\nnumerical comparisons with reference experiments from the computational fluid\ncommunity. We also show that the visually appealing results obtained in the CG\ncommunity can be reproduced with increased efficiency and an easier\nimplementation.",
    "published": "2006-07-24T12:25:59Z",
    "link": "http://arxiv.org/pdf/math/0607597v1.pdf",
    "category": [
      "math.NA",
      "cs.GR",
      "ACM I.3.7 ACM I.3.5"
    ],
    "authors": [
      "Mathieu Coquerelle",
      "Jrmie Allard",
      "Georges-Henri Cottet",
      "Marie-Paule Cani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0608003v2",
    "title": "On a solution to display non-filled-in quaternionic Julia sets",
    "summary": "During early 1980s, the so-called `escape time' method, developed to display\nthe Julia sets for complex dynamical systems, was exported to quaternions in\norder to draw analogous pictures in this wider numerical field. Despite of the\nfine results in the complex plane, where all topological configurations of\nJulia sets have been successfully displayed, the `escape time' method fails to\nrender properly the non-filled-in variety of quaternionic Julia sets. So their\ndigital visualisation remained an open problem for several years. Both the\nsolution for extending this old method to non-filled-in quaternionic Julia sets\nand its implementation into a program are explained here.",
    "published": "2006-08-01T19:25:17Z",
    "link": "http://arxiv.org/pdf/cs/0608003v2.pdf",
    "category": [
      "cs.GR",
      "cs.MS",
      "math.DS"
    ],
    "authors": [
      "Alessandro Rosa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/math/0608789v7",
    "title": "One method for proving inequalities by computer",
    "summary": "In this article we consider a method for proving a class of analytical\ninequalities via minimax rational approximations. All numerical calculations in\nthis paper are given by Maple computer program.",
    "published": "2006-08-31T14:59:20Z",
    "link": "http://arxiv.org/pdf/math/0608789v7.pdf",
    "category": [
      "math.CA",
      "cs.GR",
      "cs.MS",
      "cs.NA",
      "math.GM",
      "math.NA",
      "26Dxx, 33F05, 41A20"
    ],
    "authors": [
      "Branko J. Malesevic"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0609084v1",
    "title": "Non-photorealistic image rendering with a labyrinthine tiling",
    "summary": "The paper describes a new image processing for a non-photorealistic\nrendering. The algorithm is based on a random generation of gray tones and\ncompeting statistical requirements. The gray tone value of each pixel in the\nstarting image is replaced selecting among randomly generated tone values,\naccording to the statistics of nearest-neighbor and next-nearest-neighbor\npixels. Two competing conditions for replacing the tone values - one position\non the local mean value the other on the local variance - produce a peculiar\npattern on the image. This pattern has a labyrinthine tiling aspect. For\ncertain subjects, the pattern enhances the look of the image.",
    "published": "2006-09-15T07:21:11Z",
    "link": "http://arxiv.org/pdf/cs/0609084v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "A. Sparavigna",
      "B. Montrucchio"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0610088v1",
    "title": "Vector field visualization with streamlines",
    "summary": "We have recently developed an algorithm for vector field visualization with\noriented streamlines, able to depict the flow directions everywhere in a dense\nvector field and the sense of the local orientations. The algorithm has useful\napplications in the visualization of the director field in nematic liquid\ncrystals. Here we propose an improvement of the algorithm able to enhance the\nvisualization of the local magnitude of the field. This new approach of the\nalgorithm is compared with the same procedure applied to the Line Integral\nConvolution (LIC) visualization.",
    "published": "2006-10-14T09:25:52Z",
    "link": "http://arxiv.org/pdf/cs/0610088v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "A. Sparavigna",
      "B. Montrucchio"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0702026v1",
    "title": "Shape preservation behavior of spline curves",
    "summary": "Shape preservation behavior of a spline consists of criterial conditions for\npreserving convexity, inflection, collinearity, torsion and coplanarity shapes\nof data polgonal arc. We present our results which acts as an improvement in\nthe definitions of and provide geometrical insight into each of the above shape\npreservation criteria. We also investigate the effect of various results from\nthe literature on various shape preservation criteria. These results have not\nbeen earlier refered in the context of shape preservation behaviour of splines.\nWe point out that each curve segment need to satisfy more than one shape\npreservation criteria. We investigate the conflict between different shape\npreservation criteria 1)on each curve segment and 2)of adjacent curve segments.\nWe derive simplified formula for shape preservation criteria for cubic curve\nsegments. We study the shape preservation behavior of cubic Catmull-Rom splines\nand see that, though being very simple spline curve, it indeed satisfy all the\nshape preservation criteria.",
    "published": "2007-02-05T10:11:58Z",
    "link": "http://arxiv.org/pdf/cs/0702026v1.pdf",
    "category": [
      "cs.GR",
      "I.3.5"
    ],
    "authors": [
      "Ravi Shankar Gautam"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0706.4224v1",
    "title": "User driven applications - new design paradigm",
    "summary": "Programs for complicated engineering and scientific tasks always have to deal\nwith a problem of showing numerous graphical results. The limits of the screen\nspace and often opposite requirements from different users are the cause of the\ninfinite discussions between designers and users, but the source of this\nongoing conflict is not in the level of interface design, but in the basic\nprinciple of current graphical output: user may change some views and details,\nbut in general the output view is absolutely defined and fixed by the\ndeveloper. Author was working for several years on the algorithm that will\nallow eliminating this problem thus allowing stepping from designer-driven\napplications to user-driven. Such type of applications in which user is\ndeciding what, when and how to show on the screen, is the dream of scientists\nand engineers working on the analysis of the most complicated tasks. The new\nparadigm is based on movable and resizable graphics, and such type of graphics\ncan be widely used not only for scientific and engineering applications.",
    "published": "2007-06-28T13:19:04Z",
    "link": "http://arxiv.org/pdf/0706.4224v1.pdf",
    "category": [
      "cs.GR",
      "cs.HC"
    ],
    "authors": [
      "Sergey Andreyev"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.1618v1",
    "title": "The Trade-offs with Space Time Cube Representation of Spatiotemporal\n  Patterns",
    "summary": "Space time cube representation is an information visualization technique\nwhere spatiotemporal data points are mapped into a cube. Fast and correct\nanalysis of such information is important in for instance geospatial and social\nvisualization applications. Information visualization researchers have\npreviously argued that space time cube representation is beneficial in\nrevealing complex spatiotemporal patterns in a dataset to users. The argument\nis based on the fact that both time and spatial information are displayed\nsimultaneously to users, an effect difficult to achieve in other\nrepresentations. However, to our knowledge the actual usefulness of space time\ncube representation in conveying complex spatiotemporal patterns to users has\nnot been empirically validated. To fill this gap we report on a\nbetween-subjects experiment comparing novice users error rates and response\ntimes when answering a set of questions using either space time cube or a\nbaseline 2D representation. For some simple questions the error rates were\nlower when using the baseline representation. For complex questions where the\nparticipants needed an overall understanding of the spatiotemporal structure of\nthe dataset, the space time cube representation resulted in on average twice as\nfast response times with no difference in error rates compared to the baseline.\nThese results provide an empirical foundation for the hypothesis that space\ntime cube representation benefits users when analyzing complex spatiotemporal\npatterns.",
    "published": "2007-07-11T13:39:34Z",
    "link": "http://arxiv.org/pdf/0707.1618v1.pdf",
    "category": [
      "cs.HC",
      "cs.GR"
    ],
    "authors": [
      "Per Ola Kristensson",
      "Nils Dahlback",
      "Daniel Anundi",
      "Marius Bjornstad",
      "Hanna Gillberg",
      "Jonas Haraldsson",
      "Ingrid Martensson",
      "Matttias Nordvall",
      "Josefin Stahl"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0708.0660v1",
    "title": "Network synchronizability analysis: the theory of subgraphs and\n  complementary graphs",
    "summary": "In this paper, subgraphs and complementary graphs are used to analyze the\nnetwork synchronizability. Some sharp and attainable bounds are provided for\nthe eigenratio of the network structural matrix, which characterizes the\nnetwork synchronizability, especially when the network's corresponding graph\nhas cycles, chains, bipartite graphs or product graphs as its subgraphs.",
    "published": "2007-08-05T05:25:45Z",
    "link": "http://arxiv.org/pdf/0708.0660v1.pdf",
    "category": [
      "cs.NI",
      "cs.GR"
    ],
    "authors": [
      "Zhisheng Duan",
      "Chao Liu",
      "Guanrong Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0708.0712v1",
    "title": "Virtual Environments for Training: From Individual Learning to\n  Collaboration with Humanoids",
    "summary": "The next generation of virtual environments for training is oriented towards\ncollaborative aspects. Therefore, we have decided to enhance our platform for\nvirtual training environments, adding collaboration opportunities and\nintegrating humanoids. In this paper we put forward a model of humanoid that\nsuits both virtual humans and representations of real users, according to\ncollaborative training activities. We suggest adaptations to the scenario model\nof our platform making it possible to write collaborative procedures. We\nintroduce a mechanism of action selection made up of a global repartition and\nan individual choice. These models are currently being integrated and validated\nin GVT, a virtual training tool for maintenance of military equipments,\ndeveloped in collaboration with the French company NEXTER-Group.",
    "published": "2007-08-06T07:42:56Z",
    "link": "http://arxiv.org/pdf/0708.0712v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Stphanie Gerbaud",
      "Nicolas Mollet",
      "Bruno Arnaldi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0709.0674v1",
    "title": "Simple Algorithmic Principles of Discovery, Subjective Beauty, Selective\n  Attention, Curiosity & Creativity",
    "summary": "I postulate that human or other intelligent agents function or should\nfunction as follows. They store all sensory observations as they come - the\ndata is holy. At any time, given some agent's current coding capabilities, part\nof the data is compressible by a short and hopefully fast program / description\n/ explanation / world model. In the agent's subjective eyes, such data is more\nregular and more \"beautiful\" than other data. It is well-known that knowledge\nof regularity and repeatability may improve the agent's ability to plan actions\nleading to external rewards. In absence of such rewards, however, known beauty\nis boring. Then \"interestingness\" becomes the first derivative of subjective\nbeauty: as the learning agent improves its compression algorithm, formerly\napparently random data parts become subjectively more regular and beautiful.\nSuch progress in compressibility is measured and maximized by the curiosity\ndrive: create action sequences that extend the observation history and yield\npreviously unknown / unpredictable but quickly learnable algorithmic\nregularity. We discuss how all of the above can be naturally implemented on\ncomputers, through an extension of passive unsupervised learning to the case of\nactive data selection: we reward a general reinforcement learner (with access\nto the adaptive compressor) for actions that improve the subjective\ncompressibility of the growing data. An unusually large breakthrough in\ncompressibility deserves the name \"discovery\". The \"creativity\" of artists,\ndancers, musicians, pure mathematicians can be viewed as a by-product of this\nprinciple. Several qualitative examples support this hypothesis.",
    "published": "2007-09-05T15:20:59Z",
    "link": "http://arxiv.org/pdf/0709.0674v1.pdf",
    "category": [
      "cs.AI",
      "cs.GR",
      "I.2.0"
    ],
    "authors": [
      "Juergen Schmidhuber"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0709.3553v1",
    "title": "Design of moveable and resizable graphics",
    "summary": "We are communicating with computers on two different levels. On upper level\nwe have a very flexible system of windows: we can move them, resize, overlap or\nput side by side. At any moment we decide what would be the best view and\nreorganize the whole view easily. Then we start any application, go to the\ninner level, and everything changes. Here we are stripped of all the\nflexibility and can work only inside the scenario, developed by the designer of\nthe program. Interface will allow us to change some tiny details, but in\ngeneral everything is fixed: graphics is neither moveable, nor resizable, and\nthe same with controls. Author designed an extremely powerful mechanism of\nturning graphical objects and controls into moveable and resizable. This can\nnot only significantly improve the existing applications, but this will bring\nthe applications to another level. (To estimate the possible difference, try to\nimagine the Windows system without its flexibility and compare it with the\ncurrent one.) This article explains in details the construction and use of\nmoveable and resizable graphical objects.",
    "published": "2007-09-22T00:21:08Z",
    "link": "http://arxiv.org/pdf/0709.3553v1.pdf",
    "category": [
      "cs.GR",
      "cs.HC"
    ],
    "authors": [
      "Sergey Andreyev"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0712.0121v1",
    "title": "Efficient Binary and Run Length Morphology and its Application to\n  Document Image Processing",
    "summary": "This paper describes the implementation and evaluation of an open source\nlibrary for mathematical morphology based on packed binary and run-length\ncompressed images for document imaging applications. Abstractions and patterns\nuseful in the implementation of the interval operations are described. A number\nof benchmarks and comparisons to bit-blit based implementations on standard\ndocument images are provided.",
    "published": "2007-12-02T07:25:59Z",
    "link": "http://arxiv.org/pdf/0712.0121v1.pdf",
    "category": [
      "cs.GR",
      "I.4; I.4.10; I.7.4; I.7.5"
    ],
    "authors": [
      "Thomas M. Breuel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0712.1549v1",
    "title": "Dynamic Multilevel Graph Visualization",
    "summary": "We adapt multilevel, force-directed graph layout techniques to visualizing\ndynamic graphs in which vertices and edges are added and removed in an online\nfashion (i.e., unpredictably). We maintain multiple levels of coarseness using\na dynamic, randomized coarsening algorithm. To ensure the vertices follow\nsmooth trajectories, we employ dynamics simulation techniques, treating the\nvertices as point particles. We simulate fine and coarse levels of the graph\nsimultaneously, coupling the dynamics of adjacent levels. Projection from\ncoarser to finer levels is adaptive, with the projection determined by an\naffine transformation that evolves alongside the graph layouts. The result is a\ndynamic graph visualizer that quickly and smoothly adapts to changes in a\ngraph.",
    "published": "2007-12-10T17:42:48Z",
    "link": "http://arxiv.org/pdf/0712.1549v1.pdf",
    "category": [
      "cs.GR",
      "cs.DM",
      "H.5.0; G.2.2"
    ],
    "authors": [
      "Todd L. Veldhuizen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0801.1500v1",
    "title": "Toward the Graphics Turing Scale on a Blue Gene Supercomputer",
    "summary": "We investigate raytracing performance that can be achieved on a class of Blue\nGene supercomputers. We measure a 822 times speedup over a Pentium IV on a 6144\nprocessor Blue Gene/L. We measure the computational performance as a function\nof number of processors and problem size to determine the scaling performance\nof the raytracing calculation on the Blue Gene. We find nontrivial scaling\nbehavior at large number of processors. We discuss applications of this\ntechnology to scientific visualization with advanced lighting and high\nresolution. We utilize three racks of a Blue Gene/L in our calculations which\nis less than three percent of the the capacity of the worlds largest Blue Gene\ncomputer.",
    "published": "2008-01-09T20:51:02Z",
    "link": "http://arxiv.org/pdf/0801.1500v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Michael McGuigan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0801.2175v1",
    "title": "MathPSfrag 2: Convenient LaTeX Labels in Mathematica",
    "summary": "This article introduces the next version of MathPSfrag. MathPSfrag is a\nMathematica package that during export automatically replaces all expressions\nin a plot by corresponding LaTeX commands. The new version can also produce\nLaTeX independent images; e.g., PDF files for inclusion in pdfLaTeX. Moreover\nfrom these files a preview is generated and shown within Mathematica.",
    "published": "2008-01-15T18:34:44Z",
    "link": "http://arxiv.org/pdf/0801.2175v1.pdf",
    "category": [
      "cs.GR",
      "I.3.4"
    ],
    "authors": [
      "Johannes Groe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0801.2405v2",
    "title": "Multiple Uncertainties in Time-Variant Cosmological Particle Data",
    "summary": "Though the mediums for visualization are limited, the potential dimensions of\na dataset are not. In many areas of scientific study, understanding the\ncorrelations between those dimensions and their uncertainties is pivotal to\nmining useful information from a dataset. Obtaining this insight can\nnecessitate visualizing the many relationships among temporal, spatial, and\nother dimensionalities of data and its uncertainties. We utilize multiple views\nfor interactive dataset exploration and selection of important features, and we\napply those techniques to the unique challenges of cosmological particle\ndatasets. We show how interactivity and incorporation of multiple visualization\ntechniques help overcome the problem of limited visualization dimensions and\nallow many types of uncertainty to be seen in correlation with other variables.",
    "published": "2008-01-15T22:57:41Z",
    "link": "http://arxiv.org/pdf/0801.2405v2.pdf",
    "category": [
      "astro-ph",
      "cs.GR",
      "cs.HC"
    ],
    "authors": [
      "Steve Haroz",
      "Kwan-Liu Ma",
      "Katrin Heitmann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0801.3249v1",
    "title": "Complex Eigenvalues for Binary Subdivision Schemes",
    "summary": "Convergence properties of binary stationary subdivision schemes for curves\nhave been analyzed using the techniques of z-transforms and eigenanalysis.\nEigenanalysis provides a way to determine derivative continuity at specific\npoints based on the eigenvalues of a finite matrix. None of the well-known\nsubdivision schemes for curves have complex eigenvalues. We prove when a\nconvergent scheme with palindromic mask can have complex eigenvalues and that a\nlower limit for the size of the mask exists in this case. We find a scheme with\ncomplex eigenvalues achieving this lower bound. Furthermore we investigate this\nscheme numerically and explain from a geometric viewpoint why such a scheme has\nnot yet been used in computer-aided geometric design.",
    "published": "2008-01-21T18:27:09Z",
    "link": "http://arxiv.org/pdf/0801.3249v1.pdf",
    "category": [
      "cs.GR",
      "cs.NA",
      "I.3.5"
    ],
    "authors": [
      "Christian Kuehn"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0802.1617v1",
    "title": "Discrete Complex Structure on Surfel Surfaces",
    "summary": "This paper defines a theory of conformal parametrization of digital surfaces\nmade of surfels equipped with a normal vector. The main idea is to locally\nproject each surfel to the tangent plane, therefore deforming its aspect-ratio.\nIt is a generalization of the theory known for polyhedral surfaces. The main\ndifference is that the conformal ratios that appear are no longer real in\ngeneral. It yields a generalization of the standard Laplacian on weighted\ngraphs.",
    "published": "2008-02-12T11:06:38Z",
    "link": "http://arxiv.org/pdf/0802.1617v1.pdf",
    "category": [
      "cs.CG",
      "cs.GR",
      "math.CV"
    ],
    "authors": [
      "Christian Mercat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0802.3355v1",
    "title": "PVM-Distributed Implementation of the Radiance Code",
    "summary": "The Parallel Virtual Machine (PVM) tool has been used for a distributed\nimplementation of Greg Ward's Radiance code. In order to generate exactly the\nsame primary rays with both the sequential and the parallel codes, the quincunx\nsampling technique used in Radiance for the reduction of the number of primary\nrays by interpolation, must be left untouched in the parallel implementation.\nThe octree of local ambient values used in Radiance for the indirect\nillumination has been shared among all the processors. Both static and dynamic\nimage partitioning techniques which replicate the octree of the complete scene\nin all the processors and have load-balancing, have been developed for one\nframe rendering. Speedups larger than 7.5 have been achieved in a network of 8\nworkstations. For animation sequences, a new dynamic partitioning distribution\ntechnique with superlinear speedups has also been developed.",
    "published": "2008-02-22T17:32:17Z",
    "link": "http://arxiv.org/pdf/0802.3355v1.pdf",
    "category": [
      "cs.DC",
      "cs.GR"
    ],
    "authors": [
      "Francisco R. Villatoro",
      "Antonio J. Nebro",
      "Jose E. Fernndez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.0561v1",
    "title": "Realistic Haptic Rendering of Interacting Deformable Objects in Virtual\n  Environments",
    "summary": "A new computer haptics algorithm to be used in general interactive\nmanipulations of deformable virtual objects is presented. In multimodal\ninteractive simulations, haptic feedback computation often comes from contact\nforces. Subsequently, the fidelity of haptic rendering depends significantly on\ncontact space modeling. Contact and friction laws between deformable models are\noften simplified in up to date methods. They do not allow a \"realistic\"\nrendering of the subtleties of contact space physical phenomena (such as slip\nand stick effects due to friction or mechanical coupling between contacts). In\nthis paper, we use Signorini's contact law and Coulomb's friction law as a\ncomputer haptics basis. Real-time performance is made possible thanks to a\nlinearization of the behavior in the contact space, formulated as the so-called\nDelassus operator, and iteratively solved by a Gauss-Seidel type algorithm.\nDynamic deformation uses corotational global formulation to obtain the Delassus\noperator in which the mass and stiffness ratio are dissociated from the\nsimulation time step. This last point is crucial to keep stable haptic\nfeedback. This global approach has been packaged, implemented, and tested.\nStable and realistic 6D haptic feedback is demonstrated through a clipping task\nexperiment.",
    "published": "2008-04-03T13:49:51Z",
    "link": "http://arxiv.org/pdf/0804.0561v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Christian Duriez",
      "Frdric Dubois",
      "Abderrahmane Kheddar",
      "Claude Andriot"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.3103v1",
    "title": "Size matters: performance declines if your pixels are too big or too\n  small",
    "summary": "We present a conceptual model that describes the effect of pixel size on\ntarget acquisition. We demonstrate the use of our conceptual model by applying\nit to predict and explain the results of an experiment to evaluate users'\nperformance in a target acquisition task involving three distinct display\nsizes: standard desktop, small and large displays. The results indicate that\nusers are fastest on standard desktop displays, undershoots are the most common\nerror on small displays and overshoots are the most common error on large\ndisplays. We propose heuristics to maintain usability when changing displays.\nFinally, we contribute to the growing body of evidence that amplitude does\naffect performance in a display-based pointing task.",
    "published": "2008-04-18T21:02:19Z",
    "link": "http://arxiv.org/pdf/0804.3103v1.pdf",
    "category": [
      "cs.GR",
      "cs.HC"
    ],
    "authors": [
      "Vassilis Kostakos",
      "Eamonn O'Neill"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0805.0162v2",
    "title": "Morphing of Triangular Meshes in Shape Space",
    "summary": "We present a novel approach to morph between two isometric poses of the same\nnon-rigid object given as triangular meshes. We model the morphs as linear\ninterpolations in a suitable shape space $\\mathcal{S}$. For triangulated 3D\npolygons, we prove that interpolating linearly in this shape space corresponds\nto the most isometric morph in $\\mathbb{R}^3$. We then extend this shape space\nto arbitrary triangulations in 3D using a heuristic approach and show the\npractical use of the approach using experiments. Furthermore, we discuss a\nmodified shape space that is useful for isometric skeleton morphing. All of the\nnewly presented approaches solve the morphing problem without the need to solve\na minimization problem.",
    "published": "2008-05-01T23:08:30Z",
    "link": "http://arxiv.org/pdf/0805.0162v2.pdf",
    "category": [
      "cs.CG",
      "cs.GR"
    ],
    "authors": [
      "Stefanie Wuhrer",
      "Prosenjit Bose",
      "Chang Shu",
      "Joseph O'Rourke",
      "Alan Brunton"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0806.2925v2",
    "title": "Neural networks in 3D medical scan visualization",
    "summary": "For medical volume visualization, one of the most important tasks is to\nreveal clinically relevant details from the 3D scan (CT, MRI ...), e.g. the\ncoronary arteries, without obscuring them with less significant parts. These\nvolume datasets contain different materials which are difficult to extract and\nvisualize with 1D transfer functions based solely on the attenuation\ncoefficient. Multi-dimensional transfer functions allow a much more precise\nclassification of data which makes it easier to separate different surfaces\nfrom each other. Unfortunately, setting up multi-dimensional transfer functions\ncan become a fairly complex task, generally accomplished by trial and error.\nThis paper explains neural networks, and then presents an efficient way to\nspeed up visualization process by semi-automatic transfer function generation.\nWe describe how to use neural networks to detect distinctive features shown in\nthe 2D histogram of the volume data and how to use this information for data\nclassification.",
    "published": "2008-06-18T08:36:15Z",
    "link": "http://arxiv.org/pdf/0806.2925v2.pdf",
    "category": [
      "cs.AI",
      "cs.GR",
      "I.3; I.2.6"
    ],
    "authors": [
      "Denan Zuki",
      "Andreas Elsner",
      "Zikrija Avdagi",
      "Gitta Domik"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0807.1667v1",
    "title": "Quasi-Mandelbrot sets for perturbed complex analytic maps: visual\n  patterns",
    "summary": "We consider perturbations of the complex quadratic map $ z \\to z^2 +c$ and\ncorresponding changes in their quasi-Mandelbrot sets. Depending on particular\nperturbation, visual forms of quasi-Mandelbrot set changes either sharply (when\nthe perturbation reaches some critical value) or continuously. In the latter\ncase we have a smooth transition from the classical form of the set to some\nforms, constructed from mostly linear structures, as it is typical for\ntwo-dimensional real number dynamics. Two examples of continuous evolution of\nthe quasi-Mandelbrot set are described.",
    "published": "2008-07-10T14:40:35Z",
    "link": "http://arxiv.org/pdf/0807.1667v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "A. V. Toporensky"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0809.0884v1",
    "title": "On the role of metaphor in information visualization",
    "summary": "The concept of metaphor, in particular graphical (or visual) metaphor, is\ncentral to the field of information visualization. Information graphics and\ninteractive information visualization systems employ a variety of metaphorical\ndevices to make abstract, complex, voluminous, or otherwise\ndifficult-to-comprehend information understandable in graphical terms. This\npaper explores the use of metaphor in information visualization, advancing the\ntheory previously argued by Johnson, Lakoff, Tversky et al. that many\ninformation graphics are metaphorically understood in terms of cognitively\nentrenched spatial patterns known as image schemas. These patterns serve to\nstructure and constrain abstract reasoning processes via metaphorical\nprojection operations that are grounded in everyday perceptual experiences with\nphenomena such as containment, movement, and force dynamics. Building on\nprevious research, I argue that information graphics promote comprehension of\ntheir target information through the use of graphical patterns that invoke\nthese preexisting schematic structures. I further theorize that the degree of\nstructural alignment of a particular graphic with one or more corresponding\nimage schemas accounts for its perceived degree of intuitiveness. Accordingly,\nimage schema theory can provide a powerful explanatory and predictive framework\nfor visualization research. I review relevant theories of analogy and metaphor,\nand discuss the image schematic properties of several common types of\ninformation graphic. I conclude with the proposal that the inventory of image\nschemas culled from linguistic studies can serve as the basis for an inventory\nof design elements suitable for developing intuitive and effective new\ninformation visualization techniques.",
    "published": "2008-09-04T19:55:40Z",
    "link": "http://arxiv.org/pdf/0809.0884v1.pdf",
    "category": [
      "cs.HC",
      "cs.GR"
    ],
    "authors": [
      "John S. Risch"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0809.4093v2",
    "title": "Perspective Drawing of Surfaces with Line Hidden Line Elimination,\n  Dibujando Superficies En Perspectiva Con Eliminacion De Lineas Ocultas",
    "summary": "An efficient computer algorithm is described for the perspective drawing of a\nwide class of surfaces. The class includes surfaces corresponding lo\nsingle-valued, continuous functions which are defined over rectangular domains.\nThe algorithm automatically computes and eliminates hidden lines. The number of\ncomputations in the algorithm grows linearly with the number of sample points\non the surface to be drawn. An analysis of the algorithm is presented, and\nextensions lo certain multi-valued functions are indicated. The algorithm is\nimplemented and tested on .Net 2.0 platform that left interactive use. Running\ntimes are found lo be exceedingly efficient for visualization, where\ninteraction on-line and view-point control, enables effective and rapid\nexamination of a surfaces from many perspectives.",
    "published": "2008-09-24T05:50:56Z",
    "link": "http://arxiv.org/pdf/0809.4093v2.pdf",
    "category": [
      "cs.GR",
      "cs.CG"
    ],
    "authors": [
      "Ignacio Vega-Paez",
      "Jose Angel Ortega",
      "Georgina G. Pulido"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0810.2021v1",
    "title": "Visualization Optimization : Application to the RoboCup Rescue Domain",
    "summary": "In this paper we demonstrate the use of intelligent optimization\nmethodologies on the visualization optimization of virtual / simulated\nenvironments. The problem of automatic selection of an optimized set of views,\nwhich better describes an on-going simulation over a virtual environment is\naddressed in the context of the RoboCup Rescue Simulation domain. A generic\narchitecture for optimization is proposed and described. We outline the\npossible extensions of this architecture and argue on how several problems\nwithin the fields of Interactive Rendering and Visualization can benefit from\nit.",
    "published": "2008-10-13T12:53:57Z",
    "link": "http://arxiv.org/pdf/0810.2021v1.pdf",
    "category": [
      "cs.GR",
      "cs.AI",
      "I.3.7; I.2.8"
    ],
    "authors": [
      "Pedro Miguel Moreira",
      "Lus Paulo Reis",
      "Antnio Augusto de Sousa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0810.4201v2",
    "title": "Interchanging Interactive 3-d Graphics for Astronomy",
    "summary": "We demonstrate how interactive, three-dimensional (3-d) scientific\nvisualizations can be efficiently interchanged between a variety of mediums.\nThrough the use of an appropriate interchange format, and a unified interaction\ninterface, we minimize the effort to produce visualizations appropriate for\nundertaking knowledge discovery at the astronomer's desktop, as part of\nconference presentations, in digital publications or as Web content. We use\nexamples from cosmological visualization to address some of the issues of\ninterchange, and to describe our approach to adapting S2PLOT desktop\nvisualizations to the Web.\n  Supporting demonstrations are available at\nhttp://astronomy.swin.edu.au/s2plot/interchange/",
    "published": "2008-10-23T02:58:55Z",
    "link": "http://arxiv.org/pdf/0810.4201v2.pdf",
    "category": [
      "astro-ph",
      "cs.GR"
    ],
    "authors": [
      "C. J. Fluke",
      "D. G. Barnes",
      "N. T. Jones"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0811.2055v2",
    "title": "GPU-Based Interactive Visualization of Billion Point Cosmological\n  Simulations",
    "summary": "Despite the recent advances in graphics hardware capabilities, a brute force\napproach is incapable of interactively displaying terabytes of data. We have\nimplemented a system that uses hierarchical level-of-detailing for the results\nof cosmological simulations, in order to display visually accurate results\nwithout loading in the full dataset (containing over 10 billion points). The\nguiding principle of the program is that the user should not be able to\ndistinguish what they are seeing from a full rendering of the original data.\nFurthermore, by using a tree-based system for levels of detail, the size of the\nunderlying data is limited only by the capacity of the IO system containing it.",
    "published": "2008-11-13T09:34:42Z",
    "link": "http://arxiv.org/pdf/0811.2055v2.pdf",
    "category": [
      "cs.GR",
      "astro-ph"
    ],
    "authors": [
      "Tamas Szalay",
      "Volker Springel",
      "Gerard Lemson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0811.4121v1",
    "title": "String Art: Circle Drawing Using Straight Lines",
    "summary": "An algorithm to generate the locus of a circle using the intersection points\nof straight lines is proposed. The pixels on the circle are plotted independent\nof one another and the operations involved in finding the locus of the circle\nfrom the intersection of straight lines are parallelizable. Integer only\narithmetic and algorithmic optimizations are used for speedup. The proposed\nalgorithm makes use of an envelope to form a parabolic arc which is consequent\ntransformed into a circle. The use of parabolic arcs for the transformation\nresults in higher pixel errors as the radius of the circle to be drawn\nincreases. At its current state, the algorithm presented may be suitable only\nfor generating circles for string art.",
    "published": "2008-11-25T17:12:22Z",
    "link": "http://arxiv.org/pdf/0811.4121v1.pdf",
    "category": [
      "cs.GR",
      "cs.OH",
      "I.3.3"
    ],
    "authors": [
      "Sankar K",
      "Sarad AV"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0812.0754v2",
    "title": "Strong Spatial Mixing and Approximating Partition Functions of Two-State\n  Spin Systems without Hard Constrains",
    "summary": "We prove Gibbs distribution of two-state spin systems(also known as binary\nMarkov random fields) without hard constrains on a tree exhibits strong spatial\nmixing(also known as strong correlation decay), under the assumption that, for\narbitrary `external field', the absolute value of `inverse temperature' is\nsmall, or the `external field' is uniformly large or small. The first condition\non `inverse temperature' is tight if the distribution is restricted to\nferromagnetic or antiferromagnetic Ising models.\n  Thanks to Weitz's self-avoiding tree, we extends the result for sparse on\naverage graphs, which generalizes part of the recent work of Mossel and\nSly\\cite{MS08}, who proved the strong spatial mixing property for ferromagnetic\nIsing model. Our proof yields a different approach, carefully exploiting the\nmonotonicity of local recursion. To our best knowledge, the second condition of\n`external field' for strong spatial mixing in this paper is first considered\nand stated in term of `maximum average degree' and `interaction energy'. As an\napplication, we present an FPTAS for partition functions of two-state spin\nmodels without hard constrains under the above assumptions in a general family\nof graphs including interesting bounded degree graphs.",
    "published": "2008-12-03T16:56:53Z",
    "link": "http://arxiv.org/pdf/0812.0754v2.pdf",
    "category": [
      "cs.DM",
      "cs.GR",
      "F.2.0"
    ],
    "authors": [
      "Jinshan Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0812.0893v2",
    "title": "Linear-Time Algorithms for Geometric Graphs with Sublinearly Many Edge\n  Crossings",
    "summary": "We provide linear-time algorithms for geometric graphs with sublinearly many\ncrossings. That is, we provide algorithms running in O(n) time on connected\ngeometric graphs having n vertices and k crossings, where k is smaller than n\nby an iterated logarithmic factor. Specific problems we study include Voronoi\ndiagrams and single-source shortest paths. Our algorithms all run in linear\ntime in the standard comparison-based computational model; hence, we make no\nassumptions about the distribution or bit complexities of edge weights, nor do\nwe utilize unusual bit-level operations on memory words. Instead, our\nalgorithms are based on a planarization method that \"zeroes in\" on edge\ncrossings, together with methods for extending planar separator decompositions\nto geometric graphs with sublinearly many crossings. Incidentally, our\nplanarization algorithm also solves an open computational geometry problem of\nChazelle for triangulating a self-intersecting polygonal chain having n\nsegments and k crossings in linear time, for the case when k is sublinear in n\nby an iterated logarithmic factor.",
    "published": "2008-12-04T10:29:00Z",
    "link": "http://arxiv.org/pdf/0812.0893v2.pdf",
    "category": [
      "cs.CG",
      "cs.DM",
      "cs.DS",
      "cs.GR",
      "F.2.2; G.2.2; G.3"
    ],
    "authors": [
      "David Eppstein",
      "Michael T. Goodrich",
      "Darren Strash"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0812.1119v1",
    "title": "An analysis of a random algorithm for estimating all the matchings",
    "summary": "Counting the number of all the matchings on a bipartite graph has been\ntransformed into calculating the permanent of a matrix obtained from the\nextended bipartite graph by Yan Huo, and Rasmussen presents a simple approach\n(RM) to approximate the permanent, which just yields a critical ratio\nO($n\\omega(n)$) for almost all the 0-1 matrices, provided it's a simple\npromising practical way to compute this #P-complete problem. In this paper, the\nperformance of this method will be shown when it's applied to compute all the\nmatchings based on that transformation. The critical ratio will be proved to be\nvery large with a certain probability, owning an increasing factor larger than\nany polynomial of $n$ even in the sense for almost all the 0-1 matrices. Hence,\nRM fails to work well when counting all the matchings via computing the\npermanent of the matrix. In other words, we must carefully utilize the known\nmethods of estimating the permanent to count all the matchings through that\ntransformation.",
    "published": "2008-12-05T12:16:53Z",
    "link": "http://arxiv.org/pdf/0812.1119v1.pdf",
    "category": [
      "cs.GR",
      "cs.AI",
      "F.2.0"
    ],
    "authors": [
      "Jinshan Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0812.1647v1",
    "title": "Polyomino-Based Digital Halftoning",
    "summary": "In this work, we present a new method for generating a threshold structure.\nThis kind of structure can be advantageously used in various halftoning\nalgorithms such as clustered-dot or dispersed-dot dithering, error diffusion\nwith threshold modulation, etc. The proposed method is based on rectifiable\npolyominoes -- a non-periodic hierarchical structure, which tiles the Euclidean\nplane with no gaps. Each polyomino contains a fixed number of discrete\nthreshold values. Thanks to its inherent non-periodic nature combined with\noff-line optimization of threshold values, our polyomino-based threshold\nstructure shows blue-noise spectral properties. The halftone images produced\nwith this threshold structure have high visual quality. Although the proposed\nmethod is general, and can be applied on any polyomino tiling, we consider one\nparticular case: tiling with G-hexominoes. We compare our polyomino-based\nthreshold structure with the best known state-of-the-art methods for generation\nthreshold matrices, and conclude considerable improvement achieved with our\nmethod.",
    "published": "2008-12-09T10:12:36Z",
    "link": "http://arxiv.org/pdf/0812.1647v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "David Vanderhaeghe",
      "Victor Ostromoukhov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0901.4643v3",
    "title": "Visual tool for estimating the fractal dimension of images",
    "summary": "This work presents a new Visual Basic 6.0 application for estimating the\nfractal dimension of images, based on an optimized version of the box-counting\nalgorithm. Following the attempt to separate the real information from noise,\nwe considered also the family of all band-pass filters with the same band-width\n(specified as parameter). The fractal dimension can be thus represented as a\nfunction of the pixel color code. The program was used for the study of\npaintings cracks, as an additional tool which can help the critic to decide if\nan artistic work is original or not. In its second version, the application was\nextended for working also with csv files and three-dimensional images.",
    "published": "2009-01-29T14:41:45Z",
    "link": "http://arxiv.org/pdf/0901.4643v3.pdf",
    "category": [
      "physics.comp-ph",
      "cs.GR",
      "nlin.PS"
    ],
    "authors": [
      "I. V. Grossu",
      "C. Besliu",
      "M. V. Rusu",
      "Al. Jipa",
      "C. C. Bordeianu",
      "D. Felea",
      "E. Stan",
      "T. Esanu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0903.1448v1",
    "title": "The Digital Restoration of Da Vinci's Sketches",
    "summary": "A sketch, found in one of Leonardo da Vinci's notebooks and covered by the\nwritten notes of this genius, has been recently restored. The restoration\nreveals a possible self-portrait of the artist, drawn when he was young. Here,\nwe discuss the discovery of this self-portrait and the procedure used for\nrestoration. Actually, this is a restoration performed on the digital image of\nthe sketch, a procedure that can easily extended and applied to ancient\ndocuments for studies of art and palaeography.",
    "published": "2009-03-09T08:06:09Z",
    "link": "http://arxiv.org/pdf/0903.1448v1.pdf",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "Amelia Sparavigna"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0903.2119v1",
    "title": "Adaptive Mesh Approach for Predicting Algorithm Behavior with\n  Application to Visibility Culling in Computer Graphics",
    "summary": "We propose a concise approximate description, and a method for efficiently\nobtaining this description, via adaptive random sampling of the performance\n(running time, memory consumption, or any other profileable numerical quantity)\nof a given algorithm on some low-dimensional rectangular grid of inputs. The\nformal correctness is proven under reasonable assumptions on the algorithm\nunder consideration; and the approach's practical benefit is demonstrated by\npredicting for which observer positions and viewing directions an occlusion\nculling algorithm yields a net performance benefit or loss compared to a simple\nbrute force renderer.",
    "published": "2009-03-12T10:16:13Z",
    "link": "http://arxiv.org/pdf/0903.2119v1.pdf",
    "category": [
      "cs.PF",
      "cs.GR",
      "C.4; I.3"
    ],
    "authors": [
      "Matthias Fischer",
      "Claudius Jhn",
      "Martin Ziegler"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0903.3524v1",
    "title": "Ambient Isotopic Meshing of Implicit Algebraic Surface with\n  Singularities",
    "summary": "A complete method is proposed to compute a certified, or ambient isotopic,\nmeshing for an implicit algebraic surface with singularities. By certified, we\nmean a meshing with correct topology and any given geometric precision. We\npropose a symbolic-numeric method to compute a certified meshing for the\nsurface inside a box containing singularities and use a modified\nPlantinga-Vegter marching cube method to compute a certified meshing for the\nsurface inside a box without singularities. Nontrivial examples are given to\nshow the effectiveness of the algorithm. To our knowledge, this is the first\nmethod to compute a certified meshing for surfaces with singularities.",
    "published": "2009-03-20T13:53:35Z",
    "link": "http://arxiv.org/pdf/0903.3524v1.pdf",
    "category": [
      "cs.CG",
      "cs.GR",
      "G.1.2"
    ],
    "authors": [
      "Jin-San Cheng",
      "Xiao-Shan Gao",
      "Jia Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0906.1226v1",
    "title": "On the Complexity of Smooth Spline Surfaces from Quad Meshes",
    "summary": "This paper derives strong relations that boundary curves of a smooth complex\nof patches have to obey when the patches are computed by local averaging. These\nrelations restrict the choice of reparameterizations for geometric continuity.\nIn particular, when one bicubic tensor-product B-spline patch is associated\nwith each facet of a quadrilateral mesh with n-valent vertices and we do not\nwant segments of the boundary curves forced to be linear, then the relations\ndictate the minimal number and multiplicity of knots: For general data, the\ntensor-product spline patches must have at least two internal double knots per\nedge to be able to model a G^1-conneced complex of C^1 splines. This lower\nbound on the complexity of any construction is proven to be sharp by suitably\ninterpreting an existing surface construction. That is, we have a tight bound\non the complexity of smoothing quad meshes with bicubic tensor-product B-spline\npatches.",
    "published": "2009-06-05T22:57:04Z",
    "link": "http://arxiv.org/pdf/0906.1226v1.pdf",
    "category": [
      "cs.GR",
      "cs.CC"
    ],
    "authors": [
      "Jorg Peters",
      "Jianhua Fan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0906.2274v1",
    "title": "A Neural Network Classifier of Volume Datasets",
    "summary": "Many state-of-the art visualization techniques must be tailored to the\nspecific type of dataset, its modality (CT, MRI, etc.), the recorded object or\nanatomical region (head, spine, abdomen, etc.) and other parameters related to\nthe data acquisition process. While parts of the information (imaging modality\nand acquisition sequence) may be obtained from the meta-data stored with the\nvolume scan, there is important information which is not stored explicitly\n(anatomical region, tracing compound). Also, meta-data might be incomplete,\ninappropriate or simply missing.\n  This paper presents a novel and simple method of determining the type of\ndataset from previously defined categories. 2D histograms based on intensity\nand gradient magnitude of datasets are used as input to a neural network, which\nclassifies it into one of several categories it was trained with. The proposed\nmethod is an important building block for visualization systems to be used\nautonomously by non-experts. The method has been tested on 80 datasets, divided\ninto 3 classes and a \"rest\" class.\n  A significant result is the ability of the system to classify datasets into a\nspecific class after being trained with only one dataset of that class. Other\nadvantages of the method are its easy implementation and its high computational\nperformance.",
    "published": "2009-06-12T11:17:05Z",
    "link": "http://arxiv.org/pdf/0906.2274v1.pdf",
    "category": [
      "cs.GR",
      "cs.AI",
      "I.3.6; I.2.6"
    ],
    "authors": [
      "Denan Zuki",
      "Christof Rezk-Salama",
      "Andreas Kolb"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0906.3074v1",
    "title": "Feynman Algorithm Implementation for Comparison with Euler in a Uniform\n  Elastic Two-Layer 2D and 3D Object Dynamic Deformation Framework in OpenGL\n  with GUI",
    "summary": "We implement for comparative purposes the Feynman algorithm within a\nC++-based framework for two-layer uniform facet elastic object for real-time\nsoftbody simulation based on physics modeling methods. To facilitate the\ncomparison, we implement initial timing measurements on the same hardware\nagainst that of Euler integrator in the softbody framework by varying different\nalgorithm parameters. Due to a relatively large number of such variations we\nimplement a GLUI-based user-interface to allow for much more finer control over\nthe simulation process at real-time, which was lacking completely in the\nprevious versions of the framework. We show our currents results based on the\nenhanced framework. The two-layered elastic object consists of inner and outer\nelastic mass-spring surfaces and compressible internal pressure. The density of\nthe inner layer can be set differently from the density of the outer layer; the\nmotion of the inner layer can be opposite to the motion of the outer layer.\nThese special features, which cannot be achieved by a single layered object,\nresult in improved imitation of a soft body, such as tissue's liquid\nnon-uniform deformation. The inertial behavior of the elastic object is well\nillustrated in environments with gravity and collisions with walls, ceiling,\nand floor. The collision detection is defined by elastic collision penalty\nmethod and the motion of the object is guided by the Ordinary Differential\nEquation computation. Users can interact with the modeled objects, deform them,\nand observe the response to their action in real-time and we provide an\nextensible framework and its implementation for comparative studies of\ndifferent physical-based modeling and integration algorithm implementations.",
    "published": "2009-06-17T05:39:28Z",
    "link": "http://arxiv.org/pdf/0906.3074v1.pdf",
    "category": [
      "cs.GR",
      "cs.DS",
      "cs.HC",
      "I.3.7"
    ],
    "authors": [
      "Miao Song"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0906.3224v1",
    "title": "Personal applications, based on moveable / resizable elements",
    "summary": "All the modern day applications have the interface, absolutely defined by the\ndevelopers. The use of adaptive interface or dynamic layout allows some\nvariations, but even all of them are predetermined on the design stage, because\nthe best reaction (from designer's view) on any possible users' movement was\nhardcoded. But there is a different world of applications, totally constructed\non moveable / resizable elements; such applications turn the full control to\nthe users. The crucial thing in such programs is that not something but\neverything must become moveable and resizable. This article describes the\nfeatures of such applications and the algorithm behind their design.",
    "published": "2009-06-17T16:07:01Z",
    "link": "http://arxiv.org/pdf/0906.3224v1.pdf",
    "category": [
      "cs.HC",
      "cs.GR"
    ],
    "authors": [
      "Sergey Andreyev"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0906.4036v3",
    "title": "Physical Modeling Techniques in Active Contours for Image Segmentation",
    "summary": "Physical modeling method, represented by simulation and visualization of the\nprinciples in physics, is introduced in the shape extraction of the active\ncontours. The objectives of adopting this concept are to address the several\nmajor difficulties in the application of Active Contours. Primarily, a\ntechnique is developed to realize the topological changes of Parametric Active\nContours (Snakes). The key strategy is to imitate the process of a balloon\nexpanding and filling in a closed space with several objects. After removing\nthe touched balloon surfaces, the objects can be identified by surrounded\nremaining balloon surfaces. A burned region swept by Snakes is utilized to\ntrace the contour and to give a criterion for stopping the movement of Snake\ncurve. When the Snakes terminates evolution totally, through ignoring this\ncriterion, it can form a connected area by evolving the Snakes again and\ncontinuing the region burning. The contours extracted from the boundaries of\nthe burned area can represent the child snake of each object respectively.\nSecondly, a novel scheme is designed to solve the problems of leakage of the\ncontour from the large gaps, and the segmentation error in Geometric Active\nContours (GAC). It divides the segmentation procedure into two processing\nstages. By simulating the wave propagating in the isotropic substance at the\nfinal stage, it can significantly enhance the effect of image force in GAC\nbased on Level Set and give the satisfied solutions to the two problems.\nThirdly, to support the physical models for active contours above, we introduce\na general image force field created on a template plane over the image plane.\nThis force is more adaptable to noisy images with complicated geometric shapes.",
    "published": "2009-06-22T16:38:30Z",
    "link": "http://arxiv.org/pdf/0906.4036v3.pdf",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "Hongyu Lu",
      "Shanglian Bao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0907.3604v1",
    "title": "Image Sampling with Quasicrystals",
    "summary": "We investigate the use of quasicrystals in image sampling. Quasicrystals\nproduce space-filling, non-periodic point sets that are uniformly discrete and\nrelatively dense, thereby ensuring the sample sites are evenly spread out\nthroughout the sampled image. Their self-similar structure can be attractive\nfor creating sampling patterns endowed with a decorative symmetry. We present a\nbrief general overview of the algebraic theory of cut-and-project quasicrystals\nbased on the geometry of the golden ratio. To assess the practical utility of\nquasicrystal sampling, we evaluate the visual effects of a variety of\nnon-adaptive image sampling strategies on photorealistic image reconstruction\nand non-photorealistic image rendering used in multiresolution image\nrepresentations. For computer visualization of point sets used in image\nsampling, we introduce a mosaic rendering technique.",
    "published": "2009-07-21T10:08:48Z",
    "link": "http://arxiv.org/pdf/0907.3604v1.pdf",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "Mark Grundland",
      "Jiri Patera",
      "Zuzana Masakova",
      "Neil A. Dodgson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0907.4364v2",
    "title": "Dynamic Deformation of Uniform Elastic Two-Layer Objects",
    "summary": "This thesis presents a two-layer uniform facet elastic object for real-time\nsimulation based on physics modeling method. It describes the elastic object\nprocedural modeling algorithm with particle system from the simplest\none-dimensional object, to more complex two-dimensional and three-dimensional\nobjects.\n  The double-layered elastic object consists of inner and outer elastic mass\nspring surfaces and compressible internal pressure. The density of the inner\nlayer can be set different from the density of the outer layer; the motion of\nthe inner layer can be opposite to the motion of the outer layer. These special\nfeatures, which cannot be achieved by a single layered object, result in\nimproved imitation of a soft body, such as tissue's liquidity non-uniform\ndeformation. The construction of the double-layered elastic object is closer to\nthe real tissue's physical structure.\n  The inertial behavior of the elastic object is well illustrated in\nenvironments with gravity and collisions with walls, ceiling, and floor. The\ncollision detection is defined by elastic collision penalty method and the\nmotion of the object is guided by the Ordinary Differential Equation\ncomputation.\n  Users can interact with the modeled objects, deform them, and observe the\nresponse to their action in real time.",
    "published": "2009-07-24T19:13:02Z",
    "link": "http://arxiv.org/pdf/0907.4364v2.pdf",
    "category": [
      "cs.GR",
      "I.3.7; I.3.5; I.3.6"
    ],
    "authors": [
      "Miao Song"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0908.3889v2",
    "title": "Integrating Post-Newtonian Equations on Graphics Processing Units",
    "summary": "We report on early results of a numerical and statistical study of binary\nblack hole inspirals. The two black holes are evolved using post-Newtonian\napproximations starting with initially randomly distributed spin vectors. We\ncharacterize certain aspects of the distribution shortly before merger. In\nparticular we note the uniform distribution of black hole spin vector dot\nproducts shortly before merger and a high correlation between the initial and\nfinal black hole spin vector dot products in the equal-mass, maximally spinning\ncase. These simulations were performed on Graphics Processing Units, and we\ndemonstrate a speed-up of a factor 50 over a more conventional CPU\nimplementation.",
    "published": "2009-08-26T20:00:38Z",
    "link": "http://arxiv.org/pdf/0908.3889v2.pdf",
    "category": [
      "gr-qc",
      "astro-ph.CO",
      "astro-ph.EP",
      "astro-ph.GA",
      "astro-ph.HE",
      "astro-ph.IM",
      "astro-ph.SR",
      "cs.DC",
      "cs.GR",
      "cs.PF"
    ],
    "authors": [
      "Frank Herrmann",
      "John Silberholz",
      "Matias Bellone",
      "Gustavo Guerberoff",
      "Manuel Tiglio"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0908.4374v1",
    "title": "Visualization of Mined Pattern and Its Human Aspects",
    "summary": "Researchers got success in mining the Web usage data effectively and\nefficiently. But representation of the mined patterns is often not in a form\nsuitable for direct human consumption. Hence mechanisms and tools that can\nrepresent mined patterns in easily understandable format are utilized.\nDifferent techniques are used for pattern analysis, one of them is\nvisualization. Visualization can provide valuable assistance for data analysis\nand decision making tasks. In the data visualization process, technical\nrepresentations of web pages are replaced by user attractive text\ninterpretations. Experiments with the real world problems showed that the\nvisualization can significantly increase the quality and usefulness of web log\nmining results. However, how decision makers perceive and interact with a\nvisual representation can strongly influence their understanding of the data as\nwell as the usefulness of the visual presentation. Human factors therefore\ncontribute significantly to the visualization process and should play an\nimportant role in the design and evaluation of visualization tools. This\nelectronic document is a live template. The various components of your paper,\ntitle, text, heads, etc., are already defined on the style sheet, as\nillustrated by the portions given in this document.",
    "published": "2009-08-30T05:30:40Z",
    "link": "http://arxiv.org/pdf/0908.4374v1.pdf",
    "category": [
      "cs.HC",
      "cs.GR"
    ],
    "authors": [
      "Ratnesh Kumar Jain",
      "Dr. Suresh Jain",
      "Dr. R. S. Kasana"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0909.3137v1",
    "title": "Succinct Representation of Well-Spaced Point Clouds",
    "summary": "A set of n points in low dimensions takes Theta(n w) bits to store on a w-bit\nmachine. Surface reconstruction and mesh refinement impose a requirement on the\ndistribution of the points they process. I show how to use this assumption to\nlossily compress a set of n input points into a representation that takes only\nO(n) bits, independent of the word size. The loss can keep inter-point\ndistances to within 10% relative error while still achieving a factor of three\nspace savings. The representation allows standard quadtree operations, along\nwith computing the restricted Voronoi cell of a point, in time O(w^2 + log n),\nwhich can be improved to time O(log n) if w is in Theta(log n). Thus one can\nuse this compressed representation to perform mesh refinement or surface\nreconstruction in O(n) bits with only a logarithmic slowdown.",
    "published": "2009-09-17T01:39:59Z",
    "link": "http://arxiv.org/pdf/0909.3137v1.pdf",
    "category": [
      "cs.CG",
      "cs.DS",
      "cs.GR"
    ],
    "authors": [
      "Benot Hudson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0910.0505v2",
    "title": "Hard Data on Soft Errors: A Large-Scale Assessment of Real-World Error\n  Rates in GPGPU",
    "summary": "Graphics processing units (GPUs) are gaining widespread use in computational\nchemistry and other scientific simulation contexts because of their huge\nperformance advantages relative to conventional CPUs. However, the reliability\nof GPUs in error-intolerant applications is largely unproven. In particular, a\nlack of error checking and correcting (ECC) capability in the memory subsystems\nof graphics cards has been cited as a hindrance to the acceptance of GPUs as\nhigh-performance coprocessors, but the impact of this design has not been\npreviously quantified.\n  In this article we present MemtestG80, our software for assessing memory\nerror rates on NVIDIA G80 and GT200-architecture-based graphics cards.\nFurthermore, we present the results of a large-scale assessment of GPU error\nrate, conducted by running MemtestG80 on over 20,000 hosts on the Folding@home\ndistributed computing network. Our control experiments on consumer-grade and\ndedicated-GPGPU hardware in a controlled environment found no errors. However,\nour survey over cards on Folding@home finds that, in their installed\nenvironments, two-thirds of tested GPUs exhibit a detectable, pattern-sensitive\nrate of memory soft errors. We demonstrate that these errors persist after\ncontrolling for overclocking and environmental proxies for temperature, but\ndepend strongly on board architecture.",
    "published": "2009-10-03T02:04:22Z",
    "link": "http://arxiv.org/pdf/0910.0505v2.pdf",
    "category": [
      "cs.AR",
      "cs.GR",
      "B.3.4"
    ],
    "authors": [
      "Imran S. Haque",
      "Vijay S. Pande"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0910.4084v1",
    "title": "Complementary Space for Enhanced Uncertainty and Dynamics Visualization",
    "summary": "Given a computer model of a physical object, it is often quite difficult to\nvisualize and quantify any global effects on the shape representation caused by\nlocal uncertainty and local errors in the data. This problem is further\namplified when dealing with hierarchical representations containing varying\nlevels of detail and / or shapes undergoing dynamic deformations. In this\npaper, we compute, quantify and visualize the complementary topological and\ngeometrical features of 3D shape models, namely, the tunnels, pockets and\ninternal voids of the object. We find that this approach sheds a unique light\non how a model is affected by local uncertainty, errors or modifications and\nshow how the presence or absence of complementary shape features can be\nessential to an object's structural form and function.",
    "published": "2009-10-20T22:00:54Z",
    "link": "http://arxiv.org/pdf/0910.4084v1.pdf",
    "category": [
      "cs.CG",
      "cs.GR",
      "I.6.4"
    ],
    "authors": [
      "Chandrajit Bajaj",
      "Andrew Gillette",
      "Samrat Goswami",
      "Bong June Kwon",
      "Jose Rivera"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0910.4854v1",
    "title": "Yet Another Pacman 3D Adventures",
    "summary": "This game is meant to be extension of the overly-beaten pacman-style game\n(code-named \"Yet Another Pacman 3D Adventures\", or YAP3DAD) from the proposed\nideas and other projects with advance visual and computer graphics features,\nincluding a-game-in-a-game approach. The project is an open-source project\npublished on SourceForge.net for possible future development and extension.",
    "published": "2009-10-26T10:55:16Z",
    "link": "http://arxiv.org/pdf/0910.4854v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Serguei A. Mokhov",
      "Yingying She"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0911.0902v1",
    "title": "Digital Image Watermarking for Arbitrarily Shaped Objects Based On\n  SA-DWT",
    "summary": "Many image watermarking schemes have been proposed in recent years, but they\nusually involve embedding a watermark to the entire image without considering\nonly a particular object in the image, which the image owner may be interested\nin. This paper proposes a watermarking scheme that can embed a watermark to an\narbitrarily shaped object in an image. Before embedding, the image owner\nspecifies an object of arbitrary shape that is of a concern to him. Then the\nobject is transformed into the wavelet domain using in place lifting shape\nadaptive DWT(SADWT) and a watermark is embedded by modifying the wavelet\ncoefficients. In order to make the watermark robust and transparent, the\nwatermark is embedded in the average of wavelet blocks using the visual model\nbased on the human visual system. Wavelet coefficients n least significant bits\n(LSBs) are adjusted in concert with the average. Simulation results shows that\nthe proposed watermarking scheme is perceptually invisible and robust against\nmany attacks such as lossy compression (e.g.JPEG, JPEG2000), scaling, adding\nnoise, filtering, etc.",
    "published": "2009-11-04T18:11:30Z",
    "link": "http://arxiv.org/pdf/0911.0902v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "A. Essaouabi",
      "E. Ibnelhaj",
      "F. Fegragui"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0911.3349v1",
    "title": "Seeing Science",
    "summary": "The ability to represent scientific data and concepts visually is becoming\nincreasingly important due to the unprecedented exponential growth of\ncomputational power during the present digital age. The data sets and\nsimulations scientists in all fields can now create are literally thousands of\ntimes as large as those created just 20 years ago. Historically successful\nmethods for data visualization can, and should, be applied to today's huge data\nsets, but new approaches, also enabled by technology, are needed as well.\nIncreasingly, \"modular craftsmanship\" will be applied, as relevant\nfunctionality from the graphically and technically best tools for a job are\ncombined as-needed, without low-level programming.",
    "published": "2009-11-17T17:01:33Z",
    "link": "http://arxiv.org/pdf/0911.3349v1.pdf",
    "category": [
      "astro-ph.IM",
      "cs.CV",
      "cs.GR",
      "stat.AP"
    ],
    "authors": [
      "Alyssa Goodman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0911.5157v3",
    "title": "Analyzing Midpoint Subdivision",
    "summary": "Midpoint subdivision generalizes the Lane-Riesenfeld algorithm for uniform\ntensor product splines and can also be applied to non regular meshes. For\nexample, midpoint subdivision of degree 2 is a specific Doo-Sabin algorithm and\nmidpoint subdivision of degree 3 is a specific Catmull-Clark algorithm. In\n2001, Zorin and Schroeder were able to prove C1-continuity for midpoint\nsubdivision surfaces analytically up to degree 9. Here, we develop general\nanalysis tools to show that the limiting surfaces under midpoint subdivision of\nany degree >= 2 are C1-continuous at their extraordinary points.",
    "published": "2009-11-26T22:47:37Z",
    "link": "http://arxiv.org/pdf/0911.5157v3.pdf",
    "category": [
      "cs.GR",
      "cs.CG",
      "I.3.5"
    ],
    "authors": [
      "Hartmut Prautzsch",
      "Qi Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0912.2706v2",
    "title": "On the theory of moveable objects",
    "summary": "User-driven applications belong to the new type of programs, in which users\nget the full control of WHAT, WHEN, and HOW must appear on the screen. Such\nprograms can exist only if the screen view is organized not according with the\npredetermined scenario, written by the developers, but if any screen object can\nbe moved, resized, and reconfigured by any user at any moment. This article\ndescribes the algorithm, by which an object of an arbitrary shape can be turned\ninto moveable and resizable. It also explains some rules of such design and the\ntechnique, which can be useful in many cases. Both the individual movements of\nobjects and their synchronous movements are analysed. After discussing the\nindividually moveable controls, different types of groups are analysed and the\narbitrary grouping of controls is considered.",
    "published": "2009-12-14T19:00:29Z",
    "link": "http://arxiv.org/pdf/0912.2706v2.pdf",
    "category": [
      "cs.HC",
      "cs.GR"
    ],
    "authors": [
      "Sergey Andreyev"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0912.3923v1",
    "title": "Secure Watermarking Scheme for Color Image Using Intensity of Pixel and\n  LSB Substitution",
    "summary": "In this paper a novel spatial domain LSB based watermarking scheme for color\nImages is proposed. The proposed scheme is of type blind and invisible\nwatermarking. Our scheme introduces the concept of storing variable number of\nbits in each pixel based on the actual color value of pixel. Equal or higher\nthe color value of channels with respect to intensity of pixel stores higher\nnumber of watermark bits. The Red, Green and Blue channel of the color image\nhas been used for watermark embedding. The watermark is embedded into selected\nchannels of pixel. The proposed method supports high watermark embedding\ncapacity, which is equivalent to the size of cover image. The security of\nwatermark is preserved by permuting the watermark bits using secret key. The\nproposed scheme is found robust to various image processing operations such as\nimage compression, blurring, salt and pepper noise, filtering and cropping.",
    "published": "2009-12-19T18:47:39Z",
    "link": "http://arxiv.org/pdf/0912.3923v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Nagaraj V. Dharwadkar",
      "B. B. Amberker"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0912.5494v1",
    "title": "Teaching Physical Based Animation via OpenGL Slides",
    "summary": "This work expands further our earlier poster presentation and integration of\nthe OpenGL Slides Framework (OGLSF) - to make presentations with real-time\nanimated graphics where each slide is a scene with tidgets - and physical based\nanimation of elastic two-, three-layer softbody objects. The whole project is\nvery interactive, and serves dual purpose - delivering the teaching material in\na classroom setting with real running animated examples as well as releasing\nthe source code to the students to show how the actual working things are made.",
    "published": "2009-12-30T17:53:18Z",
    "link": "http://arxiv.org/pdf/0912.5494v1.pdf",
    "category": [
      "cs.GR",
      "cs.HC",
      "I.3.7; I.3.6; I.4.9; H.5.2"
    ],
    "authors": [
      "Miao Song",
      "Serguei A. Mokhov",
      "Peter Grogono"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0912.5380v1",
    "title": "Computing Principal Components Dynamically",
    "summary": "In this paper we present closed-form solutions for efficiently updating the\nprincipal components of a set of $n$ points, when $m$ points are added or\ndeleted from the point set. For both operations performed on a discrete point\nset in $\\mathbb{R}^d$, we can compute the new principal components in $O(m)$\ntime for fixed $d$. This is a significant improvement over the commonly used\napproach of recomputing the principal components from scratch, which takes\n$O(n+m)$ time. An important application of the above result is the dynamical\ncomputation of bounding boxes based on principal component analysis. PCA\nbounding boxes are very often used in many fields, among others in computer\ngraphics for collision detection and fast rendering. We have implemented and\nevaluated few algorithms for computing dynamically PCA bounding boxes in\n$\\mathbb{R}^3$. In addition, we present closed-form solutions for computing\ndynamically principal components of continuous point sets in $\\mathbb{R}^2$ and\n$\\mathbb{R}^3$. In both cases, discrete and continuous, to compute the new\nprincipal components, no additional data structures or storage are needed.",
    "published": "2009-12-30T18:07:56Z",
    "link": "http://arxiv.org/pdf/0912.5380v1.pdf",
    "category": [
      "cs.GR",
      "cs.CG"
    ],
    "authors": [
      "Darko Dimitrov",
      "Mathias Holst",
      "Christian Knauer",
      "Klaus Kriegel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1001.2734v1",
    "title": "Planar Visibility: Testing and Counting",
    "summary": "In this paper we consider query versions of visibility testing and visibility\ncounting. Let $S$ be a set of $n$ disjoint line segments in $\\R^2$ and let $s$\nbe an element of $S$. Visibility testing is to preprocess $S$ so that we can\nquickly determine if $s$ is visible from a query point $q$. Visibility counting\ninvolves preprocessing $S$ so that one can quickly estimate the number of\nsegments in $S$ visible from a query point $q$.\n  We present several data structures for the two query problems. The structures\nbuild upon a result by O'Rourke and Suri (1984) who showed that the subset,\n$V_S(s)$, of $\\R^2$ that is weakly visible from a segment $s$ can be\nrepresented as the union of a set, $C_S(s)$, of $O(n^2)$ triangles, even though\nthe complexity of $V_S(s)$ can be $\\Omega(n^4)$. We define a variant of their\ncovering, give efficient output-sensitive algorithms for computing it, and\nprove additional properties needed to obtain approximation bounds. Some of our\nbounds rely on a new combinatorial result that relates the number of segments\nof $S$ visible from a point $p$ to the number of triangles in $\\bigcup_{s\\in S}\nC_S(s)$ that contain $p$.",
    "published": "2010-01-15T19:45:18Z",
    "link": "http://arxiv.org/pdf/1001.2734v1.pdf",
    "category": [
      "cs.CG",
      "cs.GR"
    ],
    "authors": [
      "Joachim Gudmundsson",
      "Pat Morin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1001.3481v2",
    "title": "Resolution scalability improvement for JPEG2000 standard color image",
    "summary": "Removed by arXiv administration. This article was plagiarised from\nhttp://www.dmi.unict.it/~battiato/download/NSIP_2003_VQ.pdf and other\nlocations.",
    "published": "2010-01-20T07:35:21Z",
    "link": "http://arxiv.org/pdf/1001.3481v2.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "U. Vijayasankar",
      "S. Prasadh.",
      "A. Arul Lawrence Selvakumar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1001.3496v1",
    "title": "Spatial Domain Watermarking Scheme for Colored Images Based on\n  Log-average Luminance",
    "summary": "In this paper a new watermarking scheme is presented based on log-average\nluminance. A colored-image is divided into blocks after converting the RGB\ncolored image to YCbCr color space. A monochrome image of 1024 bytes is used as\nthe watermark. To embed the watermark, 16 blocks of size 8X8 are selected and\nused to embed the watermark image into the original image. The selected blocks\nare chosen spirally (beginning form the center of the image) among the blocks\nthat have log-average luminance higher than or equal the log-average luminance\nof the entire image. Each byte of the monochrome watermark is added by updating\na luminance value of a pixel of the image. If the byte of the watermark image\nrepresented white color (255) a value <alpha> is added to the image pixel\nluminance value, if it is black (0) the <alpha> is subtracted from the\nluminance value. To extract the watermark, the selected blocks are chosen as\nthe above, if the difference between the luminance value of the watermarked\nimage pixel and the original image pixel is greater than 0, the watermark pixel\nis supposed to be white, otherwise it supposed to be black. Experimental\nresults show that the proposed scheme is efficient against changing the\nwatermarked image to grayscale, image cropping, and JPEG compression.",
    "published": "2010-01-20T08:08:39Z",
    "link": "http://arxiv.org/pdf/1001.3496v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Jamal A. Hussein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1001.3974v2",
    "title": "Modelacion y Visualizacion Tridimensional Interactiva de Variables\n  Electricas en Celdas de Electro-Obtencion con Electrodos Bipolares",
    "summary": "The use of floating bipolar electrodes in electrowinning cells of copper\nconstitutes a nonconventional technology that promises economic and operational\nimpacts. This paper presents a computational tool for the simulation and\nanalysis of such electrochemical cells. A new model is developed for floating\nelectrodes and a method of finite difference is used to obtain the\nthreedimensional distribution of the potential and the field of current density\ninside the cell. The analysis of the results is based on a technique for the\ninteractive visualization of three-dimensional vectorial fields as lines of\nflow.",
    "published": "2010-01-22T12:57:59Z",
    "link": "http://arxiv.org/pdf/1001.3974v2.pdf",
    "category": [
      "cs.GR",
      "cs.CE"
    ],
    "authors": [
      "Csar Mena Labraa",
      "Ricardo Snchez Schulz",
      "Lautaro Salazar Silva"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1001.4002v1",
    "title": "Aplicacion Grafica para el estudio de un Modelo de Celda Electrolitica\n  usando Tecnicas de Visualizacion de Campos Vectoriales",
    "summary": "The use of floating bipolar electrodes in electrowinning cells of copper\nconstitutes a nonconventional technology that promises economic and operational\nimpacts. This thesis presents a computational tool for the simulation and\nanalysis of such electrochemical cells. A new model is developed for floating\nelectrodes and a method of finite difference is used to obtain the\nthreedimensional distribution of the potential and the field of current density\ninside the cell. The analysis of the results is based on a technique for the\ninteractive visualization of three-dimensional vectorial fields as lines of\nflow.",
    "published": "2010-01-22T18:23:27Z",
    "link": "http://arxiv.org/pdf/1001.4002v1.pdf",
    "category": [
      "cs.GR",
      "cs.CE"
    ],
    "authors": [
      "Csar Mena Labraa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1002.4006v1",
    "title": "Text/Graphics Separation and Skew Correction of Text Regions of Business\n  Card Images for Mobile Devices",
    "summary": "Separation of the text regions from background texture and graphics is an\nimportant step of any optical character recognition system for the images\ncontaining both texts and graphics. In this paper, we have presented a novel\ntext/graphics separation technique and a method for skew correction of text\nregions extracted from business card images captured with a cell-phone camera.\nAt first, the background is eliminated at a coarse level based on intensity\nvariance. This makes the foreground components distinct from each other. Then\nthe non-text components are removed using various characteristic features of\ntext and graphics. Finally, the text regions are skew corrected for further\nprocessing. Experimenting with business card images of various resolutions, we\nhave found an optimum performance of 98.25% (recall) with 0.75 MP images, that\ntakes 0.17 seconds processing time and 1.1 MB peak memory on a moderately\npowerful computer (DualCore 1.73 GHz Processor, 1 GB RAM, 1 MB L2 Cache). The\ndeveloped technique is computationally efficient and consumes low memory so as\nto be applicable on mobile devices.",
    "published": "2010-02-21T19:46:12Z",
    "link": "http://arxiv.org/pdf/1002.4006v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Ayatullah Faruk Mollah",
      "Subhadip Basu",
      "Mita Nasipuri"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1002.4317v1",
    "title": "CLD-shaped Brushstrokes in Non-Photorealistic Rendering",
    "summary": "Rendering techniques based on a random grid can be improved by adapting\nbrushstrokes to the shape of different areas of the original picture. In this\npaper, the concept of Coherence Length Diagram is applied to determine the\nadaptive brushstrokes, in order to simulate an impressionist painting. Some\nexamples are provided to instance the proposed algorithm.",
    "published": "2010-02-23T12:32:34Z",
    "link": "http://arxiv.org/pdf/1002.4317v1.pdf",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "Amelia Carolina Sparavigna",
      "Roberto Marazzato"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1003.1401v1",
    "title": "Macro and micro view on steady states in state space",
    "summary": "This paper describes visualization of chaotic attractor and elements of the\nsingularities in 3D space. 3D view of these effects enables to create a\ndemonstrative projection about relations of chaos generated by physical\ncircuit, the Chua's circuit. Via macro views on chaotic attractor is obtained\nnot only visual space illustration of representative point motion in state\nspace, but also its relation to planes of singularity elements. Our created\nprogram enables view on chaotic attractor both in 2D and 3D space together with\nplane objects visualization -- elements of singularities.",
    "published": "2010-03-06T16:42:53Z",
    "link": "http://arxiv.org/pdf/1003.1401v1.pdf",
    "category": [
      "cs.GR",
      "94C99, 68U05",
      "B.7.2"
    ],
    "authors": [
      "Branislav Sobota",
      "Milan Guzan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1003.1410v2",
    "title": "Local Space-Time Smoothing for Version Controlled Documents",
    "summary": "Unlike static documents, version controlled documents are continuously edited\nby one or more authors. Such collaborative revision process makes traditional\nmodeling and visualization techniques inappropriate. In this paper we propose a\nnew representation based on local space-time smoothing that captures important\nrevision patterns. We demonstrate the applicability of our framework using\nexperiments on synthetic and real-world data.",
    "published": "2010-03-06T18:08:12Z",
    "link": "http://arxiv.org/pdf/1003.1410v2.pdf",
    "category": [
      "cs.GR",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Seungyeon Kim",
      "Guy Lebanon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1003.4036v1",
    "title": "A Very Simple Approach for 3-D to 2-D Mapping",
    "summary": "Many times we need to plot 3-D functions e.g., in many scientificc\nexperiments. To plot this 3-D functions on 2-D screen it requires some kind of\nmapping. Though OpenGL, DirectX etc 3-D rendering libraries have made this job\nvery simple, still these libraries come with many complex pre- operations that\nare simply not intended, also to integrate these libraries with any kind of\nsystem is often a tough trial. This article presents a very simple method of\nmapping from 3D to 2D, that is free from any complex pre-operation, also it\nwill work with any graphics system where we have some primitive 2-D graphics\nfunction. Also we discuss the inverse transform and how to do basic computer\ngraphics transformations using our coordinate mapping system.",
    "published": "2010-03-21T23:32:56Z",
    "link": "http://arxiv.org/pdf/1003.4036v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Sandipan Dey",
      "Ajith Abraham",
      "Sugata Sanyal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1004.0766v1",
    "title": "Text/Graphics Separation for Business Card Images for Mobile Devices",
    "summary": "Separation of the text regions from background texture and graphics is an\nimportant step of any optical character recognition sytem for the images\ncontaing both texts and graphics. In this paper, we have presented a novel\ntext/graphics separation technique for business card images captured with a\ncell-phone camera. At first, the background is eliminated at a coarse level\nbased on intensity variance. This makes the foreground components distinct from\neach other. Then the non-text components are removed using various\ncharacteristic features of text and graphics. Finally, the text regions are\nskew corrected and binarized for further processing. Experimenting with\nbusiness card images of various resolutions, we have found an optimum\nperformance of 98.54% with 0.75 MP images, that takes 0.17 seconds processing\ntime and 1.1 MB peak memory on a moderately powerful computer (DualCore 1.73\nGHz Processor, 1 GB RAM, 1 MB L2 Cache). The developed technique is\ncomputationally efficient and consumes low memory so as to be applicable on\nmobile devices.",
    "published": "2010-04-06T03:54:27Z",
    "link": "http://arxiv.org/pdf/1004.0766v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Ayatullah Faruk Mollah",
      "Subhadip Basu",
      "Mita Nasipuri",
      "Dipak Kumar Basu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1004.2447v1",
    "title": "Autoplot: A browser for scientific data on the web",
    "summary": "Autoplot is software developed for the Virtual Observatories in Heliophysics\nto provide intelligent and automated plotting capabilities for many typical\ndata products that are stored in a variety of file formats or databases.\nAutoplot has proven to be a flexible tool for exploring, accessing, and viewing\ndata resources as typically found on the web, usually in the form of a\ndirectory containing data files with multiple parameters contained in each\nfile. Data from a data source is abstracted into a common internal data model\ncalled QDataSet. Autoplot is built from individually useful components, and can\nbe extended and reused to create specialized data handling and analysis\napplications and is being used in a variety of science visualization and\nanalysis applications. Although originally developed for viewing\nheliophysics-related time series and spectrograms, its flexible and generic\ndata representation model makes it potentially useful for the Earth sciences.",
    "published": "2010-04-14T16:40:41Z",
    "link": "http://arxiv.org/pdf/1004.2447v1.pdf",
    "category": [
      "cs.GR",
      "physics.data-an",
      "physics.space-ph"
    ],
    "authors": [
      "J. Faden",
      "R. S. Weigel",
      "J. Merka",
      "R. H. W. Friedel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1004.4485v1",
    "title": "Finding and Classifying Critical Points of 2D Vector Fields: A\n  Cell-Oriented Approach Using Group Theory",
    "summary": "We present a novel approach to finding critical points in cell-wise\nbarycentrically or bilinearly interpolated vector fields on surfaces. The\nPoincar\\e index of the critical points is determined by investigating the\nqualitative behavior of 0-level sets of the interpolants of the vector field\ncomponents in parameter space using precomputed combinatorial results, thus\navoiding the computation of the Jacobian of the vector field at the critical\npoints in order to determine its index. The locations of the critical points\nwithin a cell are determined analytically to achieve accurate results. This\napproach leads to a correct treatment of cases with two first-order critical\npoints or one second-order critical point of bilinearly interpolated vector\nfields within one cell, which would be missed by examining the linearized field\nonly. We show that for the considered interpolation schemes determining the\nindex of a critical point can be seen as a coloring problem of cell edges. A\ncomplete classification of all possible colorings in terms of the types and\nnumber of critical points yielded by each coloring is given using computational\ngroup theory. We present an efficient algorithm that makes use of these\nprecomputed classifications in order to find and classify critical points in a\ncell-by-cell fashion. Issues of numerical stability, construction of the\ntopological skeleton, topological simplification, and the statistics of the\ndifferent types of critical points are also discussed.",
    "published": "2010-04-26T11:26:33Z",
    "link": "http://arxiv.org/pdf/1004.4485v1.pdf",
    "category": [
      "cs.GR",
      "68-04, 68R05"
    ],
    "authors": [
      "Felix Effenberger",
      "Daniel Weiskopf"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1004.5424v1",
    "title": "Graphic Symbol Recognition using Graph Based Signature and Bayesian\n  Network Classifier",
    "summary": "We present a new approach for recognition of complex graphic symbols in\ntechnical documents. Graphic symbol recognition is a well known challenge in\nthe field of document image analysis and is at heart of most graphic\nrecognition systems. Our method uses structural approach for symbol\nrepresentation and statistical classifier for symbol recognition. In our system\nwe represent symbols by their graph based signatures: a graphic symbol is\nvectorized and is converted to an attributed relational graph, which is used\nfor computing a feature vector for the symbol. This signature corresponds to\ngeometry and topology of the symbol. We learn a Bayesian network to encode\njoint probability distribution of symbol signatures and use it in a supervised\nlearning scenario for graphic symbol recognition. We have evaluated our method\non synthetically deformed and degraded images of pre-segmented 2D architectural\nand electronic symbols from GREC databases and have obtained encouraging\nrecognition rates.",
    "published": "2010-04-30T00:04:39Z",
    "link": "http://arxiv.org/pdf/1004.5424v1.pdf",
    "category": [
      "cs.CV",
      "cs.GR",
      "I.4.0; I.5.0"
    ],
    "authors": [
      "Muhammad Muzzamil Luqman",
      "Thierry Brouard",
      "Jean-Yves Ramel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1004.5427v1",
    "title": "Employing fuzzy intervals and loop-based methodology for designing\n  structural signature: an application to symbol recognition",
    "summary": "Motivation of our work is to present a new methodology for symbol\nrecognition. We support structural methods for representing visual associations\nin graphic documents. The proposed method employs a structural approach for\nsymbol representation and a statistical classifier for recognition. We\nvectorize a graphic symbol, encode its topological and geometrical information\nby an ARG and compute a signature from this structural graph. To address the\nsensitivity of structural representations to deformations and degradations, we\nuse data adapted fuzzy intervals while computing structural signature. The\njoint probability distribution of signatures is encoded by a Bayesian network.\nThis network in fact serves as a mechanism for pruning irrelevant features and\nchoosing a subset of interesting features from structural signatures, for\nunderlying symbol set. Finally we deploy the Bayesian network in supervised\nlearning scenario for recognizing query symbols. We have evaluated the\nrobustness of our method against noise, on synthetically deformed and degraded\nimages of pre-segmented 2D architectural and electronic symbols from GREC\ndatabases and have obtained encouraging recognition rates. A second set of\nexperimentation was carried out for evaluating the performance of our method\nagainst context noise i.e. symbols cropped from complete documents. The results\nsupport the use of our signature by a symbol spotting system.",
    "published": "2010-04-30T00:16:22Z",
    "link": "http://arxiv.org/pdf/1004.5427v1.pdf",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "Muhammad Muzzamil Luqman",
      "Mathieu Delalandre",
      "Thierry Brouard",
      "Jean-Yves Ramel",
      "Josep Llads"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1005.3163v1",
    "title": "Virtual Texturing",
    "summary": "In this thesis a rendering system and an accompanying tool chain for Virtual\nTexturing is presented. Our tools allow to automatically retexture existing\ngeometry in order to apply unique texturing on each face. Furthermore we\ninvestigate several techniques that try to minimize visual artifacts in the\ncase that only a small amount of pages can be streamed per frame. We analyze\nthe influence of different heuristics that are responsible for the page\nselection. Alongside these results we present a measurement method to allow the\ncomparison of our heuristics.",
    "published": "2010-05-18T11:54:39Z",
    "link": "http://arxiv.org/pdf/1005.3163v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Andreas Neu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1005.3181v1",
    "title": "Multi-sensorial interaction with a nano-scale phenomenon : the force\n  curve",
    "summary": "Using Atomic Force Microscopes (AFM) to manipulate nano-objects is an actual\nchallenge for surface scientists. Basic haptic interfacesbetween the AFM and\nexperimentalists have already been implemented. Themulti-sensory renderings\n(seeing, hearing and feeling) studied from acognitive point of view increase\nthe efficiency of the actual interfaces. Toallow the experimentalist to feel\nand touch the nano-world, we add mixedrealities between an AFM and a force\nfeedback device, enriching thus thedirect connection by a modeling engine. We\npresent in this paper the firstresults from a real-time remote-control handling\nof an AFM by our ForceFeedback Gestural Device through the example of the\napproach-retract curve.",
    "published": "2010-05-18T13:01:46Z",
    "link": "http://arxiv.org/pdf/1005.3181v1.pdf",
    "category": [
      "cs.GR",
      "cs.HC",
      "physics.comp-ph"
    ],
    "authors": [
      "Sylvain Marliere",
      "Daniela Urma",
      "Jean-Loup Florens",
      "Florence Marchi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1005.3185v1",
    "title": "Dynamical issues in interactive representation of physical objects",
    "summary": "The quality of a simulator equipped with a haptic interface is given by the\ndynamical properties of its components: haptic interface, simulator and control\nsystem. Some application areas of such kind of simulator like musical\nsynthesis, animation or more general, instrumental art have specific\nrequirements as for the \"haptic rendering\" of small movements that go beyond\nthe usual haptic interfaces allow. Object properties variability and different\nsituations of object combination represent important aspects of such type of\napplication which makes that the user can be interested as much in the\nrestitution of certain global properties of an entire object domain as in the\nrestitution of properties that are specific to an isolate object. In the\ntraditional approaches, the usual criteria are founded on the paradigm of\ntransparency and are related to the impedance error introduced by the technical\naspects of the system. As a general aim, rather than to minimize these effects,\nwe look to characterize them by physical metaphors conferring to haptic medium\nthe role of a tool. This positioning leads to firstly analyze the natural human\nobject interaction as a simplified evolutive system and then considers its\nsynthesis in the case of the interactive physical simulation. By means of a\nfrequential method, this approach is presented for some elementary\nconfigurations of the simulator",
    "published": "2010-05-18T13:08:00Z",
    "link": "http://arxiv.org/pdf/1005.3185v1.pdf",
    "category": [
      "cs.GR",
      "cs.HC",
      "cs.RO"
    ],
    "authors": [
      "Jean-Loup Florens",
      "Alina Voda",
      "Daniela Urma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1005.3190v1",
    "title": "From granular avalanches to fluid turbulences through oozing pastes. A\n  mesoscopic physically-based particle model",
    "summary": "In this paper, we describe how we can precisely produce complex and various\ndynamic morphological features such as structured and chaotic features which\noccur in sand pilings (piles, avalanches, internal collapses, arches) , in\nflowing fluids (laminar flowing, Kelvin-Helmholtz and Von Karmann eddies), and\nin cohesive pastes (twist-and-turn oozing and packing) using only a single\nunified model, called \"mesoscopic model\". This model is a physically-based\nparticle model whose behavior depends on only four simple, but easy to\nunderstand, physically-based parameters : elasticity, viscosity and their local\nareas of influence. It is fast to compute and easy to understand by\nnon-physicist users.",
    "published": "2010-05-18T13:10:28Z",
    "link": "http://arxiv.org/pdf/1005.3190v1.pdf",
    "category": [
      "cs.GR",
      "physics.comp-ph"
    ],
    "authors": [
      "Annie Luciani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1005.4405v1",
    "title": "A physically-based particle model of emergent crowd behaviors",
    "summary": "This paper presents a modeling process in order to produce a realistic\nsimulation of crowds in the ancient Greek agora of Argos. This place was a\nsocial theater in which two kinds of collective phenomena took place:\ninterpersonal interactions (small group discussion and negotiation, etc.) and\nglobal collective phenomena, such as flowing and jamming. In this paper, we\nfocus on the second type of collective human phenomena, called non-deliberative\nemergent crowd phenomena. This is a typical case of collective emergent\nself-organization. When a great number of individuals move within a confined\nenvironment and under a common fate, collective structures appear\nspontaneously: jamming with inner collapses, organized flowing with queues,\ncurls, and vortices, propagation effects, etc. These are particularly relevant\nfeatures to enhance the realism - more precisely the \"truthfulness\" - of models\nof this kind of collective phenomena. We assume that this truthfulness is\nstrongly associated with the concept of emergence: evolutions are not\npredetermined by the individual characters, but emerge from the interaction of\nnumerous characters. The evolutions are not repetitive, and evolve on the basis\nof small changes. This paper demonstrates that the physically-based interacting\nparticles system is an adequate candidate to model emergent crowd effects: it\nassociates a large number of elementary dynamic actors via elementary\nnon-linear dynamic interactions. Our model of the scene is regulated as a\nlarge, dynamically coupled network of second order differential automata. We\ntake advantage of symbolic non-photorealistic and efficient visualization to\nrender the style of the person, rather than the person itself. As an artistic\nrepresentation, NPR reinforces the symbolic acceptance of the scene by the\nobserver, triggering an immediate and intuitive recognition of the scene as a\nplausible scene from ancient Greece.",
    "published": "2010-05-19T06:37:24Z",
    "link": "http://arxiv.org/pdf/1005.4405v1.pdf",
    "category": [
      "cs.GR",
      "physics.comp-ph"
    ],
    "authors": [
      "Laure Hegeas",
      "Annie Luciani",
      "Jolle Thollot",
      "Nicolas Castagn"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1005.3992v2",
    "title": "Groebner bases in Java with applications in computer graphics",
    "summary": "In this paper we present a Java implementation of the algorithm that computes\nBuchbereger's and reduced Groebner's basis step by step. The Java application\nenables graphical representation of the intersection of two surfaces in\n3-dimensional space and determines conditions of existence and planarity of the\nintersection.",
    "published": "2010-05-19T11:26:36Z",
    "link": "http://arxiv.org/pdf/1005.3992v2.pdf",
    "category": [
      "cs.MS",
      "cs.GR",
      "math.MG",
      "math.RA"
    ],
    "authors": [
      "Branko J. Malesevic",
      "Ivana V. Jovovic",
      "Milan Z. Campara"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1005.4563v1",
    "title": "Physically-based particle simulation and visualization of pastes and\n  gels",
    "summary": "This paper is focused on the question of simulation and visualiza- tion of 3D\ngel and paste dynamic effects. In a first part, we introduce a 3D physically\nbased particle (or mass-interaction) model, with a small number of masses and\nfew powerful interaction parameters, which is able to generate the dynamic\nfeatures of both gels and pastes. This model proves that the 3D\nmass-interaction method is relevant for the simulation of such phenomena,\nwithout an explicit knowledge of their underly- ing physics. In a second part,\nwe expose an original rendering process, the Flow Structuring Method that\nenhances the dynamic properties of the simulation and offers a realistic\nvisualization. This process ignores all the properties of the underlying\nphysical model. It leads to a reconstruction of the spatial structure of the\ngel (or paste) flow only through an analysis of the output of the simula- tion\nwhich is a set of unorganized points moving in a 3D space. Finally, the paper\npresents realistic renderings obtained by using implicit surfaces and\nray-tracing techniques on the Structured Flow previously obtained.",
    "published": "2010-05-25T13:14:11Z",
    "link": "http://arxiv.org/pdf/1005.4563v1.pdf",
    "category": [
      "cs.GR",
      "physics.comp-ph"
    ],
    "authors": [
      "Claire Guilbaud",
      "Annie Luciani",
      "Nicolas Castagn"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1006.2368v1",
    "title": "L2-optimal image interpolation and its applications to medical imaging",
    "summary": "Digital medical images are always displayed scaled to fit particular view.\nInterpolation is responsible for this scaling, and if not done properly, can\nsignificantly degrade diagnostic image quality. However, theoretically-optimal\ninterpolation algorithms may also be the most time-consuming and impractical.\nWe propose a new approach, adapted to the needs of digital medical imaging, to\ncombine high interpolation speed and superior L2-optimal image quality.",
    "published": "2010-06-11T19:05:05Z",
    "link": "http://arxiv.org/pdf/1006.2368v1.pdf",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "Oleg Pianykh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1006.3661v1",
    "title": "Fractal Basins and Boundaries in 2D Maps inspired in Discrete Population\n  Models",
    "summary": "Two-dimensional maps can model interactions between populations. Despite\ntheir simplicity, these dynamical systems can show some complex situations, as\nmultistability or fractal boundaries between basins that lead to remarkable\npictures. Some of them are shown and explained here for three different 2D\ndiscrete models.",
    "published": "2010-06-18T10:40:23Z",
    "link": "http://arxiv.org/pdf/1006.3661v1.pdf",
    "category": [
      "nlin.CD",
      "cs.GR",
      "math.DS"
    ],
    "authors": [
      "Daniele Fournier-Prunaret",
      "Ricardo Lopez-Ruiz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1006.4903v2",
    "title": "Toric degenerations of Bezier patches",
    "summary": "The control polygon of a Bezier curve is well-defined and has geometric\nsignificance---there is a sequence of weights under which the limiting position\nof the curve is the control polygon. For a Bezier surface patch, there are many\npossible polyhedral control structures, and none are canonical. We propose a\nnot necessarily polyhedral control structure for surface patches, regular\ncontrol surfaces, which are certain C^0 spline surfaces. While not unique,\nregular control surfaces are exactly the possible limiting positions of a\nBezier patch when the weights are allowed to vary.",
    "published": "2010-06-25T03:11:37Z",
    "link": "http://arxiv.org/pdf/1006.4903v2.pdf",
    "category": [
      "cs.GR",
      "math.AG",
      "65D17, 14M25",
      "I.3.5"
    ],
    "authors": [
      "Luis David Garcia-Puente",
      "Frank Sottile",
      "Chungang Zhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1007.2204v1",
    "title": "What's wrong with Phong - Designers' appraisal of shading in CAD-systems",
    "summary": "The Phong illumination model is still widely used in realtime 3D\nvisualization systems. The aim of this article is to document problems with the\nPhong illumination model that are encountered by an important professional user\ngroup, namely digital designers. This leads to a visual evaluation of Phong\nillumination, which at least in this condensed form seems still to be missing\nin the literature. It is hoped that by explicating these flaws, awareness about\nthe limitations and interdependencies of the model will increase, both among\nfellow users, and among researchers and developers.",
    "published": "2010-07-13T21:09:11Z",
    "link": "http://arxiv.org/pdf/1007.2204v1.pdf",
    "category": [
      "cs.GR",
      "I.3.7; J.6"
    ],
    "authors": [
      "Jrg M. Hahn"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1007.3726v1",
    "title": "Multi-GPU Accelerated Multi-Spin Monte Carlo Simulations of the 2D Ising\n  Model",
    "summary": "A modern graphics processing unit (GPU) is able to perform massively parallel\nscientific computations at low cost. We extend our implementation of the\ncheckerboard algorithm for the two dimensional Ising model [T. Preis et al., J.\nComp. Phys. 228, 4468 (2009)] in order to overcome the memory limitations of a\nsingle GPU which enables us to simulate significantly larger systems. Using\nmulti-spin coding techniques, we are able to accelerate simulations on a single\nGPU by factors up to 35 compared to an optimized single Central Processor Unit\n(CPU) core implementation which employs multi-spin coding. By combining the\nCompute Unified Device Architecture (CUDA) with the Message Parsing Interface\n(MPI) on the CPU level, a single Ising lattice can be updated by a cluster of\nGPUs in parallel. For large systems, the computation time scales nearly\nlinearly with the number of GPUs used. As proof of concept we reproduce the\ncritical temperature of the 2D Ising model using finite size scaling\ntechniques.",
    "published": "2010-07-21T19:30:57Z",
    "link": "http://arxiv.org/pdf/1007.3726v1.pdf",
    "category": [
      "physics.comp-ph",
      "cs.GR",
      "math-ph",
      "math.MP"
    ],
    "authors": [
      "Benjamin Block",
      "Peter Virnau",
      "Tobias Preis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1008.0208v2",
    "title": "Parametric polynomial minimal surfaces of arbitrary degree",
    "summary": "Weierstrass representation is a classical parameterization of minimal\nsurfaces. However, two functions should be specified to construct the\nparametric form in Weierestrass representation. In this paper, we propose an\nexplicit parametric form for a class of parametric polynomial minimal surfaces\nof arbitrary degree. It includes the classical Enneper surface for cubic case.\nThe proposed minimal surfaces also have some interesting properties such as\nsymmetry, containing straight lines and self-intersections. According to the\nshape properties, the proposed minimal surface can be classified into four\ncategories with respect to $n=4k-1$ $n=4k+1$, $n=4k$ and $n=4k+2$. The explicit\nparametric form of corresponding conjugate minimal surfaces is given and the\nisometric deformation is also implemented.",
    "published": "2010-08-01T22:58:04Z",
    "link": "http://arxiv.org/pdf/1008.0208v2.pdf",
    "category": [
      "cs.GR",
      "math.DG"
    ],
    "authors": [
      "Gang Xu",
      "Guozhao Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1008.1188v1",
    "title": "Data visualization in political and social sciences",
    "summary": "The basic objective of data visualization is to provide an efficient\ngraphical display for summarizing and reasoning about quantitative information.\nDuring the last decades, political science has accumulated a large corpus of\nvarious kinds of data such as comprehensive factbooks and atlases,\ncharacterizing all or most of existing states by multiple and objectively\nassessed numerical indicators within certain time lapse. As a consequence,\nthere exists a continuous trend for political science to gradually become a\nmore quantitative scientific field and to use quantitative information in the\nanalysis and reasoning. It is believed that any objective analysis in political\nscience must be multidimensional and combine various sources of quantitative\ninformation; however, human capabilities for perception of large massifs of\nnumerical information are limited. Hence, methods and approaches for\nvisualization of quantitative and qualitative data (and, especially\nmultivariate data) is an extremely important topic. Data visualization\napproaches can be classified into several groups, starting from creating\ninformative charts and diagrams (statistical graphics and infographics) and\nending with advanced statistical methods for visualizing multidimensional\ntables containing both quantitative and qualitative information. In this\narticle we provide a short review of existing methods of data visualization\nmethods with applications in political and social science.",
    "published": "2010-08-06T13:29:11Z",
    "link": "http://arxiv.org/pdf/1008.1188v1.pdf",
    "category": [
      "cs.GR",
      "cs.CE",
      "cs.CY",
      "00A66",
      "J.4"
    ],
    "authors": [
      "Andrei Zinovyev"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1008.1664v1",
    "title": "L-systems in Geometric Modeling",
    "summary": "We show that parametric context-sensitive L-systems with affine geometry\ninterpretation provide a succinct description of some of the most fundamental\nalgorithms of geometric modeling of curves. Examples include the\nLane-Riesenfeld algorithm for generating B-splines, the de Casteljau algorithm\nfor generating Bezier curves, and their extensions to rational curves. Our\nresults generalize the previously reported geometric-modeling applications of\nL-systems, which were limited to subdivision curves.",
    "published": "2010-08-10T08:34:46Z",
    "link": "http://arxiv.org/pdf/1008.1664v1.pdf",
    "category": [
      "cs.GR",
      "cs.FL"
    ],
    "authors": [
      "Przemyslaw Prusinkiewicz",
      "Mitra Shirmohammadi",
      "Faramarz Samavati"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1008.2205v3",
    "title": "Viewpoints: A high-performance high-dimensional exploratory data\n  analysis tool",
    "summary": "Scientific data sets continue to increase in both size and complexity. In the\npast, dedicated graphics systems at supercomputing centers were required to\nvisualize large data sets, but as the price of commodity graphics hardware has\ndropped and its capability has increased, it is now possible, in principle, to\nview large complex data sets on a single workstation. To do this in practice,\nan investigator will need software that is written to take advantage of the\nrelevant graphics hardware. The Viewpoints visualization package described\nherein is an example of such software. Viewpoints is an interactive tool for\nexploratory visual analysis of large, high-dimensional (multivariate) data. It\nleverages the capabilities of modern graphics boards (GPUs) to run on a single\nworkstation or laptop. Viewpoints is minimalist: it attempts to do a small set\nof useful things very well (or at least very quickly) in comparison with\nsimilar packages today. Its basic feature set includes linked scatter plots\nwith brushing, dynamic histograms, normalization and outlier detection/removal.\nViewpoints was originally designed for astrophysicists, but it has since been\nused in a variety of fields that range from astronomy, quantum chemistry, fluid\ndynamics, machine learning, bioinformatics, and finance to information\ntechnology server log mining. In this article, we describe the Viewpoints\npackage and show examples of its usage.",
    "published": "2010-08-12T20:00:28Z",
    "link": "http://arxiv.org/pdf/1008.2205v3.pdf",
    "category": [
      "astro-ph.IM",
      "cs.GR",
      "physics.data-an"
    ],
    "authors": [
      "P. R. Gazis",
      "C. Levit",
      "M. J. Way"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1008.2819v1",
    "title": "A symmetric motion picture of the twist-spun trefoil",
    "summary": "With the aid of a computer, we provide a motion picture of the twist-spun\ntrefoil which exhibits the periodicity well.",
    "published": "2010-08-17T05:04:20Z",
    "link": "http://arxiv.org/pdf/1008.2819v1.pdf",
    "category": [
      "math.GT",
      "cs.GR",
      "Primary 57Q45, Secondary 68U05, 68U07"
    ],
    "authors": [
      "Ayumu Inoue"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1009.2231v2",
    "title": "Symbolic landforms created by ancient earthworks near Lake Titicaca",
    "summary": "Interesting landforms created by an ancient network of earthworks are shown,\nusing Google satellite imagery enhanced by an image processing. This network\ncovers a large part of the land near the Titicaca Lake. Satellite images\nclearly display the slopes of hills criss-crossed with terrace walls and the\nsurfaces of the plains covered with raised fields, indicating that this was\nonce a highly productive agricultural place for the south central Andes. Some\nof the landforms are rather remarkable, having a clear symbolic function. Among\nthem, there are structures which seem to represent birds, where ponds are their\neyes.",
    "published": "2010-09-12T11:56:13Z",
    "link": "http://arxiv.org/pdf/1009.2231v2.pdf",
    "category": [
      "physics.geo-ph",
      "cs.GR"
    ],
    "authors": [
      "Amelia Carolina Sparavigna"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1009.4602v1",
    "title": "Geoglyphs of Titicaca as an ancient example of graphic design",
    "summary": "The paper proposes an ancient landscape design as an example of graphic\ndesign for an age and place where no written documents existed. It is created\nby a network of earthworks, which constitute the remains of an extensive\nancient agricultural system. It can be seen by means of the Google satellite\nimagery on the Peruvian region near the Titicaca Lake, as a texture\nsuperimposed to the background landform. In this texture, many drawings\n(geoglyphs) can be observed.",
    "published": "2010-09-23T13:08:32Z",
    "link": "http://arxiv.org/pdf/1009.4602v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Amelia Carolina Sparavigna"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1009.4674v3",
    "title": "Intuitive representation of surface properties of biomolecules using\n  BioBlender",
    "summary": "In this and the associated article 'BioBlender: Fast and Efficient All Atom\nMorphing of Proteins Using Blender Game Engine', by Zini et al., we present\nBioBlender, a complete instrument for the elaboration of motion (Zini et al.)\nand the visualization (here) of proteins and other macromolecules, using\ninstruments of computer graphics. The availability of protein structures\nenables the study of their surfaces and surface properties such as\nelectrostatic potential (EP) and hydropathy (MLP), based on atomic\ncontribution. Recent advances in 3D animation and rendering software have not\nyet been exploited for the representation of proteins and other biological\nmolecules in an intuitive, animated form. Taking advantage of an open-source,\n3D animation and rendering software, Blender, we developed BioBlender, a\npackage dedicated to biological work: elaboration of proteins' motions with the\nsimultaneous visualization of chemical and physical features. EP and MLP are\ncalculated using physico-chemical programs and custom programs and scripts,\norganized and accessed within BioBlender interface. A new visual code is\nintroduced for MLP visualization: a range of optical features that permits a\nphotorealistic rendering of its spatial distribution on the surface of the\nprotein. EP is represented as animated line particles that flow along field\nlines proportional to the total charge of the protein. Our system permits EP\nand MLP visualization of molecules and, in the case of moving proteins, the\ncontinuous perception of these features, calculated for each intermediate\nconformation. Using real world tactile/sight feelings, the nanoscale world of\nproteins becomes more understandable, familiar to our everyday life, making it\neasier to introduce \"un-seen\" phenomena (concepts) such as hydropathy or\ncharges.",
    "published": "2010-09-23T18:19:43Z",
    "link": "http://arxiv.org/pdf/1009.4674v3.pdf",
    "category": [
      "q-bio.BM",
      "cs.GR"
    ],
    "authors": [
      "Raluca Mihaela Andrei",
      "Marco Callieri",
      "Maria Francesca Zini",
      "Tiziana Loni",
      "Giuseppe Maraziti",
      "Mike Chen Pan",
      "Monica Zopp"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1009.5183v1",
    "title": "A Framework for an Ego-centered and Time-aware Visualization of\n  Relations in Arbitrary Data Repositories",
    "summary": "Understanding constellations in large data collections has become a common\ntask. One obstacle a user has to overcome is the internal complexity of these\nrepositories. For example, extracting connected data from a normalized\nrelational database requires knowledge of the table structure which might not\nbe available for the casual user. In this paper we present a visualization\nframework which presents the collection as a set of entities and relations (on\nthe data level). Using rating functions, we divide large relation networks into\nsmall graphs which resemble ego-centered networks. These graphs are connected\nso the user can browse from one to another. To further assist the user, we\npresent two views which embed information on the evolution of the relations\ninto the graphs. Each view emphasizes another aspect of temporal development.\nThe framework can be adapted to any repository by a flexible data interface and\na graph configuration file. We present some first web-based applications\nincluding a visualization of the DBLP data set. We use the DBLP visualization\nto evaluate our approach.",
    "published": "2010-09-27T08:16:36Z",
    "link": "http://arxiv.org/pdf/1009.5183v1.pdf",
    "category": [
      "cs.GR",
      "cs.DL"
    ],
    "authors": [
      "Florian Reitz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1009.5423v2",
    "title": "The Need to Support of Data Flow Graph Visualization of Forensic Lucid\n  Programs, Forensic Evidence, and their Evaluation by GIPSY",
    "summary": "Lucid programs are data-flow programs and can be visually represented as data\nflow graphs (DFGs) and composed visually. Forensic Lucid, a Lucid dialect, is a\nlanguage to specify and reason about cyberforensic cases. It includes the\nencoding of the evidence (representing the context of evaluation) and the crime\nscene modeling in order to validate claims against the model and perform event\nreconstruction, potentially within large swaths of digital evidence. To aid\ninvestigators to model the scene and evaluate it, instead of typing a Forensic\nLucid program, we propose to expand the design and implementation of the Lucid\nDFG programming onto Forensic Lucid case modeling and specification to enhance\nthe usability of the language and the system and its behavior. We briefly\ndiscuss the related work on visual programming an DFG modeling in an attempt to\ndefine and select one approach or a composition of approaches for Forensic\nLucid based on various criteria such as previous implementation, wide use,\nformal backing in terms of semantics and translation. In the end, we solicit\nthe readers' constructive, opinions, feedback, comments, and recommendations\nwithin the context of this short discussion.",
    "published": "2010-09-28T01:30:40Z",
    "link": "http://arxiv.org/pdf/1009.5423v2.pdf",
    "category": [
      "cs.PL",
      "cs.CR",
      "cs.GR",
      "D.1.7; D.2.11; D.3.2; D.3.4"
    ],
    "authors": [
      "Serguei A. Mokhov",
      "Joey Paquet",
      "Mourad Debbabi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1010.0552v2",
    "title": "Inaccessibility-Inside Theorem for Point in Polygon",
    "summary": "The manuscript presents a theoretical proof in conglomeration with new\ndefinitions on Inaccessibility and Inside for a point S related to a simple or\nself intersecting polygon P. The proposed analytical solution depicts a novel\nway of solving the point in polygon problem by employing the properties of\nepigraphs and hypographs, explicitly. Contrary to the ambiguous solutions given\nby the cross over for the simple and self intersecting polygons and the\nsolution of a point being multiply inside a self intersecting polygon given by\nthe winding number rule, the current solution gives unambiguous and singular\nresult for both kinds of polygons. Finally, the current theoretical solution\nproves to be mathematically correct for simple and self intersecting polygons.",
    "published": "2010-10-04T11:49:35Z",
    "link": "http://arxiv.org/pdf/1010.0552v2.pdf",
    "category": [
      "cs.CG",
      "cs.GR"
    ],
    "authors": [
      "Shriprakash Sinha",
      "Luca Nanetti"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1010.2623v2",
    "title": "Surface Curvature Effects on Reflectance from Translucent Materials",
    "summary": "Most of the physically based techniques for rendering translucent objects use\nthe diffusion theory of light scattering in turbid media. The widely used\ndipole diffusion model (Jensen et al. 2001) applies the diffusion-theory\nformula derived for a planar interface to objects of arbitrary shapes. This\npaper presents first results of our investigation of how surface curvature\naffects the diffuse reflectance from translucent materials.",
    "published": "2010-10-13T10:35:23Z",
    "link": "http://arxiv.org/pdf/1010.2623v2.pdf",
    "category": [
      "cs.GR",
      "physics.optics",
      "I.4.1; I.4.8"
    ],
    "authors": [
      "Konstantin Kolchin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1011.0093v1",
    "title": "Fast Color Quantization Using Weighted Sort-Means Clustering",
    "summary": "Color quantization is an important operation with numerous applications in\ngraphics and image processing. Most quantization methods are essentially based\non data clustering algorithms. However, despite its popularity as a general\npurpose clustering algorithm, k-means has not received much respect in the\ncolor quantization literature because of its high computational requirements\nand sensitivity to initialization. In this paper, a fast color quantization\nmethod based on k-means is presented. The method involves several modifications\nto the conventional (batch) k-means algorithm including data reduction, sample\nweighting, and the use of triangle inequality to speed up the nearest neighbor\nsearch. Experiments on a diverse set of images demonstrate that, with the\nproposed modifications, k-means becomes very competitive with state-of-the-art\ncolor quantization methods in terms of both effectiveness and efficiency.",
    "published": "2010-10-30T16:56:17Z",
    "link": "http://arxiv.org/pdf/1011.0093v1.pdf",
    "category": [
      "cs.CV",
      "cs.GR",
      "I.4.1"
    ],
    "authors": [
      "M. Emre Celebi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1011.1787v4",
    "title": "Volume-Enclosing Surface Extraction",
    "summary": "In this paper we present a new method, which allows for the construction of\ntriangular isosurfaces from three-dimensional data sets, such as 3D image data\nand/or numerical simulation data that are based on regularly shaped, cubic\nlattices. This novel volume-enclosing surface extraction technique, which has\nbeen named VESTA, can produce up to six different results due to the nature of\nthe discretized 3D space under consideration. VESTA is neither template-based\nnor it is necessarily required to operate on 2x2x2 voxel cell neighborhoods\nonly. The surface tiles are determined with a very fast and robust construction\ntechnique while potential ambiguities are detected and resolved. Here, we\nprovide an in-depth comparison between VESTA and various versions of the\nwell-known and very popular Marching Cubes algorithm for the very first time.\nIn an application section, we demonstrate the extraction of VESTA isosurfaces\nfor various data sets ranging from computer tomographic scan data to simulation\ndata of relativistic hydrodynamic fireball expansions.",
    "published": "2010-11-01T08:53:59Z",
    "link": "http://arxiv.org/pdf/1011.1787v4.pdf",
    "category": [
      "cs.CG",
      "cs.GR",
      "nucl-th"
    ],
    "authors": [
      "B. R. Schlei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1011.3189v5",
    "title": "Warping Peirce Quincuncial Panoramas",
    "summary": "The Peirce quincuncial projection is a mapping of the surface of a sphere to\nthe interior of a square. It is a conformal map except for four points on the\nequator. These points of non-conformality cause significant artifacts in\nphotographic applications. In this paper, we propose an algorithm and\nuser-interface to mitigate these artifacts. Moreover, in order to facilitate an\ninteractive user-interface, we present a fast algorithm for calculating the\nPeirce quincuncial projection of spherical imagery. We then promote the Peirce\nquincuncial projection as a viable alternative to the more popular\nstereographic projection in some scenarios.",
    "published": "2010-11-14T07:53:26Z",
    "link": "http://arxiv.org/pdf/1011.3189v5.pdf",
    "category": [
      "cs.CV",
      "cs.GR",
      "eess.IV"
    ],
    "authors": [
      "Chamberlain Fong",
      "Brian K. Vogel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1011.3583v1",
    "title": "Fast GPGPU Data Rearrangement Kernels using CUDA",
    "summary": "Many high performance-computing algorithms are bandwidth limited, hence the\nneed for optimal data rearrangement kernels as well as their easy integration\ninto the rest of the application. In this work, we have built a CUDA library of\nfast kernels for a set of data rearrangement operations. In particular, we have\nbuilt generic kernels for rearranging m dimensional data into n dimensions,\nincluding Permute, Reorder, Interlace/De-interlace, etc. We have also built\nkernels for generic Stencil computations on a two-dimensional data using\ntemplates and functors that allow application developers to rapidly build\ncustomized high performance kernels. All the kernels built achieve or surpass\nbest-known performance in terms of bandwidth utilization.",
    "published": "2010-11-16T04:38:53Z",
    "link": "http://arxiv.org/pdf/1011.3583v1.pdf",
    "category": [
      "cs.DC",
      "cs.GR",
      "cs.PF"
    ],
    "authors": [
      "Michael Bader",
      "Hans-Joachim Bungartz",
      "Dheevatsa Mudigere",
      "Srihari Narasimhan",
      "Babu Narayanan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1011.6049v1",
    "title": "Video Stippling",
    "summary": "In this paper, we consider rendering color videos using a non-photo-realistic\nart form technique commonly called stippling. Stippling is the art of rendering\nimages using point sets, possibly with various attributes like sizes,\nelementary shapes, and colors. Producing nice stippling is attractive not only\nfor the sake of image depiction but also because it yields a compact vectorial\nformat for storing the semantic information of media. Moreover, stippling is by\nconstruction easily tunable to various device resolutions without suffering\nfrom bitmap sampling artifacts when resizing. The underlying core technique for\nstippling images is to compute a centroidal Voronoi tessellation on a\nwell-designed underlying density. This density relates to the image content,\nand is used to compute a weighted Voronoi diagram. By considering videos as\nimage sequences and initializing properly the stippling of one image by the\nresult of its predecessor, one avoids undesirable point flickering artifacts\nand can produce stippled videos that nevertheless still exhibit noticeable\nartifacts. To overcome this, our method improves over the naive scheme by\nconsidering dynamic point creation and deletion according to the current scene\nsemantic complexity, and show how to effectively vectorize video while\nadjusting for both color and contrast characteristics. Furthermore, we explain\nhow to produce high quality stippled ``videos'' (eg., fully dynamic\nspatio-temporal point sets) for media containing various fading effects, like\nquick motions of objects or progressive shot changes. We report on practical\nperformances of our implementation, and present several stippled video results\nrendered on-the-fly using our viewer that allows both spatio-temporal dynamic\nrescaling (eg., upscale vectorially frame rate).",
    "published": "2010-11-28T15:04:34Z",
    "link": "http://arxiv.org/pdf/1011.6049v1.pdf",
    "category": [
      "cs.GR",
      "cs.CG"
    ],
    "authors": [
      "Thomas Houit",
      "Frank Nielsen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1012.0467v1",
    "title": "MT4j - A Cross-platform Multi-touch Development Framework",
    "summary": "This article describes requirements and challenges of crossplatform\nmulti-touch software engineering, and presents the open source framework\nMulti-Touch for Java (MT4j) as a solution. MT4j is designed for rapid\ndevelopment of graphically rich applications on a variety of contemporary\nhardware, from common PCs and notebooks to large-scale ambient displays, as\nwell as different operating systems. The framework has a special focus on\nmaking multi-touch software development easier and more efficient. Architecture\nand abstractions used by MT4j are described, and implementations of several\ncommon use cases are presented.",
    "published": "2010-12-02T16:01:21Z",
    "link": "http://arxiv.org/pdf/1012.0467v1.pdf",
    "category": [
      "cs.HC",
      "cs.GR",
      "H.5.2; D.2.11; D.2.7"
    ],
    "authors": [
      "Uwe Laufs",
      "Christopher Ruff",
      "Jan Zibuschka"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1101.1240v1",
    "title": "Chameleon: A Color-Adaptive Web Browser for Mobile OLED Displays",
    "summary": "Displays based on organic light-emitting diode (OLED) technology are\nappearing on many mobile devices. Unlike liquid crystal displays (LCD), OLED\ndisplays consume dramatically different power for showing different colors. In\nparticular, OLED displays are inefficient for showing bright colors. This has\nmade them undesirable for mobile devices because much of the web content is of\nbright colors.\n  To tackle this problem, we present the motivational studies, design, and\nrealization of Chameleon, a color adaptive web browser that renders web pages\nwith power-optimized color schemes under user-supplied constraints. Driven by\nthe findings from our motivational studies, Chameleon provides end users with\nimportant options, offloads tasks that are not absolutely needed in real-time,\nand accomplishes real-time tasks by carefully enhancing the codebase of a\nbrowser engine. According to measure-ments with OLED smartphones, Chameleon is\nable to re-duce average system power consumption for web browsing by 41% and\nreduce display power consumption by 64% without introducing any noticeable\ndelay.",
    "published": "2010-12-13T18:45:13Z",
    "link": "http://arxiv.org/pdf/1101.1240v1.pdf",
    "category": [
      "cs.GR",
      "cs.HC"
    ],
    "authors": [
      "Mian Dong",
      "Lin Zhong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1012.3057v2",
    "title": "Speeding Up the 3D Surface Generator VESTA",
    "summary": "The very recent volume-enclosing surface extraction algorithm, VESTA, is\nrevisited. VESTA is used to determine implicit surfaces that are potentially\ncontained in 3D data sets, such as 3D image data and/or 3D simulation data.\nVESTA surfaces are non-degenerate, i.e., they always enclose a volume that is\nlarger than zero and they never self-intersect, prior to a further processing,\ne.g., towards isosurfaces. In addition to its ability to deal with local cell\nambiguities consistently - and thereby avoiding the accidental generation of\nholes in the final surfaces - the information of the interior and/or exterior\nof enclosed 3D volumes is propagated correctly to each of the final surface\ntiles. Particular emphasis is put here on the speed up of the original\nformulation of VESTA, while applying the algorithm to 2x2x2 voxel\nneighborhoods.",
    "published": "2010-12-14T15:24:04Z",
    "link": "http://arxiv.org/pdf/1012.3057v2.pdf",
    "category": [
      "cs.CG",
      "cs.GR"
    ],
    "authors": [
      "B. R. Schlei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1012.3359v2",
    "title": "Curve Reconstruction in Riemannian Manifolds: Ordering Motion Frames",
    "summary": "In this article we extend the computational geometric curve reconstruction\napproach to curves in Riemannian manifolds. We prove that the minimal spanning\ntree, given a sufficiently dense sample, correctly reconstructs the smooth arcs\nand further closed and simple curves in Riemannian manifolds. The proof is\nbased on the behaviour of the curve segment inside the tubular neighbourhood of\nthe curve. To take care of the local topological changes of the manifold, the\ntubular neighbourhood is constructed in consideration with the injectivity\nradius of the underlying Riemannian manifold. We also present examples of\nsuccessfully reconstructed curves and show an applications of curve\nreconstruction to ordering motion frames.",
    "published": "2010-12-15T15:28:37Z",
    "link": "http://arxiv.org/pdf/1012.3359v2.pdf",
    "category": [
      "cs.CG",
      "cs.GR",
      "cs.RO",
      "math.DG"
    ],
    "authors": [
      "Pratik Shah",
      "Samaresh Chatterji"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1101.0243v1",
    "title": "Across Browsers SVG Implementation",
    "summary": "In this work SVG will be translated into VML or HTML by using Javascript\nbased on Backbase Client Framework. The target of this project is to implement\nSVG to be viewed in Internet Explorer without any plug-in and work together\nwith other Backbase Client Framework languages. The result of this project will\nbe added as an extension to the current Backbase Client Framework.",
    "published": "2010-12-31T12:30:34Z",
    "link": "http://arxiv.org/pdf/1101.0243v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Liang Wang",
      "Nies Huijsmans",
      "Michael S. Lew",
      "Dan Tsymbala"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1101.0262v1",
    "title": "High Speed and Area Efficient 2D DWT Processor based Image Compression\"\n  Signal & Image Processing",
    "summary": "This paper presents a high speed and area efficient DWT processor based\ndesign for Image Compression applications. In this proposed design, pipelined\npartially serial architecture has been used to enhance the speed along with\noptimal utilization and resources available on target FPGA. The proposed model\nhas been designed and simulated using Simulink and System Generator blocks,\nsynthesized with Xilinx Synthesis tool (XST) and implemented on Spartan 2 and 3\nbased XC2S100-5tq144 and XC3S500E-4fg320 target device. The results show that\nproposed design can operate at maximum frequency 231 MHz in case of Spartan 3\nby consuming power of 117mW at 28 degree/c junction temperature. The result\ncomparison has shown an improvement of 15% in speed.",
    "published": "2010-12-31T14:34:06Z",
    "link": "http://arxiv.org/pdf/1101.0262v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Sugreev Kaur",
      "Rajesh Mehra"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1101.0301v1",
    "title": "Specular holography",
    "summary": "By tooling an spot-illuminated surface to control the flow of specular glints\nunder motion, one can produce holographic view-dependent imagery. This paper\npresents the differential equation that governs the shape of the specular\nsurfaces, and illustrates how solutions can be constructed for different kinds\nof motion, lighting, host surface geometries, and fabrication constraints,\nleading to some novel forms of holography.",
    "published": "2010-12-31T21:23:11Z",
    "link": "http://arxiv.org/pdf/1101.0301v1.pdf",
    "category": [
      "cs.GR",
      "cs.CG",
      "physics.optics"
    ],
    "authors": [
      "Matthew Brand"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1101.0395v1",
    "title": "Improving the Performance of K-Means for Color Quantization",
    "summary": "Color quantization is an important operation with many applications in\ngraphics and image processing. Most quantization methods are essentially based\non data clustering algorithms. However, despite its popularity as a general\npurpose clustering algorithm, k-means has not received much respect in the\ncolor quantization literature because of its high computational requirements\nand sensitivity to initialization. In this paper, we investigate the\nperformance of k-means as a color quantizer. We implement fast and exact\nvariants of k-means with several initialization schemes and then compare the\nresulting quantizers to some of the most popular quantizers in the literature.\nExperiments on a diverse set of images demonstrate that an efficient\nimplementation of k-means with an appropriate initialization strategy can in\nfact serve as a very effective color quantizer.",
    "published": "2011-01-02T10:09:11Z",
    "link": "http://arxiv.org/pdf/1101.0395v1.pdf",
    "category": [
      "cs.GR",
      "I.4.1"
    ],
    "authors": [
      "M. Emre Celebi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1101.0663v1",
    "title": "The Role of Computer Graphics in Documentary Film Production",
    "summary": "We discuss a topic on the role of computer graphics in the production of\ndocumentaries, which is often ignored in favor of other topics. Typically,\nexcept for some rare occasions, documentary producers and computer scientists\nor digital artists that do computer graphics are relatively far apart in their\ndomains and rarely intercommunicate to have a joint production; yet it happens,\nand perhaps more so in the present and the future.\n  We attempt to classify the documentaries on the amount and techniques of\ncomputer graphics used for documentaries. We come up with the initial\ncategories such as \"plain\" (no graphics), \"in-between\", \"all-out\" -- nearly\n100% of the documentary consisting of computer-generated imagery. Computer\ngraphics can be used to enhance the scenery, fill in the gaps in the missing\nstoryline pieces, or animate between scenes. It can incorporate stereoscopic\neffects for higher viewer impression as well as interactivity aspects. It can\nalso be used simply in old archived image and film restoration.",
    "published": "2011-01-04T06:53:36Z",
    "link": "http://arxiv.org/pdf/1101.0663v1.pdf",
    "category": [
      "cs.GR",
      "cs.HC"
    ],
    "authors": [
      "Miao Song"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1101.5490v1",
    "title": "Ray-Based Reflectance Model for Diffraction",
    "summary": "We present a novel method of simulating wave effects in graphics using\nray--based renderers with a new function: the Wave BSDF (Bidirectional\nScattering Distribution Function). Reflections from neighboring surface patches\nrepresented by local BSDFs are mutually independent. However, in many surfaces\nwith wavelength-scale microstructures, interference and diffraction requires a\njoint analysis of reflected wavefronts from neighboring patches. We demonstrate\na simple method to compute the BSDF for the entire microstructure, which can be\nused independently for each patch. This allows us to use traditional ray--based\nrendering pipelines to synthesize wave effects of light and sound. We exploit\nthe Wigner Distribution Function (WDF) to create transmissive, reflective, and\nemissive BSDFs for various diffraction phenomena in a physically accurate way.\nIn contrast to previous methods for computing interference, we circumvent the\nneed to explicitly keep track of the phase of the wave by using BSDFs that\ninclude positive as well as negative coefficients. We describe and compare the\ntheory in relation to well understood concepts in rendering and demonstrate a\nstraightforward implementation. In conjunction with standard raytracers, such\nas PBRT, we demonstrate wave effects for a range of scenarios such as\nmulti--bounce diffraction materials, holograms and reflection of high frequency\nsurfaces.",
    "published": "2011-01-28T09:41:43Z",
    "link": "http://arxiv.org/pdf/1101.5490v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Tom Cuypers",
      "Se Baek Oh",
      "Tom Haber",
      "Philippe Bekaert",
      "Ramesh Raskar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1102.0200v3",
    "title": "Harmonic Functions for Data Reconstruction on 3D Manifolds",
    "summary": "In computer graphics, smooth data reconstruction on 2D or 3D manifolds\nusually refers to subdivision problems. Such a method is only valid based on\ndense sample points. The manifold usually needs to be triangulated into meshes\n(or patches) and each node on the mesh will have an initial value. While the\nmesh is refined the algorithm will provide a smooth function on the redefined\nmanifolds. However, when data points are not dense and the original mesh is not\nallowed to be changed, how is the \"continuous and/or smooth\" reconstruction\npossible? This paper will present a new method using harmonic functions to\nsolve the problem. Our method contains the following steps: (1) Partition the\nboundary surfaces of the 3D manifold based on sample points so that each sample\npoint is on the edge of the partition. (2) Use gradually varied interpolation\non the edges so that each point on edge will be assigned a value. In addition,\nall values on the edge are gradually varied. (3) Use discrete harmonic function\nto fit the unknown points, i.e. the points inside each partition patch.\n  The fitted function will be a harmonic or a local harmonic function in each\npartitioned area. The function on edge will be \"near\" continuous (or \"near\"\ngradually varied). If we need a smoothed surface on the manifold, we can apply\nsubdivision algorithms. This paper has also a philosophical advantage over\ntriangulation meshes. People usually use triangulation for data reconstruction.\nThis paper employs harmonic functions, a generalization of triangulation\nbecause linearity is a form of harmonic. Therefore, local harmonic\ninitialization is more sophisticated then triangulation. This paper is a\nconceptual and methodological paper. This paper does not focus on detailed\nmathematical analysis nor fine algorithm design.",
    "published": "2011-02-01T16:15:13Z",
    "link": "http://arxiv.org/pdf/1102.0200v3.pdf",
    "category": [
      "math.NA",
      "cs.GR"
    ],
    "authors": [
      "Li Chen",
      "Feng Luo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1102.0634v1",
    "title": "Glioblastoma Multiforme Segmentation in MRI Data with a Balloon\n  Inflation Approach",
    "summary": "Gliomas are the most common primary brain tumors, evolving from the cerebral\nsupportive cells. For clinical follow-up, the evaluation of the preoperative\ntumor volume is essential. Volumetric assessment of tumor volume with manual\nsegmentation of its outlines is a time-consuming process that can be overcome\nwith the help of computer-assisted segmentation methods. In this paper, a\nsemi-automatic approach for World Health Organization (WHO) grade IV glioma\nsegmentation is introduced that uses balloon inflation forces, and relies on\nthe detection of high-intensity tumor boundaries that are coupled by using\ncontrast agent gadolinium. The presented method is evaluated on 27 magnetic\nresonance imaging (MRI) data sets and the ground truth data of the tumor\nboundaries - for evaluation of the results - are manually extracted by\nneurosurgeons.",
    "published": "2011-02-03T10:00:15Z",
    "link": "http://arxiv.org/pdf/1102.0634v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Denan Zuki",
      "Jan Egger",
      "Miriam H. A. Bauer",
      "Daniela Kuhnt",
      "Barbara Carl",
      "Bernd Freisleben",
      "Andreas Kolb",
      "Christopher Nimsky"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1102.2652v1",
    "title": "Rule-based transformations for geometric modelling",
    "summary": "The context of this paper is the use of formal methods for topology-based\ngeometric modelling. Topology-based geometric modelling deals with objects of\nvarious dimensions and shapes. Usually, objects are defined by a graph-based\ntopological data structure and by an embedding that associates each topological\nelement (vertex, edge, face, etc.) with relevant data as their geometric shape\n(position, curve, surface, etc.) or application dedicated data (e.g. molecule\nconcentration level in a biological context). We propose to define\ntopology-based geometric objects as labelled graphs. The arc labelling defines\nthe topological structure of the object whose topological consistency is then\nensured by labelling constraints. Nodes have as many labels as there are\ndifferent data kinds in the embedding. Labelling constraints ensure then that\nthe embedding is consistent with the topological structure. Thus,\ntopology-based geometric objects constitute a particular subclass of a category\nof labelled graphs in which nodes have multiple labels.",
    "published": "2011-02-14T01:09:24Z",
    "link": "http://arxiv.org/pdf/1102.2652v1.pdf",
    "category": [
      "cs.GR",
      "cs.DM",
      "I.3.5; G.2.2"
    ],
    "authors": [
      "Thomas Bellet",
      "Agns Arnould",
      "Pascale Le Gall"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1102.3165v1",
    "title": "An Approximation Algorithm for Computing Shortest Paths in Weighted 3-d\n  Domains",
    "summary": "We present the first polynomial time approximation algorithm for computing\nshortest paths in weighted three-dimensional domains. Given a polyhedral domain\n$\\D$, consisting of $n$ tetrahedra with positive weights, and a real number\n$\\eps\\in(0,1)$, our algorithm constructs paths in $\\D$ from a fixed source\nvertex to all vertices of $\\D$, whose costs are at most $1+\\eps$ times the\ncosts of (weighted) shortest paths, in\n$O(\\C(\\D)\\frac{n}{\\eps^{2.5}}\\log\\frac{n}{\\eps}\\log^3\\frac{1}{\\eps})$ time,\nwhere $\\C(\\D)$ is a geometric parameter related to the aspect ratios of\ntetrahedra. The efficiency of the proposed algorithm is based on an in-depth\nstudy of the local behavior of geodesic paths and additive Voronoi diagrams in\nweighted three-dimensional domains, which are of independent interest. The\npaper extends the results of Aleksandrov, Maheshwari and Sack [JACM 2005] to\nthree dimensions.",
    "published": "2011-02-15T19:50:45Z",
    "link": "http://arxiv.org/pdf/1102.3165v1.pdf",
    "category": [
      "cs.CG",
      "cs.DS",
      "cs.GR",
      "cs.RO"
    ],
    "authors": [
      "Lyudmil Aleksandrov",
      "Hristo Djidjev",
      "Anil Maheshwari",
      "Joerg-Rudiger Sack"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1102.3328v1",
    "title": "An Efficient and Integrated Algorithm for Video Enhancement in\n  Challenging Lighting Conditions",
    "summary": "We describe a novel integrated algorithm for real-time enhancement of video\nacquired under challenging lighting conditions. Such conditions include low\nlighting, haze, and high dynamic range situations. The algorithm automatically\ndetects the dominate source of impairment, then depending on whether it is low\nlighting, haze or others, a corresponding pre-processing is applied to the\ninput video, followed by the core enhancement algorithm. Temporal and spatial\nredundancies in the video input are utilized to facilitate real-time processing\nand to improve temporal and spatial consistency of the output. The proposed\nalgorithm can be used as an independent module, or be integrated in either a\nvideo encoder or a video decoder for further optimizations.",
    "published": "2011-02-16T13:04:18Z",
    "link": "http://arxiv.org/pdf/1102.3328v1.pdf",
    "category": [
      "cs.GR",
      "cs.CV"
    ],
    "authors": [
      "Xuan Dong",
      " Jiangtao",
      " Wen",
      "Weixin Li",
      " Yi",
      " Pang",
      "Guan Wang",
      "Yao Lu",
      "Wei Meng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1102.4992v1",
    "title": "Mathematics of Human Motion: from Animation towards Simulation (A View\n  form the Outside)",
    "summary": "Simulation of human motion is the subject of study in a number of\ndisciplines: Biomechanics, Robotics, Computer Animation, Control Theory,\nNeurophysiology, Medicine, Ergonomics. Since the author has never visited any\nof these fields, this review is indeed a passer-by's impression. On the other\nhand, he happens to be a human (who occasionally is moving) and, as everybody\nelse, rates himself an expert in Applied Common Sense. Thus the author hopes\nthat this view from the {\\em outside} will be of some interest not only for the\nstrangers like himself, but for those who are {\\em inside} as well.\n  Two flaws of the text that follows are inevitable. First, some essential\nissues that are too familar to the specialists to discuss them may be missing.\nSecond, the author probably failed to provide the uniform \"level-of-detail\" for\nthis wide range of topics.",
    "published": "2011-02-24T13:54:29Z",
    "link": "http://arxiv.org/pdf/1102.4992v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "A. I. Zhmakin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1102.5123v1",
    "title": "Scientific Visualization in Astronomy: Towards the Petascale Astronomy\n  Era",
    "summary": "Astronomy is entering a new era of discovery, coincident with the\nestablishment of new facilities for observation and simulation that will\nroutinely generate petabytes of data. While an increasing reliance on automated\ndata analysis is anticipated, a critical role will remain for\nvisualization-based knowledge discovery. We have investigated scientific\nvisualization applications in astronomy through an examination of the\nliterature published during the last two decades. We identify the two most\nactive fields for progress - visualization of large-N particle data and\nspectral data cubes - discuss open areas of research, and introduce a mapping\nbetween astronomical sources of data and data representations used in general\npurpose visualization tools. We discuss contributions using high performance\ncomputing architectures (e.g: distributed processing and GPUs), collaborative\nastronomy visualization, the use of workflow systems to store metadata about\nvisualization parameters, and the use of advanced interaction devices. We\nexamine a number of issues that may be limiting the spread of scientific\nvisualization research in astronomy and identify six grand challenges for\nscientific visualization research in the Petascale Astronomy Era.",
    "published": "2011-02-24T22:54:18Z",
    "link": "http://arxiv.org/pdf/1102.5123v1.pdf",
    "category": [
      "astro-ph.IM",
      "cs.GR"
    ],
    "authors": [
      "Amr Hassan",
      "Christopher J. Fluke"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1103.2063v1",
    "title": "Augmented reality usage for prototyping speed up",
    "summary": "The first part of the article describes our approach for solution of this\nproblem by means of Augmented Reality. The merging of the real world model and\ndigital objects allows streamline the work with the model and speed up the\nwhole production phase significantly. The main advantage of augmented reality\nis the possibility of direct manipulation with the scene using a portable\ndigital camera. Also adding digital objects into the scene could be done using\nidentification markers placed on the surface of the model. Therefore it is not\nnecessary to work with special input devices and lose the contact with the real\nworld model. Adjustments are done directly on the model. The key problem of\noutlined solution is the ability of identification of an object within the\ncamera picture and its replacement with the digital object. The second part of\nthe article is focused especially on the identification of exact position and\norientation of the marker within the picture. The identification marker is\ngeneralized into the triple of points which represents a general plane in\nspace. There is discussed the space identification of these points and the\ndescription of representation of their position and orientation be means of\ntransformation matrix. This matrix is used for rendering of the graphical\nobjects (e. g. in OpenGL and Direct3D).",
    "published": "2011-03-10T16:00:52Z",
    "link": "http://arxiv.org/pdf/1103.2063v1.pdf",
    "category": [
      "cs.HC",
      "cs.GR"
    ],
    "authors": [
      "Jiri Stastny",
      "David Prochazka",
      "Tomas Koubek",
      "Jaromir Landa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1103.5028v2",
    "title": "User guide to TIM, a ray-tracing program for forbidden ray optics",
    "summary": "This user guide outlines the use of TIM, an interactive ray-tracing program\nwith a number of special powers. TIM can be customised and embedded into\ninternet pages, making it suitable not only for research but also for its\ndissemination.",
    "published": "2011-03-25T16:45:22Z",
    "link": "http://arxiv.org/pdf/1103.5028v2.pdf",
    "category": [
      "physics.ed-ph",
      "cs.GR"
    ],
    "authors": [
      "Dean Lambert",
      "Alasdair C. Hamilton",
      "George Constable",
      "Harsh Snehanshu",
      "Sharvil Talati",
      "Johannes Courtial"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1104.2580v2",
    "title": "Hypothesize and Bound: A Computational Focus of Attention Mechanism for\n  Simultaneous N-D Segmentation, Pose Estimation and Classification Using Shape\n  Priors",
    "summary": "Given the ever increasing bandwidth of the visual information available to\nmany intelligent systems, it is becoming essential to endow them with a sense\nof what is worthwhile their attention and what can be safely disregarded. This\narticle presents a general mathematical framework to efficiently allocate the\navailable computational resources to process the parts of the input that are\nrelevant to solve a given perceptual problem. By this we mean to find the\nhypothesis H (i.e., the state of the world) that maximizes a function L(H),\nrepresenting how well each hypothesis \"explains\" the input. Given the large\nbandwidth of the sensory input, fully evaluating L(H) for each hypothesis H is\ncomputationally infeasible (e.g., because it would imply checking a large\nnumber of pixels). To address this problem we propose a mathematical framework\nwith two key ingredients. The first one is a Bounding Mechanism (BM) to compute\nlower and upper bounds of L(H), for a given computational budget. These bounds\nare much cheaper to compute than L(H) itself, can be refined at any time by\nincreasing the budget allocated to a hypothesis, and are frequently enough to\ndiscard a hypothesis. To compute these bounds, we develop a novel theory of\nshapes and shape priors. The second ingredient is a Focus of Attention\nMechanism (FoAM) to select which hypothesis' bounds should be refined next,\nwith the goal of discarding non-optimal hypotheses with the least amount of\ncomputation. The proposed framework: 1) is very efficient since most hypotheses\nare discarded with minimal computation; 2) is parallelizable; 3) is guaranteed\nto find the globally optimal hypothesis; and 4) its running time depends on the\nproblem at hand, not on the bandwidth of the input. We instantiate the proposed\nframework for the problem of simultaneously estimating the class, pose, and a\nnoiseless version of a 2D shape in a 2D image.",
    "published": "2011-04-13T18:59:52Z",
    "link": "http://arxiv.org/pdf/1104.2580v2.pdf",
    "category": [
      "cs.CV",
      "cs.CG",
      "cs.GR",
      "cs.LG"
    ],
    "authors": [
      "Diego Rother",
      "Simon Schtz",
      "Ren Vidal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1105.3617v1",
    "title": "Face Shape and Reflectance Acquisition using a Multispectral Light Stage",
    "summary": "In this thesis, we discuss the design and calibration (geometric and\nradiometric) of a novel shape and reflectance acquisition device called the\n\"Multispectral Light Stage\". This device can capture highly detailed facial\ngeometry (down to the level of skin pores detail) and Multispectral reflectance\nmap which can be used to estimate biophysical skin parameters such as the\ndistribution of pigmentation and blood beneath the surface of the skin. We\nextend the analysis of the original spherical gradient photometric stereo\nmethod to study the effects of deformed diffuse lobes on the quality of\nrecovered surface normals. Based on our modified radiance equations, we develop\na minimal image set method to recover high quality photometric normals using\nonly four, instead of six, spherical gradient images. Using the same radiance\nequations, we explore a Quadratic Programming (QP) based algorithm for\ncorrection of surface normals obtained using spherical gradient photometric\nstereo. Based on the proposed minimal image sets method, we present a\nperformance capture sequence that significantly reduces the data capture\nrequirement and post-processing computational cost of existing photometric\nstereo based performance geometry capture methods. Furthermore, we explore the\nuse of images captured in our Light Stage to generate stimuli images for a\npsychology experiment exploring the neural representation of 3D shape and\ntexture of a human face.",
    "published": "2011-05-18T13:00:44Z",
    "link": "http://arxiv.org/pdf/1105.3617v1.pdf",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "Abhishek Dutta"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1105.5678v1",
    "title": "Time-Dependent 2-D Vector Field Topology: An Approach Inspired by\n  Lagrangian Coherent Structures",
    "summary": "This paper presents an approach to a time-dependent variant of the concept of\nvector field topology for 2-D vector fields. Vector field topology is defined\nfor steady vector fields and aims at discriminating the domain of a vector\nfield into regions of qualitatively different behaviour. The presented approach\nrepresents a generalization for saddle-type critical points and their\nseparatrices to unsteady vector fields based on generalized streak lines, with\nthe classical vector field topology as its special case for steady vector\nfields. The concept is closely related to that of Lagrangian coherent\nstructures obtained as ridges in the finite-time Lyapunov exponent field. The\nproposed approach is evaluated on both 2-D time-dependent synthetic and vector\nfields from computational fluid dynamics.",
    "published": "2011-05-28T02:28:19Z",
    "link": "http://arxiv.org/pdf/1105.5678v1.pdf",
    "category": [
      "cs.GR",
      "math.AP",
      "math.DS",
      "nlin.CD",
      "physics.data-an",
      "physics.flu-dyn",
      "I.3.8; J.2"
    ],
    "authors": [
      "Filip Sadlo",
      "Daniel Weiskopf"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1106.2877v1",
    "title": "Injectivity of 2D Toric Bzier Patches",
    "summary": "Rational B\\'{e}zier functions are widely used as mapping functions in surface\nreparameterization, finite element analysis, image warping and morphing. The\ninjectivity (one-to-one property) of a mapping function is typically necessary\nfor these applications. Toric B\\'{e}zier patches are generalizations of\nclassical patches (triangular, tensor product) which are defined on the convex\nhull of a set of integer lattice points. We give a geometric condition on the\ncontrol points that we show is equivalent to the injectivity of every 2D toric\nB\\'{e}zier patch with those control points for all possible choices of weights.\nThis condition refines that of Craciun, et al., which only implied injectivity\non the interior of a patch.",
    "published": "2011-06-15T05:35:51Z",
    "link": "http://arxiv.org/pdf/1106.2877v1.pdf",
    "category": [
      "cs.GR",
      "math.AG",
      "65D17, 14M25",
      "I.3.5"
    ],
    "authors": [
      "Frank Sottile",
      "Chungang Zhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1107.1525v1",
    "title": "Accelerating Lossless Data Compression with GPUs",
    "summary": "Huffman compression is a statistical, lossless, data compression algorithm\nthat compresses data by assigning variable length codes to symbols, with the\nmore frequently appearing symbols given shorter codes than the less. This work\nis a modification of the Huffman algorithm which permits uncompressed data to\nbe decomposed into indepen- dently compressible and decompressible blocks,\nallowing for concurrent compression and decompression on multiple processors.\nWe create implementations of this modified algorithm on a current NVIDIA GPU\nusing the CUDA API as well as on a current Intel chip and the performance\nresults are compared, showing favorable GPU performance for nearly all tests.\nLastly, we discuss the necessity for high performance data compression in\ntoday's supercomputing ecosystem.",
    "published": "2011-06-21T22:55:02Z",
    "link": "http://arxiv.org/pdf/1107.1525v1.pdf",
    "category": [
      "cs.IT",
      "cs.GR",
      "cs.PF",
      "math.IT"
    ],
    "authors": [
      "R. L. Cloud",
      "M. L. Curry",
      "H. L. Ward",
      "A. Skjellum",
      "P. Bangalore"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1107.0690v1",
    "title": "A Framework for Designing 3D Virtual Environments",
    "summary": "The process of design and development of virtual environments can be\nsupported by tools and frameworks, to save time in technical aspects and\nfocusing on the content. In this paper we present an academic framework which\nprovides several levels of abstraction to ease this work. It includes\nstate-of-the-art components we devised or integrated adopting open-source\nsolutions in order to face specific problems. Its architecture is modular and\ncustomizable, the code is open-source.",
    "published": "2011-07-04T17:51:00Z",
    "link": "http://arxiv.org/pdf/1107.0690v1.pdf",
    "category": [
      "cs.GR",
      "cs.MM"
    ],
    "authors": [
      "Salvatore Catanese",
      "Emilio Ferrara",
      "Giacomo Fiumara",
      "Francesco Pagano"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1107.2715v1",
    "title": "Stereo pairs in Astrophysics",
    "summary": "Stereoscopic visualization is seldom used in Astrophysical publications and\npresentations compared to other scientific fields, e.g., Biochemistry, where it\nhas been recognized as a valuable tool for decades. We put forth the view that\nstereo pairs can be a useful tool for the Astrophysics community in\ncommunicating a truer representation of astrophysical data. Here, we review the\nmain theoretical aspects of stereoscopy, and present a tutorial to easily\ncreate stereo pairs using Python. We then describe how stereo pairs provide a\nway to incorporate 3D data in 2D publications of standard journals. We\nillustrate the use of stereo pairs with one conceptual and two Astrophysical\nscience examples: an integral field spectroscopy study of a supernova remnant,\nand numerical simulations of a relativistic AGN jet. We also use these examples\nto make the case that stereo pairs are not merely an ostentatious way to\npresent data, but an enhancement in the communication of scientific results in\npublications because they provide the reader with a realistic view of\nmulti-dimensional data, be it of observational or theoretical nature. In\nrecognition of the ongoing 3D expansion in the commercial sector, we advocate\nan increased use of stereo pairs in Astrophysics publications and presentations\nas a first step towards new interactive and multi-dimensional publication\nmethods.",
    "published": "2011-07-14T02:42:12Z",
    "link": "http://arxiv.org/pdf/1107.2715v1.pdf",
    "category": [
      "astro-ph.IM",
      "cs.GR"
    ],
    "authors": [
      "Frdric Vogt",
      "Alexander Y. Wagner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1107.3013v1",
    "title": "Linear-Time Poisson-Disk Patterns",
    "summary": "We present an algorithm for generating Poisson-disc patterns taking O(N) time\nto generate $N$ points. The method is based on a grid of regions which can\ncontain no more than one point in the final pattern, and uses an explicit model\nof point arrival times under a uniform Poisson process.",
    "published": "2011-07-15T08:58:09Z",
    "link": "http://arxiv.org/pdf/1107.3013v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Thouis R. Jones",
      "David R. Karger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1107.3680v1",
    "title": "3-Phase Recognition Approach to Pseudo 3D Building Generation from 2D\n  Floor Plan",
    "summary": "Nowadays three dimension (3D) architectural visualisation has become a\npowerful tool in the conceptualisation, design and presentation of\narchitectural products in the construction industry, providing realistic\ninteraction and walkthrough on engineering products. Traditional ways of\nimplementing 3D models involves the use of specialised 3D authoring tools along\nwith skilled 3D designers with blueprints of the model and this is a slow and\nlaborious process. The aim of this paper is to automate this process by simply\nanalyzing the blueprint document and generating the 3D scene automatically. For\nthis purpose we have devised a 3-Phase recognition approach to pseudo 3D\nbuilding generation from 2D floor plan and developed a software accordingly.\nOur 3-phased 3D building system has been implemented using C, C++ and OpenCV\nlibrary [24] for the Image Processing module; The Save Module generated an XML\nfile for storing the processed floor plan objects attributes; while the\nIrrlitch [14] game engine was used to implement the Interactive 3D module.\nThough still at its infancy, our proposed system gave commendable results. We\ntested our system on 6 floor plans with complexities ranging from low to high\nand the results seems to be very promising with an average processing time of\naround 3s and a 3D generation in 4s. In addition the system provides an\ninteractive walk-though and allows users to modify components.",
    "published": "2011-07-19T10:50:31Z",
    "link": "http://arxiv.org/pdf/1107.3680v1.pdf",
    "category": [
      "cs.GR",
      "cs.CV"
    ],
    "authors": [
      "Raj Kishen Moloo",
      "Muhammad Ajmal Sheik Dawood",
      "Abu Salmaan Auleear"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1108.3529v1",
    "title": "Fat Triangulations and Differential Geometry",
    "summary": "We study the differential geometric consequences of our previous result on\nthe existence of fat triangulations, in conjunction with a result of Cheeger,\nM\\\"{u}ller and Schrader, regarding the convergence of Lipschitz-Killing\ncurvatures of piecewise-flat approximations of smooth Riemannian manifolds. A\nfurther application to the existence of quasiconformal mappings between\nmanifolds, as well as an extension of the triangulation result to the case of\nalmost Riemannian manifolds, are also given. In addition, the notion of fatness\nof triangulations and its relation to metric curvature and to excess is\nexplored. Moreover, applications of the main results, and in particular a\npurely metric approach to Regge calculus, are also investigated.",
    "published": "2011-08-17T17:22:46Z",
    "link": "http://arxiv.org/pdf/1108.3529v1.pdf",
    "category": [
      "math.DG",
      "cs.GR",
      "Primary: 53C23, 83C27, 57Q15, Secondary: 30C65, 68U05"
    ],
    "authors": [
      "Emil Saucan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1108.5673v1",
    "title": "Partial wave analysis at BES III harnessing the power of GPUs",
    "summary": "Partial wave analysis is a core tool in hadron spectroscopy. With the high\nstatistics data available at facilities such as the Beijing Spectrometer III,\nthis procedure becomes computationally very expensive. We have successfully\nimplemented a framework for performing partial wave analysis on graphics\nprocessors. We discuss the implementation, the parallel computing frameworks\nemployed and the performance achieved, with a focus on the recent transition to\nthe OpenCL framework.",
    "published": "2011-08-29T17:56:15Z",
    "link": "http://arxiv.org/pdf/1108.5673v1.pdf",
    "category": [
      "physics.data-an",
      "cs.GR",
      "hep-ex"
    ],
    "authors": [
      "Niklaus Berger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1109.1175v2",
    "title": "Estimating 3D Human Shapes from Measurements",
    "summary": "The recent advances in 3-D imaging technologies give rise to databases of\nhuman shapes, from which statistical shape models can be built. These\nstatistical models represent prior knowledge of the human shape and enable us\nto solve shape reconstruction problems from partial information. Generating\nhuman shape from traditional anthropometric measurements is such a problem,\nsince these 1-D measurements encode 3-D shape information. Combined with a\nstatistical shape model, these easy-to-obtain measurements can be leveraged to\ncreate 3D human shapes. However, existing methods limit the creation of the\nshapes to the space spanned by the database and thus require a large amount of\ntraining data. In this paper, we introduce a technique that extrapolates the\nstatistically inferred shape to fit the measurement data using nonlinear\noptimization. This method ensures that the generated shape is both human-like\nand satisfies the measurement conditions. We demonstrate the effectiveness of\nthe method and compare it to existing approaches through extensive experiments,\nusing both synthetic data and real human measurements.",
    "published": "2011-09-06T13:22:49Z",
    "link": "http://arxiv.org/pdf/1109.1175v2.pdf",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "Stefanie Wuhrer",
      "Chang Shu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1109.1914v2",
    "title": "Jacobians and Hessians of Mean Value Coordinates for Closed Triangular\n  Meshes",
    "summary": "In this technical note, we present the formulae of the derivatives of the\nMean Value Coordinates based transformations, using an enclosing triangle mesh,\nacting as a cage for the deformation of an interior object.",
    "published": "2011-09-09T06:49:52Z",
    "link": "http://arxiv.org/pdf/1109.1914v2.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Jean-Marc Thiery",
      "Julien Tierny",
      "Tamy Boubekeur"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1109.4095v2",
    "title": "Kara: A System for Visualising and Visual Editing of Interpretations for\n  Answer-Set Programs",
    "summary": "In answer-set programming (ASP), the solutions of a problem are encoded in\ndedicated models, called answer sets, of a logical theory. These answer sets\nare computed from the program that represents the theory by means of an ASP\nsolver and returned to the user as sets of ground first-order literals. As this\ntype of representation is often cumbersome for the user to interpret, tools\nlike ASPVIZ and IDPDraw were developed that allow for visualising answer sets.\nThe tool Kara, introduced in this paper, follows these approaches, using ASP\nitself as a language for defining visualisations of interpretations. Unlike\nexisting tools that position graphic primitives according to static coordinates\nonly, Kara allows for more high-level specifications, supporting graph\nstructures, grids, and relative positioning of graphical elements. Moreover,\ngeneralising the functionality of previous tools, Kara provides modifiable\nvisualisations such that interpretations can be manipulated by graphically\nediting their visualisations. This is realised by resorting to abductive\nreasoning techniques. Kara is part of SeaLion, a forthcoming integrated\ndevelopment environment (IDE) for ASP.",
    "published": "2011-09-19T17:09:21Z",
    "link": "http://arxiv.org/pdf/1109.4095v2.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "cs.GR",
      "cs.PL"
    ],
    "authors": [
      "Christian Kloimllner",
      "Johannes Oetsch",
      "Jrg Phrer",
      "Hans Tompits"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1109.6073v1",
    "title": "Evaluation of a Bundling Technique for Parallel Coordinates",
    "summary": "We describe a technique for bundled curve representations in\nparallel-coordinates plots and present a controlled user study evaluating their\neffectiveness. Replacing the traditional C^0 polygonal lines by C^1 continuous\npiecewise Bezier curves makes it easier to visually trace data points through\neach coordinate axis. The resulting Bezier curves can then be bundled to\nvisualize data with given cluster structures. Curve bundles are efficient to\ncompute, provide visual separation between data clusters, reduce visual\nclutter, and present a clearer overview of the dataset. A controlled user study\nwith 14 participants confirmed the effectiveness of curve bundling for\nparallel-coordinates visualization: 1) compared to polygonal lines, it is\nequally capable of revealing correlations between neighboring data attributes;\n2) its geometric cues can be effective in displaying cluster information. For\nsome datasets curve bundling allows the color perceptual channel to be applied\nto other data attributes, while for complex cluster patterns, bundling and\ncolor can represent clustering far more clearly than either alone.",
    "published": "2011-09-28T01:44:43Z",
    "link": "http://arxiv.org/pdf/1109.6073v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Julian Heinrich",
      "Yuan Luo",
      "Arthur E. Kirkpatrick",
      "Hao Zhang",
      "Daniel Weiskopf"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1109.6288v1",
    "title": "Using Stereoscopic 3D Technologies for the Diagnosis and Treatment of\n  Amblyopia in Children",
    "summary": "The 3D4Amb project aims at developing a system based on the stereoscopic 3D\ntechonlogy, like the NVIDIA 3D Vision, for the diagnosis and treatment of\namblyopia in young children. It exploits the active shutter technology to\nprovide binocular vision, i.e. to show different images to the amblyotic (or\nlazy) and the normal eye. It would allow easy diagnosis of amblyopia and its\ntreatment by means of interactive games or other entertainment activities. It\nshould not suffer from the compliance problems of the classical treatment, it\nis suitable to domestic use, and it could at least partially substitute\nocclusion or patching of the normal eye.",
    "published": "2011-09-28T18:35:51Z",
    "link": "http://arxiv.org/pdf/1109.6288v1.pdf",
    "category": [
      "cs.HC",
      "cs.GR"
    ],
    "authors": [
      "Angelo Gargantini"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1109.6494v1",
    "title": "A Survey of Ocean Simulation and Rendering Techniques in Computer\n  Graphics",
    "summary": "This paper presents a survey of ocean simulation and rendering methods in\ncomputer graphics. To model and animate the ocean's surface, these methods\nmainly rely on two main approaches: on the one hand, those which approximate\nocean dynamics with parametric, spectral or hybrid models and use empirical\nlaws from oceanographic research. We will see that this type of methods\nessentially allows the simulation of ocean scenes in the deep water domain,\nwithout breaking waves. On the other hand, physically-based methods use\nNavier-Stokes Equations (NSE) to represent breaking waves and more generally\nocean surface near the shore. We also describe ocean rendering methods in\ncomputer graphics, with a special interest in the simulation of phenomena such\nas foam and spray, and light's interaction with the ocean surface.",
    "published": "2011-09-29T11:50:29Z",
    "link": "http://arxiv.org/pdf/1109.6494v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Emmanuelle Darles",
      "Benot Crespin",
      "Djamchid Ghazanfarpour",
      "Jean-Christophe Gonzato"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1110.3649v3",
    "title": "Algorithms to automatically quantify the geometric similarity of\n  anatomical surfaces",
    "summary": "We describe new approaches for distances between pairs of 2-dimensional\nsurfaces (embedded in 3-dimensional space) that use local structures and global\ninformation contained in inter-structure geometric relationships. We present\nalgorithms to automatically determine these distances as well as geometric\ncorrespondences. This is motivated by the aspiration of students of natural\nscience to understand the continuity of form that unites the diversity of life.\nAt present, scientists using physical traits to study evolutionary\nrelationships among living and extinct animals analyze data extracted from\ncarefully defined anatomical correspondence points (landmarks). Identifying and\nrecording these landmarks is time consuming and can be done accurately only by\ntrained morphologists. This renders these studies inaccessible to\nnon-morphologists, and causes phenomics to lag behind genomics in elucidating\nevolutionary patterns. Unlike other algorithms presented for morphological\ncorrespondences our approach does not require any preliminary marking of\nspecial features or landmarks by the user. It also differs from other seminal\nwork in computational geometry in that our algorithms are polynomial in nature\nand thus faster, making pairwise comparisons feasible for significantly larger\nnumbers of digitized surfaces. We illustrate our approach using three datasets\nrepresenting teeth and different bones of primates and humans, and show that it\nleads to highly accurate results.",
    "published": "2011-10-17T12:23:30Z",
    "link": "http://arxiv.org/pdf/1110.3649v3.pdf",
    "category": [
      "math.NA",
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "D. Boyer",
      "Y. Lipman",
      "E. St. Clair",
      "J. Puente",
      "T. Funkhouser",
      "B. Patel",
      "J. Jernvall",
      "I. Daubechies"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1110.4623v1",
    "title": "Efficient Synchronization Primitives for GPUs",
    "summary": "In this paper, we revisit the design of synchronization\nprimitives---specifically barriers, mutexes, and semaphores---and how they\napply to the GPU. Previous implementations are insufficient due to the\ndiscrepancies in hardware and programming model of the GPU and CPU. We create\nnew implementations in CUDA and analyze the performance of spinning on the GPU,\nas well as a method of sleeping on the GPU, by running a set of memory-system\nbenchmarks on two of the most common GPUs in use, the Tesla- and Fermi-class\nGPUs from NVIDIA. From our results we define higher-level principles that are\nvalid for generic many-core processors, the most important of which is to limit\nthe number of atomic accesses required for a synchronization operation because\natomic accesses are slower than regular memory accesses. We use the results of\nthe benchmarks to critique existing synchronization algorithms and guide our\nnew implementations, and then define an abstraction of GPUs to classify any GPU\nbased on the behavior of the memory system. We use this abstraction to create\nsuitable implementations of the primitives specifically targeting the GPU, and\nanalyze the performance of these algorithms on Tesla and Fermi. We then predict\nperformance on future GPUs based on characteristics of the abstraction. We also\nexamine the roles of spin waiting and sleep waiting in each primitive and how\ntheir performance varies based on the machine abstraction, then give a set of\nguidelines for when each strategy is useful based on the characteristics of the\nGPU and expected contention.",
    "published": "2011-10-20T19:43:58Z",
    "link": "http://arxiv.org/pdf/1110.4623v1.pdf",
    "category": [
      "cs.OS",
      "cs.DC",
      "cs.DS",
      "cs.GR",
      "D.4.1; I.3.2"
    ],
    "authors": [
      "Jeff A. Stuart",
      "John D. Owens"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1110.5015v1",
    "title": "Spectral descriptors for deformable shapes",
    "summary": "Informative and discriminative feature descriptors play a fundamental role in\ndeformable shape analysis. For example, they have been successfully employed in\ncorrespondence, registration, and retrieval tasks. In the recent years,\nsignificant attention has been devoted to descriptors obtained from the\nspectral decomposition of the Laplace-Beltrami operator associated with the\nshape. Notable examples in this family are the heat kernel signature (HKS) and\nthe wave kernel signature (WKS). Laplacian-based descriptors achieve\nstate-of-the-art performance in numerous shape analysis tasks; they are\ncomputationally efficient, isometry-invariant by construction, and can\ngracefully cope with a variety of transformations. In this paper, we formulate\na generic family of parametric spectral descriptors. We argue that in order to\nbe optimal for a specific task, the descriptor should take into account the\nstatistics of the corpus of shapes to which it is applied (the \"signal\") and\nthose of the class of transformations to which it is made insensitive (the\n\"noise\"). While such statistics are hard to model axiomatically, they can be\nlearned from examples. Following the spirit of the Wiener filter in signal\nprocessing, we show a learning scheme for the construction of optimal spectral\ndescriptors and relate it to Mahalanobis metric learning. The superiority of\nthe proposed approach is demonstrated on the SHREC'10 benchmark.",
    "published": "2011-10-23T04:26:03Z",
    "link": "http://arxiv.org/pdf/1110.5015v1.pdf",
    "category": [
      "cs.CV",
      "cs.CG",
      "cs.GR",
      "math.DG"
    ],
    "authors": [
      "Alexander M. Bronstein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1110.5360v1",
    "title": "New Zealand involvement in Radio Astronomical VLBI Image Processing",
    "summary": "With the establishment of the AUT University 12m radio telescope at\nWarkworth, New Zealand has now become a part of the international Very Long\nBaseline Interferometry (VLBI) community. A major product of VLBI observations\nare images in the radio domain of astronomical objects such as Active Galactic\nNuclei (AGN). Using large geographical separations between radio antennas, very\nhigh angular resolution can be achieved. Detailed images can be created using\nthe technique of VLBI Earth Rotation Aperture Synthesis. We review the current\nprocess of VLBI radio imaging. In addition we model VLBI configurations using\nthe Warkworth telescope, AuScope (a new array of three 12m antennas in\nAustralia) and the Australian Square Kilometre Array Pathfinder (ASKAP) array\ncurrently under construction in Western Australia, and discuss how the\nconfiguration of these arrays affects the quality of images. Recent imaging\nresults that demonstrate the modeled improvements from inclusion of the AUT and\nfirst ASKAP telescope in the Australian Long Baseline Array (LBA) are\npresented.",
    "published": "2011-10-24T21:39:12Z",
    "link": "http://arxiv.org/pdf/1110.5360v1.pdf",
    "category": [
      "astro-ph.IM",
      "cs.GR"
    ],
    "authors": [
      "Stuart Weston",
      "Tim Natusch",
      "Sergei Gulyaev"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1111.1400v1",
    "title": "Student's T Robust Bundle Adjustment Algorithm",
    "summary": "Bundle adjustment (BA) is the problem of refining a visual reconstruction to\nproduce better structure and viewing parameter estimates. This problem is often\nformulated as a nonlinear least squares problem, where data arises from\ninterest point matching. Mismatched interest points cause serious problems in\nthis approach, as a single mismatch will affect the entire reconstruction. In\nthis paper, we propose a novel robust Student's t BA algorithm (RST-BA). We\nmodel reprojection errors using the heavy tailed Student's t-distribution, and\nuse an implicit trust region method to compute the maximum a posteriori (MAP)\nestimate of the camera and viewing parameters in this model. The resulting\nalgorithm exploits the sparse structure essential for reconstructing\nmulti-image scenarios, has the same time complexity as standard L2 bundle\nadjustment (L2-BA), and can be implemented with minimal changes to the standard\nleast squares framework. We show that the RST-BA is more accurate than either\nL2-BA or L2-BA with a sigma-edit rule for outlier removal for a range of\nsimulated error generation scenarios. The new method has also been used to\nreconstruct lunar topography using data from the NASA Apollo 15 orbiter, and we\npresent visual and quantitative comparisons of RST-BA and L2-BA methods for\nthis application. In particular, using the RST-BA algorithm we were able to\nreconstruct a DEM from unprocessed data with many outliers and no ground\ncontrol points, which was not possible with the L2-BA method.",
    "published": "2011-11-06T10:56:13Z",
    "link": "http://arxiv.org/pdf/1111.1400v1.pdf",
    "category": [
      "stat.CO",
      "cs.GR",
      "math.OC",
      "62F35, 65K10"
    ],
    "authors": [
      "Aleksandr Y. Aravkin",
      "Michael Styer",
      "Zachary Moratto",
      "Ara Nefian",
      "Michael Broxton"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1111.3969v2",
    "title": "The Object Projection Feature Estimation Problem in Unsupervised\n  Markerless 3D Motion Tracking",
    "summary": "3D motion tracking is a critical task in many computer vision applications.\nExisting 3D motion tracking techniques require either a great amount of\nknowledge on the target object or specific hardware. These requirements\ndiscourage the wide spread of commercial applications based on 3D motion\ntracking. 3D motion tracking systems that require no knowledge on the target\nobject and run on a single low-budget camera require estimations of the object\nprojection features (namely, area and position). In this paper, we define the\nobject projection feature estimation problem and we present a novel 3D motion\ntracking system that needs no knowledge on the target object and that only\nrequires a single low-budget camera, as installed in most computers and\nsmartphones. Our system estimates, in real time, the three-dimensional position\nof a non-modeled unmarked object that may be non-rigid, non-convex, partially\noccluded, self occluded, or motion blurred, given that it is opaque, evenly\ncolored, and enough contrasting with the background in each frame. Our system\nis also able to determine the most relevant object to track in the screen. Our\n3D motion tracking system does not impose hard constraints, therefore it allows\na market-wide implementation of applications that use 3D motion tracking.",
    "published": "2011-11-16T21:26:55Z",
    "link": "http://arxiv.org/pdf/1111.3969v2.pdf",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "Luis Quesada",
      "Alejandro J. Len"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1111.6321v1",
    "title": "Shape and Trajectory Tracking of Moving Obstacles",
    "summary": "This work presents new methods and algorithms for tracking the shape and\ntrajectory of moving reflecting obstacles with broken rays, or rays reflecting\nat an obstacle. While in tomography the focus of the reconstruction method is\nto recover the velocity structure of the domain, the shape and trajectory\nreconstruction procedure directly finds the shape and trajectory of the\nobstacle. The physical signal carrier for this innovative method are ultrasonic\nbeams. When the speed of sound is constant, the rays are straight line segments\nand the shape and trajectory of moving objects will be reconstructed with\nmethods based on the travel time equation and ellipsoid geometry. For variable\nspeed of sound, we start with the eikonal equation and a system of differential\nequations that has its origins in acoustics and seismology. In this case, the\nrays are curves that are not necessarily straight line segments and we develop\nalgorithms for shape and trajectory tracking based on the numerical solution of\nthese equations. We present methods and algorithms for shape and trajectory\ntracking of moving obstacles with reflected rays when the location of the\nreceiver of the reflected ray is not known in advance. The shape and trajectory\ntracking method is very efficient because it is not necessary for the reflected\nsignal to traverse the whole domain or the same path back to the transmitter.\nIt could be received close to the point of reflection or far away from the\ntransmitter. This optimizes the energy spent by transmitters for tracking the\nobject, reduces signal attenuation and improves image resolution. It is a safe\nand secure method. We also present algorithms for tracking the shape and\ntrajectory of absorbing obstacles. The new methods and algorithms for shape and\ntrajectory tracking enable new applications and an application to one-hop\nInternet routing is presented.",
    "published": "2011-11-28T00:10:06Z",
    "link": "http://arxiv.org/pdf/1111.6321v1.pdf",
    "category": [
      "cs.GR",
      "cs.DS",
      "math.OC"
    ],
    "authors": [
      "Kamen Lozev"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1112.3110v1",
    "title": "GPU-based Image Analysis on Mobile Devices",
    "summary": "With the rapid advances in mobile technology many mobile devices are capable\nof capturing high quality images and video with their embedded camera. This\npaper investigates techniques for real-time processing of the resulting images,\nparticularly on-device utilizing a graphical processing unit. Issues and\nlimitations of image processing on mobile devices are discussed, and the\nperformance of graphical processing units on a range of devices measured\nthrough a programmable shader implementation of Canny edge detection.",
    "published": "2011-12-14T03:46:46Z",
    "link": "http://arxiv.org/pdf/1112.3110v1.pdf",
    "category": [
      "cs.GR",
      "cs.CV",
      "I.3.1; I.4.8"
    ],
    "authors": [
      "Andrew Ensor",
      "Seth Hall"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1112.6032v1",
    "title": "A self-rendering digital image encoding",
    "summary": "Without careful long-term preservation digital data may be lost to a number\nof factors, including physical media decay, lack of suitable decoding\nequipment, and the absence of software. When raw data can be read but lack\nsuitable annotations as to provenance, the ability to interpret them is more\nstraightforward if they can be assessed through simple visual techniques. In\nthis regard digital images are a special case since their data have a natural\nrepresentation on two-dimensional media surfaces. This paper presents a novel\nbinary image pixel encoding that produces an approximate analog rendering of\nencoded images when the image bits are arranged spatially in an appropriate\nmanner. This simultaneous digital and analog representation acts to inseparably\nannotate bits as image data, which may contribute to the longevity of\nso-encoded images.",
    "published": "2011-12-27T23:40:12Z",
    "link": "http://arxiv.org/pdf/1112.6032v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Daniel L. Ruderman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1201.0070v1",
    "title": "Fast B-spline Curve Fitting by L-BFGS",
    "summary": "We propose a novel method for fitting planar B-spline curves to unorganized\ndata points. In traditional methods, optimization of control points and foot\npoints are performed in two very time-consuming steps in each iteration: 1)\ncontrol points are updated by setting up and solving a linear system of\nequations; and 2) foot points are computed by projecting each data point onto a\nB-spline curve. Our method uses the L-BFGS optimization method to optimize\ncontrol points and foot points simultaneously and therefore it does not need to\nperform either matrix computation or foot point projection in every iteration.\nAs a result, our method is much faster than existing methods.",
    "published": "2011-12-30T06:23:54Z",
    "link": "http://arxiv.org/pdf/1201.0070v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Wenni Zheng",
      "Pengbo Bo",
      "Yang Liu",
      "Wenping Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1201.1409v1",
    "title": "Interactive Character Posing by Sparse Coding",
    "summary": "Character posing is of interest in computer animation. It is difficult due to\nits dependence on inverse kinematics (IK) techniques and articulate property of\nhuman characters . To solve the IK problem, classical methods that rely on\nnumerical solutions often suffer from the under-determination problem and can\nnot guarantee naturalness. Existing data-driven methods address this problem by\nlearning from motion capture data. When facing a large variety of poses\nhowever, these methods may not be able to capture the pose styles or be\napplicable in real-time environment. Inspired from the low-rank motion\nde-noising and completion model in \\cite{lai2011motion}, we propose a novel\nmodel for character posing based on sparse coding. Unlike conventional\napproaches, our model directly captures the pose styles in Euclidean space to\nprovide intuitive training error measurements and facilitate pose synthesis. A\npose dictionary is learned in training stage and based on it natural poses are\nsynthesized to satisfy users' constraints . We compare our model with existing\nmodels for tasks of pose de-noising and completion. Experiments show our model\nobtains lower de-noising and completion error. We also provide User\nInterface(UI) examples illustrating that our model is effective for interactive\ncharacter posing.",
    "published": "2012-01-06T13:11:01Z",
    "link": "http://arxiv.org/pdf/1201.1409v1.pdf",
    "category": [
      "cs.GR",
      "cs.AI",
      "I.7"
    ],
    "authors": [
      "Ranch Y. Q. Lai",
      "Pong C. Yuen",
      "K. W. Lee",
      "J. H. Lai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1201.2936v1",
    "title": "Finding Convex Hulls Using Quickhull on the GPU",
    "summary": "We present a convex hull algorithm that is accelerated on commodity graphics\nhardware. We analyze and identify the hurdles of writing a recursive divide and\nconquer algorithm on the GPU and divise a framework for representing this class\nof problems. Our framework transforms the recursive splitting step into a\npermutation step that is well-suited for graphics hardware. Our convex hull\nalgorithm of choice is Quickhull. Our parallel Quickhull implementation (for\nboth 2D and 3D cases) achieves an order of magnitude speedup over standard\ncomputational geometry libraries.",
    "published": "2012-01-13T17:48:47Z",
    "link": "http://arxiv.org/pdf/1201.2936v1.pdf",
    "category": [
      "cs.CG",
      "cs.DS",
      "cs.GR"
    ],
    "authors": [
      "Stanley Tzeng",
      "John D. Owens"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1201.3671v1",
    "title": "Visualizing Flat Spacetime: Viewing Optical versus Special Relativistic\n  Effects",
    "summary": "A simple visual representation of Minkowski spacetime appropriate for a\nstudent with a background in geometry and algebra is presented. Minkowski\nspacetime can be modeled with a Euclidean 4-space to yield accurate\nvisualizations as predicted by special relativity theory. The contributions of\nrelativistic aberration as compared to classical pre-relativistic aberration to\nthe geometry are discussed in the context of its visual representation.",
    "published": "2012-01-17T23:58:24Z",
    "link": "http://arxiv.org/pdf/1201.3671v1.pdf",
    "category": [
      "physics.ed-ph",
      "cs.CG",
      "cs.GR",
      "physics.comp-ph",
      "I.3.3; I.3.5; I.3.6; I.4.10; E.2; H.5.2"
    ],
    "authors": [
      "Don V. Black",
      "M. Gopi",
      "F. Wessel",
      "R. Pajarola",
      "F. Kuester"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1201.5788v1",
    "title": "A toolkit to describe and interactively display three-manifolds embedded\n  in four-space",
    "summary": "A data structure and toolkit are presented here that allow for the\ndescription and manipulation of mathematical models of three-manifolds and\ntheir interactive display from multiple viewpoints via the OpenGL 3D graphics\npackage. The data structure and vector math package can be extended to support\nan arbitrary number of Euclidean spatial dimensions.\n  A model in 4-space is described by its bounding pure simplicial 3-complex. By\nintersecting a 3-flat with this 3-manifold, the algorithm will extract the\nrequested closed pure simplicial 2-complex surface enclosing the desired 3D\nslice. The user can interactively rotate, pan, zoom, and shade arbitrary 3D\nsolid or wire-frame views of the revealed 3D object created by intersection,\nthus exploring both expected and unexpected symmetries or asymmetries in the\nworld of 3-manifolds in 4-space.",
    "published": "2012-01-25T20:18:39Z",
    "link": "http://arxiv.org/pdf/1201.5788v1.pdf",
    "category": [
      "cs.CG",
      "cs.GR",
      "I.3.3; I.3.5; I.3.6; I.4.10; E.2; H.5.2"
    ],
    "authors": [
      "Don V. Black"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1202.1444v2",
    "title": "Fully Automatic Expression-Invariant Face Correspondence",
    "summary": "We consider the problem of computing accurate point-to-point correspondences\namong a set of human face scans with varying expressions. Our fully automatic\napproach does not require any manually placed markers on the scan. Instead, the\napproach learns the locations of a set of landmarks present in a database and\nuses this knowledge to automatically predict the locations of these landmarks\non a newly available scan. The predicted landmarks are then used to compute\npoint-to-point correspondences between a template model and the newly available\nscan. To accurately fit the expression of the template to the expression of the\nscan, we use as template a blendshape model. Our algorithm was tested on a\ndatabase of human faces of different ethnic groups with strongly varying\nexpressions. Experimental results show that the obtained point-to-point\ncorrespondence is both highly accurate and consistent for most of the tested 3D\nface models.",
    "published": "2012-02-07T15:05:05Z",
    "link": "http://arxiv.org/pdf/1202.1444v2.pdf",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "Augusto Salazar",
      "Stefanie Wuhrer",
      "Chang Shu",
      "Flavio Prieto"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1202.1808v1",
    "title": "Personalised product design using virtual interactive techniques",
    "summary": "Use of Virtual Interactive Techniques for personalized product design is\ndescribed in this paper. Usually products are designed and built by considering\ngeneral usage patterns and Prototyping is used to mimic the static or working\nbehaviour of an actual product before manufacturing the product. The user does\nnot have any control on the design of the product. Personalized design\npostpones design to a later stage. It allows for personalized selection of\nindividual components by the user. This is implemented by displaying the\nindividual components over a physical model constructed using Cardboard or\nThermocol in the actual size and shape of the original product. The components\nof the equipment or product such as screen, buttons etc. are then projected\nusing a projector connected to the computer into the physical model. Users can\ninteract with the prototype like the original working equipment and they can\nselect, shape, position the individual components displayed on the interaction\npanel using simple hand gestures. Computer Vision techniques as well as sound\nprocessing techniques are used to detect and recognize the user gestures\ncaptured using a web camera and microphone.",
    "published": "2012-02-08T20:26:26Z",
    "link": "http://arxiv.org/pdf/1202.1808v1.pdf",
    "category": [
      "cs.MM",
      "cs.CV",
      "cs.GR",
      "68u05, 68u20",
      "H.5.2; I.3.7"
    ],
    "authors": [
      "Kurien Zacharia",
      "Eldo P. Elias",
      "Surekha Mariam Varghese"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1202.1841v1",
    "title": "Semantic Visualization and Navigation in Textual Corpus",
    "summary": "This paper gives a survey of related work on the information visualization\ndomain and study the real integration of the cartography paradigms in actual\ninformation search systems. Based on this study, we propose a semantic\nvisualization and navigation approach which offer to users three search modes:\nprecise search, connotative search and thematic search. The objective is to\npropose to the users of an information search system, new interaction paradigms\nwhich support the semantic aspect of the considered information space and guide\nusers in their searches by assisting them to locate their interest center and\nto improve serendipity.",
    "published": "2012-02-08T21:38:11Z",
    "link": "http://arxiv.org/pdf/1202.1841v1.pdf",
    "category": [
      "cs.IR",
      "cs.DL",
      "cs.GR",
      "cs.SI"
    ],
    "authors": [
      "Frihane Kboubi",
      "Anja Habacha Chaibi",
      "Mohamed BenAhmed"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1202.2868v1",
    "title": "Visual definition of procedures for automatic virtual scene generation",
    "summary": "With more and more digital media, especially in the field of virtual reality\nwhere detailed and convincing scenes are much required, procedural scene\ngeneration is a big helping tool for artists. A problem is that defining scene\ndescriptions through these procedures usually requires a knowledge in formal\nlanguage grammars, programming theory and manually editing textual files using\na strict syntax, making it less intuitive to use. Luckily, graphical user\ninterfaces has made a lot of tasks on computers easier to perform and out of\nthe belief that creating computer programs can also be one of them, visual\nprogramming languages (VPLs) have emerged. The goal in VPLs is to shift more\nwork from the programmer to the integrated development environment (IDE),\nmaking programming an user-friendlier task.\n  In this thesis, an approach of using a VPL for defining procedures that\nautomatically generate virtual scenes is presented. The methods required to\nbuild a VPL are presented, including a novel method of generating readable code\nin a structured programming language. Also, the methods for achieving basic\nprinciples of VPLs will be shown -- suitable visual presentation of information\nand guiding the programmer in the right direction using constraints. On the\nother hand, procedural generation methods are presented in the context of\nvisual programming -- adapting the application programming interface (API) of\nthese methods to better serve the user. The main focus will be on the methods\nfor urban modeling, such as building, city layout and details generation with\nrandom number generation used to create non-deterministic scenes.",
    "published": "2012-02-10T16:58:00Z",
    "link": "http://arxiv.org/pdf/1202.2868v1.pdf",
    "category": [
      "cs.GR",
      "cs.PL"
    ],
    "authors": [
      "Drazen Lucanin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1202.5360v1",
    "title": "Efficient and Effective Volume Visualization with Enhanced Isosurface\n  Rendering",
    "summary": "Compared with full volume rendering, isosurface rendering has several well\nrecognized advantages in efficiency and accuracy. However, standard isosurface\nrendering has some limitations in effectiveness. First, it uses a monotone\ncolored approach and can only visualize the geometry features of an isosurface.\nThe lack of the capability to illustrate the material property and the internal\nstructures behind an isosurface has been a big limitation of this method in\napplications. Another limitation of isosurface rendering is the difficulty to\nreveal physically meaningful structures, which are hidden in one or multiple\nisosurfaces. As such, the application requirements of extract and recombine\nstructures of interest can not be implemented effectively with isosurface\nrendering. In this work, we develop an enhanced isosurface rendering technique\nto improve the effectiveness while maintaining the performance efficiency of\nthe standard isosurface rendering. First, an isosurface color enhancement\nmethod is proposed to illustrate the neighborhood density and to reveal some of\nthe internal structures. Second, we extend the structure extraction capability\nof isosurface rendering by enabling explicit scene exploration within a\n3D-view, using surface peeling, voxel-selecting, isosurface segmentation, and\nmulti-surface-structure visualization. Our experiments show that the color\nenhancement not only improves the visual fidelity of the rendering, but also\nreveals the internal structures without significant increase of the\ncomputational cost. Explicit scene exploration is also demonstrated as a\npowerful tool in some application scenarios, such as displaying multiple\nabdominal organs.",
    "published": "2012-02-24T01:39:12Z",
    "link": "http://arxiv.org/pdf/1202.5360v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Fei Yang",
      "Yong Cao",
      "Jie Tian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1202.6609v2",
    "title": "Towards an Integrated Visualization Of Semantically Enriched 3D City\n  Models: An Ontology of 3D Visualization Techniques",
    "summary": "3D city models - which represent in 3 dimensions the geometric elements of a\ncity - are increasingly used for an intended wide range of applications. Such\nuses are made possible by using semantically enriched 3D city models and by\npresenting such enriched 3D city models in a way that allows decision-making\nprocesses to be carried out from the best choices among sets of objectives, and\nacross issues and scales. In order to help in such a decision-making process we\nhave defined a framework to find the best visualization technique(s) for a set\nof potentially heterogeneous data that have to be visualized within the same 3D\ncity model, in order to perform a given task in a specific context. We have\nchosen an ontology-based approach. This approach and the specification and use\nof the resulting ontology of 3D visualization techniques are described in this\npaper.",
    "published": "2012-02-29T17:15:53Z",
    "link": "http://arxiv.org/pdf/1202.6609v2.pdf",
    "category": [
      "cs.AI",
      "cs.GR",
      "cs.HC"
    ],
    "authors": [
      "Claudine Mtral",
      "Nizar Ghoula",
      "Gilles Falquet"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1203.3574v1",
    "title": "Artimate: an articulatory animation framework for audiovisual speech\n  synthesis",
    "summary": "We present a modular framework for articulatory animation synthesis using\nspeech motion capture data obtained with electromagnetic articulography (EMA).\nAdapting a skeletal animation approach, the articulatory motion data is applied\nto a three-dimensional (3D) model of the vocal tract, creating a portable\nresource that can be integrated in an audiovisual (AV) speech synthesis\nplatform to provide realistic animation of the tongue and teeth for a virtual\ncharacter. The framework also provides an interface to articulatory animation\nsynthesis, as well as an example application to illustrate its use with a 3D\ngame engine. We rely on cross-platform, open-source software and open standards\nto provide a lightweight, accessible, and portable workflow.",
    "published": "2012-03-15T21:23:45Z",
    "link": "http://arxiv.org/pdf/1203.3574v1.pdf",
    "category": [
      "cs.HC",
      "cs.GR"
    ],
    "authors": [
      "Ingmar Steiner",
      "Slim Ouni"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1204.1461v1",
    "title": "Efficient computational noise in GLSL",
    "summary": "We present GLSL implementations of Perlin noise and Perlin simplex noise that\nrun fast enough for practical consideration on current generation GPU hardware.\nThe key benefits are that the functions are purely computational, i.e. they use\nneither textures nor lookup tables, and that they are implemented in GLSL\nversion 1.20, which means they are compatible with all current GLSL-capable\nplatforms, including OpenGL ES 2.0 and WebGL 1.0. Their performance is on par\nwith previously presented GPU implementations of noise, they are very\nconvenient to use, and they scale well with increasing parallelism in present\nand upcoming GPU architectures.",
    "published": "2012-04-06T12:03:45Z",
    "link": "http://arxiv.org/pdf/1204.1461v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Ian McEwan",
      "David Sheets",
      "Stefan Gustavson",
      "Mark Richardson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1204.4734v1",
    "title": "Numerical Analysis of Diagonal-Preserving, Ripple-Minimizing and\n  Low-Pass Image Resampling Methods",
    "summary": "Image resampling is a necessary component of any operation that changes the\nsize of an image or its geometry.\n  Methods tuned for natural image upsampling (roughly speaking, image\nenlargement) are analyzed and developed with a focus on their ability to\npreserve diagonal features and suppress overshoots. Monotone, locally bounded\nand almost monotone \"direct\" interpolation and filtering methods, as well as\nface split and vertex split surface subdivision methods, alone or in\ncombination, are studied. Key properties are established by way of proofs and\ncounterexamples as well as numerical experiments involving 1D curve and 2D\ndiagonal data resampling.\n  In addition, the Remez minimax method for the computation of low-cost\npolynomial approximations of low-pass filter kernels tuned for natural image\ndownsampling (roughly speaking, image reduction) is refactored for relative\nerror minimization in the presence of roots in the interior of the interval of\napproximation and so that even and odd functions are approximated with like\npolynomials. The accuracy and frequency response of the approximations are\ntabulated and plotted against the original, establishing their rapid\nconvergence.",
    "published": "2012-04-20T20:05:46Z",
    "link": "http://arxiv.org/pdf/1204.4734v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Chantal Racette"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1204.6216v2",
    "title": "Geodesics in Heat",
    "summary": "We introduce the heat method for computing the shortest geodesic distance to\na specified subset (e.g., point or curve) of a given domain. The heat method is\nrobust, efficient, and simple to implement since it is based on solving a pair\nof standard linear elliptic problems. The method represents a significant\nbreakthrough in the practical computation of distance on a wide variety of\ngeometric domains, since the resulting linear systems can be prefactored once\nand subsequently solved in near-linear time. In practice, distance can be\nupdated via the heat method an order of magnitude faster than with\nstate-of-the-art methods while maintaining a comparable level of accuracy. We\nprovide numerical evidence that the method converges to the exact geodesic\ndistance in the limit of refinement; we also explore smoothed approximations of\ndistance suitable for applications where more regularity is required.",
    "published": "2012-04-24T20:26:58Z",
    "link": "http://arxiv.org/pdf/1204.6216v2.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Keenan Crane",
      "Clarisse Weischedel",
      "Max Wardetzky"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1205.0282v1",
    "title": "A Distributed GPU-based Framework for real-time 3D Volume Rendering of\n  Large Astronomical Data Cubes",
    "summary": "We present a framework to interactively volume-render three-dimensional data\ncubes using distributed ray-casting and volume bricking over a cluster of\nworkstations powered by one or more graphics processing units (GPUs) and a\nmulti-core CPU. The main design target for this framework is to provide an\nin-core visualization solution able to provide three-dimensional interactive\nviews of terabyte-sized data cubes. We tested the presented framework using a\ncomputing cluster comprising 64 nodes with a total of 128 GPUs. The framework\nproved to be scalable to render a 204 GB data cube with an average of 30 frames\nper second. Our performance analyses also compare between using NVIDIA Tesla\n1060 and 2050 GPU architectures and the effect of increasing the visualization\noutput resolution on the rendering performance. Although our initial focus, and\nthe examples presented in this work, is volume rendering of spectral data cubes\nfrom radio astronomy, we contend that our approach has applicability to other\ndisciplines where close to real-time volume rendering of terabyte-order 3D data\nsets is a requirement.",
    "published": "2012-05-01T23:17:42Z",
    "link": "http://arxiv.org/pdf/1205.0282v1.pdf",
    "category": [
      "astro-ph.IM",
      "cs.DC",
      "cs.GR"
    ],
    "authors": [
      "A. H. Hassan",
      "C. J. Fluke",
      "D. G. Barnes"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1206.4880v1",
    "title": "Dynamic Domain Classification for Fractal Image Compression",
    "summary": "Fractal image compression is attractive except for its high encoding time\nrequirements. The image is encoded as a set of contractive affine\ntransformations. The image is partitioned into non-overlapping range blocks,\nand a best matching domain block larger than the range block is identified.\nThere are many attempts on improving the encoding time by reducing the size of\nsearch pool for range-domain matching. But these methods are attempting to\nprepare a static domain pool that remains unchanged throughout the encoding\nprocess. This paper proposes dynamic preparation of separate domain pool for\neach range block. This will result in significant reduction in the encoding\ntime. The domain pool for a particular range block can be selected based upon a\nparametric value. Here we use classification based on local fractal dimension.",
    "published": "2012-05-20T17:22:49Z",
    "link": "http://arxiv.org/pdf/1206.4880v1.pdf",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "K. Revathy",
      "M. Jayamohan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1205.5204v1",
    "title": "Visualizing 2D Flows with Animated Arrow Plots",
    "summary": "Flow fields are often represented by a set of static arrows to illustrate\nscientific vulgarization, documentary film, meteorology, etc. This simple\nschematic representation lets an observer intuitively interpret the main\nproperties of a flow: its orientation and velocity magnitude. We propose to\ngenerate dynamic versions of such representations for 2D unsteady flow fields.\nOur algorithm smoothly animates arrows along the flow while controlling their\ndensity in the domain over time. Several strategies have been combined to lower\nthe unavoidable popping artifacts arising when arrows appear and disappear and\nto achieve visually pleasing animations. Disturbing arrow rotations in low\nvelocity regions are also handled by continuously morphing arrow glyphs to\nsemi-transparent discs. To substantiate our method, we provide results for\nsynthetic and real velocity field datasets.",
    "published": "2012-05-23T15:29:16Z",
    "link": "http://arxiv.org/pdf/1205.5204v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Bruno Jobard",
      "Nicolas Ray",
      "Dmitry Sokolov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1206.1148v2",
    "title": "From individual to population: Challenges in Medical Visualization",
    "summary": "In this paper, we first give a high-level overview of medical visualization\ndevelopment over the past 30 years, focusing on key developments and the trends\nthat they represent. During this discussion, we will refer to a number of key\npapers that we have also arranged on the medical visualization research\ntimeline. Based on the overview and our observations of the field, we then\nidentify and discuss the medical visualization research challenges that we\nforesee for the coming decade.",
    "published": "2012-06-06T08:38:27Z",
    "link": "http://arxiv.org/pdf/1206.1148v2.pdf",
    "category": [
      "cs.GR",
      "physics.med-ph"
    ],
    "authors": [
      "Charl P. Botha",
      "Bernhard Preim",
      "Arie Kaufman",
      "Shigeo Takahashi",
      "Anders Ynnerman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1206.1428v2",
    "title": "Visualization in Connectomics",
    "summary": "Connectomics is a field of neuroscience that analyzes neuronal connections. A\nconnectome is a complete map of a neuronal system, comprising all neuronal\nconnections between its structures. The term \"connectome\" is close to the word\n\"genome\" and implies completeness of all neuronal connections, in the same way\nas a genome is a complete listing of all nucleotide sequences. The goal of\nconnectomics is to create a complete representation of the brain's wiring. Such\na representation is believed to increase our understanding of how functional\nbrain states emerge from their underlying anatomical structure. Furthermore, it\ncan provide important information for the cure of neuronal dysfunctions like\nschizophrenia or autism. In this paper, we review the current state-of-the-art\nof visualization and image processing techniques in the field of connectomics\nand describe some remaining challenges.",
    "published": "2012-06-07T09:17:34Z",
    "link": "http://arxiv.org/pdf/1206.1428v2.pdf",
    "category": [
      "cs.GR",
      "q-bio.NC"
    ],
    "authors": [
      "Hanspeter Pfister",
      "Verena Kaynig",
      "Charl P. Botha",
      "Stefan Bruckner",
      "Vincent J. Dercksen",
      "Hans-Christian Hege",
      "Jos B. T. M. Roerdink"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1206.1968v4",
    "title": "A novel 2.5D approach for interfacing with web applications",
    "summary": "Web applications need better user interface to be interactive and attractive.\nA new approach/concept of dimensional enhancement - 2.5D \"a 2D display of a\nvirtual 3D environment\", which can be implemented in social networking sites\nand further in other system applications.",
    "published": "2012-06-09T20:04:38Z",
    "link": "http://arxiv.org/pdf/1206.1968v4.pdf",
    "category": [
      "cs.HC",
      "cs.GR"
    ],
    "authors": [
      "Saurabh Sarkar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1206.4634v1",
    "title": "Artist Agent: A Reinforcement Learning Approach to Automatic Stroke\n  Generation in Oriental Ink Painting",
    "summary": "Oriental ink painting, called Sumi-e, is one of the most appealing painting\nstyles that has attracted artists around the world. Major challenges in\ncomputer-based Sumi-e simulation are to abstract complex scene information and\ndraw smooth and natural brush strokes. To automatically find such strokes, we\npropose to model the brush as a reinforcement learning agent, and learn desired\nbrush-trajectories by maximizing the sum of rewards in the policy search\nframework. We also provide elaborate design of actions, states, and rewards\ntailored for a Sumi-e agent. The effectiveness of our proposed approach is\ndemonstrated through simulated Sumi-e experiments.",
    "published": "2012-06-18T15:14:24Z",
    "link": "http://arxiv.org/pdf/1206.4634v1.pdf",
    "category": [
      "cs.LG",
      "cs.GR",
      "stat.ML"
    ],
    "authors": [
      "Ning Xie",
      "Hirotaka Hachiya",
      "Masashi Sugiyama"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1206.3975v1",
    "title": "The Ultrasound Visualization Pipeline - A Survey",
    "summary": "Ultrasound is one of the most frequently used imaging modality in medicine.\nThe high spatial resolution, its interactive nature and non-invasiveness makes\nit the first choice in many examinations. Image interpretation is one of\nultrasound's main challenges. Much training is required to obtain a confident\nskill level in ultrasound-based diagnostics. State-of-the-art graphics\ntechniques is needed to provide meaningful visualizations of ultrasound in\nreal-time. In this paper we present the process-pipeline for ultrasound\nvisualization, including an overview of the tasks performed in the specific\nsteps. To provide an insight into the trends of ultrasound visualization\nresearch, we have selected a set of significant publications and divided them\ninto a technique-based taxonomy covering the topics pre-processing,\nsegmentation, registration, rendering and augmented reality. For the different\ntechnique types we discuss the difference between ultrasound-based techniques\nand techniques for other modalities.",
    "published": "2012-06-18T16:05:47Z",
    "link": "http://arxiv.org/pdf/1206.3975v1.pdf",
    "category": [
      "cs.GR",
      "cs.CV"
    ],
    "authors": [
      "smund Birkeland",
      "Veronika Solteszova",
      "Dieter Hnigmann",
      "Odd Helge Gilja",
      "Svein Brekke",
      "Timo Ropinski",
      "Ivan Viola"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1206.6049v5",
    "title": "Improved visualisation of brain arteriovenous malformations using color\n  intensity projections with hue cycling",
    "summary": "Color intensity projections (CIP) have been shown to improve the\nvisualisation of greyscale angiography images by combining greyscale images\ninto a single color image. A key property of the combined CIP image is the\nencoding of the arrival time information from greyscale images into the hue of\nthe color in the CIP image. A few minor improvements to the calculation of the\nCIP image are introduced that substantially improve the quality of the\nvisualisation. One improvement is interpolating of the greyscale images in time\nbefore calculation of the CIP image. A second is the use of hue cycling - where\nthe hue of the color is cycled through more than once in an image. The hue\ncycling allows the variation of the hue to be concentrated in structures of\ninterest. If there is a zero time point hue cycling can be applied after zero\ntime and before zero time can be indicated by greyscale. If there is an end\ntime point hue cycling can be applied before the end time and pixels can be set\nto black after the end time. An angiogram of a brain is used to demonstrate the\nsubstantial improvements hue cycling brings to CIP images. A third improvement\nis the use of maximum intensity projection for 2D rendering of a 3D CIP image\nvolume. A fourth improvement allowing interpreters to interactively adjust the\nphase of the hue via standard contrast - brightness controls using lookup\ntables. Other potential applications of CIP are also mentioned.",
    "published": "2012-06-25T11:05:36Z",
    "link": "http://arxiv.org/pdf/1206.6049v5.pdf",
    "category": [
      "cs.GR",
      "cs.HC"
    ],
    "authors": [
      "Keith S. Cover"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1206.6850v1",
    "title": "Visualization of Collaborative Data",
    "summary": "Collaborative data consist of ratings relating two distinct sets of objects:\nusers and items. Much of the work with such data focuses on filtering:\npredicting unknown ratings for pairs of users and items. In this paper we focus\non the problem of visualizing the information. Given all of the ratings, our\ntask is to embed all of the users and items as points in the same Euclidean\nspace. We would like to place users near items that they have rated (or would\nrate) high, and far away from those they would give a low rating. We pose this\nproblem as a real-valued non-linear Bayesian network and employ Markov chain\nMonte Carlo and expectation maximization to find an embedding. We present a\nmetric by which to judge the quality of a visualization and compare our results\nto local linear embedding and Eigentaste on three real-world datasets.",
    "published": "2012-06-27T16:24:29Z",
    "link": "http://arxiv.org/pdf/1206.6850v1.pdf",
    "category": [
      "cs.GR",
      "cs.AI",
      "cs.HC"
    ],
    "authors": [
      "Guobiao Mei",
      "Christian R. Shelton"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1207.0704v1",
    "title": "Speckle Reduction using Stochastic Distances",
    "summary": "This paper presents a new approach for filter design based on stochastic\ndistances and tests between distributions. A window is defined around each\npixel, samples are compared and only those which pass a goodness-of-fit test\nare used to compute the filtered value. The technique is applied to intensity\nSynthetic Aperture Radar (SAR) data, using the Gamma model with varying number\nof looks allowing, thus, changes in heterogeneity. Modified Nagao-Matsuyama\nwindows are used to define the samples. The proposal is compared with the Lee's\nfilter which is considered a standard, using a protocol based on simulation.\nAmong the criteria used to quantify the quality of filters, we employ the\nequivalent number of looks (related to the signal-to-noise ratio), line\ncontrast, and edge preservation. Moreover, we also assessed the filters by the\nUniversal Image Quality Index and the Pearson's correlation between edges.",
    "published": "2012-07-03T14:57:44Z",
    "link": "http://arxiv.org/pdf/1207.0704v1.pdf",
    "category": [
      "cs.IT",
      "cs.CV",
      "cs.GR",
      "math.IT",
      "stat.AP",
      "stat.ML"
    ],
    "authors": [
      "Leonardo Torres",
      "Tamer Cavalcante",
      "Alejandro C. Frery"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1207.0757v1",
    "title": "Generalized Statistical Complexity of SAR Imagery",
    "summary": "A new generalized Statistical Complexity Measure (SCM) was proposed by Rosso\net al in 2010. It is a functional that captures the notions of order/disorder\nand of distance to an equilibrium distribution. The former is computed by a\nmeasure of entropy, while the latter depends on the definition of a stochastic\ndivergence. When the scene is illuminated by coherent radiation, image data is\ncorrupted by speckle noise, as is the case of ultrasound-B, sonar, laser and\nSynthetic Aperture Radar (SAR) sensors. In the amplitude and intensity formats,\nthis noise is multiplicative and non-Gaussian requiring, thus, specialized\ntechniques for image processing and understanding. One of the most successful\nfamily of models for describing these images is the Multiplicative Model which\nleads, among other probability distributions, to the G0 law. This distribution\nhas been validated in the literature as an expressive and tractable model,\ndeserving the \"universal\" denomination for its ability to describe most types\nof targets. In order to compute the statistical complexity of a site in an\nimage corrupted by speckle noise, we assume that the equilibrium distribution\nis that of fully developed speckle, namely the Gamma law in intensity format,\nwhich appears in areas with little or no texture. We use the Shannon entropy\nalong with the Hellinger distance to measure the statistical complexity of\nintensity SAR images, and we show that it is an expressive feature capable of\nidentifying many types of targets.",
    "published": "2012-07-03T17:25:18Z",
    "link": "http://arxiv.org/pdf/1207.0757v1.pdf",
    "category": [
      "cs.IT",
      "cs.GR",
      "math.IT",
      "stat.AP",
      "stat.ML"
    ],
    "authors": [
      "Eliana S. de Almeida",
      "Antonio Carlos de Medeiros",
      "Osvaldo A. Rosso",
      "Alejandro C. Frery"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1207.0771v1",
    "title": "Polarimetric SAR Image Smoothing with Stochastic Distances",
    "summary": "Polarimetric Synthetic Aperture Radar (PolSAR) images are establishing as an\nimportant source of information in remote sensing applications. The most\ncomplete format this type of imaging produces consists of complex-valued\nHermitian matrices in every image coordinate and, as such, their visualization\nis challenging. They also suffer from speckle noise which reduces the\nsignal-to-noise ratio. Smoothing techniques have been proposed in the\nliterature aiming at preserving different features and, analogously,\nprojections from the cone of Hermitian positive matrices to different color\nrepresentation spaces are used for enhancing certain characteristics. In this\nwork we propose the use of stochastic distances between models that describe\nthis type of data in a Nagao-Matsuyama-type of smoothing technique. The\nresulting images are shown to present good visualization properties (noise\nreduction with preservation of fine details) in all the considered\nvisualization spaces.",
    "published": "2012-07-03T18:11:46Z",
    "link": "http://arxiv.org/pdf/1207.0771v1.pdf",
    "category": [
      "cs.IT",
      "cs.CV",
      "cs.GR",
      "math.IT",
      "stat.AP",
      "stat.ML"
    ],
    "authors": [
      "Leonardo Torres",
      "Antonio C. Medeiros",
      "Alejandro C. Frery"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1207.2378v1",
    "title": "Parametric and Nonparametric Tests for Speckled Imagery",
    "summary": "Synthetic aperture radar (SAR) has a pivotal role as a remote imaging method.\nObtained by means of coherent illumination, SAR images are contaminated with\nspeckle noise. The statistical modeling of such contamination is well described\naccording with the multiplicative model and its implied G0 distribution. The\nunderstanding of SAR imagery and scene element identification is an important\nobjective in the field. In particular, reliable image contrast tools are\nsought. Aiming the proposition of new tools for evaluating SAR image contrast,\nwe investigated new methods based on stochastic divergence. We propose several\ndivergence measures specifically tailored for G0 distributed data. We also\nintroduce a nonparametric approach based on the Kolmogorov-Smirnov distance for\nG0 data. We devised and assessed tests based on such measures, and their\nperformances were quantified according to their test sizes and powers. Using\nMonte Carlo simulation, we present a robustness analysis of test statistics and\nof maximum likelihood estimators for several degrees of innovative\ncontamination. It was identified that the proposed tests based on triangular\nand arithmetic-geometric measures outperformed the Kolmogorov-Smirnov\nmethodology.",
    "published": "2012-07-10T14:42:45Z",
    "link": "http://arxiv.org/pdf/1207.2378v1.pdf",
    "category": [
      "stat.CO",
      "cs.GR"
    ],
    "authors": [
      "Renato J. Cintra",
      "Abrao D. C. Nascimento",
      "Alejandro C. Frery"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1207.2597v1",
    "title": "Automated Training and Maintenance through Kinect",
    "summary": "In this paper, we have worked on reducing burden on mechanic involving\ncomplex automobile maintenance activities that are performed in centralised\nworkshops. We have presented a system prototype that combines Augmented Reality\nwith Kinect. With the use of Kinect, very high quality sensors are available at\nconsiderably low costs, thus reducing overall expenditure for system design.\nThe system can be operated either in Speech mode or in Gesture mode. The system\ncan be controlled by various audio commands if user opts for Speech mode. The\nsame controlling can also be done by using a set of Gestures in Gesture mode.\n  Gesture recognition is the task performed by Kinect system. This system,\nbundled with RGB and Depth camera, processes the skeletal data by keeping track\nof 20 different body joints. Recognizing Gestures is done by verifying user\nmovements and checking them against predefined condition. Augmented Reality\nmodule captures real-time image data streams from high resolution camera. This\nmodule then generates 3D model that is superimposed on real time data.",
    "published": "2012-07-11T11:17:28Z",
    "link": "http://arxiv.org/pdf/1207.2597v1.pdf",
    "category": [
      "cs.CV",
      "cs.ET",
      "cs.GR",
      "cs.HC"
    ],
    "authors": [
      "Saket Warade",
      "Jagannath Aghav",
      "Petitpierre Claude",
      "Sandeep Udayagiri"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1207.2959v1",
    "title": "Hypothesis Testing in Speckled Data with Stochastic Distances",
    "summary": "Images obtained with coherent illumination, as is the case of sonar,\nultrasound-B, laser and Synthetic Aperture Radar -- SAR, are affected by\nspeckle noise which reduces the ability to extract information from the data.\nSpecialized techniques are required to deal with such imagery, which has been\nmodeled by the G0 distribution and under which regions with different degrees\nof roughness and mean brightness can be characterized by two parameters; a\nthird parameter, the number of looks, is related to the overall signal-to-noise\nratio. Assessing distances between samples is an important step in image\nanalysis; they provide grounds of the separability and, therefore, of the\nperformance of classification procedures. This work derives and compares eight\nstochastic distances and assesses the performance of hypothesis tests that\nemploy them and maximum likelihood estimation. We conclude that tests based on\nthe triangular distance have the closest empirical size to the theoretical one,\nwhile those based on the arithmetic-geometric distances have the best power.\nSince the power of tests based on the triangular distance is close to optimum,\nwe conclude that the safest choice is using this distance for hypothesis\ntesting, even when compared with classical distances as Kullback-Leibler and\nBhattacharyya.",
    "published": "2012-07-12T13:45:41Z",
    "link": "http://arxiv.org/pdf/1207.2959v1.pdf",
    "category": [
      "stat.ML",
      "cs.GR"
    ],
    "authors": [
      "Abrao D. C. Nascimento",
      "Renato J. Cintra",
      "Alejandro C. Frery"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1207.3351v1",
    "title": "Combining Brain-Computer Interfaces and Haptics: Detecting Mental\n  Workload to Adapt Haptic Assistance",
    "summary": "In this paper we introduce the combined use of Brain-Computer Interfaces\n(BCI) and Haptic interfaces. We propose to adapt haptic guides based on the\nmental activity measured by a BCI system. This novel approach is illustrated\nwithin a proof-of-concept system: haptic guides are toggled during a\npath-following task thanks to a mental workload index provided by a BCI. The\naim of this system is to provide haptic assistance only when the user's brain\nactivity reflects a high mental workload. A user study conducted with 8\nparticipants shows that our proof-of-concept is operational and exploitable.\nResults show that activation of haptic guides occurs in the most difficult part\nof the path-following task. Moreover it allows to increase task performance by\n53% by activating assistance only 59% of the time. Taken together, these\nresults suggest that BCI could be used to determine when the user needs\nassistance during haptic interaction and to enable haptic guides accordingly.",
    "published": "2012-07-13T13:13:27Z",
    "link": "http://arxiv.org/pdf/1207.3351v1.pdf",
    "category": [
      "cs.GR",
      "cs.HC"
    ],
    "authors": [
      "Laurent George",
      "Maud Marchal",
      "Loez Glondu",
      "Anatole Lcuyer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1207.3899v1",
    "title": "Fast View Frustum Culling of Spatial Object by Analytical Bounding Bin",
    "summary": "It is a common sense to apply the VFC (view frustum culling) of spatial\nobject to bounding cube of the object in 3D graphics. The accuracy of VFC can\nnot be guaranteed even in cube rotated three-dimensionally. In this paper is\nproposed a method which is able to carry out more precise and fast VFC of any\nspatial object in the image domain of cube by an analytic mapping, and is\ndemonstrated the effect of the method for terrain block on global surface.",
    "published": "2012-07-17T07:17:27Z",
    "link": "http://arxiv.org/pdf/1207.3899v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Munsu Ju",
      "Yunchol Jong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1207.3921v1",
    "title": "PlotXY: a high quality plotting system for the Herschel Interactive\n  Processing Environment (HIPE), and the astronomical community",
    "summary": "The Herschel Interactive Processing Environment (HIPE) was developed by the\nEuropean Space Agency (ESA) in collaboration with NASA and the Herschel\nInstrument Control Centres to provide the astronomical community a complete\nenvironment to process and analyze the data gathered by the Herschel Space\nObservatory. One of the most important components of HIPE is the plotting\nsystem (named PlotXY) that we present here. With PlotXY it is possible to\nproduce easily high quality publication ready 2D plots. It provides a long list\nof features, with fully configurable components, and interactive zooming. The\nentire code of HIPE is written in Java and is open source released under the\nGNU Lesser General Public License version 3. A new version of PlotXY is being\ndeveloped to be independent from the HIPE code base; it is available to the\nsoftware development community for the inclusion in other projects at the URL\nhttp://code.google.com/p/jplot2d/.",
    "published": "2012-07-17T09:06:59Z",
    "link": "http://arxiv.org/pdf/1207.3921v1.pdf",
    "category": [
      "cs.GR",
      "astro-ph.IM"
    ],
    "authors": [
      "Pasquale Panuzzo",
      "Jinjing Li",
      "Emmanuel Caux"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1208.1679v1",
    "title": "Color Assessment and Transfer for Web Pages",
    "summary": "Colors play a particularly important role in both designing and accessing Web\npages. A well-designed color scheme improves Web pages' visual aesthetic and\nfacilitates user interactions. As far as we know, existing color assessment\nstudies focus on images; studies on color assessment and editing for Web pages\nare rare. This paper investigates color assessment for Web pages based on\nexisting online color theme-rating data sets and applies this assessment to Web\ncolor edit. This study consists of three parts. First, we study the extraction\nof a Web page's color theme. Second, we construct color assessment models that\nscore the color compatibility of a Web page by leveraging machine learning\ntechniques. Third, we incorporate the learned color assessment model into a new\napplication, namely, color transfer for Web pages. Our study combines\ntechniques from computer graphics, Web mining, computer vision, and machine\nlearning. Experimental results suggest that our constructed color assessment\nmodels are effective, and useful in the color transfer for Web pages, which has\nreceived little attention in both Web mining and computer graphics communities.",
    "published": "2012-08-07T02:24:36Z",
    "link": "http://arxiv.org/pdf/1208.1679v1.pdf",
    "category": [
      "cs.HC",
      "cs.CV",
      "cs.GR",
      "H.4.m; H.2.8"
    ],
    "authors": [
      "Ou Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1208.1983v1",
    "title": "An algorithm for improving the quality of compacted JPEG image by\n  minimizes the blocking artifacts",
    "summary": "The Block Transform Coded, JPEG- a lossy image compression format has been\nused to keep storage and bandwidth requirements of digital image at practical\nlevels. However, JPEG compression schemes may exhibit unwanted image artifacts\nto appear - such as the 'blocky' artifact found in smooth/monotone areas of an\nimage, caused by the coarse quantization of DCT coefficients. A number of image\nfiltering approaches have been analyzed in literature incorporating\nvalue-averaging filters in order to smooth out the discontinuities that appear\nacross DCT block boundaries. Although some of these approaches are able to\ndecrease the severity of these unwanted artifacts to some extent, other\napproaches have certain limitations that cause excessive blurring to\nhigh-contrast edges in the image. The image deblocking algorithm presented in\nthis paper aims to filter the blocked boundaries. This is accomplished by\nemploying smoothening, detection of blocked edges and then filtering the\ndifference between the pixels containing the blocked edge. The deblocking\nalgorithm presented has been successful in reducing blocky artifacts in an\nimage and therefore increases the subjective as well as objective quality of\nthe reconstructed image.",
    "published": "2012-08-09T17:47:07Z",
    "link": "http://arxiv.org/pdf/1208.1983v1.pdf",
    "category": [
      "cs.GR",
      "68U10",
      "I.4.2"
    ],
    "authors": [
      "Sukhpal Singh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1208.3794v1",
    "title": "General Midpoint Subdivision",
    "summary": "In this paper, we introduce two generalizations of midpoint subdivision and\nanalyze the smoothness of the resulting subdivision surfaces at regular and\nextraordinary points.\n  The smoothing operators used in midpoint and mid-edge subdivision connect the\nmidpoints of adjacent faces or of adjacent edges, respectively. An arbitrary\ncombination of these two operators and the refinement operator that splits each\nface with m vertices into m quadrilateral subfaces forms a general midpoint\nsubdivision operator. We analyze the smoothness of the resulting subdivision\nsurfaces by estimating the norm of a special second order difference scheme and\nby using established methods for analyzing midpoint subdivision. The surfaces\nare smooth at their regular points and they are also smooth at extraordinary\npoints for a certain subclass of general midpoint subdivision schemes.\n  Generalizing the smoothing rules of non general midpoint subdivision schemes\naround extraordinary and regular vertices or faces results in a class of\nsubdivision schemes, which includes the Catmull-Clark algorithm with restricted\nparameters. We call these subdivision schemes generalized Catmull-Clark schemes\nand we analyze their smoothness properties.",
    "published": "2012-08-18T23:40:24Z",
    "link": "http://arxiv.org/pdf/1208.3794v1.pdf",
    "category": [
      "cs.GR",
      "math.NA",
      "65D18, 65D17, 68U07, 68U05",
      "I.3.5"
    ],
    "authors": [
      "Qi Chen",
      "Hartmut Prautzsch"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1208.5124v1",
    "title": "A Novel Data Hiding Scheme for Binary Images",
    "summary": "This paper presents a new scheme for hiding a secret message in binary\nimages. Given m*n cover image block, the new scheme can conceal as many as\nlog(m*n +1) bits of data in block, by changing at most one bit in the block.\nThe hiding ability of the new scheme is the same as Chang et al.'s scheme and\nhigher than Tseng et al.'s scheme. Additionally, the security of the new scheme\nis higher than the two above schemes.",
    "published": "2012-08-25T10:45:55Z",
    "link": "http://arxiv.org/pdf/1208.5124v1.pdf",
    "category": [
      "cs.CR",
      "cs.GR"
    ],
    "authors": [
      "Do Van Tuan",
      "Tran Dang Hien",
      "Pham Van At"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1209.0999v1",
    "title": "Visual Exploration of Simulated and Measured Blood Flow",
    "summary": "Morphology of cardiovascular tissue is influenced by the unsteady behavior of\nthe blood flow and vice versa. Therefore, the pathogenesis of several\ncardiovascular diseases is directly affected by the blood-flow dynamics.\nUnderstanding flow behavior is of vital importance to understand the\ncardiovascular system and potentially harbors a considerable value for both\ndiagnosis and risk assessment. The analysis of hemodynamic characteristics\ninvolves qualitative and quantitative inspection of the blood-flow field.\nVisualization plays an important role in the qualitative exploration, as well\nas the definition of relevant quantitative measures and its validation. There\nare two main approaches to obtain information about the blood flow: simulation\nby computational fluid dynamics, and in-vivo measurements. Although research on\nblood flow simulation has been performed for decades, many open problems remain\nconcerning accuracy and patient-specific solutions. Possibilities for real\nmeasurement of blood flow have recently increased considerably by new\ndevelopments in magnetic resonance imaging which enable the acquisition of 3D\nquantitative measurements of blood-flow velocity fields. This chapter presents\nthe visualization challenges for both simulation and real measurements of\nunsteady blood-flow fields.",
    "published": "2012-09-05T14:47:55Z",
    "link": "http://arxiv.org/pdf/1209.0999v1.pdf",
    "category": [
      "cs.GR",
      "cs.CV"
    ],
    "authors": [
      "Anna Vilanova",
      "Bernhard Preim",
      "Roy van Pelt",
      "Rocco Gasteiger",
      "Mathias Neugebauer",
      "Thomas Wischgoll"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1209.4982v1",
    "title": "Using multimodal speech production data to evaluate articulatory\n  animation for audiovisual speech synthesis",
    "summary": "The importance of modeling speech articulation for high-quality audiovisual\n(AV) speech synthesis is widely acknowledged. Nevertheless, while\nstate-of-the-art, data-driven approaches to facial animation can make use of\nsophisticated motion capture techniques, the animation of the intraoral\narticulators (viz. the tongue, jaw, and velum) typically makes use of simple\nrules or viseme morphing, in stark contrast to the otherwise high quality of\nfacial modeling. Using appropriate speech production data could significantly\nimprove the quality of articulatory animation for AV synthesis.",
    "published": "2012-09-22T10:36:11Z",
    "link": "http://arxiv.org/pdf/1209.4982v1.pdf",
    "category": [
      "cs.HC",
      "cs.GR"
    ],
    "authors": [
      "Ingmar Steiner",
      "Korin Richmond",
      "Slim Ouni"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1209.6491v3",
    "title": "Review of Statistical Shape Spaces for 3D Data with Comparative Analysis\n  for Human Faces",
    "summary": "With systems for acquiring 3D surface data being evermore commonplace, it has\nbecome important to reliably extract specific shapes from the acquired data. In\nthe presence of noise and occlusions, this can be done through the use of\nstatistical shape models, which are learned from databases of clean examples of\nthe shape in question. In this paper, we review, analyze and compare different\nstatistical models: from those that analyze the variation in geometry globally\nto those that analyze the variation in geometry locally. We first review how\ndifferent types of models have been used in the literature, then proceed to\ndefine the models and analyze them theoretically, in terms of both their\nstatistical and computational aspects. We then perform extensive experimental\ncomparison on the task of model fitting, and give intuition about which type of\nmodel is better for a few applications. Due to the wide availability of\ndatabases of high-quality data, we use the human face as the specific shape we\nwish to extract from corrupted data.",
    "published": "2012-09-28T11:48:59Z",
    "link": "http://arxiv.org/pdf/1209.6491v3.pdf",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "Alan Brunton",
      "Augusto Salazar",
      "Timo Bolkart",
      "Stefanie Wuhrer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1209.6560v1",
    "title": "Sparse Modeling of Intrinsic Correspondences",
    "summary": "We present a novel sparse modeling approach to non-rigid shape matching using\nonly the ability to detect repeatable regions. As the input to our algorithm,\nwe are given only two sets of regions in two shapes; no descriptors are\nprovided so the correspondence between the regions is not know, nor we know how\nmany regions correspond in the two shapes. We show that even with such scarce\ninformation, it is possible to establish very accurate correspondence between\nthe shapes by using methods from the field of sparse modeling, being this, the\nfirst non-trivial use of sparse models in shape correspondence. We formulate\nthe problem of permuted sparse coding, in which we solve simultaneously for an\nunknown permutation ordering the regions on two shapes and for an unknown\ncorrespondence in functional representation. We also propose a robust variant\ncapable of handling incomplete matches. Numerically, the problem is solved\nefficiently by alternating the solution of a linear assignment and a sparse\ncoding problem. The proposed methods are evaluated qualitatively and\nquantitatively on standard benchmarks containing both synthetic and scanned\nobjects.",
    "published": "2012-09-28T16:05:37Z",
    "link": "http://arxiv.org/pdf/1209.6560v1.pdf",
    "category": [
      "cs.GR",
      "cs.CG",
      "cs.CV"
    ],
    "authors": [
      "J. Pokrass",
      "A. M. Bronstein",
      "M. M. Bronstein",
      "P. Sprechmann",
      "G. Sapiro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1210.0026v1",
    "title": "Coupled quasi-harmonic bases",
    "summary": "The use of Laplacian eigenbases has been shown to be fruitful in many\ncomputer graphics applications. Today, state-of-the-art approaches to shape\nanalysis, synthesis, and correspondence rely on these natural harmonic bases\nthat allow using classical tools from harmonic analysis on manifolds. However,\nmany applications involving multiple shapes are obstacled by the fact that\nLaplacian eigenbases computed independently on different shapes are often\nincompatible with each other. In this paper, we propose the construction of\ncommon approximate eigenbases for multiple shapes using approximate joint\ndiagonalization algorithms. We illustrate the benefits of the proposed approach\non tasks from shape editing, pose transfer, correspondence, and similarity.",
    "published": "2012-09-28T20:29:37Z",
    "link": "http://arxiv.org/pdf/1210.0026v1.pdf",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "A. Kovnatsky",
      "M. M. Bronstein",
      "A. M. Bronstein",
      "K. Glashoff",
      "R. Kimmel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1210.0228v1",
    "title": "Invariance And Inner Fractals In Polynomial And Transcendental Fractals",
    "summary": "A lot of formal and informal recreational study took place in the fields of\nMeromorphic Maps, since Mandelbrot popularized the map z <- z^2 + c. An\nimmediate generalization of the Mandelbrot z <-z^n + c also known as the\nMultibrot family were also studied. In the current paper, general truncated\npolynomial maps of the form z <- \\sum_{p>=2} a_px^p +c are studied. Two\nfundamental properties of these polynomial maps are hereby presented. One of\nthem is the existence of shape preserving transformations on fractal images,\nand another one is the existence of embedded Multibrot fractals inside a\npolynomial fractal. Any transform expression with transcendental terms also\nshows embedded Multibrot fractals, due to Taylor series expansion possible on\nthe transcendental functions. We present a method by which existence of\nembedded fractals can be predicted. A gallery of images is presented alongside\nto showcase the findings.",
    "published": "2012-09-30T18:22:20Z",
    "link": "http://arxiv.org/pdf/1210.0228v1.pdf",
    "category": [
      "math.DS",
      "cs.GR",
      "nlin.PS"
    ],
    "authors": [
      "Nabarun Mondal",
      "Partha P. Ghosh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1210.0880v1",
    "title": "Schrdinger Diffusion for Shape Analysis with Texture",
    "summary": "In recent years, quantities derived from the heat equation have become\npopular in shape processing and analysis of triangulated surfaces. Such\nmeasures are often robust with respect to different kinds of perturbations,\nincluding near-isometries, topological noise and partialities. Here, we propose\nto exploit the semigroup of a Schr\\\"{o}dinger operator in order to deal with\ntexture data, while maintaining the desirable properties of the heat kernel. We\ndefine a family of Schr\\\"{o}dinger diffusion distances analogous to the ones\nassociated to the heat kernels, and show that they are continuous under\nperturbations of the data. As an application, we introduce a method for\nretrieval of textured shapes through comparison of Schr\\\"{o}dinger diffusion\ndistance histograms with the earth's mover distance, and present some numerical\nexperiments showing superior performance compared to an analogous method that\nignores the texture.",
    "published": "2012-10-02T19:03:04Z",
    "link": "http://arxiv.org/pdf/1210.0880v1.pdf",
    "category": [
      "cs.CV",
      "cs.CG",
      "cs.GR",
      "math.AP",
      "68U05, 35K08",
      "I.3.5; I.2.10; G.1.8"
    ],
    "authors": [
      "Jose A. Iglesias",
      "Ron Kimmel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1210.1192v3",
    "title": "Reduction of Blocking Artifacts In JPEG Compressed Image",
    "summary": "In JPEG (DCT based) compresses image data by representing the original image\nwith a small number of transform coefficients. It exploits the fact that for\ntypical images a large amount of signal energy is concentrated in a small\nnumber of coefficients. The goal of DCT transform coding is to minimize the\nnumber of retained transform coefficients while keeping distortion at an\nacceptable level.In JPEG, it is done in 8X8 non overlapping blocks. It divides\nan image into blocks of equal size and processes each block independently.\nBlock processing allows the coder to adapt to the local image statistics,\nexploit the correlation present among neighboring image pixels, and to reduce\ncomputational and storage requirements. One of the most degradation of the\nblock transform coding is the blocking artifact. These artifacts appear as a\nregular pattern of visible block boundaries. This degradation is a direct\nresult of the coarse quantization of the coefficients and the independent\nprocessing of the blocks which does not take into account the existing\ncorrelations among adjacent block pixels. In this paper attempt is being made\nto reduce the blocking artifact introduced by the Block DCT Transform in JPEG.",
    "published": "2012-10-03T18:53:36Z",
    "link": "http://arxiv.org/pdf/1210.1192v3.pdf",
    "category": [
      "cs.GR",
      "cs.MM",
      "68U10",
      "I.4.2"
    ],
    "authors": [
      "Sukhpal Singh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1210.3325v3",
    "title": "Vortices within vortices: hierarchical nature of vortex tubes in\n  turbulence",
    "summary": "The JHU turbulence database [1] can be used with a state of the art\nvisualisation tool [2] to generate high quality fluid dynamics videos. In this\nwork we investigate the classical idea that smaller structures in turbulent\nflows, while engaged in their own internal dynamics, are advected by the larger\nstructures. They are not advected undistorted, however. We see instead that the\nsmall scale structures are sheared and twisted by the larger scales. This\nilluminates the basic mechanisms of the turbulent cascade.",
    "published": "2012-10-11T19:14:50Z",
    "link": "http://arxiv.org/pdf/1210.3325v3.pdf",
    "category": [
      "physics.flu-dyn",
      "cs.GR"
    ],
    "authors": [
      "Kai Brger",
      "Marc Treib",
      "Rdiger Westermann",
      "Suzanne Werner",
      "Cristian C Lalescu",
      "Alexander Szalay",
      "Charles Meneveau",
      "Gregory L Eyink"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1210.8025v1",
    "title": "Beltrami Representation and its applications to texture map and video\n  compression",
    "summary": "Surface parameterizations and registrations are important in computer\ngraphics and imaging, where 1-1 correspondences between meshes are computed. In\npractice, surface maps are usually represented and stored as 3D coordinates\neach vertex is mapped to, which often requires lots of storage memory. This\ncauses inconvenience in data transmission and data storage. To tackle this\nproblem, we propose an effective algorithm for compressing surface\nhomeomorphisms using Fourier approximation of the Beltrami representation. The\nBeltrami representation is a complex-valued function defined on triangular\nfaces of the surface mesh with supreme norm strictly less than 1. Under\nsuitable normalization, there is a 1-1 correspondence between the set of\nsurface homeomorphisms and the set of Beltrami representations. Hence, every\nbijective surface map is associated with a unique Beltrami representation.\nConversely, given a Beltrami representation, the corresponding bijective\nsurface map can be exactly reconstructed using the Linear Beltrami Solver\nintroduced in this paper. Using the Beltrami representation, the surface\nhomeomorphism can be easily compressed by Fourier approximation, without\ndistorting the bijectivity of the map. The storage memory can be effectively\nreduced, which is useful for many practical problems in computer graphics and\nimaging. In this paper, we proposed to apply the algorithm to texture map\ncompression and video compression. With our proposed algorithm, the storage\nrequirement for the texture properties of a textured surface can be\nsignificantly reduced. Our algorithm can further be applied to compressing\nmotion vector fields for video compression, which effectively improve the\ncompression ratio.",
    "published": "2012-10-18T12:17:12Z",
    "link": "http://arxiv.org/pdf/1210.8025v1.pdf",
    "category": [
      "cs.MM",
      "cs.GR",
      "math.DG"
    ],
    "authors": [
      "Lok Ming Lui",
      "Ka Chun Lam",
      "Tsz Wai Wong",
      "XianFeng Gu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1210.6192v1",
    "title": "Textural Approach to Palmprint Identification",
    "summary": "Biometrics which use of human physiological characteristics for identifying\nan individual is now a widespread method of identification and authentication.\nBiometric identification is a technology which uses several image processing\ntechniques and describes the general procedure for identification and\nverification using feature extraction, storage and matching from the digitized\nimage of biometric characters such as Finger Print, Face, Iris or Palm Print.\nThe current paper uses palm print biometrics. Here we have presented an\nidentification approach using textural properties of palm print images. The\nelegance of the method is that the conventional edge detection technique is\nextended to suitably describe the texture features. In this technique all the\ncharacteristics of the palm such as principal lines, edges and wrinkles are\nconsidered with equal importance.",
    "published": "2012-10-23T10:52:31Z",
    "link": "http://arxiv.org/pdf/1210.6192v1.pdf",
    "category": [
      "cs.CV",
      "cs.CR",
      "cs.GR"
    ],
    "authors": [
      "Rachita Misra",
      "Kasturika B ray"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1211.0729v8",
    "title": "A Simple Algorithm for Computing BOCP",
    "summary": "In this article, we devise a concise algorithm for computing BOCP. Our method\nis simple, easy-to-implement but without loss of efficiency. Given two\ncircular-arc polygons with $m$ and $n$ edges respectively, our method runs in\n$O(m+n+(l+k)\\log l)$ time, using $O(m+n+k)$ space, where $k$ is the number of\nintersections, and $l$ is the number of {edge}s. Our algorithm has the power to\napproximate to linear complexity when $k$ and $l$ are small. The superiority of\nthe proposed algorithm is also validated through empirical study.",
    "published": "2012-11-04T22:38:11Z",
    "link": "http://arxiv.org/pdf/1211.0729v8.pdf",
    "category": [
      "cs.DS",
      "cs.CG",
      "cs.GR",
      "E.1; I.3.5; I.3.6"
    ],
    "authors": [
      "Jack Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1211.1768v2",
    "title": "Nearest Neighbor Value Interpolation",
    "summary": "This paper presents the nearest neighbor value (NNV) algorithm for high\nresolution (H.R.) image interpolation. The difference between the proposed\nalgorithm and conventional nearest neighbor algorithm is that the concept\napplied, to estimate the missing pixel value, is guided by the nearest value\nrather than the distance. In other words, the proposed concept selects one\npixel, among four directly surrounding the empty location, whose value is\nalmost equal to the value generated by the conventional bilinear interpolation\nalgorithm. The proposed method demonstrated higher performances in terms of\nH.R. when compared to the conventional interpolation algorithms mentioned.",
    "published": "2012-11-08T06:50:44Z",
    "link": "http://arxiv.org/pdf/1211.1768v2.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Olivier Rukundo",
      "Hanqiang Cao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1211.2569v1",
    "title": "Teichmller extremal mapping and its applications to landmark matching\n  registration",
    "summary": "Registration, which aims to find an optimal 1-1 correspondence between\nshapes, is an important process in different research areas. Conformal mappings\nhave been widely used to obtain a diffeomorphism between shapes that minimizes\nangular distortion. Conformal registrations are beneficial since it preserves\nthe local geometry well. However, when landmark constraints are enforced,\nconformal mappings generally do not exist. This motivates us to look for a\nunique landmark matching quasi-conformal registration, which minimizes the\nconformality distortion. Under suitable condition on the landmark constraints,\na unique diffeomporphism, called the Teichm\\\"uller extremal mapping between two\nsurfaces can be obtained, which minimizes the maximal conformality distortion.\nIn this paper, we propose an efficient iterative algorithm, called the\nQuasi-conformal (QC) iterations, to compute the Teichm\\\"uller mapping. The\nbasic idea is to represent the set of diffeomorphisms using Beltrami\ncoefficients (BCs), and look for an optimal BC associated to the desired\nTeichm\\\"uller mapping. The associated diffeomorphism can be efficiently\nreconstructed from the optimal BC using the Linear Beltrami Solver(LBS). Using\nBCs to represent diffeomorphisms guarantees the diffeomorphic property of the\nregistration. Using our proposed method, the Teichm\\\"uller mapping can be\naccurately and efficiently computed within 10 seconds. The obtained\nregistration is guaranteed to be bijective. The proposed algorithm can also be\nextended to compute Teichm\\\"uller mapping with soft landmark constraints. We\napplied the proposed algorithm to real applications, such as brain landmark\nmatching registration, constrained texture mapping and human face registration.\nExperimental results shows that our method is both effective and efficient in\ncomputing a non-overlap landmark matching registration with least amount of\nconformality distortion.",
    "published": "2012-11-12T11:16:31Z",
    "link": "http://arxiv.org/pdf/1211.2569v1.pdf",
    "category": [
      "cs.CG",
      "cs.GR",
      "cs.MM",
      "math.DG"
    ],
    "authors": [
      "Lok Ming Lui",
      "Ka Chun Lam",
      "Shing-Tung Yau",
      "Xianfeng Gu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1211.3297v2",
    "title": "Gap Processing for Adaptive Maximal Poisson-Disk Sampling",
    "summary": "In this paper, we study the generation of maximal Poisson-disk sets with\nvarying radii. First, we present a geometric analysis of gaps in such disk\nsets. This analysis is the basis for maximal and adaptive sampling in Euclidean\nspace and on manifolds. Second, we propose efficient algorithms and data\nstructures to detect gaps and update gaps when disks are inserted, deleted,\nmoved, or have their radius changed. We build on the concepts of the regular\ntriangulation and the power diagram. Third, we will show how our analysis can\nmake a contribution to the state-of-the-art in surface remeshing.",
    "published": "2012-11-14T13:21:03Z",
    "link": "http://arxiv.org/pdf/1211.3297v2.pdf",
    "category": [
      "cs.GR",
      "I.3.6"
    ],
    "authors": [
      "Dong-Ming Yan",
      "Peter Wonka"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1211.3659v1",
    "title": "Color scales that are effective in both color and grayscale",
    "summary": "We consider the problem of finding a color scale which performs well when\nconverted to a grayscale. We assume that each color is converted to a shade of\ngray with the same intensity as the color. We also assume that the color scales\nhave a linear variation of intensity and hue, and find scales which maximize\nthe average chroma (or \"colorfulness\") of the colors. We find two classes of\nsolutions, which traverse the color wheel in opposite directions. The two\nclasses of scales start with hues near cyan and red. The average chroma of the\nscales are 65-77% those of the pure colors.",
    "published": "2012-11-15T17:08:58Z",
    "link": "http://arxiv.org/pdf/1211.3659v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Silas Alben"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1211.4500v1",
    "title": "Dynamic Facial Expression of Emotion Made Easy",
    "summary": "Facial emotion expression for virtual characters is used in a wide variety of\nareas. Often, the primary reason to use emotion expression is not to study\nemotion expression generation per se, but to use emotion expression in an\napplication or research project. What is then needed is an easy to use and\nflexible, but also validated mechanism to do so. In this report we present such\na mechanism. It enables developers to build virtual characters with dynamic\naffective facial expressions. The mechanism is based on Facial Action Coding.\nIt is easy to implement, and code is available for download. To show the\nvalidity of the expressions generated with the mechanism we tested the\nrecognition accuracy for 6 basic emotions (joy, anger, sadness, surprise,\ndisgust, fear) and 4 blend emotions (enthusiastic, furious, frustrated, and\nevil). Additionally we investigated the effect of VC distance (z-coordinate),\nthe effect of the VC's face morphology (male vs. female), the effect of a\nlateral versus a frontal presentation of the expression, and the effect of\nintensity of the expression. Participants (n=19, Western and Asian subjects)\nrated the intensity of each expression for each condition (within subject\nsetup) in a non forced choice manner. All of the basic emotions were uniquely\nperceived as such. Further, the blends and confusion details of basic emotions\nare compatible with findings in psychology.",
    "published": "2012-11-19T17:10:50Z",
    "link": "http://arxiv.org/pdf/1211.4500v1.pdf",
    "category": [
      "cs.HC",
      "cs.GR"
    ],
    "authors": [
      "Joost Broekens",
      "Chao Qu",
      "Willem-Paul Brinkman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1211.4896v1",
    "title": "Tera-scale Astronomical Data Analysis and Visualization",
    "summary": "We present a high-performance, graphics processing unit (GPU)-based framework\nfor the efficient analysis and visualization of (nearly) terabyte (TB)-sized\n3-dimensional images. Using a cluster of 96 GPUs, we demonstrate for a 0.5 TB\nimage: (1) volume rendering using an arbitrary transfer function at 7--10\nframes per second; (2) computation of basic global image statistics such as the\nmean intensity and standard deviation in 1.7 s; (3) evaluation of the image\nhistogram in 4 s; and (4) evaluation of the global image median intensity in\njust 45 s. Our measured results correspond to a raw computational throughput\napproaching one teravoxel per second, and are 10--100 times faster than the\nbest possible performance with traditional single-node, multi-core CPU\nimplementations. A scalability analysis shows the framework will scale well to\nimages sized 1 TB and beyond. Other parallel data analysis algorithms can be\nadded to the framework with relative ease, and accordingly, we present our\nframework as a possible solution to the image analysis and visualization\nrequirements of next-generation telescopes, including the forthcoming Square\nKilometre Array pathfinder radiotelescopes.",
    "published": "2012-11-20T23:00:51Z",
    "link": "http://arxiv.org/pdf/1211.4896v1.pdf",
    "category": [
      "astro-ph.IM",
      "cs.DC",
      "cs.GR"
    ],
    "authors": [
      "A. H. Hassan",
      "C. J. Fluke",
      "D. G. Barnes",
      "V. A. Kilborn"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1211.5556v1",
    "title": "Improving Perceptual Color Difference using Basic Color Terms",
    "summary": "We suggest a new color distance based on two observations. First, perceptual\ncolor differences were designed to be used to compare very similar colors. They\ndo not capture human perception for medium and large color differences well.\nThresholding was proposed to solve the problem for large color differences,\ni.e. two totally different colors are always the same distance apart. We show\nthat thresholding alone cannot improve medium color differences. We suggest to\nalleviate this problem using basic color terms. Second, when a color distance\nis used for edge detection, many small distances around the just noticeable\ndifference may account for false edges. We suggest to reduce the effect of\nsmall distances.",
    "published": "2012-11-23T17:13:07Z",
    "link": "http://arxiv.org/pdf/1211.5556v1.pdf",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "Ofir Pele",
      "Michael Werman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1211.5669v1",
    "title": "Analysis-suitable T-splines: characterization, refineability, and\n  approximation",
    "summary": "We establish several fundamental properties of analysis-suitable T-splines\nwhich are important for design and analysis. First, we characterize T-spline\nspaces and prove that the space of smooth bicubic polynomials, defined over the\nextended T-mesh of an analysis-suitable T-spline, is contained in the\ncorresponding analysis-suitable T-spline space. This is accomplished through\nthe theory of perturbed analysis-suitable T-spline spaces and a simple\ntopological dimension formula. Second, we establish the theory of\nanalysis-suitable local refinement and describe the conditions under which two\nanalysis-suitable T-spline spaces are nested. Last, we demonstrate that these\nresults can be used to establish basic approximation results which are critical\nfor analysis.",
    "published": "2012-11-24T12:56:58Z",
    "link": "http://arxiv.org/pdf/1211.5669v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Xin Li",
      "M. A. Scott"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1211.5842v1",
    "title": "A Novel Algorithm for Real-time Procedural Generation of Building Floor\n  Plans",
    "summary": "Real-time generation of natural-looking floor plans is vital in games with\ndynamic environments. This paper presents an algorithm to generate suburban\nhouse floor plans in real-time. The algorithm is based on the work presented in\n[1]. However, the corridor placement is redesigned to produce floor plans\nsimilar to real houses. Moreover, an optimization stage is added to find a\ncorridor placement with the minimum used space, an approach that is designed to\nmimic the real-life practices to minimize the wasted spaces in the design. The\nresults show very similar floor plans to the ones designed by an architect.",
    "published": "2012-11-26T02:13:52Z",
    "link": "http://arxiv.org/pdf/1211.5842v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Maysam Mirahmadi",
      "Abdallah Shami"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1212.0981v1",
    "title": "A Conformal Approach for Surface Inpainting",
    "summary": "We address the problem of surface inpainting, which aims to fill in holes or\nmissing regions on a Riemann surface based on its surface geometry. In\npractical situation, surfaces obtained from range scanners often have holes\nwhere the 3D models are incomplete. In order to analyze the 3D shapes\neffectively, restoring the incomplete shape by filling in the surface holes is\nnecessary. In this paper, we propose a novel conformal approach to inpaint\nsurface holes on a Riemann surface based on its surface geometry. The basic\nidea is to represent the Riemann surface using its conformal factor and mean\ncurvature. According to Riemann surface theory, a Riemann surface can be\nuniquely determined by its conformal factor and mean curvature up to a rigid\nmotion. Given a Riemann surface $S$, its mean curvature $H$ and conformal\nfactor $\\lambda$ can be computed easily through its conformal parameterization.\nConversely, given $\\lambda$ and $H$, a Riemann surface can be uniquely\nreconstructed by solving the Gauss-Codazzi equation on the conformal parameter\ndomain. Hence, the conformal factor and the mean curvature are two geometric\nquantities fully describing the surface. With this $\\lambda$-$H$ representation\nof the surface, the problem of surface inpainting can be reduced to the problem\nof image inpainting of $\\lambda$ and $H$ on the conformal parameter domain.\nOnce $\\lambda$ and $H$ are inpainted, a Riemann surface can be reconstructed\nwhich effectively restores the 3D surface with missing holes. Since the\ninpainting model is based on the geometric quantities $\\lambda$ and $H$, the\nrestored surface follows the surface geometric pattern. We test the proposed\nalgorithm on synthetic data as well as real surface data. Experimental results\nshow that our proposed method is an effective surface inpainting algorithm to\nfill in surface holes on an incomplete 3D models based their surface geometry.",
    "published": "2012-12-05T10:01:23Z",
    "link": "http://arxiv.org/pdf/1212.0981v1.pdf",
    "category": [
      "math.DG",
      "cs.CG",
      "cs.GR",
      "cs.MM"
    ],
    "authors": [
      "Lok Ming Lui",
      "Chengfeng Wen",
      "Xianfeng Gu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1212.1617v2",
    "title": "Similarity of Polygonal Curves in the Presence of Outliers",
    "summary": "The Fr\\'{e}chet distance is a well studied and commonly used measure to\ncapture the similarity of polygonal curves. Unfortunately, it exhibits a high\nsensitivity to the presence of outliers. Since the presence of outliers is a\nfrequently occurring phenomenon in practice, a robust variant of Fr\\'{e}chet\ndistance is required which absorbs outliers. We study such a variant here. In\nthis modified variant, our objective is to minimize the length of subcurves of\ntwo polygonal curves that need to be ignored (MinEx problem), or alternately,\nmaximize the length of subcurves that are preserved (MaxIn problem), to achieve\na given Fr\\'{e}chet distance. An exact solution to one problem would imply an\nexact solution to the other problem. However, we show that these problems are\nnot solvable by radicals over $\\mathbb{Q}$ and that the degree of the\npolynomial equations involved is unbounded in general. This motivates the\nsearch for approximate solutions. We present an algorithm, which approximates,\nfor a given input parameter $\\delta$, optimal solutions for the \\MinEx\\ and\n\\MaxIn\\ problems up to an additive approximation error $\\delta$ times the\nlength of the input curves. The resulting running time is upper bounded by\n$\\mathcal{O} \\left(\\frac{n^3}{\\delta} \\log \\left(\\frac{n}{\\delta}\n\\right)\\right)$, where $n$ is the complexity of the input polygonal curves.",
    "published": "2012-12-07T14:22:12Z",
    "link": "http://arxiv.org/pdf/1212.1617v2.pdf",
    "category": [
      "cs.CG",
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "Jean-Lou De Carufel",
      "Amin Gheibi",
      "Anil Maheshwari",
      "Jrg-Rdiger Sack",
      "Christian Scheffer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1212.2845v1",
    "title": "Dynamic Simulation of Soft Heterogeneous Objects",
    "summary": "This paper describes a 2D and 3D simulation engine that quantitatively models\nthe statics, dynamics, and non-linear deformation of heterogeneous soft bodies\nin a computationally efficient manner. There is a large body of work simulating\ncompliant mechanisms. These normally assume small deformations with homogeneous\nmaterial properties actuated with external forces. There is also a large body\nof research on physically-based deformable objects for applications in computer\ngraphics with the purpose of generating realistic appearances at the expense of\naccuracy. Here we present a simulation framework in which an object may be\ncomposed of any number of interspersed materials with varying properties\n(stiffness, density, etc.) to enable true heterogeneous multi-material\nsimulation. Collisions are handled to prevent self-penetration due to large\ndeformation, which also allows multiple bodies to interact. A volumetric\nactuation method is implemented to impart motion to the structures which opens\nthe door to the design of novel structures and mechanisms. The simulator was\nimplemented efficiently such that objects with thousands of degrees of freedom\ncan be simulated at suitable framerates for user interaction using a single\nthread of a typical desktop computer. The code is written in platform agnostic\nC++ and is fully open source. This research opens the door to the dynamic\nsimulation of freeform 3D multi-material mechanisms and objects in a manner\nsuitable for design automation.",
    "published": "2012-12-12T15:41:08Z",
    "link": "http://arxiv.org/pdf/1212.2845v1.pdf",
    "category": [
      "cs.GR",
      "cs.RO",
      "physics.comp-ph"
    ],
    "authors": [
      "Jonathan Hiller",
      "Hod Lipson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1212.3333v1",
    "title": "Single-Pass GPU-Raycasting for Structured Adaptive Mesh Refinement Data",
    "summary": "Structured Adaptive Mesh Refinement (SAMR) is a popular numerical technique\nto study processes with high spatial and temporal dynamic range. It reduces\ncomputational requirements by adapting the lattice on which the underlying\ndifferential equations are solved to most efficiently represent the solution.\nParticularly in astrophysics and cosmology such simulations now can capture\nspatial scales ten orders of magnitude apart and more. The irregular locations\nand extensions of the refined regions in the SAMR scheme and the fact that\ndifferent resolution levels partially overlap, poses a challenge for GPU-based\ndirect volume rendering methods. kD-trees have proven to be advantageous to\nsubdivide the data domain into non-overlapping blocks of equally sized cells,\noptimal for the texture units of current graphics hardware, but previous\nGPU-supported raycasting approaches for SAMR data using this data structure\nrequired a separate rendering pass for each node, preventing the application of\nmany advanced lighting schemes that require simultaneous access to more than\none block of cells. In this paper we present a single-pass GPU-raycasting\nalgorithm for SAMR data that is based on a kD-tree. The tree is efficiently\nencoded by a set of 3D-textures, which allows to adaptively sample complete\nrays entirely on the GPU without any CPU interaction. We discuss two different\ndata storage strategies to access the grid data on the GPU and apply them to\nseveral datasets to prove the benefits of the proposed method.",
    "published": "2012-12-13T21:00:02Z",
    "link": "http://arxiv.org/pdf/1212.3333v1.pdf",
    "category": [
      "astro-ph.IM",
      "cs.GR"
    ],
    "authors": [
      "Ralf Kaehler",
      "Tom Abel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1212.4490v1",
    "title": "Sketch-to-Design: Context-based Part Assembly",
    "summary": "Designing 3D objects from scratch is difficult, especially when the user\nintent is fuzzy without a clear target form. In the spirit of\nmodeling-by-example, we facilitate design by providing reference and\ninspiration from existing model contexts. We rethink model design as navigating\nthrough different possible combinations of part assemblies based on a large\ncollection of pre-segmented 3D models. We propose an interactive\nsketch-to-design system, where the user sketches prominent features of parts to\ncombine. The sketched strokes are analyzed individually and in context with the\nother parts to generate relevant shape suggestions via a design gallery\ninterface. As the session progresses and more parts get selected, contextual\ncues becomes increasingly dominant and the system quickly converges to a final\ndesign. As a key enabler, we use pre-learned part-based contextual information\nto allow the user to quickly explore different combinations of parts. Our\nexperiments demonstrate the effectiveness of our approach for efficiently\ndesigning new variations from existing shapes.",
    "published": "2012-12-18T12:52:26Z",
    "link": "http://arxiv.org/pdf/1212.4490v1.pdf",
    "category": [
      "cs.GR",
      "cs.CV"
    ],
    "authors": [
      "Xiaohua Xie",
      "Kai Xu",
      "Niloy J. Mitra",
      "Daniel Cohen-Or",
      "Baoquan Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1301.0289v1",
    "title": "Reconstructing Self Organizing Maps as Spider Graphs for better visual\n  interpretation of large unstructured datasets",
    "summary": "Self-Organizing Maps (SOM) are popular unsupervised artificial neural network\nused to reduce dimensions and visualize data. Visual interpretation from\nSelf-Organizing Maps (SOM) has been limited due to grid approach of data\nrepresentation, which makes inter-scenario analysis impossible. The paper\nproposes a new way to structure SOM. This model reconstructs SOM to show\nstrength between variables as the threads of a cobweb and illuminate\ninter-scenario analysis. While Radar Graphs are very crude representation of\nspider web, this model uses more lively and realistic cobweb representation to\ntake into account the difference in strength and length of threads. This model\nallows for visualization of highly unstructured dataset with large number of\ndimensions, common in Bigdata sources.",
    "published": "2012-12-24T17:10:28Z",
    "link": "http://arxiv.org/pdf/1301.0289v1.pdf",
    "category": [
      "cs.GR",
      "stat.ML"
    ],
    "authors": [
      "Aaditya Prakash"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1212.6048v1",
    "title": "Discrete Surface Modeling Based on Google Earth: A Case Study",
    "summary": "Google Earth (GE) has become a powerful tool for geological, geophysical and\ngeographical modeling; yet GE can be accepted to acquire elevation data of\nterrain. In this paper, we present a real study case of building the discrete\nsurface model (DSM) at Haut-Barr Castle in France based on the elevation data\nof terrain points extracted from GE using the COM API. We first locate the\nposition of Haut-Barr Castle and determine the region of the study area, then\nextract elevation data of terrain at Haut-Barr, and thirdly create a planar\ntriangular mesh that covers the study area and finally generate the desired DSM\nby calculating the elevation of vertices in the planar mesh via interpolating\nwith Universal Kriging (UK) and Inverse Distance Weighting (IDW). The generated\nDSM can reflect the features of the ground surface at Haut-Barr well, and can\nbe used for constructingthe Sealed Engineering Geological Model (SEGM) in\nfurther step.",
    "published": "2012-12-25T13:23:32Z",
    "link": "http://arxiv.org/pdf/1212.6048v1.pdf",
    "category": [
      "cs.GR",
      "physics.geo-ph"
    ],
    "authors": [
      "Gang Mei",
      "John C. Tipper",
      "Nengxiong Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1212.6250v1",
    "title": "Computer-Assisted Interactive Documentary and Performance Arts in\n  Illimitable Space",
    "summary": "This major component of the research described in this thesis is 3D computer\ngraphics, specifically the realistic physics-based softbody simulation and\nhaptic responsive environments. Minor components include advanced\nhuman-computer interaction environments, non-linear documentary storytelling,\nand theatre performance. The journey of this research has been unusual because\nit requires a researcher with solid knowledge and background in multiple\ndisciplines; who also has to be creative and sensitive in order to combine the\npossible areas into a new research direction. [...] It focuses on the advanced\ncomputer graphics and emerges from experimental cinematic works and theatrical\nartistic practices. Some development content and installations are completed to\nprove and evaluate the described concepts and to be convincing. [...] To\nsummarize, the resulting work involves not only artistic creativity, but\nsolving or combining technological hurdles in motion tracking, pattern\nrecognition, force feedback control, etc., with the available documentary\nfootage on film, video, or images, and text via a variety of devices [....] and\nprogramming, and installing all the needed interfaces such that it all works in\nreal-time. Thus, the contribution to the knowledge advancement is in solving\nthese interfacing problems and the real-time aspects of the interaction that\nhave uses in film industry, fashion industry, new age interactive theatre,\ncomputer games, and web-based technologies and services for entertainment and\neducation. It also includes building up on this experience to integrate Kinect-\nand haptic-based interaction, artistic scenery rendering, and other forms of\ncontrol. This research work connects all the research disciplines, seemingly\ndisjoint fields of research, such as computer graphics, documentary film,\ninteractive media, and theatre performance together.",
    "published": "2012-12-26T20:49:45Z",
    "link": "http://arxiv.org/pdf/1212.6250v1.pdf",
    "category": [
      "cs.MM",
      "cs.CY",
      "cs.GR",
      "cs.HC"
    ],
    "authors": [
      "Miao Song"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1212.6923v1",
    "title": "The Geant4 Visualisation System - a multi-driver graphics system",
    "summary": "From the beginning the Geant4 Visualisation System was designed to support\nseveral simultaneous graphics systems written to common abstract interfaces.\nToday it has matured into a powerful diagnostic and presentational tool. It\ncomes with a library of models that may be added to the current scene and which\ninclude the representation of the Geant4 geometry hierarchy, simulated\ntrajectories and user-written hits and digitisations. The workhorse is the\nOpenGL suite of drivers for X, Xm, Qt and Win32. There is an Open Inventor\ndriver. Scenes can be exported in special graphics formats for offline viewing\nin the DAWN, VRML, HepRApp and gMocren browsers. PostScript can be generated\nthrough OpenGL, Open Inventor, DAWN and HepRApp. Geant4's own tracking\nalgorithms are used by the Ray Tracer. Not all drivers support all features but\nall drivers bring added functionality of some sort. This paper describes the\ninterfaces and details the individual drivers.",
    "published": "2012-12-31T16:41:07Z",
    "link": "http://arxiv.org/pdf/1212.6923v1.pdf",
    "category": [
      "cs.GR",
      "hep-ex"
    ],
    "authors": [
      "John Allison",
      "Laurent Garnier",
      "Akinori Kimura",
      "Joseph Perl"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1301.1378v2",
    "title": "Apollonian Circumcircles of IFS Fractals",
    "summary": "Euclidean triangles and IFS fractals seem to be disparate geometrical\nconcepts, unless we consider the Sierpi\\'{n}ski gasket, which is a self-similar\ncollection of triangles. The \"circumcircle\" hints at a direct link, as it can\nbe derived for three-map IFS fractals in general, defined in an Apollonian\nmanner. Following this path, one may discover a broader relationship between\npolygons and IFS fractals.",
    "published": "2013-01-08T01:57:09Z",
    "link": "http://arxiv.org/pdf/1301.1378v2.pdf",
    "category": [
      "cs.CG",
      "cs.GR",
      "28A80 (Primary), 68U05, 52A27 (Secondary)"
    ],
    "authors": [
      "Jzsef Vass"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1301.1379v2",
    "title": "On Intersecting IFS Fractals with Lines",
    "summary": "IFS fractals - the attractors of Iterated Function Systems - have motivated\nplenty of research to date, partly due to their simplicity and applicability in\nvarious fields, such as the modeling of plants in computer graphics, and the\ndesign of fractal antennas. The statement and resolution of the Fractal-Line\nIntersection Problem is imperative for a more efficient treatment of certain\napplications. This paper intends to take further steps towards this resolution,\nbuilding on the literature. For the broad class of hyperdense fractals, a\nverifiable condition guaranteeing intersection with any line passing through\nthe convex hull of a planar IFS fractal is shown, in general R^d for\nhyperplanes. The condition also implies a constructive algorithm for finding\nthe points of intersection. Under certain conditions, an infinite number of\napproximate intersections are guaranteed, if there is at least one.\nQuantification of the intersection is done via an explicit formula for the\ninvariant measure of IFS.",
    "published": "2013-01-08T01:57:24Z",
    "link": "http://arxiv.org/pdf/1301.1379v2.pdf",
    "category": [
      "math.DS",
      "cs.GR",
      "28A80 (Primary) 37F99, 52A35 (Secondary)"
    ],
    "authors": [
      "Jzsef Vass"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1302.5666v1",
    "title": "3T MR-Guided Brachytherapy for Gynecologic Malignancies",
    "summary": "Gynecologic malignancies are a leading cause of death in women worldwide.\nStandard treatment for many primary and recurrent gynecologic cancer cases\nincludes a combination of external beam radiation, followed by brachytherapy.\nMagnetic Resonance Imaging (MRI) is benefitial in diagnostic evaluation, in\nmapping the tumor location to tailor radiation dose, and in monitoring the\ntumor response to treatment. Initial studies of MR-guidance in gynecologic\nbrachtherapy demonstrate the ability to optimize tumor coverage and reduce\nradiation dose to normal tissues, resulting in improved outcomes for patients.\nIn this article we describe a methodology to aid applicator placement and\ntreatment planning for 3 Tesla (3T) MR-guided brachytherapy that was developed\nspecifically for gynecologic cancers. This has been used in 18 cases to date in\nthe Advanced Multimodality Image Guided Operating suite at Brigham and Women's\nHospital. It is comprised of state of the art methods for MR imaging, image\nanalysis, and treatment planning. An MR sequence using 3D-balanced steady state\nfree precession in a 3T MR scan was identified as the best sequence for\ncatheter identification with ballooning artifact at the tip. 3D treatment\nplanning was performed using MR images. Item in development include a software\nmodule designed to support virtual needle trajectory planning that includes\nprobabilistic bias correction, graph based segmentation, and image registration\nalgorithms. The results demonstrate that 3T MR has a role in gynecologic\nbrachytherapy. These novel developments improve targeted treatment to the tumor\nwhile sparing the normal tissues.",
    "published": "2013-01-10T16:52:18Z",
    "link": "http://arxiv.org/pdf/1302.5666v1.pdf",
    "category": [
      "physics.med-ph",
      "cs.GR"
    ],
    "authors": [
      "Tina Kapur",
      "Jan Egger",
      "Antonio Damato",
      "Ehud J. Schmidt",
      "Akila N. Viswanathan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1301.3455v1",
    "title": "3D Geological Modeling and Visualization of Rock Masses Based on Google\n  Earth: A Case Study",
    "summary": "Google Earth (GE) has become a powerful tool for geological modeling and\nvisualization. An interesting and useful feature of GE, Google Street View, can\nallow the GE users to view geological structure such as layers of rock masses\nat a field site. In this paper, we introduce a practical solution for building\n3D geological models for rock masses based on the data acquired by use with GE.\nA real study case at Haut-Barr, France is presented to demonstrate our\nsolution. We first locate the position of Haut-Barr in GE, and then determine\nthe shape and scale of the rock masses in the study area, and thirdly acquire\nthe layout of layers of rock masses in the Google Street View, and finally\ncreate the approximate 3D geological models by extruding and intersecting. The\ngenerated 3D geological models can simply reflect the basic structure of the\nrock masses at Haut-Barr, and can be used for visualizing the rock bodies\ninteractively.",
    "published": "2013-01-15T19:14:06Z",
    "link": "http://arxiv.org/pdf/1301.3455v1.pdf",
    "category": [
      "cs.GR",
      "physics.geo-ph"
    ],
    "authors": [
      "Gang Mei",
      "John C. Tipper",
      "Nengxiong Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1301.4535v1",
    "title": "Applications and a Three-dimensional Desktop Environment for an\n  Immersive Virtual Reality System",
    "summary": "We developed an application launcher called Multiverse for scientific\nvisualizations in a CAVE-type virtual reality (VR) system. Multiverse can be\nregarded as a type of three-dimensional (3D) desktop environment. In\nMultiverse, a user in a CAVE room can browse multiple visualization\napplications with 3D icons and explore movies that float in the air. Touching\none of the movies causes \"teleportation\" into the application's VR space. After\nanalyzing the simulation data using the application, the user can jump back\ninto Multiverse's VR desktop environment in the CAVE.",
    "published": "2013-01-19T07:01:46Z",
    "link": "http://arxiv.org/pdf/1301.4535v1.pdf",
    "category": [
      "physics.comp-ph",
      "cs.GR"
    ],
    "authors": [
      "Akira Kageyama",
      "Youhei Masada"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1301.4546v3",
    "title": "An Approach to Exascale Visualization: Interactive Viewing of In-Situ\n  Visualization",
    "summary": "In the coming era of exascale supercomputing, in-situ visualization will be a\ncrucial approach for reducing the output data size. A problem of in-situ\nvisualization is that it loses interactivity if a steering method is not\nadopted. In this paper, we propose a new method for the interactive analysis of\nin-situ visualization images produced by a batch simulation job. A key idea is\nto apply numerous (thousands to millions) in-situ visualizations\nsimultaneously. The viewer then analyzes the image database interactively\nduring postprocessing. If each movie can be compressed to 100 MB, one million\nmovies will only require 100 TB, which is smaller than the size of the raw\nnumerical data in exascale supercomputing. We performed a feasibility study\nusing the proposed method. Multiple movie files were produced by a simulation\nand they were analyzed using a specially designed movie player. The user could\nchange the viewing angle, the visualization method, and the parameters\ninteractively by retrieving an appropriate sequence of images from the movie\ndataset.",
    "published": "2013-01-19T08:39:58Z",
    "link": "http://arxiv.org/pdf/1301.4546v3.pdf",
    "category": [
      "physics.comp-ph",
      "cs.GR"
    ],
    "authors": [
      "Akira Kageyama",
      "Tomoki Yamada"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1301.6007v1",
    "title": "Immersive VR Visualizations by VFIVE. Part 1: Development",
    "summary": "We have been developing a visualization application for CAVE-type virtual\nreality (VR) systems for more than a decade. This application, VFIVE, is\ncurrently used in several CAVE systems in Japan for routine visualizations. It\nis also used as a base system of further developments of advanced\nvisualizations. The development of VFIVE is summarized.",
    "published": "2013-01-25T11:03:18Z",
    "link": "http://arxiv.org/pdf/1301.6007v1.pdf",
    "category": [
      "cs.GR",
      "physics.comp-ph"
    ],
    "authors": [
      "Akira Kageyama",
      "Nobuaki Ohno"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1301.6008v1",
    "title": "Immersive VR Visualizations by VFIVE. Part 2: Applications",
    "summary": "VFIVE is a scientific visualization application for CAVE-type immersive\nvirtual reality systems. The source codes are freely available. VFIVE is used\nas a research tool in various VR systems. It also lays the groundwork for\ndevelopments of new visualization software for CAVEs. In this paper, we pick up\nfive CAVE systems in four different institutions in Japan. Applications of\nVFIVE in each CAVE system are summarized. Special emphases will be placed on\nscientific and technical achievements made possible by VFIVE.",
    "published": "2013-01-25T11:07:37Z",
    "link": "http://arxiv.org/pdf/1301.6008v1.pdf",
    "category": [
      "cs.GR",
      "physics.comp-ph"
    ],
    "authors": [
      "Akira Kageyama",
      "Nobuaki Ohno",
      "Shintaro Kawahara",
      "Kazuo Kashiyama",
      "Hiroaki Ohtani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1301.6336v1",
    "title": "Approximation of Polyhedral Surface Uniformization",
    "summary": "We present a constructive approach for approximating the conformal map\n(uniformization) of a polyhedral surface to a canonical domain in the plane.\nThe main tool is a characterization of convex spaces of quasiconformal\nsimplicial maps and their approximation properties. As far as we are aware,\nthis is the first algorithm proved to approximate the uniformization of general\npolyhedral surfaces.",
    "published": "2013-01-27T09:35:33Z",
    "link": "http://arxiv.org/pdf/1301.6336v1.pdf",
    "category": [
      "cs.CG",
      "cs.GR",
      "cs.NA",
      "math.NA"
    ],
    "authors": [
      "Yaron Lipman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1301.6809v2",
    "title": "Skeletal Representations and Applications",
    "summary": "When representing a solid object there are alternatives to the use of\ntraditional explicit (surface meshes) or implicit (zero crossing of implicit\nfunctions) methods. Skeletal representations encode shape information in a\nmixed fashion: they are composed of a set of explicit primitives, yet they are\nable to efficiently encode the shape's volume as well as its topology. I will\ndiscuss, in two dimensions, how symmetry can be used to reduce the\ndimensionality of the data (from a 2D solid to a 1D curve), and how this\nrelates to the classical definition of skeletons by Medial Axis Transform.\nWhile the medial axis of a 2D shape is composed of a set of curves, in 3D it\nresults in a set of sheets connected in a complex fashion. Because of this\ncomplexity, medial skeletons are difficult to use in practical applications.\nCurve skeletons address this problem by strictly requiring their geometry to be\none dimensional, resulting in an intuitive yet powerful shape representation.\nIn this report I will define both medial and curve skeletons and discuss their\nmutual relationship. I will also present several algorithms for their\ncomputation and a variety of scenarios where skeletons are employed, with a\nspecial focus on geometry processing and shape analysis.",
    "published": "2013-01-29T00:18:00Z",
    "link": "http://arxiv.org/pdf/1301.6809v2.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Andrea Tagliasacchi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1302.0439v2",
    "title": "Correcting Camera Shake by Incremental Sparse Approximation",
    "summary": "The problem of deblurring an image when the blur kernel is unknown remains\nchallenging after decades of work. Recently there has been rapid progress on\ncorrecting irregular blur patterns caused by camera shake, but there is still\nmuch room for improvement. We propose a new blind deconvolution method using\nincremental sparse edge approximation to recover images blurred by camera\nshake. We estimate the blur kernel first from only the strongest edges in the\nimage, then gradually refine this estimate by allowing for weaker and weaker\nedges. Our method competes with the benchmark deblurring performance of the\nstate-of-the-art while being significantly faster and easier to generalize.",
    "published": "2013-02-03T00:46:11Z",
    "link": "http://arxiv.org/pdf/1302.0439v2.pdf",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "Paul Shearer",
      "Anna C. Gilbert",
      "Alfred O. Hero III"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1302.1547v1",
    "title": "Perception, Attention, and Resources: A Decision-Theoretic Approach to\n  Graphics Rendering",
    "summary": "We describe work to control graphics rendering under limited computational\nresources by taking a decision-theoretic perspective on perceptual costs and\ncomputational savings of approximations. The work extends earlier work on the\ncontrol of rendering by introducing methods and models for computing the\nexpected cost associated with degradations of scene components. The expected\ncost is computed by considering the perceptual cost of degradations and a\nprobability distribution over the attentional focus of viewers. We review the\ncritical literature describing findings on visual search and attention, discuss\nthe implications of the findings, and introduce models of expected perceptual\ncost. Finally, we discuss policies that harness information about the expected\ncost of scene components.",
    "published": "2013-02-06T15:56:18Z",
    "link": "http://arxiv.org/pdf/1302.1547v1.pdf",
    "category": [
      "cs.AI",
      "cs.GR"
    ],
    "authors": [
      "Eric J. Horvitz",
      "Jed Lengyel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1302.2024v1",
    "title": "User Interface for Volume Rendering in Virtual Reality Environments",
    "summary": "Volume Rendering applications require sophisticated user interaction for the\ndefinition and refinement of transfer functions. Traditional 2D desktop user\ninterface elements have been developed to solve this task, but such concepts do\nnot map well to the interaction devices available in Virtual Reality\nenvironments.\n  In this paper, we propose an intuitive user interface for Volume Rendering\nspecifically designed for Virtual Reality environments. The proposed interface\nallows transfer function design and refinement based on intuitive two-handed\noperation of Wand-like controllers. Additional interaction modes such as\nnavigation and clip plane manipulation are supported as well.\n  The system is implemented using the Sony PlayStation Move controller system.\nThis choice is based on controller device capabilities as well as application\nand environment constraints.\n  Initial results document the potential of our approach.",
    "published": "2013-02-08T13:11:39Z",
    "link": "http://arxiv.org/pdf/1302.2024v1.pdf",
    "category": [
      "cs.GR",
      "cs.HC"
    ],
    "authors": [
      "Jonathan Klein",
      "Dennis Reuling",
      "Jan Grimm",
      "Andreas Pfau",
      "Damien Lefloch",
      "Martin Lambers",
      "Andreas Kolb"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1302.3917v1",
    "title": "k-d Darts: Sampling by k-Dimensional Flat Searches",
    "summary": "We formalize the notion of sampling a function using k-d darts. A k-d dart is\na set of independent, mutually orthogonal, k-dimensional subspaces called k-d\nflats. Each dart has d choose k flats, aligned with the coordinate axes for\nefficiency. We show that k-d darts are useful for exploring a function's\nproperties, such as estimating its integral, or finding an exemplar above a\nthreshold. We describe a recipe for converting an algorithm from point sampling\nto k-d dart sampling, assuming the function can be evaluated along a k-d flat.\n  We demonstrate that k-d darts are more efficient than point-wise samples in\nhigh dimensions, depending on the characteristics of the sampling domain: e.g.\nthe subregion of interest has small volume and evaluating the function along a\nflat is not too expensive. We present three concrete applications using line\ndarts (1-d darts): relaxed maximal Poisson-disk sampling, high-quality\nrasterization of depth-of-field blur, and estimation of the probability of\nfailure from a response surface for uncertainty quantification. In these\napplications, line darts achieve the same fidelity output as point darts in\nless time. We also demonstrate the accuracy of higher dimensional darts for a\nvolume estimation problem. For Poisson-disk sampling, we use significantly less\nmemory, enabling the generation of larger point clouds in higher dimensions.",
    "published": "2013-02-16T01:14:33Z",
    "link": "http://arxiv.org/pdf/1302.3917v1.pdf",
    "category": [
      "cs.GR",
      "I.3.5"
    ],
    "authors": [
      "Mohamed S. Ebeida",
      "Anjul Patney",
      "Scott A. Mitchell",
      "Keith R. Dalbey",
      "Andrew A. Davidson",
      "John D. Owens"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/9811019v1",
    "title": "Locked and Unlocked Polygonal Chains in 3D",
    "summary": "In this paper, we study movements of simple polygonal chains in 3D. We say\nthat an open, simple polygonal chain can be straightened if it can be\ncontinuously reconfigured to a straight sequence of segments in such a manner\nthat both the length of each link and the simplicity of the chain are\nmaintained throughout the movement. The analogous concept for closed chains is\nconvexification: reconfiguration to a planar convex polygon. Chains that cannot\nbe straightened or convexified are called locked. While there are open chains\nin 3D that are locked, we show that if an open chain has a simple orthogonal\nprojection onto some plane, it can be straightened. For closed chains, we show\nthat there are unknotted but locked closed chains, and we provide an algorithm\nfor convexifying a planar simple polygon in 3D with a polynomial number of\nmoves.",
    "published": "1998-11-11T20:36:50Z",
    "link": "http://arxiv.org/pdf/cs/9811019v1.pdf",
    "category": [
      "cs.CG",
      "cs.DS",
      "cs.RO",
      "F.2.2; I.2.9"
    ],
    "authors": [
      "T. Biedl",
      "E. Demaine",
      "M. Demaine",
      "S. Lazard",
      "A. Lubiw",
      "J. O'Rourke",
      "M. Overmars",
      "S. Robbins",
      "I. Streinu",
      "G. Toussaint",
      "S. Whitesides"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0006005v1",
    "title": "Novelty Detection for Robot Neotaxis",
    "summary": "The ability of a robot to detect and respond to changes in its environment is\npotentially very useful, as it draws attention to new and potentially important\nfeatures. We describe an algorithm for learning to filter out previously\nexperienced stimuli to allow further concentration on novel features. The\nalgorithm uses a model of habituation, a biological process which causes a\ndecrement in response with repeated presentation. Experiments with a mobile\nrobot are presented in which the robot detects the most novel stimulus and\nturns towards it (`neotaxis').",
    "published": "2000-06-02T11:32:17Z",
    "link": "http://arxiv.org/pdf/cs/0006005v1.pdf",
    "category": [
      "cs.RO",
      "cs.NE",
      "nlin.AO",
      "I.2.6"
    ],
    "authors": [
      "Stephen Marsland",
      "Ulrich Nehmzow",
      "Jonathan Shapiro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0006006v1",
    "title": "A Real-Time Novelty Detector for a Mobile Robot",
    "summary": "Recognising new or unusual features of an environment is an ability which is\npotentially very useful to a robot. This paper demonstrates an algorithm which\nachieves this task by learning an internal representation of `normality' from\nsonar scans taken as a robot explores the environment. This model of the\nenvironment is used to evaluate the novelty of each sonar scan presented to it\nwith relation to the model. Stimuli which have not been seen before, and\ntherefore have more novelty, are highlighted by the filter. The filter has the\nability to forget about features which have been learned, so that stimuli which\nare seen only rarely recover their response over time. A number of robot\nexperiments are presented which demonstrate the operation of the filter.",
    "published": "2000-06-02T12:00:15Z",
    "link": "http://arxiv.org/pdf/cs/0006006v1.pdf",
    "category": [
      "cs.RO",
      "cs.NE",
      "I.2.6"
    ],
    "authors": [
      "Stephen Marsland",
      "Ulrich Nehmzow",
      "Jonathan Shapiro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0006007v1",
    "title": "Novelty Detection on a Mobile Robot Using Habituation",
    "summary": "In this paper a novelty filter is introduced which allows a robot operating\nin an un structured environment to produce a self-organised model of its\nsurroundings and to detect deviations from the learned model. The environment\nis perceived using the rob ot's 16 sonar sensors. The algorithm produces a\nnovelty measure for each sensor scan relative to the model it has learned. This\nmeans that it highlights stimuli which h ave not been previously experienced.\nThe novelty filter proposed uses a model of hab ituation. Habituation is a\ndecrement in behavioural response when a stimulus is pre sented repeatedly.\nRobot experiments are presented which demonstrate the reliable o peration of\nthe filter in a number of environments.",
    "published": "2000-06-02T12:33:13Z",
    "link": "http://arxiv.org/pdf/cs/0006007v1.pdf",
    "category": [
      "cs.RO",
      "cs.NE",
      "nlin.AO",
      "I.2.6"
    ],
    "authors": [
      "Stephen Marsland",
      "Ulrich Nehmzow",
      "Jonathan Shapiro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0006030v2",
    "title": "Multiagent Control of Self-reconfigurable Robots",
    "summary": "We demonstrate how multiagent systems provide useful control techniques for\nmodular self-reconfigurable (metamorphic) robots. Such robots consist of many\nmodules that can move relative to each other, thereby changing the overall\nshape of the robot to suit different tasks. Multiagent control is particularly\nwell-suited for tasks involving uncertain and changing environments. We\nillustrate this approach through simulation experiments of Proteo, a\nmetamorphic robot system currently under development.",
    "published": "2000-06-20T20:17:44Z",
    "link": "http://arxiv.org/pdf/cs/0006030v2.pdf",
    "category": [
      "cs.RO",
      "cs.DC",
      "cs.MA",
      "I.2.9; I.2.11; H.3.4"
    ],
    "authors": [
      "Hristo Bojinov",
      "Arancha Casal",
      "Tad Hogg"
    ]
  },
  {
    "id": "http://arxiv.org/abs/nlin/0109019v1",
    "title": "Olfactory search at high Reynolds number",
    "summary": "Locating the source of odor in a turbulent environment - a common behavior\nfor living organisms - is non-trivial because of the random nature of mixing.\nHere we analyze the statistical physics aspects of the problem and propose an\nefficient strategy for olfactory search which can work in turbulent plumes. The\nalgorithm combines the maximum likelihood inference of the source position with\nan active search. Our approach provides the theoretical basis for the design of\nolfactory robots and the quantitative tools for the analysis of the observed\nolfactory search behavior of living creatures (e.g. odor modulated optomotor\nanemotaxis of moth)",
    "published": "2001-09-18T20:29:24Z",
    "link": "http://arxiv.org/pdf/nlin/0109019v1.pdf",
    "category": [
      "nlin.CD",
      "cs.RO",
      "nlin.AO",
      "physics.bio-ph"
    ],
    "authors": [
      "Eugene Balkovsky",
      "Boris I. Shraiman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0204044v1",
    "title": "Robust Global Localization Using Clustered Particle Filtering",
    "summary": "Global mobile robot localization is the problem of determining a robot's pose\nin an environment, using sensor data, when the starting position is unknown. A\nfamily of probabilistic algorithms known as Monte Carlo Localization (MCL) is\ncurrently among the most popular methods for solving this problem. MCL\nalgorithms represent a robot's belief by a set of weighted samples, which\napproximate the posterior probability of where the robot is located by using a\nBayesian formulation of the localization problem. This article presents an\nextension to the MCL algorithm, which addresses its problems when localizing in\nhighly symmetrical environments; a situation where MCL is often unable to\ncorrectly track equally probable poses for the robot. The problem arises from\nthe fact that sample sets in MCL often become impoverished, when samples are\ngenerated according to their posterior likelihood. Our approach incorporates\nthe idea of clusters of samples and modifies the proposal distribution\nconsidering the probability mass of those clusters. Experimental results are\npresented that show that this new extension to the MCL algorithm successfully\nlocalizes in symmetric environments where ordinary MCL often fails.",
    "published": "2002-04-21T01:21:22Z",
    "link": "http://arxiv.org/pdf/cs/0204044v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "I.2.9"
    ],
    "authors": [
      "Javier Nicolas Sanchez",
      "Adam Milstein",
      "Evan Williamson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0205015v1",
    "title": "Instabilities of Robot Motion",
    "summary": "Instabilities of robot motion are caused by topological reasons. In this\npaper we find a relation between the topological properties of a configuration\nspace (the structure of its cohomology algebra) and the character of\ninstabilities, which are unavoidable in any motion planning algorithm. More\nspecifically, let $X$ denote the space of all admissible configurations of a\nmechanical system. A {\\it motion planner} is given by a splitting $X\\times X =\nF_1\\cup F_2\\cup ... \\cup F_k$ (where $F_1, ..., F_k$ are pairwise disjoint\nENRs, see below) and by continuous maps $s_j: F_j \\to PX,$ such that $E\\circ\ns_j =1_{F_j}$. Here $PX$ denotes the space of all continuous paths in $X$\n(admissible motions of the system) and $E: PX\\to X\\times X$ denotes the map\nwhich assigns to a path the pair of its initial -- end points. Any motion\nplanner determines an algorithm of motion planning for the system. In this\npaper we apply methods of algebraic topology to study the minimal number of\nsets $F_j$ in any motion planner in $X$. We also introduce a new notion of {\\it\norder of instability} of a motion planner; it describes the number of\nessentially distinct motions which may occur as a result of small perturbations\nof the input data. We find the minimal order of instability, which may have\nmotion planners on a given configuration space $X$. We study a number of\nspecific problems: motion of a rigid body in $\\R^3$, a robot arm, motion in\n$\\R^3$ in the presence of obstacles, and others.",
    "published": "2002-05-12T11:23:21Z",
    "link": "http://arxiv.org/pdf/cs/0205015v1.pdf",
    "category": [
      "cs.RO",
      "cs.CG",
      "math.AT",
      "I.2.9; I.3.5"
    ],
    "authors": [
      "Michael Farber"
    ]
  },
  {
    "id": "http://arxiv.org/abs/math/0210018v1",
    "title": "Topological robotics: motion planning in projective spaces",
    "summary": "We study an elementary problem of topological robotics: rotation of a line,\nwhich is fixed by a revolving joint at a base point: one wants to bring the\nline from its initial position to a final position by a continuous motion in\nthe space. The final goal is to construct an algorithm which will perform this\ntask once the initial and final positions are given.\n  Any such motion planning algorithm will have instabilities, which are caused\nby topological reasons. A general approach to study instabilities of robot\nmotion was suggested recently by the first named author. With any\npath-connected topological space X one associates a number TC(X), called the\ntopological complexity of X. This number is of fundamental importance for the\nmotion planning problem: TC(X) determines character of instabilities which have\nall motion planning algorithms in X.\n  In the present paper we study the topological complexity of real projective\nspaces. In particular we compute TC(RP^n) for all n<24. Our main result is that\n(for n distinct from 1, 3, 7) the problem of calculating of TC(RP^n) is\nequivalent to finding the smallest k such that RP^n can be immersed into the\nEuclidean space R^{k-1}.",
    "published": "2002-10-02T09:13:38Z",
    "link": "http://arxiv.org/pdf/math/0210018v1.pdf",
    "category": [
      "math.AT",
      "cs.RO",
      "math.DG"
    ],
    "authors": [
      "Michael Farber",
      "Serge Tabachnikov",
      "Sergey Yuzvinsky"
    ]
  },
  {
    "id": "http://arxiv.org/abs/math/0210115v1",
    "title": "Topological Robotics: Subspace Arrangements and Collision Free Motion\n  Planning",
    "summary": "We study an elementary problem of the topological robotics: collective motion\nof a set of $n$ distinct particles which one has to move from an initial\nconfiguration to a final configuration, with the requirement that no collisions\noccur in the process of motion. The ultimate goal is to construct an algorithm\nwhich will perform this task once the initial and the final configurations are\ngiven. This reduces to a topological problem of finding the topological\ncomplexity TC(C_n(\\R^m)) of the configutation space C_n(\\R^m) of $n$ distinct\nordered particles in \\R^m. We solve this problem for m=2 (the planar case) and\nfor all odd m, including the case m=3 (particles in the three-dimensional\nspace). We also study a more general motion planning problem in Euclidean space\nwith a hyperplane arrangement as obstacle.",
    "published": "2002-10-08T06:39:32Z",
    "link": "http://arxiv.org/pdf/math/0210115v1.pdf",
    "category": [
      "math.AT",
      "cs.RO",
      "math.DG"
    ],
    "authors": [
      "Michael Farber",
      "Sergey Yuzvinsky"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0212022v1",
    "title": "Algorithms for Rapidly Dispersing Robot Swarms in Unknown Environments",
    "summary": "We develop and analyze algorithms for dispersing a swarm of primitive robots\nin an unknown environment, R. The primary objective is to minimize the\nmakespan, that is, the time to fill the entire region. An environment is\ncomposed of pixels that form a connected subset of the integer grid.\n  There is at most one robot per pixel and robots move horizontally or\nvertically at unit speed. Robots enter R by means of k>=1 door pixels\n  Robots are primitive finite automata, only having local communication, local\nsensors, and a constant-sized memory.\n  We first give algorithms for the single-door case (i.e., k=1), analyzing the\nalgorithms both theoretically and experimentally. We prove that our algorithms\nhave optimal makespan 2A-1, where A is the area of R.\n  We next give an algorithm for the multi-door case (k>1), based on a\nwall-following version of the leader-follower strategy. We prove that our\nstrategy is O(log(k+1))-competitive, and that this bound is tight for our\nstrategy and other related strategies.",
    "published": "2002-12-10T16:36:50Z",
    "link": "http://arxiv.org/pdf/cs/0212022v1.pdf",
    "category": [
      "cs.RO",
      "I.2.9"
    ],
    "authors": [
      "Tien-Ruey Hsiang",
      "Esther M. Arkin",
      "Michael Bender",
      "Sandor P. Fekete",
      "Joseph S. B. Mitchell"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0212027v1",
    "title": "Qualitative Study of a Robot Arm as a Hamiltonian System",
    "summary": "A double pendulum subject to external torques is used as a model to study the\nstability of a planar manipulator with two links and two rotational driven\njoints. The hamiltonian equations of motion and the fixed points (stationary\nsolutions) in phase space are determined. Under suitable conditions, the\npresence of constant torques does not change the number of fixed points, and\npreserves the topology of orbits in their linear neighborhoods; two equivalent\ninvariant manifolds are observed, each corresponding to a saddle-center fixed\npoint.",
    "published": "2002-12-11T12:16:47Z",
    "link": "http://arxiv.org/pdf/cs/0212027v1.pdf",
    "category": [
      "cs.RO",
      "I.2.9"
    ],
    "authors": [
      "G. A. Monerat",
      "E. V. Correa Silva",
      "A. G. Cyrino"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0307004v1",
    "title": "State complexes for metamorphic robots",
    "summary": "A metamorphic robotic system is an aggregate of homogeneous robot units which\ncan individually and selectively locomote in such a way as to change the global\nshape of the system. We introduce a mathematical framework for defining and\nanalyzing general metamorphic robots. This formal structure, combined with\nideas from geometric group theory, leads to a natural extension of a\nconfiguration space for metamorphic robots -- the state complex -- which is\nespecially adapted to parallelization. We present an algorithm for optimizing\nreconfiguration sequences with respect to elapsed time. A universal geometric\nproperty of state complexes -- non-positive curvature -- is the key to proving\nconvergence to the globally time-optimal solution.",
    "published": "2003-07-02T19:41:07Z",
    "link": "http://arxiv.org/pdf/cs/0307004v1.pdf",
    "category": [
      "cs.RO",
      "cs.CG",
      "I.2.9"
    ],
    "authors": [
      "A. Abrams",
      "R. Ghrist"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0309018v1",
    "title": "Using Propagation for Solving Complex Arithmetic Constraints",
    "summary": "Solving a system of nonlinear inequalities is an important problem for which\nconventional numerical analysis has no satisfactory method. With a\nbox-consistency algorithm one can compute a cover for the solution set to\narbitrarily close approximation. Because of difficulties in the use of\npropagation for complex arithmetic expressions, box consistency is computed\nwith interval arithmetic. In this paper we present theorems that support a\nsimple modification of propagation that allows complex arithmetic expressions\nto be handled efficiently. The version of box consistency that is obtained in\nthis way is stronger than when interval arithmetic is used.",
    "published": "2003-09-11T18:37:09Z",
    "link": "http://arxiv.org/pdf/cs/0309018v1.pdf",
    "category": [
      "math.NA",
      "cs.AR",
      "cs.CC",
      "cs.NA",
      "cs.PF",
      "cs.RO",
      "B.8; G.1.5;G.1.6;I.2.9;I.3.1;C.1.4;D.2.4;F.2"
    ],
    "authors": [
      "M. H. van Emden",
      "B. Moa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0311019v1",
    "title": "Replay Debugging of Complex Real-Time Systems: Experiences from Two\n  Industrial Case Studies",
    "summary": "Deterministic replay is a method for allowing complex multitasking real-time\nsystems to be debugged using standard interactive debuggers. Even though\nseveral replay techniques have been proposed for parallel, multi-tasking and\nreal-time systems, the solutions have so far lingered on a prototype academic\nlevel, with very little results to show from actual state-of-the-practice\ncommercial applications. This paper describes a major deterministic replay\ndebugging case study performed on a full-scale industrial robot control system,\nas well as a minor replay instrumentation case study performed on a military\naircraft radar system. In this article, we will show that replay debugging is\nfeasible in complex multi-million lines of code software projects running on\ntop of off-the-shelf real-time operating systems. Furthermore, we will discuss\nhow replay debugging can be introduced in existing systems without\nimpracticable analysis efforts. In addition, we will present benchmarking\nresults from both studies, indicating that the instrumentation overhead is\nacceptable and affordable.",
    "published": "2003-11-17T19:15:59Z",
    "link": "http://arxiv.org/pdf/cs/0311019v1.pdf",
    "category": [
      "cs.RO",
      "D.2.5"
    ],
    "authors": [
      "Daniel Sundmark",
      "Henrik Thane",
      "Joel Huselius",
      "Anders Pettersson",
      "Roger Mellander",
      "Ingemar Reiyer",
      "Mattias Kallvi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0404002v1",
    "title": "Mathematical Analysis of Multi-Agent Systems",
    "summary": "We review existing approaches to mathematical modeling and analysis of\nmulti-agent systems in which complex collective behavior arises out of local\ninteractions between many simple agents. Though the behavior of an individual\nagent can be considered to be stochastic and unpredictable, the collective\nbehavior of such systems can have a simple probabilistic description. We show\nthat a class of mathematical models that describe the dynamics of collective\nbehavior of multi-agent systems can be written down from the details of the\nindividual agent controller. The models are valid for Markov or memoryless\nagents, in which each agents future state depends only on its present state and\nnot any of the past states. We illustrate the approach by analyzing in detail\napplications from the robotics domain: collaboration and foraging in groups of\nrobots.",
    "published": "2004-04-02T02:00:00Z",
    "link": "http://arxiv.org/pdf/cs/0404002v1.pdf",
    "category": [
      "cs.RO",
      "cs.MA",
      "I.2.9; I.2.11; I.6.5"
    ],
    "authors": [
      "Kristina Lerman",
      "Aram Galstyan",
      "Tad Hogg"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0404036v1",
    "title": "Online Searching with an Autonomous Robot",
    "summary": "We discuss online strategies for visibility-based searching for an object\nhidden behind a corner, using Kurt3D, a real autonomous mobile robot. This task\nis closely related to a number of well-studied problems. Our robot uses a\nthree-dimensional laser scanner in a stop, scan, plan, go fashion for building\na virtual three-dimensional environment. Besides planning trajectories and\navoiding obstacles, Kurt3D is capable of identifying objects like a chair. We\nderive a practically useful and asymptotically optimal strategy that guarantees\na competitive ratio of 2, which differs remarkably from the well-studied\nscenario without the need of stopping for surveying the environment. Our\nstrategy is used by Kurt3D, documented in a separate video.",
    "published": "2004-04-16T21:46:15Z",
    "link": "http://arxiv.org/pdf/cs/0404036v1.pdf",
    "category": [
      "cs.RO",
      "cs.DS",
      "I.2.9"
    ],
    "authors": [
      "Sandor P. Fekete",
      "Rolf Klein",
      "Andreas Nuechter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0411022v1",
    "title": "Topological Navigation of Simulated Robots using Occupancy Grid",
    "summary": "Formerly I presented a metric navigation method in the Webots mobile robot\nsimulator. The navigating Khepera-like robot builds an occupancy grid of the\nenvironment and explores the square-shaped room around with a value iteration\nalgorithm. Now I created a topological navigation procedure based on the\noccupancy grid process. The extension by a skeletonization algorithm results a\ngraph of important places and the connecting routes among them. I also show the\nsignificant time profit gained during the process.",
    "published": "2004-11-08T20:22:52Z",
    "link": "http://arxiv.org/pdf/cs/0411022v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Richard Szabo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0411023v1",
    "title": "Design and Implementation of a General Decision-making Model in RoboCup\n  Simulation",
    "summary": "The study of the collaboration, coordination and negotiation among different\nagents in a multi-agent system (MAS) has always been the most challenging yet\npopular in the research of distributed artificial intelligence. In this paper,\nwe will suggest for RoboCup simulation, a typical MAS, a general\ndecision-making model, rather than define a different algorithm for each tactic\n(e.g. ball handling, pass, shoot and interception, etc.) in soccer games as\nmost RoboCup simulation teams did. The general decision-making model is based\non two critical factors in soccer games: the vertical distance to the goal line\nand the visual angle for the goalpost. We have used these two parameters to\nformalize the defensive and offensive decisions in RoboCup simulation and the\nresults mentioned above had been applied in NOVAURO, original name is UJDB, a\nRoboCup simulation team of Jiangsu University, whose decision-making model,\ncompared with that of Tsinghua University, the world champion team in 2001, is\na universal model and easier to be implemented.",
    "published": "2004-11-08T20:24:32Z",
    "link": "http://arxiv.org/pdf/cs/0411023v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Changda Wang",
      "Xianyi Chen",
      "Xibin Zhao",
      "Shiguang Ju"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0411024v1",
    "title": "Space Robotics Part 2: Space-based Manipulators",
    "summary": "In this second of three short papers, I introduce some of the basic concepts\nof space robotics with an emphasis on some specific challenging areas of\nresearch that are peculiar to the application of robotics to space\ninfrastructure development. The style of these short papers is pedagogical and\nthe concepts in this paper are developed from fundamental manipulator robotics.\nThis second paper considers the application of space manipulators to on-orbit\nservicing (OOS), an application which has considerable commercial application.\nI provide some background to the notion of robotic on-orbit servicing and\nexplore how manipulator control algorithms may be modified to accommodate space\nmanipulators which operate in the micro-gravity of space.",
    "published": "2004-11-08T20:28:48Z",
    "link": "http://arxiv.org/pdf/cs/0411024v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Alex Ellery"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0411025v1",
    "title": "Bionic Humans Using EAP as Artificial Muscles Reality and Challenges",
    "summary": "For many years, the idea of a human with bionic muscles immediately conjures\nup science fiction images of a TV series superhuman character that was\nimplanted with bionic muscles and portrayed with strength and speed far\nsuperior to any normal human. As fantastic as this idea may seem, recent\ndevelopments in electroactive polymers (EAP) may one day make such bionics\npossible. Polymers that exhibit large displacement in response to stimulation\nthat is other than electrical signal were known for many years. Initially, EAP\nreceived relatively little attention due to their limited actuation capability.\nHowever, in the recent years, the view of the EAP materials has changed due to\nthe introduction of effective new materials that significantly surpassed the\ncapability of the widely used piezoelectric polymer, PVDF. As this technology\ncontinues to evolve, novel mechanisms that are biologically inspired are\nexpected to emerge. EAP materials can potentially provide actuation with\nlifelike response and more flexible configurations. While further improvements\nin performance and robustness are still needed, there already have been several\nreported successes. In recognition of the need for cooperation in this\nmultidisciplinary field, the author initiated and organized a series of\ninternational forums that are leading to a growing number of research and\ndevelopment projects and to great advances in the field. In 1999, he challenged\nthe worldwide science and engineering community of EAP experts to develop a\nrobotic arm that is actuated by artificial muscles to win a wrestling match\nagainst a human opponent. In this paper, the field of EAP as artificial muscles\nwill be reviewed covering the state of the art, the challenges and the vision\nfor the progress in future years.",
    "published": "2004-11-08T20:32:11Z",
    "link": "http://arxiv.org/pdf/cs/0411025v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Yoseph Bar-Cohen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0411018v1",
    "title": "Artificial Intelligence and Systems Theory: Applied to Cooperative\n  Robots",
    "summary": "This paper describes an approach to the design of a population of cooperative\nrobots based on concepts borrowed from Systems Theory and Artificial\nIntelligence. The research has been developed under the SocRob project, carried\nout by the Intelligent Systems Laboratory at the Institute for Systems and\nRobotics - Instituto Superior Tecnico (ISR/IST) in Lisbon. The acronym of the\nproject stands both for \"Society of Robots\" and \"Soccer Robots\", the case study\nwhere we are testing our population of robots. Designing soccer robots is a\nvery challenging problem, where the robots must act not only to shoot a ball\ntowards the goal, but also to detect and avoid static (walls, stopped robots)\nand dynamic (moving robots) obstacles. Furthermore, they must cooperate to\ndefeat an opposing team. Our past and current research in soccer robotics\nincludes cooperative sensor fusion for world modeling, object recognition and\ntracking, robot navigation, multi-robot distributed task planning and\ncoordination, including cooperative reinforcement learning in cooperative and\nadversarial environments, and behavior-based architectures for real time task\nexecution of cooperating robot teams.",
    "published": "2004-11-08T20:41:44Z",
    "link": "http://arxiv.org/pdf/cs/0411018v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Pedro U. Lima",
      "Luis M. M. Custodio"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0411020v1",
    "title": "Dynamic Modelling and Adaptive Traction Control for Mobile Robots",
    "summary": "Mobile robots have received a great deal of research in recent years. A\nsignificant amount of research has been published in many aspects related to\nmobile robots. Most of the research is devoted to design and develop some\ncontrol techniques for robot motion and path planning. A large number of\nresearchers have used kinematic models to develop motion control strategy for\nmobile robots. Their argument and assumption that these models are valid if the\nrobot has low speed, low acceleration and light load. However, dynamic\nmodelling of mobile robots is very important as they are designed to travel at\nhigher speed and perform heavy duty work. This paper presents and discusses a\nnew approach to develop a dynamic model and control strategy for wheeled mobile\nrobot which I modelled as a rigid body that roles on two wheels and a castor.\nThe motion control strategy consists of two levels. The first level is dealing\nwith the dynamic of the system and denoted as Low level controller. The second\nlevel is developed to take care of path planning and trajectory generation.",
    "published": "2004-11-08T20:44:03Z",
    "link": "http://arxiv.org/pdf/cs/0411020v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "A. Albagul",
      " Wahyudi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0411021v1",
    "title": "Coevolution Based Adaptive Monte Carlo Localization (CEAMCL)",
    "summary": "An adaptive Monte Carlo localization algorithm based on coevolution mechanism\nof ecological species is proposed. Samples are clustered into species, each of\nwhich represents a hypothesis of the robots pose. Since the coevolution between\nthe species ensures that the multiple distinct hypotheses can be tracked\nstably, the problem of premature convergence when using MCL in highly symmetric\nenvironments can be solved. And the sample size can be adjusted adaptively over\ntime according to the uncertainty of the robots pose by using the population\ngrowth model. In addition, by using the crossover and mutation operators in\nevolutionary computation, intra-species evolution can drive the samples move\ntowards the regions where the desired posterior density is large. So a small\nsize of samples can represent the desired density well enough to make precise\nlocalization. The new algorithm is termed coevolution based adaptive Monte\nCarlo localization (CEAMCL). Experiments have been carried out to prove the\nefficiency of the new localization algorithm.",
    "published": "2004-11-08T20:45:18Z",
    "link": "http://arxiv.org/pdf/cs/0411021v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Luo Ronghua",
      "Hong Bingrong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0412049v1",
    "title": "Neural Networks in Mobile Robot Motion",
    "summary": "This paper deals with a path planning and intelligent control of an\nautonomous robot which should move safely in partially structured environment.\nThis environment may involve any number of obstacles of arbitrary shape and\nsize; some of them are allowed to move. We describe our approach to solving the\nmotion-planning problem in mobile robot control using neural networks-based\ntechnique. Our method of the construction of a collision-free path for moving\nrobot among obstacles is based on two neural networks. The first neural network\nis used to determine the \"free\" space using ultrasound range finder data. The\nsecond neural network \"finds\" a safe direction for the next robot section of\nthe path in the workspace while avoiding the nearest obstacles. Simulation\nexamples of generated path with proposed techniques will be presented.",
    "published": "2004-12-11T12:32:10Z",
    "link": "http://arxiv.org/pdf/cs/0412049v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Danica Janglova"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0412050v1",
    "title": "Gyroscopically Stabilized Robot: Balance and Tracking",
    "summary": "The single wheel, gyroscopically stabilized robot - Gyrover, is a dynamically\nstable but statically unstable, underactuated system. In this paper, based on\nthe dynamic model of the robot, we investigate two classes of nonholonomic\nconstraints associated with the system. Then, based on the backstepping\ntechnology, we propose a control law for balance control of Gyrover. Next,\nthrough transferring the systems states from Cartesian coordinate to polar\ncoordinate, control laws for point-to-point control and line tracking in\nCartesian space are provided.",
    "published": "2004-12-11T12:38:11Z",
    "link": "http://arxiv.org/pdf/cs/0412050v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Yongsheng Ou",
      "Yangsheng Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0412051v1",
    "title": "Dynamic replanning in uncertain environments for a sewer inspection\n  robot",
    "summary": "The sewer inspection robot MAKRO is an autonomous multi-segment robot with\nworm-like shape driven by wheels. It is currently under development in the\nproject MAKRO-PLUS. The robot has to navigate autonomously within sewer\nsystems. Its first tasks will be to take water probes, analyze it onboard, and\nmeasure positions of manholes and pipes to detect polluted-loaded sewage and to\nimprove current maps of sewer systems. One of the challenging problems is the\ncontroller software, which should enable the robot to navigate in the sewer\nsystem and perform the inspection tasks autonomously, not inflicting any\nself-damage. This paper focuses on the route planning and replanning aspect of\nthe robot. The robots software has four different levels, of which the planning\nsystem is the highest level, and the remaining three are controller levels each\nwith a different degree of abstraction. The planner coordinates the sequence of\nactions that are to be successively executed by the robot.",
    "published": "2004-12-11T12:42:10Z",
    "link": "http://arxiv.org/pdf/cs/0412051v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Oliver Adria",
      "Hermann Streich",
      "Joachim Hertzberg"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0412052v1",
    "title": "WebotsTM: Professional Mobile Robot Simulation",
    "summary": "Cyberbotics Ltd. develops WebotsTM, a mobile robotics simulation software\nthat provides you with a rapid prototyping environment for modelling,\nprogramming and simulating mobile robots. The provided robot libraries enable\nyou to transfer your control programs to several commercially available real\nmobile robots. WebotsTM lets you define and modify a complete mobile robotics\nsetup, even several different robots sharing the same environment. For each\nobject, you can define a number of properties, such as shape, color, texture,\nmass, friction, etc. You can equip each robot with a large number of available\nsensors and actuators. You can program these robots using your favorite\ndevelopment environment, simulate them and optionally transfer the resulting\nprograms onto your real robots. WebotsTM has been developed in collaboration\nwith the Swiss Federal Institute of Technology in Lausanne, thoroughly tested,\nwell documented and continuously maintained for over 7 years. It is now the\nmain commercial product available from Cyberbotics Ltd.",
    "published": "2004-12-11T12:45:08Z",
    "link": "http://arxiv.org/pdf/cs/0412052v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Olivier Michel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0412053v1",
    "title": "Dynamic simulation of task constrained of a rigid-flexible manipulator",
    "summary": "A rigid-flexible manipulator may be assigned tasks in a moving environment\nwhere the winds or vibrations affect the position and/or orientation of surface\nof operation. Consequently, losses of the contact and perhaps degradation of\nthe performance may occur as references are changed. When the environment is\nmoving, knowledge of the angle &#945; between the contact surface and the\nhorizontal is required at every instant. In this paper, different profiles for\nthe time varying angle &#945; are proposed to investigate the effect of this\nchange into the contact force and the joint torques of a rigid-flexible\nmanipulator. The coefficients of the equation of the proposed rotating surface\nare changing with time to determine the new X and Y coordinates of the moving\nsurface as the surface rotates.",
    "published": "2004-12-11T12:48:08Z",
    "link": "http://arxiv.org/pdf/cs/0412053v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Atef A. Ata",
      "Habib Johar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0412054v1",
    "title": "Assembly and Disassembly Planning by using Fuzzy Logic & Genetic\n  Algorithms",
    "summary": "The authors propose the implementation of hybrid Fuzzy Logic-Genetic\nAlgorithm (FL-GA) methodology to plan the automatic assembly and disassembly\nsequence of products. The GA-Fuzzy Logic approach is implemented onto two\nlevels. The first level of hybridization consists of the development of a Fuzzy\ncontroller for the parameters of an assembly or disassembly planner based on\nGAs. This controller acts on mutation probability and crossover rate in order\nto adapt their values dynamically while the algorithm runs. The second level\nconsists of the identification of theoptimal assembly or disassembly sequence\nby a Fuzzy function, in order to obtain a closer control of the technological\nknowledge of the assembly/disassembly process. Two case studies were analyzed\nin order to test the efficiency of the Fuzzy-GA methodologies.",
    "published": "2004-12-11T12:50:36Z",
    "link": "http://arxiv.org/pdf/cs/0412054v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "L. M. Galantucci",
      "G. Percoco",
      "R. Spina"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0412055v1",
    "title": "Robotic Applications in Cardiac Surgery",
    "summary": "Traditionally, cardiac surgery has been performed through a median\nsternotomy, which allows the surgeon generous access to the heart and\nsurrounding great vessels. As a paradigm shift in the size and location of\nincisions occurs in cardiac surgery, new methods have been developed to allow\nthe surgeon the same amount of dexterity and accessibility to the heart in\nconfined spaces and in a less invasive manner. Initially, long instruments\nwithout pivot points were used, however, more recent robotic telemanipulation\nsystems have been applied that allow for improved dexterity, enabling the\nsurgeon to perform cardiac surgery from a distance not previously possible. In\nthis rapidly evolving field, we review the recent history and clinical results\nof using robotics in cardiac surgery.",
    "published": "2004-12-11T12:52:58Z",
    "link": "http://arxiv.org/pdf/cs/0412055v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Alan P. Kypson",
      "W. Randolph Chitwood Jr"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0412056v1",
    "title": "One-Chip Solution to Intelligent Robot Control: Implementing Hexapod\n  Subsumption Architecture Using a Contemporary Microprocessor",
    "summary": "This paper introduces a six-legged autonomous robot managed by a single\ncontroller and a software core modeled on subsumption architecture. We begin by\ndiscussing the features and capabilities of IsoPod, a new processor for\nrobotics which has enabled a streamlined implementation of our project. We\nargue that this processor offers a unique set of hardware and software\nfeatures, making it a practical development platform for robotics in general\nand for subsumption-based control architectures in particular. Next, we\nsummarize original ideas on subsumption architecture implementation for a\nsix-legged robot, as presented by its inventor Rodney Brooks in 1980s. A\ncomparison is then made to a more recent example of a hexapod control\narchitecture based on subsumption. The merits of both systems are analyzed and\na new subsumption architecture layout is formulated as a response. We conclude\nwith some remarks regarding the development of this project as a hint at new\npotentials for intelligent robot design, opened by a recent development in\nembedded controller market.",
    "published": "2004-12-11T12:55:30Z",
    "link": "http://arxiv.org/pdf/cs/0412056v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Nikita Pashenkov",
      "Ryuichi Iwamasa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0412057v1",
    "title": "How to achieve various gait patterns from single nominal",
    "summary": "In this paper is presented an approach to achieving on-line modification of\nnominal biped gait without recomputing entire dynamics when steady motion is\nperformed. Straight, dynamically balanced walk was used as a nominal gait, and\napplied modifications were speed-up and slow-down walk and turning left and\nright. It is shown that the disturbances caused by these modifications\njeopardize dynamic stability, but they can be simply compensated to enable walk\ncontinuation.",
    "published": "2004-12-11T12:57:33Z",
    "link": "http://arxiv.org/pdf/cs/0412057v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Miomir Vukobratovic",
      "Dejan Andric",
      "Branislav Borovac"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0501092v1",
    "title": "Multi-Vehicle Cooperative Control Using Mixed Integer Linear Programming",
    "summary": "We present methods to synthesize cooperative strategies for multi-vehicle\ncontrol problems using mixed integer linear programming. Complex multi-vehicle\ncontrol problems are expressed as mixed logical dynamical systems. Optimal\nstrategies for these systems are then solved for using mixed integer linear\nprogramming. We motivate the methods on problems derived from an adversarial\ngame between two teams of robots called RoboFlag. We assume the strategy for\none team is fixed and governed by state machines. The strategy for the other\nteam is generated using our methods. Finally, we perform an average case\ncomputational complexity study on our approach.",
    "published": "2005-01-31T01:03:54Z",
    "link": "http://arxiv.org/pdf/cs/0501092v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.MA",
      "I.2.9; I.2.8; I.2.11"
    ],
    "authors": [
      "Matthew G. Earl",
      "Raffaello D'Andrea"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0504081v1",
    "title": "A Decomposition Approach to Multi-Vehicle Cooperative Control",
    "summary": "We present methods that generate cooperative strategies for multi-vehicle\ncontrol problems using a decomposition approach. By introducing a set of tasks\nto be completed by the team of vehicles and a task execution method for each\nvehicle, we decomposed the problem into a combinatorial component and a\ncontinuous component. The continuous component of the problem is captured by\ntask execution, and the combinatorial component is captured by task assignment.\nIn this paper, we present a solver for task assignment that generates\nnear-optimal assignments quickly and can be used in real-time applications. To\nmotivate our methods, we apply them to an adversarial game between two teams of\nvehicles. One team is governed by simple rules and the other by our algorithms.\nIn our study of this game we found phase transitions, showing that the task\nassignment problem is most difficult to solve when the capabilities of the\nadversaries are comparable. Finally, we implement our algorithms in a\nmulti-level architecture with a variable replanning rate at each level to\nprovide feedback on a dynamically changing and uncertain environment.",
    "published": "2005-04-18T03:53:27Z",
    "link": "http://arxiv.org/pdf/cs/0504081v1.pdf",
    "category": [
      "cs.RO",
      "I.2.9; I.2.8; I.2.11"
    ],
    "authors": [
      "Matthew Earl",
      "Raffaello D'Andrea"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0505042v1",
    "title": "Iterative MILP Methods for Vehicle Control Problems",
    "summary": "Mixed integer linear programming (MILP) is a powerful tool for planning and\ncontrol problems because of its modeling capability and the availability of\ngood solvers. However, for large models, MILP methods suffer computationally.\nIn this paper, we present iterative MILP algorithms that address this issue. We\nconsider trajectory generation problems with obstacle avoidance requirements\nand minimum time trajectory generation problems. The algorithms use fewer\nbinary variables than standard MILP methods and require less computational\neffort.",
    "published": "2005-05-16T03:54:08Z",
    "link": "http://arxiv.org/pdf/cs/0505042v1.pdf",
    "category": [
      "cs.RO",
      "I.2.9; I.2.8; J.2"
    ],
    "authors": [
      "Matthew Earl",
      "Raffaello D'Andrea"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0505045v1",
    "title": "A T Step Ahead Optimal Target Detection Algorithm for a Multi Sensor\n  Surveillance System",
    "summary": "This paper presents a methodology for optimal target detection in a multi\nsensor surveillance system. The system consists of mobile sensors that guard a\nrectangular surveillance zone crisscrossed by moving targets. Targets percolate\nthe surveillance zone in a poisson fashion with uniform velocities. Under these\nstatistics this paper computes a motion strategy for a sensor that maximizes\ntarget detections for the next T time steps. A coordination mechanism between\nsensors ensures that overlapping areas between sensors is reduced. This\ncoordination mechanism is interleaved with the motion strategy computation to\nreduce detections of the same target by more than one sensor. To avoid an\nexhaustive search in the joint space of all sensors the coordination mechanism\nconstraints the search by assigning priorities to the sensors. A comparison of\nthis methodology with other multi target tracking schemes verifies its efficacy\nin maximizing detections. A tabulation of these comparisons is reported in\nresults section of the paper",
    "published": "2005-05-17T13:06:41Z",
    "link": "http://arxiv.org/pdf/cs/0505045v1.pdf",
    "category": [
      "cs.MA",
      "cs.RO"
    ],
    "authors": [
      "K Madhava Krishna",
      "Henry Hexmoor",
      "Shravan Sogani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0507056v1",
    "title": "Explorations in engagement for humans and robots",
    "summary": "This paper explores the concept of engagement, the process by which\nindividuals in an interaction start, maintain and end their perceived\nconnection to one another. The paper reports on one aspect of engagement among\nhuman interactors--the effect of tracking faces during an interaction. It also\ndescribes the architecture of a robot that can participate in conversational,\ncollaborative interactions with engagement gestures. Finally, the paper reports\non findings of experiments with human participants who interacted with a robot\nwhen it either performed or did not perform engagement gestures. Results of the\nhuman-robot studies indicate that people become engaged with robots: they\ndirect their attention to the robot more often in interactions where engagement\ngestures are present, and they find interactions more appropriate when\nengagement gestures are present than when they are not.",
    "published": "2005-07-21T21:56:34Z",
    "link": "http://arxiv.org/pdf/cs/0507056v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.RO",
      "I.2.7; I.2.9"
    ],
    "authors": [
      "Candace L. Sidner",
      "Christopher Lee",
      "Cory Kidd",
      "Neal Lesh",
      "Charles Rich"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0510059v1",
    "title": "Cybercars : Past, Present and Future of the Technology",
    "summary": "Automobile has become the dominant transport mode in the world in the last\ncentury. In order to meet a continuously growing demand for transport, one\nsolution is to change the control approach for vehicle to full driving\nautomation, which removes the driver from the control loop to improve\nefficiency and reduce accidents. Recent work shows that there are several\nrealistic paths towards this deployment : driving assistance on passenger cars,\nautomated commercial vehicles on dedicated infrastructures, and new forms of\nurban transport (car-sharing and cybercars). Cybercars have already been put\ninto operation in Europe, and it seems that this approach could lead the way\ntowards full automation on most urban, and later interurban infrastructures.\nThe European project CyberCars has brought many improvements in the technology\nneeded to operate cybercars over the last three years. A new, larger European\nproject is now being prepared to carry this work further in order to meet more\nambitious objectives in terms of safety and efficiency. This paper will present\npast and present technologies and will focus on the future developments.",
    "published": "2005-10-20T15:03:48Z",
    "link": "http://arxiv.org/pdf/cs/0510059v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Michel Parent",
      "Arnaud De La Fortelle"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0510076v1",
    "title": "Applying Evolutionary Optimisation to Robot Obstacle Avoidance",
    "summary": "This paper presents an artificial evolutionbased method for stereo image\nanalysis and its application to real-time obstacle detection and avoidance for\na mobile robot. It uses the Parisian approach, which consists here in splitting\nthe representation of the robot's environment into a large number of simple\nprimitives, the \"flies\", which are evolved following a biologically inspired\nscheme and give a fast, low-cost solution to the obstacle detection problem in\nmobile robotics.",
    "published": "2005-10-25T07:07:01Z",
    "link": "http://arxiv.org/pdf/cs/0510076v1.pdf",
    "category": [
      "cs.AI",
      "cs.RO"
    ],
    "authors": [
      "Olivier Pauplin",
      "Jean Louchet",
      "Evelyne Lutton",
      "Michel Parent"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0511067v1",
    "title": "Effects of Initial Stance of Quadruped Trotting on Walking Stability",
    "summary": "It is very important for quadruped walking machine to keep its stability in\nhigh speed walking. It has been indicated that moment around the supporting\ndiagonal line of quadruped in trotting gait largely influences walking\nstability. In this paper, moment around the supporting diagonal line of\nquadruped in trotting gait is modeled and its effects on body attitude are\nanalyzed. The degree of influence varies with different initial stances of\nquadruped and we get the optimal initial stance of quadruped in trotting gait\nwith maximal walking stability. Simulation results are presented. Keywords:\nquadruped, trotting, attitude, walking stability.",
    "published": "2005-11-18T14:39:01Z",
    "link": "http://arxiv.org/pdf/cs/0511067v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Dongqing He",
      "Peisun Ma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0511068v1",
    "title": "An Agent-based Manufacturing Management System for Production and\n  Logistics within Cross-Company Regional and National Production Networks",
    "summary": "The goal is the development of a simultaneous, dynamic, technological as well\nas logistical real-time planning and an organizational control of the\nproduction by the production units themselves, working in the production\nnetwork under the use of Multi-Agent-Technology. The design of the\nmulti-agent-based manufacturing management system, the models of the single\nagents, algorithms for the agent-based, decentralized dispatching of orders,\nstrategies and data management concepts as well as their integration into the\nSCM, basing on the solution described, will be explained in the following.\n  Keywords: production engineering and management, dynamic manufacturing\nplanning and control, multi-agentsystems (MAS), supply-chain-management (SCM),\ne-manufacturing",
    "published": "2005-11-18T14:41:09Z",
    "link": "http://arxiv.org/pdf/cs/0511068v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "S. Heinrich",
      "H. Durr",
      "T. Hanel",
      "J. Lassig"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0511069v1",
    "title": "Nonlinear Receding-Horizon Control of Rigid Link Robot Manipulators",
    "summary": "The approximate nonlinear receding-horizon control law is used to treat the\ntrajectory tracking control problem of rigid link robot manipulators. The\nderived nonlinear predictive law uses a quadratic performance index of the\npredicted tracking error and the predicted control effort. A key feature of\nthis control law is that, for their implementation, there is no need to perform\nan online optimization, and asymptotic tracking of smooth reference\ntrajectories is guaranteed. It is shown that this controller achieves the\npositions tracking objectives via link position measurements. The stability\nconvergence of the output tracking error to the origin is proved. To enhance\nthe robustness of the closed loop system with respect to payload uncertainties\nand viscous friction, an integral action is introduced in the loop. A nonlinear\nobserver is used to estimate velocity. Simulation results for a two-link rigid\nrobot are performed to validate the performance of the proposed controller.\n  Keywords: receding-horizon control, nonlinear observer, robot manipulators,\nintegral action, robustness.",
    "published": "2005-11-18T14:42:51Z",
    "link": "http://arxiv.org/pdf/cs/0511069v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "R. Hedjar",
      "P. Boucher"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0601004v1",
    "title": "Integration of navigation and action selection functionalities in a\n  computational model of cortico-basal ganglia-thalamo-cortical loops",
    "summary": "This article describes a biomimetic control architecture affording an animat\nboth action selection and navigation functionalities. It satisfies the survival\nconstraint of an artificial metabolism and supports several complementary\nnavigation strategies. It builds upon an action selection model based on the\nbasal ganglia of the vertebrate brain, using two interconnected cortico-basal\nganglia-thalamo-cortical loops: a ventral one concerned with appetitive actions\nand a dorsal one dedicated to consummatory actions. The performances of the\nresulting model are evaluated in simulation. The experiments assess the\nprolonged survival permitted by the use of high level navigation strategies and\nthe complementarity of navigation strategies in dynamic environments. The\ncorrectness of the behavioral choices in situations of antagonistic or\nsynergetic internal states are also tested. Finally, the modelling choices are\ndiscussed with regard to their biomimetic plausibility, while the experimental\nresults are estimated in terms of animat adaptivity.",
    "published": "2006-01-03T10:39:24Z",
    "link": "http://arxiv.org/pdf/cs/0601004v1.pdf",
    "category": [
      "cs.AI",
      "cs.RO"
    ],
    "authors": [
      "Benot Girard",
      "David Filliat",
      "Jean-Arcady Meyer",
      "Alain Berthoz",
      "Agns Guillot"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0601040v1",
    "title": "New Technologies for Sustainable Urban Transport in Europe",
    "summary": "In the past few years, the European Commission has financed several projects\nto examine how new technologies could improve the sustainability of European\ncities. These technologies concern new public transportation modes such as\nguided buses to form high capacity networks similar to light rail but at a\nlower cost and better flexibility, PRT (Personal Rapid Transit) and cybercars\n(small urban vehicles with fully automatic driving capabilities to be used in\ncarsharing mode, mostly as a complement to mass transport). They also concern\nprivate vehicles with technologies which could improve the efficiency of the\nvehicles as well as their safety (Intelligent Speed Adaptation, Adaptive Cruise\n>.Control, Stop&Go, Lane Keeping,...) and how these new vehicles can complement\nmass transport in the form of car-sharing services.",
    "published": "2006-01-10T13:57:28Z",
    "link": "http://arxiv.org/pdf/cs/0601040v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Michel Parent"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0601053v1",
    "title": "Wavefront Propagation and Fuzzy Based Autonomous Navigation",
    "summary": "Path planning and obstacle avoidance are the two major issues in any\nnavigation system. Wavefront propagation algorithm, as a good path planner, can\nbe used to determine an optimal path. Obstacle avoidance can be achieved using\npossibility theory. Combining these two functions enable a robot to\nautonomously navigate to its destination. This paper presents the approach and\nresults in implementing an autonomous navigation system for an indoor mobile\nrobot. The system developed is based on a laser sensor used to retrieve data to\nupdate a two dimensional world model of therobot environment. Waypoints in the\npath are incorporated into the obstacle avoidance. Features such as ageing of\nobjects and smooth motion planning are implemented to enhance efficiency and\nalso to cater for dynamic environments.",
    "published": "2006-01-14T08:09:23Z",
    "link": "http://arxiv.org/pdf/cs/0601053v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Adel Al-Jumaily",
      "Cindy Leung"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0601054v1",
    "title": "Control of a Lightweight Flexible Robotic Arm Using Sliding Modes",
    "summary": "This paper presents a robust control scheme for flexible link robotic\nmanipulators, which is based on considering the flexible mechanical structure\nas a system with slow (rigid) and fast (flexible) modes that can be controlled\nseparately. The rigid dynamics is controlled by means of a robust sliding-mode\napproach with wellestablished stability properties while an LQR optimal design\nis adopted for the flexible dynamics. Experimental results show that this\ncomposite approach achieves good closed loop tracking properties both for the\nrigid and the flexible dynamics.",
    "published": "2006-01-14T08:10:49Z",
    "link": "http://arxiv.org/pdf/cs/0601054v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Victor Etxebarria",
      "Arantza Sanz",
      "Ibone Lizarraga"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0601055v1",
    "title": "A Hybrid Three Layer Architecture for Fire Agent Management in Rescue\n  Simulation Environment",
    "summary": "This paper presents a new architecture called FAIS for imple- menting\nintelligent agents cooperating in a special Multi Agent environ- ment, namely\nthe RoboCup Rescue Simulation System. This is a layered architecture which is\ncustomized for solving fire extinguishing problem. Structural decision making\nalgorithms are combined with heuristic ones in this model, so it's a hybrid\narchitecture.",
    "published": "2006-01-14T08:12:02Z",
    "link": "http://arxiv.org/pdf/cs/0601055v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Alborz Geramifard",
      "Peyman Nayeri",
      "Reza Zamani-Nasab",
      "Jafar Habibi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0601056v1",
    "title": "Dynamic Balance Control of Multi-arm Free-Floating Space Robots",
    "summary": "This paper investigates the problem of the dynamic balance control of\nmulti-arm free-floating space robot during capturing an active object in close\nproximity. The position and orientation of space base will be affected during\nthe operation of space manipulator because of the dynamics coupling between the\nmanipulator and space base. This dynamics coupling is unique characteristics of\nspace robot system. Such a disturbance will produce a serious impact between\nthe manipulator hand and the object. To ensure reliable and precise operation,\nwe propose to develop a space robot system consisting of two arms, with one arm\n(mission arm) for accomplishing the capture mission, and the other one (balance\narm) compensating for the disturbance of the base. We present the coordinated\ncontrol concept for balance of the attitude of the base using the balance arm.\nThe mission arm can move along the given trajectory to approach and capture the\ntarget with no considering the disturbance from the coupling of the base. We\nestablish a relationship between the motion of two arm that can realize the\nzeros reaction to the base. The simulation studies verified the validity and\nefficiency of the proposed control method.",
    "published": "2006-01-14T08:13:06Z",
    "link": "http://arxiv.org/pdf/cs/0601056v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Panfeng Huang",
      "Yangsheng Xu",
      "Bin Liang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0601057v1",
    "title": "Robust Motion Control for Mobile Manipulator Using Resolved Acceleration\n  and Proportional-Integral Active Force Control",
    "summary": "A resolved acceleration control (RAC) and proportional-integral active force\ncontrol (PIAFC) is proposed as an approach for the robust motion control of a\nmobile manipulator (MM) comprising a differentially driven wheeled mobile\nplatform with a two-link planar arm mounted on top of the platform. The study\nemphasizes on the integrated kinematic and dynamic control strategy in which\nthe RAC is used to manipulate the kinematic component while the PIAFC is\nimplemented to compensate the dynamic effects including the bounded\nknown/unknown disturbances and uncertainties. The effectivenss and robustness\nof the proposed scheme are investigated through a rigorous simulation study and\nlater complemented with experimental results obtained through a number of\nexperiments performed on a fully developed working prototype in a laboratory\nenvironment. A number of disturbances in the form of vibratory and impact\nforces are deliberately introduced into the system to evaluate the system\nperformances. The investigation clearly demonstrates the extreme robustness\nfeature of the proposed control scheme compared to other systems considered in\nthe study.",
    "published": "2006-01-14T08:14:10Z",
    "link": "http://arxiv.org/pdf/cs/0601057v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Musa Mailah",
      "Endra Pitowarno",
      "Hishamuddin Jamaluddin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0601058v1",
    "title": "CAGD - Computer Aided Gripper Design for a Flexible Gripping System",
    "summary": "This paper is a summary of the recently accomplished research work on\nflexible gripping systems. The goal is to develop a gripper which can be used\nfor a great amount of geometrically variant workpieces. The economic aspect is\nof particular importance during the whole development. The high flexibility of\nthe gripper is obtained by three parallel used principles. These are human and\ncomputer based analysis of the gripping object as well as mechanical adaptation\nof the gripper to the object with the help of servo motors. The focus is on the\ngripping of free-form surfaces with suction cup.",
    "published": "2006-01-14T08:15:47Z",
    "link": "http://arxiv.org/pdf/cs/0601058v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Michael Sdahl",
      "Bernd Kuhlenkoetter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0601059v1",
    "title": "A Descriptive Model of Robot Team and the Dynamic Evolution of Robot\n  Team Cooperation",
    "summary": "At present, the research on robot team cooperation is still in qualitative\nanalysis phase and lacks the description model that can quantitatively describe\nthe dynamical evolution of team cooperative relationships with constantly\nchangeable task demand in Multi-robot field. First this paper whole and static\ndescribes organization model HWROM of robot team, then uses Markov course and\nBayesian theorem for reference, dynamical describes the team cooperative\nrelationships building. Finally from cooperative entity layer, ability layer\nand relative layer we research team formation and cooperative mechanism, and\ndiscuss how to optimize relative action sets during the evolution. The dynamic\nevolution model of robot team and cooperative relationships between robot teams\nproposed and described in this paper can not only generalize the robot team as\na whole, but also depict the dynamic evolving process quantitatively. Users can\nalso make the prediction of the cooperative relationship and the action of the\nrobot team encountering new demands based on this model. Journal web page & a\nlot of robotic related papers www.ars-journal.com",
    "published": "2006-01-14T08:18:15Z",
    "link": "http://arxiv.org/pdf/cs/0601059v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Shu-qin Li",
      "Lan Shuai",
      "Xian-yi Cheng",
      "Zhen-min Tang",
      "Jing-yu Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0601060v1",
    "title": "Robot Swarms in an Uncertain World: Controllable Adaptability",
    "summary": "There is a belief that complexity and chaos are essential for adaptability.\nBut life deals with complexity every moment, without the chaos that engineers\nfear so, by invoking goal-directed behaviour. Goals can be programmed. That is\nwhy living organisms give us hope to achieve adaptability in robots. In this\npaper a method for the description of a goal-directed, or programmed,\nbehaviour, interacting with uncertainty of environment, is described. We\nsuggest reducing the structural (goals, intentions) and stochastic components\n(probability to realise the goal) of individual behaviour to random variables\nwith nominal values to apply probabilistic approach. This allowed us to use a\nNormalized Entropy Index to detect the system state by estimating the\ncontribution of each agent to the group behaviour. The number of possible group\nstates is 27. We argue that adaptation has a limited number of possible paths\nbetween these 27 states. Paths and states can be programmed so that after\nadjustment to any particular case of task and conditions, adaptability will\nnever involve chaos. We suggest the application of the model to operation of\nrobots or other devices in remote and/or dangerous places.",
    "published": "2006-01-14T08:20:26Z",
    "link": "http://arxiv.org/pdf/cs/0601060v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Olga Bogatyreva",
      "Alexandr Shillerov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0601061v1",
    "title": "Modular Adaptive System Based on a Multi-Stage Neural Structure for\n  Recognition of 2D Objects of Discontinuous Production",
    "summary": "This is a presentation of a new system for invariant recognition of 2D\nobjects with overlapping classes, that can not be effectively recognized with\nthe traditional methods. The translation, scale and partial rotation invariant\ncontour object description is transformed in a DCT spectrum space. The obtained\nfrequency spectrums are decomposed into frequency bands in order to feed\ndifferent BPG neural nets (NNs). The NNs are structured in three stages -\nfiltering and full rotation invariance; partial recognition; general\nclassification. The designed multi-stage BPG Neural Structure shows very good\naccuracy and flexibility when tested with 2D objects used in the discontinuous\nproduction. The reached speed and the opportunuty for an easy restructuring and\nreprogramming of the system makes it suitable for application in different\napplied systems for real time work.",
    "published": "2006-01-14T08:25:25Z",
    "link": "http://arxiv.org/pdf/cs/0601061v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "I. Topalova"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0601062v1",
    "title": "Study of Self-Organization Model of Multiple Mobile Robot",
    "summary": "A good organization model of multiple mobile robot should be able to improve\nthe efficiency of the system, reduce the complication of robot interactions,\nand detract the difficulty of computation. From the sociology aspect of\ntopology, structure and organization, this paper studies the multiple mobile\nrobot organization formation and running mechanism in the dynamic, complicated\nand unknown environment. It presents and describes in detail a Hierarchical-\nWeb Recursive Organization Model (HWROM) and forming algorithm. It defines the\nrobot society leader; robotic team leader and individual robot as the same\nstructure by the united framework and describes the organization model by the\nrecursive structure. The model uses task-oriented and top-down method to\ndynamically build and maintain structures and organization. It uses\nmarket-based techniques to assign task, form teams and allocate resources in\ndynamic environment. The model holds several characteristics of\nself-organization, dynamic, conciseness, commonness and robustness.",
    "published": "2006-01-14T08:27:04Z",
    "link": "http://arxiv.org/pdf/cs/0601062v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Ceng Xian-yi",
      "Li Shu-qin",
      "Xia De-shen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0601063v1",
    "title": "Optimal Point-to-Point Trajectory Tracking of Redundant Manipulators\n  using Generalized Pattern Search",
    "summary": "Optimal point-to-point trajectory planning for planar redundant manipulator\nis considered in this study. The main objective is to minimize the sum of the\nposition error of the end-effector at each intermediate point along the\ntrajectory so that the end-effector can track the prescribed trajectory\naccurately. An algorithm combining Genetic Algorithm and Pattern Search as a\nGeneralized Pattern Search GPS is introduced to design the optimal trajectory.\nTo verify the proposed algorithm, simulations for a 3-D-O-F planar manipulator\nwith different end-effector trajectories have been carried out. A comparison\nbetween the Genetic Algorithm and the Generalized Pattern Search shows that The\nGPS gives excellent tracking performance.",
    "published": "2006-01-14T08:29:07Z",
    "link": "http://arxiv.org/pdf/cs/0601063v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Atef A. Ata",
      "Thi Rein Myo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0601064v1",
    "title": "Robotics Vision-based Heuristic Reasoning for Underwater Target Tracking\n  and Navigation",
    "summary": "This paper presents a robotics vision-based heuristic reasoning system for\nunderwater target tracking and navigation. This system is introduced to improve\nthe level of automation of underwater Remote Operated Vehicles (ROVs)\noperations. A prototype which combines computer vision with an underwater\nrobotics system is successfully designed and developed to perform target\ntracking and intelligent navigation. ...",
    "published": "2006-01-14T08:34:52Z",
    "link": "http://arxiv.org/pdf/cs/0601064v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Chua Kia",
      "Mohd Rizal Arshad"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0601065v1",
    "title": "New Intelligent Transmission Concept for Hybrid Mobile Robot Speed\n  Control",
    "summary": "This paper presents a new concept of a mobile robot speed control by using\ntwo degree of freedom gear transmission. The developed intelligent speed\ncontroller utilizes a gear box which comprises of epicyclic gear train with two\ninputs, one coupled with the engine shaft and another with the shaft of a\nvariable speed dc motor. The net output speed is a combination of the two input\nspeeds and is governed by the transmission ratio of the planetary gear train.\nThis new approach eliminates the use of a torque converter which is otherwise\nan indispensable part of all available automatic transmissions, thereby\nreducing the power loss that occurs in the box during the fluid coupling. By\ngradually varying the speed of the dc motor a stepless transmission has been\nachieved. The other advantages of the developed controller are pulling over and\nreversing the vehicle, implemented by intelligent mixing of the dc motor and\nengine speeds. This approach eliminates traditional braking system in entire\nvehicle design. The use of two power sources, IC engine and battery driven DC\nmotor, utilizes the modern idea of hybrid vehicles. The new mobile robot speed\ncontroller is capable of driving the vehicle even in extreme case of IC engine\nfailure, for example, due to gas depletion.",
    "published": "2006-01-14T08:35:52Z",
    "link": "http://arxiv.org/pdf/cs/0601065v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Nazim Mir-Nasiri",
      "Sulaiman Hussaini"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0603010v1",
    "title": "Asymptotic constant-factor approximation algorithm for the Traveling\n  Salesperson Problem for Dubins' vehicle",
    "summary": "This article proposes the first known algorithm that achieves a\nconstant-factor approximation of the minimum length tour for a Dubins' vehicle\nthrough $n$ points on the plane. By Dubins' vehicle, we mean a vehicle\nconstrained to move at constant speed along paths with bounded curvature\nwithout reversing direction. For this version of the classic Traveling\nSalesperson Problem, our algorithm closes the gap between previously\nestablished lower and upper bounds; the achievable performance is of order\n$n^{2/3}$.",
    "published": "2006-03-02T07:07:55Z",
    "link": "http://arxiv.org/pdf/cs/0603010v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Ketan Savla",
      "Emilio Frazzoli",
      "Francesco Bullo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/math/0603155v3",
    "title": "Vers une commande multivariable sans modle",
    "summary": "A control strategy without any precise mathematical model is derived for\nlinear or nonlinear systems which are assumed to be finite-dimensional. Two\nconvincing numerical simulations are provided.",
    "published": "2006-03-07T08:15:15Z",
    "link": "http://arxiv.org/pdf/math/0603155v3.pdf",
    "category": [
      "math.OC",
      "cs.CE",
      "cs.RO",
      "physics.class-ph"
    ],
    "authors": [
      "Michel Fliess",
      "Cdric Join",
      "Mamadou Mboup",
      "Hebertt Sira-Ramirez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0603026v1",
    "title": "The Snowblower Problem",
    "summary": "We introduce the snowblower problem (SBP), a new optimization problem that is\nclosely related to milling problems and to some material-handling problems. The\nobjective in the SBP is to compute a short tour for the snowblower to follow to\nremove all the snow from a domain (driveway, sidewalk, etc.). When a snowblower\npasses over each region along the tour, it displaces snow into a nearby region.\nThe constraint is that if the snow is piled too high, then the snowblower\ncannot clear the pile.\n  We give an algorithmic study of the SBP. We show that in general, the problem\nis NP-complete, and we present polynomial-time approximation algorithms for\nremoving snow under various assumptions about the operation of the snowblower.\nMost commercially-available snowblowers allow the user to control the direction\nin which the snow is thrown. We differentiate between the cases in which the\nsnow can be thrown in any direction, in any direction except backwards, and\nonly to the right. For all cases, we give constant-factor approximation\nalgorithms; the constants increase as the throw direction becomes more\nrestricted.\n  Our results are also applicable to robotic vacuuming (or lawnmowing) with\nbounded capacity dust bin and to some versions of material-handling problems,\nin which the goal is to rearrange cartons on the floor of a warehouse.",
    "published": "2006-03-07T20:35:48Z",
    "link": "http://arxiv.org/pdf/cs/0603026v1.pdf",
    "category": [
      "cs.DS",
      "cs.CC",
      "cs.RO",
      "F.2.2; I.3.5"
    ],
    "authors": [
      "Esther M. Arkin",
      "Michael A. Bender",
      "Joseph S. B. Mitchell",
      "Valentin Polishchuk"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0603070v1",
    "title": "Predicting the Path of an Open System",
    "summary": "The expected path of an open system,which is a big Poincare system,has been\nfound in this paper.This path has been obtained from the actual and from the\nexpected droop of the open system.The actual droop has been reconstructed from\nthe variations in the power and in the frequency of the open system.The\nexpected droop has been found as a function of rotation from the expected\npotential energy of the open system under synchronization of that system.",
    "published": "2006-03-17T09:27:01Z",
    "link": "http://arxiv.org/pdf/cs/0603070v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "S. Z. Stefanov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0604110v1",
    "title": "Modeling and Mathematical Analysis of Swarms of Microscopic Robots",
    "summary": "The biologically-inspired swarm paradigm is being used to design\nself-organizing systems of locally interacting artificial agents. A major\ndifficulty in designing swarms with desired characteristics is understanding\nthe causal relation between individual agent and collective behaviors.\nMathematical analysis of swarm dynamics can address this difficulty to gain\ninsight into system design. This paper proposes a framework for mathematical\nmodeling of swarms of microscopic robots that may one day be useful in medical\napplications. While such devices do not yet exist, the modeling approach can be\nhelpful in identifying various design trade-offs for the robots and be a useful\nguide for their eventual fabrication. Specifically, we examine microscopic\nrobots that reside in a fluid, for example, a bloodstream, and are able to\ndetect and respond to different chemicals. We present the general mathematical\nmodel of a scenario in which robots locate a chemical source. We solve the\nscenario in one-dimension and show how results can be used to evaluate certain\ndesign decisions.",
    "published": "2006-04-27T23:33:25Z",
    "link": "http://arxiv.org/pdf/cs/0604110v1.pdf",
    "category": [
      "cs.MA",
      "cs.RO"
    ],
    "authors": [
      "Aram Galstyan",
      "Tad Hogg",
      "Kristina Lerman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0604111v1",
    "title": "Analysis of Dynamic Task Allocation in Multi-Robot Systems",
    "summary": "Dynamic task allocation is an essential requirement for multi-robot systems\noperating in unknown dynamic environments. It allows robots to change their\nbehavior in response to environmental changes or actions of other robots in\norder to improve overall system performance. Emergent coordination algorithms\nfor task allocation that use only local sensing and no direct communication\nbetween robots are attractive because they are robust and scalable. However, a\nlack of formal analysis tools makes emergent coordination algorithms difficult\nto design. In this paper we present a mathematical model of a general dynamic\ntask allocation mechanism. Robots using this mechanism have to choose between\ntwo types of task, and the goal is to achieve a desired task division in the\nabsence of explicit communication and global knowledge. Robots estimate the\nstate of the environment from repeated local observations and decide which task\nto choose based on these observations. We model the robots and observations as\nstochastic processes and study the dynamics of the collective behavior.\nSpecifically, we analyze the effect that the number of observations and the\nchoice of the decision function have on the performance of the system. The\nmathematical models are validated in a multi-robot multi-foraging scenario. The\nmodel's predictions agree very closely with experimental results from\nsensor-based simulations.",
    "published": "2006-04-27T23:56:10Z",
    "link": "http://arxiv.org/pdf/cs/0604111v1.pdf",
    "category": [
      "cs.RO",
      "cs.MA"
    ],
    "authors": [
      "Kristina Lerman",
      "Chris Jones",
      "Aram Galstyan",
      "Maja J Mataric"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0605070v1",
    "title": "Curve Shortening and the Rendezvous Problem for Mobile Autonomous Robots",
    "summary": "If a smooth, closed, and embedded curve is deformed along its normal vector\nfield at a rate proportional to its curvature, it shrinks to a circular point.\nThis curve evolution is called Euclidean curve shortening and the result is\nknown as the Gage-Hamilton-Grayson Theorem. Motivated by the rendezvous problem\nfor mobile autonomous robots, we address the problem of creating a polygon\nshortening flow. A linear scheme is proposed that exhibits several analogues to\nEuclidean curve shortening: The polygon shrinks to an elliptical point, convex\npolygons remain convex, and the perimeter of the polygon is monotonically\ndecreasing.",
    "published": "2006-05-16T22:30:01Z",
    "link": "http://arxiv.org/pdf/cs/0605070v1.pdf",
    "category": [
      "cs.RO",
      "cs.MA",
      "I.2.9"
    ],
    "authors": [
      "Stephen L. Smith",
      "Mireille E. Broucke",
      "Bruce A. Francis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/math/0605498v1",
    "title": "Cross-Entropic Learning of a Machine for the Decision in a Partially\n  Observable Universe",
    "summary": "Revision of the paper previously entitled \"Learning a Machine for the\nDecision in a Partially Observable Markov Universe\" In this paper, we are\ninterested in optimal decisions in a partially observable universe. Our\napproach is to directly approximate an optimal strategic tree depending on the\nobservation. This approximation is made by means of a parameterized\nprobabilistic law. A particular family of hidden Markov models, with input\n\\emph{and} output, is considered as a model of policy. A method for optimizing\nthe parameters of these HMMs is proposed and applied. This optimization is\nbased on the cross-entropic principle for rare events simulation developed by\nRubinstein.",
    "published": "2006-05-18T07:47:58Z",
    "link": "http://arxiv.org/pdf/math/0605498v1.pdf",
    "category": [
      "math.OC",
      "cs.AI",
      "cs.LG",
      "cs.NE",
      "cs.RO",
      "math.ST",
      "stat.TH"
    ],
    "authors": [
      "Frederic Dambreville"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0605096v1",
    "title": "Circle Formation of Weak Robots and Lyndon Words",
    "summary": "A Lyndon word is a non-empty word strictly smaller in the lexicographic order\nthan any of its suffixes, except itself and the empty word. In this paper, we\nshow how Lyndon words can be used in the distributed control of a set of n weak\nmobile robots. By weak, we mean that the robots are anonymous, memoryless,\nwithout any common sense of direction, and unable to communicate in an other\nway than observation. An efficient and simple deterministic protocol to form a\nregular n-gon is presented and proven for n prime.",
    "published": "2006-05-22T12:09:33Z",
    "link": "http://arxiv.org/pdf/cs/0605096v1.pdf",
    "category": [
      "cs.DC",
      "cs.RO",
      "C.2.4"
    ],
    "authors": [
      "Yoann Dieudonn",
      "Franck Petit"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0607060v1",
    "title": "Circle Formation of Weak Mobile Robots",
    "summary": "In this paper we prove the conjecture of D\\'{e}fago & Konagaya. Furthermore,\nwe describe a deterministic protocol for forming a regular n-gon in finite\ntime.",
    "published": "2006-07-12T12:57:28Z",
    "link": "http://arxiv.org/pdf/cs/0607060v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Yoann Dieudonne",
      "Ouiddad Labbani-Igbida",
      "Franck Petit"
    ]
  },
  {
    "id": "http://arxiv.org/abs/physics/0607116v1",
    "title": "Utilisation de la substitution sensorielle par lectro-stimulation\n  linguale pour la prvention des escarres chez les paraplgiques.\n  Etude prliminaire",
    "summary": "Pressure ulcers are recognized as a major health issue in individuals with\nspinal cord injuries and new approaches to prevent this pathology are\nnecessary. An innovative health strategy is being developed through the use of\ncomputer and sensory substitution via the tongue in order to compensate for the\nsensory loss in the buttock area for individuals with paraplegia. This sensory\ncompensation will enable individuals with spinal cord injuries to be aware of a\nlocalized excess of pressure at the skin/seat interface and, consequently, will\nenable them to prevent the formation of pressure ulcers by relieving the\ncutaneous area of suffering. This work reports an initial evaluation of this\napproach and the feasibility of creating an adapted behavior, with a change in\npressure as a response to electro-stimulated information on the tongue.\nObtained during a clinical study in 10 healthy seated subjects, the first\nresults are encouraging, with 92% success in 100 performed tests. These\nresults, which have to be completed and validated in the paraplegic population,\nmay lead to a new approach to education in health to prevent the formation of\npressure ulcers within this population. Keywords: Spinal Cord Injuries,\nPressure Ulcer, Sensory Substitution, Health Education, Biomedical Informatics.",
    "published": "2006-07-12T13:57:42Z",
    "link": "http://arxiv.org/pdf/physics/0607116v1.pdf",
    "category": [
      "physics.med-ph",
      "cs.RO",
      "q-bio.NC"
    ],
    "authors": [
      "Alexandre Moreau-Gaudry",
      "Fabien Robineau",
      "Pierre-Frdric Andr",
      "Anne Prince",
      "Pierre Pauget",
      "Jacques Demongeot",
      "Yohan Payan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0608105v2",
    "title": "Application Layer Definition and Analyses of Controller Area Network Bus\n  for Wire Harness Assembly Machine",
    "summary": "With the feature of multi-master bus access, nondestructive contention-based\narbitration and flexible configuration, Controller Area Network (CAN) bus is\napplied into the control system of Wire Harness Assembly Machine (WHAM). To\naccomplish desired goal, the specific features of the CAN bus is analyzed by\ncompared with other field buses and the functional performances in the CAN bus\nsystem of WHAM is discussed. Then the application layer planning of CAN bus for\ndynamic priority is presented. The critical issue for the use of CAN bus system\nin WHAM is the data transfer rate between different nodes. So processing\nefficient model is introduced to assist analyzing data transfer procedure.\nThrough the model, it is convenient to verify the real time feature of the CAN\nbus system in WHAM.",
    "published": "2006-08-28T12:42:38Z",
    "link": "http://arxiv.org/pdf/cs/0608105v2.pdf",
    "category": [
      "cs.RO",
      "cs.NI"
    ],
    "authors": [
      "Hui Guo",
      "Ying Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0609097v1",
    "title": "Traveing Salesperson Problems for a double integrator",
    "summary": "In this paper we propose some novel path planning strategies for a double\nintegrator with bounded velocity and bounded control inputs. First, we study\nthe following version of the Traveling Salesperson Problem (TSP): given a set\nof points in $\\real^d$, find the fastest tour over the point set for a double\nintegrator. We first give asymptotic bounds on the time taken to complete such\na tour in the worst-case. Then, we study a stochastic version of the TSP for\ndouble integrator where the points are randomly sampled from a uniform\ndistribution in a compact environment in $\\real^2$ and $\\real^3$. We propose\nnovel algorithms that perform within a constant factor of the optimal strategy\nwith high probability. Lastly, we study a dynamic TSP: given a stochastic\nprocess that generates targets, is there a policy which guarantees that the\nnumber of unvisited targets does not diverge over time? If such stable policies\nexist, what is the minimum wait for a target? We propose novel stabilizing\nreceding-horizon algorithms whose performances are within a constant factor\nfrom the optimum with high probability, in $\\real^2$ as well as $\\real^3$. We\nalso argue that these algorithms give identical performances for a particular\nnonholonomic vehicle, Dubins vehicle.",
    "published": "2006-09-17T23:38:32Z",
    "link": "http://arxiv.org/pdf/cs/0609097v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Ketan Savla",
      "Francesco Bullo",
      "Emilio Frazzoli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0609140v2",
    "title": "Motion Primitives for Robotic Flight Control",
    "summary": "We introduce a simple framework for learning aggressive maneuvers in flight\ncontrol of UAVs. Having inspired from biological environment, dynamic movement\nprimitives are analyzed and extended using nonlinear contraction theory.\nAccordingly, primitives of an observed movement are stably combined and\nconcatenated. We demonstrate our results experimentally on the Quanser\nHelicopter, in which we first imitate aggressive maneuvers and then use them as\nprimitives to achieve new maneuvers that can fly over an obstacle.",
    "published": "2006-09-25T19:06:59Z",
    "link": "http://arxiv.org/pdf/cs/0609140v2.pdf",
    "category": [
      "cs.RO",
      "cs.LG"
    ],
    "authors": [
      "Baris E. Perk",
      "J. J. E. Slotine"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0611006v1",
    "title": "Evolving controllers for simulated car racing",
    "summary": "This paper describes the evolution of controllers for racing a simulated\nradio-controlled car around a track, modelled on a real physical track. Five\ndifferent controller architectures were compared, based on neural networks,\nforce fields and action sequences. The controllers use either egocentric (first\nperson), Newtonian (third person) or no information about the state of the car\n(open-loop controller). The only controller that was able to evolve good racing\nbehaviour was based on a neural network acting on egocentric inputs.",
    "published": "2006-11-02T00:47:57Z",
    "link": "http://arxiv.org/pdf/cs/0611006v1.pdf",
    "category": [
      "cs.NE",
      "cs.LG",
      "cs.RO"
    ],
    "authors": [
      "Julian Togelius",
      "Simon M. Lucas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0611022v1",
    "title": "Multirobot rendezvous with visibility sensors in nonconvex environments",
    "summary": "This paper presents a coordination algorithm for mobile autonomous robots.\nRelying upon distributed sensing the robots achieve rendezvous, that is, they\nmove to a common location. Each robot is a point mass moving in a nonconvex\nenvironment according to an omnidirectional kinematic model. Each robot is\nequipped with line-of-sight limited-range sensors, i.e., a robot can measure\nthe relative position of any object (robots or environment boundary) if and\nonly if the object is within a given distance and there are no obstacles\nin-between. The algorithm is designed using the notions of robust visibility,\nconnectivity-preserving constraint sets, and proximity graphs. Simulations\nillustrate the theoretical results on the correctness of the proposed\nalgorithm, and its performance in asynchronous setups and with sensor\nmeasurement and control errors.",
    "published": "2006-11-06T02:50:42Z",
    "link": "http://arxiv.org/pdf/cs/0611022v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Anurag Ganguli",
      "Jorge Cortes",
      "Francesco Bullo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0611111v1",
    "title": "Distributed Control of Microscopic Robots in Biomedical Applications",
    "summary": "Current developments in molecular electronics, motors and chemical sensors\ncould enable constructing large numbers of devices able to sense, compute and\nact in micron-scale environments. Such microscopic machines, of sizes\ncomparable to bacteria, could simultaneously monitor entire populations of\ncells individually in vivo. This paper reviews plausible capabilities for\nmicroscopic robots and the physical constraints due to operation in fluids at\nlow Reynolds number, diffusion-limited sensing and thermal noise from Brownian\nmotion. Simple distributed controls are then presented in the context of\nprototypical biomedical tasks, which require control decisions on millisecond\ntime scales. The resulting behaviors illustrate trade-offs among speed,\naccuracy and resource use. A specific example is monitoring for patterns of\nchemicals in a flowing fluid released at chemically distinctive sites.\nInformation collected from a large number of such devices allows estimating\nproperties of cell-sized chemical sources in a macroscopic volume. The\nmicroscopic devices moving with the fluid flow in small blood vessels can\ndetect chemicals released by tissues in response to localized injury or\ninfection. We find the devices can readily discriminate a single cell-sized\nchemical source from the background chemical concentration, providing\nhigh-resolution sensing in both time and space. By contrast, such a source\nwould be difficult to distinguish from background when diluted throughout the\nblood volume as obtained with a blood sample.",
    "published": "2006-11-21T23:22:20Z",
    "link": "http://arxiv.org/pdf/cs/0611111v1.pdf",
    "category": [
      "cs.RO",
      "cs.MA",
      "I.2.9; I.2.11"
    ],
    "authors": [
      "Tad Hogg"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0611136v1",
    "title": "Neural Computation with Rings of Quasiperiodic Oscillators",
    "summary": "We describe the use of quasiperiodic oscillators for computation and control\nof robots. We also describe their relationship to central pattern generators in\nsimple organisms and develop a group theory for describing the dynamics of\nthese systems.",
    "published": "2006-11-27T15:28:57Z",
    "link": "http://arxiv.org/pdf/cs/0611136v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "E. A. Rietman",
      "R. W. Hillis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0612029v1",
    "title": "A Classification of 6R Manipulators",
    "summary": "This paper presents a classification of generic 6-revolute jointed (6R)\nmanipulators using homotopy class of their critical point manifold. A part of\nclassification is listed in this paper because of the complexity of homotopy\nclass of 4-torus. The results of this classification will serve future research\nof the classification and topological properties of maniplators joint space and\nworkspace.",
    "published": "2006-12-05T16:04:30Z",
    "link": "http://arxiv.org/pdf/cs/0612029v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Ming-Zhe Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0701040v1",
    "title": "Curve Tracking Control for Legged Locomotion in Horizontal Plane",
    "summary": "We derive a hybrid feedback control law for the lateral leg spring (LLS)\nmodel so that the center of mass of a legged runner follows a curved path in\nhorizontal plane. The control law enables the runner to change the placement\nand the elasticity of its legs to move in a desired direction. Stable motion\nalong a curved path is achieved using curvature, bearing and relative distance\nbetween the runner and the curve as feedback. Constraints on leg parameters\ndetermine the class of curves that can be followed. We also derive an optimal\ncontrol law that stabilizes the orientation of the runner's body relative to\nthe velocity of the runner's center of mass.",
    "published": "2007-01-06T20:55:15Z",
    "link": "http://arxiv.org/pdf/cs/0701040v1.pdf",
    "category": [
      "cs.RO",
      "I.2.9"
    ],
    "authors": [
      "F. Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0701077v3",
    "title": "Asynchronous Distributed Searchlight Scheduling",
    "summary": "This paper develops and compares two simple asynchronous distributed\nsearchlight scheduling algorithms for multiple robotic agents in nonconvex\npolygonal environments. A searchlight is a ray emitted by an agent which cannot\npenetrate the boundary of the environment. A point is detected by a searchlight\nif and only if the point is on the ray at some instant. Targets are points\nwhich can move continuously with unbounded speed. The objective of the proposed\nalgorithms is for the agents to coordinate the slewing (rotation about a point)\nof their searchlights in a distributed manner, i.e., using only local sensing\nand limited communication, such that any target will necessarily be detected in\nfinite time. The first algorithm we develop, called the DOWSS (Distributed One\nWay Sweep Strategy), is a distributed version of a known algorithm described\noriginally in 1990 by Sugihara et al \\cite{KS-IS-MY:90}, but it can be very\nslow in clearing the entire environment because only one searchlight may slew\nat a time. In an effort to reduce the time to clear the environment, we develop\na second algorithm, called the PTSS (Parallel Tree Sweep Strategy), in which\nsearchlights sweep in parallel if guards are placed according to an environment\npartition belonging to a class we call PTSS partitions. Finally, we discuss how\nDOWSS and PTSS could be combined with with deployment, or extended to\nenvironments with holes.",
    "published": "2007-01-11T20:55:17Z",
    "link": "http://arxiv.org/pdf/cs/0701077v3.pdf",
    "category": [
      "cs.MA",
      "cs.RO",
      "I.2.11"
    ],
    "authors": [
      "Karl J. Obermeyer",
      "Anurag Ganguli",
      "Francesco Bullo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/cs/0703067v2",
    "title": "Target assignment for robotic networks: asymptotic performance under\n  limited communication",
    "summary": "We are given an equal number of mobile robotic agents, and distinct target\nlocations. Each agent has simple integrator dynamics, a limited communication\nrange, and knowledge of the position of every target. We address the problem of\ndesigning a distributed algorithm that allows the group of agents to divide the\ntargets among themselves and, simultaneously, leads each agent to reach its\nunique target. We do not require connectivity of the communication graph at any\ntime. We introduce a novel assignment-based algorithm with the following\nfeatures: initial assignments and robot motions follow a greedy rule, and\ndistributed refinements of the assignment exploit an implicit circular ordering\nof the targets. We prove correctness of the algorithm, and give worst-case\nasymptotic bounds on the time to complete the assignment as the environment\ngrows with the number of agents. We show that among a certain class of\ndistributed algorithms, our algorithm is asymptotically optimal. The analysis\nutilizes results on the Euclidean traveling salesperson problem.",
    "published": "2007-03-14T19:20:45Z",
    "link": "http://arxiv.org/pdf/cs/0703067v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Stephen L. Smith",
      "Francesco Bullo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0704.3268v1",
    "title": "2D Path Solutions from a Single Layer Excitable CNN Model",
    "summary": "An easily implementable path solution algorithm for 2D spatial problems,\nbased on excitable/programmable characteristics of a specific cellular\nnonlinear network (CNN) model is presented and numerically investigated. The\nnetwork is a single layer bioinspired model which was also implemented in CMOS\ntechnology. It exhibits excitable characteristics with regionally bistable\ncells. The related response realizes propagations of trigger autowaves, where\nthe excitable mode can be globally preset and reset. It is shown that, obstacle\ndistributions in 2D space can also be directly mapped onto the coupled cell\narray in the network. Combining these two features, the network model can serve\nas the main block in a 2D path computing processor. The related algorithm and\nconfigurations are numerically experimented with circuit level parameters and\nperformance estimations are also presented. The simplicity of the model also\nallows alternative technology and device level implementation, which may become\ncritical in autonomous processor design of related micro or nanoscale robotic\napplications.",
    "published": "2007-04-24T20:20:46Z",
    "link": "http://arxiv.org/pdf/0704.3268v1.pdf",
    "category": [
      "cs.RO",
      "cs.NE"
    ],
    "authors": [
      "Koray Karahaliloglu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.0738v1",
    "title": "The Optimization of a Novel Prismatic Drive",
    "summary": "The design of a mechanical transmission taking into account the transmitted\nforces is reported in this paper. This transmission is based on Slide-o-Cam, a\ncam mechanism with multiple rollers mounted on a common translating follower.\nThe design of Slide-o-Cam, a transmission intended to produce a sliding motion\nfrom a turning drive, or vice versa, was reported elsewhere. This transmission\nprovides pure-rolling motion, thereby reducing the friction of rack-and-pinions\nand linear drives. The pressure angle is a relevant performance index for this\ntransmission because it determines the amount of force transmitted to the load\nvs. that transmitted to the machine frame. To assess the transmission\ncapability of the mechanism, the Hertz formula is introduced to calculate the\nstresses on the rollers and on the cams. The final transmission is intended to\nreplace the current ball-screws in the Orthoglide, a three-DOF parallel robot\nfor the production of translational motions, currently under development for\nmachining applications at Ecole Centrale de Nantes.",
    "published": "2007-05-05T10:28:22Z",
    "link": "http://arxiv.org/pdf/0705.0738v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Stphane Caro",
      "Emilie Bouyer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.0856v1",
    "title": "The Multiobjective Optimization of a Prismatic Drive",
    "summary": "The multiobjective optimization of Slide-o-Cam is reported in this paper.\nSlide-o-Cam is a cam mechanism with multiple rollers mounted on a common\ntranslating follower. This transmission provides pure-rolling motion, thereby\nreducing the friction of rack-and-pinions and linear drives. A Pareto frontier\nis obtained by means of multiobjective optimization. This optimization is based\non three objective functions: (i) the pressure angle, which is a suitable\nperformance index for the transmission because it determines the amount of\nforce transmitted to the load vs. that transmitted to the machine frame; (ii)\nthe Hertz pressure used to evaluate the stresses produced on the contact\nsurface between cam and roller; and (iii) the size of the mechanism,\ncharacterized by the number of cams and their width.",
    "published": "2007-05-07T06:39:17Z",
    "link": "http://arxiv.org/pdf/0705.0856v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Emilie Bouyer",
      "Stphane Caro",
      "Damien Chablat",
      "Jorge Angeles"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.0956v1",
    "title": "On Isotropic Sets of Points in the Plane. Application to the Design of\n  Robot Archirectures",
    "summary": "Various performance indices are used for the design of serial manipulators.\nOne method of optimization relies on the condition number of the Jacobian\nmatrix. The minimization of the condition number leads, under certain\nconditions, to isotropic configurations, for which the roundoff-error\namplification is lowest. In this paper, the isotropy conditions, introduced\nelsewhere, are the motivation behind the introduction of isotropic sets of\npoints. By connecting together these points, we define families of isotropic\nmanipulators. This paper is devoted to planar manipulators, the concepts being\ncurrently extended to their spatial counterparts. Furthermore, only\nmanipulators with revolute joints are considered here.",
    "published": "2007-05-07T18:19:06Z",
    "link": "http://arxiv.org/pdf/0705.0956v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Jorge Angeles",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.0959v1",
    "title": "The Kinematic Analysis of a Symmetrical Three-Degree-of-Freedom Planar\n  Parallel Manipulator",
    "summary": "Presented in this paper is the kinematic analysis of a symmetrical\nthree-degree-of-freedom planar parallel manipulator. In opposite to serial\nmanipulators, parallel manipulators can admit not only multiple inverse\nkinematic solutions, but also multiple direct kinematic solutions. This\nproperty produces more complicated kinematic models but allows more flexibility\nin trajectory planning. To take into account this property, the notion of\naspects, i.e. the maximal singularity-free domains, was introduced, based on\nthe notion of working modes, which makes it possible to separate the inverse\nkinematic solutions. The aim of this paper is to show that a non-singular\nassembly-mode changing trajectory exist for a symmetrical planar parallel\nmanipulator, with equilateral base and platform triangle.",
    "published": "2007-05-07T18:28:17Z",
    "link": "http://arxiv.org/pdf/0705.0959v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Philippe Wenger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.0960v1",
    "title": "Uniqueness Domains in the Workspace of Parallel Manipulators",
    "summary": "This work investigates new kinematic features of parallel manipulators. It is\nwell known that parallel manipulators admit generally several direct kinematic\nsolutions for a given set of input joint values. The aim of this paper is to\ncharacterize the uniqueness domains in the workspace of parallel manipulators,\nas well as their image in the joint space. The study focuses on the most usual\ncase of parallel manipulators with only one inverse kinematic solution. The\nnotion of aspect introduced for serial manipulators in [Borrel 86] is redefined\nfor such parallel manipulators. Then, it is shown that it is possible to link\nseveral solutions to the forward kinematic problem without meeting a\nsingularity, thus meaning that the aspects are not uniqueness domains. An\nadditional set of surfaces, namely the characteristic surfaces, are\ncharacterized which divide the workspace into basic regions and yield new\nuniqueness domains. This study is illustrated all along the paper with a 3-RPR\nplanar parallel manipulator. An octree model of spaces is used to compute the\njoint space, the workspace and all other newly defined sets.",
    "published": "2007-05-07T18:33:34Z",
    "link": "http://arxiv.org/pdf/0705.0960v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.0961v1",
    "title": "The Kinematic design of a 3-dof Hybrid Manipulator",
    "summary": "This paper focuses on the kinematic properties of a new\nthree-degree-of-freedom hybrid manipulator. This manipulator is obtained by\nadding in series to a five-bar planar mechanism (similar to the one studied by\nBajpai and Roth) a third revolute passing through the line of centers of the\ntwo actuated revolute joints of the above linkage. The resulting architecture\nis hybrid in that it has both serial and parallel links. Fully-parallel\nmanipulators are known for the existence of particularly undesirable\nsingularities (referred to as parallel singularities) where control is lost [4]\nand [6]. On the other hand, due to their cantilever type of kinematic\narrangement, fully serial manipulators suffer from a lack of stiffness and from\nrelatively large positioning errors. The hybrid manipulator studied is\nintrinsically stiffer and more accurate. Furthermore, since all actuators are\nlocated on the first axis, the inertial effects are considerably reduced. In\naddition, it is shown that the special kinematic structure of our manipulator\nhas the potential of avoiding parallel singularities by a suitable choice of\nthe \"working mode\", thus leading to larger workspaces. The influence of the\ndifferent structural dimensions (e.g. the link lengths) on the kinematic and\nmechanical properties are analysed in view of the optimal design of such hybrid\nmanipulators.",
    "published": "2007-05-07T18:36:02Z",
    "link": "http://arxiv.org/pdf/0705.0961v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Philippe Wenger",
      "Jorge Angeles"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.0962v1",
    "title": "Definition sets for the Direct Kinematics of Parallel Manipulators",
    "summary": "The aim of this paper is to characterize the uniqueness domains in the\nworkspace of parallel manipulators, as well as their image in the joint space.\nThe notion of aspect introduced for serial manipulators in [Borrel 86] is\nredefined for such parallel manipulators. Then, it is shown that it is possible\nto link several solutions to the direct kinematic problem without meeting a\nsingularity, thus meaning that the aspects are not uniqueness domains.\nAdditional surfaces are characterized in the workspace which yield new\nuniqueness domains. An octree model of spaces is used to compute the joint\nspace, the workspace and all other newly defined sets. This study is\nillustrated all along the paper with a 3-RPR planar parallel manipulator.",
    "published": "2007-05-07T18:39:19Z",
    "link": "http://arxiv.org/pdf/0705.0962v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.0982v1",
    "title": "A New Three-DOF Parallel Mechanism: Milling Machine Applications",
    "summary": "This paper describes a new parallel kinematic architecture for machining\napplications, namely, the orthoglide. This machine features three fixed\nparallel linear joints which are mounted orthogonally and a mobile platform\nwhich moves in the Cartesian x-y-z space with fixed orientation. The main\ninterest of the orthoglide is that it takes benefit from the advantages of the\npopular PPP serial machines (regular Cartesian workspace shape and uniform\nperformances) as well as from the parallel kinematic arrangement of the links\n(less inertia and better dynamic performances), which makes the orthoglide well\nsuited to high-speed machining applications. Possible extension of the\northoglide to 5-axis machining is also investigated.",
    "published": "2007-05-07T20:01:20Z",
    "link": "http://arxiv.org/pdf/0705.0982v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Philippe Wenger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.1036v1",
    "title": "Strategies for the Design of a Slide-o-Cam Transmission",
    "summary": "The optimization of the pressure angle in a cam-follower transmission is\nreported in this paper. This transmission is based on Slide-o-Cam, a cam\nmechanism with multiple rollers mounted on a common translating follower. The\ndesign of Slide-o-Cam, a transmission intended to produce a sliding motion from\na turning drive, or vice versa, was reported elsewhere. This transmission\nprovides pure-rolling motion, thereby reducing the friction of rack-and-pinions\nand linear drives. The pressure angle is a suitable performance index for this\ntransmission because it determines the amount of force transmitted to the load\nvs. that transmitted to the machine frame. Two alternative design strategies\nare studied, namely, (i) increase the number of lobes on each cam or (ii)\nincrease the number of cams. This device is intended to replace the current\nball-screws in Orthoglide, a three-DOF parallel robot for the production of\ntranslational motions, currently under development at Ecole Centrale de Nantes\nfor machining applications.",
    "published": "2007-05-08T07:09:57Z",
    "link": "http://arxiv.org/pdf/0705.1036v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Jorge Angeles"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.1037v1",
    "title": "Regions of Feasible Point-to-Point Trajectories in the Cartesian\n  Workspace of Fully-Parallel Manipulators",
    "summary": "The goal of this paper is to define the n-connected regions in the Cartesian\nworkspace of fully-parallel manipulators, i.e. the maximal regions where it is\npossible to execute point-to-point motions. The manipulators considered in this\nstudy may have multiple direct and inverse kinematic solutions. The N-connected\nregions are characterized by projection, onto the Cartesian workspace, of the\nconnected components of the reachable configuration space defined in the\nCartesian product of the Cartesian space by the joint space. Generalized octree\nmodels are used for the construction of all spaces. This study is illustrated\nwith a simple planar fully-parallel manipulator.",
    "published": "2007-05-08T07:11:02Z",
    "link": "http://arxiv.org/pdf/0705.1037v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Philippe Wenger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.1038v1",
    "title": "The Design of Parallel Kinematic Machine Tools Using Kinetostatic\n  Performance Criteria",
    "summary": "Most industrial machine tools have a serial kinematic architecture, which\nmeans that each axis has to carry the following one, including its actuators\nand joints. High Speed Machining highlights some drawbacks of such\narchitectures: heavy moving parts require from the machine structure high\nstiffness to limit bending problems that lower the machine accuracy, and limit\nthe dynamic performances of the feed axes. That is why PKMs attract more and\nmore researchers and companies, because they are claimed to offer several\nadvantages over their serial counterparts, like high structural rigidity and\nhigh dynamic capacities. Indeed, the parallel kinematic arrangement of the\nlinks provides higher stiffness and lower moving masses that reduce inertia\neffects. Thus, PKMs have better dynamic performances. However, the design of a\nparallel kinematic machine tool (PKMT) is a hard task that requires further\nresearch studies before wide industrial use can be expected. Many criteria need\nto be taken into account in the design of a PKMT. We pay special attention to\nthe description of kinetostatic criteria that rely on the conditioning of the\nJacobian matrix of the mechanism. The organisation of this paper is as follows:\nnext section introduces general remarks about PKMs, then is explained why PKMs\ncan be interesting alternative machine tool designs. Then are presented\nexisting PKMTs. An application to the design of a small-scale machine tool\nprototype developed at IRCCyN is presented at the end of this paper.",
    "published": "2007-05-08T07:13:25Z",
    "link": "http://arxiv.org/pdf/0705.1038v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Flix Majou",
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.1148v1",
    "title": "Sparation des Solutions aux Modles Gomtriques Direct et\n  Inverse pour les Manipulateurs Pleinement Parallles",
    "summary": "This article provides a formalism making it possible to manage the solutions\nof the direct and inverse kinematic models of the fully parallel manipulators.\nWe introduce the concept of working modes to separate the solutions from the\nopposite geometrical model. Then, we define, for each working mode, the aspects\nof these manipulators. To separate the solutions from the direct kinematics\nmodel, we introduce the concept of characteristic surfaces. Then, we define the\nuniqueness domains, as being the greatest domains of the workspace in which\nthere is unicity of solutions. The principal applications of this work are the\ndesign, the trajectory planning.",
    "published": "2007-05-08T19:10:18Z",
    "link": "http://arxiv.org/pdf/0705.1148v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Philippe Wenger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.1150v1",
    "title": "On the Kinetostatic Optimization of Revolute-Coupled Planar Manipulators",
    "summary": "Proposed in this paper is a kinetostatic performance index for the optimum\ndimensioning of planar manipulators of the serial type. The index is based on\nthe concept of distance of the underlying Jacobian matrix to a given isotropic\nmatrix that is used as a reference model for purposes of performance\nevaluation. Applications of the index fall in the realm of design, but control\napplications are outlined. The paper focuses on planar manipulators, the basic\nconcepts being currently extended to their three-dimensional counterparts.",
    "published": "2007-05-08T19:11:12Z",
    "link": "http://arxiv.org/pdf/0705.1150v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Jorge Angeles"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.1215v1",
    "title": "Kinematic Calibration of the Orthoglide-Type Mechanisms",
    "summary": "The paper proposes a novel calibration approach for the Orthoglide-type\nmechanisms based on observations of the manipulator leg parallelism during\nmotions between the prespecified test postures. It employs a low-cost measuring\nsystem composed of standard comparator indicators attached to the universal\nmagnetic stands. They are sequentially used for measuring the deviation of the\nrelevant leg location while the manipulator moves the TCP along the Cartesian\naxes. Using the measured differences, the developed algorithm estimates the\njoint offsets that are treated as the most essential parameters to be adjusted.\nThe sensitivity of the measurement methods and the calibration accuracy are\nalso studied. Experimental results are presented that demonstrate validity of\nthe proposed calibration technique.",
    "published": "2007-05-09T07:21:35Z",
    "link": "http://arxiv.org/pdf/0705.1215v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Anatoly Pashkevich",
      "Damien Chablat",
      "Philippe Wenger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.1217v1",
    "title": "The Design of a Novel Prismatic Drive for a Three-DOF\n  Parallel-Kinematics Machine",
    "summary": "The design of a novel prismatic drive is reported in this paper. This\ntransmission is based on Slide-O-Cam, a cam mechanism with multiple rollers\nmounted on a common translating follower. The design of Slide-O-Cam was\nreported elsewhere. This drive thus provides pure-rolling motion, thereby\nreducing the friction of rack-and-pinions and linear drives. Such properties\ncan be used to design new transmissions for parallel-kinematics machines. In\nthis paper, this transmission is optimized to replace ball-screws in\nOrthoglide, a three-DOF parallel robot optimized for machining applications.",
    "published": "2007-05-09T07:27:45Z",
    "link": "http://arxiv.org/pdf/0705.1217v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Jrome Renotte",
      "Damien Chablat",
      "Jorge Angeles"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.1218v1",
    "title": "Calibration of quasi-isotropic parallel kinematic Machines: Orthoglide",
    "summary": "The paper proposes a novel approach for the geometrical model calibration of\nquasi-isotropic parallel kinematic mechanisms of the Orthoglide family. It is\nbased on the observations of the manipulator leg parallelism during motions\nbetween the specific test postures and employs a low-cost measuring system\ncomposed of standard comparator indicators attached to the universal magnetic\nstands. They are sequentially used for measuring the deviation of the relevant\nleg location while the manipulator moves the TCP along the Cartesian axes.\nUsing the measured differences, the developed algorithm estimates the joint\noffsets and the leg lengths that are treated as the most essential parameters.\nValidity of the proposed calibration technique is confirmed by the experimental\nresults.",
    "published": "2007-05-09T07:30:48Z",
    "link": "http://arxiv.org/pdf/0705.1218v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Anatoly Pashkevich",
      "Roman Gomolitsky",
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.1271v1",
    "title": "Design of a 3 Axis Parallel Machine Tool for High Speed Machining: The\n  Orthoglide",
    "summary": "The Orthoglide project aims at designing a new 3-axis machine tool for High\nSpeed Machining. Basis kinematics is a 3 degree-of-freedom translational\nparallel mechanism. This basis was submitted to isotropic and manipulability\nconstraints that allowed the optmization of its kinematic architecture and legs\narchitecture. Thus, several leg morphologies are convenient for the chosen\nmechanism. We explain the process that led us to the choice we made for the\nOrthoglide. A static study is presented to show how singular configurations of\nthe legs can cause stiffness problems.",
    "published": "2007-05-09T12:23:53Z",
    "link": "http://arxiv.org/pdf/0705.1271v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Flix Majou",
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.1272v1",
    "title": "The Isoconditioning Loci of Planar Three-DOF Parallel Manipulators",
    "summary": "The subject of this paper is a special class of parallel manipulators. First,\nwe analyze a family of three-degree-of-freedom manipulators. Two Jacobian\nmatrices appear in the kinematic relations between the joint-rate and the\nCartesian-velocity vectors, which are called the \"inverse kinematics\" and the\n\"direct kinematics\" matrices. The singular configurations of these matrices are\nstudied. The isotropic configurations are then studied based on the\ncharacteristic length of this manipulator. The isoconditioning loci of all\nJacobian matrices are computed to define a global performance index to compare\nthe different working modes.",
    "published": "2007-05-09T12:27:08Z",
    "link": "http://arxiv.org/pdf/0705.1272v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Stphane Caro",
      "Philippe Wenger",
      "Jorge Angeles"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.1280v1",
    "title": "A Novel method for the design of 2-DOF Parallel mechanisms for machining\n  applications",
    "summary": "Parallel Kinematic Mechanisms (PKM) are interesting alternative designs for\nmachine tools. A design method based on velocity amplification factors analysis\nis presented in this paper. The comparative study of two simple\ntwo-degree-of-freedom PKM dedicated to machining applications is led through\nthis method: the common desired properties are the largest square Cartesian\nworkspace for given kinetostatic performances. The orientation and position of\nthe Cartesian workspace are chosen to avoid singularities and to produce the\nbest ratio between Cartesian workspace size and mechanism size. The machine\nsize of each resulting design is used as a comparative criterion.",
    "published": "2007-05-09T13:18:59Z",
    "link": "http://arxiv.org/pdf/0705.1280v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Flix Majou",
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.1282v1",
    "title": "Design of a Three-Axis Isotropic Parallel Manipulator for Machining\n  Applications: The Orthoglide",
    "summary": "The orthoglide is a 3-DOF parallel mechanism designed at IRCCyN for machining\napplications. It features three fixed parallel linear joints which are mounted\northogonally and a mobile platform which moves in the Cartesian x-y-z space\nwith fixed orientation. The orthoglide has been designed as function of a\nprescribed Cartesian workspace with prescribed kinetostatic performances. The\ninteresting features of the orthoglide are a regular Cartesian workspace shape,\nuniform performances in all directions and good compactness. A small-scale\nprototype of the orthoglide under development is presented at the end of this\npaper.",
    "published": "2007-05-09T13:23:37Z",
    "link": "http://arxiv.org/pdf/0705.1282v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.1284v1",
    "title": "Workspace Analysis of the Orthoglide using Interval Analysis",
    "summary": "This paper addresses the workspace analysis of the orthoglide, a 3-DOF\nparallel mechanism designed for machining applications. This machine features\nthree fixed parallel linear joints which are mounted orthogonally and a mobile\nplatform which moves in the Cartesian x-y-z space with fixed orientation. The\nworkspace analysis is conducted on the bases of prescribed kinetostatic\nperformances. The interesting features of the orthoglide are a regular\nCartesian workspace shape, uniform performances in all directions and good\ncompactness. Interval analysis based methods for computing the dextrous\nworkspace and the largest cube enclosed in this workspace are presented.",
    "published": "2007-05-09T13:24:39Z",
    "link": "http://arxiv.org/pdf/0705.1284v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Philippe Wenger",
      "Jean-Pierre Merlet"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.1285v1",
    "title": "Priphriques haptiques et simulation d'objets, de robots et de\n  mannequins dans un environnement de CAO-Robotique : eM-Virtual Desktop",
    "summary": "This paper presents the development of a new software in order to manage\nobjects, robots and mannequins in using the possibilities given by the haptic\nfeedback of the Phantom desktop devices. The haptic device provides 6\npositional degree of freedom sensing but three degrees force feedback. This\nsoftware called eM-Virtual Desktop is integrated in the Tecnomatix's solution\ncalled eM-Workplace. The eM-Workplace provides powerful solutions for planning\nand designing of complex assembly facilities, lines and workplaces. In the\ndigital mockup context, the haptic interfaces can be used to reduce the\ndevelopment cycle of products. Three different loops are used to manage the\ngraphic, the collision detection and the haptic feedback according to theirs\nown frequencies. The developed software is currently tested in industrial\ncontext by a European automotive constructor.",
    "published": "2007-05-09T13:26:46Z",
    "link": "http://arxiv.org/pdf/0705.1285v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Fouad Bennis",
      "Bernard Hoessler",
      "Matthieu Guibert"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.1343v1",
    "title": "The Optimal Design of Three Degree-of-Freedom Parallel Mechanisms for\n  Machining Applications",
    "summary": "The subject of this paper is the optimal design of a parallel mechanism\nintended for three-axis machining applications. Parallel mechanisms are\ninteresting alternative designs in this context but most of them are designed\nfor three- or six-axis machining applications. In the last case, the position\nand the orientation of the tool are coupled and the shape of the workspace is\ncomplex. The aim of this paper is to use a simple parallel mechanism with\ntwo-degree-of-freedom (dof) for translational motions and to add one leg to\nhave one-dof rotational motion. The kinematics and singular configurations are\nstudied as well as an optimization method. The three-degree-of-freedom\nmechanisms analyzed in this paper can be extended to four-axis machines by\nadding a fourth axis in series with the first two.",
    "published": "2007-05-09T19:13:46Z",
    "link": "http://arxiv.org/pdf/0705.1343v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Philippe Wenger",
      "Flix Majou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.1344v1",
    "title": "Classification of one family of 3R positioning Manipulators",
    "summary": "The aim of this paper is to classify one family of 3R serial positioning\nmanipulators. This categorization is based on the number of cusp points of\nquaternary, binary, generic and non-generic manipulators. It was found three\nsubsets of manipulators with 0, 2 or 4 cusp points and one homotopy class for\ngeneric quaternary manipulators. This classification allows us to define the\ndesign parameters for which the manipulator is cuspidal or not, i.e., for which\nthe manipulator can or cannot change posture without meeting a singularity,\nrespectively.",
    "published": "2007-05-09T19:16:05Z",
    "link": "http://arxiv.org/pdf/0705.1344v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Maher Baili",
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.1394v1",
    "title": "The Orthoglide: Kinematics and Workspace Analysis",
    "summary": "The paper addresses kinematic and geometrical aspects of the Orthoglide, a\nthree-DOF parallel mechanism. This machine consists of three fixed linear\njoints, which are mounted orthogonally, three identical legs and a mobile\nplatform, which moves in the Cartesian x-y-z space with fixed orientation. New\nsolutions to solve inverse/direct kinematics are proposed and a detailed\nworkspace analysis is performed taking into account specific joint limit\nconstraints.",
    "published": "2007-05-10T06:53:24Z",
    "link": "http://arxiv.org/pdf/0705.1394v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Anatoly Pashkevich",
      "Damien Chablat",
      "Philippe Wenger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.1395v1",
    "title": "Subjective Evaluation of Forms in an Immersive Environment",
    "summary": "User's perception of product, by essence subjective, is a major topic in\nmarketing and industrial design. Many methods, based on users' tests, are used\nso as to characterise this perception. We are interested in three main methods:\nmultidimensional scaling, semantic differential method, and preference mapping.\nThese methods are used to built a perceptual space, in order to position the\nnew product, to specify requirements by the study of user's preferences, to\nevaluate some product attributes, related in particular to style (aesthetic).\nThese early stages of the design are primordial for a good orientation of the\nproject. In parallel, virtual reality tools and interfaces are more and more\nefficient for suggesting to the user complex feelings, and creating in this way\nvarious levels of perceptions. In this article, we present on an example the\nuse of multidimensional scaling, semantic differential method and preference\nmapping for the subjective assessment of virtual products. These products,\nwhich geometrical form is variable, are defined with a CAD model and are\nproposed to the user with a spacemouse and stereoscopic glasses. Advantages and\nlimitations of such evaluation is next discussed..",
    "published": "2007-05-10T06:54:11Z",
    "link": "http://arxiv.org/pdf/0705.1395v1.pdf",
    "category": [
      "cs.HC",
      "cs.RO"
    ],
    "authors": [
      "Jean-Franois Petiot",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.1397v1",
    "title": "Realistic Rendering of Kinetostatic Indices of Mechanisms",
    "summary": "The work presented in this paper is related to the use of a haptic device in\nan environment of robotic simulation. Such device introduces a new approach to\nfeel and to understand the boundaries of the workspace of mechanisms as well as\nits kinetostatic properties. Indeed, these concepts are abstract and thus often\ndifficult to understand for the end-users. To catch his attention, we propose\nto amplify the problems of the mechanisms in order to help him to take the good\ndecisions.",
    "published": "2007-05-10T06:56:25Z",
    "link": "http://arxiv.org/pdf/0705.1397v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Fouad Bennis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.1399v1",
    "title": "A New Concept of Modular Parallel Mechanism for Machining Applications",
    "summary": "The subject of this paper is the design of a new concept of modular parallel\nmechanisms for three, four or five-axis machining applications. Most parallel\nmechanisms are designed for three- or six-axis machining applications. In the\nlast case, the position and the orientation of the tool are coupled and the\nshape of the workspace is complex. The aim of this paper is to use a simple\nparallel mechanism with two-degree-of-freedom (dof) for translation motions and\nto add one or two legs to add one or two-dofs for rotation motions. The\nkinematics and singular configurations are studied for each mechanism.",
    "published": "2007-05-10T07:03:29Z",
    "link": "http://arxiv.org/pdf/0705.1399v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Philippe Wenger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.1400v1",
    "title": "A Workspace based Classification of 3R Orthogonal Manipulators",
    "summary": "A classification of a family of 3-revolute (3R) positioning manipulators is\nestablished. This classification is based on the topology of their workspace.\nThe workspace is characterized in a half-cross section by the singular curves\nof the manipulator. The workspace topology is defined by the number of cusps\nand nodes that appear on these singular curves. The design parameters space is\nshown to be partitioned into nine subspaces of distinct workspace topologies.\nEach separating surface is given as an explicit expression in the\nDH-parameters.",
    "published": "2007-05-10T07:05:37Z",
    "link": "http://arxiv.org/pdf/0705.1400v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Philippe Wenger",
      "Maher Baili",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.1409v1",
    "title": "Singularity Surfaces and Maximal Singularity-Free Boxes in the Joint\n  Space of Planar 3-RPR Parallel Manipulators",
    "summary": "In this paper, a method to compute joint space singularity surfaces of 3-RPR\nplanar parallel manipulators is first presented. Then, a procedure to determine\nmaximal joint space singularity-free boxes is introduced. Numerical examples\nare given in order to illustrate graphically the results. This study is of high\ninterest for planning trajectories in the joint space of 3-RPR parallel\nmanipulators and for manipulators design as it may constitute a tool for\nchoosing appropriate joint limits and thus for sizing the link lengths of the\nmanipulator.",
    "published": "2007-05-10T08:32:06Z",
    "link": "http://arxiv.org/pdf/0705.1409v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Mazen Zein",
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.1410v1",
    "title": "Kinematics analysis of the parallel module of the VERNE machine",
    "summary": "The paper derives the inverse and forward kinematic equations of a spatial\nthree-degree-of-freedom parallel mechanism, which is the parallel module of a\nhybrid serial-parallel 5-axis machine tool. This parallel mechanism consists of\na moving platform that is connected to a fixed base by three non-identical\nlegs. Each leg is made up of one prismatic and two pair spherical joint, which\nare connected in a way that the combined effects of the three legs lead to an\nover-constrained mechanism with complex motion. This motion is defined as a\nsimultaneous combination of rotation and translation.",
    "published": "2007-05-10T08:32:53Z",
    "link": "http://arxiv.org/pdf/0705.1410v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Daniel Kanaan",
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0705.1450v1",
    "title": "An Algorithm for Computing Cusp Points in the Joint Space of 3-RPR\n  Parallel Manipulators",
    "summary": "This paper presents an algorithm for detecting and computing the cusp points\nin the joint space of 3-RPR planar parallel manipulators. In manipulator\nkinematics, cusp points are special points, which appear on the singular curves\nof the manipulators. The nonsingular change of assembly mode of 3-RPR parallel\nmanipulators was shown to be associated with the existence of cusp points. At\neach of these points, three direct kinematic solutions coincide. In the\nliterature, a condition for the existence of three coincident direct kinematic\nsolutions was established, but has never been exploited, because the algebra\ninvolved was too complicated to be solved. The algorithm presented in this\npaper solves this equation and detects all the cusp points in the joint space\nof these manipulators.",
    "published": "2007-05-10T12:10:12Z",
    "link": "http://arxiv.org/pdf/0705.1450v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Mazen Zein",
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0706.0457v1",
    "title": "Challenges and Opportunities of Evolutionary Robotics",
    "summary": "Robotic hardware designs are becoming more complex as the variety and number\nof on-board sensors increase and as greater computational power is provided in\never-smaller packages on-board robots. These advances in hardware, however, do\nnot automatically translate into better software for controlling complex\nrobots. Evolutionary techniques hold the potential to solve many difficult\nproblems in robotics which defy simple conventional approaches, but present\nmany challenges as well. Numerous disciplines including artificial life,\ncognitive science and neural networks, rule-based systems, behavior-based\ncontrol, genetic algorithms and other forms of evolutionary computation have\ncontributed to shaping the current state of evolutionary robotics. This paper\nprovides an overview of developments in the emerging field of evolutionary\nrobotics, and discusses some of the opportunities and challenges which\ncurrently face practitioners in the field.",
    "published": "2007-06-04T16:08:22Z",
    "link": "http://arxiv.org/pdf/0706.0457v1.pdf",
    "category": [
      "cs.NE",
      "cs.RO"
    ],
    "authors": [
      "D. A. Sofge",
      "M. A. Potter",
      "M. D. Bugajska",
      "A. C. Schultz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0706.1061v1",
    "title": "Design, Implementation, and Cooperative Coevolution of an Autonomous/\n  Teleoperated Control System for a Serpentine Robotic Manipulator",
    "summary": "Design, implementation, and machine learning issues associated with\ndeveloping a control system for a serpentine robotic manipulator are explored.\nThe controller developed provides autonomous control of the serpentine robotic\nmanipulatorduring operation of the manipulator within an enclosed environment\nsuch as an underground storage tank. The controller algorithms make use of both\nlow-level joint angle control employing force/position feedback constraints,\nand high-level coordinated control of end-effector positioning. This approach\nhas resulted in both high-level full robotic control and low-level telerobotic\ncontrol modes, and provides a high level of dexterity for the operator.",
    "published": "2007-06-07T19:27:12Z",
    "link": "http://arxiv.org/pdf/0706.1061v1.pdf",
    "category": [
      "cs.NE",
      "cs.RO"
    ],
    "authors": [
      "Donald Sofge",
      "Gerald Chiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.0724v1",
    "title": "Workspace Analysis of the Parallel Module of the VERNE Machine",
    "summary": "The paper addresses geometric aspects of a spatial three-degree-of-freedom\nparallel module, which is the parallel module of a hybrid serial-parallel\n5-axis machine tool. This parallel module consists of a moving platform that is\nconnected to a fixed base by three non-identical legs. Each leg is made up of\none prismatic and two pairs of spherical joint, which are connected in a way\nthat the combined effects of the three legs lead to an over-constrained\nmechanism with complex motion. This motion is defined as a simultaneous\ncombination of rotation and translation. A method for computing the complete\nworkspace of the VERNE parallel module for various tool lengths is presented.\nAn algorithm describing this method is also introduced.",
    "published": "2007-07-05T06:43:49Z",
    "link": "http://arxiv.org/pdf/0707.0724v1.pdf",
    "category": [
      "cs.RO",
      "physics.class-ph"
    ],
    "authors": [
      "Daniel Kanaan",
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.1193v1",
    "title": "Singular curves and cusp points in the joint space of 3-RPR parallel\n  manipulators",
    "summary": "This paper investigates the singular curves in two-dimensional slices of the\njoint space of a family of planar parallel manipulators. It focuses on special\npoints, referred to as cusp points, which may appear on these curves. Cusp\npoints play an important role in the kinematic behavior of parallel\nmanipulators since they make possible a nonsingular change of assembly mode.\nThe purpose of this study is twofold. First, it reviews an important previous\nwork, which, to the authors' knowledge, has never been exploited yet. Second,\nit determines the cusp points in any two-dimensional slice of the joint space.\nFirst results show that the number of cusp points may vary from zero to eight.\nThis work finds applications in both design and trajectory planning.",
    "published": "2007-07-09T07:38:47Z",
    "link": "http://arxiv.org/pdf/0707.1193v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Mazen Zein",
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.1824v1",
    "title": "The Kinematics of Manipulators Built From Closed Planar Mechanisms",
    "summary": "The paper discusses the kinematics of manipulators builts of planar closed\nkinematic chains. A special kinematic scheme is extracted from the array of\nthese mechanisms that looks the most promising for the creation of different\ntypes of robotic manipulators. The structural features of this manipulator\ndetermine a number of its original properties that essentially simplify its\ncontrol. These features allow the main control problems to be effectively\novercome by application of the simple kinematic problems. The workspace and\nsingular configurations of a basic planar manipulator are studied. By using a\ngraphic simulation method, motions of the designed mechanism are examined. A\nprototype of this mechanism was implemented to verify the proposed approach.",
    "published": "2007-07-12T15:42:46Z",
    "link": "http://arxiv.org/pdf/0707.1824v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Leonid Slutski",
      "Damien Chablat",
      "Jorge Angeles"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.1957v1",
    "title": "Moveability and Collision Analysis for Fully-Parallel Manipulators",
    "summary": "The aim of this paper is to characterize the moveability of fully-parallel\nmanipulators in the presence of obstacles. Fully parallel manipulators are used\nin applications where accuracy, stiffness or high speeds and accelerations are\nrequired \\cite{Merlet:97}. However, one of its main drawbacks is a relatively\nsmall workspace compared to the one of serial manipulators. This is due mainly\nto the existence of potential internal collisions, and the existence of\nsingularities. In this paper, the notion of free aspect is defined which\npermits to exhibit domains of the workspace and the joint space free of\nsingularity and collision. The main application of this study is the\nmoveability analysis in the workspace of the manipulator as well as\npath-planning, control and design.",
    "published": "2007-07-13T09:59:25Z",
    "link": "http://arxiv.org/pdf/0707.1957v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Philippe Wenger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.2006v1",
    "title": "Working Modes and Aspects in Fully-Parallel Manipulator",
    "summary": "The aim of this paper is to characterize the notion of aspect in the\nworkspace and in the joint space for parallel manipulators. In opposite to the\nserial manipulators, the parallel manipulators can admit not only multiple\ninverse kinematic solutions, but also multiple direct kinematic solutions. The\nnotion of aspect introduced for serial manipulators in [Borrel 86], and\nredefined for parallel manipulators with only one inverse kinematic solution in\n[Wenger 1997], is redefined for general fully parallel manipulators. Two\nJacobian matrices appear in the kinematic relations between the joint-rate and\nthe Cartesian-velocity vectors, which are called the \"inverse kinematics\" and\nthe \"direct kinematics\" matrices. The study of these matrices allow to\nrespectively define the parallel and the serial singularities. The notion of\nworking modes is introduced to separate inverse kinematic solutions. Thus, we\ncan find out domains of the workspace and the joint space exempt of\nsingularity. Application of this study is the moveability analysis in the\nworkspace of the manipulator as well as path-planing and control. This study is\nillustrated in this paper with a RR-RRR planar parallel manipulator.",
    "published": "2007-07-13T13:40:56Z",
    "link": "http://arxiv.org/pdf/0707.2006v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Philippe Wenger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.2017v1",
    "title": "The Isoconditioning Loci of A Class of Closed-Chain Manipulators",
    "summary": "The subject of this paper is a special class of closed-chain manipulators.\nFirst, we analyze a family of two-degree-of-freedom (dof) five-bar planar\nlinkages. Two Jacobian matrices appear in the kinematic relations between the\njoint-rate and the Cartesian-velocity vectors, which are called the ``inverse\nkinematics\" and the \"direct kinematics\" matrices. It is shown that the loci of\npoints of the workspace where the condition number of the direct-kinematics\nmatrix remains constant, i.e., the isoconditioning loci, are the coupler points\nof the four-bar linkage obtained upon locking the middle joint of the linkage.\nFurthermore, if the line of centers of the two actuated revolutes is used as\nthe axis of a third actuated revolute, then a three-dof hybrid manipulator is\nobtained. The isoconditioning loci of this manipulator are surfaces of\nrevolution generated by the isoconditioning curves of the two-dof manipulator,\nwhose axis of symmetry is that of the third actuated revolute.",
    "published": "2007-07-13T14:18:45Z",
    "link": "http://arxiv.org/pdf/0707.2017v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Philippe Wenger",
      "Jorge Angeles"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.2027v1",
    "title": "Workspace and Assembly modes in Fully-Parallel Manipulators : A\n  Descriptive Study",
    "summary": "The goal of this paper is to explain, using a typical example, the\ndistribution of the different assembly modes in the workspace and their\neffective role in the execution of trajectories. The singular and non-singular\nchanges of assembly mode are described and compared to each other. The\nnon-singular change of assembly mode is more deeply analysed and discussed in\nthe context of trajectory planning. In particular, it is shown that, according\nto the location of the initial and final configurations with respect to the\nuniqueness domains in the workspace, there are three different cases to\nconsider before planning a linking trajectory.",
    "published": "2007-07-13T15:04:13Z",
    "link": "http://arxiv.org/pdf/0707.2027v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.2034v1",
    "title": "Conception Isotropique D'Une Morphologie Parallle : Application \n  L'Usinage",
    "summary": "The aim of this paper is the isotropic design of a hybrid morphology\ndedicated to 3-axis machining applications. It is necessary to ensure the\nfeasibility of continuous, singularity-free trajectories, as well as a good\nmanipulability in position and velocity. We want to propose an alternative\ndesign to conventional serial machine-tools. We compare a serial PPP\nmachine-tool (three prismatic orthogonal axes) with a hybrid architecture which\nwe optimize only the first two axes. The critrerion used for the optimization\nis the conditioning of the Jacobian matrices. The optimum, namely isotropy, can\nbe obtained which provides our architecture with excellent manipulability\nproperties.",
    "published": "2007-07-13T15:24:29Z",
    "link": "http://arxiv.org/pdf/0707.2034v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Philippe Wenger",
      "Jorge Angeles"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.2042v1",
    "title": "A distributed Approach for Access and Visibility Task under Ergonomic\n  Constraints with a Manikin in a Virtual Reality Environment",
    "summary": "This paper presents a new method, based on a multi-agent system and on\ndigital mock-up technology, to assess an efficient path planner for a manikin\nfor access and visibility task under ergonomic constraints. In order to solve\nthis problem, the human operator is integrated in the process optimization to\ncontribute to a global perception of the environment. This operator cooperates,\nin real-time, with several automatic local elementary agents. The result of\nthis work validates solutions brought by digital mock-up and that can be\napplied to simulate maintenance task.",
    "published": "2007-07-13T15:34:22Z",
    "link": "http://arxiv.org/pdf/0707.2042v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Florence Bidault",
      "Damien Chablat",
      "Patrick Chedmail",
      "Laurent Pino"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.2185v1",
    "title": "Modlisation Dynamique d'un Robot Parallle  3-DDL : l'Orthoglide",
    "summary": "In this article, we propose a method for calculation of the inverse and\ndirect dynamic models of the Orthoglide, a parallel robot with threedegrees of\nfreedom in translation. These models are calculated starting from the elements\nof the dynamic model of the kinematic chain structure and equations of\nNewton-Euler applied to the platform. These models are obtained in explicit\nform having an interesting physical interpretation.",
    "published": "2007-07-15T07:14:51Z",
    "link": "http://arxiv.org/pdf/0707.2185v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Sylvain Guegan",
      "Wisama Khalil",
      "Damien Chablat",
      "Philippe Wenger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.2227v1",
    "title": "Degeneracy study of the forward kinematics of planar 3-RPR parallel\n  manipulators",
    "summary": "This paper investigates two situations in which the forward kinematics of\nplanar 3-RPR parallel manipulators degenerates. These situations have not been\naddressed before. The first degeneracy arises when the three input joint\nvariables r1, r2 and r3 satisfy a certain relationship. This degeneracy yields\na double root of the characteristic polynomial in t, which could be erroneously\ninterpreted as two coalesce assembly modes. But, unlike what arises in\nnon-degenerate cases, this double root yields two sets of solutions for the\nposition coordinates (x, y) of the platform. In the second situation, we show\nthat the forward kinematics degenerates over the whole joint space if the base\nand platform triangles are congruent and the platform triangle is rotated by\n180 deg about one of its sides. For these \"degenerate\" manipulators, which are\ndefined here for the first time, the forward kinematics is reduced to the\nsolution of a 3rd-degree polynomial and a quadratics in sequence. Such\nmanipulators constitute, in turn, a new family of analytic planar manipulators\nthat would be more suitable for industrial applications.",
    "published": "2007-07-15T17:57:21Z",
    "link": "http://arxiv.org/pdf/0707.2227v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Philippe Wenger",
      "Damien Chablat",
      "Mazen Zein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.2228v1",
    "title": "Kinematic Analysis of a Family of 3R Manipulators",
    "summary": "The workspace topologies of a family of 3-revolute (3R) positioning\nmanipulators are enumerated. The workspace is characterized in a half-cross\nsection by the singular curves. The workspace topology is defined by the number\nof cusps that appear on these singular curves. The design parameters space is\nshown to be divided into five domains where all manipulators have the same\nnumber of cusps. Each separating surface is given as an explicit expression in\nthe DH-parameters. As an application of this work, we provide a necessary and\nsufficient condition for a 3R orthogonal manipulator to be cuspidal, i.e. to\nchange posture without meeting a singularity. This condition is set as an\nexplicit expression in the DH parameters.",
    "published": "2007-07-15T18:00:53Z",
    "link": "http://arxiv.org/pdf/0707.2228v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Maher Baili",
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.2229v1",
    "title": "The Computation of All 4R Serial Spherical Wrists With an Isotropic\n  Architecture",
    "summary": "A spherical wrist of the serial type with n revolute (R) joints is said to be\nisotropic if it can attain a posture whereby the singular values of its\nJacobian matrix are all equal to sqrt(n/3). What isotropy brings about is\nrobustness to manufacturing, assembly, and measurement errors, thereby\nguaranteeing a maximum orientation accuracy. In this paper we investigate the\nexistence of redundant isotropic architectures, which should add to the\ndexterity of the wrist under design by virtue of its extra degree of freedom.\nThe problem formulation, for, leads to a system of eight quadratic equations\nwith eight unknowns. The Bezout number of this system is thus 2^8=256, its BKK\nbound being 192. However, the actual number of solutions is shown to be 32. We\nlist all solutions of the foregoing algebraic problem. All these solutions are\nreal, but distinct solutions do not necessarily lead to distinct manipulators.\nUpon discarding those algebraic solutions that yield no new wrists, we end up\nwith exactly eight distinct architectures, the eight corresponding manipulators\nbeing displayed at their isotropic postures.",
    "published": "2007-07-15T18:04:09Z",
    "link": "http://arxiv.org/pdf/0707.2229v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Jorge Angeles"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.2238v1",
    "title": "A design oriented study for 3R Orthogonal Manipulators With Geometric\n  Simplifications",
    "summary": "This paper proposes a method to calculate the largest Regular Dextrous\nWorkspace (RDW) of some types of three-revolute orthogonal manipulators that\nhave at least one of their DH parameters equal to zero. Then a new performance\nindex based on the RDW is introduced, the isocontours of this index are plotted\nin the parameter space of the interesting types of manipulators and finally an\ninspection of the domains of the parameter spaces is conducted in order to\nidentify the better manipulator architectures. The RDW is a part of the\nworkspace whose shape is regular (cube, cylinder) and the performances\n(conditioning index) are bounded inside. The groups of 3R orthogonal\nmanipulators studied have interesting kinematic properties such as, a\nwell-connected workspace that is fully reachable with four inverse kinematic\nsolutions and that does not contain any void. This study is of high interest\nfor the design of alternative manipulator geometries.",
    "published": "2007-07-15T20:25:24Z",
    "link": "http://arxiv.org/pdf/0707.2238v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Mazen Zein",
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.2270v1",
    "title": "Design of a Spherical Wrist with Parallel Architecture: Application to\n  Vertebrae of an Eel Robot",
    "summary": "The design of a spherical wrist with parallel architecture is the object of\nthis article. This study is part of a larger project, which aims to design and\nto build an eel robot for inspection of immersed piping. The kinematic analysis\nof the mechanism is presented first to characterize the singular configurations\nas well as the isotropic configurations. We add the design constraints related\nto the application, such as (i) the compactness of the mechanism, (ii) the\nsymmetry of the elements in order to ensure static and dynamic balance and\n(iii) the possibility of the mechanism to fill the elliptic form of the ell\nsections.",
    "published": "2007-07-16T07:41:16Z",
    "link": "http://arxiv.org/pdf/0707.2270v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Philippe Wenger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.2275v1",
    "title": "Passive Control Architecture for Virtual Humans",
    "summary": "In the present paper, we introduce a new control architecture aimed at\ndriving virtual humans in interaction with virtual environments, by motion\ncapture. It brings decoupling of functionalities, and also of stability thanks\nto passivity. We show projections can break passivity, and thus must be used\ncarefully. Our control scheme enables task space and internal control, contact,\nand joint limits management. Thanks to passivity, it can be easily extended.\nBesides, we introduce a new tool as for manikin's control, which makes it able\nto build passive projections, so as to guide the virtual manikin when sharp\nmovements are needed.",
    "published": "2007-07-16T08:33:43Z",
    "link": "http://arxiv.org/pdf/0707.2275v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Antoine Rennuit",
      "Alain Micaelli",
      "Xavier Merlhiot",
      "Claude Andriot",
      "Franois Guillaume",
      "Nicolas Chevassus",
      "Damien Chablat",
      "Patrick Chedmail"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.2718v1",
    "title": "Animation of virtual mannequins, robot-like simulation or motion\n  captures",
    "summary": "In order to optimize the costs and time of design of the new products while\nimproving their quality, concurrent engineering is based on the digital model\nof these products, the numerical model. However, in order to be able to avoid\ndefinitively physical model, old support of the design, without loss of\ninformation, new tools must be available. Especially, a tool making it possible\nto check simply and quickly the maintainability of complex mechanical sets\nusing the numerical model is necessary. Since one decade, our team works on the\ncreation of tool for the generation and the analysis of trajectories of virtual\nmannequins. The simulation of human tasks can be carried out either by\nrobot-like simulation or by simulation by motion capture. This paper presents\nsome results on the both two methods. The first method is based on a\nmulti-agent system and on a digital mock-up technology, to assess an efficient\npath planner for a manikin or a robot for access and visibility task taking\ninto account ergonomic constraints or joint and mechanical limits. In order to\nsolve this problem, the human operator is integrated in the process\noptimization to contribute to a global perception of the environment. This\noperator cooperates, in real-time, with several automatic local elementary\nagents. In the case of the second approach, we worked with the CEA and EADS/CCR\nto solve the constraints related to the evolution of human virtual in its\nenvironment on the basis of data resulting from motion capture system. An\napproach using of the virtual guides was developed to allow to the user the\nrealization of precise trajectory in absence of force feedback. The result of\nthis work validates solutions through the digital mock-up; it can be applied to\nsimulate maintenability and mountability tasks.",
    "published": "2007-07-18T12:59:15Z",
    "link": "http://arxiv.org/pdf/0707.2718v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.2721v1",
    "title": "A Framework to Illustrate Kinematic Behavior of Mechanisms by Haptic\n  Feedback",
    "summary": "The kinematic properties of mechanisms are well known by the researchers and\nteachers. The theory based on the study of Jacobian matrices allows us to\nexplain, for example, the singular configuration. However, in many cases, the\nphysical sense of such properties is difficult to explain to students. The aim\nof this article is to use haptic feedback to render to the user the\nsignification of different kinematic indices. The framework uses a Phantom Omni\nand a serial and parallel mechanism with two degrees of freedom. The\nend-effector of both mechanisms can be moved either by classical mouse, or\nPhantom Omni with or without feedback.",
    "published": "2007-07-18T13:02:29Z",
    "link": "http://arxiv.org/pdf/0707.2721v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Qinqin Zhang",
      "Damien Chablat",
      "Fouad Bennis",
      "Wei Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.2833v1",
    "title": "A Comparative Study between Two Three-DOF Parallel Kinematic Machines\n  using Kinetostatic Criteria and Interval Analysis",
    "summary": "This paper addresses the workspace analysis of two 3-DOF translational\nparallel mechanisms designed for machining applications. The two machines\nfeatures three fixed linear joints. The joint axes of the first machine are\northogonal whereas these of the second are parallel. In both cases, the mobile\nplatform moves in the Cartesian $x-y-z$ space with fixed orientation. The\nworkspace analysis is conducted on the basis of prescribed kinetostatic\nperformances. Interval analysis based methods are used to compute the dextrous\nworkspace and the largest cube enclosed in this workspace.",
    "published": "2007-07-19T04:44:06Z",
    "link": "http://arxiv.org/pdf/0707.2833v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Philippe Wenger",
      "Jean-Pierre Merlet"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.2841v1",
    "title": "The Virtual Manufacturing concept: Scope, Socio-Economic Aspects and\n  Future Trends",
    "summary": "The research area \"Virtual Manufacturing (VM)'' is the use of information\ntechnology and computer simulation to model real world manufacturing processes\nfor the purpose of analysing and understanding them. As automation technologies\nsuch as CAD/CAM have substantially shortened the time required to design\nproducts, Virtual Manufacturing will have a similar effect on the manufacturing\nphase thanks to the modelling, simulation and optimisation of the product and\nthe processes involved in its fabrication. After a description of Virtual\nManufacturing (definitions and scope), we present some socio-economic factors\nof VM and finaly some \"hot topics'' for the future are proposed.",
    "published": "2007-07-19T07:15:53Z",
    "link": "http://arxiv.org/pdf/0707.2841v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Philippe Dpinc",
      "Eric Nol",
      "Peer-Oliver Woelk"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.2842v1",
    "title": "A Classification of 3R Orthogonal Manipulators by the Topology of their\n  Workspace",
    "summary": "A classification of a family of 3-revolute (3R) positining manipulators is\nestablished. This classification is based on the topology of their workspace.\nThe workspace is characterized in a half-cross section by the singular curves.\nThe workspace topology is defined by the number of cusps and nodes that appear\non these singular curves. The design parameters space is shown to be divided\ninto nine domains of distinct workspace topologies, in which all manipulators\nhave similar global kinematic properties. Each separating surface is given as\nan explicit expression in the DH-parameters.",
    "published": "2007-07-19T07:20:26Z",
    "link": "http://arxiv.org/pdf/0707.2842v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Maher Baili",
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.3186v1",
    "title": "Kinematic and stiffness analysis of the Orthoglide, a PKM with simple,\n  regular workspace and homogeneous performances",
    "summary": "The Orthoglide is a Delta-type PKM dedicated to 3-axis rapid machining\napplications that was originally developed at IRCCyN in 2000-2001 to meet the\nadvantages of both serial 3-axis machines (regular workspace and homogeneous\nperformances) and parallel kinematic architectures (good dynamic performances\nand stiffness). This machine has three fixed parallel linear joints that are\nmounted orthogonally. The geometric parameters of the Orthoglide were defined\nas function of the size of a prescribed cubic Cartesian workspace that is free\nof singularities and internal collision. The interesting features of the\nOrthoglide are a regular Cartesian workspace shape, uniform performances in all\ndirections and good compactness. In this paper, a new method is proposed to\nanalyze the stiffness of overconstrained Delta-type manipulators, such as the\nOrthoglide. The Orthoglide is then benchmarked according to geometric,\nkinematic and stiffness criteria: workspace to footprint ratio, velocity and\nforce transmission factors, sensitivity to geometric errors, torsional\nstiffness and translational stiffness.",
    "published": "2007-07-21T05:24:17Z",
    "link": "http://arxiv.org/pdf/0707.3186v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Anatoly Pashkevich",
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.3507v1",
    "title": "Workspace and Kinematic Analysis of the VERNE machine",
    "summary": "This paper describes the workspace and the inverse and direct kinematic\nanalysis of the VERNE machine, a serial/parallel 5-axis machine tool designed\nby Fatronik for IRCCyN. This machine is composed of a three-degree-of-freedom\n(DOF) parallel module and a two-DOF serial tilting table. The parallel module\nconsists of a moving platform that is connected to a fixed base by three\nnon-identical legs. This feature involves (i) a simultaneous combination of\nrotation and translation for the moving platform, which is balanced by the\ntilting table and (ii) workspace whose shape and volume vary as a function of\nthe tool length. This paper summarizes results obtained in the context of the\nEuropean projects NEXT (\"Next Generation of Productions Systems\").",
    "published": "2007-07-24T09:13:22Z",
    "link": "http://arxiv.org/pdf/0707.3507v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Daniel Kanaan",
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.3534v1",
    "title": "The Kinetostatic Optimization of a Novel Prismatic Drive",
    "summary": "The design of a mechanical transmission taking into account the transmitted\nforces is reported in this paper. This transmission is based on Slide-o-Cam, a\ncam mechanism with multiple rollers mounted on a common translating follower.\nThe design of Slide-o-Cam, a transmission intended to produce a sliding motion\nfrom a turning drive, or vice versa, was reported elsewhere. This transmission\nprovides pure-rolling motion, thereby reducing the friction of rack-and-pinions\nand linear drives. The pressure angle is a suitable performance index for this\ntransmission because it determines the amount of force transmitted to the load\nvs. that transmitted to the machine frame. To assess the transmission\ncapability of the mechanism, the Hertz formula is introduced to calculate the\nstresses on the rollers and on the cams. The final transmission is intended to\nreplace the current ball-screws in the Orthoglide, a three-DOF parallel robot\nfor the production of translational motions, currently under development for\nmachining applications at Ecole Centrale de Nantes.",
    "published": "2007-07-24T12:18:05Z",
    "link": "http://arxiv.org/pdf/0707.3534v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Stphane Caro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.3550v1",
    "title": "A Six Degree-Of-Freedom Haptic Device Based On The Orthoglide And A\n  Hybrid Agile Eye",
    "summary": "This paper is devoted to the kinematic design of a new six degree-of-freedom\nhaptic device using two parallel mechanisms. The first one, called orthoglide,\nprovides the translation motions and the second one, called agile eye, produces\nthe rotational motions. These two motions are decoupled to simplify the direct\nand inverse kinematics, as it is needed for real-time control. To reduce the\ninertial load, the motors are fixed on the base and a transmission with two\nuniversal joints is used to transmit the rotational motions from the base to\nthe end-effector. Two alternative wrists are proposed (i), the agile eye with\nthree degrees of freedom or (ii) a hybrid wrist made by the assembly of a\ntwo-dof agile eye with a rotary motor. The last one is optimized to increase\nits stiffness and to decrease the number of moving parts.",
    "published": "2007-07-24T13:42:08Z",
    "link": "http://arxiv.org/pdf/0707.3550v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Philippe Wenger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.3552v1",
    "title": "Analyse Comparative des Manipulateurs 3R  Axes Orthogonaux",
    "summary": "A family of 3R orthogonal manipulators without offset on the third body can\nbe divided into exactly nine workspace topologies. The workspace is\ncharacterized in a half-cross section by the singular curves. The workspace\ntopology is defined by the number of cusps and nodes that appear on these\nsingular curves. Based on this classification, we evaluate theses manipulators\nby the condition number related to the joint space and the proportion of the\nregion with four inverse kinematic solutions compared to a sphere containing\nall the workspace. This second performance number is in relation with the\nworkspace. We determine finally le topology of workspace to which belong\nmanipulators having the best performance number values.",
    "published": "2007-07-24T13:46:22Z",
    "link": "http://arxiv.org/pdf/0707.3552v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Maher Baili",
      "Damien Chablat",
      "Philippe Wenger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.3553v1",
    "title": "An Exhaustive Study of the Workspace Topologies of all 3R Orthogonal\n  Manipulators with Geometric Simplifications",
    "summary": "This paper analyses the workspace of the three-revolute orthogonal\nmanipulators that have at least one of their DH parameters equal to zero. These\nmanipulators are classified into different groups with similar kinematic\nproperties. The classification criteria are based on the topology of the\nworkspace. Each group is evaluated according to interesting kinematic\nproperties such as the size of the workspace subregion reachable with four\ninverse kinematic solutions, the existence and the size of voids, and the size\nof the regions of feasible paths in the workspace.",
    "published": "2007-07-24T13:49:51Z",
    "link": "http://arxiv.org/pdf/0707.3553v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Mazen Zein",
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.3560v1",
    "title": "Integration of a Balanced Virtual Manikin in a Virtual Reality Platform\n  aimed at Virtual Prototyping",
    "summary": "The work presented here is aimed at introducing a virtual human controller in\na virtual prototyping framework. After a brief introduction describing the\nproblem solved in the paper, we describe the interest as for digital humans in\nthe context of concurrent engineering. This leads us to draw a control\narchitecture enabling to drive virtual humans in a real-time immersed way, and\nto interact with the product, through motion capture. Unfortunately, we show\nthis control scheme can lead to unfeasible movements because of the lack of\nbalance control. Introducing such a controller is a problem that was never\naddressed in the context of real-time. We propose an implementation of a\nbalance controller, that we insert into the previously described control\nscheme. Next section is dedicated to show the results we obtained. Finally, we\npropose a virtual reality platform into which the digital character controller\nis integrated.",
    "published": "2007-07-24T14:23:37Z",
    "link": "http://arxiv.org/pdf/0707.3560v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Antoine Rennuit",
      "Alain Micaelli",
      "Xavier Merlhiot",
      "Claude Andriot",
      "Franois Guillaume",
      "Nicolas Chevassus",
      "Damien Chablat",
      "Patrick Chedmail"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.3562v1",
    "title": "Balanced Virtual Humans Interacting with their Environment",
    "summary": "The animation of human avatars seems very successful; the computer graphics\nindustry shows outstanding results in films everyday, the game industry\nachieves exploits... Nevertheless, the animation and control processes of such\nmanikins are very painful. It takes days to a specialist to build such animated\nsequences, and it is not adaptive to any type of modifications. Our main\npurpose is the virtual human for engineering, especially virtual prototyping.\nAs for this domain of activity, such amounts of time are prohibitive.",
    "published": "2007-07-24T14:26:28Z",
    "link": "http://arxiv.org/pdf/0707.3562v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Antoine Rennuit",
      "Alain Micaelli",
      "Xavier Merlhiot",
      "Claude Andriot",
      "Franois Guillaume",
      "Nicolas Chevassus",
      "Damien Chablat",
      "Patrick Chedmail"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.3563v1",
    "title": "Virtual reality: A human centered tool for improving Manufacturing",
    "summary": "Manufacturing is using Virtual Reality tools to enhance the product life\ncycle. Their definitions are still in flux and it is necessary to define their\nconnections. Thus, firstly, we will introduce more closely some definitions\nwhere we will find that, if the Virtual manufacturing concepts originate from\nmachining operations and evolve in this manufacturing area, there exist a lot\nof applications in different fields such as casting, forging, sheet\nmetalworking and robotics (mechanisms). From the recent projects in Europe or\nin USA, we notice that the human perception or the simulation of mannequin is\nmore and more needed in both fields. In this context, we have isolated some\napplications as ergonomic studies, assembly and maintenance simulation, design\nor training where the virtual reality tools can be applied. Thus, we find out a\nfamily of applications where the virtual reality tools give the engineers the\nmain role in the optimization process. We will illustrate our paper by several\nexamples where virtual reality interfaces are used and combined with\noptimization tools as multi-agent systems.",
    "published": "2007-07-24T14:28:01Z",
    "link": "http://arxiv.org/pdf/0707.3563v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Fouad Bennis",
      "Damien Chablat",
      "Philippe Dpinc"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.3564v1",
    "title": "A New Six Degree-of-Freedom Haptic Device based on the Orthoglide and\n  the Agile Eye",
    "summary": "The aim of this paper is to present a new six degree-of-freedom (dof) haptic\ndevice using two parallel mechanisms. The first one, called orthoglide,\nprovides the translation motions and the second one produces the rotational\nmotions. These two motions are decoupled to simplify the direct and inverse\nkinematics, as it is needed for real-times control. To reduce the inertial\nload, the motors are fixed on the base and a transmission with two universal\njoints is used to transmit the rotational motions from the base to the\nend-effector. The main feature of the orthoglide and of the agile eye mechanism\nis the existence of an isotropic configuration. The length of the legs and the\nrange limits of the orthoglide are optimized to have homogeneous performance\nthroughout the Cartesian workspace, which has a nearly cubic workspace. These\nproperties permit to have a high stiffness throughout the workspace and\nworkspace limits that are easily understandable by the user.",
    "published": "2007-07-24T14:29:41Z",
    "link": "http://arxiv.org/pdf/0707.3564v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Philippe Wenger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.3574v1",
    "title": "L'orthoglide : une machine-outil rapide d'architecture parallle\n  isotrope",
    "summary": "This article presents the Orthoglide project. The purpose of this project is\nthe realization of a prototype of machine tool to three degrees of translation.\nThe characteristic of this machine is a parallel kinematic architecture\noptimized to obtain a compact workspace with homogeneous performance. For that,\nthe principal criterion of design which was used is the isotropy.",
    "published": "2007-07-24T15:14:38Z",
    "link": "http://arxiv.org/pdf/0707.3574v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Philippe Wenger",
      "Damien Chablat",
      "Flix Majou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.3665v1",
    "title": "A Comparative Study of Parallel Kinematic Architectures for Machining\n  Applications",
    "summary": "Parallel kinematic mechanisms are interesting alternative designs for\nmachining applications. Three 2-DOF parallel mechanism architectures dedicated\nto machining applications are studied in this paper. The three mechanisms have\ntwo constant length struts gliding along fixed linear actuated joints with\ndifferent relative orientation. The comparative study is conducted on the basis\nof a same prescribed Cartesian workspace for the three mechanisms. The common\ndesired workspace properties are a rectangular shape and given kinetostatic\nperformances. The machine size of each resulting design is used as a\ncomparative criterion. The 2-DOF machine mechanisms analyzed in this paper can\nbe extended to 3-axis machines by adding a third joint.",
    "published": "2007-07-25T04:40:01Z",
    "link": "http://arxiv.org/pdf/0707.3665v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Philippe Wenger",
      "Clment Gosselin",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.3666v1",
    "title": "Kinematic Analysis of a New Parallel Machine Tool: the Orthoglide",
    "summary": "This paper describes a new parallel kinematic architecture for machining\napplications: the orthoglide. This machine features three fixed parallel linear\njoints which are mounted orthogonally and a mobile platform which moves in the\nCartesian x-y-z space with fixed orientation. The main interest of the\northoglide is that it takes benefit from the advantages of the popular PPP\nserial machines (regular Cartesian workspace shape and uniform performances) as\nwell as from the parallel kinematic arrangement of the links (less inertia and\nbetter dynamic performances), which makes the orthoglide well suited to\nhigh-speed machining applications. Possible extension of the orthoglide to\n5-axis machining is also investigated.",
    "published": "2007-07-25T04:42:19Z",
    "link": "http://arxiv.org/pdf/0707.3666v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0707.3673v1",
    "title": "The Computation of All 4R Serial Spherical Wrists With an Isotropic\n  Architecture",
    "summary": "A spherical wrist of the serial type is said to be isotropic if it can attain\na posture whereby the singular values of its Jacobian matrix are all identical\nand nonzero. What isotropy brings about is robustness to manufacturing,\nassembly, and measurement errors, thereby guaranteeing a maximum orientation\naccuracy. In this paper we investigate the existence of redundant isotropic\narchitectures, which should add to the dexterity of the wrist under design by\nvirtue of its extra degree of freedom. The problem formulation leads to a\nsystem of eight quadratic equations with eight unknowns. The Bezout number of\nthis system is thus 2^8 = 256, its BKK bound being 192. However, the actual\nnumber of solutions is shown to be 32. We list all solutions of the foregoing\nalgebraic problem. All these solutions are real, but distinct solutions do not\nnecessarily lead to distinct manipulators. Upon discarding those algebraic\nsolutions that yield no new wrists, we end up with exactly eight distinct\narchitectures, the eight corresponding manipulators being displayed at their\nisotropic posture.",
    "published": "2007-07-25T06:51:53Z",
    "link": "http://arxiv.org/pdf/0707.3673v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Jorge Angeles"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0708.0495v1",
    "title": "Virtual Manufacturing : Tools for improving Design and Production",
    "summary": "The research area \"Virtual Manufacturing\" can be defined as an integrated\nmanufacturing environment which can enhance one or several levels of decision\nand control in manufacturing process. Several domains can be addressed: Product\nand Process Design, Process and Production Planning, Machine Tool, Robot and\nManufacturing System. As automation technologies such as CAD/CAM have\nsubstantially shortened the time required to design products, Virtual\nManufacturing will have a similar effect on the manufacturing phase thanks to\nthe modelling, simulation and optimisation of the product and the processes\ninvolved in its fabrication.",
    "published": "2007-08-03T11:15:21Z",
    "link": "http://arxiv.org/pdf/0708.0495v1.pdf",
    "category": [
      "cs.RO",
      "physics.class-ph"
    ],
    "authors": [
      "Philippe Dpinc",
      "Damien Chablat",
      "Peer-Oliver Woelk"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0708.0607v1",
    "title": "Real-time control and monitoring system for LIPI's Public Cluster",
    "summary": "We have developed a monitoring and control system for LIPI's Public Cluster.\nThe system consists of microcontrollers and full web-based user interfaces for\ndaily operation. It is argued that, due to its special natures, the cluster\nrequires fully dedicated and self developed control and monitoring system. We\ndiscuss the implementation of using parallel port and dedicated\nmicro-controller for this purpose. We also show that integrating such systems\nenables an autonomous control system based on the real time monitoring, for\ninstance an autonomous power supply control based on the actual temperature,\netc.",
    "published": "2007-08-04T05:16:43Z",
    "link": "http://arxiv.org/pdf/0708.0607v1.pdf",
    "category": [
      "cs.DC",
      "cs.RO"
    ],
    "authors": [
      "I. Firmansyah",
      "B. Hermanto",
      " Hadiyanto",
      "L. T. Handoko"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0708.1049v1",
    "title": "An Interval Analysis Based Study for the Design and the Comparison of\n  3-DOF Parallel Kinematic Machines",
    "summary": "This paper addresses an interval analysis based study that is applied to the\ndesign and the comparison of 3-DOF parallel kinematic machines. Two design\ncriteria are used, (i) a regular workspace shape and, (ii) a kinetostatic\nperformance index that needs to be as homogeneous as possible throughout the\nworkspace. The interval analysis based method takes these two criteria into\naccount: on the basis of prescribed kinetostatic performances, the workspace is\nanalysed to find out the largest regular dextrous workspace enclosed in the\nCartesian workspace. An algorithm describing this method is introduced. Two\n3-DOF translational parallel mechanisms designed for machining applications are\ncompared using this method. The first machine features three fixed linear\njoints which are mounted orthogonally and the second one features three linear\njoints which are mounted in parallel. In both cases, the mobile platform moves\nin the Cartesian x-y-z space with fixed orientation.",
    "published": "2007-08-08T07:06:48Z",
    "link": "http://arxiv.org/pdf/0708.1049v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Philippe Wenger",
      "Flix Majou",
      "Jean-Pierre Merlet"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0708.3381v1",
    "title": "Architecture Optimization of a 3-DOF Translational Parallel Mechanism\n  for Machining Applications, the Orthoglide",
    "summary": "This paper addresses the architecture optimization of a 3-DOF translational\nparallel mechanism designed for machining applications. The design optimization\nis conducted on the basis of a prescribed Cartesian workspace with prescribed\nkinetostatic performances. The resulting machine, the Orthoglide, features\nthree fixed parallel linear joints which are mounted orthogonally and a mobile\nplatform which moves in the Cartesian x-y-z space with fixed orientation. The\ninteresting features of the Orthoglide are a regular Cartesian workspace shape,\nuniform performances in all directions and good compactness. A small-scale\nprototype of the Orthoglide under development is presented at the end of this\npaper.",
    "published": "2007-08-24T18:25:36Z",
    "link": "http://arxiv.org/pdf/0708.3381v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Philippe Wenger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0708.3607v1",
    "title": "Parametric stiffness analysis of the Orthoglide",
    "summary": "This paper presents a parametric stiffness analysis of the Orthoglide. A\ncompliant modeling and a symbolic expression of the stiffness matrix are\nconducted. This allows a simple systematic analysis of the influence of the\ngeometric design parameters and to quickly identify the critical link\nparameters. Our symbolic model is used to display the stiffest areas of the\nworkspace for a specific machining task. Our approach can be applied to any\nparallel manipulator for which stiffness is a critical issue.",
    "published": "2007-08-27T13:59:35Z",
    "link": "http://arxiv.org/pdf/0708.3607v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Flix Majou",
      "Clment Gosselin",
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0708.3613v1",
    "title": "Kinematics and Workspace Analysis of a Three-Axis Parallel Manipulator:\n  the Orthoglide",
    "summary": "The paper addresses kinematic and geometrical aspects of the Orthoglide, a\nthree-DOF parallel mechanism. This machine consists of three fixed linear\njoints, which are mounted orthogonally, three identical legs and a mobile\nplatform, which moves in the Cartesian x-y-z space with fixed orientation. New\nsolutions to solve inverse/direct kinematics are proposed and we perform a\ndetailed workspace and singularity analysis, taking into account specific joint\nlimit constraints.",
    "published": "2007-08-27T14:05:34Z",
    "link": "http://arxiv.org/pdf/0708.3613v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Anatoly Pashkevich",
      "Damien Chablat",
      "Philippe Wenger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0708.3723v1",
    "title": "Parametric Stiffness Analysis of the Orthoglide",
    "summary": "This paper presents a parametric stiffness analysis of the Orthoglide, a\n3-DOF translational Parallel Kinematic Machine. First, a compliant modeling of\nthe Orthoglide is conducted based on an existing method. Then stiffness matrix\nis symbolically computed. This allows one to easily study the influence of the\ngeometric design parameters on the matrix elements. Critical links are\ndisplayed. Cutting forces are then modeled so that static displacements of the\nOrthoglide tool during slot milling are symbolically computed. Influence of the\ngeometric design parameters on the static displacements is checked as well.\nOther machining operations can be modeled. This parametric stiffness analysis\ncan be applied to any parallel manipulator for which stiffness is a critical\nissue.",
    "published": "2007-08-28T07:17:46Z",
    "link": "http://arxiv.org/pdf/0708.3723v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Flix Majou",
      "Clment Gosselin",
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0708.3809v1",
    "title": "Design Strategies for the Geometric Synthesis of Orthoglide-type\n  Mechanisms",
    "summary": "The paper addresses the geometric synthesis of Orthoglide-type mechanism, a\nfamily of 3-DOF parallel manipulators for rapid machining applications, which\ncombine advantages of both serial mechanisms and parallel kinematic\narchitectures. These manipulators possess quasi-isotropic kinematic\nperformances and are made up of three actuated fixed prismatic joints, which\nare mutually orthogonal and connected to a mobile platform via three\nparallelogram chains. The platform moves in the Cartesian space with fixed\norientation, similar to conventional XYZ-machine. Three strategies have been\nproposed to define the Orthoglide geometric parameters (manipulator link\nlengths and actuated joint limits) as functions of a cubic workspace size and\ndextrous properties expressed by bounds on the velocity transmission factors,\nmanipulability or the Jacobian condition number. Low inertia and intrinsic\nstiffness have been set as additional design goals expressed by the minimal\nlink length requirement. For each design strategy, analytical expressions for\ncomputing the Orthoglide parameters are proposed. It is showed that the\nproposed strategies yield Pareto-optimal solutions, which differ by the\nkinematic performances outside the prescribed Cartesian cube (but within the\nworkspace bounded by the actuated joint limits). The proposed technique is\nillustrated with numerical examples for the Orthoglide prototype design.",
    "published": "2007-08-28T15:40:39Z",
    "link": "http://arxiv.org/pdf/0708.3809v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Anatoly Pashkevich",
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0708.3811v1",
    "title": "An Exhaustive Study of the Workspaces Tolopogies of all 3R Orthogonal\n  Manipulators with Geometric Simplifications",
    "summary": "This paper proposes a classification of three-revolute orthogonal\nmanipulators that have at least one of their DH parameters equal to zero. This\nclassification is based on the topology of their workspace. The workspace is\ncharacterized in a half-cross section by the singular curves. The workspace\ntopology is defined by the number of cusps and nodes that appear on these\nsingular curves. The manipulators are classified into different types with\nsimilar kinematic properties. Each type is evaluated according to interesting\nkinematic properties such as, whether the workspace is fully reachable with\nfour inverse kinematic solutions or not, the existence of voids, and the\nfeasibility of continuous trajectories in the workspace. It is found that\nseveral orthogonal manipulators have a \"well-connected\" workspace, that is,\ntheir workspace is fully accessible with four inverse kinematic solutions and\nany continuous trajectory is feasible. This result is of interest for the\ndesign of alternative manipulator geometries.",
    "published": "2007-08-28T15:51:50Z",
    "link": "http://arxiv.org/pdf/0708.3811v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Mazen Zein",
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0708.3896v1",
    "title": "The Isoconditioning Loci of Planar Three-DOF Parallel Manipulators",
    "summary": "The subject of this paper is a special class of three-degree-of-freedom\nparallel manipulators. The singular configurations of the two Jacobian matrices\nare first studied. The isotropic configurations are then found based on the\ncharacteristic length of this manipulator. The isoconditioning loci for the\nJacobian matrices are plotted to define a global performance index allowing the\ncomparison of the different working modes. The index thus resulting is compared\nwith the Cartesian workspace surface and the average of the condition number.",
    "published": "2007-08-29T07:08:21Z",
    "link": "http://arxiv.org/pdf/0708.3896v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Philippe Wenger",
      "Stphane Caro",
      "Jorge Angeles"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0708.3920v1",
    "title": "Kinematic analysis of the 3-RPR parallel manipulator",
    "summary": "The aim of this paper is the kinematic study of a 3-RPR planar parallel\nmanipulator where the three fixed revolute joints are actuated. The direct and\ninverse kinematic problem as well as the singular configuration is\ncharacterized. On parallel singular configurations, the motion produce by the\nmobile platform can be compared to the Reuleaux straight-line mechanism.",
    "published": "2007-08-29T09:28:52Z",
    "link": "http://arxiv.org/pdf/0708.3920v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Philippe Wenger",
      "Ilian Bonev"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0708.3936v1",
    "title": "Working and Assembly Modes of the Agile Eye",
    "summary": "This paper deals with the in-depth kinematic analysis of a special spherical\nparallel wrist, called the Agile Eye. The Agile Eye is a three-legged spherical\nparallel robot with revolute joints in which all pairs of adjacent joint axes\nare orthogonal. Its most peculiar feature, demonstrated in this paper for the\nfirst time, is that its (orientation) workspace is unlimited and flawed only by\nsix singularity curves (rather than surfaces). Furthermore, these curves\ncorrespond to self-motions of the mobile platform. This paper also demonstrates\nthat, unlike for any other such complex spatial robots, the four solutions to\nthe direct kinematics of the Agile Eye (assembly modes) have a simple geometric\nrelationship with the eight solutions to the inverse kinematics (working\nmodes).",
    "published": "2007-08-29T11:24:41Z",
    "link": "http://arxiv.org/pdf/0708.3936v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Ilian Bonev",
      "Damien Chablat",
      "Philippe Wenger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0708.4324v2",
    "title": "Sensitivity Analysis of the Orthoglide, a 3-DOF Translational Parallel\n  Kinematic Machine",
    "summary": "This paper presents a sensitivity analysis of the Orthoglide, a 3-DOF\ntranslational Parallel Kinematic Machine. Two complementary methods are\ndeveloped to analyze its sensitivity to its dimensional and angular variations.\nFirst, a linkage kinematic analysis method is used to have a rough idea of the\ninfluence of the dimensional variations on the location of the end-effector.\nBesides, this method shows that variations in the design parameters of the same\ntype from one leg to the other have the same influence on the end-effector.\nHowever, this method does not take into account the variations in the\nparallelograms. Thus, a differential vector method is used to study the\ninfluence of the dimensional and angular variations in the parts of the\nmanipulator on the position and orientation of the end-effector, and\nparticularly the influence of the variations in the parallelograms. It turns\nout that the kinematic isotropic configuration of the manipulator is the least\nsensitive one to its dimensional and angular variations. On the contrary, the\nclosest configurations to its kinematic singular configurations are the most\nsensitive ones to geometrical variations.",
    "published": "2007-08-31T11:53:35Z",
    "link": "http://arxiv.org/pdf/0708.4324v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Stphane Caro",
      "Philippe Wenger",
      "Fouad Bennis",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0709.0409v1",
    "title": "A DH-parameter based condition for 3R orthogonal manipulators to have 4\n  distinct inverse kinematic solutions",
    "summary": "Positioning 3R manipulators may have two or four inverse kinematic solutions\n(IKS). This paper derives a necessary and sufficient condition for 3R\npositioning manipulators with orthogonal joint axes to have four distinct IKS.\nWe show that the transition between manipulators with 2 and 4 IKS is defined by\nthe set of manipulators with a quadruple root of their inverse kinematics. The\nresulting condition is explicit and states that the last link length of the\nmanipulator must be greater than a quantity that depends on three of its\nremaining DH-parameters. This result is of interest for the design of new\nmanipulators.",
    "published": "2007-09-04T12:27:14Z",
    "link": "http://arxiv.org/pdf/0709.0409v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Philippe Wenger",
      "Damien Chablat",
      "Maher Baili"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0709.0680v1",
    "title": "Designing a Virtual Manikin Animation Framework Aimed at Virtual\n  Prototyping",
    "summary": "In the industry, numerous commercial packages provide tools to introduce, and\nanalyse human behaviour in the product's environment (for maintenance,\nergonomics...), thanks to Virtual Humans. We will focus on control. Thanks to\nalgorithms newly introduced in recent research papers, we think we can provide\nan implementation, which even widens, and simplifies the animation capacities\nof virtual manikins. In order to do so, we are going to express the industrial\nexpectations as for Virtual Humans, without considering feasibility (not to\nbias the issue). The second part will show that no commercial application\nprovides the tools that perfectly meet the needs. Thus we propose a new\nanimation framework that better answers the problem. Our contribution is the\nintegration - driven by need ~ of available new scientific techniques to\nanimate Virtual Humans, in a new control scheme that better answers industrial\nexpectations.",
    "published": "2007-09-05T15:52:53Z",
    "link": "http://arxiv.org/pdf/0709.0680v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Antoine Rennuit",
      "Alain Micaelli",
      "Claude Andriot",
      "Franois Guillaume",
      "Nicolas Chevassus",
      "Damien Chablat",
      "Patrick Chedmail"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0709.1099v1",
    "title": "Multi-Sensor Fusion Method using Dynamic Bayesian Network for Precise\n  Vehicle Localization and Road Matching",
    "summary": "This paper presents a multi-sensor fusion strategy for a novel road-matching\nmethod designed to support real-time navigational features within advanced\ndriving-assistance systems. Managing multihypotheses is a useful strategy for\nthe road-matching problem. The multi-sensor fusion and multi-modal estimation\nare realized using Dynamical Bayesian Network. Experimental results, using data\nfrom Antilock Braking System (ABS) sensors, a differential Global Positioning\nSystem (GPS) receiver and an accurate digital roadmap, illustrate the\nperformances of this approach, especially in ambiguous situations.",
    "published": "2007-09-07T15:03:37Z",
    "link": "http://arxiv.org/pdf/0709.1099v1.pdf",
    "category": [
      "cs.AI",
      "cs.RO"
    ],
    "authors": [
      "Cherif Smaili",
      "Maan El Badaoui El Najjar",
      "Franois Charpillet"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0709.1744v1",
    "title": "Experiments with small helicopter automated landings at unusual\n  attitudes",
    "summary": "This paper describes a set of experiments involving small helicopters landing\nautomated landing at unusual attitudes. By leveraging the increased agility of\nsmall air vehicles, we show that it is possible to automatically land a small\nhelicopter on surfaces pitched at angles up to 60 degrees. Such maneuvers\nrequire considerable agility from the vehicle and its avionics system, and they\npose significant technical and safety challenges. Our work builds upon previous\nactivities in human-inspired, high-agility flight for small rotorcraft.\nHowever, it was not possible to leverage manual flight test data to extract\nlanding maneuvers due to stringent attitude and position control requirements.\nAvailability of low-cost, local navigation systems requiring no on-board\ninstrumentation has proven particularly important for these experiments to be\nsuccessful.",
    "published": "2007-09-12T02:16:44Z",
    "link": "http://arxiv.org/pdf/0709.1744v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "S. Bayraktar",
      "E. Feron"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0710.0903v1",
    "title": "Control and Monitoring System for Modular Wireless Robot",
    "summary": "We introduce our concept on the modular wireless robot consisting of three\nmain modules : main unit, data acquisition and data processing modules. We have\ndeveloped a generic prototype with an integrated control and monitoring system\nto enhance its flexibility, and to enable simple operation through a web-based\ninterface accessible wirelessly. In present paper, we focus on the\nmicrocontroller based hardware to enable data acquisition and remote mechanical\ncontrol.",
    "published": "2007-10-03T23:05:29Z",
    "link": "http://arxiv.org/pdf/0710.0903v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "I. Firmansyah",
      "B. Hermanto",
      "L. T. Handoko"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0711.0574v1",
    "title": "Singular Curves in the Joint Space and Cusp Points of 3-RPR parallel\n  manipulators",
    "summary": "This paper investigates the singular curves in the joint space of a family of\nplanar parallel manipulators. It focuses on special points, referred to as cusp\npoints, which may appear on these curves. Cusp points play an important role in\nthe kinematic behavior of parallel manipulators since they make possible a\nnonsingular change of assembly mode. The purpose of this study is twofold.\nFirst, it exposes a method to compute joint space singular curves of 3-RPR\nplanar parallel manipulators. Second, it presents an algorithm for detecting\nand computing all cusp points in the joint space of these same manipulators.",
    "published": "2007-11-05T08:14:07Z",
    "link": "http://arxiv.org/pdf/0711.0574v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Mazen Zein",
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0711.0694v5",
    "title": "Performance Bounds for Lambda Policy Iteration and Application to the\n  Game of Tetris",
    "summary": "We consider the discrete-time infinite-horizon optimal control problem\nformalized by Markov Decision Processes. We revisit the work of Bertsekas and\nIoffe, that introduced $\\lambda$ Policy Iteration, a family of algorithms\nparameterized by $\\lambda$ that generalizes the standard algorithms Value\nIteration and Policy Iteration, and has some deep connections with the Temporal\nDifferences algorithm TD($\\lambda$) described by Sutton and Barto. We deepen\nthe original theory developped by the authors by providing convergence rate\nbounds which generalize standard bounds for Value Iteration described for\ninstance by Puterman. Then, the main contribution of this paper is to develop\nthe theory of this algorithm when it is used in an approximate form and show\nthat this is sound. Doing so, we extend and unify the separate analyses\ndevelopped by Munos for Approximate Value Iteration and Approximate Policy\nIteration. Eventually, we revisit the use of this algorithm in the training of\na Tetris playing controller as originally done by Bertsekas and Ioffe. We\nprovide an original performance bound that can be applied to such an\nundiscounted control problem. Our empirical results are different from those of\nBertsekas and Ioffe (which were originally qualified as \"paradoxical\" and\n\"intriguing\"), and much more conform to what one would expect from a learning\nexperiment. We discuss the possible reason for such a difference.",
    "published": "2007-11-05T17:07:22Z",
    "link": "http://arxiv.org/pdf/0711.0694v5.pdf",
    "category": [
      "cs.AI",
      "cs.RO"
    ],
    "authors": [
      "Bruno Scherrer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0711.1765v1",
    "title": "Kinematic calibration of orthoglide-type mechanisms",
    "summary": "The paper proposes a novel calibration approach for the Orthoglide-type\nmechanisms based on observations of the manipulator leg parallelism during\nmo-tions between the prespecified test postures. It employs a low-cost\nmeasuring system composed of standard comparator indicators attached to the\nuniversal magnetic stands. They are sequentially used for measuring the\ndeviation of the relevant leg location while the manipulator moves the TCP\nalong the Cartesian axes. Using the measured differences, the developed\nalgorithm estimates the joint offsets that are treated as the most essential\nparameters to be adjusted. The sensitivity of the meas-urement methods and the\ncalibration accuracy are also studied. Experimental re-sults are presented that\ndemonstrate validity of the proposed calibration technique",
    "published": "2007-11-12T12:57:46Z",
    "link": "http://arxiv.org/pdf/0711.1765v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Anatoly Pashkevich",
      "Damien Chablat",
      "Philippe Wenger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0712.2100v1",
    "title": "Medical image computing and computer-aided medical interventions applied\n  to soft tissues. Work in progress in urology",
    "summary": "Until recently, Computer-Aided Medical Interventions (CAMI) and Medical\nRobotics have focused on rigid and non deformable anatomical structures.\nNowadays, special attention is paid to soft tissues, raising complex issues due\nto their mobility and deformation. Mini-invasive digestive surgery was probably\none of the first fields where soft tissues were handled through the development\nof simulators, tracking of anatomical structures and specific assistance\nrobots. However, other clinical domains, for instance urology, are concerned.\nIndeed, laparoscopic surgery, new tumour destruction techniques (e.g. HIFU,\nradiofrequency, or cryoablation), increasingly early detection of cancer, and\nuse of interventional and diagnostic imaging modalities, recently opened new\nchallenges to the urologist and scientists involved in CAMI. This resulted in\nthe last five years in a very significant increase of research and developments\nof computer-aided urology systems. In this paper, we propose a description of\nthe main problems related to computer-aided diagnostic and therapy of soft\ntissues and give a survey of the different types of assistance offered to the\nurologist: robotization, image fusion, surgical navigation. Both research\nprojects and operational industrial systems are discussed.",
    "published": "2007-12-13T06:45:28Z",
    "link": "http://arxiv.org/pdf/0712.2100v1.pdf",
    "category": [
      "cs.OH",
      "cs.RO"
    ],
    "authors": [
      "Jocelyne Troccaz",
      "Michael Baumann",
      "Peter Berkelman",
      "Philippe Cinquin",
      "Vincent Daanen",
      "Antoine Leroy",
      "Maud Marchal",
      "Yohan Payan",
      "Emmanuel Promayon",
      "Sandrine Voros",
      "Stphane Bart",
      "Michel Bolla",
      "Emmanuel Chartier-Kastler",
      "Jean-Luc Descotes",
      "Andre Dusserre",
      "Jean-Yves Giraud",
      "Jean-Alexandre Long",
      "Ronan Moalic",
      "Pierre Mozer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0712.3299v1",
    "title": "Computer- and robot-assisted urological surgery",
    "summary": "The author reviews the computer and robotic tools available to urologists to\nhelp in diagnosis and technical procedures. The first part concerns the\ncontribution of robotics and presents several systems at various stages of\ndevelopment (laboratory prototypes, systems under validation or marketed\nsystems). The second part describes image fusion tools and navigation systems\ncurrently under development or evaluation. Several studies on computerized\nsimulation of urological procedures are also presented.",
    "published": "2007-12-19T22:09:18Z",
    "link": "http://arxiv.org/pdf/0712.3299v1.pdf",
    "category": [
      "cs.OH",
      "cs.RO"
    ],
    "authors": [
      "Jocelyne Troccaz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0801.0678v1",
    "title": "Implementation of perception and action at nanoscale",
    "summary": "Real time combination of nanosensors and nanoactuators with virtual reality\nenvironment and multisensorial interfaces enable us to efficiently act and\nperceive at nanoscale. Advanced manipulation of nanoobjects and new strategies\nfor scientific education are the key motivations. We have no existing intuitive\nrepresentation of the nanoworld ruled by laws foreign to our experience. A\ncentral challenge is then the construction of nanoworld simulacrum that we can\nstart to visit and to explore. In this nanoworld simulacrum, object\nidentifications will be based on probed entity physical and chemical intrinsic\nproperties, on their interactions with sensors and on the final choices made in\nbuilding a multisensorial interface so that these objects become coherent\nelements of the human sphere of action and perception. Here we describe a 1D\nvirtual nanomanipulator, part of the Cit\\'e des Sciences EXPO NANO in Paris,\nthat is the first realization based on this program.",
    "published": "2008-01-04T13:38:39Z",
    "link": "http://arxiv.org/pdf/0801.0678v1.pdf",
    "category": [
      "cs.RO",
      "cs.HC"
    ],
    "authors": [
      "Sylvain Marlire",
      "Jean Loup Florens",
      "Florence Marchi",
      "Annie Luciani",
      "Joel Chevrier"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0801.0830v9",
    "title": "Evolution of central pattern generators for the control of a five-link\n  bipedal walking mechanism",
    "summary": "Central pattern generators (CPGs), with a basis is neurophysiological\nstudies, are a type of neural network for the generation of rhythmic motion.\nWhile CPGs are being increasingly used in robot control, most applications are\nhand-tuned for a specific task and it is acknowledged in the field that generic\nmethods and design principles for creating individual networks for a given task\nare lacking. This study presents an approach where the connectivity and\noscillatory parameters of a CPG network are determined by an evolutionary\nalgorithm with fitness evaluations in a realistic simulation with accurate\nphysics. We apply this technique to a five-link planar walking mechanism to\ndemonstrate its feasibility and performance. In addition, to see whether\nresults from simulation can be acceptably transferred to real robot hardware,\nthe best evolved CPG network is also tested on a real mechanism. Our results\nalso confirm that the biologically inspired CPG model is well suited for legged\nlocomotion, since a diverse manifestation of networks have been observed to\nsucceed in fitness simulations during evolution.",
    "published": "2008-01-06T00:20:25Z",
    "link": "http://arxiv.org/pdf/0801.0830v9.pdf",
    "category": [
      "cs.NE",
      "cs.RO",
      "92B20, 92B25, 70E60, 68T05, 68U20",
      "I.2.2; I.2.9"
    ],
    "authors": [
      "Atilim Gunes Baydin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0801.4355v1",
    "title": "TER: A Robot for Remote Ultrasonic Examination: Experimental Evaluations",
    "summary": "This chapter:\n  o Motivates the clinical use of robotic tele-echography\n  o Introduces the TER system\n  o Describes technical and clinical evaluations performed with TER",
    "published": "2008-01-28T18:39:41Z",
    "link": "http://arxiv.org/pdf/0801.4355v1.pdf",
    "category": [
      "cs.OH",
      "cs.RO"
    ],
    "authors": [
      "Jean-Jacques Banihachemi",
      "Eric Boidard",
      "Jean-Luc Bosson",
      "Luc Bressollette",
      "Ivan Bricault",
      "Philippe Cinquin",
      "Gilbert Ferretti",
      "Maud Marchal",
      "Thomas Martinelli",
      "Alexandre Moreau-Gaudry",
      "Franck Pelissier",
      "Christian Roux",
      "Dominique Saragaglia",
      "Pierre Thorel",
      "Jocelyne Troccaz",
      "Adriana Vilchis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0802.2773v1",
    "title": "Stiffness Analysis of 3-d.o.f. Overconstrained Translational Parallel\n  Manipulators",
    "summary": "The paper presents a new stiffness modelling method for overconstrained\nparallel manipulators, which is applied to 3-d.o.f. translational mechanisms.\nIt is based on a multidimensional lumped-parameter model that replaces the link\nflexibility by localized 6-d.o.f. virtual springs. In contrast to other works,\nthe method includes a FEA-based link stiffness evaluation and employs a new\nsolution strategy of the kinetostatic equations, which allows computing the\nstiffness matrix for the overconstrained architectures and for the singular\nmanipulator postures. The advantages of the developed technique are confirmed\nby application examples, which deal with comparative stiffness analysis of two\ntranslational parallel manipulators.",
    "published": "2008-02-20T09:30:13Z",
    "link": "http://arxiv.org/pdf/0802.2773v1.pdf",
    "category": [
      "cs.RO",
      "physics.class-ph"
    ],
    "authors": [
      "Anatoly Pashkevich",
      "Damien Chablat",
      "Philippe Wenger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0802.3414v4",
    "title": "A Universal In-Place Reconfiguration Algorithm for Sliding Cube-Shaped\n  Robots in a Quadratic Number of Moves",
    "summary": "In the modular robot reconfiguration problem, we are given $n$ cube-shaped\nmodules (or robots) as well as two configurations, i.e., placements of the $n$\nmodules so that their union is face-connected. The goal is to find a sequence\nof moves that reconfigures the modules from one configuration to the other\nusing \"sliding moves,\" in which a module slides over the face or edge of a\nneighboring module, maintaining connectivity of the configuration at all times.\n  For many years it has been known that certain module configurations in this\nmodel require at least $\\Omega(n^2)$ moves to reconfigure between them. In this\npaper, we introduce the first universal reconfiguration algorithm -- i.e., we\nshow that any $n$-module configuration can reconfigure itself into any\nspecified $n$-module configuration using just sliding moves. Our algorithm\nachieves reconfiguration in $O(n^2)$ moves, making it asymptotically tight. We\nalso present a variation that reconfigures in-place, it ensures that throughout\nthe reconfiguration process, all modules, except for one, will be contained in\nthe union of the bounding boxes of the start and end configuration.",
    "published": "2008-02-23T00:54:13Z",
    "link": "http://arxiv.org/pdf/0802.3414v4.pdf",
    "category": [
      "cs.CG",
      "cs.MA",
      "cs.RO"
    ],
    "authors": [
      "Zachary Abel",
      "Hugo A. Akitaya",
      "Scott Duke Kominers",
      "Matias Korman",
      "Frederick Stock"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0803.0189v2",
    "title": "Quiescence of Self-stabilizing Gossiping among Mobile Agents in Graphs",
    "summary": "This paper considers gossiping among mobile agents in graphs: agents move on\nthe graph and have to disseminate their initial information to every other\nagent. We focus on self-stabilizing solutions for the gossip problem, where\nagents may start from arbitrary locations in arbitrary states.\nSelf-stabilization requires (some of the) participating agents to keep moving\nforever, hinting at maximizing the number of agents that could be allowed to\nstop moving eventually. This paper formalizes the self-stabilizing agent gossip\nproblem, introduces the quiescence number (i.e., the maximum number of\neventually stopping agents) of self-stabilizing solutions and investigates the\nquiescence number with respect to several assumptions related to agent\nanonymity, synchrony, link duplex capacity, and whiteboard capacity.",
    "published": "2008-03-03T09:14:21Z",
    "link": "http://arxiv.org/pdf/0803.0189v2.pdf",
    "category": [
      "cs.DC",
      "cs.PF",
      "cs.RO"
    ],
    "authors": [
      "Toshimitsu Masuzawa",
      "Sbastien Tixeuil"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0803.1221v1",
    "title": "Non-Singular Assembly-mode Changing Motions for 3-RPR Parallel\n  Manipulators",
    "summary": "When moving from one arbitrary location at another, a parallel manipulator\nmay change its assembly-mode without crossing a singularity. Because the\nnon-singular change of assembly-mode cannot be simply detected, the actual\nassembly-mode during motion is difficult to track. This paper proposes a global\nexplanatory approach to help better understand non-singular assembly-mode\nchanging motions for 3-RPR planar parallel manipulators. The approach consists\nin fixing one of the actuated joints and analyzing the configuration-space as a\nsurface in a 3-dimensional space. Such a global description makes it possible\nto display all possible non-singular assembly-mode changing trajectories.",
    "published": "2008-03-08T06:54:47Z",
    "link": "http://arxiv.org/pdf/0803.1221v1.pdf",
    "category": [
      "cs.RO",
      "physics.class-ph"
    ],
    "authors": [
      "Mazen Zein",
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0803.1626v1",
    "title": "Genetic-Algorithm Seeding Of Idiotypic Networks For Mobile-Robot\n  Navigation",
    "summary": "Robot-control designers have begun to exploit the properties of the human\nimmune system in order to produce dynamic systems that can adapt to complex,\nvarying, real-world tasks. Jernes idiotypic-network theory has proved the most\npopular artificial-immune-system (AIS) method for incorporation into\nbehaviour-based robotics, since idiotypic selection produces highly adaptive\nresponses. However, previous efforts have mostly focused on evolving the\nnetwork connections and have often worked with a single, pre-engineered set of\nbehaviours, limiting variability. This paper describes a method for encoding\nbehaviours as a variable set of attributes, and shows that when the encoding is\nused with a genetic algorithm (GA), multiple sets of diverse behaviours can\ndevelop naturally and rapidly, providing much greater scope for flexible\nbehaviour-selection. The algorithm is tested extensively with a simulated\ne-puck robot that navigates around a maze by tracking colour. Results show that\nhighly successful behaviour sets can be generated within about 25 minutes, and\nthat much greater diversity can be obtained when multiple autonomous\npopulations are used, rather than a single one.",
    "published": "2008-03-11T16:26:47Z",
    "link": "http://arxiv.org/pdf/0803.1626v1.pdf",
    "category": [
      "cs.NE",
      "cs.RO"
    ],
    "authors": [
      "Amanda Whitbrook",
      "Uwe Aickelin",
      "Jonathan Garibaldi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0803.2981v1",
    "title": "Idiotypic Immune Networks in Mobile Robot Control",
    "summary": "Jerne's idiotypic network theory postulates that the immune response involves\ninter-antibody stimulation and suppression as well as matching to antigens. The\ntheory has proved the most popular Artificial Immune System (ais) model for\nincorporation into behavior-based robotics but guidelines for implementing\nidiotypic selection are scarce. Furthermore, the direct effects of employing\nthe technique have not been demonstrated in the form of a comparison with\nnon-idiotypic systems. This paper aims to address these issues. A method for\nintegrating an idiotypic ais network with a Reinforcement Learning based\ncontrol system (rl) is described and the mechanisms underlying antibody\nstimulation and suppression are explained in detail. Some hypotheses that\naccount for the network advantage are put forward and tested using three\nsystems with increasing idiotypic complexity. The basic rl, a simplified hybrid\nais-rl that implements idiotypic selection independently of derived\nconcentration levels and a full hybrid ais-rl scheme are examined. The test bed\ntakes the form of a simulated Pioneer robot that is required to navigate\nthrough maze worlds detecting and tracking door markers.",
    "published": "2008-03-20T12:24:43Z",
    "link": "http://arxiv.org/pdf/0803.2981v1.pdf",
    "category": [
      "cs.NE",
      "cs.AI",
      "cs.RO"
    ],
    "authors": [
      "Amanda Whitbrook",
      "Uwe Aickelin",
      "Jonathan Garibaldi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.2036v1",
    "title": "Towards Physarum robots: computing and manipulating on water surface",
    "summary": "Plasmodium of Physarym polycephalum is an ideal biological substrate for\nimplementing concurrent and parallel computation, including combinatorial\ngeometry and optimization on graphs. We report results of scoping experiments\non Physarum computing in conditions of minimal friction, on the water surface.\nWe show that plasmodium of Physarum is capable for computing a basic spanning\ntrees and manipulating of light-weight objects. We speculate that our results\npave the pathways towards design and implementation of amorphous biological\nrobots.",
    "published": "2008-04-13T00:42:28Z",
    "link": "http://arxiv.org/pdf/0804.2036v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Andrew Adamatzky"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.3862v1",
    "title": "Image Processing in Optical Guidance for Autonomous Landing of Lunar\n  Probe",
    "summary": "Because of the communication delay between earth and moon, the GNC technology\nof lunar probe is becoming more important than ever. Current navigation\ntechnology is not able to provide precise motion estimation for probe landing\ncontrol system Computer vision offers a new approach to solve this problem. In\nthis paper, author introduces an image process algorithm of computer vision\nnavigation for autonomous landing of lunar probe. The purpose of the algorithm\nis to detect and track feature points which are factors of navigation. Firstly,\nfixation areas are detected as sub-images and matched. Secondly, feature points\nare extracted from sub-images and tracked. Computer simulation demonstrates the\nresult of algorithm takes less computation and fulfils requests of navigation\nalgorithm.",
    "published": "2008-04-24T08:22:00Z",
    "link": "http://arxiv.org/pdf/0804.3862v1.pdf",
    "category": [
      "cs.RO",
      "I.4.9"
    ],
    "authors": [
      "Ding Meng",
      "Cao Yun-feng",
      "Wu Qing-xian",
      "Zhang Zhen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.3874v1",
    "title": "Hardware In The Loop Simulator in UAV Rapid Development Life Cycle",
    "summary": "Field trial is very critical and high risk in autonomous UAV development life\ncycle. Hardware in the loop (HIL) simulation is a computer simulation that has\nthe ability to simulate UAV flight characteristic, sensor modeling and actuator\nmodeling while communicating in real time with the UAV autopilot hardware. HIL\nsimulation can be used to test the UAV autopilot hardware reliability, test the\nclosed loop performance of the overall system and tuning the control parameter.\nBy rigorous testing in the HIL simulator, the risk in the field trial can be\nminimized.",
    "published": "2008-04-24T09:35:55Z",
    "link": "http://arxiv.org/pdf/0804.3874v1.pdf",
    "category": [
      "cs.RO",
      "B.7.2"
    ],
    "authors": [
      "Widyawardana Adiprawita",
      "Adang Suwandi Ahmad",
      "Jaka Semibiring"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.3879v1",
    "title": "Effects of Leaders Position and Shape on Aerodynamic Performances of V\n  Flight Formation",
    "summary": "The influences of the leader in a group of V flight formation are dealt with.\nThe investigation is focused on the effect of its position and shape on\naerodynamics performances of a given V flight formation. Vortices generated the\nwing tip of the leader moves downstream forming a pair of opposite rotating\nline vortices. These vortices are generally undesirable because they create a\ndownwash that increases the induced drag on leaders wing. However, this\ndownwash is also accompanied by an upwash that can beneficial to the followers\nwing flying behind the leaders one, namely a favorable lift for the followers\nwing. How much contributions of the leaders wing to the followers wing in the V\nformation flight is determined by the strength of tip vortices generated by the\nleaders wing which is influenced by its position and shape including incidence\nangle, dihedral angle, aspect ratio and taper ratio. The prediction of\naerodynamic performances of the V flight formation including lift, drag and\nmoment coefficients is numerically performed by solving Navier Stokes equations\nwith k e turbulence model. The computational domain is defined with multiblock\ntopology to capture the complex geometry arrangement of the V flight formation.",
    "published": "2008-04-24T10:01:29Z",
    "link": "http://arxiv.org/pdf/0804.3879v1.pdf",
    "category": [
      "cs.RO",
      "J.2"
    ],
    "authors": [
      "H. P. Thien",
      "M. A. Moelyadi",
      "H. Muhammad"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.3881v1",
    "title": "Automated Flight Test and System Identification for Rotary Wing Small\n  Aerial Platform using Frequency Responses Analysis",
    "summary": "This paper proposes an autopilot system that can be used to control the small\nscale rotorcraft during the flight test for linear-frequency-domain system\nidentification. The input frequency swept is generated automatically as part of\nthe autopilot control command. Therefore the bandwidth coverage and consistency\nof the frequency swept is guaranteed to produce high quality data for system\nidentification. Beside that we can set the safety parameter during the flight\ntest (maximum roll or pitch value, minimum altitude, etc) so the safety of the\nwhole flight test is guaranteed. This autopilot for automated flight test will\nbe tested using hardware in the loop simulator for hover flight condition.",
    "published": "2008-04-24T10:07:34Z",
    "link": "http://arxiv.org/pdf/0804.3881v1.pdf",
    "category": [
      "cs.RO",
      "B.4.4"
    ],
    "authors": [
      "Widyawardana Adiprawita",
      "Adang Suwandi Ahmad",
      "Jaka Semibiring"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.3882v1",
    "title": "Virtual Reality Simulation of Fire Fighting Robot Dynamic and Motion",
    "summary": "This paper presents one approach in designing a Fire Fighting Robot which has\nbeen contested annually in a robotic student competition in many countries\nfollowing the rules initiated at the Trinity College. The approach makes use of\ncomputer simulation and animation in a virtual reality environment. In the\nsimulation, the amount of time, starting from home until the flame is\ndestroyed, can be confirmed. The efficacy of algorithms and parameter values\nemployed can be easily evaluated. Rather than spending time building the real\nrobot in a trial and error fashion, now students can explore more variation of\nalgorithm, parameter and sensor-actuator configuration in the early stage of\ndesign. Besides providing additional excitement during learning process and\nenhancing students understanding to the engineering aspects of the design, this\napproach could become a useful tool to increase the chance of winning the\ncontest.",
    "published": "2008-04-24T10:13:53Z",
    "link": "http://arxiv.org/pdf/0804.3882v1.pdf",
    "category": [
      "cs.RO",
      "H.5.1"
    ],
    "authors": [
      "Joga D. Setiawan",
      "Mochamad Subchan",
      "Agus Budiyono"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.3885v1",
    "title": "Heading Lock Maneuver Testing of Autonomous Underwater Vehicle",
    "summary": "In recent years, Autonomous Underwater Vehicle (UAV) research and development\nat Bandung Institute of Technology in Indonesia has achieved the testing stage\nin the field. This testing was still being classified as the early testing,\nsince some of the preliminary tests were carried out in the scale of the\nlaboratory. The paper would discuss the laboratory test and several tests that\nwere done in the field. Discussions were stressed in the procedure and the aim\nthat will be achieved, along with several early results. The testing was\ncarried out in the lake with the area around 8300 Ha and the maximum depth of\n50 meters. The location of the testing was chosen with consideration of\nminimizing the effect of the current and the wave, as well as the location that\nwas not too far from the Laboratory. The type of testing that will be discussed\nin paper was Heading Lock Maneuver Testing. The vehicle was tested to move with\na certain cruising speed, afterwards it was commanded by an arbitrarily\nselected heading direction. The response and the behavior of the vehicle were\nrecorded as the data produced by the testing.",
    "published": "2008-04-24T10:25:41Z",
    "link": "http://arxiv.org/pdf/0804.3885v1.pdf",
    "category": [
      "cs.RO",
      "B.6.2"
    ],
    "authors": [
      "K. Muljowidodo",
      "N. Sapto Adi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.3891v1",
    "title": "Development of Architectures for Internet Telerobotics Systems",
    "summary": "This paper presents our experience in developing and implementing Internet\ntelerobotics system. Internet telerobotics system refers to a robot system\ncontrolled and monitored remotely through the Internet. A robot manipulator\nwith five degrees of freedom, called Mentor, is employed. Client-server\narchitecture is chosen as a platform for our Internet telerobotics system.\nThree generations of telerobotics systems have evolved in this research. The\nfirst generation was based on CGI and two tiered architecture, where a client\npresents a Graphical User Interface to the user, and utilizes the user's data\nentry and actions to perform requests to robot server running on a different\nmachine. The second generation was developed using Java. We also employ Java 3D\nfor creating and manipulating 3D geometry of manipulator links and for\nconstructing the structures used in rendering that geometry, resulting in 3D\nrobot movement simulation presented to the users(clients) through their web\nbrowser. Recent development in our Internet telerobotics includes object\nrecognition through image captured by a camera, which poses challenging\nproblem, given the undeterministic latency of the Internet. The third\ngeneration is centered around the use of CORBA for development platform of\ndistributed internet telerobotics system, aimed at distributing task of\ntelerobotics system.",
    "published": "2008-04-24T10:43:46Z",
    "link": "http://arxiv.org/pdf/0804.3891v1.pdf",
    "category": [
      "cs.RO",
      "I.5.5"
    ],
    "authors": [
      "Riyanto Bambang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.3894v1",
    "title": "Unmanned Aerial Vehicle Instrumentation for Rapid Aerial Photo System",
    "summary": "This research will proposed a new kind of relatively low cost autonomous UAV\nthat will enable farmers to make just in time mosaics of aerial photo of their\ncrop. These mosaics of aerial photo should be able to be produced with\nrelatively low cost and within the 24 hours of acquisition constraint. The\nautonomous UAV will be equipped with payload management system specifically\ndeveloped for rapid aerial mapping. As mentioned before turn around time is the\nkey factor, so accuracy is not the main focus (not orthorectified aerial\nmapping). This system will also be equipped with special software to post\nprocess the aerial photos to produce the mosaic aerial photo map",
    "published": "2008-04-24T10:48:13Z",
    "link": "http://arxiv.org/pdf/0804.3894v1.pdf",
    "category": [
      "cs.RO",
      "B.7.2"
    ],
    "authors": [
      "Widyawardana Adiprawita",
      "Adang Suwandi Ahmad",
      "Jaka Semibiring"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.3895v1",
    "title": "First Principle Approach to Modeling of Small Scale Helicopter",
    "summary": "The establishment of global helicopter linear model is very precious and\nuseful for the design of the linear control laws, since it is never afforded in\nthe published literatures. In the first principle approach, the mathematical\nmodel was developed using basic helicopter theory accounting for particular\ncharacteristic of the miniature helicopter. No formal system identification\nprocedures are required for the proposed model structure. The relevant\npublished literatures however did not present the linear models required for\nthe design of linear control laws. The paper presents a step by step\ndevelopment of linear model for small scale helicopter based on first-principle\napproach. Beyond the previous work in literatures, the calculation of the\nstability derivatives is presented in detail. A computer program is used to\nsolve the equilibrium conditions and then calculate the change in aerodynamics\nforces and moments due to the change in each degree of freedom and control\ninput. The detail derivation allows the comprehensive analysis of relative\ndominance of vehicle states and input variables to force and moment components.\nHence it facilitates the development of minimum complexity small scale\nhelicopter dynamics model.",
    "published": "2008-04-24T10:52:30Z",
    "link": "http://arxiv.org/pdf/0804.3895v1.pdf",
    "category": [
      "cs.RO",
      "I.6.1"
    ],
    "authors": [
      "A. Budiyono",
      "T. Sudiyanto",
      "H. Lesmana"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.3897v1",
    "title": "Optimal Tracking Controller Design for a Small Scale Helicopter",
    "summary": "A model helicopter is more difficult to control than its full scale\ncounterparts. This is due to its greater sensitivity to control inputs and\ndisturbances as well as higher bandwidth of dynamics. This works is focused on\ndesigning practical tracking controller for a small scale helicopter following\npredefined trajectories. A tracking controller based on optimal control theory\nis synthesized as part of the development of an autonomous helicopter. Some\nissues in regards to control constraints are addressed. The weighting between\nstate tracking performance and control power expenditure is analyzed. Overall\nperformance of the control design is evaluated based on its time domain\nhistories of trajectories as well as control inputs.",
    "published": "2008-04-24T10:58:35Z",
    "link": "http://arxiv.org/pdf/0804.3897v1.pdf",
    "category": [
      "cs.RO",
      "C.3"
    ],
    "authors": [
      "Agus Budiyono",
      "Singgih S. Wibowo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.4395v1",
    "title": "Development of a peristaltic micropump for bio-medical applications\n  based on mini LIPCA",
    "summary": "This paper presents the design, fabrication, and experimental\ncharacterization of a peristaltic micropump. The micropump is composed of two\nlayers fabricated from polydimethylsiloxane (PDMS) material. The first layer\nhas a rectangular channel and two valve seals. Three rectangular mini\nlightweight piezo-composite actuators are integrated in the second layer, and\nused as actuation parts. Two layers are bonded, and covered by two polymethyl\nmethacrylate (PMMA) plates, which help increase the stiffness of the micropump.\nA maximum flow rate of 900 mokroliter per min and a maximum backpressure of 1.8\nkPa are recorded when water is used as pump liquid. We measured the power\nconsumption of the micropump. The micropump is found to be a promising\ncandidate for bio-medical application due to its bio-compatibility,\nportability, bidirectionality, and simple effective design.",
    "published": "2008-04-28T12:59:55Z",
    "link": "http://arxiv.org/pdf/0804.4395v1.pdf",
    "category": [
      "cs.RO",
      "B.1.2"
    ],
    "authors": [
      "My Pham",
      "Thanh Tung Nguyen",
      "Nam Seo Goo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.4717v1",
    "title": "Intelligent Unmanned Explorer for Deep Space Exploration",
    "summary": "asteroids or comets have received remarkable attention in the world. In small\nbody explorations, especially, detailed in-situ surface exploration by tiny\nrover is one of effective and fruitful means and is expected to make strong\ncontributions towards scientific studies. JAXA ISAS is promoting MUSES C\nmission, which is the worlds first sample and return attempt to or from the\nnear earth asteroid. Hayabusa spacecraft in MUSES C mission took the tiny\nrover, which was expected to perform the in-situ surface exploration by\nhopping. This paper describes the system design, mobility and intelligence of\nthe developed unmanned explorer. This paper also presents the ground\nexperimental results and the flight results.",
    "published": "2008-04-30T01:18:37Z",
    "link": "http://arxiv.org/pdf/0804.4717v1.pdf",
    "category": [
      "cs.RO",
      "I.6.1"
    ],
    "authors": [
      "T. Kubota",
      "T. Yoshimitsu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.4749v1",
    "title": "Study of improving nano-contouring performance by employing\n  cross-coupling controller",
    "summary": "For the tracking stage path planning, we design a two-axis cross-coupling\ncontrol system which uses the PI controller to compensate the contour error\nbetween axes. In this paper, the stage adoptive is designed by our laboratory\n(Precision Machine Center of National Formosa University). The cross-coupling\ncontroller calculates the actuating signal of each axis by combining multi-axes\nposition error. Hence, the cross-coupling controller improves the stage\ntracking ability and decreases the contour error. The experiments show\nexcellent stage motion. This finding confirms that the proposed method is a\npowerful and efficient tool for improving stage tracking ability. Also found\nwere the stages tracking to minimize contour error of two types circular to\napproximately 25nm.",
    "published": "2008-04-30T07:57:25Z",
    "link": "http://arxiv.org/pdf/0804.4749v1.pdf",
    "category": [
      "cs.RO",
      "B.1.2"
    ],
    "authors": [
      "Wen Yuh Jywe",
      "Shih Shin Chen",
      "Hung-Shu Wang",
      "Chien Hung Liu",
      "Hsin Hung Jwo",
      "Yun Feng Teng",
      "Tung Hsien Hsieh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.4750v1",
    "title": "The Numerical Control Design for a Pair of Dubins Vehicles",
    "summary": "In this paper, a model of a pair of Dubins vehicles is considered. The\nvehicles move from an initial position and orientation to final position and\norientation. A long the motion, the two vehicles are not allowed to collide\nhowever the two vehicles cant to far each other. The optimal control of the\nvehicle is found using the Pontryagins Maximum Principle (PMP). This PMP leads\nto a Hamiltonian system consisting of a system of differential equation and its\nadjoint. The originally differential equation has initial and final condition\nbut the adjoint system doesn't have one. The classical difficulty is solved\nnumerically by the greatest gradient descent method. Some simulation results\nare presented in this paper.",
    "published": "2008-04-30T08:03:05Z",
    "link": "http://arxiv.org/pdf/0804.4750v1.pdf",
    "category": [
      "cs.RO",
      "I.2.8"
    ],
    "authors": [
      "Heru Tjahjana",
      "Iwan Pranoto",
      "Hari Muhammad",
      "J. Naiborhu",
      " Miswanto"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.4752v1",
    "title": "Simulation of Dynamic Yaw Stability Derivatives of a Bird Using CFD",
    "summary": "Simulation results on dynamic yaw stability derivatives of a gull bird by\nmeans of computational fluid dynamics are presented. Two different kinds of\nmotions are used for determining the dynamic yaw stability derivatives CNr and\nCNbeta . Concerning the first one, simple lateral translation and yaw rotary\nmotions in yaw are considered. The second one consists of combined motions. To\ndetermine dynamic yaw stability derivatives of the bird, the simulation of an\nunsteady flow with a bird model showing a harmonic motion is performed. The\nunsteady flow solution for each time step is obtained by solving unsteady Euler\nequations based on a finite volume approach for a smaller reduced frequency.\nThen, an evaluation of unsteady forces and moments for one cycle is conducted\nusing harmonic Fourier analysis. The results on the dynamic yaw stability\nderivatives for both simulations of the model motion show a good agreement.",
    "published": "2008-04-30T08:16:33Z",
    "link": "http://arxiv.org/pdf/0804.4752v1.pdf",
    "category": [
      "cs.RO",
      "I.2.9"
    ],
    "authors": [
      "M. A. Moelyadi",
      "G. Sachs"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.4753v1",
    "title": "Wavelet Based Iterative Learning Control with Fuzzy PD Feedback for\n  Position Tracking of A Pneumatic Servo System",
    "summary": "In this paper, a wavelet-based iterative learning control (WILC) scheme with\nFuzzy PD feedback is presented for a pneumatic control system with nonsmooth\nnonlinearities and uncertain parameters. The wavelet transform is employed to\nextract the learnable dynamics from measured output signal before it can be\nused to update the control profile. The wavelet transform is adopted to\ndecompose the original signal into many low-resolution signals that contain the\nlearnable and unlearnable parts. The desired control profile is then compared\nwith the learnable part of the transformed signal. Thus, the effects from\nunlearnable dynamics on the controlled system can be attenuated by a Fuzzy PD\nfeedback controller. As for the rules of Fuzzy PD controller in the feedback\nloop, a genetic algorithm (GA) is employed to search for the inference rules of\noptimization. A proportional-valve controlled pneumatic cylinder actuator\nsystem is used as the control target for simulation. Simulation results have\nshown a much-improved positiontracking performance.",
    "published": "2008-04-30T08:22:19Z",
    "link": "http://arxiv.org/pdf/0804.4753v1.pdf",
    "category": [
      "cs.RO",
      "I.2.6"
    ],
    "authors": [
      "C. E. Huang",
      "J. S. Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.4754v1",
    "title": "Positive Real Synthesis of Networked Control System An LMI Approach",
    "summary": "This paper presents the positive real analysis and synthesis for Networked\nControl Systems (NCS) in discrete time. Based on the definition of passivity,\nthe sufficient condition of NCS is given by stochastic Lyapunov functional. The\ncontroller via state feedback is designed to guarantee the stability of NCS and\nclosed-loop positive realness. It is shown that a mode-dependent positive real\ncontroller exists if a set of coupled linear matrix inequalities has solutions.\nThe controller can be then constructed in terms of the solutions.",
    "published": "2008-04-30T08:25:46Z",
    "link": "http://arxiv.org/pdf/0804.4754v1.pdf",
    "category": [
      "cs.RO",
      "I.2.8"
    ],
    "authors": [
      "Bambang Riyanto",
      "Imam Arifin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.4757v1",
    "title": "Analysis of Stability, Response and LQR Controller Design of a Small\n  Scale Helicopter Dynamics",
    "summary": "This paper presents how to use feedback controller with helicopter dynamics\nstate space model. A simplified analysis is presented for controller design\nusing LQR of small scale helicopters for axial and forward flights. Our\napproach is simple and gives the basic understanding about how to develop\ncontroller for solving the stability of linear helicopter flight dynamics.",
    "published": "2008-04-30T08:32:27Z",
    "link": "http://arxiv.org/pdf/0804.4757v1.pdf",
    "category": [
      "cs.RO",
      "I.2.8"
    ],
    "authors": [
      "Hardian Reza Dharmayanda",
      "Taesam Kang",
      "Young Jae Lee",
      "Sangkyung Sung"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0804.4759v1",
    "title": "Design and control of dynamical quantum processes in ortho para H2\n  conversion on surfaces",
    "summary": "We present here a novel, cost-effective method for increasing and controlling\nthe ortho para H2 (o p H2) conversion yield. First, we invoke two processes\nderived from fundamental, surface science insights, based on the effect of\nmolecular orientation on the hydrogen solid surface reaction, i.e., dynamical\nquantum filtering and steering, and apply them to enhance the o p H2 conversion\nyield. Second, we find an important factor that can significantly influence the\nyield i.e., inhomogeneity of spin density distribution. This factor gives us a\npromising possibility to increase the yield and to find the best catalyst e.g.,\ndesign of materials that can function as catalysts for the o p H2 conversion.",
    "published": "2008-04-30T08:38:19Z",
    "link": "http://arxiv.org/pdf/0804.4759v1.pdf",
    "category": [
      "cs.RO",
      "I.2.8"
    ],
    "authors": [
      "Rifki Muhida",
      "Riza Muhida",
      "Wilson A. Dino",
      "Hiroshi Nakanishi",
      "Hideaki Kasai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0805.3390v1",
    "title": "Design of Attitude Stability System for Prolate Dual-spin Satellite in\n  Its Inclined Elliptical Orbit",
    "summary": "In general, most of communication satellites were designed to be operated in\ngeostationary orbit. And many of them were designed in prolate dual-spin\nconfiguration. As a prolate dual-spin vehicle, they have to be stabilized\nagainst their internal energy dissipation effect. Several countries that\nlocated in southern hemisphere, has shown interest to use communication\nsatellite. Because of those countries southern latitude, an idea emerged to\nincline the communication satellite (due to its prolate dualspin configuration)\nin elliptical orbit. This work is focused on designing Attitude Stability\nSystem for prolate dual-spin satellite in the effect of perturbed field of\ngravity due to the inclination of its elliptical orbit. DANDE (De-spin Active\nNutation Damping Electronics) provides primary stabilization method for the\nsatellite in its orbit. Classical Control Approach is used for the iteration of\nDANDE parameters. The control performance is evaluated based on time response\nanalysis.",
    "published": "2008-05-22T06:17:57Z",
    "link": "http://arxiv.org/pdf/0805.3390v1.pdf",
    "category": [
      "cs.RO",
      "I.2.9"
    ],
    "authors": [
      "J. Muliadi",
      "S. D. Jenie",
      "A. Budiyono"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0806.0473v1",
    "title": "Kinematic Analysis of the vertebra of an eel like robot",
    "summary": "The kinematic analysis of a spherical wrist with parallel architecture is the\nobject of this article. This study is part of a larger French project, which\naims to design and to build an eel like robot to imitate the eel swimming. To\nimplement direct and inverse kinematics on the control law of the prototype, we\nneed to evaluate the workspace without any collisions between the different\nbodies. The tilt and torsion parameters are used to represent the workspace.",
    "published": "2008-06-03T09:33:53Z",
    "link": "http://arxiv.org/pdf/0806.0473v1.pdf",
    "category": [
      "cs.RO",
      "physics.class-ph"
    ],
    "authors": [
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0806.0740v1",
    "title": "Modeling And Simulation Of Prolate Dual-Spin Satellite Dynamics In An\n  Inclined Elliptical Orbit: Case Study Of Palapa B2R Satellite",
    "summary": "In response to the interest to re-use Palapa B2R satellite nearing its End of\nLife (EOL) time, an idea to incline the satellite orbit in order to cover a new\nregion has emerged in the recent years. As a prolate dual-spin vehicle, Palapa\nB2R has to be stabilized against its internal energy dissipation effect. This\nwork is focused on analyzing the dynamics of the reusable satellite in its\ninclined orbit. The study discusses in particular the stability of the prolate\ndual-spin satellite under the effect of perturbed field of gravitation due to\nthe inclination of its elliptical orbit. Palapa B2R physical data was\nsubstituted into the dual-spin's equation of motion. The coefficient of zonal\nharmonics J2 was induced into the gravity-gradient moment term that affects the\nsatellite attitude. The satellite's motion and attitude were then simulated in\nthe perturbed gravitational field by J2, with the variation of orbit's\neccentricity and inclination. The analysis of the satellite dynamics and its\nstability was conducted for designing a control system for the vehicle in its\nnew inclined orbit.",
    "published": "2008-06-04T10:33:07Z",
    "link": "http://arxiv.org/pdf/0806.0740v1.pdf",
    "category": [
      "cs.RO",
      "I.2.9"
    ],
    "authors": [
      "J. Muliadi",
      "S. D. Jenie",
      "A. Budiyono"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0806.0743v1",
    "title": "Onboard Multivariable Controller Design for a Small Scale Helicopter\n  Using Coefficient Diagram Method",
    "summary": "A mini scale helicopter exhibits not only increased sensitivity to control\ninputs and disturbances, but also higher bandwidth of its dynamics. These\nproperties make model helicopters, as a flying robot, more difficult to\ncontrol. The dynamics model accuracy will determine the performance of the\ndesigned controller. It is attractive in this regards to have a controller that\ncan accommodate the unmodeled dynamics or parameter changes and perform well in\nsuch situations. Coefficient Diagram Method (CDM) is chosen as the candidate to\nsynthesize such a controller due to its simplicity and convenience in\ndemonstrating integrated performance measures including equivalent time\nconstant, stability indices and robustness. In this study, CDM is implemented\nfor a design of multivariable controller for a small scale helicopter during\nhover and cruise flight. In the synthesis of MIMO CDM, good design common sense\nbased on hands-on experience is necessary. The low level controller algorithm\nis designed as part of hybrid supervisory control architecture to be\nimplemented on an onboard computer system. Its feasibility and performance are\nevaluated based on its robustness, desired time domain system responses and\ncompliance to hard-real time requirements.",
    "published": "2008-06-04T10:45:49Z",
    "link": "http://arxiv.org/pdf/0806.0743v1.pdf",
    "category": [
      "cs.RO",
      "I.2.9"
    ],
    "authors": [
      "A. Budiyono"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0806.4020v1",
    "title": "Design, Development and Testing of Underwater Vehicles: ITB Experience",
    "summary": "The last decade has witnessed increasing worldwide interest in the research\nof underwater robotics with particular focus on the area of autonomous\nunderwater vehicles (AUVs). The underwater robotics technology has enabled\nhuman to access the depth of the ocean to conduct environmental surveys,\nresources mapping as well as scientific and military missions. This capability\nis especially valuable for countries with major water or oceanic resources. As\nan archipelagic nation with more than 13,000 islands, Indonesia has one of the\nmost abundant living and non-organic oceanic resources. The needs for the\nmapping, exploration, and environmental preservation of the vast marine\nresources are therefore imperative. The challenge of the deep water exploration\nhas been the complex issues associated with hazardous and unstructured undersea\nand sea-bed environments. The paper reports the design, development and testing\nefforts of underwater vehicle that have been conducted at Institut Teknologi\nBandung. Key technology areas have been identified and step-by-step development\nis presented in conjunction with the need to meet the challenge of underwater\nvehicle operation. A number of future research directions are also highlighted.",
    "published": "2008-06-25T03:56:40Z",
    "link": "http://arxiv.org/pdf/0806.4020v1.pdf",
    "category": [
      "cs.RO",
      "I.2.9"
    ],
    "authors": [
      " Muljowidodo",
      "Said D. Jenie",
      "Agus Budiyono",
      "Sapto A. Nugroho"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0806.4021v1",
    "title": "Linear Parameter Varying Model Identification for Control of\n  Rotorcraft-based UAV",
    "summary": "A rotorcraft-based unmanned aerial vehicle exhibits more complex properties\ncompared to its full-size counterparts due to its increased sensitivity to\ncontrol inputs and disturbances and higher bandwidth of its dynamics. As an\naerial vehicle with vertical take-off and landing capability, the helicopter\nspecifically poses a difficult problem of transition between forward flight and\nunstable hover and vice versa. The LPV control technique explicitly takes into\naccount the change in performance due to the real-time parameter variations.\nThe technique therefore theoretically guarantees the performance and robustness\nover the entire operating envelope. In this study, we investigate a new\napproach implementing model identification for use in the LPV control\nframework. The identification scheme employs recursive least square technique\nimplemented on the LPV system represented by dynamics of helicopter during a\ntransition. The airspeed as the scheduling of parameter trajectory is not\nassumed to vary slowly. The exclusion of slow parameter change requirement\nallows for the application of the algorithm for aggressive maneuvering\ncapability without the need of expensive computation. The technique is tested\nnumerically and will be validated in the autonomous flight of a small scale\nhelicopter.",
    "published": "2008-06-25T04:09:29Z",
    "link": "http://arxiv.org/pdf/0806.4021v1.pdf",
    "category": [
      "cs.RO",
      "I.2.9"
    ],
    "authors": [
      "Agus Budiyono",
      "H. Y Sutarto"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0806.4648v1",
    "title": "An Algebraic Approach for the MIMO Control of Small Scale Helicopter",
    "summary": "The control of small-scale helicopter is a MIMO problem. To use of classical\ncontrol approach to formally solve a MIMO problem, one needs to come up with\nmultidimensional Root Locus diagram to tune the control parameters. The problem\nwith the required dimension of the RL diagram for MIMO design has forced the\ndesign procedure of classical approach to be conducted in cascaded multi-loop\nSISO system starting from the innermost loop outward. To implement this control\napproach for a helicopter, a pitch and roll attitude control system is often\nsubordinated to a, respectively, longitudinal and lateral velocity control\nsystem in a nested architecture. The requirement for this technique to work is\nthat the inner attitude control loop must have a higher bandwidth than the\nouter velocity control loop which is not the case for high performance mini\nhelicopter. To address the above problems, an algebraic design approach is\nproposed in this work. The designed control using s-CDM approach is\ndemonstrated for hovering control of small-scale helicopter simultaneously\nsubjected to plant parameter uncertainties and wind disturbances.",
    "published": "2008-06-28T04:36:03Z",
    "link": "http://arxiv.org/pdf/0806.4648v1.pdf",
    "category": [
      "cs.RO",
      "I.2.8"
    ],
    "authors": [
      "A. Budiyono",
      "T. Sudiyanto"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0807.2358v2",
    "title": "Polygon Exploration with Time-Discrete Vision",
    "summary": "With the advent of autonomous robots with two- and three-dimensional scanning\ncapabilities, classical visibility-based exploration methods from computational\ngeometry have gained in practical importance. However, real-life laser scanning\nof useful accuracy does not allow the robot to scan continuously while in\nmotion; instead, it has to stop each time it surveys its environment. This\nrequirement was studied by Fekete, Klein and Nuechter for the subproblem of\nlooking around a corner, but until now has not been considered in an online\nsetting for whole polygonal regions.\n  We give the first algorithmic results for this important algorithmic problem\nthat combines stationary art gallery-type aspects with watchman-type issues in\nan online scenario: We demonstrate that even for orthoconvex polygons, a\ncompetitive strategy can be achieved only for limited aspect ratio A (the ratio\nof the maximum and minimum edge length of the polygon), i.e., for a given lower\nbound on the size of an edge; we give a matching upper bound by providing an\nO(log A)-competitive strategy for simple rectilinear polygons, using the\nassumption that each edge of the polygon has to be fully visible from some scan\npoint.",
    "published": "2008-07-15T12:10:08Z",
    "link": "http://arxiv.org/pdf/0807.2358v2.pdf",
    "category": [
      "cs.CG",
      "cs.RO",
      "F.2.2; I.2.9"
    ],
    "authors": [
      "Sandor P. Fekete",
      "Christiane Schmidt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0807.2648v2",
    "title": "On Endogenous Reconfiguration in Mobile Robotic Networks",
    "summary": "In this paper, our focus is on certain applications for mobile robotic\nnetworks, where reconfiguration is driven by factors intrinsic to the network\nrather than changes in the external environment. In particular, we study a\nversion of the coverage problem useful for surveillance applications, where the\nobjective is to position the robots in order to minimize the average distance\nfrom a random point in a given environment to the closest robot. This problem\nhas been well-studied for omni-directional robots and it is shown that optimal\nconfiguration for the network is a centroidal Voronoi configuration and that\nthe coverage cost belongs to $\\Theta(m^{-1/2})$, where $m$ is the number of\nrobots in the network. In this paper, we study this problem for more realistic\nmodels of robots, namely the double integrator (DI) model and the differential\ndrive (DD) model. We observe that the introduction of these motion constraints\nin the algorithm design problem gives rise to an interesting behavior. For a\n\\emph{sparser} network, the optimal algorithm for these models of robots mimics\nthat for omni-directional robots. We propose novel algorithms whose\nperformances are within a constant factor of the optimal asymptotically (i.e.,\nas $m \\to +\\infty$). In particular, we prove that the coverage cost for the DI\nand DD models of robots is of order $m^{-1/3}$. Additionally, we show that, as\nthe network grows, these novel algorithms outperform the conventional\nalgorithm; hence necessitating a reconfiguration in the network in order to\nmaintain optimal quality of service.",
    "published": "2008-07-16T20:09:18Z",
    "link": "http://arxiv.org/pdf/0807.2648v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Ketan Savla",
      "Emilio Frazzoli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0807.3223v2",
    "title": "The NAO humanoid: a combination of performance and affordability",
    "summary": "This article presents the design of the autonomous humanoid robot called NAO\nthat is built by the French company Aldebaran-Robotics. With its height of 0.57\nm and its weight about 4.5 kg, this innovative robot is lightweight and\ncompact. It distinguishes itself from its existing Japanese, American, and\nother counterparts thanks to its pelvis kinematics design, its proprietary\nactuation system based on brush DC motors, its electronic, computer and\ndistributed software architectures. This robot has been designed to be\naffordable without sacrificing quality and performance. It is an open and\neasy-to-handle platform where the user can change all the embedded system\nsoftware or just add some applications to make the robot adopt specific\nbehaviours. The robot's head and forearms are modular and can be changed to\npromote further evolution. The comprehensive and functional design is one of\nthe reasons that helped select NAO to replace the AIBO quadrupeds in the 2008\nRoboCup standard league.",
    "published": "2008-07-21T09:28:09Z",
    "link": "http://arxiv.org/pdf/0807.3223v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "David Gouaillier",
      "Vincent Hugel",
      "Pierre Blazevic",
      "Chris Kilner",
      "Jerome Monceaux",
      "Pascal Lafourcade",
      "Brice Marnier",
      "Julien Serre",
      "Bruno Maisonnier"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0807.3225v3",
    "title": "Exploiting Bird Locomotion Kinematics Data for Robotics Modeling",
    "summary": "We present here the results of an analysis carried out by biologists and\nroboticists with the aim of modeling bird locomotion kinematics for robotics\npurposes. The aim was to develop a bio-inspired kinematic model of the bird leg\nfrom biological data. We first acquired and processed kinematic data for\nsagittal and top views obtained by X-ray radiography of quails walking. Data\nprocessing involved filtering and specific data reconstruction in three\ndimensions, as two-dimensional views cannot be synchronized. We then designed a\nrobotic model of a bird-like leg based on a kinematic analysis of the\nbiological data. Angular velocity vectors were calculated to define the number\nof degrees of freedom (DOF) at each joint and the orientation of the rotation\naxes.",
    "published": "2008-07-21T09:37:48Z",
    "link": "http://arxiv.org/pdf/0807.3225v3.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Vincent Hugel",
      "Remi Hackert",
      "Anick Abourachid"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0807.4345v1",
    "title": "Avoider robot design to dim the fire with dt basic mini system",
    "summary": "Avoider robot is mean robot who is designed to avoid the block in around.\nExcept that, this robot is also added by an addition application to dim the\nfire. This robot is made with ultrasonic sensor PING. This sensor is set on the\nfront, right and left from robot. This sensor is used robot to look for the\nright street, so that robot can walk on. After the robot can look for the right\nstreet, next accomplished the robot is looking for the fire in around. And the\nnext, dim the fire with fan. This robot is made with basic stamp 2\nmicro-controller. And that micro-controller can be found in dt-basic mini\nsystem module. This robot is made with servo motor on the right and left side,\nwhich is used to movement.",
    "published": "2008-07-28T02:46:45Z",
    "link": "http://arxiv.org/pdf/0807.4345v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Eri Prasetyo",
      "Wahyu K. R.",
      "Bumi Prabu Prabowo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0808.1247v1",
    "title": "Self-Motions of General 3-RPR Planar Parallel Robots",
    "summary": "This paper studies the kinematic geometry of general 3-RPR planar parallel\nrobots with actuated base joints. These robots, while largely overlooked, have\nsimple direct kinematics and large singularity-free workspace. Furthermore,\ntheir kinematic geometry is the same as that of a newly developed parallel\nrobot with SCARA-type motions. Starting from the direct and inverse kinematic\nmodel, the expressions for the singularity loci of 3-RPR planar parallel robots\nare determined. Then, the global behaviour at all singularities is\ngeometrically described by studying the degeneracy of the direct kinematic\nmodel. Special cases of self-motions are then examined and the degree of\nfreedom gained in such special configurations is kinematically interpreted.\nFinally, a practical example is discussed and experimental validations\nperformed on an actual robot prototype are presented.",
    "published": "2008-08-08T17:17:23Z",
    "link": "http://arxiv.org/pdf/0808.1247v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Sbastien Briot",
      "Ilian Bonev",
      "Damien Chablat",
      "Philippe Wenger",
      "Vigen Arakelian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0808.1661v1",
    "title": "Medical robotics: where we come from, where we are and where we could go",
    "summary": "This short note presents a viewpoint about medical robotics.",
    "published": "2008-08-12T13:21:52Z",
    "link": "http://arxiv.org/pdf/0808.1661v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Jocelyne Troccaz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0808.2931v1",
    "title": "Spatial planning with constraints on translational distances between\n  geometric objects",
    "summary": "The main constraint on relative position of geometric objects, used in\nspatial planning for computing the C-space maps (for example, in robotics, CAD,\nand packaging), is the relative non-overlapping of objects. This is the\nsimplest constraint in which the minimum translational distance between objects\nis greater than zero, or more generally, than some positive value. We present a\ntechnique, based on the Minkowski operations, for generating the translational\nC-space maps for spatial planning with more general and more complex\nconstraints on the relative position of geometric objects, such as constraints\non various types (not only on the minimum) of the translational distances\nbetween objects. The developed technique can also be used, respectively, for\nspatial planning with constraints on translational distances in a given\ndirection, and rotational distances between geometric objects, as well as for\nspatial planning with given dynamic geometric situation of moving objects.",
    "published": "2008-08-21T14:00:36Z",
    "link": "http://arxiv.org/pdf/0808.2931v1.pdf",
    "category": [
      "cs.CG",
      "cs.RO"
    ],
    "authors": [
      "Gennady Pustylnik"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0809.0727v1",
    "title": "Microcontroller-based System for Modular Networked Robot",
    "summary": "A prototype of modular networked robot for autonomous monitoring works with\nfull control over web through wireless connection has been developed. The robot\nis equipped with a particular set of built-in analyzing tools and appropriate\ncensors, depending on its main purposes, to enable self-independent and\nreal-time data acquisition and processing. The paper is focused on the\nmicrocontroller-based system to realize the modularity. The whole system is\ndivided into three modules : main unit, data acquisition and data processing,\nwhile the analyzed results and all aspects of control and monitoring systems\nare fully accessible over an integrated web-interface. This concept leads to\nsome unique features : enhancing flexibility due to enabling partial\nreplacement of the modules according to user needs, easy access over web for\nremote users, and low development and maintenance cost due to software\ndominated components.",
    "published": "2008-09-04T00:13:11Z",
    "link": "http://arxiv.org/pdf/0809.0727v1.pdf",
    "category": [
      "cs.RO",
      "cs.CY"
    ],
    "authors": [
      "I. Firmansyah",
      "Z. Akbar",
      "B. Hermanto",
      "L. T. Handoko"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0809.3044v1",
    "title": "Kinetostatic Performance of a Planar Parallel Mechanism with Variable\n  Actuation",
    "summary": "This paper deals with a new planar parallel mechanism with variable actuation\nand its kinetostatic performance. A drawback of parallel mechanisms is the non\nhomogeneity of kinetostatic performance within their workspace. The common\napproach to solve this problem is the introduction of actuation redundancy,\nthat involves force control algorithms. Another approach, highlighted in this\npaper, is to select the actuated joint in each limb with regard to the pose of\nthe end-effector. First, the architecture of the mechanism and two kinetostatic\nperformance indices are described. Then, the actuating modes of the mechanism\nare compared.",
    "published": "2008-09-18T14:13:40Z",
    "link": "http://arxiv.org/pdf/0809.3044v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Novona Rakotomanga",
      "Damien Chablat",
      "Stphane Caro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0809.3179v1",
    "title": "Kinematic and Dynamic Analyses of the Orthoglide 5-axis",
    "summary": "This paper deals with the kinematic and dynamic analyses of the Orthoglide\n5-axis, a five-degree-of-freedom manipulator. It is derived from two\nmanipulators: i) the Orthoglide 3-axis; a three dof translational manipulator\nand ii) the Agile eye; a parallel spherical wrist. First, the kinematic and\ndynamic models of the Orthoglide 5-axis are developed. The geometric and\ninertial parameters of the manipulator are determined by means of a CAD\nsoftware. Then, the required motors performances are evaluated for some test\ntrajectories. Finally, the motors are selected in the catalogue from the\nprevious results.",
    "published": "2008-09-18T15:11:50Z",
    "link": "http://arxiv.org/pdf/0809.3179v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Raza Ur-Rehman",
      "Stphane Caro",
      "Damien Chablat",
      "Philippe Wenger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0809.3180v1",
    "title": "Singularity Analysis of Limited-dof Parallel Manipulators using\n  Grassmann-Cayley Algebra",
    "summary": "This paper characterizes geometrically the singularities of limited DOF\nparallel manipulators. The geometric conditions associated with the dependency\nof six Pl\\\"ucker vector of lines (finite and infinite) constituting the rows of\nthe inverse Jacobian matrix are formulated using Grassmann-Cayley algebra.\nManipulators under consideration do not need to have a passive spherical joint\nsomewhere in each leg. This study is illustrated with three example robots",
    "published": "2008-09-18T15:14:20Z",
    "link": "http://arxiv.org/pdf/0809.3180v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Daniel Kanaan",
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0809.3181v1",
    "title": "Framework for Dynamic Evaluation of Muscle Fatigue in Manual Handling\n  Work",
    "summary": "Muscle fatigue is defined as the point at which the muscle is no longer able\nto sustain the required force or work output level. The overexertion of muscle\nforce and muscle fatigue can induce acute pain and chronic pain in human body.\nWhen muscle fatigue is accumulated, the functional disability can be resulted\nas musculoskeletal disorders (MSD). There are several posture exposure analysis\nmethods useful for rating the MSD risks, but they are mainly based on static\npostures. Even in some fatigue evaluation methods, muscle fatigue evaluation is\nonly available for static postures, but not suitable for dynamic working\nprocess. Meanwhile, some existing muscle fatigue models based on physiological\nmodels cannot be easily used in industrial ergonomic evaluations. The external\ndynamic load is definitely the most important factor resulting muscle fatigue,\nthus we propose a new fatigue model under a framework for evaluating fatigue in\ndynamic working processes. Under this framework, virtual reality system is\ntaken to generate virtual working environment, which can be interacted with the\nwork with haptic interfaces and optical motion capture system. The motion\ninformation and load information are collected and further processed to\nevaluate the overall work load of the worker based on dynamic muscle fatigue\nmodels and other work evaluation criterions and to give new information to\ncharacterize the penibility of the task in design process.",
    "published": "2008-09-18T15:15:58Z",
    "link": "http://arxiv.org/pdf/0809.3181v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Liang Ma",
      "Fouad Bennis",
      "Damien Chablat",
      "Wei Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0809.3182v1",
    "title": "SINGULAB - A Graphical user Interface for the Singularity Analysis of\n  Parallel Robots based on Grassmann-Cayley Algebra",
    "summary": "This paper presents SinguLab, a graphical user interface for the singularity\nanalysis of parallel robots. The algorithm is based on Grassmann-Cayley\nalgebra. The proposed tool is interactive and introduces the designer to the\nsingularity analysis performed by this method, showing all the stages along the\nprocedure and eventually showing the solution algebraically and graphically,\nallowing as well the singularity verification of different robot poses.",
    "published": "2008-09-18T15:19:36Z",
    "link": "http://arxiv.org/pdf/0809.3182v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Patricia Ben-Horin",
      "Moshe Shoham",
      "Stphane Caro",
      "Damien Chablat",
      "Philippe Wenger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0809.3384v1",
    "title": "Changing Assembly Modes without Passing Parallel Singularities in\n  Non-Cuspidal 3-R\\underline{P}R Planar Parallel Robots",
    "summary": "This paper demonstrates that any general 3-DOF three-legged planar parallel\nrobot with extensible legs can change assembly modes without passing through\nparallel singularities (configurations where the mobile platform loses its\nstiffness). While the results are purely theoretical, this paper questions the\nvery definition of parallel singularities.",
    "published": "2008-09-19T14:25:17Z",
    "link": "http://arxiv.org/pdf/0809.3384v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Ilian Bonev",
      "Sbastien Briot",
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0809.4784v1",
    "title": "A Computational Study on Emotions and Temperament in Multi-Agent Systems",
    "summary": "Recent advances in neurosciences and psychology have provided evidence that\naffective phenomena pervade intelligence at many levels, being inseparable from\nthe cognitionaction loop. Perception, attention, memory, learning,\ndecisionmaking, adaptation, communication and social interaction are some of\nthe aspects influenced by them. This work draws its inspirations from\nneurobiology, psychophysics and sociology to approach the problem of building\nautonomous robots capable of interacting with each other and building\nstrategies based on temperamental decision mechanism. Modelling emotions is a\nrelatively recent focus in artificial intelligence and cognitive modelling.\nSuch models can ideally inform our understanding of human behavior. We may see\nthe development of computational models of emotion as a core research focus\nthat will facilitate advances in the large array of computational systems that\nmodel, interpret or influence human behavior. We propose a model based on a\nscalable, flexible and modular approach to emotion which allows runtime\nevaluation between emotional quality and performance. The results achieved\nshowed that the strategies based on temperamental decision mechanism strongly\ninfluence the system performance and there are evident dependency between\nemotional state of the agents and their temperamental type, as well as the\ndependency between the team performance and the temperamental configuration of\nthe team members, and this enable us to conclude that the modular approach to\nemotional programming based on temperamental theory is the good choice to\ndevelop computational mind models for emotional behavioral Multi-Agent systems.",
    "published": "2008-09-27T16:33:34Z",
    "link": "http://arxiv.org/pdf/0809.4784v1.pdf",
    "category": [
      "cs.AI",
      "cs.MA",
      "cs.RO"
    ],
    "authors": [
      "Luis Paulo Reis",
      "Daria Barteneva",
      "Nuno Lau"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0810.0830v1",
    "title": "Stiffness Analysis Of Multi-Chain Parallel Robotic Systems",
    "summary": "The paper presents a new stiffness modelling method for multi-chain parallel\nrobotic manipulators with flexible links and compliant actuating joints. In\ncontrast to other works, the method involves a FEA-based link stiffness\nevaluation and employs a new solution strategy of the kinetostatic equations,\nwhich allows computing the stiffness matrix for singular postures and to take\ninto account influence of the internal forces. The advantages of the developed\ntechnique are confirmed by application examples, which deal with stiffness\nanalysis of the Orthoglide manipulator.",
    "published": "2008-10-05T15:03:22Z",
    "link": "http://arxiv.org/pdf/0810.0830v1.pdf",
    "category": [
      "cs.RO",
      "physics.class-ph"
    ],
    "authors": [
      "Anatoly Pashkevich",
      "Damien Chablat",
      "Philippe Wenger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0810.1997v2",
    "title": "Characterizing 1-Dof Henneberg-I graphs with efficient configuration\n  spaces",
    "summary": "We define and study exact, efficient representations of realization spaces of\na natural class of underconstrained 2D Euclidean Distance Constraint\nSystems(EDCS) or Frameworks based on 1-dof Henneberg-I graphs. Each\nrepresentation corresponds to a choice of parameters and yields a different\nparametrized configuration space. Our notion of efficiency is based on the\nalgebraic complexities of sampling the configuration space and of obtaining a\nrealization from the sample (parametrized) configuration. Significantly, we\ngive purely combinatorial characterizations that capture (i) the class of\ngraphs that have efficient configuration spaces and (ii) the possible choices\nof representation parameters that yield efficient configuration spaces for a\ngiven graph. Our results automatically yield an efficient algorithm for\nsampling realizations, without missing extreme or boundary realizations. In\naddition, our results formally show that our definition of efficient\nconfiguration space is robust and that our characterizations are tight. We\nchoose the class of 1-dof Henneberg-I graphs in order to take the next step in\na systematic and graded program of combinatorial characterizations of efficient\nconfiguration spaces. In particular, the results presented here are the first\ncharacterizations that go beyond graphs that have connected and convex\nconfiguration spaces.",
    "published": "2008-10-12T20:17:21Z",
    "link": "http://arxiv.org/pdf/0810.1997v2.pdf",
    "category": [
      "cs.CG",
      "cs.RO",
      "cs.SC"
    ],
    "authors": [
      "Heping Gao",
      "Meera Sitharam"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0810.2665v2",
    "title": "Path Planner for Objects, Robots and Mannequins by Multi-Agents Systems\n  or Motion Captures",
    "summary": "In order to optimise the costs and time of design of the new products while\nimproving their quality, concurrent engineering is based on the digital model\nof these products. However, in order to be able to avoid definitively physical\nmodel without loss of information, new tools must be available. Especially, a\ntool making it possible to check simply and quickly the maintainability of\ncomplex mechanical sets using the numerical model is necessary. Since one\ndecade, the MCM team of IRCCyN works on the creation of tools for the\ngeneration and the analysis of trajectories of virtual mannequins. The\nsimulation of human tasks can be carried out either by robot-like simulation or\nby simulation by motion capture. This paper presents some results on the both\ntwo methods. The first method is based on a multi-agent system and on a digital\nmock-up technology, to assess an efficient path planner for a manikin or a\nrobot for access and visibility task taking into account ergonomic constraints\nor joint limits. The human operator is integrated in the process optimisation\nto contribute to a global perception of the environment. This operator\ncooperates, in real-time, with several automatic local elementary agents. In\nthe second method, we worked with the CEA and EADS/CCR to solve the constraints\nrelated to the evolution of human virtual in its environment on the basis of\ndata resulting from motion capture system. An approach using of the virtual\nguides was developed to allow to the user the realization of precise trajectory\nin absence of force feedback.",
    "published": "2008-10-15T11:13:12Z",
    "link": "http://arxiv.org/pdf/0810.2665v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0810.2666v1",
    "title": "A Vision-based Computed Torque Control for Parallel Kinematic Machines",
    "summary": "In this paper, a novel approach for parallel kinematic machine control\nrelying on a fast exteroceptive measure is implemented and validated on the\nOrthoglide robot. This approach begins with rewriting the robot models as a\nfunction of the only end-effector pose. It is shown that such an operation\nreduces the model complexity. Then, this approach uses a classical Cartesian\nspace computed torque control with a fast exteroceptive measure, reducing the\ncontrol schemes complexity. Simulation results are given to show the expected\nperformance improvements and experiments prove the practical feasibility of the\napproach.",
    "published": "2008-10-15T11:14:15Z",
    "link": "http://arxiv.org/pdf/0810.2666v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Flavien Paccot",
      "Philippe Lemoine",
      "Nicolas Andreff",
      "Damien Chablat",
      "Philippe Martinet"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0810.3283v2",
    "title": "Quantum robot: structure, algorithms and applications",
    "summary": "This paper has been withdrawn.",
    "published": "2008-10-18T01:18:03Z",
    "link": "http://arxiv.org/pdf/0810.3283v2.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "quant-ph"
    ],
    "authors": [
      "Daoyi Dong",
      "Chunlin Chen",
      "Chenbin Zhang",
      "Zonghai Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0811.1520v1",
    "title": "Modeling Microscopic Chemical Sensors in Capillaries",
    "summary": "Nanotechnology-based microscopic robots could provide accurate in vivo\nmeasurement of chemicals in the bloodstream for detailed biological research\nand as an aid to medical treatment. Quantitative performance estimates of such\ndevices require models of how chemicals in the blood diffuse to the devices.\nThis paper models microscopic robots and red blood cells (erythrocytes) in\ncapillaries using realistic distorted cell shapes. The models evaluate two\nsensing scenarios: robots moving with the cells past a chemical source on the\nvessel wall, and robots attached to the wall for longer-term chemical\nmonitoring. Using axial symmetric geometry with realistic flow speeds and\ndiffusion coefficients, we compare detection performance with a simpler model\nthat does not include the cells. The average chemical absorption is\nquantitatively similar in both models, indicating the simpler model is an\nadequate design guide to sensor performance in capillaries. However,\ndetermining the variation in forces and absorption as cells move requires the\nfull model.",
    "published": "2008-11-10T18:04:47Z",
    "link": "http://arxiv.org/pdf/0811.1520v1.pdf",
    "category": [
      "cs.RO",
      "physics.bio-ph",
      "q-bio.TO"
    ],
    "authors": [
      "Tad Hogg"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0811.3536v1",
    "title": "Analyse de la rigidit des machines outils 3 axes d'architecture\n  parallle hyperstatique",
    "summary": "The paper presents a new stiffness modelling method for overconstrained\nparallel manipulators, which is applied to 3-d.o.f. translational mechanisms.\nIt is based on a multidimensional lumped-parameter model that replaces the link\nflexibility by localized 6-d.o.f. virtual springs. In contrast to other works,\nthe method includes a FEA-based link stiffness evaluation and employs a new\nsolution strategy of the kinetostatic equations, which allows computing the\nstiffness matrix for the overconstrained architectures and for the singular\nmanipulator postures. The advantages of the developed technique are confirmed\nby application examples, which deal with comparative stiffness analysis of two\ntranslational parallel manipulators.",
    "published": "2008-11-21T13:47:01Z",
    "link": "http://arxiv.org/pdf/0811.3536v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Anatoly Pashkevich",
      "Damien Chablat",
      "Philippe Wenger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0811.4733v1",
    "title": "Kinematic Analysis of a Serial - Parallel Machine Tool: the VERNE\n  machine",
    "summary": "The paper derives the inverse and the forward kinematic equations of a serial\n- parallel 5-axis machine tool: the VERNE machine. This machine is composed of\na three-degree-of-freedom (DOF) parallel module and a two-DOF serial tilting\ntable. The parallel module consists of a moving platform that is connected to a\nfixed base by three non-identical legs. These legs are connected in a way that\nthe combined effects of the three legs lead to an over-constrained mechanism\nwith complex motion. This motion is defined as a simultaneous combination of\nrotation and translation. In this paper we propose symbolical methods that able\nto calculate all kinematic solutions and identify the acceptable one by adding\nanalytical constraint on the disposition of legs of the parallel module.",
    "published": "2008-11-28T15:32:24Z",
    "link": "http://arxiv.org/pdf/0811.4733v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Daniel Kanaan",
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0812.0070v1",
    "title": "An Integrated Software-based Solution for Modular and Self-independent\n  Networked Robot",
    "summary": "An integrated software-based solution for a modular and self-independent\nnetworked robot is introduced. The wirelessly operatable robot has been\ndeveloped mainly for autonomous monitoring works with full control over web.\nThe integrated software solution covers three components : a) the digital\nsignal processing unit for data retrieval and monitoring system; b) the\nexternally executable codes for control system; and c) the web programming for\ninterfacing the end-users with the robot. It is argued that this integrated\nsoftware-based approach is crucial to realize a flexible, modular and low\ndevelopment cost mobile monitoring apparatus.",
    "published": "2008-11-29T12:52:54Z",
    "link": "http://arxiv.org/pdf/0812.0070v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "I. Firmansyah",
      "Z. Akbar",
      "B. Hermanto",
      "L. T. Handoko"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0812.2313v1",
    "title": "Urologic robots and future directions",
    "summary": "PURPOSE OF REVIEW: Robot-assisted laparoscopic surgery in urology has gained\nimmense popularity with the daVinci system, but a lot of research teams are\nworking on new robots. The purpose of this study is to review current urologic\nrobots and present future development directions. RECENT FINDINGS: Future\nsystems are expected to advance in two directions: improvements of remote\nmanipulation robots and developments of image-guided robots. SUMMARY: The final\ngoal of robots is to allow safer and more homogeneous outcomes with less\nvariability of surgeon performance, as well as new tools to perform tasks on\nthe basis of medical transcutaneous imaging, in a less invasive way, at lower\ncosts. It is expected that improvements for a remote system could be augmented\nin reality, with haptic feedback, size reduction, and development of new tools\nfor natural orifice translumenal endoscopic surgery. The paradigm of\nimage-guided robots is close to clinical availability and the most advanced\nrobots are presented with end-user technical assessments. It is also notable\nthat the potential of robots lies much further ahead than the accomplishments\nof the daVinci system. The integration of imaging with robotics holds a\nsubstantial promise, because this can accomplish tasks otherwise impossible.\nImage-guided robots have the potential to offer a paradigm shift.",
    "published": "2008-12-12T08:38:23Z",
    "link": "http://arxiv.org/pdf/0812.2313v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Pierre Mozer",
      "Jocelyne Troccaz",
      "Dan Stoianovici"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0812.3226v1",
    "title": "BiopSym: a simulator for enhanced learning of ultrasound-guided prostate\n  biopsy",
    "summary": "This paper describes a simulator of ultrasound-guided prostate biopsies for\ncancer diagnosis. When performing biopsy series, the clinician has to move the\nultrasound probe and to mentally integrate the real-time bi-dimensional images\ninto a three-dimensional (3D) representation of the anatomical environment.\nSuch a 3D representation is necessary to sample regularly the prostate in order\nto maximize the probability of detecting a cancer if any. To make the training\nof young physicians easier and faster we developed a simulator that combines\nimages computed from three-dimensional ultrasound recorded data to haptic\nfeedback. The paper presents the first version of this simulator.",
    "published": "2008-12-17T09:22:47Z",
    "link": "http://arxiv.org/pdf/0812.3226v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Stefano Sclaverano",
      "Grgoire Chevreau",
      "Lucile Vadcard",
      "Pierre Mozer",
      "Jocelyne Troccaz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0812.4614v2",
    "title": "I, Quantum Robot: Quantum Mind control on a Quantum Computer",
    "summary": "The logic which describes quantum robots is not orthodox quantum logic, but a\ndeductive calculus which reproduces the quantum tasks (computational processes,\nand actions) taking into account quantum superposition and quantum\nentanglement. A way toward the realization of intelligent quantum robots is to\nadopt a quantum metalanguage to control quantum robots. A physical\nimplementation of a quantum metalanguage might be the use of coherent states in\nbrain signals.",
    "published": "2008-12-25T16:31:05Z",
    "link": "http://arxiv.org/pdf/0812.4614v2.pdf",
    "category": [
      "quant-ph",
      "cs.AI",
      "cs.LO",
      "cs.RO"
    ],
    "authors": [
      "Paola Zizzi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0901.0222v1",
    "title": "Dynamic Muscle Fatigue Evaluation in Virtual Working Environment",
    "summary": "Musculoskeletal disorder (MSD) is one of the major health problems in\nmechanical work especially in manual handling jobs. Muscle fatigue is believed\nto be the main reason for MSD. Posture analysis techniques have been used to\nexpose MSD risks of the work, but most of the conventional methods are only\nsuitable for static posture analysis. Meanwhile the subjective influences from\nthe inspectors can result differences in the risk assessment. Another\ndisadvantage is that the evaluation has to be taken place in the workshop, so\nit is impossible to avoid some design defects before data collection in the\nfield environment and it is time consuming. In order to enhance the efficiency\nof ergonomic MSD risk evaluation and avoid subjective influences, we develop a\nnew muscle fatigue model and a new fatigue index to evaluate the human muscle\nfatigue during manual handling jobs in this paper. Our new fatigue model is\nclosely related to the muscle load during working procedure so that it can be\nused to evaluate the dynamic working process. This muscle fatigue model is\nmathematically validated and it is to be further experimental validated and\nintegrated into a virtual working environment to evaluate the muscle fatigue\nand predict the MSD risks quickly and objectively.",
    "published": "2009-01-02T08:49:04Z",
    "link": "http://arxiv.org/pdf/0901.0222v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Liang Ma",
      "Damien Chablat",
      "Fouad Bennis",
      "Wei Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0901.0825v1",
    "title": "A new muscle fatigue and recovery model and its ergonomics application\n  in human simulation",
    "summary": "Although automatic techniques have been employed in manufacturing industries\nto increase productivity and efficiency, there are still lots of manual\nhandling jobs, especially for assembly and maintenance jobs. In these jobs,\nmusculoskeletal disorders (MSDs) are one of the major health problems due to\noverload and cumulative physical fatigue. With combination of conventional\nposture analysis techniques, digital human modelling and simulation (DHM)\ntechniques have been developed and commercialized to evaluate the potential\nphysical exposures. However, those ergonomics analysis tools are mainly based\non posture analysis techniques, and until now there is still no fatigue index\navailable in the commercial software to evaluate the physical fatigue easily\nand quickly. In this paper, a new muscle fatigue and recovery model is proposed\nand extended to evaluate joint fatigue level in manual handling jobs. A special\napplication case is described and analyzed by digital human simulation\ntechnique.",
    "published": "2009-01-07T13:39:33Z",
    "link": "http://arxiv.org/pdf/0901.0825v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Liang Ma",
      "Damien Chablat",
      "Fouad Bennis",
      "Wei Zhang",
      "Franois Guillaume"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0901.4466v1",
    "title": "Physarum boats: If plasmodium sailed it would never leave a port",
    "summary": "Plasmodium of \\emph{Physarum polycephalum} is a single huge (visible by naked\neye) cell with myriad of nuclei. The plasmodium is a promising substrate for\nnon-classical, nature-inspired, computing devices. It is capable for\napproximation of shortest path, computation of planar proximity graphs and\nplane tessellations, primitive memory and decision-making. The unique\nproperties of the plasmodium make it an ideal candidate for a role of amorphous\nbiological robots with massive parallel information processing and distributed\ninputs and outputs. We show that when adhered to light-weight object resting on\na water surface the plasmodium can propel the object by oscillating its\nprotoplasmic pseudopodia. In experimental laboratory conditions and\ncomputational experiments we study phenomenology of the plasmodium-floater\nsystem, and possible mechanisms of controlling motion of objects propelled by\non board plasmodium.",
    "published": "2009-01-28T14:12:32Z",
    "link": "http://arxiv.org/pdf/0901.4466v1.pdf",
    "category": [
      "cs.RO",
      "q-bio.CB",
      "I.2.9; J.3"
    ],
    "authors": [
      "Andrew Adamatzky"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0902.0465v3",
    "title": "AxialGen: A Research Prototype for Automatically Generating the Axial\n  Map",
    "summary": "AxialGen is a research prototype for automatically generating the axial map,\nwhich consists of the least number of the longest visibility lines (or axial\nlines) for representing individual linearly stretched parts of open space of an\nurban environment. Open space is the space between closed spaces such as\nbuildings and street blocks. This paper aims to provide an accessible guide to\nsoftware AxialGen, and the underlying concepts and ideas. We concentrate on the\nexplanation and illustration of the key concept of bucket: its definition,\nformation and how it is used in generating the axial map.\n  Keywords: Bucket, visibility, medial axes, axial lines, isovists, axial map",
    "published": "2009-02-03T10:08:03Z",
    "link": "http://arxiv.org/pdf/0902.0465v3.pdf",
    "category": [
      "cs.RO",
      "cs.CG"
    ],
    "authors": [
      "Bin Jiang",
      "Xintao Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0902.1834v1",
    "title": "Optimal Probabilistic Ring Exploration by Asynchronous Oblivious Robots",
    "summary": "We consider a team of $k$ identical, oblivious, asynchronous mobile robots\nthat are able to sense (\\emph{i.e.}, view) their environment, yet are unable to\ncommunicate, and evolve on a constrained path. Previous results in this weak\nscenario show that initial symmetry yields high lower bounds when problems are\nto be solved by \\emph{deterministic} robots. In this paper, we initiate\nresearch on probabilistic bounds and solutions in this context, and focus on\nthe \\emph{exploration} problem of anonymous unoriented rings of any size. It is\nknown that $\\Theta(\\log n)$ robots are necessary and sufficient to solve the\nproblem with $k$ deterministic robots, provided that $k$ and $n$ are coprime.\nBy contrast, we show that \\emph{four} identical probabilistic robots are\nnecessary and sufficient to solve the same problem, also removing the coprime\nconstraint. Our positive results are constructive.",
    "published": "2009-02-11T10:18:32Z",
    "link": "http://arxiv.org/pdf/0902.1834v1.pdf",
    "category": [
      "cs.DS",
      "cs.CC",
      "cs.DC",
      "cs.RO"
    ],
    "authors": [
      "Stphane Devismes",
      "Franck Petit",
      "Sbastien Tixeuil"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0902.2186v1",
    "title": "A List of Household Objects for Robotic Retrieval Prioritized by People\n  with ALS (Version 092008)",
    "summary": "This technical report is designed to serve as a citable reference for the\noriginal prioritized object list that the Healthcare Robotics Lab at Georgia\nTech released on its website in September of 2008. It is also expected to serve\nas the primary citable reference for the research associated with this list\nuntil the publication of a detailed, peer-reviewed paper.\n  The original prioritized list of object classes resulted from a needs\nassessment involving 8 motor-impaired patients with amyotrophic lateral\nsclerosis (ALS) and targeted, in-person interviews of 15 motor-impaired ALS\npatients. All of these participants were drawn from the Emory ALS Center.\n  The prioritized object list consists of 43 object classes ranked by how\nimportant the participants considered each class to be for retrieval by an\nassistive robot. We intend for this list to be used by researchers to inform\nthe design and benchmarking of robotic systems, especially research related to\nautonomous mobile manipulation.",
    "published": "2009-02-12T18:18:42Z",
    "link": "http://arxiv.org/pdf/0902.2186v1.pdf",
    "category": [
      "cs.RO",
      "cs.HC"
    ],
    "authors": [
      "Young Sang Choi",
      "Travis Deyle",
      "Charles C. Kemp"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0903.0735v1",
    "title": "Modeling the Experience of Emotion",
    "summary": "Affective computing has proven to be a viable field of research comprised of\na large number of multidisciplinary researchers resulting in work that is\nwidely published. The majority of this work consists of computational models of\nemotion recognition, computational modeling of causal factors of emotion and\nemotion expression through rendered and robotic faces. A smaller part is\nconcerned with modeling the effects of emotion, formal modeling of cognitive\nappraisal theory and models of emergent emotions. Part of the motivation for\naffective computing as a field is to better understand emotional processes\nthrough computational modeling. One of the four major topics in affective\ncomputing is computers that have emotions (the others are recognizing,\nexpressing and understanding emotions). A critical and neglected aspect of\nhaving emotions is the experience of emotion (Barrett, Mesquita, Ochsner, and\nGross, 2007): what does the content of an emotional episode look like, how does\nthis content change over time and when do we call the episode emotional. Few\nmodeling efforts have these topics as primary focus. The launch of a journal on\nsynthetic emotions should motivate research initiatives in this direction, and\nthis research should have a measurable impact on emotion research in\npsychology. I show that a good way to do so is to investigate the psychological\ncore of what an emotion is: an experience. I present ideas on how the\nexperience of emotion could be modeled and provide evidence that several\ncomputational models of emotion are already addressing the issue.",
    "published": "2009-03-04T11:26:24Z",
    "link": "http://arxiv.org/pdf/0903.0735v1.pdf",
    "category": [
      "cs.AI",
      "cs.HC",
      "cs.RO"
    ],
    "authors": [
      "Joost Broekens"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0903.2695v1",
    "title": "Dynamic Multi-Vehicle Routing with Multiple Classes of Demands",
    "summary": "In this paper we study a dynamic vehicle routing problem in which there are\nmultiple vehicles and multiple classes of demands. Demands of each class arrive\nin the environment randomly over time and require a random amount of on-site\nservice that is characteristic of the class. To service a demand, one of the\nvehicles must travel to the demand location and remain there for the required\non-site service time. The quality of service provided to each class is given by\nthe expected delay between the arrival of a demand in the class, and that\ndemand's service completion. The goal is to design a routing policy for the\nservice vehicles which minimizes a convex combination of the delays for each\nclass. First, we provide a lower bound on the achievable values of the convex\ncombination of delays. Then, we propose a novel routing policy and analyze its\nperformance under heavy load conditions (i.e., when the fraction of time the\nservice vehicles spend performing on-site service approaches one). The policy\nperforms within a constant factor of the lower bound (and thus the optimal),\nwhere the constant depends only on the number of classes, and is independent of\nthe number of vehicles, the arrival rates of demands, the on-site service\ntimes, and the convex combination coefficients.",
    "published": "2009-03-16T04:50:49Z",
    "link": "http://arxiv.org/pdf/0903.2695v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Marco Pavone",
      "Stephen L. Smith",
      "Francesco Bullo",
      "Emilio Frazzoli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0903.3624v1",
    "title": "Distributed and Adaptive Algorithms for Vehicle Routing in a Stochastic\n  and Dynamic Environment",
    "summary": "In this paper we present distributed and adaptive algorithms for motion\ncoordination of a group of m autonomous vehicles. The vehicles operate in a\nconvex environment with bounded velocity and must service demands whose time of\narrival, location and on-site service are stochastic; the objective is to\nminimize the expected system time (wait plus service) of the demands. The\ngeneral problem is known as the m-vehicle Dynamic Traveling Repairman Problem\n(m-DTRP). The best previously known control algorithms rely on centralized\na-priori task assignment and are not robust against changes in the environment,\ne.g. changes in load conditions; therefore, they are of limited applicability\nin scenarios involving ad-hoc networks of autonomous vehicles operating in a\ntime-varying environment. First, we present a new class of policies for the\n1-DTRP problem that: (i) are provably optimal both in light- and heavy-load\ncondition, and (ii) are adaptive, in particular, they are robust against\nchanges in load conditions. Second, we show that partitioning policies, whereby\nthe environment is partitioned among the vehicles and each vehicle follows a\ncertain set of rules in its own region, are optimal in heavy-load conditions.\nFinally, by combining the new class of algorithms for the 1-DTRP with suitable\npartitioning policies, we design distributed algorithms for the m-DTRP problem\nthat (i) are spatially distributed, scalable to large networks, and adaptive to\nnetwork changes, (ii) are within a constant-factor of optimal in heavy-load\nconditions and stabilize the system in any load condition. Simulation results\nare presented and discussed.",
    "published": "2009-03-20T22:48:08Z",
    "link": "http://arxiv.org/pdf/0903.3624v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Marco Pavone",
      "Emilio Frazzoli",
      "Francesco Bullo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0903.4545v1",
    "title": "Computer- and robot-assisted Medical Intervention",
    "summary": "Medical robotics includes assistive devices used by the physician in order to\nmake his/her diagnostic or therapeutic practices easier and more efficient.\nThis chapter focuses on such systems. It introduces the general field of\nComputer-Assisted Medical Interventions, its aims, its different components and\ndescribes the place of robots in that context. The evolutions in terms of\ngeneral design and control paradigms in the development of medical robots are\npresented and issues specific to that application domain are discussed. A view\nof existing systems, on-going developments and future trends is given. A\ncase-study is detailed. Other types of robotic help in the medical environment\n(such as for assisting a handicapped person, for rehabilitation of a patient or\nfor replacement of some damaged/suppressed limbs or organs) are out of the\nscope of this chapter.",
    "published": "2009-03-26T10:36:02Z",
    "link": "http://arxiv.org/pdf/0903.4545v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Jocelyne Troccaz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0903.4696v1",
    "title": "Multidimensional Online Robot Motion",
    "summary": "We consider three related problems of robot movement in arbitrary dimensions:\ncoverage, search, and navigation. For each problem, a spherical robot is asked\nto accomplish a motion-related task in an unknown environment whose geometry is\nlearned by the robot during navigation. The robot is assumed to have tactile\nand global positioning sensors. We view these problems from the perspective of\n(non-linear) competitiveness as defined by Gabriely and Rimon. We first show\nthat in 3 dimensions and higher, there is no upper bound on competitiveness:\nevery online algorithm can do arbitrarily badly compared to the optimal. We\nthen modify the problems by assuming a fixed clearance parameter. We are able\nto give optimally competitive algorithms under this assumption.",
    "published": "2009-03-26T20:39:55Z",
    "link": "http://arxiv.org/pdf/0903.4696v1.pdf",
    "category": [
      "cs.CG",
      "cs.RO",
      "F.2.2; I.2.9"
    ],
    "authors": [
      "Joshua Brown Kramer",
      "Lucas Sabalka"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0903.4930v1",
    "title": "Time manipulation technique for speeding up reinforcement learning in\n  simulations",
    "summary": "A technique for speeding up reinforcement learning algorithms by using time\nmanipulation is proposed. It is applicable to failure-avoidance control\nproblems running in a computer simulation. Turning the time of the simulation\nbackwards on failure events is shown to speed up the learning by 260% and\nimprove the state space exploration by 12% on the cart-pole balancing task,\ncompared to the conventional Q-learning and Actor-Critic algorithms.",
    "published": "2009-03-28T01:09:00Z",
    "link": "http://arxiv.org/pdf/0903.4930v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "authors": [
      "Petar Kormushev",
      "Kohei Nomoto",
      "Fangyan Dong",
      "Kaoru Hirota"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0903.5267v1",
    "title": "Equitable Partitioning Policies for Mobile Robotic Networks",
    "summary": "The most widely applied strategy for workload sharing is to equalize the\nworkload assigned to each resource. In mobile multi-agent systems, this\nprinciple directly leads to equitable partitioning policies in which (i) the\nworkspace is divided into subregions of equal measure, (ii) there is a\nbijective correspondence between agents and subregions, and (iii) each agent is\nresponsible for service requests originating within its own subregion. In this\npaper, we design provably correct, spatially-distributed and adaptive policies\nthat allow a team of agents to achieve a convex and equitable partition of a\nconvex workspace, where each subregion has the same measure. We also consider\nthe issue of achieving convex and equitable partitions where subregions have\nshapes similar to those of regular polygons. Our approach is related to the\nclassic Lloyd algorithm, and exploits the unique features of power diagrams. We\ndiscuss possible applications to routing of vehicles in stochastic and dynamic\nenvironments. Simulation results are presented and discussed.",
    "published": "2009-03-30T17:26:28Z",
    "link": "http://arxiv.org/pdf/0903.5267v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Marco Pavone",
      "Alessandro Arsie",
      "Emilio Frazzoli",
      "Francesco Bullo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0904.0052v1",
    "title": "Stiffness Analysis of Overconstrained Parallel Manipulators",
    "summary": "The paper presents a new stiffness modeling method for overconstrained\nparallel manipulators with flexible links and compliant actuating joints. It is\nbased on a multidimensional lumped-parameter model that replaces the link\nflexibility by localized 6-dof virtual springs that describe both\ntranslational/rotational compliance and the coupling between them. In contrast\nto other works, the method involves a FEA-based link stiffness evaluation and\nemploys a new solution strategy of the kinetostatic equations for the unloaded\nmanipulator configuration, which allows computing the stiffness matrix for the\noverconstrained architectures, including singular manipulator postures. The\nadvantages of the developed technique are confirmed by application examples,\nwhich deal with comparative stiffness analysis of two translational parallel\nmanipulators of 3-PUU and 3-PRPaR architectures. Accuracy of the proposed\napproach was evaluated for a case study, which focuses on stiffness analysis of\nOrthoglide parallel manipulator.",
    "published": "2009-04-01T19:29:16Z",
    "link": "http://arxiv.org/pdf/0904.0052v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Anatoly Pashkevich",
      "Damien Chablat",
      "Philippe Wenger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0904.0058v1",
    "title": "Kinematics of A 3-PRP planar parallel robot",
    "summary": "Recursive modelling for the kinematics of a 3-PRP planar parallel robot is\npresented in this paper. Three planar chains connecting to the moving platform\nof the manipulator are located in a vertical plane. Knowing the motion of the\nplatform, we develop the inverse kinematics and determine the positions,\nvelocities and accelerations of the robot. Several matrix equations offer\niterative expressions and graphs for the displacements, velocities and\naccelerations of three prismatic actuators.",
    "published": "2009-04-01T19:31:33Z",
    "link": "http://arxiv.org/pdf/0904.0058v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Damien Chablat",
      "Stefan Staicu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0904.0145v1",
    "title": "Kinematic and Dynamic Analysis of the 2-DOF Spherical Wrist of\n  Orthoglide 5-axis",
    "summary": "This paper deals with the kinematics and dynamics of a two degree of freedom\nspherical manipulator, the wrist of Orthoglide 5-axis. The latter is a parallel\nkinematics machine composed of two manipulators: i) the Orthoglide 3-axis; a\nthree-dof translational parallel manipulator that belongs to the family of\nDelta robots, and ii) the Agile eye; a two-dof parallel spherical wrist. The\ngeometric and inertial parameters used in the model are determined by means of\na CAD software. The performance of the spherical wrist is emphasized by means\nof several test trajectories. The effects of machining and/or cutting forces\nand the length of the cutting tool on the dynamic performance of the wrist are\nalso analyzed. Finally, a preliminary selection of the motors is proposed from\nthe velocities and torques required by the actuators to carry out the test\ntrajectories.",
    "published": "2009-04-01T19:33:59Z",
    "link": "http://arxiv.org/pdf/0904.0145v1.pdf",
    "category": [
      "cs.RO",
      "physics.class-ph"
    ],
    "authors": [
      "Raza Ur-Rehman",
      "Stphane Caro",
      "Damien Chablat",
      "Philippe Wenger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0904.0545v2",
    "title": "Time Hopping technique for faster reinforcement learning in simulations",
    "summary": "This preprint has been withdrawn by the author for revision",
    "published": "2009-04-03T10:38:06Z",
    "link": "http://arxiv.org/pdf/0904.0545v2.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "authors": [
      "Petar Kormushev",
      "Kohei Nomoto",
      "Fangyan Dong",
      "Kaoru Hirota"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0904.0546v1",
    "title": "Eligibility Propagation to Speed up Time Hopping for Reinforcement\n  Learning",
    "summary": "A mechanism called Eligibility Propagation is proposed to speed up the Time\nHopping technique used for faster Reinforcement Learning in simulations.\nEligibility Propagation provides for Time Hopping similar abilities to what\neligibility traces provide for conventional Reinforcement Learning. It\npropagates values from one state to all of its temporal predecessors using a\nstate transitions graph. Experiments on a simulated biped crawling robot\nconfirm that Eligibility Propagation accelerates the learning process more than\n3 times.",
    "published": "2009-04-03T10:42:28Z",
    "link": "http://arxiv.org/pdf/0904.0546v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "authors": [
      "Petar Kormushev",
      "Kohei Nomoto",
      "Fangyan Dong",
      "Kaoru Hirota"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0904.1629v1",
    "title": "Fuzzy inference based mentality estimation for eye robot agent",
    "summary": "Household robots need to communicate with human beings in a friendly fashion.\nTo achieve better understanding of displayed information, an importance and a\ncertainty of the information should be communicated together with the main\ninformation. The proposed intent expression system aims to convey this\nadditional information using an eye robot. The eye motions are represented as\nstates in a pleasure-arousal space model. Change of the model state is\ncalculated by fuzzy inference according to the importance and certainty of the\ndisplayed information. This change influences the arousal-sleep coordinate in\nthe space which corresponds to activeness in communication. The eye robot\nprovides a basic interface for the mascot robot system which is an easy to\nunderstand information terminal for home environments in a humatronics society.",
    "published": "2009-04-10T03:17:39Z",
    "link": "http://arxiv.org/pdf/0904.1629v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "authors": [
      "Yoichi Yamazaki",
      "Fangyan Dong",
      "Yuta Masuda",
      "Yukiko Uehara",
      "Petar Kormushev",
      "Hai An Vu",
      "Phuc Quang Le",
      "Kaoru Hirota"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0904.1631v1",
    "title": "Intent expression using eye robot for mascot robot system",
    "summary": "An intent expression system using eye robots is proposed for a mascot robot\nsystem from a viewpoint of humatronics. The eye robot aims at providing a basic\ninterface method for an information terminal robot system. To achieve better\nunderstanding of the displayed information, the importance and the degree of\ncertainty of the information should be communicated along with the main\ncontent. The proposed intent expression system aims at conveying this\nadditional information using the eye robot system. Eye motions are represented\nas the states in a pleasure-arousal space model. Changes in the model state are\ncalculated by fuzzy inference according to the importance and degree of\ncertainty of the displayed information. These changes influence the\narousal-sleep coordinates in the space that corresponds to levels of liveliness\nduring communication. The eye robot provides a basic interface for the mascot\nrobot system that is easy to be understood as an information terminal for home\nenvironments in a humatronics society.",
    "published": "2009-04-10T03:35:33Z",
    "link": "http://arxiv.org/pdf/0904.1631v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "authors": [
      "Yoichi Yamazaki",
      "Fangyan Dong",
      "Yuta Masuda",
      "Yukiko Uehara",
      "Petar Kormushev",
      "Hai An Vu",
      "Phuc Quang Le",
      "Kaoru Hirota"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0904.1907v1",
    "title": "Average Entropy Functions",
    "summary": "The closure of the set of entropy functions associated with n discrete\nvariables, Gammar*n, is a convex cone in (2n-1)- dimensional space, but its\nfull characterization remains an open problem. In this paper, we map Gammar*n\nto an n-dimensional region Phi*n by averaging the joint entropies with the same\nnumber of variables, and show that the simpler Phi*n can be characterized\nsolely by the Shannon-type information inequalities",
    "published": "2009-04-13T04:51:55Z",
    "link": "http://arxiv.org/pdf/0904.1907v1.pdf",
    "category": [
      "cs.IT",
      "cs.RO",
      "math.IT"
    ],
    "authors": [
      "Qi Chen",
      "Chen He",
      "Lingge Jiang",
      "Qingchuan Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0904.3944v1",
    "title": "Better Global Polynomial Approximation for Image Rectification",
    "summary": "When using images to locate objects, there is the problem of correcting for\ndistortion and misalignment in the images. An elegant way of solving this\nproblem is to generate an error correcting function that maps points in an\nimage to their corrected locations. We generate such a function by fitting a\npolynomial to a set of sample points. The objective is to identify a polynomial\nthat passes \"sufficiently close\" to these points with \"good\" approximation of\nintermediate points. In the past, it has been difficult to achieve good global\npolynomial approximation using only sample points. We report on the development\nof a global polynomial approximation algorithm for solving this problem. Key\nWords: Polynomial approximation, interpolation, image rectification.",
    "published": "2009-04-24T21:19:59Z",
    "link": "http://arxiv.org/pdf/0904.3944v1.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Christopher O. Ward"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0904.4836v1",
    "title": "FaceBots: Steps Towards Enhanced Long-Term Human-Robot Interaction by\n  Utilizing and Publishing Online Social Information",
    "summary": "Our project aims at supporting the creation of sustainable and meaningful\nlonger-term human-robot relationships through the creation of embodied robots\nwith face recognition and natural language dialogue capabilities, which exploit\nand publish social information available on the web (Facebook). Our main\nunderlying experimental hypothesis is that such relationships can be\nsignificantly enhanced if the human and the robot are gradually creating a pool\nof shared episodic memories that they can co-refer to (shared memories), and if\nthey are both embedded in a social web of other humans and robots they both\nknow and encounter (shared friends). In this paper, we are presenting such a\nrobot, which as we will see achieves two significant novelties.",
    "published": "2009-04-30T13:02:35Z",
    "link": "http://arxiv.org/pdf/0904.4836v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "H.5.2; I.2.9"
    ],
    "authors": [
      "Nikolaos Mavridis",
      "Shervin Emami",
      "Chandan Datta",
      "Wajahat Kamzi",
      "Chiraz BenAbdelkader",
      "Panos Toulis",
      "Andry Tanoto",
      "Tamer Rabie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0905.0749v1",
    "title": "Soft Motion Trajectory Planner for Service Manipulator Robot",
    "summary": "Human interaction introduces two main constraints: Safety and Comfort.\nTherefore service robot manipulator can't be controlled like industrial robotic\nmanipulator where personnel is isolated from the robot's work envelope. In this\npaper, we present a soft motion trajectory planner to try to ensure that these\nconstraints are satisfied. This planner can be used on-line to establish visual\nand force control loop suitable in presence of human. The cubic trajectories\nbuild by this planner are good candidates as output of a manipulation task\nplanner. The obtained system is then homogeneous from task planning to robot\ncontrol. The soft motion trajectory planner limits jerk, acceleration and\nvelocity in cartesian space using quaternion. Experimental results carried out\non a Mitsubishi PA10-6CE arm are presented.",
    "published": "2009-05-06T06:12:28Z",
    "link": "http://arxiv.org/pdf/0905.0749v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Xavier Broqure",
      "Daniel Sidobre",
      "Ignacio Herrera-Aguilar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0905.3967v1",
    "title": "Optimal byzantine resilient convergence in oblivious robot networks",
    "summary": "Given a set of robots with arbitrary initial location and no agreement on a\nglobal coordinate system, convergence requires that all robots asymptotically\napproach the exact same, but unknown beforehand, location. Robots are\noblivious-- they do not recall the past computations -- and are allowed to move\nin a one-dimensional space. Additionally, robots cannot communicate directly,\ninstead they obtain system related information only via visual sensors. We draw\na connection between the convergence problem in robot networks, and the\ndistributed \\emph{approximate agreement} problem (that requires correct\nprocesses to decide, for some constant $\\epsilon$, values distance $\\epsilon$\napart and within the range of initial proposed values). Surprisingly, even\nthough specifications are similar, the convergence implementation in robot\nnetworks requires specific assumptions about synchrony and Byzantine\nresilience. In more details, we prove necessary and sufficient conditions for\nthe convergence of mobile robots despite a subset of them being Byzantine (i.e.\nthey can exhibit arbitrary behavior). Additionally, we propose a deterministic\nconvergence algorithm for robot networks and analyze its correctness and\ncomplexity in various synchrony settings. The proposed algorithm tolerates f\nByzantine robots for (2f+1)-sized robot networks in fully synchronous networks,\n(3f+1)-sized in semi-synchronous networks. These bounds are optimal for the\nclass of cautious algorithms, which guarantee that correct robots always move\ninside the range of positions of the correct robots.",
    "published": "2009-05-25T19:17:06Z",
    "link": "http://arxiv.org/pdf/0905.3967v1.pdf",
    "category": [
      "cs.DC",
      "cs.RO"
    ],
    "authors": [
      "Zohir Bouzid",
      "Maria Potop-Butucaru",
      "Sbastien Tixeuil"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0906.0651v1",
    "title": "Optimal Byzantine Resilient Convergence in Asynchronous Robot Networks",
    "summary": "We propose the first deterministic algorithm that tolerates up to $f$\nbyzantine faults in $3f+1$-sized networks and performs in the asynchronous\nCORDA model. Our solution matches the previously established lower bound for\nthe semi-synchronous ATOM model on the number of tolerated Byzantine robots.\nOur algorithm works under bounded scheduling assumptions for oblivious robots\nmoving in a uni-dimensional space.",
    "published": "2009-06-03T06:39:38Z",
    "link": "http://arxiv.org/pdf/0906.0651v1.pdf",
    "category": [
      "cs.DC",
      "cs.RO"
    ],
    "authors": [
      "Zohir Bouzid",
      "Maria Potop-Butucaru",
      "Sbastien Tixeuil"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0906.4973v1",
    "title": "Vision Based Navigation for a Mobile Robot with Different Field of Views",
    "summary": "The basic idea behind evolutionary robotics is to evolve a set of neural\ncontrollers for a particular task at hand. It involves use of various input\nparameters such as infrared sensors, light sensors and vision based methods.\nThis paper aims to explore the evolution of vision based navigation in a mobile\nrobot. It discusses in detail the effect of different field of views for a\nmobile robot. The individuals have been evolved using different FOV values and\nthe results have been recorded and analyzed.The optimum values for FOV have\nbeen proposed after evaluating more than 100 different values. It has been\nobserved that the optimum FOV value requires lesser number of generations for\nevolution and the mobile robot trained with that particular value is able to\nnavigate well in the environment.",
    "published": "2009-06-26T16:15:09Z",
    "link": "http://arxiv.org/pdf/0906.4973v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Rizwan A. Khan",
      "M. Aasim Qureshi",
      "Saqib Saeed"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0906.5022v1",
    "title": "Chemical Power for Microscopic Robots in Capillaries",
    "summary": "The power available to microscopic robots (nanorobots) that oxidize\nbloodstream glucose while aggregated in circumferential rings on capillary\nwalls is evaluated with a numerical model using axial symmetry and\ntime-averaged release of oxygen from passing red blood cells. Robots about one\nmicron in size can produce up to several tens of picowatts, in steady-state, if\nthey fully use oxygen reaching their surface from the blood plasma. Robots with\npumps and tanks for onboard oxygen storage could collect oxygen to support\nburst power demands two to three orders of magnitude larger. We evaluate\neffects of oxygen depletion and local heating on surrounding tissue. These\nresults give the power constraints when robots rely entirely on ambient\navailable oxygen and identify aspects of the robot design significantly\naffecting available power. More generally, our numerical model provides an\napproach to evaluating robot design choices for nanomedicine treatments in and\nnear capillaries.",
    "published": "2009-06-26T23:54:08Z",
    "link": "http://arxiv.org/pdf/0906.5022v1.pdf",
    "category": [
      "cs.RO",
      "physics.bio-ph"
    ],
    "authors": [
      "Tad Hogg",
      "Robert A. Freitas Jr"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0907.1072v2",
    "title": "Self-Assembling Systems are Distributed Systems",
    "summary": "In 2004, Klavins et al. introduced the use of graph grammars to describe --\nand to program -- systems of self-assembly. We show that these graph grammars\ncan be embedded in a graph rewriting characterization of distributed systems\nthat was proposed by Degano and Montanari over twenty years ago. We apply this\nembedding to generalize Soloveichik and Winfree's local determinism criterion\n(for achieving a unique terminal assembly), from assembly systems of 4-sided\ntiles that embed in the plane, to arbitrary graph assembly systems. We present\na partial converse of the embedding result, by providing sufficient conditions\nunder which systems of distributed processors can be simulated by graph\nassembly systems topologically, in the plane, and in 3-space. We conclude by\ndefining a new complexity measure: \"surface cost\" (essentially the convex hull\nof the space inhabited by agents at the conclusion of a self-assembled\ncomputation). We show that, for growth-bounded graphs, executing a subroutine\nto find a Maximum Independent Set only increases the surface cost of a\nself-assembling computation by a constant factor. We obtain this complexity\nbound by using the simulation results to import the distributed computing\nnotions of \"local synchronizer\" and \"deterministic coin flipping\" into\nself-assembly.",
    "published": "2009-07-06T19:04:52Z",
    "link": "http://arxiv.org/pdf/0907.1072v2.pdf",
    "category": [
      "cs.FL",
      "cs.DC",
      "cs.RO",
      "F.1.1"
    ],
    "authors": [
      "Aaron Sterling"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0907.1839v1",
    "title": "An Evolved Neural Controller for Bipdedal Walking with Dynamic Balance",
    "summary": "We successfully evolved a neural network controller that produces dynamic\nwalking in a simulated bipedal robot with compliant actuators, a difficult\ncontrol problem. The evolutionary evaluation uses a detailed software\nsimulation of a physical robot. We describe: 1) a novel theoretical method to\nencourage populations to evolve \"around\" local optima, which employs multiple\ndemes and fitness functions of progressively increasing difficulty, and 2) the\nnovel genetic representation of the neural controller.",
    "published": "2009-07-10T15:21:56Z",
    "link": "http://arxiv.org/pdf/0907.1839v1.pdf",
    "category": [
      "cs.NE",
      "cs.RO",
      "D.2.2; I.2.8"
    ],
    "authors": [
      "Michael E. Palmer",
      "Daniel B. Miller"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0907.2759v1",
    "title": "On Cyclic and Nearly Cyclic Multiagent Interactions in the Plane",
    "summary": "We discuss certain types of cyclic and nearly cyclic interactions among N\n\"point\"-agents in the plane, leading to formations of interesting limiting\ngeometric configurations. Cyclic pursuit and local averaging interactions have\nbeen analyzed in the context of multi-agent gathering. In this paper, we\nconsider some nearly cyclic interactions that break symmetry leading to factor\ncirculants rather than circulant interaction matrices.",
    "published": "2009-07-16T07:10:17Z",
    "link": "http://arxiv.org/pdf/0907.2759v1.pdf",
    "category": [
      "cs.MA",
      "cs.RO"
    ],
    "authors": [
      "Frederique Oggier",
      "Alfred Bruckstein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0908.0221v1",
    "title": "FPGA-based Controller for a Mobile Robot",
    "summary": "With application in the robotics and automation, more and more it becomes\nnecessary the development of applications based on methodologies that\nfacilitate future modifications, updates and enhancements in the original\nprojected system. This project presents a conception of mobile robots using\nrapid prototyping, distributing the several control actions in growing levels\nof complexity and computing proposal oriented to embed systems implementation.\nThis kind of controller can be tested on different platform representing the\nmobile robots using reprogrammable logic components (FPGA). This mobile robot\nwill detect obstacle and also be able to control the speed. Different modules\nwill be Actuators, Sensors, wireless transmission. All this modules will be\ninterfaced using FPGA controller. I would like to construct a mechanically\nsimple robot model, which can measure the distance from obstacle with the aid\nof sensor and accordingly should able to control the speed of motor. I would\nlike to construct a mechanically simple robot model, which can measure the\ndistance from obstacle with the aid of sensor and accordingly should able to\ncontrol the speed of motor.",
    "published": "2009-08-03T10:30:55Z",
    "link": "http://arxiv.org/pdf/0908.0221v1.pdf",
    "category": [
      "cs.RO",
      "cs.AR"
    ],
    "authors": [
      "Shilpa Kale",
      "S. S. Shriramwar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0908.0390v1",
    "title": "Byzantine Convergence in Robots Networks: The Price of Asynchrony",
    "summary": "We study the convergence problem in fully asynchronous, uni-dimensional robot\nnetworks that are prone to Byzantine (i.e. malicious) failures. In these\nsettings, oblivious anonymous robots with arbitrary initial positions are\nrequired to eventually converge to an a apriori unknown position despite a\nsubset of them exhibiting Byzantine behavior. Our contribution is twofold. We\npropose a deterministic algorithm that solves the problem in the most generic\nsettings: fully asynchronous robots that operate in the non-atomic CORDA model.\nOur algorithm provides convergence in 5f+1-sized networks where f is the upper\nbound on the number of Byzantine robots. Additionally, we prove that 5f+1 is a\nlower bound whenever robot scheduling is fully asynchronous. This constrasts\nwith previous results in partially synchronous robots networks, where 3f+1\nrobots are necessary and sufficient.",
    "published": "2009-08-04T06:15:33Z",
    "link": "http://arxiv.org/pdf/0908.0390v1.pdf",
    "category": [
      "cs.DC",
      "cs.RO"
    ],
    "authors": [
      "Zohir Bouzid",
      "Maria Potop-Butucaru",
      "Sbastien Tixeuil"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0908.2440v1",
    "title": "Reconfiguration of 3D Crystalline Robots Using O(log n) Parallel Moves",
    "summary": "We consider the theoretical model of Crystalline robots, which have been\nintroduced and prototyped by the robotics community. These robots consist of\nindependently manipulable unit-square atoms that can extend/contract arms on\neach side and attach/detach from neighbors. These operations suffice to\nreconfigure between any two given (connected) shapes. The worst-case number of\nsequential moves required to transform one connected configuration to another\nis known to be Theta(n). However, in principle, atoms can all move\nsimultaneously. We develop a parallel algorithm for reconfiguration that runs\nin only O(log n) parallel steps, although the total number of operations\nincreases slightly to Theta(nlogn). The result is the first (theoretically)\nalmost-instantaneous universally reconfigurable robot built from simple units.",
    "published": "2009-08-17T20:42:44Z",
    "link": "http://arxiv.org/pdf/0908.2440v1.pdf",
    "category": [
      "cs.CG",
      "cs.RO"
    ],
    "authors": [
      "Greg Aloupis",
      "Sebastien Collette",
      "Erik D. Demaine",
      "Stefan Langerman",
      "Vera Sacristan",
      "Stefanie Wuhrer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0908.2656v1",
    "title": "Semantic Robot Vision Challenge: Current State and Future Directions",
    "summary": "The Semantic Robot Vision Competition provided an excellent opportunity for\nour research lab to integrate our many ideas under one umbrella, inspiring both\ncollaboration and new research. The task, visual search for an unknown object,\nis relevant to both the vision and robotics communities. Moreover, since the\ninterplay of robotics and vision is sometimes ignored, the competition provides\na venue to integrate two communities. In this paper, we outline a number of\nmodifications to the competition to both improve the state-of-the-art and\nincrease participation.",
    "published": "2009-08-19T02:13:27Z",
    "link": "http://arxiv.org/pdf/0908.2656v1.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Scott Helmer",
      "David Meger",
      "Pooja Viswanathan",
      "Sancho McCann",
      "Matthew Dockrey",
      "Pooyan Fazli",
      "Tristram Southey",
      "Marius Muja",
      "Michael Joya",
      "Jim Little",
      "David Lowe",
      "Alan Mackworth"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0908.3359v2",
    "title": "Geometric Analysis of the Conformal Camera for Intermediate-Level Vision\n  and Perisaccadic Perception",
    "summary": "A binocular system developed by the author in terms of projective Fourier\ntransform (PFT) of the conformal camera, which numerically integrates the head,\neyes, and visual cortex, is used to process visual information during saccadic\neye movements. Although we make three saccades per second at the eyeball's\nmaximum speed of 700 deg/sec, our visual system accounts for these incisive eye\nmovements to produce a stable percept of the world. This visual constancy is\nmaintained by neuronal receptive field shifts in various retinotopically\norganized cortical areas prior to saccade onset, giving the brain access to\nvisual information from the saccade's target before the eyes' arrival. It\nintegrates visual information acquisition across saccades. Our modeling\nutilizes basic properties of PFT. First, PFT is computable by FFT in complex\nlogarithmic coordinates that approximate the retinotopy. Second, a translation\nin retinotopic (logarithmic) coordinates, modeled by the shift property of the\nFourier transform, remaps the presaccadic scene into a postsaccadic reference\nframe. It also accounts for the perisaccadic mislocalization observed by human\nsubjects in laboratory experiments. Because our modeling involves\ncross-disciplinary areas of conformal geometry, abstract and computational\nharmonic analysis, computational vision, and visual neuroscience, we include\nthe corresponding background material and elucidate how these different areas\ninterwove in our modeling of primate perception. In particular, we present the\nphysiological and behavioral facts underlying the neural processes related to\nour modeling. We also emphasize the conformal camera's geometry and discuss how\nit is uniquely useful in the intermediate-level vision computational aspects of\nnatural scene understanding.",
    "published": "2009-08-24T04:28:59Z",
    "link": "http://arxiv.org/pdf/0908.3359v2.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Jacek Turski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0908.3653v1",
    "title": "Chaotic Transitions in Wall Following Robots",
    "summary": "In this paper we examine how simple agents similar to Braitenberg vehicles\ncan exhibit chaotic movement patterns. The agents are wall following robots as\ndescribed by Steve Mesburger and Alfred Hubler in their paper \"Chaos in Wall\nFollowing Robots\". These agents uses a simple forward facing distance sensor,\nwith a limited field of view \"phi\" for navigation. An agent drives forward at a\nconstant velocity and uses the sensor to turn right when it is too close to an\nobject and left when it is too far away.\n  For a flat wall the agent stays a fixed distance from the wall and travels\nalong it, regardless of the sensor's capabilities. But, if the wall represents\na periodic function, the agent drives on a periodic path when the sensor has a\nnarrow field of view. The agent's trajectory transitions to chaos when the\nsensor's field of view is increased. Numerical experiments were performed with\nsquare, triangle, and sawtooth waves for the wall, to find this pattern. The\nbifurcations of the agents were analyzed, finding both border collision and\nperiod doubling bifurcations. Detailed experimental results will be reported\nseparately.",
    "published": "2009-08-25T18:03:22Z",
    "link": "http://arxiv.org/pdf/0908.3653v1.pdf",
    "category": [
      "nlin.CD",
      "cs.RO",
      "nlin.AO"
    ],
    "authors": [
      "Harry W. Bullen IV",
      "Priya Ranjan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0908.3929v1",
    "title": "A Dynamic Boundary Guarding Problem with Translating Targets",
    "summary": "We introduce a problem in which a service vehicle seeks to guard a deadline\n(boundary) from dynamically arriving mobile targets. The environment is a\nrectangle and the deadline is one of its edges. Targets arrive continuously\nover time on the edge opposite the deadline, and move towards the deadline at a\nfixed speed. The goal for the vehicle is to maximize the fraction of targets\nthat are captured before reaching the deadline. We consider two cases; when the\nservice vehicle is faster than the targets, and; when the service vehicle is\nslower than the targets. In the first case we develop a novel vehicle policy\nbased on computing longest paths in a directed acyclic graph. We give a lower\nbound on the capture fraction of the policy and show that the policy is optimal\nwhen the distance between the target arrival edge and deadline becomes very\nlarge. We present numerical results which suggest near optimal performance away\nfrom this limiting regime. In the second case, when the targets are slower than\nthe vehicle, we propose a policy based on servicing fractions of the\ntranslational minimum Hamiltonian path. In the limit of low target speed and\nhigh arrival rate, the capture fraction of this policy is within a small\nconstant factor of the optimal.",
    "published": "2009-08-27T02:26:40Z",
    "link": "http://arxiv.org/pdf/0908.3929v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Stephen L. Smith",
      "Shaunak D. Bopardikar",
      "Francesco Bullo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0908.4464v2",
    "title": "The eel-like robot",
    "summary": "The aim of this project is to design, study and build an \"eel-like robot\"\nprototype able to swim in three dimensions. The study is based on the analysis\nof eel swimming and results in the realization of a prototype with 12\nvertebrae, a skin and a head with two fins. To reach these objectives, a\nmultidisciplinary group of teams and laboratories has been formed in the\nframework of two French projects.",
    "published": "2009-08-31T06:27:46Z",
    "link": "http://arxiv.org/pdf/0908.4464v2.pdf",
    "category": [
      "cs.RO",
      "physics.class-ph"
    ],
    "authors": [
      "Frdric Boyer",
      "Damien Chablat",
      "Philippe Lemoine",
      "Philippe Wenger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0909.0108v1",
    "title": "On the optimal design of parallel robots taking into account their\n  deformations and natural frequencies",
    "summary": "This paper discusses the utility of using simple stiffness and vibrations\nmodels, based on the Jacobian matrix of a manipulator and only the rigidity of\nthe actuators, whenever its geometry is optimised. In many works, these\nsimplified models are used to propose optimal design of robots. However, the\nelasticity of the drive system is often negligible in comparison with the\nelasticity of the elements, especially in applications where high dynamic\nperformances are needed. Therefore, the use of such a simplified model may lead\nto the creation of robots with long legs, which will be submitted to large\nbending and twisting deformations. This paper presents an example of\nmanipulator for which it is preferable to use a complete stiffness or vibration\nmodel to obtain the most suitable design and shows that the use of simplified\nmodels can lead to mechanisms with poorer rigidity.",
    "published": "2009-09-01T06:46:58Z",
    "link": "http://arxiv.org/pdf/0909.0108v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Sbastien Briot",
      "Anatoly Pashkevich",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0909.0442v1",
    "title": "Kinematic analysis of a class of analytic planar 3-RPR parallel\n  manipulators",
    "summary": "A class of analytic planar 3-RPR manipulators is analyzed in this paper.\nThese manipulators have congruent base and moving platforms and the moving\nplatform is rotated of 180 deg about an axis in the plane. The forward\nkinematics is reduced to the solution of a 3rd-degree polynomial and a\nquadratic equation in sequence. The singularities are calculated and plotted in\nthe joint space. The second-order singularities (cups points), which play an\nimportant role in non-singular change of assembly-mode motions, are also\nanalyzed.",
    "published": "2009-09-02T14:37:01Z",
    "link": "http://arxiv.org/pdf/0909.0442v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Philippe Wenger",
      "Damien Chablat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/0909.1460v1",
    "title": "Accuracy Improvement for Stiffness Modeling of Parallel Manipulators",
    "summary": "The paper focuses on the accuracy improvement of stiffness models for\nparallel manipulators, which are employed in high-speed precision machining. It\nis based on the integrated methodology that combines analytical and numerical\ntechniques and deals with multidimensional lumped-parameter models of the\nlinks. The latter replace the link flexibility by localized 6-dof virtual\nsprings describing both translational/rotational compliance and the coupling\nbetween them. There is presented detailed accuracy analysis of the stiffness\nidentification procedures employed in the commercial CAD systems (including\nstatistical analysis of round-off errors, evaluating the confidence intervals\nfor stiffness matrices). The efficiency of the developed technique is confirmed\nby application examples, which deal with stiffness analysis of translational\nparallel manipulators.",
    "published": "2009-09-08T11:22:09Z",
    "link": "http://arxiv.org/pdf/0909.1460v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Anatoly Pashkevich",
      "Alexandr Klimchik",
      "Damien Chablat",
      "Philippe Wenger"
    ]
  }
]