[
  {
    "id": "http://arxiv.org/abs/2512.19691v1",
    "title": "Scalably Enhancing the Clinical Validity of a Task Benchmark with Physician Oversight",
    "summary": "Automating the calculation of clinical risk scores offers a significant opportunity to reduce physician administrative burden and enhance patient care. The current standard for evaluating this capability is MedCalc-Bench, a large-scale dataset constructed using LLM-based feature extraction and rule-based aggregation. However, treating such model-generated benchmarks as static oracles risks enshrining historical model errors as evaluation gold standards, a problem dangerously amplified when these datasets serve as reward signals for Reinforcement Learning (RL). In this work, we propose viewing benchmarks for complex tasks such as clinical score computation as ''in-progress living documents'' that should be periodically re-evaluated as the processes for creating them improve. We introduce a systematic, physician-in-the-loop pipeline that leverages advanced agentic verifiers to audit and relabel MedCalc-Bench, utilizing automated triage to reserve scarce clinician attention for the most contentious instances. Our audit reveals that a notable fraction of original labels diverge from medical ground truth due to extraction errors, calculator logic mismatches, and clinical ambiguity. To study whether this label noise meaningfully impacts downstream RL training, we fine-tune a Qwen3-8B model via Group Relative Policy Optimization (GRPO) and demonstrate that training on corrected labels yields an 8.7% absolute improvement in accuracy over the original baseline -- validating that label noise materially affects model evaluation. These findings underscore that in safety-critical domains, rigorous benchmark maintenance is a prerequisite for genuine model alignment.",
    "published": "2025-12-22T18:59:34Z",
    "updated": "2025-12-22T18:59:34Z",
    "link": "http://arxiv.org/pdf/2512.19691v1.pdf",
    "category": [
      "cs.AI",
      "stat.AP"
    ],
    "authors": [
      "Junze Ye",
      "Daniel Tawfik",
      "Alex J. Goodell",
      "Nikhil V. Kotha",
      "Mark K. Buyyounouski",
      "Mohsen Bayati"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.09595v2",
    "title": "LiveOIBench: Can Large Language Models Outperform Human Contestants in Informatics Olympiads?",
    "summary": "Competitive programming problems increasingly serve as valuable benchmarks to evaluate the coding capabilities of large language models (LLMs) due to their complexity and ease of verification. Yet, current coding benchmarks face limitations such as lack of exceptionally challenging problems, insufficient test case coverage, reliance on online platform APIs that limit accessibility. To address these issues, we introduce LiveOIBench, a comprehensive benchmark featuring 403 expert-curated Olympiad-level competitive programming problems, each with an average of 60 expert-designed test cases. The problems are sourced directly from 72 official contests of 14 Informatics Olympiads in different regions conducted between 2023 and 2025. LiveOIBench distinguishes itself through four key features: (1) meticulously curated high-quality tasks with detailed subtask rubrics and extensive private test cases; (2) direct integration of elite contestant performance data to enable informative comparison against top-performing humans; (3) planned continuous, contamination-free updates from newly released Olympiad problems; and (4) a self-contained evaluation system facilitating offline and easy-to-reproduce assessments. Benchmarking 34 popular general-purpose and reasoning LLMs, we find that GPT-5 achieves a notable 81.76th percentile, a strong result that nonetheless falls short of top human contestants, who usually place above 90th. In contrast, among open-weight reasoning models, GPT-OSS-120B achieves only a 60th percentile, underscoring significant capability disparities from frontier closed models. Detailed analyses indicate that robust reasoning models prioritize precise problem analysis over excessive exploration, suggesting future models should emphasize structured analysis and minimize unnecessary exploration. All data, code, and leaderboard results are publicly available on our website.",
    "published": "2025-10-10T17:54:24Z",
    "updated": "2025-12-22T18:56:01Z",
    "link": "http://arxiv.org/pdf/2510.09595v2.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Kaijian Zou",
      "Aaron Xiong",
      "Yunxiang Zhang",
      "Frederick Zhang",
      "Yueqi Ren",
      "Jirong Yang",
      "Ayoung Lee",
      "Shitanshu Bhushan",
      "Lu Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19678v1",
    "title": "WorldWarp: Propagating 3D Geometry with Asynchronous Video Diffusion",
    "summary": "Generating long-range, geometrically consistent video presents a fundamental dilemma: while consistency demands strict adherence to 3D geometry in pixel space, state-of-the-art generative models operate most effectively in a camera-conditioned latent space. This disconnect causes current methods to struggle with occluded areas and complex camera trajectories. To bridge this gap, we propose WorldWarp, a framework that couples a 3D structural anchor with a 2D generative refiner. To establish geometric grounding, WorldWarp maintains an online 3D geometric cache built via Gaussian Splatting (3DGS). By explicitly warping historical content into novel views, this cache acts as a structural scaffold, ensuring each new frame respects prior geometry. However, static warping inevitably leaves holes and artifacts due to occlusions. We address this using a Spatio-Temporal Diffusion (ST-Diff) model designed for a \"fill-and-revise\" objective. Our key innovation is a spatio-temporal varying noise schedule: blank regions receive full noise to trigger generation, while warped regions receive partial noise to enable refinement. By dynamically updating the 3D cache at every step, WorldWarp maintains consistency across video chunks. Consequently, it achieves state-of-the-art fidelity by ensuring that 3D logic guides structure while diffusion logic perfects texture. Project page: \\href{https://hyokong.github.io/worldwarp-page/}{https://hyokong.github.io/worldwarp-page/}.",
    "published": "2025-12-22T18:53:50Z",
    "updated": "2025-12-22T18:53:50Z",
    "link": "http://arxiv.org/pdf/2512.19678v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Hanyang Kong",
      "Xingyi Yang",
      "Xiaoxu Zheng",
      "Xinchao Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19673v1",
    "title": "Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies",
    "summary": "Existing reinforcement learning (RL) approaches treat large language models (LLMs) as a single unified policy, overlooking their internal mechanisms. Understanding how policy evolves across layers and modules is therefore crucial for enabling more targeted optimization and raveling out complex reasoning mechanisms. In this paper, we decompose the language model policy by leveraging the intrinsic split of the Transformer residual stream and the equivalence between the composition of hidden states with the unembedding matrix and the resulting samplable policy. This decomposition reveals Internal Layer Policies, corresponding to contributions from individual layers, and Internal Modular Policies, which align with the self-attention and feed-forward network (FFN) components within each layer. By analyzing the entropy of internal policy, we find that: (a) Early layers keep high entropy for exploration, top layers converge to near-zero entropy for refinement, with convergence patterns varying across model series. (b) LLama's prediction space rapidly converges in the final layer, whereas Qwen-series models, especially Qwen3, exhibit a more human-like, progressively structured reasoning pattern. Motivated by these findings, we propose Bottom-up Policy Optimization (BuPO), a novel RL paradigm that directly optimizes the internal layer policy during early training. By aligning training objective at lower layer, BuPO reconstructs foundational reasoning capabilities and achieves superior performance. Extensive experiments on complex reasoning benchmarks demonstrates the effectiveness of our method. Our code is available at https://github.com/Trae1ounG/BuPO.",
    "published": "2025-12-22T18:51:48Z",
    "updated": "2025-12-22T18:51:48Z",
    "link": "http://arxiv.org/pdf/2512.19673v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Yuqiao Tan",
      "Minzheng Wang",
      "Shizhu He",
      "Huanxuan Liao",
      "Chengfeng Zhao",
      "Qiunan Lu",
      "Tian Liang",
      "Jun Zhao",
      "Kang Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.23004v2",
    "title": "Bridging the Gap Between Scientific Laws Derived by AI Systems and Canonical Knowledge via Abductive Inference with AI-Noether",
    "summary": "Advances in AI have shown great potential in contributing to the acceleration of scientific discovery. Symbolic regression can fit interpretable models to data, but these models are not necessarily derivable from established theory. Recent systems (e.g., AI-Descartes, AI-Hilbert) enforce derivability from prior knowledge. However, when existing theories are incomplete or incorrect, these machine-generated hypotheses may fall outside the theoretical scope. Automatically finding corrections to axiom systems to close this gap remains a central challenge in scientific discovery. We propose a solution: an open-source algebraic geometry-based system that, given an incomplete axiom system expressible as polynomials and a hypothesis that the axioms cannot derive, generates a minimal set of candidate axioms that, when added to the theory, provably derive the (possibly noisy) hypothesis. We illustrate the efficacy of our approach by showing that it can reconstruct key axioms required to derive the carrier-resolved photo-Hall effect, Einstein's relativistic laws, and several other laws.",
    "published": "2025-09-26T23:50:25Z",
    "updated": "2025-12-22T18:45:53Z",
    "link": "http://arxiv.org/pdf/2509.23004v2.pdf",
    "category": [
      "cs.AI",
      "cs.SC",
      "math.AG"
    ],
    "authors": [
      "Karan Srivastava",
      "Sanjeeb Dash",
      "Ryan Cory-Wright",
      "Barry Trager",
      "Cristina Cornelio",
      "Lior Horesh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19663v1",
    "title": "Beyond CLIP: Knowledge-Enhanced Multimodal Transformers for Cross-Modal Alignment in Diabetic Retinopathy Diagnosis",
    "summary": "Diabetic retinopathy (DR) is a leading cause of preventable blindness worldwide, demanding accurate automated diagnostic systems. While general-domain vision-language models like Contrastive Language-Image Pre-Training (CLIP) perform well on natural image tasks, they struggle in medical domain applications, particularly in cross-modal retrieval for ophthalmological images. We propose a novel knowledge-enhanced joint embedding framework that integrates retinal fundus images, clinical text, and structured patient data through a multimodal transformer architecture to address the critical gap in medical image-text alignment. Our approach employs separate encoders for each modality: a Vision Transformer (ViT-B/16) for retinal images, Bio-ClinicalBERT for clinical narratives, and a multilayer perceptron for structured demographic and clinical features. These modalities are fused through a joint transformer with modality-specific embeddings, trained using multiple objectives including contrastive losses between modality pairs, reconstruction losses for images and text, and classification losses for DR severity grading according to ICDR and SDRG schemes. Experimental results on the Brazilian Multilabel Ophthalmological Dataset (BRSET) demonstrate significant improvements over baseline models. Our framework achieves near-perfect text-to-image retrieval performance with Recall@1 of 99.94% compared to fine-tuned CLIP's 1.29%, while maintaining state-of-the-art classification accuracy of 97.05% for SDRG and 97.97% for ICDR. Furthermore, zero-shot evaluation on the unseen DeepEyeNet dataset validates strong generalizability with 93.95% Recall@1 versus 0.22% for fine-tuned CLIP. These results demonstrate that our multimodal training approach effectively captures cross-modal relationships in the medical domain, establishing both superior retrieval capabilities and robust diagnostic performance.",
    "published": "2025-12-22T18:41:45Z",
    "updated": "2025-12-22T18:41:45Z",
    "link": "http://arxiv.org/pdf/2512.19663v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Argha Kamal Samanta",
      "Harshika Goyal",
      "Vasudha Joshi",
      "Tushar Mungle",
      "Pabitra Mitra"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19654v1",
    "title": "Clustering with Label Consistency",
    "summary": "Designing efficient, effective, and consistent metric clustering algorithms is a significant challenge attracting growing attention. Traditional approaches focus on the stability of cluster centers; unfortunately, this neglects the real-world need for stable point labels, i.e., stable assignments of points to named sets (clusters). In this paper, we address this gap by initiating the study of label-consistent metric clustering. We first introduce a new notion of consistency, measuring the label distance between two consecutive solutions. Then, armed with this new definition, we design new consistent approximation algorithms for the classical $k$-center and $k$-median problems.",
    "published": "2025-12-22T18:32:23Z",
    "updated": "2025-12-22T18:32:23Z",
    "link": "http://arxiv.org/pdf/2512.19654v1.pdf",
    "category": [
      "cs.DS",
      "cs.AI"
    ],
    "authors": [
      "Diptarka Chakraborty",
      "Hendrik Fichtenberger",
      "Bernhard Haeupler",
      "Silvio Lattanzi",
      "Ashkan Norouzi-Fard",
      "Ola Svensson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2306.00029v2",
    "title": "CodeTF: One-stop Transformer Library for State-of-the-art Code LLMs",
    "summary": "Code intelligence plays a key role in transforming modern software engineering. Recently, deep learning-based models, especially Transformer-based large language models (LLMs), have demonstrated remarkable potential in tackling these tasks by leveraging massive open-source code data and programming language features. However, the development and deployment of such models often require expertise in both machine learning and software engineering, creating a barrier for the model adoption. In this paper, we present CodeTF, an open-source Transformer-based library for state-of-the-art Code LLMs and code intelligence. Following the principles of modular design and extensible framework, we design CodeTF with a unified interface to enable rapid access and development across different types of models, datasets and tasks. Our library supports a collection of pretrained Code LLM models and popular code benchmarks, including a standardized interface to train and serve code LLMs efficiently, and data features such as language-specific parsers and utility functions for extracting code attributes. In this paper, we describe the design principles, the architecture, key modules and components, and compare with other related library tools. Finally, we hope CodeTF is able to bridge the gap between machine learning/generative AI and software engineering, providing a comprehensive open-source solution for developers, researchers, and practitioners.",
    "published": "2023-05-31T05:24:48Z",
    "updated": "2025-12-22T18:29:22Z",
    "link": "http://arxiv.org/pdf/2306.00029v2.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Nghi D. Q. Bui",
      "Hung Le",
      "Yue Wang",
      "Junnan Li",
      "Akhilesh Deepak Gotmare",
      "Steven C. H. Hoi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.01353v2",
    "title": "Differentiable Nonlinear Model Predictive Control",
    "summary": "The efficient computation of parametric solution sensitivities is a key challenge in the integration of learning-enhanced methods with nonlinear model predictive control (MPC), as their availability is crucial for many learning algorithms. This paper discusses the computation of solution sensitivities of general nonlinear programs (NLPs) using the implicit function theorem (IFT) and smoothed optimality conditions treated in interior-point methods (IPM). We detail sensitivity computation within a sequential quadratic programming (SQP) method which employs an IPM for the quadratic subproblems. Previous works presented in the machine learning community are limited to convex or unconstrained formulations, or lack an implementation for efficient sensitivity evaluation. The publication is accompanied by an efficient open-source implementation within the acados framework, providing both forward and adjoint sensitivities for general optimal control problems, achieving speedups exceeding 3x over the state-of-the-art solvers mpc.pytorch and cvxpygen.",
    "published": "2025-05-02T15:43:37Z",
    "updated": "2025-12-22T18:27:42Z",
    "link": "http://arxiv.org/pdf/2505.01353v2.pdf",
    "category": [
      "math.OC",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Jonathan Frey",
      "Katrin Baumgärtner",
      "Gianluca Frison",
      "Dirk Reinhardt",
      "Jasper Hoffmann",
      "Leonard Fichtner",
      "Sebastien Gros",
      "Moritz Diehl"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.04049v2",
    "title": "WANDER: An Explainable Decision-Support Framework for HPC",
    "summary": "High-performance computing (HPC) systems expose many interdependent configuration knobs that impact runtime, resource usage, power, and variability. Existing predictive tools model these outcomes, but do not support structured exploration, explanation, or guided reconfiguration. We present WANDER, a decision-support framework that synthesizes alternate configurations using counterfactual analysis aligned with user goals and constraints. We introduce a composite trade-off score that ranks suggestions based on prediction uncertainty, consistency between feature-target relationships using causal models, and similarity between feature distributions against historical data. To our knowledge, WANDER is the first such system to unify prediction, exploration, and explanation for HPC tuning under a common query interface. Across multiple datasets WANDER generates interpretable and trustworthy, human-readable alternatives that guide users to achieve their performance objectives.",
    "published": "2025-06-04T15:15:23Z",
    "updated": "2025-12-22T18:19:18Z",
    "link": "http://arxiv.org/pdf/2506.04049v2.pdf",
    "category": [
      "cs.PF",
      "cs.AI"
    ],
    "authors": [
      "Ankur Lahiry",
      "Banooqa Banday",
      "Tanzima Z. Islam"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.09312v3",
    "title": "Explaining Tournament Solutions with Minimal Supports",
    "summary": "Tournaments are widely used models to represent pairwise dominance between candidates, alternatives, or teams. We study the problem of providing certified explanations for why a candidate appears among the winners under various tournament rules. To this end, we identify minimal supports, minimal sub-tournaments in which the candidate is guaranteed to win regardless of how the rest of the tournament is completed (that is, the candidate is a necessary winner of the sub-tournament). This notion corresponds to an abductive explanation for the question,\"Why does the winner win the tournament?\", a central concept in formal explainable AI. We focus on common tournament solutions: the top cycle, the uncovered set, the Copeland rule, the Borda rule, the maximin rule, and the weighted uncovered set. For each rule we determine the size of the smallest minimal supports, and we present polynomial-time algorithms to compute them for all solutions except for the weighted uncovered set, for which the problem is NP-complete. Finally, we show how minimal supports can serve to produce compact, certified, and intuitive explanations for tournament solutions.",
    "published": "2025-09-11T09:55:50Z",
    "updated": "2025-12-22T18:14:54Z",
    "link": "http://arxiv.org/pdf/2509.09312v3.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Clément Contet",
      "Umberto Grandi",
      "Jérôme Mengin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19620v1",
    "title": "Exploring the features used for summary evaluation by Human and GPT",
    "summary": "Summary assessment involves evaluating how well a generated summary reflects the key ideas and meaning of the source text, requiring a deep understanding of the content. Large Language Models (LLMs) have been used to automate this process, acting as judges to evaluate summaries with respect to the original text. While previous research investigated the alignment between LLMs and Human responses, it is not yet well understood what properties or features are exploited by them when asked to evaluate based on a particular quality dimension, and there has not been much attention towards mapping between evaluation scores and metrics. In this paper, we address this issue and discover features aligned with Human and Generative Pre-trained Transformers (GPTs) responses by studying statistical and machine learning metrics. Furthermore, we show that instructing GPTs to employ metrics used by Human can improve their judgment and conforming them better with human responses.",
    "published": "2025-12-22T17:54:49Z",
    "updated": "2025-12-22T17:54:49Z",
    "link": "http://arxiv.org/pdf/2512.19620v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Zahra Sadeghi",
      "Evangelos Milios",
      "Frank Rudzicz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19609v1",
    "title": "MapTrace: Scalable Data Generation for Route Tracing on Maps",
    "summary": "While Multimodal Large Language Models have achieved human-like performance on many visual and textual reasoning tasks, their proficiency in fine-grained spatial understanding, such as route tracing on maps remains limited. Unlike humans, who can quickly learn to parse and navigate maps, current models often fail to respect fundamental path constraints, in part due to the prohibitive cost and difficulty of collecting large-scale, pixel-accurate path annotations. To address this, we introduce a scalable synthetic data generation pipeline that leverages synthetic map images and pixel-level parsing to automatically produce precise annotations for this challenging task. Using this pipeline, we construct a fine-tuning dataset of 23k path samples across 4k maps, enabling models to acquire more human-like spatial capabilities. Using this dataset, we fine-tune both open-source and proprietary MLLMs. Results on MapBench show that finetuning substantially improves robustness, raising success rates by up to 6.4 points, while also reducing path-tracing error (NDTW). These gains highlight that fine-grained spatial reasoning, absent in pretrained models, can be explicitly taught with synthetic supervision.",
    "published": "2025-12-22T17:45:39Z",
    "updated": "2025-12-22T17:45:39Z",
    "link": "http://arxiv.org/pdf/2512.19609v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Artemis Panagopoulou",
      "Aveek Purohit",
      "Achin Kulshrestha",
      "Soroosh Yazdani",
      "Mohit Goyal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.23950v2",
    "title": "InterMT: Multi-Turn Interleaved Preference Alignment with Human Feedback",
    "summary": "As multimodal large models (MLLMs) continue to advance across challenging tasks, a key question emerges: What essential capabilities are still missing? A critical aspect of human learning is continuous interaction with the environment -- not limited to language, but also involving multimodal understanding and generation. To move closer to human-level intelligence, models must similarly support multi-turn, multimodal interaction. In particular, they should comprehend interleaved multimodal contexts and respond coherently in ongoing exchanges. In this work, we present an initial exploration through the InterMT -- the first preference dataset for multi-turn multimodal interaction, grounded in real human feedback. In this exploration, we particularly emphasize the importance of human oversight, introducing expert annotations to guide the process, motivated by the fact that current MLLMs lack such complex interactive capabilities. InterMT captures human preferences at both global and local levels into nine sub-dimensions, consists of 15.6k prompts, 52.6k multi-turn dialogue instances, and 32.4k human-labeled preference pairs. To compensate for the lack of capability for multi-modal understanding and generation, we introduce an agentic workflow that leverages tool-augmented MLLMs to construct multi-turn QA instances. To further this goal, we introduce InterMT-Bench to assess the ability of MLLMs in assisting judges with multi-turn, multimodal tasks. We demonstrate the utility of \\InterMT through applications such as judge moderation and further reveal the multi-turn scaling law of judge model. We hope the open-source of our data can help facilitate further research on aligning current MLLMs to the next step. Our project website can be found at https://pku-intermt.github.io .",
    "published": "2025-05-29T19:00:42Z",
    "updated": "2025-12-22T17:36:54Z",
    "link": "http://arxiv.org/pdf/2505.23950v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Boyuan Chen",
      "Donghai Hong",
      "Jiaming Ji",
      "Jiacheng Zheng",
      "Bowen Dong",
      "Jiayi Zhou",
      "Kaile Wang",
      "Juntao Dai",
      "Xuyao Wang",
      "Wenqi Chen",
      "Qirui Zheng",
      "Wenxin Li",
      "Sirui Han",
      "Yike Guo",
      "Yaodong Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.22782v3",
    "title": "Enhancing Multi-Agent Collaboration with Attention-Based Actor-Critic Policies",
    "summary": "This paper introduces Team-Attention-Actor-Critic (TAAC), a reinforcement learning algorithm designed to enhance multi-agent collaboration in cooperative environments. TAAC employs a Centralized Training/Centralized Execution scheme incorporating multi-headed attention mechanisms in both the actor and critic. This design facilitates dynamic, inter-agent communication, allowing agents to explicitly query teammates, thereby efficiently managing the exponential growth of joint-action spaces while ensuring a high degree of collaboration. We further introduce a penalized loss function which promotes diverse yet complementary roles among agents. We evaluate TAAC in a simulated soccer environment against benchmark algorithms representing other multi-agent paradigms, including Proximal Policy Optimization and Multi-Agent Actor-Attention-Critic. We find that TAAC exhibits superior performance and enhanced collaborative behaviors across a variety of metrics (win rates, goal differentials, Elo ratings, inter-agent connectivity, balanced spatial distributions, and frequent tactical interactions such as ball possession swaps).",
    "published": "2025-07-30T15:48:38Z",
    "updated": "2025-12-22T17:22:59Z",
    "link": "http://arxiv.org/pdf/2507.22782v3.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Hugo Garrido-Lestache Belinchon",
      "Jeremy Kedziora"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.07935v6",
    "title": "Working with AI: Measuring the Applicability of Generative AI to Occupations",
    "summary": "With generative AI emerging as a general-purpose technology, understanding its economic effects is among society's most pressing questions. Existing studies of AI impact have largely relied on predictions of AI capabilities or focused narrowly on individual firms. Drawing instead on real-world AI usage, we analyze a dataset of 200k anonymized conversations with Microsoft Bing Copilot to measure AI applicability to occupations. We use an LLM-based pipeline to classify the O*NET work activities assisted or performed by AI in each conversation. We find that the most common and successful AI-assisted work activities involve information work--the creation, processing, and communication of information. At the occupation level, we find widespread AI applicability cutting across sectors, as most occupations have information work components. Our methodology also allows us to predict which occupations are more likely to delegate tasks to AI and which are more likely to use AI to assist existing workflows.",
    "published": "2025-07-10T17:16:33Z",
    "updated": "2025-12-22T17:01:55Z",
    "link": "http://arxiv.org/pdf/2507.07935v6.pdf",
    "category": [
      "cs.AI",
      "cs.CY",
      "econ.GN"
    ],
    "authors": [
      "Kiran Tomlinson",
      "Sonia Jaffe",
      "Will Wang",
      "Scott Counts",
      "Siddharth Suri"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19576v1",
    "title": "LeLaR: The First In-Orbit Demonstration of an AI-Based Satellite Attitude Controller",
    "summary": "Attitude control is essential for many satellite missions. Classical controllers, however, are time-consuming to design and sensitive to model uncertainties and variations in operational boundary conditions. Deep Reinforcement Learning (DRL) offers a promising alternative by learning adaptive control strategies through autonomous interaction with a simulation environment. Overcoming the Sim2Real gap, which involves deploying an agent trained in simulation onto the real physical satellite, remains a significant challenge. In this work, we present the first successful in-orbit demonstration of an AI-based attitude controller for inertial pointing maneuvers. The controller was trained entirely in simulation and deployed to the InnoCube 3U nanosatellite, which was developed by the Julius-Maximilians-Universität Würzburg in cooperation with the Technische Universität Berlin, and launched in January 2025. We present the AI agent design, the methodology of the training procedure, the discrepancies between the simulation and the observed behavior of the real satellite, and a comparison of the AI-based attitude controller with the classical PD controller of InnoCube. Steady-state metrics confirm the robust performance of the AI-based controller during repeated in-orbit maneuvers.",
    "published": "2025-12-22T17:00:25Z",
    "updated": "2025-12-22T17:00:25Z",
    "link": "http://arxiv.org/pdf/2512.19576v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "eess.SY"
    ],
    "authors": [
      "Kirill Djebko",
      "Tom Baumann",
      "Erik Dilger",
      "Frank Puppe",
      "Sergio Montenegro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19570v1",
    "title": "The Epistemological Consequences of Large Language Models: Rethinking collective intelligence and institutional knowledge",
    "summary": "We examine epistemological threats posed by human and LLM interaction. We develop collective epistemology as a theory of epistemic warrant distributed across human collectives, using bounded rationality and dual process theory as background. We distinguish internalist justification, defined as reflective understanding of why a proposition is true, from externalist justification, defined as reliable transmission of truths. Both are necessary for collective rationality, but only internalist justification produces reflective knowledge. We specify reflective knowledge as follows: agents understand the evaluative basis of a claim, when that basis is unavailable agents consistently assess the reliability of truth sources, and agents have a duty to apply these standards within their domains of competence. We argue that LLMs approximate externalist reliabilism because they can reliably transmit information whose justificatory basis is established elsewhere, but they do not themselves possess reflective justification. Widespread outsourcing of reflective work to reliable LLM outputs can weaken reflective standards of justification, disincentivize comprehension, and reduce agents' capacity to meet professional and civic epistemic duties. To mitigate these risks, we propose a three tier norm program that includes an epistemic interaction model for individual use, institutional and organizational frameworks that seed and enforce norms for epistemically optimal outcomes, and deontic constraints at organizational and or legislative levels that instantiate discursive norms and curb epistemic vices.",
    "published": "2025-12-22T16:52:37Z",
    "updated": "2025-12-22T16:52:37Z",
    "link": "http://arxiv.org/pdf/2512.19570v1.pdf",
    "category": [
      "cs.HC",
      "cs.AI"
    ],
    "authors": [
      "Angjelin Hila"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19569v1",
    "title": "Owning the Intelligence: Global AI Patents Landscape and Europe's Quest for Technological Sovereignty",
    "summary": "Artificial intelligence has become a key arena of global technological competition and a central concern for Europe's quest for technological sovereignty. This paper analyzes global AI patenting from 2010 to 2023 to assess Europe's position in an increasingly bipolar innovation landscape dominated by the United States and China. Using linked patent, firm, ownership, and citation data, we examine the geography, specialization, and international diffusion of AI innovation. We find a highly concentrated patent landscape: China leads in patent volumes, while the United States dominates in citation impact and technological influence. Europe accounts for a limited share of AI patents but exhibits signals of relatively high patent quality. Technological proximity reveals global convergence toward U.S. innovation trajectories, with Europe remaining fragmented rather than forming an autonomous pole. Gravity-model estimates show that cross-border AI knowledge flows are driven primarily by technological capability and specialization, while geographic and institutional factors play a secondary role. EU membership does not significantly enhance intra-European knowledge diffusion, suggesting that technological capacity, rather than political integration, underpins participation in global AI innovation networks.",
    "published": "2025-12-22T16:52:36Z",
    "updated": "2025-12-22T16:52:36Z",
    "link": "http://arxiv.org/pdf/2512.19569v1.pdf",
    "category": [
      "econ.GN",
      "cs.AI"
    ],
    "authors": [
      "Lapo Santarlasci",
      "Armando Rungi",
      "Loredana Fattorini",
      "Nestor Maslej"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19564v1",
    "title": "Results of the 2024 CommonRoad Motion Planning Competition for Autonomous Vehicles",
    "summary": "Over the past decade, a wide range of motion planning approaches for autonomous vehicles has been developed to handle increasingly complex traffic scenarios. However, these approaches are rarely compared on standardized benchmarks, limiting the assessment of relative strengths and weaknesses. To address this gap, we present the setup and results of the 4th CommonRoad Motion Planning Competition held in 2024, conducted using the CommonRoad benchmark suite. This annual competition provides an open-source and reproducible framework for benchmarking motion planning algorithms. The benchmark scenarios span highway and urban environments with diverse traffic participants, including passenger cars, buses, and bicycles. Planner performance is evaluated along four dimensions: efficiency, safety, comfort, and compliance with selected traffic rules. This report introduces the competition format and provides a comparison of representative high-performing planners from the 2023 and 2024 editions.",
    "published": "2025-12-22T16:46:40Z",
    "updated": "2025-12-22T16:46:40Z",
    "link": "http://arxiv.org/pdf/2512.19564v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Yanliang Huang",
      "Xia Yan",
      "Peiran Yin",
      "Zhenduo Zhang",
      "Zeyan Shao",
      "Youran Wang",
      "Haoliang Huang",
      "Matthias Althoff"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19562v1",
    "title": "REALM: A Real-to-Sim Validated Benchmark for Generalization in Robotic Manipulation",
    "summary": "Vision-Language-Action (VLA) models empower robots to understand and execute tasks described by natural language instructions. However, a key challenge lies in their ability to generalize beyond the specific environments and conditions they were trained on, which is presently difficult and expensive to evaluate in the real-world. To address this gap, we present REALM, a new simulation environment and benchmark designed to evaluate the generalization capabilities of VLA models, with a specific emphasis on establishing a strong correlation between simulated and real-world performance through high-fidelity visuals and aligned robot control. Our environment offers a suite of 15 perturbation factors, 7 manipulation skills, and more than 3,500 objects. Finally, we establish two task sets that form our benchmark and evaluate the π_{0}, π_{0}-FAST, and GR00T N1.5 VLA models, showing that generalization and robustness remain an open challenge. More broadly, we also show that simulation gives us a valuable proxy for the real-world and allows us to systematically probe for and quantify the weaknesses and failure modes of VLAs. Project page: https://martin-sedlacek.com/realm",
    "published": "2025-12-22T16:44:23Z",
    "updated": "2025-12-22T16:44:23Z",
    "link": "http://arxiv.org/pdf/2512.19562v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Martin Sedlacek",
      "Pavlo Yefanov",
      "Georgy Ponimatkin",
      "Jai Bardhan",
      "Simon Pilc",
      "Mederic Fourmy",
      "Evangelos Kazakos",
      "Cees G. M. Snoek",
      "Josef Sivic",
      "Vladimir Petrik"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19560v1",
    "title": "BabyFlow: 3D modeling of realistic and expressive infant faces",
    "summary": "Early detection of developmental disorders can be aided by analyzing infant craniofacial morphology, but modeling infant faces is challenging due to limited data and frequent spontaneous expressions. We introduce BabyFlow, a generative AI model that disentangles facial identity and expression, enabling independent control over both. Using normalizing flows, BabyFlow learns flexible, probabilistic representations that capture the complex, non-linear variability of expressive infant faces without restrictive linear assumptions. To address scarce and uncontrolled expressive data, we perform cross-age expression transfer, adapting expressions from adult 3D scans to enrich infant datasets with realistic and systematic expressive variants. As a result, BabyFlow improves 3D reconstruction accuracy, particularly in highly expressive regions such as the mouth, eyes, and nose, and supports synthesis and modification of infant expressions while preserving identity. Additionally, by integrating with diffusion models, BabyFlow generates high-fidelity 2D infant images with consistent 3D geometry, providing powerful tools for data augmentation and early facial analysis.",
    "published": "2025-12-22T16:42:58Z",
    "updated": "2025-12-22T16:42:58Z",
    "link": "http://arxiv.org/pdf/2512.19560v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Antonia Alomar",
      "Mireia Masias",
      "Marius George Linguraru",
      "Federico M. Sukno",
      "Gemma Piella"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19557v1",
    "title": "Augmenting Intelligence: A Hybrid Framework for Scalable and Stable Explanations",
    "summary": "Current approaches to Explainable AI (XAI) face a \"Scalability-Stability Dilemma.\" Post-hoc methods (e.g., LIME, SHAP) may scale easily but suffer from instability, while supervised explanation frameworks (e.g., TED) offer stability but require prohibitive human effort to label every training instance. This paper proposes a Hybrid LRR-TED framework that addresses this dilemma through a novel \"Asymmetry of Discovery.\" When applied to customer churn prediction, we demonstrate that automated rule learners (GLRM) excel at identifying broad \"Safety Nets\" (retention patterns) but struggle to capture specific \"Risk Traps\" (churn triggers)-a phenomenon we term the Anna Karenina Principle of Churn. By initialising the explanation matrix with automated safety rules and augmenting it with a Pareto-optimal set of just four human-defined risk rules, our approach achieves 94.00% predictive accuracy. This configuration outperforms the full 8-rule manual expert baseline while reducing human annotation effort by 50%, proposing a shift in the paradigm for Human-in-the-Loop AI: moving experts from the role of \"Rule Writers\" to \"Exception Handlers.\"",
    "published": "2025-12-22T16:40:14Z",
    "updated": "2025-12-22T16:40:14Z",
    "link": "http://arxiv.org/pdf/2512.19557v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Lawrence Krukrubo",
      "Julius Odede",
      "Olawande Olusegun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19554v1",
    "title": "CARE What Fails: Contrastive Anchored-REflection for Verifiable Multimodal",
    "summary": "Group-relative reinforcement learning with verifiable rewards (RLVR) often wastes the most informative data it already has the failures. When all rollouts are wrong, gradients stall; when one happens to be correct, the update usually ignores why the others are close-but-wrong, and credit can be misassigned to spurious chains. We present CARE (Contrastive Anchored REflection), a failure-centric post-training framework for multimodal reasoning that turns errors into supervision. CARE combines: (i) an anchored-contrastive objective that forms a compact subgroup around the best rollout and a set of semantically proximate hard negatives, performs within-subgroup z-score normalization with negative-only scaling, and includes an all-negative rescue to prevent zero-signal batches; and (ii) Reflection-Guided Resampling (RGR), a one-shot structured self-repair that rewrites a representative failure and re-scores it with the same verifier, converting near-misses into usable positives without any test-time reflection. CARE improves accuracy and training smoothness while explicitly increasing the share of learning signal that comes from failures. On Qwen2.5-VL-7B, CARE lifts macro-averaged accuracy by 4.6 points over GRPO across six verifiable visual-reasoning benchmarks; with Qwen3-VL-8B it reaches competitive or state-of-the-art results on MathVista and MMMU-Pro under an identical evaluation protocol.",
    "published": "2025-12-22T16:34:21Z",
    "updated": "2025-12-22T16:34:21Z",
    "link": "http://arxiv.org/pdf/2512.19554v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Yongxin Wang",
      "Zhicheng Yang",
      "Meng Cao",
      "Mingfei Han",
      "Haokun Lin",
      "Yingying Zhu",
      "Xiaojun Chang",
      "Xiaodan Liang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19551v1",
    "title": "Towards Closed-Loop Embodied Empathy Evolution: Probing LLM-Centric Lifelong Empathic Motion Generation in Unseen Scenarios",
    "summary": "In the literature, existing human-centric emotional motion generation methods primarily focus on boosting performance within a single scale-fixed dataset, largely neglecting the flexible and scale-increasing motion scenarios (e.g., sports, dance), whereas effectively learning these newly emerging scenarios can significantly enhance the model's real-world generalization ability. Inspired by this, this paper proposes a new LLM-Centric Lifelong Empathic Motion Generation (L^2-EMG) task, which aims to equip LLMs with the capability to continually acquire emotional motion generation knowledge across different unseen scenarios, potentially contributing to building a closed-loop and self-evolving embodied agent equipped with both empathy and intelligence. Further, this paper poses two key challenges in the L^2-EMG task, i.e., the emotion decoupling challenge and the scenario adapting challenge. To this end, this paper proposes an Emotion-Transferable and Scenario-Adapted Mixture of Experts (ES-MoE) approach which designs a causal-guided emotion decoupling block and a scenario-adapted expert constructing block to address the two challenges, respectively. Especially, this paper constructs multiple L^2-EMG datasets to validate the effectiveness of the ES-MoE approach. Extensive evaluations show that ES-MoE outperforms advanced baselines.",
    "published": "2025-12-22T16:31:30Z",
    "updated": "2025-12-22T16:31:30Z",
    "link": "http://arxiv.org/pdf/2512.19551v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Jiawen Wang",
      "Jingjing Wang Tianyang Chen",
      "Min Zhang",
      "Guodong Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2409.20302v6",
    "title": "OM4OV: Leveraging Ontology Matching for Ontology Versioning",
    "summary": "Due to the dynamic nature of the Semantic Web, version control is necessary to capture time-varying information for widely used ontologies. Despite the long-standing recognition of ontology versioning (OV) as a crucial component of efficient ontology management, many approaches treat OV as similar to ontology matching (OM) and directly reuse OM systems for OV tasks. In this study, we systematically analyse the similarities and differences between OM and OV and formalise the OM4OV pipeline. The pipeline is implemented and evaluated in the state-of-the-art OM system Agent-OM. The experimental results indicate that OM systems can be reused for OV tasks, but without necessary extensions, the current OM4OV pipeline can produce skewed measurements, poor performance in detecting update entities, and limited explainability for false mappings. To tackle these issues, we propose an optimisation method called the cross-reference (CR) mechanism, building upon the existing alignments from OM to reduce the number of matching candidates and improve overall OV performance.",
    "published": "2024-09-30T14:00:04Z",
    "updated": "2025-12-22T16:29:48Z",
    "link": "http://arxiv.org/pdf/2409.20302v6.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "authors": [
      "Zhangcheng Qiang",
      "Kerry Taylor",
      "Weiqing Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.24116v2",
    "title": "AIDOVECL: AI-generated Dataset of Outpainted Vehicles for Eye-level Classification and Localization",
    "summary": "Image labeling is a critical bottleneck in the development of computer vision technologies, often constraining the potential of machine learning models due to the time-intensive nature of manual annotations. This work introduces a novel approach that leverages outpainting to mitigate the problem of annotated data scarcity by generating artificial contexts and annotations, significantly reducing manual labeling efforts. We apply this technique to a particularly acute challenge in autonomous driving, urban planning, and environmental monitoring: the lack of diverse, eye-level vehicle images in desired classes. Our dataset comprises AI-generated vehicle images obtained by detecting and cropping vehicles from manually selected seed images, which are then outpainted onto larger canvases to simulate varied real-world conditions. The outpainted images include detailed annotations, providing high-quality ground truth data. Advanced outpainting techniques and image quality assessments ensure visual fidelity and contextual relevance. Ablation results show that incorporating AIDOVECL improves overall detection performance by up to 10%, and delivers gains of up to 40% in settings with greater diversity of context, object scale, and placement, with underrepresented classes achieving up to 50% higher true positives. AIDOVECL enhances vehicle detection by augmenting real training data and supporting evaluation across diverse scenarios. By demonstrating outpainting as an automatic annotation paradigm, it offers a practical and versatile solution for building fine-grained datasets with reduced labeling effort across multiple machine learning domains. The code and links to datasets used in this study are available for further research and replication at https://github.com/amir-kazemi/aidovecl .",
    "published": "2024-10-31T16:46:23Z",
    "updated": "2025-12-22T16:25:04Z",
    "link": "http://arxiv.org/pdf/2410.24116v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Amir Kazemi",
      "Qurat ul ain Fatima",
      "Volodymyr Kindratenko",
      "Christopher Tessum"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19535v1",
    "title": "CASA: Cross-Attention via Self-Attention for Efficient Vision-Language Fusion",
    "summary": "Vision-language models (VLMs) are commonly trained by inserting image tokens from a pretrained vision encoder into the textual stream of a language model. This allows text and image information to fully attend to one another within the model, but becomes extremely costly for high-resolution images, long conversations, or streaming videos, both in memory and compute. VLMs leveraging cross-attention are an efficient alternative to token insertion but exhibit a clear performance gap, in particular on tasks involving fine-grained visual details. We find that a key to improving such models is to also enable local text-to-text interaction in the dedicated cross-attention layers. Building on this, we propose CASA, Cross-Attention via Self-Attention, a simple and efficient paradigm which substantially reduces the gap with full token insertion on common image understanding benchmarks, while enjoying the same scalability as cross-attention models when applied to long-context multimodal tasks such as streaming video captioning. For samples and code, please see our project page at https://kyutai.org/casa .",
    "published": "2025-12-22T16:21:39Z",
    "updated": "2025-12-22T16:21:39Z",
    "link": "http://arxiv.org/pdf/2512.19535v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Moritz Böhle",
      "Amélie Royer",
      "Juliette Marrie",
      "Edouard Grave",
      "Patrick Pérez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19530v1",
    "title": "Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement",
    "summary": "Predicting reaction outcomes across continuous solvent composition ranges remains a critical challenge in organic synthesis and process chemistry. Traditional machine learning approaches often treat solvent identity as a discrete categorical variable, which prevents systematic interpolation and extrapolation across the solvent space. This work introduces the \\textbf{Catechol Benchmark}, a high-throughput transient flow chemistry dataset comprising 1,227 experimental yield measurements for the rearrangement of allyl-substituted catechol in 24 pure solvents and their binary mixtures, parameterized by continuous volume fractions ($\\% B$). We evaluate various architectures under rigorous leave-one-solvent-out and leave-one-mixture-out protocols to test generalization to unseen chemical environments.\n  Our results demonstrate that classical tabular methods (e.g., Gradient-Boosted Decision Trees) and large language model embeddings (e.g., Qwen-7B) struggle with quantitative precision, yielding Mean Squared Errors (MSE) of 0.099 and 0.129, respectively. In contrast, we propose a hybrid GNN-based architecture that integrates Graph Attention Networks (GATs) with Differential Reaction Fingerprints (DRFP) and learned mixture-aware solvent encodings. This approach achieves an \\textbf{MSE of 0.0039} ($\\pm$ 0.0003), representing a 60\\% error reduction over competitive baselines and a $>25\\times$ improvement over tabular ensembles. Ablation studies confirm that explicit molecular graph message-passing and continuous mixture encoding are essential for robust generalization. The complete dataset, evaluation protocols, and reference implementations are released to facilitate data-efficient reaction prediction and continuous solvent representation learning.",
    "published": "2025-12-22T16:19:01Z",
    "updated": "2025-12-22T16:19:01Z",
    "link": "http://arxiv.org/pdf/2512.19530v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Hongsheng Xing",
      "Qiuxin Si"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19526v1",
    "title": "QuantiPhy: A Quantitative Benchmark Evaluating Physical Reasoning Abilities of Vision-Language Models",
    "summary": "Understanding the physical world is essential for generalist AI agents. However, it remains unclear whether state-of-the-art vision perception models (e.g., large VLMs) can reason physical properties quantitatively. Existing evaluations are predominantly VQA-based and qualitative, offering limited insight into whether these models can infer the kinematic quantities of moving objects from video observations. To address this, we present QuantiPhy, the first benchmark designed to quantitatively measure a VLM's physical reasoning ability. Comprising more than 3.3K video-text instances with numerical ground truth, QuantiPhy evaluates a VLM's performance on estimating an object's size, velocity, and acceleration at a given timestamp, using one of these properties as an input prior. The benchmark standardizes prompts and scoring to assess numerical accuracy, enabling fair comparisons across models. Our experiments on state-of-the-art VLMs reveal a consistent gap between their qualitative plausibility and actual numerical correctness. We further provide an in-depth analysis of key factors like background noise, counterfactual priors, and strategic prompting and find that state-of-the-art VLMs lean heavily on pre-trained world knowledge rather than faithfully using the provided visual and textual inputs as references when reasoning kinematic properties quantitatively. QuantiPhy offers the first rigorous, scalable testbed to move VLMs beyond mere verbal plausibility toward a numerically grounded physical understanding.",
    "published": "2025-12-22T16:18:00Z",
    "updated": "2025-12-22T16:18:00Z",
    "link": "http://arxiv.org/pdf/2512.19526v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Li Puyin",
      "Tiange Xiang",
      "Ella Mao",
      "Shirley Wei",
      "Xinye Chen",
      "Adnan Masood",
      "Li Fei-fei",
      "Ehsan Adeli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19516v1",
    "title": "LacaDM: A Latent Causal Diffusion Model for Multiobjective Reinforcement Learning",
    "summary": "Multiobjective reinforcement learning (MORL) poses significant challenges due to the inherent conflicts between objectives and the difficulty of adapting to dynamic environments. Traditional methods often struggle to generalize effectively, particularly in large and complex state-action spaces. To address these limitations, we introduce the Latent Causal Diffusion Model (LacaDM), a novel approach designed to enhance the adaptability of MORL in discrete and continuous environments. Unlike existing methods that primarily address conflicts between objectives, LacaDM learns latent temporal causal relationships between environmental states and policies, enabling efficient knowledge transfer across diverse MORL scenarios. By embedding these causal structures within a diffusion model-based framework, LacaDM achieves a balance between conflicting objectives while maintaining strong generalization capabilities in previously unseen environments. Empirical evaluations on various tasks from the MOGymnasium framework demonstrate that LacaDM consistently outperforms the state-of-art baselines in terms of hypervolume, sparsity, and expected utility maximization, showcasing its effectiveness in complex multiobjective tasks.",
    "published": "2025-12-22T16:08:03Z",
    "updated": "2025-12-22T16:08:03Z",
    "link": "http://arxiv.org/pdf/2512.19516v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Xueming Yan",
      "Bo Yin",
      "Yaochu Jin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19512v1",
    "title": "Anatomy-R1: Enhancing Anatomy Reasoning in Multimodal Large Language Models via Anatomical Similarity Curriculum and Group Diversity Augmentation",
    "summary": "Multimodal Large Language Models (MLLMs) have achieved impressive progress in natural image reasoning, yet their potential in medical imaging remains underexplored, especially in clinical anatomical surgical images. Anatomy understanding tasks demand precise understanding and clinically coherent answers, which are difficult to achieve due to the complexity of medical data and the scarcity of high-quality expert annotations. These challenges limit the effectiveness of conventional Supervised Fine-Tuning (SFT) strategies. While recent work has demonstrated that Group Relative Policy Optimization (GRPO) can enhance reasoning in MLLMs without relying on large amounts of data, we find two weaknesses that hinder GRPO's reasoning performance in anatomy recognition: 1) knowledge cannot be effectively shared between different anatomical structures, resulting in uneven information gain and preventing the model from converging, and 2) the model quickly converges to a single reasoning path, suppressing the exploration of diverse strategies. To overcome these challenges, we propose two novel methods. First, we implement a progressive learning strategy called Anatomical Similarity Curriculum Learning by controlling question difficulty via the similarity of answer choices, enabling the model to master complex problems incrementally. Second, we utilize question augmentation referred to as Group Diversity Question Augmentation to expand the model's search space for difficult queries, mitigating the tendency to produce uniform responses. Comprehensive experiments on the SGG-VQA and OmniMedVQA benchmarks show our method achieves a significant improvement across the two benchmarks, demonstrating its effectiveness in enhancing the medical reasoning capabilities of MLLMs. The code can be found in https://github.com/tomato996/Anatomy-R1",
    "published": "2025-12-22T16:06:36Z",
    "updated": "2025-12-22T16:06:36Z",
    "link": "http://arxiv.org/pdf/2512.19512v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Ziyang Song",
      "Zelin Zang",
      "Zuyao Chen",
      "Xusheng Liang",
      "Dong Yi",
      "Jinlin Wu",
      "Hongbin Liu",
      "Jiebo Luo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19506v1",
    "title": "DK-STN: A Domain Knowledge Embedded Spatio-Temporal Network Model for MJO Forecast",
    "summary": "Understanding and predicting the Madden-Julian Oscillation (MJO) is fundamental for precipitation forecasting and disaster prevention. To date, long-term and accurate MJO prediction has remained a challenge for researchers. Conventional MJO prediction methods using Numerical Weather Prediction (NWP) are resource-intensive, time-consuming, and highly unstable (most NWP methods are sensitive to seasons, with better MJO forecast results in winter). While existing Artificial Neural Network (ANN) methods save resources and speed forecasting, their accuracy never reaches the 28 days predicted by the state-of-the-art NWP method, i.e., the operational forecasts from ECMWF, since neural networks cannot handle climate data effectively. In this paper, we present a Domain Knowledge Embedded Spatio-Temporal Network (DK-STN), a stable neural network model for accurate and efficient MJO forecasting. It combines the benefits of NWP and ANN methods and successfully improves the forecast accuracy of ANN methods while maintaining a high level of efficiency and stability. We begin with a spatial-temporal network (STN) and embed domain knowledge in it using two key methods: (i) applying a domain knowledge enhancement method and (ii) integrating a domain knowledge processing method into network training. We evaluated DK-STN with the 5th generation of ECMWF reanalysis (ERA5) data and compared it with ECMWF. Given 7 days of climate data as input, DK-STN can generate reliable forecasts for the following 28 days in 1-2 seconds, with an error of only 2-3 days in different seasons. DK-STN significantly exceeds ECMWF in that its forecast accuracy is equivalent to ECMWF's, while its efficiency and stability are significantly superior.",
    "published": "2025-12-22T16:00:55Z",
    "updated": "2025-12-22T16:00:55Z",
    "link": "http://arxiv.org/pdf/2512.19506v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Hongliang Li",
      "Nong Zhang",
      "Zhewen Xu",
      "Xiang Li",
      "Changzheng Liu",
      "Chongbo Zhao",
      "Jie Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.20063v2",
    "title": "SAEs Are Good for Steering -- If You Select the Right Features",
    "summary": "Sparse Autoencoders (SAEs) have been proposed as an unsupervised approach to learn a decomposition of a model's latent space. This enables useful applications such as steering - influencing the output of a model towards a desired concept - without requiring labeled data. Current methods identify SAE features to steer by analyzing the input tokens that activate them. However, recent work has highlighted that activations alone do not fully describe the effect of a feature on the model's output. In this work, we draw a distinction between two types of features: input features, which mainly capture patterns in the model's input, and output features, which have a human-understandable effect on the model's output. We propose input and output scores to characterize and locate these types of features, and show that high values for both scores rarely co-occur in the same features. These findings have practical implications: after filtering out features with low output scores, we obtain 2-3x improvements when steering with SAEs, making them competitive with supervised methods.",
    "published": "2025-05-26T14:47:59Z",
    "updated": "2025-12-22T15:49:59Z",
    "link": "http://arxiv.org/pdf/2505.20063v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Dana Arad",
      "Aaron Mueller",
      "Yonatan Belinkov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19494v1",
    "title": "Kolmogorov-Arnold Graph Neural Networks Applied to Inorganic Nanomaterials Dataset",
    "summary": "The recent development of Kolmogorov-Arnold Networks (KANs) introduced new discoveries in the field of Graph Neural Networks (GNNs), expanding the existing set of models with KAN-based versions of GNNs, which often surpass the accuracy of MultiLayer Perceptron (MLP)-based GNNs. These models were widely tested on the graph datasets consisting of organic molecules; however, those studies disregarded the inorganic nanomaterials datasets. In this work, we close this gap by applying Kolmogorov-Arnold Graph Neural Networks (KAGNNs) to a recently published large inorganic nanomaterials dataset called CHILI. For this, we adapt and test KAGNNs appropriate for this dataset. Our experiments reveal that on the CHILI datasets, particularly on the CHILI-3K, KAGNNs substantially surpass conventional GNNs in classification, achieving state-of-the-art results.",
    "published": "2025-12-22T15:49:24Z",
    "updated": "2025-12-22T15:49:24Z",
    "link": "http://arxiv.org/pdf/2512.19494v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Nikita Volzhin",
      "Soowhan Yoon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.15925v3",
    "title": "VERDI: VLM-Embedded Reasoning for Autonomous Driving",
    "summary": "While autonomous driving (AD) stacks struggle with decision making under partial observability and real-world complexity, human drivers are capable of commonsense reasoning to make near-optimal decisions with limited information. Recent work has attempted to leverage finetuned Vision-Language Models (VLMs) for trajectory planning at inference time to emulate human behavior. Despite their success in benchmark evaluations, these methods are often impractical to deploy (a 70B parameter VLM inference at merely 8 tokens per second requires more than 160G of memory), and their monolithic network structure prohibits safety decomposition. To bridge this gap, we propose VLM-Embedded Reasoning for autonomous Driving (VERDI), a training-time framework that distills the reasoning process and commonsense knowledge of VLMs into the AD stack. VERDI augments modular differentiable end-to-end (e2e) AD models by aligning intermediate module outputs at the perception, prediction, and planning stages with text features explaining the driving reasoning process produced by VLMs. By encouraging alignment in latent space, VERDI enables the modular AD stack to internalize structured reasoning, without incurring the inference-time costs of large VLMs. We validate VERDI in both open-loop (NuScenes and Bench2Drive benchmarks) and closed-loop (HugSim Simulator) settings. We find that VERDI outperforms existing e2e methods that do not embed reasoning by up to 11% in $\\ell_{2}$ distance and 11% in driving performance, while maintaining real-time inference speed.",
    "published": "2025-05-21T18:24:36Z",
    "updated": "2025-12-22T15:37:49Z",
    "link": "http://arxiv.org/pdf/2505.15925v3.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Bowen Feng",
      "Zhiting Mei",
      "Baiang Li",
      "Julian Ost",
      "Filippo Ghilotti",
      "Roger Girgis",
      "Anirudha Majumdar",
      "Felix Heide"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19481v1",
    "title": "A Dataset and Preliminary Study of Using GPT-5 for Code-change Impact Analysis",
    "summary": "Understanding source code changes and their impact on other code entities is a crucial skill in software development. However, the analysis of code changes and their impact is often performed manually and therefore is time-consuming. Recent advancements in AI, and in particular large language models (LLMs) show promises to help developers in various code analysis tasks. However, the extent to which this potential can be utilized for understanding code changes and their impact is underexplored. To address this gap, we study the capabilities of GPT-5 and GPT-5-mini to predict the code entities impacted by given source code changes. We construct a dataset containing information about seed-changes, change pairs, and change types for each commit. Existing datasets lack crucial information about seed changes and impacted code entities. Our experiments evaluate the LLMs in two configurations: (1) seed-change information and the parent commit tree and (2) seed-change information, the parent commit tree, and the diff hunk of each seed change. We found that both LLMs perform poorly in the two experiments, whereas GPT-5 outperforms GPT-5-mini. Furthermore, the provision of the diff hunks helps both models to slightly improve their performance.",
    "published": "2025-12-22T15:32:45Z",
    "updated": "2025-12-22T15:32:45Z",
    "link": "http://arxiv.org/pdf/2512.19481v1.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Katharina Stengg",
      "Christian Macho",
      "Martin Pinzger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19472v1",
    "title": "Multi-Layer Confidence Scoring for Detection of Out-of-Distribution Samples, Adversarial Attacks, and In-Distribution Misclassifications",
    "summary": "The recent explosive growth in Deep Neural Networks applications raises concerns about the black-box usage of such models, with limited trasparency and trustworthiness in high-stakes domains, which have been crystallized as regulatory requirements such as the European Union Artificial Intelligence Act. While models with embedded confidence metrics have been proposed, such approaches cannot be applied to already existing models without retraining, limiting their broad application. On the other hand, post-hoc methods, which evaluate pre-trained models, focus on solving problems related to improving the confidence in the model's predictions, and detecting Out-Of-Distribution or Adversarial Attacks samples as independent applications. To tackle the limited applicability of already existing methods, we introduce Multi-Layer Analysis for Confidence Scoring (MACS), a unified post-hoc framework that analyzes intermediate activations to produce classification-maps. From the classification-maps, we derive a score applicable for confidence estimation, detecting distributional shifts and adversarial attacks, unifying the three problems in a common framework, and achieving performances that surpass the state-of-the-art approaches in our experiments with the VGG16 and ViTb16 models with a fraction of their computational overhead.",
    "published": "2025-12-22T15:25:10Z",
    "updated": "2025-12-22T15:25:10Z",
    "link": "http://arxiv.org/pdf/2512.19472v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Lorenzo Capelli",
      "Leandro de Souza Rosa",
      "Gianluca Setti",
      "Mauro Mangia",
      "Riccardo Rovatti"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.16416v2",
    "title": "SSL4RL: Revisiting Self-supervised Learning as Intrinsic Reward for Visual-Language Reasoning",
    "summary": "Vision-language models (VLMs) have shown remarkable abilities by integrating large language models with visual inputs. However, they often fail to utilize visual evidence adequately, either depending on linguistic priors in vision-centric tasks or resorting to textual shortcuts during reasoning. Although reinforcement learning (RL) can align models with desired behaviors, its application to VLMs has been hindered by the lack of scalable and reliable reward mechanisms. To overcome this challenge, we propose SSL4RL, a novel framework that leverages self-supervised learning (SSL) tasks as a source of verifiable rewards for RL-based fine-tuning. Our approach reformulates SSL objectives-such as predicting image rotation or reconstructing masked patches-into dense, automatic reward signals, eliminating the need for human preference data or unreliable AI evaluators. Experiments show that SSL4RL substantially improves performance on both vision-centric and vision-language reasoning benchmarks. Furthermore, through systematic ablations, we identify key factors-such as task difficulty, model scale, and semantic alignment with the target domain-that influence the effectiveness of SSL4RL tasks, offering new design principles for future work. We also demonstrate the framework's generality by applying it to graph learning, where it yields significant gains. SSL4RL establishes a versatile and effective paradigm for aligning multimodal models using verifiable, self-supervised objectives.",
    "published": "2025-10-18T09:22:40Z",
    "updated": "2025-12-22T15:14:59Z",
    "link": "http://arxiv.org/pdf/2510.16416v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Xiaojun Guo",
      "Runyu Zhou",
      "Yifei Wang",
      "Qi Zhang",
      "Chenheng Zhang",
      "Stefanie Jegelka",
      "Xiaohan Wang",
      "Jiajun Chai",
      "Guojun Yin",
      "Wei Lin",
      "Yisen Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19458v1",
    "title": "An Agentic Framework for Autonomous Materials Computation",
    "summary": "Large Language Models (LLMs) have emerged as powerful tools for accelerating scientific discovery, yet their static knowledge and hallucination issues hinder autonomous research applications. Recent advances integrate LLMs into agentic frameworks, enabling retrieval, reasoning, and tool use for complex scientific workflows. Here, we present a domain-specialized agent designed for reliable automation of first-principles materials computations. By embedding domain expertise, the agent ensures physically coherent multi-step workflows and consistently selects convergent, well-posed parameters, thereby enabling reliable end-to-end computational execution. A new benchmark of diverse computational tasks demonstrates that our system significantly outperforms standalone LLMs in both accuracy and robustness. This work establishes a verifiable foundation for autonomous computational experimentation and represents a key step toward fully automated scientific discovery.",
    "published": "2025-12-22T15:03:57Z",
    "updated": "2025-12-22T15:03:57Z",
    "link": "http://arxiv.org/pdf/2512.19458v1.pdf",
    "category": [
      "cs.AI",
      "cond-mat.mtrl-sci"
    ],
    "authors": [
      "Zeyu Xia",
      "Jinzhe Ma",
      "Congjie Zheng",
      "Shufei Zhang",
      "Yuqiang Li",
      "Hang Su",
      "P. Hu",
      "Changshui Zhang",
      "Xingao Gong",
      "Wanli Ouyang",
      "Lei Bai",
      "Dongzhan Zhou",
      "Mao Su"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19456v1",
    "title": "Activations as Features: Probing LLMs for Generalizable Essay Scoring Representations",
    "summary": "Automated essay scoring (AES) is a challenging task in cross-prompt settings due to the diversity of scoring criteria. While previous studies have focused on the output of large language models (LLMs) to improve scoring accuracy, we believe activations from intermediate layers may also provide valuable information. To explore this possibility, we evaluated the discriminative power of LLMs' activations in cross-prompt essay scoring task. Specifically, we used activations to fit probes and further analyzed the effects of different models and input content of LLMs on this discriminative power. By computing the directions of essays across various trait dimensions under different prompts, we analyzed the variation in evaluation perspectives of large language models concerning essay types and traits. Results show that the activations possess strong discriminative power in evaluating essay quality and that LLMs can adapt their evaluation perspectives to different traits and essay types, effectively handling the diversity of scoring criteria in cross-prompt settings.",
    "published": "2025-12-22T15:01:07Z",
    "updated": "2025-12-22T15:01:07Z",
    "link": "http://arxiv.org/pdf/2512.19456v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Jinwei Chi",
      "Ke Wang",
      "Yu Chen",
      "Xuanye Lin",
      "Qiang Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2408.10566v5",
    "title": "Overcoming Growth-Induced Forgetting in Task-Agnostic Continual Learning",
    "summary": "In continual learning (CL), model growth enhances adaptability to new data. However, when model growth is applied improperly, especially in task-agnostic CL, where the entire grown model is used for inference, it can lead to severe degradation of learned knowledge, a problem we term growth-induced forgetting. Most existing methods that adopt model growth to improve adaptability often overlook the forgetting issue, resulting in compromised knowledge retention, making them unsuitable for task-agnostic settings. To promote both adaptability and knowledge retention with model growth, we identify the key: gradient and parameter sparsity. Introducing SparseGrow, which increases gradient sparsity through layer expansion and gradient gating to enable focused updates on parameters while preserving critical parameters, thus inhibiting forgetting. Moreover, it promotes parameter sparsity with sparse initialization and training, aiming at better control of model plasticity, improving adaptability over new data. Extensive experiments across diverse datasets, task-agnostic settings, and a large number of tasks demonstrate the necessity of controlled layer expansion and validate the effectiveness of SparseGrow in achieving high adaptability while minimizing forgetting in continual learning. By enabling model growth with sparsified gradients and parameters, SparseGrow paves the way for building scalable lifelong learning systems capable of continual adaptation with better knowledge retention.",
    "published": "2024-08-20T06:05:52Z",
    "updated": "2025-12-22T14:46:47Z",
    "link": "http://arxiv.org/pdf/2408.10566v5.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Yuqing Zhao",
      "Jiannong Cao",
      "Divya Saxena",
      "Xiaoyun Liu",
      "Changlin Song",
      "Bo Yuan",
      "Julie McCann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.14396v4",
    "title": "Continuous Vision-Language-Action Co-Learning with Semantic-Physical Alignment for Behavioral Cloning",
    "summary": "Language-conditioned manipulation facilitates human-robot interaction via behavioral cloning (BC), which learns control policies from human demonstrations and serves as a cornerstone of embodied AI. Overcoming compounding errors in sequential action decisions remains a central challenge to improving BC performance. Existing approaches mitigate compounding errors through data augmentation, expressive representation, or temporal abstraction. However, they suffer from physical discontinuities and semantic-physical misalignment, leading to inaccurate action cloning and intermittent execution. In this paper, we present Continuous vision-language-action Co-Learning with Semantic-Physical Alignment (CCoL), a novel BC framework that ensures temporally consistent execution and fine-grained semantic grounding. It generates robust and smooth action execution trajectories through continuous co-learning across vision, language, and proprioceptive inputs (e.g., robot internal states). Meanwhile, we anchor language semantics to visuomotor representations by a bidirectional cross-attention to learn contextual information for action generation, successfully overcoming the problem of semantic-physical misalignment. Extensive experiments show that CCoL achieves an average 8.0% relative improvement across three simulation suites, with up to 19.2% relative gain in human-demonstrated bimanual insertion tasks. Real-world tests on a 7-DoF robot further confirm CCoL's generalization under unseen and noisy object states.",
    "published": "2025-11-18T12:01:06Z",
    "updated": "2025-12-22T14:45:53Z",
    "link": "http://arxiv.org/pdf/2511.14396v4.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Xiuxiu Qi",
      "Yu Yang",
      "Jiannong Cao",
      "Luyao Bai",
      "Chongshan Fan",
      "Chengtai Cao",
      "Hongpeng Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19438v1",
    "title": "MT-Mark: Rethinking Image Watermarking via Mutual-Teacher Collaboration with Adaptive Feature Modulation",
    "summary": "Existing deep image watermarking methods follow a fixed embedding-distortion-extraction pipeline, where the embedder and extractor are weakly coupled through a final loss and optimized in isolation. This design lacks explicit collaboration, leaving no structured mechanism for the embedder to incorporate decoding-aware cues or for the extractor to guide embedding during training. To address this architectural limitation, we rethink deep image watermarking by reformulating embedding and extraction as explicitly collaborative components. To realize this reformulation, we introduce a Collaborative Interaction Mechanism (CIM) that establishes direct, bidirectional communication between the embedder and extractor, enabling a mutual-teacher training paradigm and coordinated optimization. Built upon this explicitly collaborative architecture, we further propose an Adaptive Feature Modulation Module (AFMM) to support effective interaction. AFMM enables content-aware feature regulation by decoupling modulation structure and strength, guiding watermark embedding toward stable image features while suppressing host interference during extraction. Under CIM, the AFMMs on both sides form a closed-loop collaboration that aligns embedding behavior with extraction objectives. This architecture-level redesign changes how robustness is learned in watermarking systems. Rather than relying on exhaustive distortion simulation, robustness emerges from coordinated representation learning between embedding and extraction. Experiments on real-world and AI-generated datasets demonstrate that the proposed method consistently outperforms state-of-the-art approaches in watermark extraction accuracy while maintaining high perceptual quality, showing strong robustness and generalization.",
    "published": "2025-12-22T14:36:08Z",
    "updated": "2025-12-22T14:36:08Z",
    "link": "http://arxiv.org/pdf/2512.19438v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Fei Ge",
      "Ying Huang",
      "Jie Liu",
      "Guixuan Zhang",
      "Zhi Zeng",
      "Shuwu Zhang",
      "Hu Guan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.18822v2",
    "title": "AdaCtrl: Towards Adaptive and Controllable Reasoning via Difficulty-Aware Budgeting",
    "summary": "Modern large reasoning models demonstrate impressive problem-solving capabilities by employing sophisticated reasoning strategies. However, they often struggle to balance efficiency and effectiveness, frequently generating unnecessarily lengthy reasoning chains for simple problems. In this work, we propose AdaCtrl, a novel framework to support both difficulty-aware adaptive reasoning budget allocation and explicit user control over reasoning depth. AdaCtrl dynamically adjusts its reasoning length based on self-assessed problem difficulty, while also allowing users to manually control the budget to prioritize either efficiency or effectiveness. This is achieved through a two-stage training pipeline: an initial cold-start fine-tuning phase to instill the ability to self-aware difficulty and adjust reasoning budget, followed by a difficulty-aware reinforcement learning (RL) stage that refines the model's adaptive reasoning strategies and calibrates its difficulty assessments based on its evolving capabilities during online training. To enable intuitive user interaction, we design explicit length-triggered tags that function as a natural interface for budget control. Empirical results show that AdaCtrl adapts reasoning length based on estimated difficulty, compared to the standard training baseline that also incorporates fine-tuning and RL, it yields performance improvements and simultaneously reduces response length by 10.06% and 12.14% on the more challenging AIME2024 and AIME2025 datasets, which require elaborate reasoning, and by 62.05% and 91.04% on the MATH500 and GSM8K datasets, where more concise responses are sufficient. Furthermore, AdaCtrl enables precise user control over the reasoning budget, allowing for tailored responses to meet specific needs.",
    "published": "2025-05-24T18:46:50Z",
    "updated": "2025-12-22T14:30:53Z",
    "link": "http://arxiv.org/pdf/2505.18822v2.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Shijue Huang",
      "Hongru Wang",
      "Wanjun Zhong",
      "Zhaochen Su",
      "Jiazhan Feng",
      "Bowen Cao",
      "Yi R. Fung"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19428v1",
    "title": "Attention Is Not What You Need",
    "summary": "We revisit a basic question in sequence modeling: is explicit self-attention actually necessary for strong performance and reasoning? We argue that standard multi-head attention is best seen as a form of tensor lifting: hidden vectors are mapped into a high-dimensional space of pairwise interactions, and learning proceeds by constraining this lifted tensor through gradient descent. This mechanism is extremely expressive but mathematically opaque, because after many layers it becomes very hard to describe the model with a small family of explicit invariants.\n  To explore an alternative, we propose an attention-free architecture based on Grassmann flows. Instead of forming an L by L attention matrix, our Causal Grassmann layer (i) linearly reduces token states, (ii) encodes local token pairs as two-dimensional subspaces on a Grassmann manifold via Plucker coordinates, and (iii) fuses these geometric features back into the hidden states through gated mixing. Information therefore propagates by controlled deformations of low-rank subspaces over multi-scale local windows, so the core computation lives on a finite-dimensional manifold rather than in an unstructured tensor space.\n  On the Wikitext-2 language modeling benchmark, purely Grassmann-based models with 13 to 18 million parameters achieve validation perplexities within about 10 to 15 percent of size-matched Transformers. On the SNLI natural language inference task, a Grassmann-Plucker head on top of DistilBERT slightly outperforms a Transformer head, with best validation and test accuracies of 0.8550 and 0.8538 compared to 0.8545 and 0.8511. We analyze the complexity of Grassmann mixing, show linear scaling in sequence length for fixed rank, and argue that such manifold-based designs offer a more structured route toward geometric and invariant-based interpretations of neural reasoning.",
    "published": "2025-12-22T14:29:18Z",
    "updated": "2025-12-22T14:29:18Z",
    "link": "http://arxiv.org/pdf/2512.19428v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "math.AG"
    ],
    "authors": [
      "Zhang Chong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.15735v2",
    "title": "Deep Reinforcement Learning Optimization for Uncertain Nonlinear Systems via Event-Triggered Robust Adaptive Dynamic Programming",
    "summary": "This work proposes a unified control architecture that couples a Reinforcement Learning (RL)-driven controller with a disturbance-rejection Extended State Observer (ESO), complemented by an Event-Triggered Mechanism (ETM) to limit unnecessary computations. The ESO is utilized to estimate the system states and the lumped disturbance in real time, forming the foundation for effective disturbance compensation. To obtain near-optimal behavior without an accurate system description, a value-iteration-based Adaptive Dynamic Programming (ADP) method is adopted for policy approximation. The inclusion of the ETM ensures that parameter updates of the learning module are executed only when the state deviation surpasses a predefined bound, thereby preventing excessive learning activity and substantially reducing computational load. A Lyapunov-oriented analysis is used to characterize the stability properties of the resulting closed-loop system. Numerical experiments further confirm that the developed approach maintains strong control performance and disturbance tolerance, while achieving a significant reduction in sampling and processing effort compared with standard time-triggered ADP schemes.",
    "published": "2025-12-05T22:52:22Z",
    "updated": "2025-12-22T14:25:02Z",
    "link": "http://arxiv.org/pdf/2512.15735v2.pdf",
    "category": [
      "math.OC",
      "cs.AI",
      "eess.SY"
    ],
    "authors": [
      "Ningwei Bai",
      "Chi Pui Chan",
      "Qichen Yin",
      "Tengyang Gong",
      "Yunda Yan",
      "Zezhi Tang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19410v1",
    "title": "Research Program: Theory of Learning in Dynamical Systems",
    "summary": "Modern learning systems increasingly interact with data that evolve over time and depend on hidden internal state. We ask a basic question: when is such a dynamical system learnable from observations alone? This paper proposes a research program for understanding learnability in dynamical systems through the lens of next-token prediction. We argue that learnability in dynamical systems should be studied as a finite-sample question, and be based on the properties of the underlying dynamics rather than the statistical properties of the resulting sequence. To this end, we give a formulation of learnability for stochastic processes induced by dynamical systems, focusing on guarantees that hold uniformly at every time step after a finite burn-in period. This leads to a notion of dynamic learnability which captures how the structure of a system, such as stability, mixing, observability, and spectral properties, governs the number of observations required before reliable prediction becomes possible. We illustrate the framework in the case of linear dynamical systems, showing that accurate prediction can be achieved after finite observation without system identification, by leveraging improper methods based on spectral filtering. We survey the relationship between learning in dynamical systems and classical PAC, online, and universal prediction theories, and suggest directions for studying nonlinear and controlled systems.",
    "published": "2025-12-22T14:05:31Z",
    "updated": "2025-12-22T14:05:31Z",
    "link": "http://arxiv.org/pdf/2512.19410v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Elad Hazan",
      "Shai Shalev Shwartz",
      "Nathan Srebro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.14031v5",
    "title": "A Riemannian Optimization Perspective of the Gauss-Newton Method for Feedforward Neural Networks",
    "summary": "In this work, we establish non-asymptotic convergence bounds for the Gauss-Newton method in training neural networks with smooth activations. In the underparameterized regime, the Gauss-Newton gradient flow in parameter space induces a Riemannian gradient flow on a low-dimensional embedded submanifold of the function space. Using tools from Riemannian optimization, we establish geodesic Polyak-Lojasiewicz and Lipschitz-smoothness conditions for the loss under appropriately chosen output scaling, yielding geometric convergence to the optimal in-class predictor at an explicit rate independent of the conditioning of the Gram matrix. In the overparameterized regime, we propose adaptive, curvature-aware regularization schedules that ensure fast geometric convergence to a global optimum at a rate independent of the minimum eigenvalue of the neural tangent kernel and, locally, of the modulus of strong convexity of the loss. These results demonstrate that Gauss-Newton achieves accelerated convergence rates in settings where first-order methods exhibit slow convergence due to ill-conditioned kernel matrices and loss landscapes.",
    "published": "2024-12-18T16:51:47Z",
    "updated": "2025-12-22T13:49:48Z",
    "link": "http://arxiv.org/pdf/2412.14031v5.pdf",
    "category": [
      "math.OC",
      "cs.AI",
      "cs.LG",
      "eess.SY",
      "stat.ML"
    ],
    "authors": [
      "Semih Cayci"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.10190v2",
    "title": "Temporal Causal Reasoning with (Non-Recursive) Structural Equation Models",
    "summary": "Structural Equation Models (SEM) are the standard approach to representing causal dependencies between variables in causal models. In this paper we propose a new interpretation of SEMs when reasoning about Actual Causality, in which SEMs are viewed as mechanisms transforming the dynamics of exogenous variables into the dynamics of endogenous variables. This allows us to combine counterfactual causal reasoning with existing temporal logic formalisms, and to introduce a temporal logic, CPLTL, for causal reasoning about such structures. We show that the standard restriction to so-called \\textit{recursive} models (with no cycles in the dependency graph) is not necessary in our approach, allowing us to reason about mutually dependent processes and feedback loops. Finally, we introduce new notions of model equivalence for temporal causal models, and show that CPLTL has an efficient model-checking procedure.",
    "published": "2025-01-17T13:37:58Z",
    "updated": "2025-12-22T13:46:47Z",
    "link": "http://arxiv.org/pdf/2501.10190v2.pdf",
    "category": [
      "cs.AI",
      "cs.LO"
    ],
    "authors": [
      "Maksim Gladyshev",
      "Natasha Alechina",
      "Mehdi Dastani",
      "Dragan Doder",
      "Brian Logan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19396v1",
    "title": "EchoTrail-GUI: Building Actionable Memory for GUI Agents via Critic-Guided Self-Exploration",
    "summary": "Contemporary GUI agents, while increasingly capable due to advances in Large Vision-Language Models (VLMs), often operate with a critical limitation: they treat each task in isolation, lacking a mechanism to systematically learn from past successes. This digital ''amnesia'' results in sub-optimal performance, repeated errors, and poor generalization to novel challenges. To bridge this gap, we introduce EchoTrail-GUI, a novel framework designed to mimic human-like experiential learning by equipping agents with a dynamic, accessible memory. Our framework operates in three distinct stages. First, during Experience Exploration, an agent autonomously interacts with GUI environments to build a curated database of successful task trajectories, validated by a reward model. Crucially, the entire knowledge base construction is thus fully automated, requiring no human supervision. Second, in the Memory Injection stage, upon receiving a new task, our system efficiently retrieves the most relevant past trajectories to serve as actionable ''memories''. Finally, during GUI Task Inference, these memories are injected as in-context guidance to inform the agent's reasoning and decision-making process. We demonstrate the efficacy of our approach on benchmarks including Android World and AndroidLab. The results show that EchoTrail-GUI significantly improves the task success rate and operational efficiency of baseline agents, validating the power of structured memory in creating more robust and intelligent GUI automation.",
    "published": "2025-12-22T13:42:18Z",
    "updated": "2025-12-22T13:42:18Z",
    "link": "http://arxiv.org/pdf/2512.19396v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Runze Li",
      "Yuwen Zhai",
      "Bo Xu",
      "LiWu Xu",
      "Nian Shi",
      "Wei Zhang",
      "Ran Lin",
      "Liang Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.13907v2",
    "title": "Assessing High-Risk AI Systems under the EU AI Act: From Legal Requirements to Technical Verification",
    "summary": "The implementation of the AI Act requires practical mechanisms to verify compliance with legal obligations, yet concrete and operational mappings from high-level requirements to verifiable assessment activities remain limited, contributing to uneven readiness across Member States. This paper presents a structured mapping that translates high-level AI Act requirements into concrete, implementable verification activities applicable across the AI lifecycle. The mapping is derived through a systematic process in which legal requirements are decomposed into operational sub-requirements and grounded in authoritative standards and recognised practices. From this basis, verification activities are identified and characterised along two dimensions: the type of verification performed and the lifecycle target to which it applies. By making explicit the link between regulatory intent and technical and organisational assurance practices, the proposed mapping reduces interpretive uncertainty and provides a reusable reference for consistent, technology-agnostic compliance verification under the AI Act.",
    "published": "2025-12-15T21:24:29Z",
    "updated": "2025-12-22T13:38:32Z",
    "link": "http://arxiv.org/pdf/2512.13907v2.pdf",
    "category": [
      "cs.CY",
      "cs.AI"
    ],
    "authors": [
      "Alessio Buscemi",
      "Tom Deckenbrunnen",
      "Fahria Kabir",
      "Kateryna Mishchenko",
      "Nishat Mowla"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19387v1",
    "title": "DSTED: Decoupling Temporal Stabilization and Discriminative Enhancement for Surgical Workflow Recognition",
    "summary": "Purpose: Surgical workflow recognition enables context-aware assistance and skill assessment in computer-assisted interventions. Despite recent advances, current methods suffer from two critical challenges: prediction jitter across consecutive frames and poor discrimination of ambiguous phases. This paper aims to develop a stable framework by selectively propagating reliable historical information and explicitly modeling uncertainty for hard sample enhancement.\n  Methods: We propose a dual-pathway framework DSTED with Reliable Memory Propagation (RMP) and Uncertainty-Aware Prototype Retrieval (UPR). RMP maintains temporal coherence by filtering and fusing high-confidence historical features through multi-criteria reliability assessment. UPR constructs learnable class-specific prototypes from high-uncertainty samples and performs adaptive prototype matching to refine ambiguous frame representations. Finally, a confidence-driven gate dynamically balances both pathways based on prediction certainty.\n  Results: Our method achieves state-of-the-art performance on AutoLaparo-hysterectomy with 84.36% accuracy and 65.51% F1-score, surpassing the second-best method by 3.51% and 4.88% respectively. Ablations reveal complementary gains from RMP (2.19%) and UPR (1.93%), with synergistic effects when combined. Extensive analysis confirms substantial reduction in temporal jitter and marked improvement on challenging phase transitions.\n  Conclusion: Our dual-pathway design introduces a novel paradigm for stable workflow recognition, demonstrating that decoupling the modeling of temporal consistency and phase ambiguity yields superior performance and clinical applicability.",
    "published": "2025-12-22T13:36:26Z",
    "updated": "2025-12-22T13:36:26Z",
    "link": "http://arxiv.org/pdf/2512.19387v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Yueyao Chen",
      "Kai-Ni Wang",
      "Dario Tayupo",
      "Arnaud Huaulm'e",
      "Krystel Nyangoh Timoh",
      "Pierre Jannin",
      "Qi Dou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2408.11607v3",
    "title": "Networked Communication for Mean-Field Games with Function Approximation and Empirical Mean-Field Estimation",
    "summary": "Recent algorithms allow decentralised agents, possibly connected via a communication network, to learn equilibria in mean-field games from a non-episodic run of the empirical system. However, these algorithms are for tabular settings: this computationally limits the size of agents' observation space, meaning the algorithms cannot handle anything but small state spaces, nor generalise beyond policies depending only on the agent's local state to so-called 'population-dependent' policies. We address this limitation by introducing function approximation to the existing setting, drawing on the Munchausen Online Mirror Descent method that has previously been employed only in finite-horizon, episodic, centralised settings. While this permits us to include the mean field in the observation for players' policies, it is unrealistic to assume decentralised agents have access to this global information: we therefore also provide new algorithms allowing agents to locally estimate the global empirical distribution, and to improve this estimate via inter-agent communication. We prove theoretically that exchanging policy information helps networked agents outperform both independent and even centralised agents in function-approximation settings. Our experiments demonstrate this happening empirically, and show that the communication network allows decentralised agents to estimate the mean field for population-dependent policies.",
    "published": "2024-08-21T13:32:46Z",
    "updated": "2025-12-22T13:33:03Z",
    "link": "http://arxiv.org/pdf/2408.11607v3.pdf",
    "category": [
      "cs.MA",
      "cs.AI",
      "cs.GT",
      "cs.LG",
      "eess.SY"
    ],
    "authors": [
      "Patrick Benjamin",
      "Alessandro Abate"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2306.02766v6",
    "title": "Networked Communication for Decentralised Agents in Mean-Field Games",
    "summary": "Methods like multi-agent reinforcement learning struggle to scale with growing population size. Mean-field games (MFGs) are a game-theoretic approach that can circumvent this by finding a solution for an abstract infinite population, which can then be used as an approximate solution for the $N$-agent problem. However, classical mean-field algorithms usually only work under restrictive conditions. We take steps to address this by introducing networked communication to MFGs, in particular to settings that use a single, non-episodic run of $N$ decentralised agents to simulate the infinite population, as is likely to be most reasonable in real-world deployments. We prove that our architecture's sample guarantees lie between those of earlier theoretical algorithms for the centralised- and independent-learning architectures, varying dependent on network structure and the number of communication rounds. However, the sample guarantees of the three theoretical algorithms do not actually result in practical convergence times. We thus contribute practical enhancements to all three algorithms allowing us to present their first empirical demonstrations. We then show that in practical settings where the theoretical hyperparameters are not observed, giving fewer loops but poorer estimation of the Q-function, our communication scheme still respects the earlier theoretical analysis: it considerably accelerates learning over the independent case, which hardly seems to learn at all, and often performs similarly to the centralised case, while removing the restrictive assumption of the latter. We provide ablations and additional studies showing that our networked approach also has advantages over both alternatives in terms of robustness to update failures and to changes in population size.",
    "published": "2023-06-05T10:45:39Z",
    "updated": "2025-12-22T13:25:46Z",
    "link": "http://arxiv.org/pdf/2306.02766v6.pdf",
    "category": [
      "cs.MA",
      "cs.AI",
      "cs.LG",
      "cs.SI",
      "eess.SY"
    ],
    "authors": [
      "Patrick Benjamin",
      "Alessandro Abate"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19379v1",
    "title": "OmniMER: Indonesian Multimodal Emotion Recognition via Auxiliary-Enhanced LLM Adaptation",
    "summary": "Indonesian, spoken by over 200 million people, remains underserved in multimodal emotion recognition research despite its dominant presence on Southeast Asian social media platforms. We introduce IndoMER, the first multimodal emotion recognition benchmark for Indonesian, comprising 1,944 video segments from 203 speakers with temporally aligned text, audio, and visual annotations across seven emotion categories. The dataset exhibits realistic challenges including cross-modal inconsistency and long-tailed class distributions shaped by Indonesian cultural communication norms. To address these challenges, we propose OmniMER, a multimodal adaptation framework built upon Qwen2.5-Omni that enhances emotion recognition through three auxiliary modality-specific perception tasks: emotion keyword extraction for text, facial expression analysis for video, and prosody analysis for audio. These auxiliary tasks help the model identify emotion-relevant cues in each modality before fusion, reducing reliance on spurious correlations in low-resource settings. Experiments on IndoMER show that OmniMER achieves 0.582 Macro-F1 on sentiment classification and 0.454 on emotion recognition, outperforming the base model by 7.6 and 22.1 absolute points respectively. Cross-lingual evaluation on the Chinese CH-SIMS dataset further demonstrates the generalizability of the proposed framework. The dataset and code are publicly available. https://github.com/yanxm01/INDOMER",
    "published": "2025-12-22T13:23:55Z",
    "updated": "2025-12-22T13:23:55Z",
    "link": "http://arxiv.org/pdf/2512.19379v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.MM"
    ],
    "authors": [
      "Xueming Yan",
      "Boyan Xu",
      "Yaochu Jin",
      "Lixian Xiao",
      "Wenlong Ye",
      "Runyang Cai",
      "Zeqi Zheng",
      "Jingfa Liu",
      "Aimin Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19367v1",
    "title": "Sprecher Networks: A Parameter-Efficient Kolmogorov-Arnold Architecture",
    "summary": "We present Sprecher Networks (SNs), a family of trainable neural architectures inspired by the classical Kolmogorov-Arnold-Sprecher (KAS) construction for approximating multivariate continuous functions. Distinct from Multi-Layer Perceptrons (MLPs) with fixed node activations and Kolmogorov-Arnold Networks (KANs) featuring learnable edge activations, SNs utilize shared, learnable splines (monotonic and general) within structured blocks incorporating explicit shift parameters and mixing weights. Our approach directly realizes Sprecher's specific 1965 sum of shifted splines formula in its single-layer variant and extends it to deeper, multi-layer compositions. We further enhance the architecture with optional lateral mixing connections that enable intra-block communication between output dimensions, providing a parameter-efficient alternative to full attention mechanisms. Beyond parameter efficiency with $O(LN + LG)$ scaling (where $G$ is the knot count of the shared splines) versus MLPs' $O(LN^2)$, SNs admit a sequential evaluation strategy that reduces peak forward-intermediate memory from $O(N^2)$ to $O(N)$ (treating batch size as constant), making much wider architectures feasible under memory constraints. We demonstrate empirically that composing these blocks into deep networks leads to highly parameter and memory-efficient models, discuss theoretical motivations, and compare SNs with related architectures (MLPs, KANs, and networks with learnable node activations).",
    "published": "2025-12-22T13:09:45Z",
    "updated": "2025-12-22T13:09:45Z",
    "link": "http://arxiv.org/pdf/2512.19367v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "math.NA"
    ],
    "authors": [
      "Christian Hägg",
      "Kathlén Kohn",
      "Giovanni Luca Marchetti",
      "Boris Shapiro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19366v1",
    "title": "Learning General Policies with Policy Gradient Methods",
    "summary": "While reinforcement learning methods have delivered remarkable results in a number of settings, generalization, i.e., the ability to produce policies that generalize in a reliable and systematic way, has remained a challenge. The problem of generalization has been addressed formally in classical planning where provable correct policies that generalize over all instances of a given domain have been learned using combinatorial methods. The aim of this work is to bring these two research threads together to illuminate the conditions under which (deep) reinforcement learning approaches, and in particular, policy optimization methods, can be used to learn policies that generalize like combinatorial methods do. We draw on lessons learned from previous combinatorial and deep learning approaches, and extend them in a convenient way. From the former, we model policies as state transition classifiers, as (ground) actions are not general and change from instance to instance. From the latter, we use graph neural networks (GNNs) adapted to deal with relational structures for representing value functions over planning states, and in our case, policies. With these ingredients in place, we find that actor-critic methods can be used to learn policies that generalize almost as well as those obtained using combinatorial approaches while avoiding the scalability bottleneck and the use of feature pools. Moreover, the limitations of the DRL methods on the benchmarks considered have little to do with deep learning or reinforcement learning algorithms, and result from the well-understood expressive limitations of GNNs, and the tradeoff between optimality and generalization (general policies cannot be optimal in some domains). Both of these limitations are addressed without changing the basic DRL methods by adding derived predicates and an alternative cost structure to optimize.",
    "published": "2025-12-22T13:08:58Z",
    "updated": "2025-12-22T13:08:58Z",
    "link": "http://arxiv.org/pdf/2512.19366v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Simon Ståhlberg",
      "Blai Bonet",
      "Hector Geffner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19355v1",
    "title": "First-Order Representation Languages for Goal-Conditioned RL",
    "summary": "First-order relational languages have been used in MDP planning and reinforcement learning (RL) for two main purposes: specifying MDPs in compact form, and representing and learning policies that are general and not tied to specific instances or state spaces. In this work, we instead consider the use of first-order languages in goal-conditioned RL and generalized planning. The question is how to learn goal-conditioned and general policies when the training instances are large and the goal cannot be reached by random exploration alone. The technique of Hindsight Experience Replay (HER) provides an answer to this question: it relabels unsuccessful trajectories as successful ones by replacing the original goal with one that was actually achieved. If the target policy must generalize across states and goals, trajectories that do not reach the original goal states can enable more data- and time-efficient learning. In this work, we show that further performance gains can be achieved when states and goals are represented by sets of atoms. We consider three versions: goals as full states, goals as subsets of the original goals, and goals as lifted versions of these subgoals. The result is that the latter two successfully learn general policies on large planning instances with sparse rewards by automatically creating a curriculum of easier goals of increasing complexity. The experiments illustrate the computational gains of these versions, their limitations, and opportunities for addressing them.",
    "published": "2025-12-22T12:54:32Z",
    "updated": "2025-12-22T12:54:32Z",
    "link": "http://arxiv.org/pdf/2512.19355v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Simon Ståhlberg",
      "Hector Geffner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19350v1",
    "title": "PENDULUM: A Benchmark for Assessing Sycophancy in Multimodal Large Language Models",
    "summary": "Sycophancy, an excessive tendency of AI models to agree with user input at the expense of factual accuracy or in contradiction of visual evidence, poses a critical and underexplored challenge for multimodal large language models (MLLMs). While prior studies have examined this behavior in text-only settings of large language models, existing research on visual or multimodal counterparts remains limited in scope and depth of analysis. To address this gap, we introduce a comprehensive evaluation benchmark, \\textit{PENDULUM}, comprising approximately 2,000 human-curated Visual Question Answering pairs specifically designed to elicit sycophantic responses. The benchmark spans six distinct image domains of varying complexity, enabling a systematic investigation of how image type and inherent challenges influence sycophantic tendencies. Through extensive evaluation of state-of-the-art MLLMs. we observe substantial variability in model robustness and a pronounced susceptibility to sycophantic and hallucinatory behavior. Furthermore, we propose novel metrics to quantify sycophancy in visual reasoning, offering deeper insights into its manifestations across different multimodal contexts. Our findings highlight the urgent need for developing sycophancy-resilient architectures and training strategies to enhance factual consistency and reliability in future MLLMs. Our proposed dataset with MLLMs response are available at https://github.com/ashikiut/pendulum/.",
    "published": "2025-12-22T12:49:12Z",
    "updated": "2025-12-22T12:49:12Z",
    "link": "http://arxiv.org/pdf/2512.19350v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "A. B. M. Ashikur Rahman",
      "Saeed Anwar",
      "Muhammad Usman",
      "Irfan Ahmad",
      "Ajmal Mian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.02864v3",
    "title": "Mathematical exploration and discovery at scale",
    "summary": "AlphaEvolve (Novikov et al., 2025) is a generic evolutionary coding agent that combines the generative capabilities of LLMs with automated evaluation in an iterative evolutionary framework that proposes, tests, and refines algorithmic solutions to challenging scientific and practical problems. In this paper we showcase AlphaEvolve as a tool for autonomously discovering novel mathematical constructions and advancing our understanding of long-standing open problems.\n  To demonstrate its breadth, we considered a list of 67 problems spanning mathematical analysis, combinatorics, geometry, and number theory. The system rediscovered the best known solutions in most of the cases and discovered improved solutions in several. In some instances, AlphaEvolve is also able to generalize results for a finite number of input values into a formula valid for all input values. Furthermore, we are able to combine this methodology with Deep Think and AlphaProof in a broader framework where the additional proof-assistants and reasoning systems provide automated proof generation and further mathematical insights.\n  These results demonstrate that large language model-guided evolutionary search can autonomously discover mathematical constructions that complement human intuition, at times matching or even improving the best known results, highlighting the potential for significant new ways of interaction between mathematicians and AI systems. We present AlphaEvolve as a powerful new tool for mathematical discovery, capable of exploring vast search spaces to solve complex optimization problems at scale, often with significantly reduced requirements on preparation and computation time.",
    "published": "2025-11-03T16:04:07Z",
    "updated": "2025-12-22T12:49:01Z",
    "link": "http://arxiv.org/pdf/2511.02864v3.pdf",
    "category": [
      "cs.NE",
      "cs.AI",
      "math.CA",
      "math.CO",
      "math.MG"
    ],
    "authors": [
      "Bogdan Georgiev",
      "Javier Gómez-Serrano",
      "Terence Tao",
      "Adam Zsolt Wagner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19349v1",
    "title": "VIGOR+: Iterative Confounder Generation and Validation via LLM-CEVAE Feedback Loop",
    "summary": "Hidden confounding remains a fundamental challenge in causal inference from observational data. Recent advances leverage Large Language Models (LLMs) to generate plausible hidden confounders based on domain knowledge, yet a critical gap exists: LLM-generated confounders often exhibit semantic plausibility without statistical utility. We propose VIGOR+ (Variational Information Gain for iterative cOnfounder Refinement), a novel framework that closes the loop between LLM-based confounder generation and CEVAE-based statistical validation. Unlike prior approaches that treat generation and validation as separate stages, VIGOR+ establishes an iterative feedback mechanism: validation signals from CEVAE (including information gain, latent consistency metrics, and diagnostic messages) are transformed into natural language feedback that guides subsequent LLM generation rounds. This iterative refinement continues until convergence criteria are met. We formalize the feedback mechanism, prove convergence properties under mild assumptions, and provide a complete algorithmic framework.",
    "published": "2025-12-22T12:48:29Z",
    "updated": "2025-12-22T12:48:29Z",
    "link": "http://arxiv.org/pdf/2512.19349v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "JiaWei Zhu",
      "ZiHeng Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.14579v2",
    "title": "GSRender: Deduplicated Occupancy Prediction via Weakly Supervised 3D Gaussian Splatting",
    "summary": "Weakly-supervised 3D occupancy perception is crucial for vision-based autonomous driving in outdoor environments. Previous methods based on NeRF often face a challenge in balancing the number of samples used. Too many samples can decrease efficiency, while too few can compromise accuracy, leading to variations in the mean Intersection over Union (mIoU) by 5-10 points. Furthermore, even with surrounding-view image inputs, only a single image is rendered from each viewpoint at any given moment. This limitation leads to duplicated predictions, which significantly impacts the practicality of the approach. However, this issue has largely been overlooked in existing research. To address this, we propose GSRender, which uses 3D Gaussian Splatting for weakly-supervised occupancy estimation, simplifying the sampling process. Additionally, we introduce the Ray Compensation module, which reduces duplicated predictions by compensating for features from adjacent frames. Finally, we redesign the dynamic loss to remove the influence of dynamic objects from adjacent frames. Extensive experiments show that our approach achieves SOTA results in RayIoU (+6.0), while also narrowing the gap with 3D- supervised methods. This work lays a solid foundation for weakly-supervised occupancy perception. The code is available at https://github.com/Jasper-sudo-Sun/GSRender.",
    "published": "2024-12-19T06:57:37Z",
    "updated": "2025-12-22T12:47:43Z",
    "link": "http://arxiv.org/pdf/2412.14579v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Qianpu Sun",
      "Changyong Shu",
      "Sifan Zhou",
      "Runxi Cheng",
      "Yongxian Wei",
      "Zichen Yu",
      "Dawei Yang",
      "Sirui Han",
      "Yuan Chun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.10713v2",
    "title": "PACIFIC: a framework for generating benchmarks to check Precise Automatically Checked Instruction Following In Code",
    "summary": "Large Language Model (LLM)-based code assistants have emerged as a powerful application of generative AI, demonstrating impressive capabilities in code generation and comprehension. A key requirement for these systems is their ability to accurately follow user instructions. We present Precise Automatically Checked Instruction Following In Code (PACIFIC), a novel framework designed to automatically generate benchmarks that rigorously assess sequential instruction-following and code dry-running capabilities in LLMs, while allowing control over benchmark difficulty. PACIFIC produces benchmark variants with clearly defined expected outputs, enabling straightforward and reliable evaluation through simple output comparisons. In contrast to existing approaches that often rely on tool usage or agentic behavior, our work isolates and evaluates the LLM's intrinsic ability to reason through code behavior step-by-step without execution (dry running) and to follow instructions. Furthermore, our framework mitigates training data contamination by facilitating effortless generation of novel benchmark variations. We validate our framework by generating a suite of benchmarks spanning a range of difficulty levels and evaluating multiple state-of-the-art LLMs. Our results demonstrate that PACIFIC can produce increasingly challenging benchmarks that effectively differentiate instruction-following and dry running capabilities, even among advanced models. Overall, our framework offers a scalable, contamination-resilient methodology for assessing core competencies of LLMs in code-related tasks.",
    "published": "2025-12-11T14:49:56Z",
    "updated": "2025-12-22T12:47:11Z",
    "link": "http://arxiv.org/pdf/2512.10713v2.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Itay Dreyfuss",
      "Antonio Abu Nassar",
      "Samuel Ackerman",
      "Axel Ben David",
      "Eitan Farchi",
      "Rami Katan",
      "Orna Raz",
      "Marcel Zalmanovici"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.04978v4",
    "title": "Aligning Perception, Reasoning, Modeling and Interaction: A Survey on Physical AI",
    "summary": "The rapid advancement of embodied intelligence and world models has intensified efforts to integrate physical laws into AI systems, yet physical perception and symbolic physics reasoning have developed along separate trajectories without a unified bridging framework. This work provides a comprehensive overview of physical AI, establishing clear distinctions between theoretical physics reasoning and applied physical understanding while systematically examining how physics-grounded methods enhance AI's real-world comprehension across structured symbolic reasoning, embodied systems, and generative models. Through rigorous analysis of recent advances, we advocate for intelligent systems that ground learning in both physical principles and embodied reasoning processes, transcending pattern recognition toward genuine understanding of physical laws. Our synthesis envisions next-generation world models capable of explaining physical phenomena and predicting future states, advancing safe, generalizable, and interpretable AI systems. We maintain a continuously updated resource at https://github.com/AI4Phys/Awesome-AI-for-Physics.",
    "published": "2025-10-06T16:16:03Z",
    "updated": "2025-12-22T12:44:21Z",
    "link": "http://arxiv.org/pdf/2510.04978v4.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Kun Xiang",
      "Terry Jingchen Zhang",
      "Yinya Huang",
      "Jixi He",
      "Zirong Liu",
      "Yueling Tang",
      "Ruizhe Zhou",
      "Lijing Luo",
      "Youpeng Wen",
      "Xiuwei Chen",
      "Bingqian Lin",
      "Jianhua Han",
      "Hang Xu",
      "Hanhui Li",
      "Bin Dong",
      "Xiaodan Liang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.07984v3",
    "title": "Restrictive Hierarchical Semantic Segmentation for Stratified Tooth Layer Detection",
    "summary": "Accurate understanding of anatomical structures is essential for reliably staging certain dental diseases. A way of introducing this within semantic segmentation models is by utilising hierarchy-aware methodologies. However, existing hierarchy-aware segmentation methods largely encode anatomical structure through the loss functions, providing weak and indirect supervision. We introduce a general framework that embeds an explicit anatomical hierarchy into semantic segmentation by coupling a recurrent, level-wise prediction scheme with restrictive output heads and top-down feature conditioning. At each depth of the class tree, the backbone is re-run on the original image concatenated with logits from the previous level. Child class features are conditioned using Feature-wise Linear Modulation of their parent class probabilities, to modulate child feature spaces for fine grained detection. A probabilistic composition rule enforces consistency between parent and descendant classes. Hierarchical loss combines per-level class weighted Dice and cross entropy loss and a consistency term loss, ensuring parent predictions are the sum of their children. We validate our approach on our proposed dataset, TL-pano, containing 194 panoramic radiographs with dense instance and semantic segmentation annotations, of tooth layers and alveolar bone. Utilising UNet and HRNet as donor models across a 5-fold cross validation scheme, the hierarchical variants consistently increase IoU, Dice, and recall, particularly for fine-grained anatomies, and produce more anatomically coherent masks. However, hierarchical variants also demonstrated increased recall over precision, implying increased false positives. The results demonstrate that explicit hierarchical structuring improves both performance and clinical plausibility, especially in low data dental imaging regimes.",
    "published": "2025-12-08T19:15:08Z",
    "updated": "2025-12-22T12:27:35Z",
    "link": "http://arxiv.org/pdf/2512.07984v3.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Ryan Banks",
      "Camila Lindoni Azevedo",
      "Hongying Tang",
      "Yunpeng Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19323v1",
    "title": "Alternative positional encoding functions for neural transformers",
    "summary": "A key module in neural transformer-based deep architectures is positional encoding. This module enables a suitable way to encode positional information as input for transformer neural layers. This success has been rooted in the use of sinusoidal functions of various frequencies, in order to capture recurrent patterns of differing typical periods. In this work, an alternative set of periodic functions is proposed for positional encoding. These functions preserve some key properties of sinusoidal ones, while they depart from them in fundamental ways. Some tentative experiments are reported, where the original sinusoidal version is substantially outperformed. This strongly suggests that the alternative functions may have a wider use in other transformer architectures.",
    "published": "2025-12-22T12:17:47Z",
    "updated": "2025-12-22T12:17:47Z",
    "link": "http://arxiv.org/pdf/2512.19323v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Ezequiel Lopez-Rubio",
      "Macoris Decena-Gimenez",
      "Rafael Marcos Luque-Baena"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19320v1",
    "title": "MAGIC: Achieving Superior Model Merging via Magnitude Calibration",
    "summary": "The proliferation of pre-trained models has given rise to a wide array of specialised, fine-tuned models. Model merging aims to merge the distinct capabilities of these specialised models into a unified model, requiring minimal or even no additional training. A core objective of model merging is to ensure the merged model retains the behavioural characteristics of the specialised models, typically achieved through feature alignment. We identify that features consist of two critical components: direction and magnitude. Prior research has predominantly focused on directional alignment, while the influence of magnitude remains largely neglected, despite its pronounced vulnerability to perturbations introduced by common merging operations (e.g., parameter fusion and sparsification). Such perturbations to magnitude inevitably lead to feature deviations in the merged model from the specialised models, resulting in subsequent performance degradation. To address this, we propose MAGnItude Calibration (MAGIC), a plug-and-play framework that rectifies layer-wise magnitudes in feature and weight spaces, with three variants. Specifically, our Feature Space Calibration (FSC) realigns the merged model's features using a small set of unlabelled data, while Weight Space Calibration (WSC) extends this calibration to the weight space without requiring additional data. Combining these yields Dual Space Calibration (DSC). Comprehensive experiments demonstrate that MAGIC consistently boosts performance across diverse Computer Vision tasks (+4.3% on eight datasets) and NLP tasks (+8.0% on Llama) without additional training. Our code is available at: https://github.com/lyymuwu/MAGIC",
    "published": "2025-12-22T12:13:17Z",
    "updated": "2025-12-22T12:13:17Z",
    "link": "http://arxiv.org/pdf/2512.19320v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "authors": [
      "Yayuan Li",
      "Jian Zhang",
      "Jintao Guo",
      "Zihan Cheng",
      "Lei Qi",
      "Yinghuan Shi",
      "Yang Gao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19317v1",
    "title": "SafeMed-R1: Adversarial Reinforcement Learning for Generalizable and Robust Medical Reasoning in Vision-Language Models",
    "summary": "Vision--Language Models (VLMs) show significant promise for Medical Visual Question Answering (VQA), yet their deployment in clinical settings is hindered by severe vulnerability to adversarial attacks. Standard adversarial training, while effective for simpler tasks, often degrades both generalization performance and the quality of generated clinical reasoning. We introduce SafeMed-R1, a hybrid defense framework that ensures robust performance while preserving high-quality, interpretable medical reasoning. SafeMed-R1 employs a two-stage approach: at training time, we integrate Adversarial Training with Group Relative Policy Optimization (AT-GRPO) to explicitly robustify the reasoning process against worst-case perturbations; at inference time, we augment the model with Randomized Smoothing to provide certified $L_2$-norm robustness guarantees. We evaluate SafeMed-R1 on the OmniMedVQA benchmark across eight medical imaging modalities comprising over 88,000 samples. Our experiments reveal that standard fine-tuned VLMs, despite achieving 95\\% accuracy on clean inputs, collapse to approximately 25\\% under PGD attacks. In contrast, SafeMed-R1 maintains 84.45\\% accuracy under the same adversarial conditions, representing a 59 percentage point improvement in robustness. Furthermore, we demonstrate that models trained with explicit chain-of-thought reasoning exhibit superior adversarial robustness compared to instruction-only variants, suggesting a synergy between interpretability and security in medical AI systems.",
    "published": "2025-12-22T12:07:33Z",
    "updated": "2025-12-22T12:07:33Z",
    "link": "http://arxiv.org/pdf/2512.19317v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "A. A. Gde Yogi Pramana",
      "Jason Ray",
      "Anthony Jaya",
      "Michael Wijaya"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19311v1",
    "title": "MixFlow Training: Alleviating Exposure Bias with Slowed Interpolation Mixture",
    "summary": "This paper studies the training-testing discrepancy (a.k.a. exposure bias) problem for improving the diffusion models. During training, the input of a prediction network at one training timestep is the corresponding ground-truth noisy data that is an interpolation of the noise and the data, and during testing, the input is the generated noisy data. We present a novel training approach, named MixFlow, for improving the performance. Our approach is motivated by the Slow Flow phenomenon: the ground-truth interpolation that is the nearest to the generated noisy data at a given sampling timestep is observed to correspond to a higher-noise timestep (termed slowed timestep), i.e., the corresponding ground-truth timestep is slower than the sampling timestep. MixFlow leverages the interpolations at the slowed timesteps, named slowed interpolation mixture, for post-training the prediction network for each training timestep. Experiments over class-conditional image generation (including SiT, REPA, and RAE) and text-to-image generation validate the effectiveness of our approach. Our approach MixFlow over the RAE models achieve strong generation results on ImageNet: 1.43 FID (without guidance) and 1.10 (with guidance) at 256 x 256, and 1.55 FID (without guidance) and 1.10 (with guidance) at 512 x 512.",
    "published": "2025-12-22T12:00:12Z",
    "updated": "2025-12-22T12:00:12Z",
    "link": "http://arxiv.org/pdf/2512.19311v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Hui Li",
      "Jiayue Lyu",
      "Fu-Yun Wang",
      "Kaihui Cheng",
      "Siyu Zhu",
      "Jingdong Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.04521v2",
    "title": "Dynamic Pricing for On-Demand DNN Inference in the Edge-AI Market",
    "summary": "The convergence of edge computing and Artificial Intelligence (AI) gives rise to Edge-AI, which enables the deployment of real-time AI applications at the network edge. A key research challenge in Edge-AI is edge inference acceleration, which aims to realize low-latency high-accuracy Deep Neural Network (DNN) inference by offloading partitioned inference tasks from end devices to edge servers. However, existing research has yet to adopt a practical Edge-AI market perspective, which would explore the personalized inference needs of AI users (e.g., inference accuracy, latency, and task complexity), the revenue incentives for AI service providers that offer edge inference services, and multi-stakeholder governance within a market-oriented context. To bridge this gap, we propose an Auction-based Edge Inference Pricing Mechanism (AERIA) for revenue maximization to tackle the multi-dimensional optimization problem of DNN model partition, edge inference pricing, and resource allocation. We develop a multi-exit device-edge synergistic inference scheme for on-demand DNN inference acceleration, and theoretically analyze the auction dynamics amongst the AI service providers, AI users and edge infrastructure provider. Owing to the strategic mechanism design via randomized consensus estimate and cost sharing techniques, the Edge-AI market attains several desirable properties. These include competitiveness in revenue maximization, incentive compatibility, and envy-freeness, which are crucial to maintain the effectiveness, truthfulness, and fairness in auction outcomes. Extensive simulations based on four representative DNN inference workloads demonstrate that AERIA significantly outperforms several state-of-the-art approaches in revenue maximization. This validates the efficacy of AERIA for on-demand DNN inference in the Edge-AI market.",
    "published": "2025-03-06T15:08:31Z",
    "updated": "2025-12-22T11:48:52Z",
    "link": "http://arxiv.org/pdf/2503.04521v2.pdf",
    "category": [
      "cs.AI",
      "cs.CE",
      "cs.DC",
      "cs.SE"
    ],
    "authors": [
      "Songyuan Li",
      "Jia Hu",
      "Geyong Min",
      "Haojun Huang",
      "Jiwei Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19299v1",
    "title": "Helios: A Foundational Language Model for Smart Energy Knowledge Reasoning and Application",
    "summary": "In the global drive toward carbon neutrality, deeply coordinated smart energy systems underpin industrial transformation. However, the interdisciplinary, fragmented, and fast-evolving expertise in this domain prevents general-purpose LLMs, which lack domain knowledge and physical-constraint awareness, from delivering precise engineering-aligned inference and generation. To address these challenges, we introduce Helios, a large language model tailored to the smart energy domain, together with a comprehensive suite of resources to advance LLM research in this field. Specifically, we develop Enersys, a multi-agent collaborative framework for end-to-end dataset construction, through which we produce: (1) a smart energy knowledge base, EnerBase, to enrich the model's foundational expertise; (2) an instruction fine-tuning dataset, EnerInstruct, to strengthen performance on domain-specific downstream tasks; and (3) an RLHF dataset, EnerReinforce, to align the model with human preferences and industry standards. Leveraging these resources, Helios undergoes large-scale pretraining, SFT, and RLHF. We also release EnerBench, a benchmark for evaluating LLMs in smart energy scenarios, and demonstrate that our approach significantly enhances domain knowledge mastery, task execution accuracy, and alignment with human preferences.",
    "published": "2025-12-22T11:43:35Z",
    "updated": "2025-12-22T11:43:35Z",
    "link": "http://arxiv.org/pdf/2512.19299v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Haoyu Jiang",
      "Fanjie Zeng",
      "Boan Qu",
      "Xiaojie Lin",
      "Wei Zhong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19297v1",
    "title": "Causal-Guided Detoxify Backdoor Attack of Open-Weight LoRA Models",
    "summary": "Low-Rank Adaptation (LoRA) has emerged as an efficient method for fine-tuning large language models (LLMs) and is widely adopted within the open-source community. However, the decentralized dissemination of LoRA adapters through platforms such as Hugging Face introduces novel security vulnerabilities: malicious adapters can be easily distributed and evade conventional oversight mechanisms. Despite these risks, backdoor attacks targeting LoRA-based fine-tuning remain relatively underexplored. Existing backdoor attack strategies are ill-suited to this setting, as they often rely on inaccessible training data, fail to account for the structural properties unique to LoRA, or suffer from high false trigger rates (FTR), thereby compromising their stealth. To address these challenges, we propose Causal-Guided Detoxify Backdoor Attack (CBA), a novel backdoor attack framework specifically designed for open-weight LoRA models. CBA operates without access to original training data and achieves high stealth through two key innovations: (1) a coverage-guided data generation pipeline that synthesizes task-aligned inputs via behavioral exploration, and (2) a causal-guided detoxification strategy that merges poisoned and clean adapters by preserving task-critical neurons. Unlike prior approaches, CBA enables post-training control over attack intensity through causal influence-based weight allocation, eliminating the need for repeated retraining. Evaluated across six LoRA models, CBA achieves high attack success rates while reducing FTR by 50-70\\% compared to baseline methods. Furthermore, it demonstrates enhanced resistance to state-of-the-art backdoor defenses, highlighting its stealth and robustness.",
    "published": "2025-12-22T11:40:47Z",
    "updated": "2025-12-22T11:40:47Z",
    "link": "http://arxiv.org/pdf/2512.19297v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Linzhi Chen",
      "Yang Sun",
      "Hongru Wei",
      "Yuqi Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.12489v2",
    "title": "A Comprehensive Survey on Generative AI for Video-to-Music Generation",
    "summary": "The burgeoning growth of video-to-music generation can be attributed to the ascendancy of multimodal generative models. However, there is a lack of literature that comprehensively combs through the work in this field. To fill this gap, this paper presents a comprehensive review of video-to-music generation using deep generative AI techniques, focusing on three key components: conditioning input construction, conditioning mechanism, and music generation frameworks. We categorize existing approaches based on their designs for each component, clarifying the roles of different strategies. Preceding this, we provide a fine-grained categorization of video and music modalities, illustrating how different categories influence the design of components within the generation pipelines. Furthermore, we summarize available multimodal datasets and evaluation metrics while highlighting ongoing challenges in the field.",
    "published": "2025-02-18T03:18:54Z",
    "updated": "2025-12-22T11:32:28Z",
    "link": "http://arxiv.org/pdf/2502.12489v2.pdf",
    "category": [
      "eess.AS",
      "cs.AI",
      "cs.MM"
    ],
    "authors": [
      "Shulei Ji",
      "Songruoyao Wu",
      "Zihao Wang",
      "Shuyu Li",
      "Kejun Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19287v1",
    "title": "Vibe Reasoning: Eliciting Frontier AI Mathematical Capabilities -- A Case Study on IMO 2025 Problem 6",
    "summary": "We introduce Vibe Reasoning, a human-AI collaborative paradigm for solving complex mathematical problems. Our key insight is that frontier AI models already possess the knowledge required to solve challenging problems -- they simply do not know how, what, or when to apply it. Vibe Reasoning transforms AI's latent potential into manifested capability through generic meta-prompts, agentic grounding, and model orchestration. We demonstrate this paradigm through IMO 2025 Problem 6, a combinatorial optimization problem where autonomous AI systems publicly reported failures. Our solution combined GPT-5's exploratory capabilities with Gemini 3 Pro's proof strengths, leveraging agentic workflows with Python code execution and file-based memory, to derive both the correct answer (2112) and a rigorous mathematical proof. Through iterative refinement across multiple attempts, we discovered the necessity of agentic grounding and model orchestration, while human prompts evolved from problem-specific hints to generic, transferable meta-prompts. We analyze why capable AI fails autonomously, how each component addresses specific failure modes, and extract principles for effective vibe reasoning. Our findings suggest that lightweight human guidance can unlock frontier models' mathematical reasoning potential. This is ongoing work; we are developing automated frameworks and conducting broader evaluations to further validate Vibe Reasoning's generality and effectiveness.",
    "published": "2025-12-22T11:30:19Z",
    "updated": "2025-12-22T11:30:19Z",
    "link": "http://arxiv.org/pdf/2512.19287v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Jiaao Wu",
      "Xian Zhang",
      "Fan Yang",
      "Yinpeng Dong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19280v1",
    "title": "Digital Twin-Driven Zero-Shot Fault Diagnosis of Axial Piston Pumps Using Fluid-Borne Noise Signals",
    "summary": "Axial piston pumps are crucial components in fluid power systems, where reliable fault diagnosis is essential for ensuring operational safety and efficiency. Traditional data-driven methods require extensive labeled fault data, which is often impractical to obtain, while model-based approaches suffer from parameter uncertainties. This paper proposes a digital twin (DT)-driven zero-shot fault diagnosis framework utilizing fluid-borne noise (FBN) signals. The framework calibrates a high-fidelity DT model using only healthy-state data, generates synthetic fault signals for training deep learning classifiers, and employs a physics-informed neural network (PINN) as a virtual sensor for flow ripple estimation. Gradient-weighted class activation mapping (Grad-CAM) is integrated to visualize the decision-making process of neural networks, revealing that large kernels matching the subsequence length in time-domain inputs and small kernels in time-frequency domain inputs enable higher diagnostic accuracy by focusing on physically meaningful features. Experimental validations demonstrate that training on signals from the calibrated DT model yields diagnostic accuracies exceeding 95\\% on real-world benchmarks, while uncalibrated models result in significantly lower performance, highlighting the framework's effectiveness in data-scarce scenarios.",
    "published": "2025-12-22T11:24:42Z",
    "updated": "2025-12-22T11:24:42Z",
    "link": "http://arxiv.org/pdf/2512.19280v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Chang Dong",
      "Jianfeng Tao",
      "Chengliang Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19275v1",
    "title": "Is Visual Realism Enough? Evaluating Gait Biometric Fidelity in Generative AI Human Animation",
    "summary": "Generative AI (GenAI) models have revolutionized animation, enabling the synthesis of humans and motion patterns with remarkable visual fidelity. However, generating truly realistic human animation remains a formidable challenge, where even minor inconsistencies can make a subject appear unnatural. This limitation is particularly critical when AI-generated videos are evaluated for behavioral biometrics, where subtle motion cues that define identity are easily lost or distorted. The present study investigates whether state-of-the-art GenAI human animation models can preserve the subtle spatio-temporal details needed for person identification through gait biometrics. Specifically, we evaluate four different GenAI models across two primary evaluation tasks to assess their ability to i) restore gait patterns from reference videos under varying conditions of complexity, and ii) transfer these gait patterns to different visual identities. Our results show that while visual quality is mostly high, biometric fidelity remains low in tasks focusing on identification, suggesting that current GenAI models struggle to disentangle identity from motion. Furthermore, through an identity transfer task, we expose a fundamental flaw in appearance-based gait recognition: when texture is disentangled from motion, identification collapses, proving current GenAI models rely on visual attributes rather than temporal dynamics.",
    "published": "2025-12-22T11:19:46Z",
    "updated": "2025-12-22T11:19:46Z",
    "link": "http://arxiv.org/pdf/2512.19275v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Ivan DeAndres-Tame",
      "Chengwei Ye",
      "Ruben Tolosana",
      "Ruben Vera-Rodriguez",
      "Shiqi Yu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.16301v2",
    "title": "Adaptation of Agentic AI",
    "summary": "Cutting-edge agentic AI systems are built on foundation models that can be adapted to plan, reason, and interact with external tools to perform increasingly complex and specialized tasks. As these systems grow in capability and scope, adaptation becomes a central mechanism for improving performance, reliability, and generalization. In this paper, we unify the rapidly expanding research landscape into a systematic framework that spans both agent adaptations and tool adaptations. We further decompose these into tool-execution-signaled and agent-output-signaled forms of agent adaptation, as well as agent-agnostic and agent-supervised forms of tool adaptation. We demonstrate that this framework helps clarify the design space of adaptation strategies in agentic AI, makes their trade-offs explicit, and provides practical guidance for selecting or switching among strategies during system design. We then review the representative approaches in each category, analyze their strengths and limitations, and highlight key open challenges and future opportunities. Overall, this paper aims to offer a conceptual foundation and practical roadmap for researchers and practitioners seeking to build more capable, efficient, and reliable agentic AI systems.",
    "published": "2025-12-18T08:38:51Z",
    "updated": "2025-12-22T11:05:54Z",
    "link": "http://arxiv.org/pdf/2512.16301v2.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Pengcheng Jiang",
      "Jiacheng Lin",
      "Zhiyi Shi",
      "Zifeng Wang",
      "Luxi He",
      "Yichen Wu",
      "Ming Zhong",
      "Peiyang Song",
      "Qizheng Zhang",
      "Heng Wang",
      "Xueqiang Xu",
      "Hanwen Xu",
      "Pengrui Han",
      "Dylan Zhang",
      "Jiashuo Sun",
      "Chaoqi Yang",
      "Kun Qian",
      "Tian Wang",
      "Changran Hu",
      "Manling Li",
      "Quanzheng Li",
      "Hao Peng",
      "Sheng Wang",
      "Jingbo Shang",
      "Chao Zhang",
      "Jiaxuan You",
      "Liyuan Liu",
      "Pan Lu",
      "Yu Zhang",
      "Heng Ji",
      "Yejin Choi",
      "Dawn Song",
      "Jimeng Sun",
      "Jiawei Han"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.10035v2",
    "title": "FastFLUX: Pruning FLUX with Block-wise Replacement and Sandwich Training",
    "summary": "Recent advancements in text-to-image (T2I) generation have led to the emergence of highly expressive models such as diffusion transformers (DiTs), exemplified by FLUX. However, their massive parameter sizes lead to slow inference, high memory usage, and poor deployability. Existing acceleration methods (e.g., single-step distillation and attention pruning) often suffer from significant performance degradation and incur substantial training costs. To address these limitations, we propose FastFLUX, an architecture-level pruning framework designed to enhance the inference efficiency of FLUX. At its core is the Block-wise Replacement with Linear Layers (BRLL) method, which replaces structurally complex residual branches in ResBlocks with lightweight linear layers while preserving the original shortcut connections for stability. Furthermore, we introduce Sandwich Training (ST), a localized fine-tuning strategy that leverages LoRA to supervise neighboring blocks, mitigating performance drops caused by structural replacement. Experiments show that our FastFLUX maintains high image quality under both qualitative and quantitative evaluations, while significantly improving inference speed, even with 20\\% of the hierarchy pruned. Our code will be available soon.",
    "published": "2025-06-10T20:48:30Z",
    "updated": "2025-12-22T10:46:52Z",
    "link": "http://arxiv.org/pdf/2506.10035v2.pdf",
    "category": [
      "cs.GR",
      "cs.AI"
    ],
    "authors": [
      "Fuhan Cai",
      "Yong Guo",
      "Jie Li",
      "Wenbo Li",
      "Jian Chen",
      "Xiangzhong Fang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.17860v4",
    "title": "Towards Facilitated Fairness Assessment of AI-based Skin Lesion Classifiers Through GenAI-based Image Synthesis",
    "summary": "Recent advances in deep learning and on-device inference could transform routine screening for skin cancers. Along with the anticipated benefits of this technology, potential dangers arise from unforeseen and inherent biases. A significant obstacle is building evaluation datasets that accurately reflect key demographics, including sex, age, and race, as well as other underrepresented groups. To address this, we train a state-of-the-art generative model to generate synthetic data in a controllable manner to assess the fairness of publicly available skin cancer classifiers. To evaluate whether synthetic images can be used as a fairness testing dataset, we prepare a real-image dataset (MILK10K) as a benchmark and compare the True Positive Rate result of three models (DeepGuide, MelaNet, and SkinLesionDensnet). As a result, the classification tendencies observed in each model when tested on real and generated images showed similar patterns across different attribute data sets. We confirm that highly realistic synthetic images facilitate model fairness verification.",
    "published": "2025-07-23T18:33:27Z",
    "updated": "2025-12-22T10:41:08Z",
    "link": "http://arxiv.org/pdf/2507.17860v4.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Ko Watanabe",
      "Stanislav Frolov",
      "Aya Hassan",
      "David Dembinsky",
      "Adriano Lucieri",
      "Andreas Dengel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19253v1",
    "title": "Machine Unlearning in the Era of Quantum Machine Learning: An Empirical Study",
    "summary": "We present the first comprehensive empirical study of machine unlearning (MU) in hybrid quantum-classical neural networks. While MU has been extensively explored in classical deep learning, its behavior within variational quantum circuits (VQCs) and quantum-augmented architectures remains largely unexplored. First, we adapt a broad suite of unlearning methods to quantum settings, including gradient-based, distillation-based, regularization-based and certified techniques. Second, we introduce two new unlearning strategies tailored to hybrid models. Experiments across Iris, MNIST, and Fashion-MNIST, under both subset removal and full-class deletion, reveal that quantum models can support effective unlearning, but outcomes depend strongly on circuit depth, entanglement structure, and task complexity. Shallow VQCs display high intrinsic stability with minimal memorization, whereas deeper hybrid models exhibit stronger trade-offs between utility, forgetting strength, and alignment with retrain oracle. We find that certain methods, e.g. EU-k, LCA, and Certified Unlearning, consistently provide the best balance across metrics. These findings establish baseline empirical insights into quantum machine unlearning and highlight the need for quantum-aware algorithms and theoretical guarantees, as quantum machine learning systems continue to expand in scale and capability. We publicly release our code at: https://github.com/CrivoiCarla/HQML.",
    "published": "2025-12-22T10:40:03Z",
    "updated": "2025-12-22T10:40:03Z",
    "link": "http://arxiv.org/pdf/2512.19253v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Carla Crivoi",
      "Radu Tudor Ionescu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.16280v2",
    "title": "Love, Lies, and Language Models: Investigating AI's Role in Romance-Baiting Scams",
    "summary": "Romance-baiting scams have become a major source of financial and emotional harm worldwide. These operations are run by organized crime syndicates that traffic thousands of people into forced labor, requiring them to build emotional intimacy with victims over weeks of text conversations before pressuring them into fraudulent cryptocurrency investments. Because the scams are inherently text-based, they raise urgent questions about the role of Large Language Models (LLMs) in both current and future automation.\n  We investigate this intersection by interviewing 145 insiders and 5 scam victims, performing a blinded long-term conversation study comparing LLM scam agents to human operators, and executing an evaluation of commercial safety filters. Our findings show that LLMs are already widely deployed within scam organizations, with 87% of scam labor consisting of systematized conversational tasks readily susceptible to automation. In a week-long study, an LLM agent not only elicited greater trust from study participants (p=0.007) but also achieved higher compliance with requests than human operators (46% vs. 18% for humans). Meanwhile, popular safety filters detected 0.0% of romance baiting dialogues. Together, these results suggest that romance-baiting scams may be amenable to full-scale LLM automation, while existing defenses remain inadequate to prevent their expansion.",
    "published": "2025-12-18T07:59:15Z",
    "updated": "2025-12-22T10:37:08Z",
    "link": "http://arxiv.org/pdf/2512.16280v2.pdf",
    "category": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "authors": [
      "Gilad Gressel",
      "Rahul Pankajakshan",
      "Shir Rozenfeld",
      "Ling Li",
      "Ivan Franceschini",
      "Krishnashree Achuthan",
      "Yisroel Mirsky"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19247v1",
    "title": "Auto-Prompting with Retrieval Guidance for Frame Detection in Logistics",
    "summary": "Prompt engineering plays a critical role in adapting large language models (LLMs) to complex reasoning and labeling tasks without the need for extensive fine-tuning. In this paper, we propose a novel prompt optimization pipeline for frame detection in logistics texts, combining retrieval-augmented generation (RAG), few-shot prompting, chain-of-thought (CoT) reasoning, and automatic CoT synthesis (Auto-CoT) to generate highly effective task-specific prompts. Central to our approach is an LLM-based prompt optimizer agent that iteratively refines the prompts using retrieved examples, performance feedback, and internal self-evaluation. Our framework is evaluated on a real-world logistics text annotation task, where reasoning accuracy and labeling efficiency are critical. Experimental results show that the optimized prompts - particularly those enhanced via Auto-CoT and RAG - improve real-world inference accuracy by up to 15% compared to baseline zero-shot or static prompts. The system demonstrates consistent improvements across multiple LLMs, including GPT-4o, Qwen 2.5 (72B), and LLaMA 3.1 (70B), validating its generalizability and practical value. These findings suggest that structured prompt optimization is a viable alternative to full fine-tuning, offering scalable solutions for deploying LLMs in domain-specific NLP applications such as logistics.",
    "published": "2025-12-22T10:29:51Z",
    "updated": "2025-12-22T10:29:51Z",
    "link": "http://arxiv.org/pdf/2512.19247v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Do Minh Duc",
      "Quan Xuan Truong",
      "Nguyen Tat Dat",
      "Nguyen Van Vinh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.17452v2",
    "title": "Learning What to Write: Write-Gated KV for Efficient Long-Context Inference",
    "summary": "Long-context LLM inference is bottlenecked by the quadratic attention complexity and linear KV cache growth. Prior approaches mitigate this via post-hoc selection or eviction but overlook the root inefficiency: indiscriminate writing to persistent memory. In this paper, we formalize KV cache management as a causal system of three primitives: KV Admission, Selection, and Eviction. We instantiate KV Admission via Write-Gated KV, a lightweight mechanism that learns to predict token utility before it enters the cache. By filtering out low-utility states early to maintain a compact global cache alongside a sliding local cache, Write-Gated KV reduces memory usage by 46-57% and delivers 3.03-3.45$\\times$ prefill and 1.89-2.56$\\times$ decode speedups on Llama model with negligible accuracy loss, all while remaining compatible with FlashAttention and paged-KV systems. These results demonstrate that learning what to write, is a principled and practical recipe for efficient long-context inference. Code is available at https://github.com/EMCLab-Sinica/WG-KV .",
    "published": "2025-12-19T11:08:58Z",
    "updated": "2025-12-22T10:23:36Z",
    "link": "http://arxiv.org/pdf/2512.17452v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Yen-Chieh Huang",
      "Pi-Cheng Hsiu",
      "Rui Fang",
      "Ming-Syan Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.11646v2",
    "title": "What-If Decision Support for Product Line Extension Using Conditional Deep Generative Models",
    "summary": "Product line extension is a strategically important managerial decision that requires anticipating how consumer segments and purchasing contexts may respond to hypothetical product designs that do not yet exist in the market. Such decisions are inherently uncertain because managers must infer future outcomes from historical purchase data without direct market observations. This study addresses this challenge by proposing a data-driven decision support framework that enables forward-looking what-if analysis based on historical transaction data. We introduce a Conditional Tabular Variational Autoencoder (CTVAE) that learns the conditional joint distribution of product attributes and consumer characteristics from large-scale tabular data. By conditioning the generative process on controllable design variables such as container type, volume, flavor, and calorie content, the proposed model generates synthetic consumer attribute distributions for hypothetical line-extended products. This enables systematic exploration of alternative design scenarios without costly market pretests. The framework is evaluated using home-scan panel data covering more than 20,000 consumers and 700 soft drink products. Empirical results show that the CTVAE outperforms existing tabular generative models in capturing conditional consumer attribute distributions. Simulation-based analyses further demonstrate that the generated synthetic data support knowledge-driven reasoning for assessing cannibalization risks and identifying potential target segments. These findings highlight the value of conditional deep generative models as core components of decision support systems for product line extension planning.",
    "published": "2025-11-10T08:50:03Z",
    "updated": "2025-12-22T10:22:37Z",
    "link": "http://arxiv.org/pdf/2511.11646v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "authors": [
      "Yinxing Li",
      "Tsukasa Ishigaki"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19240v1",
    "title": "ChemATP: A Training-Free Chemical Reasoning Framework for Large Language Models",
    "summary": "Large Language Models (LLMs) exhibit strong general reasoning but struggle in molecular science due to the lack of explicit chemical priors in standard string representations. Current solutions face a fundamental dilemma. Training-based methods inject priors into parameters, but this static coupling hinders rapid knowledge updates and often compromises the model's general reasoning capabilities. Conversely, existing training-free methods avoid these issues but rely on surface-level prompting, failing to provide the fine-grained atom-level priors essential for precise chemical reasoning. To address this issue, we introduce ChemATP, a framework that decouples chemical knowledge from the reasoning engine. By constructing the first atom-level textual knowledge base, ChemATP enables frozen LLMs to explicitly retrieve and reason over this information dynamically. This architecture ensures interpretability and adaptability while preserving the LLM's intrinsic general intelligence. Experiments show that ChemATP significantly outperforms training-free baselines and rivals state-of-the-art training-based models, demonstrating that explicit prior injection is a competitive alternative to implicit parameter updates.",
    "published": "2025-12-22T10:21:40Z",
    "updated": "2025-12-22T10:21:40Z",
    "link": "http://arxiv.org/pdf/2512.19240v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Mingxu Zhang",
      "Dazhong Shen",
      "Qi Zhang",
      "Ying Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19238v1",
    "title": "Identifying Features Associated with Bias Against 93 Stigmatized Groups in Language Models and Guardrail Model Safety Mitigation",
    "summary": "Large language models (LLMs) have been shown to exhibit social bias, however, bias towards non-protected stigmatized identities remain understudied. Furthermore, what social features of stigmas are associated with bias in LLM outputs is unknown. From psychology literature, it has been shown that stigmas contain six shared social features: aesthetics, concealability, course, disruptiveness, origin, and peril. In this study, we investigate if human and LLM ratings of the features of stigmas, along with prompt style and type of stigma, have effect on bias towards stigmatized groups in LLM outputs. We measure bias against 93 stigmatized groups across three widely used LLMs (Granite 3.0-8B, Llama-3.1-8B, Mistral-7B) using SocialStigmaQA, a benchmark that includes 37 social scenarios about stigmatized identities; for example deciding wether to recommend them for an internship. We find that stigmas rated by humans to be highly perilous (e.g., being a gang member or having HIV) have the most biased outputs from SocialStigmaQA prompts (60% of outputs from all models) while sociodemographic stigmas (e.g. Asian-American or old age) have the least amount of biased outputs (11%). We test if the amount of biased outputs could be decreased by using guardrail models, models meant to identify harmful input, using each LLM's respective guardrail model (Granite Guardian 3.0, Llama Guard 3.0, Mistral Moderation API). We find that bias decreases significantly by 10.4%, 1.4%, and 7.8%, respectively. However, we show that features with significant effect on bias remain unchanged post-mitigation and that guardrail models often fail to recognize the intent of bias in prompts. This work has implications for using LLMs in scenarios involving stigmatized groups and we suggest future work towards improving guardrail models for bias mitigation.",
    "published": "2025-12-22T10:20:20Z",
    "updated": "2025-12-22T10:20:20Z",
    "link": "http://arxiv.org/pdf/2512.19238v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Anna-Maria Gueorguieva",
      "Aylin Caliskan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19234v1",
    "title": "DeliveryBench: Can Agents Earn Profit in Real World?",
    "summary": "LLMs and VLMs are increasingly deployed as embodied agents, yet existing benchmarks largely revolve around simple short-term tasks and struggle to capture rich realistic constraints that shape real-world decision making. To close this gap, we propose DeliveryBench, a city-scale embodied benchmark grounded in the real-world profession of food delivery. Food couriers naturally operate under long-horizon objectives (maximizing net profit over hours) while managing diverse constraints, e.g., delivery deadline, transportation expense, vehicle battery, and necessary interactions with other couriers and customers. DeliveryBench instantiates this setting in procedurally generated 3D cities with diverse road networks, buildings, functional locations, transportation modes, and realistic resource dynamics, enabling systematic evaluation of constraint-aware, long-horizon planning. We benchmark a range of VLM-based agents across nine cities and compare them with human players. Our results reveal a substantial performance gap to humans, and find that these agents are short-sighted and frequently break basic commonsense constraints. Additionally, we observe distinct personalities across models (e.g., adventurous GPT-5 vs. conservative Claude), highlighting both the brittleness and the diversity of current VLM-based embodied agents in realistic, constraint-dense environments. Our code, data, and benchmark are available at https://deliverybench.github.io.",
    "published": "2025-12-22T10:17:49Z",
    "updated": "2025-12-22T10:17:49Z",
    "link": "http://arxiv.org/pdf/2512.19234v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Lingjun Mao",
      "Jiawei Ren",
      "Kun Zhou",
      "Jixuan Chen",
      "Ziqiao Ma",
      "Lianhui Qin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19228v1",
    "title": "Generation of Programmatic Rules for Document Forgery Detection Using Large Language Models",
    "summary": "Document forgery poses a growing threat to legal, economic, and governmental processes, requiring increasingly sophisticated verification mechanisms. One approach involves the use of plausibility checks, rule-based procedures that assess the correctness and internal consistency of data, to detect anomalies or signs of manipulation. Although these verification procedures are essential for ensuring data integrity, existing plausibility checks are manually implemented by software engineers, which is time-consuming. Recent advances in code generation with large language models (LLMs) offer new potential for automating and scaling the generation of these checks. However, adapting LLMs to the specific requirements of an unknown domain remains a significant challenge. This work investigates the extent to which LLMs, adapted on domain-specific code and data through different fine-tuning strategies, can generate rule-based plausibility checks for forgery detection on constrained hardware resources. We fine-tune open-source LLMs, Llama 3.1 8B and OpenCoder 8B, on structured datasets derived from real-world application scenarios and evaluate the generated plausibility checks on previously unseen forgery patterns. The results demonstrate that the models are capable of generating executable and effective verification procedures. This also highlights the potential of LLMs as scalable tools to support human decision-making in security-sensitive contexts where comprehensibility is required.",
    "published": "2025-12-22T10:08:25Z",
    "updated": "2025-12-22T10:08:25Z",
    "link": "http://arxiv.org/pdf/2512.19228v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Valentin Schmidberger",
      "Manuel Eberhardinger",
      "Setareh Maghsudi",
      "Johannes Maucher"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19221v1",
    "title": "From Pixels to Predicates Structuring urban perception with scene graphs",
    "summary": "Perception research is increasingly modelled using streetscapes, yet many approaches still rely on pixel features or object co-occurrence statistics, overlooking the explicit relations that shape human perception. This study proposes a three stage pipeline that transforms street view imagery (SVI) into structured representations for predicting six perceptual indicators. In the first stage, each image is parsed using an open-set Panoptic Scene Graph model (OpenPSG) to extract object predicate object triplets. In the second stage, compact scene-level embeddings are learned through a heterogeneous graph autoencoder (GraphMAE). In the third stage, a neural network predicts perception scores from these embeddings. We evaluate the proposed approach against image-only baselines in terms of accuracy, precision, and cross-city generalization. Results indicate that (i) our approach improves perception prediction accuracy by an average of 26% over baseline models, and (ii) maintains strong generalization performance in cross-city prediction tasks. Additionally, the structured representation clarifies which relational patterns contribute to lower perception scores in urban scenes, such as graffiti on wall and car parked on sidewalk. Overall, this study demonstrates that graph-based structure provides expressive, generalizable, and interpretable signals for modelling urban perception, advancing human-centric and context-aware urban analytics.",
    "published": "2025-12-22T10:02:53Z",
    "updated": "2025-12-22T10:02:53Z",
    "link": "http://arxiv.org/pdf/2512.19221v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Yunlong Liu",
      "Shuyang Li",
      "Pengyuan Liu",
      "Yu Zhang",
      "Rudi Stouffs"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19219v1",
    "title": "Towards Minimal Fine-Tuning of VLMs",
    "summary": "We introduce Image-LoRA, a lightweight parameter efficient fine-tuning (PEFT) recipe for transformer-based vision-language models (VLMs). Image-LoRA applies low-rank adaptation only to the value path of attention layers within the visual-token span, reducing adapter-only training FLOPs roughly in proportion to the visual-token fraction. We further adapt only a subset of attention heads, selected using head influence scores estimated with a rank-1 Image-LoRA, and stabilize per-layer updates via selection-size normalization. Across screen-centric grounding and referring benchmarks spanning text-heavy to image-heavy regimes, Image-LoRA matches or closely approaches standard LoRA accuracy while using fewer trainable parameters and lower adapter-only training FLOPs. The method also preserves the pure-text reasoning performance of VLMs before and after fine-tuning, as further shown on GSM8K.",
    "published": "2025-12-22T10:02:10Z",
    "updated": "2025-12-22T10:02:10Z",
    "link": "http://arxiv.org/pdf/2512.19219v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Tiange Luo",
      "Lajanugen Logeswaran",
      "Jaekyeom Kim",
      "Justin Johnson",
      "Honglak Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.04618v2",
    "title": "Neural Decoding of Overt Speech from ECoG Using Vision Transformers and Contrastive Representation Learning",
    "summary": "Speech Brain Computer Interfaces (BCIs) offer promising solutions to people with severe paralysis unable to communicate. A number of recent studies have demonstrated convincing reconstruction of intelligible speech from surface electrocorticographic (ECoG) or intracortical recordings by predicting a series of phonemes or words and using downstream language models to obtain meaningful sentences. A current challenge is to reconstruct speech in a streaming mode by directly regressing cortical signals into acoustic speech. While this has been achieved recently using intracortical data, further work is needed to obtain comparable results with surface ECoG recordings. In particular, optimizing neural decoders becomes critical in this case. Here we present an offline speech decoding pipeline based on an encoder-decoder deep neural architecture, integrating Vision Transformers and contrastive learning to enhance the direct regression of speech from ECoG signals. The approach is evaluated on two datasets, one obtained with clinical subdural electrodes in an epileptic patient, and another obtained with the fully implantable WIMAGINE epidural system in a participant of a motor BCI trial. To our knowledge this presents a first attempt to decode speech from a fully implantable and wireless epidural recording system offering perspectives for long-term use.",
    "published": "2025-12-04T09:47:15Z",
    "updated": "2025-12-22T09:55:28Z",
    "link": "http://arxiv.org/pdf/2512.04618v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Mohamed Baha Ben Ticha",
      "Xingchen Ran",
      "Guillaume Saldanha",
      "Gaël Le Godais",
      "Philémon Roussel",
      "Marc Aubert",
      "Amina Fontanell",
      "Thomas Costecalde",
      "Lucas Struber",
      "Serpil Karakas",
      "Shaomin Zhang",
      "Philippe Kahane",
      "Guillaume Charvet",
      "Stéphan Chabardès",
      "Blaise Yvert"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.20647v2",
    "title": "The Reasoning Lingua Franca: A Double-Edged Sword for Multilingual AI",
    "summary": "Large Reasoning Models (LRMs) achieve strong performance on mathematical, scientific, and other question-answering tasks, but their multilingual reasoning abilities remain underexplored. When presented with non-English questions, LRMs often default to reasoning in English, raising concerns about interpretability and the handling of linguistic and cultural nuances. We systematically compare an LRM's reasoning in English versus the language of the question. Our evaluation spans two tasks: MGSM and GPQA Diamond. Beyond measuring answer accuracy, we also analyze cognitive attributes in the reasoning traces. We find that English reasoning traces exhibit a substantially higher presence of these cognitive behaviors, and that reasoning in English generally yields higher final-answer accuracy, with the performance gap increasing as tasks become more complex. However, this English-centric strategy is susceptible to a key failure mode - getting \"Lost in Translation,\" where translation steps lead to errors that would have been avoided by question's language reasoning.",
    "published": "2025-10-23T15:22:00Z",
    "updated": "2025-12-22T09:52:15Z",
    "link": "http://arxiv.org/pdf/2510.20647v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Alan Saji",
      "Raj Dabre",
      "Anoop Kunchukuttan",
      "Ratish Puduppully"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19210v1",
    "title": "Observer, Not Player: Simulating Theory of Mind in LLMs through Game Observation",
    "summary": "We present an interactive framework for evaluating whether large language models (LLMs) exhibit genuine \"understanding\" in a simple yet strategic environment. As a running example, we focus on Rock-Paper-Scissors (RPS), which, despite its apparent simplicity, requires sequential reasoning, adaptation, and strategy recognition. Our system positions the LLM as an Observer whose task is to identify which strategies are being played and to articulate the reasoning behind this judgment. The purpose is not to test knowledge of Rock-Paper-Scissors itself, but to probe whether the model can exhibit mind-like reasoning about sequential behavior. To support systematic evaluation, we provide a benchmark consisting of both static strategies and lightweight dynamic strategies specified by well-prompted rules. We quantify alignment between the Observer's predictions and the ground-truth distributions induced by actual strategy pairs using three complementary signals: Cross-Entropy, Brier score, and Expected Value (EV) discrepancy. These metrics are further integrated into a unified score, the Union Loss, which balances calibration, sensitivity, and payoff alignment. Together with a Strategy Identification Rate (SIR) metric, our framework captures not only predictive accuracy but also whether the model can stably identify the latent strategies in play. The demo emphasizes interactivity, transparency, and reproducibility. Users can adjust LLM distributions in real time, visualize losses as they evolve, and directly inspect reasoning snippets to identify where and why failures occur. In doing so, our system provides a practical and interpretable proxy for mind-like inference in sequential games, offering insights into both the strengths and limitations of current LLM reasoning.",
    "published": "2025-12-22T09:49:13Z",
    "updated": "2025-12-22T09:49:13Z",
    "link": "http://arxiv.org/pdf/2512.19210v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Jerry Wang",
      "Ting Yiu Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19206v1",
    "title": "MixKVQ: Query-Aware Mixed-Precision KV Cache Quantization for Long-Context Reasoning",
    "summary": "Long Chain-of-Thought (CoT) reasoning has significantly advanced the capabilities of Large Language Models (LLMs), but this progress is accompanied by substantial memory and latency overhead from the extensive Key-Value (KV) cache. Although KV cache quantization is a promising compression technique, existing low-bit quantization methods often exhibit severe performance degradation on complex reasoning tasks. Fixed-precision quantization struggles to handle outlier channels in the key cache, while current mixed-precision strategies fail to accurately identify components requiring high-precision representation. We find that an effective low-bit KV cache quantization strategy must consider two factors: a key channel's intrinsic quantization difficulty and its relevance to the query. Based on this insight, we propose MixKVQ, a novel plug-and-play method that introduces a lightweight, query-aware algorithm to identify and preserve critical key channels that need higher precision, while applying per-token quantization for value cache. Experiments on complex reasoning datasets demonstrate that our approach significantly outperforms existing low-bit methods, achieving performance comparable to a full-precision baseline at a substantially reduced memory footprint.",
    "published": "2025-12-22T09:44:26Z",
    "updated": "2025-12-22T09:44:26Z",
    "link": "http://arxiv.org/pdf/2512.19206v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Tao Zhang",
      "Ziqian Zeng",
      "Hao Peng",
      "Huiping Zhuang",
      "Cen Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.08438v3",
    "title": "A Survey of 3D Reconstruction with Event Cameras",
    "summary": "Event cameras are rapidly emerging as powerful vision sensors for 3D reconstruction, uniquely capable of asynchronously capturing per-pixel brightness changes. Compared to traditional frame-based cameras, event cameras produce sparse yet temporally dense data streams, enabling robust and accurate 3D reconstruction even under challenging conditions such as high-speed motion, low illumination, and extreme dynamic range scenarios. These capabilities offer substantial promise for transformative applications across various fields, including autonomous driving, robotics, aerial navigation, and immersive virtual reality. In this survey, we present the first comprehensive review exclusively dedicated to event-based 3D reconstruction. Existing approaches are systematically categorised based on input modality into stereo, monocular, and multimodal systems, and further classified according to reconstruction methodologies, including geometry-based techniques, deep learning approaches, and neural rendering techniques such as Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS). Within each category, methods are chronologically organised to highlight the evolution of key concepts and advancements. Furthermore, we provide a detailed summary of publicly available datasets specifically suited to event-based reconstruction tasks. Finally, we discuss significant open challenges in dataset availability, standardised evaluation, effective representation, and dynamic scene reconstruction, outlining insightful directions for future research. This survey aims to serve as an essential reference and provides a clear and motivating roadmap toward advancing the state of the art in event-driven 3D reconstruction.",
    "published": "2025-05-13T11:04:04Z",
    "updated": "2025-12-22T09:39:55Z",
    "link": "http://arxiv.org/pdf/2505.08438v3.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Chuanzhi Xu",
      "Haoxian Zhou",
      "Langyi Chen",
      "Haodong Chen",
      "Zeke Zexi Hu",
      "Zhicheng Lu",
      "Ying Zhou",
      "Vera Chung",
      "Qiang Qu",
      "Weidong Cai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.11792v3",
    "title": "Solver-Informed RL: Grounding Large Language Models for Authentic Optimization Modeling",
    "summary": "Optimization modeling is fundamental to decision-making across diverse domains. Despite progress in automating optimization formulation from natural language descriptions, Large Language Models (LLMs) often struggle to generate formally correct and usable models against hallucinations, posing a challenge for reliable automation. Inspired by the success of Reinforcement Learning (RL) in enhancing Large Reasoning Models, we present Solver-Informed Reinforcement Learning (SIRL), a novel framework that significantly improves the authenticity of LLMs for optimization modeling using Reinforcement Learning with Verifiable Reward by leveraging external optimization solvers as verifiers. These verifiers automatically assess the executable code and the instance-level mathematical model represented by the associated LP file, yielding precise and comprehensive feedback signals -- including syntax, feasibility, and solution quality, serving as direct rewards for the RL process. This automated verification process, particularly from classic optimization solvers, also underpins our instance-enhanced self-consistency method to synthesize high-quality training data. Extensive experiments on diverse public benchmarks demonstrate that SIRL achieves state-of-the-art performance, substantially outperforming existing methods in generating accurate and executable optimization models. Our code is publicly available at https://github.com/Cardinal-Operations/SIRL.",
    "published": "2025-05-17T02:32:03Z",
    "updated": "2025-12-22T09:39:43Z",
    "link": "http://arxiv.org/pdf/2505.11792v3.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Yitian Chen",
      "Jingfan Xia",
      "Siyu Shao",
      "Dongdong Ge",
      "Yinyu Ye"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19199v1",
    "title": "On the Koopman-Based Generalization Bounds for Multi-Task Deep Learning",
    "summary": "The paper establishes generalization bounds for multitask deep neural networks using operator-theoretic techniques. The authors propose a tighter bound than those derived from conventional norm based methods by leveraging small condition numbers in the weight matrices and introducing a tailored Sobolev space as an expanded hypothesis space. This enhanced bound remains valid even in single output settings, outperforming existing Koopman based bounds. The resulting framework maintains key advantages such as flexibility and independence from network width, offering a more precise theoretical understanding of multitask deep learning in the context of kernel methods.",
    "published": "2025-12-22T09:36:24Z",
    "updated": "2025-12-22T09:36:24Z",
    "link": "http://arxiv.org/pdf/2512.19199v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Mahdi Mohammadigohari",
      "Giuseppe Di Fatta",
      "Giuseppe Nicosia",
      "Panos M. Pardalos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19184v1",
    "title": "Operator-Based Generalization Bound for Deep Learning: Insights on Multi-Task Learning",
    "summary": "This paper presents novel generalization bounds for vector-valued neural networks and deep kernel methods, focusing on multi-task learning through an operator-theoretic framework. Our key development lies in strategically combining a Koopman based approach with existing techniques, achieving tighter generalization guarantees compared to traditional norm-based bounds. To mitigate computational challenges associated with Koopman-based methods, we introduce sketching techniques applicable to vector valued neural networks. These techniques yield excess risk bounds under generic Lipschitz losses, providing performance guarantees for applications including robust and multiple quantile regression. Furthermore, we propose a novel deep learning framework, deep vector-valued reproducing kernel Hilbert spaces (vvRKHS), leveraging Perron Frobenius (PF) operators to enhance deep kernel methods. We derive a new Rademacher generalization bound for this framework, explicitly addressing underfitting and overfitting through kernel refinement strategies. This work offers novel insights into the generalization properties of multitask learning with deep learning architectures, an area that has been relatively unexplored until recent developments.",
    "published": "2025-12-22T09:18:30Z",
    "updated": "2025-12-22T09:18:30Z",
    "link": "http://arxiv.org/pdf/2512.19184v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Mahdi Mohammadigohari",
      "Giuseppe Di Fatta",
      "Giuseppe Nicosia",
      "Panos M. Pardalos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.17629v2",
    "title": "SCOPE: Sequential Causal Optimization of Process Interventions",
    "summary": "Prescriptive Process Monitoring (PresPM) recommends interventions during business processes to optimize key performance indicators (KPIs). In realistic settings, interventions are rarely isolated: organizations need to align sequences of interventions to jointly steer the outcome of a case. Existing PresPM approaches fall short in this respect. Many focus on a single intervention decision, while others treat multiple interventions independently, ignoring how they interact over time. Methods that do address these dependencies depend either on simulation or data augmentation to approximate the process to train a Reinforcement Learning (RL) agent, which can create a reality gap and introduce bias. We introduce SCOPE, a PresPM approach that learns aligned sequential intervention recommendations. SCOPE employs backward induction to estimate the effect of each candidate intervention action, propagating its impact from the final decision point back to the first. By leveraging causal learners, our method can utilize observational data directly, unlike methods that require constructing process approximations for reinforcement learning. Experiments on both an existing synthetic dataset and a new semi-synthetic dataset show that SCOPE consistently outperforms state-of-the-art PresPM techniques in optimizing the KPI. The novel semi-synthetic setup, based on a real-life event log, is provided as a reusable benchmark for future work on sequential PresPM.",
    "published": "2025-12-19T14:33:02Z",
    "updated": "2025-12-22T09:18:11Z",
    "link": "http://arxiv.org/pdf/2512.17629v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Jakob De Moor",
      "Hans Weytjens",
      "Johannes De Smedt",
      "Jochen De Weerdt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.09166v5",
    "title": "An Exploration of Default Images in Text-to-Image Generation",
    "summary": "In the creative practice of text-to-image (TTI) generation, images are synthesized from textual prompts. By design, TTI models always yield an output, even if the prompt contains unknown terms. In this case, the model may generate default images: images that closely resemble each other across many unrelated prompts. Studying default images is valuable for designing better solutions for prompt engineering and TTI generation. We present the first investigation into default images on Midjourney. We describe an initial study in which we manually created input prompts triggering default images, and several ablation studies. Building on these, we conduct a computational analysis of over 750,000 images, revealing consistent default images across unrelated prompts. We also conduct an online user study investigating how default images may affect user satisfaction. Our work lays the foundation for understanding default images in TTI generation, highlighting their practical relevance as well as challenges and future research directions.",
    "published": "2025-05-14T05:59:23Z",
    "updated": "2025-12-22T09:17:43Z",
    "link": "http://arxiv.org/pdf/2505.09166v5.pdf",
    "category": [
      "cs.HC",
      "cs.AI"
    ],
    "authors": [
      "Hannu Simonen",
      "Atte Kiviniemi",
      "Hannah Johnston",
      "Helena Barranha",
      "Jonas Oppenlaender"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19180v1",
    "title": "Practical Quantum-Classical Feature Fusion for complex data Classification",
    "summary": "Hybrid quantum and classical learning aims to couple quantum feature maps with the robustness of classical neural networks, yet most architectures treat the quantum circuit as an isolated feature extractor and merge its measurements with classical representations by direct concatenation. This neglects that the quantum and classical branches constitute distinct computational modalities and limits reliable performance on complex, high dimensional tabular and semi structured data, including remote sensing, environmental monitoring, and medical diagnostics. We present a multimodal formulation of hybrid learning and propose a cross attention mid fusion architecture in which a classical representation queries quantum derived feature tokens through an attention block with residual connectivity. The quantum branch is kept within practical NISQ budgets and uses up to nine qubits. We evaluate on Wine, Breast Cancer, Forest CoverType, FashionMNIST, and SteelPlatesFaults, comparing a quantum only model, a classical baseline, residual hybrid models, and the proposed mid fusion model under a consistent protocol. Pure quantum and standard hybrid designs underperform due to measurement induced information loss, while cross attention mid fusion is consistently competitive and improves performance on the more complex datasets in most cases. These findings suggest that quantum derived information becomes most valuable when integrated through principled multimodal fusion rather than used in isolation or loosely appended to classical features.",
    "published": "2025-12-22T09:16:08Z",
    "updated": "2025-12-22T09:16:08Z",
    "link": "http://arxiv.org/pdf/2512.19180v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Azadeh Alavi",
      "Fatemeh Kouchmeshki",
      "Abdolrahman Alavi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19178v1",
    "title": "Vision-Language-Policy Model for Dynamic Robot Task Planning",
    "summary": "Bridging the gap between natural language commands and autonomous execution in unstructured environments remains an open challenge for robotics. This requires robots to perceive and reason over the current task scene through multiple modalities, and to plan their behaviors to achieve their intended goals. Traditional robotic task-planning approaches often struggle to bridge low-level execution with high-level task reasoning, and cannot dynamically update task strategies when instructions change during execution, which ultimately limits their versatility and adaptability to new tasks. In this work, we propose a novel language model-based framework for dynamic robot task planning. Our Vision-Language-Policy (VLP) model, based on a vision-language model fine-tuned on real-world data, can interpret semantic instructions and integrate reasoning over the current task scene to generate behavior policies that control the robot to accomplish the task. Moreover, it can dynamically adjust the task strategy in response to changes in the task, enabling flexible adaptation to evolving task requirements. Experiments conducted with different robots and a variety of real-world tasks show that the trained model can efficiently adapt to novel scenarios and dynamically update its policy, demonstrating strong planning autonomy and cross-embodiment generalization. Videos: https://robovlp.github.io/",
    "published": "2025-12-22T09:12:48Z",
    "updated": "2025-12-22T09:12:48Z",
    "link": "http://arxiv.org/pdf/2512.19178v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Jin Wang",
      "Kim Tien Ly",
      "Jacques Cloete",
      "Nikos Tsagarakis",
      "Ioannis Havoutis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19155v1",
    "title": "Can We Test Consciousness Theories on AI? Ablations, Markers, and Robustness",
    "summary": "The search for reliable indicators of consciousness has fragmented into competing theoretical camps (Global Workspace Theory (GWT), Integrated Information Theory (IIT), and Higher-Order Theories (HOT)), each proposing distinct neural signatures. We adopt a synthetic neuro-phenomenology approach: constructing artificial agents that embody these mechanisms to test their functional consequences through precise architectural ablations impossible in biological systems. Across three experiments, we report dissociations suggesting these theories describe complementary functional layers rather than competing accounts. In Experiment 1, a no-rewire Self-Model lesion abolishes metacognitive calibration while preserving first-order task performance, yielding a synthetic blindsight analogue consistent with HOT predictions. In Experiment 2, workspace capacity proves causally necessary for information access: a complete workspace lesion produces qualitative collapse in access-related markers, while partial reductions show graded degradation, consistent with GWT's ignition framework. In Experiment 3, we uncover a broadcast-amplification effect: GWT-style broadcasting amplifies internal noise, creating extreme fragility. The B2 agent family is robust to the same latent perturbation; this robustness persists in a Self-Model-off / workspace-read control, cautioning against attributing the effect solely to $z_{\\text{self}}$ compression. We also report an explicit negative result: raw perturbational complexity (PCI-A) decreases under the workspace bottleneck, cautioning against naive transfer of IIT-adjacent proxies to engineered agents. These results suggest a hierarchical design principle: GWT provides broadcast capacity, while HOT provides quality control. We emphasize that our agents are not conscious; they are reference implementations for testing functional predictions of consciousness theories.",
    "published": "2025-12-22T08:52:07Z",
    "updated": "2025-12-22T08:52:07Z",
    "link": "http://arxiv.org/pdf/2512.19155v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Yin Jun Phua"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19154v1",
    "title": "Beyond Sliding Windows: Learning to Manage Memory in Non-Markovian Environments",
    "summary": "Recent success in developing increasingly general purpose agents based on sequence models has led to increased focus on the problem of deploying computationally limited agents within the vastly more complex real-world. A key challenge experienced in these more realistic domains is highly non-Markovian dependencies with respect to the agent's observations, which are less common in small controlled domains. The predominant approach for dealing with this in the literature is to stack together a window of the most recent observations (Frame Stacking), but this window size must grow with the degree of non-Markovian dependencies, which results in prohibitive computational and memory requirements for both action inference and learning. In this paper, we are motivated by the insight that in many environments that are highly non-Markovian with respect to time, the environment only causally depends on a relatively small number of observations over that time-scale. A natural direction would then be to consider meta-algorithms that maintain relatively small adaptive stacks of memories such that it is possible to express highly non-Markovian dependencies with respect to time while considering fewer observations at each step and thus experience substantial savings in both compute and memory requirements. Hence, we propose a meta-algorithm (Adaptive Stacking) for achieving exactly that with convergence guarantees and quantify the reduced computation and memory constraints for MLP, LSTM, and Transformer-based agents. Our experiments utilize popular memory tasks, which give us control over the degree of non-Markovian dependencies. This allows us to demonstrate that an appropriate meta-algorithm can learn the removal of memories not predictive of future rewards without excessive removal of important experiences. Code: https://github.com/geraudnt/adaptive-stacking",
    "published": "2025-12-22T08:50:30Z",
    "updated": "2025-12-22T08:50:30Z",
    "link": "http://arxiv.org/pdf/2512.19154v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Geraud Nangue Tasse",
      "Matthew Riemer",
      "Benjamin Rosman",
      "Tim Klinger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.09392v4",
    "title": "Potent but Stealthy: Rethink Profile Pollution against Sequential Recommendation via Bi-level Constrained Reinforcement Paradigm",
    "summary": "Sequential Recommenders, which exploit dynamic user intents through interaction sequences, is vulnerable to adversarial attacks. While existing attacks primarily rely on data poisoning, they require large-scale user access or fake profiles thus lacking practicality. In this paper, we focus on the Profile Pollution Attack that subtly contaminates partial user interactions to induce targeted mispredictions. Previous PPA methods suffer from two limitations, i.e., i) over-reliance on sequence horizon impact restricts fine-grained perturbations on item transitions, and ii) holistic modifications cause detectable distribution shifts. To address these challenges, we propose a constrained reinforcement driven attack CREAT that synergizes a bi-level optimization framework with multi-reward reinforcement learning to balance adversarial efficacy and stealthiness. We first develop a Pattern Balanced Rewarding Policy, which integrates pattern inversion rewards to invert critical patterns and distribution consistency rewards to minimize detectable shifts via unbalanced co-optimal transport. Then we employ a Constrained Group Relative Reinforcement Learning paradigm, enabling step-wise perturbations through dynamic barrier constraints and group-shared experience replay, achieving targeted pollution with minimal detectability. Extensive experiments demonstrate the effectiveness of CREAT.",
    "published": "2025-11-12T15:00:52Z",
    "updated": "2025-12-22T08:42:42Z",
    "link": "http://arxiv.org/pdf/2511.09392v4.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Jiajie Su",
      "Zihan Nan",
      "Yunshan Ma",
      "Xiaobo Xia",
      "Xiaohua Feng",
      "Weiming Liu",
      "Xiang Chen",
      "Xiaolin Zheng",
      "Chaochao Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19135v1",
    "title": "Understanding Chain-of-Thought in Large Language Models via Topological Data Analysis",
    "summary": "With the development of large language models (LLMs), particularly with the introduction of the long reasoning chain technique, the reasoning ability of LLMs in complex problem-solving has been significantly enhanced. While acknowledging the power of long reasoning chains, we cannot help but wonder: Why do different reasoning chains perform differently in reasoning? What components of the reasoning chains play a key role? Existing studies mainly focus on evaluating reasoning chains from a functional perspective, with little attention paid to their structural mechanisms. To address this gap, this work is the first to analyze and evaluate the quality of the reasoning chain from a structural perspective. We apply persistent homology from Topological Data Analysis (TDA) to map reasoning steps into semantic space, extract topological features, and analyze structural changes. These changes reveal semantic coherence, logical redundancy, and identify logical breaks and gaps. By calculating homology groups, we assess connectivity and redundancy at various scales, using barcode and persistence diagrams to quantify stability and consistency. Our results show that the topological structural complexity of reasoning chains correlates positively with accuracy. More complex chains identify correct answers sooner, while successful reasoning exhibits simpler topologies, reducing redundancy and cycles, enhancing efficiency and interpretability. This work provides a new perspective on reasoning chain quality assessment and offers guidance for future optimization.",
    "published": "2025-12-22T08:28:08Z",
    "updated": "2025-12-22T08:28:08Z",
    "link": "http://arxiv.org/pdf/2512.19135v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Chenghao Li",
      "Chaoning Zhang",
      "Yi Lu",
      "Shuxu Chen",
      "Xudong Wang",
      "Jiaquan Zhang",
      "Zhicheng Wang",
      "Zhengxun Jin",
      "Kuien Liu",
      "Sung-Ho Bae",
      "Guoqing Wang",
      "Yang Yang",
      "Hen Tao Shen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.14806v4",
    "title": "Let the Barbarians In: How AI Can Accelerate Systems Performance Research",
    "summary": "Artificial Intelligence (AI) is beginning to transform the research process by automating the discovery of new solutions. This shift depends on the availability of reliable verifiers, which AI-driven approaches require to validate candidate solutions. Research focused on improving systems performance is especially well-suited to this paradigm because system performance problems naturally admit such verifiers: candidates can be implemented in real systems or simulators and evaluated against predefined workloads. We term this iterative cycle of generation, evaluation, and refinement AI-Driven Research for Systems (ADRS). Using several open-source ADRS instances (i.e., OpenEvolve, GEPA, and ShinkaEvolve), we demonstrate across ten case studies (e.g., multi-region cloud scheduling, mixture-of-experts load balancing, LLM-based SQL, transaction scheduling) that ADRS-generated solutions can match or even outperform human state-of-the-art designs. Based on these findings, we outline best practices (e.g., level of prompt specification, amount of feedback, robust evaluation) for effectively using ADRS, and we discuss future research directions and their implications. Although we do not yet have a universal recipe for applying ADRS across all of systems research, we hope our preliminary findings, together with the challenges we identify, offer meaningful guidance for future work as researcher effort shifts increasingly toward problem formulation and strategic oversight.\n  Note: This paper is an extension of our prior work [14]. It adds extensive evaluation across multiple ADRS frameworks and provides deeper analysis and insights into best practices.",
    "published": "2025-12-16T18:51:23Z",
    "updated": "2025-12-22T08:18:12Z",
    "link": "http://arxiv.org/pdf/2512.14806v4.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Audrey Cheng",
      "Shu Liu",
      "Melissa Pan",
      "Zhifei Li",
      "Shubham Agarwal",
      "Mert Cemri",
      "Bowen Wang",
      "Alexander Krentsel",
      "Tian Xia",
      "Jongseok Park",
      "Shuo Yang",
      "Jeff Chen",
      "Lakshya Agrawal",
      "Ashwin Naren",
      "Shulu Li",
      "Ruiying Ma",
      "Aditya Desai",
      "Jiarong Xing",
      "Koushik Sen",
      "Matei Zaharia",
      "Ion Stoica"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.13142v3",
    "title": "Can AI Understand What We Cannot Say? Measuring Multilevel Alignment Through Abortion Stigma Across Cognitive, Interpersonal, and Structural Levels",
    "summary": "As large language models increasingly mediate stigmatized health decisions, their capacity to genuinely understand complex psychological and physiological phenomena remains poorly evaluated. Can AI understand what we cannot say? We investigate whether LLMs coherently represent abortion stigma across the cognitive, interpersonal, and structural levels where it operates. We systematically tested 627 demographically diverse personas across five leading LLMs using the validated Individual Level Abortion Stigma Scale (ILAS). Our multilevel analysis examined whether models coherently represent stigma at the cognitive level (self-judgment), interpersonal level (worries about judgment and isolation), and structural level (community condemnation and disclosure patterns), as well as overall stigma. Models fail tests of genuine understanding across all levels. They overestimate interpersonal stigma while underestimating cognitive stigma, assume uniform community condemnation, introduce demographic biases absent from human validation data, miss the empirically validated stigma-secrecy relationship, and contradict themselves within theoretical constructs. These patterns reveal that current alignment approaches ensure appropriate language but not coherent multilevel understanding. This work provides empirical evidence that current LLMs lack coherent multilevel understanding of psychological and physiological constructs. AI safety in high-stakes contexts demands new approaches to design (multilevel coherence), evaluation (continuous auditing), governance and regulation (mandatory audits, accountability, deployment restrictions), and AI literacy in domains where understanding what people cannot say determines whether support helps or harms.",
    "published": "2025-12-15T09:50:00Z",
    "updated": "2025-12-22T07:53:31Z",
    "link": "http://arxiv.org/pdf/2512.13142v3.pdf",
    "category": [
      "cs.AI",
      "cs.HC"
    ],
    "authors": [
      "Anika Sharma",
      "Malavika Mampally",
      "Chidaksh Ravuru",
      "Kandyce Brennan",
      "Neil Gaikwad"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.11712v3",
    "title": "Mitigating Hallucination Through Theory-Consistent Symmetric Multimodal Preference Optimization",
    "summary": "Direct Preference Optimization (DPO) has emerged as an effective approach for mitigating hallucination in Multimodal Large Language Models (MLLMs). Although existing methods have achieved significant progress by utilizing vision-oriented contrastive objectives for enhancing MLLMs' attention to visual inputs and hence reducing hallucination, they suffer from non-rigorous optimization objective function and indirect preference supervision. To address these limitations, we propose a Symmetric Multimodal Preference Optimization (SymMPO), which conducts symmetric preference learning with direct preference supervision (i.e., response pairs) for visual understanding enhancement, while maintaining rigorous theoretical alignment with standard DPO. In addition to conventional ordinal preference learning, SymMPO introduces a preference margin consistency loss to quantitatively regulate the preference gap between symmetric preference pairs. Comprehensive evaluation across five benchmarks demonstrate SymMPO's superior performance, validating its effectiveness in hallucination mitigation of MLLMs.",
    "published": "2025-06-13T12:29:15Z",
    "updated": "2025-12-22T07:47:22Z",
    "link": "http://arxiv.org/pdf/2506.11712v3.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Wenqi Liu",
      "Xuemeng Song",
      "Jiaxi Li",
      "Yinwei Wei",
      "Na Zheng",
      "Jianhua Yin",
      "Liqiang Nie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19114v1",
    "title": "HyperLoad: A Cross-Modality Enhanced Large Language Model-Based Framework for Green Data Center Cooling Load Prediction",
    "summary": "The rapid growth of artificial intelligence is exponentially escalating computational demand, inflating data center energy use and carbon emissions, and spurring rapid deployment of green data centers to relieve resource and environmental stress. Achieving sub-minute orchestration of renewables, storage, and loads, while minimizing PUE and lifecycle carbon intensity, hinges on accurate load forecasting. However, existing methods struggle to address small-sample scenarios caused by cold start, load distortion, multi-source data fragmentation, and distribution shifts in green data centers. We introduce HyperLoad, a cross-modality framework that exploits pre-trained large language models (LLMs) to overcome data scarcity. In the Cross-Modality Knowledge Alignment phase, textual priors and time-series data are mapped to a common latent space, maximizing the utility of prior knowledge. In the Multi-Scale Feature Modeling phase, domain-aligned priors are injected through adaptive prefix-tuning, enabling rapid scenario adaptation, while an Enhanced Global Interaction Attention mechanism captures cross-device temporal dependencies. The public DCData dataset is released for benchmarking. Under both data sufficient and data scarce settings, HyperLoad consistently surpasses state-of-the-art (SOTA) baselines, demonstrating its practicality for sustainable green data center management.",
    "published": "2025-12-22T07:35:16Z",
    "updated": "2025-12-22T07:35:16Z",
    "link": "http://arxiv.org/pdf/2512.19114v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Haoyu Jiang",
      "Boan Qu",
      "Junjie Zhu",
      "Fanjie Zeng",
      "Xiaojie Lin",
      "Wei Zhong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19107v1",
    "title": "FC-MIR: A Mobile Screen Awareness Framework for Intent-Aware Recommendation based on Frame-Compressed Multimodal Trajectory Reasoning",
    "summary": "Identifying user intent from mobile UI operation trajectories is critical for advancing UI understanding and enabling task automation agents. While Multimodal Large Language Models (MLLMs) excel at video understanding tasks, their real-time mobile deployment is constrained by heavy computational costs and inefficient redundant frame processing. To address these issues, we propose the FC-MIR framework: leveraging keyframe sampling and adaptive concatenation, it cuts visual redundancy to boost inference efficiency, while integrating state-of-the-art closed-source MLLMs or fine-tuned models (e.g., Qwen3-VL) for trajectory summarization and intent prediction. We further expand task scope to explore generating post-prediction operations and search suggestions, and introduce a fine-grained metric to evaluate the practical utility of summaries, predictions, and suggestions. For rigorous assessment, we construct a UI trajectory dataset covering scenarios from UI-Agents (Agent-I) and real user interactions (Person-I). Experimental results show our compression method retains performance at 50%-60% compression rates; both closed-source and fine-tuned MLLMs demonstrate strong intent summarization, supporting potential lightweight on-device deployment. However, MLLMs still struggle with useful and \"surprising\" suggestions, leaving room for improvement. Finally, we deploy the framework in a real-world setting, integrating UI perception and UI-Agent proxies to lay a foundation for future progress in this field.",
    "published": "2025-12-22T07:21:07Z",
    "updated": "2025-12-22T07:21:07Z",
    "link": "http://arxiv.org/pdf/2512.19107v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Zhe Yang",
      "Xiaoshuang Sheng",
      "Zhengnan Zhang",
      "Jidong Wu",
      "Zexing Wang",
      "Xin He",
      "Shenghua Xu",
      "Guanjing Xiong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.25300v3",
    "title": "Scaling Behaviors of LLM Reinforcement Learning Post-Training: An Empirical Study in Mathematical Reasoning",
    "summary": "While scaling laws for large language models (LLMs) during pre-training have been extensively studied, their behavior under reinforcement learning (RL) post-training remains largely unexplored. This paper presents a systematic empirical investigation of scaling behaviors in RL-based post-training, with a particular focus on mathematical reasoning. Based on a set of experiments across the full Qwen2.5 dense model series (0.5B to 72B), we characterize how model scale, data volume, and computational budget interact to shape performance. Our analysis leads to four key findings: 1. Larger models consistently exhibit superior learning efficiency on both compute and data metrics. 2. The relationship between test loss, compute, and data can be modeled by a predictive power-law which is robust across both base and instruction-tuned models. 3. Although larger models exhibit higher learning efficiency, the analytical learning efficiency term k(N) in the power-law reveals a latent saturation trend in learning efficiency as model size continues to increase. 4. In data-constrained regimes, repeated reuse of high-quality data proves highly effective, as final performance is primarily governed by the total number of optimization steps rather than the uniqueness of samples. Collectively, these results provide a principled foundation and practical guidelines for efficiently scaling the reasoning capabilities of LLMs through RL post-training.",
    "published": "2025-09-29T17:10:35Z",
    "updated": "2025-12-22T07:20:59Z",
    "link": "http://arxiv.org/pdf/2509.25300v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Zelin Tan",
      "Hejia Geng",
      "Xiaohang Yu",
      "Mulei Zhang",
      "Guancheng Wan",
      "Yifan Zhou",
      "Qiang He",
      "Xiangyuan Xue",
      "Heng Zhou",
      "Yutao Fan",
      "Zhongzhi Li",
      "Zaibin Zhang",
      "Guibin Zhang",
      "Chen Zhang",
      "Zhenfei Yin",
      "Philip Torr",
      "Lei Bai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.02314v4",
    "title": "MAGIC: Few-Shot Mask-Guided Anomaly Inpainting with Prompt Perturbation, Spatially Adaptive Guidance, and Context Awareness",
    "summary": "Few-shot anomaly generation is a key challenge in industrial quality control. Although diffusion models are promising, existing methods struggle: global prompt-guided approaches corrupt normal regions, and existing inpainting-based methods often lack the in-distribution diversity essential for robust downstream models. We propose MAGIC, a fine-tuned inpainting framework that generates high-fidelity anomalies that strictly adhere to the mask while maximizing this diversity. MAGIC introduces three complementary components: (i) Gaussian prompt perturbation, which prevents model overfitting in the few-shot setting by learning and sampling from a smooth manifold of realistic anomalies, (ii) spatially adaptive guidance that applies distinct guidance strengths to the anomaly and background regions, and (iii) context-aware mask alignment to relocate masks for plausible placement within the host object. Under consistent identical evaluation protocol, MAGIC outperforms state-of-the-art methods on diverse anomaly datasets in downstream tasks",
    "published": "2025-07-03T04:54:37Z",
    "updated": "2025-12-22T07:17:17Z",
    "link": "http://arxiv.org/pdf/2507.02314v4.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "JaeHyuck Choi",
      "MinJun Kim",
      "Je Hyeong Hong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19097v1",
    "title": "DIVER-1 : Deep Integration of Vast Electrophysiological Recordings at Scale",
    "summary": "Electrophysiology signals such as EEG and iEEG are central to neuroscience, brain-computer interfaces, and clinical applications, yet existing foundation models remain limited in scale despite clear evidence that scaling improves performance. We introduce DIVER-1, a family of EEG and iEEG foundation models trained on the largest and most diverse corpus to date-5.3k hours of iEEG and 54k hours of EEG (1.6M channel-hours from over 17.7k subjects)-and scaled up to 1.82B parameters. We present the first systematic scaling law analysis for this domain, showing that they follow data-constrained scaling laws: for a given amount of data and compute, smaller models trained for extended epochs consistently outperform larger models trained briefly. This behavior contrasts with prior electrophysiology foundation models that emphasized model size over training duration. To achieve strong performance, we also design architectural innovations including any-variate attention, sliding temporal conditional positional encoding, and multi-domain reconstruction. DIVER-1 iEEG and EEG models each achieve state-of-the-art performance on their respective benchmarks, establishing a concrete guidelines for efficient scaling and resource allocation in electrophysiology foundation model development.",
    "published": "2025-12-22T07:07:43Z",
    "updated": "2025-12-22T07:07:43Z",
    "link": "http://arxiv.org/pdf/2512.19097v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Danny Dongyeop Han",
      "Yonghyeon Gwon",
      "Ahhyun Lucy Lee",
      "Taeyang Lee",
      "Seong Jin Lee",
      "Jubin Choi",
      "Sebin Lee",
      "Jihyun Bang",
      "Seungju Lee",
      "David Keetae Park",
      "Shinjae Yoo",
      "Chun Kee Chung",
      "Jiook Cha"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19096v1",
    "title": "Conditioning Accept-Desirability models in the context of AGM-like belief change",
    "summary": "We discuss conditionalisation for Accept-Desirability models in an abstract decision-making framework, where uncertain rewards live in a general linear space, and events are special projection operators on that linear space. This abstract setting allows us to unify classical and quantum probabilities, and extend them to an imprecise probabilities context. We introduce a new conditioning rule for our Accept-Desirability models, based on the idea that observing an event introduces new indifferences between options. We associate a belief revision operator with our conditioning rule, and investigate which of the AGM axioms for belief revision still hold in our more general framework. We investigate two interesting special cases where all of these axioms are shown to still hold: classical propositional logic and full conditional probabilities.",
    "published": "2025-12-22T07:07:34Z",
    "updated": "2025-12-22T07:07:34Z",
    "link": "http://arxiv.org/pdf/2512.19096v1.pdf",
    "category": [
      "cs.AI",
      "math.LO",
      "math.PR"
    ],
    "authors": [
      "Kathelijne Coussement",
      "Gert de Cooman",
      "Keano De Vos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19093v1",
    "title": "Tool-Augmented Hybrid Ensemble Reasoning with Distillation for Bilingual Mathematical Problem Solving",
    "summary": "Bilingual mathematical problem solving needs a clear link between language reasoning and symbolic calculation. Large language models often handle language well but are weak in accurate computation. This paper presents HERALD (Hybrid Ensemble Reasoning with Adaptive Learning and Distillation), a framework that joins reasoning and calculation using NuminaMath-7B-TIR, GPT-4o, and Mistral-7B. HERALD uses adaptive routing, tool-based reinforcement learning, and knowledge distillation to connect different reasoning paths. Confidence calibration keeps weighting stable, and dual-path checking keeps results correct. Reinforcement learning controls tool use to cut redundancy, and distillation lowers delay without hurting accuracy. The system shows that combining symbolic checking, adaptive ensembles, and bilingual fine-tuning helps achieve both fluent reasoning and precise calculation. HERALD offers a practical solution for multilingual mathematical reasoning with better accuracy, stability, and clarity.",
    "published": "2025-12-22T07:02:16Z",
    "updated": "2025-12-22T07:02:16Z",
    "link": "http://arxiv.org/pdf/2512.19093v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Peiqing Lu",
      "Yuan Zhang",
      "Haoyun Zhang",
      "Jiasen Zheng",
      "Kejian Tong",
      "Wenjun Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.17582v3",
    "title": "GateRA: Token-Aware Modulation for Parameter-Efficient Fine-Tuning",
    "summary": "Parameter-efficient fine-tuning (PEFT) methods, such as LoRA, DoRA, and HiRA, enable lightweight adaptation of large pre-trained models via low-rank updates. However, existing PEFT approaches apply static, input-agnostic updates to all tokens, disregarding the varying importance and difficulty of different inputs. This uniform treatment can lead to overfitting on trivial content or under-adaptation on more informative regions, especially in autoregressive settings with distinct prefill and decoding dynamics. In this paper, we propose GateRA, a unified framework that introduces token-aware modulation to dynamically adjust the strength of PEFT updates. By incorporating adaptive gating into standard PEFT branches, GateRA enables selective, token-level adaptation, preserving pre-trained knowledge for well-modeled inputs while focusing capacity on challenging cases. Empirical visualizations reveal phase-sensitive behaviors, where GateRA automatically suppresses updates for redundant prefill tokens while emphasizing adaptation during decoding. To promote confident and efficient modulation, we further introduce an entropy-based regularization that encourages near-binary gating decisions. This regularization prevents diffuse update patterns and leads to interpretable, sparse adaptation without hard thresholding. Finally, we present a theoretical analysis showing that GateRA induces a soft gradient-masking effect over the PEFT path, enabling continuous and differentiable control over adaptation. Experiments on multiple commonsense reasoning benchmarks demonstrate that GateRA consistently outperforms or matches prior PEFT methods.",
    "published": "2025-11-15T17:55:47Z",
    "updated": "2025-12-22T06:51:54Z",
    "link": "http://arxiv.org/pdf/2511.17582v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Jie Ou",
      "Shuaihong Jiang",
      "Yingjun Du",
      "Cees G. M. Snoek"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19084v1",
    "title": "$γ(3,4)$ `Attention' in Cognitive Agents: Ontology-Free Knowledge Representations With Promise Theoretic Semantics",
    "summary": "The semantics and dynamics of `attention' are closely related to promise theoretic notions developed for autonomous agents and can thus easily be written down in promise framework. In this way one may establish a bridge between vectorized Machine Learning and Knowledge Graph representations without relying on language models implicitly. Our expectations for knowledge presume a degree of statistical stability, i.e. average invariance under repeated observation, or `trust' in the data. Both learning networks and knowledge graph representations can meaningfully coexist to preserve different aspects of data. While vectorized data are useful for probabilistic estimation, graphs preserve the intentionality of the source even under data fractionation. Using a Semantic Spacetime $γ(3,4)$ graph, one avoids complex ontologies in favour of classification of features by their roles in semantic processes. The latter favours an approach to reasoning under conditions of uncertainty. Appropriate attention to causal boundary conditions may lead to orders of magnitude compression of data required for such context determination, as required in the contexts of autonomous robotics, defence deployments, and ad hoc emergency services.",
    "published": "2025-12-22T06:48:53Z",
    "updated": "2025-12-22T06:48:53Z",
    "link": "http://arxiv.org/pdf/2512.19084v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Mark Burgess"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19081v1",
    "title": "Population-Evolve: a Parallel Sampling and Evolutionary Method for LLM Math Reasoning",
    "summary": "Test-time scaling has emerged as a promising direction for enhancing the reasoning capabilities of Large Language Models in last few years. In this work, we propose Population-Evolve, a training-free method inspired by Genetic Algorithms to optimize LLM reasoning. Our approach maintains a dynamic population of candidate solutions for each problem via parallel reasoning. By incorporating an evolve prompt, the LLM self-evolves its population in all iterations. Upon convergence, the final answer is derived via majority voting. Furthermore, we establish a unification framework that interprets existing test-time scaling strategies through the lens of genetic algorithms. Empirical results demonstrate that Population-Evolve achieves superior accuracy with low performance variance and computational efficiency. Our findings highlight the potential of evolutionary strategies to unlock the reasoning power of LLMs during inference.",
    "published": "2025-12-22T06:42:46Z",
    "updated": "2025-12-22T06:42:46Z",
    "link": "http://arxiv.org/pdf/2512.19081v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Yanzhi Zhang",
      "Yitong Duan",
      "Zhaoxi Zhang",
      "Jiyan He",
      "Shuxin Zheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19069v1",
    "title": "Can abstract concepts from LLM improve SLM performance?",
    "summary": "Large language models (LLMs) excel at diverse tasks, but their deployment on resource-constrained devices remains challenging. Existing methods like quantization, pruning, and distillation can reduce memory footprint but often demand extensive experimentation and careful infrastructure design. Leveraging existing techniques for extracting high-level concepts (represented as steering vectors) from larger models, we investigate their transferability to smaller language models (SLM) during inference. We demonstrate through extensive experimentation that these concepts can be effectively transferred to smaller models, irrespective of their family (e.g., Phi, Llama, Qwen), leading to performance improvements across a wide range of tasks. Furthermore, we introduce inference-time scaling to enhance performance by dynamically adjusting the steering intensity which has resulted in a 7-15\\% of accuracy improvement for Qwen3-0.6B.",
    "published": "2025-12-22T06:17:25Z",
    "updated": "2025-12-22T06:17:25Z",
    "link": "http://arxiv.org/pdf/2512.19069v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Siddharth Tandon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.15178v4",
    "title": "GUIDEd Agents: Enhancing Navigation Policies through Task-Specific Uncertainty Abstraction in Localization-Limited Environments",
    "summary": "Autonomous vehicles performing navigation tasks in complex environments face significant challenges due to uncertainty in state estimation. In many scenarios, such as stealth operations or resource-constrained settings, accessing high-precision localization comes at a significant cost, forcing robots to rely primarily on less precise state estimates. Our key observation is that different tasks require varying levels of precision in different regions: a robot navigating a crowded space might need precise localization near obstacles but can operate effectively with less precision elsewhere. In this paper, we present a planning method for integrating task-specific uncertainty requirements directly into navigation policies. We introduce Task-Specific Uncertainty Maps (TSUMs), which abstract the acceptable levels of state estimation uncertainty across different regions. TSUMs align task requirements and environmental features using a shared representation space, generated via a domain-adapted encoder. Using TSUMs, we propose Generalized Uncertainty Integration for Decision-Making and Execution (GUIDE), a policy conditioning framework that incorporates these uncertainty requirements into robot decision-making. We find that TSUMs provide an effective way to abstract task-specific uncertainty requirements, and conditioning policies on TSUMs enables the robot to reason about the context-dependent value of certainty and adapt its behavior accordingly. We show how integrating GUIDE into reinforcement learning frameworks allows the agent to learn navigation policies that effectively balance task completion and uncertainty management without explicit reward engineering. We evaluate GUIDE on various real-world robotic navigation tasks and find that it demonstrates significant improvement in task completion rates compared to baseline methods that do not explicitly consider task-specific uncertainty.",
    "published": "2024-10-19T18:46:17Z",
    "updated": "2025-12-22T06:16:10Z",
    "link": "http://arxiv.org/pdf/2410.15178v4.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "eess.SY"
    ],
    "authors": [
      "Gokul Puthumanaillam",
      "Paulo Padrao",
      "Jose Fuentes",
      "Leonardo Bobadilla",
      "Melkior Ornik"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.14075v2",
    "title": "Explainable Graph Spectral Clustering For GloVe-like Text Embeddings",
    "summary": "In a previous paper, we proposed an introduction to the explainability of Graph Spectral Clustering results for textual documents, given that document similarity is computed as cosine similarity in term vector space.\n  In this paper, we generalize this idea by considering other embeddings of documents, in particular, based on the GloVe embedding idea.",
    "published": "2025-08-12T11:20:27Z",
    "updated": "2025-12-22T06:08:18Z",
    "link": "http://arxiv.org/pdf/2508.14075v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Mieczysław A. Kłopotek",
      "Sławomir T. Wierzchoń",
      "Bartłomiej Starosta",
      "Piotr Borkowski",
      "Dariusz Czerski",
      "Eryk Laskowski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19061v1",
    "title": "Fraud Detection Through Large-Scale Graph Clustering with Heterogeneous Link Transformation",
    "summary": "Collaborative fraud, where multiple fraudulent accounts coordinate to exploit online payment systems, poses significant challenges due to the formation of complex network structures. Traditional detection methods that rely solely on high-confidence identity links suffer from limited coverage, while approaches using all available linkages often result in fragmented graphs with reduced clustering effectiveness. In this paper, we propose a novel graph-based fraud detection framework that addresses the challenge of large-scale heterogeneous graph clustering through a principled link transformation approach. Our method distinguishes between \\emph{hard links} (high-confidence identity relationships such as phone numbers, credit cards, and national IDs) and \\emph{soft links} (behavioral associations including device fingerprints, cookies, and IP addresses). We introduce a graph transformation technique that first identifies connected components via hard links, merges them into super-nodes, and then reconstructs a weighted soft-link graph amenable to efficient embedding and clustering. The transformed graph is processed using LINE (Large-scale Information Network Embedding) for representation learning, followed by HDBSCAN (Hierarchical Density-Based Spatial Clustering of Applications with Noise) for density-based cluster discovery. Experiments on a real-world payment platform dataset demonstrate that our approach achieves significant graph size reduction (from 25 million to 7.7 million nodes), doubles the detection coverage compared to hard-link-only baselines, and maintains high precision across identified fraud clusters. Our framework provides a scalable and practical solution for industrial-scale fraud detection systems.",
    "published": "2025-12-22T05:59:13Z",
    "updated": "2025-12-22T05:59:13Z",
    "link": "http://arxiv.org/pdf/2512.19061v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Chi Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.07019v7",
    "title": "UniHR: Hierarchical Representation Learning for Unified Knowledge Graph Link Prediction",
    "summary": "Real-world knowledge graphs (KGs) contain not only standard triple-based facts, but also more complex, heterogeneous types of facts, such as hyper-relational facts with auxiliary key-value pairs, temporal facts with additional timestamps, and nested facts that imply relationships between facts. These richer forms of representation have attracted significant attention due to their enhanced expressiveness and capacity to model complex semantics in real-world scenarios. However, most existing studies suffer from two main limitations: (1) they typically focus on modeling only specific types of facts, thus making it difficult to generalize to real-world scenarios with multiple fact types; and (2) they struggle to achieve generalizable hierarchical (inter-fact and intra-fact) modeling due to the complexity of these representations. To overcome these limitations, we propose UniHR, a Unified Hierarchical Representation learning framework, which consists of a learning-optimized Hierarchical Data Representation (HiDR) module and a unified Hierarchical Structure Learning (HiSL) module. The HiDR module unifies hyper-relational KGs, temporal KGs, and nested factual KGs into triple-based representations. Then HiSL incorporates intra-fact and inter-fact message passing, focusing on enhancing both semantic information within individual facts and enriching the structural information between facts. To go beyond the unified method itself, we further explore the potential of unified representation in complex real-world scenarios. Extensive experiments on 9 datasets across 5 types of KGs demonstrate the effectiveness of UniHR and highlight the strong potential of unified representations. Code and data are available at https://github.com/zjukg/UniHR.",
    "published": "2024-11-11T14:22:42Z",
    "updated": "2025-12-22T05:48:26Z",
    "link": "http://arxiv.org/pdf/2411.07019v7.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Zhiqiang Liu",
      "Yin Hua",
      "Mingyang Chen",
      "Yichi Zhang",
      "Zhuo Chen",
      "Lei Liang",
      "Wen Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.11185v2",
    "title": "Bleeding Pathways: Vanishing Discriminability in LLM Hidden States Fuels Jailbreak Attacks",
    "summary": "LLMs remain vulnerable to jailbreak attacks that exploit adversarial prompts to circumvent safety measures. Current safety fine-tuning approaches face two critical limitations. First, they often fail to strike a balance between security and utility, where stronger safety measures tend to over-reject harmless user requests. Second, they frequently miss malicious intent concealed within seemingly benign tasks, leaving models exposed to exploitation. Our work identifies a fundamental cause of these issues: during response generation, an LLM's capacity to differentiate harmful from safe outputs deteriorates. Experimental evidence confirms this, revealing that the separability between hidden states for safe and harmful responses diminishes as generation progresses. This weakening discrimination forces models to make compliance judgments earlier in the generation process, restricting their ability to recognize developing harmful intent and contributing to both aforementioned failures. To mitigate this vulnerability, we introduce DEEPALIGN - an inherent defense framework that enhances the safety of LLMs. By applying contrastive hidden-state steering at the midpoint of response generation, DEEPALIGN amplifies the separation between harmful and benign hidden states, enabling continuous intrinsic toxicity detection and intervention throughout the generation process. Across diverse LLMs spanning varying architectures and scales, it reduced attack success rates of nine distinct jailbreak attacks to near-zero or minimal. Crucially, it preserved model capability while reducing over-refusal. Models equipped with DEEPALIGN exhibited up to 3.5% lower error rates in rejecting challenging benign queries and maintained standard task performance with less than 1% decline. This marks a substantial advance in the safety-utility Pareto frontier.",
    "published": "2025-03-14T08:32:12Z",
    "updated": "2025-12-22T05:32:02Z",
    "link": "http://arxiv.org/pdf/2503.11185v2.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Yingjie Zhang",
      "Tong Liu",
      "Zhe Zhao",
      "Guozhu Meng",
      "Kai Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19682v1",
    "title": "GenEnv: Difficulty-Aligned Co-Evolution Between LLM Agents and Environment Simulators",
    "summary": "Training capable Large Language Model (LLM) agents is critically bottlenecked by the high cost and static nature of real-world interaction data. We address this by introducing GenEnv, a framework that establishes a difficulty-aligned co-evolutionary game between an agent and a scalable, generative environment simulator. Unlike traditional methods that evolve models on static datasets, GenEnv instantiates a dataevolving: the simulator acts as a dynamic curriculum policy, continuously generating tasks specifically tailored to the agent's ``zone of proximal development''. This process is guided by a simple but effective $α$-Curriculum Reward, which aligns task difficulty with the agent's current capabilities. We evaluate GenEnv on five benchmarks, including API-Bank, ALFWorld, BFCL, Bamboogle, and TravelPlanner. Across these tasks, GenEnv improves agent performance by up to \\textbf{+40.3\\%} over 7B baselines and matches or exceeds the average performance of larger models. Compared to Gemini 2.5 Pro-based offline data augmentation, GenEnv achieves better performance while using 3.3$\\times$ less data. By shifting from static supervision to adaptive simulation, GenEnv provides a data-efficient pathway for scaling agent capabilities.",
    "published": "2025-12-22T18:57:13Z",
    "updated": "2025-12-22T18:57:13Z",
    "link": "http://arxiv.org/pdf/2512.19682v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Jiacheng Guo",
      "Ling Yang",
      "Peter Chen",
      "Qixin Xiao",
      "Yinjie Wang",
      "Xinzhe Juan",
      "Jiahao Qiu",
      "Ke Shen",
      "Mengdi Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19651v1",
    "title": "Exploring Zero-Shot ACSA with Unified Meaning Representation in Chain-of-Thought Prompting",
    "summary": "Aspect-Category Sentiment Analysis (ACSA) provides granular insights by identifying specific themes within reviews and their associated sentiment. While supervised learning approaches dominate this field, the scarcity and high cost of annotated data for new domains present significant barriers. We argue that leveraging large language models (LLMs) in a zero-shot setting is a practical alternative where resources for data annotation are limited. In this work, we propose a novel Chain-of-Thought (CoT) prompting technique that utilises an intermediate Unified Meaning Representation (UMR) to structure the reasoning process for the ACSA task. We evaluate this UMR-based approach against a standard CoT baseline across three models (Qwen3-4B, Qwen3-8B, and Gemini-2.5-Pro) and four diverse datasets. Our findings suggest that UMR effectiveness may be model-dependent. Whilst preliminary results indicate comparable performance for mid-sized models such as Qwen3-8B, these observations warrant further investigation, particularly regarding the potential applicability to smaller model architectures. Further research is required to establish the generalisability of these findings across different model scales.",
    "published": "2025-12-22T18:23:37Z",
    "updated": "2025-12-22T18:23:37Z",
    "link": "http://arxiv.org/pdf/2512.19651v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Filippos Ventirozos",
      "Peter Appleby",
      "Matthew Shardlow"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19630v1",
    "title": "Diacritic Restoration for Low-Resource Indigenous Languages: Case Study with Bribri and Cook Islands Māori",
    "summary": "We present experiments on diacritic restoration, a form of text normalization essential for natural language processing (NLP) tasks. Our study focuses on two extremely under-resourced languages: Bribri, a Chibchan language spoken in Costa Rica, and Cook Islands Māori, a Polynesian language spoken in the Cook Islands. Specifically, this paper: (i) compares algorithms for diacritics restoration in under-resourced languages, including tonal diacritics, (ii) examines the amount of data required to achieve target performance levels, (iii) contrasts results across varying resource conditions, and (iv) explores the related task of diacritic correction. We find that fine-tuned, character-level LLMs perform best, likely due to their ability to decompose complex characters into their UTF-8 byte representations. In contrast, massively multilingual models perform less effectively given our data constraints. Across all models, reliable performance begins to emerge with data budgets of around 10,000 words. Zero-shot approaches perform poorly in all cases. This study responds both to requests from the language communities and to broader NLP research questions concerning model performance and generalization in under-resourced contexts.",
    "published": "2025-12-22T18:04:24Z",
    "updated": "2025-12-22T18:04:24Z",
    "link": "http://arxiv.org/pdf/2512.19630v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Rolando Coto-Solano",
      "Daisy Li",
      "Manoela Teleginski Ferraz",
      "Olivia Sasse",
      "Cha Krupka",
      "Sharid Loáiciga",
      "Sally Akevai Tenamu Nicholas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19612v1",
    "title": "MauBERT: Universal Phonetic Inductive Biases for Few-Shot Acoustic Units Discovery",
    "summary": "This paper introduces MauBERT, a multilingual extension of HuBERT that leverages articulatory features for robust cross-lingual phonetic representation learning. We continue HuBERT pre-training with supervision based on a phonetic-to-articulatory feature mapping in 55 languages. Our models learn from multilingual data to predict articulatory features or phones, resulting in language-independent representations that capture multilingual phonetic properties. Through comprehensive ABX discriminability testing, we show MauBERT models produce more context-invariant representations than state-of-the-art multilingual self-supervised learning models. Additionally, the models effectively adapt to unseen languages and casual speech with minimal self-supervised fine-tuning (10 hours of speech). This establishes an effective approach for instilling linguistic inductive biases in self-supervised speech models.",
    "published": "2025-12-22T17:47:49Z",
    "updated": "2025-12-22T17:47:49Z",
    "link": "http://arxiv.org/pdf/2512.19612v1.pdf",
    "category": [
      "cs.CL",
      "eess.AS"
    ],
    "authors": [
      "Angelo Ortiz Tandazo",
      "Manel Khentout",
      "Youssef Benchekroun",
      "Thomas Hueber",
      "Emmanuel Dupoux"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.05594v2",
    "title": "SoK: Are Watermarks in LLMs Ready for Deployment?",
    "summary": "Large Language Models (LLMs) have transformed natural language processing, demonstrating impressive capabilities across diverse tasks. However, deploying these models introduces critical risks related to intellectual property violations and potential misuse, particularly as adversaries can imitate these models to steal services or generate misleading outputs. We specifically focus on model stealing attacks, as they are highly relevant to proprietary LLMs and pose a serious threat to their security, revenue, and ethical deployment. While various watermarking techniques have emerged to mitigate these risks, it remains unclear how far the community and industry have progressed in developing and deploying watermarks in LLMs.\n  To bridge this gap, we aim to develop a comprehensive systematization for watermarks in LLMs by 1) presenting a detailed taxonomy for watermarks in LLMs, 2) proposing a novel intellectual property classifier to explore the effectiveness and impacts of watermarks on LLMs under both attack and attack-free environments, 3) analyzing the limitations of existing watermarks in LLMs, and 4) discussing practical challenges and potential future directions for watermarks in LLMs. Through extensive experiments, we show that despite promising research outcomes and significant attention from leading companies and community to deploy watermarks, these techniques have yet to reach their full potential in real-world applications due to their unfavorable impacts on model utility of LLMs and downstream tasks. Our findings provide an insightful understanding of watermarks in LLMs, highlighting the need for practical watermarks solutions tailored to LLM deployment.",
    "published": "2025-06-05T21:12:51Z",
    "updated": "2025-12-22T17:37:53Z",
    "link": "http://arxiv.org/pdf/2506.05594v2.pdf",
    "category": [
      "cs.CR",
      "cs.CL"
    ],
    "authors": [
      "Kieu Dang",
      "Phung Lai",
      "NhatHai Phan",
      "Yelong Shen",
      "Ruoming Jin",
      "Abdallah Khreishah",
      "My T. Thai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19585v1",
    "title": "Increasing the Thinking Budget is Not All You Need",
    "summary": "Recently, a new wave of thinking-capable Large Language Models has emerged, demonstrating exceptional capabilities across a wide range of reasoning benchmarks. Early studies have begun to explore how the amount of compute in terms of the length of the reasoning process, the so-called thinking budget, impacts model performance. In this work, we propose a systematic investigation of the thinking budget as a key parameter, examining its interaction with various configurations such as self-consistency, reflection, and others. Our goal is to provide an informative, balanced comparison framework that considers both performance outcomes and computational cost. Among our findings, we discovered that simply increasing the thinking budget is not the most effective use of compute. More accurate responses can instead be achieved through alternative configurations, such as self-consistency and self-reflection.",
    "published": "2025-12-22T17:12:04Z",
    "updated": "2025-12-22T17:12:04Z",
    "link": "http://arxiv.org/pdf/2512.19585v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Ignacio Iacobacci",
      "Zhaozhi Qian",
      "Faroq AL-Tam",
      "Muhammad AL-Qurishi",
      "Riad Souissi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.20490v3",
    "title": "RadAgents: Multimodal Agentic Reasoning for Chest X-ray Interpretation with Radiologist-like Workflows",
    "summary": "Agentic systems offer a potential path to solve complex clinical tasks through collaboration among specialized agents, augmented by tool use and external knowledge bases. Nevertheless, for chest X-ray (CXR) interpretation, prevailing methods remain limited: (i) reasoning is frequently neither clinically interpretable nor aligned with guidelines, reflecting mere aggregation of tool outputs; (ii) multimodal evidence is insufficiently fused, yielding text-only rationales that are not visually grounded; and (iii) systems rarely detect or resolve cross-tool inconsistencies and provide no principled verification mechanisms. To bridge the above gaps, we present RadAgents, a multi-agent framework that couples clinical priors with task-aware multimodal reasoning and encodes a radiologist-style workflow into a modular, auditable pipeline. In addition, we integrate grounding and multimodal retrieval-augmentation to verify and resolve context conflicts, resulting in outputs that are more reliable, transparent, and consistent with clinical practice.",
    "published": "2025-09-24T19:08:01Z",
    "updated": "2025-12-22T17:02:44Z",
    "link": "http://arxiv.org/pdf/2509.20490v3.pdf",
    "category": [
      "cs.MA",
      "cs.CL",
      "cs.CV"
    ],
    "authors": [
      "Kai Zhang",
      "Corey D Barrett",
      "Jangwon Kim",
      "Lichao Sun",
      "Tara Taghavi",
      "Krishnaram Kenthapadi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19543v1",
    "title": "Algerian Dialect",
    "summary": "We present Algerian Dialect, a large-scale sentiment-annotated dataset consisting of 45,000 YouTube comments written in Algerian Arabic dialect. The comments were collected from more than 30 Algerian press and media channels using the YouTube Data API. Each comment is manually annotated into one of five sentiment categories: very negative, negative, neutral, positive, and very positive. In addition to sentiment labels, the dataset includes rich metadata such as collection timestamps, like counts, video URLs, and annotation dates. This dataset addresses the scarcity of publicly available resources for Algerian dialect and aims to support research in sentiment analysis, dialectal Arabic NLP, and social media analytics. The dataset is publicly available on Mendeley Data under a CC BY 4.0 license at https://doi.org/10.17632/zzwg3nnhsz.2.",
    "published": "2025-12-22T16:26:15Z",
    "updated": "2025-12-22T16:26:15Z",
    "link": "http://arxiv.org/pdf/2512.19543v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Zakaria Benmounah",
      "Abdennour Boulesnane"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.16401v2",
    "title": "Navigating the Reality Gap: Privacy-Preserving Adaptation of ASR for Challenging Low-Resource Domains",
    "summary": "Automatic Speech Recognition (ASR) holds immense potential to assist in clinical documentation and patient report generation, particularly in resource-constrained regions. However, deployment is currently hindered by a technical deadlock: a severe \"Reality Gap\" between laboratory performance and noisy, real-world clinical audio, coupled with strict privacy and resource constraints. We quantify this gap, showing that a robust multilingual model (IndicWav2Vec) degrades to a 40.94% WER on rural clinical data from India, rendering it unusable. To address this, we explore a zero-data-exfiltration framework enabling localized, continual adaptation via Low-Rank Adaptation (LoRA). We conduct a rigorous investigative study of continual learning strategies, characterizing the trade-offs between data-driven and parameter-driven stability. Our results demonstrate that multi-domain Experience Replay (ER) yields the primary performance gains, achieving a 17.1% relative improvement in target WER and reducing catastrophic forgetting by 55% compared to naive adaptation. Furthermore, we observed that standard Elastic Weight Consolidation (EWC) faced numerical stability challenges when applied to LoRA in noisy environments. Our experiments show that a stabilized, linearized formulation effectively controls gradient magnitudes and enables stable convergence. Finally, we verify via a domain-specific spot check that acoustic adaptation is a fundamental prerequisite for usability which cannot be bypassed by language models alone.",
    "published": "2025-12-18T10:56:27Z",
    "updated": "2025-12-22T16:22:23Z",
    "link": "http://arxiv.org/pdf/2512.16401v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Darshil Chauhan",
      "Adityasinh Solanki",
      "Vansh Patel",
      "Kanav Kapoor",
      "Ritvik Jain",
      "Aditya Bansal",
      "Pratik Narang",
      "Dhruv Kumar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19537v1",
    "title": "Event Extraction in Large Language Model",
    "summary": "Large language models (LLMs) and multimodal LLMs are changing event extraction (EE): prompting and generation can often produce structured outputs in zero shot or few shot settings. Yet LLM based pipelines face deployment gaps, including hallucinations under weak constraints, fragile temporal and causal linking over long contexts and across documents, and limited long horizon knowledge management within a bounded context window. We argue that EE should be viewed as a system component that provides a cognitive scaffold for LLM centered solutions. Event schemas and slot constraints create interfaces for grounding and verification; event centric structures act as controlled intermediate representations for stepwise reasoning; event links support relation aware retrieval with graph based RAG; and event stores offer updatable episodic and agent memory beyond the context window. This survey covers EE in text and multimodal settings, organizing tasks and taxonomy, tracing method evolution from rule based and neural models to instruction driven and generative frameworks, and summarizing formulations, decoding strategies, architectures, representations, datasets, and evaluation. We also review cross lingual, low resource, and domain specific settings, and highlight open challenges and future directions for reliable event centric systems. Finally, we outline open challenges and future directions that are central to the LLM era, aiming to evolve EE from static extraction into a structurally reliable, agent ready perception and memory layer for open world systems.",
    "published": "2025-12-22T16:22:14Z",
    "updated": "2025-12-22T16:22:14Z",
    "link": "http://arxiv.org/pdf/2512.19537v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Bobo Li",
      "Xudong Han",
      "Jiang Liu",
      "Yuzhe Ding",
      "Liqiang Jing",
      "Zhaoqi Zhang",
      "Jinheng Li",
      "Xinya Du",
      "Fei Li",
      "Meishan Zhang",
      "Min Zhang",
      "Aixin Sun",
      "Philip S. Yu",
      "Hao Fei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2402.08971v3",
    "title": "Structured Language Generation Model: Loss Calibration and Formatted Decoding for Robust Structure Prediction and Knowledge Retrieval",
    "summary": "Modern generative pre-trained language models excel at open-ended text generation, yet continue to underperform on structure-related tasks such as NER, relation extraction, and semantic role labeling, especially when compared to encoder-only models of similar sizes. While this gap has been attributed to limited structure knowledge, we hypothesize this is also due to the missing connection between the model's internal representations of linguistic structure and the output space used during supervised fine-tuning. We propose the Structured Language Generation Model (SLGM), a model- and task-agnostic framework that reformulates structured prediction as a classification problem through three components: (1) reinforced input formatting with structural cues, (2) loss design, and (3) format-aware decoding that constrains generation to task-valid outputs. Across 5 tasks and 13 datasets, SLGM substantially improves structure prediction without relying on dataset-specific engineering or additional model parameters, strengthening alignment between the model's internal structure representation and output. It outperforms baseline fine-tuning on models of the same size, achieves comparable performance to much larger models when used with <1B parameter models, and acts as a zero-weight adapter that reproduces the benefits of dataset-specific fine-tuning in low-resource settings.",
    "published": "2024-02-14T06:33:22Z",
    "updated": "2025-12-22T16:15:22Z",
    "link": "http://arxiv.org/pdf/2402.08971v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Minho Lee",
      "Junghyun Min",
      "Yerang Kim",
      "Woochul Lee",
      "Yeonsoo Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.23863v2",
    "title": "SPELL: Self-Play Reinforcement Learning for evolving Long-Context Language Models",
    "summary": "Progress in long-context reasoning for large language models (LLMs) has lagged behind other recent advances. This gap arises not only from the intrinsic difficulty of processing long texts, but also from the scarcity of reliable human annotations and programmatically verifiable reward signals. In this paper, we propose SPELL, a multi-role self-play reinforcement learning framework that enables scalable, label-free optimization for long-context reasoning. SPELL integrates three cyclical roles-questioner, responder, and verifier-within a single model to enable continual self-improvement. The questioner generates questions from raw documents paired with reference answers; the responder learns to solve these questions based on the documents; and the verifier evaluates semantic equivalence between the responder's output and the questioner's reference answer, producing reward signals to guide continual training. To stabilize training, we introduce an automated curriculum that gradually increases document length and a reward function that adapts question difficulty to the model's evolving capabilities. Extensive experiments on six long-context benchmarks show that SPELL consistently improves performance across diverse LLMs and outperforms equally sized models fine-tuned on large-scale annotated data. Notably, SPELL achieves an average 7.6-point gain in pass@8 on the strong reasoning model Qwen3-30B-A3B-Thinking, raising its performance ceiling and showing promise for scaling to even more capable models.",
    "published": "2025-09-28T13:08:10Z",
    "updated": "2025-12-22T16:06:03Z",
    "link": "http://arxiv.org/pdf/2509.23863v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Ziyi Yang",
      "Weizhou Shen",
      "Chenliang Li",
      "Ruijun Chen",
      "Fanqi Wan",
      "Ming Yan",
      "Xiaojun Quan",
      "Fei Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19475v1",
    "title": "A Large-Language-Model Framework for Automated Humanitarian Situation Reporting",
    "summary": "Timely and accurate situational reports are essential for humanitarian decision-making, yet current workflows remain largely manual, resource intensive, and inconsistent. We present a fully automated framework that uses large language models (LLMs) to transform heterogeneous humanitarian documents into structured and evidence-grounded reports. The system integrates semantic text clustering, automatic question generation, retrieval augmented answer extraction with citations, multi-level summarization, and executive summary generation, supported by internal evaluation metrics that emulate expert reasoning. We evaluated the framework across 13 humanitarian events, including natural disasters and conflicts, using more than 1,100 documents from verified sources such as ReliefWeb. The generated questions achieved 84.7 percent relevance, 84.0 percent importance, and 76.4 percent urgency. The extracted answers reached 86.3 percent relevance, with citation precision and recall both exceeding 76 percent. Agreement between human and LLM based evaluations surpassed an F1 score of 0.80. Comparative analysis shows that the proposed framework produces reports that are more structured, interpretable, and actionable than existing baselines. By combining LLM reasoning with transparent citation linking and multi-level evaluation, this study demonstrates that generative AI can autonomously produce accurate, verifiable, and operationally useful humanitarian situation reports.",
    "published": "2025-12-22T15:28:55Z",
    "updated": "2025-12-22T15:28:55Z",
    "link": "http://arxiv.org/pdf/2512.19475v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Ivan Decostanzi",
      "Yelena Mejova",
      "Kyriaki Kalimeri"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19466v1",
    "title": "Epistemological Fault Lines Between Human and Artificial Intelligence",
    "summary": "Large language models (LLMs) are widely described as artificial intelligence, yet their epistemic profile diverges sharply from human cognition. Here we show that the apparent alignment between human and machine outputs conceals a deeper structural mismatch in how judgments are produced. Tracing the historical shift from symbolic AI and information filtering systems to large-scale generative transformers, we argue that LLMs are not epistemic agents but stochastic pattern-completion systems, formally describable as walks on high-dimensional graphs of linguistic transitions rather than as systems that form beliefs or models of the world. By systematically mapping human and artificial epistemic pipelines, we identify seven epistemic fault lines, divergences in grounding, parsing, experience, motivation, causal reasoning, metacognition, and value. We call the resulting condition Epistemia: a structural situation in which linguistic plausibility substitutes for epistemic evaluation, producing the feeling of knowing without the labor of judgment. We conclude by outlining consequences for evaluation, governance, and epistemic literacy in societies increasingly organized around generative AI.",
    "published": "2025-12-22T15:20:21Z",
    "updated": "2025-12-22T15:20:21Z",
    "link": "http://arxiv.org/pdf/2512.19466v1.pdf",
    "category": [
      "cs.CY",
      "cs.CL",
      "cs.HC"
    ],
    "authors": [
      "Walter Quattrociocchi",
      "Valerio Capraro",
      "Matjaž Perc"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19455v1",
    "title": "SiamGPT: Quality-First Fine-Tuning for Stable Thai Text Generation",
    "summary": "Open-weights large language models remain difficult to deploy for Thai due to unstable generation under complex instructions, despite strong English performance. To mitigate these limitations, We present SiamGPT-32B, an open-weights model based on Qwen3-32B, fine-tuned with a Quality-First strategy emphasizing curated supervision over data scale. The fine-tuning pipeline combines translated high-complexity English instruction data with a Thai-adapted AutoIF framework for instruction and linguistic constraints. Using supervised fine-tuning only, without continual pretraining or corpus expansion, SiamGPT-32B improves instruction adherence, multi-turn robustness, and linguistic stability. Evaluations on the SEA-HELM benchmark show that SiamGPT-32B achieves the strongest overall performance among similar-scale open-weights Thai models, with consistent gains in instruction following, multi-turn dialogue, and natural language understanding.",
    "published": "2025-12-22T15:00:25Z",
    "updated": "2025-12-22T15:00:25Z",
    "link": "http://arxiv.org/pdf/2512.19455v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Thittipat Pairatsuppawat",
      "Abhibhu Tachaapornchai",
      "Paweekorn Kusolsomboon",
      "Chutikan Chaiwong",
      "Thodsaporn Chay-intr",
      "Kobkrit Viriyayudhakorn",
      "Nongnuch Ketui",
      "Aslan B. Wong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19432v1",
    "title": "MobileWorld: Benchmarking Autonomous Mobile Agents in Agent-User Interactive, and MCP-Augmented Environments",
    "summary": "Among existing online mobile-use benchmarks, AndroidWorld has emerged as the dominant benchmark due to its reproducible environment and deterministic evaluation; however, recent agents achieving over 90% success rates indicate its saturation and motivate the need for a more challenging benchmark. In addition, its environment lacks key application categories, such as e-commerce and enterprise communication, and does not reflect realistic mobile-use scenarios characterized by vague user instructions and hybrid tool usage. To bridge this gap, we introduce MobileWorld, a substantially more challenging benchmark designed to better reflect real-world mobile usage, comprising 201 tasks across 20 applications, while maintaining the same level of reproducible evaluation as AndroidWorld. The difficulty of MobileWorld is twofold. First, it emphasizes long-horizon tasks with cross-application interactions: MobileWorld requires nearly twice as many task-completion steps on average (27.8 vs. 14.3) and includes far more multi-application tasks (62.2% vs. 9.5%) compared to AndroidWorld. Second, MobileWorld extends beyond standard GUI manipulation by introducing novel task categories, including agent-user interaction and MCP-augmented tasks. To ensure robust evaluation, we provide snapshot-based container environment and precise functional verifications, including backend database inspection and task callback APIs. We further develop a planner-executor agentic framework with extended action spaces to support user interactions and MCP calls. Our results reveal a sharp performance drop compared to AndroidWorld, with the best agentic framework and end-to-end model achieving 51.7% and 20.9% success rates, respectively. Our analysis shows that current models struggle significantly with user interaction and MCP calls, offering a strategic roadmap toward more robust, next-generation mobile intelligence.",
    "published": "2025-12-22T14:31:28Z",
    "updated": "2025-12-22T14:31:28Z",
    "link": "http://arxiv.org/pdf/2512.19432v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Quyu Kong",
      "Xu Zhang",
      "Zhenyu Yang",
      "Nolan Gao",
      "Chen Liu",
      "Panrong Tong",
      "Chenglin Cai",
      "Hanzhang Zhou",
      "Jianan Zhang",
      "Liangyu Chen",
      "Zhidan Liu",
      "Steven Hoi",
      "Yue Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19424v1",
    "title": "CodeSimpleQA: Scaling Factuality in Code Large Language Models",
    "summary": "Large language models (LLMs) have made significant strides in code generation, achieving impressive capabilities in synthesizing code snippets from natural language instructions. However, a critical challenge remains in ensuring LLMs generate factually accurate responses about programming concepts, technical implementations, etc. Most previous code-related benchmarks focus on code execution correctness, overlooking the factual accuracy of programming knowledge. To address this gap, we present CodeSimpleQA, a comprehensive bilingual benchmark designed to evaluate the factual accuracy of code LLMs in answering code-related questions, which contains carefully curated question-answer pairs in both English and Chinese, covering diverse programming languages and major computer science domains. Further, we create CodeSimpleQA-Instruct, a large-scale instruction corpus with 66M samples, and develop a post-training framework combining supervised fine-tuning and reinforcement learning. Our comprehensive evaluation of diverse LLMs reveals that even frontier LLMs struggle with code factuality. Our proposed framework demonstrates substantial improvements over the base model, underscoring the critical importance of factuality-aware alignment in developing reliable code LLMs.",
    "published": "2025-12-22T14:27:17Z",
    "updated": "2025-12-22T14:27:17Z",
    "link": "http://arxiv.org/pdf/2512.19424v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Jian Yang",
      "Wei Zhang",
      "Yizhi Li",
      "Shawn Guo",
      "Haowen Wang",
      "Aishan Liu",
      "Ge Zhang",
      "Zili Wang",
      "Zhoujun Li",
      "Xianglong Liu",
      "Weifeng Lv"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19414v1",
    "title": "From Retrieval to Reasoning: A Framework for Cyber Threat Intelligence NER with Explicit and Adaptive Instructions",
    "summary": "The automation of Cyber Threat Intelligence (CTI) relies heavily on Named Entity Recognition (NER) to extract critical entities from unstructured text. Currently, Large Language Models (LLMs) primarily address this task through retrieval-based In-Context Learning (ICL). This paper analyzes this mainstream paradigm, revealing a fundamental flaw: its success stems not from global semantic similarity but largely from the incidental overlap of entity types within retrieved examples. This exposes the limitations of relying on unreliable implicit induction. To address this, we propose TTPrompt, a framework shifting from implicit induction to explicit instruction. TTPrompt maps the core concepts of CTI's Tactics, Techniques, and Procedures (TTPs) into an instruction hierarchy: formulating task definitions as Tactics, guiding strategies as Techniques, and annotation guidelines as Procedures. Furthermore, to handle the adaptability challenge of static guidelines, we introduce Feedback-driven Instruction Refinement (FIR). FIR enables LLMs to self-refine guidelines by learning from errors on minimal labeled data, adapting to distinct annotation dialects. Experiments on five CTI NER benchmarks demonstrate that TTPrompt consistently surpasses retrieval-based baselines. Notably, with refinement on just 1% of training data, it rivals models fine-tuned on the full dataset. For instance, on LADDER, its Micro F1 of 71.96% approaches the fine-tuned baseline, and on the complex CTINexus, its Macro F1 exceeds the fine-tuned ACLM model by 10.91%.",
    "published": "2025-12-22T14:13:01Z",
    "updated": "2025-12-22T14:13:01Z",
    "link": "http://arxiv.org/pdf/2512.19414v1.pdf",
    "category": [
      "cs.CR",
      "cs.CL"
    ],
    "authors": [
      "Jiaren Peng",
      "Hongda Sun",
      "Xuan Tian",
      "Cheng Huang",
      "Zeqing Li",
      "Rui Yan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.08398v2",
    "title": "Ontology-Based Knowledge Graph Framework for Industrial Standard Documents via Hierarchical and Propositional Structuring",
    "summary": "Ontology-based knowledge graph (KG) construction is a core technology that enables multidimensional understanding and advanced reasoning over domain knowledge. Industrial standards, in particular, contain extensive technical information and complex rules presented in highly structured formats that combine tables, scopes of application, constraints, exceptions, and numerical calculations, making KG construction especially challenging. In this study, we propose a method that organizes such documents into a hierarchical semantic structure, decomposes sentences and tables into atomic propositions derived from conditional and numerical rules, and integrates them into an ontology-knowledge graph through LLM-based triple extraction. Our approach captures both the hierarchical and logical structures of documents, effectively representing domain-specific semantics that conventional methods fail to reflect. To verify its effectiveness, we constructed rule, table, and multi-hop QA datasets, as well as a toxic clause detection dataset, from industrial standards, and implemented an ontology-aware KG-RAG framework for comparative evaluation. Experimental results show that our method achieves significant performance improvements across all QA types compared to existing KG-RAG approaches. This study demonstrates that reliable and scalable knowledge representation is feasible even for industrial documents with intertwined conditions, constraints, and scopes, contributing to future domain-specific RAG development and intelligent document management.",
    "published": "2025-12-09T09:26:37Z",
    "updated": "2025-12-22T13:57:26Z",
    "link": "http://arxiv.org/pdf/2512.08398v2.pdf",
    "category": [
      "cs.IR",
      "cs.CL"
    ],
    "authors": [
      "Jiin Park",
      "Hyuna Jeon",
      "Yoonseo Lee",
      "Jisu Hong",
      "Misuk Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19400v1",
    "title": "Kunnafonidilaw ka Cadeau: an ASR dataset of present-day Bambara",
    "summary": "We present Kunkado, a 160-hour Bambara ASR dataset compiled from Malian radio archives to capture present-day spontaneous speech across a wide range of topics. It includes code-switching, disfluencies, background noise, and overlapping speakers that practical ASR systems encounter in real-world use. We finetuned Parakeet-based models on a 33.47-hour human-reviewed subset and apply pragmatic transcript normalization to reduce variability in number formatting, tags, and code-switching annotations. Evaluated on two real-world test sets, finetuning with Kunkado reduces WER from 44.47\\% to 37.12\\% on one and from 36.07\\% to 32.33\\% on the other. In human evaluation, the resulting model also outperforms a comparable system with the same architecture trained on 98 hours of cleaner, less realistic speech. We release the data and models to support robust ASR for predominantly oral languages.",
    "published": "2025-12-22T13:52:33Z",
    "updated": "2025-12-22T13:52:33Z",
    "link": "http://arxiv.org/pdf/2512.19400v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yacouba Diarra",
      "Panga Azazia Kamate",
      "Nouhoum Souleymane Coulibaly",
      "Michael Leventhal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.16229v2",
    "title": "LoPA: Scaling dLLM Inference via Lookahead Parallel Decoding",
    "summary": "Diffusion Large Language Models (dLLMs) have demonstrated significant potential for high-speed inference. However, current confidence-driven decoding strategies are constrained by limited parallelism, typically achieving only 1--3 tokens per forward pass (TPF). In this work, we identify that the degree of parallelism during dLLM inference is highly sensitive to the Token Filling Order (TFO). Then, we introduce Lookahead PArallel Decoding LoPA, a training-free, plug-and-play algorithm, to identify a superior TFO and hence accelerate inference. LoPA concurrently explores distinct candidate TFOs via parallel branches, and selects the one with the highest potential for future parallelism based on branch confidence. We apply LoPA to the state-of-the-art D2F model and observe a substantial enhancement in decoding efficiency. Notably, LoPA increases the TPF of D2F-Dream to 10.1 on the GSM8K while maintaining performance superior to the Dream baseline. Furthermore, to facilitate this unprecedented degree of parallelism, we develop a specialized multi-device inference system featuring Branch Parallelism (BP), which achieves a single-sample throughput of 1073.9 tokens per second under multi-GPU deployment. The code is available at https://github.com/zhijie-group/LoPA.",
    "published": "2025-12-18T06:22:01Z",
    "updated": "2025-12-22T13:29:11Z",
    "link": "http://arxiv.org/pdf/2512.16229v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Chenkai Xu",
      "Yijie Jin",
      "Jiajun Li",
      "Yi Tu",
      "Guoping Long",
      "Dandan Tu",
      "Mingcong Song",
      "Hongjie Si",
      "Tianqi Hou",
      "Junchi Yan",
      "Zhijie Deng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19378v1",
    "title": "HATS: High-Accuracy Triple-Set Watermarking for Large Language Models",
    "summary": "Misuse of LLM-generated text can be curbed by watermarking techniques that embed implicit signals into the output. We propose a watermark that partitions the vocabulary at each decoding step into three sets (Green/Yellow/Red) with fixed ratios and restricts sampling to the Green and Yellow sets. At detection time, we replay the same partitions, compute Green-enrichment and Red-depletion statistics, convert them to one-sided z-scores, and aggregate their p-values via Fisher's method to decide whether a passage is watermarked. We implement generation, detection, and testing on Llama 2 7B, and evaluate true-positive rate, false-positive rate, and text quality. Results show that the triple-partition scheme achieves high detection accuracy at fixed FPR while preserving readability.",
    "published": "2025-12-22T13:23:29Z",
    "updated": "2025-12-22T13:23:29Z",
    "link": "http://arxiv.org/pdf/2512.19378v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Zhiqing Hu",
      "Chenxu Zhao",
      "Jiazhong Lu",
      "Xiaolei Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.17231v2",
    "title": "Efficient and Stealthy Jailbreak Attacks via Adversarial Prompt Distillation from LLMs to SLMs",
    "summary": "As the scale and complexity of jailbreaking attacks on large language models (LLMs) continue to escalate, their efficiency and practical applicability are constrained, posing a profound challenge to LLM security. Jailbreaking techniques have advanced from manual prompt engineering to automated methodologies. Recent advances have automated jailbreaking approaches that harness LLMs to generate jailbreak instructions and adversarial examples, delivering encouraging results. Nevertheless, these methods universally include an LLM generation phase, which, due to the complexities of deploying and reasoning with LLMs, impedes effective implementation and broader adoption. To mitigate this issue, we introduce \\textbf{Adversarial Prompt Distillation}, an innovative framework that integrates masked language modeling, reinforcement learning, and dynamic temperature control to distill LLM jailbreaking prowess into smaller language models (SLMs). This methodology enables efficient, robust jailbreak attacks while maintaining high success rates and accommodating a broader range of application contexts. Empirical evaluations affirm the approach's superiority in attack efficacy, resource optimization, and cross-model versatility. Our research underscores the practicality of transferring jailbreak capabilities to SLMs, reveals inherent vulnerabilities in LLMs, and provides novel insights to advance LLM security investigations. Our code is available at: https://github.com/lxgem/Efficient_and_Stealthy_Jailbreak_Attacks_via_Adversarial_Prompt.",
    "published": "2025-05-26T08:27:51Z",
    "updated": "2025-12-22T13:04:30Z",
    "link": "http://arxiv.org/pdf/2506.17231v2.pdf",
    "category": [
      "cs.CL",
      "cs.CR"
    ],
    "authors": [
      "Xiang Li",
      "Chong Zhang",
      "Jia Wang",
      "Fangyu Wu",
      "Yushi Li",
      "Xiaobo Jin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.18998v3",
    "title": "Mirage of Mastery: Memorization Tricks LLMs into Artificially Inflated Self-Knowledge",
    "summary": "When artificial intelligence mistakes memorization for intelligence, it creates a dangerous mirage of reasoning. Existing studies treat memorization and self-knowledge deficits in LLMs as separate issues and do not recognize an intertwining link that degrades the trustworthiness of LLM responses. In our study, we utilize a novel framework to ascertain if LLMs genuinely learn reasoning patterns from training data or merely memorize them to assume competence across problems of similar complexity focused on STEM domains. Our analysis shows a noteworthy problem in generalization: LLMs draw confidence from memorized solutions to infer a higher self-knowledge about their reasoning ability, which manifests as an over 45% inconsistency in feasibility assessments when faced with self-validated, logically coherent task perturbations. This effect is most pronounced in science and medicine domains, which tend to have maximal standardized jargon and problems, further confirming our approach. Significant wavering within the self-knowledge of LLMs also shows flaws in current architectures and training patterns, highlighting the need for techniques that ensure a balanced, consistent stance on models' perceptions of their own knowledge for maximum AI explainability and trustworthiness. Our code and results are available publicly at https://github.com/Sahil-R-Kale/mirage_of_mastery",
    "published": "2025-06-23T18:01:16Z",
    "updated": "2025-12-22T12:50:45Z",
    "link": "http://arxiv.org/pdf/2506.18998v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Sahil Kale"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.02025v2",
    "title": "Style Over Story: A Process-Oriented Study of Authorial Creativity in Large Language Models",
    "summary": "Evaluations of large language models (LLMs)' creativity have focused primarily on the quality of their outputs rather than the processes that shape them. This study takes a process-oriented approach, drawing on narratology to examine LLMs as computational authors. We introduce constraint-based decision-making as a lens for authorial creativity. Using controlled prompting to assign authorial personas, we analyze the creative preferences of the models. Our findings show that LLMs consistently emphasize Style over other elements, including Character, Event, and Setting. By also probing the reasoning the models provide for their choices, we show that distinctive profiles emerge across models and argue that our approach provides a novel systematic tool for analyzing AI's authorial creativity.",
    "published": "2025-10-02T13:57:14Z",
    "updated": "2025-12-22T12:27:15Z",
    "link": "http://arxiv.org/pdf/2510.02025v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Donghoon Jung",
      "Jiwoo Choi",
      "Songeun Chae",
      "Seohyon Jung"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19305v1",
    "title": "CienaLLM: Generative Climate-Impact Extraction from News Articles with Autoregressive LLMs",
    "summary": "Understanding and monitoring the socio-economic impacts of climate hazards requires extracting structured information from heterogeneous news articles on a large scale. To that end, we have developed CienaLLM, a modular framework based on schema-guided Generative Information Extraction. CienaLLM uses open-weight Large Language Models for zero-shot information extraction from news articles, and supports configurable prompts and output schemas, multi-step pipelines, and cloud or on-premise inference. To systematically assess how the choice of LLM family, size, precision regime, and prompting strategy affect performance, we run a large factorial study in models, precisions, and prompt engineering techniques. An additional response parsing step nearly eliminates format errors while preserving accuracy; larger models deliver the strongest and most stable performance, while quantization offers substantial efficiency gains with modest accuracy trade-offs; and prompt strategies show heterogeneous, model-specific effects. CienaLLM matches or outperforms the supervised baseline in accuracy for extracting drought impacts from Spanish news, although at a higher inference cost. While evaluated in droughts, the schema-driven and model-agnostic design is suitable for adapting to related information extraction tasks (e.g., other hazards, sectors, or languages) by editing prompts and schemas rather than retraining. We release code, configurations, and schemas to support reproducible use.",
    "published": "2025-12-22T11:53:01Z",
    "updated": "2025-12-22T11:53:01Z",
    "link": "http://arxiv.org/pdf/2512.19305v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Javier Vela-Tambo",
      "Jorge Gracia",
      "Fernando Dominguez-Castro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19173v1",
    "title": "CycleChart: A Unified Consistency-Based Learning Framework for Bidirectional Chart Understanding and Generation",
    "summary": "Current chart-specific tasks, such as chart question answering, chart parsing, and chart generation, are typically studied in isolation, preventing models from learning the shared semantics that link chart generation and interpretation. We introduce CycleChart, a consistency-based learning framework for bidirectional chart understanding and generation. CycleChart adopts a schema-centric formulation as a common interface across tasks. We construct a consistent multi-task dataset, where each chart sample includes aligned annotations for schema prediction, data parsing, and question answering. To learn cross-directional chart semantics, CycleChart introduces a generate-parse consistency objective: the model generates a chart schema from a table and a textual query, then learns to recover the schema and data from the generated chart, enforcing semantic alignment across directions. CycleChart achieves strong results on chart generation, chart parsing, and chart question answering, demonstrating improved cross-task generalization and marking a step toward more general chart understanding models.",
    "published": "2025-12-22T09:07:34Z",
    "updated": "2025-12-22T09:07:34Z",
    "link": "http://arxiv.org/pdf/2512.19173v1.pdf",
    "category": [
      "cs.CL",
      "cs.CV"
    ],
    "authors": [
      "Dazhen Deng",
      "Sen Yang",
      "Yuchen He",
      "Yuan Tian",
      "Yingcai Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19171v1",
    "title": "JEPA-Reasoner: Decoupling Latent Reasoning from Token Generation",
    "summary": "While Joint-Embedding Predictive Architecture (JEPA) has emerged as a powerful architecture for learning rich latent representations, it fundamentally lacks generative abilities. Meanwhile, latent space reasoning attempts for Transformer models like COCONUT do improve performance, but they ultimately rely on token-by-token generation, which still accumulates compounding error and relies on context information to gain reasoning insights. To address these limitations, we propose JEPA-Reasoner, a novel JEPA model enhanced with generative ability that reasons in latent space. We augment it with a separate action-taker model, Talker, to produce human-readable sentences. Our approach demonstrates that decoupling latent space reasoning and token generation enables JEPA-Reasoner to produce mixed latent vectors that might lay the foundation for multi-threaded reasoning, while performing autoregressive generation with superior robustness to compounding error.",
    "published": "2025-12-22T09:05:06Z",
    "updated": "2025-12-22T09:05:06Z",
    "link": "http://arxiv.org/pdf/2512.19171v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Bingyang Kelvin Liu",
      "Ziyu Patrick Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19161v1",
    "title": "From Speech to Subtitles: Evaluating ASR Models in Subtitling Italian Television Programs",
    "summary": "Subtitles are essential for video accessibility and audience engagement. Modern Automatic Speech Recognition (ASR) systems, built upon Encoder-Decoder neural network architectures and trained on massive amounts of data, have progressively reduced transcription errors on standard benchmark datasets. However, their performance in real-world production environments, particularly for non-English content like long-form Italian videos, remains largely unexplored. This paper presents a case study on developing a professional subtitling system for an Italian media company. To inform our system design, we evaluated four state-of-the-art ASR models (Whisper Large v2, AssemblyAI Universal, Parakeet TDT v3 0.6b, and WhisperX) on a 50-hour dataset of Italian television programs. The study highlights their strengths and limitations, benchmarking their performance against the work of professional human subtitlers. The findings indicate that, while current models cannot meet the media industry's accuracy needs for full autonomy, they can serve as highly effective tools for enhancing human productivity. We conclude that a human-in-the-loop (HITL) approach is crucial and present the production-grade, cloud-based infrastructure we designed to support this workflow.",
    "published": "2025-12-22T08:57:16Z",
    "updated": "2025-12-22T08:57:16Z",
    "link": "http://arxiv.org/pdf/2512.19161v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Alessandro Lucca",
      "Francesco Pierri"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.09566v3",
    "title": "Syzygy of Thoughts: Improving LLM CoT with the Minimal Free Resolution",
    "summary": "Chain-of-Thought (CoT) prompting enhances the reasoning of large language models (LLMs) by decomposing problems into sequential steps, mimicking human logic and reducing errors. However, complex tasks with vast solution spaces and vague constraints often exceed the capacity of a single reasoning chain. Inspired by Minimal Free Resolution (MFR) in commutative algebra and algebraic geometry, we propose Syzygy of Thoughts (SoT)-a novel framework that extends CoT by introducing auxiliary, interrelated reasoning paths. SoT captures deeper logical dependencies, enabling more robust and structured problem-solving. MFR decomposes a module into a sequence of free modules with minimal rank, providing a structured analytical approach to complex systems. This method introduces the concepts of \"Module\", \"Betti numbers\",\"Freeness\", \"Mapping\", \"Exactness\" and \"Minimality\", enabling the systematic decomposition of the original complex problem into logically complete minimal subproblems while preserving key problem features and reducing reasoning length. We tested SoT across diverse datasets (e.g., GSM8K, MATH) and models (e.g., GPT-4o-mini, Qwen2.5), achieving inference accuracy that matches or surpasses mainstream CoTs standards. Additionally, by aligning the sampling process with algebraic constraints, our approach enhances the scalability of inference time in LLMs, ensuring both transparent reasoning and high performance. Our code will be publicly available at https://github.com/dlMARiA/Syzygy-of-thoughts.",
    "published": "2025-04-13T13:35:41Z",
    "updated": "2025-12-22T08:34:18Z",
    "link": "http://arxiv.org/pdf/2504.09566v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Chenghao Li",
      "Chaoning Zhang",
      "Yi Lu",
      "Jiaquan Zhang",
      "Qigan Sun",
      "Xudong Wang",
      "Jiwei Wei",
      "Guoqing Wang",
      "Yang Yang",
      "Heng Tao Shen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19134v1",
    "title": "QuCo-RAG: Quantifying Uncertainty from the Pre-training Corpus for Dynamic Retrieval-Augmented Generation",
    "summary": "Dynamic Retrieval-Augmented Generation adaptively determines when to retrieve during generation to mitigate hallucinations in large language models (LLMs). However, existing methods rely on model-internal signals (e.g., logits, entropy), which are fundamentally unreliable because LLMs are typically ill-calibrated and often exhibit high confidence in erroneous outputs. We propose QuCo-RAG, which shifts from subjective confidence to objective statistics computed from pre-training data. Our method quantifies uncertainty through two stages: (1) before generation, we identify low-frequency entities indicating long-tail knowledge gaps; (2) during generation, we verify entity co-occurrence in the pre-training corpus, where zero co-occurrence often signals hallucination risk. Both stages leverage Infini-gram for millisecond-latency queries over 4 trillion tokens, triggering retrieval when uncertainty is high. Experiments on multi-hop QA benchmarks show QuCo-RAG achieves EM gains of 5--12 points over state-of-the-art baselines with OLMo-2 models, and transfers effectively to models with undisclosed pre-training data (Llama, Qwen, GPT), improving EM by up to 14 points. Domain generalization on biomedical QA further validates the robustness of our paradigm. These results establish corpus-grounded verification as a principled, practically model-agnostic paradigm for dynamic RAG. Our code is publicly available at https://github.com/ZhishanQ/QuCo-RAG.",
    "published": "2025-12-22T08:28:05Z",
    "updated": "2025-12-22T08:28:05Z",
    "link": "http://arxiv.org/pdf/2512.19134v1.pdf",
    "category": [
      "cs.CL",
      "cs.IR"
    ],
    "authors": [
      "Dehai Min",
      "Kailin Zhang",
      "Tongtong Wu",
      "Lu Cheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19126v1",
    "title": "AWPO: Enhancing Tool-Use of Large Language Models through Explicit Integration of Reasoning Rewards",
    "summary": "While reinforcement learning (RL) shows promise in training tool-use large language models (LLMs) using verifiable outcome rewards, existing methods largely overlook the potential of explicit reasoning rewards to bolster reasoning and tool utilization. Furthermore, natively combining reasoning and outcome rewards may yield suboptimal performance or conflict with the primary optimization objective. To address this, we propose advantage-weighted policy optimization (AWPO) -- a principled RL framework that effectively integrates explicit reasoning rewards to enhance tool-use capability. AWPO incorporates variance-aware gating and difficulty-aware weighting to adaptively modulate advantages from reasoning signals based on group-relative statistics, alongside a tailored clipping mechanism for stable optimization. Extensive experiments demonstrate that AWPO achieves state-of-the-art performance across standard tool-use benchmarks, significantly outperforming strong baselines and leading closed-source models in challenging multi-turn scenarios. Notably, with exceptional parameter efficiency, our 4B model surpasses Grok-4 by 16.0 percent in multi-turn accuracy while preserving generalization capability on the out-of-distribution MMLU-Pro benchmark.",
    "published": "2025-12-22T08:07:00Z",
    "updated": "2025-12-22T08:07:00Z",
    "link": "http://arxiv.org/pdf/2512.19126v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Zihan Lin",
      "Xiaohan Wang",
      "Hexiong Yang",
      "Jiajun Chai",
      "Jie Cao",
      "Guojun Yin",
      "Wei Lin",
      "Ran He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19125v1",
    "title": "SAP: Syntactic Attention Pruning for Transformer-based Language Models",
    "summary": "This paper introduces Syntactic Attention Pruning (SAP), a novel method for effectively pruning attention heads in Transformer models. Unlike conventional approaches that rely solely on mathematical analysis of model weights and activations, SAP incorporates both the syntactic structure and attention patterns of sentences to guide the pruning process. By leveraging these linguistic features, SAP not only achieves performance comparable to state-of-the-art methods but also enhances the interpretability of model behavior. To further improve robustness, we propose Candidate Filtering (CF), a mechanism that prioritizes heads based on their contribution to model performance, mitigating degradation during pruning. Experimental results indicate that SAP effectively preserves critical heads of a high density of strong attention values, outperforming existing head pruning strategies in retrain-free settings. These findings position SAP as a promising foundation for a new direction in model compression research, offering high flexibility for pruning across all transformer-based language models.",
    "published": "2025-12-22T08:05:01Z",
    "updated": "2025-12-22T08:05:01Z",
    "link": "http://arxiv.org/pdf/2512.19125v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Tzu-Yun Lee",
      "Ding-Yong Hong",
      "Jan-Jan Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19122v1",
    "title": "BanglaForge: LLM Collaboration with Self-Refinement for Bangla Code Generation",
    "summary": "Bangla is a low-resource language for code generation, lacking large-scale annotated datasets and tools to transform natural language specifications into executable programs. This makes Bangla-to-code generation a challenging task requiring innovative solutions. To address this, we introduce BanglaForge, a novel framework for generating code from Bangla function descriptions. BanglaForge leverages a retrieval-augmented dual-model collaboration paradigm with self-refinement, combining in-context learning, llm-based translation, systematic prompt engineering, and iterative self-refinement based on execution feedback, where a coder generates initial solutions and a reviewer enhances them for robustness. On the BLP-2025 Bangla Code Generation benchmark, BanglaForge achieves a competitive Pass@1 accuracy of 84.00%, demonstrating the effectiveness of retrieval, model collaboration, and self-refinement for low-resource Bangla code generation.",
    "published": "2025-12-22T07:53:16Z",
    "updated": "2025-12-22T07:53:16Z",
    "link": "http://arxiv.org/pdf/2512.19122v1.pdf",
    "category": [
      "cs.SE",
      "cs.CL"
    ],
    "authors": [
      "Mahir Labib Dihan",
      "Sadif Ahmed",
      "Md Nafiu Rahman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19117v1",
    "title": "Stop saying LLM: Large Discourse Models (LDM) and Artificial Discursive Agent (ADA)?",
    "summary": "This paper proposes an epistemological shift in the analysis of large generative models, replacing the category ''Large Language Models'' (LLM) with that of ''Large Discourse Models'' (LDM), and then with that of Artificial Discursive Agent (ADA). The theoretical framework is based on an ontological triad distinguishing three regulatory instances: the apprehension of the phenomenal regularities of the referential world, the structuring of embodied cognition, and the structural-linguistic sedimentation of the utterance within a socio-historical context. LDMs, operating on the product of these three instances (the document), model the discursive projection of a portion of human experience reified by the learning corpus. The proposed program aims to replace the ''fascination/fear'' dichotomy with public trials and procedures that make the place, uses, and limits of artificial discursive agents in contemporary social space decipherable, situating this approach within a perspective of governance and co-regulation involving the State, industry, civil society, and academia.",
    "published": "2025-12-22T07:43:43Z",
    "updated": "2025-12-22T07:43:43Z",
    "link": "http://arxiv.org/pdf/2512.19117v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Amar Lakel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19092v1",
    "title": "A Large Language Model Based Method for Complex Logical Reasoning over Knowledge Graphs",
    "summary": "Reasoning over knowledge graphs (KGs) with first-order logic (FOL) queries is challenging due to the inherent incompleteness of real-world KGs and the compositional complexity of logical query structures. Most existing methods rely on embedding entities and relations into continuous geometric spaces and answer queries via differentiable set operations. While effective for simple query patterns, these approaches often struggle to generalize to complex queries involving multiple operators, deeper reasoning chains, or heterogeneous KG schemas. We propose ROG (Reasoning Over knowledge Graphs with large language models), an ensemble-style framework that combines query-aware KG neighborhood retrieval with large language model (LLM)-based chain-of-thought reasoning. ROG decomposes complex FOL queries into sequences of simpler sub-queries, retrieves compact, query-relevant subgraphs as contextual evidence, and performs step-by-step logical inference using an LLM, avoiding the need for task-specific embedding optimization. Experiments on standard KG reasoning benchmarks demonstrate that ROG consistently outperforms strong embedding-based baselines in terms of mean reciprocal rank (MRR), with particularly notable gains on high-complexity query types. These results suggest that integrating structured KG retrieval with LLM-driven logical reasoning offers a robust and effective alternative for complex KG reasoning tasks.",
    "published": "2025-12-22T07:01:05Z",
    "updated": "2025-12-22T07:01:05Z",
    "link": "http://arxiv.org/pdf/2512.19092v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Ziyan Zhang",
      "Chao Wang",
      "Zhuo Chen",
      "Lei Chen",
      "Chiyi Li",
      "Kai Song"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.22255v3",
    "title": "Kronecker Factorization Improves Efficiency and Interpretability of Sparse Autoencoders",
    "summary": "Sparse Autoencoders (SAEs) have demonstrated significant promise in interpreting the hidden states of language models by decomposing them into interpretable latent directions. However, training and interpreting SAEs at scale remains challenging, especially when large dictionary sizes are used. While decoders can leverage sparse-aware kernels for efficiency, encoders still require computationally intensive linear operations with large output dimensions. To address this, we propose KronSAE, a novel architecture that factorizes the latent representation via Kronecker product decomposition, drastically reducing memory and computational overhead. Furthermore, we introduce mAND, a differentiable activation function approximating the binary AND operation, which improves interpretability and performance in our factorized framework.",
    "published": "2025-05-28T11:41:11Z",
    "updated": "2025-12-22T06:48:29Z",
    "link": "http://arxiv.org/pdf/2505.22255v3.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Vadim Kurochkin",
      "Yaroslav Aksenov",
      "Daniil Laptev",
      "Daniil Gavrilov",
      "Nikita Balagansky"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19070v1",
    "title": "Watch Closely: Mitigating Object Hallucinations in Large Vision-Language Models with Disentangled Decoding",
    "summary": "Large Vision-Language Models (LVLMs) bridge the gap between visual and linguistic modalities, demonstrating strong potential across a variety of domains. However, despite significant progress, LVLMs still suffer from severe hallucination issues in object recognition tasks. These models often fail to accurately identify certain objects, leading to text generation that appears fluent but does not correspond to the visual content, which can have serious consequences in real-world applications. Recently, several methods have been proposed to alleviate LVLM hallucinations, but most focus solely on reducing hallucinations in the language modality. To mitigate hallucinations in both the language and visual modalities, we introduce Hallucination Disentangled Decoding (HDD) method that requires no training. HDD enhances the original image by segmenting it and selecting images that augment the original, while also utilizing a blank image to eliminate language prior hallucinations in both the original and segmented images. This design not only reduces the model's dependence on language priors but also enhances its visual performance. (Code: https://github.com/rickeyhhh/Hallucination-Disentangled-Decoding)",
    "published": "2025-12-22T06:20:53Z",
    "updated": "2025-12-22T06:20:53Z",
    "link": "http://arxiv.org/pdf/2512.19070v1.pdf",
    "category": [
      "cs.CV",
      "cs.CL"
    ],
    "authors": [
      "Ruiqi Ma",
      "Yu Yan",
      "Chunhong Zhang",
      "Minghao Yin",
      "XinChao Liu",
      "Zhihong Jin",
      "Zheng Hu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19693v1",
    "title": "The Prism Hypothesis: Harmonizing Semantic and Pixel Representations via Unified Autoencoding",
    "summary": "Deep representations across modalities are inherently intertwined. In this paper, we systematically analyze the spectral characteristics of various semantic and pixel encoders. Interestingly, our study uncovers a highly inspiring and rarely explored correspondence between an encoder's feature spectrum and its functional role: semantic encoders primarily capture low-frequency components that encode abstract meaning, whereas pixel encoders additionally retain high-frequency information that conveys fine-grained detail. This heuristic finding offers a unifying perspective that ties encoder behavior to its underlying spectral structure. We define it as the Prism Hypothesis, where each data modality can be viewed as a projection of the natural world onto a shared feature spectrum, just like the prism. Building on this insight, we propose Unified Autoencoding (UAE), a model that harmonizes semantic structure and pixel details via an innovative frequency-band modulator, enabling their seamless coexistence. Extensive experiments on ImageNet and MS-COCO benchmarks validate that our UAE effectively unifies semantic abstraction and pixel-level fidelity into a single latent space with state-of-the-art performance.",
    "published": "2025-12-22T18:59:57Z",
    "updated": "2025-12-22T18:59:57Z",
    "link": "http://arxiv.org/pdf/2512.19693v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Weichen Fan",
      "Haiwen Diao",
      "Quan Wang",
      "Dahua Lin",
      "Ziwei Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19692v1",
    "title": "Interact2Ar: Full-Body Human-Human Interaction Generation via Autoregressive Diffusion Models",
    "summary": "Generating realistic human-human interactions is a challenging task that requires not only high-quality individual body and hand motions, but also coherent coordination among all interactants. Due to limitations in available data and increased learning complexity, previous methods tend to ignore hand motions, limiting the realism and expressivity of the interactions. Additionally, current diffusion-based approaches generate entire motion sequences simultaneously, limiting their ability to capture the reactive and adaptive nature of human interactions. To address these limitations, we introduce Interact2Ar, the first end-to-end text-conditioned autoregressive diffusion model for generating full-body, human-human interactions. Interact2Ar incorporates detailed hand kinematics through dedicated parallel branches, enabling high-fidelity full-body generation. Furthermore, we introduce an autoregressive pipeline coupled with a novel memory technique that facilitates adaptation to the inherent variability of human interactions using efficient large context windows. The adaptability of our model enables a series of downstream applications, including temporal motion composition, real-time adaptation to disturbances, and extension beyond dyadic to multi-person scenarios. To validate the generated motions, we introduce a set of robust evaluators and extended metrics designed specifically for assessing full-body interactions. Through quantitative and qualitative experiments, we demonstrate the state-of-the-art performance of Interact2Ar.",
    "published": "2025-12-22T18:59:50Z",
    "updated": "2025-12-22T18:59:50Z",
    "link": "http://arxiv.org/pdf/2512.19692v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Pablo Ruiz-Ponce",
      "Sergio Escalera",
      "José García-Rodríguez",
      "Jiankang Deng",
      "Rolandos Alexandros Potamias"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19687v1",
    "title": "Pushing the Frontier of Audiovisual Perception with Large-Scale Multimodal Correspondence Learning",
    "summary": "We introduce Perception Encoder Audiovisual, PE-AV, a new family of encoders for audio and video understanding trained with scaled contrastive learning. Built on PE, PE-AV makes several key contributions to extend representations to audio, and natively support joint embeddings across audio-video, audio-text, and video-text modalities. PE-AV's unified cross-modal embeddings enable novel tasks such as speech retrieval, and set a new state of the art across standard audio and video benchmarks. We unlock this by building a strong audiovisual data engine that synthesizes high-quality captions for O(100M) audio-video pairs, enabling large-scale supervision consistent across modalities. Our audio data includes speech, music, and general sound effects-avoiding single-domain limitations common in prior work. We exploit ten pairwise contrastive objectives, showing that scaling cross-modality and caption-type pairs strengthens alignment and improves zero-shot performance. We further develop PE-A-Frame by fine-tuning PE-AV with frame-level contrastive objectives, enabling fine-grained audio-frame-to-text alignment for tasks such as sound event detection.",
    "published": "2025-12-22T18:59:07Z",
    "updated": "2025-12-22T18:59:07Z",
    "link": "http://arxiv.org/pdf/2512.19687v1.pdf",
    "category": [
      "cs.SD",
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Apoorv Vyas",
      "Heng-Jui Chang",
      "Cheng-Fu Yang",
      "Po-Yao Huang",
      "Luya Gao",
      "Julius Richter",
      "Sanyuan Chen",
      "Matt Le",
      "Piotr Dollár",
      "Christoph Feichtenhofer",
      "Ann Lee",
      "Wei-Ning Hsu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19686v1",
    "title": "Visual-Aware CoT: Achieving High-Fidelity Visual Consistency in Unified Models",
    "summary": "Recently, the introduction of Chain-of-Thought (CoT) has largely improved the generation ability of unified models. However, it is observed that the current thinking process during generation mainly focuses on the text consistency with the text prompt, ignoring the \\textbf{visual context consistency} with the visual reference images during the multi-modal generation, e.g., multi-reference generation. The lack of such consistency results in the failure in maintaining key visual features (like human ID, object attribute, style). To this end, we integrate the visual context consistency into the reasoning of unified models, explicitly motivating the model to sustain such consistency by 1) Adaptive Visual Planning: generating structured visual check list to figure out the visual element of needed consistency keeping, and 2) Iterative Visual Correction: performing self-reflection with the guidance of check lists and refining the generated result in an iterative manner. To achieve this, we use supervised finetuning to teach the model how to plan the visual checking, conduct self-reflection and self-refinement, and use flow-GRPO to further enhance the visual consistency through a customized visual checking reward. The experiments show that our method outperforms both zero-shot unified models and those with text CoTs in multi-modal generation, demonstrating higher visual context consistency.",
    "published": "2025-12-22T18:59:03Z",
    "updated": "2025-12-22T18:59:03Z",
    "link": "http://arxiv.org/pdf/2512.19686v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zixuan Ye",
      "Quande Liu",
      "Cong Wei",
      "Yuanxing Zhang",
      "Xintao Wang",
      "Pengfei Wan",
      "Kun Gai",
      "Wenhan Luo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19684v1",
    "title": "Zero-shot Reconstruction of In-Scene Object Manipulation from Video",
    "summary": "We build the first system to address the problem of reconstructing in-scene object manipulation from a monocular RGB video. It is challenging due to ill-posed scene reconstruction, ambiguous hand-object depth, and the need for physically plausible interactions. Existing methods operate in hand centric coordinates and ignore the scene, hindering metric accuracy and practical use. In our method, we first use data-driven foundation models to initialize the core components, including the object mesh and poses, the scene point cloud, and the hand poses. We then apply a two-stage optimization that recovers a complete hand-object motion from grasping to interaction, which remains consistent with the scene information observed in the input video.",
    "published": "2025-12-22T18:58:29Z",
    "updated": "2025-12-22T18:58:29Z",
    "link": "http://arxiv.org/pdf/2512.19684v1.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Dixuan Lin",
      "Tianyou Wang",
      "Zhuoyang Pan",
      "Yufu Wang",
      "Lingjie Liu",
      "Kostas Daniilidis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19683v1",
    "title": "From Indoor to Open World: Revealing the Spatial Reasoning Gap in MLLMs",
    "summary": "While Multimodal Large Language Models (MLLMs) have achieved impressive performance on semantic tasks, their spatial intelligence--crucial for robust and grounded AI systems--remains underdeveloped. Existing benchmarks fall short of diagnosing this limitation: they either focus on overly simplified qualitative reasoning or rely on domain-specific indoor data, constrained by the lack of outdoor datasets with verifiable metric ground truth. To bridge this gap, we introduce a large-scale benchmark built from pedestrian-perspective videos captured with synchronized stereo cameras, LiDAR, and IMU/GPS sensors. This dataset provides metrically precise 3D information, enabling the automatic generation of spatial reasoning questions that span a hierarchical spectrum--from qualitative relational reasoning to quantitative metric and kinematic understanding. Evaluations reveal that the performance gains observed in structured indoor benchmarks vanish in open-world settings. Further analysis using synthetic abnormal scenes and blinding tests confirms that current MLLMs depend heavily on linguistic priors instead of grounded visual reasoning. Our benchmark thus provides a principled platform for diagnosing these limitations and advancing physically grounded spatial intelligence.",
    "published": "2025-12-22T18:58:12Z",
    "updated": "2025-12-22T18:58:12Z",
    "link": "http://arxiv.org/pdf/2512.19683v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Mingrui Wu",
      "Zhaozhi Wang",
      "Fangjinhua Wang",
      "Jiaolong Yang",
      "Marc Pollefeys",
      "Tong Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.20072v3",
    "title": "Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies",
    "summary": "Vision-Language-Action (VLA) models adapt large vision-language backbones to map images and instructions into robot actions. However, prevailing VLAs either generate actions auto-regressively in a fixed left-to-right order or attach separate MLP or diffusion heads outside the backbone, leading to fragmented information pathways and specialized training requirements that hinder a unified, scalable architecture. We present Discrete Diffusion VLA, a unified-transformer policy that models discretized action chunks with discrete diffusion. The design retains diffusion's progressive refinement paradigm while remaining natively compatible with the discrete token interface of VLMs. Our method achieves an adaptive decoding order that resolves easy action elements before harder ones and uses secondary re-masking to revisit uncertain predictions across refinement rounds, which improves consistency and enables robust error correction. This unified decoder preserves pre-trained vision-language priors, supports parallel decoding, breaks the autoregressive bottleneck, and reduces the number of function evaluations. Discrete Diffusion VLA achieves 96.3% avg. success rates on LIBERO, 71.2% visual matching on SimplerEnv-Fractal and 54.2% overall on SimplerEnv-Bridge. We also provide ablation study on vision-language ability retention on LIBERO-OOD (Out-of-Distribution) benchmark, with our method improving over autoregressive, MLP decoder and continuous diffusion baselines. These findings indicate that discrete-diffusion VLA supports precise action modeling and consistent training, laying groundwork for scaling VLA to larger models and datasets. Our code is available at https://github.com/Liang-ZX/DiscreteDiffusionVLA/tree/libero.",
    "published": "2025-08-27T17:39:11Z",
    "updated": "2025-12-22T18:57:39Z",
    "link": "http://arxiv.org/pdf/2508.20072v3.pdf",
    "category": [
      "cs.CV",
      "cs.LG",
      "cs.RO"
    ],
    "authors": [
      "Zhixuan Liang",
      "Yizhuo Li",
      "Tianshuo Yang",
      "Chengyue Wu",
      "Sitong Mao",
      "Tian Nian",
      "Liuao Pei",
      "Shunbo Zhou",
      "Xiaokang Yang",
      "Jiangmiao Pang",
      "Yao Mu",
      "Ping Luo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19680v1",
    "title": "VA-$π$: Variational Policy Alignment for Pixel-Aware Autoregressive Generation",
    "summary": "Autoregressive (AR) visual generation relies on tokenizers to map images to and from discrete sequences. However, tokenizers are trained to reconstruct clean images from ground-truth tokens, while AR generators are optimized only for token likelihood. This misalignment leads to generated token sequences that may decode into low-quality images, without direct supervision from the pixel space. We propose VA-$π$, a lightweight post-training framework that directly optimizes AR models with a principled pixel-space objective. VA-$π$ formulates the generator-tokenizer alignment as a variational optimization, deriving an evidence lower bound (ELBO) that unifies pixel reconstruction and autoregressive modeling. To optimize under the discrete token space, VA-$π$ introduces a reinforcement-based alignment strategy that treats the AR generator as a policy, uses pixel-space reconstruction quality as its intrinsic reward. The reward is measured by how well the predicted token sequences can reconstruct the original image under teacher forcing, giving the model direct pixel-level guidance without expensive free-running sampling. The regularization term of the ELBO serves as a natural regularizer, maintaining distributional consistency of tokens. VA-$π$ enables rapid adaptation of existing AR generators, without neither tokenizer retraining nor external reward models. With only 1% ImageNet-1K data and 25 minutes of tuning, it reduces FID from 14.36 to 7.65 and improves IS from 86.55 to 116.70 on LlamaGen-XXL, while also yielding notable gains in the text-to-image task on GenEval for both visual generation model (LlamaGen: from 0.306 to 0.339) and unified multi-modal model (Janus-Pro: from 0.725 to 0.744). Code is available at https://github.com/Lil-Shake/VA-Pi.",
    "published": "2025-12-22T18:54:30Z",
    "updated": "2025-12-22T18:54:30Z",
    "link": "http://arxiv.org/pdf/2512.19680v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xinyao Liao",
      "Qiyuan He",
      "Kai Xu",
      "Xiaoye Qu",
      "Yicong Li",
      "Wei Wei",
      "Angela Yao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19676v1",
    "title": "Efficient Vision Mamba for MRI Super-Resolution via Hybrid Selective Scanning",
    "summary": "Background: High-resolution MRI is critical for diagnosis, but long acquisition times limit clinical use. Super-resolution (SR) can enhance resolution post-scan, yet existing deep learning methods face fidelity-efficiency trade-offs. Purpose: To develop a computationally efficient and accurate deep learning framework for MRI SR that preserves anatomical detail for clinical integration. Materials and Methods: We propose a novel SR framework combining multi-head selective state-space models (MHSSM) with a lightweight channel MLP. The model uses 2D patch extraction with hybrid scanning to capture long-range dependencies. Each MambaFormer block integrates MHSSM, depthwise convolutions, and gated channel mixing. Evaluation used 7T brain T1 MP2RAGE maps (n=142) and 1.5T prostate T2w MRI (n=334). Comparisons included Bicubic interpolation, GANs (CycleGAN, Pix2pix, SPSR), transformers (SwinIR), Mamba (MambaIR), and diffusion models (I2SB, Res-SRDiff). Results: Our model achieved superior performance with exceptional efficiency. For 7T brain data: SSIM=0.951+-0.021, PSNR=26.90+-1.41 dB, LPIPS=0.076+-0.022, GMSD=0.083+-0.017, significantly outperforming all baselines (p<0.001). For prostate data: SSIM=0.770+-0.049, PSNR=27.15+-2.19 dB, LPIPS=0.190+-0.095, GMSD=0.087+-0.013. The framework used only 0.9M parameters and 57 GFLOPs, reducing parameters by 99.8% and computation by 97.5% versus Res-SRDiff, while outperforming SwinIR and MambaIR in accuracy and efficiency. Conclusion: The proposed framework provides an efficient, accurate MRI SR solution, delivering enhanced anatomical detail across datasets. Its low computational demand and state-of-the-art performance show strong potential for clinical translation.",
    "published": "2025-12-22T18:53:13Z",
    "updated": "2025-12-22T18:53:13Z",
    "link": "http://arxiv.org/pdf/2512.19676v1.pdf",
    "category": [
      "cs.CV",
      "physics.med-ph"
    ],
    "authors": [
      "Mojtaba Safari",
      "Shansong Wang",
      "Vanessa L Wildman",
      "Mingzhe Hu",
      "Zach Eidex",
      "Chih-Wei Chang",
      "Erik H Middlebrooks",
      "Richard L. J Qiu",
      "Pretesh Patel",
      "Ashesh B. Jania",
      "Hui Mao",
      "Zhen Tian",
      "Xiaofeng Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19675v1",
    "title": "Multimodal LLMs for Historical Dataset Construction from Archival Image Scans: German Patents (1877-1918)",
    "summary": "We leverage multimodal large language models (LLMs) to construct a dataset of 306,070 German patents (1877-1918) from 9,562 archival image scans using our LLM-based pipeline powered by Gemini-2.5-Pro and Gemini-2.5-Flash-Lite. Our benchmarking exercise provides tentative evidence that multimodal LLMs can create higher quality datasets than our research assistants, while also being more than 795 times faster and 205 times cheaper in constructing the patent dataset from our image corpus. About 20 to 50 patent entries are embedded on each page, arranged in a double-column format and printed in Gothic and Roman fonts. The font and layout complexity of our primary source material suggests to us that multimodal LLMs are a paradigm shift in how datasets are constructed in economic history. We open-source our benchmarking and patent datasets as well as our LLM-based data pipeline, which can be easily adapted to other image corpora using LLM-assisted coding tools, lowering the barriers for less technical researchers. Finally, we explain the economics of deploying LLMs for historical dataset construction and conclude by speculating on the potential implications for the field of economic history.",
    "published": "2025-12-22T18:53:03Z",
    "updated": "2025-12-22T18:53:03Z",
    "link": "http://arxiv.org/pdf/2512.19675v1.pdf",
    "category": [
      "econ.GN",
      "cs.CV",
      "cs.DL"
    ],
    "authors": [
      "Niclas Griesshaber",
      "Jochen Streb"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.10999v3",
    "title": "DDAE++: Enhancing Diffusion Models Towards Unified Generative and Discriminative Learning",
    "summary": "While diffusion models excel at image synthesis, useful representations have been shown to emerge from generative pre-training, suggesting a path towards unified generative and discriminative learning. However, suboptimal semantic flow within current architectures can hinder this potential: features encoding the richest high-level semantics are underutilized and diluted when propagating through decoding layers, impeding the formation of an explicit semantic bottleneck layer. To address this, we introduce self-conditioning, a lightweight mechanism that reshapes the model's layer-wise semantic hierarchy without external guidance. By aggregating and rerouting intermediate features to guide subsequent decoding layers, our method concentrates more high-level semantics, concurrently strengthening global generative guidance and forming more discriminative representations. This simple approach yields a dual-improvement trend across pixel-space UNet, UViT and latent-space DiT models with minimal overhead. Crucially, it creates an architectural semantic bridge that propagates discriminative improvements into generation and accommodates further techniques such as contrastive self-distillation. Experiments show that our enhanced models, especially self-conditioned DiT, are powerful dual learners that yield strong and transferable representations on image and dense classification tasks, surpassing various generative self-supervised models in linear probing while also improving or maintaining high generation quality.",
    "published": "2025-05-16T08:47:16Z",
    "updated": "2025-12-22T18:48:24Z",
    "link": "http://arxiv.org/pdf/2505.10999v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Weilai Xiang",
      "Hongyu Yang",
      "Di Huang",
      "Yunhong Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19661v1",
    "title": "Over++: Generative Video Compositing for Layer Interaction Effects",
    "summary": "In professional video compositing workflows, artists must manually create environmental interactions-such as shadows, reflections, dust, and splashes-between foreground subjects and background layers. Existing video generative models struggle to preserve the input video while adding such effects, and current video inpainting methods either require costly per-frame masks or yield implausible results. We introduce augmented compositing, a new task that synthesizes realistic, semi-transparent environmental effects conditioned on text prompts and input video layers, while preserving the original scene. To address this task, we present Over++, a video effect generation framework that makes no assumptions about camera pose, scene stationarity, or depth supervision. We construct a paired effect dataset tailored for this task and introduce an unpaired augmentation strategy that preserves text-driven editability. Our method also supports optional mask control and keyframe guidance without requiring dense annotations. Despite training on limited data, Over++ produces diverse and realistic environmental effects and outperforms existing baselines in both effect generation and scene preservation.",
    "published": "2025-12-22T18:39:58Z",
    "updated": "2025-12-22T18:39:58Z",
    "link": "http://arxiv.org/pdf/2512.19661v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Luchao Qi",
      "Jiaye Wu",
      "Jun Myeong Choi",
      "Cary Phillips",
      "Roni Sengupta",
      "Dan B Goldman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.12715v2",
    "title": "AsyMoE: Leveraging Modal Asymmetry for Enhanced Expert Specialization in Large Vision-Language Models",
    "summary": "Large Vision-Language Models (LVLMs) have demonstrated impressive performance on multimodal tasks through scaled architectures and extensive training. However, existing Mixture of Experts (MoE) approaches face challenges due to the asymmetry between visual and linguistic processing. Visual information is spatially complete, while language requires maintaining sequential context. As a result, MoE models struggle to balance modality-specific features and cross-modal interactions. Through systematic analysis, we observe that language experts in deeper layers progressively lose contextual grounding and rely more on parametric knowledge rather than utilizing the provided visual and linguistic information. To address this, we propose AsyMoE, a novel architecture that models this asymmetry using three specialized expert groups. We design intra-modality experts for modality-specific processing, hyperbolic inter-modality experts for hierarchical cross-modal interactions, and evidence-priority language experts to suppress parametric biases and maintain contextual grounding. Extensive experiments demonstrate that AsyMoE achieves 26.58% and 15.45% accuracy improvements over vanilla MoE and modality-specific MoE respectively, with 25.45% fewer activated parameters than dense models.",
    "published": "2025-09-16T06:16:05Z",
    "updated": "2025-12-22T18:22:20Z",
    "link": "http://arxiv.org/pdf/2509.12715v2.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Heng Zhang",
      "Haichuan Hu",
      "Yaomin Shen",
      "Weihao Yu",
      "Yilei Yuan",
      "Haochen You",
      "Guo Cheng",
      "Zijian Zhang",
      "Lubin Gan",
      "Huihui Wei",
      "Hao Zhang",
      "Jin Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.00908v2",
    "title": "GraphGeo: Multi-Agent Debate Framework for Visual Geo-localization with Heterogeneous Graph Neural Networks",
    "summary": "Visual geo-localization requires extensive geographic knowledge and sophisticated reasoning to determine image locations without GPS metadata. Traditional retrieval methods are constrained by database coverage and quality. Recent Large Vision-Language Models (LVLMs) enable direct location reasoning from image content, yet individual models struggle with diverse geographic regions and complex scenes. Existing multi-agent systems improve performance through model collaboration but treat all agent interactions uniformly. They lack mechanisms to handle conflicting predictions effectively. We propose \\textbf{GraphGeo}, a multi-agent debate framework using heterogeneous graph neural networks for visual geo-localization. Our approach models diverse debate relationships through typed edges, distinguishing supportive collaboration, competitive argumentation, and knowledge transfer. We introduce a dual-level debate mechanism combining node-level refinement and edge-level argumentation modeling. A cross-level topology refinement strategy enables co-evolution between graph structure and agent representations. Experiments on multiple benchmarks demonstrate GraphGeo significantly outperforms state-of-the-art methods. Our framework transforms cognitive conflicts between agents into enhanced geo-localization accuracy through structured debate.",
    "published": "2025-11-02T11:58:55Z",
    "updated": "2025-12-22T18:21:18Z",
    "link": "http://arxiv.org/pdf/2511.00908v2.pdf",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "Heng Zheng",
      "Yuling Shi",
      "Xiaodong Gu",
      "Haochen You",
      "Zijian Zhang",
      "Lubin Gan",
      "Hao Zhang",
      "Wenjun Huang",
      "Jin Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19648v1",
    "title": "4D Gaussian Splatting as a Learned Dynamical System",
    "summary": "We reinterpret 4D Gaussian Splatting as a continuous-time dynamical system, where scene motion arises from integrating a learned neural dynamical field rather than applying per-frame deformations. This formulation, which we call EvoGS, treats the Gaussian representation as an evolving physical system whose state evolves continuously under a learned motion law. This unlocks capabilities absent in deformation-based approaches:(1) sample-efficient learning from sparse temporal supervision by modeling the underlying motion law; (2) temporal extrapolation enabling forward and backward prediction beyond observed time ranges; and (3) compositional dynamics that allow localized dynamics injection for controllable scene synthesis. Experiments on dynamic scene benchmarks show that EvoGS achieves better motion coherence and temporal consistency compared to deformation-field baselines while maintaining real-time rendering",
    "published": "2025-12-22T18:20:29Z",
    "updated": "2025-12-22T18:20:29Z",
    "link": "http://arxiv.org/pdf/2512.19648v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Arnold Caleb Asiimwe",
      "Carl Vondrick"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.00767v2",
    "title": "InterPose: Learning to Generate Human-Object Interactions from Large-Scale Web Videos",
    "summary": "Human motion generation has shown great advances thanks to the recent diffusion models trained on large-scale motion capture data. Most of existing works, however, currently target animation of isolated people in empty scenes. Meanwhile, synthesizing realistic human-object interactions in complex 3D scenes remains a critical challenge in computer graphics and robotics. One obstacle towards generating versatile high-fidelity human-object interactions is the lack of large-scale datasets with diverse object manipulations. Indeed, existing motion capture data is typically restricted to single people and manipulations of limited sets of objects. To address this issue, we propose an automatic motion extraction pipeline and use it to collect interaction-rich human motions. Our new dataset InterPose contains 73.8K sequences of 3D human motions and corresponding text captions automatically obtained from 45.8K videos with human-object interactions. We perform extensive experiments and demonstrate InterPose to bring significant improvements to state-of-the-art methods for human motion generation. Moreover, using InterPose we develop an LLM-based agent enabling zero-shot animation of people interacting with diverse objects and scenes.",
    "published": "2025-08-31T09:38:59Z",
    "updated": "2025-12-22T18:14:12Z",
    "link": "http://arxiv.org/pdf/2509.00767v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yangsong Zhang",
      "Abdul Ahad Butt",
      "Gül Varol",
      "Ivan Laptev"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19632v1",
    "title": "Generative diffusion models for agricultural AI: plant image generation, indoor-to-outdoor translation, and expert preference alignment",
    "summary": "The success of agricultural artificial intelligence depends heavily on large, diverse, and high-quality plant image datasets, yet collecting such data in real field conditions is costly, labor intensive, and seasonally constrained. This paper investigates diffusion-based generative modeling to address these challenges through plant image synthesis, indoor-to-outdoor translation, and expert preference aligned fine tuning. First, a Stable Diffusion model is fine tuned on captioned indoor and outdoor plant imagery to generate realistic, text conditioned images of canola and soybean. Evaluation using Inception Score, Frechet Inception Distance, and downstream phenotype classification shows that synthetic images effectively augment training data and improve accuracy. Second, we bridge the gap between high resolution indoor datasets and limited outdoor imagery using DreamBooth-based text inversion and image guided diffusion, generating translated images that enhance weed detection and classification with YOLOv8. Finally, a preference guided fine tuning framework trains a reward model on expert scores and applies reward weighted updates to produce more stable and expert aligned outputs. Together, these components demonstrate a practical pathway toward data efficient generative pipelines for agricultural AI.",
    "published": "2025-12-22T18:07:08Z",
    "updated": "2025-12-22T18:07:08Z",
    "link": "http://arxiv.org/pdf/2512.19632v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Da Tan",
      "Michael Beck",
      "Christopher P. Bidinosti",
      "Robert H. Gulden",
      "Christopher J. Henry"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19629v1",
    "title": "LoGoPlanner: Localization Grounded Navigation Policy with Metric-aware Visual Geometry",
    "summary": "Trajectory planning in unstructured environments is a fundamental and challenging capability for mobile robots. Traditional modular pipelines suffer from latency and cascading errors across perception, localization, mapping, and planning modules. Recent end-to-end learning methods map raw visual observations directly to control signals or trajectories, promising greater performance and efficiency in open-world settings. However, most prior end-to-end approaches still rely on separate localization modules that depend on accurate sensor extrinsic calibration for self-state estimation, thereby limiting generalization across embodiments and environments. We introduce LoGoPlanner, a localization-grounded, end-to-end navigation framework that addresses these limitations by: (1) finetuning a long-horizon visual-geometry backbone to ground predictions with absolute metric scale, thereby providing implicit state estimation for accurate localization; (2) reconstructing surrounding scene geometry from historical observations to supply dense, fine-grained environmental awareness for reliable obstacle avoidance; and (3) conditioning the policy on implicit geometry bootstrapped by the aforementioned auxiliary tasks, thereby reducing error propagation.We evaluate LoGoPlanner in both simulation and real-world settings, where its fully end-to-end design reduces cumulative error while metric-aware geometry memory enhances planning consistency and obstacle avoidance, leading to more than a 27.3\\% improvement over oracle-localization baselines and strong generalization across embodiments and environments. The code and models have been made publicly available on the \\href{https://steinate.github.io/logoplanner.github.io/}{project page}.",
    "published": "2025-12-22T18:03:08Z",
    "updated": "2025-12-22T18:03:08Z",
    "link": "http://arxiv.org/pdf/2512.19629v1.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Jiaqi Peng",
      "Wenzhe Cai",
      "Yuqiang Yang",
      "Tai Wang",
      "Yuan Shen",
      "Jiangmiao Pang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.11154v3",
    "title": "From Easy to Hard: Progressive Active Learning Framework for Infrared Small Target Detection with Single Point Supervision",
    "summary": "Recently, single-frame infrared small target (SIRST) detection with single point supervision has drawn wide-spread attention. However, the latest label evolution with single point supervision (LESPS) framework suffers from instability, excessive label evolution, and difficulty in exerting embedded network performance. Inspired by organisms gradually adapting to their environment and continuously accumulating knowledge, we construct an innovative Progressive Active Learning (PAL) framework, which drives the existing SIRST detection networks progressively and actively recognizes and learns harder samples. Specifically, to avoid the early low-performance model leading to the wrong selection of hard samples, we propose a model pre-start concept, which focuses on automatically selecting a portion of easy samples and helping the model have basic task-specific learning capabilities. Meanwhile, we propose a refined dual-update strategy, which can promote reasonable learning of harder samples and continuous refinement of pseudo-labels. In addition, to alleviate the risk of excessive label evolution, a decay factor is reasonably introduced, which helps to achieve a dynamic balance between the expansion and contraction of target annotations. Extensive experiments show that existing SIRST detection networks equipped with our PAL framework have achieved state-of-the-art (SOTA) results on multiple public datasets. Furthermore, our PAL framework can build an efficient and stable bridge between full supervision and single point supervision tasks. Our code is available at https://github.com/YuChuang1205/PAL",
    "published": "2024-12-15T11:08:49Z",
    "updated": "2025-12-22T17:52:35Z",
    "link": "http://arxiv.org/pdf/2412.11154v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Chuang Yu",
      "Jinmiao Zhao",
      "Yunpeng Liu",
      "Sicheng Zhao",
      "Yimian Dai",
      "Xiangyu Yue"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19605v1",
    "title": "KerJEPA: Kernel Discrepancies for Euclidean Self-Supervised Learning",
    "summary": "Recent breakthroughs in self-supervised Joint-Embedding Predictive Architectures (JEPAs) have established that regularizing Euclidean representations toward isotropic Gaussian priors yields provable gains in training stability and downstream generalization. We introduce a new, flexible family of KerJEPAs, self-supervised learning algorithms with kernel-based regularizers. One instance of this family corresponds to the recently-introduced LeJEPA Epps-Pulley regularizer which approximates a sliced maximum mean discrepancy (MMD) with a Gaussian prior and Gaussian kernel. By expanding the class of viable kernels and priors and computing the closed-form high-dimensional limit of sliced MMDs, we develop alternative KerJEPAs with a number of favorable properties including improved training stability and design flexibility.",
    "published": "2025-12-22T17:41:26Z",
    "updated": "2025-12-22T17:41:26Z",
    "link": "http://arxiv.org/pdf/2512.19605v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Eric Zimmermann",
      "Harley Wiltzer",
      "Justin Szeto",
      "David Alvarez-Melis",
      "Lester Mackey"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19602v1",
    "title": "No Data? No Problem: Robust Vision-Tabular Learning with Missing Values",
    "summary": "Large-scale medical biobanks provide imaging data complemented by extensive tabular information, such as demographics or clinical measurements. However, this abundance of tabular attributes does not reflect real-world datasets, where only a subset of attributes may be available. This discrepancy calls for methods that can leverage all the tabular data during training while remaining robust to missing values at inference. To address this challenge, we propose RoVTL (Robust Vision-Tabular Learning), a framework designed to handle any level of tabular data availability, from 0% to 100%. RoVTL comprises two key stages: contrastive pretraining, where we introduce tabular attribute missingness as data augmentation to promote robustness, and downstream task tuning using a gated cross-attention module for multimodal fusion. During fine-tuning, we employ a novel Tabular More vs. Fewer loss that ranks performance based on the amount of available tabular data. Combined with disentangled gradient learning, this enables consistent performance across all tabular data completeness scenarios. We evaluate RoVTL on cardiac MRI scans from the UK Biobank, demonstrating superior robustness to missing tabular data compared to prior methods. Furthermore, RoVTL successfully generalizes to an external cardiac MRI dataset for multimodal disease classification, and extends to the natural images domain, achieving robust performance on a car advertisements dataset. The code is available at https://github.com/marteczkah/RoVTL.",
    "published": "2025-12-22T17:35:32Z",
    "updated": "2025-12-22T17:35:32Z",
    "link": "http://arxiv.org/pdf/2512.19602v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Marta Hasny",
      "Laura Daza",
      "Keno Bressem",
      "Maxime Di Folco",
      "Julia Schnabel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19584v1",
    "title": "Patlak Parametric Image Estimation from Dynamic PET Using Diffusion Model Prior",
    "summary": "Dynamic PET enables the quantitative estimation of physiology-related parameters and is widely utilized in research and increasingly adopted in clinical settings. Parametric imaging in dynamic PET requires kinetic modeling to estimate voxel-wise physiological parameters based on specific kinetic models. However, parametric images estimated through kinetic model fitting often suffer from low image quality due to the inherently ill-posed nature of the fitting process and the limited counts resulting from non-continuous data acquisition across multiple bed positions in whole-body PET. In this work, we proposed a diffusion model-based kinetic modeling framework for parametric image estimation, using the Patlak model as an example. The score function of the diffusion model was pre-trained on static total-body PET images and served as a prior for both Patlak slope and intercept images by leveraging their patch-wise similarity. During inference, the kinetic model was incorporated as a data-consistency constraint to guide the parametric image estimation. The proposed framework was evaluated on total-body dynamic PET datasets with different dose levels, demonstrating the feasibility and promising performance of the proposed framework in improving parametric image quality.",
    "published": "2025-12-22T17:11:33Z",
    "updated": "2025-12-22T17:11:33Z",
    "link": "http://arxiv.org/pdf/2512.19584v1.pdf",
    "category": [
      "eess.IV",
      "cs.CV",
      "physics.med-ph"
    ],
    "authors": [
      "Ziqian Huang",
      "Boxiao Yu",
      "Siqi Li",
      "Savas Ozdemir",
      "Sangjin Bae",
      "Jae Sung Lee",
      "Guobao Wang",
      "Kuang Gong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19577v1",
    "title": "Deep Learning for Primordial $B$-mode Extraction",
    "summary": "The search for primordial gravitational waves is a central goal of cosmic microwave background (CMB) surveys. Isolating the characteristic $B$-mode polarization signal sourced by primordial gravitational waves is challenging for several reasons: the amplitude of the signal is inherently small; astrophysical foregrounds produce $B$-mode polarization contaminating the signal; and secondary $B$-mode polarization fluctuations are produced via the conversion of $E$ modes. Current and future low-noise, multi-frequency observations enable sufficient precision to address the first two of these challenges such that secondary $B$ modes will become the bottleneck for improved constraints on the amplitude of primordial gravitational waves. The dominant source of secondary $B$-mode polarization is gravitational lensing by large scale structure. Various strategies have been developed to estimate the lensing deflection and to reverse its effects the CMB, thus reducing confusion from lensing $B$ modes in the search for primordial gravitational waves. However, a few complications remain. First, there may be additional sources of secondary $B$-mode polarization, for example from patchy reionization or from cosmic polarization rotation. Second, the statistics of delensed CMB maps can become complicated and non-Gaussian, especially when advanced lensing reconstruction techniques are applied. We previously demonstrated how a deep learning network, ResUNet-CMB, can provide nearly optimal simultaneous estimates of multiple sources of secondary $B$-mode polarization. In this paper, we show how deep learning can be applied to estimate and remove multiple sources of secondary $B$-mode polarization, and we further show how this technique can be used in a likelihood analysis to produce nearly optimal, unbiased estimates of the amplitude of primordial gravitational waves.",
    "published": "2025-12-22T17:03:07Z",
    "updated": "2025-12-22T17:03:07Z",
    "link": "http://arxiv.org/pdf/2512.19577v1.pdf",
    "category": [
      "astro-ph.CO",
      "cs.CV",
      "stat.ML"
    ],
    "authors": [
      "Eric Guzman",
      "Joel Meyers"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19546v1",
    "title": "ActAvatar: Temporally-Aware Precise Action Control for Talking Avatars",
    "summary": "Despite significant advances in talking avatar generation, existing methods face critical challenges: insufficient text-following capability for diverse actions, lack of temporal alignment between actions and audio content, and dependency on additional control signals such as pose skeletons. We present ActAvatar, a framework that achieves phase-level precision in action control through textual guidance by capturing both action semantics and temporal context. Our approach introduces three core innovations: (1) Phase-Aware Cross-Attention (PACA), which decomposes prompts into a global base block and temporally-anchored phase blocks, enabling the model to concentrate on phase-relevant tokens for precise temporal-semantic alignment; (2) Progressive Audio-Visual Alignment, which aligns modality influence with the hierarchical feature learning process-early layers prioritize text for establishing action structure while deeper layers emphasize audio for refining lip movements, preventing modality interference; (3) A two-stage training strategy that first establishes robust audio-visual correspondence on diverse data, then injects action control through fine-tuning on structured annotations, maintaining both audio-visual alignment and the model's text-following capabilities. Extensive experiments demonstrate that ActAvatar significantly outperforms state-of-the-art methods in both action control and visual quality.",
    "published": "2025-12-22T16:28:27Z",
    "updated": "2025-12-22T16:28:27Z",
    "link": "http://arxiv.org/pdf/2512.19546v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ziqiao Peng",
      "Yi Chen",
      "Yifeng Ma",
      "Guozhen Zhang",
      "Zhiyao Sun",
      "Zixiang Zhou",
      "Youliang Zhang",
      "Zhengguang Zhou",
      "Zhaoxin Fan",
      "Hongyan Liu",
      "Yuan Zhou",
      "Qinglin Lu",
      "Jun He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19539v1",
    "title": "StoryMem: Multi-shot Long Video Storytelling with Memory",
    "summary": "Visual storytelling requires generating multi-shot videos with cinematic quality and long-range consistency. Inspired by human memory, we propose StoryMem, a paradigm that reformulates long-form video storytelling as iterative shot synthesis conditioned on explicit visual memory, transforming pre-trained single-shot video diffusion models into multi-shot storytellers. This is achieved by a novel Memory-to-Video (M2V) design, which maintains a compact and dynamically updated memory bank of keyframes from historical generated shots. The stored memory is then injected into single-shot video diffusion models via latent concatenation and negative RoPE shifts with only LoRA fine-tuning. A semantic keyframe selection strategy, together with aesthetic preference filtering, further ensures informative and stable memory throughout generation. Moreover, the proposed framework naturally accommodates smooth shot transitions and customized story generation applications. To facilitate evaluation, we introduce ST-Bench, a diverse benchmark for multi-shot video storytelling. Extensive experiments demonstrate that StoryMem achieves superior cross-shot consistency over previous methods while preserving high aesthetic quality and prompt adherence, marking a significant step toward coherent minute-long video storytelling.",
    "published": "2025-12-22T16:23:24Z",
    "updated": "2025-12-22T16:23:24Z",
    "link": "http://arxiv.org/pdf/2512.19539v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Kaiwen Zhang",
      "Liming Jiang",
      "Angtian Wang",
      "Jacob Zhiyuan Fang",
      "Tiancheng Zhi",
      "Qing Yan",
      "Hao Kang",
      "Xin Lu",
      "Xingang Pan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19534v1",
    "title": "SlicerOrbitSurgerySim: An Open-Source Platform for Virtual Registration and Quantitative Comparison of Preformed Orbital Plates",
    "summary": "Poor adaptation of orbital implants remains a major contributor to postoperative complications and revision surgery. Although preformed orbital plates are widely used to reduce cost and operative time compared with customized implants, surgeons currently lack publicly available tools and standardized metrics to quantitatively compare plate fit across vendors, sizes, and patient anatomy. We developed SlicerOrbitSurgerySim, an open-source extension for the 3D Slicer platform that enables interactive virtual registration, evaluation, and comparison of multiple preformed orbital plates in a patient-specific virtual planning environment. The software generates reproducible quantitative plate-to-orbit distance metrics and visualization tools that support both patient-specific planning and population-level statistical analysis of plate adaptability. By facilitating objective comparison of implant designs and placement strategies, this tool aims to improve preoperative decision-making, reduce intraoperative plate modification, and promote collaborative research and surgical education. Pilot studies, sample datasets, and detailed tutorials are provided to support testing, transparency, and reproducibility.",
    "published": "2025-12-22T16:21:29Z",
    "updated": "2025-12-22T16:21:29Z",
    "link": "http://arxiv.org/pdf/2512.19534v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Chi Zhang",
      "Braedon Gunn",
      "Andrew M. Read-Fuller"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19528v1",
    "title": "Multi-Modal Soccer Scene Analysis with Masked Pre-Training",
    "summary": "In this work we propose a multi-modal architecture for analyzing soccer scenes from tactical camera footage, with a focus on three core tasks: ball trajectory inference, ball state classification, and ball possessor identification. To this end, our solution integrates three distinct input modalities (player trajectories, player types and image crops of individual players) into a unified framework that processes spatial and temporal dynamics using a cascade of sociotemporal transformer blocks. Unlike prior methods, which rely heavily on accurate ball tracking or handcrafted heuristics, our approach infers the ball trajectory without direct access to its past or future positions, and robustly identifies the ball state and ball possessor under noisy or occluded conditions from real top league matches. We also introduce CropDrop, a modality-specific masking pre-training strategy that prevents over-reliance on image features and encourages the model to rely on cross-modal patterns during pre-training. We show the effectiveness of our approach on a large-scale dataset providing substantial improvements over state-of-the-art baselines in all tasks. Our results highlight the benefits of combining structured and visual cues in a transformer-based architecture, and the importance of realistic masking strategies in multi-modal learning.",
    "published": "2025-12-22T16:18:45Z",
    "updated": "2025-12-22T16:18:45Z",
    "link": "http://arxiv.org/pdf/2512.19528v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Marc Peral",
      "Guillem Capellera",
      "Luis Ferraz",
      "Antonio Rubio",
      "Antonio Agudo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19522v1",
    "title": "A Convolutional Neural Deferred Shader for Physics Based Rendering",
    "summary": "Recent advances in neural rendering have achieved impressive results on photorealistic shading and relighting, by using a multilayer perceptron (MLP) as a regression model to learn the rendering equation from a real-world dataset. Such methods show promise for photorealistically relighting real-world objects, which is difficult to classical rendering, as there is no easy-obtained material ground truth. However, significant challenges still remain the dense connections in MLPs result in a large number of parameters, which requires high computation resources, complicating the training, and reducing performance during rendering. Data driven approaches require large amounts of training data for generalization; unbalanced data might bias the model to ignore the unusual illumination conditions, e.g. dark scenes. This paper introduces pbnds+: a novel physics-based neural deferred shading pipeline utilizing convolution neural networks to decrease the parameters and improve the performance in shading and relighting tasks; Energy regularization is also proposed to restrict the model reflection during dark illumination. Extensive experiments demonstrate that our approach outperforms classical baselines, a state-of-the-art neural shading model, and a diffusion-based method.",
    "published": "2025-12-22T16:16:13Z",
    "updated": "2025-12-22T16:16:13Z",
    "link": "http://arxiv.org/pdf/2512.19522v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhuo He",
      "Yingdong Ru",
      "Qianying Liu",
      "Paul Henderson",
      "Nicolas Pugeault"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.00493v2",
    "title": "SAMSA 2.0: Prompting Segment Anything with Spectral Angles for Hyperspectral Interactive Medical Image Segmentation",
    "summary": "We present SAMSA 2.0, an interactive segmentation framework for hyperspectral medical imaging that introduces spectral angle prompting to guide the Segment Anything Model (SAM) using spectral similarity alongside spatial cues. This early fusion of spectral information enables more accurate and robust segmentation across diverse spectral datasets. Without retraining, SAMSA 2.0 achieves up to +3.8% higher Dice scores compared to RGB-only models and up to +3.1% over prior spectral fusion methods. Our approach enhances few-shot and zero-shot performance, demonstrating strong generalization in challenging low-data and noisy scenarios common in clinical imaging.",
    "published": "2025-08-01T10:16:26Z",
    "updated": "2025-12-22T16:00:24Z",
    "link": "http://arxiv.org/pdf/2508.00493v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Alfie Roddan",
      "Tobias Czempiel",
      "Chi Xu",
      "Daniel S. Elson",
      "Stamatia Giannarou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19504v1",
    "title": "FusionNet: Physics-Aware Representation Learning for Multi-Spectral and Thermal Data via Trainable Signal-Processing Priors",
    "summary": "Modern deep learning models operating on multi-modal visual signals often rely on inductive biases that are poorly aligned with the physical processes governing signal formation, leading to brittle performance under cross-spectral and real-world conditions. In particular, approaches that prioritise direct thermal cues struggle to capture indirect yet persistent environmental alterations induced by sustained heat emissions.\n  This work introduces a physics-aware representation learning framework that leverages multi-spectral information to model stable signatures of long-term physical processes. Specifically, a geological Short Wave Infrared (SWIR) ratio sensitive to soil property changes is integrated with Thermal Infrared (TIR) data through an intermediate fusion architecture, instantiated as FusionNet. The proposed backbone embeds trainable differential signal-processing priors within convolutional layers, combines mixed pooling strategies, and employs wider receptive fields to enhance robustness across spectral modalities.\n  Systematic ablations show that each architectural component contributes to performance gains, with DGCNN achieving 88.7% accuracy on the SWIR ratio and FusionNet reaching 90.6%, outperforming state-of-the-art baselines across five spectral configurations. Transfer learning experiments further show that ImageNet pretraining degrades TIR performance, highlighting the importance of modality-aware training for cross-spectral learning.\n  Evaluated on real-world data, the results demonstrate that combining physics-aware feature selection with principled deep learning architectures yields robust and generalisable representations, illustrating how first-principles signal modelling can improve multi-spectral learning under challenging conditions.",
    "published": "2025-12-22T15:59:37Z",
    "updated": "2025-12-22T15:59:37Z",
    "link": "http://arxiv.org/pdf/2512.19504v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Georgios Voulgaris"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19489v1",
    "title": "Rethinking Coupled Tensor Analysis for Hyperspectral Super-Resolution: Recoverable Modeling Under Endmember Variability",
    "summary": "This work revisits the hyperspectral super-resolution (HSR) problem, i.e., fusing a pair of spatially co-registered hyperspectral (HSI) and multispectral (MSI) images to recover a super-resolution image (SRI) that enhances the spatial resolution of the HSI. Coupled tensor decomposition (CTD)-based methods have gained traction in this domain, offering recoverability guarantees under various assumptions. Existing models such as canonical polyadic decomposition (CPD) and Tucker decomposition provide strong expressive power but lack physical interpretability. The block-term decomposition model with rank-$(L_r, L_r, 1)$ terms (the LL1 model) yields interpretable factors under the linear mixture model (LMM) of spectral images, but LMM assumptions are often violated in practice -- primarily due to nonlinear effects such as endmember variability (EV). To address this, we propose modeling spectral images using a more flexible block-term tensor decomposition with rank-$(L_r, M_r, N_r)$ terms (the LMN model). This modeling choice retains interpretability, subsumes CPD, Tucker, and LL1 as special cases, and robustly accounts for non-ideal effects such as EV, offering a balanced tradeoff between expressiveness and interpretability for HSR. Importantly, under the LMN model for HSI and MSI, recoverability of the SRI can still be established under proper conditions -- providing strong theoretical support. Extensive experiments on synthetic and real datasets further validate the effectiveness and robustness of the proposed method compared with existing CTD-based approaches.",
    "published": "2025-12-22T15:43:59Z",
    "updated": "2025-12-22T15:43:59Z",
    "link": "http://arxiv.org/pdf/2512.19489v1.pdf",
    "category": [
      "eess.IV",
      "cs.CV"
    ],
    "authors": [
      "Meng Ding",
      "Xiao Fu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19486v1",
    "title": "Dynamic Stream Network for Combinatorial Explosion Problem in Deformable Medical Image Registration",
    "summary": "Combinatorial explosion problem caused by dual inputs presents a critical challenge in Deformable Medical Image Registration (DMIR). Since DMIR processes two images simultaneously as input, the combination relationships between features has grown exponentially, ultimately the model considers more interfering features during the feature modeling process. Introducing dynamics in the receptive fields and weights of the network enable the model to eliminate the interfering features combination and model the potential feature combination relationships. In this paper, we propose the Dynamic Stream Network (DySNet), which enables the receptive fields and weights to be dynamically adjusted. This ultimately enables the model to ignore interfering feature combinations and model the potential feature relationships. With two key innovations: 1) Adaptive Stream Basin (AdSB) module dynamically adjusts the shape of the receptive field, thereby enabling the model to focus on the feature relationships with greater correlation. 2) Dynamic Stream Attention (DySA) mechanism generates dynamic weights to search for more valuable feature relationships. Extensive experiments have shown that DySNet consistently outperforms the most advanced DMIR methods, highlighting its outstanding generalization ability. Our code will be released on the website: https://github.com/ShaochenBi/DySNet.",
    "published": "2025-12-22T15:43:23Z",
    "updated": "2025-12-22T15:43:23Z",
    "link": "http://arxiv.org/pdf/2512.19486v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Shaochen Bi",
      "Yuting He",
      "Weiming Wang",
      "Hao Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.10412v2",
    "title": "3DFETUS: Deep Learning-Based Standardization of Facial Planes in 3D Ultrasound",
    "summary": "The automatic localization and standardization of anatomical planes in 3D medical imaging remains a challenging problem due to variability in object pose, appearance, and image quality. In 3D ultrasound, these challenges are exacerbated by speckle noise and limited contrast, particularly in fetal imaging.\n  To address these challenges in the context of facial assessment, we present: 1) GT++, a robust algorithm that estimates standard facial planes from 3D US volumes using annotated anatomical landmarks; and 2) 3DFETUS, a deep learning model that automates and standardizes their localization in 3D fetal US volumes.\n  We evaluated our methods both qualitatively, through expert clinical review, and quantitatively. The proposed approach achieved a mean translation error of 3.21 $\\pm$ 1.98mm and a mean rotation error of 5.31 $\\pm$ 3.945$^\\circ$ per plane, outperforming other state-of-the-art methods on 3D US volumes. Clinical assessments further confirmed the effectiveness of both GT++ and 3DFETUS, demonstrating statistically significant improvements in plane estimation accuracy.",
    "published": "2025-11-13T15:33:48Z",
    "updated": "2025-12-22T15:36:44Z",
    "link": "http://arxiv.org/pdf/2511.10412v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Alomar Antonia",
      "Rubio Ricardo",
      "Albaiges Gerard",
      "Salort-Benejam Laura",
      "Caminal Julia",
      "Prat Maria",
      "Rueda Carolina",
      "Cortes Berta",
      "Piella Gemma",
      "Sukno Federico"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19479v1",
    "title": "Emotion-Director: Bridging Affective Shortcut in Emotion-Oriented Image Generation",
    "summary": "Image generation based on diffusion models has demonstrated impressive capability, motivating exploration into diverse and specialized applications. Owing to the importance of emotion in advertising, emotion-oriented image generation has attracted increasing attention. However, current emotion-oriented methods suffer from an affective shortcut, where emotions are approximated to semantics. As evidenced by two decades of research, emotion is not equivalent to semantics. To this end, we propose Emotion-Director, a cross-modal collaboration framework consisting of two modules. First, we propose a cross-Modal Collaborative diffusion model, abbreviated as MC-Diffusion. MC-Diffusion integrates visual prompts with textual prompts for guidance, enabling the generation of emotion-oriented images beyond semantics. Further, we improve the DPO optimization by a negative visual prompt, enhancing the model's sensitivity to different emotions under the same semantics. Second, we propose MC-Agent, a cross-Modal Collaborative Agent system that rewrites textual prompts to express the intended emotions. To avoid template-like rewrites, MC-Agent employs multi-agents to simulate human subjectivity toward emotions, and adopts a chain-of-concept workflow that improves the visual expressiveness of the rewritten prompts. Extensive qualitative and quantitative experiments demonstrate the superiority of Emotion-Director in emotion-oriented image generation.",
    "published": "2025-12-22T15:32:18Z",
    "updated": "2025-12-22T15:32:18Z",
    "link": "http://arxiv.org/pdf/2512.19479v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Guoli Jia",
      "Junyao Hu",
      "Xinwei Long",
      "Kai Tian",
      "Kaiyan Zhang",
      "KaiKai Zhao",
      "Ning Ding",
      "Bowen Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19451v1",
    "title": "Sign Language Recognition using Parallel Bidirectional Reservoir Computing",
    "summary": "Sign language recognition (SLR) facilitates communication between deaf and hearing communities. Deep learning based SLR models are commonly used but require extensive computational resources, making them unsuitable for deployment on edge devices. To address these limitations, we propose a lightweight SLR system that combines parallel bidirectional reservoir computing (PBRC) with MediaPipe. MediaPipe enables real-time hand tracking and precise extraction of hand joint coordinates, which serve as input features for the PBRC architecture. The proposed PBRC architecture consists of two echo state network (ESN) based bidirectional reservoir computing (BRC) modules arranged in parallel to capture temporal dependencies, thereby creating a rich feature representation for classification. We trained our PBRC-based SLR system on the Word-Level American Sign Language (WLASL) video dataset, achieving top-1, top-5, and top-10 accuracies of 60.85%, 85.86%, and 91.74%, respectively. Training time was significantly reduced to 18.67 seconds due to the intrinsic properties of reservoir computing, compared to over 55 minutes for deep learning based methods such as Bi-GRU. This approach offers a lightweight, cost-effective solution for real-time SLR on edge devices.",
    "published": "2025-12-22T14:55:54Z",
    "updated": "2025-12-22T14:55:54Z",
    "link": "http://arxiv.org/pdf/2512.19451v1.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Nitin Kumar Singh",
      "Arie Rachmad Syulistyo",
      "Yuichiro Tanaka",
      "Hakaru Tamukoh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19443v1",
    "title": "D2Pruner: Debiased Importance and Structural Diversity for MLLM Token Pruning",
    "summary": "Processing long visual token sequences poses a significant computational burden on Multimodal Large Language Models (MLLMs). While token pruning offers a path to acceleration, we find that current methods, while adequate for general understanding, catastrophically fail on fine-grained localization tasks. We attribute this failure to the inherent flaws of the two prevailing strategies: importance-based methods suffer from a strong positional bias, an inherent model artifact that distracts from semantic content, while diversity-based methods exhibit structural blindness, disregarding the user's prompt and spatial redundancy. To address this, we introduce D2Pruner, a framework that rectifies these issues by uniquely combining debiased importance with a structural pruning mechanism. Our method first secures a core set of the most critical tokens as pivots based on a debiased attention score. It then performs a Maximal Independent Set (MIS) selection on the remaining tokens, which are modeled on a hybrid graph where edges signify spatial proximity and semantic similarity. This process iteratively preserves the most important and available token while removing its neighbors, ensuring that the supplementary tokens are chosen to maximize importance and diversity. Extensive experiments demonstrate that D2Pruner has exceptional efficiency and fidelity. Applied to LLaVA-1.5-7B for general understanding tasks, it reduces FLOPs by 74.2\\% while retaining 99.2\\% of its original performance. Furthermore, in challenging localization benchmarks with InternVL-2.5-8B, it maintains 85.7\\% performance at a 90\\% token reduction rate, marking a significant advancement with up to 63. 53\\% improvement over existing methods.",
    "published": "2025-12-22T14:42:31Z",
    "updated": "2025-12-22T14:42:31Z",
    "link": "http://arxiv.org/pdf/2512.19443v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Evelyn Zhang",
      "Fufu Yu",
      "Aoqi Wu",
      "Zichen Wen",
      "Ke Yan",
      "Shouhong Ding",
      "Biqing Qi",
      "Linfeng Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19433v1",
    "title": "dMLLM-TTS: Self-Verified and Efficient Test-Time Scaling for Diffusion Multi-Modal Large Language Models",
    "summary": "Diffusion Multi-modal Large Language Models (dMLLMs) have recently emerged as a novel architecture unifying image generation and understanding. However, developing effective and efficient Test-Time Scaling (TTS) methods to unlock their full generative potential remains an underexplored challenge. To address this, we propose dMLLM-TTS, a novel framework operating on two complementary scaling axes: (1) trajectory exploration scaling to enhance the diversity of generated hypotheses, and (2) iterative refinement scaling for stable generation. Conventional TTS approaches typically perform linear search across these two dimensions, incurring substantial computational costs of O(NT) and requiring an external verifier for best-of-N selection. To overcome these limitations, we propose two innovations. First, we design an efficient hierarchical search algorithm with O(N+T) complexity that adaptively expands and prunes sampling trajectories. Second, we introduce a self-verified feedback mechanism that leverages the dMLLMs' intrinsic image understanding capabilities to assess text-image alignment, eliminating the need for external verifier. Extensive experiments on the GenEval benchmark across three representative dMLLMs (e.g., Lumina-DiMOO, MMaDA, Muddit) show that our framework substantially improves generation quality while achieving up to 6x greater efficiency than linear search. Project page: https://github.com/Alpha-VLLM/Lumina-DiMOO.",
    "published": "2025-12-22T14:31:58Z",
    "updated": "2025-12-22T14:31:58Z",
    "link": "http://arxiv.org/pdf/2512.19433v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yi Xin",
      "Siqi Luo",
      "Qi Qin",
      "Haoxing Chen",
      "Kaiwen Zhu",
      "Zhiwei Zhang",
      "Yangfan He",
      "Rongchao Zhang",
      "Jinbin Bai",
      "Shuo Cao",
      "Bin Fu",
      "Junjun He",
      "Yihao Liu",
      "Yuewen Cao",
      "Xiaohong Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.07329v2",
    "title": "Preparation of Fractal-Inspired Computational Architectures for Advanced Large Language Model Analysis",
    "summary": "It introduces FractalNet, a fractal-inspired computational architectures for advanced large language model analysis that mainly challenges model diversity on a large scale in an efficient manner. The new set-up involves a template-driven generator, runner, and evaluation framework that, through systematic permutations of convolutional, normalization, activation, and dropout layers, can create more than 1,200 variants of neural networks. Fractal templates allow for structural recursion and multi-column pathways, thus, models become deeper and wider in a balanced way. Training utilizes PyTorch, Automatic Mixed Precision (AMP), and gradient checkpointing and is carried out on the CIFAR-10 dataset for five epochs. The outcomes show that fractal-based architectures are capable of strong performance and are computationally efficient. The paper positions fractal design as a feasible and resource-efficient method of automated architecture exploration.",
    "published": "2025-11-10T17:31:39Z",
    "updated": "2025-12-22T14:21:27Z",
    "link": "http://arxiv.org/pdf/2511.07329v2.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Yash Mittal",
      "Dmitry Ignatov",
      "Radu Timofte"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.20431v3",
    "title": "BRIC: Bridging Kinematic Plans and Physical Control at Test Time",
    "summary": "We propose BRIC, a novel test-time adaptation (TTA) framework that enables long-term human motion generation by resolving execution discrepancies between diffusion-based kinematic motion planners and reinforcement learning-based physics controllers. While diffusion models can generate diverse and expressive motions conditioned on text and scene context, they often produce physically implausible outputs, leading to execution drift during simulation. To address this, BRIC dynamically adapts the physics controller to noisy motion plans at test time, while preserving pre-trained skills via a loss function that mitigates catastrophic forgetting. In addition, BRIC introduces a lightweight test-time guidance mechanism that steers the diffusion model in the signal space without updating its parameters. By combining both adaptation strategies, BRIC ensures consistent and physically plausible long-term executions across diverse environments in an effective and efficient manner. We validate the effectiveness of BRIC on a variety of long-term tasks, including motion composition, obstacle avoidance, and human-scene interaction, achieving state-of-the-art performance across all tasks.",
    "published": "2025-11-25T16:03:38Z",
    "updated": "2025-12-22T14:19:18Z",
    "link": "http://arxiv.org/pdf/2511.20431v3.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Dohun Lim",
      "Minji Kim",
      "Jaewoon Lim",
      "Sungchan Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19415v1",
    "title": "Non-Contrast CT Esophageal Varices Grading through Clinical Prior-Enhanced Multi-Organ Analysis",
    "summary": "Esophageal varices (EV) represent a critical complication of portal hypertension, affecting approximately 60% of cirrhosis patients with a significant bleeding risk of ~30%. While traditionally diagnosed through invasive endoscopy, non-contrast computed tomography (NCCT) presents a potential non-invasive alternative that has yet to be fully utilized in clinical practice. We present Multi-Organ-COhesion Network++ (MOON++), a novel multimodal framework that enhances EV assessment through comprehensive analysis of NCCT scans. Inspired by clinical evidence correlating organ volumetric relationships with liver disease severity, MOON++ synthesizes imaging characteristics of the esophagus, liver, and spleen through multimodal learning. We evaluated our approach using 1,631 patients, those with endoscopically confirmed EV were classified into four severity grades. Validation in 239 patient cases and independent testing in 289 cases demonstrate superior performance compared to conventional single organ methods, achieving an AUC of 0.894 versus 0.803 for the severe grade EV classification (G3 versus <G3) and 0.921 versus 0.793 for the differentiation of moderate to severe grades (>=G2 versus <G2). We conducted a reader study involving experienced radiologists to further validate the performance of MOON++. To our knowledge, MOON++ represents the first comprehensive multi-organ NCCT analysis framework incorporating clinical knowledge priors for EV assessment, potentially offering a promising non-invasive diagnostic alternative.",
    "published": "2025-12-22T14:17:35Z",
    "updated": "2025-12-22T14:17:35Z",
    "link": "http://arxiv.org/pdf/2512.19415v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xiaoming Zhang",
      "Chunli Li",
      "Jiacheng Hao",
      "Yuan Gao",
      "Danyang Tu",
      "Jianyi Qiao",
      "Xiaoli Yin",
      "Le Lu",
      "Ling Zhang",
      "Ke Yan",
      "Yang Hou",
      "Yu Shi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.07651v2",
    "title": "Liver Fibrosis Quantification and Analysis: The LiQA Dataset and Baseline Method",
    "summary": "Liver fibrosis represents a significant global health burden, necessitating accurate staging for effective clinical management. This report introduces the LiQA (Liver Fibrosis Quantification and Analysis) dataset, established as part of the CARE 2024 challenge. Comprising $440$ patients with multi-phase, multi-center MRI scans, the dataset is curated to benchmark algorithms for Liver Segmentation (LiSeg) and Liver Fibrosis Staging (LiFS) under complex real-world conditions, including domain shifts, missing modalities, and spatial misalignment. We further describe the challenge's top-performing methodology, which integrates a semi-supervised learning framework with external data for robust segmentation, and utilizes a multi-view consensus approach with Class Activation Map (CAM)-based regularization for staging. Evaluation of this baseline demonstrates that leveraging multi-source data and anatomical constraints significantly enhances model robustness in clinical settings.",
    "published": "2025-12-08T15:44:24Z",
    "updated": "2025-12-22T14:15:04Z",
    "link": "http://arxiv.org/pdf/2512.07651v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yuanye Liu",
      "Hanxiao Zhang",
      "Jiyao Liu",
      "Nannan Shi",
      "Yuxin Shi",
      "Arif Mahmood",
      "Murtaza Taj",
      "Xiahai Zhuang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2407.12538v3",
    "title": "High Frequency Matters: Uncertainty Guided Image Compression with Wavelet Diffusion",
    "summary": "Diffusion probabilistic models have recently achieved remarkable success in generating high-quality images. However, balancing high perceptual quality and low distortion remains challenging in application of diffusion models in image compression. To address this issue, we propose a novel Uncertainty-Guided image compression approach with wavelet Diffusion (UGDiff). Our approach focuses on high frequency compression via the wavelet transform, since high frequency components are crucial for reconstructing image details. We introduce a wavelet conditional diffusion model for high frequency prediction, followed by a residual codec that compresses and transmits prediction residuals to the decoder. This diffusion prediction-then-residual compression paradigm effectively addresses the low fidelity issue common in direct reconstructions by existing diffusion models. Considering the uncertainty from the random sampling of the diffusion model, we further design an uncertainty-weighted rate-distortion (R-D) loss tailored for residual compression, providing a more rational trade-off between rate and distortion. Comprehensive experiments on two benchmark datasets validate the effectiveness of UGDiff, surpassing state-of-the-art image compression methods in R-D performance, perceptual quality, subjective quality, and inference time. Our code is available at: https://github.com/hejiaxiang1/Wavelet-Diffusion/tree/main.",
    "published": "2024-07-17T13:21:31Z",
    "updated": "2025-12-22T14:04:56Z",
    "link": "http://arxiv.org/pdf/2407.12538v3.pdf",
    "category": [
      "eess.IV",
      "cs.CV"
    ],
    "authors": [
      "Juan Song",
      "Jiaxiang He",
      "Lijie Yang",
      "Mingtao Feng",
      "Keyan Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13031v3",
    "title": "Towards 3D Object-Centric Feature Learning for Semantic Scene Completion",
    "summary": "Vision-based 3D Semantic Scene Completion (SSC) has received growing attention due to its potential in autonomous driving. While most existing approaches follow an ego-centric paradigm by aggregating and diffusing features over the entire scene, they often overlook fine-grained object-level details, leading to semantic and geometric ambiguities, especially in complex environments. To address this limitation, we propose Ocean, an object-centric prediction framework that decomposes the scene into individual object instances to enable more accurate semantic occupancy prediction. Specifically, we first employ a lightweight segmentation model, MobileSAM, to extract instance masks from the input image. Then, we introduce a 3D Semantic Group Attention module that leverages linear attention to aggregate object-centric features in 3D space. To handle segmentation errors and missing instances, we further design a Global Similarity-Guided Attention module that leverages segmentation features for global interaction. Finally, we propose an Instance-aware Local Diffusion module that improves instance features through a generative process and subsequently refines the scene representation in the BEV space. Extensive experiments on the SemanticKITTI and SSCBench-KITTI360 benchmarks demonstrate that Ocean achieves state-of-the-art performance, with mIoU scores of 17.40 and 20.28, respectively.",
    "published": "2025-11-17T06:28:26Z",
    "updated": "2025-12-22T14:03:37Z",
    "link": "http://arxiv.org/pdf/2511.13031v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Weihua Wang",
      "Yubo Cui",
      "Xiangru Lin",
      "Zhiheng Li",
      "Zheng Fang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19402v1",
    "title": "Real2Edit2Real: Generating Robotic Demonstrations via a 3D Control Interface",
    "summary": "Recent progress in robot learning has been driven by large-scale datasets and powerful visuomotor policy architectures, yet policy robustness remains limited by the substantial cost of collecting diverse demonstrations, particularly for spatial generalization in manipulation tasks. To reduce repetitive data collection, we present Real2Edit2Real, a framework that generates new demonstrations by bridging 3D editability with 2D visual data through a 3D control interface. Our approach first reconstructs scene geometry from multi-view RGB observations with a metric-scale 3D reconstruction model. Based on the reconstructed geometry, we perform depth-reliable 3D editing on point clouds to generate new manipulation trajectories while geometrically correcting the robot poses to recover physically consistent depth, which serves as a reliable condition for synthesizing new demonstrations. Finally, we propose a multi-conditional video generation model guided by depth as the primary control signal, together with action, edge, and ray maps, to synthesize spatially augmented multi-view manipulation videos. Experiments on four real-world manipulation tasks demonstrate that policies trained on data generated from only 1-5 source demonstrations can match or outperform those trained on 50 real-world demonstrations, improving data efficiency by up to 10-50x. Moreover, experimental results on height and texture editing demonstrate the framework's flexibility and extensibility, indicating its potential to serve as a unified data generation framework.",
    "published": "2025-12-22T13:53:25Z",
    "updated": "2025-12-22T13:53:25Z",
    "link": "http://arxiv.org/pdf/2512.19402v1.pdf",
    "category": [
      "cs.RO",
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "Yujie Zhao",
      "Hongwei Fan",
      "Di Chen",
      "Shengcong Chen",
      "Liliang Chen",
      "Xiaoqi Li",
      "Guanghui Ren",
      "Hao Dong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19390v1",
    "title": "TwinAligner: Visual-Dynamic Alignment Empowers Physics-aware Real2Sim2Real for Robotic Manipulation",
    "summary": "The robotics field is evolving towards data-driven, end-to-end learning, inspired by multimodal large models. However, reliance on expensive real-world data limits progress. Simulators offer cost-effective alternatives, but the gap between simulation and reality challenges effective policy transfer. This paper introduces TwinAligner, a novel Real2Sim2Real system that addresses both visual and dynamic gaps. The visual alignment module achieves pixel-level alignment through SDF reconstruction and editable 3DGS rendering, while the dynamic alignment module ensures dynamic consistency by identifying rigid physics from robot-object interaction. TwinAligner improves robot learning by providing scalable data collection and establishing a trustworthy iterative cycle, accelerating algorithm development. Quantitative evaluations highlight TwinAligner's strong capabilities in visual and dynamic real-to-sim alignment. This system enables policies trained in simulation to achieve strong zero-shot generalization to the real world. The high consistency between real-world and simulated policy performance underscores TwinAligner's potential to advance scalable robot learning. Code and data will be released on https://twin-aligner.github.io",
    "published": "2025-12-22T13:38:11Z",
    "updated": "2025-12-22T13:38:11Z",
    "link": "http://arxiv.org/pdf/2512.19390v1.pdf",
    "category": [
      "cs.RO",
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "Hongwei Fan",
      "Hang Dai",
      "Jiyao Zhang",
      "Jinzhou Li",
      "Qiyang Yan",
      "Yujie Zhao",
      "Mingju Gao",
      "Jinghang Wu",
      "Hao Tang",
      "Hao Dong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2406.05491v4",
    "title": "One Perturbation is Enough: On Generating Universal Adversarial Perturbations against Vision-Language Pre-training Models",
    "summary": "Vision-Language Pre-training (VLP) models have exhibited unprecedented capability in many applications by taking full advantage of the multimodal alignment. However, previous studies have shown they are vulnerable to maliciously crafted adversarial samples. Despite recent success, these methods are generally instance-specific and require generating perturbations for each input sample. In this paper, we reveal that VLP models are also vulnerable to the instance-agnostic universal adversarial perturbation (UAP). Specifically, we design a novel Contrastive-training Perturbation Generator with Cross-modal conditions (C-PGC) to achieve the attack. In light that the pivotal multimodal alignment is achieved through the advanced contrastive learning technique, we devise to turn this powerful weapon against themselves, i.e., employ a malicious version of contrastive learning to train the C-PGC based on our carefully crafted positive and negative image-text pairs for essentially destroying the alignment relationship learned by VLP models. Besides, C-PGC fully utilizes the characteristics of Vision-and-Language (V+L) scenarios by incorporating both unimodal and cross-modal information as effective guidance. Extensive experiments show that C-PGC successfully forces adversarial samples to move away from their original area in the VLP model's feature space, thus essentially enhancing attacks across various victim models and V+L tasks. The GitHub repository is available at https://github.com/ffhibnese/CPGC_VLP_Universal_Attacks.",
    "published": "2024-06-08T15:01:54Z",
    "updated": "2025-12-22T13:30:54Z",
    "link": "http://arxiv.org/pdf/2406.05491v4.pdf",
    "category": [
      "cs.CV",
      "cs.CR"
    ],
    "authors": [
      "Hao Fang",
      "Jiawei Kong",
      "Wenbo Yu",
      "Bin Chen",
      "Jiawei Li",
      "Hao Wu",
      "Shutao Xia",
      "Ke Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.17436v2",
    "title": "Xiaomi MiMo-VL-Miloco Technical Report",
    "summary": "We open-source MiMo-VL-Miloco-7B and its quantized variant MiMo-VL-Miloco-7B-GGUF, a pair of home-centric vision-language models that achieve strong performance on both home-scenario understanding and general multimodal reasoning. Built on the MiMo-VL-7B backbone, MiMo-VL-Miloco-7B is specialized for smart-home environments, attaining leading F1 scores on gesture recognition and common home-scenario understanding, while also delivering consistent gains across video benchmarks such as Video-MME, Video-MMMU, and Charades-STA, as well as language understanding benchmarks including MMMU-Pro and MMLU-Pro. In our experiments, MiMo-VL-Miloco-7B outperforms strong closed-source and open-source baselines on home-scenario understanding and several multimodal reasoning benchmarks. To balance specialization and generality, we design a two-stage training pipeline that combines supervised fine-tuning with reinforcement learning based on Group Relative Policy Optimization, leveraging efficient multi-domain data. We further incorporate chain-of-thought supervision and token-budget-aware reasoning, enabling the model to learn knowledge in a data-efficient manner while also performing reasoning efficiently. Our analysis shows that targeted home-scenario training not only enhances activity and gesture understanding, but also improves text-only reasoning with only modest trade-offs on document-centric tasks. Model checkpoints, quantized GGUF weights, and our home-scenario evaluation toolkit are publicly available at https://github.com/XiaoMi/xiaomi-mimo-vl-miloco to support research and deployment in real-world smart-home applications.",
    "published": "2025-12-19T10:43:37Z",
    "updated": "2025-12-22T13:27:24Z",
    "link": "http://arxiv.org/pdf/2512.17436v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jiaze Li",
      "Jingyang Chen",
      "Yuxun Qu",
      "Shijie Xu",
      "Zhenru Lin",
      "Junyou Zhu",
      "Boshen Xu",
      "Wenhui Tan",
      "Pei Fu",
      "Jianzhong Ju",
      "Zhenbo Luo",
      "Jian Luan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.17061v2",
    "title": "REGEN: Real-Time Photorealism Enhancement in Games via a Dual-Stage Generative Network Framework",
    "summary": "Photorealism is an important aspect of modern video games since it can shape player experience and impact immersion, narrative engagement, and visual fidelity. To achieve photorealism, beyond traditional rendering pipelines, generative models have been increasingly adopted as an effective approach for bridging the gap between the visual realism of synthetic and real worlds. However, under real-time constraints of video games, existing generative approaches continue to face a tradeoff between visual quality and runtime efficiency. In this work, we present a framework for enhancing the photorealism of rendered game frames using generative networks. We propose REGEN, which first employs a robust unpaired image-to-image translation model to generate semantically consistent photorealistic frames. These generated frames are then used to create a paired dataset, which transforms the problem to a simpler unpaired image-to-image translation. This enables training with a lightweight method, achieving real-time inference without compromising visual quality. We evaluate REGEN on Unreal Engine, showing, by employing the CMMD metric, that it achieves comparable or slightly improved visual quality compared to the robust method, while improving the frame rate by 12x. Additional experiments also validate that REGEN adheres to the semantic preservation of the initial robust image-to-image translation method and maintains temporal consistency. Code, pre-trained models, and demos for this work are available at: https://github.com/stefanos50/REGEN",
    "published": "2025-08-23T15:28:05Z",
    "updated": "2025-12-22T13:11:30Z",
    "link": "http://arxiv.org/pdf/2508.17061v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Stefanos Pasios",
      "Nikos Nikolaidis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.15849v2",
    "title": "PRISM-Loc: a Lightweight Long-range LiDAR Localization in Urban Environments with Topological Maps",
    "summary": "We propose PRISM-Loc - a lightweight and robust approach for localization in large outdoor environments that combines a compact topological representation with a novel scan-matching and curb-detection module operating on raw LiDAR scans. The method is designed for resource-constrained platforms and emphasizes real-time performance and resilience to common urban sensing challenges. It provides accurate localization in compact topological maps using global place recognition and an original scan matching technique. Experiments on standard benchmarks and on an embedded platform demonstrate the effectiveness of our approach. Our method achieves a 99\\% success rate on the large-scale ITLP-Campus dataset while running at 150 ms per localization and using a 20 MB map for localization. We highlight three main contributions: (1) a compact representation for city-scale localization; (2) a novel curb detection and scan matching pipeline operating directly on raw LiDAR points; (3) a thorough evaluation of our method with performance analysis.",
    "published": "2025-06-18T19:59:50Z",
    "updated": "2025-12-22T13:08:59Z",
    "link": "http://arxiv.org/pdf/2506.15849v2.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Kirill Muravyev",
      "Artem Kobozev",
      "Vasily Yuryev",
      "Alexander Melekhin",
      "Oleg Bulichev",
      "Dmitry Yudin",
      "Konstantin Yakovlev"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19365v1",
    "title": "Efficient Spike-driven Transformer for High-performance Drone-View Geo-Localization",
    "summary": "Traditional drone-view geo-localization (DVGL) methods based on artificial neural networks (ANNs) have achieved remarkable performance. However, ANNs rely on dense computation, which results in high power consumption. In contrast, spiking neural networks (SNNs), which benefit from spike-driven computation, inherently provide low power consumption. Regrettably, the potential of SNNs for DVGL has yet to be thoroughly investigated. Meanwhile, the inherent sparsity of spike-driven computation for representation learning scenarios also results in loss of critical information and difficulties in learning long-range dependencies when aligning heterogeneous visual data sources. To address these, we propose SpikeViMFormer, the first SNN framework designed for DVGL. In this framework, a lightweight spike-driven transformer backbone is adopted to extract coarse-grained features. To mitigate the loss of critical information, the spike-driven selective attention (SSA) block is designed, which uses a spike-driven gating mechanism to achieve selective feature enhancement and highlight discriminative regions. Furthermore, a spike-driven hybrid state space (SHS) block is introduced to learn long-range dependencies using a hybrid state space. Moreover, only the backbone is utilized during the inference stage to reduce computational cost. To ensure backbone effectiveness, a novel hierarchical re-ranking alignment learning (HRAL) strategy is proposed. It refines features via neighborhood re-ranking and maintains cross-batch consistency to directly optimize the backbone. Experimental results demonstrate that SpikeViMFormer outperforms state-of-the-art SNNs. Compared with advanced ANNs, it also achieves competitive performance.Our code is available at https://github.com/ISChenawei/SpikeViMFormer",
    "published": "2025-12-22T13:07:04Z",
    "updated": "2025-12-22T13:07:04Z",
    "link": "http://arxiv.org/pdf/2512.19365v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhongwei Chen",
      "Hai-Jun Rong",
      "Zhao-Xu Yang",
      "Guoqi Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19354v1",
    "title": "ReasonCD: A Multimodal Reasoning Large Model for Implicit Change-of-Interest Semantic Mining",
    "summary": "Remote sensing image change detection is one of the fundamental tasks in remote sensing intelligent interpretation. Its core objective is to identify changes within change regions of interest (CRoI). Current multimodal large models encode rich human semantic knowledge, which is utilized for guidance in tasks such as remote sensing change detection. However, existing methods that use semantic guidance for detecting users' CRoI overly rely on explicit textual descriptions of CRoI, leading to the problem of near-complete performance failure when presented with implicit CRoI textual descriptions. This paper proposes a multimodal reasoning change detection model named ReasonCD, capable of mining users' implicit task intent. The model leverages the powerful reasoning capabilities of pre-trained large language models to mine users' implicit task intents and subsequently obtains different change detection results based on these intents. Experiments on public datasets demonstrate that the model achieves excellent change detection performance, with an F1 score of 92.1\\% on the BCDD dataset. Furthermore, to validate its superior reasoning functionality, this paper annotates a subset of reasoning data based on the SECOND dataset. Experimental results show that the model not only excels at basic reasoning-based change detection tasks but can also explain the reasoning process to aid human decision-making.",
    "published": "2025-12-22T12:54:26Z",
    "updated": "2025-12-22T12:54:26Z",
    "link": "http://arxiv.org/pdf/2512.19354v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhenyang Huang",
      "Xiao Yu",
      "Yi Zhang",
      "Decheng Wang",
      "Hang Ruan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.02789v2",
    "title": "TrackNetV5: Residual-Driven Spatio-Temporal Refinement and Motion Direction Decoupling for Fast Object Tracking",
    "summary": "The TrackNet series has established a strong baseline for fast-moving small object tracking in sports. However, existing iterations face significant limitations: V1-V3 struggle with occlusions due to a reliance on purely visual cues, while TrackNetV4, despite introducing motion inputs, suffers from directional ambiguity as its absolute difference method discards motion polarity. To overcome these bottlenecks, we propose TrackNetV5, a robust architecture integrating two novel mechanisms. First, to recover lost directional priors, we introduce the Motion Direction Decoupling (MDD) module. Unlike V4, MDD decomposes temporal dynamics into signed polarity fields, explicitly encoding both movement occurrence and trajectory direction. Second, we propose the Residual-Driven Spatio-Temporal Refinement (R-STR) head. Operating on a coarse-to-fine paradigm, this Transformer-based module leverages factorized spatio-temporal contexts to estimate a corrective residual, effectively recovering occluded targets. Extensive experiments on the TrackNetV2 dataset demonstrate that TrackNetV5 achieves a new state-of-the-art F1-score of 0.9859 and an accuracy of 0.9733, significantly outperforming previous versions. Notably, this performance leap is achieved with a marginal 3.7% increase in FLOPs compared to V4, maintaining real-time inference capabilities while delivering superior tracking precision.",
    "published": "2025-12-02T14:04:30Z",
    "updated": "2025-12-22T12:38:09Z",
    "link": "http://arxiv.org/pdf/2512.02789v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Tang Haonan",
      "Chen Yanjun",
      "Jiang Lezhi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.16504v2",
    "title": "Skeleton-Snippet Contrastive Learning with Multiscale Feature Fusion for Action Localization",
    "summary": "The self-supervised pretraining paradigm has achieved great success in learning 3D action representations for skeleton-based action recognition using contrastive learning. However, learning effective representations for skeleton-based temporal action localization remains challenging and underexplored. Unlike video-level {action} recognition, detecting action boundaries requires temporally sensitive features that capture subtle differences between adjacent frames where labels change. To this end, we formulate a snippet discrimination pretext task for self-supervised pretraining, which densely projects skeleton sequences into non-overlapping segments and promotes features that distinguish them across videos via contrastive learning. Additionally, we build on strong backbones of skeleton-based action recognition models by fusing intermediate features with a U-shaped module to enhance feature resolution for frame-level localization. Our approach consistently improves existing skeleton-based contrastive learning methods for action localization on BABEL across diverse subsets and evaluation protocols. We also achieve state-of-the-art transfer learning performance on PKUMMD with pretraining on NTU RGB+D and BABEL.",
    "published": "2025-12-18T13:15:52Z",
    "updated": "2025-12-22T12:36:43Z",
    "link": "http://arxiv.org/pdf/2512.16504v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Qiushuo Cheng",
      "Jingjing Liu",
      "Catherine Morgan",
      "Alan Whone",
      "Majid Mirmehdi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.26070v2",
    "title": "Geometric Learning of Canonical Parameterizations of $2D$-curves",
    "summary": "Most datasets encountered in computer vision and medical applications present symmetries that should be taken into account in classification tasks. A typical example is the symmetry by rotation and/or scaling in object detection. A common way to build neural networks that learn the symmetries is to use data augmentation. In order to avoid data augmentation and build more sustainable algorithms, we present an alternative method to mod out symmetries based on the notion of section of a principal fiber bundle. This framework allows the use of simple metrics on the space of objects in order to measure dissimilarities between orbits of objects under the symmetry group. Moreover, the section used can be optimized to maximize separation of classes. We illustrate this methodology on a dataset of contours of objects for the groups of translations, rotations, scalings and reparameterizations. In particular, we present a $2$-parameter family of canonical parameterizations of curves, containing the constant-speed parameterization as a special case, which we believe is interesting in its own right. We hope that this simple application will serve to convey the geometric concepts underlying this method, which have a wide range of possible applications. The code is available at the following link: $\\href{https://github.com/GiLonga/Geometric-Learning}{https://github.com/GiLonga/Geometric-Learning}$. A tutorial notebook showcasing an application of the code to a specific dataset is available at the following link: $\\href{https://github.com/ioanaciuclea/geometric-learning-notebook}{https://github.com/ioanaciuclea/geometric-learning-notebook}$",
    "published": "2025-09-30T10:45:10Z",
    "updated": "2025-12-22T12:34:40Z",
    "link": "http://arxiv.org/pdf/2509.26070v2.pdf",
    "category": [
      "cs.CV",
      "math.DG"
    ],
    "authors": [
      "Ioana Ciuclea",
      "Giorgio Longari",
      "Alice Barbara Tumpach"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19336v1",
    "title": "GANeXt: A Fully ConvNeXt-Enhanced Generative Adversarial Network for MRI- and CBCT-to-CT Synthesis",
    "summary": "The synthesis of computed tomography (CT) from magnetic resonance imaging (MRI) and cone-beam CT (CBCT) plays a critical role in clinical treatment planning by enabling accurate anatomical representation in adaptive radiotherapy. In this work, we propose GANeXt, a 3D patch-based, fully ConvNeXt-powered generative adversarial network for unified CT synthesis across different modalities and anatomical regions. Specifically, GANeXt employs an efficient U-shaped generator constructed from stacked 3D ConvNeXt blocks with compact convolution kernels, while the discriminator adopts a conditional PatchGAN. To improve synthesis quality, we incorporate a combination of loss functions, including mean absolute error (MAE), perceptual loss, segmentation-based masked MAE, and adversarial loss and a combination of Dice loss and cross-entropy for multi-head segmentation discriminator. For both tasks, training is performed with a batch size of 8 using two separate AdamW optimizers for the generator and discriminator, each equipped with a warmup and cosine decay scheduler, with learning rates of $5\\times10^{-4}$ and $1\\times10^{-3}$, respectively. Data preprocessing includes deformable registration, foreground cropping, percentile normalization for the input modality, and linear normalization of the CT to the range $[-1024, 1000]$. Data augmentation involves random zooming within $(0.8, 1.3)$ (for MRI-to-CT only), fixed-size cropping to $32\\times160\\times192$ for MRI-to-CT and $32\\times128\\times128$ for CBCT-to-CT, and random flipping. During inference, we apply a sliding-window approach with $0.8$ overlap and average folding to reconstruct the full-size sCT, followed by inversion of the CT normalization. After joint training on all regions without any fine-tuning, the final models are selected at the end of 3000 epochs for MRI-to-CT and 1000 epochs for CBCT-to-CT using the full training dataset.",
    "published": "2025-12-22T12:32:16Z",
    "updated": "2025-12-22T12:32:16Z",
    "link": "http://arxiv.org/pdf/2512.19336v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Siyuan Mei",
      "Yan Xia",
      "Fuxin Fan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19331v1",
    "title": "DeltaMIL: Gated Memory Integration for Efficient and Discriminative Whole Slide Image Analysis",
    "summary": "Whole Slide Images (WSIs) are typically analyzed using multiple instance learning (MIL) methods. However, the scale and heterogeneity of WSIs generate highly redundant and dispersed information, making it difficult to identify and integrate discriminative signals. Existing MIL methods either fail to discard uninformative cues effectively or have limited ability to consolidate relevant features from multiple patches, which restricts their performance on large and heterogeneous WSIs. To address this issue, we propose DeltaMIL, a novel MIL framework that explicitly selects semantically relevant regions and integrates the discriminative information from WSIs. Our method leverages the gated delta rule to efficiently filter and integrate information through a block combining forgetting and memory mechanisms. The delta mechanism dynamically updates the memory by removing old values and inserting new ones according to their correlation with the current patch. The gating mechanism further enables rapid forgetting of irrelevant signals. Additionally, DeltaMIL integrates a complementary local pattern mixing mechanism to retain fine-grained pathological locality. Our design enhances the extraction of meaningful cues and suppresses redundant or noisy information, which improves the model's robustness and discriminative power. Experiments demonstrate that DeltaMIL achieves state-of-the-art performance. Specifically, for survival prediction, DeltaMIL improves performance by 3.69\\% using ResNet-50 features and 2.36\\% using UNI features. For slide-level classification, it increases accuracy by 3.09\\% with ResNet-50 features and 3.75\\% with UNI features. These results demonstrate the strong and consistent performance of DeltaMIL across diverse WSI tasks.",
    "published": "2025-12-22T12:27:12Z",
    "updated": "2025-12-22T12:27:12Z",
    "link": "http://arxiv.org/pdf/2512.19331v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yueting Zhu",
      "Yuehao Song",
      "Shuai Zhang",
      "Wenyu Liu",
      "Xinggang Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19327v1",
    "title": "Extended OpenTT Games Dataset: A table tennis dataset for fine-grained shot type and point outcome",
    "summary": "Automatically detecting and classifying strokes in table tennis video can streamline training workflows, enrich broadcast overlays, and enable fine-grained performance analytics. For this to be possible, annotated video data of table tennis is needed. We extend the public OpenTTGames dataset with highly detailed, frame-accurate shot type annotations (forehand, backhand with subtypes), player posture labels (body lean and leg stance), and rally outcome tags at point end. OpenTTGames is a set of recordings from the side of the table with official labels for bounces, when the ball is above the net, or hitting the net. The dataset already contains ball coordinates near events, which are either \"bounce\", \"net\", or \"empty_event\" in the original OpenTTGames dataset, and semantic masks (humans, table, scoreboard). Our extension adds the types of stroke to the events and a per-player taxonomy so models can move beyond event spotting toward tactical understanding (e.g., whether a stroke is likely to win the point or set up an advantage). We provide a compact coding scheme and code-assisted labeling procedure to support reproducible annotations and baselines for fine-grained stroke understanding in racket sports. This fills a practical gap in the community, where many prior video resources are either not publicly released or carry restrictive/unclear licenses that hinder reuse and benchmarking. Our annotations are released under the same CC BY-NC-SA 4.0 license as OpenTTGames, allowing free non-commercial use, modification, and redistribution, with appropriate attribution.",
    "published": "2025-12-22T12:25:50Z",
    "updated": "2025-12-22T12:25:50Z",
    "link": "http://arxiv.org/pdf/2512.19327v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Moamal Fadhil Abdul",
      "Jonas Bruun Hubrechts",
      "Thomas Martini Jørgensen",
      "Emil Hovad"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19316v1",
    "title": "Neural Implicit Heart Coordinates: 3D cardiac shape reconstruction from sparse segmentations",
    "summary": "Accurate reconstruction of cardiac anatomy from sparse clinical images remains a major challenge in patient-specific modeling. While neural implicit functions have previously been applied to this task, their application to mapping anatomical consistency across subjects has been limited. In this work, we introduce Neural Implicit Heart Coordinates (NIHCs), a standardized implicit coordinate system, based on universal ventricular coordinates, that provides a common anatomical reference frame for the human heart. Our method predicts NIHCs directly from a limited number of 2D segmentations (sparse acquisition) and subsequently decodes them into dense 3D segmentations and high-resolution meshes at arbitrary output resolution. Trained on a large dataset of 5,000 cardiac meshes, the model achieves high reconstruction accuracy on clinical contours, with mean Euclidean surface errors of 2.51$\\pm$0.33 mm in a diseased cohort (n=4549) and 2.3$\\pm$0.36 mm in a healthy cohort (n=5576). The NIHC representation enables anatomically coherent reconstruction even under severe slice sparsity and segmentation noise, faithfully recovering complex structures such as the valve planes. Compared with traditional pipelines, inference time is reduced from over 60 s to 5-15 s. These results demonstrate that NIHCs constitute a robust and efficient anatomical representation for patient-specific 3D cardiac reconstruction from minimal input data.",
    "published": "2025-12-22T12:07:05Z",
    "updated": "2025-12-22T12:07:05Z",
    "link": "http://arxiv.org/pdf/2512.19316v1.pdf",
    "category": [
      "cs.CV",
      "eess.IV"
    ],
    "authors": [
      "Marica Muffoletto",
      "Uxio Hermida",
      "Charlène Mauger",
      "Avan Suinesiaputra",
      "Yiyang Xu",
      "Richard Burns",
      "Lisa Pankewitz",
      "Andrew D McCulloch",
      "Steffen E Petersen",
      "Daniel Rueckert",
      "Alistair A Young"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19302v1",
    "title": "Bridging Semantics and Geometry: A Decoupled LVLM-SAM Framework for Reasoning Segmentation in Remote Sensing",
    "summary": "Large Vision-Language Models (LVLMs) hold great promise for advancing remote sensing (RS) analysis, yet existing reasoning segmentation frameworks couple linguistic reasoning and pixel prediction through end-to-end supervised fine-tuning, leading to weak geometric grounding and limited generalization across tasks. To address this, we developed Think2Seg-RS, a decoupled framework that trains an LVLM prompter to control a frozen Segment Anything Model (SAM) via structured geometric prompts. Through a mask-only reinforcement learning objective, the LVLM learns to translate abstract semantic reasoning into spatially grounded actions, achieving state-of-the-art performance on the EarthReason dataset. Remarkably, the learned prompting policy generalizes zero-shot to multiple referring segmentation benchmarks, exposing a distinct divide between semantic-level and instance-level grounding. We further found that compact segmenters outperform larger ones under semantic-level supervision, and that negative prompts are ineffective in heterogeneous aerial backgrounds. Together, these findings establish semantic-level reasoning segmentation as a new paradigm for geospatial understanding, opening the way toward unified, interpretable LVLM-driven Earth observation. Our code and model are available at https://github.com/Ricardo-XZ/Think2Seg-RS.",
    "published": "2025-12-22T11:46:42Z",
    "updated": "2025-12-22T11:46:42Z",
    "link": "http://arxiv.org/pdf/2512.19302v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xu Zhang",
      "Junyao Ge",
      "Yang Zheng",
      "Kaitai Guo",
      "Jimin Liang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19300v1",
    "title": "RMLer: Synthesizing Novel Objects across Diverse Categories via Reinforcement Mixing Learning",
    "summary": "Novel object synthesis by integrating distinct textual concepts from diverse categories remains a significant challenge in Text-to-Image (T2I) generation. Existing methods often suffer from insufficient concept mixing, lack of rigorous evaluation, and suboptimal outputs-manifesting as conceptual imbalance, superficial combinations, or mere juxtapositions. To address these limitations, we propose Reinforcement Mixing Learning (RMLer), a framework that formulates cross-category concept fusion as a reinforcement learning problem: mixed features serve as states, mixing strategies as actions, and visual outcomes as rewards. Specifically, we design an MLP-policy network to predict dynamic coefficients for blending cross-category text embeddings. We further introduce visual rewards based on (1) semantic similarity and (2) compositional balance between the fused object and its constituent concepts, optimizing the policy via proximal policy optimization. At inference, a selection strategy leverages these rewards to curate the highest-quality fused objects. Extensive experiments demonstrate RMLer's superiority in synthesizing coherent, high-fidelity objects from diverse categories, outperforming existing methods. Our work provides a robust framework for generating novel visual concepts, with promising applications in film, gaming, and design.",
    "published": "2025-12-22T11:44:32Z",
    "updated": "2025-12-22T11:44:32Z",
    "link": "http://arxiv.org/pdf/2512.19300v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jun Li",
      "Zikun Chen",
      "Haibo Chen",
      "Shuo Chen",
      "Jian Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19283v1",
    "title": "Hand-Aware Egocentric Motion Reconstruction with Sequence-Level Context",
    "summary": "Egocentric vision systems are becoming widely available, creating new opportunities for human-computer interaction. A core challenge is estimating the wearer's full-body motion from first-person videos, which is crucial for understanding human behavior. However, this task is difficult since most body parts are invisible from the egocentric view. Prior approaches mainly rely on head trajectories, leading to ambiguity, or assume continuously tracked hands, which is unrealistic for lightweight egocentric devices. In this work, we present HaMoS, the first hand-aware, sequence-level diffusion framework that directly conditions on both head trajectory and intermittently visible hand cues caused by field-of-view limitations and occlusions, as in real-world egocentric devices. To overcome the lack of datasets pairing diverse camera views with human motion, we introduce a novel augmentation method that models such real-world conditions. We also demonstrate that sequence-level contexts such as body shape and field-of-view are crucial for accurate motion reconstruction, and thus employ local attention to infer long sequences efficiently. Experiments on public benchmarks show that our method achieves state-of-the-art accuracy and temporal smoothness, demonstrating a practical step toward reliable in-the-wild egocentric 3D motion understanding.",
    "published": "2025-12-22T11:26:41Z",
    "updated": "2025-12-22T11:26:41Z",
    "link": "http://arxiv.org/pdf/2512.19283v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Kyungwon Cho",
      "Hanbyul Joo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19271v1",
    "title": "3SGen: Unified Subject, Style, and Structure-Driven Image Generation with Adaptive Task-specific Memory",
    "summary": "Recent image generation approaches often address subject, style, and structure-driven conditioning in isolation, leading to feature entanglement and limited task transferability. In this paper, we introduce 3SGen, a task-aware unified framework that performs all three conditioning modes within a single model. 3SGen employs an MLLM equipped with learnable semantic queries to align text-image semantics, complemented by a VAE branch that preserves fine-grained visual details. At its core, an Adaptive Task-specific Memory (ATM) module dynamically disentangles, stores, and retrieves condition-specific priors, such as identity for subjects, textures for styles, and spatial layouts for structures, via a lightweight gating mechanism along with several scalable memory items. This design mitigates inter-task interference and naturally scales to compositional inputs. In addition, we propose 3SGen-Bench, a unified image-driven generation benchmark with standardized metrics for evaluating cross-task fidelity and controllability. Extensive experiments on our proposed 3SGen-Bench and other public benchmarks demonstrate our superior performance across diverse image-driven generation tasks.",
    "published": "2025-12-22T11:07:27Z",
    "updated": "2025-12-22T11:07:27Z",
    "link": "http://arxiv.org/pdf/2512.19271v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xinyang Song",
      "Libin Wang",
      "Weining Wang",
      "Zhiwei Li",
      "Jianxin Sun",
      "Dandan Zheng",
      "Jingdong Chen",
      "Qi Li",
      "Zhenan Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.17054v3",
    "title": "DeltaFlow: An Efficient Multi-frame Scene Flow Estimation Method",
    "summary": "Previous dominant methods for scene flow estimation focus mainly on input from two consecutive frames, neglecting valuable information in the temporal domain. While recent trends shift towards multi-frame reasoning, they suffer from rapidly escalating computational costs as the number of frames grows. To leverage temporal information more efficiently, we propose DeltaFlow ($Δ$Flow), a lightweight 3D framework that captures motion cues via a $Δ$ scheme, extracting temporal features with minimal computational cost, regardless of the number of frames. Additionally, scene flow estimation faces challenges such as imbalanced object class distributions and motion inconsistency. To tackle these issues, we introduce a Category-Balanced Loss to enhance learning across underrepresented classes and an Instance Consistency Loss to enforce coherent object motion, improving flow accuracy. Extensive evaluations on the Argoverse 2, Waymo and nuScenes datasets show that $Δ$Flow achieves state-of-the-art performance with up to 22% lower error and $2\\times$ faster inference compared to the next-best multi-frame supervised method, while also demonstrating a strong cross-domain generalization ability. The code is open-sourced at https://github.com/Kin-Zhang/DeltaFlow along with trained model weights.",
    "published": "2025-08-23T15:06:59Z",
    "updated": "2025-12-22T10:54:05Z",
    "link": "http://arxiv.org/pdf/2508.17054v3.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Qingwen Zhang",
      "Xiaomeng Zhu",
      "Yushan Zhang",
      "Yixi Cai",
      "Olov Andersson",
      "Patric Jensfelt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19243v1",
    "title": "VisionDirector: Vision-Language Guided Closed-Loop Refinement for Generative Image Synthesis",
    "summary": "Generative models can now produce photorealistic imagery, yet they still struggle with the long, multi-goal prompts that professional designers issue. To expose this gap and better evaluate models' performance in real-world settings, we introduce Long Goal Bench (LGBench), a 2,000-task suite (1,000 T2I and 1,000 I2I) whose average instruction contains 18 to 22 tightly coupled goals spanning global layout, local object placement, typography, and logo fidelity. We find that even state-of-the-art models satisfy fewer than 72 percent of the goals and routinely miss localized edits, confirming the brittleness of current pipelines. To address this, we present VisionDirector, a training-free vision-language supervisor that (i) extracts structured goals from long instructions, (ii) dynamically decides between one-shot generation and staged edits, (iii) runs micro-grid sampling with semantic verification and rollback after every edit, and (iv) logs goal-level rewards. We further fine-tune the planner with Group Relative Policy Optimization, yielding shorter edit trajectories (3.1 versus 4.2 steps) and stronger alignment. VisionDirector achieves new state of the art on GenEval (plus 7 percent overall) and ImgEdit (plus 0.07 absolute) while producing consistent qualitative improvements on typography, multi-object scenes, and pose editing.",
    "published": "2025-12-22T10:25:38Z",
    "updated": "2025-12-22T10:25:38Z",
    "link": "http://arxiv.org/pdf/2512.19243v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Meng Chu",
      "Senqiao Yang",
      "Haoxuan Che",
      "Suiyun Zhang",
      "Xichen Zhang",
      "Shaozuo Yu",
      "Haokun Gui",
      "Zhefan Rao",
      "Dandan Tu",
      "Rui Liu",
      "Jiaya Jia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.00086v2",
    "title": "Multi-modal On-Device Learning for Monocular Depth Estimation on Ultra-low-power MCUs",
    "summary": "Monocular depth estimation (MDE) plays a crucial role in enabling spatially-aware applications in Ultra-low-power (ULP) Internet-of-Things (IoT) platforms. However, the limited number of parameters of Deep Neural Networks for the MDE task, designed for IoT nodes, results in severe accuracy drops when the sensor data observed in the field shifts significantly from the training dataset. To address this domain shift problem, we present a multi-modal On-Device Learning (ODL) technique, deployed on an IoT device integrating a Greenwaves GAP9 MicroController Unit (MCU), a 80 mW monocular camera and a 8 x 8 pixel depth sensor, consuming $\\approx$300mW. In its normal operation, this setup feeds a tiny 107 k-parameter $μ$PyD-Net model with monocular images for inference. The depth sensor, usually deactivated to minimize energy consumption, is only activated alongside the camera to collect pseudo-labels when the system is placed in a new environment. Then, the fine-tuning task is performed entirely on the MCU, using the new data. To optimize our backpropagation-based on-device training, we introduce a novel memory-driven sparse update scheme, which minimizes the fine-tuning memory to 1.2 MB, 2.2x less than a full update, while preserving accuracy (i.e., only 2% and 1.5% drops on the KITTI and NYUv2 datasets). Our in-field tests demonstrate, for the first time, that ODL for MDE can be performed in 17.8 minutes on the IoT node, reducing the root mean squared error from 4.9 to 0.6m with only 3 k self-labeled samples, collected in a real-life deployment scenario.",
    "published": "2025-11-26T09:46:09Z",
    "updated": "2025-12-22T10:06:08Z",
    "link": "http://arxiv.org/pdf/2512.00086v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Davide Nadalini",
      "Manuele Rusci",
      "Elia Cereda",
      "Luca Benini",
      "Francesco Conti",
      "Daniele Palossi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19225v1",
    "title": "Selective Phase-Aware Training of nnU-Net for Robust Breast Cancer Segmentation in Multi-Center DCE-MRI",
    "summary": "Breast cancer remains the most common cancer among women and is a leading cause of female mortality. Dynamic contrast-enhanced MRI (DCE-MRI) is a powerful imaging tool for evaluating breast tumors, yet the field lacks a standardized benchmark for analyzing treatment responses and guiding personalized care. We participated in the MAMA-MIA Challenge's Primary Tumor Segmentation task and this work presents a proposed selective, phase-aware training framework for the nnU-Net architecture, emphasizing quality-focused data selection to strengthen model robustness and generalization. We employed the No New Net (nnU-Net) framework with a selective training strategy that systematically analyzed the impact of image quality and center-specific variability on segmentation performance. Controlled experiments on the DUKE, NACT, ISPY1, and ISPY2 datasets revealed that including ISPY scans with motion artifacts and reduced contrast impaired segmentation performance, even with advanced preprocessing, such as contrast-limited adaptive histogram equalization (CLAHE). In contrast, training on DUKE and NACT data, which exhibited clearer contrast and fewer motion artifacts despite varying resolutions, with early phase images (0000-0002) provided more stable training conditions. Our results demonstrate the importance of phase-sensitive and quality-aware training strategies in achieving reliable segmentation performance in heterogeneous clinical datasets, highlighting the limitations of the expansion of naive datasets and motivating the need for future automation of quality-based data selection strategies.",
    "published": "2025-12-22T10:05:37Z",
    "updated": "2025-12-22T10:05:37Z",
    "link": "http://arxiv.org/pdf/2512.19225v1.pdf",
    "category": [
      "eess.IV",
      "cs.CV"
    ],
    "authors": [
      "Beyza Zayim",
      "Aissiou Ikram",
      "Boukhiar Naima"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19214v1",
    "title": "HippMetric: A skeletal-representation-based framework for cross-sectional and longitudinal hippocampal substructural morphometry",
    "summary": "Accurate characterization of hippocampal substructure is crucial for detecting subtle structural changes and identifying early neurodegenerative biomarkers. However, high inter-subject variability and complex folding pattern of human hippocampus hinder consistent cross-subject and longitudinal analysis. Most existing approaches rely on subject-specific modelling and lack a stable intrinsic coordinate system to accommodate anatomical variability, which limits their ability to establish reliable inter- and intra-individual correspondence. To address this, we propose HippMetric, a skeletal representation (s-rep)-based framework for hippocampal substructural morphometry and point-wise correspondence across individuals and scans. HippMetric builds on the Axis-Referenced Morphometric Model (ARMM) and employs a deformable skeletal coordinate system aligned with hippocampal anatomy and function, providing a biologically grounded reference for correspondence. Our framework comprises two core modules: a skeletal-based coordinate system that respects the hippocampus' conserved longitudinal lamellar architecture, in which functional units (lamellae) are stacked perpendicular to the long-axis, enabling anatomically consistent localization across subjects and time; and individualized s-reps generated through surface reconstruction, deformation, and geometrically constrained spoke refinement, enforcing boundary adherence, orthogonality and non-intersection to produce mathematically valid skeletal geometry. Extensive experiments on two international cohorts demonstrate that HippMetric achieves higher accuracy, reliability, and correspondence stability compared to existing shape models.",
    "published": "2025-12-22T09:53:55Z",
    "updated": "2025-12-22T09:53:55Z",
    "link": "http://arxiv.org/pdf/2512.19214v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Na Gao",
      "Chenfei Ye",
      "Yanwu Yang",
      "Anqi Li",
      "Zhengbo He",
      "Li Liang",
      "Zhiyuan Liu",
      "Xingyu Hao",
      "Ting Ma",
      "Tengfei Guo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19213v1",
    "title": "InvCoSS: Inversion-driven Continual Self-supervised Learning in Medical Multi-modal Image Pre-training",
    "summary": "Continual self-supervised learning (CSSL) in medical imaging trains a foundation model sequentially, alleviating the need for collecting multi-modal images for joint training and offering promising improvements in downstream performance while preserving data privacy. However, most existing methods still rely on replaying data from previous stages to prevent catastrophic forgetting, which compromises privacy and limits their applicability in real-world scenarios where data transfer across sites is often restricted. In this work, we propose InvCoSS, an inversion-driven continual self-supervised learning framework for medical multi-modal image pre-training. Specifically, after training on a previous task, InvCoSS inverts the pre-trained self-supervised model to generate synthetic images that approximate the original training distribution. These synthetic images are then combined with data from the new task for joint optimization, which effectively mitigates catastrophic forgetting while strictly adhering to the constraint of no access to previous real data. Furthermore, to improve the fidelity of synthetic images, we introduce a novel InvUNet with a multi-scale fusion architecture to restore both high- and low-frequency components of the inverted images. To enhance diversity and prevent mode collapse, we design a repulsive representation-learning mechanism that encourages a diverse feature space for synthetic images without class guidance. Extensive experiments across nine downstream tasks validate the effectiveness of InvCoSS, achieving performance comparable to or even superior to prior data-replay methods while significantly reducing storage requirements and eliminating data privacy constraints.",
    "published": "2025-12-22T09:53:38Z",
    "updated": "2025-12-22T09:53:38Z",
    "link": "http://arxiv.org/pdf/2512.19213v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zihao Luo",
      "Shaohao Rui",
      "Zhenyu Tang",
      "Guotai Wang",
      "Xiaosong Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19190v1",
    "title": "PEDESTRIAN: An Egocentric Vision Dataset for Obstacle Detection on Pavements",
    "summary": "Walking has always been a primary mode of transportation and is recognized as an essential activity for maintaining good health. Despite the need for safe walking conditions in urban environments, sidewalks are frequently obstructed by various obstacles that hinder free pedestrian movement. Any object obstructing a pedestrian's path can pose a safety hazard. The advancement of pervasive computing and egocentric vision techniques offers the potential to design systems that can automatically detect such obstacles in real time, thereby enhancing pedestrian safety. The development of effective and efficient identification algorithms relies on the availability of comprehensive and well-balanced datasets of egocentric data. In this work, we introduce the PEDESTRIAN dataset, comprising egocentric data for 29 different obstacles commonly found on urban sidewalks. A total of 340 videos were collected using mobile phone cameras, capturing a pedestrian's point of view. Additionally, we present the results of a series of experiments that involved training several state-of-the-art deep learning algorithms using the proposed dataset, which can be used as a benchmark for obstacle detection and recognition tasks. The dataset can be used for training pavement obstacle detectors to enhance the safety of pedestrians in urban areas.",
    "published": "2025-12-22T09:28:23Z",
    "updated": "2025-12-22T09:28:23Z",
    "link": "http://arxiv.org/pdf/2512.19190v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Marios Thoma",
      "Zenonas Theodosiou",
      "Harris Partaourides",
      "Vassilis Vassiliades",
      "Loizos Michael",
      "Andreas Lanitis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.17098v2",
    "title": "Predictive Modeling of Maritime Radar Data Using Transformer Architecture",
    "summary": "Maritime autonomous systems require robust predictive capabilities to anticipate vessel motion and environmental dynamics. While transformer architectures have revolutionized AIS-based trajectory prediction and demonstrated feasibility for sonar frame forecasting, their application to maritime radar frame prediction remains unexplored, creating a critical gap given radar's all-weather reliability for navigation. This survey systematically reviews predictive modeling approaches relevant to maritime radar, with emphasis on transformer architectures for spatiotemporal sequence forecasting, where existing representative methods are analyzed according to data type, architecture, and prediction horizon. Our review shows that, while the literature has demonstrated transformer-based frame prediction for sonar sensing, no prior work addresses transformer-based maritime radar frame prediction, thereby defining a clear research gap and motivating a concrete research direction for future work in this area.",
    "published": "2025-12-18T21:52:43Z",
    "updated": "2025-12-22T09:17:40Z",
    "link": "http://arxiv.org/pdf/2512.17098v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Bjorna Qesaraku",
      "Jan Steckel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.13385v2",
    "title": "SNN-Driven Multimodal Human Action Recognition via Sparse Spatial-Temporal Data Fusion",
    "summary": "Multimodal human action recognition based on RGB and skeleton data fusion, while effective, is constrained by significant limitations such as high computational complexity, excessive memory consumption, and substantial energy demands, particularly when implemented with Artificial Neural Networks (ANN). These limitations restrict its applicability in resource-constrained scenarios. To address these challenges, we propose a novel Spiking Neural Network (SNN)-driven framework for multimodal human action recognition, utilizing event camera and skeleton data. Our framework is centered on two key innovations: (1) a novel multimodal SNN architecture that employs distinct backbone networks for each modality-an SNN-based Mamba for event camera data and a Spiking Graph Convolutional Network (SGN) for skeleton data-combined with a spiking semantic extraction module to capture deep semantic representations; and (2) a pioneering SNN-based discretized information bottleneck mechanism for modality fusion, which effectively balances the preservation of modality-specific semantics with efficient information compression. To validate our approach, we propose a novel method for constructing a multimodal dataset that integrates event camera and skeleton data, enabling comprehensive evaluation. Extensive experiments demonstrate that our method achieves superior performance in both recognition accuracy and energy efficiency, offering a promising solution for practical applications.",
    "published": "2025-02-19T02:50:51Z",
    "updated": "2025-12-22T09:07:34Z",
    "link": "http://arxiv.org/pdf/2502.13385v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Naichuan Zheng",
      "Hailun Xia",
      "Zeyu Liang",
      "Yuchen Du"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.09377v3",
    "title": "Gradient as Conditions: Rethinking HOG for All-in-one Image Restoration",
    "summary": "All-in-one image restoration (AIR) aims to address diverse degradations within a unified model by leveraging informative degradation conditions to guide the restoration process. However, existing methods often rely on implicitly learned priors, which may entangle feature representations and hinder performance in complex or unseen scenarios. Histogram of Oriented Gradients (HOG) as a classical gradient representation, we observe that it has strong discriminative capability across diverse degradations, making it a powerful and interpretable prior for AIR. Based on this insight, we propose HOGformer, a Transformer-based model that integrates learnable HOG features for degradation-aware restoration. The core of HOGformer is a Dynamic HOG-aware Self-Attention (DHOGSA) mechanism, which adaptively models long-range spatial dependencies conditioned on degradation-specific cues encoded by HOG descriptors. To further adapt the heterogeneity of degradations in AIR, we propose a Dynamic Interaction Feed-Forward (DIFF) module that facilitates channel-spatial interactions, enabling robust feature transformation under diverse degradations. Besides, we propose a HOG loss to explicitly enhance structural fidelity and edge sharpness. Extensive experiments on a variety of benchmarks, including adverse weather and natural degradations, demonstrate that HOGformer achieves state-of-the-art performance and generalizes well to complex real-world scenarios.Code is available at https://github.com/Fire-friend/HOGformer.",
    "published": "2025-04-12T23:52:59Z",
    "updated": "2025-12-22T09:07:03Z",
    "link": "http://arxiv.org/pdf/2504.09377v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jiawei Wu",
      "Zhifei Yang",
      "Zhe Wang",
      "Zhi Jin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19159v1",
    "title": "OmniMoGen: Unifying Human Motion Generation via Learning from Interleaved Text-Motion Instructions",
    "summary": "Large language models (LLMs) have unified diverse linguistic tasks within a single framework, yet such unification remains unexplored in human motion generation. Existing methods are confined to isolated tasks, limiting flexibility for free-form and omni-objective generation. To address this, we propose OmniMoGen, a unified framework that enables versatile motion generation through interleaved text-motion instructions. Built upon a concise RVQ-VAE and transformer architecture, OmniMoGen supports end-to-end instruction-driven motion generation. We construct X2Mo, a large-scale dataset of over 137K interleaved text-motion instructions, and introduce AnyContext, a benchmark for evaluating interleaved motion generation. Experiments show that OmniMoGen achieves state-of-the-art performance on text-to-motion, motion editing, and AnyContext, exhibiting emerging capabilities such as compositional editing, self-reflective generation, and knowledge-informed generation. These results mark a step toward the next intelligent motion generation. Project Page: https://OmniMoGen.github.io/.",
    "published": "2025-12-22T08:55:23Z",
    "updated": "2025-12-22T08:55:23Z",
    "link": "http://arxiv.org/pdf/2512.19159v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Wendong Bu",
      "Kaihang Pan",
      "Yuze Lin",
      "Jiacheng Li",
      "Kai Shen",
      "Wenqiao Zhang",
      "Juncheng Li",
      "Jun Xiao",
      "Siliang Tang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19150v1",
    "title": "AMap: Distilling Future Priors for Ahead-Aware Online HD Map Construction",
    "summary": "Online High-Definition (HD) map construction is pivotal for autonomous driving. While recent approaches leverage historical temporal fusion to improve performance, we identify a critical safety flaw in this paradigm: it is inherently ``spatially backward-looking.\" These methods predominantly enhance map reconstruction in traversed areas, offering minimal improvement for the unseen road ahead. Crucially, our analysis of downstream planning tasks reveals a severe asymmetry: while rearward perception errors are often tolerable, inaccuracies in the forward region directly precipitate hazardous driving maneuvers. To bridge this safety gap, we propose AMap, a novel framework for Ahead-aware online HD Mapping. We pioneer a ``distill-from-future\" paradigm, where a teacher model with privileged access to future temporal contexts guides a lightweight student model restricted to the current frame. This process implicitly compresses prospective knowledge into the student model, endowing it with ``look-ahead\" capabilities at zero inference-time cost. Technically, we introduce a Multi-Level BEV Distillation strategy with spatial masking and an Asymmetric Query Adaptation module to effectively transfer future-aware representations to the student's static queries. Extensive experiments on the nuScenes and Argoverse 2 benchmark demonstrate that AMap significantly enhances current-frame perception. Most notably, it outperforms state-of-the-art temporal models in critical forward regions while maintaining the efficiency of single current frame inference.",
    "published": "2025-12-22T08:46:59Z",
    "updated": "2025-12-22T08:46:59Z",
    "link": "http://arxiv.org/pdf/2512.19150v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ruikai Li",
      "Xinrun Li",
      "Mengwei Xie",
      "Hao Shan",
      "Shoumeng Qiu",
      "Xinyuan Chang",
      "Yizhe Fan",
      "Feng Xiong",
      "Han Jiang",
      "Yilong Ren",
      "Haiyang Yu",
      "Mu Xu",
      "Yang Long",
      "Varun Ojha",
      "Zhiyong Cui"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19133v1",
    "title": "WorldRFT: Latent World Model Planning with Reinforcement Fine-Tuning for Autonomous Driving",
    "summary": "Latent World Models enhance scene representation through temporal self-supervised learning, presenting a perception annotation-free paradigm for end-to-end autonomous driving. However, the reconstruction-oriented representation learning tangles perception with planning tasks, leading to suboptimal optimization for planning. To address this challenge, we propose WorldRFT, a planning-oriented latent world model framework that aligns scene representation learning with planning via a hierarchical planning decomposition and local-aware interactive refinement mechanism, augmented by reinforcement learning fine-tuning (RFT) to enhance safety-critical policy performance. Specifically, WorldRFT integrates a vision-geometry foundation model to improve 3D spatial awareness, employs hierarchical planning task decomposition to guide representation optimization, and utilizes local-aware iterative refinement to derive a planning-oriented driving policy. Furthermore, we introduce Group Relative Policy Optimization (GRPO), which applies trajectory Gaussianization and collision-aware rewards to fine-tune the driving policy, yielding systematic improvements in safety. WorldRFT achieves state-of-the-art (SOTA) performance on both open-loop nuScenes and closed-loop NavSim benchmarks. On nuScenes, it reduces collision rates by 83% (0.30% -> 0.05%). On NavSim, using camera-only sensors input, it attains competitive performance with the LiDAR-based SOTA method DiffusionDrive (87.8 vs. 88.1 PDMS).",
    "published": "2025-12-22T08:27:44Z",
    "updated": "2025-12-22T08:27:44Z",
    "link": "http://arxiv.org/pdf/2512.19133v1.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Pengxuan Yang",
      "Ben Lu",
      "Zhongpu Xia",
      "Chao Han",
      "Yinfeng Gao",
      "Teng Zhang",
      "Kun Zhan",
      "XianPeng Lang",
      "Yupeng Zheng",
      "Qichao Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.10609v2",
    "title": "MSTAR: Box-free Multi-query Scene Text Retrieval with Attention Recycling",
    "summary": "Scene text retrieval has made significant progress with the assistance of accurate text localization. However, existing approaches typically require costly bounding box annotations for training. Besides, they mostly adopt a customized retrieval strategy but struggle to unify various types of queries to meet diverse retrieval needs. To address these issues, we introduce Muti-query Scene Text retrieval with Attention Recycling (MSTAR), a box-free approach for scene text retrieval. It incorporates progressive vision embedding to dynamically capture the multi-grained representation of texts and harmonizes free-style text queries with style-aware instructions. Additionally, a multi-instance matching module is integrated to enhance vision-language alignment. Furthermore, we build the Multi-Query Text Retrieval (MQTR) dataset, the first benchmark designed to evaluate the multi-query scene text retrieval capability of models, comprising four query types and 16k images. Extensive experiments demonstrate the superiority of our method across seven public datasets and the MQTR dataset. Notably, MSTAR marginally surpasses the previous state-of-the-art model by 6.4% in MAP on Total-Text while eliminating box annotation costs. Moreover, on the MQTR benchmark, MSTAR significantly outperforms the previous models by an average of 8.5%. The code and datasets are available at https://github.com/yingift/MSTAR.",
    "published": "2025-06-12T11:54:13Z",
    "updated": "2025-12-22T08:24:53Z",
    "link": "http://arxiv.org/pdf/2506.10609v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Liang Yin",
      "Xudong Xie",
      "Zhang Li",
      "Xiang Bai",
      "Yuliang Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.15553v2",
    "title": "Deep Equilibrium Convolutional Sparse Coding for Hyperspectral Image Denoising",
    "summary": "Hyperspectral images (HSIs) play a crucial role in remote sensing but are often degraded by complex noise patterns. Ensuring the physical property of the denoised HSIs is vital for robust HSI denoising, giving the rise of deep unfolding-based methods. However, these methods map the optimization of a physical model to a learnable network with a predefined depth, which lacks convergence guarantees. In contrast, Deep Equilibrium (DEQ) models treat the hidden layers of deep networks as the solution to a fixed-point problem and models them as infinite-depth networks, naturally consistent with the optimization. Under the framework of DEQ, we propose a Deep Equilibrium Convolutional Sparse Coding (DECSC) framework that unifies local spatial-spectral correlations, nonlocal spatial self-similarities, and global spatial consistency for robust HSI denoising. Within the convolutional sparse coding (CSC) framework, we enforce shared 2D convolutional sparse representation to ensure global spatial consistency across bands, while unshared 3D convolutional sparse representation captures local spatial-spectral details. To further exploit nonlocal self-similarities, a transformer block is embedded after the 2D CSC. Additionally, a detail enhancement module is integrated with the 3D CSC to promote image detail preservation. We formulate the proximal gradient descent of the CSC model as a fixed-point problem and transform the iterative updates into a learnable network architecture within the framework of DEQ. Experimental results demonstrate that our DECSC method achieves superior denoising performance compared to state-of-the-art methods.",
    "published": "2025-08-21T13:35:11Z",
    "updated": "2025-12-22T07:57:02Z",
    "link": "http://arxiv.org/pdf/2508.15553v2.pdf",
    "category": [
      "eess.IV",
      "cs.CV"
    ],
    "authors": [
      "Jin Ye",
      "Jingran Wang",
      "Fengchao Xiong",
      "Jingzhou Chen",
      "Yuntao Qian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.15647v2",
    "title": "Hard Labels In! Rethinking the Role of Hard Labels in Mitigating Local Semantic Drift",
    "summary": "Soft labels generated by teacher models have become a dominant paradigm for knowledge transfer and recent large-scale dataset distillation such as SRe2L, RDED, LPLD, offering richer supervision than conventional hard labels. However, we observe that when only a limited number of crops per image are used, soft labels are prone to local semantic drift: a crop may visually resemble another class, causing its soft embedding to deviate from the ground-truth semantics of the original image. This mismatch between local visual content and global semantic meaning introduces systematic errors and distribution misalignment between training and testing. In this work, we revisit the overlooked role of hard labels and show that, when appropriately integrated, they provide a powerful content-agnostic anchor to calibrate semantic drift. We theoretically characterize the emergence of drift under few soft-label supervision and demonstrate that hybridizing soft and hard labels restores alignment between visual content and semantic supervision. Building on this insight, we propose a new training paradigm, Hard Label for Alleviating Local Semantic Drift (HALD), which leverages hard labels as intermediate corrective signals while retaining the fine-grained advantages of soft labels. Extensive experiments on dataset distillation and large-scale conventional classification benchmarks validate our approach, showing consistent improvements in generalization. On ImageNet-1K, we achieve 42.7% with only 285M storage for soft labels, outperforming prior state-of-the-art LPLD by 9.0%. Our findings re-establish the importance of hard labels as a complementary tool, and call for a rethinking of their role in soft-label-dominated training.",
    "published": "2025-12-17T17:54:20Z",
    "updated": "2025-12-22T07:47:31Z",
    "link": "http://arxiv.org/pdf/2512.15647v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jiacheng Cui",
      "Bingkui Tong",
      "Xinyue Bi",
      "Xiaohan Zhao",
      "Jiacheng Liu",
      "Zhiqiang Shen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19115v1",
    "title": "Generative Giants, Retrieval Weaklings: Why do Multimodal Large Language Models Fail at Multimodal Retrieval?",
    "summary": "Despite the remarkable success of multimodal large language models (MLLMs) in generative tasks, we observe that they exhibit a counterintuitive deficiency in the zero-shot multimodal retrieval task. In this work, we investigate the underlying mechanisms that hinder MLLMs from serving as effective retrievers. With the help of sparse autoencoders (SAEs), we decompose MLLM output representations into interpretable semantic concepts to probe their intrinsic behavior. Our analysis reveals that the representation space of MLLMs is overwhelmingly dominated by textual semantics; the visual information essential for multimodal retrieval only constitutes a small portion. This imbalance is compounded by the heavy focus of MLLMs on bridging image-text modalities, which facilitates generation but homogenizes embeddings and finally diminishes the discriminative power required for multimodal retrieval. We further discover that the specific feature components that contribute most to the similarity computations for MLLMs are in fact distractors that actively degrade retrieval performance. Overall, our work provides the first in-depth interpretability analysis of MLLM representations in the context of multimodal retrieval and offers possible directions for enhancing the multimodal retrieval capabilities of MLLMs.",
    "published": "2025-12-22T07:36:20Z",
    "updated": "2025-12-22T07:36:20Z",
    "link": "http://arxiv.org/pdf/2512.19115v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Hengyi Feng",
      "Zeang Sheng",
      "Meiyi Qiang",
      "Wentao Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19110v1",
    "title": "Trifocal Tensor and Relative Pose Estimation with Known Vertical Direction",
    "summary": "This work presents two novel solvers for estimating the relative poses among views with known vertical directions. The vertical directions of camera views can be easily obtained using inertial measurement units (IMUs) which have been widely used in autonomous vehicles, mobile phones, and unmanned aerial vehicles (UAVs). Given the known vertical directions, our lgorithms only need to solve for two rotation angles and two translation vectors. In this paper, a linear closed-form solution has been described, requiring only four point correspondences in three views. We also propose a minimal solution with three point correspondences using the latest Gröbner basis solver. Since the proposed methods require fewer point correspondences, they can be efficiently applied within the RANSAC framework for outliers removal and pose estimation in visual odometry. The proposed method has been tested on both synthetic data and real-world scenes from KITTI. The experimental results show that the accuracy of the estimated poses is superior to other alternative methods.",
    "published": "2025-12-22T07:26:40Z",
    "updated": "2025-12-22T07:26:40Z",
    "link": "http://arxiv.org/pdf/2512.19110v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Tao Li",
      "Zhenbao Yu",
      "Banglei Guan",
      "Jianli Han",
      "Weimin Lv",
      "Friedrich Fraundorfer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19108v1",
    "title": "GaussianImage++: Boosted Image Representation and Compression with 2D Gaussian Splatting",
    "summary": "Implicit neural representations (INRs) have achieved remarkable success in image representation and compression, but they require substantial training time and memory. Meanwhile, recent 2D Gaussian Splatting (GS) methods (\\textit{e.g.}, GaussianImage) offer promising alternatives through efficient primitive-based rendering. However, these methods require excessive Gaussian primitives to maintain high visual fidelity. To exploit the potential of GS-based approaches, we present GaussianImage++, which utilizes limited Gaussian primitives to achieve impressive representation and compression performance. Firstly, we introduce a distortion-driven densification mechanism. It progressively allocates Gaussian primitives according to signal intensity. Secondly, we employ context-aware Gaussian filters for each primitive, which assist in the densification to optimize Gaussian primitives based on varying image content. Thirdly, we integrate attribute-separated learnable scalar quantizers and quantization-aware training, enabling efficient compression of primitive attributes. Experimental results demonstrate the effectiveness of our method. In particular, GaussianImage++ outperforms GaussianImage and INRs-based COIN in representation and compression performance while maintaining real-time decoding and low memory usage.",
    "published": "2025-12-22T07:22:39Z",
    "updated": "2025-12-22T07:22:39Z",
    "link": "http://arxiv.org/pdf/2512.19108v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Tiantian Li",
      "Xinjie Zhang",
      "Xingtong Ge",
      "Tongda Xu",
      "Dailan He",
      "Jun Zhang",
      "Yan Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19095v1",
    "title": "Mamba-Based Modality Disentanglement Network for Multi-Contrast MRI Reconstruction",
    "summary": "Magnetic resonance imaging (MRI) is a cornerstone of modern clinical diagnosis, offering unparalleled soft-tissue contrast without ionizing radiation. However, prolonged scan times remain a major barrier to patient throughput and comfort. Existing accelerated MRI techniques often struggle with two key challenges: (1) failure to effectively utilize inherent K-space prior information, leading to persistent aliasing artifacts from zero-filled inputs; and (2) contamination of target reconstruction quality by irrelevant information when employing multi-contrast fusion strategies. To overcome these challenges, we present MambaMDN, a dual-domain framework for multi-contrast MRI reconstruction. Our approach first employs fully-sampled reference K-space data to complete the undersampled target data, generating structurally aligned but modality-mixed inputs. Subsequently, we develop a Mamba-based modality disentanglement network to extract and remove reference-specific features from the mixed representation. Furthermore, we introduce an iterative refinement mechanism to progressively enhance reconstruction accuracy through repeated feature purification. Extensive experiments demonstrate that MambaMDN can significantly outperform existing multi-contrast reconstruction methods.",
    "published": "2025-12-22T07:06:34Z",
    "updated": "2025-12-22T07:06:34Z",
    "link": "http://arxiv.org/pdf/2512.19095v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Weiyi Lyu",
      "Xinming Fang",
      "Jun Wang",
      "Jun Shi",
      "Guixu Zhang",
      "Juncheng Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19091v1",
    "title": "Auditing Significance, Metric Choice, and Demographic Fairness in Medical AI Challenges",
    "summary": "Open challenges have become the de facto standard for comparative ranking of medical AI methods. Despite their importance, medical AI leaderboards exhibit three persistent limitations: (1) score gaps are rarely tested for statistical significance, so rank stability is unknown; (2) single averaged metrics are applied to every organ, hiding clinically important boundary errors; (3) performance across intersecting demographics is seldom reported, masking fairness and equity gaps. We introduce RankInsight, an open-source toolkit that seeks to address these limitations. RankInsight (1) computes pair-wise significance maps that show the nnU-Net family outperforms Vision-Language and MONAI submissions with high statistical certainty; (2) recomputes leaderboards with organ-appropriate metrics, reversing the order of the top four models when Dice is replaced by NSD for tubular structures; and (3) audits intersectional fairness, revealing that more than half of the MONAI-based entries have the largest gender-race discrepancy on our proprietary Johns Hopkins Hospital dataset. The RankInsight toolkit is publicly released and can be directly applied to past, ongoing, and future challenges. It enables organizers and participants to publish rankings that are statistically sound, clinically meaningful, and demographically fair.",
    "published": "2025-12-22T07:00:49Z",
    "updated": "2025-12-22T07:00:49Z",
    "link": "http://arxiv.org/pdf/2512.19091v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Ariel Lubonja",
      "Pedro R. A. S. Bassi",
      "Wenxuan Li",
      "Hualin Qiao",
      "Randal Burns",
      "Alan L. Yuille",
      "Zongwei Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19088v1",
    "title": "Retrieving Objects from 3D Scenes with Box-Guided Open-Vocabulary Instance Segmentation",
    "summary": "Locating and retrieving objects from scene-level point clouds is a challenging problem with broad applications in robotics and augmented reality. This task is commonly formulated as open-vocabulary 3D instance segmentation. Although recent methods demonstrate strong performance, they depend heavily on SAM and CLIP to generate and classify 3D instance masks from images accompanying the point cloud, leading to substantial computational overhead and slow processing that limit their deployment in real-world settings. Open-YOLO 3D alleviates this issue by using a real-time 2D detector to classify class-agnostic masks produced directly from the point cloud by a pretrained 3D segmenter, eliminating the need for SAM and CLIP and significantly reducing inference time. However, Open-YOLO 3D often fails to generalize to object categories that appear infrequently in the 3D training data. In this paper, we propose a method that generates 3D instance masks for novel objects from RGB images guided by a 2D open-vocabulary detector. Our approach inherits the 2D detector's ability to recognize novel objects while maintaining efficient classification, enabling fast and accurate retrieval of rare instances from open-ended text queries. Our code will be made available at https://github.com/ndkhanh360/BoxOVIS.",
    "published": "2025-12-22T06:57:42Z",
    "updated": "2025-12-22T06:57:42Z",
    "link": "http://arxiv.org/pdf/2512.19088v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Khanh Nguyen",
      "Dasith de Silva Edirimuni",
      "Ghulam Mubashar Hassan",
      "Ajmal Mian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.04034v2",
    "title": "UCS: A Universal Model for Curvilinear Structure Segmentation",
    "summary": "Curvilinear structure segmentation (CSS) is essential in various domains, including medical imaging, landscape analysis, industrial surface inspection, and plant analysis. While existing methods achieve high performance within specific domains, their generalizability is limited. On the other hand, large-scale models such as Segment Anything Model (SAM) exhibit strong generalization but are not optimized for curvilinear structures. Existing adaptations of SAM primarily focus on general object segmentation and lack specialized design for CSS tasks. To bridge this gap, we propose the Universal Curvilinear structure Segmentation (UCS) model, which adapts SAM to CSS tasks while further enhancing its cross-domain generalization. UCS features a novel encoder architecture integrating a pretrained SAM encoder with two innovations: a Sparse Adapter, strategically inserted to inherit the pre-trained SAM encoder's generalization capability while minimizing the number of fine-tuning parameters, and a Prompt Generation module, which leverages Fast Fourier Transform with a high-pass filter to generate curve-specific prompts. Furthermore, the UCS incorporates a mask decoder that eliminates reliance on manual interaction through a dual-compression module: a Hierarchical Feature Compression module, which aggregates the outputs of the sampled encoder to enhance detail preservation, and a Guidance Feature Compression module, which extracts and compresses image-driven guidance features. Evaluated on a comprehensive multi-domain dataset, including an in-house dataset covering eight natural curvilinear structures, UCS demonstrates state-of-the-art generalization and open-set segmentation performance across medical, engineering, natural, and plant imagery, establishing a new benchmark for universal CSS. The source code is available at https://github.com/kylechuuuuu/UCS.",
    "published": "2025-04-05T03:05:04Z",
    "updated": "2025-12-22T06:52:02Z",
    "link": "http://arxiv.org/pdf/2504.04034v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Kai Zhu",
      "Li Chen",
      "Dianshuo Li",
      "Yunxiang Cao",
      "Jun Cheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19058v1",
    "title": "6DAttack: Backdoor Attacks in the 6DoF Pose Estimation",
    "summary": "Deep learning advances have enabled accurate six-degree-of-freedom (6DoF) object pose estimation, widely used in robotics, AR/VR, and autonomous systems. However, backdoor attacks pose significant security risks. While most research focuses on 2D vision, 6DoF pose estimation remains largely unexplored. Unlike traditional backdoors that only change classes, 6DoF attacks must control continuous parameters like translation and rotation, rendering 2D methods inapplicable. We propose 6DAttack, a framework using 3D object triggers to induce controlled erroneous poses while maintaining normal behavior. Evaluations on PVNet, DenseFusion, and PoseDiffusion across LINEMOD, YCB-Video, and CO3D show high attack success rates (ASRs) without compromising clean performance. Backdoored models achieve up to 100% clean ADD accuracy and 100% ASR, with triggered samples reaching 97.70% ADD-P. Furthermore, a representative defense remains ineffective. Our findings reveal a serious, underexplored threat to 6DoF pose estimation.",
    "published": "2025-12-22T05:49:57Z",
    "updated": "2025-12-22T05:49:57Z",
    "link": "http://arxiv.org/pdf/2512.19058v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jihui Guo",
      "Zongmin Zhang",
      "Zhen Sun",
      "Yuhao Yang",
      "Jinlin Wu",
      "Fu Zhang",
      "Xinlei He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19048v1",
    "title": "WaTeRFlow: Watermark Temporal Robustness via Flow Consistency",
    "summary": "Image watermarking supports authenticity and provenance, yet many schemes are still easy to bypass with various distortions and powerful generative edits. Deep learning-based watermarking has improved robustness to diffusion-based image editing, but a gap remains when a watermarked image is converted to video by image-to-video (I2V), in which per-frame watermark detection weakens. I2V has quickly advanced from short, jittery clips to multi-second, temporally coherent scenes, and it now serves not only content creation but also world-modeling and simulation workflows, making cross-modal watermark recovery crucial. We present WaTeRFlow, a framework tailored for robustness under I2V. It consists of (i) FUSE (Flow-guided Unified Synthesis Engine), which exposes the encoder-decoder to realistic distortions via instruction-driven edits and a fast video diffusion proxy during training, (ii) optical-flow warping with a Temporal Consistency Loss (TCL) that stabilizes per-frame predictions, and (iii) a semantic preservation loss that maintains the conditioning signal. Experiments across representative I2V models show accurate watermark recovery from frames, with higher first-frame and per-frame bit accuracy and resilience when various distortions are applied before or after video generation.",
    "published": "2025-12-22T05:33:59Z",
    "updated": "2025-12-22T05:33:59Z",
    "link": "http://arxiv.org/pdf/2512.19048v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Utae Jeong",
      "Sumin In",
      "Hyunju Ryu",
      "Jaewan Choi",
      "Feng Yang",
      "Jongheon Jeong",
      "Seungryong Kim",
      "Sangpil Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19049v1",
    "title": "Decoupled Generative Modeling for Human-Object Interaction Synthesis",
    "summary": "Synthesizing realistic human-object interaction (HOI) is essential for 3D computer vision and robotics, underpinning animation and embodied control. Existing approaches often require manually specified intermediate waypoints and place all optimization objectives on a single network, which increases complexity, reduces flexibility, and leads to errors such as unsynchronized human and object motion or penetration. To address these issues, we propose Decoupled Generative Modeling for Human-Object Interaction Synthesis (DecHOI), which separates path planning and action synthesis. A trajectory generator first produces human and object trajectories without prescribed waypoints, and an action generator conditions on these paths to synthesize detailed motions. To further improve contact realism, we employ adversarial training with a discriminator that focuses on the dynamics of distal joints. The framework also models a moving counterpart and supports responsive, long-sequence planning in dynamic scenes, while preserving plan consistency. Across two benchmarks, FullBodyManipulation and 3D-FUTURE, DecHOI surpasses prior methods on most quantitative metrics and qualitative evaluations, and perceptual studies likewise prefer our results.",
    "published": "2025-12-22T05:33:59Z",
    "updated": "2025-12-22T05:33:59Z",
    "link": "http://arxiv.org/pdf/2512.19049v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Hwanhee Jung",
      "Seunggwan Lee",
      "Jeongyoon Yoon",
      "SeungHyeon Kim",
      "Giljoo Nam",
      "Qixing Huang",
      "Sangpil Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19036v1",
    "title": "Distinguishing Visually Similar Actions: Prompt-Guided Semantic Prototype Modulation for Few-Shot Action Recognition",
    "summary": "Few-shot action recognition aims to enable models to quickly learn new action categories from limited labeled samples, addressing the challenge of data scarcity in real-world applications. Current research primarily addresses three core challenges: (1) temporal modeling, where models are prone to interference from irrelevant static background information and struggle to capture the essence of dynamic action features; (2) visual similarity, where categories with subtle visual differences are difficult to distinguish; and (3) the modality gap between visual-textual support prototypes and visual-only queries, which complicates alignment within a shared embedding space. To address these challenges, this paper proposes a CLIP-SPM framework, which includes three components: (1) the Hierarchical Synergistic Motion Refinement (HSMR) module, which aligns deep and shallow motion features to improve temporal modeling by reducing static background interference; (2) the Semantic Prototype Modulation (SPM) strategy, which generates query-relevant text prompts to bridge the modality gap and integrates them with visual features, enhancing the discriminability between similar actions; and (3) the Prototype-Anchor Dual Modulation (PADM) method, which refines support prototypes and aligns query features with a global semantic anchor, improving consistency across support and query samples. Comprehensive experiments across standard benchmarks, including Kinetics, SSv2-Full, SSv2-Small, UCF101, and HMDB51, demonstrate that our CLIP-SPM achieves competitive performance under 1-shot, 3-shot, and 5-shot settings. Extensive ablation studies and visual analyses further validate the effectiveness of each component and its contributions to addressing the core challenges. The source code and models are publicly available at GitHub.",
    "published": "2025-12-22T05:13:58Z",
    "updated": "2025-12-22T05:13:58Z",
    "link": "http://arxiv.org/pdf/2512.19036v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xiaoyang Li",
      "Mingming Lu",
      "Ruiqi Wang",
      "Hao Li",
      "Zewei Le"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19032v1",
    "title": "Automatic Neuronal Activity Segmentation in Fast Four Dimensional Spatio-Temporal Fluorescence Imaging using Bayesian Approach",
    "summary": "Fluorescence Microcopy Calcium Imaging is a fundamental tool to in-vivo record and analyze large scale neuronal activities simultaneously at a single cell resolution. Automatic and precise detection of behaviorally relevant neuron activity from the recordings is critical to study the mapping of brain activity in organisms. However a perpetual bottleneck to this problem is the manual segmentation which is time and labor intensive and lacks generalizability. To this end, we present a Bayesian Deep Learning Framework to detect neuronal activities in 4D spatio-temporal data obtained by light sheet microscopy. Our approach accounts for the use of temporal information by calculating pixel wise correlation maps and combines it with spatial information given by the mean summary image. The Bayesian framework not only produces probability segmentation maps but also models the uncertainty pertaining to active neuron detection. To evaluate the accuracy of our framework we implemented the test of reproducibility to assert the generalization of the network to detect neuron activity. The network achieved a mean Dice Score of 0.81 relative to the synthetic Ground Truth obtained by Otsu's method and a mean Dice Score of 0.79 between the first and second run for test of reproducibility. Our method successfully deployed can be used for rapid detection of active neuronal activities for behavioural studies.",
    "published": "2025-12-22T05:08:52Z",
    "updated": "2025-12-22T05:08:52Z",
    "link": "http://arxiv.org/pdf/2512.19032v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ran Li",
      "Pan Xiao",
      "Kaushik Dutta",
      "Youdong Guo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.09885v3",
    "title": "MCGA: Mixture of Codebooks Hyperspectral Reconstruction via Grayscale-Aware Attention",
    "summary": "Reconstructing hyperspectral images (HSIs) from RGB inputs provides a cost-effective alternative to hyperspectral cameras, but reconstructing high-dimensional spectra from three channels is inherently ill-posed. Existing methods typically directly regress RGB-to-HSI mappings using large attention networks, which are computationally expensive and handle ill-posedness only implicitly. We propose MCGA, a Mixture-of-Codebooks with Grayscale-aware Attention framework that explicitly addresses these challenges using spectral priors and photometric consistency. MCGA first learns transferable spectral priors via a mixture-of-codebooks (MoC) from heterogeneous HSI datasets, then aligns RGB features with these priors through grayscale-aware photometric attention (GANet). Efficiency and robustness are further improved via top-K attention design and test-time adaptation (TTA). Experiments on multiple real-world benchmarks demonstrate the state-of-the-art accuracy, strong cross-dataset generalization, and 4-5x faster inference. Codes will be available once acceptance at https://github.com/Fibonaccirabbit/MCGA.",
    "published": "2025-07-14T03:46:06Z",
    "updated": "2025-12-22T05:02:30Z",
    "link": "http://arxiv.org/pdf/2507.09885v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhanjiang Yang",
      "Lijun Sun",
      "Jiawei Dong",
      "Xiaoxin An",
      "Yang Liu",
      "Meng Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.19291v2",
    "title": "Modeling spectral filtering effects on color-matching functions: Implications for observer variability",
    "summary": "This study investigates the impact of spectral filtering on color-matching functions (CMFs) and its implications for observer variability modeling. We conducted color matching experiments with two observers, both with and without a spectral filter in front of a bipartite field. Using a novel computational approach, we estimated the filter transmittance and transformation matrix necessary to convert unfiltered CMFs to filtered CMFs. Statistical analysis revealed good agreement between estimated and measured filter characteristics, particularly in central wavelength regions. Applying this methodology to compare between Stiles and Burch 1955 (SB1955) mean observer CMFs and our previously published \"ICVIO\" mean observer CMFs, we identified a \"yellow\" (short-wavelength suppressing) filter that effectively transforms between these datasets. This finding aligns with our hypothesis that observed differences between the CMF sets are attributable to age-related lens yellowing (average observer age: 49 years in ICVIO versus 30 years in SB1955). Our approach enables efficient representation of observer variability through a single filter rather than three separate functions, offering potentially reduced experimental overhead while maintaining accuracy in characterizing individual color vision differences.",
    "published": "2025-08-25T13:04:04Z",
    "updated": "2025-12-22T05:01:02Z",
    "link": "http://arxiv.org/pdf/2508.19291v2.pdf",
    "category": [
      "astro-ph.IM",
      "cs.CV"
    ],
    "authors": [
      "Luvin Munish Ragoo",
      "Ivar Farup",
      "Casper F. Andersen",
      "Graham Finlayson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.22552v7",
    "title": "Probing forced responses and causality in data-driven climate emulators: conceptual limitations and the role of reduced-order models",
    "summary": "A central challenge in climate science and applied mathematics is developing data-driven models of multiscale systems that capture both stationary statistics and responses to external perturbations. Current neural climate emulators aim to resolve the atmosphere-ocean system in all its complexity but often struggle to reproduce forced responses, limiting their use in causal studies such as Green's function experiments. To explore the origin of these limitations, we first examine a simplified dynamical system that retains key features of climate variability. We interpret the results through linear response theory, providing a rigorous framework to evaluate neural models beyond stationary statistics and to probe causal mechanisms. We argue that the ability of emulators of multiscale systems to reproduce perturbed statistics depends critically on (i) the choice of an appropriate coarse-grained representation and (ii) careful parameterizations of unresolved processes. These insights highlight reduced-order models, tailored to specific goals, processes, and scales, as valuable alternatives to general-purpose emulators. We next consider a real-world application by developing a neural model to investigate the joint variability of the surface temperature field and radiative fluxes. The model infers a multiplicative noise process directly from data, largely reproduces the system's probability distribution, and enables causal studies through forced responses. We discuss its limitations and outline directions for future work. Overall, these results expose key challenges in data-driven modeling of multiscale physical systems and underscore the value of coarse-grained, stochastic approaches, with response theory providing a principled framework to guide model design and enhance causal understanding.",
    "published": "2025-06-27T18:04:36Z",
    "updated": "2025-12-22T18:48:57Z",
    "link": "http://arxiv.org/pdf/2506.22552v7.pdf",
    "category": [
      "nlin.CD",
      "cond-mat.stat-mech",
      "cs.LG",
      "physics.ao-ph"
    ],
    "authors": [
      "Fabrizio Falasca"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19649v1",
    "title": "Deep Legendre Transform",
    "summary": "We introduce a novel deep learning algorithm for computing convex conjugates of differentiable convex functions, a fundamental operation in convex analysis with various applications in different fields such as optimization, control theory, physics and economics. While traditional numerical methods suffer from the curse of dimensionality and become computationally intractable in high dimensions, more recent neural network-based approaches scale better, but have mostly been studied with the aim of solving optimal transport problems and require the solution of complicated optimization or max-min problems. Using an implicit Fenchel formulation of convex conjugation, our approach facilitates an efficient gradient-based framework for the minimization of approximation errors and, as a byproduct, also provides a posteriori error estimates for the approximation quality. Numerical experiments demonstrate our method's ability to deliver accurate results across different high-dimensional examples. Moreover, by employing symbolic regression with Kolmogorov--Arnold networks, it is able to obtain the exact convex conjugates of specific convex functions.",
    "published": "2025-12-22T18:22:11Z",
    "updated": "2025-12-22T18:22:11Z",
    "link": "http://arxiv.org/pdf/2512.19649v1.pdf",
    "category": [
      "cs.LG",
      "math.OC"
    ],
    "authors": [
      "Aleksey Minabutdinov",
      "Patrick Cheridito"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.12085v2",
    "title": "GraphShaper: Geometry-aware Alignment for Improving Transfer Learning in Text-Attributed Graphs",
    "summary": "Graph foundation models represent a transformative paradigm for learning transferable representations across diverse graph domains. Recent methods leverage large language models to unify graph and text modalities into a shared representation space using contrastive learning. However, systematic evaluations reveal significant performance degradation at structural boundaries where distinct topological patterns converge, with accuracy losses exceeding 20 percentage points. This issue arises from a key limitation: current methods assume all graph structures can be encoded within a single Euclidean space. In reality, tree structures require hyperbolic geometry to preserve hierarchical branching, while cyclic patterns depend on spherical geometry for closure properties. At structural boundaries, nodes experience conflicting geometric constraints that uniform encoding spaces cannot resolve. This raises a crucial challenge: \\textbf{Can alignment frameworks be designed to respect the intrinsic geometric diversity of graph structures?} We introduce \\textbf{GraphShaper}, a geometry-aware framework that enhances graph encoding through multi-geometric specialization. Our approach employs expert networks tailored to different geometric spaces, dynamically computing fusion weights to adaptively integrate geometric properties based on local structural characteristics. This adaptive fusion preserves structural integrity before alignment with text embeddings. Extensive experiments demonstrate that GraphShaper achieves 9.47\\% accuracy improvements on citation networks and 7.63\\% on social networks in zero-shot settings.",
    "published": "2025-10-14T02:48:50Z",
    "updated": "2025-12-22T18:20:12Z",
    "link": "http://arxiv.org/pdf/2510.12085v2.pdf",
    "category": [
      "cs.LG",
      "cs.GR"
    ],
    "authors": [
      "Heng Zhang",
      "Tianyi Zhang",
      "Yuling Shi",
      "Xiaodong Gu",
      "Yaomin Shen",
      "Haochen You",
      "Zijian Zhang",
      "Yilei Yuan",
      "Jin Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19643v1",
    "title": "The Best of Both Worlds: Hybridizing Neural Operators and Solvers for Stable Long-Horizon Inference",
    "summary": "Numerical simulation of time-dependent partial differential equations (PDEs) is central to scientific and engineering applications, but high-fidelity solvers are often prohibitively expensive for long-horizon or time-critical settings. Neural operator (NO) surrogates offer fast inference across parametric and functional inputs; however, most autoregressive NO frameworks remain vulnerable to compounding errors, and ensemble-averaged metrics provide limited guarantees for individual inference trajectories. In practice, error accumulation can become unacceptable beyond the training horizon, and existing methods lack mechanisms for online monitoring or correction. To address this gap, we propose ANCHOR (Adaptive Numerical Correction for High-fidelity Operator Rollouts), an online, instance-aware hybrid inference framework for stable long-horizon prediction of nonlinear, time-dependent PDEs. ANCHOR treats a pretrained NO as the primary inference engine and adaptively couples it with a classical numerical solver using a physics-informed, residual-based error estimator. Inspired by adaptive time-stepping in numerical analysis, ANCHOR monitors an exponential moving average (EMA) of the normalized PDE residual to detect accumulating error and trigger corrective solver interventions without requiring access to ground-truth solutions. We show that the EMA-based estimator correlates strongly with the true relative L2 error, enabling data-free, instance-aware error control during inference. Evaluations on four canonical PDEs: 1D and 2D Burgers', 2D Allen-Cahn, and 3D heat conduction, demonstrate that ANCHOR reliably bounds long-horizon error growth, stabilizes extrapolative rollouts, and significantly improves robustness over standalone neural operators, while remaining substantially more efficient than high-fidelity numerical solvers.",
    "published": "2025-12-22T18:17:28Z",
    "updated": "2025-12-22T18:17:28Z",
    "link": "http://arxiv.org/pdf/2512.19643v1.pdf",
    "category": [
      "cs.LG",
      "cs.CE"
    ],
    "authors": [
      "Rajyasri Roy",
      "Dibyajyoti Nayak",
      "Somdatta Goswami"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.08401v3",
    "title": "Source-Optimal Training is Transfer-Suboptimal",
    "summary": "We prove that training a source model optimally for its own task is generically suboptimal when the objective is downstream transfer. We study the source-side optimization problem in L2-SP ridge regression and show a fundamental mismatch between the source-optimal and transfer-optimal source regularization: outside of a measure-zero set, $τ_0^* \\neq τ_S^*$. We characterize the transfer-optimal source penalty $τ_0^*$ as a function of task alignment and identify an alignment-dependent reversal: with imperfect alignment ($0<ρ<1$), transfer benefits from stronger source regularization, while in super-aligned regimes ($ρ>1$), transfer benefits from weaker regularization. In isotropic settings, the decision of whether transfer helps is independent of the target sample size and noise, depending only on task alignment and source characteristics. We verify the linear predictions in a synthetic ridge regression experiment, and we present CIFAR-10 experiments as evidence that the source-optimal versus transfer-optimal mismatch can persist in nonlinear networks.",
    "published": "2025-11-11T16:16:10Z",
    "updated": "2025-12-22T17:58:14Z",
    "link": "http://arxiv.org/pdf/2511.08401v3.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "math.ST"
    ],
    "authors": [
      "C. Evans Hedges"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.17196v3",
    "title": "Shape it Up! Restoring LLM Safety during Finetuning",
    "summary": "Finetuning large language models (LLMs) enables user-specific customization but introduces critical safety risks: even a few harmful examples can compromise safety alignment. A common mitigation strategy is to update the model more strongly on examples deemed safe, while downweighting or excluding those flagged as unsafe. However, because safety context can shift within a single example, updating the model equally on both harmful and harmless parts of a response is suboptimal-a coarse treatment we term static safety shaping. In contrast, we propose dynamic safety shaping (DSS), a framework that uses fine-grained safety signals to reinforce learning from safe segments of a response while suppressing unsafe content. To enable such fine-grained control during finetuning, we introduce a key insight: guardrail models, traditionally used for filtering, can be repurposed to evaluate partial responses, tracking how safety risk evolves throughout the response, segment by segment. This leads to the Safety Trajectory Assessment of Response (STAR), a token-level signal that enables shaping to operate dynamically over the training sequence. Building on this, we present STAR-DSS, guided by STAR scores, that robustly mitigates finetuning risks and delivers substantial safety improvements across diverse threats, datasets, and model families-all without compromising capability on intended tasks. We encourage future safety research to build on dynamic shaping principles for stronger mitigation against evolving finetuning risks. Our code is publicly available at https://github.com/poloclub/star-dss.",
    "published": "2025-05-22T18:05:16Z",
    "updated": "2025-12-22T17:30:15Z",
    "link": "http://arxiv.org/pdf/2505.17196v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "ShengYun Peng",
      "Pin-Yu Chen",
      "Jianfeng Chi",
      "Seongmin Lee",
      "Duen Horng Chau"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19550v1",
    "title": "DFORD: Directional Feedback based Online Ordinal Regression Learning",
    "summary": "In this paper, we introduce directional feedback in the ordinal regression setting, in which the learner receives feedback on whether the predicted label is on the left or the right side of the actual label. This is a weak supervision setting for ordinal regression compared to the full information setting, where the learner can access the labels. We propose an online algorithm for ordinal regression using directional feedback. The proposed algorithm uses an exploration-exploitation scheme to learn from directional feedback efficiently. Furthermore, we introduce its kernel-based variant to learn non-linear ordinal regression models in an online setting. We use a truncation trick to make the kernel implementation more memory efficient. The proposed algorithm maintains the ordering of the thresholds in the expected sense. Moreover, it achieves the expected regret of $\\mathcal{O}(\\log T)$. We compare our approach with a full information and a weakly supervised algorithm for ordinal regression on synthetic and real-world datasets. The proposed approach, which learns using directional feedback, performs comparably (sometimes better) to its full information counterpart.",
    "published": "2025-12-22T16:31:14Z",
    "updated": "2025-12-22T16:31:14Z",
    "link": "http://arxiv.org/pdf/2512.19550v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Naresh Manwani",
      "M Elamparithy",
      "Tanish Taneja"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19540v1",
    "title": "Active Convolved Illumination with Deep Transfer Learning for Complex Beam Transmission through Atmospheric Turbulence",
    "summary": "Atmospheric turbulence imposes a fundamental limitation across a broad range of applications, including optical imaging, remote sensing, and free-space optical communication. Recent advances in adaptive optics, wavefront shaping, and machine learning, driven by synergistic progress in fundamental theories, optoelectronic hardware, and computational algorithms, have demonstrated substantial potential in mitigating turbulence-induced distortions. Recently, active convolved illumination (ACI) was proposed as a versatile and physics-driven technique for transmitting structured light beams with minimal distortion through highly challenging turbulent regimes. While distinct in its formulation, ACI shares conceptual similarities with other physics-driven distortion correction approaches and stands to benefit from complementary integration with data-driven deep learning (DL) models. Inspired by recent work coupling deep learning with traditional turbulence mitigation strategies, the present work investigates the feasibility of integrating ACI with neural network-based methods. We outline a conceptual framework for coupling ACI with data-driven models and identify conditions under which learned representations can meaningfully support ACI's correlation-injection mechanism. As a representative example, we employ a convolutional neural network (CNN) together with a transfer-learning approach to examine how a learned model may operate in tandem with ACI. This exploratory study demonstrates feasible implementation pathways and establishes an early foundation for assessing the potential of future ACI-DL hybrid architectures, representing a step toward evaluating broader synergistic interactions between ACI and modern DL models.",
    "published": "2025-12-22T16:24:12Z",
    "updated": "2025-12-22T16:24:12Z",
    "link": "http://arxiv.org/pdf/2512.19540v1.pdf",
    "category": [
      "physics.optics",
      "cs.LG"
    ],
    "authors": [
      "Adrian A. Moazzam",
      "Anindya Ghoshroy",
      "Breeanne Heusdens",
      "Durdu O. Guney",
      "Roohollah Askari"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19527v1",
    "title": "Deep Learning for Unrelated-Machines Scheduling: Handling Variable Dimensions",
    "summary": "Deep learning has been effectively applied to many discrete optimization problems. However, learning-based scheduling on unrelated parallel machines remains particularly difficult to design. Not only do the numbers of jobs and machines vary, but each job-machine pair has a unique processing time, dynamically altering feature dimensions. We propose a novel approach with a neural network tailored for offline deterministic scheduling of arbitrary sizes on unrelated machines. The goal is to minimize a complex objective function that includes the makespan and the weighted tardiness of jobs and machines. Unlike existing online approaches, which process jobs sequentially, our method generates a complete schedule considering the entire input at once. The key contribution of this work lies in the sophisticated architecture of our model. By leveraging various NLP-inspired architectures, it effectively processes any number of jobs and machines with varying feature dimensions imposed by unrelated processing times. Our approach enables supervised training on small problem instances while demonstrating strong generalization to much larger scheduling environments. Trained and tested on instances with 8 jobs and 4 machines, costs were only 2.51% above optimal. Across all tested configurations of up to 100 jobs and 10 machines, our network consistently outperformed an advanced dispatching rule, which incurred 22.22% higher costs on average. As our method allows fast retraining with simulated data and adaptation to various scheduling conditions, we believe it has the potential to become a standard approach for learning-based scheduling on unrelated machines and similar problem environments.",
    "published": "2025-12-22T16:18:29Z",
    "updated": "2025-12-22T16:18:29Z",
    "link": "http://arxiv.org/pdf/2512.19527v1.pdf",
    "category": [
      "cs.LG",
      "cs.DM"
    ],
    "authors": [
      "Diego Hitzges",
      "Guillaume Sagnol"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19524v1",
    "title": "Initialization of a Polyharmonic Cascade, Launch and Testing",
    "summary": "This paper concludes a series of studies on the polyharmonic cascade, a deep machine learning architecture theoretically derived from indifference principles and the theory of random functions. A universal initialization procedure is proposed, based on symmetric constellations in the form of hyperoctahedra with a central point. This initialization not only ensures stable training of cascades with tens and hundreds of layers (up to 500 layers without skip connections), but also radically simplifies the computations. Scalability and robustness are demonstrated on MNIST (98.3% without convolutions or augmentations), HIGGS (AUC approximately 0.885 on 11M examples), and Epsilon (AUC approximately 0.963 with 2000 features). All linear algebra is reduced to 2D operations and is efficiently executed on GPUs. A public repository and an archived snapshot are provided for full reproducibility.",
    "published": "2025-12-22T16:17:37Z",
    "updated": "2025-12-22T16:17:37Z",
    "link": "http://arxiv.org/pdf/2512.19524v1.pdf",
    "category": [
      "cs.LG",
      "math.NA"
    ],
    "authors": [
      "Yuriy N. Bakhvalov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.17654v2",
    "title": "Estimating Spatially Resolved Radiation Fields Using Neural Networks",
    "summary": "We present an in-depth analysis on how to build and train neural networks to estimate the spatial distribution of scattered radiation fields for radiation protection dosimetry in medical radiation fields, such as those found in interventional radiology and cardiology. We present three different synthetically generated datasets with increasing complexity for training, using a Monte-Carlo Simulation application based on Geant4. On those datasets, we evaluate convolutional and fully connected architectures of neural networks to demonstrate which design decisions work well for reconstructing the fluence and spectra distributions over the spatial domain of such radiation fields. All our datasets, as well as our training pipeline, are published as open source in separate repositories.",
    "published": "2025-12-19T14:52:04Z",
    "updated": "2025-12-22T16:13:25Z",
    "link": "http://arxiv.org/pdf/2512.17654v2.pdf",
    "category": [
      "cs.LG",
      "physics.comp-ph",
      "physics.med-ph"
    ],
    "authors": [
      "Felix Lehner",
      "Pasquale Lombardo",
      "Susana Castillo",
      "Oliver Hupe",
      "Marcus Magnor"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.11076v3",
    "title": "Addition is almost all you need: Compressing neural networks with double binary factorization",
    "summary": "Binary quantization approaches, which replace weight matrices with binary matrices and substitute costly multiplications with cheaper additions, offer a computationally efficient approach to address the increasing computational and storage requirements of Large Language Models (LLMs). However, the severe quantization constraint ($\\pm1$) can lead to significant accuracy degradation. In this paper, we propose Double Binary Factorization (DBF), a novel method that factorizes dense weight matrices into products of two binary (sign) matrices, each accompanied by scaling vectors. DBF preserves the efficiency advantages of binary representations while achieving compression rates that are competitive with or superior to state-of-the-art methods. Specifically, in a 1-bit per weight range, DBF is better than existing binarization approaches. In a 2-bit per weight range, DBF is competitive with the best quantization methods like QuIP\\# and QTIP. Unlike most existing compression techniques, which offer limited compression level choices, DBF allows fine-grained control over compression ratios by adjusting the factorization's intermediate dimension. Based on this advantage, we further introduce an algorithm for estimating non-uniform layer-wise compression ratios for DBF, based on previously developed channel pruning criteria.\n  Code available at: https://github.com/usamec/double_binary",
    "published": "2025-05-16T10:07:36Z",
    "updated": "2025-12-22T16:05:29Z",
    "link": "http://arxiv.org/pdf/2505.11076v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Vladimír Boža",
      "Vladimír Macko"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19510v1",
    "title": "Toward Scalable and Valid Conditional Independence Testing with Spectral Representations",
    "summary": "Conditional independence (CI) is central to causal inference, feature selection, and graphical modeling, yet it is untestable in many settings without additional assumptions. Existing CI tests often rely on restrictive structural conditions, limiting their validity on real-world data. Kernel methods using the partial covariance operator offer a more principled approach but suffer from limited adaptivity, slow convergence, and poor scalability. In this work, we explore whether representation learning can help address these limitations. Specifically, we focus on representations derived from the singular value decomposition of the partial covariance operator and use them to construct a simple test statistic, reminiscent of the Hilbert-Schmidt Independence Criterion (HSIC). We also introduce a practical bi-level contrastive algorithm to learn these representations. Our theory links representation learning error to test performance and establishes asymptotic validity and power guarantees. Preliminary experiments suggest that this approach offers a practical and statistically grounded path toward scalable CI testing, bridging kernel-based theory with modern representation learning.",
    "published": "2025-12-22T16:05:18Z",
    "updated": "2025-12-22T16:05:18Z",
    "link": "http://arxiv.org/pdf/2512.19510v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Alek Frohlich",
      "Vladimir Kostic",
      "Karim Lounici",
      "Daniel Perazzo",
      "Massimiliano Pontil"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.14455v3",
    "title": "Nonparametric estimation of conditional probability distributions using a generative approach based on conditional push-forward neural networks",
    "summary": "We introduce conditional push-forward neural networks (CPFN), a generative framework for conditional distribution estimation. Instead of directly modeling the conditional density $f_{Y|X}$, CPFN learns a stochastic map $\\varphi=\\varphi(x,u)$ such that $\\varphi(x,U)$ and $Y|X=x$ follow approximately the same law, with $U$ a suitable random vector of pre-defined latent variables. This enables efficient conditional sampling and straightforward estimation of conditional statistics through Monte Carlo methods. The model is trained via an objective function derived from a Kullback-Leibler formulation, without requiring invertibility or adversarial training. We establish a near-asymptotic consistency result and demonstrate experimentally that CPFN can achieve performance competitive with, or even superior to, state-of-the-art methods, including kernel estimators, tree-based algorithms, and popular deep learning techniques, all while remaining lightweight and easy to train.",
    "published": "2025-11-18T12:59:20Z",
    "updated": "2025-12-22T16:00:38Z",
    "link": "http://arxiv.org/pdf/2511.14455v3.pdf",
    "category": [
      "cs.LG",
      "stat.ME"
    ],
    "authors": [
      "Nicola Rares Franco",
      "Lorenzo Tedesco"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2306.05300v3",
    "title": "Anti-Correlated Noise in Epoch-Based Stochastic Gradient Descent: Implications for Weight Variances in Flat Directions",
    "summary": "Stochastic Gradient Descent (SGD) has become a cornerstone of neural network optimization due to its computational efficiency and generalization capabilities. However, the gradient noise introduced by SGD is often assumed to be uncorrelated over time, despite the common practice of epoch-based training where data is sampled without replacement. In this work, we challenge this assumption and investigate the effects of epoch-based noise correlations on the stationary distribution of discrete-time SGD with momentum. Our main contributions are twofold: First, we calculate the exact autocorrelation of the noise during epoch-based training under the assumption that the noise is independent of small fluctuations in the weight vector, revealing that SGD noise is inherently anti-correlated over time. Second, we explore the influence of these anti-correlations on the variance of weight fluctuations. We find that for directions with curvature of the loss greater than a hyperparameter-dependent crossover value, the conventional predictions of isotropic weight variance under stationarity, based on uncorrelated and curvature-proportional noise, are recovered. Anti-correlations have negligible effect here. However, for relatively flat directions, the weight variance is significantly reduced, leading to a considerable decrease in loss fluctuations compared to the constant weight variance assumption. Furthermore, we present a numerical experiment where training with these anti-correlations enhances test performance, suggesting that the inherent noise structure induced by epoch-based training may play a role in finding flatter minima that generalize better.",
    "published": "2023-06-08T15:45:57Z",
    "updated": "2025-12-22T15:54:45Z",
    "link": "http://arxiv.org/pdf/2306.05300v3.pdf",
    "category": [
      "cs.LG",
      "cond-mat.dis-nn"
    ],
    "authors": [
      "Marcel Kühn",
      "Bernd Rosenow"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.24936v2",
    "title": "OAT-FM: Optimal Acceleration Transport for Improved Flow Matching",
    "summary": "As a powerful technique in generative modeling, Flow Matching (FM) aims to learn velocity fields from noise to data, which is often explained and implemented as solving Optimal Transport (OT) problems. In this study, we bridge FM and the recent theory of Optimal Acceleration Transport (OAT), developing an improved FM method called OAT-FM and exploring its benefits in both theory and practice. In particular, we demonstrate that the straightening objective hidden in existing OT-based FM methods is mathematically equivalent to minimizing the physical action associated with acceleration defined by OAT. Accordingly, instead of enforcing constant velocity, OAT-FM optimizes the acceleration transport in the product space of sample and velocity, whose objective corresponds to a necessary and sufficient condition of flow straightness. An efficient algorithm is designed to achieve OAT-FM with low complexity. OAT-FM motivates a new two-phase FM paradigm: Given a generative model trained by an arbitrary FM method, whose velocity information has been relatively reliable, we can fine-tune and improve it via OAT-FM. This paradigm eliminates the risk of data distribution drift and the need to generate a large number of noise data pairs, which consistently improves model performance in various generative tasks. Code is available at: https://github.com/AngxiaoYue/OAT-FM",
    "published": "2025-09-29T15:36:27Z",
    "updated": "2025-12-22T15:45:08Z",
    "link": "http://arxiv.org/pdf/2509.24936v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Angxiao Yue",
      "Anqi Dong",
      "Hongteng Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19491v1",
    "title": "Learning from sanctioned government suppliers: A machine learning and network science approach to detecting fraud and corruption in Mexico",
    "summary": "Detecting fraud and corruption in public procurement remains a major challenge for governments worldwide. Most research to-date builds on domain-knowledge-based corruption risk indicators of individual contract-level features and some also analyzes contracting network patterns. A critical barrier for supervised machine learning is the absence of confirmed non-corrupt, negative, examples, which makes conventional machine learning inappropriate for this task. Using publicly available data on federally funded procurement in Mexico and company sanction records, this study implements positive-unlabeled (PU) learning algorithms that integrate domain-knowledge-based red flags with network-derived features to identify likely corrupt and fraudulent contracts. The best-performing PU model on average captures 32 percent more known positives and performs on average 2.3 times better than random guessing, substantially outperforming approaches based solely on traditional red flags. The analysis of the Shapley Additive Explanations reveals that network-derived features, particularly those associated with contracts in the network core or suppliers with high eigenvector centrality, are the most important. Traditional red flags further enhance model performance in line with expectations, albeit mainly for contracts awarded through competitive tenders. This methodology can support law enforcement in Mexico, and it can be adapted to other national contexts too.",
    "published": "2025-12-22T15:44:47Z",
    "updated": "2025-12-22T15:44:47Z",
    "link": "http://arxiv.org/pdf/2512.19491v1.pdf",
    "category": [
      "cs.LG",
      "cs.CY"
    ],
    "authors": [
      "Martí Medina-Hern ández",
      "Janos Kertész",
      "Mihály Fazekas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19488v1",
    "title": "Lightweight Intrusion Detection in IoT via SHAP-Guided Feature Pruning and Knowledge-Distilled Kronecker Networks",
    "summary": "The widespread deployment of Internet of Things (IoT) devices requires intrusion detection systems (IDS) with high accuracy while operating under strict resource constraints. Conventional deep learning IDS are often too large and computationally intensive for edge deployment. We propose a lightweight IDS that combines SHAP-guided feature pruning with knowledge-distilled Kronecker networks. A high-capacity teacher model identifies the most relevant features through SHAP explanations, and a compressed student leverages Kronecker-structured layers to minimize parameters while preserving discriminative inputs. Knowledge distillation transfers softened decision boundaries from teacher to student, improving generalization under compression. Experiments on the TON\\_IoT dataset show that the student is nearly three orders of magnitude smaller than the teacher yet sustains macro-F1 above 0.986 with millisecond-level inference latency. The results demonstrate that explainability-driven pruning and structured compression can jointly enable scalable, low-latency, and energy-efficient IDS for heterogeneous IoT environments.",
    "published": "2025-12-22T15:43:39Z",
    "updated": "2025-12-22T15:43:39Z",
    "link": "http://arxiv.org/pdf/2512.19488v1.pdf",
    "category": [
      "cs.LG",
      "cs.NI"
    ],
    "authors": [
      "Hafsa Benaddi",
      "Mohammed Jouhari",
      "Nouha Laamech",
      "Anas Motii",
      "Khalil Ibrahimi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19469v1",
    "title": "GLUE: Generative Latent Unification of Expertise-Informed Engineering Models",
    "summary": "Engineering complex systems (aircraft, buildings, vehicles) requires accounting for geometric and performance couplings across subsystems. As generative models proliferate for specialized domains (wings, structures, engines), a key research gap is how to coordinate frozen, pre-trained submodels to generate full-system designs that are feasible, diverse, and high-performing. We introduce Generative Latent Unification of Expertise-Informed Engineering Models (GLUE), which orchestrates pre-trained, frozen subsystem generators while enforcing system-level feasibility, optimality, and diversity. We propose and benchmark (i) data-driven GLUE models trained on pre-generated system-level designs and (ii) a data-free GLUE model trained online on a differentiable geometry layer. On a UAV design problem with five coupling constraints, we find that data-driven approaches yield diverse, high-performing designs but require large datasets to satisfy constraints reliably. The data-free approach is competitive with Bayesian optimization and gradient-based optimization in performance and feasibility while training a full generative model in only 10 min on a RTX 4090 GPU, requiring more than two orders of magnitude fewer geometry evaluations and FLOPs than the data-driven method. Ablations focused on data-free training show that subsystem output continuity affects coordination, and equality constraints can trigger mode collapse unless mitigated. By integrating unmodified, domain-informed submodels into a modular generative workflow, this work provides a viable path for scaling generative design to complex, real-world engineering systems.",
    "published": "2025-12-22T15:23:19Z",
    "updated": "2025-12-22T15:23:19Z",
    "link": "http://arxiv.org/pdf/2512.19469v1.pdf",
    "category": [
      "cs.CE",
      "cs.LG"
    ],
    "authors": [
      "Tim Aebersold",
      "Soheyl Massoudi",
      "Mark D. Fuge"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.17593v2",
    "title": "A Unified Representation of Neural Networks Architectures",
    "summary": "In this paper we consider the limiting case of neural networks (NNs) architectures when the number of neurons in each hidden layer and the number of hidden layers tend to infinity thus forming a continuum, and we derive approximation errors as a function of the number of neurons and/or hidden layers. Firstly, we consider the case of neural networks with a single hidden layer and we derive an integral infinite width neural representation that generalizes existing continuous neural networks (CNNs) representations. Then we extend this to deep residual CNNs that have a finite number of integral hidden layers and residual connections. Secondly, we revisit the relation between neural ODEs and deep residual NNs and we formalize approximation errors via discretization techniques. Then, we merge these two approaches into a unified homogeneous representation of NNs as a Distributed Parameter neural Network (DiPaNet) and we show that most of the existing finite and infinite-dimensional NNs architectures are related via homogenization/discretization with the DiPaNet representation. Our approach is purely deterministic and applies to general, uniformly continuous matrix weight functions. Relations with neural fields and other neural integro-differential equations are discussed along with further possible generalizations and applications of the DiPaNet framework.",
    "published": "2025-12-19T14:01:50Z",
    "updated": "2025-12-22T15:11:58Z",
    "link": "http://arxiv.org/pdf/2512.17593v2.pdf",
    "category": [
      "cs.LG",
      "math.OC"
    ],
    "authors": [
      "Christophe Prieur",
      "Mircea Lazar",
      "Bogdan Robu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.18540v2",
    "title": "Deep Variational Free Energy Calculation of Hydrogen Hugoniot",
    "summary": "We develop a deep variational free energy framework to compute the equation of state of hydrogen in the warm dense matter region. This method parameterizes the variational density matrix of hydrogen nuclei and electrons at finite temperature using three deep generative models: a normalizing flow model for the Boltzmann distribution of the classical nuclei, an autoregressive transformer for the distribution of electrons in excited states, and a permutational equivariant flow model for the unitary backflow transformation of electron coordinates in Hartree-Fock states. By jointly optimizing the three neural networks to minimize the variational free energy, we obtain the equation of state and related thermodynamic properties of dense hydrogen for the temperature range where electrons occupy excited states. We compare our results with other theoretical and experimental results on the deuterium Hugoniot curve, aiming to resolve existing discrepancies. Our results bridge the gap between the results obtained by path-integral Monte Carlo calculations at high temperature and ground-state electronic methods at low temperature, thus providing a valuable benchmark for hydrogen in the warm dense matter region.",
    "published": "2025-07-24T16:07:13Z",
    "updated": "2025-12-22T14:56:25Z",
    "link": "http://arxiv.org/pdf/2507.18540v2.pdf",
    "category": [
      "cond-mat.str-el",
      "cs.LG",
      "physics.comp-ph"
    ],
    "authors": [
      "Zihang Li",
      "Hao Xie",
      "Xinyang Dong",
      "Lei Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.14081v2",
    "title": "Personalized and Resilient Distributed Learning Through Opinion Dynamics",
    "summary": "In this paper, we address two practical challenges of distributed learning in multi-agent network systems, namely personalization and resilience. Personalization is the need of heterogeneous agents to learn local models tailored to their own data and tasks, while still generalizing well; on the other hand, the learning process must be resilient to cyberattacks or anomalous training data to avoid disruption. Motivated by a conceptual affinity between these two requirements, we devise a distributed learning algorithm that combines distributed gradient descent and the Friedkin-Johnsen model of opinion dynamics to fulfill both of them. We quantify its convergence speed and the neighborhood that contains the final learned models, which can be easily controlled by tuning the algorithm parameters to enforce a more personalized/resilient behavior. We numerically showcase the effectiveness of our algorithm on synthetic and real-world distributed learning tasks, where it achieves high global accuracy both for personalized models and with malicious agents compared to standard strategies.",
    "published": "2025-05-20T08:39:16Z",
    "updated": "2025-12-22T14:49:44Z",
    "link": "http://arxiv.org/pdf/2505.14081v2.pdf",
    "category": [
      "cs.MA",
      "cs.LG",
      "eess.SP",
      "math.OC"
    ],
    "authors": [
      "Luca Ballotta",
      "Nicola Bastianello",
      "Riccardo M. G. Ferrari",
      "Karl H. Johansson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19442v1",
    "title": "Real-Time Streamable Generative Speech Restoration with Flow Matching",
    "summary": "Diffusion-based generative models have greatly impacted the speech processing field in recent years, exhibiting high speech naturalness and spawning a new research direction. Their application in real-time communication is, however, still lagging behind due to their computation-heavy nature involving multiple calls of large DNNs.\n  Here, we present Stream.FM, a frame-causal flow-based generative model with an algorithmic latency of 32 milliseconds (ms) and a total latency of 48 ms, paving the way for generative speech processing in real-time communication. We propose a buffered streaming inference scheme and an optimized DNN architecture, show how learned few-step numerical solvers can boost output quality at a fixed compute budget, explore model weight compression to find favorable points along a compute/quality tradeoff, and contribute a model variant with 24 ms total latency for the speech enhancement task.\n  Our work looks beyond theoretical latencies, showing that high-quality streaming generative speech processing can be realized on consumer GPUs available today. Stream.FM can solve a variety of speech processing tasks in a streaming fashion: speech enhancement, dereverberation, codec post-filtering, bandwidth extension, STFT phase retrieval, and Mel vocoding. As we verify through comprehensive evaluations and a MUSHRA listening test, Stream.FM establishes a state-of-the-art for generative streaming speech restoration, exhibits only a reasonable reduction in quality compared to a non-streaming variant, and outperforms our recent work (Diffusion Buffer) on generative streaming speech enhancement while operating at a lower latency.",
    "published": "2025-12-22T14:41:17Z",
    "updated": "2025-12-22T14:41:17Z",
    "link": "http://arxiv.org/pdf/2512.19442v1.pdf",
    "category": [
      "eess.SP",
      "cs.LG",
      "cs.SD"
    ],
    "authors": [
      "Simon Welker",
      "Bunlong Lay",
      "Maris Hillemann",
      "Tal Peer",
      "Timo Gerkmann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19440v1",
    "title": "Binary Kernel Logistic Regression: a sparsity-inducing formulation and a convergent decomposition training algorithm",
    "summary": "Kernel logistic regression (KLR) is a widely used supervised learning method for binary and multi-class classification, which provides estimates of the conditional probabilities of class membership for the data points. Unlike other kernel methods such as Support Vector Machines (SVMs), KLRs are generally not sparse. Previous attempts to deal with sparsity in KLR include a heuristic method referred to as the Import Vector Machine (IVM) and ad hoc regularizations such as the $\\ell_{1/2}$-based one. Achieving a good trade-off between prediction accuracy and sparsity is still a challenging issue with a potential significant impact from the application point of view. In this work, we revisit binary KLR and propose an extension of the training formulation proposed by Keerthi et al., which is able to induce sparsity in the trained model, while maintaining good testing accuracy. To efficiently solve the dual of this formulation, we devise a decomposition algorithm of Sequential Minimal Optimization type which exploits second-order information, and for which we establish global convergence. Numerical experiments conducted on 12 datasets from the literature show that the proposed binary KLR approach achieves a competitive trade-off between accuracy and sparsity with respect to IVM, $\\ell_{1/2}$-based regularization for KLR, and SVM while retaining the advantages of providing informative estimates of the class membership probabilities.",
    "published": "2025-12-22T14:40:30Z",
    "updated": "2025-12-22T14:40:30Z",
    "link": "http://arxiv.org/pdf/2512.19440v1.pdf",
    "category": [
      "cs.LG",
      "math.OC"
    ],
    "authors": [
      "Antonio Consolo",
      "Andrea Manno",
      "Edoardo Amaldi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19439v1",
    "title": "An Inverse Scattering Inspired Fourier Neural Operator for Time-Dependent PDE Learning",
    "summary": "Learning accurate and stable time-advancement operators for nonlinear partial differential equations (PDEs) remains challenging, particularly for chaotic, stiff, and long-horizon dynamical systems. While neural operator methods such as the Fourier Neural Operator (FNO) and Koopman-inspired extensions achieve good short-term accuracy, their long-term stability is often limited by unconstrained latent representations and cumulative rollout errors. In this work, we introduce an inverse scattering inspired Fourier Neural Operator(IS-FNO), motivated by the reversibility and spectral evolution structure underlying the classical inverse scattering transform. The proposed architecture enforces a near-reversible pairing between lifting and projection maps through an explicitly invertible neural transformation, and models latent temporal evolution using exponential Fourier layers that naturally encode linear and nonlinear spectral dynamics. We systematically evaluate IS-FNO against baseline FNO and Koopman-based models on a range of benchmark PDEs, including the Michelson-Sivashinsky and Kuramoto-Sivashinsky equations (in one and two dimensions), as well as the integrable Korteweg-de Vries and Kadomtsev-Petviashvili equations. The results demonstrate that IS-FNO achieves lower short-term errors and substantially improved long-horizon stability in non-stiff regimes. For integrable systems, reduced IS-FNO variants that embed analytical scattering structure retain competitive long-term accuracy despite limited model capacity. Overall, this work shows that incorporating physical structure -- particularly reversibility and spectral evolution -- into neural operator design significantly enhances robustness and long-term predictive fidelity for nonlinear PDE dynamics.",
    "published": "2025-12-22T14:40:13Z",
    "updated": "2025-12-22T14:40:13Z",
    "link": "http://arxiv.org/pdf/2512.19439v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Rixin Yu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.04453v3",
    "title": "ESSA: Evolutionary Strategies for Scalable Alignment",
    "summary": "Alignment of Large Language Models (LLMs) typically relies on Reinforcement Learning from Human Feedback (RLHF) with gradient-based optimizers such as Proximal Policy Optimization (PPO) or Group Relative Policy Optimization (GRPO). While effective, these methods require complex distributed training, large memory budgets, and careful hyperparameter tuning, all of which become increasingly difficult at billion-parameter scale. We present ESSA, Evolutionary Strategies for Scalable Alignment, a gradient-free framework that aligns LLMs using only forward inference and black-box optimization. ESSA focuses optimization on Low-Rank Adapters (LoRA) and further compresses their parameter space by optimizing only the singular values from an singular value decomposition (SVD) of each adapter matrix. This dimensionality reduction makes evolutionary search practical even for very large models and allows efficient operation in quantized INT4 and INT8 inference mode. Across these benchmarks ESSA improves the test accuracy of Qwen2.5-Math-7B by 12.6% on GSM8K and 14.8% on PRM800K, and raises the accuracy of LLaMA3.1-8B on IFEval by 22.5%, all compared with GRPO. In large-scale settings ESSA shows stronger scaling than gradient-based methods: on Qwen2.5-32B for PRM800K it reaches near-optimal accuracy twice as fast on 16 GPUs and six times as fast on 128 GPUs compared with GRPO. These results position evolutionary strategies as a compelling, hardware-friendly alternative to gradient-based LLM alignment, combining competitive quality with substantially reduced wall-clock time and engineering overhead.",
    "published": "2025-07-06T16:23:07Z",
    "updated": "2025-12-22T14:35:03Z",
    "link": "http://arxiv.org/pdf/2507.04453v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Daria Korotyshova",
      "Boris Shaposhnikov",
      "Alexey Malakhov",
      "Alexey Khokhulin",
      "Nikita Surnachev",
      "Kirill Ovcharenko",
      "George Bredis",
      "Alexey Gorbatovski",
      "Viacheslav Sinii",
      "Daniil Gavrilov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2311.11871v4",
    "title": "Training robust and generalizable quantum models",
    "summary": "Adversarial robustness and generalization are both crucial properties of reliable machine learning models. In this paper, we study these properties in the context of quantum machine learning based on Lipschitz bounds. We derive parameter-dependent Lipschitz bounds for quantum models with trainable encoding, showing that the norm of the data encoding has a crucial impact on the robustness against data perturbations. Further, we derive a bound on the generalization error which explicitly involves the parameters of the data encoding. Our theoretical findings give rise to a practical strategy for training robust and generalizable quantum models by regularizing the Lipschitz bound in the cost. Further, we show that, for fixed and non-trainable encodings, as those frequently employed in quantum machine learning, the Lipschitz bound cannot be influenced by tuning the parameters. Thus, trainable encodings are crucial for systematically adapting robustness and generalization during training. The practical implications of our theoretical findings are illustrated with numerical results.",
    "published": "2023-11-20T16:06:35Z",
    "updated": "2025-12-22T14:29:58Z",
    "link": "http://arxiv.org/pdf/2311.11871v4.pdf",
    "category": [
      "quant-ph",
      "cs.LG",
      "math.OC"
    ],
    "authors": [
      "Julian Berberich",
      "Daniel Fink",
      "Daniel Pranjić",
      "Christian Tutschku",
      "Christian Holm"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.17473v2",
    "title": "Alternating Direction Method of Multipliers for Nonlinear Matrix Decompositions",
    "summary": "We present an algorithm based on the alternating direction method of multipliers (ADMM) for solving nonlinear matrix decompositions (NMD). Given an input matrix $X \\in \\mathbb{R}^{m \\times n}$ and a factorization rank $r \\ll \\min(m, n)$, NMD seeks matrices $W \\in \\mathbb{R}^{m \\times r}$ and $H \\in \\mathbb{R}^{r \\times n}$ such that $X \\approx f(WH)$, where $f$ is an element-wise nonlinear function. We evaluate our method on several representative nonlinear models: the rectified linear unit activation $f(x) = \\max(0, x)$, suitable for nonnegative sparse data approximation, the component-wise square $f(x) = x^2$, applicable to probabilistic circuit representation, and the MinMax transform $f(x) = \\min(b, \\max(a, x))$, relevant for recommender systems. The proposed framework flexibly supports diverse loss functions, including least squares, $\\ell_1$ norm, and the Kullback-Leibler divergence, and can be readily extended to other nonlinearities and metrics. We illustrate the applicability, efficiency, and adaptability of the approach on real-world datasets, highlighting its potential for a broad range of applications.",
    "published": "2025-12-19T11:40:06Z",
    "updated": "2025-12-22T14:13:49Z",
    "link": "http://arxiv.org/pdf/2512.17473v2.pdf",
    "category": [
      "eess.SP",
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "authors": [
      "Atharva Awari",
      "Nicolas Gillis",
      "Arnaud Vandaele"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19409v1",
    "title": "Symplectic Reservoir Representation of Legendre Dynamics",
    "summary": "Modern learning systems act on internal representations of data, yet how these representations encode underlying physical or statistical structure is often left implicit. In physics, conservation laws of Hamiltonian systems such as symplecticity guarantee long-term stability, and recent work has begun to hard-wire such constraints into learning models at the loss or output level. Here we ask a different question: what would it mean for the representation itself to obey a symplectic conservation law in the sense of Hamiltonian mechanics?\n  We express this symplectic constraint through Legendre duality: the pairing between primal and dual parameters, which becomes the structure that the representation must preserve. We formalize Legendre dynamics as stochastic processes whose trajectories remain on Legendre graphs, so that the evolving primal-dual parameters stay Legendre dual. We show that this class includes linear time-invariant Gaussian process regression and Ornstein-Uhlenbeck dynamics.\n  Geometrically, we prove that the maps that preserve all Legendre graphs are exactly symplectomorphisms of cotangent bundles of the form \"cotangent lift of a base diffeomorphism followed by an exact fibre translation\". Dynamically, this characterization leads to the design of a Symplectic Reservoir (SR), a reservoir-computing architecture that is a special case of recurrent neural network and whose recurrent core is generated by Hamiltonian systems that are at most linear in the momentum.\n  Our main theorem shows that every SR update has this normal form and therefore transports Legendre graphs to Legendre graphs, preserving Legendre duality at each time step. Overall, SR implements a geometrically constrained, Legendre-preserving representation map, injecting symplectic geometry and Hamiltonian mechanics directly at the representational level.",
    "published": "2025-12-22T14:04:13Z",
    "updated": "2025-12-22T14:04:13Z",
    "link": "http://arxiv.org/pdf/2512.19409v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Robert Simon Fong",
      "Gouhei Tanaka",
      "Kazuyuki Aihara"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19399v1",
    "title": "Brain-Grounded Axes for Reading and Steering LLM States",
    "summary": "Interpretability methods for large language models (LLMs) typically derive directions from textual supervision, which can lack external grounding. We propose using human brain activity not as a training signal but as a coordinate system for reading and steering LLM states. Using the SMN4Lang MEG dataset, we construct a word-level brain atlas of phase-locking value (PLV) patterns and extract latent axes via ICA. We validate axes with independent lexica and NER-based labels (POS/log-frequency used as sanity checks), then train lightweight adapters that map LLM hidden states to these brain axes without fine-tuning the LLM. Steering along the resulting brain-derived directions yields a robust lexical (frequency-linked) axis in a mid TinyLlama layer, surviving perplexity-matched controls, and a brain-vs-text probe comparison shows larger log-frequency shifts (relative to the text probe) with lower perplexity for the brain axis. A function/content axis (axis 13) shows consistent steering in TinyLlama, Qwen2-0.5B, and GPT-2, with PPL-matched text-level corroboration. Layer-4 effects in TinyLlama are large but inconsistent, so we treat them as secondary (Appendix). Axis structure is stable when the atlas is rebuilt without GPT embedding-change features or with word2vec embeddings (|r|=0.64-0.95 across matched axes), reducing circularity concerns. Exploratory fMRI anchoring suggests potential alignment for embedding change and log frequency, but effects are sensitive to hemodynamic modeling assumptions and are treated as population-level evidence only. These results support a new interface: neurophysiology-grounded axes provide interpretable and controllable handles for LLM behavior.",
    "published": "2025-12-22T13:51:03Z",
    "updated": "2025-12-22T13:51:03Z",
    "link": "http://arxiv.org/pdf/2512.19399v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Sandro Andric"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.17383v2",
    "title": "Confidence Calibration in Vision-Language-Action Models",
    "summary": "Trustworthy robot behavior requires not only high levels of task success but also that the robot can reliably quantify how likely it is to succeed. To this end, we present a first-of-its-kind study of confidence calibration in vision-language-action (VLA) foundation models, which map visual observations and natural language instructions to low-level robot motor commands. We establish a confidence baseline for VLAs, examine how task success relates to calibration error and how calibration evolves over time, and introduce two lightweight techniques to remedy the miscalibration we observe: prompt ensembles and action-wise Platt scaling. Our aim in this study is to begin to develop the tools and conceptual understanding necessary to render VLAs both highly performant and highly trustworthy via reliable uncertainty quantification.",
    "published": "2025-07-23T10:26:10Z",
    "updated": "2025-12-22T13:33:33Z",
    "link": "http://arxiv.org/pdf/2507.17383v2.pdf",
    "category": [
      "cs.RO",
      "cs.LG"
    ],
    "authors": [
      "Thomas P Zollo",
      "Richard Zemel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19383v1",
    "title": "Real-Time Machine Learning for Embedded Anomaly Detection",
    "summary": "The spread of a resource-constrained Internet of Things (IoT) environment and embedded devices has put pressure on the real-time detection of anomalies occurring at the edge. This survey presents an overview of machine-learning methods aimed specifically at on-device anomaly detection with extremely strict constraints for latency, memory, and power consumption. Lightweight algorithms such as Isolation Forest, One-Class SVM, recurrent architectures, and statistical techniques are compared here according to the realities of embedded implementation. Our survey brings out significant trade-offs of accuracy and computational efficiency of detection, as well as how hardware constraints end up fundamentally redefining algorithm choice. The survey is completed with a set of practical recommendations on the choice of the algorithm depending on the equipment profiles and new trends in TinyML, which can help close the gap between detection capabilities and embedded reality. The paper serves as a strategic roadmap for engineers deploying anomaly detection in edge environments that are constrained by bandwidth and may be safety-critical.",
    "published": "2025-12-22T13:27:23Z",
    "updated": "2025-12-22T13:27:23Z",
    "link": "http://arxiv.org/pdf/2512.19383v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Abdelmadjid Benmachiche",
      "Khadija Rais",
      "Hamda Slimi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19376v1",
    "title": "A Critical Assessment of Pattern Comparisons Between POD and Autoencoders in Intraventricular Flows",
    "summary": "Understanding intraventricular hemodynamics requires compact and physically interpretable representations of the underlying flow structures, as characteristic flow patterns are closely associated with cardiovascular conditions and can support early detection of cardiac deterioration. Conventional visualization of velocity or pressure fields, however, provides limited insight into the coherent mechanisms driving these dynamics. Reduced-order modeling techniques, like Proper Orthogonal Decomposition (POD) and Autoencoder (AE) architectures, offer powerful alternatives to extract dominant flow features from complex datasets. This study systematically compares POD with several AE variants (Linear, Nonlinear, Convolutional, and Variational) using left ventricular flow fields obtained from computational fluid dynamics simulations. We show that, for a suitably chosen latent dimension, AEs produce modes that become nearly orthogonal and qualitatively resemble POD modes that capture a given percentage of kinetic energy. As the number of latent modes increases, AE modes progressively lose orthogonality, leading to linear dependence, spatial redundancy, and the appearance of repeated modes with substantial high-frequency content. This degradation reduces interpretability and introduces noise-like components into AE-based reduced-order models, potentially complicating their integration with physics-based formulations or neural-network surrogates. The extent of interpretability loss varies across the AEs, with nonlinear, convolutional, and variational models exhibiting distinct behaviors in orthogonality preservation and feature localization. Overall, the results indicate that AEs can reproduce POD-like coherent structures under specific latent-space configurations, while highlighting the need for careful mode selection to ensure physically meaningful representations of cardiac flow dynamics.",
    "published": "2025-12-22T13:21:11Z",
    "updated": "2025-12-22T13:21:11Z",
    "link": "http://arxiv.org/pdf/2512.19376v1.pdf",
    "category": [
      "physics.flu-dyn",
      "cs.LG"
    ],
    "authors": [
      "Eneko Lazpita",
      "Andrés Bell-Navas",
      "Jesús Garicano-Mena",
      "Petros Koumoutsakos",
      "Soledad Le Clainche"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19373v1",
    "title": "Cluster-Based Generalized Additive Models Informed by Random Fourier Features",
    "summary": "Explainable machine learning aims to strike a balance between prediction accuracy and model transparency, particularly in settings where black-box predictive models, such as deep neural networks or kernel-based methods, achieve strong empirical performance but remain difficult to interpret. This work introduces a mixture of generalized additive models (GAMs) in which random Fourier feature (RFF) representations are leveraged to uncover locally adaptive structure in the data. In the proposed method, an RFF-based embedding is first learned and then compressed via principal component analysis. The resulting low-dimensional representations are used to perform soft clustering of the data through a Gaussian mixture model. These cluster assignments are then applied to construct a mixture-of-GAMs framework, where each local GAM captures nonlinear effects through interpretable univariate smooth functions. Numerical experiments on real-world regression benchmarks, including the California Housing, NASA Airfoil Self-Noise, and Bike Sharing datasets, demonstrate improved predictive performance relative to classical interpretable models. Overall, this construction provides a principled approach for integrating representation learning with transparent statistical modeling.",
    "published": "2025-12-22T13:15:52Z",
    "updated": "2025-12-22T13:15:52Z",
    "link": "http://arxiv.org/pdf/2512.19373v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Xin Huang",
      "Jia Li",
      "Jun Yu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19363v1",
    "title": "From Points to Coalitions: Hierarchical Contrastive Shapley Values for Prioritizing Data Samples",
    "summary": "How should we quantify the value of each training example when datasets are large, heterogeneous, and geometrically structured? Classical Data-Shapley answers in principle, but its O(n!) complexity and point-wise perspective are ill-suited to modern scales. We propose Hierarchical Contrastive Data Valuation (HCDV), a three-stage framework that (i) learns a contrastive, geometry-preserving representation, (ii) organizes the data into a balanced coarse-to-fine hierarchy of clusters, and (iii) assigns Shapley-style payoffs to coalitions via local Monte-Carlo games whose budgets are propagated downward. HCDV collapses the factorial burden to O(T sum_{l} K_{l}) = O(T K_max log n), rewards examples that sharpen decision boundaries, and regularizes outliers through curvature-based smoothness. We prove that HCDV approximately satisfies the four Shapley axioms with surplus loss O(eta log n), enjoys sub-Gaussian coalition deviation tilde O(1/sqrt{T}), and incurs at most k epsilon_infty regret for top-k selection. Experiments on four benchmarks--tabular, vision, streaming, and a 45M-sample CTR task--plus the OpenDataVal suite show that HCDV lifts accuracy by up to +5 pp, slashes valuation time by up to 100x, and directly supports tasks such as augmentation filtering, low-latency streaming updates, and fair marketplace payouts.",
    "published": "2025-12-22T13:04:16Z",
    "updated": "2025-12-22T13:04:16Z",
    "link": "http://arxiv.org/pdf/2512.19363v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Canran Xiao",
      "Jiabao Dou",
      "Zhiming Lin",
      "Zong Ke",
      "Liwei Hou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19361v1",
    "title": "Interpretable Hybrid Deep Q-Learning Framework for IoT-Based Food Spoilage Prediction with Synthetic Data Generation and Hardware Validation",
    "summary": "The need for an intelligent, real-time spoilage prediction system has become critical in modern IoT-driven food supply chains, where perishable goods are highly susceptible to environmental conditions. Existing methods often lack adaptability to dynamic conditions and fail to optimize decision making in real time. To address these challenges, we propose a hybrid reinforcement learning framework integrating Long Short-Term Memory (LSTM) and Recurrent Neural Networks (RNN) for enhanced spoilage prediction. This hybrid architecture captures temporal dependencies within sensor data, enabling robust and adaptive decision making. In alignment with interpretable artificial intelligence principles, a rule-based classifier environment is employed to provide transparent ground truth labeling of spoilage levels based on domain-specific thresholds. This structured design allows the agent to operate within clearly defined semantic boundaries, supporting traceable and interpretable decisions. Model behavior is monitored using interpretability-driven metrics, including spoilage accuracy, reward-to-step ratio, loss reduction rate, and exploration decay. These metrics provide both quantitative performance evaluation and insights into learning dynamics. A class-wise spoilage distribution visualization is used to analyze the agents decision profile and policy behavior. Extensive evaluations on simulated and real-time hardware data demonstrate that the LSTM and RNN based agent outperforms alternative reinforcement learning approaches in prediction accuracy and decision efficiency while maintaining interpretability. The results highlight the potential of hybrid deep reinforcement learning with integrated interpretability for scalable IoT-based food monitoring systems.",
    "published": "2025-12-22T12:59:48Z",
    "updated": "2025-12-22T12:59:48Z",
    "link": "http://arxiv.org/pdf/2512.19361v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Isshaan Singh",
      "Divyansh Chawla",
      "Anshu Garg",
      "Shivin Mangal",
      "Pallavi Gupta",
      "Khushi Agarwal",
      "Nimrat Singh Khalsa",
      "Nandan Patel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19342v1",
    "title": "Faster Distributed Inference-Only Recommender Systems via Bounded Lag Synchronous Collectives",
    "summary": "Recommender systems are enablers of personalized content delivery, and therefore revenue, for many large companies. In the last decade, deep learning recommender models (DLRMs) are the de-facto standard in this field. The main bottleneck in DLRM inference is the lookup of sparse features across huge embedding tables, which are usually partitioned across the aggregate RAM of many nodes. In state-of-the-art recommender systems, the distributed lookup is implemented via irregular all-to-all (alltoallv) communication, and often presents the main bottleneck. Today, most related work sees this operation as a given; in addition, every collective is synchronous in nature. In this work, we propose a novel bounded lag synchronous (BLS) version of the alltoallv operation. The bound can be a parameter allowing slower processes to lag behind entire iterations before the fastest processes block. In special applications such as inference-only DLRM, the accuracy of the application is fully preserved. We implement BLS alltoallv in a new PyTorch Distributed backend and evaluate it with a BLS version of the reference DLRM code. We show that for well balanced, homogeneous-access DLRM runs our BLS technique does not offer notable advantages. But for unbalanced runs, e.g. runs with strongly irregular embedding table accesses or with delays across different processes, our BLS technique improves both the latency and throughput of inference-only DLRM. In the best-case scenario, the proposed reduced synchronisation can mask the delays across processes altogether.",
    "published": "2025-12-22T12:36:54Z",
    "updated": "2025-12-22T12:36:54Z",
    "link": "http://arxiv.org/pdf/2512.19342v1.pdf",
    "category": [
      "cs.DC",
      "cs.LG"
    ],
    "authors": [
      "Kiril Dichev",
      "Filip Pawlowski",
      "Albert-Jan Yzelman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.20944v3",
    "title": "Semantic Superiority vs. Forensic Efficiency: A Comparative Analysis of Deep Learning and Psycholinguistics for Business Email Compromise Detection",
    "summary": "Business Email Compromise (BEC) is a sophisticated social engineering threat that manipulates organizational hierarchies, leading to significant financial damage. According to the 2024 FBI Internet Crime Report, BEC accounts for over $2.9 billion in annual losses, presenting a massive economic asymmetry: the financial cost of a False Negative (fraud loss) exceeds the operational cost of a False Positive (manual review) by a ratio of approximately 5,480:1. This paper contrasts two detection paradigms: a Forensic Psycholinguistic Stream (CatBoost), which analyzes linguistic cues like urgency and authority with high interpretability, and a Semantic Stream (DistilBERT), which utilizes deep learning for contextual understanding. We evaluated both streams on a hybrid dataset (N=7,990) containing human-legitimate and AI-synthesized adversarial fraud. Benchmarked on Tesla T4 infrastructure, DistilBERT achieved near-perfect detection on synthetic threats (AUC >0.99, F1 =0.998) with acceptable real-time latency (7.4 ms). CatBoost achieved competitive detection (AUC =0.991, F1 =0.949) at 8.4x lower latency (0.8 ms) with negligible resource consumption. We conclude that while DistilBERT offers maximum accuracy for GPU-equipped organizations, CatBoost provides a viable, cost-effective alternative for edge deployments. Both approaches demonstrate a theoretical ROI exceeding 99.9% when optimized via cost-sensitive learning.",
    "published": "2025-11-26T00:34:46Z",
    "updated": "2025-12-22T12:31:00Z",
    "link": "http://arxiv.org/pdf/2511.20944v3.pdf",
    "category": [
      "cs.LG",
      "cs.CR"
    ],
    "authors": [
      "Yaw Osei Adjei",
      "Frederick Ayivor",
      "Davis Opoku"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19334v1",
    "title": "Orthogonal Approximate Message Passing with Optimal Spectral Initializations for Rectangular Spiked Matrix Models",
    "summary": "We propose an orthogonal approximate message passing (OAMP) algorithm for signal estimation in the rectangular spiked matrix model with general rotationally invariant (RI) noise. We establish a rigorous state evolution that precisely characterizes the algorithm's high-dimensional dynamics and enables the construction of iteration-wise optimal denoisers. Within this framework, we accommodate spectral initializations under minimal assumptions on the empirical noise spectrum. In the rectangular setting, where a single rank-one component typically generates multiple informative outliers, we further propose a procedure for combining these outliers under mild non-Gaussian signal assumptions. For general RI noise models, the predicted performance of the proposed optimal OAMP algorithm agrees with replica-symmetric predictions for the associated Bayes-optimal estimator, and we conjecture that it is statistically optimal within a broad class of iterative estimation methods.",
    "published": "2025-12-22T12:28:53Z",
    "updated": "2025-12-22T12:28:53Z",
    "link": "http://arxiv.org/pdf/2512.19334v1.pdf",
    "category": [
      "cs.IT",
      "cs.LG",
      "math.ST"
    ],
    "authors": [
      "Haohua Chen",
      "Songbin Liu",
      "Junjie Ma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19332v1",
    "title": "A Logical View of GNN-Style Computation and the Role of Activation Functions",
    "summary": "We study the numerical and Boolean expressiveness of MPLang, a declarative language that captures the computation of graph neural networks (GNNs) through linear message passing and activation functions. We begin with A-MPLang, the fragment without activation functions, and give a characterization of its expressive power in terms of walk-summed features. For bounded activation functions, we show that (under mild conditions) all eventually constant activations yield the same expressive power - numerical and Boolean - and that it subsumes previously established logics for GNNs with eventually constant activation functions but without linear layers. Finally, we prove the first expressive separation between unbounded and bounded activations in the presence of linear layers: MPLang with ReLU is strictly more powerful for numerical queries than MPLang with eventually constant activation functions, e.g., truncated ReLU. This hinges on subtle interactions between linear aggregation and eventually constant non-linearities, and it establishes that GNNs using ReLU are more expressive than those restricted to eventually constant activations and linear layers.",
    "published": "2025-12-22T12:27:36Z",
    "updated": "2025-12-22T12:27:36Z",
    "link": "http://arxiv.org/pdf/2512.19332v1.pdf",
    "category": [
      "cs.LG",
      "cs.LO"
    ],
    "authors": [
      "Pablo Barceló",
      "Floris Geerts",
      "Matthias Lanzinger",
      "Klara Pakhomenko",
      "Jan Van den Bussche"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19309v1",
    "title": "Time-Vertex Machine Learning for Optimal Sensor Placement in Temporal Graph Signals: Applications in Structural Health Monitoring",
    "summary": "Structural Health Monitoring (SHM) plays a crucial role in maintaining the safety and resilience of infrastructure. As sensor networks grow in scale and complexity, identifying the most informative sensors becomes essential to reduce deployment costs without compromising monitoring quality. While Graph Signal Processing (GSP) has shown promise by leveraging spatial correlations among sensor nodes, conventional approaches often overlook the temporal dynamics of structural behavior. To overcome this limitation, we propose Time-Vertex Machine Learning (TVML), a novel framework that integrates GSP, time-domain analysis, and machine learning to enable interpretable and efficient sensor placement by identifying representative nodes that minimize redundancy while preserving critical information. We evaluate the proposed approach on two bridge datasets for damage detection and time-varying graph signal reconstruction tasks. The results demonstrate the effectiveness of our approach in enhancing SHM systems by providing a robust, adaptive, and efficient solution for sensor placement.",
    "published": "2025-12-22T11:59:47Z",
    "updated": "2025-12-22T11:59:47Z",
    "link": "http://arxiv.org/pdf/2512.19309v1.pdf",
    "category": [
      "cs.LG",
      "eess.SP"
    ],
    "authors": [
      "Keivan Faghih Niresi",
      "Jun Qing",
      "Mengjie Zhao",
      "Olga Fink"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.17531v2",
    "title": "NetworkFF: Unified Layer Optimization in Forward-Only Neural Networks",
    "summary": "The Forward-Forward algorithm eliminates backpropagation's memory constraints and biological implausibility through dual forward passes with positive and negative data. However, conventional implementations suffer from critical inter-layer isolation, where layers optimize goodness functions independently without leveraging collective learning dynamics. This isolation constrains representational coordination and limits convergence efficiency in deeper architectures. This paper introduces Collaborative Forward-Forward (CFF) learning, extending the original algorithm through inter-layer cooperation mechanisms that preserve forward-only computation while enabling global context integration. Our framework implements two collaborative paradigms: Fixed CFF (F-CFF) with constant inter-layer coupling and Adaptive CFF (A-CFF) with learnable collaboration parameters that evolve during training. The collaborative goodness function incorporates weighted contributions from all layers, enabling coordinated feature learning while maintaining memory efficiency and biological plausibility. Comprehensive evaluation on MNIST and Fashion-MNIST demonstrates significant performance improvements over baseline Forward-Forward implementations. These findings establish inter-layer collaboration as a fundamental enhancement to Forward-Forward learning, with immediate applicability to neuromorphic computing architectures and energy-constrained AI systems.",
    "published": "2025-12-19T12:54:03Z",
    "updated": "2025-12-22T11:36:59Z",
    "link": "http://arxiv.org/pdf/2512.17531v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Salar Beigzad"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.23941v2",
    "title": "Brain-language fusion enables interactive neural readout and in-silico experimentation",
    "summary": "Large language models (LLMs) have revolutionized human-machine interaction, and have been extended by embedding diverse modalities such as images into a shared language space. Yet, neural decoding has remained constrained by static, non-interactive methods. We introduce CorText, a framework that integrates neural activity directly into the latent space of an LLM, enabling open-ended, natural language interaction with brain data. Trained on fMRI data recorded during viewing of natural scenes, CorText generates accurate image captions and can answer more detailed questions better than controls, while having access to neural data only. We showcase that CorText achieves zero-shot generalization beyond semantic categories seen during training. In-silico microstimulation experiments, which enable counterfactual prompts on brain activity, reveal a consistent, and graded mapping between brain-state and language output. These advances mark a shift from passive decoding toward generative, flexible interfaces between brain activity and language.",
    "published": "2025-09-28T15:35:25Z",
    "updated": "2025-12-22T11:33:19Z",
    "link": "http://arxiv.org/pdf/2509.23941v2.pdf",
    "category": [
      "cs.LG",
      "q-bio.NC"
    ],
    "authors": [
      "Victoria Bosch",
      "Daniel Anthes",
      "Adrien Doerig",
      "Sushrut Thorat",
      "Peter König",
      "Tim Christian Kietzmann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19286v1",
    "title": "GShield: Mitigating Poisoning Attacks in Federated Learning",
    "summary": "Federated Learning (FL) has recently emerged as a revolutionary approach to collaborative training Machine Learning models. In particular, it enables decentralized model training while preserving data privacy, but its distributed nature makes it highly vulnerable to a severe attack known as Data Poisoning. In such scenarios, malicious clients inject manipulated data into the training process, thereby degrading global model performance or causing targeted misclassification. In this paper, we present a novel defense mechanism called GShield, designed to detect and mitigate malicious and low-quality updates, especially under non-independent and identically distributed (non-IID) data scenarios. GShield operates by learning the distribution of benign gradients through clustering and Gaussian modeling during an initial round, enabling it to establish a reliable baseline of trusted client behavior. With this benign profile, GShield selectively aggregates only those updates that align with the expected gradient patterns, effectively isolating adversarial clients and preserving the integrity of the global model. An extensive experimental campaign demonstrates that our proposed defense significantly improves model robustness compared to the state-of-the-art methods while maintaining a high accuracy of performance across both tabular and image datasets. Furthermore, GShield improves the accuracy of the targeted class by 43\\% to 65\\% after detecting malicious and low-quality clients.",
    "published": "2025-12-22T11:29:28Z",
    "updated": "2025-12-22T11:29:28Z",
    "link": "http://arxiv.org/pdf/2512.19286v1.pdf",
    "category": [
      "cs.CR",
      "cs.LG"
    ],
    "authors": [
      "Sameera K. M.",
      "Serena Nicolazzo",
      "Antonino Nocera",
      "Vinod P.",
      "Rafidha Rehiman K. A"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19269v1",
    "title": "Translating Flow to Policy via Hindsight Online Imitation",
    "summary": "Recent advances in hierarchical robot systems leverage a high-level planner to propose task plans and a low-level policy to generate robot actions. This design allows training the planner on action-free or even non-robot data sources (e.g., videos), providing transferable high-level guidance. Nevertheless, grounding these high-level plans into executable actions remains challenging, especially with the limited availability of high-quality robot data. To this end, we propose to improve the low-level policy through online interactions. Specifically, our approach collects online rollouts, retrospectively annotates the corresponding high-level goals from achieved outcomes, and aggregates these hindsight-relabeled experiences to update a goal-conditioned imitation policy. Our method, Hindsight Flow-conditioned Online Imitation (HinFlow), instantiates this idea with 2D point flows as the high-level planner. Across diverse manipulation tasks in both simulation and physical world, our method achieves more than $2\\times$ performance improvement over the base policy, significantly outperforming the existing methods. Moreover, our framework enables policy acquisition from planners trained on cross-embodiment video data, demonstrating its potential for scalable and transferable robot learning.",
    "published": "2025-12-22T11:06:06Z",
    "updated": "2025-12-22T11:06:06Z",
    "link": "http://arxiv.org/pdf/2512.19269v1.pdf",
    "category": [
      "cs.RO",
      "cs.LG"
    ],
    "authors": [
      "Yitian Zheng",
      "Zhangchen Ye",
      "Weijun Dong",
      "Shengjie Wang",
      "Yuyang Liu",
      "Chongjie Zhang",
      "Chuan Wen",
      "Yang Gao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19250v1",
    "title": "Small Language Models as Compiler Experts: Auto-Parallelization for Heterogeneous Systems",
    "summary": "Traditional auto-parallelizing compilers, reliant on rigid heuristics, struggle with the complexity of modern heterogeneous systems. This paper presents a comprehensive evaluation of small (approximately 1B parameter) language-model-driven compiler auto-parallelization. We evaluate three models: gemma3, llama3.2, and qwen2.5, using six reasoning strategies across 11 real-world kernels drawn from scientific computing, graph algorithms, and machine learning. Our system is benchmarked against strong compiler baselines, including LLVM Polly, TVM, and Triton. Across 376 total evaluations, the proposed approach achieves an average speedup of 6.81x and a peak performance of 43.25x on convolution operations. We analyze scalability, verify correctness using multiple sanitizers, and confirm robustness across diverse compilers and hardware platforms. Our results demonstrate that small, efficient language models can serve as powerful reasoning engines for complex compiler optimization tasks.",
    "published": "2025-12-22T10:34:45Z",
    "updated": "2025-12-22T10:34:45Z",
    "link": "http://arxiv.org/pdf/2512.19250v1.pdf",
    "category": [
      "cs.LG",
      "cs.PL"
    ],
    "authors": [
      "Prathamesh Devadiga"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19246v1",
    "title": "From Black-Box Tuning to Guided Optimization via Hyperparameters Interaction Analysis",
    "summary": "Hyperparameters tuning is a fundamental, yet computationally expensive, step in optimizing machine learning models. Beyond optimization, understanding the relative importance and interaction of hyperparameters is critical to efficient model development. In this paper, we introduce MetaSHAP, a scalable semi-automated eXplainable AI (XAI) method, that uses meta-learning and Shapley values analysis to provide actionable and dataset-aware tuning insights. MetaSHAP operates over a vast benchmark of over 09 millions evaluated machine learning pipelines, allowing it to produce interpretable importance scores and actionable tuning insights that reveal how much each hyperparameter matters, how it interacts with others and in which value ranges its influence is concentrated. For a given algorithm and dataset, MetaSHAP learns a surrogate performance model from historical configurations, computes hyperparameters interactions using SHAP-based analysis, and derives interpretable tuning ranges from the most influential hyperparameters. This allows practitioners not only to prioritize which hyperparameters to tune, but also to understand their directionality and interactions. We empirically validate MetaSHAP on a diverse benchmark of 164 classification datasets and 14 classifiers, demonstrating that it produces reliable importance rankings and competitive performance when used to guide Bayesian optimization.",
    "published": "2025-12-22T10:28:22Z",
    "updated": "2025-12-22T10:28:22Z",
    "link": "http://arxiv.org/pdf/2512.19246v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Moncef Garouani",
      "Ayah Barhrhouj"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19232v1",
    "title": "Regression generation adversarial network based on dual data evaluation strategy for industrial application",
    "summary": "Soft sensing infers hard-to-measure data through a large number of easily obtainable variables. However, in complex industrial scenarios, the issue of insufficient data volume persists, which diminishes the reliability of soft sensing. Generative Adversarial Networks (GAN) are one of the effective solutions for addressing insufficient samples. Nevertheless, traditional GAN fail to account for the mapping relationship between labels and features, which limits further performance improvement. Although some studies have proposed solutions, none have considered both performance and efficiency simultaneously. To address these problems, this paper proposes the multi-task learning-based regression GAN framework that integrates regression information into both the discriminator and generator, and implements a shallow sharing mechanism between the discriminator and regressor. This approach significantly enhances the quality of generated samples while improving the algorithm's operational efficiency. Moreover, considering the importance of training samples and generated samples, a dual data evaluation strategy is designed to make GAN generate more diverse samples, thereby increasing the generalization of subsequent modeling. The superiority of method is validated through four classic industrial soft sensing cases: wastewater treatment plants, surface water, $CO_2$ absorption towers, and industrial gas turbines.",
    "published": "2025-12-22T10:14:00Z",
    "updated": "2025-12-22T10:14:00Z",
    "link": "http://arxiv.org/pdf/2512.19232v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Zesen Wang",
      "Yonggang Li",
      "Lijuan Lan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19223v1",
    "title": "Phase-space entropy at acquisition reflects downstream learnability",
    "summary": "Modern learning systems work with data that vary widely across domains, but they all ultimately depend on how much structure is already present in the measurements before any model is trained. This raises a basic question: is there a general, modality-agnostic way to quantify how acquisition itself preserves or destroys the information that downstream learners could use? Here we propose an acquisition-level scalar $ΔS_{\\mathcal B}$ based on instrument-resolved phase space. Unlike pixelwise distortion or purely spectral errors that often saturate under aggressive undersampling, $ΔS_{\\mathcal B}$ directly quantifies how acquisition mixes or removes joint space--frequency structure at the instrument scale. We show theoretically that \\(ΔS_{\\mathcal B}\\) correctly identifies the phase-space coherence of periodic sampling as the physical source of aliasing, recovering classical sampling-theorem consequences. Empirically, across masked image classification, accelerated MRI, and massive MIMO (including over-the-air measurements), $|ΔS_{\\mathcal B}|$ consistently ranks sampling geometries and predicts downstream reconstruction/recognition difficulty \\emph{without training}. In particular, minimizing $|ΔS_{\\mathcal B}|$ enables zero-training selection of variable-density MRI mask parameters that matches designs tuned by conventional pre-reconstruction criteria. These results suggest that phase-space entropy at acquisition reflects downstream learnability, enabling pre-training selection of candidate sampling policies and as a shared notion of information preservation across modalities.",
    "published": "2025-12-22T10:03:51Z",
    "updated": "2025-12-22T10:03:51Z",
    "link": "http://arxiv.org/pdf/2512.19223v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Xiu-Cheng Wang",
      "Jun-Jie Zhanga",
      "Nan Cheng",
      "Long-Gang Pang",
      "Taijiao Du",
      "Deyu Meng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2402.13081v2",
    "title": "IT Intrusion Detection Using Statistical Learning and Testbed Measurements",
    "summary": "We study automated intrusion detection in an IT infrastructure, specifically the problem of identifying the start of an attack, the type of attack, and the sequence of actions an attacker takes, based on continuous measurements from the infrastructure. We apply statistical learning methods, including Hidden Markov Model (HMM), Long Short-Term Memory (LSTM), and Random Forest Classifier (RFC) to map sequences of observations to sequences of predicted attack actions. In contrast to most related research, we have abundant data to train the models and evaluate their predictive power. The data comes from traces we generate on an in-house testbed where we run attacks against an emulated IT infrastructure. Central to our work is a machine-learning pipeline that maps measurements from a high-dimensional observation space to a space of low dimensionality or to a small set of observation symbols. Investigating intrusions in offline as well as online scenarios, we find that both HMM and LSTM can be effective in predicting attack start time, attack type, and attack actions. If sufficient training data is available, LSTM achieves higher prediction accuracy than HMM. HMM, on the other hand, requires less computational resources and less training data for effective prediction. Also, we find that the methods we study benefit from data produced by traditional intrusion detection systems like SNORT.",
    "published": "2024-02-20T15:25:56Z",
    "updated": "2025-12-22T09:39:40Z",
    "link": "http://arxiv.org/pdf/2402.13081v2.pdf",
    "category": [
      "cs.LG",
      "cs.CR"
    ],
    "authors": [
      "Xiaoxuan Wang",
      "Rolf Stadler"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.15661v2",
    "title": "Prospects for quantum advantage in machine learning from the representability of functions",
    "summary": "Demonstrating quantum advantage in machine learning tasks requires navigating a complex landscape of proposed models and algorithms. To bring clarity to this search, we introduce a framework that connects the structure of parametrized quantum circuits to the mathematical nature of the functions they can actually learn. Within this framework, we show how fundamental properties, like circuit depth and non-Clifford gate count, directly determine whether a model's output leads to efficient classical simulation or surrogation. We argue that this analysis uncovers common pathways to dequantization that underlie many existing simulation methods. More importantly, it reveals critical distinctions between models that are fully simulatable, those whose function space is classically tractable, and those that remain robustly quantum. This perspective provides a conceptual map of this landscape, clarifying how different models relate to classical simulability and pointing to where opportunities for quantum advantage may lie.",
    "published": "2025-12-17T18:14:59Z",
    "updated": "2025-12-22T09:34:23Z",
    "link": "http://arxiv.org/pdf/2512.15661v2.pdf",
    "category": [
      "quant-ph",
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Sergi Masot-Llima",
      "Elies Gil-Fuster",
      "Carlos Bravo-Prieto",
      "Jens Eisert",
      "Tommaso Guaita"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19196v1",
    "title": "Self-Consistent Probability Flow for High-Dimensional Fokker-Planck Equations",
    "summary": "Solving high-dimensional Fokker-Planck (FP) equations is a challenge in computational physics and stochastic dynamics, due to the curse of dimensionality (CoD) and the bottleneck of evaluating second-order diffusion terms. Existing deep learning approaches, such as Physics-Informed Neural Networks (PINNs), face computational challenges as dimensionality increases, driven by the $O(D^2)$ complexity of automatic differentiation for second-order derivatives. While recent probability flow approaches bypass this by learning score functions or matching velocity fields, they often involve serial computational operations or depend on sampling efficiency in complex distributions. To address these issues, we propose the Self-Consistent Probability Flow (SCPF) method. We reformulate the second-order FP equation into an equivalent first-order deterministic Probability Flow ODE (PF-ODE) constraint. Unlike score matching or velocity matching, SCPF solves this problem by minimizing the residual of the PF-ODE continuity equation, which avoids explicit Hessian computation. We leverage Continuous Normalizing Flows (CNF) combined with the Hutchinson Trace Estimator (HTE) to reduce the training complexity to linear scale $O(D)$, achieving an effective $O(1)$ wall-clock time on GPUs. To address data sparsity in high dimensions, we apply a generative adaptive sampling strategy and theoretically prove that dynamically aligning collocation points with the evolving probability mass is a necessary condition to bound the approximation error. Experiments on diverse benchmarks -- ranging from anisotropic Ornstein-Uhlenbeck (OU) processes and high-dimensional Brownian motions with time-varying diffusion terms, to Geometric OU processes featuring non-Gaussian solutions -- demonstrate that SCPF effectively mitigates the CoD, maintaining high accuracy and constant computational cost for problems up to 100 dimensions.",
    "published": "2025-12-22T09:31:31Z",
    "updated": "2025-12-22T09:31:31Z",
    "link": "http://arxiv.org/pdf/2512.19196v1.pdf",
    "category": [
      "physics.comp-ph",
      "cs.LG",
      "math.NA"
    ],
    "authors": [
      "Xiaolong Wu",
      "Qifeng Liao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19194v1",
    "title": "Causal Heterogeneous Graph Learning Method for Chronic Obstructive Pulmonary Disease Prediction",
    "summary": "Due to the insufficient diagnosis and treatment capabilities at the grassroots level, there are still deficiencies in the early identification and early warning of acute exacerbation of Chronic obstructive pulmonary disease (COPD), often resulting in a high prevalence rate and high burden, but the screening rate is relatively low. In order to gradually improve this situation. In this paper, this study develop a Causal Heterogeneous Graph Representation Learning (CHGRL) method for COPD comorbidity risk prediction method that: a) constructing a heterogeneous Our dataset includes the interaction between patients and diseases; b) A cause-aware heterogeneous graph learning architecture has been constructed, combining causal inference mechanisms with heterogeneous graph learning, which can support heterogeneous graph causal learning for different types of relationships; and c) Incorporate the causal loss function in the model design, and add counterfactual reasoning learning loss and causal regularization loss on the basis of the cross-entropy classification loss. We evaluate our method and compare its performance with strong GNN baselines. Following experimental evaluation, the proposed model demonstrates high detection accuracy.",
    "published": "2025-12-22T09:30:25Z",
    "updated": "2025-12-22T09:30:25Z",
    "link": "http://arxiv.org/pdf/2512.19194v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Leming Zhou",
      "Zuo Wang",
      "Zhigang Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.09574v2",
    "title": "MOORL: A Framework for Integrating Offline-Online Reinforcement Learning",
    "summary": "Sample efficiency and exploration remain critical challenges in Deep Reinforcement Learning (DRL), particularly in complex domains. Offline RL, which enables agents to learn optimal policies from static, pre-collected datasets, has emerged as a promising alternative. However, offline RL is constrained by issues such as out-of-distribution (OOD) actions that limit policy performance and generalization. To overcome these limitations, we propose Meta Offline-Online Reinforcement Learning (MOORL), a hybrid framework that unifies offline and online RL for efficient and scalable learning. While previous hybrid methods rely on extensive design components and added computational complexity to utilize offline data effectively, MOORL introduces a meta-policy that seamlessly adapts across offline and online trajectories. This enables the agent to leverage offline data for robust initialization while utilizing online interactions to drive efficient exploration. Our theoretical analysis demonstrates that the hybrid approach enhances exploration by effectively combining the complementary strengths of offline and online data. Furthermore, we demonstrate that MOORL learns a stable Q-function without added complexity. Extensive experiments on 28 tasks from the D4RL and V-D4RL benchmarks validate its effectiveness, showing consistent improvements over state-of-the-art offline and hybrid RL baselines. With minimal computational overhead, MOORL achieves strong performance, underscoring its potential for practical applications in real-world scenarios.",
    "published": "2025-06-11T10:12:50Z",
    "updated": "2025-12-22T09:20:25Z",
    "link": "http://arxiv.org/pdf/2506.09574v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Gaurav Chaudhary",
      "Wassim Uddin Mondal",
      "Laxmidhar Behera"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.12815v2",
    "title": "From Novelty to Imitation: Self-Distilled Rewards for Offline Reinforcement Learning",
    "summary": "Offline Reinforcement Learning (RL) aims to learn effective policies from a static dataset without requiring further agent-environment interactions. However, its practical adoption is often hindered by the need for explicit reward annotations, which can be costly to engineer or difficult to obtain retrospectively. To address this, we propose ReLOAD (Reinforcement Learning with Offline Reward Annotation via Distillation), a novel reward annotation framework for offline RL. Unlike existing methods that depend on complex alignment procedures, our approach adapts Random Network Distillation (RND) to generate intrinsic rewards from expert demonstrations using a simple yet effective embedding discrepancy measure. First, we train a predictor network to mimic a fixed target network's embeddings based on expert state transitions. Later, the prediction error between these networks serves as a reward signal for each transition in the static dataset. This mechanism provides a structured reward signal without requiring handcrafted reward annotations. We provide a formal theoretical construct that offers insights into how RND prediction errors effectively serve as intrinsic rewards by distinguishing expert-like transitions. Experiments on the D4RL benchmark demonstrate that ReLOAD enables robust offline policy learning and achieves performance competitive with traditional reward-annotated methods.",
    "published": "2025-07-17T06:16:06Z",
    "updated": "2025-12-22T09:16:29Z",
    "link": "http://arxiv.org/pdf/2507.12815v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Gaurav Chaudhary",
      "Laxmidhar Behera"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19172v1",
    "title": "Finite-sample guarantees for data-driven forward-backward operator methods",
    "summary": "We establish finite sample certificates on the quality of solutions produced by data-based forward-backward (FB) operator splitting schemes. As frequently happens in stochastic regimes, we consider the problem of finding a zero of the sum of two operators, where one is either unavailable in closed form or computationally expensive to evaluate, and shall therefore be approximated using a finite number of noisy oracle samples. Under the lens of algorithmic stability, we then derive probabilistic bounds on the distance between a true zero and the FB output without making specific assumptions about the underlying data distribution. We show that under weaker conditions ensuring the convergence of FB schemes, stability bounds grow proportionally to the number of iterations. Conversely, stronger assumptions yield stability guarantees that are independent of the iteration count. We then specialize our results to a popular FB stochastic Nash equilibrium seeking algorithm and validate our theoretical bounds on a control problem for smart grids, where the energy price uncertainty is approximated by means of historical data.",
    "published": "2025-12-22T09:07:09Z",
    "updated": "2025-12-22T09:07:09Z",
    "link": "http://arxiv.org/pdf/2512.19172v1.pdf",
    "category": [
      "math.OC",
      "cs.LG",
      "eess.SY"
    ],
    "authors": [
      "Filippo Fabiani",
      "Barbara Franci"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.13123v3",
    "title": "Stopping Rules for Stochastic Gradient Descent via Anytime-Valid Confidence Sequences",
    "summary": "We study stopping rules for stochastic gradient descent (SGD) for convex optimization from the perspective of anytime-valid confidence sequences. Classical analyses of SGD provide convergence guarantees in expectation or at a fixed horizon, but offer no statistically valid way to assess, at an arbitrary time, how close the current iterate is to the optimum. We develop an anytime-valid, data-dependent upper confidence sequence for the weighted average suboptimality of projected SGD, constructed via nonnegative supermartingales and requiring no smoothness or strong convexity. This confidence sequence yields a simple stopping rule that is provably $\\varepsilon$-optimal with probability at least $1-α$, with explicit bounds on the stopping time under standard stochastic approximation stepsizes. To the best of our knowledge, these are the first rigorous, time-uniform performance guarantees and finite-time $\\varepsilon$-optimality certificates for projected SGD with general convex objectives, based solely on observable trajectory quantities.",
    "published": "2025-12-15T09:26:45Z",
    "updated": "2025-12-22T08:50:20Z",
    "link": "http://arxiv.org/pdf/2512.13123v3.pdf",
    "category": [
      "math.OC",
      "cs.LG",
      "math.ST",
      "stat.ML"
    ],
    "authors": [
      "Liviu Aolaritei",
      "Michael I. Jordan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.00066v2",
    "title": "Sharpness-Controlled Group Relative Policy Optimization with Token-Level Probability Shaping",
    "summary": "Reinforcement learning with verifiable rewards (RLVR) has become a practical route to improve large language model reasoning, and Group Relative Policy Optimization (GRPO) is a widely used optimizer in this setting. This paper revisits GRPO from a generalization perspective. Recent analysis shows that population performance can be controlled by a robust empirical objective that decomposes into the training loss plus a sharpness term measured by the gradient norm. We develop a token-level view of this sharpness term and show that GRPO can be dominated by a small subset of tokens with disproportionately large per-token gradients, which increases sharpness and can harm generalization. Motivated by this view, we propose Token-Regulated GRPO (TR-GRPO), which introduces a monotone probability shaping function to assign token weights based on the model's own token probabilities, and integrates these weights into the standard GRPO. Our analysis yields a bound that isolates a probability dependent multiplicative factor in token-gradient magnitudes, explaining how probability-aware weighting suppresses sharp directions while preserving learning signal on semantically critical tokens. Experiments on logic puzzles, mathematical reasoning, and tool-augmented question answering show consistent improvements over GRPO, along with smoother gradient-norm trajectories, supporting TR-GRPO as a simple and effective generalization-oriented upgrade to GRPO for RLVR.",
    "published": "2025-10-29T08:07:47Z",
    "updated": "2025-12-22T08:49:46Z",
    "link": "http://arxiv.org/pdf/2511.00066v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Tue Le",
      "Nghi D. Q. Bui",
      "Linh Ngo Van",
      "Trung Le"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.16750v3",
    "title": "Theoretical Convergence Guarantees for Variational Autoencoders",
    "summary": "Variational Autoencoders (VAE) are popular generative models used to sample from complex data distributions. Despite their empirical success in various machine learning tasks, significant gaps remain in understanding their theoretical properties, particularly regarding convergence guarantees. This paper aims to bridge that gap by providing non-asymptotic convergence guarantees for VAE trained using both Stochastic Gradient Descent and Adam algorithms. We derive a convergence rate of $\\mathcal{O}(\\log n / \\sqrt{n})$, where $n$ is the number of iterations of the optimization algorithm, with explicit dependencies on the batch size, the number of variational samples, and other key hyperparameters. Our theoretical analysis applies to both Linear VAE and Deep Gaussian VAE, as well as several VAE variants, including $β$-VAE and IWAE. Additionally, we empirically illustrate the impact of hyperparameters on convergence, offering new insights into the theoretical understanding of VAE training.",
    "published": "2024-10-22T07:12:38Z",
    "updated": "2025-12-22T08:46:43Z",
    "link": "http://arxiv.org/pdf/2410.16750v3.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Sobihan Surendran",
      "Antoine Godichon-Baggioni",
      "Sylvain Le Corff"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19147v1",
    "title": "RP-CATE: Recurrent Perceptron-based Channel Attention Transformer Encoder for Industrial Hybrid Modeling",
    "summary": "Nowadays, industrial hybrid modeling which integrates both mechanistic modeling and machine learning-based modeling techniques has attracted increasing interest from scholars due to its high accuracy, low computational cost, and satisfactory interpretability. Nevertheless, the existing industrial hybrid modeling methods still face two main limitations. First, current research has mainly focused on applying a single machine learning method to one specific task, failing to develop a comprehensive machine learning architecture suitable for modeling tasks, which limits their ability to effectively represent complex industrial scenarios. Second, industrial datasets often contain underlying associations (e.g., monotonicity or periodicity) that are not adequately exploited by current research, which can degrade model's predictive performance. To address these limitations, this paper proposes the Recurrent Perceptron-based Channel Attention Transformer Encoder (RP-CATE), with three distinctive characteristics: 1: We developed a novel architecture by replacing the self-attention mechanism with channel attention and incorporating our proposed Recurrent Perceptron (RP) Module into Transformer, achieving enhanced effectiveness for industrial modeling tasks compared to the original Transformer. 2: We proposed a new data type called Pseudo-Image Data (PID) tailored for channel attention requirements and developed a cyclic sliding window method for generating PID. 3: We introduced the concept of Pseudo-Sequential Data (PSD) and a method for converting industrial datasets into PSD, which enables the RP Module to capture the underlying associations within industrial dataset more effectively. An experiment aimed at hybrid modeling in chemical engineering was conducted by using RP-CATE and the experimental results demonstrate that RP-CATE achieves the best performance compared to other baseline models.",
    "published": "2025-12-22T08:44:58Z",
    "updated": "2025-12-22T08:44:58Z",
    "link": "http://arxiv.org/pdf/2512.19147v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Haoran Yang",
      "Yinan Zhang",
      "Wenjie Zhang",
      "Dongxia Wang",
      "Peiyu Liu",
      "Yuqi Ye",
      "Kexin Chen",
      "Wenhai Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19142v1",
    "title": "A Convex Loss Function for Set Prediction with Optimal Trade-offs Between Size and Conditional Coverage",
    "summary": "We consider supervised learning problems in which set predictions provide explicit uncertainty estimates. Using Choquet integrals (a.k.a. Lov{á}sz extensions), we propose a convex loss function for nondecreasing subset-valued functions obtained as level sets of a real-valued function. This loss function allows optimal trade-offs between conditional probabilistic coverage and the ''size'' of the set, measured by a non-decreasing submodular function. We also propose several extensions that mimic loss functions and criteria for binary classification with asymmetric losses, and show how to naturally obtain sets with optimized conditional coverage. We derive efficient optimization algorithms, either based on stochastic gradient descent or reweighted least-squares formulations, and illustrate our findings with a series of experiments on synthetic datasets for classification and regression tasks, showing improvements over approaches that aim for marginal coverage.",
    "published": "2025-12-22T08:41:31Z",
    "updated": "2025-12-22T08:41:31Z",
    "link": "http://arxiv.org/pdf/2512.19142v1.pdf",
    "category": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "authors": [
      "Francis Bach"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19131v1",
    "title": "Evidential Trust-Aware Model Personalization in Decentralized Federated Learning for Wearable IoT",
    "summary": "Decentralized federated learning (DFL) enables collaborative model training across edge devices without centralized coordination, offering resilience against single points of failure. However, statistical heterogeneity arising from non-identically distributed local data creates a fundamental challenge: nodes must learn personalized models adapted to their local distributions while selectively collaborating with compatible peers. Existing approaches either enforce a single global model that fits no one well, or rely on heuristic peer selection mechanisms that cannot distinguish between peers with genuinely incompatible data distributions and those with valuable complementary knowledge. We present Murmura, a framework that leverages evidential deep learning to enable trust-aware model personalization in DFL. Our key insight is that epistemic uncertainty from Dirichlet-based evidential models directly indicates peer compatibility: high epistemic uncertainty when a peer's model evaluates local data reveals distributional mismatch, enabling nodes to exclude incompatible influence while maintaining personalized models through selective collaboration. Murmura introduces a trust-aware aggregation mechanism that computes peer compatibility scores through cross-evaluation on local validation samples and personalizes model aggregation based on evidential trust with adaptive thresholds. Evaluation on three wearable IoT datasets (UCI HAR, PAMAP2, PPG-DaLiA) demonstrates that Murmura reduces performance degradation from IID to non-IID conditions compared to baseline (0.9% vs. 19.3%), achieves 7.4$\\times$ faster convergence, and maintains stable accuracy across hyperparameter choices. These results establish evidential uncertainty as a principled foundation for compatibility-aware personalization in decentralized heterogeneous environments.",
    "published": "2025-12-22T08:26:54Z",
    "updated": "2025-12-22T08:26:54Z",
    "link": "http://arxiv.org/pdf/2512.19131v1.pdf",
    "category": [
      "cs.DC",
      "cs.LG"
    ],
    "authors": [
      "Murtaza Rangwala",
      "Richard O. Sinnott",
      "Rajkumar Buyya"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19123v1",
    "title": "A Composable Channel-Adaptive Architecture for Seizure Classification",
    "summary": "Objective: We develop a channel-adaptive (CA) architecture that seamlessly processes multi-variate time-series with an arbitrary number of channels, and in particular intracranial electroencephalography (iEEG) recordings. Methods: Our CA architecture first processes the iEEG signal using state-of-the-art models applied to each single channel independently. The resulting features are then fused using a vector-symbolic algorithm which reconstructs the spatial relationship using a trainable scalar per channel. Finally, the fused features are accumulated in a long-term memory of up to 2 minutes to perform the classification. Each CA-model can then be pre-trained on a large corpus of iEEG recordings from multiple heterogeneous subjects. The pre-trained model is personalized to each subject via a quick fine-tuning routine, which uses equal or lower amounts of data compared to existing state-of-the-art models, but requiring only 1/5 of the time. Results: We evaluate our CA-models on a seizure detection task both on a short-term (~20 hours) and a long-term (~2500 hours) dataset. In particular, our CA-EEGWaveNet is trained on a single seizure of the tested subject, while the baseline EEGWaveNet is trained on all but one. Even in this challenging scenario, our CA-EEGWaveNet surpasses the baseline in median F1-score (0.78 vs 0.76). Similarly, CA-EEGNet based on EEGNet, also surpasses its baseline in median F1-score (0.79 vs 0.74). Conclusion and significance: Our CA-model addresses two issues: first, it is channel-adaptive and can therefore be trained across heterogeneous subjects without loss of performance; second, it increases the effective temporal context size to a clinically-relevant length. Therefore, our model is a drop-in replacement for existing models, bringing better characteristics and performance across the board.",
    "published": "2025-12-22T07:57:20Z",
    "updated": "2025-12-22T07:57:20Z",
    "link": "http://arxiv.org/pdf/2512.19123v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Francesco Carzaniga",
      "Michael Hersche",
      "Kaspar Schindler",
      "Abbas Rahimi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.08985v3",
    "title": "Low-Regret and Low-Complexity Learning for Hierarchical Inference",
    "summary": "This work focuses on Hierarchical Inference (HI) in edge intelligence systems, where a compact Local-ML model on an end-device works in conjunction with a high-accuracy Remote-ML model on an edge-server. HI aims to reduce latency, improve accuracy, and lower bandwidth usage by first using the Local-ML model for inference and offloading to the Remote-ML only when the local inference is likely incorrect. A critical challenge in HI is estimating the likelihood of the local inference being incorrect, especially when data distributions and offloading costs change over time -- a problem we term Hierarchical Inference Learning (HIL). We introduce a novel approach to HIL by modeling the probability of correct inference by the Local-ML as an increasing function of the model's confidence measure, a structure motivated by empirical observations but previously unexploited. We propose two policies, HI-LCB and HI-LCB-lite, based on the Upper Confidence Bound (UCB) framework. We demonstrate that both policies achieve order-optimal regret of $O(\\log T)$, a significant improvement over existing HIL policies with $O(T^{2/3})$ regret guarantees. Notably, HI-LCB-lite has an $O(1)$ per-sample computational complexity, making it well-suited for deployment on devices with severe resource limitations. Simulations using real-world datasets confirm that our policies outperform existing state-of-the-art HIL methods.",
    "published": "2025-08-12T14:53:54Z",
    "updated": "2025-12-22T07:34:52Z",
    "link": "http://arxiv.org/pdf/2508.08985v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Sameep Chattopadhyay",
      "Vinay Sutar",
      "Jaya Prakash Champati",
      "Sharayu Moharir"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19104v1",
    "title": "Explicit and Non-asymptotic Query Complexities of Rank-Based Zeroth-order Algorithm on Stochastic Smooth Functions",
    "summary": "Zeroth-order (ZO) optimization with ordinal feedback has emerged as a fundamental problem in modern machine learning systems, particularly in human-in-the-loop settings such as reinforcement learning from human feedback, preference learning, and evolutionary strategies. While rank-based ZO algorithms enjoy strong empirical success and robustness properties, their theoretical understanding, especially under stochastic objectives and standard smoothness assumptions, remains limited. In this paper, we study rank-based zeroth-order optimization for stochastic functions where only ordinal feedback of the stochastic function is available. We propose a simple and computationally efficient rank-based ZO algorithm. Under standard assumptions including smoothness, strong convexity, and bounded second moments of stochastic gradients, we establish explicit non-asymptotic query complexity bounds for both convex and nonconvex objectives. Notably, our results match the best-known query complexities of value-based ZO algorithms, demonstrating that ordinal information alone is sufficient for optimal query efficiency in stochastic settings. Our analysis departs from existing drift-based and information-geometric techniques, offering new tools for the study of rank-based optimization under noise. These findings narrow the gap between theory and practice and provide a principled foundation for optimization driven by human preferences.",
    "published": "2025-12-22T07:18:57Z",
    "updated": "2025-12-22T07:18:57Z",
    "link": "http://arxiv.org/pdf/2512.19104v1.pdf",
    "category": [
      "math.OC",
      "cs.LG"
    ],
    "authors": [
      "Haishan Ye"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19103v1",
    "title": "Timely Parameter Updating in Over-the-Air Federated Learning",
    "summary": "Incorporating over-the-air computations (OAC) into the model training process of federated learning (FL) is an effective approach to alleviating the communication bottleneck in FL systems. Under OAC-FL, every client modulates its intermediate parameters, such as gradient, onto the same set of orthogonal waveforms and simultaneously transmits the radio signal to the edge server. By exploiting the superposition property of multiple-access channels, the edge server can obtain an automatically aggregated global gradient from the received signal. However, the limited number of orthogonal waveforms available in practical systems is fundamentally mismatched with the high dimensionality of modern deep learning models. To address this issue, we propose Freshness Freshness-mAgnItude awaRe top-k (FAIR-k), an algorithm that selects, in each communication round, the most impactful subset of gradients to be updated over the air. In essence, FAIR-k combines the complementary strengths of the Round-Robin and Top-k algorithms, striking a delicate balance between timeliness (freshness of parameter updates) and importance (gradient magnitude). Leveraging tools from Markov analysis, we characterize the distribution of parameter staleness under FAIR-k. Building on this, we establish the convergence rate of OAC-FL with FAIR-k, which discloses the joint effect of data heterogeneity, channel noise, and parameter staleness on the training efficiency. Notably, as opposed to conventional analyses that assume a universal Lipschitz constant across all the clients, our framework adopts a finer-grained model of the data heterogeneity. The analysis demonstrates that since FAIR-k promotes fresh (and fair) parameter updates, it not only accelerates convergence but also enhances communication efficiency by enabling an extended period of local training without significantly affecting overall training efficiency.",
    "published": "2025-12-22T07:18:13Z",
    "updated": "2025-12-22T07:18:13Z",
    "link": "http://arxiv.org/pdf/2512.19103v1.pdf",
    "category": [
      "cs.LG",
      "cs.DC"
    ],
    "authors": [
      "Jiaqi Zhu",
      "Zhongyuan Zhao",
      "Xiao Li",
      "Ruihao Du",
      "Shi Jin",
      "Howard H. Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19099v1",
    "title": "Dual Model Deep Learning for Alzheimer Prognostication",
    "summary": "Disease modifying therapies for Alzheimer's disease demand precise timing decisions, yet current predictive models require longitudinal observations and provide no uncertainty quantification, rendering them impractical at the critical first visit when treatment decisions must be made. We developed PROGRESS (PRognostic Generalization from REsting Static Signatures), a dual-model deep learning framework that transforms a single baseline cerebrospinal fluid biomarker assessment into actionable prognostic estimates without requiring prior clinical history. The framework addresses two complementary clinical questions: a probabilistic trajectory network predicts individualized cognitive decline with calibrated uncertainty bounds achieving near-nominal coverage, enabling honest prognostic communication; and a deep survival model estimates time to conversion from mild cognitive impairment to dementia. Using data from over 3,000 participants across 43 Alzheimer's Disease Research Centers in the National Alzheimer's Coordinating Center database, PROGRESS substantially outperforms Cox proportional hazards, Random Survival Forests, and gradient boosting methods for survival prediction. Risk stratification identifies patient groups with seven-fold differences in conversion rates, enabling clinically meaningful treatment prioritization. Leave-one-center-out validation demonstrates robust generalizability, with survival discrimination remaining strong across held-out sites despite heterogeneous measurement conditions spanning four decades of assay technologies. By combining superior survival prediction with trustworthy trajectory uncertainty quantification, PROGRESS bridges the gap between biomarker measurement and personalized clinical decision-making.",
    "published": "2025-12-22T07:08:20Z",
    "updated": "2025-12-22T07:08:20Z",
    "link": "http://arxiv.org/pdf/2512.19099v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Alireza Moayedikia",
      "Sara Fin",
      "Uffe Kock Wiil"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.04659v3",
    "title": "Nowcast3D: Reliable precipitation nowcasting via gray-box learning",
    "summary": "Extreme-precipitation nowcasting requires high spatial and temporal resolution together with extended lead times, yet current approaches remain constrained. Numerical weather prediction systems and their deep-learning emulators operate at relatively coarse space-time resolution and struggle to capture rapidly evolving convective systems. Radar extrapolation methods, which advect recent fields using estimated motion, have difficulty capturing the complex evolution of precipitation. Purely data-driven models often produce overly smoothed reflectivity fields and underestimate intensity. Hybrid 2D radar-based methods discard crucial vertical information, preventing accurate reconstruction of height-dependent dynamics. We introduce Nowcast3D, a gray-box, fully three-dimensional nowcasting framework that operates directly on volumetric radar reflectivity and couples physically constrained neural operators with data-driven learning. The model learns three fields that govern reflectivity evolution: a three-dimensional flow field for advective transport, a spatially varying diffusion field for local dispersive spreading, and a residual source term for unresolved microphysical effects. These learned operators advance the forecast in time under explicit physical constraints, while a conditional diffusion model, conditioned on both the observations and the physics-based forecast, generates ensembles of future radar volumes that quantify forecast uncertainty. In a blind evaluation by 160 meteorologists, Nowcast3D is preferred in 57% of post-hoc and 51% of prior assessments. By explicitly embedding three-dimensional dynamics and uncertainty into a single framework, Nowcast3D offers a scalable and robust approach for reliable nowcasting of extreme precipitation.",
    "published": "2025-11-06T18:44:35Z",
    "updated": "2025-12-22T07:04:01Z",
    "link": "http://arxiv.org/pdf/2511.04659v3.pdf",
    "category": [
      "cs.LG",
      "physics.ao-ph"
    ],
    "authors": [
      "Huaguan Chen",
      "Wei Han",
      "Haofei Sun",
      "Ning Lin",
      "Xingtao Song",
      "Yunfan Yang",
      "Jie Tian",
      "Yang Liu",
      "Ji-Rong Wen",
      "Xiaoye Zhang",
      "Xueshun Shen",
      "Hao Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19067v1",
    "title": "On Cost-Aware Sequential Hypothesis Testing with Random Costs and Action Cancellation",
    "summary": "We study a variant of cost-aware sequential hypothesis testing in which a single active Decision Maker (DM) selects actions with positive, random costs to identify the true hypothesis under an average error constraint, while minimizing the expected total cost. The DM may abort an in-progress action, yielding no sample, by truncating its realized cost at a smaller, tunable deterministic limit, which we term a per-action deadline. We analyze how this cancellation option can be exploited under two cost-revelation models: ex-post, where the cost is revealed only after the sample is obtained, and ex-ante, where the cost accrues before sample acquisition.\n  In the ex-post model, per-action deadlines do not affect the expected total cost, and the cost-error tradeoffs coincide with the baseline obtained by replacing deterministic costs with cost means. In the ex-ante model, we show how per-action deadlines inflate the expected number of times actions are applied, and that the resulting expected total cost can be reduced to the constant-cost setting by introducing an effective per-action cost. We characterize when deadlines are beneficial and study several families in detail.",
    "published": "2025-12-22T06:14:17Z",
    "updated": "2025-12-22T06:14:17Z",
    "link": "http://arxiv.org/pdf/2512.19067v1.pdf",
    "category": [
      "cs.IT",
      "cs.LG"
    ],
    "authors": [
      "George Vershinin",
      "Asaf Cohen",
      "Omer Gurewitz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.03560v2",
    "title": "Stochastic Optimization with Optimal Importance Sampling",
    "summary": "Importance Sampling (IS) is a widely used variance reduction technique for enhancing the efficiency of Monte Carlo methods, particularly in rare-event simulation and related applications. Despite its effectiveness, the performance of IS is highly sensitive to the choice of the proposal distribution and often requires stochastic calibration. While the design and analysis of IS have been extensively studied in estimation settings, applying IS within stochastic optimization introduces a fundamental challenge: the decision variable and the importance sampling distribution are mutually dependent, creating a circular optimization structure. This interdependence complicates both convergence analysis and variance control. We consider convex stochastic optimization problems with linear constraints and propose a single-loop stochastic approximation algorithm, based on a joint variant of Nesterov's dual averaging, that jointly updates the decision variable and the importance sampling distribution, without time-scale separation or nested optimization. The method is globally convergent and achieves minimal asymptotic variance among stochastic gradient schemes, matching the performance of an oracle sampler adapted to the optimal solution.",
    "published": "2025-04-04T16:10:18Z",
    "updated": "2025-12-22T06:01:20Z",
    "link": "http://arxiv.org/pdf/2504.03560v2.pdf",
    "category": [
      "math.OC",
      "cs.LG",
      "math.ST",
      "stat.ML"
    ],
    "authors": [
      "Liviu Aolaritei",
      "Bart P. G. Van Parys",
      "Henry Lam",
      "Michael I. Jordan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.16963v2",
    "title": "Compression is Routing: Reconstruction Error as an Intrinsic Signal for Modular Language Models",
    "summary": "Current Large Language Models (LLMs) face three major challenges: context length limitations, high inference costs, and catastrophic forgetting during continual learning. While Mixture-of-Experts (MoE) architectures mitigate some of these conflicts, their routing mechanisms typically rely on explicitly trained auxiliary classifiers. This not only increases system complexity but also often lacks interpretability when handling mixed-domain inputs.\n  Building upon the premise that ``Compression is Intelligence,'' this paper proposes a novel architectural philosophy: Compression is Routing. We trained an 87M-parameter end-to-end Transformer Autoencoder, achieving a 64x sequence length compression (compressing 512 tokens into 8 latent vectors). Experimental results demonstrate that this compressor possesses extreme domain discriminative capability: it achieves a reconstruction accuracy of 99.47% on the in-domain (code) validation set; accuracy drops sharply to 47.76% on a semi-out-of-distribution domain (Wiki text); and further plummets to just 0.57% on a fully out-of-distribution domain (random sequences).\n  This extreme and systematic performance discrepancy establishes the validity of reconstruction error as an Intrinsic Distribution Fingerprint. Based on this, we propose that expert modules can be automatically scheduled using reconstruction residuals directly, without the need for explicit gating networks. This mechanism offers excellent scalability. Furthermore, this architecture provides a new perspective on ``VRAM compression'' for handling ultra-long contexts. This report aims to verify the physical validity of this foundational architecture, offering a new research perspective for the next generation of scalable modular neural networks.",
    "published": "2025-12-18T09:02:03Z",
    "updated": "2025-12-22T05:58:51Z",
    "link": "http://arxiv.org/pdf/2512.16963v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Zhongpan Tang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19057v1",
    "title": "Efficient Personalization of Generative Models via Optimal Experimental Design",
    "summary": "Preference learning from human feedback has the ability to align generative models with the needs of end-users. Human feedback is costly and time-consuming to obtain, which creates demand for data-efficient query selection methods. This work presents a novel approach that leverages optimal experimental design to ask humans the most informative preference queries, from which we can elucidate the latent reward function modeling user preferences efficiently. We formulate the problem of preference query selection as the one that maximizes the information about the underlying latent preference model. We show that this problem has a convex optimization formulation, and introduce a statistically and computationally efficient algorithm ED-PBRL that is supported by theoretical guarantees and can efficiently construct structured queries such as images or text. We empirically present the proposed framework by personalizing a text-to-image generative model to user-specific styles, showing that it requires less preference queries compared to random query selection.",
    "published": "2025-12-22T05:47:25Z",
    "updated": "2025-12-22T05:47:25Z",
    "link": "http://arxiv.org/pdf/2512.19057v1.pdf",
    "category": [
      "cs.LG",
      "cs.IT"
    ],
    "authors": [
      "Guy Schacht",
      "Ziyad Sheebaelhamd",
      "Riccardo De Santi",
      "Mojmír Mutný",
      "Andreas Krause"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.22714v2",
    "title": "Libra: Unleashing GPU Heterogeneity for High-Performance Sparse Matrix Multiplication",
    "summary": "Sparse matrix multiplication operators (i.e., SpMM and SDDMM) are widely used in deep learning and scientific computing. Modern accelerators are commonly equipped with Tensor Core Units (TCUs) and CUDA cores to accelerate sparse operators. The former excels at structured matrix computations, whereas the latter offers greater programming flexibility. However, how to combine these two resources to maximize sparse-operator performance remains unclear. In this work, we first identify the source of performance gains in hybrid computation and systematically analyze their complementary strengths. Motivated by this, we propose Libra, a holistic framework that efficiently leverages heterogeneous computing resources to accelerate both SpMM and SDDMM operators. Specifically, Libra introduces a 2D-aware (locality and utilization) workload distribution method to precisely identify the optimal task mapping, simultaneously leveraging the data reuse capabilities of TCUs and the flexibility of CUDA cores to minimize computational redundancy. Libra further incorporates hybrid load balancing, occupancy-aware task scheduling, and efficient kernel implementations to maximize execution efficiency. Extensive experiments on H100 and RTX 4090 GPUs demonstrate that Libra surpasses all the 12 up-to-date baselines significantly, e.g., on average 1.77x speedup over FlashSparse, 1.73x over RoDe, and 2.9x over DGL for end-to-end GNN applications. Libra opens up a new perspective for sparse operator acceleration by fully unleashing the power of heterogeneous GPU resources.",
    "published": "2025-06-28T01:50:13Z",
    "updated": "2025-12-22T05:47:00Z",
    "link": "http://arxiv.org/pdf/2506.22714v2.pdf",
    "category": [
      "cs.DC",
      "cs.LG",
      "cs.PF"
    ],
    "authors": [
      "Jinliang Shi",
      "Shigang Li",
      "Youxuan Xu",
      "Xueying Wang",
      "Rongtian Fu",
      "Zhi Ma",
      "Tong Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19038v1",
    "title": "Time-series Forecast for Indoor Zone Air Temperature with Long Horizons: A Case Study with Sensor-based Data from a Smart Building",
    "summary": "With the press of global climate change, extreme weather and sudden weather changes are becoming increasingly common. To maintain a comfortable indoor environment and minimize the contribution of the building to climate change as much as possible, higher requirements are placed on the operation and control of HVAC systems, e.g., more energy-efficient and flexible to response to the rapid change of weather. This places demands on the rapid modeling and prediction of zone air temperatures of buildings. Compared to the traditional simulation-based approach such as EnergyPlus and DOE2, a hybrid approach combined physics and data-driven is more suitable. Recently, the availability of high-quality datasets and algorithmic breakthroughs have driven a considerable amount of work in this field. However, in the niche of short- and long-term predictions, there are still some gaps in existing research. This paper aims to develop a time series forecast model to predict the zone air temperature in a building located in America on a 2-week horizon. The findings could be further improved to support intelligent control and operation of HVAC systems (i.e. demand flexibility) and could also be used as hybrid building energy modeling.",
    "published": "2025-12-22T05:19:05Z",
    "updated": "2025-12-22T05:19:05Z",
    "link": "http://arxiv.org/pdf/2512.19038v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Liping Sun",
      "Yucheng Guo",
      "Siliang Lu",
      "Zhenzhen Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19037v1",
    "title": "Elevating Intrusion Detection and Security Fortification in Intelligent Networks through Cutting-Edge Machine Learning Paradigms",
    "summary": "The proliferation of IoT devices and their reliance on Wi-Fi networks have introduced significant security vulnerabilities, particularly the KRACK and Kr00k attacks, which exploit weaknesses in WPA2 encryption to intercept and manipulate sensitive data. Traditional IDS using classifiers face challenges such as model overfitting, incomplete feature extraction, and high false positive rates, limiting their effectiveness in real-world deployments. To address these challenges, this study proposes a robust multiclass machine learning based intrusion detection framework. The methodology integrates advanced feature selection techniques to identify critical attributes, mitigating redundancy and enhancing detection accuracy. Two distinct ML architectures are implemented: a baseline classifier pipeline and a stacked ensemble model combining noise injection, Principal Component Analysis (PCA), and meta learning to improve generalization and reduce false positives. Evaluated on the AWID3 data set, the proposed ensemble architecture achieves superior performance, with an accuracy of 98%, precision of 98%, recall of 98%, and a false positive rate of just 2%, outperforming existing state-of-the-art methods. This work demonstrates the efficacy of combining preprocessing strategies with ensemble learning to fortify network security against sophisticated Wi-Fi attacks, offering a scalable and reliable solution for IoT environments. Future directions include real-time deployment and adversarial resilience testing to further enhance the model's adaptability.",
    "published": "2025-12-22T05:14:26Z",
    "updated": "2025-12-22T05:14:26Z",
    "link": "http://arxiv.org/pdf/2512.19037v1.pdf",
    "category": [
      "cs.CR",
      "cs.LG"
    ],
    "authors": [
      "Md Minhazul Islam Munna",
      "Md Mahbubur Rahman",
      "Jaroslav Frnda",
      "Muhammad Shahid Anwar",
      "Alpamis Kutlimuratov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19031v1",
    "title": "A Surrogate-Augmented Symbolic CFD-Driven Training Framework for Accelerating Multi-objective Physical Model Development",
    "summary": "Computational Fluid Dynamics (CFD)-driven training combines machine learning (ML) with CFD solvers to develop physically consistent closure models with improved predictive accuracy. In the original framework, each ML-generated candidate model is embedded in a CFD solver and evaluated against reference data, requiring hundreds to thousands of high-fidelity simulations and resulting in prohibitive computational cost for complex flows. To overcome this limitation, we propose an extended framework that integrates surrogate modeling into symbolic CFD-driven training in real time to reduce training cost. The surrogate model learns to approximate the errors of ML-generated models based on previous CFD evaluations and is continuously refined during training. Newly generated models are first assessed using the surrogate, and only those predicted to yield small errors or high uncertainty are subsequently evaluated with full CFD simulations. Discrete expressions generated by symbolic regression are mapped into a continuous space using averaged input-symbol values as inputs to a probabilistic surrogate model. To support multi-objective model training, particularly when fixed weighting of competing quantities is challenging, the surrogate is extended to a multi-output formulation by generalizing the kernel to a matrix form, providing one mean and variance prediction per training objective. Selection metrics based on these probabilistic outputs are used to identify an optimal training setup. The proposed surrogate-augmented CFD-driven training framework is demonstrated across a range of statistically one- and two-dimensional flows, including both single- and multi-expression model optimization. In all cases, the framework substantially reduces training cost while maintaining predictive accuracy comparable to that of the original CFD-driven approach.",
    "published": "2025-12-22T05:04:09Z",
    "updated": "2025-12-22T05:04:09Z",
    "link": "http://arxiv.org/pdf/2512.19031v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Yuan Fang",
      "Fabian Waschkowski",
      "Maximilian Reissmann",
      "Richard D. Sandberg",
      "Takuo Oda",
      "Koichi Tanimoto"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19130v1",
    "title": "D$^{2}$Stream: Decoupled Dual-Stream Temporal-Speaker Interaction for Audio-Visual Speaker Detection",
    "summary": "Audio-visual speaker detection aims to identify the active speaker in videos by leveraging complementary audio and visual cues. Existing methods often suffer from computational inefficiency or suboptimal performance due to joint modeling of temporal and speaker interactions. We propose D$^{2}$Stream, a decoupled dual-stream framework that separates cross-frame temporal modeling from within-frame speaker discrimination. Audio and visual features are first aligned via cross-modal attention, then fed into two lightweight streams: a Temporal Interaction Stream captures long-range temporal dependencies, while a Speaker Interaction Stream models per-frame inter-person relationships. The temporal and relational features extracted by the two streams interact via cross-attention to enrich representations. A lightweight Voice Gate module further mitigates false positives from non-speech facial movements. On AVA-ActiveSpeaker, D$^{2}$Stream achieves a new state-of-the-art at 95.6% mAP, with 80% reduction in computation compared to GNN-based models and 30% fewer parameters than attention-based alternatives, while also generalizing well on Columbia ASD. Source code is available at https://anonymous.4open.science/r/D2STREAM.",
    "published": "2025-12-22T08:21:22Z",
    "updated": "2025-12-22T08:21:22Z",
    "link": "http://arxiv.org/pdf/2512.19130v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Junhao Xiao",
      "Shun Feng",
      "Zhiyu Wu",
      "Jianjun Li",
      "Zhiyuan Ma",
      "Yi Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.00898v2",
    "title": "Empowering LLMs with Structural Role Inference for Zero-Shot Graph Learning",
    "summary": "Large Language Models have emerged as a promising approach for graph learning due to their powerful reasoning capabilities. However, existing methods exhibit systematic performance degradation on structurally important nodes such as bridges and hubs. We identify the root cause of these limitations. Current approaches encode graph topology into static features but lack reasoning scaffolds to transform topological patterns into role-based interpretations. This limitation becomes critical in zero-shot scenarios where no training data establishes structure-semantics mappings. To address this gap, we propose DuoGLM, a training-free dual-perspective framework for structure-aware graph reasoning. The local perspective constructs relation-aware templates capturing semantic interactions between nodes and neighbors. The global perspective performs topology-to-role inference to generate functional descriptions of structural positions. These complementary perspectives provide explicit reasoning mechanisms enabling LLMs to distinguish topologically similar but semantically different nodes. Extensive experiments across eight benchmark datasets demonstrate substantial improvements. DuoGLM achieves 14.3\\% accuracy gain in zero-shot node classification and 7.6\\% AUC improvement in cross-domain transfer compared to existing methods. The results validate the effectiveness of explicit role reasoning for graph understanding with LLMs.",
    "published": "2025-11-02T11:33:14Z",
    "updated": "2025-12-22T18:21:46Z",
    "link": "http://arxiv.org/pdf/2511.00898v2.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Heng Zhang",
      "Jing Liu",
      "Jiajun Wu",
      "Haochen You",
      "Lubin Gan",
      "Yuling Shi",
      "Xiaodong Gu",
      "Zijian Zhang",
      "Shuai Chen",
      "Wenjun Huang",
      "Jin Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.10611v2",
    "title": "HyperAgent: Leveraging Hypergraphs for Topology Optimization in Multi-Agent Communication",
    "summary": "Recent advances in large language model-powered multi-agent systems have demonstrated remarkable collective intelligence through effective communication. However, existing approaches face two primary challenges: (i) \\textit{Ineffective group collaboration modeling}, as they rely on pairwise edge representations in graph structures, limiting their ability to capture relationships among multiple agents; and (ii) \\textit{Limited task-adaptiveness in communication topology design}, leading to excessive communication cost for simple tasks and insufficient coordination for complex scenarios. These issues restrict the scalability and practical deployment of adaptive collaboration frameworks. To address these challenges, we propose \\textbf{HyperAgent}, a hypergraph-based framework that optimizes communication topologies and effectively captures group collaboration patterns using direct hyperedge representations. Unlike edge-based approaches, HyperAgent uses hyperedges to link multiple agents within the same subtask and employs hypergraph convolutional layers to achieve one-step information aggregation in collaboration groups. Additionally, it incorporates a variational autoencoder framework with sparsity regularization to dynamically adjust hypergraph topologies based on task complexity. Experiments highlight the superiority of HyperAgent in both performance and efficiency. For instance, on GSM8K, HyperAgent achieves 95.07\\% accuracy while reducing token consumption by 25.33\\%, demonstrating the potential of hypergraph-based optimization for multi-agent communication.",
    "published": "2025-10-12T13:47:42Z",
    "updated": "2025-12-22T18:20:47Z",
    "link": "http://arxiv.org/pdf/2510.10611v2.pdf",
    "category": [
      "cs.MA",
      "cs.GR"
    ],
    "authors": [
      "Heng Zhang",
      "Yuling Shi",
      "Xiaodong Gu",
      "Zijian Zhang",
      "Haochen You",
      "Lubin Gan",
      "Yilei Yuan",
      "Jin Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.10585v2",
    "title": "D3MAS: Decompose, Deduce, and Distribute for Enhanced Knowledge Sharing in Multi-Agent Systems",
    "summary": "Multi-agent systems powered by large language models exhibit strong capabilities in collaborative problem-solving. However, these systems suffer from substantial knowledge redundancy. Agents duplicate efforts in retrieval and reasoning processes. This inefficiency stems from a deeper issue: current architectures lack mechanisms to ensure agents share minimal sufficient information at each operational stage. Empirical analysis reveals an average knowledge duplication rate of 47.3\\% across agent communications. We propose D3MAS (Decompose, Deduce, and Distribute), a hierarchical coordination framework addressing redundancy through structural design rather than explicit optimization. The framework organizes collaboration across three coordinated layers. Task decomposition filters irrelevant sub-problems early. Collaborative reasoning captures complementary inference paths across agents. Distributed memory provides access to non-redundant knowledge. These layers coordinate through structured message passing in a unified heterogeneous graph. This cross-layer alignment ensures information remains aligned with actual task needs. Experiments on four challenging datasets show that D3MAS consistently improves reasoning accuracy by 8.7\\% to 15.6\\% and reduces knowledge redundancy by 46\\% on average.",
    "published": "2025-10-12T13:01:41Z",
    "updated": "2025-12-22T18:20:32Z",
    "link": "http://arxiv.org/pdf/2510.10585v2.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Heng Zhang",
      "Yuling Shi",
      "Xiaodong Gu",
      "Haochen You",
      "Zijian Zhang",
      "Lubin Gan",
      "Yilei Yuan",
      "Jin Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.10581v2",
    "title": "GraphTracer: Graph-Guided Failure Tracing in LLM Agents for Robust Multi-Turn Deep Search",
    "summary": "Multi-agent systems powered by Large Language Models excel at complex tasks through coordinated collaboration, yet they face high failure rates in multi-turn deep search scenarios. Existing temporal attribution methods struggle to accurately diagnose root causes, particularly when errors propagate across multiple agents. Attempts to automate failure attribution by analyzing action sequences remain ineffective due to their inability to account for information dependencies that span agents. This paper identifies two core challenges: \\textit{(i) distinguishing symptoms from root causes in multi-agent error propagation}, and \\textit{(ii) tracing information dependencies beyond temporal order}. To address these issues, we introduce \\textbf{GraphTracer}, a framework that redefines failure attribution through information flow analysis. GraphTracer constructs Information Dependency Graphs (IDGs) to explicitly capture how agents reference and build on prior outputs. It localizes root causes by tracing through these dependency structures instead of relying on temporal sequences. GraphTracer also uses graph-aware synthetic data generation to target critical nodes, creating realistic failure scenarios. Evaluations on the Who\\&When benchmark and integration into production systems demonstrate that GraphTracer-8B achieves up to 18.18\\% higher attribution accuracy compared to state-of-the-art models and enables 4.8\\% to 14.2\\% performance improvements in deployed multi-agent frameworks, establishing a robust solution for multi-agent system debugging.",
    "published": "2025-10-12T12:55:42Z",
    "updated": "2025-12-22T18:19:37Z",
    "link": "http://arxiv.org/pdf/2510.10581v2.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Heng Zhang",
      "Yuling Shi",
      "Xiaodong Gu",
      "Haochen You",
      "Zijian Zhang",
      "Lubin Gan",
      "Yilei Yuan",
      "Jin Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.00911v2",
    "title": "G2rammar: Bilingual Grammar Modeling for Enhanced Text-attributed Graph Learning",
    "summary": "Text-attributed graphs require models to effectively integrate both structural topology and semantic content. Recent approaches apply large language models to graphs by linearizing structures into token sequences through random walks. These methods create concise graph vocabularies to replace verbose natural language descriptions. However, they overlook a critical component that makes language expressive: grammar. In natural language, grammar assigns syntactic roles to words and defines their functions within sentences. Similarly, nodes in graphs play distinct structural roles as hubs, bridges, or peripheral members. Current graph language methods provide tokens without grammatical annotations to indicate these structural or semantic roles. This absence limits language models' ability to reason about graph topology effectively. We propose \\textbf{G2rammar}, a bilingual grammar framework that explicitly encodes both structural and semantic grammar for text-attributed graphs. Structural grammar characterizes topological roles through centrality and neighborhood patterns. Semantic grammar captures content relationships through textual informativity. The framework implements two-stage learning with structural grammar pre-training followed by semantic grammar fine-tuning. Extensive experiments on real-world datasets demonstrate that G2rammar consistently outperforms competitive baselines by providing language models with the grammatical context needed to understand graph structures.",
    "published": "2025-11-02T12:06:56Z",
    "updated": "2025-12-22T18:18:58Z",
    "link": "http://arxiv.org/pdf/2511.00911v2.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Heng Zheng",
      "Haochen You",
      "Zijun Liu",
      "Zijian Zhang",
      "Lubin Gan",
      "Hao Zhang",
      "Wenjun Huang",
      "Jin Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19583v1",
    "title": "Learning Generalizable Hand-Object Tracking from Synthetic Demonstrations",
    "summary": "We present a system for learning generalizable hand-object tracking controllers purely from synthetic data, without requiring any human demonstrations. Our approach makes two key contributions: (1) HOP, a Hand-Object Planner, which can synthesize diverse hand-object trajectories; and (2) HOT, a Hand-Object Tracker that bridges synthetic-to-physical transfer through reinforcement learning and interaction imitation learning, delivering a generalizable controller conditioned on target hand-object states. Our method extends to diverse object shapes and hand morphologies. Through extensive evaluations, we show that our approach enables dexterous hands to track challenging, long-horizon sequences including object re-arrangement and agile in-hand reorientation. These results represent a significant step toward scalable foundation controllers for manipulation that can learn entirely from synthetic data, breaking the data bottleneck that has long constrained progress in dexterous manipulation.",
    "published": "2025-12-22T17:08:54Z",
    "updated": "2025-12-22T17:08:54Z",
    "link": "http://arxiv.org/pdf/2512.19583v1.pdf",
    "category": [
      "cs.RO",
      "cs.GR"
    ],
    "authors": [
      "Yinhuai Wang",
      "Runyi Yu",
      "Hok Wai Tsui",
      "Xiaoyi Lin",
      "Hui Zhang",
      "Qihan Zhao",
      "Ke Fan",
      "Miao Li",
      "Jie Song",
      "Jingbo Wang",
      "Qifeng Chen",
      "Ping Tan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.17440v2",
    "title": "Four special Poncelet triangle families about the incircle",
    "summary": "We describe four special families of ellipse-inscribed Poncelet triangles about the incircle which maintain certain triangle centers stationary and which also display interesting conservations.",
    "published": "2025-12-19T10:50:17Z",
    "updated": "2025-12-22T10:05:12Z",
    "link": "http://arxiv.org/pdf/2512.17440v2.pdf",
    "category": [
      "math.MG",
      "cs.GR"
    ],
    "authors": [
      "Ronaldo A. Garcia",
      "Mark Helman",
      "Dan Reznik"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19567v1",
    "title": "LIMOncello: Revisited IKFoM on the SGal(3) Manifold for Fast LiDAR-Inertial Odometry",
    "summary": "This work introduces LIMOncello, a tightly coupled LiDAR-Inertial Odometry system that models 6-DoF motion on the $\\mathrm{SGal}(3)$ manifold within an iterated error-state Kalman filter backend. Compared to state representations defined on $\\mathrm{SO}(3)\\times\\mathbb{R}^6$, the use of $\\mathrm{SGal}(3)$ provides a coherent and numerically stable discrete-time propagation model that helps limit drift in low-observability conditions.\n  LIMOncello also includes a lightweight incremental i-Octree mapping backend that enables faster updates and substantially lower memory usage than incremental kd-tree style map structures, without relying on locality-restricted search heuristics. Experiments on multiple real-world datasets show that LIMOncello achieves competitive accuracy while improving robustness in geometrically sparse environments. The system maintains real-time performance with stable memory growth and is released as an extensible open-source implementation at https://github.com/CPerezRuiz335/LIMOncello.",
    "published": "2025-12-22T16:50:10Z",
    "updated": "2025-12-22T16:50:10Z",
    "link": "http://arxiv.org/pdf/2512.19567v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Carlos Pérez-Ruiz",
      "Joan Solà"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.17136v2",
    "title": "Towards Senior-Robot Interaction: Reactive Robot Dog Gestures",
    "summary": "As the global population ages, many seniors face the problem of loneliness. Companion robots offer a potential solution. However, current companion robots often lack advanced functionality, while task-oriented robots are not designed for social interaction, limiting their suitability and acceptance by seniors. Our work introduces a senior-oriented system for quadruped robots that allows for more intuitive user input and provides more socially expressive output. For user input, we implemented a MediaPipe-based module for hand gesture and head movement recognition, enabling control without a remote. For output, we designed and trained robotic dog gestures using curriculum-based reinforcement learning in Isaac Gym, progressing from simple standing to three-legged balancing and leg extensions, and more. The final tests achieved over 95\\% success on average in simulation, and we validated a key social gesture (the paw-lift) on a Unitree robot. Real-world tests demonstrated the feasibility and social expressiveness of this framework, while also revealing sim-to-real challenges in joint compliance, load distribution, and balance control. These contributions advance the development of practical quadruped robots as social companions for the senior and outline pathways for sim-to-real adaptation and inform future user studies.",
    "published": "2025-12-19T00:09:18Z",
    "updated": "2025-12-22T15:50:31Z",
    "link": "http://arxiv.org/pdf/2512.17136v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Chunyang Meng",
      "Eduardo B. Sandoval",
      "Ricardo Sosa",
      "Francisco Cruz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19453v1",
    "title": "MaP-AVR: A Meta-Action Planner for Agents Leveraging Vision Language Models and Retrieval-Augmented Generation",
    "summary": "Embodied robotic AI systems designed to manage complex daily tasks rely on a task planner to understand and decompose high-level tasks. While most research focuses on enhancing the task-understanding abilities of LLMs/VLMs through fine-tuning or chain-of-thought prompting, this paper argues that defining the planned skill set is equally crucial. To handle the complexity of daily environments, the skill set should possess a high degree of generalization ability. Empirically, more abstract expressions tend to be more generalizable. Therefore, we propose to abstract the planned result as a set of meta-actions. Each meta-action comprises three components: {move/rotate, end-effector status change, relationship with the environment}. This abstraction replaces human-centric concepts, such as grasping or pushing, with the robot's intrinsic functionalities. As a result, the planned outcomes align seamlessly with the complete range of actions that the robot is capable of performing. Furthermore, to ensure that the LLM/VLM accurately produces the desired meta-action format, we employ the Retrieval-Augmented Generation (RAG) technique, which leverages a database of human-annotated planning demonstrations to facilitate in-context learning. As the system successfully completes more tasks, the database will self-augment to continue supporting diversity. The meta-action set and its integration with RAG are two novel contributions of our planner, denoted as MaP-AVR, the meta-action planner for agents composed of VLM and RAG. To validate its efficacy, we design experiments using GPT-4o as the pre-trained LLM/VLM model and OmniGibson as our robotic platform. Our approach demonstrates promising performance compared to the current state-of-the-art method. Project page: https://map-avr.github.io/.",
    "published": "2025-12-22T14:58:52Z",
    "updated": "2025-12-22T14:58:52Z",
    "link": "http://arxiv.org/pdf/2512.19453v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Zhenglong Guo",
      "Yiming Zhao",
      "Feng Jiang",
      "Heng Jin",
      "Zongbao Feng",
      "Jianbin Zhou",
      "Siyuan Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19408v1",
    "title": "Mixed formulation and structure-preserving discretization of Cosserat rod dynamics in a port-Hamiltonian framework",
    "summary": "An energy-based modeling framework for the nonlinear dynamics of spatial Cosserat rods undergoing large displacements and rotations is proposed. The mixed formulation features independent displacement, velocity and stress variables and is further objective and locking-free. Finite rotations are represented using a director formulation that avoids singularities and yields a constant mass matrix. This results in an infinite-dimensional nonlinear port-Hamiltonian (PH) system governed by partial differential-algebraic equations with a quadratic energy functional. Using a time-differentiated compliance form of the stress-strain relations allows for the imposition of kinematic constraints, such as inextensibility or shear-rigidity. A structure-preserving finite element discretization leads to a finite-dimensional system with PH structure, thus facilitating the design of an energy-momentum consistent integration scheme. Dissipative material behavior (via the generalized-Maxwell model) and non-standard actuation approaches (via pneumatic chambers or tendons) integrate naturally into the framework. As illustrated by selected numerical examples, the present framework establishes a new approach to energy-momentum consistent formulations in computational mechanics involving finite rotations.",
    "published": "2025-12-22T14:04:03Z",
    "updated": "2025-12-22T14:04:03Z",
    "link": "http://arxiv.org/pdf/2512.19408v1.pdf",
    "category": [
      "math.NA",
      "cs.CE",
      "cs.RO",
      "eess.SY",
      "math.DS"
    ],
    "authors": [
      "Philipp L. Kinon",
      "Simon R. Eugster",
      "Peter Betsch"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19347v1",
    "title": "OMP: One-step Meanflow Policy with Directional Alignment",
    "summary": "Robot manipulation, a key capability of embodied AI, has turned to data-driven generative policy frameworks, but mainstream approaches like Diffusion Models suffer from high inference latency and Flow-based Methods from increased architectural complexity. While simply applying meanFlow on robotic tasks achieves single-step inference and outperforms FlowPolicy, it lacks few-shot generalization due to fixed temperature hyperparameters in its Dispersive Loss and misaligned predicted-true mean velocities. To solve these issues, this study proposes an improved MeanFlow-based Policies: we introduce a lightweight Cosine Loss to align velocity directions and use the Differential Derivation Equation (DDE) to optimize the Jacobian-Vector Product (JVP) operator. Experiments on Adroit and Meta-World tasks show the proposed method outperforms MP1 and FlowPolicy in average success rate, especially in challenging Meta-World tasks, effectively enhancing few-shot generalization and trajectory accuracy of robot manipulation policies while maintaining real-time performance, offering a more robust solution for high-precision robotic manipulation.",
    "published": "2025-12-22T12:45:35Z",
    "updated": "2025-12-22T12:45:35Z",
    "link": "http://arxiv.org/pdf/2512.19347v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Han Fang",
      "Yize Huang",
      "Yuheng Zhao",
      "Paul Weng",
      "Xiao Li",
      "Yutong Ban"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19289v1",
    "title": "Comparison and Evaluation of Different Simulation Environments for Rigid Body Systems",
    "summary": "Rigid body dynamics simulators are important tools for the design, analysis and optimization of mechanical systems in a variety of technical and scientific applications. This study examines four different simulation environments (Adams, Simscape, OpenModelica, and VEROSIM), focusing in particular on the comparison of the modeling methods, the numerical solvers, and the treatment of numerical problems that arise especially in closed-loop kinematics (esp. redundant boundary conditions and static equilibrium problem). A novel and complex crane boom of a real forestry machine serves as a practical benchmark application example. The direct comparison of the different solution approaches in the examined simulation tools supports the user in selecting the most suitable tool for his application.",
    "published": "2025-12-22T11:31:50Z",
    "updated": "2025-12-22T11:31:50Z",
    "link": "http://arxiv.org/pdf/2512.19289v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Longxiang Shao",
      "Ulrich Dahmen",
      "Juergen Rossmann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19270v1",
    "title": "Are All Data Necessary? Efficient Data Pruning for Large-scale Autonomous Driving Dataset via Trajectory Entropy Maximization",
    "summary": "Collecting large-scale naturalistic driving data is essential for training robust autonomous driving planners. However, real-world datasets often contain a substantial amount of repetitive and low-value samples, which lead to excessive storage costs and bring limited benefits to policy learning. To address this issue, we propose an information-theoretic data pruning method that effectively reduces the training data volume without compromising model performance. Our approach evaluates the trajectory distribution information entropy of driving data and iteratively selects high-value samples that preserve the statistical characteristics of the original dataset in a model-agnostic manner. From a theoretical perspective, we show that maximizing trajectory entropy effectively constrains the Kullback-Leibler divergence between the pruned subset and the original data distribution, thereby maintaining generalization ability. Comprehensive experiments on the NuPlan benchmark with a large-scale imitation learning framework demonstrate that the proposed method can reduce the dataset size by up to 40% while maintaining closed-loop performance. This work provides a lightweight and theoretically grounded approach for scalable data management and efficient policy learning in autonomous driving systems.",
    "published": "2025-12-22T11:07:18Z",
    "updated": "2025-12-22T11:07:18Z",
    "link": "http://arxiv.org/pdf/2512.19270v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Zhaoyang Liu",
      "Weitao Zhou",
      "Junze Wen",
      "Cheng Jing",
      "Qian Cheng",
      "Kun Jiang",
      "Diange Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19245v1",
    "title": "Vision-Aided Relative State Estimation for Approach and Landing on a Moving Platform with Inertial Measurements",
    "summary": "This paper tackles the problem of estimating the relative position, orientation, and velocity between a UAV and a planar platform undergoing arbitrary 3D motion during approach and landing. The estimation relies on measurements from Inertial Measurement Units (IMUs) mounted on both systems, assuming there is a suitable communication channel to exchange data, together with visual information provided by an onboard monocular camera, from which the bearing (line-of-sight direction) to the platform's center and the normal vector of its planar surface are extracted. We propose a cascade observer with a complementary filter on SO(3) to reconstruct the relative attitude, followed by a linear Riccati observer for relative position and velocity estimation. Convergence of both observers is established under persistently exciting conditions, and the cascade is shown to be almost globally asymptotically and locally exponentially stable. We further extend the design to the case where the platform's rotation is restricted to its normal axis and show that its measured linear acceleration can be exploited to recover the remaining unobservable rotation angle. A sufficient condition to ensure local exponential convergence in this setting is provided. The performance of the proposed observers is validated through extensive simulations.",
    "published": "2025-12-22T10:28:20Z",
    "updated": "2025-12-22T10:28:20Z",
    "link": "http://arxiv.org/pdf/2512.19245v1.pdf",
    "category": [
      "eess.SY",
      "cs.RO"
    ],
    "authors": [
      "Tarek Bouazza",
      "Alessandro Melis",
      "Soulaimane Berkane",
      "Robert Mahony",
      "Tarek Hamel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19148v1",
    "title": "A Flexible Field-Based Policy Learning Framework for Diverse Robotic Systems and Sensors",
    "summary": "We present a cross robot visuomotor learning framework that integrates diffusion policy based control with 3D semantic scene representations from D3Fields to enable category level generalization in manipulation. Its modular design supports diverse robot camera configurations including UR5 arms with Microsoft Azure Kinect arrays and bimanual manipulators with Intel RealSense sensors through a low latency control stack and intuitive teleoperation. A unified configuration layer enables seamless switching between setups for flexible data collection training and evaluation. In a grasp and lift block task the framework achieved an 80 percent success rate after only 100 demonstration episodes demonstrating robust skill transfer between platforms and sensing modalities. This design paves the way for scalable real world studies in cross robotic generalization.",
    "published": "2025-12-22T08:45:33Z",
    "updated": "2025-12-22T08:45:33Z",
    "link": "http://arxiv.org/pdf/2512.19148v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Jose Gustavo Buenaventura Carreon",
      "Floris Erich",
      "Roman Mykhailyshyn",
      "Tomohiro Motoda",
      "Ryo Hanai",
      "Yukiyasu Domae"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19083v1",
    "title": "CoDrone: Autonomous Drone Navigation Assisted by Edge and Cloud Foundation Models",
    "summary": "Autonomous navigation for Unmanned Aerial Vehicles faces key challenges from limited onboard computational resources, which restrict deployed deep neural networks to shallow architectures incapable of handling complex environments. Offloading tasks to remote edge servers introduces high latency, creating an inherent trade-off in system design. To address these limitations, we propose CoDrone - the first cloud-edge-end collaborative computing framework integrating foundation models into autonomous UAV cruising scenarios - effectively leveraging foundation models to enhance performance of resource-constrained unmanned aerial vehicle platforms. To reduce onboard computation and data transmission overhead, CoDrone employs grayscale imagery for the navigation model. When enhanced environmental perception is required, CoDrone leverages the edge-assisted foundation model Depth Anything V2 for depth estimation and introduces a novel one-dimensional occupancy grid-based navigation method - enabling fine-grained scene understanding while advancing efficiency and representational simplicity of autonomous navigation. A key component of CoDrone is a Deep Reinforcement Learning-based neural scheduler that seamlessly integrates depth estimation with autonomous navigation decisions, enabling real-time adaptation to dynamic environments. Furthermore, the framework introduces a UAV-specific vision language interaction module incorporating domain-tailored low-level flight primitives to enable effective interaction between the cloud foundation model and the UAV. The introduction of VLM enhances open-set reasoning capabilities in complex unseen scenarios. Experimental results show CoDrone outperforms baseline methods under varying flight speeds and network conditions, achieving a 40% increase in average flight distance and a 5% improvement in average Quality of Navigation.",
    "published": "2025-12-22T06:48:12Z",
    "updated": "2025-12-22T06:48:12Z",
    "link": "http://arxiv.org/pdf/2512.19083v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Pengyu Chen",
      "Tao Ouyang",
      "Ke Luo",
      "Weijie Hong",
      "Xu Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.08817v2",
    "title": "Geometric Data-Driven Multi-Jet Locomotion Inspired by Salps",
    "summary": "Salps are marine animals consisting of chains of jellyfish-like units. Their efficient underwater locomotion by coordinating multi-jet propulsion has aroused great interest in robotics. This paper presents a geometric mechanics framework for salp-inspired robots. We study a new type of geometric mechanics models inspired by salps, in which control inputs are not restricted to the shape axes, analyze nonlinear controllability, and develop motion planning and feedback control methods. We introduce the \"LandSalp\" robot, which serves as a physical realization of the reduced-order, drag-dominated model of salp swimming, enabling controlled evaluation of locomotion strategies without many confounding factors of underwater experiments. We extend least-squares- and inverse-dynamics-based system identification to learn the Riemannian metric of the drag-dominated model from experimental data using Lie group differentiation. With about three minutes of data, we identify an accurate model of LandSalp. Simulation and hardware experiments demonstrate omnidirectional locomotion, shape regulation, and bending maneuvers, providing a principled pathway toward more capable salp-inspired robots.",
    "published": "2025-03-11T18:51:12Z",
    "updated": "2025-12-22T06:37:08Z",
    "link": "http://arxiv.org/pdf/2503.08817v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Yanhao Yang",
      "Nina L. Hecht",
      "Yousef Salaman-Maclara",
      "Nathan Justus",
      "Zachary A. Thomas",
      "Farhan Rozaidi",
      "Ross L. Hatton"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.19043v1",
    "title": "EGM: Efficiently Learning General Motion Tracking Policy for High Dynamic Humanoid Whole-Body Control",
    "summary": "Learning a general motion tracking policy from human motions shows great potential for versatile humanoid whole-body control. Conventional approaches are not only inefficient in data utilization and training processes but also exhibit limited performance when tracking highly dynamic motions. To address these challenges, we propose EGM, a framework that enables efficient learning of a general motion tracking policy. EGM integrates four core designs. Firstly, we introduce a Bin-based Cross-motion Curriculum Adaptive Sampling strategy to dynamically orchestrate the sampling probabilities based on tracking error of each motion bin, eficiently balancing the training process across motions with varying dificulty and durations. The sampled data is then processed by our proposed Composite Decoupled Mixture-of-Experts (CDMoE) architecture, which efficiently enhances the ability to track motions from different distributions by grouping experts separately for upper and lower body and decoupling orthogonal experts from shared experts to separately handle dedicated features and general features. Central to our approach is a key insight we identified: for training a general motion tracking policy, data quality and diversity are paramount. Building on these designs, we develop a three-stage curriculum training flow to progressively enhance the policy's robustness against disturbances. Despite training on only 4.08 hours of data, EGM generalized robustly across 49.25 hours of test motions, outperforming baselines on both routine and highly dynamic tasks.",
    "published": "2025-12-22T05:25:24Z",
    "updated": "2025-12-22T05:25:24Z",
    "link": "http://arxiv.org/pdf/2512.19043v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Chao Yang",
      "Yingkai Sun",
      "Peng Ye",
      "Xin Chen",
      "Chong Yu",
      "Tao Chen"
    ]
  }
]