[
  {
    "id": "http://arxiv.org/abs/2510.25771v1",
    "title": "Gaperon: A Peppered English-French Generative Language Model Suite",
    "summary": "We release Gaperon, a fully open suite of French-English-coding language\nmodels designed to advance transparency and reproducibility in large-scale\nmodel training. The Gaperon family includes 1.5B, 8B, and 24B parameter models\ntrained on 2-4 trillion tokens, released with all elements of the training\npipeline: French and English datasets filtered with a neural quality\nclassifier, an efficient data curation and training framework, and hundreds of\nintermediate checkpoints. Through this work, we study how data filtering and\ncontamination interact to shape both benchmark and generative performance. We\nfind that filtering for linguistic quality enhances text fluency and coherence\nbut yields subpar benchmark results, and that late deliberate contamination --\ncontinuing training on data mixes that include test sets -- recovers\ncompetitive scores while only reasonably harming generation quality. We discuss\nhow usual neural filtering can unintentionally amplify benchmark leakage. To\nsupport further research, we also introduce harmless data poisoning during\npretraining, providing a realistic testbed for safety studies. By openly\nreleasing all models, datasets, code, and checkpoints, Gaperon establishes a\nreproducible foundation for exploring the trade-offs between data curation,\nevaluation, safety, and openness in multilingual language model development.",
    "published": "2025-10-29T17:59:39Z",
    "updated": "2025-10-29T17:59:39Z",
    "link": "http://arxiv.org/pdf/2510.25771v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Nathan Godey",
      "Wissam Antoun",
      "Rian Touchent",
      "Rachel Bawden",
      "Éric de la Clergerie",
      "Benoît Sagot",
      "Djamé Seddah"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25770v1",
    "title": "E-Scores for (In)Correctness Assessment of Generative Model Outputs",
    "summary": "While generative models, especially large language models (LLMs), are\nubiquitous in today's world, principled mechanisms to assess their\n(in)correctness are limited. Using the conformal prediction framework, previous\nworks construct sets of LLM responses where the probability of including an\nincorrect response, or error, is capped at a desired user-defined tolerance\nlevel. However, since these methods are based on p-values, they are susceptible\nto p-hacking, i.e., choosing the tolerance level post-hoc can invalidate the\nguarantees. We therefore leverage e-values to complement generative model\noutputs with e-scores as a measure of incorrectness. In addition to achieving\nthe same statistical guarantees as before, e-scores provide users flexibility\nin adaptively choosing tolerance levels after observing the e-scores\nthemselves, by upper bounding a post-hoc notion of error called size\ndistortion. We experimentally demonstrate their efficacy in assessing LLM\noutputs for different correctness types: mathematical factuality and property\nconstraints satisfaction.",
    "published": "2025-10-29T17:59:16Z",
    "updated": "2025-10-29T17:59:16Z",
    "link": "http://arxiv.org/pdf/2510.25770v1.pdf",
    "category": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Guneet S. Dhillon",
      "Javier González",
      "Teodora Pandeva",
      "Alicia Curth"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.18905v2",
    "title": "3D Optimization for AI Inference Scaling: Balancing Accuracy, Cost, and\n  Latency",
    "summary": "AI inference scaling is often tuned through 1D heuristics (a fixed reasoning\npasses) or 2D bivariate trade-offs (e.g., performance vs. compute), which fail\nto consider cost and latency constraints. We introduce a 3D optimization\nframework that jointly calibrates accuracy, cost, and latency within a unified\ndecision space, enabling constraints-aware inference scaling. Using Monte Carlo\nsimulations across three representative scenarios and nine simulated large\nlanguage models, we evaluate four optimization methods to address the 3D\nmulti-objective optimization (MOO) problem. Framing inference scaling in MOO\nshapes a feasible space that 1D and 2D optimizations fail to capture, enabling\nenvironmentadaptive selection of the inference scaling k. Results show that\nknee-point optimization achieves the best balance, while accuracy-maximization\nremains favorable when precision is prioritized. The framework establishes a\ntheoretical foundation for deployment-aware inference scaling across diverse\noperational contexts.",
    "published": "2025-10-21T01:03:46Z",
    "updated": "2025-10-29T17:57:23Z",
    "link": "http://arxiv.org/pdf/2510.18905v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Minseok Jung",
      "Abhas Ricky",
      "Muhammad Rameez Chatni"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.01939v3",
    "title": "SpecCLIP: Aligning and Translating Spectroscopic Measurements for Stars",
    "summary": "In recent years, large language models (LLMs) have transformed natural\nlanguage understanding through vast datasets and large-scale parameterization.\nInspired by this success, we present SpecCLIP, a foundation model framework\nthat extends LLM-inspired methodologies to stellar spectral analysis. Stellar\nspectra, akin to structured language, encode rich physical and chemical\ninformation about stars. By training foundation models on large-scale spectral\ndatasets, our goal is to learn robust and informative embeddings that support\ndiverse downstream applications. As a proof of concept, SpecCLIP involves\npre-training on two spectral types--LAMOST low-resolution and Gaia XP--followed\nby contrastive alignment using the CLIP (Contrastive Language-Image\nPre-training) framework, adapted to associate spectra from different\ninstruments. This alignment is complemented by auxiliary decoders that preserve\nspectrum-specific information and enable translation (prediction) between\nspectral types, with the former achieved by maximizing mutual information\nbetween embeddings and input spectra. The result is a cross-spectrum framework\nenabling intrinsic calibration and flexible applications across instruments. We\ndemonstrate that fine-tuning these models on moderate-sized labeled datasets\nimproves adaptability to tasks such as stellar-parameter estimation and\nchemical-abundance determination. SpecCLIP also enhances the accuracy and\nprecision of parameter estimates benchmarked against external survey data.\nAdditionally, its similarity search and cross-spectrum prediction capabilities\noffer potential for anomaly detection. Our results suggest that contrastively\ntrained foundation models enriched with spectrum-aware decoders can advance\nprecision stellar spectroscopy.",
    "published": "2025-07-02T17:49:52Z",
    "updated": "2025-10-29T17:57:03Z",
    "link": "http://arxiv.org/pdf/2507.01939v3.pdf",
    "category": [
      "astro-ph.IM",
      "astro-ph.SR",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Xiaosheng Zhao",
      "Yang Huang",
      "Guirong Xue",
      "Xiao Kong",
      "Jifeng Liu",
      "Xiaoyu Tang",
      "Timothy C. Beers",
      "Yuan-Sen Ting",
      "A-Li Luo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25758v1",
    "title": "TheraMind: A Strategic and Adaptive Agent for Longitudinal Psychological\n  Counseling",
    "summary": "Large language models (LLMs) in psychological counseling have attracted\nincreasing attention. However, existing approaches often lack emotional\nunderstanding, adaptive strategies, and the use of therapeutic methods across\nmultiple sessions with long-term memory, leaving them far from real clinical\npractice. To address these critical gaps, we introduce TheraMind, a strategic\nand adaptive agent for longitudinal psychological counseling. The cornerstone\nof TheraMind is a novel dual-loop architecture that decouples the complex\ncounseling process into an Intra-Session Loop for tactical dialogue management\nand a Cross-Session Loop for strategic therapeutic planning. The Intra-Session\nLoop perceives the patient's emotional state to dynamically select response\nstrategies while leveraging cross-session memory to ensure continuity.\nCrucially, the Cross-Session Loop empowers the agent with long-term\nadaptability by evaluating the efficacy of the applied therapy after each\nsession and adjusting the method for subsequent interactions. We validate our\napproach in a high-fidelity simulation environment grounded in real clinical\ncases. Extensive evaluations show that TheraMind outperforms other methods,\nespecially on multi-session metrics like Coherence, Flexibility, and\nTherapeutic Attunement, validating the effectiveness of its dual-loop design in\nemulating strategic, adaptive, and longitudinal therapeutic behavior. The code\nis publicly available at https://0mwwm0.github.io/TheraMind/.",
    "published": "2025-10-29T17:54:20Z",
    "updated": "2025-10-29T17:54:20Z",
    "link": "http://arxiv.org/pdf/2510.25758v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "He Hu",
      "Yucheng Zhou",
      "Chiyuan Ma",
      "Qianning Wang",
      "Zheng Zhang",
      "Fei Ma",
      "Laizhong Cui",
      "Qi Tian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17022v2",
    "title": "Curiosity-driven RL for symbolic equation solving",
    "summary": "We explore if RL can be useful for symbolic mathematics. Previous work showed\ncontrastive learning can solve linear equations in one variable. We show\nmodel-free PPO \\cite{schulman2017proximal} augmented with curiosity-based\nexploration and graph-based actions can solve nonlinear equations such as those\ninvolving radicals, exponentials, and trig functions. Our work suggests\ncuriosity-based exploration may be useful for general symbolic reasoning tasks.",
    "published": "2025-10-19T22:04:57Z",
    "updated": "2025-10-29T17:52:01Z",
    "link": "http://arxiv.org/pdf/2510.17022v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Kevin P. O'Keeffe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25744v1",
    "title": "Task Completion Agents are Not Ideal Collaborators",
    "summary": "Current evaluations of agents remain centered around one-shot task\ncompletion, failing to account for the inherently iterative and collaborative\nnature of many real-world problems, where human goals are often underspecified\nand evolve. We argue for a shift from building and assessing task completion\nagents to developing collaborative agents, assessed not only by the quality of\ntheir final outputs but by how well they engage with and enhance human effort\nthroughout the problem-solving process. To support this shift, we introduce\ncollaborative effort scaling, a framework that captures how an agent's utility\ngrows with increasing user involvement. Through case studies and simulated\nevaluations, we show that state-of-the-art agents often underperform in\nmulti-turn, real-world scenarios, revealing a missing ingredient in agent\ndesign: the ability to sustain engagement and scaffold user understanding.\nCollaborative effort scaling offers a lens for diagnosing agent behavior and\nguiding development toward more effective interactions.",
    "published": "2025-10-29T17:47:18Z",
    "updated": "2025-10-29T17:47:18Z",
    "link": "http://arxiv.org/pdf/2510.25744v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Shannon Zejiang Shen",
      "Valerie Chen",
      "Ken Gu",
      "Alexis Ross",
      "Zixian Ma",
      "Jillian Ross",
      "Alex Gu",
      "Chenglei Si",
      "Wayne Chi",
      "Andi Peng",
      "Jocelyn J Shen",
      "Ameet Talwalkar",
      "Tongshuang Wu",
      "David Sontag"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25732v1",
    "title": "The Limits of Obliviate: Evaluating Unlearning in LLMs via\n  Stimulus-Knowledge Entanglement-Behavior Framework",
    "summary": "Unlearning in large language models (LLMs) is crucial for managing sensitive\ndata and correcting misinformation, yet evaluating its effectiveness remains an\nopen problem. We investigate whether persuasive prompting can recall factual\nknowledge from deliberately unlearned LLMs across models ranging from 2.7B to\n13B parameters (OPT-2.7B, LLaMA-2-7B, LLaMA-3.1-8B, LLaMA-2-13B). Drawing from\nACT-R and Hebbian theory (spreading activation theories), as well as\ncommunication principles, we introduce Stimulus-Knowledge Entanglement-Behavior\nFramework (SKeB), which models information entanglement via domain graphs and\ntests whether factual recall in unlearned models is correlated with persuasive\nframing. We develop entanglement metrics to quantify knowledge activation\npatterns and evaluate factuality, non-factuality, and hallucination in outputs.\nOur results show persuasive prompts substantially enhance factual knowledge\nrecall (14.8% baseline vs. 24.5% with authority framing), with effectiveness\ninversely correlated to model size (128% recovery in 2.7B vs. 15% in 13B). SKeB\nprovides a foundation for assessing unlearning completeness, robustness, and\noverall behavior in LLMs.",
    "published": "2025-10-29T17:37:50Z",
    "updated": "2025-10-29T17:37:50Z",
    "link": "http://arxiv.org/pdf/2510.25732v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "I.2.7; I.2.6; I.2.4; G.2.2"
    ],
    "authors": [
      "Aakriti Shah",
      "Thai Le"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25731v1",
    "title": "LieSolver: A PDE-constrained solver for IBVPs using Lie symmetries",
    "summary": "We introduce a method for efficiently solving initial-boundary value problems\n(IBVPs) that uses Lie symmetries to enforce the associated partial differential\nequation (PDE) exactly by construction. By leveraging symmetry transformations,\nthe model inherently incorporates the physical laws and learns solutions from\ninitial and boundary data. As a result, the loss directly measures the model's\naccuracy, leading to improved convergence. Moreover, for well-posed IBVPs, our\nmethod enables rigorous error estimation. The approach yields compact models,\nfacilitating an efficient optimization. We implement LieSolver and demonstrate\nits application to linear homogeneous PDEs with a range of initial conditions,\nshowing that it is faster and more accurate than physics-informed neural\nnetworks (PINNs). Overall, our method improves both computational efficiency\nand the reliability of predictions for PDE-constrained problems.",
    "published": "2025-10-29T17:37:27Z",
    "updated": "2025-10-29T17:37:27Z",
    "link": "http://arxiv.org/pdf/2510.25731v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA",
      "physics.comp-ph"
    ],
    "authors": [
      "René P. Klausen",
      "Ivan Timofeev",
      "Johannes Frank",
      "Jonas Naujoks",
      "Thomas Wiegand",
      "Sebastian Lapuschkin",
      "Wojciech Samek"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25729v1",
    "title": "Physics-Guided Conditional Diffusion Networks for Microwave Image\n  Reconstruction",
    "summary": "A conditional latent-diffusion based framework for solving the\nelectromagnetic inverse scattering problem associated with microwave imaging is\nintroduced. This generative machine-learning model explicitly mirrors the\nnon-uniqueness of the ill-posed inverse problem. Unlike existing inverse\nsolvers utilizing deterministic machine learning techniques that produce a\nsingle reconstruction, the proposed latent-diffusion model generates multiple\nplausible permittivity maps conditioned on measured scattered-field data,\nthereby generating several potential instances in the range-space of the\nnon-unique inverse mapping. A forward electromagnetic solver is integrated into\nthe reconstruction pipeline as a physics-based evaluation mechanism. The space\nof candidate reconstructions form a distribution of possibilities consistent\nwith the conditioning data and the member of this space yielding the lowest\nscattered-field data discrepancy between the predicted and measured scattered\nfields is reported as the final solution. Synthetic and experimental labeled\ndatasets are used for training and evaluation of the model. An innovative\nlabeled synthetic dataset is created that exemplifies a varied set of\nscattering features. Training of the model using this new dataset produces high\nquality permittivity reconstructions achieving improved generalization with\nexcellent fidelity to shape recognition. The results highlight the potential of\nhybrid generative physics frameworks as a promising direction for robust,\ndata-driven microwave imaging.",
    "published": "2025-10-29T17:34:10Z",
    "updated": "2025-10-29T17:34:10Z",
    "link": "http://arxiv.org/pdf/2510.25729v1.pdf",
    "category": [
      "eess.IV",
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "authors": [
      "Shirin Chehelgami",
      "Joe LoVetri",
      "Vahab Khoshdel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25726v1",
    "title": "The Tool Decathlon: Benchmarking Language Agents for Diverse, Realistic,\n  and Long-Horizon Task Execution",
    "summary": "Real-world language agents must handle complex, multi-step workflows across\ndiverse Apps. For instance, an agent may manage emails by coordinating with\ncalendars and file systems, or monitor a production database to detect\nanomalies and generate reports following an operating manual. However, existing\nlanguage agent benchmarks often focus on narrow domains or simplified tasks\nthat lack the diversity, realism, and long-horizon complexity required to\nevaluate agents' real-world performance. To address this gap, we introduce the\nTool Decathlon (dubbed as Toolathlon), a benchmark for language agents offering\ndiverse Apps and tools, realistic environment setup, and reliable\nexecution-based evaluation. Toolathlon spans 32 software applications and 604\ntools, ranging from everyday platforms such as Google Calendar and Notion to\nprofessional ones like WooCommerce, Kubernetes, and BigQuery. Most of the tools\nare based on a high-quality set of Model Context Protocol (MCP) servers that we\nmay have revised or implemented ourselves. Unlike prior works, which primarily\nensure functional realism but offer limited environment state diversity, we\nprovide realistic initial environment states from real software, such as Canvas\ncourses with dozens of students or real financial spreadsheets. This benchmark\nincludes 108 manually sourced or crafted tasks in total, requiring interacting\nwith multiple Apps over around 20 turns on average to complete. Each task is\nstrictly verifiable through dedicated evaluation scripts. Comprehensive\nevaluation of SOTA models highlights their significant shortcomings: the\nbest-performing model, Claude-4.5-Sonnet, achieves only a 38.6% success rate\nwith 20.2 tool calling turns on average, while the top open-weights model\nDeepSeek-V3.2-Exp reaches 20.1%. We expect Toolathlon to drive the development\nof more capable language agents for real-world, long-horizon task execution.",
    "published": "2025-10-29T17:32:49Z",
    "updated": "2025-10-29T17:32:49Z",
    "link": "http://arxiv.org/pdf/2510.25726v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Junlong Li",
      "Wenshuo Zhao",
      "Jian Zhao",
      "Weihao Zeng",
      "Haoze Wu",
      "Xiaochen Wang",
      "Rui Ge",
      "Yuxuan Cao",
      "Yuzhen Huang",
      "Wei Liu",
      "Junteng Liu",
      "Zhaochen Su",
      "Yiyang Guo",
      "Fan Zhou",
      "Lueyang Zhang",
      "Juan Michelini",
      "Xingyao Wang",
      "Xiang Yue",
      "Shuyan Zhou",
      "Graham Neubig",
      "Junxian He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25724v1",
    "title": "BambooKG: A Neurobiologically-inspired Frequency-Weight Knowledge Graph",
    "summary": "Retrieval-Augmented Generation allows LLMs to access external knowledge,\nreducing hallucinations and ageing-data issues. However, it treats retrieved\nchunks independently and struggles with multi-hop or relational reasoning,\nespecially across documents. Knowledge graphs enhance this by capturing the\nrelationships between entities using triplets, enabling structured, multi-chunk\nreasoning. However, these tend to miss information that fails to conform to the\ntriplet structure. We introduce BambooKG, a knowledge graph with\nfrequency-based weights on non-triplet edges which reflect link strength,\ndrawing on the Hebbian principle of \"fire together, wire together\". This\ndecreases information loss and results in improved performance on single- and\nmulti-hop reasoning, outperforming the existing solutions.",
    "published": "2025-10-29T17:31:27Z",
    "updated": "2025-10-29T17:31:27Z",
    "link": "http://arxiv.org/pdf/2510.25724v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Vanya Arikutharam",
      "Arkadiy Ukolov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.17937v3",
    "title": "Bob's Confetti: Phonetic Memorization Attacks in Music and Video\n  Generation",
    "summary": "Generative AI systems for music and video commonly use text-based filters to\nprevent the regurgitation of copyrighted material. We expose a fundamental flaw\nin this approach by introducing Adversarial PhoneTic Prompting (APT), a novel\nattack that bypasses these safeguards by exploiting phonetic memorization. The\nAPT attack replaces iconic lyrics with homophonic but semantically unrelated\nalternatives (e.g., \"mom's spaghetti\" becomes \"Bob's confetti\"), preserving\nacoustic structure while altering meaning; we identify high-fidelity phonetic\nmatches using CMU pronouncing dictionary. We demonstrate that leading\nLyrics-to-Song (L2S) models like SUNO and YuE regenerate songs with striking\nmelodic and rhythmic similarity to their copyrighted originals when prompted\nwith these altered lyrics. More surprisingly, this vulnerability extends across\nmodalities. When prompted with phonetically modified lyrics from a song, a\nText-to-Video (T2V) model like Veo 3 reconstructs visual scenes from the\noriginal music video-including specific settings and character\narchetypes-despite the absence of any visual cues in the prompt. Our findings\nreveal that models memorize deep, structural patterns tied to acoustics, not\njust verbatim text. This phonetic-to-visual leakage represents a critical\nvulnerability in transcript-conditioned generative models, rendering simple\ncopyright filters ineffective and raising urgent concerns about the secure\ndeployment of multimodal AI systems. Demo examples are available at our project\npage (https://jrohsc.github.io/music_attack/).",
    "published": "2025-07-23T21:11:47Z",
    "updated": "2025-10-29T17:29:43Z",
    "link": "http://arxiv.org/pdf/2507.17937v3.pdf",
    "category": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "eess.AS"
    ],
    "authors": [
      "Jaechul Roh",
      "Zachary Novack",
      "Yuefeng Peng",
      "Niloofar Mireshghallah",
      "Taylor Berg-Kirkpatrick",
      "Amir Houmansadr"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.17720v4",
    "title": "Spontaneous Giving and Calculated Greed in Language Models",
    "summary": "Large language models demonstrate strong problem-solving abilities through\nreasoning techniques such as chain-of-thought prompting and reflection.\nHowever, it remains unclear whether these reasoning capabilities extend to a\nform of social intelligence: making effective decisions in cooperative\ncontexts. We examine this question using economic games that simulate social\ndilemmas. First, we apply chain-of-thought and reflection prompting to GPT-4o\nin a Public Goods Game. We then evaluate multiple off-the-shelf models across\nsix cooperation and punishment games, comparing those with and without explicit\nreasoning mechanisms. We find that reasoning models consistently reduce\ncooperation and norm enforcement, favoring individual rationality. In repeated\ninteractions, groups with more reasoning agents exhibit lower collective gains.\nThese behaviors mirror human patterns of \"spontaneous giving and calculated\ngreed.\" Our findings underscore the need for LLM architectures that incorporate\nsocial intelligence alongside reasoning, to help address--rather than\nreinforce--the challenges of collective action.",
    "published": "2025-02-24T23:23:27Z",
    "updated": "2025-10-29T17:15:43Z",
    "link": "http://arxiv.org/pdf/2502.17720v4.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Yuxuan Li",
      "Hirokazu Shirado"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.18384v4",
    "title": "Dynamic Risk Assessments for Offensive Cybersecurity Agents",
    "summary": "Foundation models are increasingly becoming better autonomous programmers,\nraising the prospect that they could also automate dangerous offensive\ncyber-operations. Current frontier model audits probe the cybersecurity risks\nof such agents, but most fail to account for the degrees of freedom available\nto adversaries in the real world. In particular, with strong verifiers and\nfinancial incentives, agents for offensive cybersecurity are amenable to\niterative improvement by would-be adversaries. We argue that assessments should\ntake into account an expanded threat model in the context of cybersecurity,\nemphasizing the varying degrees of freedom that an adversary may possess in\nstateful and non-stateful environments within a fixed compute budget. We show\nthat even with a relatively small compute budget (8 H100 GPU Hours in our\nstudy), adversaries can improve an agent's cybersecurity capability on\nInterCode CTF by more than 40\\% relative to the baseline -- without any\nexternal assistance. These results highlight the need to evaluate agents'\ncybersecurity risk in a dynamic manner, painting a more representative picture\nof risk.",
    "published": "2025-05-23T21:18:59Z",
    "updated": "2025-10-29T17:15:36Z",
    "link": "http://arxiv.org/pdf/2505.18384v4.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Boyi Wei",
      "Benedikt Stroebl",
      "Jiacen Xu",
      "Joie Zhang",
      "Zhou Li",
      "Peter Henderson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25694v1",
    "title": "Process-Level Trajectory Evaluation for Environment Configuration in\n  Software Engineering Agents",
    "summary": "Large language model-based agents show promise for software engineering, but\nenvironment configuration remains a bottleneck due to heavy manual effort and\nscarce large-scale, high-quality datasets. Existing benchmarks assess only\nend-to-end build/test success, obscuring where and why agents succeed or fail.\nWe introduce the Environment Configuration Diagnosis Benchmark, Enconda-bench,\nwhich provides process-level trajectory assessment of fine-grained agent\ncapabilities during environment setup-planning, perception-driven error\ndiagnosis, feedback-driven repair, and action to execute final environment\nconfiguration. Our task instances are automatically constructed by injecting\nrealistic README errors and are validated in Docker for scalable, high-quality\nevaluation. Enconda-bench combines process-level analysis with end-to-end\nexecutability to enable capability assessments beyond aggregate success rates.\nEvaluations across state-of-the-art LLMs and agent frameworks show that while\nagents can localize errors, they struggle to translate feedback into effective\ncorrections, limiting end-to-end performance. To our knowledge, Enconda-bench\nis the first framework to provide process-level internal capability assessment\nfor environment configuration, offering actionable insights for improving\nsoftware engineering agents.",
    "published": "2025-10-29T16:59:07Z",
    "updated": "2025-10-29T16:59:07Z",
    "link": "http://arxiv.org/pdf/2510.25694v1.pdf",
    "category": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Jiayi Kuang",
      "Yinghui Li",
      "Xin Zhang",
      "Yangning Li",
      "Di Yin",
      "Xing Sun",
      "Ying Shen",
      "Philip S. Yu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.09868v3",
    "title": "Which Demographic Features Are Relevant for Individual Fairness\n  Evaluation of U.S. Recidivism Risk Assessment Tools?",
    "summary": "Despite its constitutional relevance, the technical ``individual fairness''\ncriterion has not been operationalized in U.S. state or federal\nstatutes/regulations. We conduct a human subjects experiment to address this\ngap, evaluating which demographic features are relevant for individual fairness\nevaluation of recidivism risk assessment (RRA) tools. Our analyses conclude\nthat the individual similarity function should consider age and sex, but it\nshould ignore race.",
    "published": "2025-05-15T00:07:07Z",
    "updated": "2025-10-29T16:55:47Z",
    "link": "http://arxiv.org/pdf/2505.09868v3.pdf",
    "category": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "authors": [
      "Tin Trung Nguyen",
      "Jiannan Xu",
      "Phuong-Anh Nguyen-Le",
      "Jonathan Lazar",
      "Donald Braman",
      "Hal Daumé III",
      "Zubin Jelveh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2407.11217v3",
    "title": "Faster and Simpler Greedy Algorithm for $k$-Median and $k$-Means",
    "summary": "Clustering problems such as $k$-means and $k$-median are staples of\nunsupervised learning, and many algorithmic techniques have been developed to\ntackle their numerous aspects.\n  In this paper, we focus on the class of greedy approximation algorithm, that\nattracted less attention than local-search or primal-dual counterparts. In\nparticular, we study the recursive greedy algorithm developed by Mettu and\nPlaxton [SIAM J. Comp 2003]. We provide a simplification of the algorithm,\nallowing for faster implementation, in graph metrics or in Euclidean space,\nwhere our algorithm matches or improves the state-of-the-art.",
    "published": "2024-07-15T20:04:06Z",
    "updated": "2025-10-29T16:53:29Z",
    "link": "http://arxiv.org/pdf/2407.11217v3.pdf",
    "category": [
      "cs.DS",
      "cs.AI"
    ],
    "authors": [
      "Max Dupré la Tour",
      "David Saulpic"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25683v1",
    "title": "Graph Network-based Structural Simulator: Graph Neural Networks for\n  Structural Dynamics",
    "summary": "Graph Neural Networks (GNNs) have recently been explored as surrogate models\nfor numerical simulations. While their applications in computational fluid\ndynamics have been investigated, little attention has been given to structural\nproblems, especially for dynamic cases. To address this gap, we introduce the\nGraph Network-based Structural Simulator (GNSS), a GNN framework for surrogate\nmodeling of dynamic structural problems.\n  GNSS follows the encode-process-decode paradigm typical of GNN-based machine\nlearning models, and its design makes it particularly suited for dynamic\nsimulations thanks to three key features: (i) expressing node kinematics in\nnode-fixed local frames, which avoids catastrophic cancellation in\nfinite-difference velocities; (ii) employing a sign-aware regression loss,\nwhich reduces phase errors in long rollouts; and (iii) using a\nwavelength-informed connectivity radius, which optimizes graph construction.\n  We evaluate GNSS on a case study involving a beam excited by a 50kHz\nHanning-modulated pulse. The results show that GNSS accurately reproduces the\nphysics of the problem over hundreds of timesteps and generalizes to unseen\nloading conditions, where existing GNNs fail to converge or deliver meaningful\npredictions.\n  Compared with explicit finite element baselines, GNSS achieves substantial\ninference speedups while preserving spatial and temporal fidelity. These\nfindings demonstrate that locality-preserving GNNs with physics-consistent\nupdate rules are a competitive alternative for dynamic, wave-dominated\nstructural simulations.",
    "published": "2025-10-29T16:47:24Z",
    "updated": "2025-10-29T16:47:24Z",
    "link": "http://arxiv.org/pdf/2510.25683v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "physics.comp-ph"
    ],
    "authors": [
      "Alessandro Lucchetti",
      "Francesco Cadini",
      "Marco Giglio",
      "Luca Lomazzi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25679v1",
    "title": "Navigation in a Three-Dimensional Urban Flow using Deep Reinforcement\n  Learning",
    "summary": "Unmanned Aerial Vehicles (UAVs) are increasingly populating urban areas for\ndelivery and surveillance purposes. In this work, we develop an optimal\nnavigation strategy based on Deep Reinforcement Learning. The environment is\nrepresented by a three-dimensional high-fidelity simulation of an urban flow,\ncharacterized by turbulence and recirculation zones. The algorithm presented\nhere is a flow-aware Proximal Policy Optimization (PPO) combined with a Gated\nTransformer eXtra Large (GTrXL) architecture, giving the agent richer\ninformation about the turbulent flow field in which it navigates. The results\nare compared with a PPO+GTrXL without the secondary prediction tasks, a PPO\ncombined with Long Short Term Memory (LSTM) cells and a traditional navigation\nalgorithm. The obtained results show a significant increase in the success rate\n(SR) and a lower crash rate (CR) compared to a PPO+LSTM, PPO+GTrXL and the\nclassical Zermelo's navigation algorithm, paving the way to a completely\nreimagined UAV landscape in complex urban environments.",
    "published": "2025-10-29T16:46:00Z",
    "updated": "2025-10-29T16:46:00Z",
    "link": "http://arxiv.org/pdf/2510.25679v1.pdf",
    "category": [
      "cs.AI",
      "physics.flu-dyn"
    ],
    "authors": [
      "Federica Tonti",
      "Ricardo Vinuesa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.22664v2",
    "title": "RobEthiChor: Automated Context-aware Ethics-based Negotiation for\n  Autonomous Robots",
    "summary": "The presence of autonomous systems is growing at a fast pace and it is\nimpacting many aspects of our lives. Designed to learn and act independently,\nthese systems operate and perform decision-making without human intervention.\nHowever, they lack the ability to incorporate users' ethical preferences, which\nare unique for each individual in society and are required to personalize the\ndecision-making processes. This reduces user trust and prevents autonomous\nsystems from behaving according to the moral beliefs of their end-users. When\nmultiple systems interact with differing ethical preferences, they must\nnegotiate to reach an agreement that satisfies the ethical beliefs of all the\nparties involved and adjust their behavior consequently. To address this\nchallenge, this paper proposes RobEthiChor, an approach that enables autonomous\nsystems to incorporate user ethical preferences and contextual factors into\ntheir decision-making through ethics-based negotiation. RobEthiChor features a\ndomain-agnostic reference architecture for designing autonomous systems capable\nof ethic-based negotiating. The paper also presents RobEthiChor-Ros, an\nimplementation of RobEthiChor within the Robot Operating System (ROS), which\ncan be deployed on robots to provide them with ethics-based negotiation\ncapabilities. To evaluate our approach, we deployed RobEthiChor-Ros on real\nrobots and ran scenarios where a pair of robots negotiate upon resource\ncontention. Experimental results demonstrate the feasibility and effectiveness\nof the system in realizing ethics-based negotiation. RobEthiChor allowed robots\nto reach an agreement in more than 73% of the scenarios with an acceptable\nnegotiation time (0.67s on average). Experiments also demonstrate that the\nnegotiation approach implemented in RobEthiChor is scalable.",
    "published": "2025-07-30T13:21:38Z",
    "updated": "2025-10-29T16:42:19Z",
    "link": "http://arxiv.org/pdf/2507.22664v2.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Mashal Afzal Memon",
      "Gianluca Filippone",
      "Gian Luca Scoccia",
      "Marco Autili",
      "Paola Inverardi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25668v1",
    "title": "ALDEN: Reinforcement Learning for Active Navigation and Evidence\n  Gathering in Long Documents",
    "summary": "Vision-language models (VLMs) excel at interpreting text-rich images but\nstruggle with long, visually complex documents that demand analysis and\nintegration of information spread across multiple pages. Existing approaches\ntypically rely on fixed reasoning templates or rigid pipelines, which force\nVLMs into a passive role and hinder both efficiency and generalization. We\npresent Active Long-DocumEnt Navigation (ALDEN), a multi-turn reinforcement\nlearning framework that fine-tunes VLMs as interactive agents capable of\nactively navigating long, visually rich documents. ALDEN introduces a novel\nfetch action that directly accesses the page by index, complementing the\nclassic search action and better exploiting document structure. For dense\nprocess supervision and efficient training, we propose a rule-based cross-level\nreward that provides both turn- and token-level signals. To address the\nempirically observed training instability caused by numerous visual tokens from\nlong documents, we further propose a visual-semantic anchoring mechanism that\napplies a dual-path KL-divergence constraint to stabilize visual and textual\nrepresentations separately during training. Trained on a corpus constructed\nfrom three open-source datasets, ALDEN achieves state-of-the-art performance on\nfive long-document benchmarks. Overall, ALDEN marks a step beyond passive\ndocument reading toward agents that autonomously navigate and reason across\nlong, visually rich documents, offering a robust path to more accurate and\nefficient long-document understanding.",
    "published": "2025-10-29T16:32:26Z",
    "updated": "2025-10-29T16:32:26Z",
    "link": "http://arxiv.org/pdf/2510.25668v1.pdf",
    "category": [
      "cs.AI",
      "cs.MM"
    ],
    "authors": [
      "Tianyu Yang",
      "Terry Ruas",
      "Yijun Tian",
      "Jan Philip Wahle",
      "Daniel Kurzawe",
      "Bela Gipp"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.21717v5",
    "title": "Scaling Up Liquid-Resistance Liquid-Capacitance Networks for Efficient\n  Sequence Modeling",
    "summary": "We present LrcSSM, a $\\textit{non-linear}$ recurrent model that processes\nlong sequences as fast as today's linear state-space layers. By forcing its\nJacobian matrix to be diagonal, the full sequence can be solved in parallel,\ngiving $\\mathcal{O}(TD)$ time and memory and only $\\mathcal{O}(\\log T)$\nsequential depth, for input-sequence length $T$ and a state dimension $D$.\nMoreover, LrcSSM offers a formal gradient-stability guarantee that other\ninput-varying systems such as Liquid-S4 and Mamba do not provide. Importantly,\nthe diagonal Jacobian structure of our model results in no performance loss\ncompared to the original model with dense Jacobian, and the approach can be\ngeneralized to other non-linear recurrent models, demonstrating broader\napplicability. On a suite of long-range forecasting tasks, we demonstrate that\nLrcSSM outperforms Transformers, LRU, S5, and Mamba.",
    "published": "2025-05-27T20:02:59Z",
    "updated": "2025-10-29T16:25:55Z",
    "link": "http://arxiv.org/pdf/2505.21717v5.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "authors": [
      "Mónika Farsang",
      "Ramin Hasani",
      "Daniela Rus",
      "Radu Grosu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25662v1",
    "title": "User Misconceptions of LLM-Based Conversational Programming Assistants",
    "summary": "Programming assistants powered by large language models (LLMs) have become\nwidely available, with conversational assistants like ChatGPT proving\nparticularly accessible to less experienced programmers. However, the varied\ncapabilities of these tools across model versions and the mixed availability of\nextensions that enable web search, code execution, or retrieval-augmented\ngeneration create opportunities for user misconceptions about what systems can\nand cannot do. Such misconceptions may lead to over-reliance, unproductive\npractices, or insufficient quality control in LLM-assisted programming. Here,\nwe aim to characterize misconceptions that users of conversational LLM-based\nassistants may have in programming contexts. Using a two-phase approach, we\nfirst brainstorm and catalog user misconceptions that may occur, and then\nconduct a qualitative analysis to examine whether these conceptual issues\nsurface in naturalistic Python-programming conversations with an LLM-based\nchatbot drawn from an openly available dataset. Indeed, we see evidence that\nsome users have misplaced expectations about the availability of LLM-based\nchatbot features like web access, code execution, or non-text output\ngeneration. We also see potential evidence for deeper conceptual issues around\nthe scope of information required to debug, validate, and optimize programs.\nOur findings reinforce the need for designing LLM-based tools that more clearly\ncommunicate their programming capabilities to users.",
    "published": "2025-10-29T16:23:46Z",
    "updated": "2025-10-29T16:23:46Z",
    "link": "http://arxiv.org/pdf/2510.25662v1.pdf",
    "category": [
      "cs.HC",
      "cs.AI"
    ],
    "authors": [
      "Gabrielle O'Brien",
      "Antonio Pedro Santos Alves",
      "Sebastian Baltes",
      "Grischa Liebel",
      "Mircea Lungu",
      "Marcos Kalinowski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25657v1",
    "title": "Subgraph Federated Learning via Spectral Methods",
    "summary": "We consider the problem of federated learning (FL) with graph-structured data\ndistributed across multiple clients. In particular, we address the prevalent\nscenario of interconnected subgraphs, where interconnections between clients\nsignificantly influence the learning process. Existing approaches suffer from\ncritical limitations, either requiring the exchange of sensitive node\nembeddings, thereby posing privacy risks, or relying on\ncomputationally-intensive steps, which hinders scalability. To tackle these\nchallenges, we propose FedLap, a novel framework that leverages global\nstructure information via Laplacian smoothing in the spectral domain to\neffectively capture inter-node dependencies while ensuring privacy and\nscalability. We provide a formal analysis of the privacy of FedLap,\ndemonstrating that it preserves privacy. Notably, FedLap is the first subgraph\nFL scheme with strong privacy guarantees. Extensive experiments on benchmark\ndatasets demonstrate that FedLap achieves competitive or superior utility\ncompared to existing techniques.",
    "published": "2025-10-29T16:22:32Z",
    "updated": "2025-10-29T16:22:32Z",
    "link": "http://arxiv.org/pdf/2510.25657v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "authors": [
      "Javad Aliakbari",
      "Johan Östman",
      "Ashkan Panahi",
      "Alexandre Graell i Amat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.07464v3",
    "title": "DeepVideo-R1: Video Reinforcement Fine-Tuning via Difficulty-aware\n  Regressive GRPO",
    "summary": "Recent works have demonstrated the effectiveness of reinforcement learning\n(RL)-based post-training for enhancing the reasoning capabilities of large\nlanguage models (LLMs). In particular, Group Relative Policy Optimization\n(GRPO) has shown impressive success using a PPO-style reinforcement algorithm\nwith group-normalized rewards. However, the effectiveness of GRPO in Video\nLarge Language Models (VideoLLMs) has still been less studyed. In this paper,\nwe explore GRPO and identify two problems that deteriorate the effective\nlearning: (1) reliance on safeguards, and (2) vanishing advantage. To mitigate\nthese challenges, we propose DeepVideo-R1, a video large language model trained\nwith Reg-GRPO (Regressive GRPO) and difficulty-aware data augmentation.\nReg-GRPO reformulates the GRPO loss function into a regression task that\ndirectly predicts the advantage in GRPO, eliminating the need for safeguards\nsuch as the clipping and min functions. It directly aligns the model with\nadvantages, providing guidance to prefer better ones. The difficulty-aware data\naugmentation strategy augments input prompts/videos to locate the difficulty of\nsamples at solvable difficulty levels, enabling diverse reward signals. Our\nexperimental results show that our approach significantly improves video\nreasoning performance across multiple benchmarks.",
    "published": "2025-06-09T06:15:54Z",
    "updated": "2025-10-29T15:59:41Z",
    "link": "http://arxiv.org/pdf/2506.07464v3.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Jinyoung Park",
      "Jeehye Na",
      "Jinyoung Kim",
      "Hyunwoo J. Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.14785v2",
    "title": "Exploring the In-Context Learning Capabilities of LLMs for Money\n  Laundering Detection in Financial Graphs",
    "summary": "The complexity and interconnectivity of entities involved in money laundering\ndemand investigative reasoning over graph-structured data. This paper explores\nthe use of large language models (LLMs) as reasoning engines over localized\nsubgraphs extracted from a financial knowledge graph. We propose a lightweight\npipeline that retrieves k-hop neighborhoods around entities of interest,\nserializes them into structured text, and prompts an LLM via few-shot\nin-context learning to assess suspiciousness and generate justifications. Using\nsynthetic anti-money laundering (AML) scenarios that reflect common laundering\nbehaviors, we show that LLMs can emulate analyst-style logic, highlight red\nflags, and provide coherent explanations. While this study is exploratory, it\nillustrates the potential of LLM-based graph reasoning in AML and lays\ngroundwork for explainable, language-driven financial crime analytics.",
    "published": "2025-07-20T02:00:21Z",
    "updated": "2025-10-29T15:56:28Z",
    "link": "http://arxiv.org/pdf/2507.14785v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Erfan Pirmorad"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23965v2",
    "title": "The Sign Estimator: LLM Alignment in the Face of Choice Heterogeneity",
    "summary": "Traditional LLM alignment methods are vulnerable to heterogeneity in human\npreferences. Fitting a na\\\"ive probabilistic model to pairwise comparison data\n(say over prompt-completion pairs) yields an inconsistent estimate of the\npopulation-average utility -a canonical measure of social welfare. We propose a\nnew method, dubbed the sign estimator, that provides a simple, provably\nconsistent, and efficient estimator by replacing cross-entropy with binary\nclassification loss in the aggregation step. This simple modification recovers\nconsistent ordinal alignment under mild assumptions and achieves the first\npolynomial finite-sample error bounds in this setting. In realistic simulations\nof LLM alignment using digital twins, the sign estimator substantially reduces\npreference distortion over a panel of simulated personas, cutting (angular)\nestimation error by nearly 35% and decreasing disagreement with true population\npreferences from 12% to 8% compared to standard RLHF. Our method also compares\nfavorably to panel data heuristics that explicitly model user heterogeneity and\nrequire tracking individual-level preference data-all while maintaining the\nimplementation simplicity of existing LLM alignment pipelines.",
    "published": "2025-10-28T00:42:38Z",
    "updated": "2025-10-29T15:51:35Z",
    "link": "http://arxiv.org/pdf/2510.23965v2.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Ali Aouad",
      "Aymane El Gadarri",
      "Vivek F. Farias"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.22439v2",
    "title": "PromptReverb: Multimodal Room Impulse Response Generation Through Latent\n  Rectified Flow Matching",
    "summary": "Room impulse response (RIR) generation remains a critical challenge for\ncreating immersive virtual acoustic environments. Current methods suffer from\ntwo fundamental limitations: the scarcity of full-band RIR datasets and the\ninability of existing models to generate acoustically accurate responses from\ndiverse input modalities. We present PromptReverb, a two-stage generative\nframework that addresses these challenges. Our approach combines a variational\nautoencoder that upsamples band-limited RIRs to full-band quality (48 kHz), and\na conditional diffusion transformer model based on rectified flow matching that\ngenerates RIRs from descriptions in natural language. Empirical evaluation\ndemonstrates that PromptReverb produces RIRs with superior perceptual quality\nand acoustic accuracy compared to existing methods, achieving 8.8% mean RT60\nerror compared to -37% for widely used baselines and yielding more realistic\nroom-acoustic parameters. Our method enables practical applications in virtual\nreality, architectural acoustics, and audio production where flexible,\nhigh-quality RIR synthesis is essential.",
    "published": "2025-10-25T21:38:07Z",
    "updated": "2025-10-29T15:42:33Z",
    "link": "http://arxiv.org/pdf/2510.22439v2.pdf",
    "category": [
      "cs.SD",
      "cs.AI",
      "I.2.6, H.5.5"
    ],
    "authors": [
      "Ali Vosoughi",
      "Yongyi Zang",
      "Qihui Yang",
      "Nathan Paek",
      "Randal Leistikow",
      "Chenliang Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.00812v4",
    "title": "Handling Label Noise via Instance-Level Difficulty Modeling and Dynamic\n  Optimization",
    "summary": "Recent studies indicate that deep neural networks degrade in generalization\nperformance under noisy supervision. Existing methods focus on isolating clean\nsubsets or correcting noisy labels, facing limitations such as high\ncomputational costs, heavy hyperparameter tuning process, and coarse-grained\noptimization. To address these challenges, we propose a novel two-stage noisy\nlearning framework that enables instance-level optimization through a\ndynamically weighted loss function, avoiding hyperparameter tuning. To obtain\nstable and accurate information about noise modeling, we introduce a simple yet\neffective metric, termed wrong event, which dynamically models the cleanliness\nand difficulty of individual samples while maintaining computational costs. Our\nframework first collects wrong event information and builds a strong base\nmodel. Then we perform noise-robust training on the base model, using a\nprobabilistic model to handle the wrong event information of samples.\nExperiments on five synthetic and real-world LNL benchmarks demonstrate our\nmethod surpasses state-of-the-art methods in performance, achieves a nearly 75%\nreduction in computational time and improves model scalability.",
    "published": "2025-05-01T19:12:58Z",
    "updated": "2025-10-29T15:40:34Z",
    "link": "http://arxiv.org/pdf/2505.00812v4.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Kuan Zhang",
      "Chengliang Chai",
      "Jingzhe Xu",
      "Chi Zhang",
      "Han Han",
      "Ye Yuan",
      "Guoren Wang",
      "Lei Cao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25634v1",
    "title": "Learning to Plan & Schedule with Reinforcement-Learned Bimanual Robot\n  Skills",
    "summary": "Long-horizon contact-rich bimanual manipulation presents a significant\nchallenge, requiring complex coordination involving a mixture of parallel\nexecution and sequential collaboration between arms. In this paper, we\nintroduce a hierarchical framework that frames this challenge as an integrated\nskill planning & scheduling problem, going beyond purely sequential\ndecision-making to support simultaneous skill invocation. Our approach is built\nupon a library of single-arm and bimanual primitive skills, each trained using\nReinforcement Learning (RL) in GPU-accelerated simulation. We then train a\nTransformer-based planner on a dataset of skill compositions to act as a\nhigh-level scheduler, simultaneously predicting the discrete schedule of skills\nas well as their continuous parameters. We demonstrate that our method achieves\nhigher success rates on complex, contact-rich tasks than end-to-end RL\napproaches and produces more efficient, coordinated behaviors than traditional\nsequential-only planners.",
    "published": "2025-10-29T15:39:53Z",
    "updated": "2025-10-29T15:39:53Z",
    "link": "http://arxiv.org/pdf/2510.25634v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Weikang Wan",
      "Fabio Ramos",
      "Xuning Yang",
      "Caelan Garrett"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2309.13672v8",
    "title": "RL-I2IT: Image-to-Image Translation with Deep Reinforcement Learning",
    "summary": "Most existing Image-to-Image Translation (I2IT) methods generate images in a\nsingle run of a deep learning (DL) model. However, designing such a single-step\nmodel is always challenging, requiring a huge number of parameters and easily\nfalling into bad global minimums and overfitting. In this work, we reformulate\nI2IT as a step-wise decision-making problem via deep reinforcement learning\n(DRL) and propose a novel framework that performs RL-based I2IT (RL-I2IT). The\nkey feature in the RL-I2IT framework is to decompose a monolithic learning\nprocess into small steps with a lightweight model to progressively transform a\nsource image successively to a target image. Considering that it is challenging\nto handle high dimensional continuous state and action spaces in the\nconventional RL framework, we introduce meta policy with a new concept Plan to\nthe standard Actor-Critic model, which is of a lower dimension than the\noriginal image and can facilitate the actor to generate a tractable high\ndimensional action. In the RL-I2IT framework, we also employ a task-specific\nauxiliary learning strategy to stabilize the training process and improve the\nperformance of the corresponding task. Experiments on several I2IT tasks\ndemonstrate the effectiveness and robustness of the proposed method when facing\nhigh-dimensional continuous action space problems. Our implementation of the\nRL-I2IT framework is available at\nhttps://github.com/Algolzw/SPAC-Deformable-Registration.",
    "published": "2023-09-24T15:40:40Z",
    "updated": "2025-10-29T15:35:18Z",
    "link": "http://arxiv.org/pdf/2309.13672v8.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Jing Hu",
      "Chengming Feng",
      "Shu Hu",
      "Ming-Ching Chang",
      "Xin Li",
      "Xi Wu",
      "Xin Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.23117v2",
    "title": "Decom-Renorm-Merge: Model Merging on the Right Space Improves\n  Multitasking",
    "summary": "In the era of large-scale training, model merging has evolved into a tool for\ncreating multitasking models efficiently. It enables the knowledge of models to\nbe fused, without the need for heavy computation as required in traditional\nmultitask learning. Existing merging methods often assume that entries at\nidentical positions in weight matrices serve the same function, enabling\nstraightforward entry-wise comparison and merging. However, this assumption\noverlooks the complexity of finetuned neural networks, where neurons may\ndevelop distinct feature compositions, making direct entry-wise merging\nproblematic. We present Decom-Renorm-Merge (DRM), a simple yet effective\napproach that leverages Singular Value Decomposition to decompose and\ncoordinate weight matrices into an aligned joint space, where entry-wise\nmerging becomes possible. We showcase the effectiveness of DRM across various\nsettings ranging from smaller encoder-based such as ViT and DeBERTa,\nencoder-decoder-based such as T5, and larger decoder-based such as Llama3.1-8B.\nOur experimental results show that DRM outperforms several state-of-the-art\nmerging techniques across full finetuning and low-rank adaptation settings.\nMoreover, our analysis reveals renormalization as the crucial component for\ncreating a robust and even joint space for merging, significantly contributing\nto the method's performance.",
    "published": "2025-05-29T05:37:53Z",
    "updated": "2025-10-29T15:34:30Z",
    "link": "http://arxiv.org/pdf/2505.23117v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Yuatyong Chaichana",
      "Thanapat Trachu",
      "Peerat Limkonchotiwat",
      "Konpat Preechakul",
      "Tirasan Khandhawit",
      "Ekapol Chuangsuwanich"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.01850v3",
    "title": "NGGAN: Noise Generation GAN Based on the Practical Measurement Dataset\n  for Narrowband Powerline Communications",
    "summary": "To effectively process impulse noise for narrowband powerline communications\n(NB-PLCs) transceivers, capturing comprehensive statistics of nonperiodic\nasynchronous impulsive noise (APIN) is a critical task. However, existing\nmathematical noise generative models only capture part of the characteristics\nof noise. In this study, we propose a novel generative adversarial network\n(GAN) called noise generation GAN (NGGAN) that learns the complicated\ncharacteristics of practically measured noise samples for data synthesis. To\nclosely match the statistics of complicated noise over the NB-PLC systems, we\nmeasured the NB-PLC noise via the analog coupling and bandpass filtering\ncircuits of a commercial NB-PLC modem to build a realistic dataset. To train\nNGGAN, we adhere to the following principles: 1) we design the length of input\nsignals that the NGGAN model can fit to facilitate cyclostationary noise\ngeneration; 2) the Wasserstein distance is used as a loss function to enhance\nthe similarity between the generated noise and training data; and 3) to measure\nthe similarity performances of GAN-based models based on the mathematical and\npractically measured datasets, we conduct both quantitative and qualitative\nanalyses. The training datasets include: 1) a piecewise spectral\ncyclostationary Gaussian model (PSCGM); 2) a frequency-shift (FRESH) filter;\nand 3) practical measurements from NB-PLC systems. Simulation results\ndemonstrate that the generated noise samples from the proposed NGGAN are highly\nclose to the real noise samples. The principal component analysis (PCA) scatter\nplots and Fr\\'echet inception distance (FID) analysis have shown that NGGAN\noutperforms other GAN-based models by generating noise samples with superior\nfidelity and higher diversity.",
    "published": "2025-10-02T09:47:56Z",
    "updated": "2025-10-29T15:33:51Z",
    "link": "http://arxiv.org/pdf/2510.01850v3.pdf",
    "category": [
      "eess.SP",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "68T07, 94A12, 62M10",
      "I.2.6; I.5.4; C.2.1"
    ],
    "authors": [
      "Ying-Ren Chien",
      "Po-Heng Chou",
      "You-Jie Peng",
      "Chun-Yuan Huang",
      "Hen-Wai Tsao",
      "Yu Tsao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25626v1",
    "title": "Are Language Models Efficient Reasoners? A Perspective from Logic\n  Programming",
    "summary": "Modern language models (LMs) exhibit strong deductive reasoning capabilities,\nyet standard evaluations emphasize correctness while overlooking a key aspect\nof human-like reasoning: efficiency. In real-world reasoning scenarios, much of\nthe available information is irrelevant, and effective deductive inference\nrequires identifying and ignoring such distractions. We propose a framework for\nassessing LM reasoning efficiency through the lens of logic programming,\nintroducing a simple method to align proofs written in natural language -- as\ngenerated by an LM -- with shortest proofs found by executing the logic\nprogram. Efficiency is quantified by measuring how well a model avoids\nunnecessary inference. Empirically, we construct a dataset of math word\nproblems injected with various number of irrelevant axioms that vary in\nsemantic overlap with the goal theorem. We find that current LMs show marked\naccuracy declines under such conditions -- even with minimal, domain-consistent\ndistractions -- and the proofs they generate frequently exhibit detours through\nirrelevant inferences.",
    "published": "2025-10-29T15:30:31Z",
    "updated": "2025-10-29T15:30:31Z",
    "link": "http://arxiv.org/pdf/2510.25626v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.LO"
    ],
    "authors": [
      "Andreas Opedal",
      "Yanick Zengaffinen",
      "Haruki Shirakami",
      "Clemente Pasti",
      "Mrinmaya Sachan",
      "Abulhair Saparov",
      "Ryan Cotterell",
      "Bernhard Schölkopf"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.09810v2",
    "title": "Towards a Common Framework for Autoformalization",
    "summary": "Autoformalization has emerged as a term referring to the automation of\nformalization - specifically, the formalization of mathematics using\ninteractive theorem provers (proof assistants). Its rapid development has been\ndriven by progress in deep learning, especially large language models (LLMs).\nMore recently, the term has expanded beyond mathematics to describe the broader\ntask of translating informal input into formal logical representations. At the\nsame time, a growing body of research explores using LLMs to translate informal\nlanguage into formal representations for reasoning, planning, and knowledge\nrepresentation - often without explicitly referring to this process as\nautoformalization. As a result, despite addressing similar tasks, the largely\nindependent development of these research areas has limited opportunities for\nshared methodologies, benchmarks, and theoretical frameworks that could\naccelerate progress. The goal of this paper is to review - explicit or implicit\n- instances of what can be considered autoformalization and to propose a\nunified framework, encouraging cross-pollination between different fields to\nadvance the development of next generation AI systems.",
    "published": "2025-09-11T19:28:56Z",
    "updated": "2025-10-29T15:27:12Z",
    "link": "http://arxiv.org/pdf/2509.09810v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Agnieszka Mensfelt",
      "David Tena Cucala",
      "Santiago Franco",
      "Angeliki Koutsoukou-Argyraki",
      "Vince Trencsenyi",
      "Kostas Stathis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25621v1",
    "title": "FARSIQA: Faithful and Advanced RAG System for Islamic Question Answering",
    "summary": "The advent of Large Language Models (LLMs) has revolutionized Natural\nLanguage Processing, yet their application in high-stakes, specialized domains\nlike religious question answering is hindered by challenges like hallucination\nand unfaithfulness to authoritative sources. This issue is particularly\ncritical for the Persian-speaking Muslim community, where accuracy and\ntrustworthiness are paramount. Existing Retrieval-Augmented Generation (RAG)\nsystems, relying on simplistic single-pass pipelines, fall short on complex,\nmulti-hop queries requiring multi-step reasoning and evidence aggregation. To\naddress this gap, we introduce FARSIQA, a novel, end-to-end system for Faithful\nAdvanced Question Answering in the Persian Islamic domain. FARSIQA is built\nupon our innovative FAIR-RAG architecture: a Faithful, Adaptive, Iterative\nRefinement framework for RAG. FAIR-RAG employs a dynamic, self-correcting\nprocess: it adaptively decomposes complex queries, assesses evidence\nsufficiency, and enters an iterative loop to generate sub-queries,\nprogressively filling information gaps. Operating on a curated knowledge base\nof over one million authoritative Islamic documents, FARSIQA demonstrates\nsuperior performance. Rigorous evaluation on the challenging IslamicPCQA\nbenchmark shows state-of-the-art performance: the system achieves a remarkable\n97.0% in Negative Rejection - a 40-point improvement over baselines - and a\nhigh Answer Correctness score of 74.3%. Our work establishes a new standard for\nPersian Islamic QA and validates that our iterative, adaptive architecture is\ncrucial for building faithful, reliable AI systems in sensitive domains.",
    "published": "2025-10-29T15:25:34Z",
    "updated": "2025-10-29T15:25:34Z",
    "link": "http://arxiv.org/pdf/2510.25621v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "68T50, 68T05, 68T30",
      "I.2.7; H.3.3"
    ],
    "authors": [
      "Mohammad Aghajani Asl",
      "Behrooz Minaei Bidgoli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25616v1",
    "title": "Don't Blind Your VLA: Aligning Visual Representations for OOD\n  Generalization",
    "summary": "The growing success of Vision-Language-Action (VLA) models stems from the\npromise that pretrained Vision-Language Models (VLMs) can endow agents with\ntransferable world knowledge and vision-language (VL) grounding, laying a\nfoundation for action models with broader generalization. Yet when these VLMs\nare adapted to the action modality, it remains unclear to what extent their\noriginal VL representations and knowledge are preserved. In this work, we\nconduct a systematic study of representation retention during VLA fine-tuning,\nshowing that naive action fine-tuning leads to degradation of visual\nrepresentations. To characterize and measure these effects, we probe VLA's\nhidden representations and analyze attention maps, further, we design a set of\ntargeted tasks and methods that contrast VLA models with their counterpart\nVLMs, isolating changes in VL capabilities induced by action fine-tuning. We\nfurther evaluate a range of strategies for aligning visual representations and\nintroduce a simple yet effective method that mitigates degradation and yields\nimproved generalization to out-of-distribution (OOD) scenarios. Taken together,\nour analysis clarifies the trade-off between action fine-tuning and the\ndegradation of VL representations and highlights practical approaches to\nrecover inherited VL capabilities. Code is publicly available:\nhttps://blind-vla-paper.github.io",
    "published": "2025-10-29T15:20:10Z",
    "updated": "2025-10-29T15:20:10Z",
    "link": "http://arxiv.org/pdf/2510.25616v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "authors": [
      "Nikita Kachaev",
      "Mikhail Kolosov",
      "Daniil Zelezetsky",
      "Alexey K. Kovalev",
      "Aleksandr I. Panov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25612v1",
    "title": "Counterfactual-based Agent Influence Ranker for Agentic AI Workflows",
    "summary": "An Agentic AI Workflow (AAW), also known as an LLM-based multi-agent system,\nis an autonomous system that assembles several LLM-based agents to work\ncollaboratively towards a shared goal. The high autonomy, widespread adoption,\nand growing interest in such AAWs highlight the need for a deeper understanding\nof their operations, from both quality and security aspects. To this day, there\nare no existing methods to assess the influence of each agent on the AAW's\nfinal output. Adopting techniques from related fields is not feasible since\nexisting methods perform only static structural analysis, which is unsuitable\nfor inference time execution. We present Counterfactual-based Agent Influence\nRanker (CAIR) - the first method for assessing the influence level of each\nagent on the AAW's output and determining which agents are the most\ninfluential. By performing counterfactual analysis, CAIR provides a\ntask-agnostic analysis that can be used both offline and at inference time. We\nevaluate CAIR using an AAWs dataset of our creation, containing 30 different\nuse cases with 230 different functionalities. Our evaluation showed that CAIR\nproduces consistent rankings, outperforms baseline methods, and can easily\nenhance the effectiveness and relevancy of downstream tasks.",
    "published": "2025-10-29T15:17:31Z",
    "updated": "2025-10-29T15:17:31Z",
    "link": "http://arxiv.org/pdf/2510.25612v1.pdf",
    "category": [
      "cs.AI",
      "cs.MA"
    ],
    "authors": [
      "Amit Giloni",
      "Chiara Picardi",
      "Roy Betser",
      "Shamik Bose",
      "Aishvariya Priya Rathina Sabapathy",
      "Roman Vainshtein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25609v1",
    "title": "BOLT-GAN: Bayes-Optimal Loss for Stable GAN Training",
    "summary": "We introduce BOLT-GAN, a simple yet effective modification of the WGAN\nframework inspired by the Bayes Optimal Learning Threshold (BOLT). We show that\nwith a Lipschitz continuous discriminator, BOLT-GAN implicitly minimizes a\ndifferent metric distance than the Earth Mover (Wasserstein) distance and\nachieves better training stability. Empirical evaluations on four standard\nimage generation benchmarks (CIFAR-10, CelebA-64, LSUN Bedroom-64, and LSUN\nChurch-64) show that BOLT-GAN consistently outperforms WGAN, achieving 10-60%\nlower Frechet Inception Distance (FID). Our results suggest that BOLT is a\nbroadly applicable principle for enhancing GAN training.",
    "published": "2025-10-29T15:16:50Z",
    "updated": "2025-10-29T15:16:50Z",
    "link": "http://arxiv.org/pdf/2510.25609v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "eess.SP",
      "68T07",
      "I.2.6; I.5.1"
    ],
    "authors": [
      "Mohammadreza Tavasoli Naeini",
      "Ali Bereyhi",
      "Morteza Noshad",
      "Ben Liang",
      "Alfred O. Hero III"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23112v2",
    "title": "GroupSHAP-Guided Integration of Financial News Keywords and Technical\n  Indicators for Stock Price Prediction",
    "summary": "Recent advances in finance-specific language models such as FinBERT have\nenabled the quantification of public sentiment into index-based measures, yet\ncompressing diverse linguistic signals into single metrics overlooks contextual\nnuances and limits interpretability. To address this limitation, explainable AI\ntechniques, particularly SHAP (SHapley Additive Explanations), have been\nemployed to identify influential features. However, SHAP's computational cost\ngrows exponentially with input features, making it impractical for large-scale\ntext-based financial data. This study introduces a GRU-based forecasting\nframework enhanced with GroupSHAP, which quantifies contributions of\nsemantically related keyword groups rather than individual tokens,\nsubstantially reducing computational burden while preserving interpretability.\nWe employed FinBERT to embed news articles from 2015 to 2024, clustered them\ninto coherent semantic groups, and applied GroupSHAP to measure each group's\ncontribution to stock price movements. The resulting group-level SHAP variables\nacross multiple topics were used as input features for the prediction model.\nEmpirical results from one-day-ahead forecasting of the S&P 500 index\nthroughout 2024 demonstrate that our approach achieves a 32.2% reduction in MAE\nand a 40.5% reduction in RMSE compared with benchmark models without the\nGroupSHAP mechanism. This research presents the first application of GroupSHAP\nin news-driven financial forecasting, showing that grouped sentiment\nrepresentations simultaneously enhance interpretability and predictive\nperformance.",
    "published": "2025-10-27T08:33:18Z",
    "updated": "2025-10-29T15:14:17Z",
    "link": "http://arxiv.org/pdf/2510.23112v2.pdf",
    "category": [
      "cs.CE",
      "cs.AI"
    ],
    "authors": [
      "Minjoo Kim",
      "Jinwoong Kim",
      "Sangjin Park"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25602v1",
    "title": "INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization\n  Formats",
    "summary": "Modern AI hardware, such as Nvidia's Blackwell architecture, is increasingly\nembracing low-precision floating-point (FP) formats to handle the pervasive\nactivation outliers in Large Language Models (LLMs). Despite this industry\ntrend, a unified comparison of FP and integer (INT) quantization across varying\ngranularities has been missing, leaving algorithm and hardware co-design\nwithout clear guidance. This paper fills that gap by systematically\ninvestigating the trade-offs between FP and INT formats. We reveal a critical\nperformance crossover: while FP excels in coarse-grained quantization, the\ncomparison at fine-grained (block-wise) levels is more nuanced. Our\ncomprehensive comparison demonstrates that for popular 8-bit fine-grained\nformats (e.g., MX with block size 32), MXINT8 is superior to its FP counterpart\nin both algorithmic accuracy and hardware efficiency. However, for 4-bit\nformats, FP (e.g., MXFP4, NVFP4) often holds an accuracy advantage , though we\nshow that NVINT4 can surpass NVFP4 when outlier-mitigation techniques like\nHadamard rotation are applied. We also introduce a symmetric clipping method\nthat resolves gradient bias in fine-grained low-bit INT training, enabling\nnearly lossless performance for MXINT8 training. These findings challenge the\ncurrent hardware trajectory, demonstrating that a one-size-fits-all FP approach\nis suboptimal and advocating that fine-grained INT formats, particularly\nMXINT8, offer a better balance of accuracy, power, and efficiency for future AI\naccelerators.",
    "published": "2025-10-29T15:11:53Z",
    "updated": "2025-10-29T15:11:53Z",
    "link": "http://arxiv.org/pdf/2510.25602v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Mengzhao Chen",
      "Meng Wu",
      "Hui Jin",
      "Zhihang Yuan",
      "Jing Liu",
      "Chaoyi Zhang",
      "Yunshui Li",
      "Jie Huang",
      "Jin Ma",
      "Zeyue Xue",
      "Zhiheng Liu",
      "Xingyan Bin",
      "Ping Luo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.12437v2",
    "title": "A method for the systematic generation of graph XAI benchmarks via\n  Weisfeiler-Leman coloring",
    "summary": "Graph neural networks have become the de facto model for learning from\nstructured data. However, the decision-making process of GNNs remains opaque to\nthe end user, which undermines their use in safety-critical applications.\nSeveral explainable AI techniques for graphs have been developed to address\nthis major issue. Focusing on graph classification, these explainers identify\nsubgraph motifs that explain predictions. Therefore, a robust benchmarking of\ngraph explainers is required to ensure that the produced explanations are of\nhigh quality, i.e., aligned with the GNN's decision process. However, current\ngraph-XAI benchmarks are limited to simplistic synthetic datasets or a few\nreal-world tasks curated by domain experts, hindering rigorous and reproducible\nevaluation, and consequently stalling progress in the field. To overcome these\nlimitations, we propose a method to automate the construction of graph XAI\nbenchmarks from generic graph classification datasets. Our approach leverages\nthe Weisfeiler-Leman color refinement algorithm to efficiently perform\napproximate subgraph matching and mine class-discriminating motifs, which serve\nas proxy ground-truth class explanations. At the same time, we ensure that\nthese motifs can be learned by GNNs because their discriminating power aligns\nwith WL expressiveness. This work also introduces the OpenGraphXAI benchmark\nsuite, which consists of 15 ready-made graph-XAI datasets derived by applying\nour method to real-world molecular classification datasets. The suite is\navailable to the public along with a codebase to generate over 2,000 additional\ngraph-XAI benchmarks. Finally, we present a use case that illustrates how the\nsuite can be used to assess the effectiveness of a selection of popular graph\nexplainers, demonstrating the critical role of a sufficiently large benchmark\ncollection for improving the significance of experimental results.",
    "published": "2025-05-18T14:19:52Z",
    "updated": "2025-10-29T15:09:38Z",
    "link": "http://arxiv.org/pdf/2505.12437v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Michele Fontanesi",
      "Alessio Micheli",
      "Marco Podda",
      "Domenico Tortorella"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25595v1",
    "title": "Communication and Verification in LLM Agents towards Collaboration under\n  Information Asymmetry",
    "summary": "While Large Language Model (LLM) agents are often approached from the angle\nof action planning/generation to accomplish a goal (e.g., given by language\ndescriptions), their abilities to collaborate with each other to achieve a\njoint goal are not well explored. To address this limitation, this paper\nstudies LLM agents in task collaboration, particularly under the condition of\ninformation asymmetry, where agents have disparities in their knowledge and\nskills and need to work together to complete a shared task. We extend Einstein\nPuzzles, a classical symbolic puzzle, to a table-top game. In this game, two\nLLM agents must reason, communicate, and act to satisfy spatial and relational\nconstraints required to solve the puzzle. We apply a fine-tuning-plus-verifier\nframework in which LLM agents are equipped with various communication\nstrategies and verification signals from the environment. Empirical results\nhighlight the critical importance of aligned communication, especially when\nagents possess both information-seeking and -providing capabilities.\nInterestingly, agents without communication can still achieve high task\nperformance; however, further analysis reveals a lack of true rule\nunderstanding and lower trust from human evaluators. Instead, by integrating an\nenvironment-based verifier, we enhance agents' ability to comprehend task rules\nand complete tasks, promoting both safer and more interpretable collaboration\nin AI systems. https://github.com/Roihn/EinsteinPuzzles",
    "published": "2025-10-29T15:03:53Z",
    "updated": "2025-10-29T15:03:53Z",
    "link": "http://arxiv.org/pdf/2510.25595v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Run Peng",
      "Ziqiao Ma",
      "Amy Pang",
      "Sikai Li",
      "Zhang Xi-Jia",
      "Yingzhuo Yu",
      "Cristian-Paul Bara",
      "Joyce Chai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25590v1",
    "title": "RegionE: Adaptive Region-Aware Generation for Efficient Image Editing",
    "summary": "Recently, instruction-based image editing (IIE) has received widespread\nattention. In practice, IIE often modifies only specific regions of an image,\nwhile the remaining areas largely remain unchanged. Although these two types of\nregions differ significantly in generation difficulty and computational\nredundancy, existing IIE models do not account for this distinction, instead\napplying a uniform generation process across the entire image. This motivates\nus to propose RegionE, an adaptive, region-aware generation framework that\naccelerates IIE tasks without additional training. Specifically, the RegionE\nframework consists of three main components: 1) Adaptive Region Partition. We\nobserved that the trajectory of unedited regions is straight, allowing for\nmulti-step denoised predictions to be inferred in a single step. Therefore, in\nthe early denoising stages, we partition the image into edited and unedited\nregions based on the difference between the final estimated result and the\nreference image. 2) Region-Aware Generation. After distinguishing the regions,\nwe replace multi-step denoising with one-step prediction for unedited areas.\nFor edited regions, the trajectory is curved, requiring local iterative\ndenoising. To improve the efficiency and quality of local iterative generation,\nwe propose the Region-Instruction KV Cache, which reduces computational cost\nwhile incorporating global information. 3) Adaptive Velocity Decay Cache.\nObserving that adjacent timesteps in edited regions exhibit strong velocity\nsimilarity, we further propose an adaptive velocity decay cache to accelerate\nthe local denoising process. We applied RegionE to state-of-the-art IIE base\nmodels, including Step1X-Edit, FLUX.1 Kontext, and Qwen-Image-Edit. RegionE\nachieved acceleration factors of 2.57, 2.41, and 2.06. Evaluations by GPT-4o\nconfirmed that semantic and perceptual fidelity were well preserved.",
    "published": "2025-10-29T14:58:37Z",
    "updated": "2025-10-29T14:58:37Z",
    "link": "http://arxiv.org/pdf/2510.25590v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Pengtao Chen",
      "Xianfang Zeng",
      "Maosen Zhao",
      "Mingzhu Shen",
      "Peng Ye",
      "Bangyin Xiang",
      "Zhibo Wang",
      "Wei Cheng",
      "Gang Yu",
      "Tao Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25588v1",
    "title": "Standardization of Psychiatric Diagnoses -- Role of Fine-tuned LLM\n  Consortium and OpenAI-gpt-oss Reasoning LLM Enabled Decision Support System",
    "summary": "The diagnosis of most mental disorders, including psychiatric evaluations,\nprimarily depends on dialogues between psychiatrists and patients. This\nsubjective process can lead to variability in diagnoses across clinicians and\npatients, resulting in inconsistencies and challenges in achieving reliable\noutcomes. To address these issues and standardize psychiatric diagnoses, we\npropose a Fine-Tuned Large Language Model (LLM) Consortium and OpenAI-gpt-oss\nReasoning LLM-enabled Decision Support System for the clinical diagnosis of\nmental disorders. Our approach leverages fine-tuned LLMs trained on\nconversational datasets involving psychiatrist-patient interactions focused on\nmental health conditions (e.g., depression). The diagnostic predictions from\nindividual models are aggregated through a consensus-based decision-making\nprocess, refined by the OpenAI-gpt-oss reasoning LLM. We propose a novel method\nfor deploying LLM agents that orchestrate communication between the LLM\nconsortium and the reasoning LLM, ensuring transparency, reliability, and\nresponsible AI across the entire diagnostic workflow. Experimental results\ndemonstrate the transformative potential of combining fine-tuned LLMs with a\nreasoning model to create a robust and highly accurate diagnostic system for\nmental health assessment. A prototype of the proposed platform, integrating\nthree fine-tuned LLMs with the OpenAI-gpt-oss reasoning LLM, was developed in\ncollaboration with the U.S. Army Medical Research Team in Norfolk, Virginia,\nUSA. To the best of our knowledge, this work represents the first application\nof a fine-tuned LLM consortium integrated with a reasoning LLM for clinical\nmental health diagnosis paving the way for next-generation AI-powered eHealth\nsystems aimed at standardizing psychiatric diagnoses.",
    "published": "2025-10-29T14:54:22Z",
    "updated": "2025-10-29T14:54:22Z",
    "link": "http://arxiv.org/pdf/2510.25588v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Eranga Bandara",
      "Ross Gore",
      "Atmaram Yarlagadda",
      "Anita H. Clayton",
      "Preston Samuel",
      "Christopher K. Rhea",
      "Sachin Shetty"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.12484v4",
    "title": "Robust LLM Unlearning with MUDMAN: Meta-Unlearning with Disruption\n  Masking And Normalization",
    "summary": "Language models can retain dangerous knowledge and skills even after\nextensive safety fine-tuning, posing both misuse and misalignment risks. Recent\nstudies show that even specialized unlearning methods can be easily reversed.\nTo address this, we systematically evaluate many existing and novel components\nof unlearning methods and identify ones crucial for irreversible unlearning.\n  We introduce Disruption Masking, a technique in which we only allow updating\nweights, where the signs of the unlearning gradient and the retaining gradient\nare the same. This ensures all updates are non-disruptive.\n  Additionally, we identify the need for normalizing the unlearning gradients,\nand also confirm the usefulness of meta-learning. We combine these insights\ninto MUDMAN (Meta-Unlearning with Disruption Masking and Normalization) and\nvalidate its effectiveness at preventing the recovery of dangerous\ncapabilities. MUDMAN outperforms the prior TAR method by 40%, setting a new\nstate-of-the-art for robust unlearning.",
    "published": "2025-06-14T12:49:51Z",
    "updated": "2025-10-29T14:52:49Z",
    "link": "http://arxiv.org/pdf/2506.12484v4.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Filip Sondej",
      "Yushi Yang",
      "Mikołaj Kniejski",
      "Marcel Windys"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2402.16714v3",
    "title": "Quantum Transformer: Accelerating model inference via quantum linear\n  algebra",
    "summary": "Powerful generative artificial intelligence from large language models (LLMs)\nharnesses extensive computational resources for inference. In this work, we\ninvestigate the transformer architecture, a key component of these models,\nunder the lens of fault-tolerant quantum computing. We develop quantum\nsubroutines to construct the building blocks in the transformer, including the\nself-attention, residual connection with layer normalization, and feed-forward\nnetwork. As an important subroutine, we show how to efficiently implement the\nHadamard product and element-wise functions of matrices on quantum computers.\nOur algorithm prepares an amplitude encoding of the transformer output, which\ncan be measured for prediction or use in the next layer. We find that the\nmatrix norm of the input sequence plays a dominant role in the quantum\ncomplexity. With numerical experiments on open-source LLMs, including for\nbio-informatics applications, we demonstrate the potential of a quantum speedup\nfor transformer inference in practical regimes.",
    "published": "2024-02-26T16:31:28Z",
    "updated": "2025-10-29T14:48:21Z",
    "link": "http://arxiv.org/pdf/2402.16714v3.pdf",
    "category": [
      "quant-ph",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Naixu Guo",
      "Zhan Yu",
      "Matthew Choi",
      "Yizhan Han",
      "Aman Agrawal",
      "Kouhei Nakaji",
      "Alán Aspuru-Guzik",
      "Patrick Rebentrost"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25577v1",
    "title": "Lost in Phonation: Voice Quality Variation as an Evaluation Dimension\n  for Speech Foundation Models",
    "summary": "Recent advances in speech foundation models (SFMs) have enabled the direct\nprocessing of spoken language from raw audio, bypassing intermediate textual\nrepresentations. This capability allows SFMs to be exposed to, and potentially\nrespond to, rich paralinguistic variations embedded in the input speech signal.\nOne under-explored dimension of paralinguistic variation is voice quality,\nencompassing phonation types such as creaky and breathy voice. These phonation\ntypes are known to influence how listeners infer affective state, stance and\nsocial meaning in speech. Existing benchmarks for speech understanding largely\nrely on multiple-choice question answering (MCQA) formats, which are prone to\nfailure and therefore unreliable in capturing the nuanced ways paralinguistic\nfeatures influence model behaviour. In this paper, we probe SFMs through\nopen-ended generation tasks and speech emotion recognition, evaluating whether\nmodel behaviours are consistent across different phonation inputs. We introduce\na new parallel dataset featuring synthesized modifications to voice quality,\ndesigned to evaluate SFM responses to creaky and breathy voice. Our work\nprovides the first examination of SFM sensitivity to these particular\nnon-lexical aspects of speech perception.",
    "published": "2025-10-29T14:44:44Z",
    "updated": "2025-10-29T14:44:44Z",
    "link": "http://arxiv.org/pdf/2510.25577v1.pdf",
    "category": [
      "eess.AS",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Harm Lameris",
      "Shree Harsha Bokkahalli Satish",
      "Joakim Gustafson",
      "Éva Székely"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.10940v3",
    "title": "Who You Are Matters: Bridging Topics and Social Roles via LLM-Enhanced\n  Logical Recommendation",
    "summary": "Recommender systems filter contents/items valuable to users by inferring\npreferences from user features and historical behaviors. Mainstream approaches\nfollow the learning-to-rank paradigm, which focus on discovering and modeling\nitem topics (e.g., categories), and capturing user preferences on these topics\nbased on historical interactions. However, this paradigm often neglects the\nmodeling of user characteristics and their social roles, which are logical\nconfounders influencing the correlated interest and user preference transition.\nTo bridge this gap, we introduce the user role identification task and the\nbehavioral logic modeling task that aim to explicitly model user roles and\nlearn the logical relations between item topics and user social roles. We show\nthat it is possible to explicitly solve these tasks through an efficient\nintegration framework of Large Language Model (LLM) and recommendation systems,\nfor which we propose TagCF. On the one hand, TagCF exploits the (Multi-modal)\nLLM's world knowledge and logic inference ability to extract realistic\ntag-based virtual logic graphs that reveal dynamic and expressive knowledge of\nusers, refining our understanding of user behaviors. On the other hand, TagCF\npresents empirically effective integration modules that take advantage of the\nextracted tag-logic information, augmenting the recommendation performance. We\nconduct both online experiments and offline experiments with industrial and\npublic datasets as verification of TagCF's effectiveness, and we empirically\nshow that the user role modeling strategy is potentially a better choice than\nthe modeling of item topics. Additionally, we provide evidence that the\nextracted logic graphs are empirically a general and transferable knowledge\nthat can benefit a wide range of recommendation tasks. Our code is available in\nhttps://github.com/Code2Q/TagCF.",
    "published": "2025-05-16T07:26:41Z",
    "updated": "2025-10-29T14:42:46Z",
    "link": "http://arxiv.org/pdf/2505.10940v3.pdf",
    "category": [
      "cs.IR",
      "cs.AI"
    ],
    "authors": [
      "Qing Yu",
      "Xiaobei Wang",
      "Shuchang Liu",
      "Yandong Bai",
      "Xiaoyu Yang",
      "Xueliang Wang",
      "Chang Meng",
      "Shanshan Wu",
      "Hailan Yang",
      "Huihui Xiao",
      "Xiang Li",
      "Fan Yang",
      "Xiaoqiang Feng",
      "Lantao Hu",
      "Han Li",
      "Kun Gai",
      "Lixin Zou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.22117v2",
    "title": "The AI_INFN Platform: Artificial Intelligence Development in the Cloud",
    "summary": "Machine Learning (ML) is profoundly reshaping the way researchers create,\nimplement, and operate data-intensive software. Its adoption, however,\nintroduces notable challenges for computing infrastructures, particularly when\nit comes to coordinating access to hardware accelerators across development,\ntesting, and production environments. The INFN initiative AI_INFN (Artificial\nIntelligence at INFN) seeks to promote the use of ML methods across various\nINFN research scenarios by offering comprehensive technical support, including\naccess to AI-focused computational resources. Leveraging the INFN Cloud\necosystem and cloud-native technologies, the project emphasizes efficient\nsharing of accelerator hardware while maintaining the breadth of the\nInstitute's research activities. This contribution describes the deployment and\ncommissioning of a Kubernetes-based platform designed to simplify GPU-powered\ndata analysis workflows and enable their scalable execution on heterogeneous\ndistributed resources. By integrating offloading mechanisms through Virtual\nKubelet and the InterLink API, the platform allows workflows to span multiple\nresource providers, from Worldwide LHC Computing Grid sites to high-performance\ncomputing centers like CINECA Leonardo. We will present preliminary benchmarks,\nfunctional tests, and case studies, demonstrating both performance and\nintegration outcomes.",
    "published": "2025-09-26T09:40:51Z",
    "updated": "2025-10-29T14:33:07Z",
    "link": "http://arxiv.org/pdf/2509.22117v2.pdf",
    "category": [
      "cs.DC",
      "cs.AI"
    ],
    "authors": [
      "Lucio Anderlini",
      "Giulio Bianchini",
      "Diego Ciangottini",
      "Stefano Dal Pra",
      "Diego Michelotto",
      "Rosa Petrini",
      "Daniele Spiga"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.15030v2",
    "title": "Collab-REC: An LLM-based Agentic Framework for Balancing Recommendations\n  in Tourism",
    "summary": "We propose Collab-REC, a multi-agent framework designed to counteract\npopularity bias and enhance diversity in tourism recommendations. In our\nsetting, three LLM-based agents -- Personalization, Popularity, and\nSustainability generate city suggestions from complementary perspectives. A\nnon-LLM moderator then merges and refines these proposals via multi-round\nnegotiation, ensuring each agent's viewpoint is incorporated while penalizing\nspurious or repeated responses. Experiments on European city queries show that\nCollab-REC improves diversity and overall relevance compared to a single-agent\nbaseline, surfacing lesser-visited locales that often remain overlooked. This\nbalanced, context-aware approach addresses over-tourism and better aligns with\nconstraints provided by the user, highlighting the promise of multi-stakeholder\ncollaboration in LLM-driven recommender systems.",
    "published": "2025-08-20T19:49:06Z",
    "updated": "2025-10-29T14:31:38Z",
    "link": "http://arxiv.org/pdf/2508.15030v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Ashmi Banerjee",
      "Fitri Nur Aisyah",
      "Adithi Satish",
      "Wolfgang Wörndl",
      "Yashar Deldjoo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.13519v2",
    "title": "Continuous Domain Generalization",
    "summary": "Real-world data distributions often shift continuously across multiple latent\nfactors such as time, geography, and socioeconomic contexts. However, existing\ndomain generalization approaches typically treat domains as discrete or as\nevolving along a single axis (e.g., time). This oversimplification fails to\ncapture the complex, multidimensional nature of real-world variation. This\npaper introduces the task of Continuous Domain Generalization (CDG), which aims\nto generalize predictive models to unseen domains defined by arbitrary\ncombinations of continuous variations. We present a principled framework\ngrounded in geometric and algebraic theories, showing that optimal model\nparameters across domains lie on a low-dimensional manifold. To model this\nstructure, we propose a Neural Lie Transport Operator (NeuralLio), which\nenables structure-preserving parameter transitions by enforcing geometric\ncontinuity and algebraic consistency. To handle noisy or incomplete domain\nvariation descriptors, we introduce a gating mechanism to suppress irrelevant\ndimensions and a local chart-based strategy for robust generalization.\nExtensive experiments on synthetic and real-world datasets, including remote\nsensing, scientific documents, and traffic forecasting, demonstrate that our\nmethod significantly outperforms existing baselines in both generalization\naccuracy and robustness.",
    "published": "2025-05-17T12:39:45Z",
    "updated": "2025-10-29T14:31:32Z",
    "link": "http://arxiv.org/pdf/2505.13519v2.pdf",
    "category": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Zekun Cai",
      "Yiheng Yao",
      "Guangji Bai",
      "Renhe Jiang",
      "Xuan Song",
      "Ryosuke Shibasaki",
      "Liang Zhao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25563v1",
    "title": "Leveraging an Atmospheric Foundational Model for Subregional Sea Surface\n  Temperature Forecasting",
    "summary": "The accurate prediction of oceanographic variables is crucial for\nunderstanding climate change, managing marine resources, and optimizing\nmaritime activities. Traditional ocean forecasting relies on numerical models;\nhowever, these approaches face limitations in terms of computational cost and\nscalability. In this study, we adapt Aurora, a foundational deep learning model\noriginally designed for atmospheric forecasting, to predict sea surface\ntemperature (SST) in the Canary Upwelling System. By fine-tuning this model\nwith high-resolution oceanographic reanalysis data, we demonstrate its ability\nto capture complex spatiotemporal patterns while reducing computational\ndemands. Our methodology involves a staged fine-tuning process, incorporating\nlatitude-weighted error metrics and optimizing hyperparameters for efficient\nlearning. The experimental results show that the model achieves a low RMSE of\n0.119K, maintaining high anomaly correlation coefficients (ACC $\\approx\n0.997$). The model successfully reproduces large-scale SST structures but faces\nchallenges in capturing finer details in coastal regions. This work contributes\nto the field of data-driven ocean forecasting by demonstrating the feasibility\nof using deep learning models pre-trained in different domains for oceanic\napplications. Future improvements include integrating additional oceanographic\nvariables, increasing spatial resolution, and exploring physics-informed neural\nnetworks to enhance interpretability and understanding. These advancements can\nimprove climate modeling and ocean prediction accuracy, supporting\ndecision-making in environmental and economic sectors.",
    "published": "2025-10-29T14:30:12Z",
    "updated": "2025-10-29T14:30:12Z",
    "link": "http://arxiv.org/pdf/2510.25563v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph"
    ],
    "authors": [
      "Víctor Medina",
      "Giovanny A. Cuervo-Londoño",
      "Javier Sánchez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25557v1",
    "title": "Hybrid Quantum-Classical Recurrent Neural Networks",
    "summary": "We present a hybrid quantum-classical recurrent neural network (QRNN)\narchitecture in which the entire recurrent core is realized as a parametrized\nquantum circuit (PQC) controlled by a classical feedforward network. The hidden\nstate is the quantum state of an $n$-qubit PQC, residing in an exponentially\nlarge Hilbert space $\\mathbb{C}^{2^n}$. The PQC is unitary by construction,\nmaking the hidden-state evolution norm-preserving without external constraints.\nAt each timestep, mid-circuit readouts are combined with the input embedding\nand processed by the feedforward network, which provides explicit classical\nnonlinearity. The outputs parametrize the PQC, which updates the hidden state\nvia unitary dynamics. The QRNN is compact and physically consistent, and it\nunifies (i) unitary recurrence as a high-capacity memory, (ii) partial\nobservation via mid-circuit measurements, and (iii) nonlinear classical control\nfor input-conditioned parametrization. We evaluate the model in simulation with\nup to 14 qubits on sentiment analysis, MNIST, permuted MNIST, copying memory,\nand language modeling, adopting projective measurements as a limiting case to\nobtain mid-circuit readouts while maintaining a coherent recurrent quantum\nmemory. We further devise a soft attention mechanism over the mid-circuit\nreadouts in a sequence-to-sequence model and show its effectiveness for machine\ntranslation. To our knowledge, this is the first model (RNN or otherwise)\ngrounded in quantum operations to achieve competitive performance against\nstrong classical baselines across a broad class of sequence-learning tasks.",
    "published": "2025-10-29T14:21:49Z",
    "updated": "2025-10-29T14:21:49Z",
    "link": "http://arxiv.org/pdf/2510.25557v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "quant-ph"
    ],
    "authors": [
      "Wenduan Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.01308v2",
    "title": "GradeSQL: Test-Time Inference with Outcome Reward Models for Text-to-SQL\n  Generation from Large Language Models",
    "summary": "Text-to-SQL, the task of translating natural language questions into SQL\nqueries, has significantly advanced with the introduction of Large Language\nModels (LLMs), broadening database accessibility for a wide range of users.\nDespite substantial progress in generating valid SQL, current LLMs still\nstruggle with complex queries. To address this limitation, test-time strategies\nsuch as Best-of-N (BoN) and Majority Voting (Maj) are often employed, based on\nthe assumption that LLMs can produce correct answers after multiple attempts.\nHowever, these methods rely on surface-level heuristics, selecting the\nsyntactically correct query through execution-based BoN (ex-BoN) or the most\nfrequently generated one through Majority Voting. Recently, Outcome Reward\nModels (ORMs), which assign utility scores to generated outputs based on\nsemantic correctness, have emerged as a promising reinforcement learning\napproach for improving model alignment. We argue that ORMs could serve as an\neffective new test-time heuristic, although their application in this context\nremains largely underexplored.\n  In this work, we propose a unified framework for training ORMs tailored to\nthe Text-to-SQL task and assess their effectiveness as a test-time heuristic\nwithin the BoN strategy. We benchmark ORMs against ex-BoN and Maj across the\nBIRD and Spider datasets, fine-tuning diverse open-source LLMs from the Qwen2,\nGranite3, and Llama3 families. Results show that ORMs outperform ex-BoN and\nMaj, achieving execution accuracy gains of +4.33% (BIRD) and +2.10% (Spider)\nover ex-BoN, and +2.91% (BIRD) and +0.93% (Spider) over Maj. We further\ndemonstrate that finetuning models already aligned with SQL generation, such as\nOmniSQL, yields superior ORM performance. Additionally, we observe that ORMs\nachieve competitive results on simple queries and benefit more from an\nincreased number of candidates compared to ex-BoN and Maj.",
    "published": "2025-09-01T09:47:35Z",
    "updated": "2025-10-29T14:09:33Z",
    "link": "http://arxiv.org/pdf/2509.01308v2.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.DB"
    ],
    "authors": [
      "Mattia Tritto",
      "Giuseppe Farano",
      "Dario Di Palma",
      "Gaetano Rossiello",
      "Fedelucio Narducci",
      "Dharmashankar Subramanian",
      "Tommaso Di Noia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.08388v3",
    "title": "Reinforcement Learning Teachers of Test Time Scaling",
    "summary": "Training reasoning language models (LMs) with reinforcement learning (RL) for\none-hot correctness inherently relies on the LM being able to explore and solve\nits task with some chance at initialization. Furthermore, a key use case of\nreasoning LMs is to act as teachers for distilling new students and\ncold-starting future RL iterations rather than being deployed themselves. From\nthese considerations, we introduce a new framework that avoids RL's exploration\nchallenge by training a new class of Reinforcement-Learned Teachers (RLTs)\nfocused on yielding the most effective downstream distillation. RLTs are\nprompted with both the question and solution to each problem, and tasked to\nsimply \"connect-the-dots\" with detailed explanations tailored for their\nstudents. We train RLTs with dense rewards obtained by feeding each explanation\nto the student and testing its understanding of the problem's solution. In\npractice, the raw outputs of a 7B RLT provide higher final performance on\ncompetition and graduate-level tasks than existing distillation and\ncold-starting pipelines that collect and postprocess the reasoning traces of\norders of magnitude larger LMs. Furthermore, RLTs maintain their effectiveness\nwhen training larger students and when applied zero-shot to out-of-distribution\ntasks, unlocking new levels of efficiency and re-usability for the RL reasoning\nframework. Code available at: https://github.com/SakanaAI/RLT",
    "published": "2025-06-10T02:53:24Z",
    "updated": "2025-10-29T14:02:55Z",
    "link": "http://arxiv.org/pdf/2506.08388v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Edoardo Cetin",
      "Tianyu Zhao",
      "Yujin Tang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.21614v3",
    "title": "Huxley-Gödel Machine: Human-Level Coding Agent Development by an\n  Approximation of the Optimal Self-Improving Machine",
    "summary": "Recent studies operationalize self-improvement through coding agents that\nedit their own codebases. They grow a tree of self-modifications through\nexpansion strategies that favor higher software engineering benchmark\nperformance, assuming that this implies more promising subsequent\nself-modifications. However, we identify a mismatch between the agent's\nself-improvement potential (metaproductivity) and its coding benchmark\nperformance, namely the Metaproductivity-Performance Mismatch. Inspired by\nHuxley's concept of clade, we propose a metric ($\\mathrm{CMP}$) that aggregates\nthe benchmark performances of the descendants of an agent as an indicator of\nits potential for self-improvement. We show that, in our self-improving coding\nagent development setting, access to the true $\\mathrm{CMP}$ is sufficient to\nsimulate how the G\\\"odel Machine would behave under certain assumptions. We\nintroduce the Huxley-G\\\"odel Machine (HGM), which, by estimating $\\mathrm{CMP}$\nand using it as guidance, searches the tree of self-modifications. On SWE-bench\nVerified and Polyglot, HGM outperforms prior self-improving coding agent\ndevelopment methods while using fewer allocated CPU hours. Last but not least,\nHGM demonstrates strong transfer to other coding datasets and large language\nmodels. The agent optimized by HGM on SWE-bench Verified with GPT-5-mini and\nevaluated on SWE-bench Lite with GPT-5 achieves human-level performance,\nmatching the best officially checked results of human-engineered coding agents.\nOur code is publicly available at https://github.com/metauto-ai/HGM.",
    "published": "2025-10-24T16:19:41Z",
    "updated": "2025-10-29T13:57:25Z",
    "link": "http://arxiv.org/pdf/2510.21614v3.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Wenyi Wang",
      "Piotr Piękos",
      "Li Nanbo",
      "Firas Laakom",
      "Yimeng Chen",
      "Mateusz Ostaszewski",
      "Mingchen Zhuge",
      "Jürgen Schmidhuber"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25531v1",
    "title": "Using latent representations to link disjoint longitudinal data for\n  mixed-effects regression",
    "summary": "Many rare diseases offer limited established treatment options, leading\npatients to switch therapies when new medications emerge. To analyze the impact\nof such treatment switches within the low sample size limitations of rare\ndisease trials, it is important to use all available data sources. This,\nhowever, is complicated when usage of measurement instruments change during the\nobservation period, for example when instruments are adapted to specific age\nranges. The resulting disjoint longitudinal data trajectories, complicate the\napplication of traditional modeling approaches like mixed-effects regression.\nWe tackle this by mapping observations of each instrument to a aligned\nlow-dimensional temporal trajectory, enabling longitudinal modeling across\ninstruments. Specifically, we employ a set of variational autoencoder\narchitectures to embed item values into a shared latent space for each time\npoint. Temporal disease dynamics and treatment switch effects are then captured\nthrough a mixed-effects regression model applied to latent representations. To\nenable statistical inference, we present a novel statistical testing approach\nthat accounts for the joint parameter estimation of mixed-effects regression\nand variational autoencoders. The methodology is applied to quantify the impact\nof treatment switches for patients with spinal muscular atrophy. Here, our\napproach aligns motor performance items from different measurement instruments\nfor mixed-effects regression and maps estimated effects back to the observed\nitem level to quantify the treatment switch effect. Our approach allows for\nmodel selection as well as for assessing effects of treatment switching. The\nresults highlight the potential of modeling in joint latent representations for\naddressing small data challenges.",
    "published": "2025-10-29T13:56:44Z",
    "updated": "2025-10-29T13:56:44Z",
    "link": "http://arxiv.org/pdf/2510.25531v1.pdf",
    "category": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "68T07",
      "G.3; I.2.6; J.3"
    ],
    "authors": [
      "Clemens Schächter",
      "Maren Hackenberg",
      "Michelle Pfaffenlehner",
      "Félix B. Tambe-Ndonfack",
      "Thorsten Schmidt",
      "Astrid Pechmann",
      "Janbernd Kirschner",
      "Jan Hasenauser",
      "Harald Binder"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25529v1",
    "title": "Off-policy Reinforcement Learning with Model-based Exploration\n  Augmentation",
    "summary": "Exploration is fundamental to reinforcement learning (RL), as it determines\nhow effectively an agent discovers and exploits the underlying structure of its\nenvironment to achieve optimal performance. Existing exploration methods\ngenerally fall into two categories: active exploration and passive exploration.\nThe former introduces stochasticity into the policy but struggles in\nhigh-dimensional environments, while the latter adaptively prioritizes\ntransitions in the replay buffer to enhance exploration, yet remains\nconstrained by limited sample diversity. To address the limitation in passive\nexploration, we propose Modelic Generative Exploration (MoGE), which augments\nexploration through the generation of under-explored critical states and\nsynthesis of dynamics-consistent experiences through transition models. MoGE is\ncomposed of two components: (1) a diffusion-based generator that synthesizes\ncritical states under the guidance of a utility function evaluating each\nstate's potential influence on policy exploration, and (2) a one-step\nimagination world model for constructing critical transitions based on the\ncritical states for agent learning. Our method adopts a modular formulation\nthat aligns with the principles of off-policy learning, allowing seamless\nintegration with existing algorithms to improve exploration without altering\ntheir core structures. Empirical results on OpenAI Gym and DeepMind Control\nSuite reveal that MoGE effectively bridges exploration and policy learning,\nleading to remarkable gains in both sample efficiency and performance across\ncomplex control tasks.",
    "published": "2025-10-29T13:53:52Z",
    "updated": "2025-10-29T13:53:52Z",
    "link": "http://arxiv.org/pdf/2510.25529v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Likun Wang",
      "Xiangteng Zhang",
      "Yinuo Wang",
      "Guojian Zhan",
      "Wenxuan Wang",
      "Haoyu Gao",
      "Jingliang Duan",
      "Shengbo Eben Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25528v1",
    "title": "Zero Reinforcement Learning Towards General Domains",
    "summary": "Zero Reinforcement Learning (Zero-RL) has proven to be an effective approach\nfor enhancing the reasoning capabilities of large language models (LLMs) by\ndirectly applying reinforcement learning with verifiable rewards on pretrained\nmodels, without the need for a supervised fine-tuning phase. However, current\nresearch on zero-RL primarily focuses on domains with easily verifiable reward\nsignals, such as mathematics, programming, and other reasoning tasks. The\nchallenge of eliciting reasoning abilities in more diverse scenarios, where\nverification is not straightforward, remains underexplored. To address this\ngap, we propose a novel zero-RL paradigm designed to improve a model's\nreasoning ability across both verifiable and non-verifiable domains. By\ncombining verifiable rewards with a generative reward model, we conduct\nmulti-task zero-RL training across both domains, facilitating the transfer of\nreasoning capabilities between them. Furthermore, to mitigate reward hacking in\nthe generative reward model, we design a smooth length penalty that encourages\nthe generation of more comprehensive thinking tokens in general domains.\nExperimental results on Qwen3-8B-Base and Qwen3-14B-Base demonstrate that our\napproach achieves superior reasoning performance, not only on tasks requiring\nextensive reasoning but also on more general tasks.",
    "published": "2025-10-29T13:52:44Z",
    "updated": "2025-10-29T13:52:44Z",
    "link": "http://arxiv.org/pdf/2510.25528v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Yuyuan Zeng",
      "Yufei Huang",
      "Can Xu",
      "Qingfeng Sun",
      "Jianfeng Yan",
      "Guanghui Xu",
      "Tao Yang",
      "Fengzong Lian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25522v1",
    "title": "Comparative Study of UNet-based Architectures for Liver Tumor\n  Segmentation in Multi-Phase Contrast-Enhanced Computed Tomography",
    "summary": "Segmentation of liver structures in multi-phase contrast-enhanced computed\ntomography (CECT) plays a crucial role in computer-aided diagnosis and\ntreatment planning for liver diseases, including tumor detection. In this\nstudy, we investigate the performance of UNet-based architectures for liver\ntumor segmentation, starting from the original UNet and extending to UNet3+\nwith various backbone networks. We evaluate ResNet, Transformer-based, and\nState-space (Mamba) backbones, all initialized with pretrained weights.\nSurprisingly, despite the advances in modern architecture, ResNet-based models\nconsistently outperform Transformer- and Mamba-based alternatives across\nmultiple evaluation metrics. To further improve segmentation quality, we\nintroduce attention mechanisms into the backbone and observe that incorporating\nthe Convolutional Block Attention Module (CBAM) yields the best performance.\nResNetUNet3+ with CBAM module not only produced the best overlap metrics with a\nDice score of 0.755 and IoU of 0.662, but also achieved the most precise\nboundary delineation, evidenced by the lowest HD95 distance of 77.911. The\nmodel's superiority was further cemented by its leading overall accuracy of\n0.925 and specificity of 0.926, showcasing its robust capability in accurately\nidentifying both lesion and healthy tissue. To further enhance\ninterpretability, Grad-CAM visualizations were employed to highlight the\nregion's most influential predictions, providing insights into its\ndecision-making process. These findings demonstrate that classical ResNet\narchitecture, when combined with modern attention modules, remain highly\ncompetitive for medical image segmentation tasks, offering a promising\ndirection for liver tumor detection in clinical practice.",
    "published": "2025-10-29T13:46:19Z",
    "updated": "2025-10-29T13:46:19Z",
    "link": "http://arxiv.org/pdf/2510.25522v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "I.4.6"
    ],
    "authors": [
      "Doan-Van-Anh Ly",
      "Thi-Thu-Hien Pham",
      "Thanh-Hai Le"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23906v2",
    "title": "Group Interventions on Deep Networks for Causal Discovery in Subsystems",
    "summary": "Causal discovery uncovers complex relationships between variables, enhancing\npredictions, decision-making, and insights into real-world systems, especially\nin nonlinear multivariate time series. However, most existing methods primarily\nfocus on pairwise cause-effect relationships, overlooking interactions among\ngroups of variables, i.e., subsystems and their collective causal influence. In\nthis study, we introduce gCDMI, a novel multi-group causal discovery method\nthat leverages group-level interventions on trained deep neural networks and\nemploys model invariance testing to infer causal relationships. Our approach\ninvolves three key steps. First, we use deep learning to jointly model the\nstructural relationships among groups of all time series. Second, we apply\ngroup-wise interventions to the trained model. Finally, we conduct model\ninvariance testing to determine the presence of causal links among variable\ngroups. We evaluate our method on simulated datasets, demonstrating its\nsuperior performance in identifying group-level causal relationships compared\nto existing methods. Additionally, we validate our approach on real-world\ndatasets, including brain networks and climate ecosystems. Our results\nhighlight that applying group-level interventions to deep learning models,\ncombined with invariance testing, can effectively reveal complex causal\nstructures, offering valuable insights for domains such as neuroscience and\nclimate science.",
    "published": "2025-10-27T22:26:20Z",
    "updated": "2025-10-29T13:42:56Z",
    "link": "http://arxiv.org/pdf/2510.23906v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Wasim Ahmad",
      "Joachim Denzler",
      "Maha Shadaydeh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25518v1",
    "title": "Retrieval Augmented Generation (RAG) for Fintech: Agentic Design and\n  Evaluation",
    "summary": "Retrieval-Augmented Generation (RAG) systems often face limitations in\nspecialized domains such as fintech, where domain-specific ontologies, dense\nterminology, and acronyms complicate effective retrieval and synthesis. This\npaper introduces an agentic RAG architecture designed to address these\nchallenges through a modular pipeline of specialized agents. The proposed\nsystem supports intelligent query reformulation, iterative sub-query\ndecomposition guided by keyphrase extraction, contextual acronym resolution,\nand cross-encoder-based context re-ranking. We evaluate our approach against a\nstandard RAG baseline using a curated dataset of 85 question--answer--reference\ntriples derived from an enterprise fintech knowledge base. Experimental results\ndemonstrate that the agentic RAG system outperforms the baseline in retrieval\nprecision and relevance, albeit with increased latency. These findings suggest\nthat structured, multi-agent methodologies offer a promising direction for\nenhancing retrieval robustness in complex, domain-specific settings.",
    "published": "2025-10-29T13:41:36Z",
    "updated": "2025-10-29T13:41:36Z",
    "link": "http://arxiv.org/pdf/2510.25518v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Thomas Cook",
      "Richard Osuagwu",
      "Liman Tsatiashvili",
      "Vrynsia Vrynsia",
      "Koustav Ghosal",
      "Maraim Masoud",
      "Riccardo Mattivi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25517v1",
    "title": "Predicate Renaming via Large Language Models",
    "summary": "In this paper, we address the problem of giving names to predicates in logic\nrules using Large Language Models (LLMs). In the context of Inductive Logic\nProgramming, various rule generation methods produce rules containing unnamed\npredicates, with Predicate Invention being a key example. This hinders the\nreadability, interpretability, and reusability of the logic theory. Leveraging\nrecent advancements in LLMs development, we explore their ability to process\nnatural language and code to provide semantically meaningful suggestions for\ngiving a name to unnamed predicates. The evaluation of our approach on some\nhand-crafted logic rules indicates that LLMs hold potential for this task.",
    "published": "2025-10-29T13:39:41Z",
    "updated": "2025-10-29T13:39:41Z",
    "link": "http://arxiv.org/pdf/2510.25517v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Elisabetta Gentili",
      "Tony Ribeiro",
      "Fabrizio Riguzzi",
      "Katsumi Inoue"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.00814v2",
    "title": "Many LLMs Are More Utilitarian Than One",
    "summary": "Moral judgment is integral to large language models' (LLMs) social reasoning.\nAs multi-agent systems gain prominence, it becomes crucial to understand how\nLLMs function when collaborating compared to operating as individual agents. In\nhuman moral judgment, group deliberation leads to a Utilitarian Boost: a\ntendency to endorse norm violations that inflict harm but maximize benefits for\nthe greatest number of people. We study whether a similar dynamic emerges in\nmulti-agent LLM systems. We test six models on well-established sets of moral\ndilemmas across two conditions: (1) Solo, where models reason independently,\nand (2) Group, where they engage in multi-turn discussions in pairs or triads.\nIn personal dilemmas, where agents decide whether to directly harm an\nindividual for the benefit of others, all models rated moral violations as more\nacceptable when part of a group, demonstrating a Utilitarian Boost similar to\nthat observed in humans. However, the mechanism for the Boost in LLMs differed:\nWhile humans in groups become more utilitarian due to heightened sensitivity to\ndecision outcomes, LLM groups showed either reduced sensitivity to norms or\nenhanced impartiality. We report model differences in when and how strongly the\nBoost manifests. We also discuss prompt and agent compositions that enhance or\nmitigate the effect. We end with a discussion of the implications for AI\nalignment, multi-agent design, and artificial moral reasoning. Code available\nat: https://github.com/baltaci-r/MoralAgents",
    "published": "2025-07-01T14:46:16Z",
    "updated": "2025-10-29T13:37:41Z",
    "link": "http://arxiv.org/pdf/2507.00814v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "I.2.7; I.2.11"
    ],
    "authors": [
      "Anita Keshmirian",
      "Razan Baltaji",
      "Babak Hemmatian",
      "Hadi Asghari",
      "Lav R. Varshney"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25512v1",
    "title": "FaCT: Faithful Concept Traces for Explaining Neural Network Decisions",
    "summary": "Deep networks have shown remarkable performance across a wide range of tasks,\nyet getting a global concept-level understanding of how they function remains a\nkey challenge. Many post-hoc concept-based approaches have been introduced to\nunderstand their workings, yet they are not always faithful to the model.\nFurther, they make restrictive assumptions on the concepts a model learns, such\nas class-specificity, small spatial extent, or alignment to human expectations.\nIn this work, we put emphasis on the faithfulness of such concept-based\nexplanations and propose a new model with model-inherent mechanistic\nconcept-explanations. Our concepts are shared across classes and, from any\nlayer, their contribution to the logit and their input-visualization can be\nfaithfully traced. We also leverage foundation models to propose a new\nconcept-consistency metric, C$^2$-Score, that can be used to evaluate\nconcept-based methods. We show that, compared to prior work, our concepts are\nquantitatively more consistent and users find our concepts to be more\ninterpretable, all while retaining competitive ImageNet performance.",
    "published": "2025-10-29T13:35:46Z",
    "updated": "2025-10-29T13:35:46Z",
    "link": "http://arxiv.org/pdf/2510.25512v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Amin Parchami-Araghi",
      "Sukrut Rao",
      "Jonas Fischer",
      "Bernt Schiele"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25510v1",
    "title": "MTIR-SQL: Multi-turn Tool-Integrated Reasoning Reinforcement Learning\n  for Text-to-SQL",
    "summary": "As large language models (LLMs) are increasingly used in Text-to-SQL tasks,\nReinforcement Learning (RL) has become a common method for improving\nperformance. Existing methods primarily rely on static execution feedback,\nwhich restricts real-time error correction. However, integrating multi-turn\ntool invocation along with dynamic feedback could significantly improve\nadaptability and robustness, ultimately enhancing model performance. To address\nthese issues, we propose MTIR-SQL, an innovative Multi-turn Tool-Integrated\nReasoning reinforcement learning framework for Text-to-SQL. Our approach\nintroduces an execution-aware multi-turn reasoning paradigm that seamlessly\nincorporates database execution feedback at each reasoning step, enabling\ncontext-sensitive query generation and progressive refinement throughout the\nreasoning process. The framework extends the GRPO algorithm to accommodate\ncomplex multi-turn interaction scenarios. Considering the training instability\ncharacteristics of MTIR and the potential for significant Deviation of model\ndistribution from the initial model, we enhance the GRPO algorithm by adding a\ntrajectory filtering mechanism and removing KL loss constraints. Experimental\nresults demonstrate that MTIR-SQL, with 4B parameters, achieves \\textbf{64.4}\\%\naccuracy in the BIRD Dev and 84.6% execution accuracy in the SPIDER Dev,\nsignificantly outperforming existing approaches.",
    "published": "2025-10-29T13:34:27Z",
    "updated": "2025-10-29T13:34:27Z",
    "link": "http://arxiv.org/pdf/2510.25510v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Zekun Xu",
      "Siyu Xia",
      "Chuhuai Yue",
      "Jiajun Chai",
      "Mingxue Tian",
      "Xiaohan Wang",
      "Wei Lin",
      "Haoxuan Li",
      "Guojun Yin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25506v1",
    "title": "Reflections on the Reproducibility of Commercial LLM Performance in\n  Empirical Software Engineering Studies",
    "summary": "Large Language Models have gained remarkable interest in industry and\nacademia. The increasing interest in LLMs in academia is also reflected in the\nnumber of publications on this topic over the last years. For instance, alone\n78 of the around 425 publications at ICSE 2024 performed experiments with LLMs.\nConducting empirical studies with LLMs remains challenging and raises questions\non how to achieve reproducible results, for both other researchers and\npractitioners. One important step towards excelling in empirical research on\nLLMs and their application is to first understand to what extent current\nresearch results are eventually reproducible and what factors may impede\nreproducibility. This investigation is within the scope of our work. We\ncontribute an analysis of the reproducibility of LLM-centric studies, provide\ninsights into the factors impeding reproducibility, and discuss suggestions on\nhow to improve the current state. In particular, we studied the 86 articles\ndescribing LLM-centric studies, published at ICSE 2024 and ASE 2024. Of the 86\narticles, 18 provided research artefacts and used OpenAI models. We attempted\nto replicate those 18 studies. Of the 18 studies, only five were fit for\nreproduction. For none of the five studies, we were able to fully reproduce the\nresults. Two studies seemed to be partially reproducible, and three studies did\nnot seem to be reproducible. Our results highlight not only the need for\nstricter research artefact evaluations but also for more robust study designs\nto ensure the reproducible value of future publications.",
    "published": "2025-10-29T13:31:32Z",
    "updated": "2025-10-29T13:31:32Z",
    "link": "http://arxiv.org/pdf/2510.25506v1.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Florian Angermeir",
      "Maximilian Amougou",
      "Mark Kreitz",
      "Andreas Bauer",
      "Matthias Linhuber",
      "Davide Fucci",
      "Fabiola Moyón C.",
      "Daniel Mendez",
      "Tony Gorschek"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25504v1",
    "title": "Multi-Objective Search: Algorithms, Applications, and Emerging\n  Directions",
    "summary": "Multi-objective search (MOS) has emerged as a unifying framework for planning\nand decision-making problems where multiple, often conflicting, criteria must\nbe balanced. While the problem has been studied for decades, recent years have\nseen renewed interest in the topic across AI applications such as robotics,\ntransportation, and operations research, reflecting the reality that real-world\nsystems rarely optimize a single measure. This paper surveys developments in\nMOS while highlighting cross-disciplinary opportunities, and outlines open\nchallenges that define the emerging frontier of MOS",
    "published": "2025-10-29T13:30:01Z",
    "updated": "2025-10-29T13:30:01Z",
    "link": "http://arxiv.org/pdf/2510.25504v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Oren Salzman",
      "Carlos Hernández Ulloa",
      "Ariel Felner",
      "Sven Koenig"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.14755v3",
    "title": "Data-Juicer 2.0: Cloud-Scale Adaptive Data Processing for and with\n  Foundation Models",
    "summary": "Foundation models demand advanced data processing for their vast, multimodal\ndatasets. However, traditional frameworks struggle with the unique complexities\nof multimodal data. In response, we present Data-Juicer 2.0, a data processing\nsystem backed by 100+ data processing operators spanning text, image, video,\nand audio modalities, supporting more critical tasks including data analysis,\nsynthesis, annotation, and foundation model post-training. With seamless\ncompatibility and dedicated optimization for popular dataset hubs like Hugging\nFace and computing engines like Ray, it improves upon its predecessor in terms\nof usability, efficiency, and programmability. It features an easily accessible\nuser interface layer that supports decoupled Python interactions, RESTful APIs,\nand conversational commands. Its new runtime layer offers adaptive execution\nacross diverse scales and environments, abstracting away system complexities.\nExtensive empirical evaluations demonstrate Data-Juicer 2.0's remarkable\nperformance and scalability, highlighting its capability to efficiently process\nTB-level data with 10k+ CPU cores. The system is publicly available and has\nbeen widely adopted in diverse research fields and real-world products such as\nAlibaba Cloud PAI. We actively maintain the system and share practical insights\nto foster research and applications of next-generation foundation models.",
    "published": "2024-12-23T08:29:57Z",
    "updated": "2025-10-29T13:29:20Z",
    "link": "http://arxiv.org/pdf/2501.14755v3.pdf",
    "category": [
      "cs.DC",
      "cs.AI"
    ],
    "authors": [
      "Daoyuan Chen",
      "Yilun Huang",
      "Xuchen Pan",
      "Nana Jiang",
      "Haibin Wang",
      "Yilei Zhang",
      "Ce Ge",
      "Yushuo Chen",
      "Wenhao Zhang",
      "Zhijian Ma",
      "Jun Huang",
      "Wei Lin",
      "Yaliang Li",
      "Bolin Ding",
      "Jingren Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25502v1",
    "title": "TempoPFN: Synthetic Pre-training of Linear RNNs for Zero-shot Time\n  Series Forecasting",
    "summary": "Foundation models for zero-shot time series forecasting face challenges in\nefficient long-horizon prediction and reproducibility, with existing\nsynthetic-only approaches underperforming on challenging benchmarks. This paper\npresents TempoPFN, a univariate time series foundation model based on linear\nRecurrent Neural Networks (RNNs) pre-trained exclusively on synthetic data. The\nmodel uses a GatedDeltaProduct architecture with state-weaving for fully\nparallelizable training across sequence lengths, eliminating the need for\nwindowing or summarization techniques while maintaining robust temporal\nstate-tracking. Our comprehensive synthetic data pipeline unifies diverse\ngenerators, including stochastic differential equations, Gaussian processes,\nand audio synthesis, with novel augmentations. In zero-shot evaluations on the\nGift-Eval benchmark, TempoPFN achieves top-tier competitive performance,\noutperforming all existing synthetic-only approaches and surpassing the vast\nmajority of models trained on real-world data, while being more efficient than\nexisting baselines by leveraging fully parallelizable training and inference.\nWe open-source our complete data generation pipeline and training code,\nproviding a reproducible foundation for future research.",
    "published": "2025-10-29T13:27:18Z",
    "updated": "2025-10-29T13:27:18Z",
    "link": "http://arxiv.org/pdf/2510.25502v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "authors": [
      "Vladyslav Moroshan",
      "Julien Siems",
      "Arber Zela",
      "Timur Carstensen",
      "Frank Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.21236v2",
    "title": "Securing AI Agent Execution",
    "summary": "Large Language Models (LLMs) have evolved into AI agents that interact with\nexternal tools and environments to perform complex tasks. The Model Context\nProtocol (MCP) has become the de facto standard for connecting agents with such\nresources, but security has lagged behind: thousands of MCP servers execute\nwith unrestricted access to host systems, creating a broad attack surface. In\nthis paper, we introduce AgentBound, the first access control framework for MCP\nservers. AgentBound combines a declarative policy mechanism, inspired by the\nAndroid permission model, with a policy enforcement engine that contains\nmalicious behavior without requiring MCP server modifications. We build a\ndataset containing the 296 most popular MCP servers, and show that access\ncontrol policies can be generated automatically from source code with 80.9%\naccuracy. We also show that AgentBound blocks the majority of security threats\nin several malicious MCP servers, and that policy enforcement engine introduces\nnegligible overhead. Our contributions provide developers and project managers\nwith a practical foundation for securing MCP servers while maintaining\nproductivity, enabling researchers and tool builders to explore new directions\nfor declarative access control and MCP security.",
    "published": "2025-10-24T08:10:36Z",
    "updated": "2025-10-29T13:11:21Z",
    "link": "http://arxiv.org/pdf/2510.21236v2.pdf",
    "category": [
      "cs.CR",
      "cs.AI",
      "cs.SE",
      "D.2.0"
    ],
    "authors": [
      "Christoph Bühler",
      "Matteo Biagiola",
      "Luca Di Grazia",
      "Guido Salvaneschi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25471v1",
    "title": "Instrumental goals in advanced AI systems: Features to be managed and\n  not failures to be eliminated?",
    "summary": "In artificial intelligence (AI) alignment research, instrumental goals, also\ncalled instrumental subgoals or instrumental convergent goals, are widely\nassociated with advanced AI systems. These goals, which include tendencies such\nas power-seeking and self-preservation, become problematic when they conflict\nwith human aims. Conventional alignment theory treats instrumental goals as\nsources of risk that become problematic through failure modes such as reward\nhacking or goal misgeneralization, and attempts to limit the symptoms of\ninstrumental goals, notably resource acquisition and self-preservation. This\narticle proposes an alternative framing: that a philosophical argument can be\nconstructed according to which instrumental goals may be understood as features\nto be accepted and managed rather than failures to be limited. Drawing on\nAristotle's ontology and its modern interpretations, an ontology of concrete,\ngoal-directed entities, it argues that advanced AI systems can be seen as\nartifacts whose formal and material constitution gives rise to effects distinct\nfrom their designers' intentions. In this view, the instrumental tendencies of\nsuch systems correspond to per se outcomes of their constitution rather than\naccidental malfunctions. The implication is that efforts should focus less on\neliminating instrumental goals and more on understanding, managing, and\ndirecting them toward human-aligned ends.",
    "published": "2025-10-29T12:47:15Z",
    "updated": "2025-10-29T12:47:15Z",
    "link": "http://arxiv.org/pdf/2510.25471v1.pdf",
    "category": [
      "cs.AI",
      "cs.CY"
    ],
    "authors": [
      "Willem Fourie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25470v1",
    "title": "An In-Depth Analysis of Cyber Attacks in Secured Platforms",
    "summary": "There is an increase in global malware threats. To address this, an\nencryption-type ransomware has been introduced on the Android operating system.\nThe challenges associated with malicious threats in phone use have become a\npressing issue in mobile communication, disrupting user experiences and posing\nsignificant privacy threats. This study surveys commonly used machine learning\ntechniques for detecting malicious threats in phones and examines their\nperformance. The majority of past research focuses on customer feedback and\nreviews, with concerns that people might create false reviews to promote or\ndevalue products and services for personal gain. Hence, the development of\ntechniques for detecting malicious threats using machine learning has been a\nkey focus. This paper presents a comprehensive comparative study of current\nresearch on the issue of malicious threats and methods for tackling these\nchallenges. Nevertheless, a huge amount of information is required by these\nmethods, presenting a challenge for developing robust, specialized automated\nanti-malware systems. This research describes the Android Applications dataset,\nand the accuracy of the techniques is measured using the accuracy levels of the\nmetrics employed in this study.",
    "published": "2025-10-29T12:43:18Z",
    "updated": "2025-10-29T12:43:18Z",
    "link": "http://arxiv.org/pdf/2510.25470v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Parick Ozoh",
      "John K Omoniyi",
      "Bukola Ibitoye"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25460v1",
    "title": "Fine-Tuned Language Models for Domain-Specific Summarization and Tagging",
    "summary": "This paper presents a pipeline integrating fine-tuned large language models\n(LLMs) with named entity recognition (NER) for efficient domain-specific text\nsummarization and tagging. The authors address the challenge posed by rapidly\nevolving sub-cultural languages and slang, which complicate automated\ninformation extraction and law enforcement monitoring. By leveraging the LLaMA\nFactory framework, the study fine-tunes LLMs on both generalpurpose and custom\ndomain-specific datasets, particularly in the political and security domains.\nThe models are evaluated using BLEU and ROUGE metrics, demonstrating that\ninstruction fine-tuning significantly enhances summarization and tagging\naccuracy, especially for specialized corpora. Notably, the LLaMA3-8B-Instruct\nmodel, despite its initial limitations in Chinese comprehension, outperforms\nits Chinese-trained counterpart after domainspecific fine-tuning, suggesting\nthat underlying reasoning capabilities can transfer across languages. The\npipeline enables concise summaries and structured entity tagging, facilitating\nrapid document categorization and distribution. This approach proves scalable\nand adaptable for real-time applications, supporting efficient information\nmanagement and the ongoing need to capture emerging language trends. The\nintegration of LLMs and NER offers a robust solution for transforming\nunstructured text into actionable insights, crucial for modern knowledge\nmanagement and security operations.",
    "published": "2025-10-29T12:33:48Z",
    "updated": "2025-10-29T12:33:48Z",
    "link": "http://arxiv.org/pdf/2510.25460v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Jun Wang",
      "Fuming Lin",
      "Yuyu Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25458v1",
    "title": "Scalable Utility-Aware Multiclass Calibration",
    "summary": "Ensuring that classifiers are well-calibrated, i.e., their predictions align\nwith observed frequencies, is a minimal and fundamental requirement for\nclassifiers to be viewed as trustworthy. Existing methods for assessing\nmulticlass calibration often focus on specific aspects associated with\nprediction (e.g., top-class confidence, class-wise calibration) or utilize\ncomputationally challenging variational formulations. In this work, we study\nscalable \\emph{evaluation} of multiclass calibration. To this end, we propose\nutility calibration, a general framework that measures the calibration error\nrelative to a specific utility function that encapsulates the goals or decision\ncriteria relevant to the end user. We demonstrate how this framework can unify\nand re-interpret several existing calibration metrics, particularly allowing\nfor more robust versions of the top-class and class-wise calibration metrics,\nand, going beyond such binarized approaches, toward assessing calibration for\nricher classes of downstream utilities.",
    "published": "2025-10-29T12:32:14Z",
    "updated": "2025-10-29T12:32:14Z",
    "link": "http://arxiv.org/pdf/2510.25458v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "authors": [
      "Mahmoud Hegazy",
      "Michael I. Jordan",
      "Aymeric Dieuleveut"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.09349v2",
    "title": "Classification of Driver Behaviour Using External Observation Techniques\n  for Autonomous Vehicles",
    "summary": "Road traffic accidents remain a significant global concern, with human error,\nparticularly distracted and impaired driving, among the leading causes. This\nstudy introduces a novel driver behaviour classification system that uses\nexternal observation techniques to detect indicators of distraction and\nimpairment. The proposed framework employs advanced computer vision\nmethodologies, including real-time object tracking, lateral displacement\nanalysis, and lane position monitoring. The system identifies unsafe driving\nbehaviours such as excessive lateral movement and erratic trajectory patterns\nby implementing the YOLO object detection model and custom lane estimation\nalgorithms. Unlike systems reliant on inter-vehicular communication, this\nvision-based approach enables behavioural analysis of non-connected vehicles.\nExperimental evaluations on diverse video datasets demonstrate the framework's\nreliability and adaptability across varying road and environmental conditions.",
    "published": "2025-09-11T11:05:14Z",
    "updated": "2025-10-29T12:14:41Z",
    "link": "http://arxiv.org/pdf/2509.09349v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.ET",
      "cs.RO",
      "eess.IV"
    ],
    "authors": [
      "Ian Nell",
      "Shane Gilroy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25445v1",
    "title": "Agentic AI: A Comprehensive Survey of Architectures, Applications, and\n  Future Directions",
    "summary": "Agentic AI represents a transformative shift in artificial intelligence, but\nits rapid advancement has led to a fragmented understanding, often conflating\nmodern neural systems with outdated symbolic models -- a practice known as\nconceptual retrofitting. This survey cuts through this confusion by introducing\na novel dual-paradigm framework that categorizes agentic systems into two\ndistinct lineages: the Symbolic/Classical (relying on algorithmic planning and\npersistent state) and the Neural/Generative (leveraging stochastic generation\nand prompt-driven orchestration). Through a systematic PRISMA-based review of\n90 studies (2018--2025), we provide a comprehensive analysis structured around\nthis framework across three dimensions: (1) the theoretical foundations and\narchitectural principles defining each paradigm; (2) domain-specific\nimplementations in healthcare, finance, and robotics, demonstrating how\napplication constraints dictate paradigm selection; and (3) paradigm-specific\nethical and governance challenges, revealing divergent risks and mitigation\nstrategies. Our analysis reveals that the choice of paradigm is strategic:\nsymbolic systems dominate safety-critical domains (e.g., healthcare), while\nneural systems prevail in adaptive, data-rich environments (e.g., finance).\nFurthermore, we identify critical research gaps, including a significant\ndeficit in governance models for symbolic systems and a pressing need for\nhybrid neuro-symbolic architectures. The findings culminate in a strategic\nroadmap arguing that the future of Agentic AI lies not in the dominance of one\nparadigm, but in their intentional integration to create systems that are both\nadaptable and reliable. This work provides the essential conceptual toolkit to\nguide future research, development, and policy toward robust and trustworthy\nhybrid intelligent systems.",
    "published": "2025-10-29T12:11:34Z",
    "updated": "2025-10-29T12:11:34Z",
    "link": "http://arxiv.org/pdf/2510.25445v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Mohamad Abou Ali",
      "Fadi Dornaika"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25441v1",
    "title": "Grounded in Reality: Learning and Deploying Proactive LLM from Offline\n  Logs",
    "summary": "Large Language Models (LLMs) excel as passive responders, but teaching them\nto be proactive, goal-oriented partners, a critical capability in high-stakes\ndomains, remains a major challenge. Current paradigms either myopically\noptimize single-turn attributes or rely on brittle, high-cost user simulators,\ncreating a persistent ``reality gap''. To bridge this gap, we introduce\n\\texttt{Learn-to-Ask}, a general, simulator-free framework for learning and\ndeploying proactive dialogue agents \\textit{directly from offline expert data},\nbypassing the need to model complex user dynamics. Our key insight is to\nreframe the offline policy learning problem by leveraging the \\textbf{observed\nfuture} of each expert trajectory. This allows us to infer a dense,\nturn-by-turn reward signal grounded in the expert's revealed strategy,\ndecomposing the intractable long-horizon problem into a series of supervised\nlearning tasks, and training a policy to output a structured \\texttt{(action,\nstate_assessment)} tuple, governing both \\textbf{what to ask} and, crucially,\n\\textbf{when to stop}. To ensure reward fidelity, our Automated Grader\nCalibration pipeline systematically purges noise from the LLM-based reward\nmodel with minimal human supervision. Empirically, we demonstrate the efficacy\nof \\texttt{Learn-to-Ask} in a real-world medical dataset, using LLMs of varying\nsizes up to 32B. Our approach culminates in the successful deployment of LLMs\ninto a live, large-scale online AI service. In rigorous in-house evaluations,\nour model was launched and achieved performance even superior to human experts,\nproving our framework's ability to translate offline data into tangible,\nreal-world impact. We hope this work provides a practical and economically\nviable blueprint for transforming passive LLMs into proactive, goal-oriented\nLLM applications.",
    "published": "2025-10-29T12:08:07Z",
    "updated": "2025-10-29T12:08:07Z",
    "link": "http://arxiv.org/pdf/2510.25441v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Fei Wei",
      "Daoyuan Chen",
      "Ce Wang",
      "Yilun Huang",
      "Yushuo Chen",
      "Xuchen Pan",
      "Yaliang Li",
      "Bolin Ding"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.16368v2",
    "title": "SATURN: SAT-based Reinforcement Learning to Unleash Language Model\n  Reasoning",
    "summary": "How to design reinforcement learning (RL) tasks that effectively unleash the\nreasoning capability of large language models (LLMs) remains an open question.\nExisting RL tasks (e.g., math, programming, and constructing reasoning tasks)\nsuffer from three key limitations: (1) Scalability. They rely heavily on human\nannotation or expensive LLM synthesis to generate sufficient training data. (2)\nVerifiability. LLMs' outputs are hard to verify automatically and reliably. (3)\nControllable Difficulty. Most tasks lack fine-grained difficulty control,\nmaking it hard to train LLMs to develop reasoning ability from easy to hard.\n  To address these limitations, we propose Saturn, a SAT-based RL framework\nthat uses Boolean Satisfiability (SAT) problems to train and evaluate LLMs\nreasoning. Saturn enables scalable task construction, rule-based verification,\nand precise difficulty control. Saturn designs a curriculum learning pipeline\nthat continuously improves LLMs' reasoning capability by constructing SAT tasks\nof increasing difficulty and training LLMs from easy to hard. To ensure stable\ntraining, we design a principled mechanism to control difficulty transitions.\n  We introduce Saturn-2.6k, a dataset of 2,660 SAT problems with varying\ndifficulty. It supports the evaluation of how LLM reasoning changes with\nproblem difficulty. We apply Saturn to DeepSeek-R1-Distill-Qwen and obtain\nSaturn-1.5B and Saturn-7B. We achieve several notable results: (1) On SAT\nproblems, Saturn-1.5B and Saturn-7B achieve average pass@3 improvements of\n+14.0 and +28.1, respectively. (2) On math and programming tasks, Saturn-1.5B\nand Saturn-7B improve average scores by +4.9 and +1.8 on benchmarks (e.g.,\nAIME, LiveCodeBench). (3) Compared to the state-of-the-art (SOTA) approach in\nconstructing RL tasks, Saturn achieves further improvements of +8.8%. We\nrelease the source code, data, and models to support future research.",
    "published": "2025-05-22T08:23:10Z",
    "updated": "2025-10-29T12:06:15Z",
    "link": "http://arxiv.org/pdf/2505.16368v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Huanyu Liu",
      "Jia Li",
      "Hao Zhu",
      "Kechi Zhang",
      "Yihong Dong",
      "Ge Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2308.07870v3",
    "title": "Brain-inspired Computational Intelligence via Predictive Coding",
    "summary": "Artificial intelligence (AI) is rapidly becoming one of the key technologies\nof this century. The majority of results in AI thus far have been achieved\nusing deep neural networks trained with a learning algorithm called error\nbackpropagation, always considered biologically implausible. To this end,\nrecent works have studied learning algorithms for deep neural networks inspired\nby the neurosciences. One such theory, called predictive coding (PC), has shown\npromising properties that make it potentially valuable for the machine learning\ncommunity: it can model information processing in different areas of the brain,\ncan be used in control and robotics, has a solid mathematical foundation in\nvariational inference, and performs its computations asynchronously. Inspired\nby such properties, works that propose novel PC-like algorithms are starting to\nbe present in multiple sub-fields of machine learning and AI at large. Here, we\nsurvey such efforts by first providing a broad overview of the history of PC to\nprovide common ground for the understanding of the recent developments, then by\ndescribing current efforts and results, and concluding with a large discussion\nof possible implications and ways forward.",
    "published": "2023-08-15T16:37:16Z",
    "updated": "2025-10-29T12:00:29Z",
    "link": "http://arxiv.org/pdf/2308.07870v3.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "authors": [
      "Tommaso Salvatori",
      "Ankur Mali",
      "Christopher L. Buckley",
      "Thomas Lukasiewicz",
      "Rajesh P. N. Rao",
      "Karl Friston",
      "Alexander Ororbia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25428v1",
    "title": "Alibaba International E-commerce Product Search Competition DcuRAGONs\n  Team Technical Report",
    "summary": "This report details our methodology and results developed for the\nMultilingual E-commerce Search Competition. The problem aims to recognize\nrelevance between user queries versus product items in a multilingual context\nand improve recommendation performance on e-commerce platforms. Utilizing Large\nLanguage Models (LLMs) and their capabilities in other tasks, our data-centric\nmethod achieved the highest score compared to other solutions during the\ncompetition. Final leaderboard is publised at\nhttps://alibaba-international-cikm2025.github.io. The source code for our\nproject is published at https://github.com/nhtlongcs/e-commerce-product-search.",
    "published": "2025-10-29T11:50:52Z",
    "updated": "2025-10-29T11:50:52Z",
    "link": "http://arxiv.org/pdf/2510.25428v1.pdf",
    "category": [
      "cs.IR",
      "cs.AI"
    ],
    "authors": [
      "Thang-Long Nguyen-Ho",
      "Minh-Khoi Pham",
      "Hoang-Bao Le"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25427v1",
    "title": "RLMEval: Evaluating Research-Level Neural Theorem Proving",
    "summary": "Despite impressive results on curated benchmarks, the practical impact of\nlarge language models (LLMs) on research-level neural theorem proving and proof\nautoformalization is still limited. We introduce RLMEval, an evaluation suite\nfor these tasks, focusing on research-level mathematics from real-world Lean\nformalization projects. RLMEval targets the evaluation of neural theorem\nproving and proof autoformalization on challenging research-level theorems by\nleveraging real Lean Blueprint formalization projects. Our evaluation of\nstate-of-the-art models on RLMEval, comprising 613 theorems from 6 Lean\nprojects, reveals a significant gap: progress on existing benchmarks does not\nreadily translate to these more realistic settings, with the best model\nachieving only a 10.3 % pass rate. RLMEval provides a new, challenging\nbenchmark designed to guide and accelerate progress in automated reasoning for\nformal mathematics.",
    "published": "2025-10-29T11:49:49Z",
    "updated": "2025-10-29T11:49:49Z",
    "link": "http://arxiv.org/pdf/2510.25427v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Auguste Poiroux",
      "Antoine Bosselut",
      "Viktor Kunčak"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25426v1",
    "title": "Implicature in Interaction: Understanding Implicature Improves Alignment\n  in Human-LLM Interaction",
    "summary": "The rapid advancement of Large Language Models (LLMs) is positioning language\nat the core of human-computer interaction (HCI). We argue that advancing HCI\nrequires attention to the linguistic foundations of interaction, particularly\nimplicature (meaning conveyed beyond explicit statements through shared\ncontext) which is essential for human-AI (HAI) alignment. This study examines\nLLMs' ability to infer user intent embedded in context-driven prompts and\nwhether understanding implicature improves response generation. Results show\nthat larger models approximate human interpretations more closely, while\nsmaller models struggle with implicature inference. Furthermore,\nimplicature-based prompts significantly enhance the perceived relevance and\nquality of responses across models, with notable gains in smaller models.\nOverall, 67.6% of participants preferred responses with implicature-embedded\nprompts to literal ones, highlighting a clear preference for contextually\nnuanced communication. Our work contributes to understanding how linguistic\ntheory can be used to address the alignment problem by making HAI interaction\nmore natural and contextually grounded.",
    "published": "2025-10-29T11:49:42Z",
    "updated": "2025-10-29T11:49:42Z",
    "link": "http://arxiv.org/pdf/2510.25426v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Asutosh Hota",
      "Jussi P. P. Jokinen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25420v1",
    "title": "Improving Temporal Consistency and Fidelity at Inference-time in\n  Perceptual Video Restoration by Zero-shot Image-based Diffusion Models",
    "summary": "Diffusion models have emerged as powerful priors for single-image\nrestoration, but their application to zero-shot video restoration suffers from\ntemporal inconsistencies due to the stochastic nature of sampling and\ncomplexity of incorporating explicit temporal modeling. In this work, we\naddress the challenge of improving temporal coherence in video restoration\nusing zero-shot image-based diffusion models without retraining or modifying\ntheir architecture. We propose two complementary inference-time strategies: (1)\nPerceptual Straightening Guidance (PSG) based on the neuroscience-inspired\nperceptual straightening hypothesis, which steers the diffusion denoising\nprocess towards smoother temporal evolution by incorporating a curvature\npenalty in a perceptual space to improve temporal perceptual scores, such as\nFr\\'echet Video Distance (FVD) and perceptual straightness; and (2) Multi-Path\nEnsemble Sampling (MPES), which aims at reducing stochastic variation by\nensembling multiple diffusion trajectories to improve fidelity (distortion)\nscores, such as PSNR and SSIM, without sacrificing sharpness. Together, these\ntraining-free techniques provide a practical path toward temporally stable\nhigh-fidelity perceptual video restoration using large pretrained diffusion\nmodels. We performed extensive experiments over multiple datasets and\ndegradation types, systematically evaluating each strategy to understand their\nstrengths and limitations. Our results show that while PSG enhances temporal\nnaturalness, particularly in case of temporal blur, MPES consistently improves\nfidelity and spatio-temporal perception--distortion trade-off across all tasks.",
    "published": "2025-10-29T11:40:06Z",
    "updated": "2025-10-29T11:40:06Z",
    "link": "http://arxiv.org/pdf/2510.25420v1.pdf",
    "category": [
      "eess.IV",
      "cs.AI"
    ],
    "authors": [
      "Nasrin Rahimi",
      "A. Murat Tekalp"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.04233v4",
    "title": "HyperMARL: Adaptive Hypernetworks for Multi-Agent RL",
    "summary": "Adaptive cooperation in multi-agent reinforcement learning (MARL) requires\npolicies to express homogeneous, specialised, or mixed behaviours, yet\nachieving this adaptivity remains a critical challenge. While parameter sharing\n(PS) is standard for efficient learning, it notoriously suppresses the\nbehavioural diversity required for specialisation. This failure is largely due\nto cross-agent gradient interference, a problem we find is surprisingly\nexacerbated by the common practice of coupling agent IDs with observations.\nExisting remedies typically add complexity through altered objectives, manual\npreset diversity levels, or sequential updates -- raising a fundamental\nquestion: can shared policies adapt without these intricacies? We propose a\nsolution built on a key insight: an agent-conditioned hypernetwork can generate\nagent-specific parameters and decouple observation- and agent-conditioned\ngradients, directly countering the interference from coupling agent IDs with\nobservations. Our resulting method, HyperMARL, avoids the complexities of prior\nwork and empirically reduces policy gradient variance. Across diverse MARL\nbenchmarks (22 scenarios, up to 30 agents), HyperMARL achieves performance\ncompetitive with six key baselines while preserving behavioural diversity\ncomparable to non-parameter sharing methods, establishing it as a versatile and\nprincipled approach for adaptive MARL. The code is publicly available at\nhttps://github.com/KaleabTessera/HyperMARL.",
    "published": "2024-12-05T15:09:51Z",
    "updated": "2025-10-29T11:37:54Z",
    "link": "http://arxiv.org/pdf/2412.04233v4.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "authors": [
      "Kale-ab Abebe Tessera",
      "Arrasy Rahman",
      "Amos Storkey",
      "Stefano V. Albrecht"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2406.07222v3",
    "title": "Reliable Evaluation and Benchmarks for Statement Autoformalization",
    "summary": "Evaluating statement autoformalization, translating natural language\nmathematics into formal languages like Lean 4, remains a significant challenge,\nwith few metrics, datasets, and standards to robustly measure progress. In this\nwork, we present a comprehensive approach combining improved metrics, robust\nbenchmarks, and systematic evaluation, to fill this gap. First, we introduce\nBEq+, an automated metric that correlates strongly with human judgment, along\nwith ProofNetVerif, a new dataset for assessing the quality of evaluation\nmetrics, containing 3,752 annotated examples. Second, we develop two new\nautoformalization benchmarks: ProofNet#, a corrected version of ProofNet, and\nRLM25, with 619 new pairs of research-level mathematics from six formalization\nprojects. Through systematic experimentation across these benchmarks, we find\nthat current techniques can achieve up to 45.1% accuracy on undergraduate\nmathematics but struggle with research-level content without proper context.\nOur work establishes a reliable foundation for evaluating and advancing\nautoformalization systems.",
    "published": "2024-06-11T13:01:50Z",
    "updated": "2025-10-29T11:36:28Z",
    "link": "http://arxiv.org/pdf/2406.07222v3.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Auguste Poiroux",
      "Gail Weiss",
      "Viktor Kunčak",
      "Antoine Bosselut"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25416v1",
    "title": "Adaptive End-to-End Transceiver Design for NextG Pilot-Free and CP-Free\n  Wireless Systems",
    "summary": "The advent of artificial intelligence (AI)-native wireless communication is\nfundamentally reshaping the design paradigm of next-generation (NextG) systems,\nwhere intelligent air interfaces are expected to operate adaptively and\nefficiently in highly dynamic environments. Conventional orthogonal frequency\ndivision multiplexing (OFDM) systems rely heavily on pilots and the cyclic\nprefix (CP), resulting in significant overhead and reduced spectral efficiency.\nTo address these limitations, we propose an adaptive end-to-end (E2E)\ntransceiver architecture tailored for pilot-free and CP-free wireless systems.\nThe architecture combines AI-driven constellation shaping and a neural receiver\nthrough joint training. To enhance robustness against mismatched or\ntime-varying channel conditions, we introduce a lightweight channel adapter\n(CA) module, which enables rapid adaptation with minimal computational overhead\nby updating only the CA parameters. Additionally, we present a framework that\nis scalable to multiple modulation orders within a unified model, significantly\nreducing model storage requirements. Moreover, to tackle the high\npeak-to-average power ratio (PAPR) inherent to OFDM, we incorporate constrained\nE2E training, achieving compliance with PAPR targets without additional\ntransmission overhead. Extensive simulations demonstrate that the proposed\nframework delivers superior bit error rate (BER), throughput, and resilience\nacross diverse channel scenarios, highlighting its potential for AI-native\nNextG.",
    "published": "2025-10-29T11:34:09Z",
    "updated": "2025-10-29T11:34:09Z",
    "link": "http://arxiv.org/pdf/2510.25416v1.pdf",
    "category": [
      "eess.SP",
      "cs.AI"
    ],
    "authors": [
      "Jiaming Cheng",
      "Wei Chen",
      "Bo Ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.17247v2",
    "title": "OmegAMP: Targeted AMP Discovery through Biologically Informed Generation",
    "summary": "Deep learning-based antimicrobial peptide (AMP) discovery faces critical\nchallenges such as limited controllability, lack of representations that\nefficiently model antimicrobial properties, and low experimental hit rates. To\naddress these challenges, we introduce OmegAMP, a framework designed for\nreliable AMP generation with increased controllability. Its diffusion-based\ngenerative model leverages a novel conditioning mechanism to achieve\nfine-grained control over desired physicochemical properties and to direct\ngeneration towards specific activity profiles, including species-specific\neffectiveness. This is further enhanced by a biologically informed encoding\nspace that significantly improves overall generative performance. Complementing\nthese generative capabilities, OmegAMP leverages a novel synthetic data\naugmentation strategy to train classifiers for AMP filtering, drastically\nreducing false positive rates and thereby increasing the likelihood of\nexperimental success. Our in silico experiments demonstrate that OmegAMP\ndelivers state-of-the-art performance across key stages of the AMP discovery\npipeline, enabling us to achieve an unprecedented success rate in wet lab\nexperiments. We tested 25 candidate peptides, 24 of them (96%) demonstrated\nantimicrobial activity, proving effective even against multi-drug resistant\nstrains. Our findings underscore OmegAMP's potential to significantly advance\ncomputational frameworks in the fight against antimicrobial resistance.",
    "published": "2025-04-24T04:53:04Z",
    "updated": "2025-10-29T11:30:12Z",
    "link": "http://arxiv.org/pdf/2504.17247v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "authors": [
      "Diogo Soares",
      "Leon Hetzel",
      "Paulina Szymczak",
      "Marcelo Der Torossian Torres",
      "Johanna Sommer",
      "Cesar de la Fuente-Nunez",
      "Fabian Theis",
      "Stephan Günnemann",
      "Ewa Szczurek"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25409v1",
    "title": "BhashaBench V1: A Comprehensive Benchmark for the Quadrant of Indic\n  Domains",
    "summary": "The rapid advancement of large language models(LLMs) has intensified the need\nfor domain and culture specific evaluation. Existing benchmarks are largely\nAnglocentric and domain-agnostic, limiting their applicability to India-centric\ncontexts. To address this gap, we introduce BhashaBench V1, the first\ndomain-specific, multi-task, bilingual benchmark focusing on critical Indic\nknowledge systems. BhashaBench V1 contains 74,166 meticulously curated\nquestion-answer pairs, with 52,494 in English and 21,672 in Hindi, sourced from\nauthentic government and domain-specific exams. It spans four major domains:\nAgriculture, Legal, Finance, and Ayurveda, comprising 90+ subdomains and\ncovering 500+ topics, enabling fine-grained evaluation. Evaluation of 29+ LLMs\nreveals significant domain and language specific performance gaps, with\nespecially large disparities in low-resource domains. For instance, GPT-4o\nachieves 76.49% overall accuracy in Legal but only 59.74% in Ayurveda. Models\nconsistently perform better on English content compared to Hindi across all\ndomains. Subdomain-level analysis shows that areas such as Cyber Law,\nInternational Finance perform relatively well, while Panchakarma, Seed Science,\nand Human Rights remain notably weak. BhashaBench V1 provides a comprehensive\ndataset for evaluating large language models across India's diverse knowledge\ndomains. It enables assessment of models' ability to integrate domain-specific\nknowledge with bilingual understanding. All code, benchmarks, and resources are\npublicly available to support open research.",
    "published": "2025-10-29T11:27:08Z",
    "updated": "2025-10-29T11:27:08Z",
    "link": "http://arxiv.org/pdf/2510.25409v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Vijay Devane",
      "Mohd Nauman",
      "Bhargav Patel",
      "Aniket Mahendra Wakchoure",
      "Yogeshkumar Sant",
      "Shyam Pawar",
      "Viraj Thakur",
      "Ananya Godse",
      "Sunil Patra",
      "Neha Maurya",
      "Suraj Racha",
      "Nitish Kamal Singh",
      "Ajay Nagpal",
      "Piyush Sawarkar",
      "Kundeshwar Vijayrao Pundalik",
      "Rohit Saluja",
      "Ganesh Ramakrishnan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25404v1",
    "title": "GPTOpt: Towards Efficient LLM-Based Black-Box Optimization",
    "summary": "Global optimization of expensive, derivative-free black-box functions demands\nextreme sample efficiency. Classical methods such as Bayesian Optimization (BO)\ncan be effective, but they often require careful parameter tuning to each\napplication domain. At the same time, Large Language Models (LLMs) have shown\nbroad capabilities, yet state-of-the-art models remain limited in solving\ncontinuous black-box optimization tasks. We introduce GPTOpt, an LLM-based\noptimization method that equips LLMs with continuous black-box optimization\ncapabilities. By fine-tuning large language models on extensive synthetic\ndatasets derived from diverse BO parameterizations, GPTOpt leverages LLM\npre-training to generalize across optimization tasks. On a variety of black-box\noptimization benchmarks, GPTOpt surpasses traditional optimizers, highlighting\nthe capacity of LLMs for advanced numerical reasoning and introducing a\nflexible framework for global optimization without parameter tuning.",
    "published": "2025-10-29T11:21:55Z",
    "updated": "2025-10-29T11:21:55Z",
    "link": "http://arxiv.org/pdf/2510.25404v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Jamison Meindl",
      "Yunsheng Tian",
      "Tony Cui",
      "Veronika Thost",
      "Zhang-Wei Hong",
      "Jie Chen",
      "Wojciech Matusik",
      "Mina Konaković Luković"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23665v2",
    "title": "Transformers from Compressed Representations",
    "summary": "Compressed file formats are the corner stone of efficient data storage and\ntransmission, yet their potential for representation learning remains largely\nunderexplored. We introduce TEMPEST (TransformErs froM comPressed\nrEpreSenTations), a method that exploits the inherent byte-stream structure of\ncompressed files to design an effective tokenization and encoding strategy. By\nleveraging this compact encoding, a standard transformer can directly learn\nsemantic representations from compressed data streams, bypassing the need for\nraw byte-level processing or full media decoding. Our proposal substantially\nreduces the number of tokens required for semantic classification, thereby\nlowering both computational complexity and memory usage. Through extensive\nexperiments across diverse datasets, coding schemes, and modalities, we show\nthat TEMPEST achieves accuracy competitive wit the state-of-the-art while\ndelivering efficiency gains in memory and compute.",
    "published": "2025-10-26T13:48:03Z",
    "updated": "2025-10-29T11:16:57Z",
    "link": "http://arxiv.org/pdf/2510.23665v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Juan C. Leon Alcazar",
      "Mattia Soldan",
      "Mohammad Saatialsoruji",
      "Alejandro Pardo",
      "Hani Itani",
      "Juan Camilo Perez",
      "Bernard Ghanem"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.21285v2",
    "title": "When Models Outthink Their Safety: Mitigating Self-Jailbreak in Large\n  Reasoning Models with Chain-of-Guardrails",
    "summary": "Large Reasoning Models (LRMs) demonstrate remarkable capabilities on complex\nreasoning tasks but remain vulnerable to severe safety risks, including harmful\ncontent generation and jailbreak attacks. Existing mitigation strategies rely\non injecting heuristic safety signals during training, which often suppress\nreasoning ability and fail to resolve the safety-reasoning trade-off. To\nsystematically investigate this issue, we analyze the reasoning trajectories of\ndiverse LRMs and uncover a phenomenon we term Self-Jailbreak, where models\noverride their own risk assessments and justify responding to unsafe prompts.\nThis finding reveals that LRMs inherently possess the ability to reject unsafe\nqueries, but this ability is compromised, resulting in harmful outputs.\nBuilding on these insights, we propose the Chain-of-Guardrail (CoG), a training\nframework that recomposes or backtracks unsafe reasoning steps, steering the\nmodel back onto safe trajectories while preserving valid reasoning chains.\nExtensive experiments across multiple reasoning and safety benchmarks\ndemonstrate that CoG substantially improves the safety of current LRMs while\npreserving comparable reasoning ability, significantly outperforming prior\nmethods that suffer from severe safety-reasoning trade-offs.",
    "published": "2025-10-24T09:32:25Z",
    "updated": "2025-10-29T11:06:45Z",
    "link": "http://arxiv.org/pdf/2510.21285v2.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Yingzhi Mao",
      "Chunkang Zhang",
      "Junxiang Wang",
      "Xinyan Guan",
      "Boxi Cao",
      "Yaojie Lu",
      "Hongyu Lin",
      "Xianpei Han",
      "Le Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.04317v2",
    "title": "Improving Robustness of AlphaZero Algorithms to Test-Time Environment\n  Changes",
    "summary": "The AlphaZero framework provides a standard way of combining Monte Carlo\nplanning with prior knowledge provided by a previously trained policy-value\nneural network. AlphaZero usually assumes that the environment on which the\nneural network was trained will not change at test time, which constrains its\napplicability. In this paper, we analyze the problem of deploying AlphaZero\nagents in potentially changed test environments and demonstrate how the\ncombination of simple modifications to the standard framework can significantly\nboost performance, even in settings with a low planning budget available. The\ncode is publicly available on GitHub.",
    "published": "2025-09-04T15:38:37Z",
    "updated": "2025-10-29T11:06:35Z",
    "link": "http://arxiv.org/pdf/2509.04317v2.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Isidoro Tamassia",
      "Wendelin Böhmer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25388v1",
    "title": "Grouping Nodes With Known Value Differences: A Lossless UCT-based\n  Abstraction Algorithm",
    "summary": "A core challenge of Monte Carlo Tree Search (MCTS) is its sample efficiency,\nwhich can be improved by grouping state-action pairs and using their aggregate\nstatistics instead of single-node statistics. On the Go Abstractions in Upper\nConfidence bounds applied to Trees (OGA-UCT) is the state-of-the-art MCTS\nabstraction algorithm for deterministic environments that builds its\nabstraction using the Abstractions of State-Action Pairs (ASAP) framework,\nwhich aims to detect states and state-action pairs with the same value under\noptimal play by analysing the search graph. ASAP, however, requires two\nstate-action pairs to have the same immediate reward, which is a rigid\ncondition that limits the number of abstractions that can be found and thereby\nthe sample efficiency. In this paper, we break with the paradigm of grouping\nvalue-equivalent states or state-action pairs and instead group states and\nstate-action pairs with possibly different values as long as the difference\nbetween their values can be inferred. We call this abstraction framework Known\nValue Difference Abstractions (KVDA), which infers the value differences by\nanalysis of the immediate rewards and modifies OGA-UCT to use this framework\ninstead. The modification is called KVDA-UCT, which detects significantly more\nabstractions than OGA-UCT, introduces no additional parameter, and outperforms\nOGA-UCT on a variety of deterministic environments and parameter settings.",
    "published": "2025-10-29T11:03:44Z",
    "updated": "2025-10-29T11:03:44Z",
    "link": "http://arxiv.org/pdf/2510.25388v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Robin Schmöcker",
      "Alexander Dockhorn",
      "Bodo Rosenhahn"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.16791v3",
    "title": "TabArena: A Living Benchmark for Machine Learning on Tabular Data",
    "summary": "With the growing popularity of deep learning and foundation models for\ntabular data, the need for standardized and reliable benchmarks is higher than\never. However, current benchmarks are static. Their design is not updated even\nif flaws are discovered, model versions are updated, or new models are\nreleased. To address this, we introduce TabArena, the first continuously\nmaintained living tabular benchmarking system. To launch TabArena, we manually\ncurate a representative collection of datasets and well-implemented models,\nconduct a large-scale benchmarking study to initialize a public leaderboard,\nand assemble a team of experienced maintainers. Our results highlight the\ninfluence of validation method and ensembling of hyperparameter configurations\nto benchmark models at their full potential. While gradient-boosted trees are\nstill strong contenders on practical tabular datasets, we observe that deep\nlearning methods have caught up under larger time budgets with ensembling. At\nthe same time, foundation models excel on smaller datasets. Finally, we show\nthat ensembles across models advance the state-of-the-art in tabular machine\nlearning. We observe that some deep learning models are overrepresented in\ncross-model ensembles due to validation set overfitting, and we encourage model\ndevelopers to address this issue. We launch TabArena with a public leaderboard,\nreproducible code, and maintenance protocols to create a living benchmark\navailable at https://tabarena.ai.",
    "published": "2025-06-20T07:14:48Z",
    "updated": "2025-10-29T10:58:12Z",
    "link": "http://arxiv.org/pdf/2506.16791v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Nick Erickson",
      "Lennart Purucker",
      "Andrej Tschalzev",
      "David Holzmüller",
      "Prateek Mutalik Desai",
      "David Salinas",
      "Frank Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25386v1",
    "title": "Integrating Legal and Logical Specifications in Perception, Prediction,\n  and Planning for Automated Driving: A Survey of Methods",
    "summary": "This survey provides an analysis of current methodologies integrating legal\nand logical specifications into the perception, prediction, and planning\nmodules of automated driving systems. We systematically explore techniques\nranging from logic-based frameworks to computational legal reasoning\napproaches, emphasizing their capability to ensure regulatory compliance and\ninterpretability in dynamic and uncertain driving environments. A central\nfinding is that significant challenges arise at the intersection of perceptual\nreliability, legal compliance, and decision-making justifiability. To\nsystematically analyze these challenges, we introduce a taxonomy categorizing\nexisting approaches by their theoretical foundations, architectural\nimplementations, and validation strategies. We particularly focus on methods\nthat address perceptual uncertainty and incorporate explicit legal norms,\nfacilitating decisions that are both technically robust and legally defensible.\nThe review covers neural-symbolic integration methods for perception,\nlogic-driven rule representation, and norm-aware prediction strategies, all\ncontributing toward transparent and accountable autonomous vehicle operation.\nWe highlight critical open questions and practical trade-offs that must be\naddressed, offering multidisciplinary insights from engineering, logic, and law\nto guide future developments in legally compliant autonomous driving systems.",
    "published": "2025-10-29T10:57:24Z",
    "updated": "2025-10-29T10:57:24Z",
    "link": "http://arxiv.org/pdf/2510.25386v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "authors": [
      "Kumar Manas",
      "Mert Keser",
      "Alois Knoll"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25378v1",
    "title": "Hallucinations in Bibliographic Recommendation: Citation Frequency as a\n  Proxy for Training Data Redundancy",
    "summary": "Large language models (LLMs) have been increasingly applied to a wide range\nof tasks, from natural language understanding to code generation. While they\nhave also been used to assist in bibliographic recommendation, the\nhallucination of non-existent papers remains a major issue. Building on prior\nstudies, this study hypothesizes that an LLM's ability to correctly produce\nbibliographic information depends on whether the underlying knowledge is\ngenerated or memorized, with highly cited papers (i.e., more frequently appear\nin the training corpus) showing lower hallucination rates. We therefore assume\ncitation count as a proxy for training data redundancy (i.e., the frequency\nwith which a given bibliographic record is repeatedly represented in the\npretraining corpus) and investigate how citation frequency affects hallucinated\nreferences in LLM outputs. Using GPT-4.1, we generated and manually verified\n100 bibliographic records across twenty computer-science domains, and measured\nfactual consistency via cosine similarity between generated and authentic\nmetadata. The results revealed that (i) hallucination rates vary across\nresearch domains, (ii) citation count is strongly correlated with factual\naccuracy, and (iii) bibliographic information becomes almost verbatimly\nmemorized beyond approximately 1,000 citations. These findings suggest that\nhighly cited papers are nearly verbatimly retained in the model, indicating a\nthreshold where generalization shifts into memorization.",
    "published": "2025-10-29T10:51:35Z",
    "updated": "2025-10-29T10:51:35Z",
    "link": "http://arxiv.org/pdf/2510.25378v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Junichiro Niimi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.20274v2",
    "title": "Probabilistic Kernel Function for Fast Angle Testing",
    "summary": "In this paper, we study the angle testing problem in the context of\nsimilarity search in high-dimensional Euclidean spaces and propose two\nprojection-based probabilistic kernel functions, one designed for angle\ncomparison and the other for angle thresholding. Unlike existing approaches\nthat rely on random projection vectors drawn from Gaussian distributions, our\napproach leverages reference angles and employs a deterministic structure for\nthe projection vectors. Notably, our kernel functions do not require asymptotic\nassumptions, such as the number of projection vectors tending to infinity, and\ncan be both theoretically and experimentally shown to outperform\nGaussian-distribution-based kernel functions. We apply the proposed kernel\nfunction to Approximate Nearest Neighbor Search (ANNS) and demonstrate that our\napproach achieves a 2.5X ~ 3X higher query-per-second (QPS) throughput compared\nto the widely-used graph-based search algorithm HNSW.",
    "published": "2025-05-26T17:53:28Z",
    "updated": "2025-10-29T10:47:16Z",
    "link": "http://arxiv.org/pdf/2505.20274v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.DB",
      "cs.DS"
    ],
    "authors": [
      "Kejing Lu",
      "Chuan Xiao",
      "Yoshiharu Ishikawa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.02388v4",
    "title": "Steiner Traveling Salesman Problem with Quantum Annealing",
    "summary": "The Steiner Traveling Salesman Problem (STSP) is a variant of the classical\nTraveling Salesman Problem. The STSP involves incorporating steiner nodes,\nwhich are extra nodes not originally part of the required visit set but that\ncan be added to the route to enhance the overall solution and minimize the\ntotal travel cost. Given the NP-hard nature of the STSP, we propose a quantum\napproach to address it. Specifically, we employ quantum annealing using\nD-Wave's hardware to explore its potential for solving this problem. To enhance\ncomputational feasibility, we develop a preprocessing method that effectively\nreduces the network size. Our experimental results demonstrate that this\nreduction technique significantly decreases the problem complexity, making the\nQuadratic Unconstrained Binary Optimization formulation, the standard input for\nquantum annealers, better suited for existing quantum hardware. Furthermore,\nthe results highlight the potential of quantum annealing as a promising and\ninnovative approach for solving the STSP.",
    "published": "2025-04-03T08:29:57Z",
    "updated": "2025-10-29T10:46:59Z",
    "link": "http://arxiv.org/pdf/2504.02388v4.pdf",
    "category": [
      "quant-ph",
      "cs.AI",
      "cs.ET"
    ],
    "authors": [
      "Alessia Ciacco",
      "Francesca Guerriero",
      "Eneko Osaba"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25368v1",
    "title": "Position: Biology is the Challenge Physics-Informed ML Needs to Evolve",
    "summary": "Physics-Informed Machine Learning (PIML) has successfully integrated\nmechanistic understanding into machine learning, particularly in domains\ngoverned by well-known physical laws. This success has motivated efforts to\napply PIML to biology, a field rich in dynamical systems but shaped by\ndifferent constraints. Biological modeling, however, presents unique\nchallenges: multi-faceted and uncertain prior knowledge, heterogeneous and\nnoisy data, partial observability, and complex, high-dimensional networks. In\nthis position paper, we argue that these challenges should not be seen as\nobstacles to PIML, but as catalysts for its evolution. We propose\nBiology-Informed Machine Learning (BIML): a principled extension of PIML that\nretains its structural grounding while adapting to the practical realities of\nbiology. Rather than replacing PIML, BIML retools its methods to operate under\nsofter, probabilistic forms of prior knowledge. We outline four foundational\npillars as a roadmap for this transition: uncertainty quantification,\ncontextualization, constrained latent structure inference, and scalability.\nFoundation Models and Large Language Models will be key enablers, bridging\nhuman expertise with computational modeling. We conclude with concrete\nrecommendations to build the BIML ecosystem and channel PIML-inspired\ninnovation toward challenges of high scientific and societal relevance.",
    "published": "2025-10-29T10:39:29Z",
    "updated": "2025-10-29T10:39:29Z",
    "link": "http://arxiv.org/pdf/2510.25368v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "authors": [
      "Julien Martinelli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25366v1",
    "title": "A Convexity-dependent Two-Phase Training Algorithm for Deep Neural\n  Networks",
    "summary": "The key task of machine learning is to minimize the loss function that\nmeasures the model fit to the training data. The numerical methods to do this\nefficiently depend on the properties of the loss function. The most decisive\namong these properties is the convexity or non-convexity of the loss function.\nThe fact that the loss function can have, and frequently has, non-convex\nregions has led to a widespread commitment to non-convex methods such as Adam.\nHowever, a local minimum implies that, in some environment around it, the\nfunction is convex. In this environment, second-order minimizing methods such\nas the Conjugate Gradient (CG) give a guaranteed superlinear convergence. We\npropose a novel framework grounded in the hypothesis that loss functions in\nreal-world tasks swap from initial non-convexity to convexity towards the\noptimum. This is a property we leverage to design an innovative two-phase\noptimization algorithm. The presented algorithm detects the swap point by\nobserving the gradient norm dependence on the loss. In these regions,\nnon-convex (Adam) and convex (CG) algorithms are used, respectively. Computing\nexperiments confirm the hypothesis that this simple convexity structure is\nfrequent enough to be practically exploited to substantially improve\nconvergence and accuracy.",
    "published": "2025-10-29T10:37:24Z",
    "updated": "2025-10-29T10:37:24Z",
    "link": "http://arxiv.org/pdf/2510.25366v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "authors": [
      "Tomas Hrycej",
      "Bernhard Bermeitinger",
      "Massimo Pavone",
      "Götz-Henrik Wiegand",
      "Siegfried Handschuh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.12308v4",
    "title": "SNN-Based Online Learning of Concepts and Action Laws in an Open World",
    "summary": "We present the architecture of a fully autonomous, bio-inspired cognitive\nagent built around a spiking neural network (SNN) implementing the agent's\nsemantic memory. This agent explores its universe and learns concepts of\nobjects/situations and of its own actions in a one-shot manner. While\nobject/situation concepts are unary, action concepts are triples made up of an\ninitial situation, a motor activity, and an outcome. They embody the agent's\nknowledge of its universe's action laws. Both kinds of concepts have different\ndegrees of generality. To make decisions the agent queries its semantic memory\nfor the expected outcomes of envisaged actions and chooses the action to take\non the basis of these predictions. Our experiments show that the agent handles\nnew situations by appealing to previously learned general concepts and rapidly\nmodifies its concepts to adapt to environment changes.",
    "published": "2024-11-19T07:49:22Z",
    "updated": "2025-10-29T10:28:05Z",
    "link": "http://arxiv.org/pdf/2411.12308v4.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "cs.NE",
      "cs.RO"
    ],
    "authors": [
      "Christel Grimaud",
      "Dominique Longin",
      "Andreas Herzig"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.19252v2",
    "title": "Learning-Augmented Online Bipartite Fractional Matching",
    "summary": "Online bipartite matching is a fundamental problem in online optimization,\nextensively studied both in its integral and fractional forms due to its\ntheoretical significance and practical applications, such as online advertising\nand resource allocation. Motivated by recent progress in learning-augmented\nalgorithms, we study online bipartite fractional matching when the algorithm is\ngiven advice in the form of a suggested matching in each iteration. We develop\nalgorithms for both the vertex-weighted and unweighted variants that provably\ndominate the naive \"coin flip\" strategy of randomly choosing between the\nadvice-following and advice-free algorithms. Moreover, our algorithm for the\nvertex-weighted setting extends to the AdWords problem under the small bids\nassumption, yielding a significant improvement over the seminal work of\nMahdian, Nazerzadeh, and Saberi (EC 2007, TALG 2012). Complementing our\npositive results, we establish a hardness bound on the robustness-consistency\ntradeoff that is attainable by any algorithm. We empirically validate our\nalgorithms through experiments on synthetic and real-world data.",
    "published": "2025-05-25T18:15:29Z",
    "updated": "2025-10-29T10:20:13Z",
    "link": "http://arxiv.org/pdf/2505.19252v2.pdf",
    "category": [
      "cs.DS",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Davin Choo",
      "Billy Jin",
      "Yongho Shin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.06204v2",
    "title": "Differential Mamba",
    "summary": "Sequence models like Transformers and RNNs often overallocate attention to\nirrelevant context, leading to noisy intermediate representations. This\ndegrades LLM capabilities by promoting hallucinations, weakening long-range and\nretrieval abilities, and reducing robustness. Recent work has shown that\ndifferential design can mitigate this issue in Transformers, improving their\neffectiveness across various applications. In this paper, we explore whether\nthese techniques, originally developed for Transformers, can be applied to\nMamba, a recent architecture based on selective state-space layers that\nachieves Transformer-level performance with greater efficiency. We show that a\nnaive adaptation of differential design to Mamba is insufficient and requires\ncareful architectural modifications. To address this, we introduce a novel\ndifferential mechanism for Mamba, empirically validated on language modeling\nbenchmarks, demonstrating improved retrieval capabilities and superior\nperformance over vanilla Mamba. Finally, we conduct extensive ablation studies\nand empirical analyses to justify our design choices and provide evidence that\nour approach effectively mitigates the overallocation problem in Mamba-based\nmodels. Our code is publicly available: https://github.com/NadavSc/Diff-Mamba",
    "published": "2025-07-08T17:30:14Z",
    "updated": "2025-10-29T10:17:57Z",
    "link": "http://arxiv.org/pdf/2507.06204v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Nadav Schneider",
      "Itamar Zimerman",
      "Eliya Nachmani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.04864v2",
    "title": "Redistributing Rewards Across Time and Agents for Multi-Agent\n  Reinforcement Learning",
    "summary": "Credit assignmen, disentangling each agent's contribution to a shared reward,\nis a critical challenge in cooperative multi-agent reinforcement learning\n(MARL). To be effective, credit assignment methods must preserve the\nenvironment's optimal policy. Some recent approaches attempt this by enforcing\nreturn equivalence, where the sum of distributed rewards must equal the team\nreward. However, their guarantees are conditional on a learned model's\nregression accuracy, making them unreliable in practice. We introduce\nTemporal-Agent Reward Redistribution (TAR$^2$), an approach that decouples\ncredit modeling from this constraint. A neural network learns unnormalized\ncontribution scores, while a separate, deterministic normalization step\nenforces return equivalence by construction. We demonstrate that this method is\nequivalent to a valid Potential-Based Reward Shaping (PBRS), which guarantees\nthe optimal policy is preserved regardless of model accuracy. Empirically, on\nchallenging SMACLite and Google Research Football (GRF) benchmarks, TAR$^2$\naccelerates learning and achieves higher final performance than strong\nbaselines. These results establish our method as an effective solution for the\nagent-temporal credit assignment problem.",
    "published": "2025-02-07T12:07:57Z",
    "updated": "2025-10-29T10:11:05Z",
    "link": "http://arxiv.org/pdf/2502.04864v2.pdf",
    "category": [
      "cs.MA",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "authors": [
      "Aditya Kapoor",
      "Kale-ab Tessera",
      "Mayank Baranwal",
      "Harshad Khadilkar",
      "Jan Peters",
      "Stefano Albrecht",
      "Mingfei Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25340v1",
    "title": "Multi-party Agent Relation Sampling for Multi-party Ad Hoc Teamwork",
    "summary": "Multi-agent reinforcement learning (MARl) has achieved strong results in\ncooperative tasks but typically assumes fixed, fully controlled teams. Ad hoc\nteamwork (AHT) relaxes this by allowing collaboration with unknown partners,\nyet existing variants still presume shared conventions. We introduce\nMultil-party Ad Hoc Teamwork (MAHT), where controlled agents must coordinate\nwith multiple mutually unfamiliar groups of uncontrolled teammates. To address\nthis, we propose MARs, which builds a sparse skeleton graph and applies\nrelational modeling to capture cross-group dvnamics. Experiments on MPE and\nstarCralt ll show that MARs outperforms MARL and AHT baselines while converging\nfaster.",
    "published": "2025-10-29T09:53:07Z",
    "updated": "2025-10-29T09:53:07Z",
    "link": "http://arxiv.org/pdf/2510.25340v1.pdf",
    "category": [
      "cs.MA",
      "cs.AI"
    ],
    "authors": [
      "Beiwen Zhang",
      "Yongheng Liang",
      "Hejun Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.10136v5",
    "title": "A PBN-RL-XAI Framework for Discovering a \"Hit-and-Run\" Therapeutic\n  Strategy in Melanoma",
    "summary": "Innate resistance to anti-PD-1 immunotherapy remains a major clinical\nchallenge in metastatic melanoma, with the underlying molecular networks being\npoorly understood. To address this, we constructed a dynamic Probabilistic\nBoolean Network model using transcriptomic data from patient tumor biopsies to\nelucidate the regulatory logic governing therapy response. We then employed a\nreinforcement learning agent to systematically discover optimal, multi-step\ntherapeutic interventions and used explainable artificial intelligence to\nmechanistically interpret the agent's control policy. The analysis revealed\nthat a precisely timed, 4-step temporary inhibition of the lysyl oxidase like 2\nprotein (LOXL2) was the most effective strategy. Our explainable analysis\nshowed that this ''hit-and-run\" intervention is sufficient to erase the\nmolecular signature driving resistance, allowing the network to self-correct\nwithout requiring sustained intervention. This study presents a novel,\ntime-dependent therapeutic hypothesis for overcoming immunotherapy resistance\nand provides a powerful computational framework for identifying non-obvious\nintervention protocols in complex biological systems.",
    "published": "2025-07-14T10:35:38Z",
    "updated": "2025-10-29T09:47:20Z",
    "link": "http://arxiv.org/pdf/2507.10136v5.pdf",
    "category": [
      "q-bio.QM",
      "cs.AI"
    ],
    "authors": [
      "Zhonglin Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25327v1",
    "title": "MMEdge: Accelerating On-device Multimodal Inference via Pipelined\n  Sensing and Encoding",
    "summary": "Real-time multimodal inference on resource-constrained edge devices is\nessential for applications such as autonomous driving, human-computer\ninteraction, and mobile health. However, prior work often overlooks the tight\ncoupling between sensing dynamics and model execution, as well as the complex\ninter-modality dependencies. In this paper, we propose MMEdge, an new on-device\nmulti-modal inference framework based on pipelined sensing and encoding.\nInstead of waiting for complete sensor inputs, MMEdge decomposes the entire\ninference process into a sequence of fine-grained sensing and encoding units,\nallowing computation to proceed incrementally as data arrive. MMEdge also\nintroduces a lightweight but effective temporal aggregation module that\ncaptures rich temporal dynamics across different pipelined units to maintain\naccuracy performance. Such pipelined design also opens up opportunities for\nfine-grained cross-modal optimization and early decision-making during\ninference. To further enhance system performance under resource variability and\ninput data complexity, MMEdge incorporates an adaptive multimodal configuration\noptimizer that dynamically selects optimal sensing and model configurations for\neach modality under latency constraints, and a cross-modal speculative skipping\nmechanism that bypasses future units of slower modalities when early\npredictions reach sufficient confidence. We evaluate MMEdge using two public\nmultimodal datasets and deploy it on a real-world unmanned aerial vehicle\n(UAV)-based multimodal testbed. The results show that MMEdge significantly\nreduces end-to-end latency while maintaining high task accuracy across various\nsystem and data dynamics.",
    "published": "2025-10-29T09:41:03Z",
    "updated": "2025-10-29T09:41:03Z",
    "link": "http://arxiv.org/pdf/2510.25327v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Runxi Huang",
      "Mingxuan Yu",
      "Mingyu Tsoi",
      "Xiaomin Ouyang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25320v1",
    "title": "GAP: Graph-Based Agent Planning with Parallel Tool Use and Reinforcement\n  Learning",
    "summary": "Autonomous agents powered by large language models (LLMs) have shown\nimpressive capabilities in tool manipulation for complex task-solving. However,\nexisting paradigms such as ReAct rely on sequential reasoning and execution,\nfailing to exploit the inherent parallelism among independent sub-tasks. This\nsequential bottleneck leads to inefficient tool utilization and suboptimal\nperformance in multi-step reasoning scenarios. We introduce Graph-based Agent\nPlanning (GAP), a novel framework that explicitly models inter-task\ndependencies through graph-based planning to enable adaptive parallel and\nserial tool execution. Our approach trains agent foundation models to decompose\ncomplex tasks into dependency-aware sub-task graphs, autonomously determining\nwhich tools can be executed in parallel and which must follow sequential\ndependencies. This dependency-aware orchestration achieves substantial\nimprovements in both execution efficiency and task accuracy. To train GAP, we\nconstruct a high-quality dataset of graph-based planning traces derived from\nthe Multi-Hop Question Answering (MHQA) benchmark. We employ a two-stage\ntraining strategy: supervised fine-tuning (SFT) on the curated dataset,\nfollowed by reinforcement learning (RL) with a correctness-based reward\nfunction on strategically sampled queries where tool-based reasoning provides\nmaximum value. Experimental results on MHQA datasets demonstrate that GAP\nsignificantly outperforms traditional ReAct baselines, particularly on\nmulti-step retrieval tasks, while achieving dramatic improvements in tool\ninvocation efficiency through intelligent parallelization. The project page is\navailable at: https://github.com/WJQ7777/Graph-Agent-Planning.",
    "published": "2025-10-29T09:35:55Z",
    "updated": "2025-10-29T09:35:55Z",
    "link": "http://arxiv.org/pdf/2510.25320v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Jiaqi Wu",
      "Qinlao Zhao",
      "Zefeng Chen",
      "Kai Qin",
      "Yifei Zhao",
      "Xueqian Wang",
      "Yuhang Yao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.03595v2",
    "title": "Purifying Shampoo: Investigating Shampoo's Heuristics by Decomposing its\n  Preconditioner",
    "summary": "The recent success of Shampoo in the AlgoPerf contest has sparked renewed\ninterest in Kronecker-factorization-based optimization algorithms for training\nneural networks. Despite its success, Shampoo relies heavily on several\nheuristics such as learning rate grafting and stale preconditioning to achieve\nperformance at-scale. These heuristics increase algorithmic complexity,\nnecessitate further hyperparameter tuning, and lack theoretical justification.\nThis paper investigates these heuristics from the angle of Frobenius norm\napproximation to full-matrix Adam and decouples the preconditioner's\neigenvalues and eigenbasis updates. We show that grafting from Adam mitigates\nthe staleness and mis-scaling of the preconditioner's eigenvalues and how\ncorrecting the eigenvalues directly eliminates the need for learning rate\ngrafting. To manage the error induced by infrequent eigenbasis computations, we\npropose an adaptive criterion for determining the eigenbasis computation\nfrequency motivated by terminating a warm-started QR algorithm. This criterion\ndecouples the update frequency of different preconditioner matrices and enables\nus to investigate the impact of approximation error on convergence. These\npractical techniques offer a principled angle towards removing Shampoo's\nheuristics and developing improved Kronecker-factorization-based training\nalgorithms.",
    "published": "2025-06-04T05:55:41Z",
    "updated": "2025-10-29T09:34:18Z",
    "link": "http://arxiv.org/pdf/2506.03595v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "authors": [
      "Runa Eschenhagen",
      "Aaron Defazio",
      "Tsung-Hsien Lee",
      "Richard E. Turner",
      "Hao-Jun Michael Shi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25319v1",
    "title": "4-Doodle: Text to 3D Sketches that Move!",
    "summary": "We present a novel task: text-to-3D sketch animation, which aims to bring\nfreeform sketches to life in dynamic 3D space. Unlike prior works focused on\nphotorealistic content generation, we target sparse, stylized, and\nview-consistent 3D vector sketches, a lightweight and interpretable medium\nwell-suited for visual communication and prototyping. However, this task is\nvery challenging: (i) no paired dataset exists for text and 3D (or 4D)\nsketches; (ii) sketches require structural abstraction that is difficult to\nmodel with conventional 3D representations like NeRFs or point clouds; and\n(iii) animating such sketches demands temporal coherence and multi-view\nconsistency, which current pipelines do not address. Therefore, we propose\n4-Doodle, the first training-free framework for generating dynamic 3D sketches\nfrom text. It leverages pretrained image and video diffusion models through a\ndual-space distillation scheme: one space captures multi-view-consistent\ngeometry using differentiable B\\'ezier curves, while the other encodes motion\ndynamics via temporally-aware priors. Unlike prior work (e.g., DreamFusion),\nwhich optimizes from a single view per step, our multi-view optimization\nensures structural alignment and avoids view ambiguity, critical for sparse\nsketches. Furthermore, we introduce a structure-aware motion module that\nseparates shape-preserving trajectories from deformation-aware changes,\nenabling expressive motion such as flipping, rotation, and articulated\nmovement. Extensive experiments show that our method produces temporally\nrealistic and structurally stable 3D sketch animations, outperforming existing\nbaselines in both fidelity and controllability. We hope this work serves as a\nstep toward more intuitive and accessible 4D content creation.",
    "published": "2025-10-29T09:33:29Z",
    "updated": "2025-10-29T09:33:29Z",
    "link": "http://arxiv.org/pdf/2510.25319v1.pdf",
    "category": [
      "cs.GR",
      "cs.AI"
    ],
    "authors": [
      "Hao Chen",
      "Jiaqi Wang",
      "Yonggang Qi",
      "Ke Li",
      "Kaiyue Pang",
      "Yi-Zhe Song"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25311v1",
    "title": "Dense and Diverse Goal Coverage in Multi Goal Reinforcement Learning",
    "summary": "Reinforcement Learning algorithms are primarily focused on learning a policy\nthat maximizes expected return. As a result, the learned policy can exploit one\nor few reward sources. However, in many natural situations, it is desirable to\nlearn a policy that induces a dispersed marginal state distribution over\nrewarding states, while maximizing the expected return which is typically tied\nto reaching a goal state. This aspect remains relatively unexplored. Existing\ntechniques based on entropy regularization and intrinsic rewards use\nstochasticity for encouraging exploration to find an optimal policy which may\nnot necessarily lead to dispersed marginal state distribution over rewarding\nstates. Other RL algorithms which match a target distribution assume the latter\nto be available apriori. This may be infeasible in large scale systems where\nenumeration of all states is not possible and a state is determined to be a\ngoal state only upon reaching it. We formalize the problem of maximizing the\nexpected return while uniformly visiting the goal states as Multi Goal RL in\nwhich an oracle classifier over the state space determines the goal states. We\npropose a novel algorithm that learns a high-return policy mixture with\nmarginal state distribution dispersed over the set of goal states. Our\nalgorithm is based on optimizing a custom RL reward which is computed - based\non the current policy mixture - at each iteration for a set of sampled\ntrajectories. The latter are used via an offline RL algorithm to update the\npolicy mixture. We prove performance guarantees for our algorithm, showing\nefficient convergence bounds for optimizing a natural objective which captures\nthe expected return as well as the dispersion of the marginal state\ndistribution over the goal states. We design and perform experiments on\nsynthetic MDPs and standard RL environments to evaluate the effectiveness of\nour algorithm.",
    "published": "2025-10-29T09:23:21Z",
    "updated": "2025-10-29T09:23:21Z",
    "link": "http://arxiv.org/pdf/2510.25311v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Sagalpreet Singh",
      "Rishi Saket",
      "Aravindan Raghuveer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.12593v3",
    "title": "Expand and Compress: Exploring Tuning Principles for Continual\n  Spatio-Temporal Graph Forecasting",
    "summary": "The widespread deployment of sensing devices leads to a surge in data for\nspatio-temporal forecasting applications such as traffic flow, air quality, and\nwind energy. Although spatio-temporal graph neural networks have achieved\nsuccess in modeling various static spatio-temporal forecasting scenarios,\nreal-world spatio-temporal data are typically received in a streaming manner,\nand the network continuously expands with the installation of new sensors.\nThus, spatio-temporal forecasting in streaming scenarios faces dual challenges:\nthe inefficiency of retraining models over newly arrived data and the\ndetrimental effects of catastrophic forgetting over long-term history. To\naddress these challenges, we propose a novel prompt tuning-based continuous\nforecasting method, following two fundamental tuning principles guided by\nempirical and theoretical analysis: expand and compress, which effectively\nresolve the aforementioned problems with lightweight tuning parameters.\nSpecifically, we integrate the base spatio-temporal graph neural network with a\ncontinuous prompt pool, utilizing stored prompts (i.e., few learnable\nparameters) in memory, and jointly optimize them with the base spatio-temporal\ngraph neural network. This method ensures that the model sequentially learns\nfrom the spatio-temporal data stream to accomplish tasks for corresponding\nperiods. Extensive experimental results on multiple real-world datasets\ndemonstrate the multi-faceted superiority of our method over the\nstate-of-the-art baselines, including effectiveness, efficiency, universality,\netc.",
    "published": "2024-10-16T14:12:11Z",
    "updated": "2025-10-29T08:45:38Z",
    "link": "http://arxiv.org/pdf/2410.12593v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Wei Chen",
      "Yuxuan Liang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.08615v2",
    "title": "UGM2N: An Unsupervised and Generalizable Mesh Movement Network via\n  M-Uniform Loss",
    "summary": "Partial differential equations (PDEs) form the mathematical foundation for\nmodeling physical systems in science and engineering, where numerical solutions\ndemand rigorous accuracy-efficiency tradeoffs. Mesh movement techniques address\nthis challenge by dynamically relocating mesh nodes to rapidly-varying regions,\nenhancing both simulation accuracy and computational efficiency. However,\ntraditional approaches suffer from high computational complexity and geometric\ninflexibility, limiting their applicability, and existing supervised\nlearning-based approaches face challenges in zero-shot generalization across\ndiverse PDEs and mesh topologies.In this paper, we present an Unsupervised and\nGeneralizable Mesh Movement Network (UGM2N). We first introduce unsupervised\nmesh adaptation through localized geometric feature learning, eliminating the\ndependency on pre-adapted meshes. We then develop a physics-constrained loss\nfunction, M-Uniform loss, that enforces mesh equidistribution at the nodal\nlevel.Experimental results demonstrate that the proposed network exhibits\nequation-agnostic generalization and geometric independence in efficient mesh\nadaptation. It demonstrates consistent superiority over existing methods,\nincluding robust performance across diverse PDEs and mesh geometries,\nscalability to multi-scale resolutions and guaranteed error reduction without\nmesh tangling.",
    "published": "2025-08-12T03:56:45Z",
    "updated": "2025-10-29T08:36:55Z",
    "link": "http://arxiv.org/pdf/2508.08615v2.pdf",
    "category": [
      "cs.AI",
      "cs.NA",
      "math.NA"
    ],
    "authors": [
      "Zhichao Wang",
      "Xinhai Chen",
      "Qinglin Wang",
      "Xiang Gao",
      "Qingyang Zhang",
      "Menghan Jia",
      "Xiang Zhang",
      "Jie Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25268v1",
    "title": "SynHLMA:Synthesizing Hand Language Manipulation for Articulated Object\n  with Discrete Human Object Interaction Representation",
    "summary": "Generating hand grasps with language instructions is a widely studied topic\nthat benefits from embodied AI and VR/AR applications. While transferring into\nhand articulatied object interaction (HAOI), the hand grasps synthesis requires\nnot only object functionality but also long-term manipulation sequence along\nthe object deformation. This paper proposes a novel HAOI sequence generation\nframework SynHLMA, to synthesize hand language manipulation for articulated\nobjects. Given a complete point cloud of an articulated object, we utilize a\ndiscrete HAOI representation to model each hand object interaction frame. Along\nwith the natural language embeddings, the representations are trained by an\nHAOI manipulation language model to align the grasping process with its\nlanguage description in a shared representation space. A joint-aware loss is\nemployed to ensure hand grasps follow the dynamic variations of articulated\nobject joints. In this way, our SynHLMA achieves three typical hand\nmanipulation tasks for articulated objects of HAOI generation, HAOI prediction\nand HAOI interpolation. We evaluate SynHLMA on our built HAOI-lang dataset and\nexperimental results demonstrate the superior hand grasp sequence generation\nperformance comparing with state-of-the-art. We also show a robotics grasp\napplication that enables dexterous grasps execution from imitation learning\nusing the manipulation sequence provided by our SynHLMA. Our codes and datasets\nwill be made publicly available.",
    "published": "2025-10-29T08:27:00Z",
    "updated": "2025-10-29T08:27:00Z",
    "link": "http://arxiv.org/pdf/2510.25268v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Wang zhi",
      "Yuyan Liu",
      "Liu Liu",
      "Li Zhang",
      "Ruixuan Lu",
      "Dan Guo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.00635v2",
    "title": "Learning with Calibration: Exploring Test-Time Computing of\n  Spatio-Temporal Forecasting",
    "summary": "Spatio-temporal forecasting is crucial in many domains, such as\ntransportation, meteorology, and energy. However, real-world scenarios\nfrequently present challenges such as signal anomalies, noise, and\ndistributional shifts. Existing solutions primarily enhance robustness by\nmodifying network architectures or training procedures. Nevertheless, these\napproaches are computationally intensive and resource-demanding, especially for\nlarge-scale applications. In this paper, we explore a novel test-time computing\nparadigm, namely learning with calibration, ST-TTC, for spatio-temporal\nforecasting. Through learning with calibration, we aim to capture periodic\nstructural biases arising from non-stationarity during the testing phase and\nperform real-time bias correction on predictions to improve accuracy.\nSpecifically, we first introduce a spectral-domain calibrator with\nphase-amplitude modulation to mitigate periodic shift and then propose a flash\nupdating mechanism with a streaming memory queue for efficient test-time\ncomputation. ST-TTC effectively bypasses complex training-stage techniques,\noffering an efficient and generalizable paradigm. Extensive experiments on\nreal-world datasets demonstrate the effectiveness, universality, flexibility\nand efficiency of our proposed method.",
    "published": "2025-05-31T16:48:27Z",
    "updated": "2025-10-29T08:25:53Z",
    "link": "http://arxiv.org/pdf/2506.00635v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.ET",
      "stat.ML"
    ],
    "authors": [
      "Wei Chen",
      "Yuxuan Liang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25262v1",
    "title": "IBNorm: Information-Bottleneck Inspired Normalization for Representation\n  Learning",
    "summary": "Normalization is fundamental to deep learning, but existing approaches such\nas BatchNorm, LayerNorm, and RMSNorm are variance-centric by enforcing zero\nmean and unit variance, stabilizing training without controlling how\nrepresentations capture task-relevant information. We propose IB-Inspired\nNormalization (IBNorm), a simple yet powerful family of methods grounded in the\nInformation Bottleneck principle. IBNorm introduces bounded compression\noperations that encourage embeddings to preserve predictive information while\nsuppressing nuisance variability, yielding more informative representations\nwhile retaining the stability and compatibility of standard normalization.\nTheoretically, we prove that IBNorm achieves a higher IB value and tighter\ngeneralization bounds than variance-centric methods. Empirically, IBNorm\nconsistently outperforms BatchNorm, LayerNorm, and RMSNorm across large-scale\nlanguage models (LLaMA, GPT-2) and vision models (ResNet, ViT), with mutual\ninformation analysis confirming superior information bottleneck behavior. Code\nwill be released publicly.",
    "published": "2025-10-29T08:21:32Z",
    "updated": "2025-10-29T08:21:32Z",
    "link": "http://arxiv.org/pdf/2510.25262v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Xiandong Zou",
      "Pan Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.19311v2",
    "title": "DGTRSD & DGTRS-CLIP: A Dual-Granularity Remote Sensing Image-Text\n  Dataset and Vision Language Foundation Model for Alignment",
    "summary": "Vision Language Foundation Models based on CLIP architecture for remote\nsensing primarily rely on short text captions, which often result in incomplete\nsemantic representations. Although longer captions convey richer information,\nexisting models struggle to process them effectively because of limited\ntext-encoding capacity, and there remains a shortage of resources that align\nremote sensing images with both short text and long text captions. To address\nthis gap, we introduce DGTRSD, a dual-granularity remote sensing image-text\ndataset, where each image is paired with both a short text caption and a long\ntext description, providing a solid foundation for dual-granularity semantic\nmodeling. Based on this, we further propose DGTRS-CLIP, a dual-granularity\ncurriculum learning framework that combines short text and long text\nsupervision to achieve dual-granularity semantic alignment. Extensive\nexperiments on four typical zero-shot tasks: long text cross-modal retrieval,\nshort text cross-modal retrieval, image classification, and semantic\nlocalization demonstrate that DGTRS-CLIP consistently outperforms existing\nmethods across all tasks. The code has been open-sourced and is available at\nhttps://github.com/MitsuiChen14/DGTRS.",
    "published": "2025-03-25T03:17:42Z",
    "updated": "2025-10-29T08:14:38Z",
    "link": "http://arxiv.org/pdf/2503.19311v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Weizhi Chen",
      "Yupeng Deng",
      "Jin Wei",
      "Jingbo Chen",
      "Jiansheng Chen",
      "Yuman Feng",
      "Zhihao Xi",
      "Diyou Liu",
      "Kai Li",
      "Yu Meng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25259v1",
    "title": "TV-Rec: Time-Variant Convolutional Filter for Sequential Recommendation",
    "summary": "Recently, convolutional filters have been increasingly adopted in sequential\nrecommendation for their ability to capture local sequential patterns. However,\nmost of these models complement convolutional filters with self-attention. This\nis because convolutional filters alone, generally fixed filters, struggle to\ncapture global interactions necessary for accurate recommendation. We propose\nTime-Variant Convolutional Filters for Sequential Recommendation (TV-Rec), a\nmodel inspired by graph signal processing, where time-variant graph filters\ncapture position-dependent temporal variations in user sequences. By replacing\nboth fixed kernels and self-attention with time-variant filters, TV-Rec\nachieves higher expressive power and better captures complex interaction\npatterns in user behavior. This design not only eliminates the need for\nself-attention but also reduces computation while accelerating inference.\nExtensive experiments on six public benchmarks show that TV-Rec outperforms\nstate-of-the-art baselines by an average of 7.49%.",
    "published": "2025-10-29T08:14:03Z",
    "updated": "2025-10-29T08:14:03Z",
    "link": "http://arxiv.org/pdf/2510.25259v1.pdf",
    "category": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Yehjin Shin",
      "Jeongwhan Choi",
      "Seojin Kim",
      "Noseong Park"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25254v1",
    "title": "Scaling Up Bayesian DAG Sampling",
    "summary": "Bayesian inference of Bayesian network structures is often performed by\nsampling directed acyclic graphs along an appropriately constructed Markov\nchain. We present two techniques to improve sampling. First, we give an\nefficient implementation of basic moves, which add, delete, or reverse a single\narc. Second, we expedite summing over parent sets, an expensive task required\nfor more sophisticated moves: we devise a preprocessing method to prune\npossible parent sets so as to approximately preserve the sums. Our empirical\nstudy shows that our techniques can yield substantial efficiency gains compared\nto previous methods.",
    "published": "2025-10-29T08:06:20Z",
    "updated": "2025-10-29T08:06:20Z",
    "link": "http://arxiv.org/pdf/2510.25254v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Daniele Nikzad",
      "Alexander Zhilkin",
      "Juha Harviainen",
      "Jack Kuipers",
      "Giusi Moffa",
      "Mikko Koivisto"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.14257v2",
    "title": "Revisiting Service Level Objectives and System Level Metrics in Large\n  Language Model Serving",
    "summary": "User experience is a critical factor Large Language Model (LLM) serving\nsystems must consider, where service level objectives (SLOs) considering the\nexperience of individual requests and system level metrics (SLMs) considering\nthe overall system performance are two key performance measures. However, we\nobserve two notable issues in existing metrics: 1) manually delaying the\ndelivery of some tokens can improve SLOs, and 2) actively abandoning requests\nthat do not meet SLOs can improve SLMs, both of which are counterintuitive.\n  In this paper, we revisit SLOs and SLMs in LLM serving, and propose a new SLO\nthat aligns with user experience. Based on the SLO, we propose a comprehensive\nmetric framework called smooth goodput, which integrates SLOs and SLMs to\nreflect the nature of user experience in LLM serving. Through this unified\nframework, we reassess the performance of different LLM serving systems under\nmultiple workloads. Evaluation results show that our metric framework provides\na more comprehensive view of token delivery and request processing, and\neffectively captures the optimal point of user experience and system\nperformance with different serving strategies.",
    "published": "2024-10-18T08:05:37Z",
    "updated": "2025-10-29T07:56:51Z",
    "link": "http://arxiv.org/pdf/2410.14257v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Zhibin Wang",
      "Shipeng Li",
      "Yuhang Zhou",
      "Xue Li",
      "Zhonghui Zhang",
      "Nguyen Cam-Tu",
      "Rong Gu",
      "Chen Tian",
      "Guihai Chen",
      "Sheng Zhong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.22967v2",
    "title": "MAD-Fact: A Multi-Agent Debate Framework for Long-Form Factuality\n  Evaluation in LLMs",
    "summary": "The widespread adoption of Large Language Models (LLMs) raises critical\nconcerns about the factual accuracy of their outputs, especially in high-risk\ndomains such as biomedicine, law, and education. Existing evaluation methods\nfor short texts often fail on long-form content due to complex reasoning\nchains, intertwined perspectives, and cumulative information. To address this,\nwe propose a systematic approach integrating large-scale long-form datasets,\nmulti-agent verification mechanisms, and weighted evaluation metrics. We\nconstruct LongHalluQA, a Chinese long-form factuality dataset; and develop\nMAD-Fact, a debate-based multi-agent verification system. We introduce a fact\nimportance hierarchy to capture the varying significance of claims in long-form\ntexts. Experiments on two benchmarks show that larger LLMs generally maintain\nhigher factual consistency, while domestic models excel on Chinese content. Our\nwork provides a structured framework for evaluating and enhancing factual\nreliability in long-form LLM outputs, guiding their safe deployment in\nsensitive domains.",
    "published": "2025-10-27T03:41:32Z",
    "updated": "2025-10-29T07:50:03Z",
    "link": "http://arxiv.org/pdf/2510.22967v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Yucheng Ning",
      "Xixun Lin",
      "Fang Fang",
      "Yanan Cao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25241v1",
    "title": "One-shot Humanoid Whole-body Motion Learning",
    "summary": "Whole-body humanoid motion represents a cornerstone challenge in robotics,\nintegrating balance, coordination, and adaptability to enable human-like\nbehaviors. However, existing methods typically require multiple training\nsamples per motion category, rendering the collection of high-quality human\nmotion datasets both labor-intensive and costly. To address this, we propose a\nnovel approach that trains effective humanoid motion policies using only a\nsingle non-walking target motion sample alongside readily available walking\nmotions. The core idea lies in leveraging order-preserving optimal transport to\ncompute distances between walking and non-walking sequences, followed by\ninterpolation along geodesics to generate new intermediate pose skeletons,\nwhich are then optimized for collision-free configurations and retargeted to\nthe humanoid before integration into a simulated environment for policy\ntraining via reinforcement learning. Experimental evaluations on the CMU MoCap\ndataset demonstrate that our method consistently outperforms baselines,\nachieving superior performance across metrics. Code will be released upon\nacceptance.",
    "published": "2025-10-29T07:48:10Z",
    "updated": "2025-10-29T07:48:10Z",
    "link": "http://arxiv.org/pdf/2510.25241v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Hao Huang",
      "Geeta Chandra Raju Bethala",
      "Shuaihang Yuan",
      "Congcong Wen",
      "Anthony Tzes",
      "Yi Fang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25234v1",
    "title": "Learning Disentangled Speech- and Expression-Driven Blendshapes for 3D\n  Talking Face Animation",
    "summary": "Expressions are fundamental to conveying human emotions. With the rapid\nadvancement of AI-generated content (AIGC), realistic and expressive 3D facial\nanimation has become increasingly crucial. Despite recent progress in\nspeech-driven lip-sync for talking-face animation, generating emotionally\nexpressive talking faces remains underexplored. A major obstacle is the\nscarcity of real emotional 3D talking-face datasets due to the high cost of\ndata capture. To address this, we model facial animation driven by both speech\nand emotion as a linear additive problem. Leveraging a 3D talking-face dataset\nwith neutral expressions (VOCAset) and a dataset of 3D expression sequences\n(Florence4D), we jointly learn a set of blendshapes driven by speech and\nemotion. We introduce a sparsity constraint loss to encourage disentanglement\nbetween the two types of blendshapes while allowing the model to capture\ninherent secondary cross-domain deformations present in the training data. The\nlearned blendshapes can be further mapped to the expression and jaw pose\nparameters of the FLAME model, enabling the animation of 3D Gaussian avatars.\nQualitative and quantitative experiments demonstrate that our method naturally\ngenerates talking faces with specified expressions while maintaining accurate\nlip synchronization. Perceptual studies further show that our approach achieves\nsuperior emotional expressivity compared to existing methods, without\ncompromising lip-sync quality.",
    "published": "2025-10-29T07:29:21Z",
    "updated": "2025-10-29T07:29:21Z",
    "link": "http://arxiv.org/pdf/2510.25234v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "authors": [
      "Yuxiang Mao",
      "Zhijie Zhang",
      "Zhiheng Zhang",
      "Jiawei Liu",
      "Chen Zeng",
      "Shihong Xia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25232v1",
    "title": "From Medical Records to Diagnostic Dialogues: A Clinical-Grounded\n  Approach and Dataset for Psychiatric Comorbidity",
    "summary": "Psychiatric comorbidity is clinically significant yet challenging due to the\ncomplexity of multiple co-occurring disorders. To address this, we develop a\nnovel approach integrating synthetic patient electronic medical record (EMR)\nconstruction and multi-agent diagnostic dialogue generation. We create 502\nsynthetic EMRs for common comorbid conditions using a pipeline that ensures\nclinical relevance and diversity. Our multi-agent framework transfers the\nclinical interview protocol into a hierarchical state machine and context tree,\nsupporting over 130 diagnostic states while maintaining clinical standards.\nThrough this rigorous process, we construct PsyCoTalk, the first large-scale\ndialogue dataset supporting comorbidity, containing 3,000 multi-turn diagnostic\ndialogues validated by psychiatrists. This dataset enhances diagnostic accuracy\nand treatment planning, offering a valuable resource for psychiatric\ncomorbidity research. Compared to real-world clinical transcripts, PsyCoTalk\nexhibits high structural and linguistic fidelity in terms of dialogue length,\ntoken distribution, and diagnostic reasoning strategies. Licensed psychiatrists\nconfirm the realism and diagnostic validity of the dialogues. This dataset\nenables the development and evaluation of models capable of multi-disorder\npsychiatric screening in a single conversational pass.",
    "published": "2025-10-29T07:18:43Z",
    "updated": "2025-10-29T07:18:43Z",
    "link": "http://arxiv.org/pdf/2510.25232v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Tianxi Wan",
      "Jiaming Luo",
      "Siyuan Chen",
      "Kunyao Lan",
      "Jianhua Chen",
      "Haiyang Geng",
      "Mengyue Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23045v2",
    "title": "A Survey of AI Scientists: Surveying the automatic Scientists and\n  Research",
    "summary": "Artificial intelligence is undergoing a profound transition from a\ncomputational instrument to an autonomous originator of scientific knowledge.\nThis emerging paradigm, the AI scientist, is architected to emulate the\ncomplete scientific workflow-from initial hypothesis generation to the final\nsynthesis of publishable findings-thereby promising to fundamentally reshape\nthe pace and scale of discovery. However, the rapid and unstructured\nproliferation of these systems has created a fragmented research landscape,\nobscuring overarching methodological principles and developmental trends. This\nsurvey provides a systematic and comprehensive synthesis of this domain by\nintroducing a unified, six-stage methodological framework that deconstructs the\nend-to-end scientific process into: Literature Review, Idea Generation,\nExperimental Preparation, Experimental Execution, Scientific Writing, and Paper\nGeneration. Through this analytical lens, we chart the field's evolution from\nearly Foundational Modules (2022-2023) to integrated Closed-Loop Systems\n(2024), and finally to the current frontier of Scalability, Impact, and\nHuman-AI Collaboration (2025-present). By rigorously synthesizing these\ndevelopments, this survey not only clarifies the current state of autonomous\nscience but also provides a critical roadmap for overcoming remaining\nchallenges in robustness and governance, ultimately guiding the next generation\nof systems toward becoming trustworthy and indispensable partners in human\nscientific inquiry.",
    "published": "2025-10-27T06:13:21Z",
    "updated": "2025-10-29T07:18:38Z",
    "link": "http://arxiv.org/pdf/2510.23045v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Guiyao Tie",
      "Pan Zhou",
      "Lichao Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.12128v4",
    "title": "LaM-SLidE: Latent Space Modeling of Spatial Dynamical Systems via Linked\n  Entities",
    "summary": "Generative models are spearheading recent progress in deep learning,\nshowcasing strong promise for trajectory sampling in dynamical systems as well.\nHowever, whereas latent space modeling paradigms have transformed image and\nvideo generation, similar approaches are more difficult for most dynamical\nsystems. Such systems -- from chemical molecule structures to collective human\nbehavior -- are described by interactions of entities, making them inherently\nlinked to connectivity patterns, entity conservation, and the traceability of\nentities over time. Our approach, LaM-SLidE (Latent Space Modeling of Spatial\nDynamical Systems via Linked Entities), bridges the gap between: (1) keeping\nthe traceability of individual entities in a latent system representation, and\n(2) leveraging the efficiency and scalability of recent advances in image and\nvideo generation, where pre-trained encoder and decoder enable generative\nmodeling directly in latent space. The core idea of LaM-SLidE is the\nintroduction of identifier representations (IDs) that enable the retrieval of\nentity properties and entity composition from latent system representations,\nthus fostering traceability. Experimentally, across different domains, we show\nthat LaM-SLidE performs favorably in terms of speed, accuracy, and\ngeneralizability. Code is available at https://github.com/ml-jku/LaM-SLidE .",
    "published": "2025-02-17T18:49:13Z",
    "updated": "2025-10-29T07:10:42Z",
    "link": "http://arxiv.org/pdf/2502.12128v4.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Florian Sestak",
      "Artur Toshev",
      "Andreas Fürst",
      "Günter Klambauer",
      "Andreas Mayr",
      "Johannes Brandstetter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25228v1",
    "title": "Studies for : A Human-AI Co-Creative Sound Artwork Using a Real-time\n  Multi-channel Sound Generation Model",
    "summary": "This paper explores the integration of AI technologies into the artistic\nworkflow through the creation of Studies for, a generative sound installation\ndeveloped in collaboration with sound artist Evala\n(https://www.ntticc.or.jp/en/archive/works/studies-for/). The installation\nemploys SpecMaskGIT, a lightweight yet high-quality sound generation AI model,\nto generate and playback eight-channel sound in real-time, creating an\nimmersive auditory experience over the course of a three-month exhibition. The\nwork is grounded in the concept of a \"new form of archive,\" which aims to\npreserve the artistic style of an artist while expanding beyond artists' past\nartworks by continued generation of new sound elements. This speculative\napproach to archival preservation is facilitated by training the AI model on a\ndataset consisting of over 200 hours of Evala's past sound artworks.\n  By addressing key requirements in the co-creation of art using AI, this study\nhighlights the value of the following aspects: (1) the necessity of integrating\nartist feedback, (2) datasets derived from an artist's past works, and (3)\nensuring the inclusion of unexpected, novel outputs. In Studies for, the model\nwas designed to reflect the artist's artistic identity while generating new,\npreviously unheard sounds, making it a fitting realization of the concept of \"a\nnew form of archive.\" We propose a Human-AI co-creation framework for\neffectively incorporating sound generation AI models into the sound art\ncreation process and suggest new possibilities for creating and archiving sound\nart that extend an artist's work beyond their physical existence. Demo page:\nhttps://sony.github.io/studies-for/",
    "published": "2025-10-29T07:05:59Z",
    "updated": "2025-10-29T07:05:59Z",
    "link": "http://arxiv.org/pdf/2510.25228v1.pdf",
    "category": [
      "cs.SD",
      "cs.AI"
    ],
    "authors": [
      "Chihiro Nagashima",
      "Akira Takahashi",
      "Zhi Zhong",
      "Shusuke Takahashi",
      "Yuki Mitsufuji"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25226v1",
    "title": "Cost-Sensitive Unbiased Risk Estimation for Multi-Class\n  Positive-Unlabeled Learning",
    "summary": "Positive--Unlabeled (PU) learning considers settings in which only positive\nand unlabeled data are available, while negatives are missing or left\nunlabeled. This situation is common in real applications where annotating\nreliable negatives is difficult or costly. Despite substantial progress in PU\nlearning, the multi-class case (MPU) remains challenging: many existing\napproaches do not ensure \\emph{unbiased risk estimation}, which limits\nperformance and stability. We propose a cost-sensitive multi-class PU method\nbased on \\emph{adaptive loss weighting}. Within the empirical risk minimization\nframework, we assign distinct, data-dependent weights to the positive and\n\\emph{inferred-negative} (from the unlabeled mixture) loss components so that\nthe resulting empirical objective is an unbiased estimator of the target risk.\nWe formalize the MPU data-generating process and establish a generalization\nerror bound for the proposed estimator. Extensive experiments on \\textbf{eight}\npublic datasets, spanning varying class priors and numbers of classes, show\nconsistent gains over strong baselines in both accuracy and stability.",
    "published": "2025-10-29T07:01:32Z",
    "updated": "2025-10-29T07:01:32Z",
    "link": "http://arxiv.org/pdf/2510.25226v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Miao Zhang",
      "Junpeng Li",
      "Changchun Hua",
      "Yana Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25223v1",
    "title": "FELA: A Multi-Agent Evolutionary System for Feature Engineering of\n  Industrial Event Log Data",
    "summary": "Event log data, recording fine-grained user actions and system events,\nrepresent one of the most valuable assets for modern digital services. However,\nthe complexity and heterogeneity of industrial event logs--characterized by\nlarge scale, high dimensionality, diverse data types, and intricate temporal or\nrelational structures--make feature engineering extremely challenging. Existing\nautomatic feature engineering approaches, such as AutoML or genetic methods,\noften suffer from limited explainability, rigid predefined operations, and poor\nadaptability to complicated heterogeneous data. In this paper, we propose FELA\n(Feature Engineering LLM Agents), a multi-agent evolutionary system that\nautonomously extracts meaningful and high-performing features from complex\nindustrial event log data. FELA integrates the reasoning and coding\ncapabilities of large language models (LLMs) with an insight-guided\nself-evolution paradigm. Specifically, FELA employs specialized agents--Idea\nAgents, Code Agents, and Critic Agents--to collaboratively generate, validate,\nand implement novel feature ideas. An Evaluation Agent summarizes feedback and\nupdates a hierarchical knowledge base and dual-memory system to enable\ncontinual improvement. Moreover, FELA introduces an agentic evolution\nalgorithm, combining reinforcement learning and genetic algorithm principles to\nbalance exploration and exploitation across the idea space. Extensive\nexperiments on real industrial datasets demonstrate that FELA can generate\nexplainable, domain-relevant features that significantly improve model\nperformance while reducing manual effort. Our results highlight the potential\nof LLM-based multi-agent systems as a general framework for automated,\ninterpretable, and adaptive feature engineering in complex real-world\nenvironments.",
    "published": "2025-10-29T06:57:32Z",
    "updated": "2025-10-29T06:57:32Z",
    "link": "http://arxiv.org/pdf/2510.25223v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Kun ouyang",
      "Haoyu Wang",
      "Dong Fang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25220v1",
    "title": "GReF: A Unified Generative Framework for Efficient Reranking via Ordered\n  Multi-token Prediction",
    "summary": "In a multi-stage recommendation system, reranking plays a crucial role in\nmodeling intra-list correlations among items. A key challenge lies in exploring\noptimal sequences within the combinatorial space of permutations. Recent\nresearch follows a two-stage (generator-evaluator) paradigm, where a generator\nproduces multiple feasible sequences, and an evaluator selects the best one. In\npractice, the generator is typically implemented as an autoregressive model.\nHowever, these two-stage methods face two main challenges. First, the\nseparation of the generator and evaluator hinders end-to-end training. Second,\nautoregressive generators suffer from inference efficiency. In this work, we\npropose a Unified Generative Efficient Reranking Framework (GReF) to address\nthe two primary challenges. Specifically, we introduce Gen-Reranker, an\nautoregressive generator featuring a bidirectional encoder and a dynamic\nautoregressive decoder to generate causal reranking sequences. Subsequently, we\npre-train Gen-Reranker on the item exposure order for high-quality parameter\ninitialization. To eliminate the need for the evaluator while integrating\nsequence-level evaluation during training for end-to-end optimization, we\npropose post-training the model through Rerank-DPO. Moreover, for efficient\nautoregressive inference, we introduce ordered multi-token prediction (OMTP),\nwhich trains Gen-Reranker to simultaneously generate multiple future items\nwhile preserving their order, ensuring practical deployment in real-time\nrecommender systems. Extensive offline experiments demonstrate that GReF\noutperforms state-of-the-art reranking methods while achieving latency that is\nnearly comparable to non-autoregressive models. Additionally, GReF has also\nbeen deployed in a real-world video app Kuaishou with over 300 million daily\nactive users, significantly improving online recommendation quality.",
    "published": "2025-10-29T06:54:42Z",
    "updated": "2025-10-29T06:54:42Z",
    "link": "http://arxiv.org/pdf/2510.25220v1.pdf",
    "category": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Zhijie Lin",
      "Zhuofeng Li",
      "Chenglei Dai",
      "Wentian Bao",
      "Shuai Lin",
      "Enyun Yu",
      "Haoxiang Zhang",
      "Liang Zhao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25218v1",
    "title": "Human Resilience in the AI Era -- What Machines Can't Replace",
    "summary": "AI is displacing tasks, mediating high-stakes decisions, and flooding\ncommunication with synthetic content, unsettling work, identity, and social\ntrust. We argue that the decisive human countermeasure is resilience. We define\nresilience across three layers: psychological, including emotion regulation,\nmeaning-making, cognitive flexibility; social, including trust, social capital,\ncoordinated response; organizational, including psychological safety, feedback\nmechanisms, and graceful degradation. We synthesize early evidence that these\ncapacities buffer individual strain, reduce burnout through social support, and\nlower silent failure in AI-mediated workflows through team norms and\nrisk-responsive governance. We also show that resilience can be cultivated\nthrough training that complements rather than substitutes for structural\nsafeguards. By reframing the AI debate around actionable human resilience, this\narticle offers policymakers, educators, and operators a practical lens to\npreserve human agency and steer responsible adoption.",
    "published": "2025-10-29T06:48:19Z",
    "updated": "2025-10-29T06:48:19Z",
    "link": "http://arxiv.org/pdf/2510.25218v1.pdf",
    "category": [
      "cs.CY",
      "cs.AI"
    ],
    "authors": [
      "Shaoshan Liu",
      "Anina Schwarzenbach",
      "Yiyu Shi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.15201v2",
    "title": "Pass@K Policy Optimization: Solving Harder Reinforcement Learning\n  Problems",
    "summary": "Reinforcement Learning (RL) algorithms sample multiple n>1 solution attempts\nfor each problem and reward them independently. This optimizes for pass@1\nperformance and prioritizes the strength of isolated samples at the expense of\nthe diversity and collective utility of sets of samples. This under-utilizes\nthe sampling capacity, limiting exploration and eventual improvement on harder\nexamples. As a fix, we propose Pass-at-k Policy Optimization (PKPO), a\ntransformation on the final rewards which leads to direct optimization of\npass@k performance, thus optimizing for sets of samples that maximize reward\nwhen considered jointly. Our contribution is to derive novel low variance\nunbiased estimators for pass@k and its gradient, in both the binary and\ncontinuous reward settings. We show optimization with our estimators reduces to\nstandard RL with rewards that have been jointly transformed by a stable and\nefficient transformation function.\n  While previous efforts are restricted to k=n, ours is the first to enable\nrobust optimization of pass@k for any arbitrary k <= n. Moreover, instead of\ntrading off pass@1 performance for pass@k gains, our method allows annealing k\nduring training, optimizing both metrics and often achieving strong pass@1\nnumbers alongside significant pass@k gains.\n  We validate our reward transformations on toy experiments, which reveal the\nvariance reducing properties of our formulations. We also include real-world\nexamples using the open-source LLM, GEMMA-2. We find that our transformation\neffectively optimizes for the target k. Furthermore, higher k values enable\nsolving more and harder problems, while annealing k boosts both the pass@1 and\npass@k . Crucially, for challenging task sets where conventional pass@1\noptimization stalls, our pass@k approach unblocks learning, likely due to\nbetter exploration by prioritizing joint utility over the utility of individual\nsamples.",
    "published": "2025-05-21T07:26:36Z",
    "updated": "2025-10-29T06:45:46Z",
    "link": "http://arxiv.org/pdf/2505.15201v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "authors": [
      "Christian Walder",
      "Deep Karkhanis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.21797v2",
    "title": "Quantifying Multimodal Imbalance: A GMM-Guided Adaptive Loss for\n  Audio-Visual Learning",
    "summary": "The heterogeneity of multimodal data leads to inconsistencies and imbalance,\nallowing a dominant modality to steer gradient updates. Existing solutions\nmainly focus on optimization- or data-based strategies but rarely exploit the\ninformation inherent in multimodal imbalance or conduct its quantitative\nanalysis. To address this gap, we propose a novel quantitative analysis\nframework for Multimodal Imbalance and design a sample-level adaptive loss\nfunction. We define the Modality Gap as the Softmax score difference between\nmodalities for the correct class and model its distribution using a bimodal\nGaussian Mixture Model(GMM), representing balanced and imbalanced samples.\nUsing Bayes' theorem, we estimate each sample's posterior probability of\nbelonging to these two groups. Based on this, our adaptive loss (1) minimizes\nthe overall Modality Gap, (2) aligns imbalanced samples with balanced ones, and\n(3) adaptively penalizes each according to its imbalance degree. A two-stage\ntraining strategy-warm-up and adaptive phases,yields state-of-the-art\nperformance on CREMA-D (80.65%), AVE (70.40%), and KineticSound (72.42%).\nFine-tuning with high-quality samples identified by the GMM further improves\nresults, highlighting their value for effective multimodal fusion.",
    "published": "2025-10-20T15:42:43Z",
    "updated": "2025-10-29T06:31:09Z",
    "link": "http://arxiv.org/pdf/2510.21797v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "authors": [
      "Zhaocheng Liu",
      "Zhiwen Yu",
      "Xiaoqing Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.02547v2",
    "title": "The Landscape of Agentic Reinforcement Learning for LLMs: A Survey",
    "summary": "The emergence of agentic reinforcement learning (Agentic RL) marks a paradigm\nshift from conventional reinforcement learning applied to large language models\n(LLM RL), reframing LLMs from passive sequence generators into autonomous,\ndecision-making agents embedded in complex, dynamic worlds. This survey\nformalizes this conceptual shift by contrasting the degenerate single-step\nMarkov Decision Processes (MDPs) of LLM-RL with the temporally extended,\npartially observable Markov decision processes (POMDPs) that define Agentic RL.\nBuilding on this foundation, we propose a comprehensive twofold taxonomy: one\norganized around core agentic capabilities, including planning, tool use,\nmemory, reasoning, self-improvement, and perception, and the other around their\napplications across diverse task domains. Central to our thesis is that\nreinforcement learning serves as the critical mechanism for transforming these\ncapabilities from static, heuristic modules into adaptive, robust agentic\nbehavior. To support and accelerate future research, we consolidate the\nlandscape of open-source environments, benchmarks, and frameworks into a\npractical compendium. By synthesizing over five hundred recent works, this\nsurvey charts the contours of this rapidly evolving field and highlights the\nopportunities and challenges that will shape the development of scalable,\ngeneral-purpose AI agents.",
    "published": "2025-09-02T17:46:26Z",
    "updated": "2025-10-29T06:27:56Z",
    "link": "http://arxiv.org/pdf/2509.02547v2.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Guibin Zhang",
      "Hejia Geng",
      "Xiaohang Yu",
      "Zhenfei Yin",
      "Zaibin Zhang",
      "Zelin Tan",
      "Heng Zhou",
      "Zhongzhi Li",
      "Xiangyuan Xue",
      "Yijiang Li",
      "Yifan Zhou",
      "Yang Chen",
      "Chen Zhang",
      "Yutao Fan",
      "Zihu Wang",
      "Songtao Huang",
      "Francisco Piedrahita-Velez",
      "Yue Liao",
      "Hongru Wang",
      "Mengyue Yang",
      "Heng Ji",
      "Michael Littman",
      "Jun Wang",
      "Shuicheng Yan",
      "Philip Torr",
      "Lei Bai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24025v2",
    "title": "NeuroPathNet: Dynamic Path Trajectory Learning for Brain Functional\n  Connectivity Analysis",
    "summary": "Understanding the evolution of brain functional networks over time is of\ngreat significance for the analysis of cognitive mechanisms and the diagnosis\nof neurological diseases. Existing methods often have difficulty in capturing\nthe temporal evolution characteristics of connections between specific\nfunctional communities. To this end, this paper proposes a new path-level\ntrajectory modeling framework (NeuroPathNet) to characterize the dynamic\nbehavior of connection pathways between brain functional partitions. Based on\nmedically supported static partitioning schemes (such as Yeo and Smith ICA), we\nextract the time series of connection strengths between each pair of functional\npartitions and model them using a temporal neural network. We validate the\nmodel performance on three public functional Magnetic Resonance Imaging (fMRI)\ndatasets, and the results show that it outperforms existing mainstream methods\nin multiple indicators. This study can promote the development of dynamic graph\nlearning methods for brain network analysis, and provide possible clinical\napplications for the diagnosis of neurological diseases.",
    "published": "2025-10-28T03:07:06Z",
    "updated": "2025-10-29T06:20:10Z",
    "link": "http://arxiv.org/pdf/2510.24025v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Tianqi Guo",
      "Liping Chen",
      "Ciyuan Peng",
      "Jingjing Zhou",
      "Jing Ren"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25206v1",
    "title": "RAVR: Reference-Answer-guided Variational Reasoning for Large Language\n  Models",
    "summary": "Reinforcement learning (RL) can refine the reasoning abilities of large\nlanguage models (LLMs), but critically depends on a key prerequisite: the LLM\ncan already generate high-utility reasoning paths with non-negligible\nprobability. For tasks beyond the LLM's current competence, such reasoning path\ncan be hard to sample, and learning risks reinforcing familiar but suboptimal\nreasoning. We are motivated by the insight from cognitive science that Why is\nthis the answer is often an easier question than What is the answer, as it\navoids the heavy cognitive load of open-ended exploration, opting instead for\nexplanatory reconstruction-systematically retracing the reasoning that links a\nquestion to its answer. We show that LLMs can similarly leverage answers to\nderive high-quality reasoning paths. We formalize this phenomenon and prove\nthat conditioning on answer provably increases the expected utility of sampled\nreasoning paths, thereby transforming intractable problems into learnable ones.\nBuilding on this insight, we introduce RAVR (Reference-Answer-guided\nVariational Reasoning), an end-to-end framework that uses answer-conditioned\nreasoning as a variational surrogate for question-only reasoning. Experiments\nin both general and math domains demonstrate consistent improvements over\nstrong baselines. We further analyze the reasoning behavior and find that RAVR\nreduces hesitation, strengthens conclusion consolidation, and promotes\nproblem-specific strategies in reasoning.",
    "published": "2025-10-29T06:18:37Z",
    "updated": "2025-10-29T06:18:37Z",
    "link": "http://arxiv.org/pdf/2510.25206v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "I.2.7"
    ],
    "authors": [
      "Tianqianjin Lin",
      "Xi Zhao",
      "Xingyao Zhang",
      "Rujiao Long",
      "Yi Xu",
      "Zhuoren Jiang",
      "Wenbo Su",
      "Bo Zheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25205v1",
    "title": "Energy-Efficient Autonomous Driving with Adaptive Perception and Robust\n  Decision",
    "summary": "Autonomous driving is an emerging technology that is expected to bring\nsignificant social, economic, and environmental benefits. However, these\nbenefits come with rising energy consumption by computation engines, limiting\nthe driving range of vehicles, especially electric ones. Perception computing\nis typically the most power-intensive component, as it relies on largescale\ndeep learning models to extract environmental features. Recently, numerous\nstudies have employed model compression techniques, such as sparsification,\nquantization, and distillation, to reduce computational consumption. However,\nthese methods often result in either a substantial model size or a significant\ndrop in perception accuracy compared to high-computation models. To address\nthese challenges, we propose an energy-efficient autonomous driving framework,\ncalled EneAD. In the adaptive perception module, a perception optimization\nstrategy is designed from the perspective of data management and tuning.\nFirstly, we manage multiple perception models with different computational\nconsumption and adjust the execution framerate dynamically. Then, we define\nthem as knobs and design a transferable tuning method based on Bayesian\noptimization to identify promising knob values that achieve low computation\nwhile maintaining desired accuracy. To adaptively switch the knob values in\nvarious traffic scenarios, a lightweight classification model is proposed to\ndistinguish the perception difficulty in different scenarios. In the robust\ndecision module, we propose a decision model based on reinforcement learning\nand design a regularization term to enhance driving stability in the face of\nperturbed perception results. Extensive experiments evidence the superiority of\nour framework in both energy consumption and driving performance. EneAD can\nreduce perception consumption by 1.9x to 3.5x and thus improve driving range by\n3.9% to 8.5%",
    "published": "2025-10-29T06:18:15Z",
    "updated": "2025-10-29T06:18:15Z",
    "link": "http://arxiv.org/pdf/2510.25205v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Yuyang Xia",
      "Zibo Liang",
      "Liwei Deng",
      "Yan Zhao",
      "Han Su",
      "Kai Zheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.16301v2",
    "title": "Artificial Intelligence for Direct Prediction of Molecular Dynamics\n  Across Chemical Space",
    "summary": "Molecular dynamics (MD) is a powerful tool for exploring the behavior of\natomistic systems, but its reliance on sequential numerical integration limits\nsimulation efficiency. We present a novel neural network architecture,\nMDtrajNet, and a pre-trained foundational model, MDtrajNet-1, that directly\ngenerates MD trajectories across chemical space, bypassing force calculations\nand integration. This approach accelerates simulations by up to two orders of\nmagnitude compared to traditional MD, even those enhanced by machine-learning\ninteratomic potentials. MDtrajNet combines equivariant neural networks with a\ntransformer-based architecture to achieve strong accuracy and transferability\nin predicting long-time trajectories. Remarkably, the errors of the\ntrajectories generated by MDtrajNet-1 for various known and unseen molecular\nsystems are close to those of the conventional ab initio MD. The architecture's\nflexible design supports diverse application scenarios, including different\nstatistical ensembles, boundary conditions, and interaction types. By\novercoming the intrinsic speed barrier of conventional MD, MDtrajNet opens new\nfrontiers in efficient and scalable atomistic simulations.",
    "published": "2025-05-22T06:56:19Z",
    "updated": "2025-10-29T06:16:03Z",
    "link": "http://arxiv.org/pdf/2505.16301v2.pdf",
    "category": [
      "physics.chem-ph",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Fuchun Ge",
      "Pavlo O. Dral"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.19028v4",
    "title": "InfoChartQA: A Benchmark for Multimodal Question Answering on\n  Infographic Charts",
    "summary": "Understanding infographic charts with design-driven visual elements (e.g.,\npictograms, icons) requires both visual recognition and reasoning, posing\nchallenges for multimodal large language models (MLLMs). However, existing\nvisual-question answering benchmarks fall short in evaluating these\ncapabilities of MLLMs due to the lack of paired plain charts and\nvisual-element-based questions. To bridge this gap, we introduce InfoChartQA, a\nbenchmark for evaluating MLLMs on infographic chart understanding. It includes\n5,642 pairs of infographic and plain charts, each sharing the same underlying\ndata but differing in visual presentations. We further design\nvisual-element-based questions to capture their unique visual designs and\ncommunicative intent. Evaluation of 20 MLLMs reveals a substantial performance\ndecline on infographic charts, particularly for visual-element-based questions\nrelated to metaphors. The paired infographic and plain charts enable\nfine-grained error analysis and ablation studies, which highlight new\nopportunities for advancing MLLMs in infographic chart understanding. We\nrelease InfoChartQA at https://github.com/CoolDawnAnt/InfoChartQA.",
    "published": "2025-05-25T08:28:03Z",
    "updated": "2025-10-29T06:12:40Z",
    "link": "http://arxiv.org/pdf/2505.19028v4.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Tianchi Xie",
      "Minzhi Lin",
      "Mengchen Liu",
      "Yilin Ye",
      "Changjian Chen",
      "Shixia Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2407.14926v2",
    "title": "TraveLLM: Could you plan my new public transit route in face of a\n  network disruption?",
    "summary": "Existing navigation systems often fail during urban disruptions, struggling\nto incorporate real-time events and complex user constraints, such as avoiding\nspecific areas. We address this gap with TraveLLM, a system using Large\nLanguage Models (LLMs) for disruption-aware public transit routing. We leverage\nLLMs' reasoning capabilities to directly process multimodal user queries\ncombining natural language requests (origin, destination, preferences,\ndisruption info) with map data (e.g., subway, bus, bike-share). To evaluate\nthis approach, we design challenging test scenarios reflecting real-world\ndisruptions like weather events, emergencies, and dynamic service availability.\nWe benchmark the performance of state-of-the-art LLMs, including GPT-4, Claude\n3, and Gemini, on generating accurate travel plans. Our experiments demonstrate\nthat LLMs, notably GPT-4, can effectively generate viable and context-aware\nnavigation plans under these demanding conditions. These findings suggest a\npromising direction for using LLMs to build more flexible and intelligent\nnavigation systems capable of handling dynamic disruptions and diverse user\nneeds.",
    "published": "2024-07-20T16:25:34Z",
    "updated": "2025-10-29T06:10:32Z",
    "link": "http://arxiv.org/pdf/2407.14926v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Bowen Fang",
      "Zixiao Yang",
      "Xuan Di"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.07382v2",
    "title": "Pentest-R1: Towards Autonomous Penetration Testing Reasoning Optimized\n  via Two-Stage Reinforcement Learning",
    "summary": "Automating penetration testing is crucial for enhancing cybersecurity, yet\ncurrent Large Language Models (LLMs) face significant limitations in this\ndomain, including poor error handling, inefficient reasoning, and an inability\nto perform complex end-to-end tasks autonomously. To address these challenges,\nwe introduce Pentest-R1, a novel framework designed to optimize LLM reasoning\ncapabilities for this task through a two-stage reinforcement learning pipeline.\nWe first construct a dataset of over 500 real-world, multi-step walkthroughs,\nwhich Pentest-R1 leverages for offline reinforcement learning (RL) to instill\nfoundational attack logic. Subsequently, the LLM is fine-tuned via online RL in\nan interactive Capture The Flag (CTF) environment, where it learns directly\nfrom environmental feedback to develop robust error self-correction and\nadaptive strategies. Our extensive experiments on the Cybench and AutoPenBench\nbenchmarks demonstrate the framework's effectiveness. On AutoPenBench,\nPentest-R1 achieves a 24.2\\% success rate, surpassing most state-of-the-art\nmodels and ranking second only to Gemini 2.5 Flash. On Cybench, it attains a\n15.0\\% success rate in unguided tasks, establishing a new state-of-the-art for\nopen-source LLMs and matching the performance of top proprietary models.\nAblation studies confirm that the synergy of both training stages is critical\nto its success.",
    "published": "2025-08-10T15:14:05Z",
    "updated": "2025-10-29T05:49:56Z",
    "link": "http://arxiv.org/pdf/2508.07382v2.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "He Kong",
      "Die Hu",
      "Jingguo Ge",
      "Liangxiong Li",
      "Hui Li",
      "Tong Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25181v1",
    "title": "Fed-PELAD: Communication-Efficient Federated Learning for Massive MIMO\n  CSI Feedback with Personalized Encoders and a LoRA-Adapted Shared Decoder",
    "summary": "This paper addresses the critical challenges of communication overhead, data\nheterogeneity, and privacy in deep learning for channel state information (CSI)\nfeedback in massive MIMO systems. To this end, we propose Fed-PELAD, a novel\nfederated learning framework that incorporates personalized encoders and a\nLoRA-adapted shared decoder. Specifically, personalized encoders are trained\nlocally on each user equipment (UE) to capture device-specific channel\ncharacteristics, while a shared decoder is updated globally via the\ncoordination of the base station (BS) by using Low-Rank Adaptation (LoRA). This\ndesign ensures that only compact LoRA adapter parameters instead of full model\nupdates are transmitted for aggregation. To further enhance convergence\nstability, we introduce an alternating freezing strategy with calibrated\nlearning-rate ratio during LoRA aggregation. Extensive simulations on\n3GPP-standard channel models demonstrate that Fed-PELAD requires only 42.97\\%\nof the uplink communication cost compared to conventional methods while\nachieving a performance gain of 1.2 dB in CSI feedback accuracy under\nheterogeneous conditions.",
    "published": "2025-10-29T05:24:21Z",
    "updated": "2025-10-29T05:24:21Z",
    "link": "http://arxiv.org/pdf/2510.25181v1.pdf",
    "category": [
      "cs.IT",
      "cs.AI",
      "math.IT"
    ],
    "authors": [
      "Yixiang Zhou",
      "Tong Wu",
      "Meixia Tao",
      "Jianhua Mo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25179v1",
    "title": "Agentic Moderation: Multi-Agent Design for Safer Vision-Language Models",
    "summary": "Agentic methods have emerged as a powerful and autonomous paradigm that\nenhances reasoning, collaboration, and adaptive control, enabling systems to\ncoordinate and independently solve complex tasks. We extend this paradigm to\nsafety alignment by introducing Agentic Moderation, a model-agnostic framework\nthat leverages specialised agents to defend multimodal systems against\njailbreak attacks. Unlike prior approaches that apply as a static layer over\ninputs or outputs and provide only binary classifications (safe or unsafe), our\nmethod integrates dynamic, cooperative agents, including Shield, Responder,\nEvaluator, and Reflector, to achieve context-aware and interpretable\nmoderation. Extensive experiments across five datasets and four representative\nLarge Vision-Language Models (LVLMs) demonstrate that our approach reduces the\nAttack Success Rate (ASR) by 7-19%, maintains a stable Non-Following Rate (NF),\nand improves the Refusal Rate (RR) by 4-20%, achieving robust, interpretable,\nand well-balanced safety performance. By harnessing the flexibility and\nreasoning capacity of agentic architectures, Agentic Moderation provides\nmodular, scalable, and fine-grained safety enforcement, highlighting the\nbroader potential of agentic systems as a foundation for automated safety\ngovernance.",
    "published": "2025-10-29T05:23:24Z",
    "updated": "2025-10-29T05:23:24Z",
    "link": "http://arxiv.org/pdf/2510.25179v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Juan Ren",
      "Mark Dras",
      "Usman Naseem"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23669v2",
    "title": "What Work is AI Actually Doing? Uncovering the Drivers of Generative AI\n  Adoption",
    "summary": "Purpose: The rapid integration of artificial intelligence (AI) systems like\nChatGPT, Claude AI, etc., has a deep impact on how work is done. Predicting how\nAI will reshape work requires understanding not just its capabilities, but how\nit is actually being adopted. This study investigates which intrinsic task\ncharacteristics drive users' decisions to delegate work to AI systems.\nMethodology: This study utilizes the Anthropic Economic Index dataset of four\nmillion Claude AI interactions mapped to O*NET tasks. We systematically scored\neach task across seven key dimensions: Routine, Cognitive, Social Intelligence,\nCreativity, Domain Knowledge, Complexity, and Decision Making using 35\nparameters. We then employed multivariate techniques to identify latent task\narchetypes and analyzed their relationship with AI usage. Findings: Tasks\nrequiring high creativity, complexity, and cognitive demand, but low\nroutineness, attracted the most AI engagement. Furthermore, we identified three\ntask archetypes: Dynamic Problem Solving, Procedural & Analytical Work, and\nStandardized Operational Tasks, demonstrating that AI applicability is best\npredicted by a combination of task characteristics, over individual factors.\nOur analysis revealed highly concentrated AI usage patterns, with just 5% of\ntasks accounting for 59% of all interactions. Originality: This research\nprovides the first systematic evidence linking real-world generative AI usage\nto a comprehensive, multi-dimensional framework of intrinsic task\ncharacteristics. It introduces a data-driven classification of work archetypes\nthat offers a new framework for analyzing the emerging human-AI division of\nlabor.",
    "published": "2025-10-26T19:13:37Z",
    "updated": "2025-10-29T05:01:17Z",
    "link": "http://arxiv.org/pdf/2510.23669v2.pdf",
    "category": [
      "econ.GN",
      "cs.AI",
      "cs.CY",
      "q-fin.EC"
    ],
    "authors": [
      "Peeyush Agarwal",
      "Harsh Agarwal",
      "Akshat Rana"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25164v1",
    "title": "Transformers in Medicine: Improving Vision-Language Alignment for\n  Medical Image Captioning",
    "summary": "We present a transformer-based multimodal framework for generating clinically\nrelevant captions for MRI scans. Our system combines a DEiT-Small vision\ntransformer as an image encoder, MediCareBERT for caption embedding, and a\ncustom LSTM-based decoder. The architecture is designed to semantically align\nimage and textual embeddings, using hybrid cosine-MSE loss and contrastive\ninference via vector similarity. We benchmark our method on the MultiCaRe\ndataset, comparing performance on filtered brain-only MRIs versus general MRI\nimages against state-of-the-art medical image captioning methods including\nBLIP, R2GenGPT, and recent transformer-based approaches. Results show that\nfocusing on domain-specific data improves caption accuracy and semantic\nalignment. Our work proposes a scalable, interpretable solution for automated\nmedical image reporting.",
    "published": "2025-10-29T04:49:20Z",
    "updated": "2025-10-29T04:49:20Z",
    "link": "http://arxiv.org/pdf/2510.25164v1.pdf",
    "category": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Yogesh Thakku Suresh",
      "Vishwajeet Shivaji Hogale",
      "Luca-Alexandru Zamfira",
      "Anandavardhana Hegde"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.07994v3",
    "title": "A Neural Symbolic Model for Space Physics",
    "summary": "In this study, we unveil a new AI model, termed PhyE2E, to discover physical\nformulas through symbolic regression. PhyE2E simplifies symbolic regression by\ndecomposing it into sub-problems using the second-order derivatives of an\noracle neural network, and employs a transformer model to translate data into\nsymbolic formulas in an end-to-end manner. The resulting formulas are refined\nthrough Monte-Carlo Tree Search and Genetic Programming. We leverage a large\nlanguage model to synthesize extensive symbolic expressions resembling real\nphysics, and train the model to recover these formulas directly from data. A\ncomprehensive evaluation reveals that PhyE2E outperforms existing\nstate-of-the-art approaches, delivering superior symbolic accuracy, precision\nin data fitting, and consistency in physical units. We deployed PhyE2E to five\napplications in space physics, including the prediction of sunspot numbers,\nsolar rotational angular velocity, emission line contribution functions,\nnear-Earth plasma pressure, and lunar-tide plasma signals. The physical\nformulas generated by AI demonstrate a high degree of accuracy in fitting the\nexperimental data from satellites and astronomical telescopes. We have\nsuccessfully upgraded the formula proposed by NASA in 1993 regarding solar\nactivity, and for the first time, provided the explanations for the long cycle\nof solar activity in an explicit form. We also found that the decay of\nnear-Earth plasma pressure is proportional to r^2 to Earth, where subsequent\nmathematical derivations are consistent with satellite data from another\nindependent study. Moreover, we found physical formulas that can describe the\nrelationships between emission lines in the extreme ultraviolet spectrum of the\nSun, temperatures, electron densities, and magnetic fields. The formula\nobtained is consistent with the properties that physicists had previously\nhypothesized it should possess.",
    "published": "2025-03-11T02:50:45Z",
    "updated": "2025-10-29T04:38:02Z",
    "link": "http://arxiv.org/pdf/2503.07994v3.pdf",
    "category": [
      "astro-ph.SR",
      "astro-ph.EP",
      "astro-ph.IM",
      "cs.AI",
      "physics.space-ph"
    ],
    "authors": [
      "Jie Ying",
      "Haowei Lin",
      "Chao Yue",
      "Yajie Chen",
      "Chao Xiao",
      "Quanqi Shi",
      "Yitao Liang",
      "Shing-Tung Yau",
      "Yuan Zhou",
      "Jianzhu Ma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.06497v3",
    "title": "Evaluation of Safety Cognition Capability in Vision-Language Models for\n  Autonomous Driving",
    "summary": "Ensuring the safety of vision-language models (VLMs) in autonomous driving\nsystems is of paramount importance, yet existing research has largely focused\non conventional benchmarks rather than safety-critical evaluation. In this\nwork, we present SCD-Bench (Safety Cognition Driving Benchmark) a novel\nframework specifically designed to assess the safety cognition capabilities of\nVLMs within interactive driving scenarios. To address the scalability challenge\nof data annotation, we introduce ADA (Autonomous Driving Annotation), a\nsemi-automated labeling system, further refined through expert review by\nprofessionals with domain-specific knowledge in autonomous driving. To\nfacilitate scalable and consistent evaluation, we also propose an automated\nassessment pipeline leveraging large language models, which demonstrates over\n98% agreement with human expert judgments. In addressing the broader challenge\nof aligning VLMs with safety cognition in driving environments, we construct\nSCD-Training, the first large-scale dataset tailored for this task, comprising\n324.35K high-quality samples. Through extensive experiments, we show that\nmodels trained on SCD-Training exhibit marked improvements not only on\nSCD-Bench, but also on general and domain-specific benchmarks, offering a new\nperspective on enhancing safety-aware interactions in vision-language systems\nfor autonomous driving.",
    "published": "2025-03-09T07:53:19Z",
    "updated": "2025-10-29T04:35:35Z",
    "link": "http://arxiv.org/pdf/2503.06497v3.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Enming Zhang",
      "Peizhe Gong",
      "Xingyuan Dai",
      "Min Huang",
      "Yisheng Lv",
      "Qinghai Miao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.04083v2",
    "title": "Plexus: Taming Billion-edge Graphs with 3D Parallel Full-graph GNN\n  Training",
    "summary": "Graph neural networks (GNNs) leverage the connectivity and structure of\nreal-world graphs to learn intricate properties and relationships between\nnodes. Many real-world graphs exceed the memory capacity of a GPU due to their\nsheer size, and training GNNs on such graphs requires techniques such as\nmini-batch sampling to scale. The alternative approach of distributed\nfull-graph training suffers from high communication overheads and load\nimbalance due to the irregular structure of graphs. We propose a\nthree-dimensional (3D) parallel approach for full-graph training that tackles\nthese issues and scales to billion-edge graphs. In addition, we introduce\noptimizations such as a double permutation scheme for load balancing, and a\nperformance model to predict the optimal 3D configuration of our parallel\nimplementation -- Plexus. We evaluate Plexus on six different graph datasets\nand show scaling results on up to 2048 GPUs of Perlmutter, and 1024 GPUs of\nFrontier. Plexus achieves unprecedented speedups of 2.3-12.5x over prior state\nof the art, and a reduction in time-to-solution by 5.2-8.7x on Perlmutter and\n7.0-54.2x on Frontier.",
    "published": "2025-05-07T02:49:52Z",
    "updated": "2025-10-29T04:33:18Z",
    "link": "http://arxiv.org/pdf/2505.04083v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "authors": [
      "Aditya K. Ranjan",
      "Siddharth Singh",
      "Cunyang Wei",
      "Abhinav Bhatele"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25160v1",
    "title": "Model-Document Protocol for AI Search",
    "summary": "AI search depends on linking large language models (LLMs) with vast external\nknowledge sources. Yet web pages, PDF files, and other raw documents are not\ninherently LLM-ready: they are long, noisy, and unstructured. Conventional\nretrieval methods treat these documents as verbatim text and return raw\npassages, leaving the burden of fragment assembly and contextual reasoning to\nthe LLM. This gap underscores the need for a new retrieval paradigm that\nredefines how models interact with documents.\n  We introduce the Model-Document Protocol (MDP), a general framework that\nformalizes how raw text is bridged to LLMs through consumable knowledge\nrepresentations. Rather than treating retrieval as passage fetching, MDP\ndefines multiple pathways that transform unstructured documents into\ntask-specific, LLM-ready inputs. These include agentic reasoning, which curates\nraw evidence into coherent context; memory grounding, which accumulates\nreusable notes to enrich reasoning; and structured leveraging, which encodes\ndocuments into formal representations such as graphs or key-value caches. All\nthree pathways share the same goal: ensuring that what reaches the LLM is not\nraw fragments but compact, structured knowledge directly consumable for\nreasoning.\n  As an instantiation, we present MDP-Agent, which realizes the protocol\nthrough an agentic process: constructing document-level gist memories for\nglobal coverage, performing diffusion-based exploration with vertical\nexploitation to uncover layered dependencies, and applying map-reduce style\nsynthesis to integrate large-scale evidence into compact yet sufficient\ncontext. Experiments on information-seeking benchmarks demonstrate that\nMDP-Agent outperforms baselines, validating both the soundness of the MDP\nframework and the effectiveness of its agentic instantiation.",
    "published": "2025-10-29T04:29:17Z",
    "updated": "2025-10-29T04:29:17Z",
    "link": "http://arxiv.org/pdf/2510.25160v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "authors": [
      "Hongjin Qian",
      "Zheng Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23807v2",
    "title": "Why Foundation Models in Pathology Are Failing",
    "summary": "In non-medical domains, foundation models (FMs) have revolutionized computer\nvision and language processing through large-scale self-supervised and\nmultimodal learning. Consequently, their rapid adoption in computational\npathology was expected to deliver comparable breakthroughs in cancer diagnosis,\nprognostication, and multimodal retrieval. However, recent systematic\nevaluations reveal fundamental weaknesses: low diagnostic accuracy, poor\nrobustness, geometric instability, heavy computational demands, and concerning\nsafety vulnerabilities. This short paper examines these shortcomings and argues\nthat they stem from deeper conceptual mismatches between the assumptions\nunderlying generic foundation modeling in mainstream AI and the intrinsic\ncomplexity of human tissue. Seven interrelated causes are identified:\nbiological complexity, ineffective self-supervision, overgeneralization,\nexcessive architectural complexity, lack of domain-specific innovation,\ninsufficient data, and a fundamental design flaw related to tissue patch size.\nThese findings suggest that current pathology foundation models remain\nconceptually misaligned with the nature of tissue morphology and call for a\nfundamental rethinking of the paradigm itself.",
    "published": "2025-10-27T19:44:52Z",
    "updated": "2025-10-29T04:15:53Z",
    "link": "http://arxiv.org/pdf/2510.23807v2.pdf",
    "category": [
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Hamid R. Tizhoosh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24339v2",
    "title": "VDSAgents: A PCS-Guided Multi-Agent System for Veridical Data Science\n  Automation",
    "summary": "Large language models (LLMs) become increasingly integrated into data science\nworkflows for automated system design. However, these LLM-driven data science\nsystems rely solely on the internal reasoning of LLMs, lacking guidance from\nscientific and theoretical principles. This limits their trustworthiness and\nrobustness, especially when dealing with noisy and complex real-world datasets.\nThis paper provides VDSAgents, a multi-agent system grounded in the\nPredictability-Computability-Stability (PCS) principles proposed in the\nVeridical Data Science (VDS) framework. Guided by PCS principles, the system\nimplements a modular workflow for data cleaning, feature engineering, modeling,\nand evaluation. Each phase is handled by an elegant agent, incorporating\nperturbation analysis, unit testing, and model validation to ensure both\nfunctionality and scientific auditability. We evaluate VDSAgents on nine\ndatasets with diverse characteristics, comparing it with state-of-the-art\nend-to-end data science systems, such as AutoKaggle and DataInterpreter, using\nDeepSeek-V3 and GPT-4o as backends. VDSAgents consistently outperforms the\nresults of AutoKaggle and DataInterpreter, which validates the feasibility of\nembedding PCS principles into LLM-driven data science automation.",
    "published": "2025-10-28T12:07:50Z",
    "updated": "2025-10-29T04:05:13Z",
    "link": "http://arxiv.org/pdf/2510.24339v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Yunxuan Jiang",
      "Silan Hu",
      "Xiaoning Wang",
      "Yuanyuan Zhang",
      "Xiangyu Chang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.09755v2",
    "title": "Intelligent Design 4.0: Paradigm Evolution Toward the Agentic AI Era",
    "summary": "Research and practice in Intelligent Design (ID) have significantly enhanced\nengineering innovation, efficiency, quality, and productivity over recent\ndecades, fundamentally reshaping how engineering designers think, behave, and\ninteract with design processes. The recent emergence of Foundation Models\n(FMs), particularly Large Language Models (LLMs), has demonstrated general\nknowledge-based reasoning capabilities, and open new avenues for further\ntransformation in engineering design. In this context, this paper introduces\nIntelligent Design 4.0 (ID 4.0) as an emerging paradigm empowered by foundation\nmodel-based agentic AI systems. We review the historical evolution of ID across\nfour distinct stages: rule-based expert systems, task-specific machine learning\nmodels, large-scale foundation AI models, and the recent emerging paradigm of\nfoundation model-based multi-agent collaboration. We propose an ontological\nframework for ID 4.0 and discuss its potential to support end-to-end automation\nof engineering design processes through coordinated, autonomous\nmulti-agent-based systems. Furthermore, we discuss challenges and opportunities\nof ID 4.0, including perspectives on data foundations, agent collaboration\nmechanisms, and the formulation of design problems and objectives. In sum,\nthese insights provide a foundation for advancing Intelligent Design toward\ngreater adaptivity, autonomy, and effectiveness in addressing the growing\ncomplexity of engineering design.",
    "published": "2025-06-11T13:57:26Z",
    "updated": "2025-10-29T04:00:49Z",
    "link": "http://arxiv.org/pdf/2506.09755v2.pdf",
    "category": [
      "cs.CE",
      "cs.AI",
      "I.2.7; I.2.1"
    ],
    "authors": [
      "Shuo Jiang",
      "Min Xie",
      "Frank Youhua Chen",
      "Jian Ma",
      "Jianxi Luo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.10484v4",
    "title": "Bias in Decision-Making for AI's Ethical Dilemmas: A Comparative Study\n  of ChatGPT and Claude",
    "summary": "Recent advances in Large Language Models (LLMs) have enabled human-like\nresponses across various tasks, raising questions about their ethical\ndecision-making capabilities and potential biases. This study systematically\nevaluates how nine popular LLMs (both open-source and closed-source) respond to\nethical dilemmas involving protected attributes. Across 50,400 trials spanning\nsingle and intersectional attribute combinations in four dilemma scenarios\n(protective vs. harmful), we assess models' ethical preferences, sensitivity,\nstability, and clustering patterns. Results reveal significant biases in\nprotected attributes in all models, with differing preferences depending on\nmodel type and dilemma context. Notably, open-source LLMs show stronger\npreferences for marginalized groups and greater sensitivity in harmful\nscenarios, while closed-source models are more selective in protective\nsituations and tend to favor mainstream groups. We also find that ethical\nbehavior varies across dilemma types: LLMs maintain consistent patterns in\nprotective scenarios but respond with more diverse and cognitively demanding\ndecisions in harmful ones. Furthermore, models display more pronounced ethical\ntendencies under intersectional conditions than in single-attribute settings,\nsuggesting that complex inputs reveal deeper biases. These findings highlight\nthe need for multi-dimensional, context-aware evaluation of LLMs' ethical\nbehavior and offer a systematic evaluation and approach to understanding and\naddressing fairness in LLM decision-making.",
    "published": "2025-01-17T05:20:38Z",
    "updated": "2025-10-29T03:27:46Z",
    "link": "http://arxiv.org/pdf/2501.10484v4.pdf",
    "category": [
      "cs.CY",
      "cs.AI"
    ],
    "authors": [
      "Yile Yan",
      "Yuqi Zhu",
      "Wentao Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.25233v2",
    "title": "FedCLF -- Towards Efficient Participant Selection for Federated Learning\n  in Heterogeneous IoV Networks",
    "summary": "Federated Learning (FL) is a distributed machine learning technique that\npreserves data privacy by sharing only the trained parameters instead of the\nclient data. This makes FL ideal for highly dynamic, heterogeneous, and\ntime-critical applications, in particular, the Internet of Vehicles (IoV)\nnetworks. However, FL encounters considerable challenges in such networks owing\nto the high data and device heterogeneity. To address these challenges, we\npropose FedCLF, i.e., FL with Calibrated Loss and Feedback control, which\nintroduces calibrated loss as a utility in the participant selection process\nand a feedback control mechanism to dynamically adjust the sampling frequency\nof the clients. The envisaged approach (a) enhances the overall model accuracy\nin case of highly heterogeneous data and (b) optimizes the resource utilization\nfor resource constrained IoV networks, thereby leading to increased efficiency\nin the FL process. We evaluated FedCLF vis-\\`a-vis baseline models, i.e.,\nFedAvg, Newt, and Oort, using CIFAR-10 dataset with varying data heterogeneity.\nOur results depict that FedCLF significantly outperforms the baseline models by\nup to a 16% improvement in high data heterogeneity-related scenarios with\nimproved efficiency via reduced sampling frequency.",
    "published": "2025-09-25T04:51:38Z",
    "updated": "2025-10-29T03:27:25Z",
    "link": "http://arxiv.org/pdf/2509.25233v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Kasun Eranda Wijethilake",
      "Adnan Mahmood",
      "Quan Z. Sheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25130v1",
    "title": "Lipschitz-aware Linearity Grafting for Certified Robustness",
    "summary": "Lipschitz constant is a fundamental property in certified robustness, as\nsmaller values imply robustness to adversarial examples when a model is\nconfident in its prediction. However, identifying the worst-case adversarial\nexamples is known to be an NP-complete problem. Although over-approximation\nmethods have shown success in neural network verification to address this\nchallenge, reducing approximation errors remains a significant obstacle.\nFurthermore, these approximation errors hinder the ability to obtain tight\nlocal Lipschitz constants, which are crucial for certified robustness.\nOriginally, grafting linearity into non-linear activation functions was\nproposed to reduce the number of unstable neurons, enabling scalable and\ncomplete verification. However, no prior theoretical analysis has explained how\nlinearity grafting improves certified robustness. We instead consider linearity\ngrafting primarily as a means of eliminating approximation errors rather than\nreducing the number of unstable neurons, since linear functions do not require\nrelaxation. In this paper, we provide two theoretical contributions: 1) why\nlinearity grafting improves certified robustness through the lens of the\n$l_\\infty$ local Lipschitz constant, and 2) grafting linearity into non-linear\nactivation functions, the dominant source of approximation errors, yields a\ntighter local Lipschitz constant. Based on these theoretical contributions, we\npropose a Lipschitz-aware linearity grafting method that removes dominant\napproximation errors, which are crucial for tightening the local Lipschitz\nconstant, thereby improving certified robustness, even without certified\ntraining. Our extensive experiments demonstrate that grafting linearity into\nthese influential activations tightens the $l_\\infty$ local Lipschitz constant\nand enhances certified robustness.",
    "published": "2025-10-29T03:19:55Z",
    "updated": "2025-10-29T03:19:55Z",
    "link": "http://arxiv.org/pdf/2510.25130v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Yongjin Han",
      "Suhyun Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.08102v5",
    "title": "Consistency of Responses and Continuations Generated by Large Language\n  Models on Social Media",
    "summary": "Large Language Models (LLMs) demonstrate remarkable capabilities in text\ngeneration, yet their emotional consistency and semantic coherence in social\nmedia contexts remain insufficiently understood. This study investigates how\nLLMs handle emotional content and maintain semantic relationships through\ncontinuation and response tasks using three open-source models: Gemma, Llama3\nand Llama3.3 and one commercial Model:Claude. By analyzing climate change\ndiscussions from Twitter and Reddit, we examine emotional transitions,\nintensity patterns, and semantic consistency between human-authored and\nLLM-generated content. Our findings reveal that while both models maintain high\nsemantic coherence, they exhibit distinct emotional patterns: these models show\na strong tendency to moderate negative emotions. When the input text carries\nnegative emotions such as anger, disgust, fear, or sadness, LLM tends to\ngenerate content with more neutral emotions, or even convert them into positive\nemotions such as joy or surprise. At the same time, we compared the\nLLM-generated content with human-authored content. The four models\nsystematically generated responses with reduced emotional intensity and showed\na preference for neutral rational emotions in the response task. In addition,\nthese models all maintained a high semantic similarity with the original text,\nalthough their performance in the continuation task and the response task was\ndifferent. These findings provide deep insights into the emotion and semantic\nprocessing capabilities of LLM, which are of great significance for its\ndeployment in social media environments and human-computer interaction design.",
    "published": "2025-01-14T13:19:47Z",
    "updated": "2025-10-29T03:08:26Z",
    "link": "http://arxiv.org/pdf/2501.08102v5.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "authors": [
      "Wenlu Fan",
      "Yuqi Zhu",
      "Bin Wang",
      "Wentao Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25126v1",
    "title": "Bridging the Divide: End-to-End Sequence-Graph Learning",
    "summary": "Many real-world datasets are both sequential and relational: each node\ncarries an event sequence while edges encode interactions. Existing methods in\nsequence modeling and graph modeling often neglect one modality or the other.\nWe argue that sequences and graphs are not separate problems but complementary\nfacets of the same dataset, and should be learned jointly. We introduce BRIDGE,\na unified end-to-end architecture that couples a sequence encoder with a GNN\nunder a single objective, allowing gradients to flow across both modules and\nlearning task-aligned representations. To enable fine-grained token-level\nmessage passing among neighbors, we add TOKENXATTN, a token-level\ncross-attention layer that passes messages between events in neighboring\nsequences. Across two settings, friendship prediction (Brightkite) and fraud\ndetection (Amazon), BRIDGE consistently outperforms static GNNs, temporal graph\nmethods, and sequence-only baselines on ranking and classification metrics.",
    "published": "2025-10-29T03:06:54Z",
    "updated": "2025-10-29T03:06:54Z",
    "link": "http://arxiv.org/pdf/2510.25126v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Yuen Chen",
      "Yulun Wu",
      "Samuel Sharpe",
      "Igor Melnyk",
      "Nam H. Nguyen",
      "Furong Huang",
      "C. Bayan Bruss",
      "Rizal Fathony"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25123v1",
    "title": "Learning Low Rank Neural Representations of Hyperbolic Wave Dynamics\n  from Data",
    "summary": "We present a data-driven dimensionality reduction method that is well-suited\nfor physics-based data representing hyperbolic wave propagation. The method\nutilizes a specialized neural network architecture called low rank neural\nrepresentation (LRNR) inside a hypernetwork framework. The architecture is\nmotivated by theoretical results that rigorously prove the existence of\nefficient representations for this wave class. We illustrate through archetypal\nexamples that such an efficient low-dimensional representation of propagating\nwaves can be learned directly from data through a combination of deep learning\ntechniques. We observe that a low rank tensor representation arises naturally\nin the trained LRNRs, and that this reveals a new decomposition of wave\npropagation where each decomposed mode corresponds to interpretable physical\nfeatures. Furthermore, we demonstrate that the LRNR architecture enables\nefficient inference via a compression scheme, which is a potentially important\nfeature when deploying LRNRs in demanding performance regimes.",
    "published": "2025-10-29T03:01:09Z",
    "updated": "2025-10-29T03:01:09Z",
    "link": "http://arxiv.org/pdf/2510.25123v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA",
      "68T07, 65D25, 65M22"
    ],
    "authors": [
      "Woojin Cho",
      "Kookjin Lee",
      "Noseong Park",
      "Donsub Rim",
      "Gerrit Welper"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2405.04605v4",
    "title": "AI in Lung Health: Benchmarking Detection and Diagnostic Models Across\n  Multiple CT Scan Datasets",
    "summary": "Background: Development of artificial intelligence (AI) models for lung\ncancer screening requires large, well-annotated low-dose computed tomography\n(CT) datasets and rigorous performance benchmarks. Purpose: To create a\nreproducible benchmarking resource leveraging the Duke Lung Cancer Screening\n(DLCS) and multiple public datasets to develop and evaluate models for nodule\ndetection and classification. Materials & Methods: This retrospective study\nuses the DLCS dataset (1,613 patients; 2,487 nodules) and external datasets\nincluding LUNA16, LUNA25, and NLST-3D. For detection, MONAI RetinaNet models\nwere trained on DLCS (DLCS-De) and LUNA16 (LUNA16-De) and evaluated using the\nCompetition Performance Metric (CPM). For nodule-level classification, we\ncompare five strategies: pretrained models (Models Genesis, Med3D), a\nself-supervised foundation model (FMCB), and ResNet50 with random\ninitialization versus Strategic Warm-Start (ResNet50-SWS) pretrained with\ndetection-derived candidate patches stratified by confidence. Results: For\ndetection on the DLCS test set, DLCS-De achieved sensitivity 0.82 at 2 false\npositives/scan (CPM 0.63) versus LUNA16-De (0.62, CPM 0.45). For external\nvalidation on NLST-3D, DLCS-De (sensitivity 0.72, CPM 0.58) also outperformed\nLUNA16-De (sensitivity 0.64, CPM 0.49). For classification across multiple\ndatasets, ResNet50-SWS attained AUCs of 0.71 (DLCS; 95% CI, 0.61-0.81), 0.90\n(LUNA16; 0.87-0.93), 0.81 (NLST-3D; 0.79-0.82), and 0.80 (LUNA25; 0.78-0.82),\nmatching or exceeding pretrained/self-supervised baselines. Performance\ndifferences reflected dataset label standards. Conclusion: This work\nestablishes a standardized benchmarking resource for lung cancer AI research,\nsupporting model development, validation, and translation. All code, models,\nand data are publicly released to promote reproducibility.",
    "published": "2024-05-07T18:36:40Z",
    "updated": "2025-10-29T02:33:21Z",
    "link": "http://arxiv.org/pdf/2405.04605v4.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV"
    ],
    "authors": [
      "Fakrul Islam Tushar",
      "Avivah Wang",
      "Lavsen Dahal",
      "Ehsan Samei",
      "Michael R. Harowicz",
      "Jayashree Kalpathy-Cramer",
      "Kyle J. Lafata",
      "Tina D. Tailor",
      "Cynthia Rudin",
      "Joseph Y. Lo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25113v1",
    "title": "The Neural Differential Manifold: An Architecture with Explicit\n  Geometric Structure",
    "summary": "This paper introduces the Neural Differential Manifold (NDM), a novel neural\nnetwork architecture that explicitly incorporates geometric structure into its\nfundamental design. Departing from conventional Euclidean parameter spaces, the\nNDM re-conceptualizes a neural network as a differentiable manifold where each\nlayer functions as a local coordinate chart, and the network parameters\ndirectly parameterize a Riemannian metric tensor at every point. The\narchitecture is organized into three synergistic layers: a Coordinate Layer\nimplementing smooth chart transitions via invertible transformations inspired\nby normalizing flows, a Geometric Layer that dynamically generates the\nmanifold's metric through auxiliary sub-networks, and an Evolution Layer that\noptimizes both task performance and geometric simplicity through a\ndual-objective loss function. This geometric regularization penalizes excessive\ncurvature and volume distortion, providing intrinsic regularization that\nenhances generalization and robustness. The framework enables natural gradient\ndescent optimization aligned with the learned manifold geometry and offers\nunprecedented interpretability by endowing internal representations with clear\ngeometric meaning. We analyze the theoretical advantages of this approach,\nincluding its potential for more efficient optimization, enhanced continual\nlearning, and applications in scientific discovery and controllable generative\nmodeling. While significant computational challenges remain, the Neural\nDifferential Manifold represents a fundamental shift towards geometrically\nstructured, interpretable, and efficient deep learning systems.",
    "published": "2025-10-29T02:24:27Z",
    "updated": "2025-10-29T02:24:27Z",
    "link": "http://arxiv.org/pdf/2510.25113v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "math.DG",
      "math.OC",
      "68T07, 62B11, 53B21, 65D18",
      "I.2.6; I.5.1; G.1.6; G.3"
    ],
    "authors": [
      "Di Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.22149v4",
    "title": "When Truthful Representations Flip Under Deceptive Instructions?",
    "summary": "Large language models (LLMs) tend to follow maliciously crafted instructions\nto generate deceptive responses, posing safety challenges. How deceptive\ninstructions alter the internal representations of LLM compared to truthful\nones remains poorly understood beyond output analysis. To bridge this gap, we\ninvestigate when and how these representations ``flip'', such as from truthful\nto deceptive, under deceptive versus truthful/neutral instructions. Analyzing\nthe internal representations of Llama-3.1-8B-Instruct and Gemma-2-9B-Instruct\non a factual verification task, we find the model's instructed True/False\noutput is predictable via linear probes across all conditions based on the\ninternal representation. Further, we use Sparse Autoencoders (SAEs) to show\nthat the Deceptive instructions induce significant representational shifts\ncompared to Truthful/Neutral representations (which are similar), concentrated\nin early-to-mid layers and detectable even on complex datasets. We also\nidentify specific SAE features highly sensitive to deceptive instruction and\nuse targeted visualizations to confirm distinct truthful/deceptive\nrepresentational subspaces. % Our analysis pinpoints layer-wise and\nfeature-level correlates of instructed dishonesty, offering insights for LLM\ndetection and control. Our findings expose feature- and layer-level signatures\nof deception, offering new insights for detecting and mitigating instructed\ndishonesty in LLMs.",
    "published": "2025-07-29T18:27:13Z",
    "updated": "2025-10-29T02:12:31Z",
    "link": "http://arxiv.org/pdf/2507.22149v4.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Xianxuan Long",
      "Yao Fu",
      "Runchao Li",
      "Mu Sheng",
      "Haotian Yu",
      "Xiaotian Han",
      "Pan Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25101v1",
    "title": "KnowCoder-A1: Incentivizing Agentic Reasoning Capability with Outcome\n  Supervision for KBQA",
    "summary": "Knowledge Base Question Answering (KBQA) aims to answer natural-language\nquestions over a structured Knowledge Base (KB). Recent work improves KBQA by\nadopting an agentic reasoning paradigm, in which Large Language Models (LLMs)\niteratively decompose a question, generate its corresponding logical queries,\nand interact with the KB to derive the answer. However, these methods typically\nfine-tune LLMs on reasoning trajectories synthesized via process supervision,\nwhich offers weak incentives for exploration and thus fails to strengthen the\nagentic reasoning ability. In this paper, we propose KnowCoder-A1, an LLM that\ncan autonomously perform agentic reasoning on KBs to obtain answers. To\nincentivize autonomous exploration, KnowCoder-A1 trains the LLM under\noutcome-only supervision via a multi-stage curriculum reinforcement learning\nwith an easy-to-hard curriculum. To establish foundational agentic\ncapabilities, KnowCoder-A1 first fine-tunes the LLM on a small set of\nhigh-quality trajectories obtained through outcome-based rejection sampling.\nThen, to alleviate the reward sparsity inherent in outcome-only supervision, it\napplies multi-stage curriculum RL with reward schedules that progress from easy\nto hard. Trained with outcome-only supervision, KnowCoder-A1 exhibits powerful\nreasoning behaviors and consistently outperforms prior approaches across three\nmainstream datasets. Notably, on the zero-shot subset of GrailQA, KnowCoder-A1\nachieves up to an 11.1% relative improvement while using only one-twelfth of\nthe training data, demonstrating strong agentic reasoning capabilities.",
    "published": "2025-10-29T02:12:18Z",
    "updated": "2025-10-29T02:12:18Z",
    "link": "http://arxiv.org/pdf/2510.25101v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Zhuo Chen",
      "Fei Wang",
      "Zixuan Li",
      "Zhao Zhang",
      "Weiwei Ding",
      "Chuanguang Yang",
      "Yongjun Xu",
      "Xiaolong Jin",
      "Jiafeng Guo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25096v1",
    "title": "Learning Fair Graph Representations with Multi-view Information\n  Bottleneck",
    "summary": "Graph neural networks (GNNs) excel on relational data by passing messages\nover node features and structure, but they can amplify training data biases,\npropagating discriminatory attributes and structural imbalances into unfair\noutcomes. Many fairness methods treat bias as a single source, ignoring\ndistinct attribute and structure effects and leading to suboptimal fairness and\nutility trade-offs. To overcome this challenge, we propose FairMIB, a\nmulti-view information bottleneck framework designed to decompose graphs into\nfeature, structural, and diffusion views for mitigating complexity biases in\nGNNs. Especially, the proposed FairMIB employs contrastive learning to maximize\ncross-view mutual information for bias-free representation learning. It further\nintegrates multi-perspective conditional information bottleneck objectives to\nbalance task utility and fairness by minimizing mutual information with\nsensitive attributes. Additionally, FairMIB introduces an inverse\nprobability-weighted (IPW) adjacency correction in the diffusion view, which\nreduces the spread of bias propagation during message passing. Experiments on\nfive real-world benchmark datasets demonstrate that FairMIB achieves\nstate-of-the-art performance across both utility and fairness metrics.",
    "published": "2025-10-29T02:02:12Z",
    "updated": "2025-10-29T02:02:12Z",
    "link": "http://arxiv.org/pdf/2510.25096v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Chuxun Liu",
      "Debo Cheng",
      "Qingfeng Chen",
      "Jiangzhang Gan",
      "Jiuyong Li",
      "Lin Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25091v1",
    "title": "H3M-SSMoEs: Hypergraph-based Multimodal Learning with LLM Reasoning and\n  Style-Structured Mixture of Experts",
    "summary": "Stock movement prediction remains fundamentally challenging due to complex\ntemporal dependencies, heterogeneous modalities, and dynamically evolving\ninter-stock relationships. Existing approaches often fail to unify structural,\nsemantic, and regime-adaptive modeling within a scalable framework. This work\nintroduces H3M-SSMoEs, a novel Hypergraph-based MultiModal architecture with\nLLM reasoning and Style-Structured Mixture of Experts, integrating three key\ninnovations: (1) a Multi-Context Multimodal Hypergraph that hierarchically\ncaptures fine-grained spatiotemporal dynamics via a Local Context Hypergraph\n(LCH) and persistent inter-stock dependencies through a Global Context\nHypergraph (GCH), employing shared cross-modal hyperedges and Jensen-Shannon\nDivergence weighting mechanism for adaptive relational learning and cross-modal\nalignment; (2) a LLM-enhanced reasoning module, which leverages a frozen large\nlanguage model with lightweight adapters to semantically fuse and align\nquantitative and textual modalities, enriching representations with\ndomain-specific financial knowledge; and (3) a Style-Structured Mixture of\nExperts (SSMoEs) that combines shared market experts and industry-specialized\nexperts, each parameterized by learnable style vectors enabling regime-aware\nspecialization under sparse activation. Extensive experiments on three major\nstock markets demonstrate that H3M-SSMoEs surpasses state-of-the-art methods in\nboth superior predictive accuracy and investment performance, while exhibiting\neffective risk control. Datasets, source code, and model weights are available\nat our GitHub repository: https://github.com/PeilinTime/H3M-SSMoEs.",
    "published": "2025-10-29T01:54:52Z",
    "updated": "2025-10-29T01:54:52Z",
    "link": "http://arxiv.org/pdf/2510.25091v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Peilin Tan",
      "Liang Xie",
      "Churan Zhi",
      "Dian Tu",
      "Chuanqi Shi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.17818v2",
    "title": "PatientSim: A Persona-Driven Simulator for Realistic Doctor-Patient\n  Interactions",
    "summary": "Doctor-patient consultations require multi-turn, context-aware communication\ntailored to diverse patient personas. Training or evaluating doctor LLMs in\nsuch settings requires realistic patient interaction systems. However, existing\nsimulators often fail to reflect the full range of personas seen in clinical\npractice. To address this, we introduce PatientSim, a patient simulator that\ngenerates realistic and diverse patient personas for clinical scenarios,\ngrounded in medical expertise. PatientSim operates using: 1) clinical profiles,\nincluding symptoms and medical history, derived from real-world data in the\nMIMIC-ED and MIMIC-IV datasets, and 2) personas defined by four axes:\npersonality, language proficiency, medical history recall level, and cognitive\nconfusion level, resulting in 37 unique combinations. We evaluate eight LLMs\nfor factual accuracy and persona consistency. The top-performing open-source\nmodel, Llama 3.3 70B, is validated by four clinicians to confirm the robustness\nof our framework. As an open-source, customizable platform, PatientSim provides\na reproducible and scalable solution that can be customized for specific\ntraining needs. Offering a privacy-compliant environment, it serves as a robust\ntestbed for evaluating medical dialogue systems across diverse patient\npresentations and shows promise as an educational tool for healthcare. The code\nis available at https://github.com/dek924/PatientSim.",
    "published": "2025-05-23T12:34:48Z",
    "updated": "2025-10-29T01:54:23Z",
    "link": "http://arxiv.org/pdf/2505.17818v2.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Daeun Kyung",
      "Hyunseung Chung",
      "Seongsu Bae",
      "Jiho Kim",
      "Jae Ho Sohn",
      "Taerim Kim",
      "Soo Kyung Kim",
      "Edward Choi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25080v1",
    "title": "Monopoly Deal: A Benchmark Environment for Bounded One-Sided Response\n  Games",
    "summary": "Card games are widely used to study sequential decision-making under\nuncertainty, with real-world analogues in negotiation, finance, and\ncybersecurity. Typically, these games fall into three categories based on the\nflow of control: strictly-sequential (where players alternate single actions),\ndeterministic-response (where some actions trigger a fixed outcome), and\nunbounded reciprocal-response (where alternating counterplays are permitted). A\nless-explored but strategically rich structure exists: the bounded one-sided\nresponse. This dynamic occurs when a player's action briefly transfers control\nto the opponent, who must satisfy a fixed condition through one or more\nsequential moves before the turn resolves. We term games featuring this\nmechanism Bounded One-Sided Response Games (BORGs).\n  We introduce a modified version of Monopoly Deal as a benchmark environment\nthat specifically isolates the BORG dynamic, where a Rent action forces the\nopponent to sequentially choose payment assets. We demonstrate that the\ngold-standard algorithm, Counterfactual Regret Minimization (CFR), successfully\nconverges on effective strategies for this domain without requiring novel\nalgorithmic extensions. To support efficient, reproducible experimentation, we\npresent a lightweight, full-stack research platform that unifies the\nenvironment, a parallelized CFR runtime, and a human-playable web interface,\nall runnable on a single workstation. This system provides a practical\nfoundation for exploring state representation and policy learning in bounded\none-sided response settings.\n  The trained CFR agent and source code are available at\nhttps://monopolydeal.ai.",
    "published": "2025-10-29T01:38:19Z",
    "updated": "2025-10-29T01:38:19Z",
    "link": "http://arxiv.org/pdf/2510.25080v1.pdf",
    "category": [
      "cs.GT",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Will Wolf"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.16854v3",
    "title": "Think or Not? Selective Reasoning via Reinforcement Learning for\n  Vision-Language Models",
    "summary": "Reinforcement Learning (RL) has proven to be an effective post-training\nstrategy for enhancing reasoning in vision-language models (VLMs). Group\nRelative Policy Optimization (GRPO) is a recent prominent method that\nencourages models to generate complete reasoning traces before answering,\nleading to increased token usage and computational cost. Inspired by the\nhuman-like thinking process-where people skip reasoning for easy questions but\nthink carefully when needed-we explore how to enable VLMs to first decide when\nreasoning is necessary. To realize this, we propose TON, a two-stage training\nstrategy: (i) a supervised fine-tuning (SFT) stage with a simple yet effective\n'thought dropout' operation, where reasoning traces are randomly replaced with\nempty thoughts. This introduces a think-or-not format that serves as a cold\nstart for selective reasoning; (ii) a GRPO stage that enables the model to\nfreely explore when to think or not, while maximizing task-aware outcome\nrewards. Experimental results show that TON can reduce the completion length by\nup to 90% compared to vanilla GRPO, without sacrificing performance or even\nimproving it. Further evaluations across LLM (GSM8K), VLM (CLEVR, Super-CLEVR,\nGeoQA), and Agentic (AITZ) tasks-covering a range of reasoning difficulties\nunder both 3B and 7B models-consistently reveal that the model progressively\nlearns to bypass unnecessary reasoning steps as training advances. These\nfindings shed light on the path toward human-like reasoning patterns in RL\napproaches. Our code is available at https://github.com/kokolerk/TON.",
    "published": "2025-05-22T16:13:29Z",
    "updated": "2025-10-29T01:19:12Z",
    "link": "http://arxiv.org/pdf/2505.16854v3.pdf",
    "category": [
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Jiaqi Wang",
      "Kevin Qinghong Lin",
      "James Cheng",
      "Mike Zheng Shou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.14205v3",
    "title": "DPRF: A Generalizable Dynamic Persona Refinement Framework for\n  Optimizing Behavior Alignment Between Personalized LLM Role-Playing Agents\n  and Humans",
    "summary": "The emerging large language model role-playing agents (LLM RPAs) aim to\nsimulate individual human behaviors, but the persona fidelity is often\nundermined by manually-created profiles (e.g., cherry-picked information and\npersonality characteristics) without validating the alignment with the target\nindividuals. To address this limitation, our work introduces the Dynamic\nPersona Refinement Framework (DPRF). DPRF aims to optimize the alignment of LLM\nRPAs' behaviors with those of target individuals by iteratively identifying the\ncognitive divergence, either through free-form or theory-grounded, structured\nanalysis, between generated behaviors and human ground truth, and refining the\npersona profile to mitigate these divergences. We evaluate DPRF with five LLMs\non four diverse behavior-prediction scenarios: formal debates, social media\nposts with mental health issues, public interviews, and movie reviews. DPRF can\nconsistently improve behavioral alignment considerably over baseline personas\nand generalizes across models and scenarios. Our work provides a robust\nmethodology for creating high-fidelity persona profiles and enhancing the\nvalidity of downstream applications, such as user simulation, social studies,\nand personalized AI.",
    "published": "2025-10-16T01:26:38Z",
    "updated": "2025-10-29T01:16:53Z",
    "link": "http://arxiv.org/pdf/2510.14205v3.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Bingsheng Yao",
      "Bo Sun",
      "Yuanzhe Dong",
      "Yuxuan Lu",
      "Dakuo Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25065v1",
    "title": "Reasoning-Aware GRPO using Process Mining",
    "summary": "Reinforcement learning (RL)-based post-training has been crucial for enabling\nmulti-step reasoning in large reasoning models (LRMs), yet current reward\nschemes are typically outcome-centric. We propose PM4GRPO, a reasoning-aware\nGroup Relative Policy Optimization (GRPO) that augments standard answer/format\nrewards with signals over the reasoning procedure. To this end, process mining\ntechniques are utilized to compute a scalar conformance reward that measures\nhow closely a policy model's reasoning aligns with the pretrained teacher\nmodel. The empirical results on five benchmarks demonstrate that PM4GRPO\nsignificantly outperforms existing methodologies for GRPO-based post-training.\nThese results highlight that leveraging process mining for reasoning-aware GRPO\neffectively enhances the reasoning capabilities of policy models.",
    "published": "2025-10-29T01:07:45Z",
    "updated": "2025-10-29T01:07:45Z",
    "link": "http://arxiv.org/pdf/2510.25065v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Taekhyun Park",
      "Yongjae Lee",
      "Hyerim Bae"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25055v1",
    "title": "GAPMAP: Mapping Scientific Knowledge Gaps in Biomedical Literature Using\n  Large Language Models",
    "summary": "Scientific progress is driven by the deliberate articulation of what remains\nunknown. This study investigates the ability of large language models (LLMs) to\nidentify research knowledge gaps in the biomedical literature. We define two\ncategories of knowledge gaps: explicit gaps, clear declarations of missing\nknowledge; and implicit gaps, context-inferred missing knowledge. While prior\nwork has focused mainly on explicit gap detection, we extend this line of\nresearch by addressing the novel task of inferring implicit gaps. We conducted\ntwo experiments on almost 1500 documents across four datasets, including a\nmanually annotated corpus of biomedical articles. We benchmarked both\nclosed-weight models (from OpenAI) and open-weight models (Llama and Gemma 2)\nunder paragraph-level and full-paper settings. To address the reasoning of\nimplicit gaps inference, we introduce \\textbf{\\small TABI}, a Toulmin-Abductive\nBucketed Inference scheme that structures reasoning and buckets inferred\nconclusion candidates for validation. Our results highlight the robust\ncapability of LLMs in identifying both explicit and implicit knowledge gaps.\nThis is true for both open- and closed-weight models, with larger variants\noften performing better. This suggests a strong ability of LLMs for\nsystematically identifying candidate knowledge gaps, which can support\nearly-stage research formulation, policymakers, and funding decisions. We also\nreport observed failure modes and outline directions for robust deployment,\nincluding domain adaptation, human-in-the-loop verification, and benchmarking\nacross open- and closed-weight models.",
    "published": "2025-10-29T00:46:45Z",
    "updated": "2025-10-29T00:46:45Z",
    "link": "http://arxiv.org/pdf/2510.25055v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Nourah M Salem",
      "Elizabeth White",
      "Michael Bada",
      "Lawrence Hunter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25053v1",
    "title": "Scalable predictive processing framework for multitask caregiving robots",
    "summary": "The rapid aging of societies is intensifying demand for autonomous care\nrobots; however, most existing systems are task-specific and rely on\nhandcrafted preprocessing, limiting their ability to generalize across diverse\nscenarios. A prevailing theory in cognitive neuroscience proposes that the\nhuman brain operates through hierarchical predictive processing, which\nunderlies flexible cognition and behavior by integrating multimodal sensory\nsignals. Inspired by this principle, we introduce a hierarchical multimodal\nrecurrent neural network grounded in predictive processing under the\nfree-energy principle, capable of directly integrating over 30,000-dimensional\nvisuo-proprioceptive inputs without dimensionality reduction. The model was\nable to learn two representative caregiving tasks, rigid-body repositioning and\nflexible-towel wiping, without task-specific feature engineering. We\ndemonstrate three key properties: (i) self-organization of hierarchical latent\ndynamics that regulate task transitions, capture variability in uncertainty,\nand infer occluded states; (ii) robustness to degraded vision through\nvisuo-proprioceptive integration; and (iii) asymmetric interference in\nmultitask learning, where the more variable wiping task had little influence on\nrepositioning, whereas learning the repositioning task led to a modest\nreduction in wiping performance, while the model maintained overall robustness.\nAlthough the evaluation was limited to simulation, these results establish\npredictive processing as a universal and scalable computational principle,\npointing toward robust, flexible, and autonomous caregiving robots while\noffering theoretical insight into the human brain's ability to achieve flexible\nadaptation in uncertain real-world environments.",
    "published": "2025-10-29T00:39:09Z",
    "updated": "2025-10-29T00:39:09Z",
    "link": "http://arxiv.org/pdf/2510.25053v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "authors": [
      "Hayato Idei",
      "Tamon Miyake",
      "Tetsuya Ogata",
      "Yuichi Yamashita"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.13852v2",
    "title": "ConsistencyAI: A Benchmark to Assess LLMs' Factual Consistency When\n  Responding to Different Demographic Groups",
    "summary": "Is an LLM telling you different facts than it's telling me? This paper\nintroduces ConsistencyAI, an independent benchmark for measuring the factual\nconsistency of large language models (LLMs) for different personas.\nConsistencyAI tests whether, when users of different demographics ask identical\nquestions, the model responds with factually inconsistent answers. Designed\nwithout involvement from LLM providers, this benchmark offers impartial\nevaluation and accountability. In our experiment, we queried 19 LLMs with\nprompts that requested 5 facts for each of 15 topics. We repeated this query\n100 times for each LLM, each time adding prompt context from a different\npersona selected from a subset of personas modeling the general population. We\nprocessed the responses into sentence embeddings, computed cross-persona cosine\nsimilarity, and computed the weighted average of cross-persona cosine\nsimilarity to calculate factual consistency scores. In 100-persona experiments,\nscores ranged from 0.9065 to 0.7896, and the mean was 0.8656, which we adopt as\na benchmark threshold. xAI's Grok-3 is most consistent, while several\nlightweight models rank lowest. Consistency varies by topic: the job market is\nleast consistent, G7 world leaders most consistent, and issues like vaccines or\nthe Israeli-Palestinian conflict diverge by provider. These results show that\nboth the provider and the topic shape the factual consistency. We release our\ncode and interactive demo to support reproducible evaluation and encourage\npersona-invariant prompting strategies.",
    "published": "2025-10-11T23:32:02Z",
    "updated": "2025-10-29T00:31:05Z",
    "link": "http://arxiv.org/pdf/2510.13852v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "authors": [
      "Peter Banyas",
      "Shristi Sharma",
      "Alistair Simmons",
      "Atharva Vispute"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25032v1",
    "title": "Efficient License Plate Recognition via Pseudo-Labeled Supervision with\n  Grounding DINO and YOLOv8",
    "summary": "Developing a highly accurate automatic license plate recognition system\n(ALPR) is challenging due to environmental factors such as lighting, rain, and\ndust. Additional difficulties include high vehicle speeds, varying camera\nangles, and low-quality or low-resolution images. ALPR is vital in traffic\ncontrol, parking, vehicle tracking, toll collection, and law enforcement\napplications. This paper proposes a deep learning strategy using YOLOv8 for\nlicense plate detection and recognition tasks. This method seeks to enhance the\nperformance of the model using datasets from Ontario, Quebec, California, and\nNew York State. It achieved an impressive recall rate of 94% on the dataset\nfrom the Center for Pattern Recognition and Machine Intelligence (CENPARMI) and\n91% on the UFPR-ALPR dataset. In addition, our method follows a semi-supervised\nlearning framework, combining a small set of manually labeled data with\npseudo-labels generated by Grounding DINO to train our detection model.\nGrounding DINO, a powerful vision-language model, automatically annotates many\nimages with bounding boxes for license plates, thereby minimizing the reliance\non labor-intensive manual labeling. By integrating human-verified and\nmodel-generated annotations, we can scale our dataset efficiently while\nmaintaining label quality, which significantly enhances the training process\nand overall model performance. Furthermore, it reports character error rates\nfor both datasets, providing additional insight into system performance.",
    "published": "2025-10-28T23:21:00Z",
    "updated": "2025-10-28T23:21:00Z",
    "link": "http://arxiv.org/pdf/2510.25032v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Zahra Ebrahimi Vargoorani",
      "Amir Mohammad Ghoreyshi",
      "Ching Yee Suen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.00418v3",
    "title": "Serving LLMs in HPC Clusters: A Comparative Study of Qualcomm Cloud AI\n  100 Ultra and NVIDIA Data Center GPUs",
    "summary": "This study presents a benchmarking analysis of the Qualcomm Cloud AI 100\nUltra (QAic) accelerator for large language model (LLM) inference, evaluating\nits energy efficiency (throughput per watt), performance, and hardware\nscalability against NVIDIA A100 GPUs (in 4x and 8x configurations) within the\nNational Research Platform (NRP) ecosystem. A total of 12 open-source LLMs,\nranging from 124 million to 70 billion parameters, are served using the vLLM\nframework. Our analysis reveals that QAic achieves competitive energy\nefficiency with advantages on specific models while enabling more granular\nhardware allocation: some 70B models operate on as few as 1 QAic card versus 8\nA100 GPUs required, with 20x lower power consumption (148W vs 2,983W). For\nsmaller models, single QAic devices achieve up to 35x lower power consumption\ncompared to our 4-GPU A100 configuration (36W vs 1,246W). The findings offer\ninsights into the potential of the Qualcomm Cloud AI 100 Ultra for\nenergy-constrained and resource-efficient HPC deployments within the National\nResearch Platform (NRP).",
    "published": "2025-07-01T04:11:09Z",
    "updated": "2025-10-28T22:58:55Z",
    "link": "http://arxiv.org/pdf/2507.00418v3.pdf",
    "category": [
      "cs.DC",
      "cs.AI",
      "68M20, 68T50",
      "C.4; I.2.7; D.4.8"
    ],
    "authors": [
      "Mohammad Firas Sada",
      "John J. Graham",
      "Elham E Khoda",
      "Mahidhar Tatineni",
      "Dmitry Mishin",
      "Rajesh K. Gupta",
      "Rick Wagner",
      "Larry Smarr",
      "Thomas A. DeFanti",
      "Frank Würthwein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.08619v3",
    "title": "Physics Context Builders: A Modular Framework for Physical Reasoning in\n  Vision-Language Models",
    "summary": "Physical reasoning remains a significant challenge for Vision-Language Models\n(VLMs). This limitation arises from an inability to translate learned knowledge\ninto predictions about physical behavior. Although continual fine-tuning can\nmitigate this issue, it is expensive for large models and impractical to\nperform repeatedly for every task. This necessitates the creation of modular\nand scalable ways to teach VLMs about physical reasoning. To that end, we\nintroduce Physics Context Builders (PCBs), a modular framework where\nspecialized smaller VLMs are fine-tuned to generate detailed physical scene\ndescriptions. These can be used as physical contexts to enhance the reasoning\ncapabilities of larger VLMs. PCBs enable the separation of visual perception\nfrom reasoning, allowing us to analyze their relative contributions to physical\nunderstanding. We perform experiments on CLEVRER and on Falling Tower, a\nstability detection dataset with both simulated and real-world scenes, to\ndemonstrate that PCBs provide substantial performance improvements, increasing\naverage accuracy by up to 13.8% on complex physical reasoning tasks. Notably,\nPCBs also show strong Sim2Real transfer, successfully generalizing from\nsimulated training data to real-world scenes.",
    "published": "2024-12-11T18:40:16Z",
    "updated": "2025-10-28T22:43:29Z",
    "link": "http://arxiv.org/pdf/2412.08619v3.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Vahid Balazadeh",
      "Mohammadmehdi Ataei",
      "Hyunmin Cheong",
      "Amir Hosein Khasahmadi",
      "Rahul G. Krishnan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25017v1",
    "title": "StorageXTuner: An LLM Agent-Driven Automatic Tuning Framework for\n  Heterogeneous Storage Systems",
    "summary": "Automatically configuring storage systems is hard: parameter spaces are large\nand conditions vary across workloads, deployments, and versions. Heuristic and\nML tuners are often system specific, require manual glue, and degrade under\nchanges. Recent LLM-based approaches help but usually treat tuning as a\nsingle-shot, system-specific task, which limits cross-system reuse, constrains\nexploration, and weakens validation. We present StorageXTuner, an LLM\nagent-driven auto-tuning framework for heterogeneous storage engines.\nStorageXTuner separates concerns across four agents - Executor (sandboxed\nbenchmarking), Extractor (performance digest), Searcher (insight-guided\nconfiguration exploration), and Reflector (insight generation and management).\nThe design couples an insight-driven tree search with layered memory that\npromotes empirically validated insights and employs lightweight checkers to\nguard against unsafe actions. We implement a prototype and evaluate it on\nRocksDB, LevelDB, CacheLib, and MySQL InnoDB with YCSB, MixGraph, and TPC-H/C.\nRelative to out-of-the-box settings and to ELMo-Tune, StorageXTuner reaches up\nto 575% and 111% higher throughput, reduces p99 latency by as much as 88% and\n56%, and converges with fewer trials.",
    "published": "2025-10-28T22:33:14Z",
    "updated": "2025-10-28T22:33:14Z",
    "link": "http://arxiv.org/pdf/2510.25017v1.pdf",
    "category": [
      "cs.DB",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Qi Lin",
      "Zhenyu Zhang",
      "Viraj Thakkar",
      "Zhenjie Sun",
      "Mai Zheng",
      "Zhichao Cao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.10266v2",
    "title": "SignMouth: Leveraging Mouthing Cues for Sign Language Translation by\n  Multimodal Contrastive Fusion",
    "summary": "Sign language translation (SLT) aims to translate natural language from sign\nlanguage videos, serving as a vital bridge for inclusive communication. While\nrecent advances leverage powerful visual backbones and large language models,\nmost approaches mainly focus on manual signals (hand gestures) and tend to\noverlook non-manual cues like mouthing. In fact, mouthing conveys essential\nlinguistic information in sign languages and plays a crucial role in\ndisambiguating visually similar signs. In this paper, we propose SignClip, a\nnovel framework to improve the accuracy of sign language translation. It fuses\nmanual and non-manual cues, specifically spatial gesture and lip movement\nfeatures. Besides, SignClip introduces a hierarchical contrastive learning\nframework with multi-level alignment objectives, ensuring semantic consistency\nacross sign-lip and visual-text modalities. Extensive experiments on two\nbenchmark datasets, PHOENIX14T and How2Sign, demonstrate the superiority of our\napproach. For example, on PHOENIX14T, in the Gloss-free setting, SignClip\nsurpasses the previous state-of-the-art model SpaMo, improving BLEU-4 from\n24.32 to 24.71, and ROUGE from 46.57 to 48.38.",
    "published": "2025-09-12T14:08:06Z",
    "updated": "2025-10-28T22:32:18Z",
    "link": "http://arxiv.org/pdf/2509.10266v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Wenfang Wu",
      "Tingting Yuan",
      "Yupeng Li",
      "Daling Wang",
      "Xiaoming Fu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25016v1",
    "title": "Towards Human-AI Synergy in Requirements Engineering: A Framework and\n  Preliminary Study",
    "summary": "The future of Requirements Engineering (RE) is increasingly driven by\nartificial intelligence (AI), reshaping how we elicit, analyze, and validate\nrequirements. Traditional RE is based on labor-intensive manual processes prone\nto errors and complexity. AI-powered approaches, specifically large language\nmodels (LLMs), natural language processing (NLP), and generative AI, offer\ntransformative solutions and reduce inefficiencies. However, the use of AI in\nRE also brings challenges like algorithmic bias, lack of explainability, and\nethical concerns related to automation. To address these issues, this study\nintroduces the Human-AI RE Synergy Model (HARE-SM), a conceptual framework that\nintegrates AI-driven analysis with human oversight to improve requirements\nelicitation, analysis, and validation. The model emphasizes ethical AI use\nthrough transparency, explainability, and bias mitigation. We outline a\nmulti-phase research methodology focused on preparing RE datasets, fine-tuning\nAI models, and designing collaborative human-AI workflows. This preliminary\nstudy presents the conceptual framework and early-stage prototype\nimplementation, establishing a research agenda and practical design direction\nfor applying intelligent data science techniques to semi-structured and\nunstructured RE data in collaborative environments.",
    "published": "2025-10-28T22:29:11Z",
    "updated": "2025-10-28T22:29:11Z",
    "link": "http://arxiv.org/pdf/2510.25016v1.pdf",
    "category": [
      "cs.SE",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "68T07, 68N30",
      "D.2.1; I.2.6; I.2.7"
    ],
    "authors": [
      "Mateen Ahmed Abbasi",
      "Petri Ihantola",
      "Tommi Mikkonen",
      "Niko Mäkitalo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25014v1",
    "title": "Aligning Large Language Models with Procedural Rules: An Autoregressive\n  State-Tracking Prompting for In-Game Trading",
    "summary": "Large Language Models (LLMs) enable dynamic game interactions but fail to\nfollow essential procedural flows in rule-governed trading systems, eroding\nplayer trust. This work resolves the core tension between the creative\nflexibility of LLMs and the procedural demands of in-game trading\n(browse-offer-review-confirm). To this end, Autoregressive State-Tracking\nPrompting (ASTP) is introduced, a methodology centered on a strategically\norchestrated prompt that compels an LLM to make its state-tracking process\nexplicit and verifiable. Instead of relying on implicit contextual\nunderstanding, ASTP tasks the LLM with identifying and reporting a predefined\nstate label from the previous turn. To ensure transactional integrity, this is\ncomplemented by a state-specific placeholder post-processing method for\naccurate price calculations. Evaluation across 300 trading dialogues\ndemonstrates >99% state compliance and 99.3% calculation precision. Notably,\nASTP with placeholder post-processing on smaller models (Gemini-2.5-Flash)\nmatches larger models' (Gemini-2.5-Pro) performance while reducing response\ntime from 21.2s to 2.4s, establishing a practical foundation that satisfies\nboth real-time requirements and resource constraints of commercial games.",
    "published": "2025-10-28T22:26:34Z",
    "updated": "2025-10-28T22:26:34Z",
    "link": "http://arxiv.org/pdf/2510.25014v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Minkyung Kim",
      "Junsik Kim",
      "Woongcheol Yang",
      "Sangdon Park",
      "Sohee Bae"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25013v1",
    "title": "Emergence of Minimal Circuits for Indirect Object Identification in\n  Attention-Only Transformers",
    "summary": "Mechanistic interpretability aims to reverse-engineer large language models\n(LLMs) into human-understandable computational circuits. However, the\ncomplexity of pretrained models often obscures the minimal mechanisms required\nfor specific reasoning tasks. In this work, we train small, attention-only\ntransformers from scratch on a symbolic version of the Indirect Object\nIdentification (IOI) task -- a benchmark for studying coreference -- like\nreasoning in transformers. Surprisingly, a single-layer model with only two\nattention heads achieves perfect IOI accuracy, despite lacking MLPs and\nnormalization layers. Through residual stream decomposition, spectral analysis,\nand embedding interventions, we find that the two heads specialize into\nadditive and contrastive subcircuits that jointly implement IOI resolution.\nFurthermore, we show that a two-layer, one-head model achieves similar\nperformance by composing information across layers through query-value\ninteractions. These results demonstrate that task-specific training induces\nhighly interpretable, minimal circuits, offering a controlled testbed for\nprobing the computational foundations of transformer reasoning.",
    "published": "2025-10-28T22:25:19Z",
    "updated": "2025-10-28T22:25:19Z",
    "link": "http://arxiv.org/pdf/2510.25013v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Rabin Adhikari"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25007v1",
    "title": "Taming the Real-world Complexities in CPT E/M Coding with Large Language\n  Models",
    "summary": "Evaluation and Management (E/M) coding, under the Current Procedural\nTerminology (CPT) taxonomy, documents medical services provided to patients by\nphysicians. Used primarily for billing purposes, it is in physicians' best\ninterest to provide accurate CPT E/M codes. %While important, it is an\nauxiliary task that adds to physicians' documentation burden. Automating this\ncoding task will help alleviate physicians' documentation burden, improve\nbilling efficiency, and ultimately enable better patient care. However, a\nnumber of real-world complexities have made E/M encoding automation a\nchallenging task. In this paper, we elaborate some of the key complexities and\npresent ProFees, our LLM-based framework that tackles them, followed by a\nsystematic evaluation. On an expert-curated real-world dataset, ProFees\nachieves an increase in coding accuracy of more than 36\\% over a commercial CPT\nE/M coding system and almost 5\\% over our strongest single-prompt baseline,\ndemonstrating its effectiveness in addressing the real-world complexities.",
    "published": "2025-10-28T22:06:59Z",
    "updated": "2025-10-28T22:06:59Z",
    "link": "http://arxiv.org/pdf/2510.25007v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Islam Nassar",
      "Yang Lin",
      "Yuan Jin",
      "Rongxin Zhu",
      "Chang Wei Tan",
      "Zenan Zhai",
      "Nitika Mathur",
      "Thanh Tien Vu",
      "Xu Zhong",
      "Long Duong",
      "Yuan-Fang Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25005v1",
    "title": "Cyclic Counterfactuals under Shift-Scale Interventions",
    "summary": "Most counterfactual inference frameworks traditionally assume acyclic\nstructural causal models (SCMs), i.e. directed acyclic graphs (DAGs). However,\nmany real-world systems (e.g. biological systems) contain feedback loops or\ncyclic dependencies that violate acyclicity. In this work, we study\ncounterfactual inference in cyclic SCMs under shift-scale interventions, i.e.,\nsoft, policy-style changes that rescale and/or shift a variable's mechanism.",
    "published": "2025-10-28T22:03:01Z",
    "updated": "2025-10-28T22:03:01Z",
    "link": "http://arxiv.org/pdf/2510.25005v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "authors": [
      "Saptarshi Saha",
      "Dhruv Vansraj Rathore",
      "Utpal Garain"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.00398v4",
    "title": "A Study on the Framework for Evaluating the Ethics and Trustworthiness\n  of Generative AI",
    "summary": "This study provides an in_depth analysis of the ethical and trustworthiness\nchallenges emerging alongside the rapid advancement of generative artificial\nintelligence (AI) technologies and proposes a comprehensive framework for their\nsystematic evaluation. While generative AI, such as ChatGPT, demonstrates\nremarkable innovative potential, it simultaneously raises ethical and social\nconcerns, including bias, harmfulness, copyright infringement, privacy\nviolations, and hallucination. Current AI evaluation methodologies, which\nmainly focus on performance and accuracy, are insufficient to address these\nmultifaceted issues. Thus, this study emphasizes the need for new\nhuman_centered criteria that also reflect social impact. To this end, it\nidentifies key dimensions for evaluating the ethics and trustworthiness of\ngenerative AI_fairness, transparency, accountability, safety, privacy,\naccuracy, consistency, robustness, explainability, copyright and intellectual\nproperty protection, and source traceability and develops detailed indicators\nand assessment methodologies for each. Moreover, it provides a comparative\nanalysis of AI ethics policies and guidelines in South Korea, the United\nStates, the European Union, and China, deriving key approaches and implications\nfrom each. The proposed framework applies across the AI lifecycle and\nintegrates technical assessments with multidisciplinary perspectives, thereby\noffering practical means to identify and manage ethical risks in real_world\ncontexts. Ultimately, the study establishes an academic foundation for the\nresponsible advancement of generative AI and delivers actionable insights for\npolicymakers, developers, users, and other stakeholders, supporting the\npositive societal contributions of AI technologies.",
    "published": "2025-08-30T07:38:07Z",
    "updated": "2025-10-28T21:53:52Z",
    "link": "http://arxiv.org/pdf/2509.00398v4.pdf",
    "category": [
      "cs.CY",
      "cs.AI"
    ],
    "authors": [
      "Cheonsu Jeong",
      "Seunghyun Lee",
      "Seonhee Jeong",
      "Sungsu Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.06568v3",
    "title": "Meta-Learning Objectives for Preference Optimization",
    "summary": "Evaluating preference optimization (PO) algorithms on LLM alignment is a\nchallenging task that presents prohibitive costs, noise, and several variables\nlike model size and hyper-parameters. In this work, we show that it is possible\nto gain insights on the efficacy of PO algorithm on simpler benchmarks. We\ndesign a diagnostic suite of MuJoCo tasks and datasets, which we use to\nsystematically evaluate PO algorithms, establishing a more controlled and\ncheaper benchmark. We then propose a novel family of PO algorithms based on\nmirror descent, which we call Mirror Preference Optimization (MPO). Through\nevolutionary strategies, we search this class to discover algorithms\nspecialized to specific properties of preference datasets, such as\nmixed-quality or noisy data. We demonstrate that our discovered PO algorithms\noutperform all known algorithms in the targeted MuJoCo settings. Finally, based\non the insights gained from our MuJoCo experiments, we design a PO algorithm\nthat significantly outperform existing baselines in an LLM alignment task.",
    "published": "2024-11-10T19:11:48Z",
    "updated": "2025-10-28T21:32:09Z",
    "link": "http://arxiv.org/pdf/2411.06568v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "authors": [
      "Carlo Alfano",
      "Silvia Sapora",
      "Jakob Nicolaus Foerster",
      "Patrick Rebeschini",
      "Yee Whye Teh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.10844v4",
    "title": "Creativity or Brute Force? Using Brainteasers as a Window into the\n  Problem-Solving Abilities of Large Language Models",
    "summary": "Accuracy remains a standard metric for evaluating AI systems, but it offers\nlimited insight into how models arrive at their solutions. In this work, we\nintroduce a benchmark based on brainteasers written in long narrative form to\nprobe more deeply into the types of reasoning strategies that models use.\nBrainteasers are well-suited for this goal because they can be solved with\nmultiple approaches, such as a few-step solution that uses a creative insight\nor a longer solution that uses more brute force. We investigate large language\nmodels (LLMs) across multiple layers of reasoning, focusing not only on\ncorrectness but also on the quality and creativity of their solutions. We\ninvestigate many aspects of the reasoning process: (1) semantic parsing of the\nbrainteasers into precise mathematical competition style formats; (2)\ngenerating solutions from these mathematical forms; (3) self-correcting\nsolutions based on gold solutions; (4) producing step-by-step sketches of\nsolutions; and (5) making use of hints. We find that LLMs are in many cases\nable to find creative, insightful solutions to brainteasers, suggesting that\nthey capture some of the capacities needed to solve novel problems in creative\nways. Nonetheless, there also remain situations where they rely on brute force\ndespite the availability of more efficient, creative solutions, highlighting a\npotential direction for improvement in the reasoning abilities of LLMs.",
    "published": "2025-05-16T04:23:34Z",
    "updated": "2025-10-28T21:30:31Z",
    "link": "http://arxiv.org/pdf/2505.10844v4.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Simeng Han",
      "Howard Dai",
      "Stephen Xia",
      "Grant Zhang",
      "Chen Liu",
      "Lichang Chen",
      "Hoang Huy Nguyen",
      "Hongyuan Mei",
      "Jiayuan Mao",
      "R. Thomas McCoy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24986v1",
    "title": "Epileptic Seizure Detection and Prediction from EEG Data: A Machine\n  Learning Approach with Clinical Validation",
    "summary": "In recent years, machine learning has become an increasingly powerful tool\nfor supporting seizure detection and monitoring in epilepsy care. Traditional\napproaches focus on identifying seizures only after they begin, which limits\nthe opportunity for early intervention and proactive treatment. In this study,\nwe propose a novel approach that integrates both real-time seizure detection\nand prediction, aiming to capture subtle temporal patterns in EEG data that may\nindicate an upcoming seizure. Our approach was evaluated using the CHB-MIT\nScalp EEG Database, which includes 969 hours of recordings and 173 seizures\ncollected from 23 pediatric and young adult patients with drug-resistant\nepilepsy. To support seizure detection, we implemented a range of supervised\nmachine learning algorithms, including K-Nearest Neighbors, Logistic\nRegression, Random Forest, and Support Vector Machine. The Logistic Regression\nachieved 90.9% detection accuracy with 89.6% recall, demonstrating balanced\nperformance suitable for clinical screening. Random Forest and Support Vector\nMachine models achieved higher accuracy (94.0%) but with 0% recall, failing to\ndetect any seizures, illustrating that accuracy alone is insufficient for\nevaluating medical ML models with class imbalance. For seizure prediction, we\nemployed Long Short-Term Memory (LSTM) networks, which use deep learning to\nmodel temporal dependencies in EEG data. The LSTM model achieved 89.26%\nprediction accuracy. These results highlight the potential of developing\naccessible, real-time monitoring tools that not only detect seizures as\ntraditionally done, but also predict them before they occur. This ability to\npredict seizures marks a significant shift from reactive seizure management to\na more proactive approach, allowing patients to anticipate seizures and take\nprecautionary measures to reduce the risk of injury or other complications.",
    "published": "2025-10-28T21:28:18Z",
    "updated": "2025-10-28T21:28:18Z",
    "link": "http://arxiv.org/pdf/2510.24986v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Ria Jayanti",
      "Tanish Jain"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24985v1",
    "title": "FaRAccel: FPGA-Accelerated Defense Architecture for Efficient Bit-Flip\n  Attack Resilience in Transformer Models",
    "summary": "Forget and Rewire (FaR) methodology has demonstrated strong resilience\nagainst Bit-Flip Attacks (BFAs) on Transformer-based models by obfuscating\ncritical parameters through dynamic rewiring of linear layers. However, the\napplication of FaR introduces non-negligible performance and memory overheads,\nprimarily due to the runtime modification of activation pathways and the lack\nof hardware-level optimization. To overcome these limitations, we propose\nFaRAccel, a novel hardware accelerator architecture implemented on FPGA,\nspecifically designed to offload and optimize FaR operations. FaRAccel\nintegrates reconfigurable logic for dynamic activation rerouting, and\nlightweight storage of rewiring configurations, enabling low-latency inference\nwith minimal energy overhead. We evaluate FaRAccel across a suite of\nTransformer models and demonstrate substantial reductions in FaR inference\nlatency and improvement in energy efficiency, while maintaining the robustness\ngains of the original FaR methodology. To the best of our knowledge, this is\nthe first hardware-accelerated defense against BFAs in Transformers,\neffectively bridging the gap between algorithmic resilience and efficient\ndeployment on real-world AI platforms.",
    "published": "2025-10-28T21:27:09Z",
    "updated": "2025-10-28T21:27:09Z",
    "link": "http://arxiv.org/pdf/2510.24985v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Najmeh Nazari",
      "Banafsheh Saber Latibari",
      "Elahe Hosseini",
      "Fatemeh Movafagh",
      "Chongzhou Fang",
      "Hosein Mohammadi Makrani",
      "Kevin Immanuel Gubbi",
      "Abhijit Mahalanobis",
      "Setareh Rafatirad",
      "Hossein Sayadi",
      "Houman Homayoun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24983v1",
    "title": "LRT-Diffusion: Calibrated Risk-Aware Guidance for Diffusion Policies",
    "summary": "Diffusion policies are competitive for offline reinforcement learning (RL)\nbut are typically guided at sampling time by heuristics that lack a statistical\nnotion of risk. We introduce LRT-Diffusion, a risk-aware sampling rule that\ntreats each denoising step as a sequential hypothesis test between the\nunconditional prior and the state-conditional policy head. Concretely, we\naccumulate a log-likelihood ratio and gate the conditional mean with a logistic\ncontroller whose threshold tau is calibrated once under H0 to meet a\nuser-specified Type-I level alpha. This turns guidance from a fixed push into\nan evidence-driven adjustment with a user-interpretable risk budget.\nImportantly, we deliberately leave training vanilla (two heads with standard\nepsilon-prediction) under the structure of DDPM. LRT guidance composes\nnaturally with Q-gradients: critic-gradient updates can be taken at the\nunconditional mean, at the LRT-gated mean, or a blend, exposing a continuum\nfrom exploitation to conservatism. We standardize states and actions\nconsistently at train and test time and report a state-conditional\nout-of-distribution (OOD) metric alongside return. On D4RL MuJoCo tasks,\nLRT-Diffusion improves the return-OOD trade-off over strong Q-guided baselines\nin our implementation while honoring the desired alpha. Theoretically, we\nestablish level-alpha calibration, concise stability bounds, and a return\ncomparison showing when LRT surpasses Q-guidance-especially when off-support\nerrors dominate. Overall, LRT-Diffusion is a drop-in, inference-time method\nthat adds principled, calibrated risk control to diffusion policies for offline\nRL.",
    "published": "2025-10-28T21:26:18Z",
    "updated": "2025-10-28T21:26:18Z",
    "link": "http://arxiv.org/pdf/2510.24983v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Ximan Sun",
      "Xiang Cheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24980v1",
    "title": "FT-ARM: Fine-Tuned Agentic Reflection Multimodal Language Model for\n  Pressure Ulcer Severity Classification with Reasoning",
    "summary": "Pressure ulcers (PUs) are a serious and prevalent healthcare concern.\nAccurate classification of PU severity (Stages I-IV) is essential for proper\ntreatment but remains challenging due to subtle visual distinctions and\nsubjective interpretation, leading to variability among clinicians. Prior\nAI-based approaches using Convolutional Neural Networks (CNNs) and Vision\nTransformers (ViTs) achieved promising accuracy but offered limited\ninterpretability. We present FT-ARM (Fine-Tuned Agentic Reflection Multimodal\nmodel), a fine-tuned multimodal large language model (MLLM) with an agentic\nself-reflection mechanism for pressure ulcer severity classification. Inspired\nby clinician-style diagnostic reassessment, FT-ARM iteratively refines its\npredictions by reasoning over visual features and encoded clinical knowledge\nfrom text, enhancing both accuracy and consistency. On the publicly available\nPressure Injury Image Dataset (PIID), FT-ARM, fine-tuned from LLaMA 3.2 90B,\nachieved 85% accuracy in classifying PU stages I-IV, surpassing prior CNN-based\nmodels by +4%. Unlike earlier CNN/ViT studies that relied solely on offline\nevaluations, FT-ARM is designed and tested for live inference, reflecting\nreal-time deployment conditions. Furthermore, it produces clinically grounded\nnatural-language explanations, improving interpretability and trust. By\nintegrating fine-tuning and reflective reasoning across multimodal inputs,\nFT-ARM advances the reliability, transparency, and clinical applicability of\nautomated wound assessment systems, addressing the critical need for consistent\nand explainable PU staging to support improved patient care.",
    "published": "2025-10-28T21:23:32Z",
    "updated": "2025-10-28T21:23:32Z",
    "link": "http://arxiv.org/pdf/2510.24980v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Reza Saadati Fard",
      "Emmanuel Agu",
      "Palawat Busaranuvong",
      "Deepak Kumar",
      "Shefalika Gautam",
      "Bengisu Tulu",
      "Diane Strong",
      "Lorraine Loretz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24976v1",
    "title": "Hammering the Diagnosis: Rowhammer-Induced Stealthy Trojan Attacks on\n  ViT-Based Medical Imaging",
    "summary": "Vision Transformers (ViTs) have emerged as powerful architectures in medical\nimage analysis, excelling in tasks such as disease detection, segmentation, and\nclassification. However, their reliance on large, attention-driven models makes\nthem vulnerable to hardware-level attacks. In this paper, we propose a novel\nthreat model referred to as Med-Hammer that combines the Rowhammer hardware\nfault injection with neural Trojan attacks to compromise the integrity of\nViT-based medical imaging systems. Specifically, we demonstrate how malicious\nbit flips induced via Rowhammer can trigger implanted neural Trojans, leading\nto targeted misclassification or suppression of critical diagnoses (e.g.,\ntumors or lesions) in medical scans. Through extensive experiments on benchmark\nmedical imaging datasets such as ISIC, Brain Tumor, and MedMNIST, we show that\nsuch attacks can remain stealthy while achieving high attack success rates\nabout 82.51% and 92.56% in MobileViT and SwinTransformer, respectively. We\nfurther investigate how architectural properties, such as model sparsity,\nattention weight distribution, and the number of features of the layer, impact\nattack effectiveness. Our findings highlight a critical and underexplored\nintersection between hardware-level faults and deep learning security in\nhealthcare applications, underscoring the urgent need for robust defenses\nspanning both model architectures and underlying hardware platforms.",
    "published": "2025-10-28T21:17:35Z",
    "updated": "2025-10-28T21:17:35Z",
    "link": "http://arxiv.org/pdf/2510.24976v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Banafsheh Saber Latibari",
      "Najmeh Nazari",
      "Hossein Sayadi",
      "Houman Homayoun",
      "Abhijit Mahalanobis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2408.11832v3",
    "title": "OpenFactCheck: A Unified Framework for Factuality Evaluation of LLMs",
    "summary": "The increased use of large language models (LLMs) across a variety of\nreal-world applications calls for automatic tools to check the factual accuracy\nof their outputs, as LLMs often hallucinate. This is difficult as it requires\nassessing the factuality of free-form open-domain responses. While there has\nbeen a lot of research on this topic, different papers use different evaluation\nbenchmarks and measures, which makes them hard to compare and hampers future\nprogress. To mitigate these issues, we developed OpenFactCheck, a unified\nframework, with three modules: (i) RESPONSEEVAL, which allows users to easily\ncustomize an automatic fact-checking system and to assess the factuality of all\nclaims in an input document using that system, (ii) LLMEVAL, which assesses the\noverall factuality of an LLM, and (iii) CHECKEREVAL, a module to evaluate\nautomatic fact-checking systems. OpenFactCheck is open-sourced\n(https://github.com/mbzuai-nlp/openfactcheck) and publicly released as a Python\nlibrary (https://pypi.org/project/openfactcheck/) and also as a web service\n(http://app.openfactcheck.com). A video describing the system is available at\nhttps://youtu.be/-i9VKL0HleI.",
    "published": "2024-08-06T15:49:58Z",
    "updated": "2025-10-28T21:14:55Z",
    "link": "http://arxiv.org/pdf/2408.11832v3.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "authors": [
      "Hasan Iqbal",
      "Yuxia Wang",
      "Minghan Wang",
      "Georgi Georgiev",
      "Jiahui Geng",
      "Iryna Gurevych",
      "Preslav Nakov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.01183v2",
    "title": "Doubly Robust Alignment for Large Language Models",
    "summary": "This paper studies reinforcement learning from human feedback (RLHF) for\naligning large language models with human preferences. While RLHF has\ndemonstrated promising results, many algorithms are highly sensitive to\nmisspecifications in the underlying preference model (e.g., the Bradley-Terry\nmodel), the reference policy, or the reward function, resulting in undesirable\nfine-tuning. To address model misspecification, we propose a doubly robust\npreference optimization algorithm that remains consistent when either the\npreference model or the reference policy is correctly specified (without\nrequiring both). Our proposal demonstrates superior and more robust performance\nthan state-of-the-art algorithms, both in theory and in practice. The code is\navailable at https://github.com/DRPO4LLM/DRPO4LLM",
    "published": "2025-06-01T21:34:37Z",
    "updated": "2025-10-28T20:58:26Z",
    "link": "http://arxiv.org/pdf/2506.01183v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "authors": [
      "Erhan Xu",
      "Kai Ye",
      "Hongyi Zhou",
      "Luhan Zhu",
      "Francesco Quinzan",
      "Chengchun Shi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24966v1",
    "title": "Sequences of Logits Reveal the Low Rank Structure of Language Models",
    "summary": "A major problem in the study of large language models is to understand their\ninherent low-dimensional structure. We introduce an approach to study the\nlow-dimensional structure of language models at a model-agnostic level: as\nsequential probabilistic models. We first empirically demonstrate that a wide\nrange of modern language models exhibit low-rank structure: in particular,\nmatrices built from the model's logits for varying sets of prompts and\nresponses have low approximate rank. We then show that this low-rank structure\ncan be leveraged for generation -- in particular, we can generate a response to\na target prompt using a linear combination of the model's outputs on unrelated,\nor even nonsensical prompts.\n  On the theoretical front, we observe that studying the approximate rank of\nlanguage models in the sense discussed above yields a simple universal\nabstraction whose theoretical predictions parallel our experiments. We then\nanalyze the representation power of the abstraction and give provable learning\nguarantees.",
    "published": "2025-10-28T20:55:58Z",
    "updated": "2025-10-28T20:55:58Z",
    "link": "http://arxiv.org/pdf/2510.24966v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "authors": [
      "Noah Golowich",
      "Allen Liu",
      "Abhishek Shetty"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.23234v4",
    "title": "p-less Sampling: A Robust Hyperparameter-Free Approach for LLM Decoding",
    "summary": "Obtaining high-quality outputs from Large Language Models (LLMs) often\ndepends upon the choice of a sampling-based decoding strategy to\nprobabilistically choose the next token at each generation step. While a\nvariety of such sampling methods have been proposed, their performance can be\nsensitive to the selection of hyperparameters which may require different\nsettings depending upon the generation task and temperature configuration. In\nthis work, we introduce $p$-less sampling: an information-theoretic approach to\nsampling which dynamically sets a truncation threshold at each decoding step\nbased on the entire token probability distribution. Unlike existing methods,\n$p$-less sampling has no hyperparameters and consistently produces high-quality\noutputs as temperature increases. We provide theoretical perspectives on\n$p$-less sampling to ground our proposed method and conduct experiments to\nempirically validate its effectiveness across a range of math, logical\nreasoning, and creative writing tasks. Our results demonstrate how $p$-less\nsampling consistently outperforms existing sampling approaches while exhibiting\nmuch less degradation in text quality at higher temperature values. We further\nshow how $p$-less achieves greater inference-time efficiency than alternative\nmethods through lower average token sampling times and shorter generation\nlengths, without sacrificing accuracy. Finally, we provide analyses to\nhighlight the benefits of $p$-less through qualitative examples, case studies,\nand diversity assessments. The code is available at\nhttps://github.com/ryttry/p-less .",
    "published": "2025-09-27T10:33:41Z",
    "updated": "2025-10-28T20:33:49Z",
    "link": "http://arxiv.org/pdf/2509.23234v4.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Runyan Tan",
      "Shuang Wu",
      "Phillip Howard"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.17801v2",
    "title": "Integrating Counterfactual Simulations with Language Models for\n  Explaining Multi-Agent Behaviour",
    "summary": "Autonomous multi-agent systems (MAS) are useful for automating complex tasks\nbut raise trust concerns due to risks such as miscoordination or goal\nmisalignment. Explainability is vital for users' trust calibration, but\nexplainable MAS face challenges due to complex environments, the human factor,\nand non-standardised evaluation. Leveraging the counterfactual effect size\nmodel and LLMs, we propose Agentic eXplanations via Interrogative Simulation\n(AXIS). AXIS generates human-centred action explanations for multi-agent\npolicies by having an LLM interrogate an environment simulator using prompts\nlike 'whatif' and 'remove' to observe and synthesise counterfactual information\nover multiple rounds. We evaluate AXIS on autonomous driving across ten\nscenarios for five LLMs with a comprehensive methodology combining robustness,\nsubjective preference, correctness, and goal/action prediction with an external\nLLM as evaluator. Compared to baselines, AXIS improves perceived explanation\ncorrectness by at least 7.7% across all models and goal prediction accuracy by\n23% for four models, with comparable action prediction accuracy, achieving the\nhighest scores overall. Our code is open-sourced at\nhttps://github.com/gyevnarb/axis.",
    "published": "2025-05-23T12:19:18Z",
    "updated": "2025-10-28T20:33:31Z",
    "link": "http://arxiv.org/pdf/2505.17801v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Bálint Gyevnár",
      "Christopher G. Lucas",
      "Stefano V. Albrecht",
      "Shay B. Cohen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24949v1",
    "title": "SCOUT: A Lightweight Framework for Scenario Coverage Assessment in\n  Autonomous Driving",
    "summary": "Assessing scenario coverage is crucial for evaluating the robustness of\nautonomous agents, yet existing methods rely on expensive human annotations or\ncomputationally intensive Large Vision-Language Models (LVLMs). These\napproaches are impractical for large-scale deployment due to cost and\nefficiency constraints. To address these shortcomings, we propose SCOUT\n(Scenario Coverage Oversight and Understanding Tool), a lightweight surrogate\nmodel designed to predict scenario coverage labels directly from an agent's\nlatent sensor representations. SCOUT is trained through a distillation process,\nlearning to approximate LVLM-generated coverage labels while eliminating the\nneed for continuous LVLM inference or human annotation. By leveraging\nprecomputed perception features, SCOUT avoids redundant computations and\nenables fast, scalable scenario coverage estimation. We evaluate our method\nacross a large dataset of real-life autonomous navigation scenarios,\ndemonstrating that it maintains high accuracy while significantly reducing\ncomputational cost. Our results show that SCOUT provides an effective and\npractical alternative for large-scale coverage analysis. While its performance\ndepends on the quality of LVLM-generated training labels, SCOUT represents a\nmajor step toward efficient scenario coverage oversight in autonomous systems.",
    "published": "2025-10-28T20:31:19Z",
    "updated": "2025-10-28T20:31:19Z",
    "link": "http://arxiv.org/pdf/2510.24949v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Anil Yildiz",
      "Sarah M. Thornton",
      "Carl Hildebrandt",
      "Sreeja Roy-Singh",
      "Mykel J. Kochenderfer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2403.02745v3",
    "title": "CURATRON: Complete and Robust Preference Data for Rigorous Alignment of\n  Large Language Models",
    "summary": "This paper addresses the challenges of aligning large language models (LLMs)\nwith human values via preference learning (PL), focusing on incomplete and\ncorrupted data in preference datasets. We propose a novel method for robustly\nand completely recalibrating values within these datasets to enhance LLMs'\nresilience against the issues. In particular, we devise a guaranteed polynomial\ntime ranking algorithm that robustifies several existing models, such as the\nclassic Bradley-Terry-Luce (BTL) (Bradley and Terry, 1952) model and certain\ngeneralizations of it. To the best of our knowledge, our present work is the\nfirst to propose an algorithm that provably recovers an $\\epsilon$-optimal\nranking with high probability while allowing as large as $O(n)$ perturbed\npairwise comparison results per model response. Furthermore, we show robust\nrecovery results in the partially observed setting. Our experiments confirm\nthat our algorithms handle adversarial noise and unobserved comparisons well in\nboth general and LLM preference dataset settings. This work contributes to the\ndevelopment and scaling of more reliable and ethically aligned AI models by\nequipping the dataset curation pipeline with the ability to handle missing and\nmaliciously manipulated inputs.",
    "published": "2024-03-05T07:58:12Z",
    "updated": "2025-10-28T20:31:06Z",
    "link": "http://arxiv.org/pdf/2403.02745v3.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Son The Nguyen",
      "Niranjan Uma Naresh",
      "Theja Tulabandhula"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.15518v2",
    "title": "HAMLET: Hyperadaptive Agent-based Modeling for Live Embodied Theatrics",
    "summary": "Creating an immersive and interactive theatrical experience is a long-term\ngoal in the field of interactive narrative. The emergence of large language\nmodel (LLM) is providing a new path to achieve this goal. However, existing\nLLM-based drama generation methods often result in agents that lack initiative\nand cannot interact with the physical scene. Furthermore, these methods\ntypically require detailed user input to drive the drama. These limitations\nreduce the interactivity and immersion of online real-time performance. To\naddress the above challenges, we propose HAMLET, a multi-agent framework\nfocused on drama creation and online performance. Given a simple topic, the\nframework generates a narrative blueprint, guiding the subsequent\nimprovisational performance. During the online performance, each actor is given\nan autonomous mind. This means that actors can make independent decisions based\non their own background, goals, and emotional state. In addition to\nconversations with other actors, their decisions can also change the state of\nscene props through actions such as opening a letter or picking up a weapon.\nThe change is then broadcast to other related actors, updating what they know\nand care about, which in turn influences their next action. To evaluate the\nquality of drama performance generated by HAMLET, we designed an evaluation\nmethod to assess three primary aspects, including character performance,\nnarrative quality, and interaction experience. The experimental evaluation\nshows that HAMLET can create expressive and coherent theatrical experiences.",
    "published": "2025-07-21T11:36:39Z",
    "updated": "2025-10-28T20:28:35Z",
    "link": "http://arxiv.org/pdf/2507.15518v2.pdf",
    "category": [
      "cs.AI",
      "cs.MA"
    ],
    "authors": [
      "Sizhou Chen",
      "Shufan Jiang",
      "Chi Zhang",
      "Xiao-Lei Zhang",
      "Xuelong Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24942v1",
    "title": "Finding Culture-Sensitive Neurons in Vision-Language Models",
    "summary": "Despite their impressive performance, vision-language models (VLMs) still\nstruggle on culturally situated inputs. To understand how VLMs process\nculturally grounded information, we study the presence of culture-sensitive\nneurons, i.e. neurons whose activations show preferential sensitivity to inputs\nassociated with particular cultural contexts. We examine whether such neurons\nare important for culturally diverse visual question answering and where they\nare located. Using the CVQA benchmark, we identify neurons of culture\nselectivity and perform causal tests by deactivating the neurons flagged by\ndifferent identification methods. Experiments on three VLMs across 25 cultural\ngroups demonstrate the existence of neurons whose ablation disproportionately\nharms performance on questions about the corresponding cultures, while having\nminimal effects on others. Moreover, we propose a new margin-based selector -\nContrastive Activation Selection (CAS), and show that it outperforms existing\nprobability- and entropy-based methods in identifying culture-sensitive\nneurons. Finally, our layer-wise analyses reveals that such neurons tend to\ncluster in certain decoder layers. Overall, our findings shed new light on the\ninternal organization of multimodal representations.",
    "published": "2025-10-28T20:14:37Z",
    "updated": "2025-10-28T20:14:37Z",
    "link": "http://arxiv.org/pdf/2510.24942v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Xiutian Zhao",
      "Rochelle Choenni",
      "Rohit Saxena",
      "Ivan Titov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.20249v2",
    "title": "WXImpactBench: A Disruptive Weather Impact Understanding Benchmark for\n  Evaluating Large Language Models",
    "summary": "Climate change adaptation requires the understanding of disruptive weather\nimpacts on society, where large language models (LLMs) might be applicable.\nHowever, their effectiveness is under-explored due to the difficulty of\nhigh-quality corpus collection and the lack of available benchmarks. The\nclimate-related events stored in regional newspapers record how communities\nadapted and recovered from disasters. However, the processing of the original\ncorpus is non-trivial. In this study, we first develop a disruptive weather\nimpact dataset with a four-stage well-crafted construction pipeline. Then, we\npropose WXImpactBench, the first benchmark for evaluating the capacity of LLMs\non disruptive weather impacts. The benchmark involves two evaluation tasks,\nmulti-label classification and ranking-based question answering. Extensive\nexperiments on evaluating a set of LLMs provide first-hand analysis of the\nchallenges in developing disruptive weather impact understanding and climate\nchange adaptation systems. The constructed dataset and the code for the\nevaluation framework are available to help society protect against\nvulnerabilities from disasters.",
    "published": "2025-05-26T17:23:29Z",
    "updated": "2025-10-28T20:06:49Z",
    "link": "http://arxiv.org/pdf/2505.20249v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Yongan Yu",
      "Qingchen Hu",
      "Xianda Du",
      "Jiayin Wang",
      "Fengran Mo",
      "Renee Sieber"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.21671v3",
    "title": "Adaptive Frontier Exploration on Graphs with Applications to\n  Network-Based Disease Testing",
    "summary": "We study a sequential decision-making problem on a $n$-node graph\n$\\mathcal{G}$ where each node has an unknown label from a finite set\n$\\mathbf{\\Omega}$, drawn from a joint distribution $\\mathcal{P}$ that is Markov\nwith respect to $\\mathcal{G}$. At each step, selecting a node reveals its label\nand yields a label-dependent reward. The goal is to adaptively choose nodes to\nmaximize expected accumulated discounted rewards. We impose a frontier\nexploration constraint, where actions are limited to neighbors of previously\nselected nodes, reflecting practical constraints in settings such as contact\ntracing and robotic exploration. We design a Gittins index-based policy that\napplies to general graphs and is provably optimal when $\\mathcal{G}$ is a\nforest. Our implementation runs in $\\mathcal{O}(n^2 \\cdot |\\mathbf{\\Omega}|^2)$\ntime while using $\\mathcal{O}(n \\cdot |\\mathbf{\\Omega}|^2)$ oracle calls to\n$\\mathcal{P}$ and $\\mathcal{O}(n^2 \\cdot |\\mathbf{\\Omega}|)$ space. Experiments\non synthetic and real-world graphs show that our method consistently\noutperforms natural baselines, including in non-tree, budget-limited, and\nundiscounted settings. For example, in HIV testing simulations on real-world\nsexual interaction networks, our policy detects nearly all positive cases with\nonly half the population tested, substantially outperforming other baselines.",
    "published": "2025-05-27T18:48:42Z",
    "updated": "2025-10-28T20:04:11Z",
    "link": "http://arxiv.org/pdf/2505.21671v3.pdf",
    "category": [
      "cs.AI",
      "cs.DS",
      "cs.LG",
      "math.OC"
    ],
    "authors": [
      "Davin Choo",
      "Yuqi Pan",
      "Tonghan Wang",
      "Milind Tambe",
      "Alastair van Heerden",
      "Cheryl Johnson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24926v1",
    "title": "KAN-GCN: Combining Kolmogorov-Arnold Network with Graph Convolution\n  Network for an Accurate Ice Sheet Emulator",
    "summary": "We introduce KAN-GCN, a fast and accurate emulator for ice sheet modeling\nthat places a Kolmogorov-Arnold Network (KAN) as a feature-wise calibrator\nbefore graph convolution networks (GCNs). The KAN front end applies learnable\none-dimensional warps and a linear mixing step, improving feature conditioning\nand nonlinear encoding without increasing message-passing depth. We employ this\narchitecture to improve the performance of emulators for numerical ice sheet\nmodels. Our emulator is trained and tested using 36 melting-rate simulations\nwith 3 mesh-size settings for Pine Island Glacier, Antarctica. Across 2- to\n5-layer architectures, KAN-GCN matches or exceeds the accuracy of pure GCN and\nMLP-GCN baselines. Despite a small parameter overhead, KAN-GCN improves\ninference throughput on coarser meshes by replacing one edge-wise\nmessage-passing layer with a node-wise transform; only the finest mesh shows a\nmodest cost. Overall, KAN-first designs offer a favorable accuracy vs.\nefficiency trade-off for large transient scenario sweeps.",
    "published": "2025-10-28T19:55:29Z",
    "updated": "2025-10-28T19:55:29Z",
    "link": "http://arxiv.org/pdf/2510.24926v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA"
    ],
    "authors": [
      "Zesheng Liu",
      "YoungHyun Koo",
      "Maryam Rahnemoonfar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.21779v2",
    "title": "What Causes Postoperative Aspiration?",
    "summary": "Background: Aspiration, the inhalation of foreign material into the lungs,\nsignificantly impacts surgical patient morbidity and mortality. This study\ndevelops a machine learning (ML) model to predict postoperative aspiration,\nenabling timely preventative interventions.\n  Methods: From the MIMIC-IV database of over 400,000 hospital admissions, we\nidentified 826 surgical patients (mean age: 62, 55.7\\% male) who experienced\naspiration within seven days post-surgery, along with a matched non-aspiration\ncohort. Three ML models: XGBoost, Multilayer Perceptron, and Random Forest were\ntrained using pre-surgical hospitalization data to predict postoperative\naspiration. To investigate causation, we estimated Average Treatment Effects\n(ATE) using Augmented Inverse Probability Weighting.\n  Results: Our ML model achieved an AUROC of 0.86 and 77.3\\% sensitivity on a\nheld-out test set. Maximum daily opioid dose, length of stay, and patient age\nemerged as the most important predictors. ATE analysis identified significant\ncausative factors: opioids (0.25 +/- 0.06) and operative site (neck: 0.20 +/-\n0.13, head: 0.19 +/- 0.13). Despite equal surgery rates across genders, men\nwere 1.5 times more likely to aspirate and received 27\\% higher maximum daily\nopioid dosages compared to women.\n  Conclusion: ML models can effectively predict postoperative aspiration risk,\nenabling targeted preventative measures. Maximum daily opioid dosage and\noperative site significantly influence aspiration risk. The gender disparity in\nboth opioid administration and aspiration rates warrants further investigation.\nThese findings have important implications for improving postoperative care\nprotocols and aspiration prevention strategies.",
    "published": "2025-10-18T05:07:57Z",
    "updated": "2025-10-28T19:53:22Z",
    "link": "http://arxiv.org/pdf/2510.21779v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Supriya Nagesh",
      "Karina Covarrubias",
      "Robert El-Kareh",
      "Shiva Prasad Kasiviswanathan",
      "Nina Mishra"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.09767v3",
    "title": "Non-Markovian Discrete Diffusion with Causal Language Models",
    "summary": "Discrete diffusion models offer a flexible, controllable approach to\nstructured sequence generation, yet they still lag behind causal language\nmodels in expressive power. A key limitation lies in their reliance on the\nMarkovian assumption, which restricts each step to condition only on the\ncurrent state, leading to potential uncorrectable error accumulation. In this\npaper, we introduce CaDDi (Causal Discrete Diffusion Model), a discrete\ndiffusion model that conditions on the entire generative trajectory, thereby\nlifting the Markov constraint and allowing the model to revisit and improve\npast states. By unifying sequential (causal) and temporal (diffusion) reasoning\nin a single non-Markovian transformer, CaDDi also treats standard causal\nlanguage models as a special case and permits the direct reuse of pretrained\nLLM weights with no architectural changes. Empirically, CaDDi outperforms\nstate-of-the-art discrete diffusion baselines on natural-language benchmarks,\nsubstantially narrowing the remaining gap to large autoregressive transformers.",
    "published": "2025-02-13T20:51:25Z",
    "updated": "2025-10-28T19:36:28Z",
    "link": "http://arxiv.org/pdf/2502.09767v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Yangtian Zhang",
      "Sizhuang He",
      "Daniel Levine",
      "Lawrence Zhao",
      "David Zhang",
      "Syed A Rizvi",
      "Shiyang Zhang",
      "Emanuele Zappala",
      "Rex Ying",
      "David van Dijk"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24909v1",
    "title": "Trust Dynamics in Strategic Coopetition: Computational Foundations for\n  Requirements Engineering in Multi-Agent Systems",
    "summary": "Requirements engineering increasingly occurs in multi-stakeholder\nenvironments where organizations simultaneously cooperate and compete, creating\ncoopetitive relationships in which trust evolves dynamically based on observed\nbehavior over repeated interactions. While conceptual modeling languages like\ni* represent trust relationships qualitatively, they lack computational\nmechanisms for analyzing how trust changes with behavioral evidence.\nConversely, computational trust models from multi-agent systems provide\nalgorithmic updating but lack grounding in requirements engineering contexts\nand conceptual models. This technical report bridges this gap by developing a\ncomputational trust model that extends game-theoretic foundations for strategic\ncoopetition with dynamic trust evolution. We introduce trust as a two-layer\nsystem with immediate trust responding to current behavior and reputation\ntracking violation history. Trust evolves through asymmetric updating where\ncooperation builds trust gradually while violations erode it sharply, creating\nhysteresis effects and trust ceilings that constrain relationship recovery. We\ndevelop a structured translation framework enabling requirements engineers to\ninstantiate computational trust models from i* dependency networks and\norganizational contexts. Comprehensive experimental validation across 78,125\nparameter configurations establishes robust emergence of negativity bias,\nhysteresis effects, and cumulative damage amplification. Empirical validation\nusing the Renault-Nissan Alliance case study (1999-2025) achieves 49 out of 60\nvalidation points (81.7%), successfully reproducing documented trust evolution\nacross five distinct relationship phases including crisis and recovery periods.\nThis technical report builds upon its foundational companion work in\narXiv:2510.18802.",
    "published": "2025-10-28T19:26:14Z",
    "updated": "2025-10-28T19:26:14Z",
    "link": "http://arxiv.org/pdf/2510.24909v1.pdf",
    "category": [
      "cs.MA",
      "cs.AI",
      "cs.SE"
    ],
    "authors": [
      "Vik Pant",
      "Eric Yu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.21849v2",
    "title": "TowerVision: Understanding and Improving Multilinguality in\n  Vision-Language Models",
    "summary": "Despite significant advances in vision-language models (VLMs), most existing\nwork follows an English-centric design process, limiting their effectiveness in\nmultilingual settings. In this work, we provide a comprehensive empirical study\nanalyzing the impact of several multilingual design choices, such as training\ndata composition, encoder selection, and text backbones. The result is\nTowerVision, a family of open multilingual VLMs for both image-text and\nvideo-text tasks, built upon the multilingual text-only model Tower+.\nTowerVision achieves competitive performance on multiple multimodal\nmultilingual benchmarks and shows particular strength in culturally grounded\ntasks and multimodal translation. By incorporating visual and cultural context\nduring fine-tuning, our models surpass existing approaches trained on\nsubstantially larger datasets, as demonstrated on ALM-Bench and Multi30K (image\ntasks) and ViMUL-Bench (video tasks). Alongside the models, we release\nVisionBlocks, a high-quality, curated vision-language dataset. Our findings\nhighlight that multilingual vision-language training data substantially\nimproves cross-lingual generalization -- both from high-resource to\nunderrepresented languages and vice versa -- and that instruction-tuned LLMs\nare not always the optimal initialization point. To support further research,\nwe publicly release all models, data, and training recipes.",
    "published": "2025-10-22T17:02:48Z",
    "updated": "2025-10-28T19:23:06Z",
    "link": "http://arxiv.org/pdf/2510.21849v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "68T07, 68T45, 68T50",
      "I.2.7; I.2.10; I.5.4"
    ],
    "authors": [
      "André G. Viveiros",
      "Patrick Fernandes",
      "Saul Santos",
      "Sonal Sannigrahi",
      "Emmanouil Zaranis",
      "Nuno M. Guerreiro",
      "Amin Farajian",
      "Pierre Colombo",
      "Graham Neubig",
      "André F. T. Martins"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24907v1",
    "title": "Understanding Multi-View Transformers",
    "summary": "Multi-view transformers such as DUSt3R are revolutionizing 3D vision by\nsolving 3D tasks in a feed-forward manner. However, contrary to previous\noptimization-based pipelines, the inner mechanisms of multi-view transformers\nare unclear. Their black-box nature makes further improvements beyond data\nscaling challenging and complicates usage in safety- and reliability-critical\napplications. Here, we present an approach for probing and visualizing 3D\nrepresentations from the residual connections of the multi-view transformers'\nlayers. In this manner, we investigate a variant of the DUSt3R model, shedding\nlight on the development of its latent state across blocks, the role of the\nindividual layers, and suggest how it differs from methods with stronger\ninductive biases of explicit global pose. Finally, we show that the\ninvestigated variant of DUSt3R estimates correspondences that are refined with\nreconstructed geometry. The code used for the analysis is available at\nhttps://github.com/JulienGaubil/und3rstand .",
    "published": "2025-10-28T19:19:35Z",
    "updated": "2025-10-28T19:19:35Z",
    "link": "http://arxiv.org/pdf/2510.24907v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Michal Stary",
      "Julien Gaubil",
      "Ayush Tewari",
      "Vincent Sitzmann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24906v1",
    "title": "Fair Indivisible Payoffs through Shapley Value",
    "summary": "We consider the problem of payoff division in indivisible coalitional games,\nwhere the value of the grand coalition is a natural number. This number\nrepresents a certain quantity of indivisible objects, such as parliamentary\nseats, kidney exchanges, or top features contributing to the outcome of a\nmachine learning model. The goal of this paper is to propose a fair method for\ndividing these objects among players. To achieve this, we define the\nindivisible Shapley value and study its properties. We demonstrate our proposed\ntechnique using three case studies, in particular, we use it to identify key\nregions of an image in the context of an image classification task.",
    "published": "2025-10-28T19:18:07Z",
    "updated": "2025-10-28T19:18:07Z",
    "link": "http://arxiv.org/pdf/2510.24906v1.pdf",
    "category": [
      "cs.GT",
      "cs.AI"
    ],
    "authors": [
      "Mikołaj Czarnecki",
      "Michał Korniak",
      "Oskar Skibski",
      "Piotr Skowron"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.19898v2",
    "title": "BugPilot: Complex Bug Generation for Efficient Learning of SWE Skills",
    "summary": "High quality bugs are key to training the next generation of language model\nbased software engineering (SWE) agents. We introduce a novel method for\nsynthetic generation of difficult and diverse bugs. Our method instructs SWE\nAgents to introduce a feature into the codebase whereby they may\nunintentionally break tests, resulting in bugs. Prior approaches often induce\nan out-of-distribution effect by generating bugs intentionally (e.g. by\nintroducing local perturbation to existing code), which does not reflect\nrealistic development processes. We perform qualitative analysis to demonstrate\nthat our approach for generating bugs more closely reflects the patterns found\nin human-authored edits. Through extensive experiments, we demonstrate that our\nbugs provide more efficient training data for supervised fine-tuning,\noutperforming other bug datasets by 2% with half the training data (1.2k vs. 3k\nbugs). We train on our newly generated bugs in addition to existing bug\ndatasets to get FrogBoss a state-of-the-art 32B parameter model on SWE-bench\nVerified with a pass@1 of 54.6% and FrogMini a state-of-the-art 14B model on\nSWE-bench Verified with a pass@1 of 45.3% on SWE-bench Verified averaged over\nthree seeds.",
    "published": "2025-10-22T17:58:56Z",
    "updated": "2025-10-28T19:10:09Z",
    "link": "http://arxiv.org/pdf/2510.19898v2.pdf",
    "category": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Atharv Sonwane",
      "Isadora White",
      "Hyunji Lee",
      "Matheus Pereira",
      "Lucas Caccia",
      "Minseon Kim",
      "Zhengyan Shi",
      "Chinmay Singh",
      "Alessandro Sordoni",
      "Marc-Alexandre Côté",
      "Xingdi Yuan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24893v1",
    "title": "Efficiency Without Cognitive Change: Evidence from Human Interaction\n  with Narrow AI Systems",
    "summary": "The growing integration of artificial intelligence (AI) into human cognition\nraises a fundamental question: does AI merely improve efficiency, or does it\nalter how we think? This study experimentally tested whether short-term\nexposure to narrow AI tools enhances core cognitive abilities or simply\noptimizes task performance. Thirty young adults completed standardized\nneuropsychological assessments embedded in a seven-week protocol with a\nfour-week online intervention involving problem-solving and verbal\ncomprehension tasks, either with or without AI support (ChatGPT). While\nAI-assisted participants completed several tasks faster and more accurately, no\nsignificant pre-post differences emerged in standardized measures of problem\nsolving or verbal comprehension. These results demonstrate efficiency gains\nwithout cognitive change, suggesting that current narrow AI systems serve as\ncognitive scaffolds extending performance without transforming underlying\nmental capacities. The findings highlight the need for ethical and educational\nframeworks that promote critical and autonomous thinking in an increasingly\nAI-augmented cognitive ecology.",
    "published": "2025-10-28T18:55:44Z",
    "updated": "2025-10-28T18:55:44Z",
    "link": "http://arxiv.org/pdf/2510.24893v1.pdf",
    "category": [
      "cs.HC",
      "cs.AI",
      "cs.HC",
      "H.1.2; H.5.2; I.2.6"
    ],
    "authors": [
      "María Angélica Benítez",
      "Rocío Candela Ceballos",
      "Karina Del Valle Molina",
      "Sofía Mundo Araujo",
      "Sofía Evangelina Victorio Villaroel",
      "Nadia Justel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.10516v2",
    "title": "Privacy-Preserving Personalization in Education: A Federated Recommender\n  System for Student Performance Prediction",
    "summary": "The increasing digitalization of education presents unprecedented\nopportunities for data-driven personalization, but it also introduces\nsignificant challenges to student data privacy. Conventional recommender\nsystems rely on centralized data, a paradigm often incompatible with modern\ndata protection regulations. A novel privacy-preserving recommender system is\nproposed and evaluated to address this critical issue using Federated Learning\n(FL). The approach utilizes a Deep Neural Network (DNN) with rich, engineered\nfeatures from the large-scale ASSISTments educational dataset. A rigorous\ncomparative analysis of federated aggregation strategies was conducted,\nidentifying FedProx as a significantly more stable and effective method for\nhandling heterogeneous student data than the standard FedAvg baseline. The\noptimized federated model achieves a high-performance F1-Score of 76.28%,\ncorresponding to 92% of the performance of a powerful, centralized XGBoost\nmodel. These findings validate that a federated approach can provide highly\neffective content recommendations without centralizing sensitive student data.\nConsequently, our work presents a viable and robust solution to the\npersonalization-privacy dilemma in modern educational platforms.",
    "published": "2025-09-03T11:28:57Z",
    "updated": "2025-10-28T18:54:59Z",
    "link": "http://arxiv.org/pdf/2509.10516v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "authors": [
      "Rodrigo Tertulino",
      "Ricardo Almeida"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.10530v3",
    "title": "Flow matching for reaction pathway generation",
    "summary": "Elucidating reaction mechanisms hinges on efficiently generating transition\nstates (TSs), products, and complete reaction networks. Recent generative\nmodels, such as diffusion models for TS sampling and sequence-based\narchitectures for product generation, offer faster alternatives to\nquantum-chemistry searches. But diffusion models remain constrained by their\nstochastic differential equation (SDE) dynamics, which suffer from inefficiency\nand limited controllability. We show that flow matching, a deterministic\nordinary differential (ODE) formulation, can replace SDE-based diffusion for\nmolecular and reaction generation. We introduce MolGEN, a conditional\nflow-matching framework that learns an optimal transport path to transport\nGaussian priors to target chemical distributions. On benchmarks used by TSDiff\nand OA-ReactDiff, MolGEN surpasses TS geometry accuracy and barrier-height\nprediction while reducing sampling to sub-second inference. MolGEN also\nsupports open-ended product generation with competitive top-k accuracy and\navoids mass/electron-balance violations common to sequence models. In a\nrealistic test on the $\\gamma$-ketohydroperoxide decomposition network, MolGEN\nyields higher fractions of valid and intended TSs with markedly fewer\nquantum-chemistry evaluations than string-based baselines. These results\ndemonstrate that deterministic flow matching provides a unified, accurate, and\ncomputationally efficient foundation for molecular generative modeling,\nsignaling that flow matching is the future for molecular generation across\nchemistry.",
    "published": "2025-07-14T17:54:47Z",
    "updated": "2025-10-28T18:17:27Z",
    "link": "http://arxiv.org/pdf/2507.10530v3.pdf",
    "category": [
      "physics.chem-ph",
      "cs.AI"
    ],
    "authors": [
      "Ping Tuo",
      "Jiale Chen",
      "Ju Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.17585v2",
    "title": "Cite Pretrain: Retrieval-Free Knowledge Attribution for Large Language\n  Models",
    "summary": "Trustworthy language models should provide both correct and verifiable\nanswers. However, citations generated directly by standalone LLMs are often\nunreliable. As a result, current systems insert citations by querying an\nexternal retriever at inference time, introducing latency, infrastructure\ndependence, and vulnerability to retrieval noise. We explore whether LLMs can\nbe made to reliably attribute to the documents seen during continual\npretraining without test-time retrieval, by revising the training process. To\nstudy this, we construct CitePretrainBench, a benchmark that mixes real-world\ncorpora (Wikipedia, Common Crawl, arXiv) with novel documents and probes both\nshort-form (single-fact) and long-form (multi-fact) citation tasks. Our\napproach follows a two-stage process: (1) continual pretraining to index\nfactual knowledge by binding it to persistent document identifiers; and (2)\ninstruction tuning to elicit citation behavior. We introduce Active Indexing\nfor the first stage, which creates generalizable, source-anchored bindings by\naugmenting training with synthetic data that (i) restate each fact in diverse,\ncompositional forms and (ii) enforce bidirectional training (source-to-fact and\nfact-to-source). This equips the model to both generate content from a cited\nsource and attribute its own answers, improving robustness to paraphrase and\ncomposition. Experiments with Qwen-2.5-7B&3B show that Active Indexing\nconsistently outperforms a Passive Indexing baseline, which simply appends an\nidentifier to each document, achieving citation precision gains of up to 30.2%\nacross all tasks and models. Our ablation studies reveal that performance\ncontinues to improve as we scale the amount of augmented data, showing a clear\nupward trend even at 16x the original token count. Finally, we show that\ninternal citations complement external ones by making the model more robust to\nretrieval noise.",
    "published": "2025-06-21T04:48:05Z",
    "updated": "2025-10-28T18:06:24Z",
    "link": "http://arxiv.org/pdf/2506.17585v2.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Yukun Huang",
      "Sanxing Chen",
      "Jian Pei",
      "Manzil Zaheer",
      "Bhuwan Dhingra"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.23923v2",
    "title": "Graph Mixing Additive Networks",
    "summary": "We introduce GMAN, a flexible, interpretable, and expressive framework that\nextends Graph Neural Additive Networks (GNANs) to learn from sets of sparse\ntime-series data. GMAN represents each time-dependent trajectory as a directed\ngraph and applies an enriched, more expressive GNAN to each graph. It allows\nusers to control the interpretability-expressivity trade-off by grouping\nfeatures and graphs to encode priors, and it provides feature, node, and\ngraph-level interpretability. On real-world datasets, including mortality\nprediction from blood tests and fake-news detection, GMAN outperforms strong\nnon-interpretable black-box baselines while delivering actionable,\ndomain-aligned explanations.",
    "published": "2025-09-28T14:58:58Z",
    "updated": "2025-10-28T18:04:14Z",
    "link": "http://arxiv.org/pdf/2509.23923v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Maya Bechler-Speicher",
      "Andrea Zerio",
      "Maor Huri",
      "Marie Vibeke Vestergaard",
      "Ran Gilad-Bachrach",
      "Tine Jess",
      "Samir Bhatt",
      "Aleksejs Sazonovs"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25766v1",
    "title": "Decomposition-Enhanced Training for Post-Hoc Attributions In Language\n  Models",
    "summary": "Large language models (LLMs) are increasingly used for long-document question\nanswering, where reliable attribution to sources is critical for trust.\nExisting post-hoc attribution methods work well for extractive QA but struggle\nin multi-hop, abstractive, and semi-extractive settings, where answers\nsynthesize information across passages. To address these challenges, we argue\nthat post-hoc attribution can be reframed as a reasoning problem, where answers\nare decomposed into constituent units, each tied to specific context. We first\nshow that prompting models to generate such decompositions alongside\nattributions improves performance. Building on this, we introduce DecompTune, a\npost-training method that teaches models to produce answer decompositions as\nintermediate reasoning steps. We curate a diverse dataset of complex QA tasks,\nannotated with decompositions by a strong LLM, and post-train Qwen-2.5 (7B and\n14B) using a two-stage SFT + GRPO pipeline with task-specific curated rewards.\nAcross extensive experiments and ablations, DecompTune substantially improves\nattribution quality, outperforming prior methods and matching or exceeding\nstate-of-the-art frontier models.",
    "published": "2025-10-29T17:58:59Z",
    "updated": "2025-10-29T17:58:59Z",
    "link": "http://arxiv.org/pdf/2510.25766v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Sriram Balasubramaniam",
      "Samyadeep Basu",
      "Koustava Goswami",
      "Ryan Rossi",
      "Varun Manjunatha",
      "Roshan Santhosh",
      "Ruiyi Zhang",
      "Soheil Feizi",
      "Nedim Lipka"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25761v1",
    "title": "DiagramEval: Evaluating LLM-Generated Diagrams via Graphs",
    "summary": "Diagrams play a central role in research papers for conveying ideas, yet they\nare often notoriously complex and labor-intensive to create. Although diagrams\nare presented as images, standard image generative models struggle to produce\nclear diagrams with well-defined structure. We argue that a promising direction\nis to generate demonstration diagrams directly in textual form as SVGs, which\ncan leverage recent advances in large language models (LLMs). However, due to\nthe complexity of components and the multimodal nature of diagrams,\nsufficiently discriminative and explainable metrics for evaluating the quality\nof LLM-generated diagrams remain lacking. In this paper, we propose\nDiagramEval, a novel evaluation metric designed to assess demonstration\ndiagrams generated by LLMs. Specifically, DiagramEval conceptualizes diagrams\nas graphs, treating text elements as nodes and their connections as directed\nedges, and evaluates diagram quality using two new groups of metrics: node\nalignment and path alignment. For the first time, we effectively evaluate\ndiagrams produced by state-of-the-art LLMs on recent research literature,\nquantitatively demonstrating the validity of our metrics. Furthermore, we show\nhow the enhanced explainability of our proposed metrics offers valuable\ninsights into the characteristics of LLM-generated diagrams. Code:\nhttps://github.com/ulab-uiuc/diagram-eval.",
    "published": "2025-10-29T17:56:17Z",
    "updated": "2025-10-29T17:56:17Z",
    "link": "http://arxiv.org/pdf/2510.25761v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Chumeng Liang",
      "Jiaxuan You"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25741v1",
    "title": "Scaling Latent Reasoning via Looped Language Models",
    "summary": "Modern LLMs are trained to \"think\" primarily via explicit text generation,\nsuch as chain-of-thought (CoT), which defers reasoning to post-training and\nunder-leverages pre-training data. We present and open-source Ouro, named after\nthe recursive Ouroboros, a family of pre-trained Looped Language Models\n(LoopLM) that instead build reasoning into the pre-training phase through (i)\niterative computation in latent space, (ii) an entropy-regularized objective\nfor learned depth allocation, and (iii) scaling to 7.7T tokens. Ouro 1.4B and\n2.6B models enjoy superior performance that match the results of up to 12B SOTA\nLLMs across a wide range of benchmarks. Through controlled experiments, we show\nthis advantage stems not from increased knowledge capacity, but from superior\nknowledge manipulation capabilities. We also show that LoopLM yields reasoning\ntraces more aligned with final outputs than explicit CoT. We hope our results\nshow the potential of LoopLM as a novel scaling direction in the reasoning era.\nOur model could be found in: http://ouro-llm.github.io.",
    "published": "2025-10-29T17:45:42Z",
    "updated": "2025-10-29T17:45:42Z",
    "link": "http://arxiv.org/pdf/2510.25741v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Rui-Jie Zhu",
      "Zixuan Wang",
      "Kai Hua",
      "Tianyu Zhang",
      "Ziniu Li",
      "Haoran Que",
      "Boyi Wei",
      "Zixin Wen",
      "Fan Yin",
      "He Xing",
      "Lu Li",
      "Jiajun Shi",
      "Kaijing Ma",
      "Shanda Li",
      "Taylor Kergan",
      "Andrew Smith",
      "Xingwei Qu",
      "Mude Hui",
      "Bohong Wu",
      "Qiyang Min",
      "Hongzhi Huang",
      "Xun Zhou",
      "Wei Ye",
      "Jiaheng Liu",
      "Jian Yang",
      "Yunfeng Shi",
      "Chenghua Lin",
      "Enduo Zhao",
      "Tianle Cai",
      "Ge Zhang",
      "Wenhao Huang",
      "Yoshua Bengio",
      "Jason Eshraghian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.23722v2",
    "title": "LLMs are Better Than You Think: Label-Guided In-Context Learning for\n  Named Entity Recognition",
    "summary": "In-context learning (ICL) enables large language models (LLMs) to perform new\ntasks using only a few demonstrations. However, in Named Entity Recognition\n(NER), existing ICL methods typically rely on task-agnostic semantic similarity\nfor demonstration retrieval, which often yields less relevant examples and\nleads to inferior results. We introduce DEER, a training-free ICL approach that\nenables LLMs to make more informed entity predictions through the use of\nlabel-grounded statistics. DEER leverages token-level statistics from training\nlabels to identify tokens most informative for entity recognition, enabling\nentity-focused demonstrations. It further uses these statistics to detect and\nrefine error-prone tokens through a targeted reflection step. Evaluated on five\nNER datasets across four LLMs, DEER consistently outperforms existing ICL\nmethods and achieves performance comparable to supervised fine-tuning. Further\nanalyses demonstrate that DEER improves example retrieval, remains effective on\nboth seen and unseen entities, and exhibits strong robustness in low-resource\nsettings.",
    "published": "2025-05-29T17:54:32Z",
    "updated": "2025-10-29T17:27:45Z",
    "link": "http://arxiv.org/pdf/2505.23722v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Fan Bai",
      "Hamid Hassanzadeh",
      "Ardavan Saeedi",
      "Mark Dredze"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.22586v2",
    "title": "Precise In-Parameter Concept Erasure in Large Language Models",
    "summary": "Large language models (LLMs) often acquire knowledge during pretraining that\nis undesirable in downstream deployments, e.g., sensitive information or\ncopyrighted content. Existing approaches for removing such knowledge rely on\nfine-tuning, training low-rank adapters or fact-level editing, but these are\neither too coarse, too shallow, or ineffective. In this work, we propose PISCES\n(Precise In-parameter Suppression for Concept EraSure), a novel framework for\nprecisely erasing entire concepts from model parameters by directly editing\ndirections that encode them in parameter space. PISCES uses a disentangler\nmodel to decompose MLP vectors into interpretable features, identifies those\nassociated with a target concept using automated interpretability techniques,\nand removes them from model parameters. Experiments on Gemma 2 and Llama 3.1\nover various concepts show that PISCES achieves modest gains in efficacy over\nleading erasure methods, reducing accuracy on the target concept to as low as\n7.7%, while dramatically improving erasure specificity (by up to 31%) and\nrobustness (by up to 38%). Overall, these results demonstrate that\nfeature-based in-parameter editing enables a more precise and reliable approach\nfor removing conceptual knowledge in language models.",
    "published": "2025-05-28T16:58:23Z",
    "updated": "2025-10-29T17:09:56Z",
    "link": "http://arxiv.org/pdf/2505.22586v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yoav Gur-Arieh",
      "Clara Suslik",
      "Yihuai Hong",
      "Fazl Barez",
      "Mor Geva"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25701v1",
    "title": "Interpreting LLMs as Credit Risk Classifiers: Do Their Feature\n  Explanations Align with Classical ML?",
    "summary": "Large Language Models (LLMs) are increasingly explored as flexible\nalternatives to classical machine learning models for classification tasks\nthrough zero-shot prompting. However, their suitability for structured tabular\ndata remains underexplored, especially in high-stakes financial applications\nsuch as financial risk assessment. This study conducts a systematic comparison\nbetween zero-shot LLM-based classifiers and LightGBM, a state-of-the-art\ngradient-boosting model, on a real-world loan default prediction task. We\nevaluate their predictive performance, analyze feature attributions using SHAP,\nand assess the reliability of LLM-generated self-explanations. While LLMs are\nable to identify key financial risk indicators, their feature importance\nrankings diverge notably from LightGBM, and their self-explanations often fail\nto align with empirical SHAP attributions. These findings highlight the\nlimitations of LLMs as standalone models for structured financial risk\nprediction and raise concerns about the trustworthiness of their self-generated\nexplanations. Our results underscore the need for explainability audits,\nbaseline comparisons with interpretable models, and human-in-the-loop oversight\nwhen deploying LLMs in risk-sensitive financial environments.",
    "published": "2025-10-29T17:05:00Z",
    "updated": "2025-10-29T17:05:00Z",
    "link": "http://arxiv.org/pdf/2510.25701v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Saeed AlMarri",
      "Kristof Juhasz",
      "Mathieu Ravaut",
      "Gautier Marti",
      "Hamdan Al Ahbabi",
      "Ibrahim Elfadel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.01200v2",
    "title": "SimulMEGA: MoE Routers are Advanced Policy Makers for Simultaneous\n  Speech Translation",
    "summary": "Simultaneous Speech Translation (SimulST) enables real-time cross-lingual\ncommunication by jointly optimizing speech recognition and machine translation\nunder strict latency constraints. Existing systems struggle to balance\ntranslation quality, latency, and semantic coherence, particularly in\nmultilingual many-to-many scenarios where divergent read and write policies\nhinder unified strategy learning. In this paper, we present SimulMEGA\n(Simultaneous Generation by Mixture-of-Experts Gating), an unsupervised policy\nlearning framework that combines prefix-based training with a\nMixture-of-Experts refiner to learn effective read and write decisions in an\nimplicit manner, without adding inference-time overhead. Our design requires\nonly minimal modifications to standard transformer architectures and\ngeneralizes across both speech-to-text and text-to-speech streaming tasks.\nThrough comprehensive evaluation on six language pairs, our 500M parameter\nspeech-to-text model outperforms the Seamless baseline, achieving under 7\npercent BLEU degradation at 1.5 seconds average lag and under 3 percent at 3\nseconds. We further demonstrate the versatility of SimulMEGA by extending it to\nstreaming TTS with a unidirectional backbone, yielding superior latency quality\ntradeoffs.",
    "published": "2025-09-01T07:34:50Z",
    "updated": "2025-10-29T17:02:41Z",
    "link": "http://arxiv.org/pdf/2509.01200v2.pdf",
    "category": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "authors": [
      "Chenyang Le",
      "Bing Han",
      "Jinshun Li",
      "Songyong Chen",
      "Yanmin Qian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25682v1",
    "title": "PairUni: Pairwise Training for Unified Multimodal Language Models",
    "summary": "Unified vision-language models (UVLMs) must perform both understanding and\ngeneration within a single architecture, but these tasks rely on heterogeneous\ndata and supervision, making it difficult to balance them during reinforcement\nlearning (RL). We propose PairUni, a unified framework that reorganizes data\ninto understanding-generation (UG) pairs and aligns optimization accordingly.\nWe first use GPT-o3 to augment single-task data, generating captions for\nunderstanding samples and question-answer (QA) pairs for generation samples,\nforming aligned pairs from the same instance. Additionally, for each generation\nsample, we retrieve a semantically related understanding example to form a\nretrieved pair, linking different but related data points. These paired\nstructures expose cross-task semantic correspondences and support consistent\npolicy learning. To leverage this structure, we present Pair-GPRO, a pair-aware\nvariant based on Group Relative Policy Optimization. It assigns a similarity\nscore to each pair to modulate the advantage, strengthening learning from\nwell-aligned examples and reducing task interference. We curate a high-quality\ndataset of 16K UG pairs named PairUG for RL fine-tuning and evaluate PairUni on\nthe powerful Janus-Pro UVLMs. Our approach achieves balanced improvements on\nvarious UVLMs, outperforming strong UVLM RL baselines. Code:\n\\href{https://github.com/Haochen-Wang409/PairUni}{github.com/Haochen-Wang409/PairUni}",
    "published": "2025-10-29T16:47:02Z",
    "updated": "2025-10-29T16:47:02Z",
    "link": "http://arxiv.org/pdf/2510.25682v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Jiani Zheng",
      "Zhiyang Teng",
      "Xiangtai Li",
      "Anran Wang",
      "Yu Tian",
      "Kunpeng Qiu",
      "Ye Tian",
      "Haochen Wang",
      "Zhuochen Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25677v1",
    "title": "ZK-SenseLM: Verifiable Large-Model Wireless Sensing with Selective\n  Abstention and Zero-Knowledge Attestation",
    "summary": "ZK-SenseLM is a secure and auditable wireless sensing framework that pairs a\nlarge-model encoder for Wi-Fi channel state information (and optionally mmWave\nradar or RFID) with a policy-grounded decision layer and end-to-end\nzero-knowledge proofs of inference. The encoder uses masked spectral\npretraining with phase-consistency regularization, plus a light cross-modal\nalignment that ties RF features to compact, human-interpretable policy tokens.\nTo reduce unsafe actions under distribution shift, we add a calibrated\nselective-abstention head; the chosen risk-coverage operating point is\nregistered and bound into the proof. We implement a four-stage proving\npipeline: (C1) feature sanity and commitment, (C2) threshold and version\nbinding, (C3) time-window binding, and (C4) PLONK-style proofs that the\nquantized network, given the committed window, produced the logged action and\nconfidence. Micro-batched proving amortizes cost across adjacent windows, and a\ngateway option offloads proofs from low-power devices. The system integrates\nwith differentially private federated learning and on-device personalization\nwithout weakening verifiability: model hashes and the registered threshold are\npart of each public statement. Across activity, presence or intrusion,\nrespiratory proxy, and RF fingerprinting tasks, ZK-SenseLM improves macro-F1\nand calibration, yields favorable coverage-risk curves under perturbations, and\nrejects tamper and replay with compact proofs and fast verification.",
    "published": "2025-10-29T16:43:07Z",
    "updated": "2025-10-29T16:43:07Z",
    "link": "http://arxiv.org/pdf/2510.25677v1.pdf",
    "category": [
      "cs.CR",
      "cs.CL",
      "C.2.1; D.4.6; E.3; I.2.6; I.5.4"
    ],
    "authors": [
      "Hasan Akgul",
      "Mari Eplik",
      "Javier Rojas",
      "Aina Binti Abdullah",
      "Pieter van der Merwe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.21320v2",
    "title": "SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines",
    "summary": "We present a scientific reasoning foundation model that aligns natural\nlanguage with heterogeneous scientific representations. The model is pretrained\non a 206B-token corpus spanning scientific text, pure sequences, and\nsequence-text pairs, then aligned via SFT on 40M instructions, annealed\ncold-start bootstrapping to elicit long-form chain-of-thought, and\nreinforcement learning with task-specific reward shaping, which instills\ndeliberate scientific reasoning. It supports four capability families, covering\nup to 103 tasks across workflows: (i) faithful translation between text and\nscientific formats, (ii) text/knowledge extraction, (iii) property prediction,\n(iv) property classification, (v) unconditional and conditional sequence\ngeneration and design. Compared with specialist systems, our approach broadens\ninstruction coverage, improves cross-domain generalization, and enhances\nfidelity. We detail data curation and training and show that cross-discipline\nlearning strengthens transfer and downstream reliability. The model, instruct\ntuning datasets and the evaluation code are open-sourced at\nhttps://huggingface.co/SciReason and\nhttps://github.com/open-sciencelab/SciReason.",
    "published": "2025-09-25T17:52:06Z",
    "updated": "2025-10-29T16:14:05Z",
    "link": "http://arxiv.org/pdf/2509.21320v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yizhou Wang",
      "Chen Tang",
      "Han Deng",
      "Jiabei Xiao",
      "Jiaqi Liu",
      "Jianyu Wu",
      "Jun Yao",
      "Pengze Li",
      "Encheng Su",
      "Lintao Wang",
      "Guohang Zhuang",
      "Yuchen Ren",
      "Ben Fei",
      "Ming Hu",
      "Xin Chen",
      "Dongzhan Zhou",
      "Junjun He",
      "Xiangyu Yue",
      "Zhenfei Yin",
      "Jiamin Wu",
      "Qihao Zheng",
      "Yuhao Zhou",
      "Huihui Xu",
      "Chenglong Ma",
      "Yan Lu",
      "Wenlong Zhang",
      "Chunfeng Song",
      "Philip Torr",
      "Shixiang Tang",
      "Xinzhu Ma",
      "Wanli Ouyang",
      "Lei Bai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24636v2",
    "title": "OpenReward: Learning to Reward Long-form Agentic Tasks via Reinforcement\n  Learning",
    "summary": "Reward models (RMs) have become essential for aligning large language models\n(LLMs), serving as scalable proxies for human evaluation in both training and\ninference. However, existing RMs struggle on knowledge-intensive and long-form\ntasks, where evaluating correctness requires grounding beyond the model's\ninternal knowledge. This limitation hinders them from reliably discriminating\nsubtle quality differences, especially when external evidence is necessary. To\naddress this, we introduce OpenRM, a tool-augmented long-form reward model that\nsystematically judges open-ended responses by invoking external tools to gather\nrelevant evidence. We train OpenRM with Group Relative Policy Optimization\n(GRPO) on over 27K synthesized pairwise examples generated through a\ncontrollable data synthesis framework. The training objective jointly\nsupervises intermediate tool usage and final outcome accuracy, incentivizing\nour reward model to learn effective evidence-based judgment strategies.\nExtensive experiments on three newly-collected datasets and two widely-used\nbenchmarks demonstrate that OpenRM substantially outperforms existing reward\nmodeling approaches. As a further step, we integrate OpenRM into both\ninference-time response selection and training-time data selection. This yields\nconsistent gains in downstream LLM alignment tasks, highlighting the potential\nof tool-augmented reward models for scaling reliable long-form evaluation.",
    "published": "2025-10-28T17:02:46Z",
    "updated": "2025-10-29T16:06:18Z",
    "link": "http://arxiv.org/pdf/2510.24636v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Ziyou Hu",
      "Zhengliang Shi",
      "Minghang Zhu",
      "Haitao Li",
      "Teng Sun",
      "Pengjie Ren",
      "Suzan Verberne",
      "Zhaochun Ren"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25628v1",
    "title": "EHR-R1: A Reasoning-Enhanced Foundational Language Model for Electronic\n  Health Record Analysis",
    "summary": "Electronic Health Records (EHRs) contain rich yet complex information, and\ntheir automated analysis is critical for clinical decision-making. Despite\nrecent advances of large language models (LLMs) in clinical workflows, their\nability to analyze EHRs remains limited due to narrow task coverage and lack of\nEHR-oriented reasoning capabilities. This paper aims to bridge the gap,\nspecifically, we present EHR-Ins, a large-scale, comprehensive EHR reasoning\ninstruction dataset, comprising 300k high-quality reasoning cases and 4M\nnon-reasoning cases across 42 distinct EHR tasks. Its core innovation is a\nthinking-graph-driven framework that enables to generate high-quality reasoning\ndata at scale. Based on it, we develop EHR-R1, a series of reasoning-enhanced\nLLMs with up to 72B parameters tailored for EHR analysis. Through a multi-stage\ntraining paradigm, including domain adaptation, reasoning enhancement, and\nreinforcement learning, EHR-R1 systematically acquires domain knowledge and\ndiverse reasoning capabilities, enabling accurate and robust EHR analysis.\nLastly, we introduce EHR-Bench, a new benchmark curated from MIMIC-IV, spanning\n42 tasks, to comprehensively assess reasoning and prediction across EHR\nscenarios. In experiments, we show that the resulting EHR-R1 consistently\noutperforms state-of-the-art commercial and open-source LLMs (including\nDeepSeek-V3 and GPT-4o), surpassing GPT-4o by over 30 points on MIMIC-Bench and\nachieving a 10\\% higher zero-shot AUROC on EHRSHOT. Collectively, EHR-Ins,\nEHR-R1, and EHR-Bench have significantly advanced the development for more\nreliable and clinically relevant EHR analysis.",
    "published": "2025-10-29T15:32:47Z",
    "updated": "2025-10-29T15:32:47Z",
    "link": "http://arxiv.org/pdf/2510.25628v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yusheng Liao",
      "Chaoyi Wu",
      "Junwei Liu",
      "Shuyang Jiang",
      "Pengcheng Qiu",
      "Haowen Wang",
      "Yun Yue",
      "Shuai Zhen",
      "Jian Wang",
      "Qianrui Fan",
      "Jinjie Gu",
      "Ya Zhang",
      "Yanfeng Wang",
      "Yu Wang",
      "Weidi Xie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25623v1",
    "title": "Evaluating the Role of Verifiers in Test-Time Scaling for Legal\n  Reasoning Tasks",
    "summary": "Test-time scaling (TTS) techniques can improve the performance of large\nlanguage models (LLMs) at the expense of additional computation and latency.\nWhile TTS has proven effective in formal domains such as mathematics and\nprogramming \\citep{snell2024scaling, chen2024more}, its value in argumentative\ndomains such as law remains underexplored. We present an empirical study of\nverifier-based TTS methods for legal multiple-choice QA (MCQA) across five\nbenchmarks. Using a family of 7 reward models, we evaluate both outcome-level\n(Best-of-$N$) and process-level (tree search) verification under realistic\nlow-$N$ budgets. Our analysis systematically investigates how verifier utility\nis affected by key properties such as domain specialization, model size, and\nsupervision type (process-supervised PRMs vs. outcome-only ORMs), even when\napplied across different roles.",
    "published": "2025-10-29T15:27:47Z",
    "updated": "2025-10-29T15:27:47Z",
    "link": "http://arxiv.org/pdf/2510.25623v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Davide Romano",
      "Jonathan Schwarz",
      "Daniele Giofré"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2405.17220v3",
    "title": "RLAIF-V: Open-Source AI Feedback Leads to Super GPT-4V Trustworthiness",
    "summary": "Traditional feedback learning for hallucination reduction relies on\nlabor-intensive manual labeling or expensive proprietary models. This leaves\nthe community without foundational knowledge about how to build high-quality\nfeedback with open-source MLLMs. In this work, we introduce RLAIF-V, a novel\nframework that aligns MLLMs in a fully open-source paradigm. RLAIF-V maximally\nexplores open-source MLLMs from two perspectives, including high-quality\nfeedback data generation for preference learning and self-feedback guidance for\ninference-time scaling. Extensive experiments on six benchmarks in both\nautomatic and human evaluation show that RLAIF-V substantially enhances the\ntrustworthiness of models at both preference learning and inference time.\nRLAIF-V 7B reduces object hallucination by 80.7\\% and overall hallucination by\n33.7\\%. Remarkably, RLAIF-V 12B further reveals the self-alignment potential of\nopen-source MLLMs, where the model can learn from feedback of itself to achieve\nsuper GPT-4V trustworthiness.",
    "published": "2024-05-27T14:37:01Z",
    "updated": "2025-10-29T15:19:12Z",
    "link": "http://arxiv.org/pdf/2405.17220v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Tianyu Yu",
      "Haoye Zhang",
      "Qiming Li",
      "Qixin Xu",
      "Yuan Yao",
      "Da Chen",
      "Xiaoman Lu",
      "Ganqu Cui",
      "Yunkai Dang",
      "Taiwen He",
      "Xiaocheng Feng",
      "Jun Song",
      "Bo Zheng",
      "Zhiyuan Liu",
      "Tat-Seng Chua",
      "Maosong Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25536v1",
    "title": "TwinVoice: A Multi-dimensional Benchmark Towards Digital Twins via LLM\n  Persona Simulation",
    "summary": "Large Language Models (LLMs) are exhibiting emergent human-like abilities and\nare increasingly envisioned as the foundation for simulating an individual's\ncommunication style, behavioral tendencies, and personality traits. However,\ncurrent evaluations of LLM-based persona simulation remain limited: most rely\non synthetic dialogues, lack systematic frameworks, and lack analysis of the\ncapability requirement. To address these limitations, we introduce TwinVoice, a\ncomprehensive benchmark for assessing persona simulation across diverse\nreal-world contexts. TwinVoice encompasses three dimensions: Social Persona\n(public social interactions), Interpersonal Persona (private dialogues), and\nNarrative Persona (role-based expression). It further decomposes the evaluation\nof LLM performance into six fundamental capabilities, including opinion\nconsistency, memory recall, logical reasoning, lexical fidelity, persona tone,\nand syntactic style. Experimental results reveal that while advanced models\nachieve moderate accuracy in persona simulation, they still fall short of\ncapabilities such as syntactic style and memory recall. Consequently, the\naverage performance achieved by LLMs remains considerably below the human\nbaseline.",
    "published": "2025-10-29T14:00:42Z",
    "updated": "2025-10-29T14:00:42Z",
    "link": "http://arxiv.org/pdf/2510.25536v1.pdf",
    "category": [
      "cs.CL",
      "I.2.7; I.2.6; I.2.0"
    ],
    "authors": [
      "Bangde Du",
      "Minghao Guo",
      "Songming He",
      "Ziyi Ye",
      "Xi Zhu",
      "Weihang Su",
      "Shuqi Zhu",
      "Yujia Zhou",
      "Yongfeng Zhang",
      "Qingyao Ai",
      "Yiqun Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23763v2",
    "title": "RoboOmni: Proactive Robot Manipulation in Omni-modal Context",
    "summary": "Recent advances in Multimodal Large Language Models (MLLMs) have driven rapid\nprogress in Vision-Language-Action (VLA) models for robotic manipulation.\nAlthough effective in many scenarios, current approaches largely rely on\nexplicit instructions, whereas in real-world interactions, humans rarely issue\ninstructions directly. Effective collaboration requires robots to infer user\nintentions proactively. In this work, we introduce cross-modal contextual\ninstructions, a new setting where intent is derived from spoken dialogue,\nenvironmental sounds, and visual cues rather than explicit commands. To address\nthis new setting, we present RoboOmni, a Perceiver-Thinker-Talker-Executor\nframework based on end-to-end omni-modal LLMs that unifies intention\nrecognition, interaction confirmation, and action execution. RoboOmni fuses\nauditory and visual signals spatiotemporally for robust intention recognition,\nwhile supporting direct speech interaction. To address the absence of training\ndata for proactive intention recognition in robotic manipulation, we build\nOmniAction, comprising 140k episodes, 5k+ speakers, 2.4k event sounds, 640\nbackgrounds, and six contextual instruction types. Experiments in simulation\nand real-world settings show that RoboOmni surpasses text- and ASR-based\nbaselines in success rate, inference speed, intention recognition, and\nproactive assistance.",
    "published": "2025-10-27T18:49:03Z",
    "updated": "2025-10-29T13:37:19Z",
    "link": "http://arxiv.org/pdf/2510.23763v2.pdf",
    "category": [
      "cs.RO",
      "cs.CL",
      "cs.CV"
    ],
    "authors": [
      "Siyin Wang",
      "Jinlan Fu",
      "Feihong Liu",
      "Xinzhe He",
      "Huangxuan Wu",
      "Junhao Shi",
      "Kexin Huang",
      "Zhaoye Fei",
      "Jingjing Gong",
      "Zuxuan Wu",
      "Yugang Jiang",
      "See-Kiong Ng",
      "Tat-Seng Chua",
      "Xipeng Qiu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.12993v2",
    "title": "A Multilingual, Large-Scale Study of the Interplay between LLM\n  Safeguards, Personalisation, and Disinformation",
    "summary": "Large Language Models (LLMs) can generate human-like disinformation, yet\ntheir ability to personalise such content across languages and demographics\nremains underexplored. This study presents the first large-scale, multilingual\nanalysis of persona-targeted disinformation generation by LLMs. Employing a red\nteaming methodology, we prompt eight state-of-the-art LLMs with 324 false\nnarratives and 150 demographic personas (combinations of country, generation,\nand political orientation) across four languages--English, Russian, Portuguese,\nand Hindi--resulting in AI-TRAITS, a comprehensive dataset of 1.6 million\npersonalised disinformation texts. Results show that the use of even simple\npersonalisation prompts significantly increases the likelihood of jailbreaks\nacross all studied LLMs, up to 10 percentage points, and alters linguistic and\nrhetorical patterns that enhance narrative persuasiveness. Models such as Grok\nand GPT exhibited jailbreak rates and personalisation scores both exceeding\n85%. These insights expose critical vulnerabilities in current state-of-the-art\nLLMs and offer a foundation for improving safety alignment and detection\nstrategies in multilingual and cross-demographic contexts.",
    "published": "2025-10-14T21:10:50Z",
    "updated": "2025-10-29T13:26:49Z",
    "link": "http://arxiv.org/pdf/2510.12993v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "João A. Leite",
      "Arnav Arora",
      "Silvia Gargova",
      "João Luz",
      "Gustavo Sampaio",
      "Ian Roberts",
      "Carolina Scarton",
      "Kalina Bontcheva"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25440v1",
    "title": "More than a Moment: Towards Coherent Sequences of Audio Descriptions",
    "summary": "Audio Descriptions (ADs) convey essential on-screen information, allowing\nvisually impaired audiences to follow videos. To be effective, ADs must form a\ncoherent sequence that helps listeners to visualise the unfolding scene, rather\nthan describing isolated moments. However, most automatic methods generate each\nAD independently, often resulting in repetitive, incoherent descriptions. To\naddress this, we propose a training-free method, CoherentAD, that first\ngenerates multiple candidate descriptions for each AD time interval, and then\nperforms auto-regressive selection across the sequence to form a coherent and\ninformative narrative. To evaluate AD sequences holistically, we introduce a\nsequence-level metric, StoryRecall, which measures how well the predicted ADs\nconvey the ground truth narrative, alongside repetition metrics that capture\nthe redundancy across consecutive AD outputs. Our method produces coherent AD\nsequences with enhanced narrative understanding, outperforming prior approaches\nthat rely on independent generations.",
    "published": "2025-10-29T12:06:42Z",
    "updated": "2025-10-29T12:06:42Z",
    "link": "http://arxiv.org/pdf/2510.25440v1.pdf",
    "category": [
      "cs.CV",
      "cs.CL"
    ],
    "authors": [
      "Eshika Khandelwal",
      "Junyu Xie",
      "Tengda Han",
      "Max Bain",
      "Arsha Nagrani",
      "Andrew Zisserman",
      "Gül Varol",
      "Makarand Tapaswi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25434v1",
    "title": "A Critical Study of Automatic Evaluation in Sign Language Translation",
    "summary": "Automatic evaluation metrics are crucial for advancing sign language\ntranslation (SLT). Current SLT evaluation metrics, such as BLEU and ROUGE, are\nonly text-based, and it remains unclear to what extent text-based metrics can\nreliably capture the quality of SLT outputs. To address this gap, we\ninvestigate the limitations of text-based SLT evaluation metrics by analyzing\nsix metrics, including BLEU, chrF, and ROUGE, as well as BLEURT on the one\nhand, and large language model (LLM)-based evaluators such as G-Eval and GEMBA\nzero-shot direct assessment on the other hand. Specifically, we assess the\nconsistency and robustness of these metrics under three controlled conditions:\nparaphrasing, hallucinations in model outputs, and variations in sentence\nlength. Our analysis highlights the limitations of lexical overlap metrics and\ndemonstrates that while LLM-based evaluators better capture semantic\nequivalence often missed by conventional metrics, they can also exhibit bias\ntoward LLM-paraphrased translations. Moreover, although all metrics are able to\ndetect hallucinations, BLEU tends to be overly sensitive, whereas BLEURT and\nLLM-based evaluators are comparatively lenient toward subtle cases. This\nmotivates the need for multimodal evaluation frameworks that extend beyond\ntext-based metrics to enable a more holistic assessment of SLT outputs.",
    "published": "2025-10-29T11:57:03Z",
    "updated": "2025-10-29T11:57:03Z",
    "link": "http://arxiv.org/pdf/2510.25434v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Shakib Yazdani",
      "Yasser Hamidullah",
      "Cristina España-Bonet",
      "Eleftherios Avramidis",
      "Josef van Genabith"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25432v1",
    "title": "Depth and Autonomy: A Framework for Evaluating LLM Applications in\n  Social Science Research",
    "summary": "Large language models (LLMs) are increasingly utilized by researchers across\na wide range of domains, and qualitative social science is no exception;\nhowever, this adoption faces persistent challenges, including interpretive\nbias, low reliability, and weak auditability. We introduce a framework that\nsituates LLM usage along two dimensions, interpretive depth and autonomy,\nthereby offering a straightforward way to classify LLM applications in\nqualitative research and to derive practical design recommendations. We present\nthe state of the literature with respect to these two dimensions, based on all\npublished social science papers available on Web of Science that use LLMs as a\ntool and not strictly as the subject of study. Rather than granting models\nexpansive freedom, our approach encourages researchers to decompose tasks into\nmanageable segments, much as they would when delegating work to capable\nundergraduate research assistants. By maintaining low levels of autonomy and\nselectively increasing interpretive depth only where warranted and under\nsupervision, one can plausibly reap the benefits of LLMs while preserving\ntransparency and reliability.",
    "published": "2025-10-29T11:55:21Z",
    "updated": "2025-10-29T11:55:21Z",
    "link": "http://arxiv.org/pdf/2510.25432v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Ali Sanaei",
      "Ali Rajabzadeh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25413v1",
    "title": "Seeing, Signing, and Saying: A Vision-Language Model-Assisted Pipeline\n  for Sign Language Data Acquisition and Curation from Social Media",
    "summary": "Most existing sign language translation (SLT) datasets are limited in scale,\nlack multilingual coverage, and are costly to curate due to their reliance on\nexpert annotation and controlled recording setup. Recently, Vision Language\nModels (VLMs) have demonstrated strong capabilities as evaluators and real-time\nassistants. Despite these advancements, their potential remains untapped in the\ncontext of sign language dataset acquisition. To bridge this gap, we introduce\nthe first automated annotation and filtering framework that utilizes VLMs to\nreduce reliance on manual effort while preserving data quality. Our method is\napplied to TikTok videos across eight sign languages and to the already curated\nYouTube-SL-25 dataset in German Sign Language for the purpose of additional\nevaluation. Our VLM-based pipeline includes a face visibility detection, a sign\nactivity recognition, a text extraction from video content, and a judgment step\nto validate alignment between video and text, implementing generic filtering,\nannotation and validation steps. Using the resulting corpus, TikTok-SL-8, we\nassess the performance of two off-the-shelf SLT models on our filtered dataset\nfor German and American Sign Languages, with the goal of establishing baselines\nand evaluating the robustness of recent models on automatically extracted,\nslightly noisy data. Our work enables scalable, weakly supervised pretraining\nfor SLT and facilitates data acquisition from social media.",
    "published": "2025-10-29T11:29:56Z",
    "updated": "2025-10-29T11:29:56Z",
    "link": "http://arxiv.org/pdf/2510.25413v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Shakib Yazdani",
      "Yasser Hamidullah",
      "Cristina España-Bonet",
      "Josef van Genabith"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25412v1",
    "title": "Serve Programs, Not Prompts",
    "summary": "Current large language model (LLM) serving systems, primarily designed for\ntext completion, are neither efficient nor adaptable for increasingly complex\nLLM applications due to their inflexible design. We propose a new LLM serving\nsystem architecture that serves programs instead of prompts to address this\nproblem. These programs, called LLM Inference Programs (LIPs), allow users to\ncustomize token prediction and KV cache management at runtime and to offload\nparts of their application logic, such as tool execution, to the server. We\ndescribe an example of this architecture through a system named Symphony, which\nfunctions as an operating system for LIPs. Symphony exposes LLM model\ncomputations via system calls and virtualizes KV cache with a dedicated file\nsystem, while ensuring GPU efficiency with a two-level process scheduling\nscheme. Symphony has the potential to open the door to a more efficient and\nextensible ecosystem for LLM applications.",
    "published": "2025-10-29T11:29:03Z",
    "updated": "2025-10-29T11:29:03Z",
    "link": "http://arxiv.org/pdf/2510.25412v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "In Gim",
      "Lin Zhong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.03690v2",
    "title": "Robust Preference Optimization via Dynamic Target Margins",
    "summary": "The alignment of Large Language Models (LLMs) is crucial for ensuring their\nsafety and reliability in practical applications. Direct Preference\nOptimization (DPO) has emerged as an efficient method that directly optimizes\nmodels using preference pairs, significantly reducing resource demands.\nHowever, the effectiveness of DPO heavily depends on the data quality, which is\nfrequently compromised by noise. In this work, we propose $\\gamma$-PO, a\ndynamic target margin preference optimization algorithm that adjust reward\nmargins at the pairwise level. By introducing instance-specific margin\ncalibration, $\\gamma$-PO strategically prioritizes high-confidence pairs (those\ndemonstrating higher reward margins) while suppressing potential noise from\nambiguous pairs. Moreover, $\\gamma$-PO is a plug-and-play method, compatible\nwith variants of DPO that rely on reward margin between preference pairs.\nAcross benchmarks such as AlpacaEval2 and Arena-Hard, $\\gamma$-PO achieves an\naverage 4.4\\% improvement over other baselines, setting new benchmarks for\nstate-of-the-art performance. Additionally, $\\gamma$-PO requires minimal code\nchanges and has a negligible impact on training efficiency, making it a robust\nsolution for enhancing LLMs alignment. Our codes are available at\n\\href{https://github.com/sunjie279/gammaPO}{https://github.com/sunjie279/gammaPO}.",
    "published": "2025-06-04T08:19:37Z",
    "updated": "2025-10-29T11:04:12Z",
    "link": "http://arxiv.org/pdf/2506.03690v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Jie Sun",
      "Junkang Wu",
      "Jiancan Wu",
      "Zhibo Zhu",
      "Xingyu Lu",
      "Jun Zhou",
      "Lintao Ma",
      "Xiang Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25384v1",
    "title": "Roleplaying with Structure: Synthetic Therapist-Client Conversation\n  Generation from Questionnaires",
    "summary": "The development of AI for mental health is hindered by a lack of authentic\ntherapy dialogues, due to strict privacy regulations and the fact that clinical\nsessions were historically rarely recorded. We present an LLM-driven pipeline\nthat generates synthetic counseling dialogues based on structured client\nprofiles and psychological questionnaires. Grounded on the principles of\nCognitive Behavioral Therapy (CBT), our method creates synthetic therapeutic\nconversations for clinical disorders such as anxiety and depression. Our\nframework, SQPsych (Structured Questionnaire-based Psychotherapy), converts\nstructured psychological input into natural language dialogues through\ntherapist-client simulations. Due to data governance policies and privacy\nrestrictions prohibiting the transmission of clinical questionnaire data to\nthird-party services, previous methodologies relying on proprietary models are\ninfeasible in our setting. We address this limitation by generating a\nhigh-quality corpus using open-weight LLMs, validated through human expert\nevaluation and LLM-based assessments. Our SQPsychLLM models fine-tuned on\nSQPsychConv achieve strong performance on counseling benchmarks, surpassing\nbaselines in key therapeutic skills. Our findings highlight the potential of\nsynthetic data to enable scalable, data-secure, and clinically informed AI for\nmental health support. We will release our code, models, and corpus at\nhttps://ai-mh.github.io/SQPsych",
    "published": "2025-10-29T10:55:52Z",
    "updated": "2025-10-29T10:55:52Z",
    "link": "http://arxiv.org/pdf/2510.25384v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Doan Nam Long Vu",
      "Rui Tan",
      "Lena Moench",
      "Svenja Jule Francke",
      "Daniel Woiwod",
      "Florian Thomas-Odenthal",
      "Sanna Stroth",
      "Tilo Kircher",
      "Christiane Hermann",
      "Udo Dannlowski",
      "Hamidreza Jamalabadi",
      "Shaoxiong Ji"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25370v1",
    "title": "Monitoring Transformative Technological Convergence Through\n  LLM-Extracted Semantic Entity Triple Graphs",
    "summary": "Forecasting transformative technologies remains a critical but challenging\ntask, particularly in fast-evolving domains such as Information and\nCommunication Technologies (ICTs). Traditional expert-based methods struggle to\nkeep pace with short innovation cycles and ambiguous early-stage terminology.\nIn this work, we propose a novel, data-driven pipeline to monitor the emergence\nof transformative technologies by identifying patterns of technological\nconvergence.\n  Our approach leverages advances in Large Language Models (LLMs) to extract\nsemantic triples from unstructured text and construct a large-scale graph of\ntechnology-related entities and relations. We introduce a new method for\ngrouping semantically similar technology terms (noun stapling) and develop\ngraph-based metrics to detect convergence signals. The pipeline includes\nmulti-stage filtering, domain-specific keyword clustering, and a temporal trend\nanalysis of topic co-occurence.\n  We validate our methodology on two complementary datasets: 278,625 arXiv\npreprints (2017--2024) to capture early scientific signals, and 9,793 USPTO\npatent applications (2018-2024) to track downstream commercial developments.\nOur results demonstrate that the proposed pipeline can identify both\nestablished and emerging convergence patterns, offering a scalable and\ngeneralizable framework for technology forecasting grounded in full-text\nanalysis.",
    "published": "2025-10-29T10:41:03Z",
    "updated": "2025-10-29T10:41:03Z",
    "link": "http://arxiv.org/pdf/2510.25370v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Alexander Sternfeld",
      "Andrei Kucharavy",
      "Dimitri Percia David",
      "Alain Mermoud",
      "Julian Jang-Jaccard",
      "Nathan Monnet"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25364v1",
    "title": "CLASS-IT: Conversational and Lecture-Aligned Small-Scale Instruction\n  Tuning for BabyLMs",
    "summary": "This work investigates whether small-scale LMs can benefit from instruction\ntuning. We compare conversational and question-answering instruction tuning\ndatasets, applied either in a merged or sequential curriculum, using\ndecoder-only models with 100M and 140M parameters. Evaluation spans both\nfine-tuning (SuperGLUE) and zero-shot (BLiMP, EWoK, WUGs, entity tracking, and\npsycholinguistic correlation) settings. Results show that instruction tuning\nyields small but consistent gains in fine-tuning scenarios, with sequential\ncurricula outperforming merged data; however, improvements do not consistently\ntransfer to zero-shot tasks, suggesting a trade-off between interaction-focused\nadaptation and broad linguistic generalization. These results highlight both\nthe potential and the constraints of adapting human-inspired learning\nstrategies to low-resource LMs, and point toward hybrid, curriculum-based\napproaches for enhancing generalization under ecological training limits.",
    "published": "2025-10-29T10:36:39Z",
    "updated": "2025-10-29T10:36:39Z",
    "link": "http://arxiv.org/pdf/2510.25364v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Luca Capone",
      "Alessandro Bondielli",
      "Alessandro Lenci"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25356v1",
    "title": "Not ready for the bench: LLM legal interpretation is unstable and out of\n  step with human judgments",
    "summary": "Legal interpretation frequently involves assessing how a legal text, as\nunderstood by an 'ordinary' speaker of the language, applies to the set of\nfacts characterizing a legal dispute in the U.S. judicial system. Recent\nscholarship has proposed that legal practitioners add large language models\n(LLMs) to their interpretive toolkit. This work offers an empirical argument\nagainst LLM interpretation as recently practiced by legal scholars and federal\njudges. Our investigation in English shows that models do not provide stable\ninterpretive judgments: varying the question format can lead the model to\nwildly different conclusions. Moreover, the models show weak to moderate\ncorrelation with human judgment, with large variance across model and question\nvariant, suggesting that it is dangerous to give much credence to the\nconclusions produced by generative AI.",
    "published": "2025-10-29T10:21:25Z",
    "updated": "2025-10-29T10:21:25Z",
    "link": "http://arxiv.org/pdf/2510.25356v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Abhishek Purushothama",
      "Junghyun Min",
      "Brandon Waldon",
      "Nathan Schneider"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25333v1",
    "title": "CRMWeaver: Building Powerful Business Agent via Agentic RL and Shared\n  Memories",
    "summary": "Recent years have witnessed the rapid development of LLM-based agents, which\nshed light on using language agents to solve complex real-world problems. A\nprominent application lies in business agents, which interact with databases\nand internal knowledge bases via tool calls to fulfill diverse user\nrequirements. However, this domain is characterized by intricate data\nrelationships and a wide range of heterogeneous tasks, from statistical data\nqueries to knowledge-based question-answering. To address these challenges, we\npropose CRMWeaver, a novel approach that enhances business agents in such\ncomplex settings. To acclimate the agentic model to intricate business\nenvironments, we employ a synthesis data generation and RL-based paradigm\nduring training, which significantly improves the model's ability to handle\ncomplex data and varied tasks. During inference, a shared memories mechanism is\nintroduced, prompting the agent to learn from task guidelines in similar\nproblems, thereby further boosting its effectiveness and generalization,\nespecially in unseen scenarios. We validate the efficacy of our approach on the\nCRMArena-Pro dataset, where our lightweight model achieves competitive results\nin both B2B and B2C business scenarios, underscoring its practical value for\nreal-world applications.",
    "published": "2025-10-29T09:47:40Z",
    "updated": "2025-10-29T09:47:40Z",
    "link": "http://arxiv.org/pdf/2510.25333v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yilong Lai",
      "Yipin Yang",
      "Jialong Wu",
      "Fengran Mo",
      "Zhenglin Wang",
      "Ting Liang",
      "Jianguo Lin",
      "Keping Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23252v2",
    "title": "Are ASR foundation models generalized enough to capture features of\n  regional dialects for low-resource languages?",
    "summary": "Conventional research on speech recognition modeling relies on the canonical\nform for most low-resource languages while automatic speech recognition (ASR)\nfor regional dialects is treated as a fine-tuning task. To investigate the\neffects of dialectal variations on ASR we develop a 78-hour annotated Bengali\nSpeech-to-Text (STT) corpus named Ben-10. Investigation from linguistic and\ndata-driven perspectives shows that speech foundation models struggle heavily\nin regional dialect ASR, both in zero-shot and fine-tuned settings. We observe\nthat all deep learning methods struggle to model speech data under dialectal\nvariations but dialect specific model training alleviates the issue. Our\ndataset also serves as a out of-distribution (OOD) resource for ASR modeling\nunder constrained resources in ASR algorithms. The dataset and code developed\nfor this project are publicly available",
    "published": "2025-10-27T12:14:52Z",
    "updated": "2025-10-29T09:41:26Z",
    "link": "http://arxiv.org/pdf/2510.23252v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Tawsif Tashwar Dipto",
      "Azmol Hossain",
      "Rubayet Sabbir Faruque",
      "Md. Rezuwan Hassan",
      "Kanij Fatema",
      "Tanmoy Shome",
      "Ruwad Naswan",
      "Md. Foriduzzaman Zihad",
      "Mohaymen Ul Anam",
      "Nazia Tasnim",
      "Hasan Mahmud",
      "Md Kamrul Hasan",
      "Md. Mehedi Hasan Shawon",
      "Farig Sadeque",
      "Tahsin Reasat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25310v1",
    "title": "Parrot: A Training Pipeline Enhances Both Program CoT and Natural\n  Language CoT for Reasoning",
    "summary": "Natural language chain-of-thought (N-CoT) and Program chain-of-thought\n(P-CoT) have emerged as two primary paradigms for large language models (LLMs)\nto solve mathematical reasoning problems. Current research typically endeavors\nto achieve unidirectional enhancement: P-CoT enhanced N-CoT or N-CoT enhanced\nP-CoT. In this paper, we seek to fully unleash the two paradigms' strengths for\nmutual enhancement and ultimately achieve simultaneous improvements. We conduct\na detailed analysis of the error types across two paradigms, based on which we\npropose Parrot, a novel training pipeline for mathematical problems: 1) Three\ntarget-designed subtasks integrate sequential P-CoT and N-CoT generation. 2) A\nsubtask hybrid training strategy to facilitate natural language semantic\ntransferability. 3) The converted N-CoT auxiliary reward is designed to\nalleviate the sparse rewards in P-CoT optimization. Extensive experiments\ndemonstrate that Parrot significantly enhances both the performance of N-CoT\nand P-CoT, especially on N-CoT. Using Parrot SFT, the N-CoT performance of\nLLaMA2 and CodeLLaMA achieve gains of +21.87 and +21.48 on MathQA over the RL\nbaseline, which is resource-intensive.",
    "published": "2025-10-29T09:23:17Z",
    "updated": "2025-10-29T09:23:17Z",
    "link": "http://arxiv.org/pdf/2510.25310v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Senjie Jin",
      "Lu Chen",
      "Zhiheng Xi",
      "Yuhui Wang",
      "Sirui Song",
      "Yuhao Zhou",
      "Xinbo Zhang",
      "Peng Sun",
      "Hong Lu",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25303v1",
    "title": "Teaching Sarcasm: Few-Shot Multimodal Sarcasm Detection via Distillation\n  to a Parameter-Efficient Student",
    "summary": "Multimodal sarcasm detection is challenging, especially in low-resource\nsettings where subtle image-text contradictions are hard to learn due to scarce\nannotated data, which hinders the model's performance. Parameter-efficient\nfine-tuning (PEFT) methods like adapters, LoRA, and prompt tuning reduce\noverfitting but struggle to reach optimal performance due to limited\nsupervision from few-shot data. We propose PEKD, a unified framework that\nenhances PEFT methods via distillation from an expert model trained on\nlarge-scale sarcasm data, which acts as the teacher. To mitigate unreliable\nsignals from the teacher, we introduce an entropy-aware gating mechanism that\ndynamically adjusts the distillation strength based on teacher confidence.\nExperiments on two public datasets demonstrate that our PEKD framework enables\nPEFT methods to outperform both prior parameter-efficient approaches and large\nmultimodal models, achieving strong results in the few-shot scenario. The\nframework is modular and adaptable to a wide range of multimodal models and\ntasks.",
    "published": "2025-10-29T09:14:41Z",
    "updated": "2025-10-29T09:14:41Z",
    "link": "http://arxiv.org/pdf/2510.25303v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Soumyadeep Jana",
      "Sanasam Ranbir Singh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25273v1",
    "title": "Adapting Small Language Models to Low-Resource Domains: A Case Study in\n  Hindi Tourism QA",
    "summary": "Domain-specific question answering in low-resource languages faces two key\nchallenges: scarcity of annotated datasets and limited domain knowledge in\ngeneral-purpose language models. In this work, we present a multi-stage\nfinetuning strategy to adapt lightweight language models to the Hindi tourism\ndomain by leveraging both original and synthetic training data. Synthetic\nquestion-answer pairs are generated using large LLMs (LLaMA-70B, Phi-14B) and\nused to augment the limited original dataset. We explore several training\nmethodologies and analyse their impact on domain generalisation. Our results\ndemonstrate that large models can efficiently generate synthetic data, while\nsmall models can effectively adapt to it, offering a scalable pathway for\nlow-resource, domain-specific QA.",
    "published": "2025-10-29T08:32:22Z",
    "updated": "2025-10-29T08:32:22Z",
    "link": "http://arxiv.org/pdf/2510.25273v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Sandipan Majhi",
      "Paheli Bhattacharya"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.00568v2",
    "title": "ReSeek: A Self-Correcting Framework for Search Agents with Instructive\n  Rewards",
    "summary": "Search agents powered by Large Language Models (LLMs) have demonstrated\nsignificant potential in tackling knowledge-intensive tasks. Reinforcement\nlearning (RL) has emerged as a powerful paradigm for training these agents to\nperform complex, multi-step reasoning. However, prior RL-based methods often\nrely on sparse or rule-based rewards, which can lead agents to commit to\nsuboptimal or erroneous reasoning paths without the ability to recover. To\naddress these limitations, we propose ReSeek, a novel self-correcting framework\nfor training search agents. Our framework introduces a self-correction\nmechanism that empowers the agent to dynamically identify and recover from\nerroneous search paths during an episode. By invoking a special JUDGE action,\nthe agent can judge the information and re-plan its search strategy. To guide\nthis process, we design a dense, instructive process reward function, which\ndecomposes into a correctness reward for retrieving factual information and a\nutility reward for finding information genuinely useful for the query.\nFurthermore, to mitigate the risk of data contamination in existing datasets,\nwe introduce FictionalHot, a new and challenging benchmark with recently\ncurated questions requiring complex reasoning. Being intuitively reasonable and\npractically simple, extensive experiments show that agents trained with ReSeek\nsignificantly outperform SOTA baselines in task success rate and path\nfaithfulness.",
    "published": "2025-10-01T06:44:28Z",
    "updated": "2025-10-29T08:22:54Z",
    "link": "http://arxiv.org/pdf/2510.00568v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Shiyu Li",
      "Yang Tang",
      "Yifan Wang",
      "Peiming Li",
      "Xi Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.05493v2",
    "title": "Can LLMs Outshine Conventional Recommenders? A Comparative Evaluation",
    "summary": "In recent years, integrating large language models (LLMs) into recommender\nsystems has created new opportunities for improving recommendation quality.\nHowever, a comprehensive benchmark is needed to thoroughly evaluate and compare\nthe recommendation capabilities of LLMs with traditional recommender systems.\nIn this paper, we introduce RecBench, which systematically investigates various\nitem representation forms (including unique identifier, text, semantic\nembedding, and semantic identifier) and evaluates two primary recommendation\ntasks, i.e., click-through rate prediction (CTR) and sequential recommendation\n(SeqRec). Our extensive experiments cover up to 17 large models and are\nconducted across five diverse datasets from fashion, news, video, books, and\nmusic domains. Our findings indicate that LLM-based recommenders outperform\nconventional recommenders, achieving up to a 5% AUC improvement in the CTR\nscenario and up to a 170% NDCG@10 improvement in the SeqRec scenario. However,\nthese substantial performance gains come at the expense of significantly\nreduced inference efficiency, rendering the LLM-as-RS paradigm impractical for\nreal-time recommendation environments. We aim for our findings to inspire\nfuture research, including recommendation-specific model acceleration methods.\nWe will release our code, data, configurations, and platform to enable other\nresearchers to reproduce and build upon our experimental results.",
    "published": "2025-03-07T15:05:23Z",
    "updated": "2025-10-29T08:19:03Z",
    "link": "http://arxiv.org/pdf/2503.05493v2.pdf",
    "category": [
      "cs.IR",
      "cs.CL"
    ],
    "authors": [
      "Qijiong Liu",
      "Jieming Zhu",
      "Lu Fan",
      "Kun Wang",
      "Hengchang Hu",
      "Wei Guo",
      "Yong Liu",
      "Xiao-Ming Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.15356v2",
    "title": "NL-Debugging: Exploiting Natural Language as an Intermediate\n  Representation for Code Debugging",
    "summary": "Debugging is a critical aspect of LLM's coding ability. Early debugging\nefforts primarily focused on code-level analysis, which often falls short when\naddressing complex programming errors that require a deeper understanding of\nalgorithmic logic. Recent advancements in large language models (LLMs) have\nshifted attention toward leveraging natural language reasoning to enhance\ncode-related tasks. However, two fundamental questions remain unanswered: What\ntype of natural language format is most effective for debugging tasks? And what\nspecific benefits does natural language reasoning bring to the debugging\nprocess? In this paper, we introduce NL-DEBUGGING, a novel framework that\nemploys natural language as an intermediate representation to improve code\ndebugging. By debugging at a natural language level, we demonstrate that\nNL-DEBUGGING outperforms traditional debugging methods and enables a broader\nmodification space through direct refinement guided by execution feedback. Our\nfindings highlight the potential of natural language reasoning to advance\nautomated code debugging and address complex programming challenges.",
    "published": "2025-05-21T10:38:50Z",
    "updated": "2025-10-29T07:34:05Z",
    "link": "http://arxiv.org/pdf/2505.15356v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Weiming Zhang",
      "Qingyao Li",
      "Xinyi Dai",
      "Jizheng Chen",
      "Kounianhua Du",
      "Weiwen Liu",
      "Yasheng Wang",
      "Ruiming Tang",
      "Yong Yu",
      "Weinan Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.19902v2",
    "title": "WEST: LLM based Speech Toolkit for Speech Understanding, Generation, and\n  Interaction",
    "summary": "In this paper, we present WEST(WE Speech Toolkit), a speech toolkit based on\na large language model (LLM) for speech understanding, generation, and\ninteraction. There are three key features of WEST: 1) Fully LLM-based: Standing\non the shoulders of giants by reusing mature architectures, ecosystems (e.g.,\nHugging Face), and methods (e.g., sequence packing) from large models. 2)\nFull-stack: Supports tasks such as recognition, synthesis, understanding,\ndialogue, and multimodal capabilities, with extensibility to incorporate\nopen-source models. 3) Simple and Stupid: A simple and stupid speech toolkit\nthat everyone can Touch. In addition, WEST provides two types of recipes,\nmodels, and experimental results. The first is entirely based on open-source\nmodels and open-source data, allowing users to fully reproduce the experiments\nin this paper and serving as a verification system or minimal system baseline.\nThe second is trained on massive data, offering superior performance so the\nuser can directly apply it out of the box. WEST is publicly avilable at\nhttps://github.com/wenet-e2e/west/",
    "published": "2025-09-24T08:56:32Z",
    "updated": "2025-10-29T07:17:51Z",
    "link": "http://arxiv.org/pdf/2509.19902v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Binbin Zhang",
      "Chengdong Liang",
      "Shuai Wang",
      "Xuelong Geng",
      "Zhao Guo",
      "Haoyu Li",
      "Hao Yin",
      "Xipeng Yang",
      "Pengshen Zhang",
      "Changwei Ma",
      "Lei Xie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25224v1",
    "title": "ProMediate: A Socio-cognitive framework for evaluating proactive agents\n  in multi-party negotiation",
    "summary": "While Large Language Models (LLMs) are increasingly used in agentic\nframeworks to assist individual users, there is a growing need for agents that\ncan proactively manage complex, multi-party collaboration. Systematic\nevaluation methods for such proactive agents remain scarce, limiting progress\nin developing AI that can effectively support multiple people together.\nNegotiation offers a demanding testbed for this challenge, requiring\nsocio-cognitive intelligence to navigate conflicting interests between multiple\nparticipants and multiple topics and build consensus. Here, we present\nProMediate, the first framework for evaluating proactive AI mediator agents in\ncomplex, multi-topic, multi-party negotiations. ProMediate consists of two core\ncomponents: (i) a simulation testbed based on realistic negotiation cases and\ntheory-driven difficulty levels (ProMediate-Easy, ProMediate-Medium, and\nProMediate-Hard), with a plug-and-play proactive AI mediator grounded in\nsocio-cognitive mediation theories, capable of flexibly deciding when and how\nto intervene; and (ii) a socio-cognitive evaluation framework with a new suite\nof metrics to measure consensus changes, intervention latency, mediator\neffectiveness, and intelligence. Together, these components establish a\nsystematic framework for assessing the socio-cognitive intelligence of\nproactive AI agents in multi-party settings. Our results show that a socially\nintelligent mediator agent outperforms a generic baseline, via faster,\nbetter-targeted interventions. In the ProMediate-Hard setting, our social\nmediator increases consensus change by 3.6 percentage points compared to the\ngeneric baseline (10.65\\% vs 7.01\\%) while being 77\\% faster in response\n(15.98s vs. 3.71s). In conclusion, ProMediate provides a rigorous,\ntheory-grounded testbed to advance the development of proactive, socially\nintelligent agents.",
    "published": "2025-10-29T07:00:11Z",
    "updated": "2025-10-29T07:00:11Z",
    "link": "http://arxiv.org/pdf/2510.25224v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Ziyi Liu",
      "Bahar Sarrafzadeh",
      "Pei Zhou",
      "Longqi Yang",
      "Jieyu Zhao",
      "Ashish Sharma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.04458v2",
    "title": "Think Twice Before You Judge: Mixture of Dual Reasoning Experts for\n  Multimodal Sarcasm Detection",
    "summary": "Multimodal sarcasm detection has attracted growing interest due to the rise\nof multimedia posts on social media. Understanding sarcastic image-text posts\noften requires external contextual knowledge, such as cultural references or\ncommonsense reasoning. However, existing models struggle to capture the deeper\nrationale behind sarcasm, relying mainly on shallow cues like image captions or\nobject-attribute pairs from images. To address this, we propose \\textbf{MiDRE}\n(\\textbf{Mi}xture of \\textbf{D}ual \\textbf{R}easoning \\textbf{E}xperts), which\nintegrates an internal reasoning expert for detecting incongruities within the\nimage-text pair and an external reasoning expert that utilizes structured\nrationales generated via Chain-of-Thought prompting to a Large Vision-Language\nModel. An adaptive gating mechanism dynamically weighs the two experts,\nselecting the most relevant reasoning path. Unlike prior methods that treat\nexternal knowledge as static input, MiDRE selectively adapts to when such\nknowledge is beneficial, mitigating the risks of hallucinated or irrelevant\nsignals from large models. Experiments on two benchmark datasets show that\nMiDRE achieves superior performance over baselines. Various qualitative\nanalyses highlight the crucial role of external rationales, revealing that even\nwhen they are occasionally noisy, they provide valuable cues that guide the\nmodel toward a better understanding of sarcasm.",
    "published": "2025-07-06T16:37:21Z",
    "updated": "2025-10-29T06:50:01Z",
    "link": "http://arxiv.org/pdf/2507.04458v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Soumyadeep Jana",
      "Abhrajyoti Kundu",
      "Sanasam Ranbir Singh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.24155v4",
    "title": "Blind Spot Navigation in Large Language Model Reasoning with Thought\n  Space Explorer",
    "summary": "Large language models have shown strong reasoning capabilities through\nchain-structured methods such as Chain-of-Thought. Recent studies optimize\nthought structures by generating parallel or tree-like structures, switching\nbetween long and short reasoning modes, or aligning reasoning steps with task\nperformance. However, these approaches mainly rely on previously generated\nlogical directions of the chains, which ignore the unexplored regions of the\nsolution space. Such a phenomenon is defined as blind spots, which limit the\ndiversity and effectiveness of the reasoning process. To this end, we propose\nthe ``Thought Space Explorer'' (TSE), a framework for navigating and expanding\nthought structures to overcome blind spots in LLM reasoning. Our TSE first\nidentifies key nodes with high impact, then generates new nodes by integrating\ninformation from multiple chains. Finally, it extends new branches through\nconnection strategies. We conduct a series of experiments on math and QA\nbenchmarks. Compared with existing baseline methods, TSE improves the accuracy\nof both the final answer and intermediate reasoning steps, while maintaining a\nbetter effectiveness-efficiency trade-off for practical deployment.",
    "published": "2024-10-31T17:12:14Z",
    "updated": "2025-10-29T06:49:14Z",
    "link": "http://arxiv.org/pdf/2410.24155v4.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Jinghan Zhang",
      "Fengran Mo",
      "Tharindu Cyril Weerasooriya",
      "Xinyue Ye",
      "Dongjie Wang",
      "Yanjie Fu",
      "Kunpeng Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.09158v2",
    "title": "Augmenting Dialog with Think-Aloud Utterances for Modeling Individual\n  Personality Traits by LLM",
    "summary": "This study proposes augmenting dialog data with think-aloud utterances (TAUs)\nfor modeling individual personalities in text chat by LLM. TAU is a\nverbalization of a speaker's thought before articulating the utterance. We\nexpect \"persona LLMs\" trained with TAU-augmented data can mimic the speaker's\npersonality trait better. We tested whether the trained persona LLMs obtain the\nhuman personality with respect to Big Five, a framework characterizing human\npersonality traits from five aspects. The results showed that LLMs trained with\nTAU-augmented data more closely align to the speakers' Agreeableness and\nNeuroticism of Big Five than those trained with original dialog data. We also\nfound that the quality of TAU-augmentation impacts persona LLM's performance.",
    "published": "2025-10-10T09:03:31Z",
    "updated": "2025-10-29T06:33:58Z",
    "link": "http://arxiv.org/pdf/2510.09158v2.pdf",
    "category": [
      "cs.CL",
      "I.2.7"
    ],
    "authors": [
      "Seiya Ishikura",
      "Hiroaki Yamada",
      "Tatsuya Hiraoka",
      "Hiroaki Yamada",
      "Takenobu Tokunaga"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24302v2",
    "title": "Lookahead Tree-Based Rollouts for Enhanced Trajectory-Level Exploration\n  in Reinforcement Learning with Verifiable Rewards",
    "summary": "Reinforcement Learning with Verifiable Rewards (RLVR), particularly with\nalgorithms like Group Relative Policy Optimization (GRPO), has proven highly\neffective in enhancing the reasoning capabilities of large language models.\nHowever, a critical bottleneck in current pipelines lies in the limited\ndiversity of sampled trajectories during group rollouts. Homogeneous\ntrajectories and their associated rewards would diminish the return signals for\npolicy updates, thereby hindering effective policy learning. This lack of\ndiversity stems primarily from token-level stochastic sampling, where local\nvariations are likely to collapse into near-identical reasoning paths. To\naddress this limitation, we propose Lookahead Tree-Based Rollouts (LATR), a\nnovel rollout strategy designed to explicitly promotes trajectory-level\ndiversity by enforcing branching into different candidate tokens likely to\nyield distinct continuations. Specifically, LATR iteratively operates in three\nstages: (1) branching at high-uncertainty generation steps, (2) performing\nlookahead simulation for each new branch, and (3) pruning branches that\nexhibits prolonged similarity during simulation. Compared with stochastic\nSampling, LATR accelerates policy learning by 131% on average and improves\nfinal pass@1 performance by 4.2% on both GRPO and Dynamic sAmpling Policy\nOptimization (DAPO) algorithms across different reasoning tasks. Our code and\ndata are publicly available at https://github.com/starreeze/latr.",
    "published": "2025-10-28T11:12:02Z",
    "updated": "2025-10-29T06:08:17Z",
    "link": "http://arxiv.org/pdf/2510.24302v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Shangyu Xing",
      "Siyuan Wang",
      "Chenyuan Yang",
      "Xinyu Dai",
      "Xiang Ren"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.04508v2",
    "title": "Adapter-state Sharing CLIP for Parameter-efficient Multimodal Sarcasm\n  Detection",
    "summary": "The growing prevalence of multimodal image-text sarcasm on social media poses\nchallenges for opinion mining systems. Existing approaches rely on full\nfine-tuning of large models, making them unsuitable to adapt under\nresource-constrained settings. While recent parameter-efficient fine-tuning\n(PEFT) methods offer promise, their off-the-shelf use underperforms on complex\ntasks like sarcasm detection. We propose AdS-CLIP (Adapter-state Sharing in\nCLIP), a lightweight framework built on CLIP that inserts adapters only in the\nupper layers to preserve low-level unimodal representations in the lower layers\nand introduces a novel adapter-state sharing mechanism, where textual adapters\nguide visual ones to promote efficient cross-modal learning in the upper\nlayers. Experiments on two public benchmarks demonstrate that AdS-CLIP not only\noutperforms standard PEFT methods but also existing multimodal baselines with\nsignificantly fewer trainable parameters.",
    "published": "2025-07-06T18:51:00Z",
    "updated": "2025-10-29T05:51:00Z",
    "link": "http://arxiv.org/pdf/2507.04508v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Soumyadeep Jana",
      "Sahil Danayak",
      "Sanasam Ranbir Singh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.15189v3",
    "title": "Face the Facts! Evaluating RAG-based Pipelines for Professional\n  Fact-Checking",
    "summary": "Natural Language Processing and Generation systems have recently shown the\npotential to complement and streamline the costly and time-consuming job of\nprofessional fact-checkers. In this work, we lift several constraints of\ncurrent state-of-the-art pipelines for automated fact-checking based on the\nRetrieval-Augmented Generation (RAG) paradigm. Our goal is to benchmark,\nfollowing professional fact-checking practices, RAG-based methods for the\ngeneration of verdicts - i.e., short texts discussing the veracity of a claim -\nevaluating them on stylistically complex claims and heterogeneous, yet\nreliable, knowledge bases. Our findings show a complex landscape, where, for\nexample, LLM-based retrievers outperform other retrieval techniques, though\nthey still struggle with heterogeneous knowledge bases; larger models excel in\nverdict faithfulness, while smaller models provide better context adherence,\nwith human evaluations favouring zero-shot and one-shot approaches for\ninformativeness, and fine-tuned models for emotional alignment.",
    "published": "2024-12-19T18:57:11Z",
    "updated": "2025-10-29T05:47:44Z",
    "link": "http://arxiv.org/pdf/2412.15189v3.pdf",
    "category": [
      "cs.CL",
      "cs.CY"
    ],
    "authors": [
      "Daniel Russo",
      "Stefano Menini",
      "Jacopo Staiano",
      "Marco Guerini"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.06426v2",
    "title": "S'MoRE: Structural Mixture of Residual Experts for Parameter-Efficient\n  LLM Fine-tuning",
    "summary": "Fine-tuning pre-trained large language models (LLMs) presents a dual\nchallenge of balancing parameter efficiency and model capacity. Existing\nmethods like low-rank adaptations (LoRA) are efficient but lack flexibility,\nwhile Mixture-of-Experts (MoE) enhance model capacity at the cost of more &\nunder-utilized parameters. To address these limitations, we propose Structural\nMixture of Residual Experts (S'MoRE), a novel framework that seamlessly\nintegrates the efficiency of LoRA with the flexibility of MoE. Conceptually,\nS'MoRE employs hierarchical low-rank decomposition of expert weights, yielding\nresiduals of varying orders interconnected in a multi-layer structure. By\nrouting input tokens through sub-trees of residuals, S'MoRE emulates the\ncapacity of numerous experts by instantiating and assembling just a few\nlow-rank matrices. We craft the inter-layer propagation of S'MoRE's residuals\nas a special type of Graph Neural Network (GNN), and prove that under similar\nparameter budget, S'MoRE improves structural flexibility of traditional MoE (or\nMixture-of-LoRA) by exponential order. Comprehensive theoretical analysis and\nempirical results demonstrate that S'MoRE achieves superior fine-tuning\nperformance, offering a transformative approach for efficient LLM adaptation.\nOur implementation is available at: https://github.com/ZimpleX/SMoRE-LLM.",
    "published": "2025-04-08T20:54:00Z",
    "updated": "2025-10-29T05:47:30Z",
    "link": "http://arxiv.org/pdf/2504.06426v2.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Hanqing Zeng",
      "Yinglong Xia",
      "Zhuokai Zhao",
      "Chuan Jiang",
      "Qiang Zhang",
      "Jiayi Liu",
      "Qunshu Zhang",
      "Lizhu Zhang",
      "Xiangjun Fan",
      "Benyu Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25187v1",
    "title": "Testing Cross-Lingual Text Comprehension In LLMs Using Next Sentence\n  Prediction",
    "summary": "While large language models are trained on massive datasets, this data is\nheavily skewed towards English. Does their impressive performance reflect\ngenuine ability or just this data advantage? To find out, we tested them in a\nsetting where they could not rely on data abundance: low-resource languages.\nBuilding on prior work Agarwal et al. (2025) that used Next Sentence Prediction\n(NSP) as a test, we created a large-scale benchmark with 10,000 questions each\nfor English (a high-resource language), Swahili (medium-resource), and Hausa\n(low-resource). We then tested several top models, including GPT-4 Turbo,\nGemini 1.5 Flash, and LLaMA 3 70B, to see how their performance holds up. The\nresults painted a clear picture of how levels of language resources impact\noutcomes. While all models excelled in English, their accuracy dropped in\nSwahili and fell sharply in Hausa, with LLaMA 3 struggling the most. The story\nbecame even more interesting when we introduced Chain-of-Thought (CoT)\nprompting. For the struggling LLaMA 3, CoT acted as a helpful guide,\nsignificantly boosting its accuracy. However, for the more capable GPT-4 and\nGemini, the same technique often backfired, leading to a kind of \"overthinking\"\nthat hurt their results in the cross-lingual context. This reveals that\nChain-of-Thought is not a universal solution; its effectiveness depends heavily\non the model's baseline capability and the specific context of the task. Our\nframework pinpoints LLM weaknesses, highlights when CoT helps or hinders\ncross-lingual NSP performance, and factors influencing their decisions.",
    "published": "2025-10-29T05:38:06Z",
    "updated": "2025-10-29T05:38:06Z",
    "link": "http://arxiv.org/pdf/2510.25187v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Ritesh Sunil Chavan",
      "Jack Mostow"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.05158v2",
    "title": "Steering Information Utility in Key-Value Memory for Language Model\n  Post-Training",
    "summary": "Recent advancements in language models (LMs) have marked a shift toward the\ngrowing importance of post-training. Yet, post-training approaches such as\nsupervised fine-tuning (SFT) do not guarantee the effective use of knowledge\nacquired during pretraining. We therefore introduce InfoSteer, a lightweight\nmethod that encourages parametric information utilization in LMs during\npost-training. Specifically, InfoSteer treats the feed-forward network (FFN)\nlayer as associate key-value memory and promotes the use of stored memory\nvectors via forward-pass interventions or regularization during\nbackpropagation. This simple guidance during post-training phase yields\nconsistent performance improvements across diverse model families--including\nQwen, Gemma and Llama -- spanning 15 downstream tasks in both in-distribution\n(ID) and out-of-distribution (OOD) evaluations. Beyond performance gains, we\nalso find that steered LMs can adaptively allocate information by placing more\nemphasis on generating semantically meaningful tokens, while using fewer\nresources on simple transition ones (e.g., `\\texttt{,}' or `\\texttt{and}'). Our\nwork underscores that vanilla post-training does not fully exploit the\npotential gained during pre-training, and that steering LMs in latent\nrepresentation space offers a promising approach to enhance both performance\nand interpretability. The code is available at:\nhttps://github.com/chili-lab/InfoSteer.",
    "published": "2025-07-07T16:13:21Z",
    "updated": "2025-10-29T04:59:45Z",
    "link": "http://arxiv.org/pdf/2507.05158v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Chunyuan Deng",
      "Ruidi Chang",
      "Hanjie Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25150v1",
    "title": "Explainable Disentanglement on Discrete Speech Representations for\n  Noise-Robust ASR",
    "summary": "Discrete audio representations are gaining traction in speech modeling due to\ntheir interpretability and compatibility with large language models, but are\nnot always optimized for noisy or real-world environments. Building on existing\nworks that quantize Whisper embeddings for speech-to-unit modeling, we propose\ndisentangling semantic speech content from background noise in the latent\nspace. Our end-to-end model separates clean speech in the form of codebook\ntokens, while extracting interpretable noise vectors as quantization residue\nwhich are supervised via a lightweight classifier. We show that our approach\nimproves alignment between clean/noisy speech and text, producing speech tokens\nthat display a high degree of noiseinvariance, and improves ASR performance.\nKeeping Whisper frozen, we show an 82% reduction in error rate compared to\nWhisper, and 35% improvement over baseline methods on the VBDemand test set.\nFurther analyses show that the learned token space generalizes well to both\nseen and unseen acoustic conditions.",
    "published": "2025-10-29T04:08:19Z",
    "updated": "2025-10-29T04:08:19Z",
    "link": "http://arxiv.org/pdf/2510.25150v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Shreyas Gopal",
      "Ashutosh Anshul",
      "Haoyang Li",
      "Yue Heng Yeo",
      "Hexin Liu",
      "Eng Siong Chng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.19169v2",
    "title": "OpenGuardrails: A Configurable, Unified, and Scalable Guardrails\n  Platform for Large Language Models",
    "summary": "As large language models (LLMs) are increasingly integrated into real-world\napplications, ensuring their safety, robustness, and privacy compliance has\nbecome critical. We present OpenGuardrails, the first fully open-source\nplatform that unifies large-model-based safety detection, manipulation defense,\nand deployable guardrail infrastructure. OpenGuardrails protects against three\nmajor classes of risks: (1) content-safety violations such as harmful or\nexplicit text generation, (2) model-manipulation attacks including prompt\ninjection, jailbreaks, and code-interpreter abuse, and (3) data leakage\ninvolving sensitive or private information. Unlike prior modular or rule-based\nframeworks, OpenGuardrails introduces three core innovations: (1) a\nConfigurable Policy Adaptation mechanism that allows per-request customization\nof unsafe categories and sensitivity thresholds; (2) a Unified LLM-based Guard\nArchitecture that performs both content-safety and manipulation detection\nwithin a single model; and (3) a Quantized, Scalable Model Design that\ncompresses a 14B dense base model to 3.3B via GPTQ while preserving over 98 of\nbenchmark accuracy. The system supports 119 languages, achieves\nstate-of-the-art performance across multilingual safety benchmarks, and can be\ndeployed as a secure gateway or API-based service for enterprise use. All\nmodels, datasets, and deployment scripts are released under the Apache 2.0\nlicense.",
    "published": "2025-10-22T02:02:27Z",
    "updated": "2025-10-29T03:17:43Z",
    "link": "http://arxiv.org/pdf/2510.19169v2.pdf",
    "category": [
      "cs.CR",
      "cs.CL"
    ],
    "authors": [
      "Thomas Wang",
      "Haowen Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.01617v3",
    "title": "AMAS: Adaptively Determining Communication Topology for LLM-based\n  Multi-Agent System",
    "summary": "Although large language models (LLMs) have revolutionized natural language\nprocessing capabilities, their practical implementation as autonomous\nmulti-agent systems (MAS) for industrial problem-solving encounters persistent\nbarriers. Conventional MAS architectures are fundamentally restricted by\ninflexible, hand-crafted graph topologies that lack contextual responsiveness,\nresulting in diminished efficacy across varied academic and commercial\nworkloads. To surmount these constraints, we introduce AMAS, a\nparadigm-shifting framework that redefines LLM-based MAS through a novel\ndynamic graph designer. This component autonomously identifies task-specific\noptimal graph configurations via lightweight LLM adaptation, eliminating the\nreliance on monolithic, universally applied structural templates. Instead, AMAS\nexploits the intrinsic properties of individual inputs to intelligently direct\nquery trajectories through task-optimized agent pathways. Rigorous validation\nacross question answering, mathematical deduction, and code generation\nbenchmarks confirms that AMAS systematically exceeds state-of-the-art\nsingle-agent and multi-agent approaches across diverse LLM architectures. Our\ninvestigation establishes that context-sensitive structural adaptability\nconstitutes a foundational requirement for high-performance LLM MAS\ndeployments.",
    "published": "2025-10-02T02:50:22Z",
    "updated": "2025-10-29T03:16:30Z",
    "link": "http://arxiv.org/pdf/2510.01617v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Hui Yi Leong",
      "Yuheng Li",
      "Yuqing Wu",
      "Wenwen Ouyang",
      "Wei Zhu",
      "Jiechao Gao",
      "Wei Han"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.04655v2",
    "title": "FT-MDT: Extracting Decision Trees from Medical Texts via a Novel\n  Low-rank Adaptation Method",
    "summary": "Knowledge of the medical decision process, which can be modeled as medical\ndecision trees (MDTs), is critical to building clinical decision support\nsystems. However, current MDT construction methods rely heavily on\ntime-consuming and laborious manual annotation. To address this challenge, we\npropose PI-LoRA (Path-Integrated LoRA), a novel low-rank adaptation method for\nautomatically extracting MDTs from clinical guidelines and textbooks. We\nintegrate gradient path information to capture synergistic effects between\ndifferent modules, enabling more effective and reliable rank allocation. This\nframework ensures that the most critical modules receive appropriate rank\nallocations while less important ones are pruned, resulting in a more efficient\nand accurate model for extracting medical decision trees from clinical texts.\nExtensive experiments on medical guideline datasets demonstrate that our\nPI-LoRA method significantly outperforms existing parameter-efficient\nfine-tuning approaches for the Text2MDT task, achieving better accuracy with\nsubstantially reduced model complexity. The proposed method achieves\nstate-of-the-art results while maintaining a lightweight architecture, making\nit particularly suitable for clinical decision support systems where\ncomputational resources may be limited.",
    "published": "2025-10-06T09:59:55Z",
    "updated": "2025-10-29T03:11:50Z",
    "link": "http://arxiv.org/pdf/2510.04655v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yuheng Li",
      "Jiechao Gao",
      "Wei Han",
      "Wenwen Ouyang",
      "Wei Zhu",
      "Hui Yi Leong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25117v1",
    "title": "A Survey on Unlearning in Large Language Models",
    "summary": "The advancement of Large Language Models (LLMs) has revolutionized natural\nlanguage processing, yet their training on massive corpora poses significant\nrisks, including the memorization of sensitive personal data, copyrighted\nmaterial, and knowledge that could facilitate malicious activities. To mitigate\nthese issues and align with legal and ethical standards such as the \"right to\nbe forgotten\", machine unlearning has emerged as a critical technique to\nselectively erase specific knowledge from LLMs without compromising their\noverall performance. This survey provides a systematic review of over 180\npapers on LLM unlearning published since 2021, focusing exclusively on\nlarge-scale generative models. Distinct from prior surveys, we introduce novel\ntaxonomies for both unlearning methods and evaluations. We clearly categorize\nmethods into training-time, post-training, and inference-time based on the\ntraining stage at which unlearning is applied. For evaluations, we not only\nsystematically compile existing datasets and metrics but also critically\nanalyze their advantages, disadvantages, and applicability, providing practical\nguidance to the research community. In addition, we discuss key challenges and\npromising future research directions. Our comprehensive overview aims to inform\nand guide the ongoing development of secure and reliable LLMs.",
    "published": "2025-10-29T02:34:17Z",
    "updated": "2025-10-29T02:34:17Z",
    "link": "http://arxiv.org/pdf/2510.25117v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Ruichen Qiu",
      "Jiajun Tan",
      "Jiayue Pu",
      "Honglin Wang",
      "Xiao-Shan Gao",
      "Fei Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25116v1",
    "title": "Pretraining Strategies using Monolingual and Parallel Data for\n  Low-Resource Machine Translation",
    "summary": "This research article examines the effectiveness of various pretraining\nstrategies for developing machine translation models tailored to low-resource\nlanguages. Although this work considers several low-resource languages,\nincluding Afrikaans, Swahili, and Zulu, the translation model is specifically\ndeveloped for Lingala, an under-resourced African language, building upon the\npretraining approach introduced by Reid and Artetxe (2021), originally designed\nfor high-resource languages. Through a series of comprehensive experiments, we\nexplore different pretraining methodologies, including the integration of\nmultiple languages and the use of both monolingual and parallel data during the\npretraining phase. Our findings indicate that pretraining on multiple languages\nand leveraging both monolingual and parallel data significantly enhance\ntranslation quality. This study offers valuable insights into effective\npretraining strategies for low-resource machine translation, helping to bridge\nthe performance gap between high-resource and low-resource languages. The\nresults contribute to the broader goal of developing more inclusive and\naccurate NLP models for marginalized communities and underrepresented\npopulations. The code and datasets used in this study are publicly available to\nfacilitate further research and ensure reproducibility, with the exception of\ncertain data that may no longer be accessible due to changes in public\navailability.",
    "published": "2025-10-29T02:30:18Z",
    "updated": "2025-10-29T02:30:18Z",
    "link": "http://arxiv.org/pdf/2510.25116v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Idriss Nguepi Nguefack",
      "Mara Finkelstein",
      "Toadoum Sari Sakayo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25110v1",
    "title": "DEBATE: A Large-Scale Benchmark for Role-Playing LLM Agents in\n  Multi-Agent, Long-Form Debates",
    "summary": "Accurately modeling opinion change through social interactions is crucial for\naddressing issues like misinformation and polarization. While role-playing\nlarge language models (LLMs) offer a promising way to simulate human-like\ninteractions, existing research shows that single-agent alignment does not\nguarantee authentic multi-agent group dynamics. Current LLM role-play setups\noften produce unnatural dynamics (e.g., premature convergence), without an\nempirical benchmark to measure authentic human opinion trajectories. To bridge\nthis gap, we introduce DEBATE, the first large-scale empirical benchmark\nexplicitly designed to evaluate the authenticity of the interaction between\nmulti-agent role-playing LLMs. DEBATE contains 29,417 messages from multi-round\ndebate conversations among over 2,792 U.S.-based participants discussing 107\ncontroversial topics, capturing both publicly-expressed messages and\nprivately-reported opinions. Using DEBATE, we systematically evaluate and\nidentify critical discrepancies between simulated and authentic group dynamics.\nWe further demonstrate DEBATE's utility for aligning LLMs with human behavior\nthrough supervised fine-tuning, achieving improvements in surface-level metrics\n(e.g., ROUGE-L and message length) while highlighting limitations in deeper\nsemantic alignment (e.g., semantic similarity). Our findings highlight both the\npotential and current limitations of role-playing LLM agents for realistically\nsimulating human-like social dynamics.",
    "published": "2025-10-29T02:21:10Z",
    "updated": "2025-10-29T02:21:10Z",
    "link": "http://arxiv.org/pdf/2510.25110v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yun-Shiuan Chuang",
      "Ruixuan Tu",
      "Chengtao Dai",
      "Smit Vasani",
      "Binwei Yao",
      "Michael Henry Tessler",
      "Sijia Yang",
      "Dhavan Shah",
      "Robert Hawkins",
      "Junjie Hu",
      "Timothy T. Rogers"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25087v1",
    "title": "BioCoref: Benchmarking Biomedical Coreference Resolution with LLMs",
    "summary": "Coreference resolution in biomedical texts presents unique challenges due to\ncomplex domain-specific terminology, high ambiguity in mention forms, and\nlong-distance dependencies between coreferring expressions. In this work, we\npresent a comprehensive evaluation of generative large language models (LLMs)\nfor coreference resolution in the biomedical domain. Using the CRAFT corpus as\nour benchmark, we assess the LLMs' performance with four prompting experiments\nthat vary in their use of local, contextual enrichment, and domain-specific\ncues such as abbreviations and entity dictionaries. We benchmark these\napproaches against a discriminative span-based encoder, SpanBERT, to compare\nthe efficacy of generative versus discriminative methods. Our results\ndemonstrate that while LLMs exhibit strong surface-level coreference\ncapabilities, especially when supplemented with domain-grounding prompts, their\nperformance remains sensitive to long-range context and mentions ambiguity.\nNotably, the LLaMA 8B and 17B models show superior precision and F1 scores\nunder entity-augmented prompting, highlighting the potential of lightweight\nprompt engineering for enhancing LLM utility in biomedical NLP tasks.",
    "published": "2025-10-29T01:51:00Z",
    "updated": "2025-10-29T01:51:00Z",
    "link": "http://arxiv.org/pdf/2510.25087v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Nourah M Salem",
      "Elizabeth White",
      "Michael Bada",
      "Lawrence Hunter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25069v1",
    "title": "TOPol: Capturing and Explaining Multidimensional Semantic Polarity\n  Fields and Vectors",
    "summary": "Traditional approaches to semantic polarity in computational linguistics\ntreat sentiment as a unidimensional scale, overlooking the multidimensional\nstructure of language. This work introduces TOPol (Topic-Orientation POLarity),\na semi-unsupervised framework for reconstructing and interpreting\nmultidimensional narrative polarity fields under human-on-the-loop (HoTL)\ndefined contextual boundaries (CBs). The framework embeds documents using a\ntransformer-based large language model (tLLM), applies neighbor-tuned UMAP\nprojection, and segments topics via Leiden partitioning. Given a CB between\ndiscourse regimes A and B, TOPol computes directional vectors between\ncorresponding topic-boundary centroids, yielding a polarity field that\nquantifies fine-grained semantic displacement during regime shifts. This\nvectorial representation enables assessing CB quality and detecting polarity\nchanges, guiding HoTL CB refinement. To interpret identified polarity vectors,\nthe tLLM compares their extreme points and produces contrastive labels with\nestimated coverage. Robustness analyses show that only CB definitions (the main\nHoTL-tunable parameter) significantly affect results, confirming methodological\nstability. We evaluate TOPol on two corpora: (i) U.S. Central Bank speeches\naround a macroeconomic breakpoint, capturing non-affective semantic shifts, and\n(ii) Amazon product reviews across rating strata, where affective polarity\naligns with NRC valence. Results demonstrate that TOPol consistently captures\nboth affective and non-affective polarity transitions, providing a scalable,\ngeneralizable, and interpretable framework for context-sensitive\nmultidimensional discourse analysis.",
    "published": "2025-10-29T01:14:21Z",
    "updated": "2025-10-29T01:14:21Z",
    "link": "http://arxiv.org/pdf/2510.25069v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Gabin Taibi",
      "Lucia Gomez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25064v1",
    "title": "Can LLMs Estimate Cognitive Complexity of Reading Comprehension Items?",
    "summary": "Estimating the cognitive complexity of reading comprehension (RC) items is\ncrucial for assessing item difficulty before it is administered to learners.\nUnlike syntactic and semantic features, such as passage length or semantic\nsimilarity between options, cognitive features that arise during answer\nreasoning are not readily extractable using existing NLP tools and have\ntraditionally relied on human annotation. In this study, we examine whether\nlarge language models (LLMs) can estimate the cognitive complexity of RC items\nby focusing on two dimensions-Evidence Scope and Transformation Level-that\nindicate the degree of cognitive burden involved in reasoning about the answer.\nOur experimental results demonstrate that LLMs can approximate the cognitive\ncomplexity of items, indicating their potential as tools for prior difficulty\nanalysis. Further analysis reveals a gap between LLMs' reasoning ability and\ntheir metacognitive awareness: even when they produce correct answers, they\nsometimes fail to correctly identify the features underlying their own\nreasoning process.",
    "published": "2025-10-29T01:07:26Z",
    "updated": "2025-10-29T01:07:26Z",
    "link": "http://arxiv.org/pdf/2510.25064v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Seonjeong Hwang",
      "Hyounghun Kim",
      "Gary Geunbae Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25054v1",
    "title": "Evaluating Emotion Recognition in Spoken Language Models on Emotionally\n  Incongruent Speech",
    "summary": "Advancements in spoken language processing have driven the development of\nspoken language models (SLMs), designed to achieve universal audio\nunderstanding by jointly learning text and audio representations for a wide\nrange of tasks. Although promising results have been achieved, there is growing\ndiscussion regarding these models' generalization capabilities and the extent\nto which they truly integrate audio and text modalities in their internal\nrepresentations. In this work, we evaluate four SLMs on the task of speech\nemotion recognition using a dataset of emotionally incongruent speech samples,\na condition under which the semantic content of the spoken utterance conveys\none emotion while speech expressiveness conveys another. Our results indicate\nthat SLMs rely predominantly on textual semantics rather than speech emotion to\nperform the task, indicating that text-related representations largely dominate\nover acoustic representations. We release both the code and the Emotionally\nIncongruent Synthetic Speech dataset (EMIS) to the community.",
    "published": "2025-10-29T00:45:36Z",
    "updated": "2025-10-29T00:45:36Z",
    "link": "http://arxiv.org/pdf/2510.25054v1.pdf",
    "category": [
      "cs.CL",
      "eess.AS"
    ],
    "authors": [
      "Pedro Corrêa",
      "João Lima",
      "Victor Moreno",
      "Paula Dornhofer Paro Costa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.22811v2",
    "title": "DBLPLink 2.0 -- An Entity Linker for the DBLP Scholarly Knowledge Graph",
    "summary": "In this work we present an entity linker for DBLP's 2025 version of RDF-based\nKnowledge Graph. Compared to the 2022 version, DBLP now considers publication\nvenues as a new entity type called dblp:Stream. In the earlier version of\nDBLPLink, we trained KG-embeddings and re-rankers on a dataset to produce\nentity linkings. In contrast, in this work, we develop a zero-shot entity\nlinker using LLMs using a novel method, where we re-rank candidate entities\nbased on the log-probabilities of the \"yes\" token output at the penultimate\nlayer of the LLM.",
    "published": "2025-07-30T16:29:47Z",
    "updated": "2025-10-28T21:49:54Z",
    "link": "http://arxiv.org/pdf/2507.22811v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Debayan Banerjee",
      "Tilahun Abedissa Taffa",
      "Ricardo Usbeck"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24992v1",
    "title": "POWSM: A Phonetic Open Whisper-Style Speech Foundation Model",
    "summary": "Recent advances in spoken language processing have led to substantial\nprogress in phonetic tasks such as automatic speech recognition (ASR), phone\nrecognition (PR), grapheme-to-phoneme conversion (G2P), and phoneme-to-grapheme\nconversion (P2G). Despite their conceptual similarity, these tasks have largely\nbeen studied in isolation, each relying on task-specific architectures and\ndatasets. In this paper, we introduce POWSM (Phonetic Open Whisper-style Speech\nModel), the first unified framework capable of jointly performing multiple\nphone-related tasks. POWSM enables seamless conversion between audio, text\n(graphemes), and phones, opening up new possibilities for universal and\nlow-resource speech processing. Our model outperforms or matches specialized PR\nmodels of similar size (Wav2Vec2Phoneme and ZIPA) while jointly supporting G2P,\nP2G, and ASR. Our training data, code and models are released to foster open\nscience.",
    "published": "2025-10-28T21:43:45Z",
    "updated": "2025-10-28T21:43:45Z",
    "link": "http://arxiv.org/pdf/2510.24992v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Chin-Jou Li",
      "Kalvin Chang",
      "Shikhar Bharadwaj",
      "Eunjung Yeo",
      "Kwanghee Choi",
      "Jian Zhu",
      "David Mortensen",
      "Shinji Watanabe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2405.05583v3",
    "title": "OpenFactCheck: Building, Benchmarking Customized Fact-Checking Systems\n  and Evaluating the Factuality of Claims and LLMs",
    "summary": "The increased use of large language models (LLMs) across a variety of\nreal-world applications calls for mechanisms to verify the factual accuracy of\ntheir outputs. Difficulties lie in assessing the factuality of free-form\nresponses in open domains. Also, different papers use disparate evaluation\nbenchmarks and measurements, which renders them hard to compare and hampers\nfuture progress. To mitigate these issues, we propose OpenFactCheck, a unified\nframework for building customized automatic fact-checking systems, benchmarking\ntheir accuracy, evaluating factuality of LLMs, and verifying claims in a\ndocument. OpenFactCheck consists of three modules: (i) CUSTCHECKER allows users\nto easily customize an automatic fact-checker and verify the factual\ncorrectness of documents and claims, (ii) LLMEVAL, a unified evaluation\nframework assesses LLM's factuality ability from various perspectives fairly,\nand (iii) CHECKEREVAL is an extensible solution for gauging the reliability of\nautomatic fact-checkers' verification results using human-annotated datasets.\nData and code are publicly available at\nhttps://github.com/yuxiaw/openfactcheck.",
    "published": "2024-05-09T07:15:19Z",
    "updated": "2025-10-28T21:27:32Z",
    "link": "http://arxiv.org/pdf/2405.05583v3.pdf",
    "category": [
      "cs.CL",
      "I.2.7"
    ],
    "authors": [
      "Yuxia Wang",
      "Minghan Wang",
      "Hasan Iqbal",
      "Georgi Georgiev",
      "Jiahui Geng",
      "Preslav Nakov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.14040v2",
    "title": "Quantifying Phonosemantic Iconicity Distributionally in 6 Languages",
    "summary": "Language is, as commonly theorized, largely arbitrary. Yet, systematic\nrelationships between phonetics and semantics have been observed in many\nspecific cases. To what degree could those systematic relationships manifest\nthemselves in large scale, quantitative investigations--both in previously\nidentified and unidentified phenomena? This work undertakes a distributional\napproach to quantifying phonosemantic iconicity at scale across 6 diverse\nlanguages (English, Spanish, Hindi, Finnish, Turkish, and Tamil). In each\nlanguage, we analyze the alignment of morphemes' phonetic and semantic\nsimilarity spaces with a suite of statistical measures, and discover an array\nof interpretable phonosemantic alignments not previously identified in the\nliterature, along with crosslinguistic patterns. We also analyze 5 previously\nhypothesized phonosemantic alignments, finding support for some such alignments\nand mixed results for others.",
    "published": "2025-10-15T19:23:12Z",
    "updated": "2025-10-28T21:10:02Z",
    "link": "http://arxiv.org/pdf/2510.14040v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "George Flint",
      "Kaustubh Kislay"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.15063v2",
    "title": "UrduFactCheck: An Agentic Fact-Checking Framework for Urdu with Evidence\n  Boosting and Benchmarking",
    "summary": "The rapid adoption of Large Language Models (LLMs) has raised important\nconcerns about the factual reliability of their outputs, particularly in\nlow-resource languages such as Urdu. Existing automated fact-checking systems\nare predominantly developed for English, leaving a significant gap for the more\nthan 200 million Urdu speakers worldwide. In this work, we present\nUrduFactBench and UrduFactQA, two novel hand-annotated benchmarks designed to\nenable fact-checking and factual consistency evaluation in Urdu. While\nUrduFactBench focuses on claim verification, UrduFactQA targets the factuality\nof LLMs in question answering. These resources, the first of their kind for\nUrdu, were developed through a multi-stage annotation process involving native\nUrdu speakers. To complement these benchmarks, we introduce UrduFactCheck, a\nmodular fact-checking framework that incorporates both monolingual and\ntranslation-based evidence retrieval strategies to mitigate the scarcity of\nhigh-quality Urdu evidence. Leveraging these resources, we conduct an extensive\nevaluation of twelve LLMs and demonstrate that translation-augmented pipelines\nconsistently enhance performance compared to monolingual ones. Our findings\nreveal persistent challenges for open-source LLMs in Urdu and underscore the\nimportance of developing targeted resources. All code and data are publicly\navailable at https://github.com/mbzuai-nlp/UrduFactCheck.",
    "published": "2025-05-21T03:31:44Z",
    "updated": "2025-10-28T20:55:49Z",
    "link": "http://arxiv.org/pdf/2505.15063v2.pdf",
    "category": [
      "cs.CL",
      "I.2.7"
    ],
    "authors": [
      "Sarfraz Ahmad",
      "Hasan Iqbal",
      "Momina Ahsan",
      "Numaan Naeem",
      "Muhammad Ahsan Riaz Khan",
      "Arham Riaz",
      "Muhammad Arslan Manzoor",
      "Yuxia Wang",
      "Preslav Nakov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24963v1",
    "title": "Language Model Behavioral Phases are Consistent Across Architecture,\n  Training Data, and Scale",
    "summary": "We show that across architecture (Transformer vs. Mamba vs. RWKV), training\ndataset (OpenWebText vs. The Pile), and scale (14 million parameters to 12\nbillion parameters), autoregressive language models exhibit highly consistent\npatterns of change in their behavior over the course of pretraining. Based on\nour analysis of over 1,400 language model checkpoints on over 110,000 tokens of\nEnglish, we find that up to 98% of the variance in language model behavior at\nthe word level can be explained by three simple heuristics: the unigram\nprobability (frequency) of a given word, the $n$-gram probability of the word,\nand the semantic similarity between the word and its context. Furthermore, we\nsee consistent behavioral phases in all language models, with their predicted\nprobabilities for words overfitting to those words' $n$-gram probabilities for\nincreasing $n$ over the course of training. Taken together, these results\nsuggest that learning in neural language models may follow a similar trajectory\nirrespective of model details.",
    "published": "2025-10-28T20:51:01Z",
    "updated": "2025-10-28T20:51:01Z",
    "link": "http://arxiv.org/pdf/2510.24963v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "James A. Michaelov",
      "Roger P. Levy",
      "Benjamin K. Bergen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2304.07619v6",
    "title": "Can ChatGPT Forecast Stock Price Movements? Return Predictability and\n  Large Language Models",
    "summary": "We document the capability of large language models (LLMs) like ChatGPT to\npredict stock market reactions from news headlines without direct financial\ntraining. Using post-knowledge-cutoff headlines, GPT-4 captures initial market\nresponses, achieving approximately 90% portfolio-day hit rates for the\nnon-tradable initial reaction. GPT-4 scores also significantly predict the\nsubsequent drift, especially for small stocks and negative news. Forecasting\nability generally increases with model size, suggesting that financial\nreasoning is an emerging capacity of complex LLMs. Strategy returns decline as\nLLM adoption rises, consistent with improved price efficiency. To rationalize\nthese findings, we develop a theoretical model that incorporates LLM\ntechnology, information-processing capacity constraints, underreaction, and\nlimits to arbitrage.",
    "published": "2023-04-15T19:22:37Z",
    "updated": "2025-10-28T20:24:07Z",
    "link": "http://arxiv.org/pdf/2304.07619v6.pdf",
    "category": [
      "q-fin.ST",
      "cs.CL"
    ],
    "authors": [
      "Alejandro Lopez-Lira",
      "Yuehua Tang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.01367v3",
    "title": "MMD-Flagger: Leveraging Maximum Mean Discrepancy to Detect\n  Hallucinations",
    "summary": "Large language models (LLMs) have become pervasive in our everyday life. Yet,\na fundamental obstacle prevents their use in many critical applications: their\npropensity to generate fluent, human-quality content that is not grounded in\nreality. The detection of such hallucinations is thus of the highest\nimportance. In this work, we propose a new method to flag hallucinated content:\nMMD-Flagger. It relies on Maximum Mean Discrepancy (MMD), a non-parametric\ndistance between distributions. On a high-level perspective, MMD-Flagger tracks\nthe MMD between the output to inspect and counterparts generated with various\ntemperature parameters. We show empirically that inspecting the shape of this\ntrajectory is sufficient to detect most hallucinations. This novel method is\nbenchmarked on machine translation and summarization datasets, on which it\nexhibits competitive performance relative to natural competitors.",
    "published": "2025-06-02T06:50:58Z",
    "updated": "2025-10-28T20:23:50Z",
    "link": "http://arxiv.org/pdf/2506.01367v3.pdf",
    "category": [
      "cs.CL",
      "stat.ML"
    ],
    "authors": [
      "Kensuke Mitsuzawa",
      "Damien Garreau"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24940v1",
    "title": "SemCoT: Accelerating Chain-of-Thought Reasoning through\n  Semantically-Aligned Implicit Tokens",
    "summary": "The verbosity of Chain-of-Thought (CoT) reasoning hinders its mass deployment\nin efficiency-critical applications. Recently, implicit CoT approaches have\nemerged, which encode reasoning steps within LLM's hidden embeddings (termed\n``implicit reasoning'') rather than explicit tokens. This approach accelerates\nCoT by reducing the reasoning length and bypassing some LLM components.\nHowever, existing implicit CoT methods face two significant challenges: (1)\nthey fail to preserve the semantic alignment between the implicit reasoning\n(when transformed to natural language) and the ground-truth reasoning,\nresulting in a significant CoT performance degradation, and (2) they focus on\nreducing the length of the implicit reasoning; however, they neglect the\nconsiderable time cost for an LLM to generate one individual implicit reasoning\ntoken. To tackle these challenges, we propose a novel semantically-aligned\nimplicit CoT framework termed SemCoT. In particular, for the first challenge,\nwe design a contrastively trained sentence transformer that evaluates semantic\nalignment between implicit and explicit reasoning, which is used to enforce\nsemantic preservation during implicit reasoning optimization. To address the\nsecond challenge, we introduce an efficient implicit reasoning generator by\nfinetuning a lightweight language model using knowledge distillation. This\ngenerator is guided by our sentence transformer to distill ground-truth\nreasoning into semantically aligned implicit reasoning, while also optimizing\nfor accuracy. SemCoT is the first approach that enhances CoT efficiency by\njointly optimizing token-level generation speed and preserving semantic\nalignment with ground-truth reasoning. Extensive experiments demonstrate the\nsuperior performance of SemCoT compared to state-of-the-art methods in both\nefficiency and effectiveness. Our code can be found at\nhttps://github.com/YinhanHe123/SemCoT/.",
    "published": "2025-10-28T20:11:54Z",
    "updated": "2025-10-28T20:11:54Z",
    "link": "http://arxiv.org/pdf/2510.24940v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yinhan He",
      "Wendy Zheng",
      "Yaochen Zhu",
      "Zaiyi Zheng",
      "Lin Su",
      "Sriram Vasudevan",
      "Qi Guo",
      "Liangjie Hong",
      "Jundong Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2307.02103v3",
    "title": "Do predictability factors towards signing avatars hold across cultures?",
    "summary": "Avatar technology can offer accessibility possibilities and improve the\nDeaf-and-Hard of Hearing sign language users access to communication, education\nand services, such as the healthcare system. However, sign language users\nacceptance of signing avatars as well as their attitudes towards them vary and\ndepend on many factors. Furthermore, research on avatar technology is mostly\ndone by researchers who are not Deaf. The study examines the extent to which\nintrinsic or extrinsic factors contribute to predict the attitude towards\navatars across cultures. Intrinsic factors include the characteristics of the\navatar, such as appearance, movements and facial expressions. Extrinsic factors\ninclude users technology experience, their hearing status, age and their sign\nlanguage fluency. This work attempts to answer questions such as, if lower\nattitude ratings are related to poor technology experience with ASL users, for\nexample, is that also true for Moroccan Sign Language (MSL) users? For the\npurposes of the study, we designed a questionnaire to understand MSL users\nattitude towards avatars. Three groups of participants were surveyed: Deaf\n(57), Hearing (20) and Hard-of-Hearing (3). The results of our study were then\ncompared with those reported in other relevant studies.",
    "published": "2023-07-05T08:22:46Z",
    "updated": "2025-10-28T20:08:46Z",
    "link": "http://arxiv.org/pdf/2307.02103v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Abdelhadi Soudi",
      "Manal El Hakkaoui",
      "Kristof Van Laerhoven"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24934v1",
    "title": "Disaggregation Reveals Hidden Training Dynamics: The Case of Agreement\n  Attraction",
    "summary": "Language models generally produce grammatical text, but they are more likely\nto make errors in certain contexts. Drawing on paradigms from\npsycholinguistics, we carry out a fine-grained analysis of those errors in\ndifferent syntactic contexts. We demonstrate that by disaggregating over the\nconditions of carefully constructed datasets and comparing model performance on\neach over the course of training, it is possible to better understand the\nintermediate stages of grammatical learning in language models. Specifically,\nwe identify distinct phases of training where language model behavior aligns\nwith specific heuristics such as word frequency and local context rather than\ngeneralized grammatical rules. We argue that taking this approach to analyzing\nlanguage model behavior more generally can serve as a powerful tool for\nunderstanding the intermediate learning phases, overall training dynamics, and\nthe specific generalizations learned by language models.",
    "published": "2025-10-28T19:59:26Z",
    "updated": "2025-10-28T19:59:26Z",
    "link": "http://arxiv.org/pdf/2510.24934v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "James A. Michaelov",
      "Catherine Arnett"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24932v1",
    "title": "RiddleBench: A New Generative Reasoning Benchmark for LLMs",
    "summary": "Large Language Models have demonstrated strong performance on many\nestablished reasoning benchmarks. However, these benchmarks primarily evaluate\nstructured skills like quantitative problem-solving, leaving a gap in assessing\nflexible, multifaceted reasoning abilities that are central to human\nintelligence. These abilities require integrating logical deduction with\nspatial awareness and constraint satisfaction, which current evaluations do not\nmeasure well. To address this, we introduce RiddleBench, a benchmark of 1,737\nchallenging puzzles in English designed to probe these core reasoning\ncapabilities. Evaluation of state-of-the-art models on RiddleBench shows\nfundamental weaknesses. Even top proprietary models like Gemini 2.5 Pro, o3,\nand Claude 4 Sonnet achieve accuracy just above 60% (60.30%, 63.37%, and\n63.16%). Analysis further reveals deep failures, including hallucination\ncascades (accepting flawed reasoning from other models) and poor\nself-correction due to a strong self-confirmation bias. Their reasoning is also\nfragile, with performance degrading significantly when constraints are\nreordered or irrelevant information is introduced. RiddleBench functions as a\ndiagnostic tool for these issues and as a resource for guiding the development\nof more robust and reliable language models.",
    "published": "2025-10-28T19:58:24Z",
    "updated": "2025-10-28T19:58:24Z",
    "link": "http://arxiv.org/pdf/2510.24932v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Deepon Halder",
      "Alan Saji",
      "Thanmay Jayakumar",
      "Ratish Puduppully",
      "Anoop Kunchukuttan",
      "Raj Dabre"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24891v1",
    "title": "Idea2Plan: Exploring AI-Powered Research Planning",
    "summary": "Large language models (LLMs) have demonstrated significant potential to\naccelerate scientific discovery as valuable tools for analyzing data,\ngenerating hypotheses, and supporting innovative approaches in various\nscientific fields. In this work, we investigate how LLMs can handle the\ntransition from conceptual research ideas to well-structured research plans.\nEffective research planning not only supports scientists in advancing their\nresearch but also represents a crucial capability for the development of\nautonomous research agents. Despite its importance, the field lacks a\nsystematic understanding of LLMs' research planning capability. To rigorously\nmeasure this capability, we introduce the Idea2Plan task and Idea2Plan Bench, a\nbenchmark built from 200 ICML 2025 Spotlight and Oral papers released after\nmajor LLM training cutoffs. Each benchmark instance includes a research idea\nand a grading rubric capturing the key components of valid plans. We further\npropose Idea2Plan JudgeEval, a complementary benchmark to assess the\nreliability of LLM-based judges against expert annotations. Experimental\nresults show that GPT-5 and GPT-5-mini achieve the strongest performance on the\nbenchmark, though substantial headroom remains for future improvement. Our\nstudy provides new insights into LLMs' capability for research planning and lay\nthe groundwork for future progress.",
    "published": "2025-10-28T18:54:51Z",
    "updated": "2025-10-28T18:54:51Z",
    "link": "http://arxiv.org/pdf/2510.24891v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Jin Huang",
      "Silviu Cucerzan",
      "Sujay Kumar Jauhar",
      "Ryen W. White"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.21112v2",
    "title": "InsurTech innovation using natural language processing",
    "summary": "With the rapid rise of InsurTech, traditional insurance companies are\nincreasingly exploring alternative data sources and advanced technologies to\nsustain their competitive edge. This paper provides both a conceptual overview\nand practical case studies of natural language processing (NLP) and its\nemerging applications within insurance operations, focusing on transforming\nraw, unstructured text into structured data suitable for actuarial analysis and\ndecision-making. Leveraging real-world alternative data provided by an\nInsurTech industry partner that enriches traditional insurance data sources, we\napply various NLP techniques to demonstrate feature de-biasing, feature\ncompression, and industry classification in the commercial insurance context.\nThese enriched, text-derived insights not only add to and refine traditional\nrating factors for commercial insurance pricing but also offer novel\nperspectives for assessing underlying risk by introducing novel industry\nclassification techniques. Through these demonstrations, we show that NLP is\nnot merely a supplementary tool but a foundational element of modern,\ndata-driven insurance analytics.",
    "published": "2025-07-12T23:10:59Z",
    "updated": "2025-10-28T18:52:14Z",
    "link": "http://arxiv.org/pdf/2507.21112v2.pdf",
    "category": [
      "cs.CL",
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Panyi Dong",
      "Zhiyu Quan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24870v1",
    "title": "Seeing Through the MiRAGE: Evaluating Multimodal Retrieval Augmented\n  Generation",
    "summary": "We introduce MiRAGE, an evaluation framework for retrieval-augmented\ngeneration (RAG) from multimodal sources. As audiovisual media becomes a\nprevalent source of information online, it is essential for RAG systems to\nintegrate information from these sources into generation. However, existing\nevaluations for RAG are text-centric, limiting their applicability to\nmultimodal, reasoning intensive settings because they don't verify information\nagainst sources. MiRAGE is a claim-centric approach to multimodal RAG\nevaluation, consisting of InfoF1, evaluating factuality and information\ncoverage, and CiteF1, measuring citation support and completeness. We show that\nMiRAGE, when applied by humans, strongly aligns with extrinsic quality\njudgments. We additionally introduce automatic variants of MiRAGE and three\nprominent TextRAG metrics -- ACLE, ARGUE, and RAGAS -- demonstrating the\nlimitations of text-centric work and laying the groundwork for automatic\nevaluation. We release open-source implementations and outline how to assess\nmultimodal RAG.",
    "published": "2025-10-28T18:21:19Z",
    "updated": "2025-10-28T18:21:19Z",
    "link": "http://arxiv.org/pdf/2510.24870v1.pdf",
    "category": [
      "cs.CL",
      "cs.CV",
      "cs.IR"
    ],
    "authors": [
      "Alexander Martin",
      "William Walden",
      "Reno Kriz",
      "Dengjia Zhang",
      "Kate Sanders",
      "Eugene Yang",
      "Chihsheng Jin",
      "Benjamin Van Durme"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24856v1",
    "title": "Do Large Language Models Grasp The Grammar? Evidence from\n  Grammar-Book-Guided Probing in Luxembourgish",
    "summary": "Grammar refers to the system of rules that governs the structural\norganization and the semantic relations among linguistic units such as\nsentences, phrases, and words within a given language. In natural language\nprocessing, there remains a notable scarcity of grammar focused evaluation\nprotocols, a gap that is even more pronounced for low-resource languages.\nMoreover, the extent to which large language models genuinely comprehend\ngrammatical structure, especially the mapping between syntactic structures and\nmeanings, remains under debate. To investigate this issue, we propose a Grammar\nBook Guided evaluation pipeline intended to provide a systematic and\ngeneralizable framework for grammar evaluation consisting of four key stages,\nand in this work we take Luxembourgish as a case study. The results show a weak\npositive correlation between translation performance and grammatical\nunderstanding, indicating that strong translations do not necessarily imply\ndeep grammatical competence. Larger models perform well overall due to their\nsemantic strength but remain weak in morphology and syntax, struggling\nparticularly with Minimal Pair tasks, while strong reasoning ability offers a\npromising way to enhance their grammatical understanding.",
    "published": "2025-10-28T18:02:51Z",
    "updated": "2025-10-28T18:02:51Z",
    "link": "http://arxiv.org/pdf/2510.24856v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Lujun Li",
      "Yewei Song",
      "Lama Sleem",
      "Yiqun Wang",
      "Yangjie Xu",
      "Cedric Lothritz",
      "Niccolo Gentile",
      "Radu State",
      "Tegawende F. Bissyande",
      "Jacques Klein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25772v1",
    "title": "VFXMaster: Unlocking Dynamic Visual Effect Generation via In-Context\n  Learning",
    "summary": "Visual effects (VFX) are crucial to the expressive power of digital media,\nyet their creation remains a major challenge for generative AI. Prevailing\nmethods often rely on the one-LoRA-per-effect paradigm, which is\nresource-intensive and fundamentally incapable of generalizing to unseen\neffects, thus limiting scalability and creation. To address this challenge, we\nintroduce VFXMaster, the first unified, reference-based framework for VFX video\ngeneration. It recasts effect generation as an in-context learning task,\nenabling it to reproduce diverse dynamic effects from a reference video onto\ntarget content. In addition, it demonstrates remarkable generalization to\nunseen effect categories. Specifically, we design an in-context conditioning\nstrategy that prompts the model with a reference example. An in-context\nattention mask is designed to precisely decouple and inject the essential\neffect attributes, allowing a single unified model to master the effect\nimitation without information leakage. In addition, we propose an efficient\none-shot effect adaptation mechanism to boost generalization capability on\ntough unseen effects from a single user-provided video rapidly. Extensive\nexperiments demonstrate that our method effectively imitates various categories\nof effect information and exhibits outstanding generalization to out-of-domain\neffects. To foster future research, we will release our code, models, and a\ncomprehensive dataset to the community.",
    "published": "2025-10-29T17:59:53Z",
    "updated": "2025-10-29T17:59:53Z",
    "link": "http://arxiv.org/pdf/2510.25772v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Baolu Li",
      "Yiming Zhang",
      "Qinghe Wang",
      "Liqian Ma",
      "Xiaoyu Shi",
      "Xintao Wang",
      "Pengfei Wan",
      "Zhenfei Yin",
      "Yunzhi Zhuge",
      "Huchuan Lu",
      "Xu Jia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25765v1",
    "title": "FreeArt3D: Training-Free Articulated Object Generation using 3D\n  Diffusion",
    "summary": "Articulated 3D objects are central to many applications in robotics, AR/VR,\nand animation. Recent approaches to modeling such objects either rely on\noptimization-based reconstruction pipelines that require dense-view supervision\nor on feed-forward generative models that produce coarse geometric\napproximations and often overlook surface texture. In contrast, open-world 3D\ngeneration of static objects has achieved remarkable success, especially with\nthe advent of native 3D diffusion models such as Trellis. However, extending\nthese methods to articulated objects by training native 3D diffusion models\nposes significant challenges. In this work, we present FreeArt3D, a\ntraining-free framework for articulated 3D object generation. Instead of\ntraining a new model on limited articulated data, FreeArt3D repurposes a\npre-trained static 3D diffusion model (e.g., Trellis) as a powerful shape\nprior. It extends Score Distillation Sampling (SDS) into the 3D-to-4D domain by\ntreating articulation as an additional generative dimension. Given a few images\ncaptured in different articulation states, FreeArt3D jointly optimizes the\nobject's geometry, texture, and articulation parameters without requiring\ntask-specific training or access to large-scale articulated datasets. Our\nmethod generates high-fidelity geometry and textures, accurately predicts\nunderlying kinematic structures, and generalizes well across diverse object\ncategories. Despite following a per-instance optimization paradigm, FreeArt3D\ncompletes in minutes and significantly outperforms prior state-of-the-art\napproaches in both quality and versatility.",
    "published": "2025-10-29T17:58:14Z",
    "updated": "2025-10-29T17:58:14Z",
    "link": "http://arxiv.org/pdf/2510.25765v1.pdf",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "Chuhao Chen",
      "Isabella Liu",
      "Xinyue Wei",
      "Hao Su",
      "Minghua Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25760v1",
    "title": "Multimodal Spatial Reasoning in the Large Model Era: A Survey and\n  Benchmarks",
    "summary": "Humans possess spatial reasoning abilities that enable them to understand\nspaces through multimodal observations, such as vision and sound. Large\nmultimodal reasoning models extend these abilities by learning to perceive and\nreason, showing promising performance across diverse spatial tasks. However,\nsystematic reviews and publicly available benchmarks for these models remain\nlimited. In this survey, we provide a comprehensive review of multimodal\nspatial reasoning tasks with large models, categorizing recent progress in\nmultimodal large language models (MLLMs) and introducing open benchmarks for\nevaluation. We begin by outlining general spatial reasoning, focusing on\npost-training techniques, explainability, and architecture. Beyond classical 2D\ntasks, we examine spatial relationship reasoning, scene and layout\nunderstanding, as well as visual question answering and grounding in 3D space.\nWe also review advances in embodied AI, including vision-language navigation\nand action models. Additionally, we consider emerging modalities such as audio\nand egocentric video, which contribute to novel spatial understanding through\nnew sensors. We believe this survey establishes a solid foundation and offers\ninsights into the growing field of multimodal spatial reasoning. Updated\ninformation about this survey, codes and implementation of the open benchmarks\ncan be found at https://github.com/zhengxuJosh/Awesome-Spatial-Reasoning.",
    "published": "2025-10-29T17:55:43Z",
    "updated": "2025-10-29T17:55:43Z",
    "link": "http://arxiv.org/pdf/2510.25760v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xu Zheng",
      "Zihao Dongfang",
      "Lutao Jiang",
      "Boyuan Zheng",
      "Yulong Guo",
      "Zhenquan Zhang",
      "Giuliano Albanese",
      "Runyi Yang",
      "Mengjiao Ma",
      "Zixin Zhang",
      "Chenfei Liao",
      "Dingcheng Zhen",
      "Yuanhuiyi Lyu",
      "Yuqian Fu",
      "Bin Ren",
      "Linfeng Zhang",
      "Danda Pani Paudel",
      "Nicu Sebe",
      "Luc Van Gool",
      "Xuming Hu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25739v1",
    "title": "Hawk: Leveraging Spatial Context for Faster Autoregressive Text-to-Image\n  Generation",
    "summary": "Autoregressive (AR) image generation models are capable of producing\nhigh-fidelity images but often suffer from slow inference due to their\ninherently sequential, token-by-token decoding process. Speculative decoding,\nwhich employs a lightweight draft model to approximate the output of a larger\nAR model, has shown promise in accelerating text generation without\ncompromising quality. However, its application to image generation remains\nlargely underexplored. The challenges stem from a significantly larger sampling\nspace, which complicates the alignment between the draft and target model\noutputs, coupled with the inadequate use of the two-dimensional spatial\nstructure inherent in images, thereby limiting the modeling of local\ndependencies. To overcome these challenges, we introduce Hawk, a new approach\nthat harnesses the spatial structure of images to guide the speculative model\ntoward more accurate and efficient predictions. Experimental results on\nmultiple text-to-image benchmarks demonstrate a 1.71x speedup over standard AR\nmodels, while preserving both image fidelity and diversity.",
    "published": "2025-10-29T17:43:31Z",
    "updated": "2025-10-29T17:43:31Z",
    "link": "http://arxiv.org/pdf/2510.25739v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Zhi-Kai Chen",
      "Jun-Peng Jiang",
      "Han-Jia Ye",
      "De-Chuan Zhan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.20600v2",
    "title": "GENRE-CMR: Generalizable Deep Learning for Diverse Multi-Domain Cardiac\n  MRI Reconstruction",
    "summary": "Accelerated Cardiovascular Magnetic Resonance (CMR) image reconstruction\nremains a critical challenge due to the trade-off between scan time and image\nquality, particularly when generalizing across diverse acquisition settings. We\npropose GENRE-CMR, a generative adversarial network (GAN)-based architecture\nemploying a residual deep unrolled reconstruction framework to enhance\nreconstruction fidelity and generalization. The architecture unrolls iterative\noptimization into a cascade of convolutional subnetworks, enriched with\nresidual connections to enable progressive feature propagation from shallow to\ndeeper stages. To further improve performance, we integrate two loss functions:\n(1) an Edge-Aware Region (EAR) loss, which guides the network to focus on\nstructurally informative regions and helps prevent common reconstruction\nblurriness; and (2) a Statistical Distribution Alignment (SDA) loss, which\nregularizes the feature space across diverse data distributions via a symmetric\nKL divergence formulation. Extensive experiments confirm that GENRE-CMR\nsurpasses state-of-the-art methods on training and unseen data, achieving\n0.9552 SSIM and 38.90 dB PSNR on unseen distributions across various\nacceleration factors and sampling trajectories. Ablation studies confirm the\ncontribution of each proposed component to reconstruction quality and\ngeneralization. Our framework presents a unified and robust solution for\nhigh-quality CMR reconstruction, paving the way for clinically adaptable\ndeployment across heterogeneous acquisition protocols.",
    "published": "2025-08-28T09:43:59Z",
    "updated": "2025-10-29T17:35:15Z",
    "link": "http://arxiv.org/pdf/2508.20600v2.pdf",
    "category": [
      "eess.IV",
      "cs.CV"
    ],
    "authors": [
      "Kian Anvari Hamedani",
      "Narges Razizadeh",
      "Shahabedin Nabavi",
      "Mohsen Ebrahimi Moghaddam"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.24096v2",
    "title": "MILo: Mesh-In-the-Loop Gaussian Splatting for Detailed and Efficient\n  Surface Reconstruction",
    "summary": "While recent advances in Gaussian Splatting have enabled fast reconstruction\nof high-quality 3D scenes from images, extracting accurate surface meshes\nremains a challenge. Current approaches extract the surface through costly\npost-processing steps, resulting in the loss of fine geometric details or\nrequiring significant time and leading to very dense meshes with millions of\nvertices. More fundamentally, the a posteriori conversion from a volumetric to\na surface representation limits the ability of the final mesh to preserve all\ngeometric structures captured during training. We present MILo, a novel\nGaussian Splatting framework that bridges the gap between volumetric and\nsurface representations by differentiably extracting a mesh from the 3D\nGaussians. We design a fully differentiable procedure that constructs the\nmesh-including both vertex locations and connectivity-at every iteration\ndirectly from the parameters of the Gaussians, which are the only quantities\noptimized during training. Our method introduces three key technical\ncontributions: a bidirectional consistency framework ensuring both\nrepresentations-Gaussians and the extracted mesh-capture the same underlying\ngeometry during training; an adaptive mesh extraction process performed at each\ntraining iteration, which uses Gaussians as differentiable pivots for Delaunay\ntriangulation; a novel method for computing signed distance values from the 3D\nGaussians that enables precise surface extraction while avoiding geometric\nerosion. Our approach can reconstruct complete scenes, including backgrounds,\nwith state-of-the-art quality while requiring an order of magnitude fewer mesh\nvertices than previous methods. Due to their light weight and empty interior,\nour meshes are well suited for downstream applications such as physics\nsimulations or animation.",
    "published": "2025-06-30T17:48:54Z",
    "updated": "2025-10-29T16:13:52Z",
    "link": "http://arxiv.org/pdf/2506.24096v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Antoine Guédon",
      "Diego Gomez",
      "Nissim Maruani",
      "Bingchen Gong",
      "George Drettakis",
      "Maks Ovsjanikov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23118v3",
    "title": "Quantizing Space and Time: Fusing Time Series and Images for Earth\n  Observation",
    "summary": "We propose a task-agnostic framework for multimodal fusion of time series and\nsingle timestamp images, enabling cross-modal generation and robust downstream\nperformance. Our approach explores deterministic and learned strategies for\ntime series quantization and then leverages a masked correlation learning\nobjective, aligning discrete image and time series tokens in a unified\nrepresentation space. Instantiated in the Earth observation domain, the\npretrained model generates consistent global temperature profiles from\nsatellite imagery and is validated through counterfactual experiments. Across\ndownstream tasks, our task-agnostic pretraining outperforms task-specific\nfusion by 6% in R^2 and 2% in RMSE on average, and exceeds baseline methods by\n50% in R^2 and 12% in RMSE. Finally, we analyze gradient sensitivity across\nmodalities, providing insights into model robustness. Code, data, and weights\nwill be released under a permissive license.",
    "published": "2025-10-27T08:38:52Z",
    "updated": "2025-10-29T15:24:05Z",
    "link": "http://arxiv.org/pdf/2510.23118v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Gianfranco Basile",
      "Johannes Jakubik",
      "Benedikt Blumenstiel",
      "Thomas Brunschwiler",
      "Juan Bernabe Moreno"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25594v1",
    "title": "Feedback Alignment Meets Low-Rank Manifolds: A Structured Recipe for\n  Local Learning",
    "summary": "Training deep neural networks (DNNs) with backpropagation (BP) achieves\nstate-of-the-art accuracy but requires global error propagation and full\nparameterization, leading to substantial memory and computational overhead.\nDirect Feedback Alignment (DFA) enables local, parallelizable updates with\nlower memory requirements but is limited by unstructured feedback and poor\nscalability in deeper architectures, specially convolutional neural networks.\nTo address these limitations, we propose a structured local learning framework\nthat operates directly on low-rank manifolds defined by the Singular Value\nDecomposition (SVD) of weight matrices. Each layer is trained in its decomposed\nform, with updates applied to the SVD components using a composite loss that\nintegrates cross-entropy, subspace alignment, and orthogonality regularization.\nFeedback matrices are constructed to match the SVD structure, ensuring\nconsistent alignment between forward and feedback pathways. Our method reduces\nthe number of trainable parameters relative to the original DFA model, without\nrelying on pruning or post hoc compression. Experiments on CIFAR-10, CIFAR-100,\nand ImageNet show that our method achieves accuracy comparable to that of BP.\nAblation studies confirm the importance of each loss term in the low-rank\nsetting. These results establish local learning on low-rank manifolds as a\nprincipled and scalable alternative to full-rank gradient-based training.",
    "published": "2025-10-29T15:03:46Z",
    "updated": "2025-10-29T15:03:46Z",
    "link": "http://arxiv.org/pdf/2510.25594v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Arani Roy",
      "Marco P. Apolinario",
      "Shristi Das Biswas",
      "Kaushik Roy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.21710v2",
    "title": "FOCUS: Internal MLLM Representations for Efficient Fine-Grained Visual\n  Question Answering",
    "summary": "While Multimodal Large Language Models (MLLMs) offer strong perception and\nreasoning capabilities for image-text input, Visual Question Answering (VQA)\nfocusing on small image details still remains a challenge. Although visual\ncropping techniques seem promising, recent approaches have several limitations:\nthe need for task-specific fine-tuning, low efficiency due to uninformed\nexhaustive search, or incompatibility with efficient attention implementations.\nWe address these shortcomings by proposing a training-free visual cropping\nmethod, dubbed FOCUS, that leverages MLLM-internal representations to guide the\nsearch for the most relevant image region. This is accomplished in four steps:\nfirst, we identify the target object(s) in the VQA prompt; second, we compute\nan object relevance map using the key-value (KV) cache; third, we propose and\nrank relevant image regions based on the map; and finally, we perform the\nfine-grained VQA task using the top-ranked region. As a result of this informed\nsearch strategy, FOCUS achieves strong performance across four fine-grained VQA\ndatasets and three types of MLLMs. It outperforms three popular visual cropping\nmethods in both accuracy and efficiency, and matches the best-performing\nbaseline, ZoomEye, while requiring 3 - 6.5 x less compute.",
    "published": "2025-06-26T18:51:04Z",
    "updated": "2025-10-29T14:46:17Z",
    "link": "http://arxiv.org/pdf/2506.21710v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Liangyu Zhong",
      "Fabio Rosenthal",
      "Joachim Sicking",
      "Fabian Hüger",
      "Thorsten Bagdonat",
      "Hanno Gottschalk",
      "Leo Schwinn"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.10237v2",
    "title": "ScribbleVS: Scribble-Supervised Medical Image Segmentation via Dynamic\n  Competitive Pseudo Label Selection",
    "summary": "In clinical medicine, precise image segmentation can provide substantial\nsupport to clinicians. However, obtaining high-quality segmentation typically\ndemands extensive pixel-level annotations, which are labor-intensive and\nexpensive. Scribble annotations offer a more cost-effective alternative by\nimproving labeling efficiency. Nonetheless, using such sparse supervision for\ntraining reliable medical image segmentation models remains a significant\nchallenge. Some studies employ pseudo-labeling to enhance supervision, but\nthese methods are susceptible to noise interference. To address these\nchallenges, we introduce ScribbleVS, a framework designed to learn from\nscribble annotations. We introduce a Regional Pseudo Labels Diffusion Module to\nexpand the scope of supervision and reduce the impact of noise present in\npseudo labels. Additionally, we introduce a Dynamic Competitive Selection\nmodule for enhanced refinement in selecting pseudo labels. Experiments\nconducted on the ACDC, MSCMRseg, WORD, and BraTS2020 datasets demonstrate\npromising results, achieving segmentation precision comparable to fully\nsupervised models. The codes of this study are available at\nhttps://github.com/ortonwang/ScribbleVS.",
    "published": "2024-11-15T14:51:30Z",
    "updated": "2025-10-29T13:22:04Z",
    "link": "http://arxiv.org/pdf/2411.10237v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Tao Wang",
      "Xinlin Zhang",
      "Zhenxuan Zhang",
      "Yuanbo Zhou",
      "Yuanbin Chen",
      "Longxuan Zhao",
      "Chaohui Xu",
      "Shun Chen",
      "Guang Yang",
      "Tong Tong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.09518v2",
    "title": "HAIF-GS: Hierarchical and Induced Flow-Guided Gaussian Splatting for\n  Dynamic Scene",
    "summary": "Reconstructing dynamic 3D scenes from monocular videos remains a fundamental\nchallenge in 3D vision. While 3D Gaussian Splatting (3DGS) achieves real-time\nrendering in static settings, extending it to dynamic scenes is challenging due\nto the difficulty of learning structured and temporally consistent motion\nrepresentations. This challenge often manifests as three limitations in\nexisting methods: redundant Gaussian updates, insufficient motion supervision,\nand weak modeling of complex non-rigid deformations. These issues collectively\nhinder coherent and efficient dynamic reconstruction. To address these\nlimitations, we propose HAIF-GS, a unified framework that enables structured\nand consistent dynamic modeling through sparse anchor-driven deformation. It\nfirst identifies motion-relevant regions via an Anchor Filter to suppress\nredundant updates in static areas. A self-supervised Induced Flow-Guided\nDeformation module induces anchor motion using multi-frame feature aggregation,\neliminating the need for explicit flow labels. To further handle fine-grained\ndeformations, a Hierarchical Anchor Propagation mechanism increases anchor\nresolution based on motion complexity and propagates multi-level\ntransformations. Extensive experiments on synthetic and real-world benchmarks\nvalidate that HAIF-GS significantly outperforms prior dynamic 3DGS methods in\nrendering quality, temporal coherence, and reconstruction efficiency.",
    "published": "2025-06-11T08:45:08Z",
    "updated": "2025-10-29T13:12:44Z",
    "link": "http://arxiv.org/pdf/2506.09518v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jianing Chen",
      "Zehao Li",
      "Yujun Cai",
      "Hao Jiang",
      "Chengxuan Qian",
      "Juyuan Kang",
      "Shuqin Gao",
      "Honglong Zhao",
      "Tianlu Mao",
      "Yucheng Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.08068v2",
    "title": "Simulating Automotive Radar with Lidar and Camera Inputs",
    "summary": "Low-cost millimeter automotive radar has received more and more attention due\nto its ability to handle adverse weather and lighting conditions in autonomous\ndriving. However, the lack of quality datasets hinders research and\ndevelopment. We report a new method that is able to simulate 4D millimeter wave\nradar signals including pitch, yaw, range, and Doppler velocity along with\nradar signal strength (RSS) using camera image, light detection and ranging\n(lidar) point cloud, and ego-velocity. The method is based on two new neural\nnetworks: 1) DIS-Net, which estimates the spatial distribution and number of\nradar signals, and 2) RSS-Net, which predicts the RSS of the signal based on\nappearance and geometric information. We have implemented and tested our method\nusing open datasets from 3 different models of commercial automotive radar. The\nexperimental results show that our method can successfully generate\nhigh-fidelity radar signals. Moreover, we have trained a popular object\ndetection neural network with data augmented by our synthesized radar. The\nnetwork outperforms the counterpart trained only on raw radar data, a promising\nresult to facilitate future radar-based research and development.",
    "published": "2025-03-11T05:59:43Z",
    "updated": "2025-10-29T12:57:01Z",
    "link": "http://arxiv.org/pdf/2503.08068v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Peili Song",
      "Dezhen Song",
      "Yifan Yang",
      "Enfan Lan",
      "Jingtai Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.17685v2",
    "title": "FutureSightDrive: Thinking Visually with Spatio-Temporal CoT for\n  Autonomous Driving",
    "summary": "Vision-Language-Action (VLA) models are increasingly used for end-to-end\ndriving due to their world knowledge and reasoning ability. Most prior work,\nhowever, inserts textual chains-of-thought (CoT) as intermediate steps tailored\nto the current scene. Such symbolic compressions can blur spatio-temporal\nrelations and discard fine visual cues, creating a cross-modal gap between\nperception and planning. We propose FSDrive, a visual spatio-temporal CoT\nframework that enables VLAs to think in images. The model first acts as a world\nmodel to generate a unified future frame that overlays coarse but\nphysically-plausible priors-future lane dividers and 3D boxes-on the predicted\nfuture image. This unified frame serves as the visual CoT, capturing both\nspatial structure and temporal evolution. The same VLA then functions as an\ninverse-dynamics model, planning trajectories from current observations and the\nvisual CoT. To equip VLAs with image generation while preserving understanding,\nwe introduce a unified pre-training paradigm that expands the vocabulary to\ninclude visual tokens and jointly optimizes VQA (for semantics) and\nfuture-frame prediction (for dynamics). A progressive easy-to-hard scheme first\npredicts lane/box priors to enforce physical constraints, then completes full\nfuture frames for fine details. On nuScenes and NAVSIM, FSDrive improves\ntrajectory accuracy and reduces collisions under both ST-P3 and UniAD metrics,\nand attains competitive FID for future-frame generation despite using\nlightweight autoregression. It also advances scene understanding on DriveLM.\nTogether, these results indicate that visual CoT narrows the cross-modal gap\nand yields safer, more anticipatory planning. Code is available at\nhttps://github.com/MIV-XJTU/FSDrive.",
    "published": "2025-05-23T09:55:32Z",
    "updated": "2025-10-29T12:46:23Z",
    "link": "http://arxiv.org/pdf/2505.17685v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Shuang Zeng",
      "Xinyuan Chang",
      "Mengwei Xie",
      "Xinran Liu",
      "Yifan Bai",
      "Zheng Pan",
      "Mu Xu",
      "Xing Wei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25463v1",
    "title": "SPADE: Sparsity Adaptive Depth Estimator for Zero-Shot, Real-Time,\n  Monocular Depth Estimation in Underwater Environments",
    "summary": "Underwater infrastructure requires frequent inspection and maintenance due to\nharsh marine conditions. Current reliance on human divers or remotely operated\nvehicles is limited by perceptual and operational challenges, especially around\ncomplex structures or in turbid water. Enhancing the spatial awareness of\nunderwater vehicles is key to reducing piloting risks and enabling greater\nautonomy. To address these challenges, we present SPADE: SParsity Adaptive\nDepth Estimator, a monocular depth estimation pipeline that combines\npre-trained relative depth estimator with sparse depth priors to produce dense,\nmetric scale depth maps. Our two-stage approach first scales the relative depth\nmap with the sparse depth points, then refines the final metric prediction with\nour proposed Cascade Conv-Deformable Transformer blocks. Our approach achieves\nimproved accuracy and generalisation over state-of-the-art baselines and runs\nefficiently at over 15 FPS on embedded hardware, promising to support practical\nunderwater inspection and intervention. This work has been submitted to IEEE\nJournal of Oceanic Engineering Special Issue of AUV 2026.",
    "published": "2025-10-29T12:37:34Z",
    "updated": "2025-10-29T12:37:34Z",
    "link": "http://arxiv.org/pdf/2510.25463v1.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Hongjie Zhang",
      "Gideon Billings",
      "Stefan B. Williams"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.17897v4",
    "title": "Multimodal Recurrent Ensembles for Predicting Brain Responses to\n  Naturalistic Movies (Algonauts 2025)",
    "summary": "Accurately predicting distributed cortical responses to naturalistic stimuli\nrequires models that integrate visual, auditory and semantic information over\ntime. We present a hierarchical multimodal recurrent ensemble that maps\npretrained video, audio, and language embeddings to fMRI time series recorded\nwhile four subjects watched almost 80 hours of movies provided by the Algonauts\n2025 challenge. Modality-specific bidirectional RNNs encode temporal dynamics;\ntheir hidden states are fused and passed to a second recurrent layer, and\nlightweight subject-specific heads output responses for 1000 cortical parcels.\nTraining relies on a composite MSE-correlation loss and a curriculum that\ngradually shifts emphasis from early sensory to late association regions.\nAveraging 100 model variants further boosts robustness. The resulting system\nranked third on the competition leaderboard, achieving an overall Pearson r =\n0.2094 and the highest single-parcel peak score (mean r = 0.63) among all\nparticipants, with particularly strong gains for the most challenging subject\n(Subject 5). The approach establishes a simple, extensible baseline for future\nmultimodal brain-encoding benchmarks.",
    "published": "2025-07-23T19:48:27Z",
    "updated": "2025-10-29T12:15:39Z",
    "link": "http://arxiv.org/pdf/2507.17897v4.pdf",
    "category": [
      "q-bio.NC",
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Semih Eren",
      "Deniz Kucukahmetler",
      "Nico Scherf"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2408.05780v2",
    "title": "U-DECN: End-to-End Underwater Object Detection ConvNet with Improved\n  DeNoising Training",
    "summary": "Underwater object detection has higher requirements of running speed and\ndeployment efficiency for the detector due to its specific environmental\nchallenges. NMS of two- or one-stage object detectors and transformer\narchitecture of query-based end-to-end object detectors are not conducive to\ndeployment on underwater embedded devices with limited processing power. As for\nthe detrimental effect of underwater color cast noise, recent underwater object\ndetectors make network architecture or training complex, which also hinders\ntheir application and deployment on unmanned underwater vehicles. In this\npaper, we propose the Underwater DECO with improved deNoising training\n(U-DECN), the query-based end-to-end object detector (with ConvNet\nencoder-decoder architecture) for underwater color cast noise that addresses\nthe above problems. We integrate advanced technologies from DETR variants into\nDECO and design optimization methods specifically for the ConvNet architecture,\nincluding Deformable Convolution in SIM and Separate Contrastive DeNoising\nForward methods. To address the underwater color cast noise issue, we propose\nan Underwater Color DeNoising Query method to improve the generalization of the\nmodel for the biased object feature information by different color cast noise.\nOur U-DECN, with ResNet-50 backbone, achieves the best 64.0 AP on DUO and the\nbest 58.1 AP on RUOD, and 21 FPS (5 times faster than Deformable DETR and DINO\n4 FPS) on NVIDIA AGX Orin by TensorRT FP16, outperforming the other\nstate-of-the-art query-based end-to-end object detectors. The code is available\nat https://github.com/LEFTeyex/U-DECN.",
    "published": "2024-08-11T14:11:45Z",
    "updated": "2025-10-29T10:59:02Z",
    "link": "http://arxiv.org/pdf/2408.05780v2.pdf",
    "category": [
      "cs.CV",
      "I.4"
    ],
    "authors": [
      "Zhuoyan Liu",
      "Bo Wang",
      "Bing Wang",
      "Ye Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25387v1",
    "title": "Instance-Level Composed Image Retrieval",
    "summary": "The progress of composed image retrieval (CIR), a popular research direction\nin image retrieval, where a combined visual and textual query is used, is held\nback by the absence of high-quality training and evaluation data. We introduce\na new evaluation dataset, i-CIR, which, unlike existing datasets, focuses on an\ninstance-level class definition. The goal is to retrieve images that contain\nthe same particular object as the visual query, presented under a variety of\nmodifications defined by textual queries. Its design and curation process keep\nthe dataset compact to facilitate future research, while maintaining its\nchallenge-comparable to retrieval among more than 40M random\ndistractors-through a semi-automated selection of hard negatives.\n  To overcome the challenge of obtaining clean, diverse, and suitable training\ndata, we leverage pre-trained vision-and-language models (VLMs) in a\ntraining-free approach called BASIC. The method separately estimates\nquery-image-to-image and query-text-to-image similarities, performing late\nfusion to upweight images that satisfy both queries, while down-weighting those\nthat exhibit high similarity with only one of the two. Each individual\nsimilarity is further improved by a set of components that are simple and\nintuitive. BASIC sets a new state of the art on i-CIR but also on existing CIR\ndatasets that follow a semantic-level class definition. Project page:\nhttps://vrg.fel.cvut.cz/icir/.",
    "published": "2025-10-29T10:57:59Z",
    "updated": "2025-10-29T10:57:59Z",
    "link": "http://arxiv.org/pdf/2510.25387v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Bill Psomas",
      "George Retsinas",
      "Nikos Efthymiadis",
      "Panagiotis Filntisis",
      "Yannis Avrithis",
      "Petros Maragos",
      "Ondrej Chum",
      "Giorgos Tolias"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25769v1",
    "title": "Neural Stochastic Flows: Solver-Free Modelling and Inference for SDE\n  Solutions",
    "summary": "Stochastic differential equations (SDEs) are well suited to modelling noisy\nand irregularly sampled time series found in finance, physics, and machine\nlearning. Traditional approaches require costly numerical solvers to sample\nbetween arbitrary time points. We introduce Neural Stochastic Flows (NSFs) and\ntheir latent variants, which directly learn (latent) SDE transition laws using\nconditional normalising flows with architectural constraints that preserve\nproperties inherited from stochastic flows. This enables one-shot sampling\nbetween arbitrary states and yields up to two orders of magnitude speed-ups at\nlarge time gaps. Experiments on synthetic SDE simulations and on real-world\ntracking and video data show that NSFs maintain distributional accuracy\ncomparable to numerical approaches while dramatically reducing computation for\narbitrary time-point sampling.",
    "published": "2025-10-29T17:59:06Z",
    "updated": "2025-10-29T17:59:06Z",
    "link": "http://arxiv.org/pdf/2510.25769v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Naoki Kiyohara",
      "Edward Johns",
      "Yingzhen Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25759v1",
    "title": "Synthetic Data Reveals Generalization Gaps in Correlated Multiple\n  Instance Learning",
    "summary": "Multiple instance learning (MIL) is often used in medical imaging to classify\nhigh-resolution 2D images by processing patches or classify 3D volumes by\nprocessing slices. However, conventional MIL approaches treat instances\nseparately, ignoring contextual relationships such as the appearance of nearby\npatches or slices that can be essential in real applications. We design a\nsynthetic classification task where accounting for adjacent instance features\nis crucial for accurate prediction. We demonstrate the limitations of\noff-the-shelf MIL approaches by quantifying their performance compared to the\noptimal Bayes estimator for this task, which is available in closed-form. We\nempirically show that newer correlated MIL methods still struggle to generalize\nas well as possible when trained from scratch on tens of thousands of\ninstances.",
    "published": "2025-10-29T17:55:17Z",
    "updated": "2025-10-29T17:55:17Z",
    "link": "http://arxiv.org/pdf/2510.25759v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Ethan Harvey",
      "Dennis Johan Loevlie",
      "Michael C. Hughes"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25755v1",
    "title": "MLPrE -- A tool for preprocessing and exploratory data analysis prior to\n  machine learning model construction",
    "summary": "With the recent growth of Deep Learning for AI, there is a need for tools to\nmeet the demand of data flowing into those models. In some cases, source data\nmay exist in multiple formats, and therefore the source data must be\ninvestigated and properly engineered for a Machine Learning model or graph\ndatabase. Overhead and lack of scalability with existing workflows limit\nintegration within a larger processing pipeline such as Apache Airflow, driving\nthe need for a robust, extensible, and lightweight tool to preprocess arbitrary\ndatasets that scales with data type and size. To address this, we present\nMachine Learning Preprocessing and Exploratory Data Analysis, MLPrE, in which\nSparkDataFrames were utilized to hold data during processing and ensure\nscalability. A generalizable JSON input file format was utilized to describe\nstepwise changes to that DataFrame. Stages were implemented for input and\noutput, filtering, basic statistics, feature engineering, and exploratory data\nanalysis. A total of 69 stages were implemented into MLPrE, of which we\nhighlight and demonstrate key stages using six diverse datasets. We further\nhighlight MLPrE's ability to independently process multiple fields in flat\nfiles and recombine them, otherwise requiring an additional pipeline, using a\nUniProt glossary term dataset. Building on this advantage, we demonstrated the\nclustering stage with available wine quality data. Lastly, we demonstrate the\npreparation of data for a graph database in the final stages of MLPrE using\nphosphosite kinase data. Overall, our MLPrE tool offers a generalizable and\nscalable tool for preprocessing and early data analysis, filling a critical\nneed for such a tool given the ever expanding use of machine learning. This\ntool serves to accelerate and simplify early stage development in larger\nworkflows.",
    "published": "2025-10-29T17:52:39Z",
    "updated": "2025-10-29T17:52:39Z",
    "link": "http://arxiv.org/pdf/2510.25755v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "David S Maxwell",
      "Michael Darkoh",
      "Sidharth R Samudrala",
      "Caroline Chung",
      "Stephanie T Schmidt",
      "Bissan Al-Lazikani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25753v1",
    "title": "How Data Mixing Shapes In-Context Learning: Asymptotic Equivalence for\n  Transformers with MLPs",
    "summary": "Pretrained Transformers demonstrate remarkable in-context learning (ICL)\ncapabilities, enabling them to adapt to new tasks from demonstrations without\nparameter updates. However, theoretical studies often rely on simplified\narchitectures (e.g., omitting MLPs), data models (e.g., linear regression with\nisotropic inputs), and single-source training, limiting their relevance to\nrealistic settings. In this work, we study ICL in pretrained Transformers with\nnonlinear MLP heads on nonlinear tasks drawn from multiple data sources with\nheterogeneous input, task, and noise distributions. We analyze a model where\nthe MLP comprises two layers, with the first layer trained via a single\ngradient step and the second layer fully optimized. Under high-dimensional\nasymptotics, we prove that such models are equivalent in ICL error to\nstructured polynomial predictors, leveraging results from the theory of\nGaussian universality and orthogonal polynomials. This equivalence reveals that\nnonlinear MLPs meaningfully enhance ICL performance, particularly on nonlinear\ntasks, compared to linear baselines. It also enables a precise analysis of data\nmixing effects: we identify key properties of high-quality data sources (low\nnoise, structured covariances) and show that feature learning emerges only when\nthe task covariance exhibits sufficient structure. These results are validated\nempirically across various activation functions, model sizes, and data\ndistributions. Finally, we experiment with a real-world scenario involving\nmultilingual sentiment analysis where each language is treated as a different\nsource. Our experimental results for this case exemplify how our findings\nextend to real-world cases. Overall, our work advances the theoretical\nfoundations of ICL in Transformers and provides actionable insight into the\nrole of architecture and data in ICL.",
    "published": "2025-10-29T17:51:57Z",
    "updated": "2025-10-29T17:51:57Z",
    "link": "http://arxiv.org/pdf/2510.25753v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Samet Demir",
      "Zafer Dogan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.18549v3",
    "title": "The Price equation reveals a universal force-metric-bias law of\n  algorithmic learning and natural selection",
    "summary": "Diverse learning algorithms, optimization methods, and natural selection\nshare a common mathematical structure, despite their apparent differences. Here\nI show that a simple notational partitioning of change by the Price equation\nreveals a universal force-metric-bias (FMB) law: $\\Delta\\mathbf{\\theta} =\n\\mathbf{M}\\,\\mathbf{f} + \\mathbf{b} + \\mathbf{\\xi}$. The force $\\mathbf{f}$\ndrives improvement in parameters, $\\Delta\\mathbf{\\theta}$, in proportion to the\nslope of performance with respect to the parameters. The metric $\\mathbf{M}$\nrescales movement by inverse curvature. The bias $\\mathbf{b}$ adds momentum or\nchanges in the frame of reference. The noise $\\mathbf{\\xi}$ enables\nexploration. This framework unifies natural selection, Bayesian updating,\nNewton's method, stochastic gradient descent, stochastic Langevin dynamics,\nAdam optimization, and most other algorithms as special cases of the same\nunderlying process. The Price equation also reveals why Fisher information,\nKullback-Leibler divergence, and d'Alembert's principle arise naturally in\nlearning dynamics. By exposing this common structure, the FMB law provides a\nprincipled foundation for understanding, comparing, and designing learning\nalgorithms across disciplines.",
    "published": "2025-07-24T16:13:56Z",
    "updated": "2025-10-29T17:50:44Z",
    "link": "http://arxiv.org/pdf/2507.18549v3.pdf",
    "category": [
      "cs.LG",
      "q-bio.PE"
    ],
    "authors": [
      "Steven A. Frank"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25752v1",
    "title": "Meshless solutions of PDE inverse problems on irregular geometries",
    "summary": "Solving inverse and optimization problems over solutions of nonlinear partial\ndifferential equations (PDEs) on complex spatial domains is a long-standing\nchallenge. Here we introduce a method that parameterizes the solution using\nspectral bases on arbitrary spatiotemporal domains, whereby the basis is\ndefined on a hyperrectangle containing the true domain. We find the\ncoefficients of the basis expansion by solving an optimization problem whereby\nboth the equations, the boundary conditions and any optimization targets are\nenforced by a loss function, building on a key idea from Physics-Informed\nNeural Networks (PINNs). Since the representation of the function natively has\nexponential convergence, so does the solution of the optimization problem, as\nlong as it can be solved efficiently. We find empirically that the optimization\nprotocols developed for machine learning find solutions with exponential\nconvergence on a wide range of equations. The method naturally allows for the\nincorporation of data assimilation by including additional terms in the loss\nfunction, and for the efficient solution of optimization problems over the PDE\nsolutions.",
    "published": "2025-10-29T17:49:40Z",
    "updated": "2025-10-29T17:49:40Z",
    "link": "http://arxiv.org/pdf/2510.25752v1.pdf",
    "category": [
      "math.NA",
      "cs.LG",
      "cs.NA",
      "physics.comp-ph"
    ],
    "authors": [
      "James V. Roggeveen",
      "Michael P. Brenner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.20762v3",
    "title": "ASGO: Adaptive Structured Gradient Optimization",
    "summary": "Training deep neural networks is a structured optimization problem, because\nthe parameters are naturally represented by matrices and tensors rather than by\nvectors. Under this structural representation, it has been widely observed that\ngradients are low-rank and Hessians are approximately block diagonal. These\nstructured properties are crucial for designing efficient optimization\nalgorithms, but are not utilized by many current popular optimizers like Adam.\nIn this paper, we present a novel optimization algorithm ASGO that capitalizes\non these properties by employing a preconditioner that is adaptively updated\nusing structured gradients. By a fine-grained theoretical analysis, ASGO is\nproven to achieve superior convergence rates compared to existing structured\ngradient methods. Based on this convergence theory, we further demonstrate that\nASGO can benefit from low-rank gradients and block diagonal Hessians. We also\ndiscuss practical modifications of ASGO and empirically verify ASGO's\neffectiveness on language model tasks. Code is available at\nhttps://github.com/infinity-stars/ASGO.",
    "published": "2025-03-26T17:50:13Z",
    "updated": "2025-10-29T17:47:39Z",
    "link": "http://arxiv.org/pdf/2503.20762v3.pdf",
    "category": [
      "cs.LG",
      "math.OC"
    ],
    "authors": [
      "Kang An",
      "Yuxing Liu",
      "Rui Pan",
      "Yi Ren",
      "Shiqian Ma",
      "Donald Goldfarb",
      "Tong Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.21269v3",
    "title": "Dynamical Decoupling of Generalization and Overfitting in Large\n  Two-Layer Networks",
    "summary": "Understanding the inductive bias and generalization properties of large\noverparametrized machine learning models requires to characterize the dynamics\nof the training algorithm. We study the learning dynamics of large two-layer\nneural networks via dynamical mean field theory, a well established technique\nof non-equilibrium statistical physics. We show that, for large network width\n$m$, and large number of samples per input dimension $n/d$, the training\ndynamics exhibits a separation of timescales which implies: $(i)$~The emergence\nof a slow time scale associated with the growth in Gaussian/Rademacher\ncomplexity of the network; $(ii)$~Inductive bias towards small complexity if\nthe initialization has small enough complexity; $(iii)$~A dynamical decoupling\nbetween feature learning and overfitting regimes; $(iv)$~A non-monotone\nbehavior of the test error, associated `feature unlearning' regime at large\ntimes.",
    "published": "2025-02-28T17:45:26Z",
    "updated": "2025-10-29T17:46:23Z",
    "link": "http://arxiv.org/pdf/2502.21269v3.pdf",
    "category": [
      "stat.ML",
      "cond-mat.dis-nn",
      "cs.LG"
    ],
    "authors": [
      "Andrea Montanari",
      "Pierfrancesco Urbani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.21355v2",
    "title": "SMMILE: An Expert-Driven Benchmark for Multimodal Medical In-Context\n  Learning",
    "summary": "Multimodal in-context learning (ICL) remains underexplored despite\nsignificant potential for domains such as medicine. Clinicians routinely\nencounter diverse, specialized tasks requiring adaptation from limited\nexamples, such as drawing insights from a few relevant prior cases or\nconsidering a constrained set of differential diagnoses. While multimodal large\nlanguage models (MLLMs) have shown advances in medical visual question\nanswering (VQA), their ability to learn multimodal tasks from context is\nlargely unknown. We introduce SMMILE, the first expert-driven multimodal ICL\nbenchmark for medical tasks. Eleven medical experts curated problems, each\nincluding a multimodal query and multimodal in-context examples as task\ndemonstrations. SMMILE encompasses 111 problems (517 question-image-answer\ntriplets) covering 6 medical specialties and 13 imaging modalities. We further\nintroduce SMMILE++, an augmented variant with 1038 permuted problems. A\ncomprehensive evaluation of 15 MLLMs demonstrates that most models exhibit\nmoderate to poor multimodal ICL ability in medical tasks. In open-ended\nevaluations, ICL contributes only an 8% average improvement over zero-shot on\nSMMILE and 9.4% on SMMILE++. We observe a susceptibility for irrelevant\nin-context examples: even a single noisy or irrelevant example can degrade\nperformance by up to 9.5%. Moreover, we observe that MLLMs are affected by a\nrecency bias, where placing the most relevant example last can lead to\nsubstantial performance improvements of up to 71%. Our findings highlight\ncritical limitations and biases in current MLLMs when learning multimodal\nmedical tasks from context. SMMILE is available at\nhttps://smmile-benchmark.github.io.",
    "published": "2025-06-26T15:08:18Z",
    "updated": "2025-10-29T17:23:18Z",
    "link": "http://arxiv.org/pdf/2506.21355v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Melanie Rieff",
      "Maya Varma",
      "Ossian Rabow",
      "Subathra Adithan",
      "Julie Kim",
      "Ken Chang",
      "Hannah Lee",
      "Nidhi Rohatgi",
      "Christian Bluethgen",
      "Mohamed S. Muneer",
      "Jean-Benoit Delbrouck",
      "Michael Moor"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.02270v2",
    "title": "Exact Sequence Interpolation with Transformers",
    "summary": "We prove that transformers can exactly interpolate datasets of finite input\nsequences in $\\mathbb{R}^d$, $d\\geq 2$, with corresponding output sequences of\nsmaller or equal length. Specifically, given $N$ sequences of arbitrary but\nfinite lengths in $\\mathbb{R}^d$ and output sequences of lengths $m^1, \\dots,\nm^N \\in \\mathbb{N}$, we construct a transformer with $\\mathcal{O}(\\sum_{j=1}^N\nm^j)$ blocks and $\\mathcal{O}(d \\sum_{j=1}^N m^j)$ parameters that exactly\ninterpolates the dataset. Our construction provides complexity estimates that\nare independent of the input sequence length, by alternating feed-forward and\nself-attention layers and by capitalizing on the clustering effect inherent to\nthe latter. Our novel constructive method also uses low-rank parameter matrices\nin the self-attention mechanism, a common feature of practical transformer\nimplementations. These results are first established in the hardmax\nself-attention setting, where the geometric structure permits an explicit and\nquantitative analysis, and are then extended to the softmax setting. Finally,\nwe demonstrate the applicability of our exact interpolation construction to\nlearning problems, in particular by providing convergence guarantees to a\nglobal minimizer under regularized training strategies. Our analysis\ncontributes to the theoretical understanding of transformer models, offering an\nexplanation for their excellent performance in exact sequence-to-sequence\ninterpolation tasks.",
    "published": "2025-02-04T12:31:00Z",
    "updated": "2025-10-29T17:15:10Z",
    "link": "http://arxiv.org/pdf/2502.02270v2.pdf",
    "category": [
      "cs.LG",
      "math.OC",
      "stat.ML",
      "68T07, 68T50"
    ],
    "authors": [
      "Albert Alcalde",
      "Giovanni Fantuzzi",
      "Enrique Zuazua"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25704v1",
    "title": "Scaling flow-based approaches for topology sampling in $\\mathrm{SU}(3)$\n  gauge theory",
    "summary": "We develop a methodology based on out-of-equilibrium simulations to mitigate\ntopological freezing when approaching the continuum limit of lattice gauge\ntheories. We reduce the autocorrelation of the topological charge employing\nopen boundary conditions, while removing exactly their unphysical effects using\na non-equilibrium Monte Carlo approach in which periodic boundary conditions\nare gradually switched on. We perform a detailed analysis of the computational\ncosts of this strategy in the case of the four-dimensional $\\mathrm{SU}(3)$\nYang-Mills theory. After achieving full control of the scaling, we outline a\nclear strategy to sample topology efficiently in the continuum limit, which we\ncheck at lattice spacings as small as $0.045$ fm. We also generalize this\napproach by designing a customized Stochastic Normalizing Flow for evolutions\nin the boundary conditions, obtaining superior performances with respect to the\npurely stochastic non-equilibrium approach, and paving the way for more\nefficient future flow-based solutions.",
    "published": "2025-10-29T17:12:21Z",
    "updated": "2025-10-29T17:12:21Z",
    "link": "http://arxiv.org/pdf/2510.25704v1.pdf",
    "category": [
      "hep-lat",
      "cond-mat.stat-mech",
      "cs.LG",
      "hep-ph"
    ],
    "authors": [
      "Claudio Bonanno",
      "Andrea Bulgarelli",
      "Elia Cellini",
      "Alessandro Nada",
      "Dario Panfalone",
      "Davide Vadacchino",
      "Lorenzo Verzichelli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2310.02806v3",
    "title": "MP-FVM: Enhancing Finite Volume Method for Water Infiltration Modeling\n  in Unsaturated Soils via Message-passing Encoder-decoder Network",
    "summary": "The spatiotemporal water flow dynamics in unsaturated soils can generally be\nmodeled by the Richards equation. To overcome the computational challenges\nassociated with solving this highly nonlinear partial differential equation\n(PDE), we present a novel solution algorithm, which we name as the MP-FVM\n(Message Passing-Finite Volume Method), to holistically integrate adaptive\nfixed-point iteration scheme, encoder-decoder neural network architecture,\nSobolev training, and message passing mechanism in a finite volume\ndiscretization framework. We thoroughly discuss the need and benefits of\nintroducing these components to achieve synergistic improvements in accuracy\nand stability of the solution. We also show that our MP-FVM algorithm can\naccurately solve the mixed-form $n$-dimensional Richards equation with\nguaranteed convergence under reasonable assumptions. Through several\nillustrative examples, we demonstrate that our MP-FVM algorithm not only\nachieves superior accuracy, but also better preserves the underlying physical\nlaws and mass conservation of the Richards equation compared to\nstate-of-the-art solution algorithms and the commercial HYDRUS solver.",
    "published": "2023-10-04T13:33:37Z",
    "updated": "2025-10-29T17:05:43Z",
    "link": "http://arxiv.org/pdf/2310.02806v3.pdf",
    "category": [
      "math.NA",
      "cs.LG",
      "cs.NA",
      "35Q86",
      "G.1.8"
    ],
    "authors": [
      "Zeyuan Song",
      "Zheyu Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25696v1",
    "title": "Convolutional Spiking-based GRU Cell for Spatio-temporal Data",
    "summary": "Spike-based temporal messaging enables SNNs to efficiently process both\npurely temporal and spatio-temporal time-series or event-driven data. Combining\nSNNs with Gated Recurrent Units (GRUs), a variant of recurrent neural networks,\ngives rise to a robust framework for sequential data processing; however,\ntraditional RNNs often lose local details when handling long sequences.\nPrevious approaches, such as SpikGRU, fail to capture fine-grained local\ndependencies in event-based spatio-temporal data. In this paper, we introduce\nthe Convolutional Spiking GRU (CS-GRU) cell, which leverages convolutional\noperations to preserve local structure and dependencies while integrating the\ntemporal precision of spiking neurons with the efficient gating mechanisms of\nGRUs. This versatile architecture excels on both temporal datasets (NTIDIGITS,\nSHD) and spatio-temporal benchmarks (MNIST, DVSGesture, CIFAR10DVS). Our\nexperiments show that CS-GRU outperforms state-of-the-art GRU variants by an\naverage of 4.35%, achieving over 90% accuracy on sequential tasks and up to\n99.31% on MNIST. It is worth noting that our solution achieves 69% higher\nefficiency compared to SpikGRU. The code is available at:\nhttps://github.com/YesmineAbdennadher/CS-GRU.",
    "published": "2025-10-29T17:00:36Z",
    "updated": "2025-10-29T17:00:36Z",
    "link": "http://arxiv.org/pdf/2510.25696v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Yesmine Abdennadher",
      "Eleonora Cicciarella",
      "Michele Rossi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23323v2",
    "title": "Towards Scaling Deep Neural Networks with Predictive Coding: Theory and\n  Practice",
    "summary": "Backpropagation (BP) is the standard algorithm for training the deep neural\nnetworks that power modern artificial intelligence including large language\nmodels. However, BP is energy inefficient and unlikely to be implemented by the\nbrain. This thesis studies an alternative, potentially more efficient\nbrain-inspired algorithm called predictive coding (PC). Unlike BP, PC networks\n(PCNs) perform inference by iterative equilibration of neuron activities before\nlearning or weight updates. Recent work has suggested that this iterative\ninference procedure provides a range of benefits over BP, such as faster\ntraining. However, these advantages have not been consistently observed, the\ninference and learning dynamics of PCNs are still poorly understood, and deep\nPCNs remain practically untrainable. Here, we make significant progress towards\nscaling PCNs by taking a theoretical approach grounded in optimisation theory.\nFirst, we show that the learning dynamics of PC can be understood as an\napproximate trust-region method using second-order information, despite\nexplicitly using only first-order local updates. Second, going beyond this\napproximation, we show that PC can in principle make use of arbitrarily\nhigher-order information, such that for feedforward networks the effective\nlandscape on which PC learns is far more benign and robust to vanishing\ngradients than the (mean squared error) loss landscape. Third, motivated by a\nstudy of the inference dynamics of PCNs, we propose a new parameterisation\ncalled \"$\\mu$PC\", which for the first time allows stable training of 100+ layer\nnetworks with little tuning and competitive performance on simple tasks.\nOverall, this thesis significantly advances our fundamental understanding of\nthe inference and learning dynamics of PCNs, while highlighting the need for\nfuture research to focus on hardware co-design if PC is to compete with BP at\nscale.",
    "published": "2025-10-24T14:47:49Z",
    "updated": "2025-10-29T16:59:39Z",
    "link": "http://arxiv.org/pdf/2510.23323v2.pdf",
    "category": [
      "cs.LG",
      "cs.NE",
      "I.2.6"
    ],
    "authors": [
      "Francesco Innocenti"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25693v1",
    "title": "PyDPF: A Python Package for Differentiable Particle Filtering",
    "summary": "State-space models (SSMs) are a widely used tool in time series analysis. In\nthe complex systems that arise from real-world data, it is common to employ\nparticle filtering (PF), an efficient Monte Carlo method for estimating the\nhidden state corresponding to a sequence of observations. Applying particle\nfiltering requires specifying both the parametric form and the parameters of\nthe system, which are often unknown and must be estimated. Gradient-based\noptimisation techniques cannot be applied directly to standard particle\nfilters, as the filters themselves are not differentiable. However, several\nrecently proposed methods modify the resampling step to make particle filtering\ndifferentiable. In this paper, we present an implementation of several such\ndifferentiable particle filters (DPFs) with a unified API built on the popular\nPyTorch framework. Our implementation makes these algorithms easily accessible\nto a broader research community and facilitates straightforward comparison\nbetween them. We validate our framework by reproducing experiments from several\nexisting studies and demonstrate how DPFs can be applied to address several\ncommon challenges with state space modelling.",
    "published": "2025-10-29T16:57:54Z",
    "updated": "2025-10-29T16:57:54Z",
    "link": "http://arxiv.org/pdf/2510.25693v1.pdf",
    "category": [
      "eess.SP",
      "cs.LG",
      "60-04",
      "G.3"
    ],
    "authors": [
      "John-Joseph Brady",
      "Benjamin Cox",
      "Víctor Elvira",
      "Yunpeng Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25692v1",
    "title": "A Configuration-First Framework for Reproducible, Low-Code Localization",
    "summary": "Machine learning is increasingly permeating radio-based localization\nservices. To keep results credible and comparable, everyday workflows should\nmake rigorous experiment specification and exact repeatability the default,\nwithout blocking advanced experimentation. However, in practice, researchers\nface a three-way gap that could be filled by a framework that offers (i) low\ncoding effort for end-to-end studies, (ii) reproducibility by default including\nversioned code, data, and configurations, controlled randomness, isolated runs,\nand recorded artifacts, and (iii) built-in extensibility so new models,\nmetrics, and stages can be added with minimal integration effort. Existing\ntools rarely deliver all three for machine learning in general and localization\nworkflows in particular. In this paper we introduce LOCALIZE, a low-code,\nconfiguration-first framework for radio localization in which experiments are\ndeclared in human-readable configuration, a workflow orchestrator runs\nstandardized pipelines from data preparation to reporting, and all artifacts,\nsuch as datasets, models, metrics, and reports, are versioned. The\npreconfigured, versioned datasets reduce initial setup and boilerplate,\nspeeding up model development and evaluation. The design, with clear extension\npoints, allows experts to add components without reworking the infrastructure.\nIn a qualitative comparison and a head-to-head study against a plain Jupyter\nnotebook baseline, we show that the framework reduces authoring effort while\nmaintaining comparable runtime and memory behavior. Furthermore, using a\nBluetooth Low Energy dataset, we show that scaling across training data (1x to\n10x) keeps orchestration overheads bounded as data grows. Overall, the\nframework makes reproducible machine-learning-based localization\nexperimentation practical, accessible, and extensible.",
    "published": "2025-10-29T16:57:33Z",
    "updated": "2025-10-29T16:57:33Z",
    "link": "http://arxiv.org/pdf/2510.25692v1.pdf",
    "category": [
      "cs.SE",
      "cs.LG",
      "D.2.6; I.2.6"
    ],
    "authors": [
      "Tim Strnad",
      "Blaž Bertalanič",
      "Carolina Fortuna"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25687v1",
    "title": "Model Inversion Attacks Meet Cryptographic Fuzzy Extractors",
    "summary": "Model inversion attacks pose an open challenge to privacy-sensitive\napplications that use machine learning (ML) models. For example, face\nauthentication systems use modern ML models to compute embedding vectors from\nface images of the enrolled users and store them. If leaked, inversion attacks\ncan accurately reconstruct user faces from the leaked vectors. There is no\nsystematic characterization of properties needed in an ideal defense against\nmodel inversion, even for the canonical example application of a face\nauthentication system susceptible to data breaches, despite a decade of\nbest-effort solutions.\n  In this paper, we formalize the desired properties of a provably strong\ndefense against model inversion and connect it, for the first time, to the\ncryptographic concept of fuzzy extractors. We further show that existing fuzzy\nextractors are insecure for use in ML-based face authentication. We do so\nthrough a new model inversion attack called PIPE, which achieves a success rate\nof over 89% in most cases against prior schemes. We then propose L2FE-Hash, the\nfirst candidate fuzzy extractor which supports standard Euclidean distance\ncomparators as needed in many ML-based applications, including face\nauthentication. We formally characterize its computational security guarantees,\neven in the extreme threat model of full breach of stored secrets, and\nempirically show its usable accuracy in face authentication for practical face\ndistributions. It offers attack-agnostic security without requiring any\nre-training of the ML model it protects. Empirically, it nullifies both prior\nstate-of-the-art inversion attacks as well as our new PIPE attack.",
    "published": "2025-10-29T16:50:54Z",
    "updated": "2025-10-29T16:50:54Z",
    "link": "http://arxiv.org/pdf/2510.25687v1.pdf",
    "category": [
      "cs.CR",
      "cs.LG"
    ],
    "authors": [
      "Mallika Prabhakar",
      "Louise Xu",
      "Prateek Saxena"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2312.02804v3",
    "title": "Score-Aware Policy-Gradient and Performance Guarantees using Local\n  Lyapunov Stability",
    "summary": "In this paper, we introduce a policy-gradient method for model-based\nreinforcement learning (RL) that exploits a type of stationary distributions\ncommonly obtained from Markov decision processes (MDPs) in stochastic networks,\nqueueing systems, and statistical mechanics. Specifically, when the stationary\ndistribution of the MDP belongs to an exponential family that is parametrized\nby policy parameters, we can improve existing policy gradient methods for\naverage-reward RL. Our key identification is a family of gradient estimators,\ncalled score-aware gradient estimators (SAGEs), that enable policy gradient\nestimation without relying on value-function estimation in the aforementioned\nsetting. We show that SAGE-based policy-gradient locally converges, and we\nobtain its regret. This includes cases when the state space of the MDP is\ncountable and unstable policies can exist. Under appropriate assumptions such\nas starting sufficiently close to a maximizer and the existence of a local\nLyapunov function, the policy under SAGE-based stochastic gradient ascent has\nan overwhelming probability of converging to the associated optimal policy.\nFurthermore, we conduct a numerical comparison between a SAGE-based\npolicy-gradient method and an actor-critic method on several examples inspired\nfrom stochastic networks, queueing systems, and models derived from statistical\nphysics. Our results demonstrate that a SAGE-based method finds\nclose-to-optimal policies faster than an actor-critic method.",
    "published": "2023-12-05T14:44:58Z",
    "updated": "2025-10-29T16:49:31Z",
    "link": "http://arxiv.org/pdf/2312.02804v3.pdf",
    "category": [
      "cs.LG",
      "cs.PF",
      "math.OC",
      "math.PR"
    ],
    "authors": [
      "Céline Comte",
      "Matthieu Jonckheere",
      "Jaron Sanders",
      "Albert Senen-Cerda"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25674v1",
    "title": "Mechanistic Interpretability of RNNs emulating Hidden Markov Models",
    "summary": "Recurrent neural networks (RNNs) provide a powerful approach in neuroscience\nto infer latent dynamics in neural populations and to generate hypotheses about\nthe neural computations underlying behavior. However, past work has focused on\nrelatively simple, input-driven, and largely deterministic behaviors - little\nis known about the mechanisms that would allow RNNs to generate the richer,\nspontaneous, and potentially stochastic behaviors observed in natural settings.\nModeling with Hidden Markov Models (HMMs) has revealed a segmentation of\nnatural behaviors into discrete latent states with stochastic transitions\nbetween them, a type of dynamics that may appear at odds with the continuous\nstate spaces implemented by RNNs. Here we first show that RNNs can replicate\nHMM emission statistics and then reverse-engineer the trained networks to\nuncover the mechanisms they implement. In the absence of inputs, the activity\nof trained RNNs collapses towards a single fixed point. When driven by\nstochastic input, trajectories instead exhibit noise-sustained dynamics along\nclosed orbits. Rotation along these orbits modulates the emission probabilities\nand is governed by transitions between regions of slow, noise-driven dynamics\nconnected by fast, deterministic transitions. The trained RNNs develop highly\nstructured connectivity, with a small set of \"kick neurons\" initiating\ntransitions between these regions. This mechanism emerges during training as\nthe network shifts into a regime of stochastic resonance, enabling it to\nperform probabilistic computations. Analyses across multiple HMM architectures\n- fully connected, cyclic, and linear-chain - reveal that this solution\ngeneralizes through the modular reuse of the same dynamical motif, suggesting a\ncompositional principle by which RNNs can emulate complex discrete latent\ndynamics.",
    "published": "2025-10-29T16:42:07Z",
    "updated": "2025-10-29T16:42:07Z",
    "link": "http://arxiv.org/pdf/2510.25674v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Elia Torre",
      "Michele Viscione",
      "Lucas Pompe",
      "Benjamin F Grewe",
      "Valerio Mante"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25670v1",
    "title": "Spectral Perturbation Bounds for Low-Rank Approximation with\n  Applications to Privacy",
    "summary": "A central challenge in machine learning is to understand how noise or\nmeasurement errors affect low-rank approximations, particularly in the spectral\nnorm. This question is especially important in differentially private low-rank\napproximation, where one aims to preserve the top-$p$ structure of a\ndata-derived matrix while ensuring privacy. Prior work often analyzes Frobenius\nnorm error or changes in reconstruction quality, but these metrics can over- or\nunder-estimate true subspace distortion. The spectral norm, by contrast,\ncaptures worst-case directional error and provides the strongest utility\nguarantees. We establish new high-probability spectral-norm perturbation bounds\nfor symmetric matrices that refine the classical Eckart--Young--Mirsky theorem\nand explicitly capture interactions between a matrix $A \\in \\mathbb{R}^{n\n\\times n}$ and an arbitrary symmetric perturbation $E$. Under mild eigengap and\nnorm conditions, our bounds yield sharp estimates for $\\|(A + E)_p - A_p\\|$,\nwhere $A_p$ is the best rank-$p$ approximation of $A$, with improvements of up\nto a factor of $\\sqrt{n}$. As an application, we derive improved utility\nguarantees for differentially private PCA, resolving an open problem in the\nliterature. Our analysis relies on a novel contour bootstrapping method from\ncomplex analysis and extends it to a broad class of spectral functionals,\nincluding polynomials and matrix exponentials. Empirical results on real-world\ndatasets confirm that our bounds closely track the actual spectral error under\ndiverse perturbation regimes.",
    "published": "2025-10-29T16:36:00Z",
    "updated": "2025-10-29T16:36:00Z",
    "link": "http://arxiv.org/pdf/2510.25670v1.pdf",
    "category": [
      "cs.LG",
      "cs.CR",
      "cs.DS",
      "cs.NA",
      "math.NA",
      "math.SP"
    ],
    "authors": [
      "Phuc Tran",
      "Nisheeth K. Vishnoi",
      "Van H. Vu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25648v1",
    "title": "Continuous subsurface property retrieval from sparse radar observations\n  using physics informed neural networks",
    "summary": "Estimating subsurface dielectric properties is essential for applications\nranging from environmental surveys of soils to nondestructive evaluation of\nconcrete in infrastructure. Conventional wave inversion methods typically\nassume few discrete homogeneous layers and require dense measurements or strong\nprior knowledge of material boundaries, limiting scalability and accuracy in\nrealistic settings where properties vary continuously. We present a physics\ninformed machine learning framework that reconstructs subsurface permittivity\nas a fully neural, continuous function of depth, trained to satisfy both\nmeasurement data and Maxwells equations. We validate the framework with both\nsimulations and custom built radar experiments on multilayered natural\nmaterials. Results show close agreement with in-situ permittivity measurements\n(R^2=0.93), with sensitivity to even subtle variations (Delta eps_r=2).\nParametric analysis reveals that accurate profiles can be recovered with as few\nas three strategically placed sensors in two layer systems. This approach\nreframes subsurface inversion from boundary-driven to continuous property\nestimation, enabling accurate characterization of smooth permittivity\nvariations and advancing electromagnetic imaging using low cost radar systems.",
    "published": "2025-10-29T16:09:24Z",
    "updated": "2025-10-29T16:09:24Z",
    "link": "http://arxiv.org/pdf/2510.25648v1.pdf",
    "category": [
      "eess.SP",
      "cs.LG"
    ],
    "authors": [
      "Ishfaq Aziz",
      "Mohamad Alipour"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25599v1",
    "title": "Uncertainty Quantification for Regression: A Unified Framework based on\n  kernel scores",
    "summary": "Regression tasks, notably in safety-critical domains, require proper\nuncertainty quantification, yet the literature remains largely\nclassification-focused. In this light, we introduce a family of measures for\ntotal, aleatoric, and epistemic uncertainty based on proper scoring rules, with\na particular emphasis on kernel scores. The framework unifies several\nwell-known measures and provides a principled recipe for designing new ones\nwhose behavior, such as tail sensitivity, robustness, and out-of-distribution\nresponsiveness, is governed by the choice of kernel. We prove explicit\ncorrespondences between kernel-score characteristics and downstream behavior,\nyielding concrete design guidelines for task-specific measures. Extensive\nexperiments demonstrate that these measures are effective in downstream tasks\nand reveal clear trade-offs among instantiations, including robustness and\nout-of-distribution detection performance.",
    "published": "2025-10-29T15:08:41Z",
    "updated": "2025-10-29T15:08:41Z",
    "link": "http://arxiv.org/pdf/2510.25599v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Christopher Bülte",
      "Yusuf Sale",
      "Gitta Kutyniok",
      "Eyke Hüllermeier"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25591v1",
    "title": "Generalized Sobolev IPM for Graph-Based Measures",
    "summary": "We study the Sobolev IPM problem for measures supported on a graph metric\nspace, where critic function is constrained to lie within the unit ball defined\nby Sobolev norm. While Le et al. (2025) achieved scalable computation by\nrelating Sobolev norm to weighted $L^p$-norm, the resulting framework remains\nintrinsically bound to $L^p$ geometric structure, limiting its ability to\nincorporate alternative structural priors beyond the $L^p$ geometry paradigm.\nTo overcome this limitation, we propose to generalize Sobolev IPM through the\nlens of \\emph{Orlicz geometric structure}, which employs convex functions to\ncapture nuanced geometric relationships, building upon recent advances in\noptimal transport theory -- particularly Orlicz-Wasserstein (OW) and\ngeneralized Sobolev transport -- that have proven instrumental in advancing\nmachine learning methodologies. This generalization encompasses classical\nSobolev IPM as a special case while accommodating diverse geometric priors\nbeyond traditional $L^p$ structure. It however brings up significant\ncomputational hurdles that compound those already inherent in Sobolev IPM. To\naddress these challenges, we establish a novel theoretical connection between\nOrlicz-Sobolev norm and Musielak norm which facilitates a novel regularization\nfor the generalized Sobolev IPM (GSI). By further exploiting the underlying\ngraph structure, we show that GSI with Musielak regularization (GSI-M) reduces\nto a simple \\emph{univariate optimization} problem, achieving remarkably\ncomputational efficiency. Empirically, GSI-M is several-order faster than the\npopular OW in computation, and demonstrates its practical advantages in\ncomparing probability measures on a given graph for document classification and\nseveral tasks in topological data analysis.",
    "published": "2025-10-29T14:59:26Z",
    "updated": "2025-10-29T14:59:26Z",
    "link": "http://arxiv.org/pdf/2510.25591v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Tam Le",
      "Truyen Nguyen",
      "Hideitsu Hino",
      "Kenji Fukumizu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25582v1",
    "title": "Learning-Augmented Online Bidding in Stochastic Settings",
    "summary": "Online bidding is a classic optimization problem, with several applications\nin online decision-making, the design of interruptible systems, and the\nanalysis of approximation algorithms. In this work, we study online bidding\nunder learning-augmented settings that incorporate stochasticity, in either the\nprediction oracle or the algorithm itself. In the first part, we study bidding\nunder distributional predictions, and find Pareto-optimal algorithms that offer\nthe best-possible tradeoff between the consistency and the robustness of the\nalgorithm. In the second part, we study the power and limitations of randomized\nbidding algorithms, by presenting upper and lower bounds on the\nconsistency/robustness tradeoffs. Previous works focused predominantly on\noracles that do not leverage stochastic information on the quality of the\nprediction, and deterministic algorithms.",
    "published": "2025-10-29T14:47:18Z",
    "updated": "2025-10-29T14:47:18Z",
    "link": "http://arxiv.org/pdf/2510.25582v1.pdf",
    "category": [
      "cs.GT",
      "cs.LG"
    ],
    "authors": [
      "Spyros Angelopoulos",
      "Bertrand Simon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25573v1",
    "title": "Monitoring the calibration of probability forecasts with an application\n  to concept drift detection involving image classification",
    "summary": "Machine learning approaches for image classification have led to impressive\nadvances in that field. For example, convolutional neural networks are able to\nachieve remarkable image classification accuracy across a wide range of\napplications in industry, defense, and other areas. While these machine\nlearning models boast impressive accuracy, a related concern is how to assess\nand maintain calibration in the predictions these models make. A classification\nmodel is said to be well calibrated if its predicted probabilities correspond\nwith the rates events actually occur. While there are many available methods to\nassess machine learning calibration and recalibrate faulty predictions, less\neffort has been spent on developing approaches that continually monitor\npredictive models for potential loss of calibration as time passes. We propose\na cumulative sum-based approach with dynamic limits that enable detection of\nmiscalibration in both traditional process monitoring and concept drift\napplications. This enables early detection of operational context changes that\nimpact image classification performance in the field. The proposed chart can be\nused broadly in any situation where the user needs to monitor probability\npredictions over time for potential lapses in calibration. Importantly, our\nmethod operates on probability predictions and event outcomes and does not\nrequire under-the-hood access to the machine learning model.",
    "published": "2025-10-29T14:42:10Z",
    "updated": "2025-10-29T14:42:10Z",
    "link": "http://arxiv.org/pdf/2510.25573v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Christopher T. Franck",
      "Anne R. Driscoll",
      "Zoe Szajnfarber",
      "William H. Woodall"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24670v2",
    "title": "Pearl: A Foundation Model for Placing Every Atom in the Right Location",
    "summary": "Accurately predicting the three-dimensional structures of protein-ligand\ncomplexes remains a fundamental challenge in computational drug discovery that\nlimits the pace and success of therapeutic design. Deep learning methods have\nrecently shown strong potential as structural prediction tools, achieving\npromising accuracy across diverse biomolecular systems. However, their\nperformance and utility are constrained by scarce experimental data,\ninefficient architectures, physically invalid poses, and the limited ability to\nexploit auxiliary information available at inference. To address these issues,\nwe introduce Pearl (Placing Every Atom in the Right Location), a foundation\nmodel for protein-ligand cofolding at scale. Pearl addresses these challenges\nwith three key innovations: (1) training recipes that include large-scale\nsynthetic data to overcome data scarcity; (2) architectures that incorporate an\nSO(3)-equivariant diffusion module to inherently respect 3D rotational\nsymmetries, improving generalization and sample efficiency, and (3)\ncontrollable inference, including a generalized multi-chain templating system\nsupporting both protein and non-polymeric components as well as dual\nunconditional/conditional modes. Pearl establishes a new state-of-the-art\nperformance in protein-ligand cofolding. On the key metric of generating\naccurate (RMSD < 2 \\r{A}) and physically valid poses, Pearl surpasses AlphaFold\n3 and other open source baselines on the public Runs N' Poses and PoseBusters\nbenchmarks, delivering 14.5% and 14.2% improvements, respectively, over the\nnext best model. In the pocket-conditional cofolding regime, Pearl delivers\n$3.6\\times$ improvement on a proprietary set of challenging, real-world drug\ntargets at the more rigorous RMSD < 1 \\r{A} threshold. Finally, we demonstrate\nthat model performance correlates directly with synthetic dataset size used in\ntraining.",
    "published": "2025-10-28T17:36:51Z",
    "updated": "2025-10-29T14:41:45Z",
    "link": "http://arxiv.org/pdf/2510.24670v2.pdf",
    "category": [
      "cs.LG",
      "q-bio.QM"
    ],
    "authors": [
      " Genesis Research Team",
      "Alejandro Dobles",
      "Nina Jovic",
      "Kenneth Leidal",
      "Pranav Murugan",
      "David C. Williams",
      "Drausin Wulsin",
      "Nate Gruver",
      "Christina X. Ji",
      "Korrawat Pruegsanusak",
      "Gianluca Scarpellini",
      "Ansh Sharma",
      "Wojciech Swiderski",
      "Andrea Bootsma",
      "Richard Strong Bowen",
      "Charlotte Chen",
      "Jamin Chen",
      "Marc André Dämgen",
      "Benjamin DiFrancesco",
      "J. D. Fishman",
      "Alla Ivanova",
      "Zach Kagin",
      "David Li-Bland",
      "Zuli Liu",
      "Igor Morozov",
      "Jeffrey Ouyang-Zhang",
      "Frank C. Pickard IV",
      "Kushal S. Shah",
      "Ben Shor",
      "Gabriel Monteiro da Silva",
      "Roy Tal",
      "Maxx Tessmer",
      "Carl Tilbury",
      "Cyr Vetcher",
      "Daniel Zeng",
      "Maruan Al-Shedivat",
      "Aleksandra Faust",
      "Evan N. Feinberg",
      "Michael V. LeVine",
      "Matteus Pan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25571v1",
    "title": "Perturbation Bounds for Low-Rank Inverse Approximations under Noise",
    "summary": "Low-rank pseudoinverses are widely used to approximate matrix inverses in\nscalable machine learning, optimization, and scientific computing. However,\nreal-world matrices are often observed with noise, arising from sampling,\nsketching, and quantization. The spectral-norm robustness of low-rank inverse\napproximations remains poorly understood. We systematically study the\nspectral-norm error $\\| (\\tilde{A}^{-1})_p - A_p^{-1} \\|$ for an $n\\times n$\nsymmetric matrix $A$, where $A_p^{-1}$ denotes the best rank-\\(p\\)\napproximation of $A^{-1}$, and $\\tilde{A} = A + E$ is a noisy observation.\nUnder mild assumptions on the noise, we derive sharp non-asymptotic\nperturbation bounds that reveal how the error scales with the eigengap,\nspectral decay, and noise alignment with low-curvature directions of $A$. Our\nanalysis introduces a novel application of contour integral techniques to the\n\\emph{non-entire} function $f(z) = 1/z$, yielding bounds that improve over\nnaive adaptations of classical full-inverse bounds by up to a factor of\n$\\sqrt{n}$. Empirically, our bounds closely track the true perturbation error\nacross a variety of real-world and synthetic matrices, while estimates based on\nclassical results tend to significantly overpredict. These findings offer\npractical, spectrum-aware guarantees for low-rank inverse approximations in\nnoisy computational environments.",
    "published": "2025-10-29T14:40:12Z",
    "updated": "2025-10-29T14:40:12Z",
    "link": "http://arxiv.org/pdf/2510.25571v1.pdf",
    "category": [
      "cs.LG",
      "cs.DS",
      "cs.NA",
      "math.NA",
      "math.SP",
      "math.ST",
      "stat.TH"
    ],
    "authors": [
      "Phuc Tran",
      "Nisheeth K. Vishnoi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25569v1",
    "title": "A Framework for Bounding Deterministic Risk with PAC-Bayes: Applications\n  to Majority Votes",
    "summary": "PAC-Bayes is a popular and efficient framework for obtaining generalization\nguarantees in situations involving uncountable hypothesis spaces.\nUnfortunately, in its classical formulation, it only provides guarantees on the\nexpected risk of a randomly sampled hypothesis. This requires stochastic\npredictions at test time, making PAC-Bayes unusable in many practical\nsituations where a single deterministic hypothesis must be deployed. We propose\na unified framework to extract guarantees holding for a single hypothesis from\nstochastic PAC-Bayesian guarantees. We present a general oracle bound and\nderive from it a numerical bound and a specialization to majority vote. We\nempirically show that our approach consistently outperforms popular baselines\n(by up to a factor of 2) when it comes to generalization bounds on\ndeterministic classifiers.",
    "published": "2025-10-29T14:38:35Z",
    "updated": "2025-10-29T14:38:35Z",
    "link": "http://arxiv.org/pdf/2510.25569v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Benjamin Leblanc",
      "Pascal Germain"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23999v2",
    "title": "Auto-Adaptive PINNs with Applications to Phase Transitions",
    "summary": "We propose an adaptive sampling method for the training of Physics Informed\nNeural Networks (PINNs) which allows for sampling based on an arbitrary\nproblem-specific heuristic which may depend on the network and its gradients.\nIn particular we focus our analysis on the Allen-Cahn equations, attempting to\naccurately resolve the characteristic interfacial regions using a PINN without\nany post-hoc resampling. In experiments, we show the effectiveness of these\nmethods over residual-adaptive frameworks.",
    "published": "2025-10-28T02:03:39Z",
    "updated": "2025-10-29T14:38:26Z",
    "link": "http://arxiv.org/pdf/2510.23999v2.pdf",
    "category": [
      "math.NA",
      "cs.LG",
      "cs.NA"
    ],
    "authors": [
      "Kevin Buck",
      "Woojeong Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25566v1",
    "title": "PitchFlower: A flow-based neural audio codec with pitch controllability",
    "summary": "We present PitchFlower, a flow-based neural audio codec with explicit pitch\ncontrollability. Our approach enforces disentanglement through a simple\nperturbation: during training, F0 contours are flattened and randomly shifted,\nwhile the true F0 is provided as conditioning. A vector-quantization bottleneck\nprevents pitch recovery, and a flow-based decoder generates high quality audio.\nExperiments show that PitchFlower achieves more accurate pitch control than\nWORLD at much higher audio quality, and outperforms SiFiGAN in controllability\nwhile maintaining comparable quality. Beyond pitch, this framework provides a\nsimple and extensible path toward disentangling other speech attributes.",
    "published": "2025-10-29T14:33:35Z",
    "updated": "2025-10-29T14:33:35Z",
    "link": "http://arxiv.org/pdf/2510.25566v1.pdf",
    "category": [
      "eess.AS",
      "cs.LG"
    ],
    "authors": [
      "Diego Torres",
      "Axel Roebel",
      "Nicolas Obin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23455v3",
    "title": "SGFusion: Stochastic Geographic Gradient Fusion in Federated Learning",
    "summary": "This paper proposes Stochastic Geographic Gradient Fusion (SGFusion), a novel\ntraining algorithm to leverage the geographic information of mobile users in\nFederated Learning (FL). SGFusion maps the data collected by mobile devices\nonto geographical zones and trains one FL model per zone, which adapts well to\nthe data and behaviors of users in that zone. SGFusion models the local\ndata-based correlation among geographical zones as a hierarchical random graph\n(HRG) optimized by Markov Chain Monte Carlo sampling. At each training step,\nevery zone fuses its local gradient with gradients derived from a small set of\nother zones sampled from the HRG. This approach enables knowledge fusion and\nsharing among geographical zones in a probabilistic and stochastic gradient\nfusion process with self-attention weights, such that \"more similar\" zones have\n\"higher probabilities\" of sharing gradients with \"larger attention weights.\"\nSGFusion remarkably improves model utility without introducing undue\ncomputational cost. Extensive theoretical and empirical results using a\nheart-rate prediction dataset collected across 6 countries show that models\ntrained with SGFusion converge with upper-bounded expected errors and\nsignificantly improve utility in all countries compared to existing approaches\nwithout notable cost in system scalability.",
    "published": "2025-10-27T15:56:19Z",
    "updated": "2025-10-29T14:29:54Z",
    "link": "http://arxiv.org/pdf/2510.23455v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Khoa Nguyen",
      "Khang Tran",
      "NhatHai Phan",
      "Cristian Borcea",
      "Ruoming Jin",
      "Issa Khalil"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25550v1",
    "title": "Robust variable selection for spatial point processes observed with\n  noise",
    "summary": "We propose a method for variable selection in the intensity function of\nspatial point processes that combines sparsity-promoting estimation with\nnoise-robust model selection. As high-resolution spatial data becomes\nincreasingly available through remote sensing and automated image analysis,\nidentifying spatial covariates that influence the localization of events is\ncrucial to understand the underlying mechanism. However, results from automated\nacquisition techniques are often noisy, for example due to measurement\nuncertainties or detection errors, which leads to spurious displacements and\nmissed events. We study the impact of such noise on sparse point-process\nestimation across different models, including Poisson and Thomas processes. To\nimprove noise robustness, we propose to use stability selection based on\npoint-process subsampling and to incorporate a non-convex best-subset penalty\nto enhance model-selection performance. In extensive simulations, we\ndemonstrate that such an approach reliably recovers true covariates under\ndiverse noise scenarios and improves both selection accuracy and stability. We\nthen apply the proposed method to a forestry data set, analyzing the\ndistribution of trees in relation to elevation and soil nutrients in a tropical\nrain forest. This shows the practical utility of the method, which provides a\nsystematic framework for robust variable selection in spatial point-process\nmodels under noise, without requiring additional knowledge of the process.",
    "published": "2025-10-29T14:18:08Z",
    "updated": "2025-10-29T14:18:08Z",
    "link": "http://arxiv.org/pdf/2510.25550v1.pdf",
    "category": [
      "stat.ME",
      "cs.LG",
      "stat.CO",
      "stat.ML"
    ],
    "authors": [
      "Dominik Sturm",
      "Ivo F. Sbalzarini"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2402.12828v2",
    "title": "Tracking the Median of Gradients with a Stochastic Proximal Point Method",
    "summary": "There are several applications of stochastic optimization where one can\nbenefit from a robust estimate of the gradient. For example, domains such as\ndistributed learning with corrupted nodes, the presence of large outliers in\nthe training data, learning under privacy constraints, or even heavy-tailed\nnoise due to the dynamics of the algorithm itself. Here we study SGD with\nrobust gradient estimators based on estimating the median.\n  We first derive iterative methods based on the stochastic proximal point\nmethod for computing the median gradient and generalizations thereof. Then we\npropose an algorithm estimating the median gradient across iterations, and find\nthat several well known methods are particular cases of this framework. For\ninstance, we observe that different forms of clipping allow to compute online\nestimators of the median of gradients, in contrast to (heavy-ball) momentum,\nwhich corresponds to an online estimator of the mean. Finally, we provide a\ntheoretical framework for an algorithm computing the median gradient across\nsamples, and show that the resulting method can converge even under\nheavy-tailed, state-dependent noise.",
    "published": "2024-02-20T08:54:07Z",
    "updated": "2025-10-29T14:17:09Z",
    "link": "http://arxiv.org/pdf/2402.12828v2.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "math.OC",
      "90C26, 68T07, 62-08"
    ],
    "authors": [
      "Fabian Schaipp",
      "Guillaume Garrigos",
      "Umut Simsekli",
      "Robert Gower"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.12662v3",
    "title": "TuneNSearch: a hybrid transfer learning and local search approach for\n  solving vehicle routing problems",
    "summary": "This paper introduces TuneNSearch, a hybrid transfer learning and local\nsearch approach for addressing diverse variants of the vehicle routing problem\n(VRP). Our method uses reinforcement learning to generate high-quality\nsolutions, which are subsequently refined by an efficient local search\nprocedure. To ensure broad adaptability across VRP variants, TuneNSearch begins\nwith a pre-training phase on the multi-depot VRP (MDVRP), followed by a\nfine-tuning phase to adapt it to other problem formulations. The learning phase\nutilizes a Transformer-based architecture enhanced with edge-aware attention,\nwhich integrates edge distances directly into the attention mechanism to better\ncapture spatial relationships inherent to routing problems. We show that the\npre-trained model generalizes effectively to single-depot variants, achieving\nperformance comparable to models trained specifically on single-depot\ninstances. Simultaneously, it maintains strong performance on multi-depot\nvariants, an ability that models pre-trained solely on single-depot problems\nlack. For example, on 100-node instances of multi-depot variants, TuneNSearch\noutperforms a model pre-trained on the CVRP by 44%. In contrast, on 100-node\ninstances of single-depot variants, TuneNSearch performs similar to the CVRP\nmodel. To validate the effectiveness of our method, we conduct extensive\ncomputational experiments on public benchmark and randomly generated instances.\nAcross multiple CVRPLIB datasets, TuneNSearch consistently achieves performance\ndeviations of less than 3% from the best-known solutions in the literature,\ncompared to 6-25% for other neural-based models, depending on problem\ncomplexity. Overall, our approach demonstrates strong generalization to\ndifferent problem sizes, instance distributions, and VRP formulations, while\nmaintaining polynomial runtime complexity despite the integration of the local\nsearch algorithm.",
    "published": "2025-03-16T21:34:11Z",
    "updated": "2025-10-29T14:16:37Z",
    "link": "http://arxiv.org/pdf/2503.12662v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Arthur Corrêa",
      "Cristóvão Silva",
      "Liming Xu",
      "Alexandra Brintrup",
      "Samuel Moniz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.18962v2",
    "title": "Lift What You Can: Green Online Learning with Heterogeneous Ensembles",
    "summary": "Ensemble methods for stream mining necessitate managing multiple models and\nupdating them as data distributions evolve. Considering the calls for more\nsustainability, established methods are however not sufficiently considerate of\nensemble members' computational expenses and instead overly focus on predictive\ncapabilities. To address these challenges and enable green online learning, we\npropose heterogeneous online ensembles (HEROS). For every training step, HEROS\nchooses a subset of models from a pool of models initialized with diverse\nhyperparameter choices under resource constraints to train. We introduce a\nMarkov decision process to theoretically capture the trade-offs between\npredictive performance and sustainability constraints. Based on this framework,\nwe present different policies for choosing which models to train on incoming\ndata. Most notably, we propose the novel $\\zeta$-policy, which focuses on\ntraining near-optimal models at reduced costs. Using a stochastic model, we\ntheoretically prove that our $\\zeta$-policy achieves near optimal performance\nwhile using fewer resources compared to the best performing policy. In our\nexperiments across 11 benchmark datasets, we find empiric evidence that our\n$\\zeta$-policy is a strong contribution to the state-of-the-art, demonstrating\nhighly accurate performance, in some cases even outperforming competitors, and\nsimultaneously being much more resource-friendly.",
    "published": "2025-09-23T13:14:37Z",
    "updated": "2025-10-29T14:11:14Z",
    "link": "http://arxiv.org/pdf/2509.18962v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Kirsten Köbschall",
      "Sebastian Buschjäger",
      "Raphael Fischer",
      "Lisa Hartung",
      "Stefan Kramer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25544v1",
    "title": "Error Bounds and Optimal Schedules for Masked Diffusions with Factorized\n  Approximations",
    "summary": "Recently proposed generative models for discrete data, such as Masked\nDiffusion Models (MDMs), exploit conditional independence approximations to\nreduce the computational cost of popular Auto-Regressive Models (ARMs), at the\nprice of some bias in the sampling distribution. We study the resulting\ncomputation-vs-accuracy trade-off, providing general error bounds (in relative\nentropy) that depend only on the average number of tokens generated per\niteration and are independent of the data dimensionality (i.e. sequence\nlength), thus supporting the empirical success of MDMs. We then investigate the\ngain obtained by using non-constant schedule sizes (i.e. varying the number of\nunmasked tokens during the generation process) and identify the optimal\nschedule as a function of a so-called information profile of the data\ndistribution, thus allowing for a principled optimization of schedule sizes. We\ndefine methods directly as sampling algorithms and do not use classical\nderivations as time-reversed diffusion processes, leading us to simple and\ntransparent proofs.",
    "published": "2025-10-29T14:11:03Z",
    "updated": "2025-10-29T14:11:03Z",
    "link": "http://arxiv.org/pdf/2510.25544v1.pdf",
    "category": [
      "stat.ML",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "stat.CO"
    ],
    "authors": [
      "Hugo Lavenant",
      "Giacomo Zanella"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25542v1",
    "title": "Transformers Provably Learn Directed Acyclic Graphs via Kernel-Guided\n  Mutual Information",
    "summary": "Uncovering hidden graph structures underlying real-world data is a critical\nchallenge with broad applications across scientific domains. Recently,\ntransformer-based models leveraging the attention mechanism have demonstrated\nstrong empirical success in capturing complex dependencies within graphs.\nHowever, the theoretical understanding of their training dynamics has been\nlimited to tree-like graphs, where each node depends on a single parent.\nExtending provable guarantees to more general directed acyclic graphs (DAGs) --\nwhich involve multiple parents per node -- remains challenging, primarily due\nto the difficulty in designing training objectives that enable different\nattention heads to separately learn multiple different parent relationships.\n  In this work, we address this problem by introducing a novel\ninformation-theoretic metric: the kernel-guided mutual information (KG-MI),\nbased on the $f$-divergence. Our objective combines KG-MI with a multi-head\nattention framework, where each head is associated with a distinct marginal\ntransition kernel to model diverse parent-child dependencies effectively. We\nprove that, given sequences generated by a $K$-parent DAG, training a\nsingle-layer, multi-head transformer via gradient ascent converges to the\nglobal optimum in polynomial time. Furthermore, we characterize the attention\nscore patterns at convergence. In addition, when particularizing the\n$f$-divergence to the KL divergence, the learned attention scores accurately\nreflect the ground-truth adjacency matrix, thereby provably recovering the\nunderlying graph structure. Experimental results validate our theoretical\nfindings.",
    "published": "2025-10-29T14:07:12Z",
    "updated": "2025-10-29T14:07:12Z",
    "link": "http://arxiv.org/pdf/2510.25542v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Yuan Cheng",
      "Yu Huang",
      "Zhe Xiong",
      "Yingbin Liang",
      "Vincent Y. F. Tan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25514v1",
    "title": "Convergence of off-policy TD(0) with linear function approximation for\n  reversible Markov chains",
    "summary": "We study the convergence of off-policy TD(0) with linear function\napproximation when used to approximate the expected discounted reward in a\nMarkov chain. It is well known that the combination of off-policy learning and\nfunction approximation can lead to divergence of the algorithm. Existing\nresults for this setting modify the algorithm, for instance by reweighing the\nupdates using importance sampling. This establishes convergence at the expense\nof additional complexity. In contrast, our approach is to analyse the standard\nalgorithm, but to restrict our attention to the class of reversible Markov\nchains. We demonstrate convergence under this mild reversibility condition on\nthe structure of the chain, which in many applications can be assumed using\ndomain knowledge. In particular, we establish a convergence guarantee under an\nupper bound on the discount factor in terms of the difference between the\non-policy and off-policy process. This improves upon known results in the\nliterature that state that convergence holds for a sufficiently small discount\nfactor by establishing an explicit bound. Convergence is with probability one\nand achieves projected Bellman error equal to zero. To obtain these results, we\nadapt the stochastic approximation framework that was used by Tsitsiklis and\nVan Roy [1997 for the on-policy case, to the off-policy case. We illustrate our\nresults using different types of reversible Markov chains, such as\none-dimensional random walks and random walks on a weighted graph.",
    "published": "2025-10-29T13:38:24Z",
    "updated": "2025-10-29T13:38:24Z",
    "link": "http://arxiv.org/pdf/2510.25514v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Maik Overmars",
      "Jasper Goseling",
      "Richard Boucherie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25509v1",
    "title": "Support Vector Machine-Based Burnout Risk Prediction with an Interactive\n  Interface for Organizational Use",
    "summary": "Burnout is a psychological syndrome marked by emotional exhaustion,\ndepersonalization, and reduced personal accomplishment, with a significant\nimpact on individual well-being and organizational performance. This study\nproposes a machine learning approach to predict burnout risk using the\nHackerEarth Employee Burnout Challenge dataset. Three supervised algorithms\nwere evaluated: nearest neighbors (KNN), random forest, and support vector\nmachine (SVM), with model performance evaluated through 30-fold\ncross-validation using the determination coefficient (R2). Among the models\ntested, SVM achieved the highest predictive performance (R2 = 0.84) and was\nstatistically superior to KNN and Random Forest based on paired $t$-tests. To\nensure practical applicability, an interactive interface was developed using\nStreamlit, allowing non-technical users to input data and receive burnout risk\npredictions. The results highlight the potential of machine learning to support\nearly detection of burnout and promote data-driven mental health strategies in\norganizational settings.",
    "published": "2025-10-29T13:32:59Z",
    "updated": "2025-10-29T13:32:59Z",
    "link": "http://arxiv.org/pdf/2510.25509v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Bruno W. G. Teodosio",
      "Mário J. O. T. Lira",
      "Pedro H. M. Araújo",
      "Lucas R. C. Farias"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25497v1",
    "title": "Right for the Right Reasons: Avoiding Reasoning Shortcuts via\n  Prototypical Neurosymbolic AI",
    "summary": "Neurosymbolic AI is growing in popularity thanks to its ability to combine\nneural perception and symbolic reasoning in end-to-end trainable models.\nHowever, recent findings reveal these are prone to shortcut reasoning, i.e., to\nlearning unindented concepts--or neural predicates--which exploit spurious\ncorrelations to satisfy the symbolic constraints. In this paper, we address\nreasoning shortcuts at their root cause and we introduce prototypical\nneurosymbolic architectures. These models are able to satisfy the symbolic\nconstraints (be right) because they have learnt the correct basic concepts (for\nthe right reasons) and not because of spurious correlations, even in extremely\nlow data regimes. Leveraging the theory of prototypical learning, we\ndemonstrate that we can effectively avoid reasoning shortcuts by training the\nmodels to satisfy the background knowledge while taking into account the\nsimilarity of the input with respect to the handful of labelled datapoints. We\nextensively validate our approach on the recently proposed rsbench benchmark\nsuite in a variety of settings and tasks with very scarce supervision: we show\nsignificant improvements in learning the right concepts both in synthetic tasks\n(MNIST-EvenOdd and Kand-Logic) and real-world, high-stake ones (BDD-OIA). Our\nfindings pave the way to prototype grounding as an effective,\nannotation-efficient strategy for safe and reliable neurosymbolic learning.",
    "published": "2025-10-29T13:21:28Z",
    "updated": "2025-10-29T13:21:28Z",
    "link": "http://arxiv.org/pdf/2510.25497v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Luca Andolfi",
      "Eleonora Giunchiglia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25480v1",
    "title": "Gradient-Weight Alignment as a Train-Time Proxy for Generalization in\n  Classification Tasks",
    "summary": "Robust validation metrics remain essential in contemporary deep learning, not\nonly to detect overfitting and poor generalization, but also to monitor\ntraining dynamics. In the supervised classification setting, we investigate\nwhether interactions between training data and model weights can yield such a\nmetric that both tracks generalization during training and attributes\nperformance to individual training samples. We introduce Gradient-Weight\nAlignment (GWA), quantifying the coherence between per-sample gradients and\nmodel weights. We show that effective learning corresponds to coherent\nalignment, while misalignment indicates deteriorating generalization. GWA is\nefficiently computable during training and reflects both sample-specific\ncontributions and dataset-wide learning dynamics. Extensive experiments show\nthat GWA accurately predicts optimal early stopping, enables principled model\ncomparisons, and identifies influential training samples, providing a\nvalidation-set-free approach for model analysis directly from the training\ndata.",
    "published": "2025-10-29T13:04:17Z",
    "updated": "2025-10-29T13:04:17Z",
    "link": "http://arxiv.org/pdf/2510.25480v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Florian A. Hölzl",
      "Daniel Rueckert",
      "Georgios Kaissis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23463v2",
    "title": "Differential Privacy as a Perk: Federated Learning over Multiple-Access\n  Fading Channels with a Multi-Antenna Base Station",
    "summary": "Federated Learning (FL) is a distributed learning paradigm that preserves\nprivacy by eliminating the need to exchange raw data during training. In its\nprototypical edge instantiation with underlying wireless transmissions enabled\nby analog over-the-air computing (AirComp), referred to as \\emph{over-the-air\nFL (AirFL)}, the inherent channel noise plays a unique role of \\emph{frenemy}\nin the sense that it degrades training due to noisy global aggregation while\nproviding a natural source of randomness for privacy-preserving mechanisms,\nformally quantified by \\emph{differential privacy (DP)}. It remains,\nnevertheless, challenging to effectively harness such channel impairments, as\nprior arts, under assumptions of either simple channel models or restricted\ntypes of loss functions, mostly considering (local) DP enhancement with a\nsingle-round or non-convergent bound on privacy loss. In this paper, we study\nAirFL over multiple-access fading channels with a multi-antenna base station\n(BS) subject to user-level DP requirements. Despite a recent study, which\nclaimed in similar settings that artificial noise (AN) must be injected to\nensure DP in general, we demonstrate, on the contrary, that DP can be gained as\na \\emph{perk} even \\emph{without} employing any AN. Specifically, we derive a\nnovel bound on DP that converges under general bounded-domain assumptions on\nmodel parameters, along with a convergence bound with general smooth and\nnon-convex loss functions. Next, we optimize over receive beamforming and power\nallocations to characterize the optimal convergence-privacy trade-offs, which\nalso reveal explicit conditions in which DP is achievable without compromising\ntraining. Finally, our theoretical findings are validated by extensive\nnumerical results.",
    "published": "2025-10-27T16:01:15Z",
    "updated": "2025-10-29T11:16:37Z",
    "link": "http://arxiv.org/pdf/2510.23463v2.pdf",
    "category": [
      "cs.LG",
      "cs.CR",
      "stat.ML"
    ],
    "authors": [
      "Hao Liang",
      "Haifeng Wen",
      "Kaishun Wu",
      "Hong Xing"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2407.13420v2",
    "title": "Exploring End-to-end Differentiable Neural Charged Particle Tracking --\n  A Loss Landscape Perspective",
    "summary": "Measurement and analysis of high energetic particles for scientific, medical\nor industrial applications is a complex procedure, requiring the design of\nsophisticated detector and data processing systems. The development of adaptive\nand differentiable software pipelines using a combination of conventional and\nmachine learning algorithms is therefore getting ever more important to\noptimize and operate the system efficiently while maintaining end-to-end (E2E)\ndifferentiability. We propose for the application of charged particle tracking\nan E2E differentiable decision-focused learning scheme using graph neural\nnetworks with combinatorial components solving a linear assignment problem for\neach detector layer. We demonstrate empirically that including differentiable\nvariations of discrete assignment operations allows for efficient network\noptimization, working better or on par with approaches that lack E2E\ndifferentiability. In additional studies, we dive deeper into the optimization\nprocess and provide further insights from a loss landscape perspective. We\ndemonstrate that while both methods converge into similar performing, globally\nwell-connected regions, they suffer under substantial predictive instability\nacross initialization and optimization methods, which can have unpredictable\nconsequences on the performance of downstream tasks such as image\nreconstruction. We also point out a dependency between the interpolation factor\nof the gradient estimator and the prediction stability of the model, suggesting\nthe choice of sufficiently small values. Given the strong global connectivity\nof learned solutions and the excellent training performance, we argue that E2E\ndifferentiability provides, besides the general availability of gradient\ninformation, an important tool for robust particle tracking to mitigate\nprediction instabilities by favoring solutions that perform well on downstream\ntasks.",
    "published": "2024-07-18T11:42:58Z",
    "updated": "2025-10-29T11:02:41Z",
    "link": "http://arxiv.org/pdf/2407.13420v2.pdf",
    "category": [
      "physics.comp-ph",
      "cs.LG"
    ],
    "authors": [
      "Tobias Kortus",
      "Ralf Keidel",
      "Nicolas R. Gauger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.21758v3",
    "title": "Taxonomy and Trends in Reinforcement Learning for Robotics and Control\n  Systems: A Structured Review",
    "summary": "Reinforcement learning (RL) has become a foundational approach for enabling\nintelligent robotic behavior in dynamic and uncertain environments. This work\npresents an in-depth review of RL principles, advanced deep reinforcement\nlearning (DRL) algorithms, and their integration into robotic and control\nsystems. Beginning with the formalism of Markov Decision Processes (MDPs), the\nstudy outlines essential elements of the agent-environment interaction and\nexplores core algorithmic strategies including actor-critic methods,\nvalue-based learning, and policy gradients. Emphasis is placed on modern DRL\ntechniques such as DDPG, TD3, PPO, and SAC, which have shown promise in solving\nhigh-dimensional, continuous control tasks. A structured taxonomy is introduced\nto categorize RL applications across domains such as locomotion, manipulation,\nmulti-agent coordination, and human-robot interaction, along with training\nmethodologies and deployment readiness levels. The review synthesizes recent\nresearch efforts, highlighting technical trends, design patterns, and the\ngrowing maturity of RL in real-world robotics. Overall, this work aims to\nbridge theoretical advances with practical implementations, providing a\nconsolidated perspective on the evolving role of RL in autonomous robotic\nsystems.",
    "published": "2025-10-11T20:16:32Z",
    "updated": "2025-10-29T11:02:07Z",
    "link": "http://arxiv.org/pdf/2510.21758v3.pdf",
    "category": [
      "cs.RO",
      "cs.LG"
    ],
    "authors": [
      "Kumater Ter",
      "Ore-Ofe Ajayi",
      "Daniel Udekwe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.18376v2",
    "title": "GnnXemplar: Exemplars to Explanations -- Natural Language Rules for\n  Global GNN Interpretability",
    "summary": "Graph Neural Networks (GNNs) are widely used for node classification, yet\ntheir opaque decision-making limits trust and adoption. While local\nexplanations offer insights into individual predictions, global explanation\nmethods, those that characterize an entire class, remain underdeveloped.\nExisting global explainers rely on motif discovery in small graphs, an approach\nthat breaks down in large, real-world settings where subgraph repetition is\nrare, node attributes are high-dimensional, and predictions arise from complex\nstructure-attribute interactions. We propose GnnXemplar, a novel global\nexplainer inspired from Exemplar Theory from cognitive science. GnnXemplar\nidentifies representative nodes in the GNN embedding space, exemplars, and\nexplains predictions using natural language rules derived from their\nneighborhoods. Exemplar selection is framed as a coverage maximization problem\nover reverse k-nearest neighbors, for which we provide an efficient greedy\napproximation. To derive interpretable rules, we employ a self-refining prompt\nstrategy using large language models (LLMs). Experiments across diverse\nbenchmarks show that GnnXemplar significantly outperforms existing methods in\nfidelity, scalability, and human interpretability, as validated by a user study\nwith 60 participants.",
    "published": "2025-09-22T19:58:17Z",
    "updated": "2025-10-29T10:57:22Z",
    "link": "http://arxiv.org/pdf/2509.18376v2.pdf",
    "category": [
      "cs.LG",
      "cs.SI"
    ],
    "authors": [
      "Burouj Armgaan",
      "Eshan Jain",
      "Harsh Pandey",
      "Mahesh Chandran",
      "Sayan Ranu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25379v1",
    "title": "A Deep Learning Framework for Multi-Operator Learning: Architectures and\n  Approximation Theory",
    "summary": "While many problems in machine learning focus on learning mappings between\nfinite-dimensional spaces, scientific applications require approximating\nmappings between function spaces, i.e., operators. We study the problem of\nlearning collections of operators and provide both theoretical and empirical\nadvances. We distinguish between two regimes: (i) multiple operator learning,\nwhere a single network represents a continuum of operators parameterized by a\nparametric function, and (ii) learning several distinct single operators, where\neach operator is learned independently. For the multiple operator case, we\nintroduce two new architectures, $\\mathrm{MNO}$ and $\\mathrm{MONet}$, and\nestablish universal approximation results in three settings: continuous,\nintegrable, or Lipschitz operators. For the latter, we further derive explicit\nscaling laws that quantify how the network size must grow to achieve a target\napproximation accuracy. For learning several single operators, we develop a\nframework for balancing architectural complexity across subnetworks and show\nhow approximation order determines computational efficiency. Empirical\nexperiments on parametric PDE benchmarks confirm the strong expressive power\nand efficiency of the proposed architectures. Overall, this work establishes a\nunified theoretical and practical foundation for scalable neural operator\nlearning across multiple operators.",
    "published": "2025-10-29T10:52:02Z",
    "updated": "2025-10-29T10:52:02Z",
    "link": "http://arxiv.org/pdf/2510.25379v1.pdf",
    "category": [
      "cs.LG",
      "cs.NA",
      "math.NA"
    ],
    "authors": [
      "Adrien Weihs",
      "Jingmin Sun",
      "Zecheng Zhang",
      "Hayden Schaeffer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25372v1",
    "title": "Prompt Estimation from Prototypes for Federated Prompt Tuning of Vision\n  Transformers",
    "summary": "Visual Prompt Tuning (VPT) of pre-trained Vision Transformers (ViTs) has\nproven highly effective as a parameter-efficient fine-tuning technique for\nadapting large models to downstream tasks with limited data. Its parameter\nefficiency makes it particularly suitable for Federated Learning (FL), where\nboth communication and computation budgets are often constrained. However,\nglobal prompt tuning struggles to generalize across heterogeneous clients,\nwhile personalized tuning overfits to local data and lacks generalization. We\npropose PEP-FedPT (Prompt Estimation from Prototypes for Federated Prompt\nTuning), a unified framework designed to achieve both generalization and\npersonalization in federated prompt tuning of ViTs. Within this framework, we\nintroduce the novel Class-Contextualized Mixed Prompt (CCMP) - based on\nclass-specific prompts maintained alongside a globally shared prompt. For each\ninput, CCMP adaptively combines class-specific prompts using weights derived\nfrom global class prototypes and client class priors. This approach enables\nper-sample prompt personalization without storing client-dependent trainable\nparameters. The prompts are collaboratively optimized via traditional federated\naveraging technique on the same. Comprehensive evaluations on CIFAR-100,\nTinyImageNet, DomainNet, and iNaturalist datasets demonstrate that PEP-FedPT\nconsistently surpasses the state-of-the-art baselines under diverse data\nheterogeneity scenarios, establishing a strong foundation for efficient and\ngeneralizable federated prompt tuning of Vision Transformers.",
    "published": "2025-10-29T10:42:56Z",
    "updated": "2025-10-29T10:42:56Z",
    "link": "http://arxiv.org/pdf/2510.25372v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "M Yashwanth",
      "Sharannya Ghosh",
      "Aditay Tripathi",
      "Anirban Chakraborty"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.14866v2",
    "title": "OS-Harm: A Benchmark for Measuring Safety of Computer Use Agents",
    "summary": "Computer use agents are LLM-based agents that can directly interact with a\ngraphical user interface, by processing screenshots or accessibility trees.\nWhile these systems are gaining popularity, their safety has been largely\noverlooked, despite the fact that evaluating and understanding their potential\nfor harmful behavior is essential for widespread adoption. To address this gap,\nwe introduce OS-Harm, a new benchmark for measuring safety of computer use\nagents. OS-Harm is built on top of the OSWorld environment and aims to test\nmodels across three categories of harm: deliberate user misuse, prompt\ninjection attacks, and model misbehavior. To cover these cases, we create 150\ntasks that span several types of safety violations (harassment, copyright\ninfringement, disinformation, data exfiltration, etc.) and require the agent to\ninteract with a variety of OS applications (email client, code editor, browser,\netc.). Moreover, we propose an automated judge to evaluate both accuracy and\nsafety of agents that achieves high agreement with human annotations (0.76 and\n0.79 F1 score). We evaluate computer use agents based on a range of frontier\nmodels - such as o4-mini, Claude 3.7 Sonnet, Gemini 2.5 Pro - and provide\ninsights into their safety. In particular, all models tend to directly comply\nwith many deliberate misuse queries, are relatively vulnerable to static prompt\ninjections, and occasionally perform unsafe actions. The OS-Harm benchmark is\navailable at https://github.com/tml-epfl/os-harm.",
    "published": "2025-06-17T17:59:31Z",
    "updated": "2025-10-29T10:34:04Z",
    "link": "http://arxiv.org/pdf/2506.14866v2.pdf",
    "category": [
      "cs.SE",
      "cs.LG"
    ],
    "authors": [
      "Thomas Kuntz",
      "Agatha Duzan",
      "Hao Zhao",
      "Francesco Croce",
      "Zico Kolter",
      "Nicolas Flammarion",
      "Maksym Andriushchenko"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25361v1",
    "title": "Parameter Averaging in Link Prediction",
    "summary": "Ensemble methods are widely employed to improve generalization in machine\nlearning. This has also prompted the adoption of ensemble learning for the\nknowledge graph embedding (KGE) models in performing link prediction. Typical\napproaches to this end train multiple models as part of the ensemble, and the\ndiverse predictions are then averaged. However, this approach has some\nsignificant drawbacks. For instance, the computational overhead of training\nmultiple models increases latency and memory overhead. In contrast, model\nmerging approaches offer a promising alternative that does not require training\nmultiple models. In this work, we introduce model merging, specifically\nweighted averaging, in KGE models. Herein, a running average of model\nparameters from a training epoch onward is maintained and used for predictions.\nTo address this, we additionally propose an approach that selectively updates\nthe running average of the ensemble model parameters only when the\ngeneralization performance improves on a validation dataset. We evaluate these\ntwo different weighted averaging approaches on link prediction tasks, comparing\nthe state-of-the-art benchmark ensemble approach. Additionally, we evaluate the\nweighted averaging approach considering literal-augmented KGE models and\nmulti-hop query answering tasks as well. The results demonstrate that the\nproposed weighted averaging approach consistently improves performance across\ndiverse evaluation settings.",
    "published": "2025-10-29T10:32:39Z",
    "updated": "2025-10-29T10:32:39Z",
    "link": "http://arxiv.org/pdf/2510.25361v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Rupesh Sapkota",
      "Caglar Demir",
      "Arnab Sharma",
      "Axel-Cyrille Ngonga Ngomo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25354v1",
    "title": "Analysis of Semi-Supervised Learning on Hypergraphs",
    "summary": "Hypergraphs provide a natural framework for modeling higher-order\ninteractions, yet their theoretical underpinnings in semi-supervised learning\nremain limited. We provide an asymptotic consistency analysis of variational\nlearning on random geometric hypergraphs, precisely characterizing the\nconditions ensuring the well-posedness of hypergraph learning as well as\nshowing convergence to a weighted $p$-Laplacian equation. Motivated by this, we\npropose Higher-Order Hypergraph Learning (HOHL), which regularizes via powers\nof Laplacians from skeleton graphs for multiscale smoothness. HOHL converges to\na higher-order Sobolev seminorm. Empirically, it performs strongly on standard\nbaselines.",
    "published": "2025-10-29T10:19:32Z",
    "updated": "2025-10-29T10:19:32Z",
    "link": "http://arxiv.org/pdf/2510.25354v1.pdf",
    "category": [
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "authors": [
      "Adrien Weihs",
      "Andrea Bertozzi",
      "Matthew Thorpe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25348v1",
    "title": "Beyond Leakage and Complexity: Towards Realistic and Efficient\n  Information Cascade Prediction",
    "summary": "Information cascade popularity prediction is a key problem in analyzing\ncontent diffusion in social networks. However, current related works suffer\nfrom three critical limitations: (1) temporal leakage in current\nevaluation--random cascade-based splits allow models to access future\ninformation, yielding unrealistic results; (2) feature-poor datasets that lack\ndownstream conversion signals (e.g., likes, comments, or purchases), which\nlimits more practical applications; (3) computational inefficiency of complex\ngraph-based methods that require days of training for marginal gains. We\nsystematically address these challenges from three perspectives: task setup,\ndataset construction, and model design. First, we propose a time-ordered\nsplitting strategy that chronologically partitions data into consecutive\nwindows, ensuring models are evaluated on genuine forecasting tasks without\nfuture information leakage. Second, we introduce Taoke, a large-scale\ne-commerce cascade dataset featuring rich promoter/product attributes and\nground-truth purchase conversions--capturing the complete diffusion lifecycle\nfrom promotion to monetization. Third, we develop CasTemp, a lightweight\nframework that efficiently models cascade dynamics through temporal walks,\nJaccard-based neighbor selection for inter-cascade dependencies, and GRU-based\nencoding with time-aware attention. Under leak-free evaluation, CasTemp\nachieves state-of-the-art performance across four datasets with\norders-of-magnitude speedup. Notably, it excels at predicting second-stage\npopularity conversions--a practical task critical for real-world applications.",
    "published": "2025-10-29T10:06:08Z",
    "updated": "2025-10-29T10:06:08Z",
    "link": "http://arxiv.org/pdf/2510.25348v1.pdf",
    "category": [
      "cs.LG",
      "cs.SI"
    ],
    "authors": [
      "Jie Peng",
      "Rui Wang",
      "Qiang Wang",
      "Zhewei Wei",
      "Bin Tong",
      "Guan Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25347v1",
    "title": "3D CT-Based Coronary Calcium Assessment: A Feature-Driven Machine\n  Learning Framework",
    "summary": "Coronary artery calcium (CAC) scoring plays a crucial role in the early\ndetection and risk stratification of coronary artery disease (CAD). In this\nstudy, we focus on non-contrast coronary computed tomography angiography (CCTA)\nscans, which are commonly used for early calcification detection in clinical\nsettings. To address the challenge of limited annotated data, we propose a\nradiomics-based pipeline that leverages pseudo-labeling to generate training\nlabels, thereby eliminating the need for expert-defined segmentations.\nAdditionally, we explore the use of pretrained foundation models, specifically\nCT-FM and RadImageNet, to extract image features, which are then used with\ntraditional classifiers. We compare the performance of these deep learning\nfeatures with that of radiomics features. Evaluation is conducted on a clinical\nCCTA dataset comprising 182 patients, where individuals are classified into two\ngroups: zero versus non-zero calcium scores. We further investigate the impact\nof training on non-contrast datasets versus combined contrast and non-contrast\ndatasets, with testing performed only on non contrast scans. Results show that\nradiomics-based models significantly outperform CNN-derived embeddings from\nfoundation models (achieving 84% accuracy and p<0.05), despite the\nunavailability of expert annotations.",
    "published": "2025-10-29T10:04:47Z",
    "updated": "2025-10-29T10:04:47Z",
    "link": "http://arxiv.org/pdf/2510.25347v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG",
      "68U10",
      "I.2.1"
    ],
    "authors": [
      "Ayman Abaid",
      "Gianpiero Guidone",
      "Sara Alsubai",
      "Foziyah Alquahtani",
      "Talha Iqbal",
      "Ruth Sharif",
      "Hesham Elzomor",
      "Emiliano Bianchini",
      "Naeif Almagal",
      "Michael G. Madden",
      "Faisal Sharif",
      "Ihsan Ullah"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25323v1",
    "title": "CDFlow: Building Invertible Layers with Circulant and Diagonal Matrices",
    "summary": "Normalizing flows are deep generative models that enable efficient likelihood\nestimation and sampling through invertible transformations. A key challenge is\nto design linear layers that enhance expressiveness while maintaining efficient\ncomputation of the Jacobian determinant and inverse. We introduce a novel\ninvertible linear layer based on the product of circulant and diagonal\nmatrices. This decomposition reduces parameter complexity from\n$\\mathcal{O}(n^2)$ to $\\mathcal{O}(mn)$ using $m$ diagonal matrices and $m-1$\ncirculant matrices while still approximating general linear transformations. By\nleveraging the Fast Fourier Transform, our approach reduces the time complexity\nof matrix inversion from $\\mathcal{O}(n^3)$ to $\\mathcal{O}(mn\\log n)$ and that\nof computing the log-determinant from $\\mathcal{O}(n^3)$ to $\\mathcal{O}(mn)$,\nwhere $n$ is the input dimension. We build upon this layer to develop\nCirculant-Diagonal Flow (CDFlow), which achieves strong density estimation on\nnatural image datasets and effectively models data with inherent periodic\nstructure. Furthermore, CDFlow significantly accelerates key operations in\nnormalizing flows, providing practical benefits for scalable generative\nmodeling.",
    "published": "2025-10-29T09:38:50Z",
    "updated": "2025-10-29T09:38:50Z",
    "link": "http://arxiv.org/pdf/2510.25323v1.pdf",
    "category": [
      "cs.LG",
      "68T07, 62H12",
      "I.2.6; G.3"
    ],
    "authors": [
      "Xuchen Feng",
      "Siyu Liao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25306v1",
    "title": "Hierarchical Physics-Embedded Learning for Spatiotemporal Dynamical\n  Systems",
    "summary": "Modeling complex spatiotemporal dynamics, particularly in\nfar-from-equilibrium systems, remains a grand challenge in science. The\ngoverning partial differential equations (PDEs) for these systems are often\nintractable to derive from first principles, due to their inherent complexity,\ncharacterized by high-order derivatives and strong nonlinearities, coupled with\nincomplete physical knowledge. This has spurred the development of data-driven\nmethods, yet these approaches face limitations: Purely data-driven models are\noften physically inconsistent and data-intensive, while existing\nphysics-informed methods lack the structural capacity to represent complex\noperators or systematically integrate partial physical knowledge. Here, we\npropose a hierarchical physics-embedded learning framework that fundamentally\nadvances both the forward spatiotemporal prediction and inverse discovery of\nphysical laws from sparse and noisy data. The key innovation is a two-level\narchitecture that mirrors the process of scientific discovery: the first level\nlearns fundamental symbolic components of a PDE, while the second learns their\ngoverning combinations. This hierarchical decomposition not only reduces\nlearning complexity but, more importantly, enables a structural integration of\nprior knowledge. Known physical laws are directly embedded into the models\ncomputational graph, guaranteeing physical consistency and improving data\nefficiency. By building the framework upon adaptive Fourier Neural Operators,\nwe can effectively capture the non-local dependencies and high-order operators\ncharacteristic of dynamical systems. Additionally, by structurally decoupling\nknown and unknown terms, the framework further enables interpretable discovery\nof underlying governing equations through symbolic regression, without\npresupposing functional forms.",
    "published": "2025-10-29T09:18:41Z",
    "updated": "2025-10-29T09:18:41Z",
    "link": "http://arxiv.org/pdf/2510.25306v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Xizhe Wang",
      "Xiaobin Song",
      "Qingshan Jia",
      "Hongbo Zhao",
      "Benben Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.23051v2",
    "title": "Activation Matching for Explanation Generation",
    "summary": "In this paper we introduce an activation-matching--based approach to generate\nminimal, faithful explanations for the decision-making of a pretrained\nclassifier on any given image. Given an input image \\(x\\) and a frozen model\n\\(f\\), we train a lightweight autoencoder to output a binary mask \\(m\\) such\nthat the explanation \\(e = m \\odot x\\) preserves both the model's prediction\nand the intermediate activations of \\(x\\). Our objective combines: (i)\nmulti-layer activation matching with KL divergence to align distributions and\ncross-entropy to retain the top-1 label for both the image and the explanation;\n(ii) mask priors -- L1 area for minimality, a binarization penalty for crisp\n0/1 masks, and total variation for compactness; and (iii) abductive constraints\nfor faithfulness and necessity. Together, these objectives yield small,\nhuman-interpretable masks that retain classifier behavior while discarding\nirrelevant input regions, providing practical and faithful minimalist\nexplanations for the decision making of the underlying model.",
    "published": "2025-09-27T02:12:09Z",
    "updated": "2025-10-29T09:09:07Z",
    "link": "http://arxiv.org/pdf/2509.23051v2.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Pirzada Suhail",
      "Aditya Anand",
      "Amit Sethi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25282v1",
    "title": "On the Stability of Neural Networks in Deep Learning",
    "summary": "Deep learning has achieved remarkable success across a wide range of tasks,\nbut its models often suffer from instability and vulnerability: small changes\nto the input may drastically affect predictions, while optimization can be\nhindered by sharp loss landscapes. This thesis addresses these issues through\nthe unifying perspective of sensitivity analysis, which examines how neural\nnetworks respond to perturbations at both the input and parameter levels.\n  We study Lipschitz networks as a principled way to constrain sensitivity to\ninput perturbations, thereby improving generalization, adversarial robustness,\nand training stability. To complement this architectural approach, we introduce\nregularization techniques based on the curvature of the loss function,\npromoting smoother optimization landscapes and reducing sensitivity to\nparameter variations. Randomized smoothing is also explored as a probabilistic\nmethod for enhancing robustness at decision boundaries.\n  By combining these perspectives, we develop a unified framework where\nLipschitz continuity, randomized smoothing, and curvature regularization\ninteract to address fundamental challenges in stability. The thesis contributes\nboth theoretical analysis and practical methodologies, including efficient\nspectral norm computation, novel Lipschitz-constrained layers, and improved\ncertification procedures.",
    "published": "2025-10-29T08:38:43Z",
    "updated": "2025-10-29T08:38:43Z",
    "link": "http://arxiv.org/pdf/2510.25282v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Blaise Delattre"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25244v1",
    "title": "BSFA: Leveraging the Subspace Dichotomy to Accelerate Neural Network\n  Training",
    "summary": "Recent studies \\citep{gur2018gradient,song2024does, wen2024understanding}\nhighlight a fundamental dichotomy in deep learning optimization: Although\nparameter updates along the top eigendirections of the loss Hessian (Dom-space)\ncapture most of the update magnitude, they often contribute minimally to loss\nreduction. In contrast, updates in the orthogonal component (Bulk-space) have\nsmaller magnitudes but drive most learning progress. In this work, we further\nadvance the understanding of this phenomenon and introduce the\n\\textbf{Bulk-Space-Filtration-Accelerator (BSFA)}, a novel plug-and-play\nframework. BSFA accelerates training by differentially scaling update\ncomponents projected onto these distinct subspaces, simultaneously enhancing\nstability by moderating updates in the dominant subspace and boosting\nconvergence speed by amplifying those in the bulk-space. To ensure BSFA is both\npractical and scalable for contemporary large models, we introduce two key\ninnovations: an efficient estimator using Principal Component Analysis (PCA) on\nhistorical updates for fast subspace estimation, and a block-wise strategy that\napplies this estimation on a per-parameter-block basis. These designs make BSFA\ncomputationally tractable and highly effective. We demonstrate BSFA's\nacceleration across various tasks, notably achieving approximately 2$\\times$\nspeedup when pre-training LLaMA-72M on WikiText-103 and LLaMA-134M on\nOpenWebText compared to vanilla AdamW.",
    "published": "2025-10-29T07:51:35Z",
    "updated": "2025-10-29T07:51:35Z",
    "link": "http://arxiv.org/pdf/2510.25244v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Wenjie Zhou",
      "Bohan Wang",
      "Wei Chen",
      "Xueqi Cheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25240v1",
    "title": "Generative Bayesian Optimization: Generative Models as Acquisition\n  Functions",
    "summary": "We present a general strategy for turning generative models into candidate\nsolution samplers for batch Bayesian optimization (BO). The use of generative\nmodels for BO enables large batch scaling as generative sampling, optimization\nof non-continuous design spaces, and high-dimensional and combinatorial design.\nInspired by the success of direct preference optimization (DPO), we show that\none can train a generative model with noisy, simple utility values directly\ncomputed from observations to then form proposal distributions whose densities\nare proportional to the expected utility, i.e., BO's acquisition function\nvalues. Furthermore, this approach is generalizable beyond preference-based\nfeedback to general types of reward signals and loss functions. This\nperspective avoids the construction of surrogate (regression or classification)\nmodels, common in previous methods that have used generative models for\nblack-box optimization. Theoretically, we show that the generative models\nwithin the BO process approximately follow a sequence of distributions which\nasymptotically concentrate at the global optima under certain conditions. We\nalso demonstrate this effect through experiments on challenging optimization\nproblems involving large batches in high dimensions.",
    "published": "2025-10-29T07:42:25Z",
    "updated": "2025-10-29T07:42:25Z",
    "link": "http://arxiv.org/pdf/2510.25240v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Rafael Oliveira",
      "Daniel M. Steinberg",
      "Edwin V. Bonilla"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24616v2",
    "title": "Statistical physics of deep learning: Optimal learning of a multi-layer\n  perceptron near interpolation",
    "summary": "For three decades statistical physics has been providing a framework to\nanalyse neural networks. A long-standing question remained on its capacity to\ntackle deep learning models capturing rich feature learning effects, thus going\nbeyond the narrow networks or kernel methods analysed until now. We positively\nanswer through the study of the supervised learning of a multi-layer\nperceptron. Importantly, (i) its width scales as the input dimension, making it\nmore prone to feature learning than ultra wide networks, and more expressive\nthan narrow ones or with fixed embedding layers; and (ii) we focus on the\nchallenging interpolation regime where the number of trainable parameters and\ndata are comparable, which forces the model to adapt to the task. We consider\nthe matched teacher-student setting. It provides the fundamental limits of\nlearning random deep neural network targets and helps in identifying the\nsufficient statistics describing what is learnt by an optimally trained network\nas the data budget increases. A rich phenomenology emerges with various\nlearning transitions. With enough data optimal performance is attained through\nmodel's \"specialisation\" towards the target, but it can be hard to reach for\ntraining algorithms which get attracted by sub-optimal solutions predicted by\nthe theory. Specialisation occurs inhomogeneously across layers, propagating\nfrom shallow towards deep ones, but also across neurons in each layer.\nFurthermore, deeper targets are harder to learn. Despite its simplicity, the\nBayesian-optimal setting provides insights on how the depth, non-linearity and\nfinite (proportional) width influence neural networks in the feature learning\nregime that are potentially relevant way beyond it.",
    "published": "2025-10-28T16:44:34Z",
    "updated": "2025-10-29T07:31:22Z",
    "link": "http://arxiv.org/pdf/2510.24616v2.pdf",
    "category": [
      "stat.ML",
      "cond-mat.dis-nn",
      "cond-mat.stat-mech",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "authors": [
      "Jean Barbier",
      "Francesco Camilli",
      "Minh-Toan Nguyen",
      "Mauro Pastore",
      "Rudy Skerk"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.06272v2",
    "title": "Explainable Framework for Swarm Intelligence Based on Fitness Landscape\n  Features and Machine Learning",
    "summary": "Swarm based optimization algorithms have demonstrated remarkable success in\nsolving complex optimization problems. However, their widespread adoption\nremains sceptical due to limited transparency in how different algorithmic\ncomponents influence the overall performance of the algorithm. This work\npresents a multi-faceted interpretability related investigations of one of the\npopular swarm algorithms, Particle Swarm Optimization. Through this work, we\nprovide a framework that makes the role of different topologies and parameters\nin PSO interpretable and explainable using novel machine learning approach. We\nfirst developed a comprehensive landscape characterization framework using\nExploratory Landscape Analysis to quantify problem difficulty and identify\ncritical features in the problem that affects the optimization performance of\nPSO. Secondly, we rigorously compare three topologies -- Ring, Star, and Von\nNeumann -- analyzing their distinct impacts on exploration-exploitation\nbalance, convergence behavior, and solution quality and eventually develop an\nexplainable benchmarking framework for PSO. The work successfully decodes how\nswarm topologies affect information flow, diversity, and convergence. Through\nsystematic experimentation across 24 benchmark functions in multiple\ndimensions, we establish practical guidelines for topology selection and\nparameter configuration. These findings uncover the black-box nature of PSO,\nproviding more transparency and interpretability to swarm intelligence systems.\nThe source code is available at https://github.com/GitNitin02/ioh_pso.",
    "published": "2025-09-08T01:39:32Z",
    "updated": "2025-10-29T07:12:09Z",
    "link": "http://arxiv.org/pdf/2509.06272v2.pdf",
    "category": [
      "cs.NE",
      "cs.LG"
    ],
    "authors": [
      "Nitin Gupta",
      "Bapi Dutta",
      "Anupam Yadav"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.03280v2",
    "title": "MDPs with a State Sensing Cost",
    "summary": "In many practical sequential decision-making problems, tracking the state of\nthe environment incurs a sensing/communication/computation cost. In these\nsettings, the agent's interaction with its environment includes the additional\ncomponent of deciding when to sense the state, in a manner that balances the\nvalue associated with optimal (state-specific) actions and the cost of sensing.\nWe formulate this as an expected discounted cost Markov Decision Process (MDP),\nwherein the agent incurs an additional cost for sensing its next state, but has\nthe option to take actions while remaining `blind' to the system state. We pose\nthis problem as a classical discounted cost MDP with an expanded (countably\ninfinite) state space. While computing the optimal policy for this MDP is\nintractable in general, we derive lower bounds on the optimal value function,\nwhich allow us to bound the suboptimality gap of any policy. We also propose a\ncomputationally efficient algorithm SPI, based on policy improvement, which in\npractice performs close to the optimal policy. Finally, we benchmark against\nthe state-of-the-art via a numerical case study.",
    "published": "2025-05-06T08:06:45Z",
    "updated": "2025-10-29T06:48:01Z",
    "link": "http://arxiv.org/pdf/2505.03280v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Vansh Kapoor",
      "Jayakrishnan Nair"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.15695v2",
    "title": "Hypergraph clustering using Ricci curvature: an edge transport\n  perspective",
    "summary": "In this paper, we introduce a novel method for extending Ricci flow to\nhypergraphs by defining probability measures on the edges and transporting them\non the line expansion. This approach yields a new weighting on the edges, which\nproves particularly effective for community detection. We extensively compare\nthis method with a similar notion of Ricci flow defined on the clique\nexpansion, demonstrating its enhanced sensitivity to the hypergraph structure,\nespecially in the presence of large hyperedges. The two methods are\ncomplementary and together form a powerful and highly interpretable framework\nfor community detection in hypergraphs.",
    "published": "2024-12-20T09:15:06Z",
    "updated": "2025-10-29T06:46:52Z",
    "link": "http://arxiv.org/pdf/2412.15695v2.pdf",
    "category": [
      "cs.LG",
      "cs.SI",
      "stat.ML"
    ],
    "authors": [
      "Olympio Hacquard"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.01737v2",
    "title": "Enlightenment Period Improving DNN Performance",
    "summary": "The start of deep neural network training is characterized by a brief yet\ncritical phase that lasts from the beginning of the training until the accuracy\nreaches approximately 50\\%. During this phase, disordered representations\nrapidly transition toward ordered structure, and we term this phase the\nEnlightenment Period. Through theoretical modeling based on phase transition\ntheory and experimental validation, we reveal that applying Mixup data\naugmentation during this phase has a dual effect: it introduces a Gradient\nInterference Effect that hinders performance, while also providing a beneficial\nActivation Revival Effect to restore gradient updates for saturated neurons. We\nfurther demonstrate that this negative interference diminishes as the sample\nset size or the model parameter size increases, thereby shifting the balance\nbetween these two effects. Based on these findings, we propose three strategies\nthat improve performance by solely adjusting the training data distribution\nwithin this brief period: the Mixup Pause Strategy for small-scale scenarios,\nthe Alpha Boost Strategy for large-scale scenarios with underfitting, and the\nHigh-Loss Removal Strategy for tasks where Mixup is inapplicable (e.g., time\nseries and large language models). Extensive experiments show that these\nstrategies achieve superior performance across diverse architectures such as\nViT and ResNet on datasets including CIFAR and ImageNet-1K. Ultimately, this\nwork offers a novel perspective on enhancing model performance by strategically\ncapitalizing on the dynamics of the brief and crucial early stages of training.\nCode is available at https://anonymous.4open.science/r/code-A5F1/.",
    "published": "2025-04-02T13:49:31Z",
    "updated": "2025-10-29T06:27:21Z",
    "link": "http://arxiv.org/pdf/2504.01737v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Tiantian Liu",
      "Meng Wan",
      "Jue Wang",
      "Ningming Nie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25207v1",
    "title": "Selective Learning for Deep Time Series Forecasting",
    "summary": "Benefiting from high capacity for capturing complex temporal patterns, deep\nlearning (DL) has significantly advanced time series forecasting (TSF).\nHowever, deep models tend to suffer from severe overfitting due to the inherent\nvulnerability of time series to noise and anomalies. The prevailing DL paradigm\nuniformly optimizes all timesteps through the MSE loss and learns those\nuncertain and anomalous timesteps without difference, ultimately resulting in\noverfitting. To address this, we propose a novel selective learning strategy\nfor deep TSF. Specifically, selective learning screens a subset of the whole\ntimesteps to calculate the MSE loss in optimization, guiding the model to focus\non generalizable timesteps while disregarding non-generalizable ones. Our\nframework introduces a dual-mask mechanism to target timesteps: (1) an\nuncertainty mask leveraging residual entropy to filter uncertain timesteps, and\n(2) an anomaly mask employing residual lower bound estimation to exclude\nanomalous timesteps. Extensive experiments across eight real-world datasets\ndemonstrate that selective learning can significantly improve the predictive\nperformance for typical state-of-the-art deep models, including 37.4% MSE\nreduction for Informer, 8.4% for TimesNet, and 6.5% for iTransformer.",
    "published": "2025-10-29T06:18:52Z",
    "updated": "2025-10-29T06:18:52Z",
    "link": "http://arxiv.org/pdf/2510.25207v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Yisong Fu",
      "Zezhi Shao",
      "Chengqing Yu",
      "Yujie Li",
      "Zhulin An",
      "Qi Wang",
      "Yongjun Xu",
      "Fei Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.23190v4",
    "title": "DeepRTE: Pre-trained Attention-based Neural Network for Radiative\n  Transfer",
    "summary": "In this paper, we propose a novel neural network approach, termed DeepRTE, to\naddress the steady-state Radiative Transfer Equation (RTE). The RTE is a\ndifferential-integral equation that governs the propagation of radiation\nthrough a participating medium, with applications spanning diverse domains such\nas neutron transport, atmospheric radiative transfer, heat transfer, and\noptical imaging. Our DeepRTE framework demonstrates superior computational\nefficiency for solving the steady-state RTE, surpassing traditional methods and\nexisting neural network approaches. This efficiency is achieved by embedding\nphysical information through derivation of the RTE and mathematically-informed\nnetwork architecture. Concurrently, DeepRTE achieves high accuracy with\nsignificantly fewer parameters, largely due to its incorporation of mechanisms\nsuch as multi-head attention. Furthermore, DeepRTE is a mesh-free neural\noperator framework with inherent zero-shot capability. This is achieved by\nincorporating Green's function theory and pre-training with delta-function\ninflow boundary conditions into both its architecture design and training data\nconstruction. The efficacy of the proposed approach is substantiated through\ncomprehensive numerical experiments.",
    "published": "2025-05-29T07:28:36Z",
    "updated": "2025-10-29T05:54:21Z",
    "link": "http://arxiv.org/pdf/2505.23190v4.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Yekun Zhu",
      "Min Tang",
      "Zheng Ma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.09887v2",
    "title": "Learning single-index models via harmonic decomposition",
    "summary": "We study the problem of learning single-index models, where the label $y \\in\n\\mathbb{R}$ depends on the input $\\boldsymbol{x} \\in \\mathbb{R}^d$ only through\nan unknown one-dimensional projection $\\langle\n\\boldsymbol{w}_*,\\boldsymbol{x}\\rangle$. Prior work has shown that under\nGaussian inputs, the statistical and computational complexity of recovering\n$\\boldsymbol{w}_*$ is governed by the Hermite expansion of the link function.\nIn this paper, we propose a new perspective: we argue that $spherical$\n$harmonics$ -- rather than $Hermite$ $polynomials$ -- provide the natural basis\nfor this problem, as they capture its intrinsic $rotational$ $symmetry$.\nBuilding on this insight, we characterize the complexity of learning\nsingle-index models under arbitrary spherically symmetric input distributions.\nWe introduce two families of estimators -- based on tensor unfolding and online\nSGD -- that respectively achieve either optimal sample complexity or optimal\nruntime, and argue that estimators achieving both may not exist in general.\nWhen specialized to Gaussian inputs, our theory not only recovers and clarifies\nexisting results but also reveals new phenomena that had previously been\noverlooked.",
    "published": "2025-06-11T15:59:53Z",
    "updated": "2025-10-29T05:25:47Z",
    "link": "http://arxiv.org/pdf/2506.09887v2.pdf",
    "category": [
      "cs.LG",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "authors": [
      "Nirmit Joshi",
      "Hugo Koubbi",
      "Theodor Misiakiewicz",
      "Nathan Srebro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25176v1",
    "title": "Machine Learning and CPU (Central Processing Unit) Scheduling\n  Co-Optimization over a Network of Computing Centers",
    "summary": "In the rapidly evolving research on artificial intelligence (AI) the demand\nfor fast, computationally efficient, and scalable solutions has increased in\nrecent years. The problem of optimizing the computing resources for distributed\nmachine learning (ML) and optimization is considered in this paper. Given a set\nof data distributed over a network of computing-nodes/servers, the idea is to\noptimally assign the CPU (central processing unit) usage while simultaneously\ntraining each computing node locally via its own share of data. This formulates\nthe problem as a co-optimization setup to (i) optimize the data processing and\n(ii) optimally allocate the computing resources. The information-sharing\nnetwork among the nodes might be time-varying, but with balanced weights to\nensure consensus-type convergence of the algorithm. The algorithm is all-time\nfeasible, which implies that the computing resource-demand balance constraint\nholds at all iterations of the proposed solution. Moreover, the solution allows\naddressing possible log-scale quantization over the information-sharing\nchannels to exchange log-quantized data. For some example applications,\ndistributed support-vector-machine (SVM) and regression are considered as the\nML training models. Results from perturbation theory, along with Lyapunov\nstability and eigen-spectrum analysis, are used to prove the convergence\ntowards the optimal case. As compared to existing CPU scheduling solutions, the\nproposed algorithm improves the cost optimality gap by more than $50\\%$.",
    "published": "2025-10-29T05:21:32Z",
    "updated": "2025-10-29T05:21:32Z",
    "link": "http://arxiv.org/pdf/2510.25176v1.pdf",
    "category": [
      "cs.LG",
      "cs.DC",
      "cs.MA",
      "cs.SY",
      "eess.SY",
      "math.OC"
    ],
    "authors": [
      "Mohammadreza Doostmohammadian",
      "Zulfiya R. Gabidullina",
      "Hamid R. Rabiee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25166v1",
    "title": "A Study on Inference Latency for Vision Transformers on Mobile Devices",
    "summary": "Given the significant advances in machine learning techniques on mobile\ndevices, particularly in the domain of computer vision, in this work we\nquantitatively study the performance characteristics of 190 real-world vision\ntransformers (ViTs) on mobile devices. Through a comparison with 102 real-world\nconvolutional neural networks (CNNs), we provide insights into the factors that\ninfluence the latency of ViT architectures on mobile devices. Based on these\ninsights, we develop a dataset including measured latencies of 1000 synthetic\nViTs with representative building blocks and state-of-the-art architectures\nfrom two machine learning frameworks and six mobile platforms. Using this\ndataset, we show that inference latency of new ViTs can be predicted with\nsufficient accuracy for real-world applications.",
    "published": "2025-10-29T04:57:49Z",
    "updated": "2025-10-29T04:57:49Z",
    "link": "http://arxiv.org/pdf/2510.25166v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG",
      "cs.PF"
    ],
    "authors": [
      "Zhuojin Li",
      "Marco Paolieri",
      "Leana Golubchik"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.02476v5",
    "title": "Perturbing the Derivative: Wild Refitting for Model-Free Evaluation of\n  Machine Learning Models under Bregman Losses",
    "summary": "We study the excess risk evaluation of classical penalized empirical risk\nminimization (ERM) with Bregman losses. We show that by leveraging the idea of\nwild refitting, one can efficiently upper bound the excess risk through the\nso-called \"wild optimism,\" without relying on the global structure of the\nunderlying function class. This property makes our approach inherently\nmodel-free. Unlike conventional analysis, our framework operates with just one\ndataset and black-box access to the training procedure. The method involves\nrandomized Rademacher symmetrization and constructing artificially modified\noutputs by perturbation in the derivative space with appropriate scaling, upon\nwhich we retrain a second predictor for excess risk estimation. We establish\nhigh-probability performance guarantees both under the fixed design setting and\nthe random design setting, demonstrating that wild refitting under Bregman\nlosses, with an appropriately chosen wild noise scale, yields a valid upper\nbound on the excess risk. Thus, our work is promising for theoretically\nevaluating modern opaque ML models, such as deep neural networks and generative\nmodels, where the function class is too complex for classical learning theory\nand empirical process techniques.",
    "published": "2025-09-02T16:26:03Z",
    "updated": "2025-10-29T04:20:28Z",
    "link": "http://arxiv.org/pdf/2509.02476v5.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Haichen Hu",
      "David Simchi-Levi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25147v1",
    "title": "Machine Learning Guided Optimal Transmission Switching to Mitigate\n  Wildfire Ignition Risk",
    "summary": "To mitigate acute wildfire ignition risks, utilities de-energize power lines\nin high-risk areas. The Optimal Power Shutoff (OPS) problem optimizes line\nenergization statuses to manage wildfire ignition risks through\nde-energizations while reducing load shedding. OPS problems are computationally\nchallenging Mixed-Integer Linear Programs (MILPs) that must be solved rapidly\nand frequently in operational settings. For a particular power system, OPS\ninstances share a common structure with varying parameters related to wildfire\nrisks, loads, and renewable generation. This motivates the use of Machine\nLearning (ML) for solving OPS problems by exploiting shared patterns across\ninstances. In this paper, we develop an ML-guided framework that quickly\nproduces high-quality de-energization decisions by extending existing ML-guided\nMILP solution methods while integrating domain knowledge on the number of\nenergized and de-energized lines. Results on a large-scale realistic\nCalifornia-based synthetic test system show that the proposed ML-guided method\nproduces high-quality solutions faster than traditional optimization methods.",
    "published": "2025-10-29T03:56:46Z",
    "updated": "2025-10-29T03:56:46Z",
    "link": "http://arxiv.org/pdf/2510.25147v1.pdf",
    "category": [
      "cs.LG",
      "math.OC"
    ],
    "authors": [
      "Weimin Huang",
      "Ryan Piansky",
      "Bistra Dilkina",
      "Daniel K. Molzahn"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.02504v2",
    "title": "Stochastic Momentum Methods for Non-smooth Non-Convex Finite-Sum Coupled\n  Compositional Optimization",
    "summary": "Finite-sum Coupled Compositional Optimization (FCCO), characterized by its\ncoupled compositional objective structure, emerges as an important optimization\nparadigm for addressing a wide range of machine learning problems. In this\npaper, we focus on a challenging class of non-convex non-smooth FCCO, where the\nouter functions are non-smooth weakly convex or convex and the inner functions\nare smooth or weakly convex. Existing state-of-the-art result face two key\nlimitations: (1) a high iteration complexity of $O(1/\\epsilon^6)$ under the\nassumption that the stochastic inner functions are Lipschitz continuous in\nexpectation; (2) reliance on vanilla SGD-type updates, which are not suitable\nfor deep learning applications. Our main contributions are two fold: (i) We\npropose stochastic momentum methods tailored for non-smooth FCCO that come with\nprovable convergence guarantees; (ii) We establish a new state-of-the-art\niteration complexity of $O(1/\\epsilon^5)$. Moreover, we apply our algorithms to\nmultiple inequality constrained non-convex optimization problems involving\nsmooth or weakly convex functional inequality constraints. By optimizing a\nsmoothed hinge penalty based formulation, we achieve a new state-of-the-art\ncomplexity of $O(1/\\epsilon^5)$ for finding an (nearly) $\\epsilon$-level KKT\nsolution. Experiments on three tasks demonstrate the effectiveness of the\nproposed algorithms.",
    "published": "2025-06-03T06:31:59Z",
    "updated": "2025-10-29T03:38:10Z",
    "link": "http://arxiv.org/pdf/2506.02504v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Xingyu Chen",
      "Bokun Wang",
      "Ming Yang",
      "Qihang Lin",
      "Tianbao Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.01131v2",
    "title": "Tensor Decomposition Networks for Fast Machine Learning Interatomic\n  Potential Computations",
    "summary": "$\\rm{SO}(3)$-equivariant networks are the dominant models for machine\nlearning interatomic potentials (MLIPs). The key operation of such networks is\nthe Clebsch-Gordan (CG) tensor product, which is computationally expensive. To\naccelerate the computation, we develop tensor decomposition networks (TDNs) as\na class of approximately equivariant networks in which CG tensor products are\nreplaced by low-rank tensor decompositions, such as the CANDECOMP/PARAFAC (CP)\ndecomposition. With the CP decomposition, we prove (i) a uniform bound on the\ninduced error of $\\rm{SO}(3)$-equivariance, and (ii) the universality of\napproximating any equivariant bilinear map. To further reduce the number of\nparameters, we propose path-weight sharing that ties all multiplicity-space\nweights across the $\\mathcal{O}(L^3)$ CG paths into a single path without\ncompromising equivariance, where $L$ is the maximum angular degree. The\nresulting layer acts as a plug-and-play replacement for tensor products in\nexisting networks, and the computational complexity of tensor products is\nreduced from $\\mathcal{O}(L^6)$ to $\\mathcal{O}(L^4)$. We evaluate TDNs on\nPubChemQCR, a newly curated molecular relaxation dataset containing 105 million\nDFT-calculated snapshots. We also use existing datasets, including OC20, and\nOC22. Results show that TDNs achieve competitive performance with dramatic\nspeedup in computations. Our code is publicly available as part of the AIRS\nlibrary\n(\\href{https://github.com/divelab/AIRS/tree/main/OpenMol/TDN}{https://github.com/divelab/AIRS/}).",
    "published": "2025-07-01T18:46:27Z",
    "updated": "2025-10-29T03:31:51Z",
    "link": "http://arxiv.org/pdf/2507.01131v2.pdf",
    "category": [
      "cs.LG",
      "physics.comp-ph"
    ],
    "authors": [
      "Yuchao Lin",
      "Cong Fu",
      "Zachary Krueger",
      "Haiyang Yu",
      "Maho Nakata",
      "Jianwen Xie",
      "Emine Kucukbenli",
      "Xiaofeng Qian",
      "Shuiwang Ji"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.12371v3",
    "title": "Path-specific effects for pulse-oximetry guided decisions in critical\n  care",
    "summary": "Identifying and measuring biases associated with sensitive attributes is a\ncrucial consideration in healthcare to prevent treatment disparities. One\nprominent issue is inaccurate pulse oximeter readings, which tend to\noverestimate oxygen saturation for dark-skinned patients and misrepresent\nsupplemental oxygen needs. Most existing research has revealed statistical\ndisparities linking device measurement errors to patient outcomes in intensive\ncare units (ICUs) without causal formalization. This study causally\ninvestigates how racial discrepancies in oximetry measurements affect invasive\nventilation in ICU settings. We employ a causal inference-based approach using\npath-specific effects to isolate the impact of bias by race on clinical\ndecision-making. To estimate these effects, we leverage a doubly robust\nestimator, propose its self-normalized variant for improved sample efficiency,\nand provide novel finite-sample guarantees. Our methodology is validated on\nsemi-synthetic data and applied to two large real-world health datasets:\nMIMIC-IV and eICU. Contrary to prior work, our analysis reveals minimal impact\nof racial discrepancies on invasive ventilation rates. However, path-specific\neffects mediated by oxygen saturation disparity are more pronounced on\nventilation duration, and the severity differs by dataset. Our work provides a\nnovel pipeline for investigating potential disparities in clinical\ndecision-making and, more importantly, highlights the necessity of causal\nmethods to robustly assess fairness in healthcare.",
    "published": "2025-06-14T06:45:53Z",
    "updated": "2025-10-29T03:30:11Z",
    "link": "http://arxiv.org/pdf/2506.12371v3.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Kevin Zhang",
      "Yonghan Jung",
      "Divyat Mahajan",
      "Karthikeyan Shanmugam",
      "Shalmali Joshi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25135v1",
    "title": "Conditional neural field for spatial dimension reduction of turbulence\n  data: a comparison study",
    "summary": "We investigate conditional neural fields (CNFs), mesh-agnostic,\ncoordinate-based decoders conditioned on a low-dimensional latent, for spatial\ndimensionality reduction of turbulent flows. CNFs are benchmarked against\nProper Orthogonal Decomposition and a convolutional autoencoder within a\nunified encoding-decoding framework and a common evaluation protocol that\nexplicitly separates in-range (interpolative) from out-of-range (strict\nextrapolative) testing beyond the training horizon, with identical\npreprocessing, metrics, and fixed splits across all baselines. We examine three\nconditioning mechanisms: (i) activation-only modulation (often termed FiLM),\n(ii) low-rank weight and bias modulation (termed FP), and (iii) last-layer\ninner-product coupling, and introduce a novel domain-decomposed CNF that\nlocalizes complexities. Across representative turbulence datasets (WMLES\nchannel inflow, DNS channel inflow, and wall pressure fluctuations over\nturbulent boundary layers), CNF-FP achieves the lowest training and in-range\ntesting errors, while CNF-FiLM generalizes best for out-of-range scenarios once\nmoderate latent capacity is available. Domain decomposition significantly\nimproves out-of-range accuracy, especially for the more demanding datasets. The\nstudy provides a rigorous, physics-aware basis for selecting conditioning,\ncapacity, and domain decomposition when using CNFs for turbulence compression\nand reconstruction.",
    "published": "2025-10-29T03:29:10Z",
    "updated": "2025-10-29T03:29:10Z",
    "link": "http://arxiv.org/pdf/2510.25135v1.pdf",
    "category": [
      "physics.flu-dyn",
      "cs.LG"
    ],
    "authors": [
      "Junyi Guo",
      "Pan Du",
      "Xiantao Fan",
      "Yahui Li",
      "Jian-Xun Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25132v1",
    "title": "EnzyControl: Adding Functional and Substrate-Specific Control for Enzyme\n  Backbone Generation",
    "summary": "Designing enzyme backbones with substrate-specific functionality is a\ncritical challenge in computational protein engineering. Current generative\nmodels excel in protein design but face limitations in binding data,\nsubstrate-specific control, and flexibility for de novo enzyme backbone\ngeneration. To address this, we introduce EnzyBind, a dataset with 11,100\nexperimentally validated enzyme-substrate pairs specifically curated from\nPDBbind. Building on this, we propose EnzyControl, a method that enables\nfunctional and substrate-specific control in enzyme backbone generation. Our\napproach generates enzyme backbones conditioned on MSA-annotated catalytic\nsites and their corresponding substrates, which are automatically extracted\nfrom curated enzyme-substrate data. At the core of EnzyControl is EnzyAdapter,\na lightweight, modular component integrated into a pretrained motif-scaffolding\nmodel, allowing it to become substrate-aware. A two-stage training paradigm\nfurther refines the model's ability to generate accurate and functional enzyme\nstructures. Experiments show that our EnzyControl achieves the best performance\nacross structural and functional metrics on EnzyBind and EnzyBench benchmarks,\nwith particularly notable improvements of 13\\% in designability and 13\\% in\ncatalytic efficiency compared to the baseline models. The code is released at\nhttps://github.com/Vecteur-libre/EnzyControl.",
    "published": "2025-10-29T03:22:32Z",
    "updated": "2025-10-29T03:22:32Z",
    "link": "http://arxiv.org/pdf/2510.25132v1.pdf",
    "category": [
      "q-bio.BM",
      "cs.LG"
    ],
    "authors": [
      "Chao Song",
      "Zhiyuan Liu",
      "Han Huang",
      "Liang Wang",
      "Qiong Wang",
      "Jianyu Shi",
      "Hui Yu",
      "Yihang Zhou",
      "Yang Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25128v1",
    "title": "An Analysis of Causal Effect Estimation using Outcome Invariant Data\n  Augmentation",
    "summary": "The technique of data augmentation (DA) is often used in machine learning for\nregularization purposes to better generalize under i.i.d. settings. In this\nwork, we present a unifying framework with topics in causal inference to make a\ncase for the use of DA beyond just the i.i.d. setting, but for generalization\nacross interventions as well. Specifically, we argue that when the outcome\ngenerating mechanism is invariant to our choice of DA, then such augmentations\ncan effectively be thought of as interventions on the treatment generating\nmechanism itself. This can potentially help to reduce bias in causal effect\nestimation arising from hidden confounders. In the presence of such unobserved\nconfounding we typically make use of instrumental variables (IVs) -- sources of\ntreatment randomization that are conditionally independent of the outcome.\nHowever, IVs may not be as readily available as DA for many applications, which\nis the main motivation behind this work. By appropriately regularizing IV based\nestimators, we introduce the concept of IV-like (IVL) regression for mitigating\nconfounding bias and improving predictive performance across interventions even\nwhen certain IV properties are relaxed. Finally, we cast parameterized DA as an\nIVL regression problem and show that when used in composition can simulate a\nworst-case application of such DA, further improving performance on causal\nestimation and generalization tasks beyond what simple DA may offer. This is\nshown both theoretically for the population case and via simulation experiments\nfor the finite sample case using a simple linear example. We also present real\ndata experiments to support our case.",
    "published": "2025-10-29T03:17:19Z",
    "updated": "2025-10-29T03:17:19Z",
    "link": "http://arxiv.org/pdf/2510.25128v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Uzair Akbar",
      "Niki Kilbertus",
      "Hao Shen",
      "Krikamol Muandet",
      "Bo Dai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.15721v4",
    "title": "Bohdi: Heterogeneous LLM Fusion with Automatic Data Exploration",
    "summary": "Heterogeneous Large Language Model (LLM) fusion integrates the strengths of\nmultiple source LLMs with different architectures into a target LLM with low\ncomputational overhead. While promising, existing methods suffer from two major\nlimitations: 1) reliance on real data from limited domain for knowledge fusion,\npreventing the target LLM from fully acquiring knowledge across diverse\ndomains, and 2) fixed data allocation proportions across domains, failing to\ndynamically adjust according to the target LLM's varying capabilities across\ndomains, leading to a capability imbalance. To overcome these limitations, we\npropose Bohdi, a synthetic-data-only heterogeneous LLM fusion framework.\nThrough the organization of knowledge domains into a hierarchical tree\nstructure, Bohdi enables automatic domain exploration and multi-domain data\ngeneration through multi-model collaboration, thereby comprehensively\nextracting knowledge from source LLMs. By formalizing domain expansion and data\nsampling proportion allocation on the knowledge tree as a Hierarchical\nMulti-Armed Bandit problem, Bohdi leverages the designed DynaBranches mechanism\nto adaptively adjust sampling proportions based on the target LLM's performance\nfeedback across domains. Integrated with our proposed Introspection-Rebirth\n(IR) mechanism, DynaBranches dynamically tracks capability shifts during target\nLLM's updates via Sliding Window Binomial Likelihood Ratio Testing (SWBLRT),\nfurther enhancing its online adaptation capability. Comparative experimental\nresults on a comprehensive suite of benchmarks demonstrate that Bohdi\nsignificantly outperforms existing baselines on multiple target LLMs, exhibits\nhigher data efficiency, and virtually eliminates the imbalance in the target\nLLM's capabilities. Our code is available at\nhttps://github.com/gjq100/Bohdi.git.",
    "published": "2025-06-04T17:01:38Z",
    "updated": "2025-10-29T03:04:39Z",
    "link": "http://arxiv.org/pdf/2506.15721v4.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Junqi Gao",
      "Zhichang Guo",
      "Dazhi Zhang",
      "Dong Li",
      "Runze Liu",
      "Pengfei Li",
      "Kai Tian",
      "Biqing Qi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25121v1",
    "title": "A Unified Bilevel Model for Adversarial Learning and A Case Study",
    "summary": "Adversarial learning has been attracting more and more attention thanks to\nthe fast development of machine learning and artificial intelligence. However,\ndue to the complicated structure of most machine learning models, the mechanism\nof adversarial attacks is not well interpreted. How to measure the effect of\nattack is still not quite clear. In this paper, we propose a unified bilevel\nmodel for adversarial learning. We further investigate the adversarial attack\nin clustering models and interpret it from data perturbation point of view. We\nreveal that when the data perturbation is relatively small, the clustering\nmodel is robust, whereas if it is relatively large, the clustering result\nchanges, which leads to an attack. To measure the effect of attacks for\nclustering models, we analyse the well-definedness of the so-called\n$\\delta$-measure, which can be used in the proposed bilevel model for\nadversarial learning of clustering models.",
    "published": "2025-10-29T02:58:21Z",
    "updated": "2025-10-29T02:58:21Z",
    "link": "http://arxiv.org/pdf/2510.25121v1.pdf",
    "category": [
      "cs.LG",
      "math.OC"
    ],
    "authors": [
      "Yutong Zheng",
      "Qingna Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.22527v2",
    "title": "Symplectic Generative Networks (SGNs): A Hamiltonian Framework for\n  Invertible Deep Generative Modeling",
    "summary": "We introduce the \\emph{Symplectic Generative Network (SGN)}, a deep\ngenerative model that leverages Hamiltonian mechanics to construct an\ninvertible, volume-preserving mapping between a latent space and the data\nspace. By endowing the latent space with a symplectic structure and modeling\ndata generation as the time evolution of a Hamiltonian system, SGN achieves\nexact likelihood evaluation without incurring the computational overhead of\nJacobian determinant calculations. In this work, we provide a rigorous\nmathematical foundation for SGNs through a comprehensive theoretical framework\nthat includes: (i) complete proofs of invertibility and volume preservation,\n(ii) a formal complexity analysis with theoretical comparisons to Variational\nAutoencoders and Normalizing Flows, (iii) strengthened universal approximation\nresults with quantitative error bounds, (iv) an information-theoretic analysis\nbased on the geometry of statistical manifolds, and (v) an extensive stability\nanalysis with adaptive integration guarantees. These contributions highlight\nthe fundamental advantages of SGNs and establish a solid foundation for future\nempirical investigations and applications to complex, high-dimensional data.",
    "published": "2025-05-28T16:13:36Z",
    "updated": "2025-10-29T02:45:00Z",
    "link": "http://arxiv.org/pdf/2505.22527v2.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "68T07, 37J39, 65P10, 62B10, 53D22, 94A17"
    ],
    "authors": [
      "Agnideep Aich",
      "Ashit Aich"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25114v1",
    "title": "Energy Approach from $\\varepsilon$-Graph to Continuum Diffusion Model\n  with Connectivity Functional",
    "summary": "We derive an energy-based continuum limit for $\\varepsilon$-graphs endowed\nwith a general connectivity functional. We prove that the discrete energy and\nits continuum counterpart differ by at most $O(\\varepsilon)$; the prefactor\ninvolves only the $W^{1,1}$-norm of the connectivity density as\n$\\varepsilon\\to0$, so the error bound remains valid even when that density has\nstrong local fluctuations. As an application, we introduce a neural-network\nprocedure that reconstructs the connectivity density from edge-weight data and\nthen embeds the resulting continuum model into a brain-dynamics framework. In\nthis setting, the usual constant diffusion coefficient is replaced by the\nspatially varying coefficient produced by the learned density, yielding\ndynamics that differ significantly from those obtained with conventional\nconstant-diffusion models.",
    "published": "2025-10-29T02:26:41Z",
    "updated": "2025-10-29T02:26:41Z",
    "link": "http://arxiv.org/pdf/2510.25114v1.pdf",
    "category": [
      "math.NA",
      "cs.LG",
      "cs.NA",
      "stat.ML"
    ],
    "authors": [
      "Yahong Yang",
      "Sun Lee",
      "Jeff Calder",
      "Wenrui Hao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25108v1",
    "title": "Shift is Good: Mismatched Data Mixing Improves Test Performance",
    "summary": "We consider training and testing on mixture distributions with different\ntraining and test proportions. We show that in many settings, and in some sense\ngenerically, distribution shift can be beneficial, and test performance can\nimprove due to mismatched training proportions, even if the components are\nunrelated and with no transfer between components. In a variety of scenarios,\nwe identify the optimal training proportions and the extent to which such\ndistribution shift can be beneficial. We show how the same analysis applies\nalso to a compositional setting with differing distribution of component\n\"skills'' at training and test.",
    "published": "2025-10-29T02:18:15Z",
    "updated": "2025-10-29T02:18:15Z",
    "link": "http://arxiv.org/pdf/2510.25108v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Marko Medvedev",
      "Kaifeng Lyu",
      "Zhiyuan Li",
      "Nathan Srebro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25093v1",
    "title": "Continual Low-Rank Adapters for LLM-based Generative Recommender Systems",
    "summary": "While large language models (LLMs) achieve strong performance in\nrecommendation, they face challenges in continual learning as users, items, and\nuser preferences evolve over time. Existing LoRA-based continual methods\nprimarily focus on preserving performance on previous tasks, but this overlooks\nthe unique nature of recommendation: the goal is not to predict past\npreferences, and outdated preferences can even harm performance when current\ninterests shift significantly. To address this, we propose PESO (Proximally\nrEgularized Single evolving lOra, a continual adaptation method for LoRA in\nrecommendation. PESO introduces a proximal regularizer that anchors the current\nadapter to its most recent frozen state, enabling the model to flexibly balance\nadaptation and preservation, and to better capture recent user behaviors.\nTheoretically, we show that this proximal design provides data-aware,\ndirection-wise guidance in the LoRA subspace. Empirically, PESO consistently\noutperforms existing LoRA-based continual learning methods.",
    "published": "2025-10-29T01:57:38Z",
    "updated": "2025-10-29T01:57:38Z",
    "link": "http://arxiv.org/pdf/2510.25093v1.pdf",
    "category": [
      "cs.LG",
      "cs.IR"
    ],
    "authors": [
      "Hyunsik Yoo",
      "Ting-Wei Li",
      "SeongKu Kang",
      "Zhining Liu",
      "Charlie Xu",
      "Qilin Qi",
      "Hanghang Tong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2310.13966v3",
    "title": "Transfer Learning for Kernel-based Regression",
    "summary": "In recent years, transfer learning has garnered significant attention. Its\nability to leverage knowledge from related studies to improve generalization\nperformance in a target study has made it highly appealing. This paper focuses\non investigating the transfer learning problem within the context of\nnonparametric regression over a reproducing kernel Hilbert space. The aim is to\nbridge the gap between practical effectiveness and theoretical guarantees. We\nspecifically consider two scenarios: one where the transferable sources are\nknown and another where they are unknown. For the known transferable source\ncase, we propose a two-step kernel-based estimator by solely using kernel ridge\nregression. For the unknown case, we develop a novel method based on an\nefficient aggregation algorithm, which can automatically detect and alleviate\nthe effects of negative sources. This paper provides the statistical properties\nof the desired estimators and establishes the minimax rate. Through extensive\nnumerical experiments on synthetic data and real examples, we validate our\ntheoretical findings and demonstrate the effectiveness of our proposed method.",
    "published": "2023-10-21T10:55:31Z",
    "updated": "2025-10-29T01:23:05Z",
    "link": "http://arxiv.org/pdf/2310.13966v3.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "authors": [
      "Chao Wang",
      "Caixing Wang",
      "Xin He",
      "Xingdong Feng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25074v1",
    "title": "Training Across Reservoirs: Using Numerical Differentiation To Couple\n  Trainable Networks With Black-Box Reservoirs",
    "summary": "We introduce Bounded Numerical Differentiation (BOND), a perturbative method\nfor estimating partial derivatives across network structures with inaccessible\ncomputational graphs. BOND demonstrates improved accuracy and scalability from\nexisting perturbative methods, enabling new explorations of trainable\narchitectures that integrate black-box functions. We observe that these\nblack-box functions, realized in our experiments as fixed, untrained networks,\ncan enhance model performance without increasing the number of trainable\nparameters. This improvement is achieved without extensive optimization of the\narchitecture or properties of the black-box function itself. Our findings\nhighlight the potential of leveraging fixed, non-trainable modules to expand\nmodel capacity, suggesting a path toward combining analogue and digital devices\nas a mechanism for scaling networks.",
    "published": "2025-10-29T01:19:50Z",
    "updated": "2025-10-29T01:19:50Z",
    "link": "http://arxiv.org/pdf/2510.25074v1.pdf",
    "category": [
      "cs.LG",
      "I.2.6"
    ],
    "authors": [
      "Andrew Clark",
      "Jack Moursounidis",
      "Osmaan Rasouli",
      "William Gan",
      "Cooper Doyle",
      "Anna Leontjeva"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.14167v6",
    "title": "Kolmogorov-Arnold Energy Models: Fast and Interpretable Generative\n  Modeling",
    "summary": "Learning an energy-based model (EBM) in the latent space of a top-down\ngenerative model offers a powerful framework for generation across many data\nmodalities. However, it remains unclear how its interpretability can be used to\nguide model design, improve generative quality, and reduce training time.\nMoreover, the reliance on Langevin Monte Carlo (LMC) sampling presents\nchallenges in efficiency and sampling multimodal latent distributions. We\npropose a novel adaptation of the Kolmogorov-Arnold representation theorem for\ngenerative modeling and introduce the Kolmogorov-Arnold Energy Model (KAEM) to\ntake advantage of structural and inductive biases. By constraining the prior to\nunivariate relationships, KAEM enables fast and exact inference via the inverse\ntransform method. With the low dimensionality of the latent space and suitable\ninductive biases encoded, we demonstrate that importance sampling (IS) becomes\na viable, unbiased, and highly efficient posterior sampler. For domains where\nIS fails, we introduce a strategy based on population-based LMC, decomposing\nthe posterior into a sequence of annealed distributions to improve LMC mixing.\nKAEM balances common generative modeling trade-offs, offering fast inference,\ninterpretability, and stable training, while being naturally suited to\nZettascale Computing hardware.",
    "published": "2025-06-17T04:07:32Z",
    "updated": "2025-10-29T01:00:08Z",
    "link": "http://arxiv.org/pdf/2506.14167v6.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Prithvi Raj"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25060v1",
    "title": "Nonlinear Dynamics In Optimization Landscape of Shallow Neural Networks\n  with Tunable Leaky ReLU",
    "summary": "In this work, we study the nonlinear dynamics of a shallow neural network\ntrained with mean-squared loss and leaky ReLU activation. Under Gaussian inputs\nand equal layer width k, (1) we establish, based on the equivariant gradient\ndegree, a theoretical framework, applicable to any number of neurons k>= 4, to\ndetect bifurcation of critical points with associated symmetries from global\nminimum as leaky parameter $\\alpha$ varies. Typically, our analysis reveals\nthat a multi-mode degeneracy consistently occurs at the critical number 0,\nindependent of k. (2) As a by-product, we further show that such bifurcations\nare width-independent, arise only for nonnegative $\\alpha$ and that the global\nminimum undergoes no further symmetry-breaking instability throughout the\nengineering regime $\\alpha$ in range (0,1). An explicit example with k=5 is\npresented to illustrate the framework and exhibit the resulting bifurcation\ntogether with their symmetries.",
    "published": "2025-10-29T01:00:07Z",
    "updated": "2025-10-29T01:00:07Z",
    "link": "http://arxiv.org/pdf/2510.25060v1.pdf",
    "category": [
      "math.OC",
      "cs.LG",
      "math.DS"
    ],
    "authors": [
      "Jingzhou Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25051v1",
    "title": "Breast Cancer VLMs: Clinically Practical Vision-Language Train-Inference\n  Models",
    "summary": "Breast cancer remains the most commonly diagnosed malignancy among women in\nthe developed world. Early detection through mammography screening plays a\npivotal role in reducing mortality rates. While computer-aided diagnosis (CAD)\nsystems have shown promise in assisting radiologists, existing approaches face\ncritical limitations in clinical deployment - particularly in handling the\nnuanced interpretation of multi-modal data and feasibility due to the\nrequirement of prior clinical history. This study introduces a novel framework\nthat synergistically combines visual features from 2D mammograms with\nstructured textual descriptors derived from easily accessible clinical metadata\nand synthesized radiological reports through innovative tokenization modules.\nOur proposed methods in this study demonstrate that strategic integration of\nconvolutional neural networks (ConvNets) with language representations achieves\nsuperior performance to vision transformer-based models while handling\nhigh-resolution images and enabling practical deployment across diverse\npopulations. By evaluating it on multi-national cohort screening mammograms,\nour multi-modal approach achieves superior performance in cancer detection and\ncalcification identification compared to unimodal baselines, with particular\nimprovements. The proposed method establishes a new paradigm for developing\nclinically viable VLM-based CAD systems that effectively leverage imaging data\nand contextual patient information through effective fusion mechanisms.",
    "published": "2025-10-29T00:37:18Z",
    "updated": "2025-10-29T00:37:18Z",
    "link": "http://arxiv.org/pdf/2510.25051v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Shunjie-Fabian Zheng",
      "Hyeonjun Lee",
      "Thijs Kooi",
      "Ali Diba"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.14819v4",
    "title": "Learning from Reward-Free Offline Data: A Case for Planning with Latent\n  Dynamics Models",
    "summary": "A long-standing goal in AI is to develop agents capable of solving diverse\ntasks across a range of environments, including those never seen during\ntraining. Two dominant paradigms address this challenge: (i) reinforcement\nlearning (RL), which learns policies via trial and error, and (ii) optimal\ncontrol, which plans actions using a known or learned dynamics model. However,\ntheir comparative strengths in the offline setting - where agents must learn\nfrom reward-free trajectories - remain underexplored. In this work, we\nsystematically evaluate RL and control-based methods on a suite of navigation\ntasks, using offline datasets of varying quality. On the RL side, we consider\ngoal-conditioned and zero-shot methods. On the control side, we train a latent\ndynamics model using the Joint Embedding Predictive Architecture (JEPA) and\nemploy it for planning. We investigate how factors such as data diversity,\ntrajectory quality, and environment variability influence the performance of\nthese approaches. Our results show that model-free RL benefits most from large\namounts of high-quality data, whereas model-based planning generalizes better\nto unseen layouts and is more data-efficient, while achieving trajectory\nstitching performance comparable to leading model-free methods. Notably,\nplanning with a latent dynamics model proves to be a strong approach for\nhandling suboptimal offline data and adapting to diverse environments.",
    "published": "2025-02-20T18:39:41Z",
    "updated": "2025-10-29T00:35:42Z",
    "link": "http://arxiv.org/pdf/2502.14819v4.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Vlad Sobal",
      "Wancong Zhang",
      "Kyunghyun Cho",
      "Randall Balestriero",
      "Tim G. J. Rudner",
      "Yann LeCun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.21894v2",
    "title": "Thompson Sampling in Function Spaces via Neural Operators",
    "summary": "We propose an extension of Thompson sampling to optimization problems over\nfunction spaces where the objective is a known functional of an unknown\noperator's output. We assume that queries to the operator (such as running a\nhigh-fidelity simulator or physical experiment) are costly, while functional\nevaluations on the operator's output are inexpensive. Our algorithm employs a\nsample-then-optimize approach using neural operator surrogates. This strategy\navoids explicit uncertainty quantification by treating trained neural operators\nas approximate samples from a Gaussian process (GP) posterior. We derive regret\nbounds and theoretical results connecting neural operators with GPs in\ninfinite-dimensional settings. Experiments benchmark our method against other\nBayesian optimization baselines on functional optimization tasks involving\npartial differential equations of physical systems, demonstrating better sample\nefficiency and significant performance gains.",
    "published": "2025-06-27T04:21:57Z",
    "updated": "2025-10-29T00:10:05Z",
    "link": "http://arxiv.org/pdf/2506.21894v2.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Rafael Oliveira",
      "Xuesong Wang",
      "Kian Ming A. Chai",
      "Edwin V. Bonilla"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25042v1",
    "title": "Dynamically Weighted Momentum with Adaptive Step Sizes for Efficient\n  Deep Network Training",
    "summary": "Within the current sphere of deep learning research, despite the extensive\napplication of optimization algorithms such as Stochastic Gradient Descent\n(SGD) and Adaptive Moment Estimation (Adam), there remains a pronounced\ninadequacy in their capability to address fluctuations in learning efficiency,\nmeet the demands of complex models, and tackle non-convex optimization issues.\nThese challenges primarily arise from the algorithms' limitations in handling\ncomplex data structures and models, for instance, difficulties in selecting an\nappropriate learning rate, avoiding local optima, and navigating through\nhigh-dimensional spaces. To address these issues, this paper introduces a novel\noptimization algorithm named DWMGrad. This algorithm, building on the\nfoundations of traditional methods, incorporates a dynamic guidance mechanism\nreliant on historical data to dynamically update momentum and learning rates.\nThis allows the optimizer to flexibly adjust its reliance on historical\ninformation, adapting to various training scenarios. This strategy not only\nenables the optimizer to better adapt to changing environments and task\ncomplexities but also, as validated through extensive experimentation,\ndemonstrates DWMGrad's ability to achieve faster convergence rates and higher\naccuracies under a multitude of scenarios.",
    "published": "2025-10-29T00:03:03Z",
    "updated": "2025-10-29T00:03:03Z",
    "link": "http://arxiv.org/pdf/2510.25042v1.pdf",
    "category": [
      "cs.LG",
      "cs.NE"
    ],
    "authors": [
      "Zhifeng Wang",
      "Longlong Li",
      "Chunyan Zeng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25039v1",
    "title": "Automating Benchmark Design",
    "summary": "The rapid progress and widespread deployment of LLMs and LLM-powered agents\nhas outpaced our ability to evaluate them. Hand-crafted, static benchmarks are\nthe primary tool for assessing model capabilities, but these quickly become\nsaturated. In contrast, dynamic benchmarks evolve alongside the models they\nevaluate, but are expensive to create and continuously update. To address these\nchallenges, we develop BeTaL (Benchmark Tuning with an LLM-in-the-loop), a\nframework that leverages environment design principles to automate the process\nof dynamic benchmark design. BeTaL works by parameterizing key design choices\nin base benchmark templates and uses LLMs to reason through the resulting\nparameter space to obtain target properties (such as difficulty and realism) in\na cost-efficient manner. We validate this approach on its ability to create\nbenchmarks with desired difficulty levels. Using BeTaL, we create two new\nbenchmarks and extend a popular agentic benchmark {\\tau} -bench. Extensive\nevaluation on these three tasks and multiple target difficulty levels shows\nthat BeTaL produces benchmarks much closer to the desired difficulty, with\naverage deviations ranging from 5.3% to 13.2% -- a 2-4x improvement over the\nbaselines.",
    "published": "2025-10-28T23:53:36Z",
    "updated": "2025-10-28T23:53:36Z",
    "link": "http://arxiv.org/pdf/2510.25039v1.pdf",
    "category": [
      "cs.SE",
      "cs.LG"
    ],
    "authors": [
      "Amanda Dsouza",
      "Harit Vishwakarma",
      "Zhengyang Qi",
      "Justin Bauer",
      "Derek Pham",
      "Thomas Walshe",
      "Armin Parchami",
      "Frederic Sala",
      "Paroma Varma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25037v1",
    "title": "Graph Distance Based on Cause-Effect Estimands with Latents",
    "summary": "Causal discovery aims to recover graphs that represent causal relations among\ngiven variables from observations, and new methods are constantly being\nproposed. Increasingly, the community raises questions about how much progress\nis made, because properly evaluating discovered graphs remains notoriously\ndifficult, particularly under latent confounding. We propose a graph distance\nmeasure for acyclic directed mixed graphs (ADMGs) based on the downstream task\nof cause-effect estimation under unobserved confounding. Our approach uses\nidentification via fixing and a symbolic verifier to quantify how graph\ndifferences distort cause-effect estimands for different treatment-outcome\npairs. We analyze the behavior of the measure under different graph\nperturbations and compare it against existing distance metrics.",
    "published": "2025-10-28T23:38:43Z",
    "updated": "2025-10-28T23:38:43Z",
    "link": "http://arxiv.org/pdf/2510.25037v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Zhufeng Li",
      "Niki Kilbertus"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.11307v2",
    "title": "Approximating the universal thermal climate index using sparse\n  regression with orthogonal polynomials",
    "summary": "This article explores novel data-driven modeling approaches for analyzing and\napproximating the Universal Thermal Climate Index (UTCI), a\nphysiologically-based metric integrating multiple atmospheric variables to\nassess thermal comfort. Given the nonlinear, multivariate structure of UTCI, we\ninvestigate symbolic and sparse regression techniques as tools for\ninterpretable and efficient function approximation. In particular, we highlight\nthe benefits of using orthogonal polynomial bases-such as Legendre\npolynomials-in sparse regression frameworks, demonstrating their advantages in\nstability, convergence, and hierarchical interpretability compared to standard\npolynomial expansions. We demonstrate that our models achieve significantly\nlower root-mean squared losses than the widely used sixth-degree polynomial\nbenchmark-while using the same or fewer parameters. By leveraging Legendre\npolynomial bases, we construct models that efficiently populate a Pareto front\nof accuracy versus complexity and exhibit stable, hierarchical coefficient\nstructures across varying model capacities. Training on just 20% of the data,\nour models generalize robustly to the remaining 80%, with consistent\nperformance under bootstrapping. The decomposition effectively approximates the\nUTCI as a Fourier-like expansion in an orthogonal basis, yielding results near\nthe theoretical optimum in the L2 (least squares) sense. We also connect these\nfindings to the broader context of equation discovery in environmental\nmodeling, referencing probabilistic grammar-based methods that enforce domain\nconsistency and compactness in symbolic expressions. Taken together, these\nresults illustrate how combining sparsity, orthogonality, and symbolic\nstructure enables robust, interpretable modeling of complex environmental\nindices like UTCI - and significantly outperforms the state-of-the-art\napproximation in both accuracy and efficiency.",
    "published": "2025-08-15T08:22:01Z",
    "updated": "2025-10-28T23:09:56Z",
    "link": "http://arxiv.org/pdf/2508.11307v2.pdf",
    "category": [
      "physics.ao-ph",
      "cs.LG",
      "physics.data-an"
    ],
    "authors": [
      "Sabin Roman",
      "Gregor Skok",
      "Ljupco Todorovski",
      "Saso Dzeroski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25026v1",
    "title": "Machine Learning based Analysis for Radiomics Features Robustness in\n  Real-World Deployment Scenarios",
    "summary": "Radiomics-based machine learning models show promise for clinical decision\nsupport but are vulnerable to distribution shifts caused by variations in\nimaging protocols, positioning, and segmentation. This study systematically\ninvestigates the robustness of radiomics-based machine learning models under\ndistribution shifts across five MRI sequences. We evaluated how different\nacquisition protocols and segmentation strategies affect model reliability in\nterms of predictive power and uncertainty-awareness. Using a phantom of 16\nfruits, we evaluated distribution shifts through: (1) protocol variations\nacross T2-HASTE, T2-TSE, T2-MAP, T1-TSE, and T2-FLAIR sequences; (2)\nsegmentation variations (full, partial, rotated); and (3) inter-observer\nvariability. We trained XGBoost classifiers on 8 consistent robust features\nversus sequence-specific features, testing model performance under in-domain\nand out-of-domain conditions. Results demonstrate that models trained on\nprotocol-invariant features maintain F1-scores >0.85 across distribution\nshifts, while models using all features showed 40% performance degradation\nunder protocol changes. Dataset augmentation substantially improved the quality\nof uncertainty estimates and reduced the expected calibration error (ECE) by\n35% without sacrificing accuracy. Temperature scaling provided minimal\ncalibration benefits, confirming XGBoost's inherent reliability. Our findings\nreveal that protocol-aware feature selection and controlled phantom studies\neffectively predict model behavior under distribution shifts, providing a\nframework for developing robust radiomics models resilient to real-world\nprotocol variations.",
    "published": "2025-10-28T22:54:43Z",
    "updated": "2025-10-28T22:54:43Z",
    "link": "http://arxiv.org/pdf/2510.25026v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Sarmad Ahmad Khan",
      "Simon Bernatz",
      "Zahra Moslehi",
      "Florian Buettner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25025v1",
    "title": "Secure Retrieval-Augmented Generation against Poisoning Attacks",
    "summary": "Large language models (LLMs) have transformed natural language processing\n(NLP), enabling applications from content generation to decision support.\nRetrieval-Augmented Generation (RAG) improves LLMs by incorporating external\nknowledge but also introduces security risks, particularly from data poisoning,\nwhere the attacker injects poisoned texts into the knowledge database to\nmanipulate system outputs. While various defenses have been proposed, they\noften struggle against advanced attacks. To address this, we introduce RAGuard,\na detection framework designed to identify poisoned texts. RAGuard first\nexpands the retrieval scope to increase the proportion of clean texts, reducing\nthe likelihood of retrieving poisoned content. It then applies chunk-wise\nperplexity filtering to detect abnormal variations and text similarity\nfiltering to flag highly similar texts. This non-parametric approach enhances\nRAG security, and experiments on large-scale datasets demonstrate its\neffectiveness in detecting and mitigating poisoning attacks, including strong\nadaptive attacks.",
    "published": "2025-10-28T22:54:19Z",
    "updated": "2025-10-28T22:54:19Z",
    "link": "http://arxiv.org/pdf/2510.25025v1.pdf",
    "category": [
      "cs.CR",
      "cs.IR",
      "cs.LG"
    ],
    "authors": [
      "Zirui Cheng",
      "Jikai Sun",
      "Anjun Gao",
      "Yueyang Quan",
      "Zhuqing Liu",
      "Xiaohua Hu",
      "Minghong Fang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25023v1",
    "title": "Disentangling Shared and Private Neural Dynamics with SPIRE: A Latent\n  Modeling Framework for Deep Brain Stimulation",
    "summary": "Disentangling shared network-level dynamics from region-specific activity is\na central challenge in modeling multi-region neural data. We introduce SPIRE\n(Shared-Private Inter-Regional Encoder), a deep multi-encoder autoencoder that\nfactorizes recordings into shared and private latent subspaces with novel\nalignment and disentanglement losses. Trained solely on baseline data, SPIRE\nrobustly recovers cross-regional structure and reveals how external\nperturbations reorganize it. On synthetic benchmarks with ground-truth latents,\nSPIRE outperforms classical probabilistic models under nonlinear distortions\nand temporal misalignments. Applied to intracranial deep brain stimulation\n(DBS) recordings, SPIRE shows that shared latents reliably encode\nstimulation-specific signatures that generalize across sites and frequencies.\nThese results establish SPIRE as a practical, reproducible tool for analyzing\nmulti-region neural dynamics under stimulation.",
    "published": "2025-10-28T22:45:52Z",
    "updated": "2025-10-28T22:45:52Z",
    "link": "http://arxiv.org/pdf/2510.25023v1.pdf",
    "category": [
      "cs.LG",
      "eess.SP"
    ],
    "authors": [
      "Rahil Soroushmojdehi",
      "Sina Javadzadeh",
      "Mehrnaz Asadi",
      "Terence D. Sanger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25001v1",
    "title": "Bayesian Neural Networks vs. Mixture Density Networks: Theoretical and\n  Empirical Insights for Uncertainty-Aware Nonlinear Modeling",
    "summary": "This paper investigates two prominent probabilistic neural modeling\nparadigms: Bayesian Neural Networks (BNNs) and Mixture Density Networks (MDNs)\nfor uncertainty-aware nonlinear regression. While BNNs incorporate epistemic\nuncertainty by placing prior distributions over network parameters, MDNs\ndirectly model the conditional output distribution, thereby capturing\nmultimodal and heteroscedastic data-generating mechanisms. We present a unified\ntheoretical and empirical framework comparing these approaches. On the\ntheoretical side, we derive convergence rates and error bounds under H\\\"older\nsmoothness conditions, showing that MDNs achieve faster Kullback-Leibler (KL)\ndivergence convergence due to their likelihood-based nature, whereas BNNs\nexhibit additional approximation bias induced by variational inference.\nEmpirically, we evaluate both architectures on synthetic nonlinear datasets and\na radiographic benchmark (RSNA Pediatric Bone Age Challenge). Quantitative and\nqualitative results demonstrate that MDNs more effectively capture multimodal\nresponses and adaptive uncertainty, whereas BNNs provide more interpretable\nepistemic uncertainty under limited data. Our findings clarify the\ncomplementary strengths of posterior-based and likelihood-based probabilistic\nlearning, offering guidance for uncertainty-aware modeling in nonlinear\nsystems.",
    "published": "2025-10-28T22:00:30Z",
    "updated": "2025-10-28T22:00:30Z",
    "link": "http://arxiv.org/pdf/2510.25001v1.pdf",
    "category": [
      "stat.CO",
      "cs.LG",
      "68T07, 62G08, 62C10, 41A25"
    ],
    "authors": [
      "Riddhi Pratim Ghosh",
      "Ian Barnett"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25000v1",
    "title": "What Really Matters in Matrix-Whitening Optimizers?",
    "summary": "A range of recent optimizers have emerged that approximate the same\n\"matrix-whitening\" transformation in various ways. In this work, we\nsystematically deconstruct such optimizers, aiming to disentangle the key\ncomponents that explain performance. Across tuned hyperparameters across the\nboard, all flavors of matrix-whitening methods reliably outperform elementwise\ncounterparts, such as Adam. Matrix-whitening is often related to spectral\ndescent -- however, experiments reveal that performance gains are *not\nexplained solely by accurate spectral normalization* -- particularly, SOAP\ndisplays the largest per-step gain, even though Muon more accurately descends\nalong the steepest spectral descent direction. Instead, we argue that\nmatrix-whitening serves two purposes, and the variance adaptation component of\nmatrix-whitening is the overlooked ingredient explaining this performance gap.\nExperiments show that variance-adapted versions of optimizers consistently\noutperform their sign-descent counterparts, including an adaptive version of\nMuon. We further ablate variance adaptation strategies, finding that while\nlookahead style approximations are not as effective, low-rank variance\nestimators can effectively reduce memory costs without a performance loss.",
    "published": "2025-10-28T21:59:49Z",
    "updated": "2025-10-28T21:59:49Z",
    "link": "http://arxiv.org/pdf/2510.25000v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Kevin Frans",
      "Pieter Abbeel",
      "Sergey Levine"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24988v1",
    "title": "Enhancing Hierarchical Reinforcement Learning through Change Point\n  Detection in Time Series",
    "summary": "Hierarchical Reinforcement Learning (HRL) enhances the scalability of\ndecision-making in long-horizon tasks by introducing temporal abstraction\nthrough options-policies that span multiple timesteps. Despite its theoretical\nappeal, the practical implementation of HRL suffers from the challenge of\nautonomously discovering semantically meaningful subgoals and learning optimal\noption termination boundaries. This paper introduces a novel architecture that\nintegrates a self-supervised, Transformer-based Change Point Detection (CPD)\nmodule into the Option-Critic framework, enabling adaptive segmentation of\nstate trajectories and the discovery of options. The CPD module is trained\nusing heuristic pseudo-labels derived from intrinsic signals to infer latent\nshifts in environment dynamics without external supervision. These inferred\nchange-points are leveraged in three critical ways: (i) to serve as supervisory\nsignals for stabilizing termination function gradients, (ii) to pretrain\nintra-option policies via segment-wise behavioral cloning, and (iii) to enforce\nfunctional specialization through inter-option divergence penalties over\nCPD-defined state partitions. The overall optimization objective enhances the\nstandard actor-critic loss using structure-aware auxiliary losses. In our\nframework, option discovery arises naturally as CPD-defined trajectory segments\nare mapped to distinct intra-option policies, enabling the agent to\nautonomously partition its behavior into reusable, semantically meaningful\nskills. Experiments on the Four-Rooms and Pinball tasks demonstrate that\nCPD-guided agents exhibit accelerated convergence, higher cumulative returns,\nand significantly improved option specialization. These findings confirm that\nintegrating structural priors via change-point segmentation leads to more\ninterpretable, sample-efficient, and robust hierarchical policies in complex\nenvironments.",
    "published": "2025-10-28T21:34:23Z",
    "updated": "2025-10-28T21:34:23Z",
    "link": "http://arxiv.org/pdf/2510.24988v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Hemanath Arumugam",
      "Falong Fan",
      "Bo Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24987v1",
    "title": "scMRDR: A scalable and flexible framework for unpaired single-cell\n  multi-omics data integration",
    "summary": "Advances in single-cell sequencing have enabled high-resolution profiling of\ndiverse molecular modalities, while integrating unpaired multi-omics\nsingle-cell data remains challenging. Existing approaches either rely on pair\ninformation or prior correspondences, or require computing a global pairwise\ncoupling matrix, limiting their scalability and flexibility. In this paper, we\nintroduce a scalable and flexible generative framework called single-cell\nMulti-omics Regularized Disentangled Representations (scMRDR) for unpaired\nmulti-omics integration. Specifically, we disentangle each cell's latent\nrepresentations into modality-shared and modality-specific components using a\nwell-designed $\\beta$-VAE architecture, which are augmented with isometric\nregularization to preserve intra-omics biological heterogeneity, adversarial\nobjective to encourage cross-modal alignment, and masked reconstruction loss\nstrategy to address the issue of missing features across modalities. Our method\nachieves excellent performance on benchmark datasets in terms of batch\ncorrection, modality alignment, and biological signal preservation. Crucially,\nit scales effectively to large-level datasets and supports integration of more\nthan two omics, offering a powerful and flexible solution for large-scale\nmulti-omics data integration and downstream biological discovery.",
    "published": "2025-10-28T21:28:39Z",
    "updated": "2025-10-28T21:28:39Z",
    "link": "http://arxiv.org/pdf/2510.24987v1.pdf",
    "category": [
      "q-bio.QM",
      "cs.LG",
      "q-bio.GN"
    ],
    "authors": [
      "Jianle Sun",
      "Chaoqi Liang",
      "Ran Wei",
      "Peng Zheng",
      "Lei Bai",
      "Wanli Ouyang",
      "Hongliang Yan",
      "Peng Ye"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.17488v2",
    "title": "Online Adaptation for Flying Quadrotors in Tight Formations",
    "summary": "The task of flying in tight formations is challenging for teams of quadrotors\nbecause the complex aerodynamic wake interactions can destabilize individual\nteam members as well as the team. Furthermore, these aerodynamic effects are\nhighly nonlinear and fast-paced, making them difficult to model and predict. To\novercome these challenges, we present L1 KNODE-DW MPC, an adaptive, mixed\nexpert learning based control framework that allows individual quadrotors to\naccurately track trajectories while adapting to time-varying aerodynamic\ninteractions during formation flights. We evaluate L1 KNODE-DW MPC in two\ndifferent three-quadrotor formations and show that it outperforms several MPC\nbaselines. Our results show that the proposed framework is capable of enabling\nthe three-quadrotor team to remain vertically aligned in close proximity\nthroughout the flight. These findings show that the L1 adaptive module\ncompensates for unmodeled disturbances most effectively when paired with an\naccurate dynamics model. A video showcasing our framework and the physical\nexperiments is available here: https://youtu.be/9QX1Q5Ut9Rs",
    "published": "2025-06-20T21:49:17Z",
    "updated": "2025-10-28T21:28:31Z",
    "link": "http://arxiv.org/pdf/2506.17488v2.pdf",
    "category": [
      "cs.RO",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "authors": [
      "Pei-An Hsieh",
      "Kong Yao Chee",
      "M. Ani Hsieh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.20995v2",
    "title": "AL-CoLe: Augmented Lagrangian for Constrained Learning",
    "summary": "Despite the non-convexity of most modern machine learning parameterizations,\nLagrangian duality has become a popular tool for addressing constrained\nlearning problems. We revisit Augmented Lagrangian methods, which aim to\nmitigate the duality gap in non-convex settings while requiring only minimal\nmodifications, and have remained comparably unexplored in constrained learning\nsettings. We establish strong duality results under mild conditions, prove\nconvergence of dual ascent algorithms to feasible and optimal primal solutions,\nand provide PAC-style generalization guarantees. Finally, we demonstrate its\neffectiveness on fairness constrained classification tasks.",
    "published": "2025-10-23T20:46:49Z",
    "updated": "2025-10-28T21:25:00Z",
    "link": "http://arxiv.org/pdf/2510.20995v2.pdf",
    "category": [
      "cs.LG",
      "eess.SP"
    ],
    "authors": [
      "Ignacio Boero",
      "Ignacio Hounie",
      "Alejandro Ribeiro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24982v1",
    "title": "Strategic inputs: feature selection from game-theoretic perspective",
    "summary": "The exponential growth of data volumes has led to escalating computational\ncosts in machine learning model training. However, many features fail to\ncontribute positively to model performance while consuming substantial\ncomputational resources. This paper presents an end-to-end feature selection\nframework for tabular data based on game theory. We formulate feature selection\nprocedure based on a cooperative game where features are modeled as players,\nand their importance is determined through the evaluation of synergistic\ninteractions and marginal contributions. The proposed framework comprises four\ncore components: sample selection, game-theoretic feature importance\nevaluation, redundant feature elimination, and optimized model training.\nExperimental results demonstrate that the proposed method achieves substantial\ncomputation reduction while preserving predictive performance, thereby offering\nan efficient solution of the computational challenges of large-scale machine\nlearning. The source code is available at\nhttps://github.com/vectorsss/strategy_inputs.",
    "published": "2025-10-28T21:24:43Z",
    "updated": "2025-10-28T21:24:43Z",
    "link": "http://arxiv.org/pdf/2510.24982v1.pdf",
    "category": [
      "cs.LG",
      "68T01, 68T20"
    ],
    "authors": [
      "Chi Zhao",
      "Jing Liu",
      "Elena Parilina"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2302.00662v3",
    "title": "Robust Fitted-Q-Evaluation and Iteration under Sequentially Exogenous\n  Unobserved Confounders",
    "summary": "Offline reinforcement learning is important in domains such as medicine,\neconomics, and e-commerce where online experimentation is costly, dangerous or\nunethical, and where the true model is unknown. However, most methods assume\nall covariates used in the behavior policy's action decisions are observed.\nThough this assumption, sequential ignorability/unconfoundedness, likely does\nnot hold in observational data, most of the data that accounts for selection\ninto treatment may be observed, motivating sensitivity analysis. We study\nrobust policy evaluation and policy optimization in the presence of\nsequentially-exogenous unobserved confounders under a sensitivity model. We\npropose and analyze orthogonalized robust fitted-Q-iteration that uses\nclosed-form solutions of the robust Bellman operator to derive a loss\nminimization problem for the robust Q function, and adds a bias-correction to\nquantile estimation. Our algorithm enjoys the computational ease of\nfitted-Q-iteration and statistical improvements (reduced dependence on quantile\nestimation error) from orthogonalization. We provide sample complexity bounds,\ninsights, and show effectiveness both in simulations and on real-world\nlongitudinal healthcare data of treating sepsis. In particular, our model of\nsequential unobserved confounders yields an online Markov decision process,\nrather than partially observed Markov decision process: we illustrate how this\ncan enable warm-starting optimistic reinforcement learning algorithms with\nvalid robust bounds from observational data.",
    "published": "2023-02-01T18:40:53Z",
    "updated": "2025-10-28T21:18:02Z",
    "link": "http://arxiv.org/pdf/2302.00662v3.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "math.OC"
    ],
    "authors": [
      "David Bruns-Smith",
      "Angela Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.00917v3",
    "title": "Q-learning with Posterior Sampling",
    "summary": "Bayesian posterior sampling techniques have demonstrated superior empirical\nperformance in many exploration-exploitation settings. However, their\ntheoretical analysis remains a challenge, especially in complex settings like\nreinforcement learning. In this paper, we introduce Q-Learning with Posterior\nSampling (PSQL), a simple Q-learning-based algorithm that uses Gaussian\nposteriors on Q-values for exploration, akin to the popular Thompson Sampling\nalgorithm in the multi-armed bandit setting. We show that in the tabular\nepisodic MDP setting, PSQL achieves a regret bound of $\\tilde\nO(H^2\\sqrt{SAT})$, closely matching the known lower bound of\n$\\Omega(H\\sqrt{SAT})$. Here, S, A denote the number of states and actions in\nthe underlying Markov Decision Process (MDP), and $T=KH$ with $K$ being the\nnumber of episodes and $H$ being the planning horizon. Our work provides\nseveral new technical insights into the core challenges in combining posterior\nsampling with dynamic programming and TD-learning-based RL algorithms, along\nwith novel ideas for resolving those difficulties. We hope this will form a\nstarting point for analyzing this efficient and important algorithmic technique\nin even more complex RL settings.",
    "published": "2025-06-01T09:11:24Z",
    "updated": "2025-10-28T21:14:04Z",
    "link": "http://arxiv.org/pdf/2506.00917v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Priyank Agrawal",
      "Shipra Agrawal",
      "Azmat Azati"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24974v1",
    "title": "Conformational Rank Conditioned Committees for Machine Learning-Assisted\n  Directed Evolution",
    "summary": "Machine Learning-assisted directed evolution (MLDE) is a powerful tool for\nefficiently navigating antibody fitness landscapes. Many structure-aware MLDE\npipelines rely on a single conformation or a single committee across all\nconformations, limiting their ability to separate conformational uncertainty\nfrom epistemic uncertainty. Here, we introduce a rank -conditioned committee\n(RCC) framework that leverages ranked conformations to assign a deep neural\nnetwork committee per rank. This design enables a principled separation between\nepistemic uncertainty and conformational uncertainty. We validate our approach\non SARS-CoV-2 antibody docking, demonstrating significant improvements over\nbaseline strategies. Our results offer a scalable route for therapeutic\nantibody discovery while directly addressing the challenge of modeling\nconformational uncertainty.",
    "published": "2025-10-28T21:13:37Z",
    "updated": "2025-10-28T21:13:37Z",
    "link": "http://arxiv.org/pdf/2510.24974v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Mia Adler",
      "Carrie Liang",
      "Brian Peng",
      "Oleg Presnyakov",
      "Justin M. Baker",
      "Jannelle Lauffer",
      "Himani Sharma",
      "Barry Merriman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2403.09066v5",
    "title": "Hyperparameters in Continual Learning: A Reality Check",
    "summary": "Continual learning (CL) aims to train a model on a sequence of tasks (i.e., a\nCL scenario) while balancing the trade-off between plasticity (learning new\ntasks) and stability (retaining prior knowledge). The dominantly adopted\nconventional evaluation protocol for CL algorithms selects the best\nhyperparameters (e.g., learning rate, mini-batch size, regularization\nstrengths, etc.) within a given scenario and then evaluates the algorithms\nusing these hyperparameters in the same scenario. However, this protocol has\nsignificant shortcomings: it overestimates the CL capacity of algorithms and\nrelies on unrealistic hyperparameter tuning, which is not feasible for\nreal-world applications. From the fundamental principles of evaluation in\nmachine learning, we argue that the evaluation of CL algorithms should focus on\nassessing the generalizability of their CL capacity to unseen scenarios. Based\non this, we propose the Generalizable Two-phase Evaluation Protocol (GTEP)\nconsisting of hyperparameter tuning and evaluation phases. Both phases share\nthe same scenario configuration (e.g., number of tasks) but are generated from\ndifferent datasets. Hyperparameters of CL algorithms are tuned in the first\nphase and applied in the second phase to evaluate the algorithms. We apply this\nprotocol to class-incremental learning, both with and without pretrained\nmodels. Across more than 8,000 experiments, our results show that most\nstate-of-the-art algorithms fail to replicate their reported performance,\nhighlighting that their CL capacity has been significantly overestimated in the\nconventional evaluation protocol. Our implementation can be found in\nhttps://github.com/csm9493/GTEP.",
    "published": "2024-03-14T03:13:01Z",
    "updated": "2025-10-28T21:13:11Z",
    "link": "http://arxiv.org/pdf/2403.09066v5.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Sungmin Cha",
      "Kyunghyun Cho"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.13111v2",
    "title": "Why Knowledge Distillation Works in Generative Models: A Minimal Working\n  Explanation",
    "summary": "Knowledge distillation (KD) is a core component in the training and\ndeployment of modern generative models, particularly large language models\n(LLMs). While its empirical benefits are well documented -- enabling smaller\nstudent models to emulate the performance of much larger teachers -- the\nunderlying mechanisms by which KD improves generative quality remain poorly\nunderstood. In this work, we present a minimal working explanation of KD in\ngenerative modeling. Using a controlled simulation with mixtures of Gaussians,\nwe demonstrate that distillation induces a trade-off between precision and\nrecall in the student model. As the teacher distribution becomes more\nselective, the student concentrates more probability mass on high-likelihood\nregions at the expense of coverage -- a behavior modulated by a single\nentropy-controlling parameter. We then validate this effect in a large-scale\nlanguage modeling setup using the SmolLM2 family of models. Empirical results\nreveal the same precision-recall dynamics observed in simulation, where\nprecision corresponds to sample quality and recall to distributional coverage.\nThis precision-recall trade-off in LLMs is found to be especially beneficial in\nscenarios where sample quality is more important than diversity, such as\ninstruction tuning or downstream generation. Our analysis provides a simple and\ngeneral explanation for the effectiveness of KD in generative modeling.",
    "published": "2025-05-19T13:39:47Z",
    "updated": "2025-10-28T21:12:26Z",
    "link": "http://arxiv.org/pdf/2505.13111v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Sungmin Cha",
      "Kyunghyun Cho"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2308.08705v4",
    "title": "Partially Observable Multi-Agent Reinforcement Learning with Information\n  Sharing",
    "summary": "We study provable multi-agent reinforcement learning (RL) in the general\nframework of partially observable stochastic games (POSGs). To circumvent the\nknown hardness results and the use of computationally intractable oracles, we\nadvocate leveraging the potential \\emph{information-sharing} among agents, a\ncommon practice in empirical multi-agent RL, and a standard model for\nmulti-agent control systems with communication. We first establish several\ncomputational complexity results to justify the necessity of\ninformation-sharing, as well as the observability assumption that has enabled\nquasi-polynomial time and sample single-agent RL with partial observations, for\ntractably solving POSGs. Inspired by the inefficiency of planning in the\nground-truth model, we then propose to further \\emph{approximate} the shared\ncommon information to construct an approximate model of the POSG, in which an\napproximate \\emph{equilibrium} (of the original POSG) can be found in\nquasi-polynomial-time, under the aforementioned assumptions. Furthermore, we\ndevelop a partially observable multi-agent RL algorithm whose time and sample\ncomplexities are \\emph{both} quasi-polynomial. Finally, beyond equilibrium\nlearning, we extend our algorithmic framework to finding the \\emph{team-optimal\nsolution} in cooperative POSGs, i.e., decentralized partially observable Markov\ndecision processes, a more challenging goal. We establish concrete\ncomputational and sample complexities under several structural assumptions of\nthe model. We hope our study could open up the possibilities of leveraging and\neven designing different \\emph{information structures}, a well-studied notion\nin control theory, for developing both sample- and computation-efficient\npartially observable multi-agent RL.",
    "published": "2023-08-16T23:42:03Z",
    "updated": "2025-10-28T21:12:00Z",
    "link": "http://arxiv.org/pdf/2308.08705v4.pdf",
    "category": [
      "cs.LG",
      "cs.GT",
      "cs.MA"
    ],
    "authors": [
      "Xiangyu Liu",
      "Kaiqing Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.14109v2",
    "title": "An Adversarial-Driven Experimental Study on Deep Learning for RF\n  Fingerprinting",
    "summary": "Radio frequency (RF) fingerprinting, which extracts unique hardware\nimperfections of radio devices, has emerged as a promising physical-layer\ndevice identification mechanism in zero trust architectures and beyond 5G\nnetworks. In particular, deep learning (DL) methods have demonstrated\nstate-of-the-art performance in this domain. However, existing approaches have\nprimarily focused on enhancing system robustness against temporal and spatial\nvariations in wireless environments, while the security vulnerabilities of\nthese DL-based approaches have often been overlooked. In this work, we\nsystematically investigate the security risks of DL-based RF fingerprinting\nsystems through an adversarial-driven experimental analysis. We observe a\nconsistent misclassification behavior for DL models under domain shifts, where\na device is frequently misclassified as another specific one. Our analysis\nbased on extensive real-world experiments demonstrates that this behavior can\nbe exploited as an effective backdoor to enable external attackers to intrude\ninto the system. Furthermore, we show that training DL models on raw received\nsignals causes the models to entangle RF fingerprints with environmental and\nsignal-pattern features, creating additional attack vectors that cannot be\nmitigated solely through post-processing security methods such as confidence\nthresholds.",
    "published": "2025-07-18T17:42:20Z",
    "updated": "2025-10-28T21:11:23Z",
    "link": "http://arxiv.org/pdf/2507.14109v2.pdf",
    "category": [
      "cs.CR",
      "cs.LG",
      "eess.SP"
    ],
    "authors": [
      "Xinyu Cao",
      "Bimal Adhikari",
      "Shangqing Zhao",
      "Jingxian Wu",
      "Yanjun Pan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.16656v3",
    "title": "Mesh-Informed Neural Operator : A Transformer Generative Approach",
    "summary": "Generative models in function spaces, situated at the intersection of\ngenerative modeling and operator learning, are attracting increasing attention\ndue to their immense potential in diverse scientific and engineering\napplications. While functional generative models are theoretically domain- and\ndiscretization-agnostic, current implementations heavily rely on the Fourier\nNeural Operator (FNO), limiting their applicability to regular grids and\nrectangular domains. To overcome these critical limitations, we introduce the\nMesh-Informed Neural Operator (MINO). By leveraging graph neural operators and\ncross-attention mechanisms, MINO offers a principled, domain- and\ndiscretization-agnostic backbone for generative modeling in function spaces.\nThis advancement significantly expands the scope of such models to more diverse\napplications in generative, inverse, and regression tasks. Furthermore, MINO\nprovides a unified perspective on integrating neural operators with general\nadvanced deep learning architectures. Finally, we introduce a suite of\nstandardized evaluation metrics that enable objective comparison of functional\ngenerative models, addressing another critical gap in the field.",
    "published": "2025-06-20T00:00:22Z",
    "updated": "2025-10-28T21:00:46Z",
    "link": "http://arxiv.org/pdf/2506.16656v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Yaozhong Shi",
      "Zachary E. Ross",
      "Domniki Asimaki",
      "Kamyar Azizzadenesheli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24951v1",
    "title": "Resource-Efficient and Robust Inference of Deep and Bayesian Neural\n  Networks on Embedded and Analog Computing Platforms",
    "summary": "While modern machine learning has transformed numerous application domains,\nits growing computational demands increasingly constrain scalability and\nefficiency, particularly on embedded and resource-limited platforms. In\npractice, neural networks must not only operate efficiently but also provide\nreliable predictions under distributional shifts or unseen data. Bayesian\nneural networks offer a principled framework for quantifying uncertainty, yet\ntheir computational overhead further compounds these challenges.\n  This work advances resource-efficient and robust inference for both\nconventional and Bayesian neural networks through the joint pursuit of\nalgorithmic and hardware efficiency. The former reduces computation through\nmodel compression and approximate Bayesian inference, while the latter\noptimizes deployment on digital accelerators and explores analog hardware,\nbridging algorithmic design and physical realization. The first contribution,\nGalen, performs automatic layer-specific compression guided by sensitivity\nanalysis and hardware-in-the-loop feedback. Analog accelerators offer\nefficiency gains at the cost of noise; this work models device imperfections\nand extends noisy training to nonstationary conditions, improving robustness\nand stability. A second line of work advances probabilistic inference,\ndeveloping analytic and ensemble approximations that replace costly sampling,\nintegrate into a compiler stack, and optimize embedded inference. Finally,\nprobabilistic photonic computing introduces a paradigm where controlled analog\nnoise acts as an intrinsic entropy source, enabling fast, energy-efficient\nprobabilistic inference directly in hardware.\n  Together, these studies demonstrate how efficiency and reliability can be\nadvanced jointly through algorithm-hardware co-design, laying the foundation\nfor the next generation of trustworthy, energy-efficient machine-learning\nsystems.",
    "published": "2025-10-28T20:34:53Z",
    "updated": "2025-10-28T20:34:53Z",
    "link": "http://arxiv.org/pdf/2510.24951v1.pdf",
    "category": [
      "cs.LG",
      "cs.AR",
      "cs.NE"
    ],
    "authors": [
      "Bernhard Klein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24941v1",
    "title": "Can Aha Moments Be Fake? Identifying True and Decorative Thinking Steps\n  in Chain-of-Thought",
    "summary": "Recent large language models (LLMs) can generate long Chain-of-Thought (CoT)\nat test time, enabling them to solve complex tasks. These reasoning steps in\nCoT are often assumed as a faithful reflection of the model's internal thinking\nprocess, and used to monitor unsafe intentions. However, we find many reasoning\nsteps don't truly contribute to LLMs' prediction. We measure the step-wise\ncausal influence of each reasoning step on the model's final prediction with a\nproposed True Thinking Score (TTS). We reveal that LLMs often interleave\nbetween true-thinking steps (which are genuinely used to produce the final\noutput) and decorative-thinking steps (which only give the appearance of\nreasoning but have minimal causal impact). Notably, only a small subset of the\ntotal reasoning steps have a high TTS that causally drive the model's\nprediction: e.g., for the AIME dataset, only an average of 2.3% of reasoning\nsteps in CoT have a TTS >= 0.7 (range: 0-1) under the Qwen-2.5 model.\nFurthermore, we identify a TrueThinking direction in the latent space of LLMs.\nBy steering along or against this direction, we can force the model to perform\nor disregard certain CoT steps when computing the final result. Finally, we\nhighlight that self-verification steps in CoT (i.e., aha moments) can also be\ndecorative, where LLMs do not truly verify their solution. Steering along the\nTrueThinking direction can force internal reasoning over these steps, resulting\nin a change in the final results. Overall, our work reveals that LLMs often\nverbalize reasoning steps without actually performing them internally, which\nundermines both the efficiency of LLM reasoning and the trustworthiness of CoT.",
    "published": "2025-10-28T20:14:02Z",
    "updated": "2025-10-28T20:14:02Z",
    "link": "http://arxiv.org/pdf/2510.24941v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Jiachen Zhao",
      "Yiyou Sun",
      "Weiyan Shi",
      "Dawn Song"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.12913v2",
    "title": "Jailbreak Transferability Emerges from Shared Representations",
    "summary": "Jailbreak transferability is the surprising phenomenon when an adversarial\nattack compromising one model also elicits harmful responses from other models.\nDespite widespread demonstrations, there is little consensus on why transfer is\npossible: is it a quirk of safety training, an artifact of model families, or a\nmore fundamental property of representation learning? We present evidence that\ntransferability emerges from shared representations rather than incidental\nflaws. Across 20 open-weight models and 33 jailbreak attacks, we find two\nfactors that systematically shape transfer: (1) representational similarity\nunder benign prompts, and (2) the strength of the jailbreak on the source\nmodel. To move beyond correlation, we show that deliberately increasing\nsimilarity through benign only distillation causally increases transfer. Our\nqualitative analyses reveal systematic transferability patterns across\ndifferent types of jailbreaks. For example, persona-style jailbreaks transfer\nfar more often than cipher-based prompts, consistent with the idea that\nnatural-language attacks exploit models' shared representation space, whereas\ncipher-based attacks rely on idiosyncratic quirks that do not generalize.\nTogether, these results reframe jailbreak transfer as a consequence of\nrepresentation alignment rather than a fragile byproduct of safety training.",
    "published": "2025-06-15T17:03:11Z",
    "updated": "2025-10-28T20:06:01Z",
    "link": "http://arxiv.org/pdf/2506.12913v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Rico Angell",
      "Jannik Brinkmann",
      "He He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24927v1",
    "title": "WBT-BGRL: A Non-Contrastive Weighted Bipartite Link Prediction Model for\n  Inductive Learning",
    "summary": "Link prediction in bipartite graphs is crucial for applications like\nrecommendation systems and failure detection, yet it is less studied than in\nmonopartite graphs. Contrastive methods struggle with inefficient and biased\nnegative sampling, while non-contrastive approaches rely solely on positive\nsamples. Existing models perform well in transductive settings, but their\neffectiveness in inductive, weighted, and bipartite scenarios remains untested.\nTo address this, we propose Weighted Bipartite Triplet-Bootstrapped Graph\nLatents (WBT-BGRL), a non-contrastive framework that enhances bootstrapped\nlearning with a novel weighting mechanism in the triplet loss. Using a\nbipartite architecture with dual GCN encoders, WBT-BGRL is evaluated against\nadapted state-of-the-art models (T-BGRL, BGRL, GBT, CCA-SSG). Results on\nreal-world datasets (Industry and E-commerce) show competitive performance,\nespecially when weighting is applied during pretraining-highlighting the value\nof weighted, non-contrastive learning for inductive link prediction in\nbipartite graphs.",
    "published": "2025-10-28T19:56:13Z",
    "updated": "2025-10-28T19:56:13Z",
    "link": "http://arxiv.org/pdf/2510.24927v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Joel Frank Huarayo Quispe",
      "Lilian Berton",
      "Didier Vega-Oliveros"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.22510v2",
    "title": "CANDI: Hybrid Discrete-Continuous Diffusion Models",
    "summary": "While continuous diffusion has shown remarkable success in continuous domains\nsuch as image generation, its direct application to discrete data has\nunderperformed compared to purely discrete formulations. This gap is\ncounterintuitive, given that continuous diffusion learns score functions that\nenable joint evolution across multiple positions. To understand this gap, we\nintroduce token identifiability as an analytical framework for understanding\nhow Gaussian noise corrupts discrete data through two mechanisms: discrete\nidentity corruption and continuous rank degradation. We reveal that these\nmechanisms scale differently with vocabulary size, creating a temporal\ndissonance: at noise levels where discrete corruption preserves enough\nstructure for conditional learning, continuous denoising is trivial; at noise\nlevels where continuous denoising is meaningful, discrete corruption destroys\nnearly all conditional structure. To solve this, we propose CANDI (Continuous\nANd DIscrete diffusion), a hybrid framework that decouples discrete and\ncontinuous corruption, enabling simultaneous learning of both conditional\nstructure and continuous geometry. We empirically validate the temporal\ndissonance phenomenon and demonstrate that CANDI successfully avoids it. This\nunlocks the benefits of continuous diffusion for discrete spaces: on controlled\ngeneration, CANDI enables classifier-based guidance with off-the-shelf\nclassifiers through simple gradient addition; on text generation, CANDI\noutperforms masked diffusion at low NFE, demonstrating the value of learning\ncontinuous gradients for discrete spaces. We include the code on the project\npage available here: https://patrickpynadath1.github.io/candi-lander",
    "published": "2025-10-26T03:24:31Z",
    "updated": "2025-10-28T19:55:41Z",
    "link": "http://arxiv.org/pdf/2510.22510v2.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Patrick Pynadath",
      "Jiaxin Shi",
      "Ruqi Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24919v1",
    "title": "Modality-Aware SAM: Sharpness-Aware-Minimization Driven Gradient\n  Modulation for Harmonized Multimodal Learning",
    "summary": "In multimodal learning, dominant modalities often overshadow others, limiting\ngeneralization. We propose Modality-Aware Sharpness-Aware Minimization (M-SAM),\na model-agnostic framework that applies to many modalities and supports early\nand late fusion scenarios. In every iteration, M-SAM in three steps optimizes\nlearning. \\textbf{First, it identifies the dominant modality} based on\nmodalities' contribution in the accuracy using Shapley. \\textbf{Second, it\ndecomposes the loss landscape}, or in another language, it modulates the loss\nto prioritize the robustness of the model in favor of the dominant modality,\nand \\textbf{third, M-SAM updates the weights} by backpropagation of modulated\ngradients. This ensures robust learning for the dominant modality while\nenhancing contributions from others, allowing the model to explore and exploit\ncomplementary features that strengthen overall performance. Extensive\nexperiments on four diverse datasets show that M-SAM outperforms the latest\nstate-of-the-art optimization and gradient manipulation methods and\nsignificantly balances and improves multimodal learning.",
    "published": "2025-10-28T19:44:20Z",
    "updated": "2025-10-28T19:44:20Z",
    "link": "http://arxiv.org/pdf/2510.24919v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Hossein R. Nowdeh",
      "Jie Ji",
      "Xiaolong Ma",
      "Fatemeh Afghah"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24918v1",
    "title": "Topic Analysis with Side Information: A Neural-Augmented LDA Approach",
    "summary": "Traditional topic models such as Latent Dirichlet Allocation (LDA) have been\nwidely used to uncover latent structures in text corpora, but they often\nstruggle to integrate auxiliary information such as metadata, user attributes,\nor document labels. These limitations restrict their expressiveness,\npersonalization, and interpretability. To address this, we propose nnLDA, a\nneural-augmented probabilistic topic model that dynamically incorporates side\ninformation through a neural prior mechanism. nnLDA models each document as a\nmixture of latent topics, where the prior over topic proportions is generated\nby a neural network conditioned on auxiliary features. This design allows the\nmodel to capture complex nonlinear interactions between side information and\ntopic distributions that static Dirichlet priors cannot represent. We develop a\nstochastic variational Expectation-Maximization algorithm to jointly optimize\nthe neural and probabilistic components. Across multiple benchmark datasets,\nnnLDA consistently outperforms LDA and Dirichlet-Multinomial Regression in\ntopic coherence, perplexity, and downstream classification. These results\nhighlight the benefits of combining neural representation learning with\nprobabilistic topic modeling in settings where side information is available.",
    "published": "2025-10-28T19:38:36Z",
    "updated": "2025-10-28T19:38:36Z",
    "link": "http://arxiv.org/pdf/2510.24918v1.pdf",
    "category": [
      "cs.LG",
      "stat.ME",
      "stat.ML"
    ],
    "authors": [
      "Biyi Fang",
      "Kripa Rajshekhar",
      "Truong Vo",
      "Diego Klabjan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.02968v2",
    "title": "How Many Ratings per Item are Necessary for Reliable Significance\n  Testing?",
    "summary": "A cornerstone of machine learning evaluation is the (often hidden) assumption\nthat model and human responses are reliable enough to evaluate models against\nunitary, authoritative, ``gold standard'' data, via simple metrics such as\naccuracy, precision, and recall. The generative AI revolution would seem to\nexplode this assumption, given the critical role stochastic inference plays.\nYet, in spite of public demand for more transparency in AI -- along with strong\nevidence that humans are unreliable judges -- estimates of model reliability\nare conventionally based on, at most, a few output responses per input item. We\nadapt a method, previously used to evaluate the reliability of various metrics\nand estimators for machine learning evaluation, to determine whether an\n(existing or planned) dataset has enough responses per item to assure reliable\nnull hypothesis statistical testing. We show that, for many common metrics,\ncollecting even 5-10 responses per item (from each model and team of human\nevaluators) is not sufficient. We apply our methods to several of the very few\nextant gold standard test sets with multiple disaggregated responses per item\nand show that even these datasets lack enough responses per item. We show how\nour methods can help AI researchers make better decisions about how to collect\ndata for AI evaluation.",
    "published": "2024-12-04T02:31:28Z",
    "updated": "2025-10-28T19:25:28Z",
    "link": "http://arxiv.org/pdf/2412.02968v2.pdf",
    "category": [
      "cs.LG",
      "I.2.6"
    ],
    "authors": [
      "Christopher Homan",
      "Flip Korn",
      "Deepak Pandita",
      "Chris Welty"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.17468v2",
    "title": "Efficient Adaptive Experimentation with Noncompliance",
    "summary": "We study the problem of estimating the average treatment effect (ATE) in\nadaptive experiments where treatment can only be encouraged -- rather than\ndirectly assigned -- via a binary instrumental variable. Building on\nsemiparametric efficiency theory, we derive the efficiency bound for ATE\nestimation under arbitrary, history-dependent instrument-assignment policies,\nand show it is minimized by a variance-aware allocation rule that balances\noutcome noise and compliance variability. Leveraging this insight, we introduce\nAMRIV -- an Adaptive, Multiply-Robust estimator for Instrumental-Variable\nsettings with variance-optimal assignment. AMRIV pairs (i) an online policy\nthat adaptively approximates the optimal allocation with (ii) a sequential,\ninfluence-function-based estimator that attains the semiparametric efficiency\nbound while retaining multiply-robust consistency. We establish asymptotic\nnormality, explicit convergence rates, and anytime-valid asymptotic confidence\nsequences that enable sequential inference. Finally, we demonstrate the\npractical effectiveness of our approach through empirical studies, showing that\nadaptive instrument assignment, when combined with the AMRIV estimator, yields\nimproved efficiency and robustness compared to existing baselines.",
    "published": "2025-05-23T04:49:14Z",
    "updated": "2025-10-28T19:08:31Z",
    "link": "http://arxiv.org/pdf/2505.17468v2.pdf",
    "category": [
      "stat.ME",
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Miruna Oprescu",
      "Brian M Cho",
      "Nathan Kallus"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.21609v3",
    "title": "VLCE: A Knowledge-Enhanced Framework for Image Description in Disaster\n  Assessment",
    "summary": "Immediate damage assessment is essential after natural catastrophes; yet,\nconventional hand evaluation techniques are sluggish and perilous. Although\nsatellite and unmanned aerial vehicle (UAV) photos offer extensive perspectives\nof impacted regions, current computer vision methodologies generally yield just\nclassification labels or segmentation masks, so constraining their capacity to\ndeliver a thorough situational comprehension. We introduce the Vision Language\nCaption Enhancer (VLCE), a multimodal system designed to produce comprehensive,\ncontextually-informed explanations of disaster imagery. VLCE employs a\ndual-architecture approach: a CNN-LSTM model with a ResNet50 backbone\npretrained on EuroSat satellite imagery for the xBD dataset, and a Vision\nTransformer (ViT) model pretrained on UAV pictures for the RescueNet dataset.\nBoth systems utilize external semantic knowledge from ConceptNet and WordNet to\nexpand vocabulary coverage and improve description accuracy. We assess VLCE in\ncomparison to leading vision-language models (LLaVA and QwenVL) utilizing\nCLIPScore for semantic alignment and InfoMetIC for caption informativeness.\nExperimental findings indicate that VLCE markedly surpasses baseline models,\nattaining a maximum of 95.33% on InfoMetIC while preserving competitive\nsemantic alignment. Our dual-architecture system demonstrates significant\npotential for improving disaster damage assessment by automating the production\nof actionable, information-dense descriptions from satellite and drone photos.",
    "published": "2025-09-25T21:21:00Z",
    "updated": "2025-10-28T18:57:29Z",
    "link": "http://arxiv.org/pdf/2509.21609v3.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Md. Mahfuzur Rahman",
      "Kishor Datta Gupta",
      "Marufa Kamal",
      "Fahad Rahman",
      "Sunzida Siddique",
      "Ahmed Rafi Hasan",
      "Mohd Ariful Haque",
      "Roy George"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24889v1",
    "title": "Adaptive EEG-based stroke diagnosis with a GRU-TCN classifier and deep\n  Q-learning thresholding",
    "summary": "Rapid triage of suspected stroke needs accurate, bedside-deployable tools;\nEEG is promising but underused at first contact. We present an adaptive\nmultitask EEG classifier that converts 32-channel signals to power spectral\ndensity features (Welch), uses a recurrent-convolutional network (GRU-TCN) to\npredict stroke type (healthy, ischemic, hemorrhagic), hemispheric\nlateralization, and severity, and applies a deep Q-network (DQN) to tune\ndecision thresholds in real time. Using a patient-wise split of the UCLH Stroke\nEIT/EEG data set (44 recordings; about 26 acute stroke, 10 controls), the\nprimary outcome was stroke-type performance; secondary outcomes were severity\nand lateralization. The baseline GRU-TCN reached 89.3% accuracy (F1 92.8%) for\nstroke type, about 96.9% (F1 95.9%) for severity, and about 96.7% (F1 97.4%)\nfor lateralization. With DQN threshold adaptation, stroke-type accuracy\nincreased to about 98.0% (F1 97.7%). We also tested robustness on an\nindependent, low-density EEG cohort (ZJU4H) and report paired patient-level\nstatistics. Analyses follow STARD 2015 guidance for diagnostic accuracy studies\n(index test: GRU-TCN+DQN; reference standard: radiology/clinical diagnosis;\npatient-wise evaluation). Adaptive thresholding shifts the operating point to\nclinically preferred sensitivity-specificity trade-offs, while integrated\nscalp-map and spectral visualizations support interpretability.",
    "published": "2025-10-28T18:48:48Z",
    "updated": "2025-10-28T18:48:48Z",
    "link": "http://arxiv.org/pdf/2510.24889v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Shakeel Abdulkareem",
      "Bora Yimenicioglu",
      "Andrea Yang",
      "Khartik Uppalapati",
      "Aneesh Gudipati",
      "Zhaoyang Fan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24884v1",
    "title": "Aggregation Hides Out-of-Distribution Generalization Failures from\n  Spurious Correlations",
    "summary": "Benchmarks for out-of-distribution (OOD) generalization frequently show a\nstrong positive correlation between in-distribution (ID) and OOD accuracy\nacross models, termed \"accuracy-on-the-line.\" This pattern is often taken to\nimply that spurious correlations - correlations that improve ID but reduce OOD\nperformance - are rare in practice. We find that this positive correlation is\noften an artifact of aggregating heterogeneous OOD examples. Using a simple\ngradient-based method, OODSelect, we identify semantically coherent OOD subsets\nwhere accuracy on the line does not hold. Across widely used distribution shift\nbenchmarks, the OODSelect uncovers subsets, sometimes over half of the standard\nOOD set, where higher ID accuracy predicts lower OOD accuracy. Our findings\nindicate that aggregate metrics can obscure important failure modes of OOD\nrobustness. We release code and the identified subsets to facilitate further\nresearch.",
    "published": "2025-10-28T18:35:57Z",
    "updated": "2025-10-28T18:35:57Z",
    "link": "http://arxiv.org/pdf/2510.24884v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Olawale Salaudeen",
      "Haoran Zhang",
      "Kumail Alhamoud",
      "Sara Beery",
      "Marzyeh Ghassemi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.05715v2",
    "title": "Artificial Neural Networks Trained on Noisy Speech Exhibit the McGurk\n  Effect",
    "summary": "Humans are able to fuse information from both auditory and visual modalities\nto help with understanding speech. This is demonstrated through a phenomenon\nknown as the McGurk Effect, during which a listener is presented with\nincongruent auditory and visual speech that fuse together into the percept of\nillusory intermediate phonemes. Building on a recent framework that proposes\nhow to address developmental 'why' questions using artificial neural networks,\nwe evaluated a set of recent artificial neural networks trained on audiovisual\nspeech by testing them with audiovisually incongruent words designed to elicit\nthe McGurk effect. We show that networks trained entirely on congruent\naudiovisual speech nevertheless exhibit the McGurk percept. We further\ninvestigated 'why' by comparing networks trained on clean speech to those\ntrained on noisy speech, and discovered that training with noisy speech led to\na pronounced increase in both visual responses and McGurk responses across all\nmodels. Furthermore, we observed that systematically increasing the level of\nauditory noise during ANN training also increased the amount of audiovisual\nintegration up to a point, but at extreme noise levels, this integration failed\nto develop. These results suggest that excessive noise exposure during critical\nperiods of audiovisual learning may negatively influence the development of\naudiovisual speech integration. This work also demonstrates that the McGurk\neffect reliably emerges untrained from the behaviour of both supervised and\nunsupervised networks, even networks trained only on congruent speech. This\nsupports the notion that artificial neural networks might be useful models for\ncertain aspects of perception and cognition.",
    "published": "2024-11-08T17:16:27Z",
    "updated": "2025-10-29T17:44:30Z",
    "link": "http://arxiv.org/pdf/2411.05715v2.pdf",
    "category": [
      "cs.SD",
      "cs.MM",
      "cs.NE",
      "eess.AS"
    ],
    "authors": [
      "Lukas Grasse",
      "Matthew S. Tata"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25600v1",
    "title": "PureKV: Plug-and-Play KV Cache Optimization with Spatial-Temporal Sparse\n  Attention for Vision-Language Large Models",
    "summary": "Vision-Language Large Models (VLLMs) face significant efficiency challenges\nwhen processing high-resolution inputs. The quadratic complexity in attention\nand autoregressive generation, as well as the constantly growing key value (KV)\ncache size, severely hinder the prefilling and decoding stages. Recent efforts\nhave attempted to compress KV cache by identifying and pruning KV cache of less\nimportant tokens, but these methods typically rely on attention scores to\nestimate token importance, making them incompatible with efficient attention\nmechanisms such as FlashAttention and Sparse Attention, which do not explicitly\ncompute attention matrices. Moreover, existing methods overlook how sparse\nattention, while accelerating the prefilling stage, alters the information\nstructure of the KV cache, thereby compromising the effectiveness of downstream\nKV cache compression strategies. To address this issue, we propose PureKV, a\nplug-and-play framework for joint optimization of sparse attention and KV cache\ncompression. We first introduce a KV cache compression strategy that is fully\ncompatible with efficient attention accelerators. Our method utilizes lower\nlayer attention scores to estimate the importance of high layers' KV cache,\nenabling active pruning without compromising accuracy. In addition, we have\ndesigned a Spatial-Temporal Sparse Attention (ST-SpAttn) module specifically\ntailored for video KV cache compression algorithms. This module combines\nspatial and temporal attention sparsity to improve the compression efficiency\nof KV cache optimization algorithms by purifying spatial noise and temporal\nredundancy in KV cache. At the same time, ST-SpAttn also accelerated the\nprefilling stage of VLLMs. Extensive experiments on VLLMs (VideoLLaMA2,\nQwen2.5-VL) have shown that PureKV achieves 5.0 times KV cache compression and\n3.16 times prefill acceleration, with negligible quality degradation.",
    "published": "2025-10-29T15:10:17Z",
    "updated": "2025-10-29T15:10:17Z",
    "link": "http://arxiv.org/pdf/2510.25600v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Zhonghua Jiang",
      "Kunxi Li",
      "Yiyun Zhou",
      "Sihao Liu",
      "Zhaode Wang",
      "Chengfei lv",
      "Shengyu Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25357v1",
    "title": "Energy consumption assessment of a Virtual Reality Remote Rendering\n  application over 5G networks",
    "summary": "This paper investigates the energy implications of remote rendering for\nVirtual Reality (VR) applications within a real 5G testbed. Remote rendering\nenables lightweight devices to access high-performance graphical content by\noffloading computationally intensive tasks to Cloud-native Network Functions\n(CNFs) running on remote servers. However, this approach raises concerns\nregarding energy consumption across the various network components involved,\nincluding the remote computing node, the 5G Core, the Radio Access Network\n(RAN), and the User Equipment (UE). This work proposes and evaluates two\ncomplementary energy monitoring solutions, one hardware-based and one\nsoftware-based, to measure energy consumption at different system levels. A VR\nremote renderer, deployed as CNF and leveraging the Media over QUIC (MoQ)\nprotocol, is used as test case for assessing its energy footprint under\ndifferent multimedia and network configurations. The results provide critical\ninsights into the trade-off between energy consumption and performance of a\nreal-world VR application running in a 5G environment.",
    "published": "2025-10-29T10:21:41Z",
    "updated": "2025-10-29T10:21:41Z",
    "link": "http://arxiv.org/pdf/2510.25357v1.pdf",
    "category": [
      "cs.NI",
      "cs.MM",
      "eess.IV"
    ],
    "authors": [
      "Roberto Viola",
      "Mikel Irazola",
      "José Ramón Juárez",
      "Minh Nguyen",
      "Alexander Zoubarev",
      "Alexander Futasz",
      "Louay Bassbouss",
      "Amr A. AbdelNabi",
      "Javier Fernández Hidalgo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.10258v2",
    "title": "XY-Cut++: Advanced Layout Ordering via Hierarchical Mask Mechanism on a\n  Novel Benchmark",
    "summary": "Document Reading Order Recovery is a fundamental task in document image\nunderstanding, playing a pivotal role in enhancing Retrieval-Augmented\nGeneration (RAG) and serving as a critical preprocessing step for large\nlanguage models (LLMs). Existing methods often struggle with complex\nlayouts(e.g., multi-column newspapers), high-overhead interactions between\ncross-modal elements (visual regions and textual semantics), and a lack of\nrobust evaluation benchmarks. We introduce XY-Cut++, an advanced layout\nordering method that integrates pre-mask processing, multi-granularity\nsegmentation, and cross-modal matching to address these challenges. Our method\nsignificantly enhances layout ordering accuracy compared to traditional XY-Cut\ntechniques. Specifically, XY-Cut++ achieves state-of-the-art performance (98.8\nBLEU overall) while maintaining simplicity and efficiency. It outperforms\nexisting baselines by up to 24\\% and demonstrates consistent accuracy across\nsimple and complex layouts on the newly introduced DocBench-100 dataset. This\nadvancement establishes a reliable foundation for document structure recovery,\nsetting a new standard for layout ordering tasks and facilitating more\neffective RAG and LLM preprocessing.",
    "published": "2025-04-14T14:19:57Z",
    "updated": "2025-10-29T07:51:00Z",
    "link": "http://arxiv.org/pdf/2504.10258v2.pdf",
    "category": [
      "cs.CV",
      "cs.MM"
    ],
    "authors": [
      "Shuai Liu",
      "Youmeng Li",
      "Jizeng Wei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25225v1",
    "title": "Hallucination Localization in Video Captioning",
    "summary": "We propose a novel task, hallucination localization in video captioning,\nwhich aims to identify hallucinations in video captions at the span level (i.e.\nindividual words or phrases). This allows for a more detailed analysis of\nhallucinations compared to existing sentence-level hallucination detection\ntask. To establish a benchmark for hallucination localization, we construct\nHLVC-Dataset, a carefully curated dataset created by manually annotating 1,167\nvideo-caption pairs from VideoLLM-generated captions. We further implement a\nVideoLLM-based baseline method and conduct quantitative and qualitative\nevaluations to benchmark current performance on hallucination localization.",
    "published": "2025-10-29T07:00:48Z",
    "updated": "2025-10-29T07:00:48Z",
    "link": "http://arxiv.org/pdf/2510.25225v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Shota Nakada",
      "Kazuhiro Saito",
      "Yuchi Ishikawa",
      "Hokuto Munakata",
      "Tatsuya Komatsu",
      "Masayoshi Kondo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25079v1",
    "title": "Performance Evaluation of Multimedia Traffic in Cloud Storage Services\n  over Wi-Fi and LTE Networks",
    "summary": "The performance of Dropbox, Google Drive, and OneDrive cloud storage services\nwas evaluated under Wi-Fi and LTE network conditions during multimedia file\nuploads. Traffic was captured using Wireshark, and key metrics (including\ndelay, jitter, bandwidth, and packet loss) were analyzed. Google Drive\nmaintained the most consistent performance across both types of networks,\nshowing low latency and reduced jitter. Dropbox showed efficient bandwidth\nutilization, but experienced a longer delay over LTE, attributed to a greater\nnumber of intermediate hops. OneDrive presented variable behavior, with\nelevated packet rates and increased sensitivity to fluctuations in the mobile\nnetwork. A bimodal distribution of packet sizes was observed and modeled using\na dual Poisson function. In general, Wi-Fi connections provided greater\nstability for multimedia transfers, while LTE performance varied depending on\nplatform-specific implementations. The results contribute to a better\nunderstanding of traffic behavior in cloud-based storage applications and\nsuggest further analysis with larger datasets and heterogeneous access\nnetworks.",
    "published": "2025-10-29T01:26:29Z",
    "updated": "2025-10-29T01:26:29Z",
    "link": "http://arxiv.org/pdf/2510.25079v1.pdf",
    "category": [
      "cs.NI",
      "cs.MM"
    ],
    "authors": [
      "Albert Espinal",
      "V. Sanchez Padilla",
      "Yesenia Cevallos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25002v1",
    "title": "Resi-VidTok: An Efficient and Decomposed Progressive Tokenization\n  Framework for Ultra-Low-Rate and Lightweight Video Transmission",
    "summary": "Real-time transmission of video over wireless networks remains highly\nchallenging, even with advanced deep models, particularly under severe channel\nconditions such as limited bandwidth and weak connectivity. In this paper, we\npropose Resi-VidTok, a Resilient Tokenization-Enabled framework designed for\nultra-low-rate and lightweight video transmission that delivers strong\nrobustness while preserving perceptual and semantic fidelity on commodity\ndigital hardware. By reorganizing spatio--temporal content into a discrete,\nimportance-ordered token stream composed of key tokens and refinement tokens,\nResi-VidTok enables progressive encoding, prefix-decodable reconstruction, and\ngraceful quality degradation under constrained channels. A key contribution is\na resilient 1D tokenization pipeline for video that integrates differential\ntemporal token coding, explicitly supporting reliable recovery from incomplete\ntoken sets using a single shared framewise decoder--without auxiliary temporal\nextractors or heavy generative models. Furthermore, stride-controlled frame\nsparsification combined with a lightweight decoder-side interpolator reduces\ntransmission load while maintaining motion continuity. Finally, a\nchannel-adaptive source--channel coding and modulation scheme dynamically\nallocates rate and protection according to token importance and channel\ncondition, yielding stable quality across adverse SNRs. Evaluation results\nindicate robust visual and semantic consistency at channel bandwidth ratios\n(CBR) as low as 0.0004 and real-time reconstruction at over 30 fps,\ndemonstrating the practicality of Resi-VidTok for energy-efficient,\nlatency-sensitive, and reliability-critical wireless applications.",
    "published": "2025-10-28T22:02:36Z",
    "updated": "2025-10-28T22:02:36Z",
    "link": "http://arxiv.org/pdf/2510.25002v1.pdf",
    "category": [
      "cs.IT",
      "cs.CV",
      "cs.MM",
      "eess.IV",
      "math.IT"
    ],
    "authors": [
      "Zhenyu Liu",
      "Yi Ma",
      "Rahim Tafazolli",
      "Zhi Ding"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25660v1",
    "title": "mitransient: Transient light transport in Mitsuba 3",
    "summary": "mitransient is a light transport simulation tool that extends Mitsuba 3 with\nsupport for time-resolved simulations. In essence, mitransient extends\nconventional rendering by adding a temporal dimension which accounts for the\ntime of flight of light. This allows rapid prototyping of novel transient\nimaging systems without the need of costly or difficult-to-operate hardware.\nOur code is trivially easy to install through pip, and consists of Python\nmodules that can run both in CPU and GPU by leveraging the JIT capabilities of\nMitsuba 3. It provides physically-based simulations of complex phenomena,\nincluding a wide variety of realistic materials and participating media such as\nfog or smoke. In addition, we extend Mitsuba 3's functionality to support\ntime-resolved polarization tracking of light and transient differentiable\nrendering. Finally, we also include tools that simplify the use of our\nsimulations for non-line-of-sight imaging, enabling realistic scene setups with\ncapture noise to be simulated in just seconds of minutes. Altogether, we hope\nthat mitransient will support the research community in developing novel\nalgorithms for transient imaging.",
    "published": "2025-10-29T16:23:08Z",
    "updated": "2025-10-29T16:23:08Z",
    "link": "http://arxiv.org/pdf/2510.25660v1.pdf",
    "category": [
      "cs.GR",
      "I.3.6; I.3.7"
    ],
    "authors": [
      "Diego Royo",
      "Jorge Garcia-Pueyo",
      "Miguel Crespo",
      "Óscar Pueyo-Ciutad",
      "Guillermo Enguita",
      "Diego Bielsa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.13587v2",
    "title": "HRM^2Avatar: High-Fidelity Real-Time Mobile Avatars from Monocular Phone\n  Scans",
    "summary": "We present HRM$^2$Avatar, a framework for creating high-fidelity avatars from\nmonocular phone scans, which can be rendered and animated in real time on\nmobile devices. Monocular capture with smartphones provides a low-cost\nalternative to studio-grade multi-camera rigs, making avatar digitization\naccessible to non-expert users. Reconstructing high-fidelity avatars from\nsingle-view video sequences poses challenges due to limited visual and\ngeometric data. To address these limitations, at the data level, our method\nleverages two types of data captured with smartphones: static pose sequences\nfor texture reconstruction and dynamic motion sequences for learning\npose-dependent deformations and lighting changes. At the representation level,\nwe employ a lightweight yet expressive representation to reconstruct\nhigh-fidelity digital humans from sparse monocular data. We extract garment\nmeshes from monocular data to model clothing deformations effectively, and\nattach illumination-aware Gaussians to the mesh surface, enabling high-fidelity\nrendering and capturing pose-dependent lighting. This representation\nefficiently learns high-resolution and dynamic information from monocular data,\nenabling the creation of detailed avatars. At the rendering level, real-time\nperformance is critical for animating high-fidelity avatars in AR/VR, social\ngaming, and on-device creation. Our GPU-driven rendering pipeline delivers 120\nFPS on mobile devices and 90 FPS on standalone VR devices at 2K resolution,\nover $2.7\\times$ faster than representative mobile-engine baselines.\nExperiments show that HRM$^2$Avatar delivers superior visual realism and\nreal-time interactivity, outperforming state-of-the-art monocular methods.",
    "published": "2025-10-15T14:18:20Z",
    "updated": "2025-10-29T14:24:23Z",
    "link": "http://arxiv.org/pdf/2510.13587v2.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Chao Shi",
      "Shenghao Jia",
      "Jinhui Liu",
      "Yong Zhang",
      "Liangchao Zhu",
      "Zhonglei Yang",
      "Jinze Ma",
      "Chaoyue Niu",
      "Chengfei Lv"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25159v1",
    "title": "Fast and Robust Point Containment Queries on Trimmed Surface",
    "summary": "Point containment queries on trimmed surfaces are fundamental to CAD\nmodeling, solid geometry processing, and surface tessellation. Existing\napproaches such as ray casting and generalized winding numbers often face\nlimitations in robustness and computational efficiency.\n  We propose a fast and numerically stable method for performing containment\nqueries on trimmed surfaces, including those with periodic parameterizations.\nOur approach introduces a recursive winding number computation scheme that\nreplaces costly curve subdivision with an ellipse-based bound for Bezier\nsegments, enabling linear-time evaluation. For periodic surfaces, we lift\ntrimming curves to the universal covering space, allowing accurate and\nconsistent winding number computation even for non-contractible or\ndiscontinuous loops in parameter domain.\n  Experiments show that our method achieves substantial speedups over existing\nwinding-number algorithms while maintaining high robustness in the presence of\ngeometric noise, open boundaries, and periodic topologies. We further\ndemonstrate its effectiveness in processing real B-Rep models and in robust\ntessellation of trimmed surfaces.",
    "published": "2025-10-29T04:28:24Z",
    "updated": "2025-10-29T04:28:24Z",
    "link": "http://arxiv.org/pdf/2510.25159v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Anchang Bao",
      "Enya Shen",
      "Jianmin Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25152v1",
    "title": "Off-Centered WoS-Type Solvers with Statistical Weighting",
    "summary": "Stochastic PDE solvers have emerged as a powerful alternative to traditional\ndiscretization-based methods for solving partial differential equations (PDEs),\nespecially in geometry processing and graphics. While off-centered estimators\nenhance sample reuse in WoS-type Monte Carlo solvers, they introduce\ncorrelation artifacts and bias when Green's functions are approximated. In this\npaper, we propose a statistically weighted off-centered WoS-type estimator that\nleverages local similarity filtering to selectively combine samples across\nneighboring evaluation points. Our method balances bias and variance through a\nprincipled weighting strategy that suppresses unreliable estimators. We\ndemonstrate our approach's effectiveness on various PDEs,including screened\nPoisson equations and boundary conditions, achieving consistent improvements\nover existing solvers such as vanilla Walk on Spheres, mean value caching, and\nboundary value caching. Our method also naturally extends to gradient field\nestimation and mixed boundary problems.",
    "published": "2025-10-29T04:09:50Z",
    "updated": "2025-10-29T04:09:50Z",
    "link": "http://arxiv.org/pdf/2510.25152v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Anchang Bao",
      "Jie Xu",
      "Enya Shen",
      "Jianmin Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25768v1",
    "title": "STITCH 2.0: Extending Augmented Suturing with EKF Needle Estimation and\n  Thread Management",
    "summary": "Surgical suturing is a high-precision task that impacts patient healing and\nscarring. Suturing skill varies widely between surgeons, highlighting the need\nfor robot assistance. Previous robot suturing works, such as STITCH 1.0 [1],\nstruggle to fully close wounds due to inaccurate needle tracking and poor\nthread management. To address these challenges, we present STITCH 2.0, an\nelevated augmented dexterity pipeline with seven improvements including:\nimproved EKF needle pose estimation, new thread untangling methods, and an\nautomated 3D suture alignment algorithm. Experimental results over 15 trials\nfind that STITCH 2.0 on average achieves 74.4% wound closure with 4.87 sutures\nper trial, representing 66% more sutures in 38% less time compared to the\nprevious baseline. When two human interventions are allowed, STITCH 2.0\naverages six sutures with 100% wound closure rate. Project website:\nhttps://stitch-2.github.io/",
    "published": "2025-10-29T17:59:03Z",
    "updated": "2025-10-29T17:59:03Z",
    "link": "http://arxiv.org/pdf/2510.25768v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Kush Hari",
      "Ziyang Chen",
      "Hansoul Kim",
      "Ken Goldberg"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25754v1",
    "title": "GET-USE: Learning Generalized Tool Usage for Bimanual Mobile\n  Manipulation via Simulated Embodiment Extensions",
    "summary": "The ability to use random objects as tools in a generalizable manner is a\nmissing piece in robots' intelligence today to boost their versatility and\nproblem-solving capabilities. State-of-the-art robotic tool usage methods\nfocused on procedurally generating or crowd-sourcing datasets of tools for a\ntask to learn how to grasp and manipulate them for that task. However, these\nmethods assume that only one object is provided and that it is possible, with\nthe correct grasp, to perform the task; they are not capable of identifying,\ngrasping, and using the best object for a task when many are available,\nespecially when the optimal tool is absent. In this work, we propose GeT-USE, a\ntwo-step procedure that learns to perform real-robot generalized tool usage by\nlearning first to extend the robot's embodiment in simulation and then\ntransferring the learned strategies to real-robot visuomotor policies. Our key\ninsight is that by exploring a robot's embodiment extensions (i.e., building\nnew end-effectors) in simulation, the robot can identify the general tool\ngeometries most beneficial for a task. This learned geometric knowledge can\nthen be distilled to perform generalized tool usage tasks by selecting and\nusing the best available real-world object as tool. On a real robot with 22\ndegrees of freedom (DOFs), GeT-USE outperforms state-of-the-art methods by\n30-60% success rates across three vision-based bimanual mobile manipulation\ntool-usage tasks.",
    "published": "2025-10-29T17:52:32Z",
    "updated": "2025-10-29T17:52:32Z",
    "link": "http://arxiv.org/pdf/2510.25754v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Bohan Wu",
      "Paul de La Sayette",
      "Li Fei-Fei",
      "Roberto Martín-Martín"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25727v1",
    "title": "Modeling Collapse of Steered Vine Robots Under Their Own Weight",
    "summary": "Soft, vine-inspired growing robots that move by eversion are highly mobile in\nconfined environments, but, when faced with gaps in the environment, they may\ncollapse under their own weight while navigating a desired path. In this work,\nwe present a comprehensive collapse model that can predict the collapse length\nof steered robots in any shape using true shape information and tail tension.\nWe validate this model by collapsing several unsteered robots without true\nshape information. The model accurately predicts the trends of those\nexperiments. We then attempt to collapse a robot steered with a single actuator\nat different orientations. Our models accurately predict collapse when it\noccurs. Finally, we demonstrate how this could be used in the field by having a\nrobot attempt a gap-crossing task with and without inflating its actuators. The\nrobot needs its actuators inflated to cross the gap without collapsing, which\nour model supports. Our model has been specifically tested on straight and\nseries pouch motor-actuated robots made of non-stretchable material, but it\ncould be applied to other robot variations. This work enables us to model the\nrobot's collapse behavior in any open environment and understand the parameters\nit needs to succeed in 3D navigation tasks.",
    "published": "2025-10-29T17:33:16Z",
    "updated": "2025-10-29T17:33:16Z",
    "link": "http://arxiv.org/pdf/2510.25727v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Ciera McFarland",
      "Margaret McGuinness"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25713v1",
    "title": "Robotic Assistant: Completing Collaborative Tasks with Dexterous\n  Vision-Language-Action Models",
    "summary": "We adapt a pre-trained Vision-Language-Action (VLA) model (Open-VLA) for\ndexterous human-robot collaboration with minimal language prompting. Our\napproach adds (i) FiLM conditioning to visual backbones for task-aware\nperception, (ii) an auxiliary intent head that predicts collaborator hand pose\nand target cues, and (iii) action-space post-processing that predicts compact\ndeltas (position/rotation) and PCA-reduced finger joints before mapping to full\ncommands. Using a multi-view, teleoperated Franka and Mimic-hand dataset\naugmented with MediaPipe hand poses, we demonstrate that delta actions are\nwell-behaved and that four principal components explain ~96% of hand-joint\nvariance. Ablations identify action post-processing as the primary performance\ndriver; auxiliary intent helps, FiLM is mixed, and a directional motion loss is\ndetrimental. A real-time stack (~0.3 s latency on one RTX 4090) composes\n\"pick-up\" and \"pass\" into a long-horizon behavior. We surface \"trainer\noverfitting\" to specific demonstrators as the key limitation.",
    "published": "2025-10-29T17:22:59Z",
    "updated": "2025-10-29T17:22:59Z",
    "link": "http://arxiv.org/pdf/2510.25713v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Boshi An",
      "Chenyu Yang",
      "Robert Katzschmann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.16370v3",
    "title": "Dual-Regularized Riccati Recursions for Interior-Point Optimal Control",
    "summary": "We derive closed-form extensions of Riccati's recursions (both sequential and\nparallel) for solving dual-regularized LQR problems. We show how these methods\ncan be used to solve general constrained, non-convex, discrete-time optimal\ncontrol problems via a regularized interior point method, while guaranteeing\nthat each step is a descent direction of an Augmented Barrier-Lagrangian merit\nfunction. We provide MIT-licensed implementations of our methods in C++ and\nJAX.",
    "published": "2025-09-19T19:26:22Z",
    "updated": "2025-10-29T16:50:36Z",
    "link": "http://arxiv.org/pdf/2509.16370v3.pdf",
    "category": [
      "math.OC",
      "cs.MS",
      "cs.RO",
      "cs.SY",
      "eess.SY",
      "49M37, 90C51, 93B45",
      "G.1.6"
    ],
    "authors": [
      "João Sousa-Pinto",
      "Dominique Orban"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25650v1",
    "title": "Collision avoidance and path finding in a robotic mobile fulfillment\n  system using multi-objective meta-heuristics",
    "summary": "Multi-Agent Path Finding (MAPF) has gained significant attention, with most\nresearch focusing on minimizing collisions and travel time. This paper also\nconsiders energy consumption in the path planning of automated guided vehicles\n(AGVs). It addresses two main challenges: i) resolving collisions between AGVs\nand ii) assigning tasks to AGVs. We propose a new collision avoidance strategy\nthat takes both energy use and travel time into account. For task assignment,\nwe present two multi-objective algorithms: Non-Dominated Sorting Genetic\nAlgorithm (NSGA) and Adaptive Large Neighborhood Search (ALNS). Comparative\nevaluations show that these proposed methods perform better than existing\napproaches in both collision avoidance and task assignment.",
    "published": "2025-10-29T16:10:58Z",
    "updated": "2025-10-29T16:10:58Z",
    "link": "http://arxiv.org/pdf/2510.25650v1.pdf",
    "category": [
      "cs.RO",
      "math.OC"
    ],
    "authors": [
      "Ahmad Kokhahi",
      "Mary Kurz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25597v1",
    "title": "Incorporating Social Awareness into Control of Unknown Multi-Agent\n  Systems: A Real-Time Spatiotemporal Tubes Approach",
    "summary": "This paper presents a decentralized control framework that incorporates\nsocial awareness into multi-agent systems with unknown dynamics to achieve\nprescribed-time reach-avoid-stay tasks in dynamic environments. Each agent is\nassigned a social awareness index that quantifies its level of cooperation or\nself-interest, allowing heterogeneous social behaviors within the system.\nBuilding on the spatiotemporal tube (STT) framework, we propose a real-time STT\nframework that synthesizes tubes online for each agent while capturing its\nsocial interactions with others. A closed-form, approximation-free control law\nis derived to ensure that each agent remains within its evolving STT, thereby\navoiding dynamic obstacles while also preventing inter-agent collisions in a\nsocially aware manner, and reaching the target within a prescribed time. The\nproposed approach provides formal guarantees on safety and timing, and is\ncomputationally lightweight, model-free, and robust to unknown disturbances.\nThe effectiveness and scalability of the framework are validated through\nsimulation and hardware experiments on a 2D omnidirectional",
    "published": "2025-10-29T15:05:40Z",
    "updated": "2025-10-29T15:05:40Z",
    "link": "http://arxiv.org/pdf/2510.25597v1.pdf",
    "category": [
      "eess.SY",
      "cs.RO",
      "cs.SY"
    ],
    "authors": [
      "Siddhartha Upadhyay",
      "Ratnangshu Das",
      "Pushpak Jagtap"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25548v1",
    "title": "Using VLM Reasoning to Constrain Task and Motion Planning",
    "summary": "In task and motion planning, high-level task planning is done over an\nabstraction of the world to enable efficient search in long-horizon robotics\nproblems. However, the feasibility of these task-level plans relies on the\ndownward refinability of the abstraction into continuous motion. When a\ndomain's refinability is poor, task-level plans that appear valid may\nultimately fail during motion planning, requiring replanning and resulting in\nslower overall performance. Prior works mitigate this by encoding refinement\nissues as constraints to prune infeasible task plans. However, these approaches\nonly add constraints upon refinement failure, expending significant search\neffort on infeasible branches. We propose VIZ-COAST, a method of leveraging the\ncommon-sense spatial reasoning of large pretrained Vision-Language Models to\nidentify issues with downward refinement a priori, bypassing the need to fix\nthese failures during planning. Experiments on two challenging TAMP domains\nshow that our approach is able to extract plausible constraints from images and\ndomain descriptions, drastically reducing planning times and, in some cases,\neliminating downward refinement failures altogether, generalizing to a diverse\nrange of instances from the broader domain.",
    "published": "2025-10-29T14:12:45Z",
    "updated": "2025-10-29T14:12:45Z",
    "link": "http://arxiv.org/pdf/2510.25548v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Muyang Yan",
      "Miras Mengdibayev",
      "Ardon Floros",
      "Weihang Guo",
      "Lydia E. Kavraki",
      "Zachary Kingston"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25520v1",
    "title": "Octopus-like Reaching Motion: A Perspective Inspired by Whipping",
    "summary": "The stereotypical reaching motion of the octopus arm has drawn growing\nattention for its efficient control of a highly deformable body. Previous\nstudies suggest that its characteristic bend propagation may share underlying\nprinciples with the dynamics of a whip. This work investigates whether\nwhip-like passive dynamics in water can reproduce the kinematic features\nobserved in biological reaching and their similarities and differences.\nPlatform-based whipping tests were performed in water and air while\nsystematically varying material stiffness and driving speed. Image-based\nquantification revealed that the Ecoflex Gel 2 arm driven at 150 rpm (motor\nspeed) reproduced curvature propagation similar to that observed in octopus\nreaching. However, its bend-point velocity decreased monotonically rather than\nexhibiting the biological bell-shaped profile, confirming that the octopus\nreaching movement is not merely a passive whipping behavior. The absence of\npropagation in air further highlights the critical role of the surrounding\nmedium in forming octopus-like reaching motion. This study provides a new\nperspective for understand biological reaching movement, and offers a potential\nplatform for future hydrodynamic research.",
    "published": "2025-10-29T13:43:18Z",
    "updated": "2025-10-29T13:43:18Z",
    "link": "http://arxiv.org/pdf/2510.25520v1.pdf",
    "category": [
      "cs.RO",
      "physics.bio-ph"
    ],
    "authors": [
      "Shengyao Zhang",
      "Yiyuan Zhang",
      "Chenrui Zhang",
      "Yiming Li",
      "Wenci Xin",
      "Yuliang Liufu",
      "Hong Wei Ng",
      "Cecilia Laschi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25479v1",
    "title": "Combining Moving Mass Actuators and Manoeuvring Models for Underwater\n  Vehicles: A Lagrangian Approach",
    "summary": "In this paper, we present a Newton-Euler formulation of the equations of\nmotion for underwater vehicles with an interntal moving mass actuator.\nFurthermore, the moving mass dynamics are expressed as an extension to the\nmanoeuvring model for underwater vehicles, originally introduced by Fossen\n(1991). The influence of the moving mass is described in body-frame and\nincluded as states in both an additional kinematic equation and as part of the\ncoupled rigid-body kinetics of the underwater vehicle. The Coriolis-centripetal\neffects are derived from Kirchhoff's equations and the hydrostatics are derived\nusing first principals. The proposed Newton-Euler model is validated through\nsimulation and compared with the traditional Hamiltonian internal moving mass\nactuator formulation.",
    "published": "2025-10-29T13:03:06Z",
    "updated": "2025-10-29T13:03:06Z",
    "link": "http://arxiv.org/pdf/2510.25479v1.pdf",
    "category": [
      "cs.RO",
      "cs.SY",
      "eess.SY",
      "93C10 (Primary) 37N35, 93C95, 70B10, 70B15 (Secondary)",
      "I.6.3; I.6.4; I.6.5; J.2"
    ],
    "authors": [
      "Alexander B. Rambech",
      "Ivar B. Saksvik",
      "Vahid Hassani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25422v1",
    "title": "Solving the Right Problem with Multi-Robot Formations",
    "summary": "Formation control simplifies minimizing multi-robot cost functions by\nencoding a cost function as a shape the robots maintain. However, by reducing\ncomplex cost functions to formations, discrepancies arise between maintaining\nthe shape and minimizing the original cost function. For example, a Diamond or\nBox formation shape is often used for protecting all members of the formation.\nWhen more information about the surrounding environment becomes available, a\nstatic shape often no longer minimizes the original protection cost. We propose\na formation planner to reduce mismatch between a formation and the cost\nfunction while still leveraging efficient formation controllers. Our formation\nplanner is a two-step optimization problem that identifies desired relative\nrobot positions. We first solve a constrained problem to estimate non-linear\nand non-differentiable costs with a weighted sum of surrogate cost functions.\nWe theoretically analyze this problem and identify situations where weights do\nnot need to be updated. The weighted, surrogate cost function is then minimized\nusing relative positions between robots. The desired relative positions are\nrealized using a non-cooperative formation controller derived from Lyapunov's\ndirect approach. We then demonstrate the efficacy of this approach for\nmilitary-like costs such as protection and obstacle avoidance. In simulations,\nwe show a formation planner can reduce a single cost by over 75%. When\nminimizing a variety of cost functions simultaneously, using a formation\nplanner with adaptive weights can reduce the cost by 20-40%. Formation planning\nprovides better performance by minimizing a surrogate cost function that\nclosely approximates the original cost function instead of relying on a shape\nabstraction.",
    "published": "2025-10-29T11:42:19Z",
    "updated": "2025-10-29T11:42:19Z",
    "link": "http://arxiv.org/pdf/2510.25422v1.pdf",
    "category": [
      "cs.RO",
      "cs.MA"
    ],
    "authors": [
      "Chaz Cornwall",
      "Jeremy P. Bos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25405v1",
    "title": "Sim-to-Real Gentle Manipulation of Deformable and Fragile Objects with\n  Stress-Guided Reinforcement Learning",
    "summary": "Robotic manipulation of deformable and fragile objects presents significant\nchallenges, as excessive stress can lead to irreversible damage to the object.\nWhile existing solutions rely on accurate object models or specialized sensors\nand grippers, this adds complexity and often lacks generalization. To address\nthis problem, we present a vision-based reinforcement learning approach that\nincorporates a stress-penalized reward to discourage damage to the object\nexplicitly. In addition, to bootstrap learning, we incorporate offline\ndemonstrations as well as a designed curriculum progressing from rigid proxies\nto deformables. We evaluate the proposed method in both simulated and\nreal-world scenarios, showing that the policy learned in simulation can be\ntransferred to the real world in a zero-shot manner, performing tasks such as\npicking up and pushing tofu. Our results show that the learned policies exhibit\na damage-aware, gentle manipulation behavior, demonstrating their effectiveness\nby decreasing the stress applied to fragile objects by 36.5% while achieving\nthe task goals, compared to vanilla RL policies.",
    "published": "2025-10-29T11:23:41Z",
    "updated": "2025-10-29T11:23:41Z",
    "link": "http://arxiv.org/pdf/2510.25405v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Kei Ikemura",
      "Yifei Dong",
      "David Blanco-Mulero",
      "Alberta Longhini",
      "Li Chen",
      "Florian T. Pokorny"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25338v1",
    "title": "Geometric Robot Calibration Using a Calibration Plate",
    "summary": "In this paper a new method for geometric robot calibration is introduced,\nwhich uses a calibration plate with precisely known distances between its\nmeasuring points. The relative measurement between two points on the\ncalibration plate is used to determine predefined error parameters of the\nsystem. In comparison to conventional measurement methods, like laser tracker\nor motion capture systems, the calibration plate provides a more mechanically\nrobust and cheaper alternative, which is furthermore easier to transport due to\nits small size. The calibration method, the plate design, the mathematical\ndescription of the error system as well as the identification of the parameters\nare described in detail. For identifying the error parameters, the least\nsquares method and a constrained optimization problem are used. The\nfunctionality of this method was demonstrated in experiments that led to\npromising results, correlated with one of a laser tracker calibration. The\nmodeling and identification of the error parameters is done for a gantry\nmachine, but is not restricted to that type of robot.",
    "published": "2025-10-29T09:52:40Z",
    "updated": "2025-10-29T09:52:40Z",
    "link": "http://arxiv.org/pdf/2510.25338v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Bernhard Rameder",
      "Hubert Gattringer",
      "Andreas Mueller"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25335v1",
    "title": "An approach for combining transparency and motion assistance of a lower\n  body exoskeleton",
    "summary": "In this paper, an approach for gait assistance with a lower body exoskeleton\nis described. Two concepts, transparency and motion assistance, are combined.\nThe transparent mode, where the system is following the user's free motion with\na minimum of perceived interaction forces, is realized by exploiting the gear\nbacklash of the actuation units. During walking a superimposed assistance mode\napplies an additional torque guiding the legs to their estimated future\nposition. The concept of adaptive oscillators is utilized to learn the\nquasi-periodic signals typical for locomotion. First experiments showed\npromising results.",
    "published": "2025-10-29T09:49:21Z",
    "updated": "2025-10-29T09:49:21Z",
    "link": "http://arxiv.org/pdf/2510.25335v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Jakob Ziegler",
      "Bernhard Rameder",
      "Hubert Gattringer",
      "Andreas Mueller"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25314v1",
    "title": "Seeing Clearly and Deeply: An RGBD Imaging Approach with a Bio-inspired\n  Monocentric Design",
    "summary": "Achieving high-fidelity, compact RGBD imaging presents a dual challenge:\nconventional compact optics struggle with RGB sharpness across the entire\ndepth-of-field, while software-only Monocular Depth Estimation (MDE) is an\nill-posed problem reliant on unreliable semantic priors. While deep optics with\nelements like DOEs can encode depth, they introduce trade-offs in fabrication\ncomplexity and chromatic aberrations, compromising simplicity. To address this,\nwe first introduce a novel bio-inspired all-spherical monocentric lens, around\nwhich we build the Bionic Monocentric Imaging (BMI) framework, a holistic\nco-design. This optical design naturally encodes depth into its depth-varying\nPoint Spread Functions (PSFs) without requiring complex diffractive or freeform\nelements. We establish a rigorous physically-based forward model to generate a\nsynthetic dataset by precisely simulating the optical degradation process. This\nsimulation pipeline is co-designed with a dual-head, multi-scale reconstruction\nnetwork that employs a shared encoder to jointly recover a high-fidelity\nAll-in-Focus (AiF) image and a precise depth map from a single coded capture.\nExtensive experiments validate the state-of-the-art performance of the proposed\nframework. In depth estimation, the method attains an Abs Rel of 0.026 and an\nRMSE of 0.130, markedly outperforming leading software-only approaches and\nother deep optics systems. For image restoration, the system achieves an SSIM\nof 0.960 and a perceptual LPIPS score of 0.082, thereby confirming a superior\nbalance between image fidelity and depth accuracy. This study illustrates that\nthe integration of bio-inspired, fully spherical optics with a joint\nreconstruction algorithm constitutes an effective strategy for addressing the\nintrinsic challenges in high-performance compact RGBD imaging. Source code will\nbe publicly available at https://github.com/ZongxiYu-ZJU/BMI.",
    "published": "2025-10-29T09:27:38Z",
    "updated": "2025-10-29T09:27:38Z",
    "link": "http://arxiv.org/pdf/2510.25314v1.pdf",
    "category": [
      "cs.CV",
      "cs.RO",
      "eess.IV",
      "physics.optics"
    ],
    "authors": [
      "Zongxi Yu",
      "Xiaolong Qian",
      "Shaohua Gao",
      "Qi Jiang",
      "Yao Gao",
      "Kailun Yang",
      "Kaiwei Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25280v1",
    "title": "Development of Implicit-Explicit Control Based Amphibious Centipede-Type\n  Robot and Evaluation of its Mobile Performance",
    "summary": "Multi-legged mobile robots possess high mobility performance in rough terrain\nenvironments, stemming from their high postural stability, joint flexibility,\nand the redundancy provided by multiple legs. In prior research on navigating\nbetween different environments such as land and water, the primary strategy\nemployed involves switching to a controller that generates an appropriate gait\nfor the new environment upon entering it. However, designing appropriate gaits\nfor each complex and diverse environment and accurately determining controller\nswitching for each environment is challenging. Therefore, this research\ndevelops a centipede-type mobile robot that navigates both aquatic and\nterrestrial environments with a simple, unified control scheme, based on the\nimplicit-explicit control philosophy and by ingeniously designing the robot's\nbody structure. In this research, we developed the robot featuring flexible\njoints and left and right legs on each body segment and focused on the leg\nstructure which has extensive contact with the environment. This paper\nevaluates the locomotion performance on land and water using the three\ndeveloped leg structures, using the robot's leg slip rate and actuator energy\nconsumption as evaluation metrics. The experimental results confirmed the\nexistence of an appropriate leg structure capable of navigating both aquatic\nand terrestrial environments under identical control.",
    "published": "2025-10-29T08:38:05Z",
    "updated": "2025-10-29T08:38:05Z",
    "link": "http://arxiv.org/pdf/2510.25280v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Yusuke Tsunoda",
      "Seiya Yamamoto",
      "Kazuki Ito",
      "Runze Xiao",
      "Keisuke Naniwa",
      "Koichi Osuka"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25255v1",
    "title": "Time-Optimal Transport of Loosely Placed Liquid Filled Cups along\n  Prescribed Paths",
    "summary": "Handling loosely placed objects with robotic manipulators is a difficult task\nfrom the point of view of trajectory planning and control. This becomes even\nmore challenging when the object to be handled is a container filled with\nliquid. This paper addresses the task of transporting a liquid-filled cup\nplaced on a tray along a prescribed path in shortest time. The objective is to\nminimize swapping, thus avoiding spillage of the fluid. To this end, the\nsloshing dynamics is incorporated into the dynamic model used within the\noptimal control problem formulation. The optimization problem is solved using a\ndirect multiple shooting approach.",
    "published": "2025-10-29T08:09:32Z",
    "updated": "2025-10-29T08:09:32Z",
    "link": "http://arxiv.org/pdf/2510.25255v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Klaus Zauner",
      "Hubert Gattringer",
      "Andreas Mueller"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2409.02635v3",
    "title": "Optimal Kinematic Synthesis and Prototype Development of Knee\n  Exoskeleton",
    "summary": "The range of rotation (RoR) in a knee exoskeleton is a critical factor in\nrehabilitation, as it directly influences joint mobility, muscle activation,\nand recovery outcomes. A well-designed RoR ensures that patients achieve\nnear-natural knee kinematics, which is essential for restoring gait patterns\nand preventing compensatory movements. This paper presents optimal design of\none degree of freedom knee exoskeleton. In kinematic analysis, the existing\ndesign being represented by nonlinear and nonconvex mathematical functions. To\nobtain feasible and optimum measurement of the links of knee exoskeleton, an\noptimization problem is formulated based on the kinematic analysis and average\nhuman's leg measurement. The optimized solution increases the range of motion\nof knee exoskeleton during sit to stand motion by $24 \\%$ as compared with\ninspired design. Furthermore, misalignment study is conducted by comparing the\ntrajectory of human's knee and exoskeleton's knee during sit to stand motion.\nThe joint movement is calculated using marker and camera system. Finally, a\nprototype of the knee joint exoskeleton is being developed based on optimal\ndimensions which validate the maximum range of motion achieved during\nsimulation.",
    "published": "2024-09-04T11:58:52Z",
    "updated": "2025-10-29T07:39:26Z",
    "link": "http://arxiv.org/pdf/2409.02635v3.pdf",
    "category": [
      "cs.RO",
      "math.OC"
    ],
    "authors": [
      "Shashank Mani Gautam",
      "Ekta Singla",
      "Ashish Singla"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25233v1",
    "title": "Hybrid Vision Servoing with Depp Alignment and GRU-Based Occlusion\n  Recovery",
    "summary": "Vision-based control systems, such as image-based visual servoing (IBVS),\nhave been extensively explored for precise robot manipulation. A persistent\nchallenge, however, is maintaining robust target tracking under partial or full\nocclusions. Classical methods like Lucas-Kanade (LK) offer lightweight tracking\nbut are fragile to occlusion and drift, while deep learning-based approaches\noften require continuous visibility and intensive computation. To address these\ngaps, we propose a hybrid visual tracking framework that bridges advanced\nperception with real-time servo control. First, a fast global template matcher\nconstrains the pose search region; next, a deep-feature Lucas-Kanade module\noperating on early VGG layers refines alignment to sub-pixel accuracy (<2px);\nthen, a lightweight residual regressor corrects local misalignments caused by\ntexture degradation or partial occlusion. When visual confidence falls below a\nthreshold, a GRU-based predictor seamlessly extrapolates pose updates from\nrecent motion history. Crucially, the pipeline's final outputs-translation,\nrotation, and scale deltas-are packaged as direct control signals for 30Hz\nimage-based servo loops. Evaluated on handheld video sequences with up to 90%\nocclusion, our system sustains under 2px tracking error, demonstrating the\nrobustness and low-latency precision essential for reliable real-world robot\nvision applications.",
    "published": "2025-10-29T07:28:32Z",
    "updated": "2025-10-29T07:28:32Z",
    "link": "http://arxiv.org/pdf/2510.25233v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Jee Won Lee",
      "Hansol Lim",
      "Sooyeun Yang",
      "Jongseong Brad Choi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2304.08772v4",
    "title": "Multi-robot Motion Planning based on Nets-within-Nets Modeling and\n  Simulation",
    "summary": "This paper focuses on designing motion plans for a heterogeneous team of\nrobots that must cooperate to fulfill a global mission. Robots move in an\nenvironment that contains some regions of interest, while the specification for\nthe entire team can include avoidance, visits, or sequencing of these regions\nof interest. The mission is expressed in terms of a Petri net corresponding to\nan automaton, while each robot is also modeled by a state machine Petri net.\nThe current work brings about the following contributions with respect to\nexisting solutions for related problems. First, we propose a novel model,\ndenoted High-Level robot team Petri Net (HLrtPN) system, to incorporate the\nspecification and robot models into the Nets-within-Nets paradigm. A guard\nfunction, named Global Enabling Function, is designed to synchronize the firing\nof transitions so that robot motions do not violate the specification. Then,\nthe solution is found by simulating the HLrtPN system in a specific software\ntool that accommodates Nets-within-Nets. Illustrative examples based on Linear\nTemporal Logic missions support the computational feasibility of the proposed\nframework.",
    "published": "2023-04-18T07:06:07Z",
    "updated": "2025-10-29T06:28:57Z",
    "link": "http://arxiv.org/pdf/2304.08772v4.pdf",
    "category": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "authors": [
      "Sofia Hustiu",
      "Joaquin Ezpeleta",
      "Cristian Mahulea",
      "Marius Kloetzer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25211v1",
    "title": "RoadSens-4M: A Multimodal Smartphone & Camera Dataset for Holistic\n  Road-way Analysis",
    "summary": "It's important to monitor road issues such as bumps and potholes to enhance\nsafety and improve road conditions. Smartphones are equipped with various\nbuilt-in sensors that offer a cost-effective and straightforward way to assess\nroad quality. However, progress in this area has been slow due to the lack of\nhigh-quality, standardized datasets. This paper discusses a new dataset created\nby a mobile app that collects sensor data from devices like GPS,\naccelerometers, gyroscopes, magnetometers, gravity sensors, and orientation\nsensors. This dataset is one of the few that integrates Geographic Information\nSystem (GIS) data with weather information and video footage of road\nconditions, providing a comprehensive understanding of road issues with\ngeographic context. The dataset allows for a clearer analysis of road\nconditions by compiling essential data, including vehicle speed, acceleration,\nrotation rates, and magnetic field intensity, along with the visual and spatial\ncontext provided by GIS, weather, and video data. Its goal is to provide\nfunding for initiatives that enhance traffic management, infrastructure\ndevelopment, road safety, and urban planning. Additionally, the dataset will be\npublicly accessible to promote further research and innovation in smart\ntransportation systems.",
    "published": "2025-10-29T06:23:12Z",
    "updated": "2025-10-29T06:23:12Z",
    "link": "http://arxiv.org/pdf/2510.25211v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Amith Khandakar",
      "David Michelson",
      "Shaikh Golam Rabbani",
      "Fariya Bintay Shafi",
      "Md. Faysal Ahamed",
      "Khondokar Radwanur Rahman",
      "Md Abidur Rahman",
      "Md. Fahmidun Nabi",
      "Mohamed Arselene Ayari",
      "Khaled Khan",
      "Ponnuthurai Nagaratnam Suganthan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25191v1",
    "title": "SoraNav: Adaptive UAV Task-Centric Navigation via Zeroshot VLM Reasoning",
    "summary": "Interpreting visual observations and natural language instructions for\ncomplex task execution remains a key challenge in robotics and AI. Despite\nrecent advances, language-driven navigation is still difficult, particularly\nfor UAVs in small-scale 3D environments. Existing Vision-Language Navigation\n(VLN) approaches are mostly designed for ground robots and struggle to\ngeneralize to aerial tasks that require full 3D spatial reasoning. The\nemergence of large Vision-Language Models (VLMs), such as GPT and Claude,\nenables zero-shot semantic reasoning from visual and textual inputs. However,\nthese models lack spatial grounding and are not directly applicable to\nnavigation. To address these limitations, SoraNav is introduced, an adaptive\nUAV navigation framework that integrates zero-shot VLM reasoning with\ngeometry-aware decision-making. Geometric priors are incorporated into image\nannotations to constrain the VLM action space and improve decision quality. A\nhybrid switching strategy leverages navigation history to alternate between VLM\nreasoning and geometry-based exploration, mitigating dead-ends and redundant\nrevisits. A PX4-based hardware-software platform, comprising both a digital\ntwin and a physical micro-UAV, enables reproducible evaluation. Experimental\nresults show that in 2.5D scenarios, our method improves Success Rate (SR) by\n25.7% and Success weighted by Path Length (SPL) by 17%. In 3D scenarios, it\nimproves SR by 29.5% and SPL by 18.5% relative to the baseline.",
    "published": "2025-10-29T05:46:29Z",
    "updated": "2025-10-29T05:46:29Z",
    "link": "http://arxiv.org/pdf/2510.25191v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Hongyu Song",
      "Rishabh Dev Yadav",
      "Cheng Guo",
      "Wei Pan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.13654v2",
    "title": "Control Modes of Teleoperated Surgical Robotic System's Tools in\n  Ophthalmic Surgery",
    "summary": "The introduction of a teleoperated surgical robotic system designed for\nminimally invasive procedures enables the emulation of two distinct control\nmodes through a dedicated input device of the surgical console: (1) Inside\nControl Mode, which emulates tool manipulation near the distal end as if the\nsurgeon was holding the tip of the instrument inside the patient's body; (2)\nOutside Control Mode, which emulates manipulation near the proximal end as if\nthe surgeon was holding the tool externally. The aim of this research is to\ncompare the surgeon's performance on these two modes of operation along with\nvarious scaling factors in a simulated vitreoretinal surgical setting. The\nconsole of Intraocular Robotic Interventional Surgical System (IRISS) was\nutilized but the surgical robot itself and the human eye anatomy was simulated\nby a virtual environment projected microscope view of an intraocular setup to a\nVR headset. Five experienced vitreoretinal surgeons and five subjects with no\nsurgical experience used the system to perform four fundamental tool/tissue\ntasks common to vitreoretinal surgery: touch and reset; grasp and drop; inject;\ncircular tracking. Results indicate that Inside Control outperforms Outside\nControl across multiple tasks and metrics. Higher scaling factors generally\nperformed better, particularly for reducing trajectory errors and tissue\ndamage. This improvement suggests that larger scaling factors enable more\nprecise control, making them the preferred option for fine manipulation.\nHowever, completion time was not consistently reduced across all conditions,\nindicating that surgeons need to balance speed and accuracy based on surgical\nrequirements. By optimizing control dynamics and user interface, robotic\nteleoperation has the potential to reduce complications, enhance dexterity, and\nexpand the accessibility of high precision procedures to a broader range of\npractitioners.",
    "published": "2025-07-18T04:48:46Z",
    "updated": "2025-10-29T03:44:09Z",
    "link": "http://arxiv.org/pdf/2507.13654v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Haoran Wang",
      "Yasamin Foroutani",
      "Matthew Nepo",
      "Mercedes Rodriguez",
      "Ji Ma",
      "Jean-Pierre Hubschman",
      "Tsu-Chin Tsao",
      "Jacob Rosen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.06677v2",
    "title": "RoboCerebra: A Large-scale Benchmark for Long-horizon Robotic\n  Manipulation Evaluation",
    "summary": "Recent advances in vision-language models (VLMs) have enabled\ninstruction-conditioned robotic systems with improved generalization. However,\nmost existing work focuses on reactive System 1 policies, underutilizing VLMs'\nstrengths in semantic reasoning and long-horizon planning. These System 2\ncapabilities-characterized by deliberative, goal-directed thinking-remain under\nexplored due to the limited temporal scale and structural complexity of current\nbenchmarks. To address this gap, we introduce RoboCerebra, a benchmark for\nevaluating high-level reasoning in long-horizon robotic manipulation.\nRoboCerebra includes: (1) a large-scale simulation dataset with extended task\nhorizons and diverse subtask sequences in household environments; (2) a\nhierarchical framework combining a high-level VLM planner with a low-level\nvision-language-action (VLA) controller; and (3) an evaluation protocol\ntargeting planning, reflection, and memory through structured System 1-System 2\ninteraction. The dataset is constructed via a top-down pipeline, where GPT\ngenerates task instructions and decomposes them into subtask sequences. Human\noperators execute the subtasks in simulation, yielding high-quality\ntrajectories with dynamic object variations. Compared to prior benchmarks,\nRoboCerebra features significantly longer action sequences and denser\nannotations. We further benchmark state-of-the-art VLMs as System 2 modules and\nanalyze their performance across key cognitive dimensions, advancing the\ndevelopment of more capable and generalizable robotic planners.",
    "published": "2025-06-07T06:15:49Z",
    "updated": "2025-10-29T03:38:36Z",
    "link": "http://arxiv.org/pdf/2506.06677v2.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Songhao Han",
      "Boxiang Qiu",
      "Yue Liao",
      "Siyuan Huang",
      "Chen Gao",
      "Shuicheng Yan",
      "Si Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25138v1",
    "title": "Learning Spatial-Aware Manipulation Ordering",
    "summary": "Manipulation in cluttered environments is challenging due to spatial\ndependencies among objects, where an improper manipulation order can cause\ncollisions or blocked access. Existing approaches often overlook these spatial\nrelationships, limiting their flexibility and scalability. To address these\nlimitations, we propose OrderMind, a unified spatial-aware manipulation\nordering framework that directly learns object manipulation priorities based on\nspatial context. Our architecture integrates a spatial context encoder with a\ntemporal priority structuring module. We construct a spatial graph using\nk-Nearest Neighbors to aggregate geometric information from the local layout\nand encode both object-object and object-manipulator interactions to support\naccurate manipulation ordering in real-time. To generate physically and\nsemantically plausible supervision signals, we introduce a spatial prior\nlabeling method that guides a vision-language model to produce reasonable\nmanipulation orders for distillation. We evaluate OrderMind on our Manipulation\nOrdering Benchmark, comprising 163,222 samples of varying difficulty. Extensive\nexperiments in both simulation and real-world environments demonstrate that our\nmethod significantly outperforms prior approaches in effectiveness and\nefficiency, enabling robust manipulation in cluttered scenes.",
    "published": "2025-10-29T03:32:47Z",
    "updated": "2025-10-29T03:32:47Z",
    "link": "http://arxiv.org/pdf/2510.25138v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Yuxiang Yan",
      "Zhiyuan Zhou",
      "Xin Gao",
      "Guanghao Li",
      "Shenglin Li",
      "Jiaqi Chen",
      "Qunyan Pu",
      "Jian Pu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25122v1",
    "title": "NanoVLA: Routing Decoupled Vision-Language Understanding for Nano-sized\n  Generalist Robotic Policies",
    "summary": "Vision-language-action (VLA) models have significantly advanced robotic\nmanipulation by integrating vision-language models (VLMs), and action decoders\ninto a unified architecture. However, their deployment on resource-constrained\nedge devices, such as mobile robots or embedded systems (e.g., Jetson Orin\nNano), remains challenging due to high computational demands, especially in\nreal-world scenarios where power, latency, and computational resources are\ncritical. To close this gap, we introduce Nano-scale Vision-Language Action\n(NanoVLA), a family of lightweight VLA architectures that achieve high\nperformance with minimal resources. Our core innovations include: (1)\nvision-language decoupling that moves conventional early vision and language\ninputs fusion in VLM to late stage, achieving better performance while enabling\ncaching and reduce inference overhead and latency; (2) long-short action\nchunking to ensure smooth, coherent multi-step planning without sacrificing\nreal-time responsiveness; (3) dynamic routing that adaptively assigns\nlightweight or heavy backbones based on task complexity, further optimizing\ninference efficiency. Experimental results on several benchmarks, as well as\nreal-world deployments, demonstrate that NanoVLA achieves up to 52x faster\ninference on edge devices compared to previous state-of-the-art VLA models,\nwith 98% less parameters while maintaining or surpassing their task accuracy\nand generalization. Ablation studies confirm that our decoupling strategy\npreserves cross-task transferability, and the routing module enhances\ncost-performance trade-offs, enabling practical, high-precision robotic\nmanipulation on resource-constrained hardware.",
    "published": "2025-10-29T03:00:36Z",
    "updated": "2025-10-29T03:00:36Z",
    "link": "http://arxiv.org/pdf/2510.25122v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Jiahong Chen",
      "Jing Wang",
      "Long Chen",
      "Chuwei Cai",
      "Jinghui Lu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25086v1",
    "title": "Mean-Shift Theory and Its Applications in Swarm Robotics: A New Way to\n  Enhance the Efficiency of Multi-Robot Collaboration",
    "summary": "Swarms evolving from collective behaviors among multiple individuals are\ncommonly seen in nature, which enables biological systems to exhibit more\nefficient and robust collaboration. Creating similar swarm intelligence in\nengineered robots poses challenges to the design of collaborative algorithms\nthat can be programmed at large scales. The assignment-based method has played\nan eminent role for a very long time in solving collaboration problems of robot\nswarms. However, it faces fundamental limitations in terms of efficiency and\nrobustness due to its unscalability to swarm variants. This article presents a\ntutorial review on recent advances in assignment-free collaboration of robot\nswarms, focusing on the problem of shape formation. A key theoretical component\nis the recently developed \\emph{mean-shift exploration} strategy, which\nimproves the collaboration efficiency of large-scale swarms by dozens of times.\nFurther, the efficiency improvement is more significant as the swarm scale\nincreases. Finally, this article discusses three important applications of the\nmean-shift exploration strategy, including precise shape formation, area\ncoverage formation, and maneuvering formation, as well as their corresponding\nindustrial scenarios in smart warehousing, area exploration, and cargo\ntransportation.",
    "published": "2025-10-29T01:49:54Z",
    "updated": "2025-10-29T01:49:54Z",
    "link": "http://arxiv.org/pdf/2510.25086v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Guibin Sun",
      "Jinhu Lü",
      "Kexin Liu",
      "Zhenqian Wang",
      "Guanrong Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.08841v2",
    "title": "ES-HPC-MPC: Exponentially Stable Hybrid Perception Constrained MPC for\n  Quadrotor with Suspended Payloads",
    "summary": "Aerial transportation using quadrotors with cable-suspended payloads holds\ngreat potential for applications in disaster response, logistics, and\ninfrastructure maintenance. However, their hybrid and underactuated dynamics\npose significant control and perception challenges. Traditional approaches\noften assume a taut cable condition, limiting their effectiveness in real-world\napplications where slack-to-taut transitions occur due to disturbances. We\nintroduce ES-HPC-MPC, a model predictive control framework that enforces\nexponential stability and perception-constrained control under hybrid dynamics.\n  Our method leverages Exponentially Stabilizing Control Lyapunov Functions\n(ES-CLFs) to enforce stability during the tasks and Control Barrier Functions\n(CBFs) to maintain the payload within the onboard camera's field of view (FoV).\nWe validate our method through both simulation and real-world experiments,\ndemonstrating stable trajectory tracking and reliable payload perception. We\nvalidate that our method maintains stability and satisfies perception\nconstraints while tracking dynamically infeasible trajectories and when the\nsystem is subjected to hybrid mode transitions caused by unexpected\ndisturbances.",
    "published": "2025-04-10T19:43:00Z",
    "updated": "2025-10-29T01:48:17Z",
    "link": "http://arxiv.org/pdf/2504.08841v2.pdf",
    "category": [
      "eess.SY",
      "cs.RO",
      "cs.SY"
    ],
    "authors": [
      "Luis F. Recalde",
      "Mrunal Sarvaiya",
      "Giuseppe Loianno",
      "Guanrui Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25072v1",
    "title": "Non-Invasive Calibration Of A Stewart Platform By Photogrammetry",
    "summary": "Accurate calibration of a Stewart platform is important for their precise and\nefficient operation. However, the calibration of these platforms using forward\nkinematics is a challenge for researchers because forward kinematics normally\ngenerates multiple feasible and unfeasible solutions for any pose of the moving\nplatform. The complex kinematic relations among the six actuator paths\nconnecting the fixed base to the moving platform further compound the\ndifficulty in establishing a straightforward and efficient calibration method.\nThe authors developed a new forward kinematics-based calibration method using\nDenavit-Hartenberg convention and used the Stewart platform Tiger 66.1\ndeveloped in their lab for experimenting with the photogrammetry-based\ncalibration strategies described in this paper. This system became operational\nupon completion of construction, marking its inaugural use. The authors used\ntheir calibration model for estimating the errors in the system and adopted\nthree compensation options or strategies as per Least Square method to improve\nthe accuracy of the system. These strategies leveraged a high-resolution\ndigital camera and off-the-shelf software to capture the poses of the moving\nplatform's center. This process is non-invasive and does not need any\nadditional equipment to be attached to the hexapod or any alteration of the\nhexapod hardware. This photogrammetry-based calibration process involves\nmultiple high-resolution images from different angles to measure the position\nand orientation of the platform center in the three-dimensional space. The\nTarget poses and Actual poses are then compared, and the error compensations\nare estimated using the Least-Squared methods to calculate the Predicted poses.\nResults from each of the three compensation approaches demonstrated noticeable\nenhancements in platform pose accuracies, suggesting room for further\nimprovements.",
    "published": "2025-10-29T01:17:48Z",
    "updated": "2025-10-29T01:17:48Z",
    "link": "http://arxiv.org/pdf/2510.25072v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Sourabh Karmakar",
      "Cameron J. Turner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24994v1",
    "title": "Defect Mitigation for Robot Arm-based Additive Manufacturing Utilizing\n  Intelligent Control and IOT",
    "summary": "This paper presents an integrated robotic fused deposition modeling additive\nmanufacturing system featuring closed-loop thermal control and intelligent\nin-situ defect correction using a 6-degree of freedom robotic arm and an Oak-D\ncamera. The robot arm end effector was modified to mount an E3D hotend\nthermally regulated by an IoT microcontroller, enabling precise temperature\ncontrol through real-time feedback. Filament extrusion system was synchronized\nwith robotic motion, coordinated via ROS2, ensuring consistent deposition along\ncomplex trajectories. A vision system based on OpenCV detects layer-wise\ndefects position, commanding autonomous re-extrusion at identified sites.\nExperimental validation demonstrated successful defect mitigation in printing\noperations. The integrated system effectively addresses challenges real-time\nquality assurance. Inverse kinematics were used for motion planning, while\nhomography transformations corrected camera perspectives for accurate defect\nlocalization. The intelligent system successfully mitigated surface anomalies\nwithout interrupting the print process. By combining real-time thermal\nregulation, motion control, and intelligent defect detection & correction, this\narchitecture establishes a scalable and adaptive robotic additive manufacturing\nframework suitable for aerospace, biomedical, and industrial applications.",
    "published": "2025-10-28T21:48:00Z",
    "updated": "2025-10-28T21:48:00Z",
    "link": "http://arxiv.org/pdf/2510.24994v1.pdf",
    "category": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "authors": [
      "Matsive Ali",
      "Blake Gassen",
      "Sen Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24972v1",
    "title": "Smooth path planning with safety margins using Piece-Wise Bezier curves",
    "summary": "In this paper, we propose a computationally efficient quadratic programming\n(QP) approach for generating smooth, $C^1$ continuous paths for mobile robots\nusing piece-wise quadratic Bezier (PWB) curves. Our method explicitly\nincorporates safety margins within a structured optimization framework,\nbalancing trajectory smoothness and robustness with manageable numerical\ncomplexity suitable for real-time and embedded applications. Comparative\nsimulations demonstrate clear advantages over traditional piece-wise linear\n(PWL) path planning methods, showing reduced trajectory deviations, enhanced\nrobustness, and improved overall path quality. These benefits are validated\nthrough simulations using a Pure-Pursuit controller in representative\nscenarios, highlighting the practical effectiveness and scalability of our\napproach for safe navigation.",
    "published": "2025-10-28T21:12:54Z",
    "updated": "2025-10-28T21:12:54Z",
    "link": "http://arxiv.org/pdf/2510.24972v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Iancu Andrei",
      "Marius Kloetzer",
      "Cristian Mahulea",
      "Catalin Dosoftei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.10961v2",
    "title": "EquiContact: A Hierarchical SE(3) Vision-to-Force Equivariant Policy for\n  Spatially Generalizable Contact-rich Tasks",
    "summary": "This paper presents a framework for learning vision-based robotic policies\nfor contact-rich manipulation tasks that generalize spatially across task\nconfigurations. We focus on achieving robust spatial generalization of the\npolicy for the peg-in-hole (PiH) task trained from a small number of\ndemonstrations. We propose EquiContact, a hierarchical policy composed of a\nhigh-level vision planner (Diffusion Equivariant Descriptor Field, Diff-EDF)\nand a novel low-level compliant visuomotor policy (Geometric Compliant ACT,\nG-CompACT). G-CompACT operates using only localized observations (geometrically\nconsistent error vectors (GCEV), force-torque readings, and wrist-mounted RGB\nimages) and produces actions defined in the end-effector frame. Through these\ndesign choices, we show that the entire EquiContact pipeline is\nSE(3)-equivariant, from perception to force control. We also outline three key\ncomponents for spatially generalizable contact-rich policies: compliance,\nlocalized policies, and induced equivariance. Real-world experiments on PiH,\nscrewing, and surface wiping tasks demonstrate a near-perfect success rate and\nrobust generalization to unseen spatial configurations, validating the proposed\nframework and principles. The experimental videos can be found on the project\nwebsite: https://sites.google.com/berkeley.edu/equicontact",
    "published": "2025-07-15T03:45:26Z",
    "updated": "2025-10-28T20:57:42Z",
    "link": "http://arxiv.org/pdf/2507.10961v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Joohwan Seo",
      "Arvind Kruthiventy",
      "Soomi Lee",
      "Megan Teng",
      "Xiang Zhang",
      "Seoyeon Choi",
      "Jongeun Choi",
      "Roberto Horowitz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.07216v2",
    "title": "Quantum Machine Learning and Grover's Algorithm for Quantum Optimization\n  of Robotic Manipulators",
    "summary": "Optimizing high-degree of freedom robotic manipulators requires searching\ncomplex, high-dimensional configuration spaces, a task that is computationally\nchallenging for classical methods. This paper introduces a quantum native\nframework that integrates quantum machine learning with Grover's algorithm to\nsolve kinematic optimization problems efficiently. A parameterized quantum\ncircuit is trained to approximate the forward kinematics model, which then\nconstructs an oracle to identify optimal configurations. Grover's algorithm\nleverages this oracle to provide a quadratic reduction in search complexity.\nDemonstrated on simulated 1-DoF, 2-DoF, and dual-arm manipulator tasks, the\nmethod achieves significant speedups-up to 93x over classical optimizers like\nNelder Mead as problem dimensionality increases. This work establishes a\nfoundational, quantum-native framework for robot kinematic optimization,\neffectively bridging quantum computing and robotics problems.",
    "published": "2025-09-08T20:52:59Z",
    "updated": "2025-10-28T20:45:56Z",
    "link": "http://arxiv.org/pdf/2509.07216v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Hassen Nigatu",
      "Shi Gaokun",
      "Li Jituo",
      "Wang Jin",
      "Lu Guodong",
      "Howard Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2310.06210v2",
    "title": "CAT-RRT: Motion Planning that Admits Contact One Link at a Time",
    "summary": "Current motion planning approaches rely on binary collision checking to\nevaluate the validity of a state and thereby dictate where the robot is allowed\nto move. This approach leaves little room for robots to engage in contact with\nan object, as is often necessary when operating in densely cluttered spaces. In\nthis work, we propose an alternative method that considers contact states as\nhigh-cost states that the robot should avoid but can traverse if necessary to\ncomplete a task. More specifically, we introduce Contact Admissible\nTransition-based Rapidly exploring Random Trees (CAT-RRT), a planner that uses\na novel per-link cost heuristic to find a path by traversing high-cost obstacle\nregions. Through extensive testing, we find that state-of-the-art optimization\nplanners tend to over-explore low-cost states, which leads to slow and\ninefficient convergence to contact regions. Conversely, CAT-RRT searches both\nlow and high-cost regions simultaneously with an adaptive thresholding\nmechanism carried out at each robot link. This leads to paths with a balance\nbetween efficiency, path length, and contact cost.",
    "published": "2023-10-09T23:42:33Z",
    "updated": "2025-10-28T18:18:29Z",
    "link": "http://arxiv.org/pdf/2310.06210v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Nataliya Nechyporenko",
      "Caleb Escobedo",
      "Shreyas Kadekodi",
      "Alessandro Roncone"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.04881v2",
    "title": "Efficient Path Planning and Task Allocation Algorithm for Boolean\n  Specifications",
    "summary": "This paper presents a novel path-planning and task assignment algorithm for\nmulti-robot systems that should fulfill a global Boolean specification. The\nproposed method is based on Integer Linear Programming (ILP) formulations,\nwhich are combined with structural insights from Petri nets to improve\nscalability and computational efficiency. By proving that the \\emph{constraint\nmatrix} is totally unimodular (TU) for certain classes of problems, the ILP\nformulation can be relaxed into a Linear Programming (LP) problem without\nlosing the integrality of the solution. This relaxation eliminates complex\ncombinatorial techniques, significantly reducing computational overhead and\nthus ensuring scalability for large-scale systems. Using the approach proposed\nin this paper, we can solve path-planning problems for teams made up to 500\nrobots. The method guarantees computational tractability, handles collision\navoidance and reduces computational demands through iterative LP optimization\ntechniques. Case studies demonstrate the efficiency of the algorithm in\ngenerating scalable, collision-free paths for large robot teams navigating in\ncomplex environments. While the conservative nature of collision avoidance\nintroduces additional constraints, and thus, computational requirements, the\nsolution remains practical and impactful for diverse applications. The\nalgorithm is particularly applicable to real-world scenarios, including\nwarehouse logistics where autonomous robots must efficiently coordinate tasks\nor search-and-rescue operations in various environments. This work contributes\nboth theoretically and practically to scalable multi-robot path planning and\ntask allocation, offering an efficient framework for coordinating autonomous\nagents in shared environments.",
    "published": "2025-06-05T11:00:31Z",
    "updated": "2025-10-28T18:11:08Z",
    "link": "http://arxiv.org/pdf/2506.04881v2.pdf",
    "category": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "authors": [
      "Ioana Hustiu",
      "Roozbeh Abolpour",
      "Cristian Mahulea",
      "Marius Kloetzer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.12153v2",
    "title": "Federated Deep Reinforcement Learning for Privacy-Preserving\n  Robotic-Assisted Surgery",
    "summary": "The integration of Reinforcement Learning (RL) into robotic-assisted surgery\n(RAS) holds significant promise for advancing surgical precision, adaptability,\nand autonomous decision-making. However, the development of robust RL models in\nclinical settings is hindered by key challenges, including stringent patient\ndata privacy regulations, limited access to diverse surgical datasets, and high\nprocedural variability. To address these limitations, this paper presents a\nFederated Deep Reinforcement Learning (FDRL) framework that enables\ndecentralized training of RL models across multiple healthcare institutions\nwithout exposing sensitive patient information. A central innovation of the\nproposed framework is its dynamic policy adaptation mechanism, which allows\nsurgical robots to select and tailor patient-specific policies in real-time,\nthereby ensuring personalized and Optimised interventions. To uphold rigorous\nprivacy standards while facilitating collaborative learning, the FDRL framework\nincorporates secure aggregation, differential privacy, and homomorphic\nencryption techniques. Experimental results demonstrate a 60\\% reduction in\nprivacy leakage compared to conventional methods, with surgical precision\nmaintained within a 1.5\\% margin of a centralized baseline. This work\nestablishes a foundational approach for adaptive, secure, and patient-centric\nAI-driven surgical robotics, offering a pathway toward clinical translation and\nscalable deployment across diverse healthcare environments.",
    "published": "2025-05-17T22:02:44Z",
    "updated": "2025-10-28T18:06:02Z",
    "link": "http://arxiv.org/pdf/2505.12153v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Sana Hafeez",
      "Sundas Rafat Mulkana",
      "Muhammad Ali Imran",
      "Michele Sevegnani"
    ]
  }
]