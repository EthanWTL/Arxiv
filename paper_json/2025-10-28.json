[
  {
    "id": "http://arxiv.org/abs/2507.03285v2",
    "title": "Memory Mosaics at scale",
    "summary": "Memory Mosaics [Zhang et al., 2025], networks of associative memories, have\ndemonstrated appealing compositional and in-context learning capabilities on\nmedium-scale networks (GPT-2 scale) and synthetic small datasets. This work\nshows that these favorable properties remain when we scale memory mosaics to\nlarge language model sizes (llama-8B scale) and real-world datasets.\n  To this end, we scale memory mosaics to 10B size, we train them on one\ntrillion tokens, we introduce a couple architectural modifications (\"Memory\nMosaics v2\"), we assess their capabilities across three evaluation dimensions:\ntraining-knowledge storage, new-knowledge storage, and in-context learning.\n  Throughout the evaluation, memory mosaics v2 match transformers on the\nlearning of training knowledge (first dimension) and significantly outperforms\ntransformers on carrying out new tasks at inference time (second and third\ndimensions). These improvements cannot be easily replicated by simply\nincreasing the training data for transformers. A memory mosaics v2 trained on\none trillion tokens still perform better on these tasks than a transformer\ntrained on eight trillion tokens.",
    "published": "2025-07-04T04:23:03Z",
    "updated": "2025-10-28T17:59:36Z",
    "link": "http://arxiv.org/pdf/2507.03285v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Jianyu Zhang",
      "LÃ©on Bottou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24709v1",
    "title": "Does Object Binding Naturally Emerge in Large Pretrained Vision\n  Transformers?",
    "summary": "Object binding, the brain's ability to bind the many features that\ncollectively represent an object into a coherent whole, is central to human\ncognition. It groups low-level perceptual features into high-level object\nrepresentations, stores those objects efficiently and compositionally in\nmemory, and supports human reasoning about individual object instances. While\nprior work often imposes object-centric attention (e.g., Slot Attention)\nexplicitly to probe these benefits, it remains unclear whether this ability\nnaturally emerges in pre-trained Vision Transformers (ViTs). Intuitively, they\ncould: recognizing which patches belong to the same object should be useful for\ndownstream prediction and thus guide attention. Motivated by the quadratic\nnature of self-attention, we hypothesize that ViTs represent whether two\npatches belong to the same object, a property we term IsSameObject. We decode\nIsSameObject from patch embeddings across ViT layers using a similarity probe,\nwhich reaches over 90% accuracy. Crucially, this object-binding capability\nemerges reliably in self-supervised ViTs (DINO, MAE, CLIP), but markedly weaker\nin ImageNet-supervised models, suggesting that binding is not a trivial\narchitectural artifact, but an ability acquired through specific pretraining\nobjectives. We further discover that IsSameObject is encoded in a\nlow-dimensional subspace on top of object features, and that this signal\nactively guides attention. Ablating IsSameObject from model activations\ndegrades downstream performance and works against the learning objective,\nimplying that emergent object binding naturally serves the pretraining\nobjective. Our findings challenge the view that ViTs lack object binding and\nhighlight how symbolic knowledge of \"which parts belong together\" emerges\nnaturally in a connectionist system.",
    "published": "2025-10-28T17:57:05Z",
    "updated": "2025-10-28T17:57:05Z",
    "link": "http://arxiv.org/pdf/2510.24709v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "authors": [
      "Yihao Li",
      "Saeed Salehi",
      "Lyle Ungar",
      "Konrad P. Kording"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2404.13397v2",
    "title": "Retrieval-Augmented Generation-based Relation Extraction",
    "summary": "Information Extraction (IE) is a transformative process that converts\nunstructured text data into a structured format by employing entity and\nrelation extraction (RE) methodologies. The identification of the relation\nbetween a pair of entities plays a crucial role within this framework. Despite\nthe existence of various techniques for relation extraction, their efficacy\nheavily relies on access to labeled data and substantial computational\nresources. In addressing these challenges, Large Language Models (LLMs) emerge\nas promising solutions; however, they might return hallucinating responses due\nto their own training data. To overcome these limitations, Retrieved-Augmented\nGeneration-based Relation Extraction (RAG4RE) in this work is proposed,\noffering a pathway to enhance the performance of relation extraction tasks.\n  This work evaluated the effectiveness of our RAG4RE approach utilizing\ndifferent LLMs. Through the utilization of established benchmarks, such as\nTACRED, TACREV, Re-TACRED, and SemEval RE datasets, our aim is to\ncomprehensively evaluate the efficacy of our RAG4RE approach. In particularly,\nwe leverage prominent LLMs including Flan T5, Llama2, and Mistral in our\ninvestigation. The results of our study demonstrate that our RAG4RE approach\nsurpasses performance of traditional RE approaches based solely on LLMs,\nparticularly evident in the TACRED dataset and its variations. Furthermore, our\napproach exhibits remarkable performance compared to previous RE methodologies\nacross both TACRED and TACREV datasets, underscoring its efficacy and potential\nfor advancing RE tasks in natural language processing.",
    "published": "2024-04-20T14:42:43Z",
    "updated": "2025-10-28T17:56:27Z",
    "link": "http://arxiv.org/pdf/2404.13397v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Sefika Efeoglu",
      "Adrian Paschke"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24706v1",
    "title": "ComboBench: Can LLMs Manipulate Physical Devices to Play Virtual Reality\n  Games?",
    "summary": "Virtual Reality (VR) games require players to translate high-level semantic\nactions into precise device manipulations using controllers and head-mounted\ndisplays (HMDs). While humans intuitively perform this translation based on\ncommon sense and embodied understanding, whether Large Language Models (LLMs)\ncan effectively replicate this ability remains underexplored. This paper\nintroduces a benchmark, ComboBench, evaluating LLMs' capability to translate\nsemantic actions into VR device manipulation sequences across 262 scenarios\nfrom four popular VR games: Half-Life: Alyx, Into the Radius, Moss: Book II,\nand Vivecraft. We evaluate seven LLMs, including GPT-3.5, GPT-4, GPT-4o,\nGemini-1.5-Pro, LLaMA-3-8B, Mixtral-8x7B, and GLM-4-Flash, compared against\nannotated ground truth and human performance. Our results reveal that while\ntop-performing models like Gemini-1.5-Pro demonstrate strong task decomposition\ncapabilities, they still struggle with procedural reasoning and spatial\nunderstanding compared to humans. Performance varies significantly across\ngames, suggesting sensitivity to interaction complexity. Few-shot examples\nsubstantially improve performance, indicating potential for targeted\nenhancement of LLMs' VR manipulation capabilities. We release all materials at\nhttps://sites.google.com/view/combobench.",
    "published": "2025-10-28T17:55:42Z",
    "updated": "2025-10-28T17:55:42Z",
    "link": "http://arxiv.org/pdf/2510.24706v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.SE"
    ],
    "authors": [
      "Shuqing Li",
      "Jiayi Yan",
      "Chenyu Niu",
      "Jen-tse Huang",
      "Yun Peng",
      "Wenxuan Wang",
      "Yepang Liu",
      "Michael R. Lyu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24702v1",
    "title": "Agent Data Protocol: Unifying Datasets for Diverse, Effective\n  Fine-tuning of LLM Agents",
    "summary": "Public research results on large-scale supervised finetuning of AI agents\nremain relatively rare, since the collection of agent training data presents\nunique challenges. In this work, we argue that the bottleneck is not a lack of\nunderlying data sources, but that a large variety of data is fragmented across\nheterogeneous formats, tools, and interfaces. To this end, we introduce the\nagent data protocol (ADP), a light-weight representation language that serves\nas an \"interlingua\" between agent datasets in diverse formats and unified agent\ntraining pipelines downstream. The design of ADP is expressive enough to\ncapture a large variety of tasks, including API/tool use, browsing, coding,\nsoftware engineering, and general agentic workflows, while remaining simple to\nparse and train on without engineering at a per-dataset level. In experiments,\nwe unified a broad collection of 13 existing agent training datasets into ADP\nformat, and converted the standardized ADP data into training-ready formats for\nmultiple agent frameworks. We performed SFT on these data, and demonstrated an\naverage performance gain of ~20% over corresponding base models, and delivers\nstate-of-the-art or near-SOTA performance on standard coding, browsing, tool\nuse, and research benchmarks, without domain-specific tuning. All code and data\nare released publicly, in the hope that ADP could help lower the barrier to\nstandardized, scalable, and reproducible agent training.",
    "published": "2025-10-28T17:53:13Z",
    "updated": "2025-10-28T17:53:13Z",
    "link": "http://arxiv.org/pdf/2510.24702v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Yueqi Song",
      "Ketan Ramaneti",
      "Zaid Sheikh",
      "Ziru Chen",
      "Boyu Gou",
      "Tianbao Xie",
      "Yiheng Xu",
      "Danyang Zhang",
      "Apurva Gandhi",
      "Fan Yang",
      "Joseph Liu",
      "Tianyue Ou",
      "Zhihao Yuan",
      "Frank Xu",
      "Shuyan Zhou",
      "Xingyao Wang",
      "Xiang Yue",
      "Tao Yu",
      "Huan Sun",
      "Yu Su",
      "Graham Neubig"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24701v1",
    "title": "Tongyi DeepResearch Technical Report",
    "summary": "We present Tongyi DeepResearch, an agentic large language model, which is\nspecifically designed for long-horizon, deep information-seeking research\ntasks. To incentivize autonomous deep research agency, Tongyi DeepResearch is\ndeveloped through an end-to-end training framework that combines agentic\nmid-training and agentic post-training, enabling scalable reasoning and\ninformation seeking across complex tasks. We design a highly scalable data\nsynthesis pipeline that is fully automatic, without relying on costly human\nannotation, and empowers all training stages. By constructing customized\nenvironments for each stage, our system enables stable and consistent\ninteractions throughout. Tongyi DeepResearch, featuring 30.5 billion total\nparameters, with only 3.3 billion activated per token, achieves\nstate-of-the-art performance across a range of agentic deep research\nbenchmarks, including Humanity's Last Exam, BrowseComp, BrowseComp-ZH,\nWebWalkerQA, xbench-DeepSearch, FRAMES and xbench-DeepSearch-2510. We\nopen-source the model, framework, and complete solutions to empower the\ncommunity.",
    "published": "2025-10-28T17:53:02Z",
    "updated": "2025-10-28T17:53:02Z",
    "link": "http://arxiv.org/pdf/2510.24701v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "cs.MA"
    ],
    "authors": [
      " Tongyi DeepResearch Team",
      "Baixuan Li",
      "Bo Zhang",
      "Dingchu Zhang",
      "Fei Huang",
      "Guangyu Li",
      "Guoxin Chen",
      "Huifeng Yin",
      "Jialong Wu",
      "Jingren Zhou",
      "Kuan Li",
      "Liangcai Su",
      "Litu Ou",
      "Liwen Zhang",
      "Pengjun Xie",
      "Rui Ye",
      "Wenbiao Yin",
      "Xinmiao Yu",
      "Xinyu Wang",
      "Xixi Wu",
      "Xuanzhong Chen",
      "Yida Zhao",
      "Zhen Zhang",
      "Zhengwei Tao",
      "Zhongwang Zhang",
      "Zile Qiao",
      "Chenxi Wang",
      "Donglei Yu",
      "Gang Fu",
      "Haiyang Shen",
      "Jiayin Yang",
      "Jun Lin",
      "Junkai Zhang",
      "Kui Zeng",
      "Li Yang",
      "Hailong Yin",
      "Maojia Song",
      "Ming Yan",
      "Peng Xia",
      "Qian Xiao",
      "Rui Min",
      "Ruixue Ding",
      "Runnan Fang",
      "Shaowei Chen",
      "Shen Huang",
      "Shihang Wang",
      "Shihao Cai",
      "Weizhou Shen",
      "Xiaobin Wang",
      "Xin Guan",
      "Xinyu Geng",
      "Yingcheng Shi",
      "Yuning Wu",
      "Zhuo Chen",
      "Zijian Li",
      "Yong Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24700v1",
    "title": "Greedy Sampling Is Provably Efficient for RLHF",
    "summary": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a key\ntechnique for post-training large language models. Despite its empirical\nsuccess, the theoretical understanding of RLHF is still limited, as learning\nthe KL-regularized target with only preference feedback poses additional\nchallenges compared with canonical RL. Existing works mostly study the\nreward-based Bradley-Terry (BT) preference model, and extend classical designs\nutilizing optimism or pessimism. This work, instead, considers the general\npreference model (whose practical relevance has been observed recently) and\nobtains performance guarantees with major, order-wise improvements over\nexisting ones. Surprisingly, these results are derived from algorithms that\ndirectly use the empirical estimates (i.e., greedy sampling), as opposed to\nconstructing optimistic or pessimistic estimates in previous works. This\ninsight has a deep root in the unique structural property of the optimal policy\nclass under the KL-regularized target, and we further specialize it to the BT\nmodel, highlighting the surprising sufficiency of greedy sampling in RLHF.",
    "published": "2025-10-28T17:52:08Z",
    "updated": "2025-10-28T17:52:08Z",
    "link": "http://arxiv.org/pdf/2510.24700v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ],
    "authors": [
      "Di Wu",
      "Chengshuai Shi",
      "Jing Yang",
      "Cong Shen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24698v1",
    "title": "ParallelMuse: Agentic Parallel Thinking for Deep Information Seeking",
    "summary": "Parallel thinking expands exploration breadth, complementing the deep\nexploration of information-seeking (IS) agents to further enhance\nproblem-solving capability. However, conventional parallel thinking faces two\nkey challenges in this setting: inefficiency from repeatedly rolling out from\nscratch, and difficulty in integrating long-horizon reasoning trajectories\nduring answer generation, as limited context capacity prevents full\nconsideration of the reasoning process. To address these issues, we propose\nParallelMuse, a two-stage paradigm designed for deep IS agents. The first\nstage, Functionality-Specified Partial Rollout, partitions generated sequences\ninto functional regions and performs uncertainty-guided path reuse and\nbranching to enhance exploration efficiency. The second stage, Compressed\nReasoning Aggregation, exploits reasoning redundancy to losslessly compress\ninformation relevant to answer derivation and synthesize a coherent final\nanswer. Experiments across multiple open-source agents and benchmarks\ndemonstrate up to 62% performance improvement with a 10--30% reduction in\nexploratory token consumption.",
    "published": "2025-10-28T17:51:50Z",
    "updated": "2025-10-28T17:51:50Z",
    "link": "http://arxiv.org/pdf/2510.24698v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Baixuan Li",
      "Dingchu Zhang",
      "Jialong Wu",
      "Wenbiao Yin",
      "Zhengwei Tao",
      "Yida Zhao",
      "Liwen Zhang",
      "Haiyang Shen",
      "Runnan Fang",
      "Pengjun Xie",
      "Jingren Zhou",
      "Yong Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24699v1",
    "title": "AgentFold: Long-Horizon Web Agents with Proactive Context Management",
    "summary": "LLM-based web agents show immense promise for information seeking, yet their\neffectiveness on long-horizon tasks is hindered by a fundamental trade-off in\ncontext management. Prevailing ReAct-based agents suffer from context\nsaturation as they accumulate noisy, raw histories, while methods that fixedly\nsummarize the full history at each step risk the irreversible loss of critical\ndetails. Addressing these, we introduce AgentFold, a novel agent paradigm\ncentered on proactive context management, inspired by the human cognitive\nprocess of retrospective consolidation. AgentFold treats its context as a\ndynamic cognitive workspace to be actively sculpted, rather than a passive log\nto be filled. At each step, it learns to execute a `folding' operation, which\nmanages its historical trajectory at multiple scales: it can perform granular\ncondensations to preserve vital, fine-grained details, or deep consolidations\nto abstract away entire multi-step sub-tasks. The results on prominent\nbenchmarks are striking: with simple supervised fine-tuning (without continual\npre-training or RL), our AgentFold-30B-A3B agent achieves 36.2% on BrowseComp\nand 47.3% on BrowseComp-ZH. Notably, this performance not only surpasses or\nmatches open-source models of a dramatically larger scale, such as the\nDeepSeek-V3.1-671B-A37B, but also surpasses leading proprietary agents like\nOpenAI's o4-mini.",
    "published": "2025-10-28T17:51:50Z",
    "updated": "2025-10-28T17:51:50Z",
    "link": "http://arxiv.org/pdf/2510.24699v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Rui Ye",
      "Zhongwang Zhang",
      "Kuan Li",
      "Huifeng Yin",
      "Zhengwei Tao",
      "Yida Zhao",
      "Liangcai Su",
      "Liwen Zhang",
      "Zile Qiao",
      "Xinyu Wang",
      "Pengjun Xie",
      "Fei Huang",
      "Siheng Chen",
      "Jingren Zhou",
      "Yong Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24694v1",
    "title": "Repurposing Synthetic Data for Fine-grained Search Agent Supervision",
    "summary": "LLM-based search agents are increasingly trained on entity-centric synthetic\ndata to solve complex, knowledge-intensive tasks. However, prevailing training\nmethods like Group Relative Policy Optimization (GRPO) discard this rich entity\ninformation, relying instead on sparse, outcome-based rewards. This critical\nlimitation renders them unable to distinguish informative \"near-miss\"\nsamples-those with substantially correct reasoning but a flawed final\nanswer-from complete failures, thus discarding valuable learning signals. We\naddress this by leveraging the very entities discarded during training. Our\nempirical analysis reveals a strong positive correlation between the number of\nground-truth entities identified during an agent's reasoning process and final\nanswer accuracy. Building on this insight, we introduce Entity-aware Group\nRelative Policy Optimization (E-GRPO), a novel framework that formulates a\ndense entity-aware reward function. E-GRPO assigns partial rewards to incorrect\nsamples proportional to their entity match rate, enabling the model to\neffectively learn from these \"near-misses\". Experiments on diverse\nquestion-answering (QA) and deep research benchmarks show that E-GRPO\nconsistently and significantly outperforms the GRPO baseline. Furthermore, our\nanalysis reveals that E-GRPO not only achieves superior accuracy but also\ninduces more efficient reasoning policies that require fewer tool calls,\ndemonstrating a more effective and sample-efficient approach to aligning search\nagents.",
    "published": "2025-10-28T17:50:40Z",
    "updated": "2025-10-28T17:50:40Z",
    "link": "http://arxiv.org/pdf/2510.24694v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Yida Zhao",
      "Kuan Li",
      "Xixi Wu",
      "Liwen Zhang",
      "Dingchu Zhang",
      "Baixuan Li",
      "Maojia Song",
      "Zhuo Chen",
      "Chenxi Wang",
      "Xinyu Wang",
      "Kewei Tu",
      "Pengjun Xie",
      "Jingren Zhou",
      "Yong Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24690v1",
    "title": "Bridging Tool Dependencies and Domain Knowledge: A Graph-Based Framework\n  for In-Context Planning",
    "summary": "We present a framework for uncovering and exploiting dependencies among tools\nand documents to enhance exemplar artifact generation. Our method begins by\nconstructing a tool knowledge graph from tool schemas,including descriptions,\narguments, and output payloads, using a DeepResearch-inspired analysis. In\nparallel, we derive a complementary knowledge graph from internal documents and\nSOPs, which is then fused with the tool graph. To generate exemplar plans, we\nadopt a deep-sparse integration strategy that aligns structural tool\ndependencies with procedural knowledge. Experiments demonstrate that this\nunified framework effectively models tool interactions and improves plan\ngeneration, underscoring the benefits of linking tool graphs with domain\nknowledge graphs for tool-augmented reasoning and planning.",
    "published": "2025-10-28T17:50:15Z",
    "updated": "2025-10-28T17:50:15Z",
    "link": "http://arxiv.org/pdf/2510.24690v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Shengjie Liu",
      "Li Dong",
      "Zhenyu Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24687v1",
    "title": "Fast algorithms enabling optimization and deep learning for\n  photoacoustic tomography in a circular detection geometry",
    "summary": "The inverse source problem arising in photoacoustic tomography and in several\nother coupled-physics modalities is frequently solved by iterative algorithms.\nSuch algorithms are based on the minimization of a certain cost functional. In\naddition, novel deep learning techniques are currently being investigated to\nfurther improve such optimization approaches. All such methods require multiple\napplications of the operator defining the forward problem, and of its adjoint.\nIn this paper, we present new asymptotically fast algorithms for numerical\nevaluation of the forward and adjoint operators, applicable in the circular\nacquisition geometry. For an $(n \\times n)$ image, our algorithms compute these\noperators in $\\mathcal{O}(n^2 \\log n)$ floating point operations. We\ndemonstrate the performance of our algorithms in numerical simulations, where\nthey are used as an integral part of several iterative image reconstruction\ntechniques: classic variational methods, such as non-negative least squares and\ntotal variation regularized least squares, as well as deep learning methods,\nsuch as learned primal dual. A Python implementation of our algorithms and\ncomputational examples is available to the general public.",
    "published": "2025-10-28T17:49:31Z",
    "updated": "2025-10-28T17:49:31Z",
    "link": "http://arxiv.org/pdf/2510.24687v1.pdf",
    "category": [
      "eess.IV",
      "cs.AI",
      "cs.NA",
      "math.AP",
      "math.NA",
      "math.OC"
    ],
    "authors": [
      "Andreas Hauptmann",
      "Leonid Kunyansky",
      "Jenni Poimala"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24677v1",
    "title": "Dissecting Role Cognition in Medical LLMs via Neuronal Ablation",
    "summary": "Large language models (LLMs) have gained significant traction in medical\ndecision support systems, particularly in the\n  context of medical question answering and role-playing simulations. A common\npractice, Prompt-Based Role Playing (PBRP),\n  instructs models to adopt different clinical roles (e.g., medical students,\nresidents, attending physicians) to simulate varied\n  professional behaviors. However, the impact of such role prompts on model\nreasoning capabilities remains unclear. This\n  study introduces the RP-Neuron-Activated Evaluation Framework(RPNA) to\nevaluate whether role prompts induce distinct,\n  role-specific cognitive processes in LLMs or merely modify linguistic style.\nWe test this framework on three medical QA\n  datasets, employing neuron ablation and representation analysis techniques to\nassess changes in reasoning pathways. Our\n  results demonstrate that role prompts do not significantly enhance the\nmedical reasoning abilities of LLMs. Instead, they\n  primarily affect surface-level linguistic features, with no evidence of\ndistinct reasoning pathways or cognitive differentiation\n  across clinical roles. Despite superficial stylistic changes, the core\ndecision-making mechanisms of LLMs remain uniform\n  across roles, indicating that current PBRP methods fail to replicate the\ncognitive complexity found in real-world medical\n  practice. This highlights the limitations of role-playing in medical AI and\nemphasizes the need for models that simulate genuine\n  cognitive processes rather than linguistic imitation.We have released the\nrelated code in the following repository:https:\n  //github.com/IAAR-Shanghai/RolePlay_LLMDoctor",
    "published": "2025-10-28T17:40:53Z",
    "updated": "2025-10-28T17:40:53Z",
    "link": "http://arxiv.org/pdf/2510.24677v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Xun Liang",
      "Huayi Lai",
      "Hanyu Wang",
      "Wentao Zhang",
      "Linfeng Zhang",
      "Yanfang Chen",
      "Feiyu Xiong",
      "Zhiyu Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24674v1",
    "title": "Learning to Drive Safely with Hybrid Options",
    "summary": "Out of the many deep reinforcement learning approaches for autonomous\ndriving, only few make use of the options (or skills) framework. That is\nsurprising, as this framework is naturally suited for hierarchical control\napplications in general, and autonomous driving tasks in specific. Therefore,\nin this work the options framework is applied and tailored to autonomous\ndriving tasks on highways. More specifically, we define dedicated options for\nlongitudinal and lateral manoeuvres with embedded safety and comfort\nconstraints. This way, prior domain knowledge can be incorporated into the\nlearning process and the learned driving behaviour can be constrained more\neasily. We propose several setups for hierarchical control with options and\nderive practical algorithms following state-of-the-art reinforcement learning\ntechniques. By separately selecting actions for longitudinal and lateral\ncontrol, the introduced policies over combined and hybrid options obtain the\nsame expressiveness and flexibility that human drivers have, while being easier\nto interpret than classical policies over continuous actions. Of all the\ninvestigated approaches, these flexible policies over hybrid options perform\nthe best under varying traffic conditions, outperforming the baseline policies\nover actions.",
    "published": "2025-10-28T17:40:04Z",
    "updated": "2025-10-28T17:40:04Z",
    "link": "http://arxiv.org/pdf/2510.24674v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "authors": [
      "Bram De Cooman",
      "Johan Suykens"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.07862v2",
    "title": "ADMN: A Layer-Wise Adaptive Multimodal Network for Dynamic Input Noise\n  and Compute Resources",
    "summary": "Multimodal deep learning systems are deployed in dynamic scenarios due to the\nrobustness afforded by multiple sensing modalities. Nevertheless, they struggle\nwith varying compute resource availability (due to multi-tenancy, device\nheterogeneity, etc.) and fluctuating quality of inputs (from sensor feed\ncorruption, environmental noise, etc.). Statically provisioned multimodal\nsystems cannot adapt when compute resources change over time, while existing\ndynamic networks struggle with strict compute budgets. Additionally, both\nsystems often neglect the impact of variations in modality quality.\nConsequently, modalities suffering substantial corruption may needlessly\nconsume resources better allocated towards other modalities. We propose ADMN, a\nlayer-wise Adaptive Depth Multimodal Network capable of tackling both\nchallenges: it adjusts the total number of active layers across all modalities\nto meet strict compute resource constraints and continually reallocates layers\nacross input modalities according to their modality quality. Our evaluations\nshowcase ADMN can match the accuracy of state-of-the-art networks while\nreducing up to 75% of their floating-point operations.",
    "published": "2025-02-11T17:19:44Z",
    "updated": "2025-10-28T17:37:03Z",
    "link": "http://arxiv.org/pdf/2502.07862v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Jason Wu",
      "Yuyang Yuan",
      "Kang Yang",
      "Lance Kaplan",
      "Mani Srivastava"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24671v1",
    "title": "Multi-Agent Scenario Generation in Roundabouts with a\n  Transformer-enhanced Conditional Variational Autoencoder",
    "summary": "With the increasing integration of intelligent driving functions into\nserial-produced vehicles, ensuring their functionality and robustness poses\ngreater challenges. Compared to traditional road testing, scenario-based\nvirtual testing offers significant advantages in terms of time and cost\nefficiency, reproducibility, and exploration of edge cases. We propose a\nTransformer-enhanced Conditional Variational Autoencoder (CVAE-T) model for\ngenerating multi-agent traffic scenarios in roundabouts, which are\ncharacterized by high vehicle dynamics and complex layouts, yet remain\nrelatively underexplored in current research. The results show that the\nproposed model can accurately reconstruct original scenarios and generate\nrealistic, diverse synthetic scenarios. Besides, two Key-Performance-Indicators\n(KPIs) are employed to evaluate the interactive behavior in the generated\nscenarios. Analysis of the latent space reveals partial disentanglement, with\nseveral latent dimensions exhibiting distinct and interpretable effects on\nscenario attributes such as vehicle entry timing, exit timing, and velocity\nprofiles. The results demonstrate the model's capability to generate scenarios\nfor the validation of intelligent driving functions involving multi-agent\ninteractions, as well as to augment data for their development and iterative\nimprovement.",
    "published": "2025-10-28T17:36:52Z",
    "updated": "2025-10-28T17:36:52Z",
    "link": "http://arxiv.org/pdf/2510.24671v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Li Li",
      "Tobias Brinkmann",
      "Till Temmen",
      "Markus Eisenbarth",
      "Jakob Andert"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24668v1",
    "title": "InteractComp: Evaluating Search Agents With Ambiguous Queries",
    "summary": "Language agents have demonstrated remarkable potential in web search and\ninformation retrieval. However, these search agents assume user queries are\ncomplete and unambiguous, an assumption that diverges from reality where users\nbegin with incomplete queries requiring clarification through interaction. Yet\nmost agents lack interactive mechanisms during the search process, and existing\nbenchmarks cannot assess this capability. To address this gap, we introduce\nInteractComp, a benchmark designed to evaluate whether search agents can\nrecognize query ambiguity and actively interact to resolve it during search.\nFollowing the principle of easy to verify, interact to disambiguate, we\nconstruct 210 expert-curated questions across 9 domains through a\ntarget-distractor methodology that creates genuine ambiguity resolvable only\nthrough interaction. Evaluation of 17 models reveals striking failure: the best\nmodel achieves only 13.73% accuracy despite 71.50% with complete context,\nexposing systematic overconfidence rather than reasoning deficits. Forced\ninteraction produces dramatic gains, demonstrating latent capability current\nstrategies fail to engage. Longitudinal analysis shows interaction capabilities\nstagnated over 15 months while search performance improved seven-fold,\nrevealing a critical blind spot. This stagnation, coupled with the immediate\nfeedback inherent to search tasks, makes InteractComp a valuable resource for\nboth evaluating and training interaction capabilities in search agents. The\ncode is available at https://github.com/FoundationAgents/InteractComp.",
    "published": "2025-10-28T17:35:54Z",
    "updated": "2025-10-28T17:35:54Z",
    "link": "http://arxiv.org/pdf/2510.24668v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Mingyi Deng",
      "Lijun Huang",
      "Yani Fan",
      "Jiayi Zhang",
      "Fashen Ren",
      "Jinyi Bai",
      "Fuzhen Yang",
      "Dayi Miao",
      "Zhaoyang Yu",
      "Yifan Wu",
      "Yanfei Zhang",
      "Fengwei Teng",
      "Yingjia Wan",
      "Song Hu",
      "Yude Li",
      "Xin Jin",
      "Conghao Hu",
      "Haoyu Li",
      "Qirui Fu",
      "Tai Zhong",
      "Xinyu Wang",
      "Xiangru Tang",
      "Nan Tang",
      "Chenglin Wu",
      "Yuyu Luo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24663v1",
    "title": "OrchDAG: Complex Tool Orchestration in Multi-Turn Interactions with Plan\n  DAGs",
    "summary": "Agentic tool use has gained traction with the rise of agentic tool calling,\nyet most existing work overlooks the complexity of multi-turn tool\ninteractions. We introduce OrchDAG, a synthetic data generation pipeline that\nmodels tool execution as directed acyclic graphs (DAGs) with controllable\ncomplexity. Using this dataset, we benchmark model performance and propose a\ngraph-based reward to enhance RLVR training. Experiments show that the dataset\npresents a challenging but solvable benchmark, and the proposed reward is\neffective when combined with GRPO-style algorithms, highlighting the importance\nof leveraging topological structure and data complexity in multi-turn tool use.",
    "published": "2025-10-28T17:28:01Z",
    "updated": "2025-10-28T17:28:01Z",
    "link": "http://arxiv.org/pdf/2510.24663v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Yifu Lu",
      "Shengjie Liu",
      "Li Dong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.01281v6",
    "title": "Arena-Lite: Efficient and Reliable Large Language Model Evaluation via\n  Tournament-Based Direct Comparisons",
    "summary": "As Large Language Models (LLMs) expand across domains, LLM judges have become\nessential for systems evaluation. Current benchmarks typically compare system\noutputs against baselines. This baseline-mediated approach, though convenient,\nyields lower reliability than direct comparison between systems. We propose\nArena-Lite which integrates tournament structure on top of head-to-head\ncomparison. The application of a tournament structure and direct comparison\neliminates the need for baseline outputs, reduces the number of required\ncomparisons, and allows higher reliability in system rankings. We conducted two\nexperiments: (1) controlled stochastic modeling and (2) empirical validation\nwith a real LLM judge. Those experiments collectively demonstrate that\nArena-Lite consistently achieves higher reliability with fewer comparisons,\neven with smaller datasets or weaker judges. We release an easy-to-use web\ndemonstration and code to foster adoption of Arena-Lite, streamlining model\nselection across research and industry communities. Arena-Lite demo and code\nare available on\n\\href{https://huggingface.co/spaces/NCSOFT/ArenaLite}{https://huggingface.co/spaces/NCSOFT/ArenaLite}",
    "published": "2024-11-02T15:23:28Z",
    "updated": "2025-10-28T17:26:20Z",
    "link": "http://arxiv.org/pdf/2411.01281v6.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Seonil Son",
      "Ju-Min Oh",
      "Heegon Jin",
      "Cheolhun Jang",
      "Jeongbeom Jeong",
      "Kuntae Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24650v1",
    "title": "Advancing site-specific disease and pest management in precision\n  agriculture: From reasoning-driven foundation models to adaptive,\n  feedback-based learning",
    "summary": "Site-specific disease management (SSDM) in crops has advanced rapidly through\nmachine and deep learning (ML and DL) for real-time computer vision. Research\nevolved from handcrafted feature extraction to large-scale automated feature\nlearning. With foundation models (FMs), crop disease datasets are now processed\nin fundamentally new ways. Unlike traditional neural networks, FMs integrate\nvisual and textual data, interpret symptoms in text, reason about\nsymptom-management relationships, and support interactive QA for growers and\neducators. Adaptive and imitation learning in robotics further enables\nfield-based disease management. This review screened approx. 40 articles on FM\napplications for SSDM, focusing on large-language models (LLMs) and\nvision-language models (VLMs), and discussing their role in adaptive learning\n(AL), reinforcement learning (RL), and digital twin frameworks for targeted\nspraying. Key findings: (a) FMs are gaining traction with surging literature in\n2023-24; (b) VLMs outpace LLMs, with a 5-10x increase in publications; (c) RL\nand AL are still nascent for smart spraying; (d) digital twins with RL can\nsimulate targeted spraying virtually; (e) addressing the sim-to-real gap is\ncritical for real-world deployment; (f) human-robot collaboration remains\nlimited, especially in human-in-the-loop approaches where robots detect early\nsymptoms and humans validate uncertain cases; (g) multi-modal FMs with\nreal-time feedback will drive next-gen SSDM. For updates, resources, and\ncontributions, visit, https://github.com/nitin-dominic/AgriPathogenDatabase, to\nsubmit papers, code, or datasets.",
    "published": "2025-10-28T17:16:47Z",
    "updated": "2025-10-28T17:16:47Z",
    "link": "http://arxiv.org/pdf/2510.24650v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Nitin Rai",
      " Daeun",
      " Choi",
      "Nathan S. Boyd",
      "Arnold W. Schumann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24645v1",
    "title": "FunReason-MT Technical Report: Overcoming the Complexity Barrier in\n  Multi-Turn Function Calling",
    "summary": "Function calling (FC) empowers large language models (LLMs) and autonomous\nagents to interface with external tools, a critical capability for solving\ncomplex, real-world problems. As this ability becomes increasingly central to\nadvanced AI systems, the need for high-quality, multi-turn training data to\ndevelop and refine it cannot be overstated. Existing data synthesis methods,\nsuch as random environment sampling or multi-agent role-playing, are not\npowerful enough to generate high-quality data in real-world environments.\nPractical challenges come in three folds: targeted model training, isolation of\ntool architecture, and multi-turn logical dependency. To address these\nstructural deficiencies, we present FunReason-MT, a novel data synthesis\nframework for real-world multi-turn tool use. FunReason-MT resolves the\ncomplexity barrier in multi-turn FC data by employing 1) Environment-API Graph\nInteractions to gather varied high-quality trajectories, 2) Advanced Tool-Query\nSynthesis to simplify hard query construction, and 3) Guided Iterative Chain\nfor sophisticated CoT generation. Evaluations on Berkeley Function-Calling\nLeaderboard (BFCLv3) demonstrate the power of our framework: a 4B model built\nupon FunReason-MT generated data achieves state-of-the-art performance among\ncomparable-sized models, outperforming most close-source models. Further\nperformance improvements on BFCLv4 confirm that FunReason-MT provides a\nreliable and robust source for agentic learning.",
    "published": "2025-10-28T17:15:26Z",
    "updated": "2025-10-28T17:15:26Z",
    "link": "http://arxiv.org/pdf/2510.24645v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Zengzhuang Xu",
      "Bingguang Hao",
      "Zechuan Wang",
      "Yuntao Wen",
      "Maolin Wang",
      "Yang Liu",
      "Long Chen",
      "Dong Wang",
      "Yicheng Chen",
      "Cunyin Peng",
      "Chenyi Zhuang",
      "Jinjie Gu",
      "Leilei Gan",
      "Xiangyu Zhao",
      "Shi Gu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.20774v2",
    "title": "FieldGen: From Teleoperated Pre-Manipulation Trajectories to\n  Field-Guided Data Generation",
    "summary": "Large-scale and diverse datasets are vital for training robust robotic\nmanipulation policies, yet existing data collection methods struggle to balance\nscale, diversity, and quality. Simulation offers scalability but suffers from\nsim-to-real gaps, while teleoperation yields high-quality demonstrations with\nlimited diversity and high labor cost. We introduce FieldGen, a field-guided\ndata generation framework that enables scalable, diverse, and high-quality\nreal-world data collection with minimal human supervision. FieldGen decomposes\nmanipulation into two stages: a pre-manipulation phase, allowing trajectory\ndiversity, and a fine manipulation phase requiring expert precision. Human\ndemonstrations capture key contact and pose information, after which an\nattraction field automatically generates diverse trajectories converging to\nsuccessful configurations. This decoupled design combines scalable trajectory\ndiversity with precise supervision. Moreover, FieldGen-Reward augments\ngenerated data with reward annotations to further enhance policy learning.\nExperiments demonstrate that policies trained with FieldGen achieve higher\nsuccess rates and improved stability compared to teleoperation-based baselines,\nwhile significantly reducing human effort in long-term real-world data\ncollection. Webpage is available at https://fieldgen.github.io/.",
    "published": "2025-10-23T17:47:12Z",
    "updated": "2025-10-28T17:10:50Z",
    "link": "http://arxiv.org/pdf/2510.20774v2.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "authors": [
      "Wenhao Wang",
      "Kehe Ye",
      "Xinyu Zhou",
      "Tianxing Chen",
      "Cao Min",
      "Qiaoming Zhu",
      "Xiaokang Yang",
      "Ping Luo",
      "Yongjian Shen",
      "Yang Yang",
      "Maoqing Yao",
      "Yao Mu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24643v1",
    "title": "The Cost of Robustness: Tighter Bounds on Parameter Complexity for\n  Robust Memorization in ReLU Nets",
    "summary": "We study the parameter complexity of robust memorization for $\\mathrm{ReLU}$\nnetworks: the number of parameters required to interpolate any given dataset\nwith $\\epsilon$-separation between differently labeled points, while ensuring\npredictions remain consistent within a $\\mu$-ball around each training sample.\nWe establish upper and lower bounds on the parameter count as a function of the\nrobustness ratio $\\rho = \\mu / \\epsilon$. Unlike prior work, we provide a\nfine-grained analysis across the entire range $\\rho \\in (0,1)$ and obtain\ntighter upper and lower bounds that improve upon existing results. Our findings\nreveal that the parameter complexity of robust memorization matches that of\nnon-robust memorization when $\\rho$ is small, but grows with increasing $\\rho$.",
    "published": "2025-10-28T17:09:43Z",
    "updated": "2025-10-28T17:09:43Z",
    "link": "http://arxiv.org/pdf/2510.24643v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Yujun Kim",
      "Chaewon Moon",
      "Chulhee Yun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24639v1",
    "title": "Causal Ordering for Structure Learning From Time Series",
    "summary": "Predicting causal structure from time series data is crucial for\nunderstanding complex phenomena in physiology, brain connectivity, climate\ndynamics, and socio-economic behaviour. Causal discovery in time series is\nhindered by the combinatorial complexity of identifying true causal\nrelationships, especially as the number of variables and time points grow. A\ncommon approach to simplify the task is the so-called ordering-based methods.\nTraditional ordering methods inherently limit the representational capacity of\nthe resulting model. In this work, we fix this issue by leveraging multiple\nvalid causal orderings, instead of a single one as standard practice. We\npropose DOTS (Diffusion Ordered Temporal Structure), using diffusion-based\ncausal discovery for temporal data. By integrating multiple orderings, DOTS\neffectively recovers the transitive closure of the underlying directed acyclic\ngraph, mitigating spurious artifacts inherent in single-ordering approaches. We\nformalise the problem under standard assumptions such as stationarity and the\nadditive noise model, and leverage score matching with diffusion processes to\nenable efficient Hessian estimation. Extensive experiments validate the\napproach. Empirical evaluations on synthetic and real-world datasets\ndemonstrate that DOTS outperforms state-of-the-art baselines, offering a\nscalable and robust approach to temporal causal discovery. On synthetic\nbenchmarks ($d{=}\\!3-\\!6$ variables, $T{=}200\\!-\\!5{,}000$ samples), DOTS\nimproves mean window-graph $F1$ from $0.63$ (best baseline) to $0.81$. On the\nCausalTime real-world benchmark ($d{=}20\\!-\\!36$), while baselines remain the\nbest on individual datasets, DOTS attains the highest average summary-graph\n$F1$ while halving runtime relative to graph-optimisation methods. These\nresults establish DOTS as a scalable and accurate solution for temporal causal\ndiscovery.",
    "published": "2025-10-28T17:06:15Z",
    "updated": "2025-10-28T17:06:15Z",
    "link": "http://arxiv.org/pdf/2510.24639v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Pedro P. Sanchez",
      "Damian Machlanski",
      "Steven McDonagh",
      "Sotirios A. Tsaftaris"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24637v1",
    "title": "All in one timestep: Enhancing Sparsity and Energy efficiency in\n  Multi-level Spiking Neural Networks",
    "summary": "Spiking Neural Networks (SNNs) are one of the most promising bio-inspired\nneural networks models and have drawn increasing attention in recent years. The\nevent-driven communication mechanism of SNNs allows for sparse and\ntheoretically low-power operations on dedicated neuromorphic hardware. However,\nthe binary nature of instantaneous spikes also leads to considerable\ninformation loss in SNNs, resulting in accuracy degradation. To address this\nissue, we propose a multi-level spiking neuron model able to provide both\nlow-quantization error and minimal inference latency while approaching the\nperformance of full precision Artificial Neural Networks (ANNs). Experimental\nresults with popular network architectures and datasets, show that multi-level\nspiking neurons provide better information compression, allowing therefore a\nreduction in latency without performance loss. When compared to binary SNNs on\nimage classification scenarios, multi-level SNNs indeed allow reducing by 2 to\n3 times the energy consumption depending on the number of quantization\nintervals. On neuromorphic data, our approach allows us to drastically reduce\nthe inference latency to 1 timestep, which corresponds to a compression factor\nof 10 compared to previously published results. At the architectural level, we\npropose a new residual architecture that we call Sparse-ResNet. Through a\ncareful analysis of the spikes propagation in residual connections we highlight\na spike avalanche effect, that affects most spiking residual architectures.\nUsing our Sparse-ResNet architecture, we can provide state-of-the-art accuracy\nresults in image classification while reducing by more than 20% the network\nactivity compared to the previous spiking ResNets.",
    "published": "2025-10-28T17:03:33Z",
    "updated": "2025-10-28T17:03:33Z",
    "link": "http://arxiv.org/pdf/2510.24637v1.pdf",
    "category": [
      "cs.NE",
      "cs.AI"
    ],
    "authors": [
      "Andrea Castagnetti",
      "Alain Pegatoquet",
      "BenoÃ®t Miramond"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.13499v3",
    "title": "Reproducible workflow for online AI in digital health",
    "summary": "Online artificial intelligence (AI) algorithms are an important component of\ndigital health interventions. These online algorithms are designed to\ncontinually learn and improve their performance as streaming data is collected\non individuals. Deploying online AI presents a key challenge: balancing\nadaptability of online AI with reproducibility. Online AI in digital\ninterventions is a rapidly evolving area, driven by advances in algorithms,\nsensors, software, and devices. Digital health intervention development and\ndeployment is a continuous process, where implementation - including the AI\ndecision-making algorithm - is interspersed with cycles of re-development and\noptimization. Each deployment informs the next, making iterative deployment a\ndefining characteristic of this field. This iterative nature underscores the\nimportance of reproducibility: data collected across deployments must be\naccurately stored to have scientific utility, algorithm behavior must be\nauditable, and results must be comparable over time to facilitate scientific\ndiscovery and trustworthy refinement. This paper proposes a reproducible\nscientific workflow for developing, deploying, and analyzing online AI\ndecision-making algorithms in digital health interventions. Grounded in\npractical experience from multiple real-world deployments, this workflow\naddresses key challenges to reproducibility across all phases of the online AI\nalgorithm development life-cycle.",
    "published": "2025-09-16T19:55:25Z",
    "updated": "2025-10-28T17:00:42Z",
    "link": "http://arxiv.org/pdf/2509.13499v3.pdf",
    "category": [
      "cs.CY",
      "cs.AI"
    ],
    "authors": [
      "Susobhan Ghosh",
      "Bhanu T. Gullapalli",
      "Daiqi Gao",
      "Asim Gazi",
      "Anna Trella",
      "Ziping Xu",
      "Kelly Zhang",
      "Susan A. Murphy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24619v1",
    "title": "Zero-Shot Cross-Lingual Transfer using Prefix-Based Adaptation",
    "summary": "With the release of new large language models (LLMs) like Llama and Mistral,\nzero-shot cross-lingual transfer has become increasingly feasible due to their\nmultilingual pretraining and strong generalization capabilities. However,\nadapting these decoder-only LLMs to new tasks across languages remains\nchallenging. While parameter-efficient fine-tuning (PeFT) techniques like\nLow-Rank Adaptation (LoRA) are widely used, prefix-based techniques such as\nsoft prompt tuning, prefix tuning, and Llama Adapter are less explored,\nespecially for zero-shot transfer in decoder-only models. We present a\ncomprehensive study of three prefix-based methods for zero-shot cross-lingual\ntransfer from English to 35+ high- and low-resource languages. Our analysis\nfurther explores transfer across linguistic families and scripts, as well as\nthe impact of scaling model sizes from 1B to 24B. With Llama 3.1 8B, prefix\nmethods outperform LoRA-baselines by up to 6% on the Belebele benchmark.\nSimilar improvements were observed with Mistral v0.3 7B as well. Despite using\nonly 1.23M learning parameters with prefix tuning, we achieve consistent\nimprovements across diverse benchmarks. These findings highlight the potential\nof prefix-based techniques as an effective and scalable alternative to LoRA,\nparticularly in low-resource multilingual settings.",
    "published": "2025-10-28T16:48:03Z",
    "updated": "2025-10-28T16:48:03Z",
    "link": "http://arxiv.org/pdf/2510.24619v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7"
    ],
    "authors": [
      "Snegha A",
      "Sayambhu Sen",
      "Piyush Singh Pasi",
      "Abhishek Singhania",
      "Preethi Jyothi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.15737v4",
    "title": "TableTime: Reformulating Time Series Classification as Training-Free\n  Table Understanding with Large Language Models",
    "summary": "Large language models (LLMs) have demonstrated their effectiveness in\nmultivariate time series classification (MTSC). Effective adaptation of LLMs\nfor MTSC necessitates informative data representations. Existing LLM-based\nmethods directly encode embeddings for time series within the latent space of\nLLMs from scratch to align with semantic space of LLMs. Despite their\neffectiveness, we reveal that these methods conceal three inherent bottlenecks:\n(1) they struggle to encode temporal and channel-specific information in a\nlossless manner, both of which are critical components of multivariate time\nseries; (2) it is much difficult to align the learned representation space with\nthe semantic space of the LLMs; (3) they require task-specific retraining,\nwhich is both computationally expensive and labor-intensive. To bridge these\ngaps, we propose TableTime, which reformulates MTSC as a table understanding\ntask. Specifically, TableTime introduces the following strategies: (1) convert\nmultivariate time series into a tabular form, thus minimizing information loss\nto the greatest extent; (2) represent tabular time series in text format to\nachieve natural alignment with the semantic space of LLMs; (3) design a\nreasoning framework that integrates contextual text information, neighborhood\nassistance, multi-path inference and problem decomposition to enhance the\nreasoning ability of LLMs and realize zero-shot classification. Extensive\nexperiments performed on 10 publicly representative datasets from UEA archive\nverify the superiorities of the TableTime.",
    "published": "2024-11-24T07:02:32Z",
    "updated": "2025-10-28T16:23:53Z",
    "link": "http://arxiv.org/pdf/2411.15737v4.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Jiahao Wang",
      "Mingyue Cheng",
      "Qingyang Mao",
      "Yitong Zhou",
      "Daoyu Wang",
      "Qi Liu",
      "Feiyang Xu",
      "Xin Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23458v2",
    "title": "BrowseConf: Confidence-Guided Test-Time Scaling for Web Agents",
    "summary": "Confidence in LLMs is a useful indicator of model uncertainty and answer\nreliability. Existing work mainly focused on single-turn scenarios, while\nresearch on confidence in complex multi-turn interactions is limited. In this\npaper, we investigate whether LLM-based search agents have the ability to\ncommunicate their own confidence through verbalized confidence scores after\nlong sequences of actions, a significantly more challenging task compared to\noutputting confidence in a single interaction. Experimenting on open-source\nagentic models, we first find that models exhibit much higher task accuracy at\nhigh confidence while having near-zero accuracy when confidence is low. Based\non this observation, we propose Test-Time Scaling (TTS) methods that use\nconfidence scores to determine answer quality, encourage the model to try again\nuntil reaching a satisfactory confidence level. Results show that our proposed\nmethods significantly reduce token consumption while demonstrating competitive\nperformance compared to baseline fixed budget TTS methods.",
    "published": "2025-10-27T15:58:51Z",
    "updated": "2025-10-28T16:23:04Z",
    "link": "http://arxiv.org/pdf/2510.23458v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Litu Ou",
      "Kuan Li",
      "Huifeng Yin",
      "Liwen Zhang",
      "Zhongwang Zhang",
      "Xixi Wu",
      "Rui Ye",
      "Zile Qiao",
      "Pengjun Xie",
      "Jingren Zhou",
      "Yong Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.21729v2",
    "title": "CustomIR: Unsupervised Fine-Tuning of Dense Embeddings for Known\n  Document Corpora",
    "summary": "Dense embedding models have become critical for modern information retrieval,\nparticularly in RAG pipelines, but their performance often degrades when\napplied to specialized corpora outside their pre-training distribution. To\naddress thi we introduce CustomIR, a framework for unsupervised adaptation of\npre-trained language embedding models to domain-specific corpora using\nsynthetically generated query-document pairs. CustomIR leverages large language\nmodels (LLMs) to create diverse queries grounded in a known target corpus,\npaired with LLM-verified hard negatives, eliminating the need for costly human\nannotation. Experiments on enterprise email and messaging datasets show that\nCustomIR consistently improves retrieval effectiveness with small models\ngaining up to 2.3 points in Recall@10. This performance increase allows these\nsmall models to rival the performance of much larger alternatives, allowing for\ncheaper RAG deployments. These results highlight that targeted synthetic\nfine-tuning offers a scalable and cost-efficient strategy for increasing\ndomain-specific performance.",
    "published": "2025-09-30T00:25:47Z",
    "updated": "2025-10-28T16:15:47Z",
    "link": "http://arxiv.org/pdf/2510.21729v2.pdf",
    "category": [
      "cs.IR",
      "cs.AI"
    ],
    "authors": [
      "Nathan Paull"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24574v1",
    "title": "DistDF: Time-Series Forecasting Needs Joint-Distribution Wasserstein\n  Alignment",
    "summary": "Training time-series forecast models requires aligning the conditional\ndistribution of model forecasts with that of the label sequence. The standard\ndirect forecast (DF) approach resorts to minimize the conditional negative\nlog-likelihood of the label sequence, typically estimated using the mean\nsquared error. However, this estimation proves to be biased in the presence of\nlabel autocorrelation. In this paper, we propose DistDF, which achieves\nalignment by alternatively minimizing a discrepancy between the conditional\nforecast and label distributions. Because conditional discrepancies are\ndifficult to estimate from finite time-series observations, we introduce a\nnewly proposed joint-distribution Wasserstein discrepancy for time-series\nforecasting, which provably upper bounds the conditional discrepancy of\ninterest. This discrepancy admits tractable, differentiable estimation from\nempirical samples and integrates seamlessly with gradient-based training.\nExtensive experiments show that DistDF improves the performance diverse\nforecast models and achieves the state-of-the-art forecasting performance. Code\nis available at https://anonymous.4open.science/r/DistDF-F66B.",
    "published": "2025-10-28T16:09:59Z",
    "updated": "2025-10-28T16:09:59Z",
    "link": "http://arxiv.org/pdf/2510.24574v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Hao Wang",
      "Licheng Pan",
      "Yuan Lu",
      "Zhixuan Chu",
      "Xiaoxi Li",
      "Shuting He",
      "Zhichao Chen",
      "Haoxuan Li",
      "Qingsong Wen",
      "Zhouchen Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24561v1",
    "title": "LoRA-DA: Data-Aware Initialization for Low-Rank Adaptation via\n  Asymptotic Analysis",
    "summary": "With the widespread adoption of LLMs, LoRA has become a dominant method for\nPEFT, and its initialization methods have attracted increasing attention.\nHowever, existing methods have notable limitations: many methods do not\nincorporate target-domain data, while gradient-based methods exploit data only\nat a shallow level by relying on one-step gradient decomposition, which remains\nunsatisfactory due to the weak empirical performance of the one-step\nfine-tuning model that serves as their basis, as well as the fact that these\nmethods either lack a rigorous theoretical foundation or depend heavily on\nrestrictive isotropic assumptions. In this paper, we establish a theoretical\nframework for data-aware LoRA initialization based on asymptotic analysis.\nStarting from a general optimization objective that minimizes the expectation\nof the parameter discrepancy between the fine-tuned and target models, we\nderive an optimization problem with two components: a bias term, which is\nrelated to the parameter distance between the fine-tuned and target models, and\nis approximated using a Fisher-gradient formulation to preserve anisotropy; and\na variance term, which accounts for the uncertainty introduced by sampling\nstochasticity through the Fisher information. By solving this problem, we\nobtain an optimal initialization strategy for LoRA. Building on this\ntheoretical framework, we develop an efficient algorithm, LoRA-DA, which\nestimates the terms in the optimization problem from a small set of target\ndomain samples and obtains the optimal LoRA initialization. Empirical results\nacross multiple benchmarks demonstrate that LoRA-DA consistently improves final\naccuracy over existing initialization methods. Additional studies show faster,\nmore stable convergence, robustness across ranks, and only a small\ninitialization overhead for LoRA-DA. The source code will be released upon\npublication.",
    "published": "2025-10-28T15:55:36Z",
    "updated": "2025-10-28T15:55:36Z",
    "link": "http://arxiv.org/pdf/2510.24561v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Qingyue Zhang",
      "Chang Chu",
      "Tianren Peng",
      "Qi Li",
      "Xiangyang Luo",
      "Zhihao Jiang",
      "Shao-Lun Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.22931v2",
    "title": "Robust Uncertainty Quantification for Self-Evolving Large Language\n  Models via Continual Domain Pretraining",
    "summary": "Continual Learning (CL) is essential for enabling self-evolving large\nlanguage models (LLMs) to adapt and remain effective amid rapid knowledge\ngrowth. Yet, despite its importance, little attention has been given to\nestablishing statistical reliability guarantees for LLMs under CL, particularly\nin the setting of continual domain pretraining (CDP). Conformal Prediction (CP)\nhas shown promise in offering correctness guarantees for LLMs, but it faces\nmajor challenges in CDP: testing data often stems from unknown or shifting\ndomain distributions, under which CP may no longer provide valid guarantees.\nMoreover, when high coverage is required, CP can yield excessively large\nprediction sets for unanswerable queries, reducing informativeness. To address\nthese challenges, we introduce an adaptive rejection and non-exchangeable CP\nframework. Our method first estimates the distribution of questions across\ndomains in the test set using transformer-based clustering, then reweights or\nresamples the calibration data accordingly. Building on this, adaptive\nrejection CP allows the LLM to selectively abstain from answering when its\nconfidence or competence shifts significantly. Extensive experiments\ndemonstrate that our framework enhances both the effectiveness and reliability\nof CP under CDP scenarios. Our code is available at:\nhttps://anonymous.4open.science/r/CPCL-8C12/",
    "published": "2025-10-27T02:15:51Z",
    "updated": "2025-10-28T15:51:13Z",
    "link": "http://arxiv.org/pdf/2510.22931v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Xiaofan Zhou",
      "Lu Cheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24551v1",
    "title": "Generative AI for Healthcare: Fundamentals, Challenges, and Perspectives",
    "summary": "Generative Artificial Intelligence (GenAI) is taking the world by storm. It\npromises transformative opportunities for advancing and disrupting existing\npractices, including healthcare. From large language models (LLMs) for clinical\nnote synthesis and conversational assistance to multimodal systems that\nintegrate medical imaging, electronic health records, and genomic data for\ndecision support, GenAI is transforming the practice of medicine and the\ndelivery of healthcare, such as diagnosis and personalized treatments, with\ngreat potential in reducing the cognitive burden on clinicians, thereby\nimproving overall healthcare delivery. However, GenAI deployment in healthcare\nrequires an in-depth understanding of healthcare tasks and what can and cannot\nbe achieved. In this paper, we propose a data-centric paradigm in the design\nand deployment of GenAI systems for healthcare. Specifically, we reposition the\ndata life cycle by making the medical data ecosystem as the foundational\nsubstrate for generative healthcare systems. This ecosystem is designed to\nsustainably support the integration, representation, and retrieval of diverse\nmedical data and knowledge. With effective and efficient data processing\npipelines, such as semantic vector search and contextual querying, it enables\nGenAI-powered operations for upstream model components and downstream clinical\napplications. Ultimately, it not only supplies foundation models with\nhigh-quality, multimodal data for large-scale pretraining and domain-specific\nfine-tuning, but also serves as a knowledge retrieval backend to support\ntask-specific inference via the agentic layer. The ecosystem enables the\ndeployment of GenAI for high-quality and effective healthcare delivery.",
    "published": "2025-10-28T15:47:44Z",
    "updated": "2025-10-28T15:47:44Z",
    "link": "http://arxiv.org/pdf/2510.24551v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Gang Chen",
      "Changshuo Liu",
      "Gene Anne Ooi",
      "Marcus Tan",
      "Zhongle Xie",
      "Jianwei Yin",
      "James Wei Luen Yip",
      "Wenqiao Zhang",
      "Jiaqi Zhu",
      "Beng Chin Ooi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.18976v3",
    "title": "GraSS: Scalable Data Attribution with Gradient Sparsification and Sparse\n  Projection",
    "summary": "Gradient-based data attribution methods, such as influence functions, are\ncritical for understanding the impact of individual training samples without\nrequiring repeated model retraining. However, their scalability is often\nlimited by the high computational and memory costs associated with per-sample\ngradient computation. In this work, we propose GraSS, a novel gradient\ncompression algorithm and its variants FactGraSS for linear layers\nspecifically, that explicitly leverage the inherent sparsity of per-sample\ngradients to achieve sub-linear space and time complexity. Extensive\nexperiments demonstrate the effectiveness of our approach, achieving\nsubstantial speedups while preserving data influence fidelity. In particular,\nFactGraSS achieves up to 165% faster throughput on billion-scale models\ncompared to the previous state-of-the-art baselines. Our code is publicly\navailable at https://github.com/TRAIS-Lab/GraSS.",
    "published": "2025-05-25T04:58:57Z",
    "updated": "2025-10-28T15:46:13Z",
    "link": "http://arxiv.org/pdf/2505.18976v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Pingbang Hu",
      "Joseph Melkonian",
      "Weijing Tang",
      "Han Zhao",
      "Jiaqi W. Ma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24534v1",
    "title": "Quantum-Resistant Networks Using Post-Quantum Cryptography",
    "summary": "Quantum networks rely on both quantum and classical channels for coordinated\noperation. Current architectures employ entanglement distribution and key\nexchange over quantum channels but often assume that classical communication is\nsufficiently secure. In practice, classical channels protected by traditional\ncryptography remain vulnerable to quantum adversaries, since large-scale\nquantum computers could break widely used public-key schemes and reduce the\neffective security of symmetric cryptography. This perspective presents a\nquantum-resistant network architecture that secures classical communication\nwith post-quantum cryptographic techniques while supporting entanglement-based\ncommunication over quantum channels. Beyond cryptographic protection, the\nframework incorporates continuous monitoring of both quantum and classical\nlayers, together with orchestration across heterogeneous infrastructures, to\nensure end-to-end security. Collectively, these mechanisms provide a pathway\ntoward scalable, robust, and secure quantum networks that remain dependable\nagainst both classical and quantum-era threats.",
    "published": "2025-10-28T15:39:12Z",
    "updated": "2025-10-28T15:39:12Z",
    "link": "http://arxiv.org/pdf/2510.24534v1.pdf",
    "category": [
      "quant-ph",
      "cs.AI",
      "cs.CR"
    ],
    "authors": [
      "Xin Jin",
      "Nitish Kumar Chandra",
      "Mohadeseh Azari",
      "Kaushik P. Seshadreesan",
      "Junyu Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24528v1",
    "title": "From Cross-Task Examples to In-Task Prompts: A Graph-Based\n  Pseudo-Labeling Framework for In-context Learning",
    "summary": "The capability of in-context learning (ICL) enables large language models\n(LLMs) to perform novel tasks without parameter updates by conditioning on a\nfew input-output examples. However, collecting high-quality examples for new or\nchallenging tasks can be costly and labor-intensive. In this work, we propose a\ncost-efficient two-stage pipeline that reduces reliance on LLMs for data\nlabeling. Our approach first leverages readily available cross-task examples to\nprompt an LLM and pseudo-label a small set of target task instances. We then\nintroduce a graph-based label propagation method that spreads label information\nto the remaining target examples without additional LLM queries. The resulting\nfully pseudo-labeled dataset is used to construct in-task demonstrations for\nICL. This pipeline combines the flexibility of cross-task supervision with the\nscalability of LLM-free propagation. Experiments across five tasks demonstrate\nthat our method achieves strong performance while lowering labeling costs.",
    "published": "2025-10-28T15:37:51Z",
    "updated": "2025-10-28T15:37:51Z",
    "link": "http://arxiv.org/pdf/2510.24528v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Zihan Chen",
      "Song Wang",
      "Xingbo Fu",
      "Chengshuai Shi",
      "Zhenyu Lei",
      "Cong Shen",
      "Jundong Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24519v1",
    "title": "Audio Signal Processing Using Time Domain Mel-Frequency Wavelet\n  Coefficient",
    "summary": "Extracting features from the speech is the most critical process in speech\nsignal processing. Mel Frequency Cepstral Coefficients (MFCC) are the most\nwidely used features in the majority of the speaker and speech recognition\napplications, as the filtering in this feature is similar to the filtering\ntaking place in the human ear. But the main drawback of this feature is that it\nprovides only the frequency information of the signal but does not provide the\ninformation about at what time which frequency is present. The wavelet\ntransform, with its flexible time-frequency window, provides time and frequency\ninformation of the signal and is an appropriate tool for the analysis of\nnon-stationary signals like speech. On the other hand, because of its uniform\nfrequency scaling, a typical wavelet transform may be less effective in\nanalysing speech signals, have poorer frequency resolution in low frequencies,\nand be less in line with human auditory perception. Hence, it is necessary to\ndevelop a feature that incorporates the merits of both MFCC and wavelet\ntransform. A great deal of studies are trying to combine both these features.\nThe present Wavelet Transform based Mel-scaled feature extraction methods\nrequire more computation when a wavelet transform is applied on top of\nMel-scale filtering, since it adds extra processing steps. Here we are\nproposing a method to extract Mel scale features in time domain combining the\nconcept of wavelet transform, thus reducing the computational burden of\ntime-frequency conversion and the complexity of wavelet extraction. Combining\nour proposed Time domain Mel frequency Wavelet Coefficient(TMFWC) technique\nwith the reservoir computing methodology has significantly improved the\nefficiency of audio signal processing.",
    "published": "2025-10-28T15:31:52Z",
    "updated": "2025-10-28T15:31:52Z",
    "link": "http://arxiv.org/pdf/2510.24519v1.pdf",
    "category": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "authors": [
      "Rinku Sebastian",
      "Simon O'Keefe",
      "Martin Trefzer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.00913v2",
    "title": "$Î²$-DQN: Improving Deep Q-Learning By Evolving the Behavior",
    "summary": "While many sophisticated exploration methods have been proposed, their lack\nof generality and high computational cost often lead researchers to favor\nsimpler methods like $\\epsilon$-greedy. Motivated by this, we introduce\n$\\beta$-DQN, a simple and efficient exploration method that augments the\nstandard DQN with a behavior function $\\beta$. This function estimates the\nprobability that each action has been taken at each state. By leveraging\n$\\beta$, we generate a population of diverse policies that balance exploration\nbetween state-action coverage and overestimation bias correction. An adaptive\nmeta-controller is designed to select an effective policy for each episode,\nenabling flexible and explainable exploration. $\\beta$-DQN is straightforward\nto implement and adds minimal computational overhead to the standard DQN.\nExperiments on both simple and challenging exploration domains show that\n$\\beta$-DQN outperforms existing baseline methods across a wide range of tasks,\nproviding an effective solution for improving exploration in deep reinforcement\nlearning.",
    "published": "2025-01-01T18:12:18Z",
    "updated": "2025-10-28T15:26:34Z",
    "link": "http://arxiv.org/pdf/2501.00913v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Hongming Zhang",
      "Fengshuo Bai",
      "Chenjun Xiao",
      "Chao Gao",
      "Bo Xu",
      "Martin MÃ¼ller"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.15545v2",
    "title": "TokenTiming: A Dynamic Alignment Method for Universal Speculative\n  Decoding Model Pairs",
    "summary": "Accelerating the inference of large language models (LLMs) has been a\ncritical challenge in generative AI. Speculative decoding (SD) substantially\nimproves LLM inference efficiency. However, its utility is limited by a\nfundamental constraint: the draft and target models must share the same\nvocabulary, thus limiting the herd of available draft models and often\nnecessitating the training of a new model from scratch. Inspired by Dynamic\nTime Warping (DTW), a classic algorithm for aligning time series, we propose\nthe algorithm TokenTiming for universal speculative decoding. It operates by\nre-encoding the draft token sequence to get a new target token sequence, and\nthen uses DTW to build a mapping to transfer the probability distributions for\nspeculative sampling. Benefiting from this, our method accommodates mismatched\nvocabularies and works with any off-the-shelf models without retraining and\nmodification. We conduct comprehensive experiments on various tasks,\ndemonstrating 1.57x speedup. This work enables a universal approach for draft\nmodel selection, making SD a more versatile and practical tool for LLM\nacceleration.",
    "published": "2025-10-17T11:25:36Z",
    "updated": "2025-10-28T15:23:35Z",
    "link": "http://arxiv.org/pdf/2510.15545v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Sibo Xiao",
      "Jinyuan Fu",
      "Zhongle Xie",
      "Lidan Shou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.21293v2",
    "title": "Understanding AI Trustworthiness: A Scoping Review of AIES & FAccT\n  Articles",
    "summary": "Background: Trustworthy AI serves as a foundational pillar for two major AI\nethics conferences: AIES and FAccT. However, current research often adopts\ntechno-centric approaches, focusing primarily on technical attributes such as\nreliability, robustness, and fairness, while overlooking the sociotechnical\ndimensions critical to understanding AI trustworthiness in real-world contexts.\n  Objectives: This scoping review aims to examine how the AIES and FAccT\ncommunities conceptualize, measure, and validate AI trustworthiness,\nidentifying major gaps and opportunities for advancing a holistic understanding\nof trustworthy AI systems.\n  Methods: We conduct a scoping review of AIES and FAccT conference proceedings\nto date, systematically analyzing how trustworthiness is defined,\noperationalized, and applied across different research domains. Our analysis\nfocuses on conceptualization approaches, measurement methods, verification and\nvalidation techniques, application areas, and underlying values.\n  Results: While significant progress has been made in defining technical\nattributes such as transparency, accountability, and robustness, our findings\nreveal critical gaps. Current research often predominantly emphasizes technical\nprecision at the expense of social and ethical considerations. The\nsociotechnical nature of AI systems remains less explored and trustworthiness\nemerges as a contested concept shaped by those with the power to define it.\n  Conclusions: An interdisciplinary approach combining technical rigor with\nsocial, cultural, and institutional considerations is essential for advancing\ntrustworthy AI. We propose actionable measures for the AI ethics community to\nadopt holistic frameworks that genuinely address the complex interplay between\nAI systems and society, ultimately promoting responsible technological\ndevelopment that benefits all stakeholders.",
    "published": "2025-10-24T09:40:38Z",
    "updated": "2025-10-28T15:20:05Z",
    "link": "http://arxiv.org/pdf/2510.21293v2.pdf",
    "category": [
      "cs.AI",
      "cs.HC"
    ],
    "authors": [
      "Siddharth Mehrotra",
      "Jin Huang",
      "Xuelong Fu",
      "Roel Dobbe",
      "Clara I. SÃ¡nchez",
      "Maarten de Rijke"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24503v1",
    "title": "Local Performance vs. Out-of-Distribution Generalization: An Empirical\n  Analysis of Personalized Federated Learning in Heterogeneous Data\n  Environments",
    "summary": "In the context of Federated Learning with heterogeneous data environments,\nlocal models tend to converge to their own local model optima during local\ntraining steps, deviating from the overall data distributions. Aggregation of\nthese local updates, e.g., with FedAvg, often does not align with the global\nmodel optimum (client drift), resulting in an update that is suboptimal for\nmost clients. Personalized Federated Learning approaches address this challenge\nby exclusively focusing on the average local performances of clients' models on\ntheir own data distribution. Generalization to out-of-distribution samples,\nwhich is a substantial benefit of FedAvg and represents a significant component\nof robustness, appears to be inadequately incorporated into the assessment and\nevaluation processes. This study involves a thorough evaluation of Federated\nLearning approaches, encompassing both their local performance and their\ngeneralization capabilities. Therefore, we examine different stages within a\nsingle communication round to enable a more nuanced understanding of the\nconsidered metrics. Furthermore, we propose and incorporate a modified approach\nof FedAvg, designated as Federated Learning with Individualized Updates (FLIU),\nextending the algorithm by a straightforward individualization step with an\nadaptive personalization factor. We evaluate and compare the approaches\nempirically using MNIST and CIFAR-10 under various distributional conditions,\nincluding benchmark IID and pathological non-IID, as well as additional novel\ntest environments with Dirichlet distribution specifically developed to stress\nthe algorithms on complex data heterogeneity.",
    "published": "2025-10-28T15:15:14Z",
    "updated": "2025-10-28T15:15:14Z",
    "link": "http://arxiv.org/pdf/2510.24503v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.DC",
      "cs.MA"
    ],
    "authors": [
      "Mortesa Hussaini",
      "Jan TheiÃ",
      "Anthony Stein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24498v1",
    "title": "Design and Optimization of Cloud Native Homomorphic Encryption Workflows\n  for Privacy-Preserving ML Inference",
    "summary": "As machine learning (ML) models become increasingly deployed through cloud\ninfrastructures, the confidentiality of user data during inference poses a\nsignificant security challenge. Homomorphic Encryption (HE) has emerged as a\ncompelling cryptographic technique that enables computation on encrypted data,\nallowing predictions to be generated without decrypting sensitive inputs.\nHowever, the integration of HE within large scale cloud native pipelines\nremains constrained by high computational overhead, orchestration complexity,\nand model compatibility issues.\n  This paper presents a systematic framework for the design and optimization of\ncloud native homomorphic encryption workflows that support privacy-preserving\nML inference. The proposed architecture integrates containerized HE modules\nwith Kubernetes-based orchestration, enabling elastic scaling and parallel\nencrypted computation across distributed environments. Furthermore,\noptimization strategies including ciphertext packing, polynomial modulus\nadjustment, and operator fusion are employed to minimize latency and resource\nconsumption while preserving cryptographic integrity. Experimental results\ndemonstrate that the proposed system achieves up to 3.2times inference\nacceleration and 40% reduction in memory utilization compared to conventional\nHE pipelines. These findings illustrate a practical pathway for deploying\nsecure ML-as-a-Service (MLaaS) systems that guarantee data confidentiality\nunder zero-trust cloud conditions.",
    "published": "2025-10-28T15:13:32Z",
    "updated": "2025-10-28T15:13:32Z",
    "link": "http://arxiv.org/pdf/2510.24498v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Tejaswini Bollikonda"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24497v1",
    "title": "Online neural fusion of distortionless differential beamformers for\n  robust speech enhancement",
    "summary": "Fixed beamforming is widely used in practice since it does not depend on the\nestimation of noise statistics and provides relatively stable performance.\nHowever, a single beamformer cannot adapt to varying acoustic conditions, which\nlimits its interference suppression capability. To address this, adaptive\nconvex combination (ACC) algorithms have been introduced, where the outputs of\nmultiple fixed beamformers are linearly combined to improve robustness.\nNevertheless, ACC often fails in highly non-stationary scenarios, such as\nrapidly moving interference, since its adaptive updates cannot reliably track\nrapid changes. To overcome this limitation, we propose a frame-online neural\nfusion framework for multiple distortionless differential beamformers, which\nestimates the combination weights through a neural network. Compared with\nconventional ACC, the proposed method adapts more effectively to dynamic\nacoustic environments, achieving stronger interference suppression while\nmaintaining the distortionless constraint.",
    "published": "2025-10-28T15:12:48Z",
    "updated": "2025-10-28T15:12:48Z",
    "link": "http://arxiv.org/pdf/2510.24497v1.pdf",
    "category": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "authors": [
      "Yuanhang Qian",
      "Kunlong Zhao",
      "Jilu Jin",
      "Xueqin Luo",
      "Gongping Huang",
      "Jingdong Chen",
      "Jacob Benesty"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.10978v3",
    "title": "Group-in-Group Policy Optimization for LLM Agent Training",
    "summary": "Recent advances in group-based reinforcement learning (RL) have driven\nfrontier large language models (LLMs) in single-turn tasks like mathematical\nreasoning. However, their scalability to multi-turn LLM agent training remains\nlimited. Unlike static tasks, agent-environment interactions unfold over many\nsteps and often yield sparse or delayed rewards, making credit assignment\nacross individual steps significantly more challenging. In this work, we\npropose Group-in-Group Policy Optimization (GiGPO), a novel RL algorithm that\nachieves fine-grained credit assignment for LLM agents while preserving the\nappealing properties of group-based RL: critic-free, low memory, and stable\nconvergence. GiGPO introduces a two-level structure for estimating relative\nadvantage: (i) At the episode-level, GiGPO computes macro relative advantages\nbased on groups of complete trajectories; (ii) At the step-level, GiGPO\nintroduces an anchor state grouping mechanism that retroactively constructs\nstep-level groups by identifying repeated environment states across\ntrajectories. Actions stemming from the same state are grouped together,\nenabling micro relative advantage estimation. This hierarchical structure\neffectively captures both global trajectory quality and local step\neffectiveness without relying on auxiliary models or additional rollouts. We\nevaluate GiGPO on challenging agent benchmarks, including ALFWorld and WebShop,\nas well as tool-integrated reasoning on search-augmented QA tasks, using\nQwen2.5-1.5B/3B/7B-Instruct. Crucially, GiGPO delivers fine-grained per-step\ncredit signals, achieves performance gains of > 12% on ALFWorld and > 9% on\nWebShop over GRPO, and obtains superior performance on QA tasks (42.1% on 3B\nand 47.2% on 7B): all while maintaining the same GPU memory overhead, identical\nLLM rollout, and incurring little to no additional time cost.",
    "published": "2025-05-16T08:26:59Z",
    "updated": "2025-10-28T15:11:36Z",
    "link": "http://arxiv.org/pdf/2505.10978v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Lang Feng",
      "Zhenghai Xue",
      "Tingcong Liu",
      "Bo An"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24495v1",
    "title": "Diffusion Models for Wireless Transceivers: From Pilot-Efficient Channel\n  Estimation to AI-Native 6G Receivers",
    "summary": "With the development of artificial intelligence (AI) techniques, implementing\nAI-based techniques to improve wireless transceivers becomes an emerging\nresearch topic. Within this context, AI-based channel characterization and\nestimation become the focus since these methods have not been solved by\ntraditional methods very well and have become the bottleneck of transceiver\nefficiency in large-scale orthogonal frequency division multiplexing (OFDM)\nsystems. Specifically, by formulating channel estimation as a generative AI\nproblem, generative AI methods such as diffusion models (DMs) can efficiently\ndeal with rough initial estimations and have great potential to cooperate with\ntraditional signal processing methods. This paper focuses on the transceiver\ndesign of OFDM systems based on DMs, provides an illustration of the potential\nof DMs in wireless transceivers, and points out the related research directions\nbrought by DMs. We also provide a proof-of-concept case study of further\nadapting DMs for better wireless receiver performance.",
    "published": "2025-10-28T15:10:11Z",
    "updated": "2025-10-28T15:10:11Z",
    "link": "http://arxiv.org/pdf/2510.24495v1.pdf",
    "category": [
      "eess.SP",
      "cs.AI"
    ],
    "authors": [
      "Yuzhi Yang",
      "Sen Yan",
      "Weijie Zhou",
      "Brahim Mefgouda",
      "Ridong Li",
      "Zhaoyang Zhang",
      "MÃ©rouane Debbah"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24488v1",
    "title": "A word association network methodology for evaluating implicit biases in\n  LLMs compared to humans",
    "summary": "As Large language models (LLMs) become increasingly integrated into our\nlives, their inherent social biases remain a pressing concern. Detecting and\nevaluating these biases can be challenging because they are often implicit\nrather than explicit in nature, so developing evaluation methods that assess\nthe implicit knowledge representations of LLMs is essential. We present a novel\nword association network methodology for evaluating implicit biases in LLMs\nbased on simulating semantic priming within LLM-generated word association\nnetworks. Our prompt-based approach taps into the implicit relational\nstructures encoded in LLMs, providing both quantitative and qualitative\nassessments of bias. Unlike most prompt-based evaluation methods, our method\nenables direct comparisons between various LLMs and humans, providing a\nvaluable point of reference and offering new insights into the alignment of\nLLMs with human cognition. To demonstrate the utility of our methodology, we\napply it to both humans and several widely used LLMs to investigate social\nbiases related to gender, religion, ethnicity, sexual orientation, and\npolitical party. Our results reveal both convergences and divergences between\nLLM and human biases, providing new perspectives on the potential risks of\nusing LLMs. Our methodology contributes to a systematic, scalable, and\ngeneralizable framework for evaluating and comparing biases across multiple\nLLMs and humans, advancing the goal of transparent and socially responsible\nlanguage technologies.",
    "published": "2025-10-28T15:03:18Z",
    "updated": "2025-10-28T15:03:18Z",
    "link": "http://arxiv.org/pdf/2510.24488v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Katherine Abramski",
      "Giulio Rossetti",
      "Massimo Stella"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.08748v4",
    "title": "Mirror Descent and Novel Exponentiated Gradient Algorithms Using\n  Trace-Form Entropies and Deformed Logarithms",
    "summary": "This paper introduces a broad class of Mirror Descent (MD) and Generalized\nExponentiated Gradient (GEG) algorithms derived from trace-form entropies\ndefined via deformed logarithms. Leveraging these generalized entropies yields\nMD \\& GEG algorithms with improved convergence behavior, robustness to\nvanishing and exploding gradients, and inherent adaptability to non-Euclidean\ngeometries through mirror maps. We establish deep connections between these\nmethods and Amari's natural gradient, revealing a unified geometric foundation\nfor additive, multiplicative, and natural gradient updates. Focusing on the\nTsallis, Kaniadakis, Sharma--Taneja--Mittal, and Kaniadakis--Lissia--Scarfone\nentropy families, we show that each entropy induces a distinct Riemannian\nmetric on the parameter space, leading to GEG algorithms that preserve the\nnatural statistical geometry. The tunable parameters of deformed logarithms\nenable adaptive geometric selection, providing enhanced robustness and\nconvergence over classical Euclidean optimization. Overall, our framework\nunifies key first-order MD optimization methods under a single\ninformation-geometric perspective based on generalized Bregman divergences,\nwhere the choice of entropy determines the underlying metric and dual geometric\nstructure.",
    "published": "2025-03-11T10:50:07Z",
    "updated": "2025-10-28T15:01:16Z",
    "link": "http://arxiv.org/pdf/2503.08748v4.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Andrzej Cichocki",
      "Toshihisa Tanaka",
      "Frank Nielsen",
      "Sergio Cruces"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24482v1",
    "title": "Sample-efficient and Scalable Exploration in Continuous-Time RL",
    "summary": "Reinforcement learning algorithms are typically designed for discrete-time\ndynamics, even though the underlying real-world control systems are often\ncontinuous in time. In this paper, we study the problem of continuous-time\nreinforcement learning, where the unknown system dynamics are represented using\nnonlinear ordinary differential equations (ODEs). We leverage probabilistic\nmodels, such as Gaussian processes and Bayesian neural networks, to learn an\nuncertainty-aware model of the underlying ODE. Our algorithm, COMBRL, greedily\nmaximizes a weighted sum of the extrinsic reward and model epistemic\nuncertainty. This yields a scalable and sample-efficient approach to\ncontinuous-time model-based RL. We show that COMBRL achieves sublinear regret\nin the reward-driven setting, and in the unsupervised RL setting (i.e., without\nextrinsic rewards), we provide a sample complexity bound. In our experiments,\nwe evaluate COMBRL in both standard and unsupervised RL settings and\ndemonstrate that it scales better, is more sample-efficient than prior methods,\nand outperforms baselines across several deep RL tasks.",
    "published": "2025-10-28T14:54:12Z",
    "updated": "2025-10-28T14:54:12Z",
    "link": "http://arxiv.org/pdf/2510.24482v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "authors": [
      "Klemens Iten",
      "Lenart Treven",
      "Bhavya Sukhija",
      "Florian DÃ¶rfler",
      "Andreas Krause"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.21142v2",
    "title": "Multimodal Dreaming: A Global Workspace Approach to World Model-Based\n  Reinforcement Learning",
    "summary": "Humans leverage rich internal models of the world to reason about the future,\nimagine counterfactuals, and adapt flexibly to new situations. In Reinforcement\nLearning (RL), world models aim to capture how the environment evolves in\nresponse to the agent's actions, facilitating planning and generalization.\nHowever, typical world models directly operate on the environment variables\n(e.g. pixels, physical attributes), which can make their training slow and\ncumbersome; instead, it may be advantageous to rely on high-level latent\ndimensions that capture relevant multimodal variables. Global Workspace (GW)\nTheory offers a cognitive framework for multimodal integration and information\nbroadcasting in the brain, and recent studies have begun to introduce efficient\ndeep learning implementations of GW. Here, we evaluate the capabilities of an\nRL system combining GW with a world model. We compare our GW-Dreamer with\nvarious versions of the standard PPO and the original Dreamer algorithms. We\nshow that performing the dreaming process (i.e., mental simulation) inside the\nGW latent space allows for training with fewer environment steps. As an\nadditional emergent property, the resulting model (but not its comparison\nbaselines) displays strong robustness to the absence of one of its observation\nmodalities (images or simulation attributes). We conclude that the combination\nof GW with World Models holds great potential for improving decision-making in\nRL agents.",
    "published": "2025-02-28T15:24:17Z",
    "updated": "2025-10-28T14:49:07Z",
    "link": "http://arxiv.org/pdf/2502.21142v2.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "authors": [
      "LÃ©opold MaytiÃ©",
      "Roland Bertin Johannet",
      "Rufin VanRullen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24476v1",
    "title": "Mitigating Hallucination in Large Language Models (LLMs): An\n  Application-Oriented Survey on RAG, Reasoning, and Agentic Systems",
    "summary": "Hallucination remains one of the key obstacles to the reliable deployment of\nlarge language models (LLMs), particularly in real-world applications. Among\nvarious mitigation strategies, Retrieval-Augmented Generation (RAG) and\nreasoning enhancement have emerged as two of the most effective and widely\nadopted approaches, marking a shift from merely suppressing hallucinations to\nbalancing creativity and reliability. However, their synergistic potential and\nunderlying mechanisms for hallucination mitigation have not yet been\nsystematically examined. This survey adopts an application-oriented perspective\nof capability enhancement to analyze how RAG, reasoning enhancement, and their\nintegration in Agentic Systems mitigate hallucinations. We propose a taxonomy\ndistinguishing knowledge-based and logic-based hallucinations, systematically\nexamine how RAG and reasoning address each, and present a unified framework\nsupported by real-world applications, evaluations, and benchmarks.",
    "published": "2025-10-28T14:48:57Z",
    "updated": "2025-10-28T14:48:57Z",
    "link": "http://arxiv.org/pdf/2510.24476v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Yihan Li",
      "Xiyuan Fu",
      "Ghanshyam Verma",
      "Paul Buitelaar",
      "Mingming Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24469v1",
    "title": "Iterative Critique-Refine Framework for Enhancing LLM Personalization",
    "summary": "Personalized text generation requires models not only to produce coherent\ntext but also to align with a target user's style, tone, and topical focus.\nExisting retrieval-augmented approaches such as LaMP and PGraphRAG enrich\nprofiles with user and neighbor histories, but they stop at generation and\noften yield outputs that drift in tone, topic, or style. We present PerFine, a\nunified, training-free critique-refine framework that enhances personalization\nthrough iterative, profile-grounded feedback. In each iteration, an LLM\ngenerator produces a draft conditioned on the retrieved profile, and a critic\nLLM - also conditioned on the same profile - provides structured feedback on\ntone, vocabulary, sentence structure, and topicality. The generator then\nrevises, while a novel knockout strategy retains the stronger draft across\niterations. We further study additional inference-time strategies such as\nBest-of-N and Topic Extraction to balance quality and efficiency. Across Yelp,\nGoodreads, and Amazon datasets, PerFine consistently improves personalization\nover PGraphRAG, with GEval gains of +7-13%, steady improvements over 3-5\nrefinement iterations, and scalability with increasing critic size. These\nresults highlight that post-hoc, profile-aware feedback offers a powerful\nparadigm for personalized LLM generation that is both training-free and\nmodel-agnostic.",
    "published": "2025-10-28T14:36:22Z",
    "updated": "2025-10-28T14:36:22Z",
    "link": "http://arxiv.org/pdf/2510.24469v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "authors": [
      "Durga Prasad Maram",
      "Dhruvin Gandhi",
      "Zonghai Yao",
      "Gayathri Akkinapalli",
      "Franck Dernoncourt",
      "Yu Wang",
      "Ryan A. Rossi",
      "Nesreen K. Ahmed"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24461v1",
    "title": "Adaptive Surrogate Gradients for Sequential Reinforcement Learning in\n  Spiking Neural Networks",
    "summary": "Neuromorphic computing systems are set to revolutionize energy-constrained\nrobotics by achieving orders-of-magnitude efficiency gains, while enabling\nnative temporal processing. Spiking Neural Networks (SNNs) represent a\npromising algorithmic approach for these systems, yet their application to\ncomplex control tasks faces two critical challenges: (1) the non-differentiable\nnature of spiking neurons necessitates surrogate gradients with unclear\noptimization properties, and (2) the stateful dynamics of SNNs require training\non sequences, which in reinforcement learning (RL) is hindered by limited\nsequence lengths during early training, preventing the network from bridging\nits warm-up period.\n  We address these challenges by systematically analyzing surrogate gradient\nslope settings, showing that shallower slopes increase gradient magnitude in\ndeeper layers but reduce alignment with true gradients. In supervised learning,\nwe find no clear preference for fixed or scheduled slopes. The effect is much\nmore pronounced in RL settings, where shallower slopes or scheduled slopes lead\nto a 2.1x improvement in both training and final deployed performance. Next, we\npropose a novel training approach that leverages a privileged guiding policy to\nbootstrap the learning process, while still exploiting online environment\ninteractions with the spiking policy. Combining our method with an adaptive\nslope schedule for a real-world drone position control task, we achieve an\naverage return of 400 points, substantially outperforming prior techniques,\nincluding Behavioral Cloning and TD3BC, which achieve at most --200 points\nunder the same conditions. This work advances both the theoretical\nunderstanding of surrogate gradient learning in SNNs and practical training\nmethodologies for neuromorphic controllers demonstrated in real-world robotic\nsystems.",
    "published": "2025-10-28T14:28:40Z",
    "updated": "2025-10-28T14:28:40Z",
    "link": "http://arxiv.org/pdf/2510.24461v1.pdf",
    "category": [
      "cs.AI",
      "cs.RO"
    ],
    "authors": [
      "Korneel Van den Berghe",
      "Stein Stroobants",
      "Vijay Janapa Reddi",
      "G. C. H. E. de Croon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24459v1",
    "title": "Affordance Representation and Recognition for Autonomous Agents",
    "summary": "The autonomy of software agents is fundamentally dependent on their ability\nto construct an actionable internal world model from the structured data that\ndefines their digital environment, such as the Document Object Model (DOM) of\nweb pages and the semantic descriptions of web services. However, constructing\nthis world model from raw structured data presents two critical challenges: the\nverbosity of raw HTML makes it computationally intractable for direct use by\nfoundation models, while the static nature of hardcoded API integrations\nprevents agents from adapting to evolving services.\n  This paper introduces a pattern language for world modeling from structured\ndata, presenting two complementary architectural patterns. The DOM Transduction\nPattern addresses the challenge of web page complexity by distilling} a\nverbose, raw DOM into a compact, task-relevant representation or world model\noptimized for an agent's reasoning core. Concurrently, the Hypermedia\nAffordances Recognition Pattern enables the agent to dynamically enrich its\nworld model by parsing standardized semantic descriptions to discover and\nintegrate the capabilities of unknown web services at runtime. Together, these\npatterns provide a robust framework for engineering agents that can efficiently\nconstruct and maintain an accurate world model, enabling scalable, adaptive,\nand interoperable automation across the web and its extended resources.",
    "published": "2025-10-28T14:27:28Z",
    "updated": "2025-10-28T14:27:28Z",
    "link": "http://arxiv.org/pdf/2510.24459v1.pdf",
    "category": [
      "cs.AI",
      "cs.MA",
      "cs.SE"
    ],
    "authors": [
      "Habtom Kahsay Gidey",
      "Niklas Huber",
      "Alexander Lenz",
      "Alois Knoll"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.21724v2",
    "title": "OmniResponse: Online Multimodal Conversational Response Generation in\n  Dyadic Interactions",
    "summary": "In this paper, we introduce Online Multimodal Conversational Response\nGeneration (OMCRG), a novel task designed to produce synchronized verbal and\nnon-verbal listener feedback online, based on the speaker's multimodal inputs.\nOMCRG captures natural dyadic interactions and introduces new challenges in\naligning generated audio with listeners' facial responses. To tackle these\nchallenges, we incorporate text as an intermediate modality to connect audio\nand facial responses. We propose OmniResponse, a Multimodal Large Language\nModel (MLLM) that autoregressively generates accurate multimodal listener\nresponses. OmniResponse leverages a pretrained LLM enhanced with two core\ncomponents: Chrono-Text Markup, which precisely timestamps generated text\ntokens, and TempoVoice, a controllable online text-to-speech (TTS) module that\noutputs speech synchronized with facial responses. To advance OMCRG research,\nwe offer ResponseNet, a dataset of 696 detailed dyadic interactions featuring\nsynchronized split-screen videos, multichannel audio, transcripts, and\nannotated facial behaviors. Comprehensive evaluations on ResponseNet\ndemonstrate that OmniResponse outperforms baseline models in terms of semantic\nspeech content, audio-visual synchronization, and generation quality. Our\ndataset, code, and models are publicly available.",
    "published": "2025-05-27T20:12:46Z",
    "updated": "2025-10-28T14:26:23Z",
    "link": "http://arxiv.org/pdf/2505.21724v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "authors": [
      "Cheng Luo",
      "Jianghui Wang",
      "Bing Li",
      "Siyang Song",
      "Bernard Ghanem"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24450v1",
    "title": "Charting the European LLM Benchmarking Landscape: A New Taxonomy and a\n  Set of Best Practices",
    "summary": "While new benchmarks for large language models (LLMs) are being developed\ncontinuously to catch up with the growing capabilities of new models and AI in\ngeneral, using and evaluating LLMs in non-English languages remains a\nlittle-charted landscape. We give a concise overview of recent developments in\nLLM benchmarking, and then propose a new taxonomy for the categorization of\nbenchmarks that is tailored to multilingual or non-English use scenarios. We\nfurther propose a set of best practices and quality standards that could lead\nto a more coordinated development of benchmarks for European languages. Among\nother recommendations, we advocate for a higher language and culture\nsensitivity of evaluation methods.",
    "published": "2025-10-28T14:13:44Z",
    "updated": "2025-10-28T14:13:44Z",
    "link": "http://arxiv.org/pdf/2510.24450v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Å pela Vintar",
      "Taja Kuzman PungerÅ¡ek",
      "Mojca Brglez",
      "Nikola LjubeÅ¡iÄ"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24448v1",
    "title": "Rethinking Visual Intelligence: Insights from Video Pretraining",
    "summary": "Large language models (LLMs) have demonstrated that large-scale pretraining\nenables systems to adapt rapidly to new problems with little supervision in the\nlanguage domain. This success, however, has not translated as effectively to\nthe visual domain, where models, including LLMs, continue to struggle with\ncompositional understanding, sample efficiency, and general-purpose\nproblem-solving. We investigate Video Diffusion Models (VDMs) as a promising\ndirection for bridging this gap. Pretraining on spatiotemporal data endows\nthese models with strong inductive biases for structure and dynamics, which we\nhypothesize can support broad task adaptability. To test this, we design a\ncontrolled evaluation in which both a pretrained LLM and a pretrained VDM are\nequipped with lightweight adapters and presented with tasks in their natural\nmodalities. Across benchmarks including ARC-AGI, ConceptARC, visual games,\nroute planning, and cellular automata, VDMs demonstrate higher data efficiency\nthan their language counterparts. Taken together, our results indicate that\nvideo pretraining offers inductive biases that support progress toward visual\nfoundation models.",
    "published": "2025-10-28T14:12:11Z",
    "updated": "2025-10-28T14:12:11Z",
    "link": "http://arxiv.org/pdf/2510.24448v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "68T07, 68T45, 68T20",
      "I.2.10; I.4.8; I.5.1; I.2.6"
    ],
    "authors": [
      "Pablo Acuaviva",
      "Aram Davtyan",
      "Mariam Hassan",
      "Sebastian Stapf",
      "Ahmad Rahimi",
      "Alexandre Alahi",
      "Paolo Favaro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.10754v2",
    "title": "BNMusic: Blending Environmental Noises into Personalized Music",
    "summary": "While being disturbed by environmental noises, the acoustic masking technique\nis a conventional way to reduce the annoyance in audio engineering that seeks\nto cover up the noises with other dominant yet less intrusive sounds. However,\nmisalignment between the dominant sound and the noise-such as mismatched\ndownbeats-often requires an excessive volume increase to achieve effective\nmasking. Motivated by recent advances in cross-modal generation, in this work,\nwe introduce an alternative method to acoustic masking, aiming to reduce the\nnoticeability of environmental noises by blending them into personalized music\ngenerated based on user-provided text prompts. Following the paradigm of music\ngeneration using mel-spectrogram representations, we propose a Blending Noises\ninto Personalized Music (BNMusic) framework with two key stages. The first\nstage synthesizes a complete piece of music in a mel-spectrogram representation\nthat encapsulates the musical essence of the noise. In the second stage, we\nadaptively amplify the generated music segment to further reduce noise\nperception and enhance the blending effectiveness, while preserving auditory\nquality. Our experiments with comprehensive evaluations on MusicBench,\nEPIC-SOUNDS, and ESC-50 demonstrate the effectiveness of our framework,\nhighlighting the ability to blend environmental noise with rhythmically\naligned, adaptively amplified, and enjoyable music segments, minimizing the\nnoticeability of the noise, thereby improving overall acoustic experiences.\nProject page: https://d-fas.github.io/BNMusic_page/.",
    "published": "2025-06-12T14:39:08Z",
    "updated": "2025-10-28T14:11:45Z",
    "link": "http://arxiv.org/pdf/2506.10754v2.pdf",
    "category": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "authors": [
      "Chi Zuo",
      "Martin B. MÃ¸ller",
      "Pablo MartÃ­nez-Nuevo",
      "Huayang Huang",
      "Yu Wu",
      "Ye Zhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24442v1",
    "title": "Law in Silico: Simulating Legal Society with LLM-Based Agents",
    "summary": "Since real-world legal experiments are often costly or infeasible, simulating\nlegal societies with Artificial Intelligence (AI) systems provides an effective\nalternative for verifying and developing legal theory, as well as supporting\nlegal administration. Large Language Models (LLMs), with their world knowledge\nand role-playing capabilities, are strong candidates to serve as the foundation\nfor legal society simulation. However, the application of LLMs to simulate\nlegal systems remains underexplored. In this work, we introduce Law in Silico,\nan LLM-based agent framework for simulating legal scenarios with individual\ndecision-making and institutional mechanisms of legislation, adjudication, and\nenforcement. Our experiments, which compare simulated crime rates with\nreal-world data, demonstrate that LLM-based agents can largely reproduce\nmacro-level crime trends and provide insights that align with real-world\nobservations. At the same time, micro-level simulations reveal that a\nwell-functioning, transparent, and adaptive legal system offers better\nprotection of the rights of vulnerable individuals.",
    "published": "2025-10-28T14:07:10Z",
    "updated": "2025-10-28T14:07:10Z",
    "link": "http://arxiv.org/pdf/2510.24442v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.MA"
    ],
    "authors": [
      "Yiding Wang",
      "Yuxuan Chen",
      "Fanxu Meng",
      "Xifan Chen",
      "Xiaolei Yang",
      "Muhan Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.16175v2",
    "title": "The Formalism-Implementation Gap in Reinforcement Learning Research",
    "summary": "The last decade has seen an upswing in interest and adoption of reinforcement\nlearning (RL) techniques, in large part due to its demonstrated capabilities at\nperforming certain tasks at \"super-human levels\". This has incentivized the\ncommunity to prioritize research that demonstrates RL agent performance, often\nat the expense of research aimed at understanding their learning dynamics.\nPerformance-focused research runs the risk of overfitting on academic\nbenchmarks -- thereby rendering them less useful -- which can make it difficult\nto transfer proposed techniques to novel problems. Further, it implicitly\ndiminishes work that does not push the performance-frontier, but aims at\nimproving our understanding of these techniques. This paper argues two points:\n(i) RL research should stop focusing solely on demonstrating agent\ncapabilities, and focus more on advancing the science and understanding of\nreinforcement learning; and (ii) we need to be more precise on how our\nbenchmarks map to the underlying mathematical formalisms. We use the popular\nArcade Learning Environment (ALE; Bellemare et al., 2013) as an example of a\nbenchmark that, despite being increasingly considered \"saturated\", can be\neffectively used for developing this understanding, and facilitating the\ndeployment of RL techniques in impactful real-world problems.",
    "published": "2025-10-17T19:35:54Z",
    "updated": "2025-10-28T14:06:41Z",
    "link": "http://arxiv.org/pdf/2510.16175v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Pablo Samuel Castro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24438v1",
    "title": "Can LLMs Write Faithfully? An Agent-Based Evaluation of LLM-generated\n  Islamic Content",
    "summary": "Large language models are increasingly used for Islamic guidance, but risk\nmisquoting texts, misapplying jurisprudence, or producing culturally\ninconsistent responses. We pilot an evaluation of GPT-4o, Ansari AI, and Fanar\non prompts from authentic Islamic blogs. Our dual-agent framework uses a\nquantitative agent for citation verification and six-dimensional scoring (e.g.,\nStructure, Islamic Consistency, Citations) and a qualitative agent for\nfive-dimensional side-by-side comparison (e.g., Tone, Depth, Originality).\nGPT-4o scored highest in Islamic Accuracy (3.93) and Citation (3.38), Ansari AI\nfollowed (3.68, 3.32), and Fanar lagged (2.76, 1.82). Despite relatively strong\nperformance, models still fall short in reliably producing accurate Islamic\ncontent and citations -- a paramount requirement in faith-sensitive writing.\nGPT-4o had the highest mean quantitative score (3.90/5), while Ansari AI led\nqualitative pairwise wins (116/200). Fanar, though trailing, introduces\ninnovations for Islamic and Arabic contexts. This study underscores the need\nfor community-driven benchmarks centering Muslim perspectives, offering an\nearly step toward more reliable AI in Islamic knowledge and other high-stakes\ndomains such as medicine, law, and journalism.",
    "published": "2025-10-28T14:05:55Z",
    "updated": "2025-10-28T14:05:55Z",
    "link": "http://arxiv.org/pdf/2510.24438v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.MA"
    ],
    "authors": [
      "Abdullah Mushtaq",
      "Rafay Naeem",
      "Ezieddin Elmahjub",
      "Ibrahim Ghaznavi",
      "Shawqi Al-Maliki",
      "Mohamed Abdallah",
      "Ala Al-Fuqaha",
      "Junaid Qadir"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.21614v2",
    "title": "Huxley-GÃ¶del Machine: Human-Level Coding Agent Development by an\n  Approximation of the Optimal Self-Improving Machine",
    "summary": "Recent studies operationalize self-improvement through coding agents that\nedit their own codebases. They grow a tree of self-modifications through\nexpansion strategies that favor higher software engineering benchmark\nperformance, assuming that this implies more promising subsequent\nself-modifications. However, we identify a mismatch between the agent's\nself-improvement potential (metaproductivity) and its coding benchmark\nperformance, namely the Metaproductivity-Performance Mismatch. Inspired by\nHuxley's concept of clade, we propose a metric ($\\mathrm{CMP}$) that aggregates\nthe benchmark performances of the descendants of an agent as an indicator of\nits potential for self-improvement. We show that, in our self-improving coding\nagent development setting, access to the true $\\mathrm{CMP}$ is sufficient to\nsimulate how the G\\\"odel Machine would behave under certain assumptions. We\nintroduce the Huxley-G\\\"odel Machine (HGM), which, by estimating $\\mathrm{CMP}$\nand using it as guidance, searches the tree of self-modifications. On SWE-bench\nVerified and Polyglot, HGM outperforms prior self-improving coding agent\ndevelopment methods while using less wall-clock time. Last but not least, HGM\ndemonstrates strong transfer to other coding datasets and large language\nmodels. The agent optimized by HGM on SWE-bench Verified with GPT-5-mini and\nevaluated on SWE-bench Lite with GPT-5 achieves human-level performance,\nmatching the best officially checked results of human-engineered coding agents.\nOur code is available at https://github.com/metauto-ai/HGM.",
    "published": "2025-10-24T16:19:41Z",
    "updated": "2025-10-28T14:03:29Z",
    "link": "http://arxiv.org/pdf/2510.21614v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Wenyi Wang",
      "Piotr PiÄkos",
      "Li Nanbo",
      "Firas Laakom",
      "Yimeng Chen",
      "Mateusz Ostaszewski",
      "Mingchen Zhuge",
      "JÃ¼rgen Schmidhuber"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24435v1",
    "title": "Human-Level Reasoning: A Comparative Study of Large Language Models on\n  Logical and Abstract Reasoning",
    "summary": "Evaluating reasoning ability in Large Language Models (LLMs) is important for\nadvancing artificial intelligence, as it transcends mere linguistic task\nperformance. It involves understanding whether these models truly understand\ninformation, perform inferences, and are able to draw conclusions in a logical\nand valid way. This study compare logical and abstract reasoning skills of\nseveral LLMs - including GPT, Claude, DeepSeek, Gemini, Grok, Llama, Mistral,\nPerplexity, and Sabi\\'a - using a set of eight custom-designed reasoning\nquestions. The LLM results are benchmarked against human performance on the\nsame tasks, revealing significant differences and indicating areas where LLMs\nstruggle with deduction.",
    "published": "2025-10-28T14:02:58Z",
    "updated": "2025-10-28T14:02:58Z",
    "link": "http://arxiv.org/pdf/2510.24435v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Benjamin Grando Moreira"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24431v1",
    "title": "MiniOneRec: An Open-Source Framework for Scaling Generative\n  Recommendation",
    "summary": "The recent success of large language models (LLMs) has renewed interest in\nwhether recommender systems can achieve similar scaling benefits. Conventional\nrecommenders, dominated by massive embedding tables, tend to plateau as\nembedding dimensions grow. In contrast, the emerging generative paradigm\nreplaces embeddings with compact Semantic ID (SID) sequences produced by\nautoregressive Transformers. Yet most industrial deployments remain\nproprietary, leaving two fundamental questions open: (1) Do the expected\nscaling laws hold on public benchmarks? (2) What is the minimal post-training\nrecipe that enables competitive performance?\n  We present MiniOneRec, to the best of our knowledge, the first fully\nopen-source generative recommendation framework, which provides an end-to-end\nworkflow spanning SID construction, supervised fine-tuning, and\nrecommendation-oriented reinforcement learning. We generate SIDs via a Residual\nQuantized VAE and post-train Qwen backbones ranging from 0.5B to 7B parameters\non the Amazon Review dataset. Our experiments reveal a consistent downward\ntrend in both training and evaluation losses with increasing model size,\nvalidating the parameter efficiency of the generative approach. To further\nenhance performance, we propose a lightweight yet effective post-training\npipeline that (1) enforces full-process SID alignment and (2) applies\nreinforcement learning with constrained decoding and hybrid rewards. Together,\nthese techniques yield significant improvements in both ranking accuracy and\ncandidate diversity.",
    "published": "2025-10-28T13:58:36Z",
    "updated": "2025-10-28T13:58:36Z",
    "link": "http://arxiv.org/pdf/2510.24431v1.pdf",
    "category": [
      "cs.IR",
      "cs.AI"
    ],
    "authors": [
      "Xiaoyu Kong",
      "Leheng Sheng",
      "Junfei Tan",
      "Yuxin Chen",
      "Jiancan Wu",
      "An Zhang",
      "Xiang Wang",
      "Xiangnan He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.14057v5",
    "title": "The human-machine paradox: how collaboration creates or destroys value,\n  and why augmentation is key to resolving it",
    "summary": "When deploying artificial skills, managers widely assume that combining them\nwith the human factor is a safe harbor, mitigating the risks of full automation\nin high-complexity tasks. This paper formally challenges the economic validity\nof this widespread assumption, arguing that the true bottom-line economic\nutility of a human-machine skill policy is dangerously misunderstood and highly\ncontingent on situational and design factors. To investigate this gap, we\ndevelop an in-silico framework based on Monte Carlo simulations grounded in\nempirical pragmatism to quantify the economic impact of human and machine\nskills in the execution of tasks presenting varying levels of complexity. Our\nresults show that a human-machine strategy can yield the highest economic\nutility in complex scenarios, but only if genuine augmentation is achieved. In\ncontrast, when failing to realize this synergy, the human-machine approach can\nperform worse than either the machine-exclusive or the human-exclusive policy,\nactively destroying value under the pressure of costs that are not compensated\nby sufficient performance gains. The takeaway for decision-makers is\nunambiguous: when the context is complex and critical, simply allocating human\nand machine skills to a task may be insufficient, and far from being a\nsilver-bullet solution or a low-risk compromise. Rather, it is a critical\nopportunity to boost competitiveness that demands a strong organizational\ncommitment to enabling augmentation. Also, our findings show that improving the\ncost-effectiveness of machine skills over time, while useful, does not replace\nthe fundamental need to focus on achieving augmentation.",
    "published": "2025-09-17T15:03:39Z",
    "updated": "2025-10-28T13:36:46Z",
    "link": "http://arxiv.org/pdf/2509.14057v5.pdf",
    "category": [
      "econ.GN",
      "cs.AI",
      "q-fin.EC"
    ],
    "authors": [
      "Riccardo Zanardelli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24411v1",
    "title": "OS-Sentinel: Towards Safety-Enhanced Mobile GUI Agents via Hybrid\n  Validation in Realistic Workflows",
    "summary": "Computer-using agents powered by Vision-Language Models (VLMs) have\ndemonstrated human-like capabilities in operating digital environments like\nmobile platforms. While these agents hold great promise for advancing digital\nautomation, their potential for unsafe operations, such as system compromise\nand privacy leakage, is raising significant concerns. Detecting these safety\nconcerns across the vast and complex operational space of mobile environments\npresents a formidable challenge that remains critically underexplored. To\nestablish a foundation for mobile agent safety research, we introduce\nMobileRisk-Live, a dynamic sandbox environment accompanied by a safety\ndetection benchmark comprising realistic trajectories with fine-grained\nannotations. Built upon this, we propose OS-Sentinel, a novel hybrid safety\ndetection framework that synergistically combines a Formal Verifier for\ndetecting explicit system-level violations with a VLM-based Contextual Judge\nfor assessing contextual risks and agent actions. Experiments show that\nOS-Sentinel achieves 10%-30% improvements over existing approaches across\nmultiple metrics. Further analysis provides critical insights that foster the\ndevelopment of safer and more reliable autonomous mobile agents.",
    "published": "2025-10-28T13:22:39Z",
    "updated": "2025-10-28T13:22:39Z",
    "link": "http://arxiv.org/pdf/2510.24411v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.HC"
    ],
    "authors": [
      "Qiushi Sun",
      "Mukai Li",
      "Zhoumianze Liu",
      "Zhihui Xie",
      "Fangzhi Xu",
      "Zhangyue Yin",
      "Kanzhi Cheng",
      "Zehao Li",
      "Zichen Ding",
      "Qi Liu",
      "Zhiyong Wu",
      "Zhuosheng Zhang",
      "Ben Kao",
      "Lingpeng Kong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24402v1",
    "title": "Metadata-Driven Retrieval-Augmented Generation for Financial Question\n  Answering",
    "summary": "Retrieval-Augmented Generation (RAG) struggles on long, structured financial\nfilings where relevant evidence is sparse and cross-referenced. This paper\npresents a systematic investigation of advanced metadata-driven\nRetrieval-Augmented Generation (RAG) techniques, proposing and evaluating a\nnovel, multi-stage RAG architecture that leverages LLM-generated metadata. We\nintroduce a sophisticated indexing pipeline to create contextually rich\ndocument chunks and benchmark a spectrum of enhancements, including\npre-retrieval filtering, post-retrieval reranking, and enriched embeddings,\nbenchmarked on the FinanceBench dataset. Our results reveal that while a\npowerful reranker is essential for precision, the most significant performance\ngains come from embedding chunk metadata directly with text (\"contextual\nchunks\"). Our proposed optimal architecture combines LLM-driven pre-retrieval\noptimizations with these contextual embeddings to achieve superior performance.\nAdditionally, we present a custom metadata reranker that offers a compelling,\ncost-effective alternative to commercial solutions, highlighting a practical\ntrade-off between peak performance and operational efficiency. This study\nprovides a blueprint for building robust, metadata-aware RAG systems for\nfinancial document analysis.",
    "published": "2025-10-28T13:16:36Z",
    "updated": "2025-10-28T13:16:36Z",
    "link": "http://arxiv.org/pdf/2510.24402v1.pdf",
    "category": [
      "cs.IR",
      "cs.AI",
      "cs.CE"
    ],
    "authors": [
      "Michail Dadopoulos",
      "Anestis Ladas",
      "Stratos Moschidis",
      "Ioannis Negkakis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24397v1",
    "title": "APTBench: Benchmarking Agentic Potential of Base LLMs During\n  Pre-Training",
    "summary": "With the rapid development of LLM-based agents, there is a growing trend to\nincorporate agent-specific data into the pre-training stage of LLMs, aiming to\nbetter align LLMs with real-world autonomous task execution. However, current\npre-training benchmarks primarily focus on isolated and static skills, e.g.,\ncommon knowledge or mathematical/code reasoning, and fail to reflect model's\nagentic capabilities. On the other hand, agent benchmarks are typically\ndesigned for post-trained models, requiring multi-turn task execution abilities\nthat base models struggle to support. Thus, there is a compelling need for a\nbenchmark that can evaluate agentic potentials during pre-training and guide\nthe model training more effectively. To address this gap, we propose APTBench,\na framework that converts real-world agent tasks and successful trajectories\ninto multiple-choice or text completion questions tailored for base models. It\nfocuses on core agentic abilities, e.g., planning and action, and covers key\nagent scenarios, software engineering and deep research. Compared to existing\ngeneral-purpose benchmarks, APTBench offers a more predictive signal of a\nmodel's downstream performance as an agent, while remaining significantly more\nlightweight and cost-effective than full-scale, end-to-end agent evaluations\nafter post-training.",
    "published": "2025-10-28T13:11:22Z",
    "updated": "2025-10-28T13:11:22Z",
    "link": "http://arxiv.org/pdf/2510.24397v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Jiarui Qin",
      "Yunjia Xi",
      "Junjie Huang",
      "Renting Rui",
      "Di Yin",
      "Weiwen Liu",
      "Yong Yu",
      "Weinan Zhang",
      "Xing Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24390v1",
    "title": "Improving LLM Reasoning via Dependency-Aware Query Decomposition and\n  Logic-Parallel Content Expansion",
    "summary": "The integration of Large Language Models (LLMs) into real-time Web\napplications, such as AI-powered search and conversational agents, presents a\nfundamental Web infrastructure challenge: reconciling the demand for\nhigh-quality, complex reasoning with the stringent low-latency and\nhigh-throughput requirements of interactive services. Current LLM reasoning,\nhindered by computationally inefficient sequential generation and rigid\nreasoning strategies, creates a critical bottleneck for the Web services.\nExisting approaches typically optimize the LLM reasoning for either efficiency\nor quality but struggle to achieve both, and thus fail to meet the dual\nrequirements of modern Web platforms. To overcome these limitations, we propose\nOrion, a novel and efficient reasoning framework that enables dependency-aware\nquery decomposition and logic-parallel content expansion. Concretely, Orion\ndecomposes a single query reasoning process into two synergistic phases: (1)\n\\textit{key point generation}, which distills logically structured key points\nthrough retrieval-augmented few-shot prompting, and (2) \\textit{content\nparallel expansion}, which concurrently elaborates on these points based on a\ndependency graph to ensure logical consistency. Furthermore, Orion introduces a\npipeline scheduling mechanism that exploits the complementary computational\ncharacteristics of the two phases (generation imposes pressure on GPU computing\nand expansion stresses on GPU memory) across multiple queries, enabling\ncross-query parallelism and dramatically improving reasoning performance (\\ie,\nefficiency and quality). Experiments on diverse benchmarks show that Orion not\nonly delivers up to 4.33x higher token generation speed and 3.42x lower answer\nlatency over the baselines but also improves reasoning quality by up to 18.75%\nthrough explicitly modeling inter-point dependencies.",
    "published": "2025-10-28T13:05:23Z",
    "updated": "2025-10-28T13:05:23Z",
    "link": "http://arxiv.org/pdf/2510.24390v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Xianjun Gao",
      "Jianchun Liu",
      "Hongli Xu",
      "Liusheng Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.19585v2",
    "title": "Detecting Latin in Historical Books with Large Language Models: A\n  Multimodal Benchmark",
    "summary": "This paper presents a novel task of extracting Latin fragments from\nmixed-language historical documents with varied layouts. We benchmark and\nevaluate the performance of large foundation models against a multimodal\ndataset of 724 annotated pages. The results demonstrate that reliable Latin\ndetection with contemporary models is achievable. Our study provides the first\ncomprehensive analysis of these models' capabilities and limits for this task.",
    "published": "2025-10-22T13:37:52Z",
    "updated": "2025-10-28T13:04:38Z",
    "link": "http://arxiv.org/pdf/2510.19585v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.DL"
    ],
    "authors": [
      "Yu Wu",
      "Ke Shu",
      "Jonas Fischer",
      "Lidia Pivovarova",
      "David Rosson",
      "Eetu MÃ¤kelÃ¤",
      "Mikko Tolonen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.26080v2",
    "title": "Evaluating the Use of Large Language Models as Synthetic Social Agents\n  in Social Science Research",
    "summary": "Large Language Models (LLMs) are being increasingly used as synthetic agents\nin social science, in applications ranging from augmenting survey responses to\npowering multi-agent simulations. This paper outlines cautions that should be\ntaken when interpreting LLM outputs and proposes a pragmatic reframing for the\nsocial sciences in which LLMs are used as high-capacity pattern matchers for\nquasi-predictive interpolation under explicit scope conditions and not as\nsubstitutes for probabilistic inference. Practical guardrails such as\nindependent draws, preregistered human baselines, reliability-aware validation,\nand subgroup calibration, are introduced so that researchers may engage in\nuseful prototyping and forecasting while avoiding category errors.",
    "published": "2025-09-30T10:53:54Z",
    "updated": "2025-10-28T13:00:46Z",
    "link": "http://arxiv.org/pdf/2509.26080v2.pdf",
    "category": [
      "cs.AI",
      "stat.AP"
    ],
    "authors": [
      "Emma Rose Madden"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24383v1",
    "title": "Policy Cards: Machine-Readable Runtime Governance for Autonomous AI\n  Agents",
    "summary": "Policy Cards are introduced as a machine-readable, deployment-layer standard\nfor expressing operational, regulatory, and ethical constraints for AI agents.\nThe Policy Card sits with the agent and enables it to follow required\nconstraints at runtime. It tells the agent what it must and must not do. As\nsuch, it becomes an integral part of the deployed agent. Policy Cards extend\nexisting transparency artifacts such as Model, Data, and System Cards by\ndefining a normative layer that encodes allow/deny rules, obligations,\nevidentiary requirements, and crosswalk mappings to assurance frameworks\nincluding NIST AI RMF, ISO/IEC 42001, and the EU AI Act. Each Policy Card can\nbe validated automatically, version-controlled, and linked to runtime\nenforcement or continuous-audit pipelines. The framework enables verifiable\ncompliance for autonomous agents, forming a foundation for distributed\nassurance in multi-agent ecosystems. Policy Cards provide a practical mechanism\nfor integrating high-level governance with hands-on engineering practice and\nenabling accountable autonomy at scale.",
    "published": "2025-10-28T12:59:55Z",
    "updated": "2025-10-28T12:59:55Z",
    "link": "http://arxiv.org/pdf/2510.24383v1.pdf",
    "category": [
      "cs.AI",
      "cs.CY",
      "cs.MA",
      "I.2.11; I.2.1; I.2.4; K.4.1; K.4.3"
    ],
    "authors": [
      "Juraj MavraÄiÄ"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.14788v2",
    "title": "Cross-Scenario Unified Modeling of User Interests at Billion Scale",
    "summary": "User interests on content platforms are inherently diverse, manifesting\nthrough complex behavioral patterns across heterogeneous scenarios such as\nsearch, feed browsing, and content discovery. Traditional recommendation\nsystems typically prioritize business metric optimization within isolated\nspecific scenarios, neglecting cross-scenario behavioral signals and struggling\nto integrate advanced techniques like LLMs at billion-scale deployments, which\nfinally limits their ability to capture holistic user interests across platform\ntouchpoints. We propose RED-Rec, an LLM-enhanced hierarchical Recommender\nEngine for Diversified scenarios, tailored for industry-level content\nrecommendation systems. RED-Rec unifies user interest representations across\nmultiple behavioral contexts by aggregating and synthesizing actions from\nvaried scenarios, resulting in comprehensive item and user modeling. At its\ncore, a two-tower LLM-powered framework enables nuanced, multifaceted\nrepresentations with deployment efficiency, and a scenario-aware dense mixing\nand querying policy effectively fuses diverse behavioral signals to capture\ncross-scenario user intent patterns and express fine-grained, context-specific\nintents during serving. We validate RED-Rec through online A/B testing on\nhundreds of millions of users in RedNote through online A/B testing, showing\nsubstantial performance gains in both content recommendation and advertisement\ntargeting tasks. We further introduce a million-scale sequential recommendation\ndataset, RED-MMU, for comprehensive offline training and evaluation. Our work\nadvances unified user modeling, unlocking deeper personalization and fostering\nmore meaningful user engagement in large-scale UGC platforms.",
    "published": "2025-10-16T15:20:49Z",
    "updated": "2025-10-28T12:58:38Z",
    "link": "http://arxiv.org/pdf/2510.14788v2.pdf",
    "category": [
      "cs.IR",
      "cs.AI"
    ],
    "authors": [
      "Manjie Xu",
      "Cheng Chen",
      "Xin Jia",
      "Jingyi Zhou",
      "Yongji Wu",
      "Zejian Wang",
      "Chi Zhang",
      "Kai Zuo",
      "Yibo Chen",
      "Xu Tang",
      "Yao Hu",
      "Yixin Zhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.17500v2",
    "title": "Generalized Exponentiated Gradient Algorithms Using the Euler\n  Two-Parameter Logarithm",
    "summary": "IIn this paper we propose and investigate a new class of Generalized\nExponentiated Gradient (GEG) algorithms using Mirror Descent (MD) updates, and\napplying the Bregman divergence with a two--parameter\n  deformation of the logarithm as a link function. This link function (referred\nhere to as the Euler logarithm) is associated with a relatively wide class of\ntrace--form entropies. In order to derive novel GEG/MD updates, we estimate a\ndeformed exponential function, which closely approximates the inverse of the\nEuler two--parameter deformed logarithm. The characteristic shape and\nproperties of the Euler logarithm and its inverse--deformed exponential\nfunctions, are tuned by two hyperparameters. By learning these hyperparameters,\nwe can adapt to the distribution of training data and adjust them to achieve\ndesired properties of gradient descent algorithms. In the literature, there\nexist nowadays more than fifty mathematically well-established entropic\nfunctionals and associated deformed logarithms, so it is impossible to\ninvestigate all of them in one research paper. Therefore, we focus here on a\nclass of trace-form entropies and the associated deformed two--parameters\nlogarithms.",
    "published": "2025-02-21T11:05:04Z",
    "updated": "2025-10-28T12:53:44Z",
    "link": "http://arxiv.org/pdf/2502.17500v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Andrzej Cichocki"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24359v1",
    "title": "An N-of-1 Artificial Intelligence Ecosystem for Precision Medicine",
    "summary": "Artificial intelligence in medicine is built to serve the average patient. By\nminimizing error across large datasets, most systems deliver strong aggregate\naccuracy yet falter at the margins: patients with rare variants,\nmultimorbidity, or underrepresented demographics. This average patient fallacy\nerodes both equity and trust. We propose a different design: a multi-agent\necosystem for N-of-1 decision support. In this environment, agents clustered by\norgan systems, patient populations, and analytic modalities draw on a shared\nlibrary of models and evidence synthesis tools. Their results converge in a\ncoordination layer that weighs reliability, uncertainty, and data density\nbefore presenting the clinician with a decision-support packet: risk estimates\nbounded by confidence ranges, outlier flags, and linked evidence. Validation\nshifts from population averages to individual reliability, measured by error in\nlow-density regions, calibration in the small, and risk--coverage trade-offs.\nAnticipated challenges include computational demands, automation bias, and\nregulatory fit, addressed through caching strategies, consensus checks, and\nadaptive trial frameworks. By moving from monolithic models to orchestrated\nintelligence, this approach seeks to align medical AI with the first principle\nof medicine: care that is transparent, equitable, and centered on the\nindividual.",
    "published": "2025-10-28T12:28:02Z",
    "updated": "2025-10-28T12:28:02Z",
    "link": "http://arxiv.org/pdf/2510.24359v1.pdf",
    "category": [
      "cs.AI",
      "cs.SY",
      "eess.SY",
      "q-bio.QM",
      "stat.AP"
    ],
    "authors": [
      "Pedram Fard",
      "Alaleh Azhir",
      "Neguine Rezaii",
      "Jiazi Tian",
      "Hossein Estiri"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2402.10028v3",
    "title": "Diffusion Models Meet Contextual Bandits",
    "summary": "Efficient online decision-making in contextual bandits is challenging, as\nmethods without informative priors often suffer from computational or\nstatistical inefficiencies. In this work, we leverage pre-trained diffusion\nmodels as expressive priors to capture complex action dependencies and develop\na practical algorithm that efficiently approximates posteriors under such\npriors, enabling both fast updates and sampling. Empirical results demonstrate\nthe effectiveness and versatility of our approach across diverse contextual\nbandit settings.",
    "published": "2024-02-15T15:48:55Z",
    "updated": "2025-10-28T12:23:40Z",
    "link": "http://arxiv.org/pdf/2402.10028v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "authors": [
      "Imad Aouali"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24356v1",
    "title": "Perception Learning: A Formal Separation of Sensory Representation\n  Learning from Decision Learning",
    "summary": "We introduce Perception Learning (PeL), a paradigm that optimizes an agent's\nsensory interface $f_\\phi:\\mathcal{X}\\to\\mathcal{Z}$ using task-agnostic\nsignals, decoupled from downstream decision learning\n$g_\\theta:\\mathcal{Z}\\to\\mathcal{Y}$. PeL directly targets label-free\nperceptual properties, such as stability to nuisances, informativeness without\ncollapse, and controlled geometry, assessed via objective\nrepresentation-invariant metrics. We formalize the separation of perception and\ndecision, define perceptual properties independent of objectives or\nreparameterizations, and prove that PeL updates preserving sufficient\ninvariants are orthogonal to Bayes task-risk gradients. Additionally, we\nprovide a suite of task-agnostic evaluation metrics to certify perceptual\nquality.",
    "published": "2025-10-28T12:19:49Z",
    "updated": "2025-10-28T12:19:49Z",
    "link": "http://arxiv.org/pdf/2510.24356v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "authors": [
      "Suman Sanyal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24345v1",
    "title": "LongWeave: A Long-Form Generation Benchmark Bridging Real-World\n  Relevance and Verifiability",
    "summary": "Generating long, informative, and factual outputs remains a major challenge\nfor Large Language Models (LLMs). Existing benchmarks for long-form generation\ntypically assess real-world queries with hard-to-verify metrics or use\nsynthetic setups that ease evaluation but overlook real-world intricacies. In\nthis paper, we introduce \\textbf{LongWeave}, which balances real-world and\nverifiable assessment with Constraint-Verifier Evaluation (CoV-Eval). CoV-Eval\nconstructs tasks by first defining verifiable targets within real-world\nscenarios, then systematically generating corresponding queries, textual\nmaterials, and constraints based on these targets. This ensures that tasks are\nboth realistic and objectively assessable, enabling rigorous assessment of\nmodel capabilities in meeting complex real-world constraints. LongWeave\nsupports customizable input/output lengths (up to 64K/8K tokens) across seven\ndistinct tasks. Evaluation on 23 LLMs shows that even state-of-the-art models\nencounter significant challenges in long-form generation as real-world\ncomplexity and output length increase.",
    "published": "2025-10-28T12:11:12Z",
    "updated": "2025-10-28T12:11:12Z",
    "link": "http://arxiv.org/pdf/2510.24345v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Zikai Xiao",
      "Fei Huang",
      "Jianhong Tu",
      "Jianhui Wei",
      "Wen Ma",
      "Yuxuan Zhou",
      "Jian Wu",
      "Bowen Yu",
      "Zuozhu Liu",
      "Junyang Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24342v1",
    "title": "A Unified Geometric Space Bridging AI Models and the Human Brain",
    "summary": "For decades, neuroscientists and computer scientists have pursued a shared\nambition: to understand intelligence and build it. Modern artificial neural\nnetworks now rival humans in language, perception, and reasoning, yet it is\nstill largely unknown whether these artificial systems organize information as\nthe brain does. Existing brain-AI alignment studies have shown the striking\ncorrespondence between the two systems, but such comparisons remain bound to\nspecific inputs and tasks, offering no common ground for comparing how AI\nmodels with different kinds of modalities-vision, language, or multimodal-are\nintrinsically organized. Here we introduce a groundbreaking concept of\nBrain-like Space: a unified geometric space in which every AI model can be\nprecisely situated and compared by mapping its intrinsic spatial attention\ntopological organization onto canonical human functional brain networks,\nregardless of input modality, task, or sensory domain. Our extensive analysis\nof 151 Transformer-based models spanning state-of-the-art large vision models,\nlarge language models, and large multimodal models uncovers a continuous\narc-shaped geometry within this space, reflecting a gradual increase of\nbrain-likeness; different models exhibit distinct distribution patterns within\nthis geometry associated with different degrees of brain-likeness, shaped not\nmerely by their modality but by whether the pretraining paradigm emphasizes\nglobal semantic abstraction and whether the positional encoding scheme\nfacilitates deep fusion across different modalities. Moreover, the degree of\nbrain-likeness for a model and its downstream task performance are not\n\"identical twins\". The Brain-like Space provides the first unified framework\nfor situating, quantifying, and comparing intelligence across domains,\nrevealing the deep organizational principles that bridge machines and the\nbrain.",
    "published": "2025-10-28T12:09:23Z",
    "updated": "2025-10-28T12:09:23Z",
    "link": "http://arxiv.org/pdf/2510.24342v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Silin Chen",
      "Yuzhong Chen",
      "Zifan Wang",
      "Junhao Wang",
      "Zifeng Jia",
      "Keith M Kendrick",
      "Tuo Zhang",
      "Lin Zhao",
      "Dezhong Yao",
      "Tianming Liu",
      "Xi Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24339v1",
    "title": "VDSAgents: A PCS-Guided Multi-Agent System for Veridical Data Science\n  Automation",
    "summary": "Large language models (LLMs) become increasingly integrated into data science\nworkflows for automated system design. However, these LLM-driven data science\nsystems rely solely on the internal reasoning of LLMs, lacking guidance from\nscientific and theoretical principles. This limits their trustworthiness and\nrobustness, especially when dealing with noisy and complex real-world datasets.\nThis paper provides VDSAgents, a multi-agent system grounded in the\nPredictability-Computability-Stability (PCS) principles proposed in the\nVeridical Data Science (VDS) framework. Guided by PCS principles, the system\nimplements a modular workflow for data cleaning, feature engineering, modeling,\nand evaluation. Each phase is handled by an elegant agent, incorporating\nperturbation analysis, unit testing, and model validation to ensure both\nfunctionality and scientific auditability. We evaluate VDSAgents on nine\ndatasets with diverse characteristics, comparing it with state-of-the-art\nend-to-end data science systems, such as AutoKaggle and DataInterpreter, using\nDeepSeek-V3 and GPT-4o as backends. VDSAgents consistently outperforms the\nresults of AutoKaggle and DataInterpreter, which validates the feasibility of\nembedding PCS principles into LLM-driven data science automation.",
    "published": "2025-10-28T12:07:50Z",
    "updated": "2025-10-28T12:07:50Z",
    "link": "http://arxiv.org/pdf/2510.24339v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Yunxuan Jiang",
      "Silan Hu",
      "Xiaoning Wang",
      "Yuanyuan Zhang",
      "Xiangyu Chang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24337v1",
    "title": "Generative Large Language Models (gLLMs) in Content Analysis: A\n  Practical Guide for Communication Research",
    "summary": "Generative Large Language Models (gLLMs), such as ChatGPT, are increasingly\nbeing used in communication research for content analysis. Studies show that\ngLLMs can outperform both crowd workers and trained coders, such as research\nassistants, on various coding tasks relevant to communication science, often at\na fraction of the time and cost. Additionally, gLLMs can decode implicit\nmeanings and contextual information, be instructed using natural language,\ndeployed with only basic programming skills, and require little to no annotated\ndata beyond a validation dataset - constituting a paradigm shift in automated\ncontent analysis. Despite their potential, the integration of gLLMs into the\nmethodological toolkit of communication research remains underdeveloped. In\ngLLM-assisted quantitative content analysis, researchers must address at least\nseven critical challenges that impact result quality: (1) codebook development,\n(2) prompt engineering, (3) model selection, (4) parameter tuning, (5)\niterative refinement, (6) validation of the model's reliability, and\noptionally, (7) performance enhancement. This paper synthesizes emerging\nresearch on gLLM-assisted quantitative content analysis and proposes a\ncomprehensive best-practice guide to navigate these challenges. Our goal is to\nmake gLLM-based content analysis more accessible to a broader range of\ncommunication researchers and ensure adherence to established disciplinary\nquality standards of validity, reliability, reproducibility, and research\nethics.",
    "published": "2025-10-28T12:01:43Z",
    "updated": "2025-10-28T12:01:43Z",
    "link": "http://arxiv.org/pdf/2510.24337v1.pdf",
    "category": [
      "cs.AI",
      "cs.SI"
    ],
    "authors": [
      "Daria Kravets-Meinke",
      "Hannah Schmid-Petri",
      "Sonja Niemann",
      "Ute Schmid"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.19477v5",
    "title": "Provable Scaling Laws for the Test-Time Compute of Large Language Models",
    "summary": "We propose two simple, principled and practical algorithms that enjoy\nprovable scaling laws for the test-time compute of large language models\n(LLMs). The first one is a two-stage knockout-style algorithm: given an input\nproblem, it first generates multiple candidate solutions, and then aggregate\nthem via a knockout tournament for the final output. Assuming that the LLM can\ngenerate a correct solution with non-zero probability and do better than a\nrandom guess in comparing a pair of correct and incorrect solutions, we prove\ntheoretically that the failure probability of this algorithm decays to zero\nexponentially or by a power law (depending on the specific way of scaling) as\nits test-time compute grows. The second one is a two-stage league-style\nalgorithm, where each candidate is evaluated by its average win rate against\nmultiple opponents, rather than eliminated upon loss to a single opponent.\nUnder analogous but more robust assumptions, we prove that its failure\nprobability also decays to zero exponentially with more test-time compute. Both\nalgorithms require a black-box LLM and nothing else (e.g., no verifier or\nreward model) for a minimalistic implementation, which makes them appealing for\npractical applications and easy to adapt for different tasks. Through extensive\nexperiments with diverse models and datasets, we validate the proposed theories\nand demonstrate the outstanding scaling properties of both algorithms.",
    "published": "2024-11-29T05:29:47Z",
    "updated": "2025-10-28T11:59:43Z",
    "link": "http://arxiv.org/pdf/2411.19477v5.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Yanxi Chen",
      "Xuchen Pan",
      "Yaliang Li",
      "Bolin Ding",
      "Jingren Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24328v1",
    "title": "Beyond MCQ: An Open-Ended Arabic Cultural QA Benchmark with Dialect\n  Variants",
    "summary": "Large Language Models (LLMs) are increasingly used to answer everyday\nquestions, yet their performance on culturally grounded and dialectal content\nremains uneven across languages. We propose a comprehensive method that (i)\ntranslates Modern Standard Arabic (MSA) multiple-choice questions (MCQs) into\nEnglish and several Arabic dialects, (ii) converts them into open-ended\nquestions (OEQs), (iii) benchmarks a range of zero-shot and fine-tuned LLMs\nunder both MCQ and OEQ settings, and (iv) generates chain-of-thought (CoT)\nrationales to fine-tune models for step-by-step reasoning. Using this method,\nwe extend an existing dataset in which QAs are parallelly aligned across\nmultiple language varieties, making it, to our knowledge, the first of its\nkind. We conduct extensive experiments with both open and closed models. Our\nfindings show that (i) models underperform on Arabic dialects, revealing\npersistent gaps in culturally grounded and dialect-specific knowledge; (ii)\nArabic-centric models perform well on MCQs but struggle with OEQs; and (iii)\nCoT improves judged correctness while yielding mixed n-gram-based metrics. The\ndeveloped dataset will be publicly released to support further research on\nculturally and linguistically inclusive evaluation.",
    "published": "2025-10-28T11:52:51Z",
    "updated": "2025-10-28T11:52:51Z",
    "link": "http://arxiv.org/pdf/2510.24328v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "F.2.2; I.2.7"
    ],
    "authors": [
      "Hunzalah Hassan Bhatti",
      "Firoj Alam"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2202.07980v3",
    "title": "Querying Inconsistent Prioritized Data with ORBITS: Algorithms,\n  Implementation, and Experiments",
    "summary": "We investigate practical algorithms for inconsistency-tolerant query\nanswering over prioritized knowledge bases, which consist of a logical theory,\na set of facts, and a priority relation between conflicting facts. We consider\nthree well-known semantics (AR, IAR and brave) based upon two notions of\noptimal repairs (Pareto and completion). Deciding whether a query answer holds\nunder these semantics is (co)NP-complete in data complexity for a large class\nof logical theories, and SAT-based procedures have been devised for\nrepair-based semantics when there is no priority relation, or the relation has\na special structure. The present paper introduces the first SAT encodings for\nPareto- and completion-optimal repairs w.r.t. general priority relations and\nproposes several ways of employing existing and new encodings to compute\nanswers under (optimal) repair-based semantics, by exploiting different\nreasoning modes of SAT solvers. The comprehensive experimental evaluation of\nour implementation compares both (i) the impact of adopting semantics based on\ndifferent kinds of repairs, and (ii) the relative performances of alternative\nprocedures for the same semantics.",
    "published": "2022-02-16T10:44:39Z",
    "updated": "2025-10-28T11:48:36Z",
    "link": "http://arxiv.org/pdf/2202.07980v3.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "cs.DB"
    ],
    "authors": [
      "Meghyn Bienvenu",
      "Camille Bourgaux"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2208.07777v4",
    "title": "Mining Large Independent Sets on Massive Graphs",
    "summary": "The Maximum Independent Set problem is fundamental for extracting\nconflict-free structure from large graphs, with applications in scheduling,\nrecommendation, and network analysis. However, existing heuristics can stagnate\nwhen search schedules are fixed and information from past solutions is\nunderused, leading to wasted effort in low-quality regions of the search space.\nWe present ARCIS, an efficient algorithm for mining large independent sets on\nmassive graphs. ARCIS couples two main components. The first is an adaptive\nrestart policy that refreshes exploration when progress slows. The second is\nConsensus-Guided Vertex Fixing, which restricts the search to the non-consensus\nregion of the graph by fixing vertices consistently observed within a round.\nThe consensus is maintained as a running intersection within each round, and\nbecause it is recomputed at every restart, the fixing is reversible. Vertices\nthat later lose support are automatically unfixed and their neighborhoods\nre-enter the working graph, which corrects occasional mistakes while preserving\nprogress. Experiments on 222 graphs from four benchmark suites show that ARCIS\nattains the best or tied-best solution quality in most instances while\ndelivering competitive runtime and low variability. Ablation studies isolate\nthe impact of each component, indicating that ARCIS is a practical and robust\nmethod for large-scale graph mining.",
    "published": "2022-08-16T14:39:38Z",
    "updated": "2025-10-28T11:42:26Z",
    "link": "http://arxiv.org/pdf/2208.07777v4.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Yu Zhang",
      "Witold Pedrycz",
      "Chanjuan Liu",
      "Enqiang Zhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24321v1",
    "title": "Few-Shot Remote Sensing Image Scene Classification with CLIP and Prompt\n  Learning",
    "summary": "Remote sensing applications increasingly rely on deep learning for scene\nclassification. However, their performance is often constrained by the scarcity\nof labeled data and the high cost of annotation across diverse geographic and\nsensor domains. While recent vision-language models like CLIP have shown\npromise by learning transferable representations at scale by aligning visual\nand textual modalities, their direct application to remote sensing remains\nsuboptimal due to significant domain gaps and the need for task-specific\nsemantic adaptation. To address this critical challenge, we systematically\nexplore prompt learning as a lightweight and efficient adaptation strategy for\nfew-shot remote sensing image scene classification. We evaluate several\nrepresentative methods, including Context Optimization, Conditional Context\nOptimization, Multi-modal Prompt Learning, and Prompting with Self-Regulating\nConstraints. These approaches reflect complementary design philosophies: from\nstatic context optimization to conditional prompts for enhanced generalization,\nmulti-modal prompts for joint vision-language adaptation, and semantically\nregularized prompts for stable learning without forgetting. We benchmark these\nprompt-learning methods against two standard baselines: zero-shot CLIP with\nhand-crafted prompts and a linear probe trained on frozen CLIP features.\nThrough extensive experiments on multiple benchmark remote sensing datasets,\nincluding cross-dataset generalization tests, we demonstrate that prompt\nlearning consistently outperforms both baselines in few-shot scenarios.\nNotably, Prompting with Self-Regulating Constraints achieves the most robust\ncross-domain performance. Our findings underscore prompt learning as a scalable\nand efficient solution for bridging the domain gap in satellite and aerial\nimagery, providing a strong foundation for future research in this field.",
    "published": "2025-10-28T11:39:22Z",
    "updated": "2025-10-28T11:39:22Z",
    "link": "http://arxiv.org/pdf/2510.24321v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Ivica Dimitrovski",
      "Vlatko Spasev",
      "Ivan Kitanovski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24320v1",
    "title": "Critique-RL: Training Language Models for Critiquing through Two-Stage\n  Reinforcement Learning",
    "summary": "Training critiquing language models to assess and provide feedback on model\noutputs is a promising way to improve LLMs for complex reasoning tasks.\nHowever, existing approaches typically rely on stronger supervisors for\nannotating critique data. To address this, we propose Critique-RL, an online RL\napproach for developing critiquing language models without stronger\nsupervision. Our approach operates on a two-player paradigm: the actor\ngenerates a response, the critic provides feedback, and the actor refines the\nresponse accordingly. We first reveal that relying solely on indirect reward\nsignals from the actor's outputs for RL optimization often leads to\nunsatisfactory critics: while their helpfulness (i.e., providing constructive\nfeedback) improves, the discriminability (i.e., determining whether a response\nis high-quality or not) remains poor, resulting in marginal performance gains.\nTo overcome this, Critique-RL adopts a two-stage optimization strategy. In\nstage I, it reinforces the discriminability of the critic with direct\nrule-based reward signals; in stage II, it introduces indirect rewards based on\nactor refinement to improve the critic's helpfulness, while maintaining its\ndiscriminability via appropriate regularization. Extensive experiments across\nvarious tasks and models show that Critique-RL delivers substantial performance\nimprovements. For example, it achieves a 9.02% gain on in-domain tasks and a\n5.70% gain on out-of-domain tasks for Qwen2.5-7B, highlighting its potential.",
    "published": "2025-10-28T11:37:01Z",
    "updated": "2025-10-28T11:37:01Z",
    "link": "http://arxiv.org/pdf/2510.24320v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Zhiheng Xi",
      "Jixuan Huang",
      "Xin Guo",
      "Boyang Hong",
      "Dingwen Yang",
      "Xiaoran Fan",
      "Shuo Li",
      "Zehui Chen",
      "Junjie Ye",
      "Siyu Yuan",
      "Zhengyin Du",
      "Xuesong Yao",
      "Yufei Xu",
      "Jiecao Chen",
      "Rui Zheng",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.11364v4",
    "title": "Offline Learning and Forgetting for Reasoning with Large Language Models",
    "summary": "Leveraging inference-time search in large language models has proven\neffective in further enhancing a trained model's capability to solve complex\nmathematical and reasoning problems. However, this approach significantly\nincreases computational costs and inference time, as the model must generate\nand evaluate multiple candidate solutions to identify a viable reasoning path.\nTo address this, we propose an effective approach that integrates search\ncapabilities directly into the model by fine-tuning it on unpaired successful\n(learning) and failed reasoning paths (forgetting) derived from diverse search\nmethods. A key challenge we identify is that naive fine-tuning can degrade the\nmodel's search capability; we show this can be mitigated with a smaller\nlearning rate. Extensive experiments on the challenging Game-of-24 and\nCountdown arithmetic puzzles show that, replacing CoT-generated data with\nsearch-generated data for offline fine-tuning improves success rates by around\n23% over inference-time search baselines, while reducing inference time by\n180$\\times$. On top of this, our learning and forgetting objective consistently\noutperforms both supervised fine-tuning and preference-based methods.",
    "published": "2025-04-15T16:30:02Z",
    "updated": "2025-10-28T11:36:51Z",
    "link": "http://arxiv.org/pdf/2504.11364v4.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Tianwei Ni",
      "Allen Nie",
      "Sapana Chaudhary",
      "Yao Liu",
      "Huzefa Rangwala",
      "Rasool Fakoor"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24318v1",
    "title": "Transformers can do Bayesian Clustering",
    "summary": "Bayesian clustering accounts for uncertainty but is computationally demanding\nat scale. Furthermore, real-world datasets often contain missing values, and\nsimple imputation ignores the associated uncertainty, resulting in suboptimal\nresults. We present Cluster-PFN, a Transformer-based model that extends\nPrior-Data Fitted Networks (PFNs) to unsupervised Bayesian clustering. Trained\nentirely on synthetic datasets generated from a finite Gaussian Mixture Model\n(GMM) prior, Cluster-PFN learns to estimate the posterior distribution over\nboth the number of clusters and the cluster assignments. Our method estimates\nthe number of clusters more accurately than handcrafted model selection\nprocedures such as AIC, BIC and Variational Inference (VI), and achieves\nclustering quality competitive with VI while being orders of magnitude faster.\nCluster-PFN can be trained on complex priors that include missing data,\noutperforming imputation-based baselines on real-world genomic datasets, at\nhigh missingness. These results show that the Cluster-PFN can provide scalable\nand flexible Bayesian clustering.",
    "published": "2025-10-28T11:36:31Z",
    "updated": "2025-10-28T11:36:31Z",
    "link": "http://arxiv.org/pdf/2510.24318v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Prajit Bhaskaran",
      "Tom Viering"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.21730v2",
    "title": "Freeze and Conquer: Reusable Ansatz for Solving the Traveling Salesman\n  Problem",
    "summary": "In this paper we present a variational algorithm for the Traveling Salesman\nProblem (TSP) that combines (i) a compact encoding of permutations, which\nreduces the qubit requirement too, (ii) an optimize-freeze-reuse strategy:\nwhere the circuit topology (``Ansatz'') is first optimized on a training\ninstance by Simulated Annealing (SA), then ``frozen'' and re-used on novel\ninstances, limited to a rapid re-optimization of only the circuit parameters.\nThis pipeline eliminates costly structural research in testing, making the\nprocedure immediately implementable on NISQ hardware.\n  On a set of $40$ randomly generated symmetric instances that span $4 - 7$\ncities, the resulting Ansatz achieves an average optimal trip sampling\nprobability of $100\\%$ for 4 city cases, $90\\%$ for 5 city cases and $80\\%$ for\n6 city cases. With 7 cities the success rate drops markedly to an average of\n$\\sim 20\\%$, revealing the onset of scalability limitations of the proposed\nmethod.\n  The results show robust generalization ability for moderate problem sizes and\nindicate how freezing the Ansatz can dramatically reduce time-to-solution\nwithout degrading solution quality. The paper also discusses scalability\nlimitations, the impact of ``warm-start'' initialization of parameters, and\nprospects for extension to more complex problems, such as Vehicle Routing and\nJob-Shop Scheduling.",
    "published": "2025-08-29T15:56:16Z",
    "updated": "2025-10-28T11:27:51Z",
    "link": "http://arxiv.org/pdf/2508.21730v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Fabrizio Fagiolo",
      "NicolÃ² Vescera"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.20234v3",
    "title": "ImageNet-trained CNNs are not biased towards texture: Revisiting feature\n  reliance through controlled suppression",
    "summary": "The hypothesis that Convolutional Neural Networks (CNNs) are inherently\ntexture-biased has shaped much of the discourse on feature use in deep\nlearning. We revisit this hypothesis by examining limitations in the\ncue-conflict experiment by Geirhos et al. To address these limitations, we\npropose a domain-agnostic framework that quantifies feature reliance through\nsystematic suppression of shape, texture, and color cues, avoiding the\nconfounds of forced-choice conflicts. By evaluating humans and neural networks\nunder controlled suppression conditions, we find that CNNs are not inherently\ntexture-biased but predominantly rely on local shape features. Nonetheless,\nthis reliance can be substantially mitigated through modern training strategies\nor architectures (ConvNeXt, ViTs). We further extend the analysis across\ncomputer vision, medical imaging, and remote sensing, revealing that reliance\npatterns differ systematically: computer vision models prioritize shape,\nmedical imaging models emphasize color, and remote sensing models exhibit a\nstronger reliance on texture. Code is available at\nhttps://github.com/tomburgert/feature-reliance.",
    "published": "2025-09-24T15:24:43Z",
    "updated": "2025-10-28T11:26:53Z",
    "link": "http://arxiv.org/pdf/2509.20234v3.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Tom Burgert",
      "Oliver Stoll",
      "Paolo Rota",
      "BegÃ¼m Demir"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24303v1",
    "title": "Retrieval and Argumentation Enhanced Multi-Agent LLMs for Judgmental\n  Forecasting",
    "summary": "Judgmental forecasting is the task of making predictions about future events\nbased on human judgment. This task can be seen as a form of claim verification,\nwhere the claim corresponds to a future event and the task is to assess the\nplausibility of that event. In this paper, we propose a novel multi-agent\nframework for claim verification, whereby different agents may disagree on\nclaim veracity and bring specific evidence for and against the claims,\nrepresented as quantitative bipolar argumentation frameworks (QBAFs). We then\ninstantiate the framework for supporting claim verification, with a variety of\nagents realised with Large Language Models (LLMs): (1) ArgLLM agents, an\nexisting approach for claim verification that generates and evaluates QBAFs;\n(2) RbAM agents, whereby LLM-empowered Relation-based Argument Mining (RbAM)\nfrom external sources is used to generate QBAFs; (3) RAG-ArgLLM agents,\nextending ArgLLM agents with a form of Retrieval-Augmented Generation (RAG) of\narguments from external sources. Finally, we conduct experiments with two\nstandard judgmental forecasting datasets, with instances of our framework with\ntwo or three agents, empowered by six different base LLMs. We observe that\ncombining evidence from agents can improve forecasting accuracy, especially in\nthe case of three agents, while providing an explainable combination of\nevidence for claim verification.",
    "published": "2025-10-28T11:12:43Z",
    "updated": "2025-10-28T11:12:43Z",
    "link": "http://arxiv.org/pdf/2510.24303v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Deniz Gorur",
      "Antoni Rago",
      "Francesca Toni"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24299v1",
    "title": "Verifying Large Language Models' Reasoning Paths via Correlation Matrix\n  Rank",
    "summary": "Despite the strong reasoning ability of large language models~(LLMs), they\nare prone to errors and hallucinations. As a result, how to check their outputs\neffectively and efficiently has become a critical problem in their\napplications. Existing checking methods heavily rely on external resources,\nsuch as trained verifiers (e.g., process/outcome reward models) or elaborate\nprompts, which lead to high computational overhead and are only applicable to\nspecific domains. In this paper, we investigate whether the internal behaviors\nof LLMs have already implied the credibility of their reasoning paths.\nSpecifically, we find that the rank of the correlation matrix between the input\nproblem and the output reasoning path is a robust indicator of reasoning\ncorrectness. Different from other correctness indicators for LLMs, the\ncalculation of the correlation matrix only relies on the LLM itself, which\navoids the hassle of training a separate model or designing complicated\nprompts. Based on it, we design a simple, plug-and-play Self-Indicator method\nto reweight candidate reasoning paths, which achieves significant performance\nimprovements than other voting and verification methods with very few\ncomputational overhead. Our experiments across multiple LLMs of varying scales\nand model families have further shown the effectiveness of Self-Indicator. It\nachieves over 75% accuracy in distinguishing correct reasoning paths from\nincorrect ones, and, in turn, improves the accuracies on three reasoning\nbenchmarks by more than 8%.",
    "published": "2025-10-28T11:01:10Z",
    "updated": "2025-10-28T11:01:10Z",
    "link": "http://arxiv.org/pdf/2510.24299v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Jiayu Liu",
      "Wei Dai",
      "Zhenya Huang",
      "Ning Miao",
      "Enhong Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24297v1",
    "title": "Investigating Intra-Abstraction Policies For Non-exact Abstraction\n  Algorithms",
    "summary": "One weakness of Monte Carlo Tree Search (MCTS) is its sample efficiency which\ncan be addressed by building and using state and/or action abstractions in\nparallel to the tree search such that information can be shared among nodes of\nthe same layer. The primary usage of abstractions for MCTS is to enhance the\nUpper Confidence Bound (UCB) value during the tree policy by aggregating visits\nand returns of an abstract node. However, this direct usage of abstractions\ndoes not take the case into account where multiple actions with the same parent\nmight be in the same abstract node, as these would then all have the same UCB\nvalue, thus requiring a tiebreak rule. In state-of-the-art abstraction\nalgorithms such as pruned On the Go Abstractions (pruned OGA), this case has\nnot been noticed, and a random tiebreak rule was implicitly chosen. In this\npaper, we propose and empirically evaluate several alternative\nintra-abstraction policies, several of which outperform the random policy\nacross a majority of environments and parameter settings.",
    "published": "2025-10-28T11:00:30Z",
    "updated": "2025-10-28T11:00:30Z",
    "link": "http://arxiv.org/pdf/2510.24297v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Robin SchmÃ¶cker",
      "Alexander Dockhorn",
      "Bodo Rosenhahn"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23444v2",
    "title": "FRBNet: Revisiting Low-Light Vision through Frequency-Domain Radial\n  Basis Network",
    "summary": "Low-light vision remains a fundamental challenge in computer vision due to\nsevere illumination degradation, which significantly affects the performance of\ndownstream tasks such as detection and segmentation. While recent\nstate-of-the-art methods have improved performance through invariant feature\nlearning modules, they still fall short due to incomplete modeling of low-light\nconditions. Therefore, we revisit low-light image formation and extend the\nclassical Lambertian model to better characterize low-light conditions. By\nshifting our analysis to the frequency domain, we theoretically prove that the\nfrequency-domain channel ratio can be leveraged to extract\nillumination-invariant features via a structured filtering process. We then\npropose a novel and end-to-end trainable module named \\textbf{F}requency-domain\n\\textbf{R}adial \\textbf{B}asis \\textbf{Net}work (\\textbf{FRBNet}), which\nintegrates the frequency-domain channel ratio operation with a learnable\nfrequency domain filter for the overall illumination-invariant feature\nenhancement. As a plug-and-play module, FRBNet can be integrated into existing\nnetworks for low-light downstream tasks without modifying loss functions.\nExtensive experiments across various downstream tasks demonstrate that FRBNet\nachieves superior performance, including +2.2 mAP for dark object detection and\n+2.9 mIoU for nighttime segmentation. Code is available at:\nhttps://github.com/Sing-Forevet/FRBNet.",
    "published": "2025-10-27T15:46:07Z",
    "updated": "2025-10-28T10:58:40Z",
    "link": "http://arxiv.org/pdf/2510.23444v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Fangtong Sun",
      "Congyu Li",
      "Ke Yang",
      "Yuchen Pan",
      "Hanwen Yu",
      "Xichuan Zhang",
      "Yiying Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.08146v3",
    "title": "Think Just Enough: Sequence-Level Entropy as a Confidence Signal for LLM\n  Reasoning",
    "summary": "We introduce a simple, yet novel entropy-based framework to drive token\nefficiency in large language models during reasoning tasks. Our approach uses\nShannon entropy from token-level logprobs as a confidence signal to enable\nearly stopping, achieving 25-50% computational savings while maintaining task\naccuracy. Crucially, we demonstrate that entropy-based confidence calibration\nrepresents an emergent property of advanced post-training optimization present\nin modern reasoning models but notably absent in standard instruction-tuned and\npre-trained models (Llama 3.3 70B). We show that the entropy threshold to stop\nreasoning varies from model to model but can be calculated easily in one shot\nusing only a few examples from existing reasoning datasets. Our results\nindicate that advanced reasoning models often know that they've gotten a\ncorrect answer early on, and that this emergent confidence awareness can be\nexploited to save tokens and reduce latency. The framework demonstrates\nconsistent performance across reasoning-optimized model families with 25-50%\ncomputational cost reduction while preserving accuracy, revealing that\nconfidence mechanisms represent a distinguishing characteristic of modern\npost-trained reasoning systems versus their predecessors.",
    "published": "2025-10-09T12:33:16Z",
    "updated": "2025-10-28T10:58:14Z",
    "link": "http://arxiv.org/pdf/2510.08146v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Aman Sharma",
      "Paras Chopra"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.13771v2",
    "title": "LittleBit: Ultra Low-Bit Quantization via Latent Factorization",
    "summary": "Deploying large language models (LLMs) often faces challenges from\nsubstantial memory and computational costs. Quantization offers a solution, yet\nperformance degradation in the sub-1-bit regime remains particularly difficult.\nThis paper introduces LittleBit, a novel method for extreme LLM compression. It\ntargets levels like 0.1 bits per weight (BPW), achieving nearly 31$\\times$\nmemory reduction, e.g., Llama2-13B to under 0.9 GB. LittleBit represents\nweights in a low-rank form using latent matrix factorization, subsequently\nbinarizing these factors. To counteract information loss from this extreme\nprecision, it integrates a multi-scale compensation mechanism. This includes\nrow, column, and an additional latent dimension that learns per-rank\nimportance. Two key contributions enable effective training: Dual\nSign-Value-Independent Decomposition (Dual-SVID) for quantization-aware\ntraining (QAT) initialization, and integrated Residual Compensation to mitigate\nerrors. Extensive experiments confirm LittleBit's superiority in sub-1-bit\nquantization: e.g., its 0.1 BPW performance on Llama2-7B surpasses the leading\nmethod's 0.7 BPW. LittleBit establishes a new, viable size-performance\ntrade-off--unlocking a potential 11.6$\\times$ speedup over FP16 at the kernel\nlevel--and makes powerful LLMs practical for resource-constrained environments.",
    "published": "2025-05-30T06:43:03Z",
    "updated": "2025-10-28T10:57:14Z",
    "link": "http://arxiv.org/pdf/2506.13771v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Banseok Lee",
      "Dongkyu Kim",
      "Youngcheon You",
      "Youngmin Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24285v1",
    "title": "ViPER: Empowering the Self-Evolution of Visual Perception Abilities in\n  Vision-Language Model",
    "summary": "The limited capacity for fine-grained visual perception presents a critical\nbottleneck for Vision-Language Models (VLMs) in real-world applications.\nAddressing this is challenging due to the scarcity of high-quality data and the\nlimitations of existing methods: supervised fine-tuning (SFT) often compromises\ngeneral capabilities, while reinforcement fine-tuning (RFT) prioritizes textual\nreasoning over visual perception. To bridge this gap, we propose a novel\ntwo-stage task that structures visual perception learning as a coarse-to-fine\nprogressive process. Based on this task formulation, we develop ViPER, a\nself-bootstrapping framework specifically designed to enable iterative\nevolution through self-critiquing and self-prediction. By synergistically\nintegrating image-level and instance-level reconstruction with a two-stage\nreinforcement learning strategy, ViPER establishes a closed-loop training\nparadigm, where internally synthesized data directly fuel the enhancement of\nperceptual ability. Applied to the Qwen2.5-VL family, ViPER produces the\nQwen-Viper series. With an average gain of 1.7% on seven comprehensive\nbenchmarks spanning various tasks and up to 6.0% on fine-grained perception,\nQwen-Viper consistently demonstrates superior performance across different\nvision-language scenarios while maintaining generalizability. Beyond enabling\nself-improvement in perceptual capabilities, ViPER provides concrete evidence\nfor the reciprocal relationship between generation and understanding, a\nbreakthrough to developing more autonomous and capable VLMs.",
    "published": "2025-10-28T10:42:57Z",
    "updated": "2025-10-28T10:42:57Z",
    "link": "http://arxiv.org/pdf/2510.24285v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Juntian Zhang",
      "Song Jin",
      "Chuanqi Cheng",
      "Yuhan Liu",
      "Yankai Lin",
      "Xun Zhang",
      "Yufei Zhang",
      "Fei Jiang",
      "Guojun Yin",
      "Wei Lin",
      "Rui Yan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24284v1",
    "title": "MCP-Flow: Facilitating LLM Agents to Master Real-World, Diverse and\n  Scaling MCP Tools",
    "summary": "Large Language Models (LLMs) increasingly rely on external tools to perform\ncomplex, realistic tasks, yet their ability to utilize the rapidly expanding\nModel Contextual Protocol (MCP) ecosystem remains limited. Existing MCP\nresearch covers few servers, depends on costly manual curation, and lacks\ntraining support, hindering progress toward real-world deployment. To overcome\nthese limitations, we introduce MCP-Flow, an automated web-agent-driven\npipeline for large-scale server discovery, data synthesis, and model training.\nMCP-Flow collects and filters data from 1166 servers and 11536 tools, producing\n68733 high-quality instruction-function call pairs and 6439 trajectories, far\nexceeding prior work in scale and diversity. Extensive experiments demonstrate\nMCP-Flow's effectiveness in driving superior MCP tool selection, function-call\ngeneration, and enhanced agentic task performance. MCP-Flow thus provides a\nscalable foundation for advancing LLM agents' proficiency in real-world MCP\nenvironments. MCP-Flow is publicly available at\n\\href{https://github.com/wwh0411/MCP-Flow}{https://github.com/wwh0411/MCP-Flow}.",
    "published": "2025-10-28T10:42:17Z",
    "updated": "2025-10-28T10:42:17Z",
    "link": "http://arxiv.org/pdf/2510.24284v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Wenhao Wang",
      "Peizhi Niu",
      "Zhao Xu",
      "Zhaoyu Chen",
      "Jian Du",
      "Yaxin Du",
      "Xianghe Pang",
      "Keduan Huang",
      "Yanfeng Wang",
      "Qiang Yan",
      "Siheng Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.05860v2",
    "title": "Benchmarking AI Models in Software Engineering: A Review, Search Tool,\n  and Unified Approach for Elevating Benchmark Quality",
    "summary": "Benchmarks are essential for unified evaluation and reproducibility. The\nrapid rise of Artificial Intelligence for Software Engineering (AI4SE) has\nproduced numerous benchmarks for tasks such as code generation and bug repair.\nHowever, this proliferation has led to major challenges: (1) fragmented\nknowledge across tasks, (2) difficulty in selecting contextually relevant\nbenchmarks, (3) lack of standardization in benchmark creation, and (4) flaws\nthat limit utility. Addressing these requires a dual approach: systematically\nmapping existing benchmarks for informed selection and defining unified\nguidelines for robust, adaptable benchmark development.\n  We conduct a review of 247 studies, identifying 273 AI4SE benchmarks since\n2014. We categorize them, analyze limitations, and expose gaps in current\npractices. Building on these insights, we introduce BenchScout, an extensible\nsemantic search tool for locating suitable benchmarks. BenchScout employs\nautomated clustering with contextual embeddings of benchmark-related studies,\nfollowed by dimensionality reduction. In a user study with 22 participants,\nBenchScout achieved usability, effectiveness, and intuitiveness scores of 4.5,\n4.0, and 4.1 out of 5.\n  To improve benchmarking standards, we propose BenchFrame, a unified framework\nfor enhancing benchmark quality. Applying BenchFrame to HumanEval yielded\nHumanEvalNext, featuring corrected errors, improved language conversion, higher\ntest coverage, and greater difficulty. Evaluating 10 state-of-the-art code\nmodels on HumanEval, HumanEvalPlus, and HumanEvalNext revealed average\npass-at-1 drops of 31.22% and 19.94%, respectively, underscoring the need for\ncontinuous benchmark refinement. We further examine BenchFrame's scalability\nthrough an agentic pipeline and confirm its generalizability on the MBPP\ndataset. All review data, user study materials, and enhanced benchmarks are\npublicly released.",
    "published": "2025-03-07T18:44:32Z",
    "updated": "2025-10-28T10:40:52Z",
    "link": "http://arxiv.org/pdf/2503.05860v2.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Roham Koohestani",
      "Philippe de Bekker",
      "BegÃ¼m KoÃ§",
      "Maliheh Izadi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24278v1",
    "title": "Training-free Source Attribution of AI-generated Images via Resynthesis",
    "summary": "Synthetic image source attribution is a challenging task, especially in data\nscarcity conditions requiring few-shot or zero-shot classification\ncapabilities. We present a new training-free one-shot attribution method based\non image resynthesis. A prompt describing the image under analysis is\ngenerated, then it is used to resynthesize the image with all the candidate\nsources. The image is attributed to the model which produced the resynthesis\nclosest to the original image in a proper feature space. We also introduce a\nnew dataset for synthetic image attribution consisting of face images from\ncommercial and open-source text-to-image generators. The dataset provides a\nchallenging attribution framework, useful for developing new attribution models\nand testing their capabilities on different generative architectures. The\ndataset structure allows to test approaches based on resynthesis and to compare\nthem to few-shot methods. Results from state-of-the-art few-shot approaches and\nother baselines show that the proposed resynthesis method outperforms existing\ntechniques when only a few samples are available for training or fine-tuning.\nThe experiments also demonstrate that the new dataset is a challenging one and\nrepresents a valuable benchmark for developing and evaluating future few-shot\nand zero-shot methods.",
    "published": "2025-10-28T10:39:04Z",
    "updated": "2025-10-28T10:39:04Z",
    "link": "http://arxiv.org/pdf/2510.24278v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Pietro Bongini",
      "Valentina Molinari",
      "Andrea Costanzo",
      "Benedetta Tondi",
      "Mauro Barni"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24272v1",
    "title": "Survey and Tutorial of Reinforcement Learning Methods in Process Systems\n  Engineering",
    "summary": "Sequential decision making under uncertainty is central to many Process\nSystems Engineering (PSE) challenges, where traditional methods often face\nlimitations related to controlling and optimizing complex and stochastic\nsystems. Reinforcement Learning (RL) offers a data-driven approach to derive\ncontrol policies for such challenges. This paper presents a survey and tutorial\non RL methods, tailored for the PSE community. We deliver a tutorial on RL,\ncovering fundamental concepts and key algorithmic families including\nvalue-based, policy-based and actor-critic methods. Subsequently, we survey\nexisting applications of these RL techniques across various PSE domains, such\nas in fed-batch and continuous process control, process optimization, and\nsupply chains. We conclude with PSE focused discussion of specialized\ntechniques and emerging directions. By synthesizing the current state of RL\nalgorithm development and implications for PSE this work identifies successes,\nchallenges, trends, and outlines avenues for future research at the interface\nof these fields.",
    "published": "2025-10-28T10:31:12Z",
    "updated": "2025-10-28T10:31:12Z",
    "link": "http://arxiv.org/pdf/2510.24272v1.pdf",
    "category": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "authors": [
      "Maximilian Bloor",
      "Max Mowbray",
      "Ehecatl Antonio Del Rio Chanona",
      "Calvin Tsay"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.23464v2",
    "title": "The Confidence Paradox: Can LLM Know When It's Wrong",
    "summary": "Document Visual Question Answering (DocVQA) models often produce\noverconfident or ethically misaligned responses, especially under uncertainty.\nExisting models like LayoutLMv3, UDOP, and DONUT focus on accuracy but lack\nethical calibration. We propose HonestVQA, a model-agnostic, self-supervised\nframework that aligns model confidence with correctness using weighted loss and\ncontrastive learning. We introduce two new metrics Honesty Score (H-Score) and\nEthical Confidence Index (ECI)-to evaluate ethical alignment. HonestVQA\nimproves accuracy and F1 by up to 4.3% across SpDocVQA, InfographicsVQA, and\nSROIE datasets, while reducing overconfidence. It also generalizes well across\ndomains, achieving 78.9% accuracy and 76.1% F1-score.",
    "published": "2025-06-30T02:06:54Z",
    "updated": "2025-10-28T10:19:32Z",
    "link": "http://arxiv.org/pdf/2506.23464v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Sahil Tripathi",
      "Md Tabrez Nafis",
      "Imran Hussain",
      "Jiechao Gao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.16925v2",
    "title": "Thermometry of simulated Bose--Einstein condensates using machine\n  learning",
    "summary": "Precise determination of thermodynamic parameters in ultracold Bose gases\nremains challenging due to the destructive nature of conventional measurement\ntechniques and inherent experimental uncertainties. We demonstrate a machine\nlearning approach for rapid, non-destructive estimation of the chemical\npotential and temperature from a single image of an \\emph{in situ} imaged\ndensity profiles of finite-temperature Bose gases. Our convolutional neural\nnetwork is trained exclusively on quasi-2D `pancake' condensates in harmonic\ntrap configurations. It achieves parameter extraction within fractions of a\nsecond. The model also demonstrates {some} zero-shot generalisation across both\ntrap geometry and thermalisation dynamics, successfully estimating the\ntemperature (although not the chemical potential) for toroidally trapped\ncondensates with errors of only a few nanokelvin despite no prior exposure to\nsuch geometries during training, and maintaining predictive accuracy during\ndynamic thermalisation processes after a relatively brief evolution without\nexplicit training on non-equilibrium states. These results suggest that\nsupervised learning can overcome traditional limitations in ultracold atom\nthermometry, with extension to broader geometric configurations, temperature\nranges, and additional parameters potentially enabling comprehensive real-time\nanalysis of quantum gas experiments. Such capabilities could significantly\nstreamline experimental workflows whilst improving measurement precision across\na range of quantum fluid systems.",
    "published": "2025-06-20T11:36:15Z",
    "updated": "2025-10-28T10:17:19Z",
    "link": "http://arxiv.org/pdf/2506.16925v2.pdf",
    "category": [
      "cond-mat.quant-gas",
      "cs.AI",
      "physics.comp-ph"
    ],
    "authors": [
      "Jack Griffiths",
      "Steven A. Wrathmall",
      "Simon A. Gardiner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24261v1",
    "title": "DynaRend: Learning 3D Dynamics via Masked Future Rendering for Robotic\n  Manipulation",
    "summary": "Learning generalizable robotic manipulation policies remains a key challenge\ndue to the scarcity of diverse real-world training data. While recent\napproaches have attempted to mitigate this through self-supervised\nrepresentation learning, most either rely on 2D vision pretraining paradigms\nsuch as masked image modeling, which primarily focus on static semantics or\nscene geometry, or utilize large-scale video prediction models that emphasize\n2D dynamics, thus failing to jointly learn the geometry, semantics, and\ndynamics required for effective manipulation. In this paper, we present\nDynaRend, a representation learning framework that learns 3D-aware and\ndynamics-informed triplane features via masked reconstruction and future\nprediction using differentiable volumetric rendering. By pretraining on\nmulti-view RGB-D video data, DynaRend jointly captures spatial geometry, future\ndynamics, and task semantics in a unified triplane representation. The learned\nrepresentations can be effectively transferred to downstream robotic\nmanipulation tasks via action value map prediction. We evaluate DynaRend on two\nchallenging benchmarks, RLBench and Colosseum, as well as in real-world robotic\nexperiments, demonstrating substantial improvements in policy success rate,\ngeneralization to environmental perturbations, and real-world applicability\nacross diverse manipulation tasks.",
    "published": "2025-10-28T10:17:11Z",
    "updated": "2025-10-28T10:17:11Z",
    "link": "http://arxiv.org/pdf/2510.24261v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Jingyi Tian",
      "Le Wang",
      "Sanping Zhou",
      "Sen Wang",
      "Jiayi Li",
      "Gang Hua"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24255v1",
    "title": "Trajectory Design for UAV-Based Low-Altitude Wireless Networks in\n  Unknown Environments: A Digital Twin-Assisted TD3 Approach",
    "summary": "Unmanned aerial vehicles (UAVs) are emerging as key enablers for low-altitude\nwireless network (LAWN), particularly when terrestrial networks are\nunavailable. In such scenarios, the environmental topology is typically\nunknown; hence, designing efficient and safe UAV trajectories is essential yet\nchallenging. To address this, we propose a digital twin (DT)-assisted training\nand deployment framework. In this framework, the UAV transmits integrated\nsensing and communication signals to provide communication services to ground\nusers, while simultaneously collecting echoes that are uploaded to the DT\nserver to progressively construct virtual environments (VEs). These VEs\naccelerate model training and are continuously updated with real-time UAV\nsensing data during deployment, supporting decision-making and enhancing flight\nsafety. Based on this framework, we further develop a trajectory design scheme\nthat integrates simulated annealing for efficient user scheduling with the\ntwin-delayed deep deterministic policy gradient algorithm for continuous\ntrajectory design, aiming to minimize mission completion time while ensuring\nobstacle avoidance. Simulation results demonstrate that the proposed approach\nachieves faster convergence, higher flight safety, and shorter mission\ncompletion time compared with baseline methods, providing a robust and\nefficient solution for LAWN deployment in unknown environments.",
    "published": "2025-10-28T10:05:53Z",
    "updated": "2025-10-28T10:05:53Z",
    "link": "http://arxiv.org/pdf/2510.24255v1.pdf",
    "category": [
      "eess.SP",
      "cs.AI"
    ],
    "authors": [
      "Jihao Luo",
      "Zesong Fei",
      "Xinyi Wang",
      "Le Zhao",
      "Yuanhao Cui",
      "Guangxu Zhu",
      "Dusit Niyato"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.00037v3",
    "title": "On Robustness of Vision-Language-Action Model against Multi-Modal\n  Perturbations",
    "summary": "In Vision-Language-Action (VLA) models, robustness to real-world\nperturbations is critical for deployment. Existing methods target simple visual\ndisturbances, overlooking the broader multi-modal perturbations that arise in\nactions, instructions, environments, and observations. Here, we first evaluate\nthe robustness of mainstream VLAs under 17 perturbations across four\nmodalities. We find (1) actions as the most fragile modality, (2) Existing\nvisual-robust VLA do not gain robustness in other modality, and (3) pi0\ndemonstrates superior robustness with a diffusion-based action head. To build\nmulti-modal robust VLAs, we propose RobustVLA against perturbations in VLA\ninputs and outputs. For output robustness, we perform offline robust\noptimization against worst-case action noise that maximizes mismatch in flow\nmatching objective. This can be seen as adversarial training, label smoothing,\nand outlier penalization. For input robustness, we enforce consistent actions\nacross input variations that preserve task semantics. To account for multiple\nperturbations, we formulate robustness as a multi-armed bandit problem and\napply an upper confidence bound algorithm to automatically identify the most\nharmful noise. Experiments on LIBERO demonstrate our RobustVLA delivers\nabsolute gains over baselines of 12.6% on the pi0 backbone and 10.4% on the\nOpenVLA backbone across all 17 perturbations, achieving 50.6x faster inference\nthan existing visual-robust VLAs, and a 10.4% gain under mixed perturbations.\nOur RobustVLA is particularly effective on real-world FR5 robot with limited\ndemonstrations, showing absolute gains by 65.6% under perturbations of four\nmodalities.",
    "published": "2025-09-26T14:42:23Z",
    "updated": "2025-10-28T09:55:21Z",
    "link": "http://arxiv.org/pdf/2510.00037v3.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Jianing Guo",
      "Zhenhong Wu",
      "Chang Tu",
      "Yiyao Ma",
      "Xiangqi Kong",
      "Zhiqian Liu",
      "Jiaming Ji",
      "Shuning Zhang",
      "Yuanpei Chen",
      "Kai Chen",
      "Qi Dou",
      "Yaodong Yang",
      "Xianglong Liu",
      "Huijie Zhao",
      "Weifeng Lv",
      "Simin Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23216v2",
    "title": "Human-Like Goalkeeping in a Realistic Football Simulation: a\n  Sample-Efficient Reinforcement Learning Approach",
    "summary": "While several high profile video games have served as testbeds for Deep\nReinforcement Learning (DRL), this technique has rarely been employed by the\ngame industry for crafting authentic AI behaviors. Previous research focuses on\ntraining super-human agents with large models, which is impractical for game\nstudios with limited resources aiming for human-like agents. This paper\nproposes a sample-efficient DRL method tailored for training and fine-tuning\nagents in industrial settings such as the video game industry. Our method\nimproves sample efficiency of value-based DRL by leveraging pre-collected data\nand increasing network plasticity. We evaluate our method training a goalkeeper\nagent in EA SPORTS FC 25, one of the best-selling football simulations today.\nOur agent outperforms the game's built-in AI by 10% in ball saving rate.\nAblation studies show that our method trains agents 50% faster compared to\nstandard DRL methods. Finally, qualitative evaluation from domain experts\nindicates that our approach creates more human-like gameplay compared to\nhand-crafted agents. As a testimony of the impact of the approach, the method\nis intended to replace the hand-crafted counterpart in next iterations of the\nseries.",
    "published": "2025-10-27T11:06:00Z",
    "updated": "2025-10-28T09:50:12Z",
    "link": "http://arxiv.org/pdf/2510.23216v2.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Alessandro Sestini",
      "Joakim Bergdahl",
      "Jean-Philippe Barrette-LaPierre",
      "Florian Fuchs",
      "Brady Chen",
      "Michael Jones",
      "Linus GisslÃ©n"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24242v1",
    "title": "Enabling Near-realtime Remote Sensing via Satellite-Ground Collaboration\n  of Large Vision-Language Models",
    "summary": "Large vision-language models (LVLMs) have recently demonstrated great\npotential in remote sensing (RS) tasks (e.g., disaster monitoring) conducted by\nlow Earth orbit (LEO) satellites. However, their deployment in real-world LEO\nsatellite systems remains largely unexplored, hindered by limited onboard\ncomputing resources and brief satellite-ground contacts. We propose Grace, a\nsatellite-ground collaborative system designed for near-realtime LVLM inference\nin RS tasks. Accordingly, we deploy compact LVLM on satellites for realtime\ninference, but larger ones on ground stations (GSs) to guarantee end-to-end\nperformance. Grace is comprised of two main phases that are asynchronous\nsatellite-GS Retrieval-Augmented Generation (RAG), and a task dispatch\nalgorithm. Firstly, we still the knowledge archive of GS RAG to satellite\narchive with tailored adaptive update algorithm during limited satellite-ground\ndata exchange period. Secondly, propose a confidence-based test algorithm that\neither processes the task onboard the satellite or offloads it to the GS.\nExtensive experiments based on real-world satellite orbital data show that\nGrace reduces the average latency by 76-95% compared to state-of-the-art\nmethods, without compromising inference accuracy.",
    "published": "2025-10-28T09:48:26Z",
    "updated": "2025-10-28T09:48:26Z",
    "link": "http://arxiv.org/pdf/2510.24242v1.pdf",
    "category": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Zihan Li",
      "Jiahao Yang",
      "Yuxin Zhang",
      "Zhe Chen",
      "Yue Gao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24241v1",
    "title": "MAGNET: A Multi-Graph Attentional Network for Code Clone Detection",
    "summary": "Code clone detection is a fundamental task in software engineering that\nunderpins refactoring, debugging, plagiarism detection, and vulnerability\nanalysis. Existing methods often rely on singular representations such as\nabstract syntax trees (ASTs), control flow graphs (CFGs), and data flow graphs\n(DFGs), which capture only partial aspects of code semantics. Hybrid approaches\nhave emerged, but their fusion strategies are typically handcrafted and\nineffective. In this study, we propose MAGNET, a multi-graph attentional\nframework that jointly leverages AST, CFG, and DFG representations to capture\nsyntactic and semantic features of source code. MAGNET integrates residual\ngraph neural networks with node-level self-attention to learn both local and\nlong-range dependencies, introduces a gated cross-attention mechanism for\nfine-grained inter-graph interactions, and employs Set2Set pooling to fuse\nmulti-graph embeddings into unified program-level representations. Extensive\nexperiments on BigCloneBench and Google Code Jam demonstrate that MAGNET\nachieves state-of-the-art performance with an overall F1 score of 96.5\\% and\n99.2\\% on the two datasets, respectively. Ablation studies confirm the critical\ncontributions of multi-graph fusion and each attentional component. Our code is\navailable at https://github.com/ZixianReid/Multigraph_match",
    "published": "2025-10-28T09:48:06Z",
    "updated": "2025-10-28T09:48:06Z",
    "link": "http://arxiv.org/pdf/2510.24241v1.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Zixian Zhang",
      "Takfarinas Saber"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24235v1",
    "title": "PaTaRM: Bridging Pairwise and Pointwise Signals via Preference-Aware\n  Task-Adaptive Reward Modeling",
    "summary": "Reward models (RMs) are central to reinforcement learning from human feedback\n(RLHF), providing the critical supervision signals that align large language\nmodels (LLMs) with human preferences. While generative reward models (GRMs)\noffer greater interpretability than traditional scalar RMs, current training\nparadigms remain limited. Pair-wise methods rely on binary good-versus-bad\nlabels, which cause mismatches for point-wise inference and necessitate complex\npairing strategies for effective application in RLHF. On the other hand,\npoint-wise methods require more elaborate absolute labeling with rubric-driven\ncriteria, resulting in poor adaptability and high annotation costs. In this\nwork, we propose the Preference-Aware Task-Adaptive Reward Model (PaTaRM), a\nunified framework that integrates a preference-aware reward (PAR) mechanism\nwith dynamic rubric adaptation. PaTaRM leverages relative preference\ninformation from pairwise data to construct robust point-wise training signals,\neliminating the need for explicit point-wise labels. Simultaneously, it employs\na task-adaptive rubric system that flexibly generates evaluation criteria for\nboth global task consistency and instance-specific fine-grained reasoning. This\ndesign enables efficient, generalizable, and interpretable reward modeling for\nRLHF. Extensive experiments show that PaTaRM achieves an average relative\nimprovement of 4.7% on RewardBench and RMBench across Qwen3-8B and Qwen3-14B\nmodels. Furthermore, PaTaRM boosts downstream RLHF performance, with an average\nimprovement of 13.6% across IFEval and InFoBench benchmarks, confirming its\neffectiveness and robustness. Our code is available at\nhttps://github.com/JaneEyre0530/PaTaRM.",
    "published": "2025-10-28T09:43:47Z",
    "updated": "2025-10-28T09:43:47Z",
    "link": "http://arxiv.org/pdf/2510.24235v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Ai Jian",
      "Jingqing Ruan",
      "Xing Ma",
      "Dailin Li",
      "QianLin Zhou",
      "Ke Zeng",
      "Xunliang Cai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.11930v2",
    "title": "The Logical Expressiveness of Temporal GNNs via Two-Dimensional Product\n  Logics",
    "summary": "In recent years, the expressive power of various neural architectures --\nincluding graph neural networks (GNNs), transformers, and recurrent neural\nnetworks -- has been characterised using tools from logic and formal language\ntheory. As the capabilities of basic architectures are becoming well\nunderstood, increasing attention is turning to models that combine multiple\narchitectural paradigms. Among them particularly important, and challenging to\nanalyse, are temporal extensions of GNNs, which integrate both spatial\n(graph-structure) and temporal (evolution over time) dimensions. In this paper,\nwe initiate the study of logical characterisation of temporal GNNs by\nconnecting them to two-dimensional product logics. We show that the expressive\npower of temporal GNNs depends on how graph and temporal components are\ncombined. In particular, temporal GNNs that apply static GNNs recursively over\ntime can capture all properties definable in the product logic of (past)\npropositional temporal logic PTL and the modal logic K. In contrast,\narchitectures such as graph-and-time TGNNs and global TGNNs can only express\nrestricted fragments of this logic, where the interaction between temporal and\nspatial operators is syntactically constrained. These provide us with the first\nresults on the logical expressiveness of temporal GNNs.",
    "published": "2025-05-17T09:34:57Z",
    "updated": "2025-10-28T09:43:41Z",
    "link": "http://arxiv.org/pdf/2505.11930v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.LO"
    ],
    "authors": [
      "Marco SÃ¤lzer",
      "PrzemysÅaw Andrzej WaÅÄga",
      "Martin Lange"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.16947v2",
    "title": "MixAT: Combining Continuous and Discrete Adversarial Training for LLMs",
    "summary": "Despite recent efforts in Large Language Model (LLM) safety and alignment,\ncurrent adversarial attacks on frontier LLMs can still consistently force\nharmful generations. Although adversarial training has been widely studied and\nshown to significantly improve the robustness of traditional machine learning\nmodels, its strengths and weaknesses in the context of LLMs are less\nunderstood. Specifically, while existing discrete adversarial attacks are\neffective at producing harmful content, training LLMs with concrete adversarial\nprompts is often computationally expensive, leading to reliance on continuous\nrelaxations. At the same time, despite their effectiveness and generalization\ncapabilities, training with continuous perturbations does not always capture\nthe full spectrum of vulnerabilities exploited by discrete attacks. In this\nwork, we aim to bridge this gap by introducing MixAT, a novel method that\ncombines stronger discrete and faster continuous attacks during training. We\nrigorously evaluate MixAT across a wide spectrum of state-of-the-art attacks,\nproposing the At Least One Attack Success Rate (ALO-ASR) metric to capture the\nworst-case vulnerability of models. We show MixAT achieves substantially better\nrobustness (ALO-ASR < 20%) compared to prior defenses (ALO-ASR > 50%), while\nmaintaining a runtime comparable to methods based on continuous relaxations. We\nfurther analyze MixAT in realistic deployment settings, exploring how chat\ntemplates, quantization, low-rank adapters, and temperature affect both\nadversarial training and evaluation, revealing additional blind spots in\ncurrent methodologies. Our results demonstrate that MixAT's discrete-continuous\ndefense offers a principled and superior robustness-accuracy tradeoff with\nminimal computational overhead, highlighting its promise for building safer\nLLMs. We provide our code and models at\nhttps://github.com/insait-institute/MixAT.",
    "published": "2025-05-22T17:32:50Z",
    "updated": "2025-10-28T09:41:22Z",
    "link": "http://arxiv.org/pdf/2505.16947v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "I.2.7; K.4.1"
    ],
    "authors": [
      "Csaba DÃ©kÃ¡ny",
      "Stefan Balauca",
      "Robin Staab",
      "Dimitar I. Dimitrov",
      "Martin Vechev"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.06041v3",
    "title": "DP-LLM: Runtime Model Adaptation with Dynamic Layer-wise Precision\n  Assignment",
    "summary": "How can we effectively handle queries for on-device large language models\n(LLMs) with varying runtime constraints, such as latency and accuracy?\nMulti-scale quantization addresses this challenge by enabling memory-efficient\nruntime model adaptation of LLMs through the overlaying of multiple model\nvariants quantized to different bitwidths. Meanwhile, an important question\nstill remains open-ended: how can models be properly configured to match a\ntarget precision or latency? While mixed-precision offers a promising solution,\nwe take this further by leveraging the key observation that the sensitivity of\neach layer dynamically changes across decoding steps. Building on this insight,\nwe introduce DP-LLM, a novel mechanism that dynamically assigns precision to\neach layer based on input values. Experimental results across multiple models\nand benchmarks demonstrate that DP-LLM achieves a superior performance-latency\ntrade-off, outperforming prior approaches.",
    "published": "2025-08-08T05:57:04Z",
    "updated": "2025-10-28T09:34:36Z",
    "link": "http://arxiv.org/pdf/2508.06041v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Sangwoo Kwon",
      "Seong Hoon Seo",
      "Jae W. Lee",
      "Yeonhong Park"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.17550v3",
    "title": "Is It Certainly a Deepfake? Reliability Analysis in Detection &\n  Generation Ecosystem",
    "summary": "As generative models are advancing in quality and quantity for creating\nsynthetic content, deepfakes begin to cause online mistrust. Deepfake detectors\nare proposed to counter this effect, however, misuse of detectors claiming fake\ncontent as real or vice versa further fuels this misinformation problem. We\npresent the first comprehensive uncertainty analysis of deepfake detectors,\nsystematically investigating how generative artifacts influence prediction\nconfidence. As reflected in detectors' responses, deepfake generators also\ncontribute to this uncertainty as their generative residues vary, so we cross\nthe uncertainty analysis of deepfake detectors and generators. Based on our\nobservations, the uncertainty manifold holds enough consistent information to\nleverage uncertainty for deepfake source detection. Our approach leverages\nBayesian Neural Networks and Monte Carlo dropout to quantify both aleatoric and\nepistemic uncertainties across diverse detector architectures. We evaluate\nuncertainty on two datasets with nine generators, with four blind and two\nbiological detectors, compare different uncertainty methods, explore region-\nand pixel-based uncertainty, and conduct ablation studies. We conduct and\nanalyze binary real/fake, multi-class real/fake, source detection, and\nleave-one-out experiments between the generator/detector combinations to share\ntheir generalization capability, model calibration, uncertainty, and robustness\nagainst adversarial attacks. We further introduce uncertainty maps that\nlocalize prediction confidence at the pixel level, revealing distinct patterns\ncorrelated with generator-specific artifacts. Our analysis provides critical\ninsights for deploying reliable deepfake detection systems and establishes\nuncertainty quantification as a fundamental requirement for trustworthy\nsynthetic media detection.",
    "published": "2025-09-22T09:09:13Z",
    "updated": "2025-10-28T09:32:18Z",
    "link": "http://arxiv.org/pdf/2509.17550v3.pdf",
    "category": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Neslihan Kose",
      "Anthony Rhodes",
      "Umur Aybars Ciftci",
      "Ilke Demir"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24217v1",
    "title": "Closing Gaps: An Imputation Analysis of ICU Vital Signs",
    "summary": "As more Intensive Care Unit (ICU) data becomes available, the interest in\ndeveloping clinical prediction models to improve healthcare protocols\nincreases. However, the lack of data quality still hinders clinical prediction\nusing Machine Learning (ML). Many vital sign measurements, such as heart rate,\ncontain sizeable missing segments, leaving gaps in the data that could\nnegatively impact prediction performance. Previous works have introduced\nnumerous time-series imputation techniques. Nevertheless, more comprehensive\nwork is needed to compare a representative set of methods for imputing ICU\nvital signs and determine the best practice. In reality, ad-hoc imputation\ntechniques that could decrease prediction accuracy, like zero imputation, are\nstill used. In this work, we compare established imputation techniques to guide\nresearchers in improving the performance of clinical prediction models by\nselecting the most accurate imputation technique. We introduce an extensible\nand reusable benchmark with currently 15 imputation and 4 amputation methods,\ncreated for benchmarking on major ICU datasets. We hope to provide a\ncomparative basis and facilitate further ML development to bring more models\ninto clinical practice.",
    "published": "2025-10-28T09:30:52Z",
    "updated": "2025-10-28T09:30:52Z",
    "link": "http://arxiv.org/pdf/2510.24217v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Alisher Turubayev",
      "Anna Shopova",
      "Fabian Lange",
      "Mahmut Kamalak",
      "Paul Mattes",
      "Victoria Ayvasky",
      "Bert Arnrich",
      "Bjarne Pfitzner",
      "Robin P. van de Water"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.06463v2",
    "title": "Accelerate Scaling of LLM Finetuning via Quantifying the Coverage and\n  Depth of Instruction Set",
    "summary": "Scaling the amount of data used for supervied fine-tuning(SFT) does not\nguarantee the proportional gains in model performance, highlighting a critical\nneed to understand what makes training samples effective. This work identifies\ntwo fundamental dataset properties that govern SFT scalability:\n\\textbf{semantic coverage}, or the breadth of task domains, and\n\\textbf{information depth}, or the richness of individual examples. We\ndemonstrate that simple proxies for these properties explain the majority of\nvalidation loss variance in our experiments. In this work, we further propose\nthe \\textbf{Information Landscape Approximation (ILA)}, a model-agnostic data\nselection framework that jointly optimizes for these two factors. ILA\nconstructs compact subsets that approximate the informational value of large\ndatasets. Empirical results show that models tuned on ILA-selected data achieve\nfaster and more sustained performance improvements across diverse tasks and\nmodel sizes compared to existing methods, a phenomenon we term\n\\textbf{accelerated scaling}.",
    "published": "2025-09-08T09:22:57Z",
    "updated": "2025-10-28T08:59:44Z",
    "link": "http://arxiv.org/pdf/2509.06463v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Chengwei Wu",
      "Li Du",
      "Hanyu Zhao",
      "Yiming Ju",
      "Jiapu Wang",
      "Tianyu Chen",
      "Haoyi Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.13898v3",
    "title": "Do Language Models Use Their Depth Efficiently?",
    "summary": "Modern LLMs are increasingly deep, and depth correlates with performance,\nalbeit with diminishing returns. However, do these models use their depth\nefficiently? Do they compose more features to create higher-order computations\nthat are impossible in shallow models, or do they merely spread the same kinds\nof computation out over more layers? To address these questions, we analyze the\nresidual stream of the Llama 3.1, Qwen 3, and OLMo 2 family of models. We find:\nFirst, comparing the output of the sublayers to the residual stream reveals\nthat layers in the second half contribute much less than those in the first\nhalf, with a clear phase transition between the two halves. Second, skipping\nlayers in the second half has a much smaller effect on future computations and\noutput predictions. Third, for multihop tasks, we are unable to find evidence\nthat models are using increased depth to compose subresults in examples\ninvolving many hops. Fourth, we seek to directly address whether deeper models\nare using their additional layers to perform new kinds of computation. To do\nthis, we train linear maps from the residual stream of a shallow model to a\ndeeper one. We find that layers with the same relative depth map best to each\nother, suggesting that the larger model simply spreads the same computations\nout over its many layers. All this evidence suggests that deeper models are not\nusing their depth to learn new kinds of computation, but only using the greater\ndepth to perform more fine-grained adjustments to the residual. This may help\nexplain why increasing scale leads to diminishing returns for stacked\nTransformer architectures.",
    "published": "2025-05-20T04:00:56Z",
    "updated": "2025-10-28T08:56:58Z",
    "link": "http://arxiv.org/pdf/2505.13898v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "authors": [
      "RÃ³bert CsordÃ¡s",
      "Christopher D. Manning",
      "Christopher Potts"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.13043v2",
    "title": "A Generalized Label Shift Perspective for Cross-Domain Gaze Estimation",
    "summary": "Aiming to generalize the well-trained gaze estimation model to new target\ndomains, Cross-domain Gaze Estimation (CDGE) is developed for real-world\napplication scenarios. Existing CDGE methods typically extract the\ndomain-invariant features to mitigate domain shift in feature space, which is\nproved insufficient by Generalized Label Shift (GLS) theory. In this paper, we\nintroduce a novel GLS perspective to CDGE and modelize the cross-domain problem\nby label and conditional shift problem. A GLS correction framework is presented\nand a feasible realization is proposed, in which a importance reweighting\nstrategy based on truncated Gaussian distribution is introduced to overcome the\ncontinuity challenges in label shift correction. To embed the reweighted source\ndistribution to conditional invariant learning, we further derive a\nprobability-aware estimation of conditional operator discrepancy. Extensive\nexperiments on standard CDGE tasks with different backbone models validate the\nsuperior generalization capability across domain and applicability on various\nmodels of proposed method.",
    "published": "2025-05-19T12:33:52Z",
    "updated": "2025-10-28T08:36:12Z",
    "link": "http://arxiv.org/pdf/2505.13043v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Hao-Ran Yang",
      "Xiaohui Chen",
      "Chuan-Xian Ren"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24178v1",
    "title": "MuSaG: A Multimodal German Sarcasm Dataset with Full-Modal Annotations",
    "summary": "Sarcasm is a complex form of figurative language in which the intended\nmeaning contradicts the literal one. Its prevalence in social media and popular\nculture poses persistent challenges for natural language understanding,\nsentiment analysis, and content moderation. With the emergence of multimodal\nlarge language models, sarcasm detection extends beyond text and requires\nintegrating cues from audio and vision. We present MuSaG, the first German\nmultimodal sarcasm detection dataset, consisting of 33 minutes of manually\nselected and human-annotated statements from German television shows. Each\ninstance provides aligned text, audio, and video modalities, annotated\nseparately by humans, enabling evaluation in unimodal and multimodal settings.\nWe benchmark nine open-source and commercial models, spanning text, audio,\nvision, and multimodal architectures, and compare their performance to human\nannotations. Our results show that while humans rely heavily on audio in\nconversational settings, models perform best on text. This highlights a gap in\ncurrent multimodal models and motivates the use of MuSaG for developing models\nbetter suited to realistic scenarios. We release MuSaG publicly to support\nfuture research on multimodal sarcasm detection and human-model alignment.",
    "published": "2025-10-28T08:33:45Z",
    "updated": "2025-10-28T08:33:45Z",
    "link": "http://arxiv.org/pdf/2510.24178v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Aaron Scott",
      "Maike ZÃ¼fle",
      "Jan Niehues"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2407.13195v6",
    "title": "Scalable Exploration via Ensemble++",
    "summary": "Thompson Sampling is a principled method for balancing exploration and\nexploitation, but its real-world adoption faces computational challenges in\nlarge-scale or non-conjugate settings. While ensemble-based approaches offer\npartial remedies, they typically require prohibitively large ensemble sizes. We\npropose Ensemble++, a scalable exploration framework using a novel\nshared-factor ensemble architecture with random linear combinations. For linear\nbandits, we provide theoretical guarantees showing that Ensemble++ achieves\nregret comparable to exact Thompson Sampling with only $\\Theta(d \\log T)$\nensemble sizes--significantly outperforming prior methods. Crucially, this\nefficiency holds across both compact and finite action sets with either\ntime-invariant or time-varying contexts without configuration changes. We\nextend this theoretical foundation to nonlinear rewards by replacing fixed\nfeatures with learnable neural representations while preserving the same\nincremental update principle, effectively bridging theory and practice for\nreal-world tasks. Comprehensive experiments across linear, quadratic, neural,\nand GPT-based contextual bandits validate our theoretical findings and\ndemonstrate Ensemble++'s superior regret-computation tradeoff versus\nstate-of-the-art methods.",
    "published": "2024-07-18T06:16:09Z",
    "updated": "2025-10-28T08:26:28Z",
    "link": "http://arxiv.org/pdf/2407.13195v6.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.HC",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ],
    "authors": [
      "Yingru Li",
      "Jiawei Xu",
      "Baoxiang Wang",
      "Zhi-Quan Luo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24170v1",
    "title": "SymMaP: Improving Computational Efficiency in Linear Solvers through\n  Symbolic Preconditioning",
    "summary": "Matrix preconditioning is a critical technique to accelerate the solution of\nlinear systems, where performance heavily depends on the selection of\npreconditioning parameters. Traditional parameter selection approaches often\ndefine fixed constants for specific scenarios. However, they rely on domain\nexpertise and fail to consider the instance-wise features for individual\nproblems, limiting their performance. In contrast, machine learning (ML)\napproaches, though promising, are hindered by high inference costs and limited\ninterpretability. To combine the strengths of both approaches, we propose a\nsymbolic discovery framework-namely, Symbolic Matrix Preconditioning\n(SymMaP)-to learn efficient symbolic expressions for preconditioning\nparameters. Specifically, we employ a neural network to search the\nhigh-dimensional discrete space for expressions that can accurately predict the\noptimal parameters. The learned expression allows for high inference efficiency\nand excellent interpretability (expressed in concise symbolic formulas), making\nit simple and reliable for deployment. Experimental results show that SymMaP\nconsistently outperforms traditional strategies across various benchmarks.",
    "published": "2025-10-28T08:25:03Z",
    "updated": "2025-10-28T08:25:03Z",
    "link": "http://arxiv.org/pdf/2510.24170v1.pdf",
    "category": [
      "math.NA",
      "cs.AI",
      "cs.NA"
    ],
    "authors": [
      "Hong Wang",
      "Jie Wang",
      "Minghao Ma",
      "Haoran Shao",
      "Haoyang Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24168v1",
    "title": "MGA: Memory-Driven GUI Agent for Observation-Centric Interaction",
    "summary": "The rapid progress of Large Language Models (LLMs) and their multimodal\nextensions (MLLMs) has enabled agentic systems capable of perceiving and acting\nacross diverse environments. A challenging yet impactful frontier is the\ndevelopment of GUI agents, which must navigate complex desktop and web\ninterfaces while maintaining robustness and generalization. Existing paradigms\ntypically model tasks as long-chain executions, concatenating historical\ntrajectories into the context. While approaches such as Mirage and GTA1 refine\nplanning or introduce multi-branch action selection, they remain constrained by\ntwo persistent issues: Dependence on historical trajectories, which amplifies\nerror propagation. And Local exploration bias, where \"decision-first,\nobservation-later\" mechanisms overlook critical interface cues. We introduce\nthe Memory-Driven GUI Agent (MGA), which reframes GUI interaction around the\nprinciple of observe first, then decide. MGA models each step as an\nindependent, context-rich environment state represented by a triad: current\nscreenshot, task-agnostic spatial information, and a dynamically updated\nstructured memory. Experiments on OSworld benchmarks, real desktop applications\n(Chrome, VSCode, VLC), and cross-task transfer demonstrate that MGA achieves\nsubstantial gains in robustness, generalization, and efficiency compared to\nstate-of-the-art baselines. The code is publicly available at:\n{https://anonymous.4open.science/r/MGA-3571}.",
    "published": "2025-10-28T08:19:58Z",
    "updated": "2025-10-28T08:19:58Z",
    "link": "http://arxiv.org/pdf/2510.24168v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Weihua Cheng",
      "Ersheng Ni",
      "Wenlong Wang",
      "Yifei Sun",
      "Junming Liu",
      "Wangyu Shen",
      "Yirong Chen",
      "Botian Shi",
      "Ding Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24166v1",
    "title": "UniPlanner: A Unified Motion Planning Framework for Autonomous Vehicle\n  Decision-Making Systems via Multi-Dataset Integration",
    "summary": "Motion planning is a critical component of autonomous vehicle decision-making\nsystems, directly determining trajectory safety and driving efficiency. While\ndeep learning approaches have advanced planning capabilities, existing methods\nremain confined to single-dataset training, limiting their robustness in\nplanning.\n  Through systematic analysis, we discover that vehicular trajectory\ndistributions and history-future correlations demonstrate remarkable\nconsistency across different datasets. Based on these findings, we propose\nUniPlanner, the first planning framework designed for multi-dataset integration\nin autonomous vehicle decision-making. UniPlanner achieves unified\ncross-dataset learning through three synergistic innovations.\n  First, the History-Future Trajectory Dictionary Network (HFTDN) aggregates\nhistory-future trajectory pairs from multiple datasets, using historical\ntrajectory similarity to retrieve relevant futures and generate cross-dataset\nplanning guidance.\n  Second, the Gradient-Free Trajectory Mapper (GFTM) learns robust\nhistory-future correlations from multiple datasets, transforming historical\ntrajectories into universal planning priors. Its gradient-free design ensures\nthe introduction of valuable priors while preventing shortcut learning, making\nthe planning knowledge safely transferable. Third, the Sparse-to-Dense (S2D)\nparadigm implements adaptive dropout to selectively suppress planning priors\nduring training for robust learning, while enabling full prior utilization\nduring inference to maximize planning performance.",
    "published": "2025-10-28T08:12:15Z",
    "updated": "2025-10-28T08:12:15Z",
    "link": "http://arxiv.org/pdf/2510.24166v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Xin Yang",
      "Yuhang Zhang",
      "Wei Li",
      "Xin Lin",
      "Wenbin Zou",
      "Chen Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.15805v3",
    "title": "FragFM: Hierarchical Framework for Efficient Molecule Generation via\n  Fragment-Level Discrete Flow Matching",
    "summary": "We introduce FragFM, a novel hierarchical framework via fragment-level\ndiscrete flow matching for efficient molecular graph generation. FragFM\ngenerates molecules at the fragment level, leveraging a coarse-to-fine\nautoencoder to reconstruct details at the atom level. Together with a\nstochastic fragment bag strategy to effectively handle an extensive fragment\nspace, our framework enables more efficient and scalable molecular generation.\nWe demonstrate that our fragment-based approach achieves better property\ncontrol than the atom-based method and additional flexibility through\nconditioning the fragment bag. We also propose a Natural Product Generation\nbenchmark (NPGen) to evaluate modern molecular graph generative models' ability\nto generate natural product-like molecules. Since natural products are\nbiologically prevalidated and differ from typical drug-like molecules, our\nbenchmark provides a more challenging yet meaningful evaluation relevant to\ndrug discovery. We conduct a FragFM comparative study against various models on\ndiverse molecular generation benchmarks, including NPGen, demonstrating\nsuperior performance. The results highlight the potential of fragment-based\ngenerative modeling for large-scale, property-aware molecular design, paving\nthe way for more efficient exploration of chemical space.",
    "published": "2025-02-19T07:01:00Z",
    "updated": "2025-10-28T08:12:05Z",
    "link": "http://arxiv.org/pdf/2502.15805v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "physics.chem-ph"
    ],
    "authors": [
      "Joongwon Lee",
      "Seonghwan Kim",
      "Seokhyun Moon",
      "Hyunwoo Kim",
      "Woo Youn Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.01271v4",
    "title": "PULSE: Practical Evaluation Scenarios for Large Multimodal Model\n  Unlearning",
    "summary": "In recent years, unlearning techniques, which are methods for inducing a\nmodel to \"forget\" previously learned information, have attracted attention as a\nway to address privacy and copyright concerns in large language models (LLMs)\nand large multimodal models (LMMs). While several unlearning benchmarks have\nbeen established for LLMs, a practical evaluation framework for unlearning in\nLMMs has been less explored. Specifically, existing unlearning benchmark for\nLMMs considers only scenarios in which the model is required to unlearn\nfine-tuned knowledge through a single unlearning operation. In this study, we\nintroduce PULSE protocol for realistic unlearning scenarios for LMMs by\nintroducing two critical perspectives: (i) Pre-trained knowledge Unlearning for\nanalyzing the effect across different knowledge acquisition phases and (ii)\nLong-term Sustainability Evaluation to address sequential requests. We then\nevaluate existing unlearning methods along these dimensions. Our results reveal\nthat, although some techniques can successfully unlearn knowledge acquired\nthrough fine-tuning, they struggle to eliminate information learned during\npre-training. Moreover, methods that effectively unlearn a batch of target data\nin a single operation exhibit substantial performance degradation when the same\ndata are split and unlearned sequentially.",
    "published": "2025-07-02T01:13:08Z",
    "updated": "2025-10-28T08:11:23Z",
    "link": "http://arxiv.org/pdf/2507.01271v4.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Tatsuki Kawakami",
      "Kazuki Egashira",
      "Atsuyuki Miyai",
      "Go Irie",
      "Kiyoharu Aizawa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.02999v2",
    "title": "Untargeted Jailbreak Attack",
    "summary": "Existing gradient-based jailbreak attacks on Large Language Models (LLMs),\nsuch as Greedy Coordinate Gradient (GCG) and COLD-Attack, typically optimize\nadversarial suffixes to align the LLM output with a predefined target response.\nHowever, by restricting the optimization objective as inducing a predefined\ntarget, these methods inherently constrain the adversarial search space, which\nlimit their overall attack efficacy. Furthermore, existing methods typically\nrequire a large number of optimization iterations to fulfill the large gap\nbetween the fixed target and the original model response, resulting in low\nattack efficiency.\n  To overcome the limitations of targeted jailbreak attacks, we propose the\nfirst gradient-based untargeted jailbreak attack (UJA), aiming to elicit an\nunsafe response without enforcing any predefined patterns. Specifically, we\nformulate an untargeted attack objective to maximize the unsafety probability\nof the LLM response, which can be quantified using a judge model. Since the\nobjective is non-differentiable, we further decompose it into two\ndifferentiable sub-objectives for optimizing an optimal harmful response and\nthe corresponding adversarial prompt, with a theoretical analysis to validate\nthe decomposition. In contrast to targeted jailbreak attacks, UJA's\nunrestricted objective significantly expands the search space, enabling a more\nflexible and efficient exploration of LLM vulnerabilities.Extensive evaluations\ndemonstrate that UJA can achieve over 80% attack success rates against recent\nsafety-aligned LLMs with only 100 optimization iterations, outperforming the\nstate-of-the-art gradient-based attacks such as I-GCG and COLD-Attack by over\n20%.",
    "published": "2025-10-03T13:38:56Z",
    "updated": "2025-10-28T08:06:26Z",
    "link": "http://arxiv.org/pdf/2510.02999v2.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Xinzhe Huang",
      "Wenjing Hu",
      "Tianhang Zheng",
      "Kedong Xiu",
      "Xiaojun Jia",
      "Di Wang",
      "Zhan Qin",
      "Kui Ren"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24161v1",
    "title": "BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and\n  Cross-Embodiment Learning",
    "summary": "Multimodal large language models (MLLMs) have advanced vision-language\nreasoning and are increasingly deployed in embodied agents. However,\nsignificant limitations remain: MLLMs generalize poorly across digital-physical\nspaces and embodiments; vision-language-action models (VLAs) produce low-level\nactions yet lack robust high-level embodied reasoning; and most embodied large\nlanguage models (ELLMs) are constrained to digital-space with poor\ngeneralization to the physical world. Thus, unified models that operate\nseamlessly across digital and physical spaces while generalizing across\nembodiments and tasks remain absent. We introduce the \\textbf{Boundless Large\nModel (BLM$_1$)}, a multimodal spatial foundation model that preserves\ninstruction following and reasoning, incorporates embodied knowledge, and\nsupports robust cross-embodiment control. BLM$_1$ integrates three key\ncapabilities -- \\textit{cross-space transfer, cross-task learning, and\ncross-embodiment generalization} -- via a two-stage training paradigm. Stage I\ninjects embodied knowledge into the MLLM through curated digital corpora while\nmaintaining language competence. Stage II trains a policy module through an\nintent-bridging interface that extracts high-level semantics from the MLLM to\nguide control, without fine-tuning the MLLM backbone. This process is supported\nby a self-collected cross-embodiment demonstration suite spanning four robot\nembodiments and six progressively challenging tasks. Evaluations across digital\nand physical benchmarks show that a single BLM$_1$ instance outperforms four\nmodel families -- MLLMs, ELLMs, VLAs, and GMLMs -- achieving\n$\\sim\\!\\textbf{6%}$ gains in digital tasks and $\\sim\\!\\textbf{3%}$ in physical\ntasks.",
    "published": "2025-10-28T07:58:39Z",
    "updated": "2025-10-28T07:58:39Z",
    "link": "http://arxiv.org/pdf/2510.24161v1.pdf",
    "category": [
      "cs.AI",
      "cs.MM",
      "cs.RO"
    ],
    "authors": [
      "Wentao Tan",
      "Bowen Wang",
      "Heng Zhi",
      "Chenyu Liu",
      "Zhe Li",
      "Jian Liu",
      "Zengrong Lin",
      "Yukun Dai",
      "Yipeng Chen",
      "Wenjie Yang",
      "Enci Xie",
      "Hao Xue",
      "Baixu Ji",
      "Chen Xu",
      "Zhibin Wang",
      "Tianshi Wang",
      "Lei Zhu",
      "Heng Tao Shen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.08263v2",
    "title": "Co-TAP: Three-Layer Agent Interaction Protocol Technical Report",
    "summary": "This paper proposes Co-TAP (T: Triple, A: Agent, P: Protocol), a three-layer\nagent interaction protocol designed to address the challenges faced by\nmulti-agent systems across the three core dimensions of Interoperability,\nInteraction and Collaboration, and Knowledge Sharing. We have designed and\nproposed a layered solution composed of three core protocols: the Human-Agent\nInteraction Protocol (HAI), the Unified Agent Protocol (UAP), and the\nMemory-Extraction-Knowledge Protocol (MEK). HAI focuses on the interaction\nlayer, standardizing the flow of information between users, interfaces, and\nagents by defining a standardized, event-driven communication paradigm. This\nensures the real-time performance, reliability, and synergy of interactions. As\nthe core of the infrastructure layer, UAP is designed to break down\ncommunication barriers among heterogeneous agents through unified service\ndiscovery and protocol conversion mechanisms, thereby enabling seamless\ninterconnection and interoperability of the underlying network. MEK, in turn,\noperates at the cognitive layer. By establishing a standardized ''Memory (M) -\nExtraction (E) - Knowledge (K)'' cognitive chain, it empowers agents with the\nability to learn from individual experiences and form shareable knowledge,\nthereby laying the foundation for the realization of true collective\nintelligence. We believe this protocol framework will provide a solid\nengineering foundation and theoretical guidance for building the next\ngeneration of efficient, scalable, and intelligent multi-agent applications.",
    "published": "2025-10-09T14:20:19Z",
    "updated": "2025-10-28T07:56:58Z",
    "link": "http://arxiv.org/pdf/2510.08263v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Shunyu An",
      "Miao Wang",
      "Yongchao Li",
      "Dong Wan",
      "Lina Wang",
      "Ling Qin",
      "Liqin Gao",
      "Congyao Fan",
      "Zhiyong Mao",
      "Jiange Pu",
      "Wenji Xia",
      "Dong Zhao",
      "Zhaohui Hao",
      "Rui Hu",
      "Ji Lu",
      "Guiyue Zhou",
      "Baoyu Tang",
      "Yanqin Gao",
      "Yongsheng Du",
      "Daigang Xu",
      "Lingjun Huang",
      "Baoli Wang",
      "Xiwen Zhang",
      "Luyao Wang",
      "Shilong Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24159v1",
    "title": "Self-supervised Synthetic Pretraining for Inference of Stellar Mass\n  Embedded in Dense Gas",
    "summary": "Stellar mass is a fundamental quantity that determines the properties and\nevolution of stars. However, estimating stellar masses in star-forming regions\nis challenging because young stars are obscured by dense gas and the regions\nare highly inhomogeneous, making spherical dynamical estimates unreliable.\nSupervised machine learning could link such complex structures to stellar mass,\nbut it requires large, high-quality labeled datasets from high-resolution\nmagneto-hydrodynamical (MHD) simulations, which are computationally expensive.\nWe address this by pretraining a vision transformer on one million synthetic\nfractal images using the self-supervised framework DINOv2, and then applying\nthe frozen model to limited high-resolution MHD simulations. Our results\ndemonstrate that synthetic pretraining improves frozen-feature regression\nstellar mass predictions, with the pretrained model performing slightly better\nthan a supervised model trained on the same limited simulations. Principal\ncomponent analysis of the extracted features further reveals semantically\nmeaningful structures, suggesting that the model enables unsupervised\nsegmentation of star-forming regions without the need for labeled data or\nfine-tuning.",
    "published": "2025-10-28T07:55:34Z",
    "updated": "2025-10-28T07:55:34Z",
    "link": "http://arxiv.org/pdf/2510.24159v1.pdf",
    "category": [
      "astro-ph.GA",
      "astro-ph.IM",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Keiya Hirashima",
      "Shingo Nozaki",
      "Naoto Harada"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24152v1",
    "title": "Enhancing Vision-Language Models for Autonomous Driving through\n  Task-Specific Prompting and Spatial Reasoning",
    "summary": "This technical report presents our solution for the RoboSense Challenge at\nIROS 2025, which evaluates Vision-Language Models (VLMs) on autonomous driving\nscene understanding across perception, prediction, planning, and corruption\ndetection tasks. We propose a systematic framework built on four core\ncomponents. First, a Mixture-of-Prompts router classifies questions and\ndispatches them to task-specific expert prompts, eliminating interference\nacross diverse question types. Second, task-specific prompts embed explicit\ncoordinate systems, spatial reasoning rules, role-playing,\nChain-of-Thought/Tree-of-Thought reasoning, and few-shot examples tailored to\neach task. Third, a visual assembly module composes multi-view images with\nobject crops, magenta markers, and adaptive historical frames based on question\nrequirements. Fourth, we configure model inference parameters (temperature,\ntop-p, message roles) per task to optimize output quality. Implemented on\nQwen2.5-VL-72B, our approach achieves 70.87% average accuracy on Phase-1 (clean\ndata) and 72.85% on Phase-2 (corrupted data), demonstrating that structured\nprompting and spatial grounding substantially enhance VLM performance on\nsafety-critical autonomous driving tasks. Code and prompt are available at\nhttps://github.com/wuaodi/UCAS-CSU-phase2.",
    "published": "2025-10-28T07:43:30Z",
    "updated": "2025-10-28T07:43:30Z",
    "link": "http://arxiv.org/pdf/2510.24152v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Aodi Wu",
      "Xubo Luo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24151v1",
    "title": "BMGQ: A Bottom-up Method for Generating Complex Multi-hop Reasoning\n  Questions from Semi-structured Data",
    "summary": "Building training-ready multi-hop question answering (QA) datasets that truly\nstress a model's retrieval and reasoning abilities remains highly challenging\nrecently. While there have been a few recent evaluation datasets that capture\nthe characteristics of hard-to-search but easy-to-verify problems -- requiring\nthe integration of ambiguous, indirect, and cross-domain cues -- these data\nresources remain scarce and are mostly designed for evaluation, making them\nunsuitable for supervised fine-tuning (SFT) or reinforcement learning (RL).\nMeanwhile, manually curating non-trivially retrievable questions -- where\nanswers cannot be found through a single direct query but instead require\nmulti-hop reasoning over oblique and loosely connected evidence -- incurs\nprohibitive human costs and fails to scale, creating a critical data bottleneck\nfor training high-capability retrieval-and-reasoning agents.\n  To address this, we present an automated framework for generating\nhigh-difficulty, training-ready multi-hop questions from semi-structured\nknowledge sources. The system (i) grows diverse, logically labeled evidence\nclusters through Natural Language Inference (NLI)-based relation typing and\ndiversity-aware expansion; (ii) applies reverse question construction to\ncompose oblique cues so that isolated signals are underinformative but their\ncombination uniquely identifies the target entity; and (iii) enforces quality\nwith a two-step evaluation pipeline that combines multi-model consensus\nfiltering with structured constraint decomposition and evidence-based matching.\nThe result is a scalable process that yields complex, retrieval-resistant yet\nverifiable questions suitable for SFT/RL training as well as challenging\nevaluation, substantially reducing human curation effort while preserving the\ndifficulty profile of strong evaluation benchmarks.",
    "published": "2025-10-28T07:43:15Z",
    "updated": "2025-10-28T07:43:15Z",
    "link": "http://arxiv.org/pdf/2510.24151v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Bingsen Qiu",
      "Zijian Liu",
      "Xiao Liu",
      "Haoshen Yang",
      "Zeren Gao",
      "Bingjie Wang",
      "Feier Zhang",
      "Yixuan Qin",
      "Chunyan Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24150v1",
    "title": "Ko-MuSR: A Multistep Soft Reasoning Benchmark for LLMs Capable of\n  Understanding Korean",
    "summary": "We present Ko-MuSR, the first benchmark to comprehensively evaluate\nmultistep, soft reasoning in long Korean narratives while minimizing data\ncontamination. Built following MuSR, Ko-MuSR features fully Korean narratives,\nreasoning chains, and multiple-choice questions verified by human annotators\nfor logical consistency and answerability. Evaluations of four large language\nmodels -- two multilingual and two Korean-specialized -- show that multilingual\nmodels outperform Korean-focused ones even in Korean reasoning tasks,\nindicating cross-lingual generalization of reasoning ability. Carefully\ndesigned prompting strategies, which combine few-shot examples, reasoning\ntraces, and task-specific hints, further boost accuracy, approaching\nhuman-level performance. Ko-MuSR offers a solid foundation for advancing Korean\nNLP by enabling systematic evaluation of long-context reasoning and prompting\nstrategies.",
    "published": "2025-10-28T07:42:59Z",
    "updated": "2025-10-28T07:42:59Z",
    "link": "http://arxiv.org/pdf/2510.24150v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Chanwoo Park",
      "Suyoung Park",
      "JiA Kang",
      "Jongyeon Park",
      "Sangho Kim",
      "Hyunji M. Park",
      "Sumin Bae",
      "Mingyu Kang",
      "Jaejin Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24145v1",
    "title": "From Observability Data to Diagnosis: An Evolving Multi-agent System for\n  Incident Management in Cloud Systems",
    "summary": "Incident management (IM) is central to the reliability of large-scale cloud\nsystems. Yet manual IM, where on-call engineers examine metrics, logs, and\ntraces is labor-intensive and error-prone in the face of massive and\nheterogeneous observability data. Existing automated IM approaches often\nstruggle to generalize across systems, provide limited interpretability, and\nincur high deployment costs, which hinders adoption in practice. In this paper,\nwe present OpsAgent, a lightweight, self-evolving multi-agent system for IM\nthat employs a training-free data processor to convert heterogeneous\nobservability data into structured textual descriptions, along with a\nmulti-agent collaboration framework that makes diagnostic inference transparent\nand auditable. To support continual capability growth, OpsAgent also introduces\na dual self-evolution mechanism that integrates internal model updates with\nexternal experience accumulation, thereby closing the deployment loop.\nComprehensive experiments on the OPENRCA benchmark demonstrate state-of-the-art\nperformance and show that OpsAgent is generalizable, interpretable,\ncost-efficient, and self-evolving, making it a practically deployable and\nsustainable solution for long-term operation in real-world cloud systems.",
    "published": "2025-10-28T07:38:15Z",
    "updated": "2025-10-28T07:38:15Z",
    "link": "http://arxiv.org/pdf/2510.24145v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Yu Luo",
      "Jiamin Jiang",
      "Jingfei Feng",
      "Lei Tao",
      "Qingliang Zhang",
      "Xidao Wen",
      "Yongqian Sun",
      "Shenglin Zhang",
      "Jielong Huang",
      "Nan Qi",
      "Dan Pei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.22092v3",
    "title": "VIRAL: Vision-grounded Integration for Reward design And Learning",
    "summary": "The alignment between humans and machines is a critical challenge in\nartificial intelligence today. Reinforcement learning, which aims to maximize a\nreward function, is particularly vulnerable to the risks associated with poorly\ndesigned reward functions. Recent advancements has shown that Large Language\nModels (LLMs) for reward generation can outperform human performance in this\ncontext. We introduce VIRAL, a pipeline for generating and refining reward\nfunctions through the use of multi-modal LLMs. VIRAL autonomously creates and\ninteractively improves reward functions based on a given environment and a goal\nprompt or annotated image. The refinement process can incorporate human\nfeedback or be guided by a description generated by a video LLM, which explains\nthe agent's policy in video form. We evaluated VIRAL in five Gymnasium\nenvironments, demonstrating that it accelerates the learning of new behaviors\nwhile ensuring improved alignment with user intent. The source-code and demo\nvideo are available at: https://github.com/VIRAL-UCBL1/VIRAL and\nhttps://youtu.be/Hqo82CxVT38.",
    "published": "2025-05-28T08:16:09Z",
    "updated": "2025-10-28T07:37:35Z",
    "link": "http://arxiv.org/pdf/2505.22092v3.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Valentin Cuzin-Rambaud",
      "Emilien Komlenovic",
      "Alexandre Faure",
      "Bruno Yun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.20280v2",
    "title": "Context-level Language Modeling by Learning Predictive Context\n  Embeddings",
    "summary": "Next-token prediction (NTP) is the cornerstone of modern large language\nmodels (LLMs) pretraining, driving their unprecedented capabilities in text\ngeneration, reasoning, and instruction following. However, the token-level\nprediction limits the model's capacity to capture higher-level semantic\nstructures and long-range contextual relationships. To overcome this\nlimitation, we introduce \\textbf{ContextLM}, a framework that augments standard\npretraining with an inherent \\textbf{next-context prediction} objective. This\nmechanism trains the model to learn predictive representations of multi-token\ncontexts, leveraging error signals derived from future token chunks. Crucially,\nContextLM achieves this enhancement while remaining fully compatible with the\nstandard autoregressive, token-by-token evaluation paradigm (e.g., perplexity).\nExtensive experiments on the GPT2 and Pythia model families, scaled up to\n$1.5$B parameters, show that ContextLM delivers consistent improvements in both\nperplexity and downstream task performance. Our analysis indicates that\nnext-context prediction provides a scalable and efficient pathway to stronger\nlanguage modeling, yielding better long-range coherence and more effective\nattention allocation with minimal computational overhead.",
    "published": "2025-10-23T07:09:45Z",
    "updated": "2025-10-28T07:35:34Z",
    "link": "http://arxiv.org/pdf/2510.20280v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Beiya Dai",
      "Yuliang Liu",
      "Daozheng Xue",
      "Qipeng Guo",
      "Kai Chen",
      "Xinbing Wang",
      "Bowen Zhou",
      "Zhouhan Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24139v1",
    "title": "Beyond Line-Level Filtering for the Pretraining Corpora of LLMs",
    "summary": "While traditional line-level filtering techniques, such as line-level\ndeduplication and trailing-punctuation filters, are commonly used, these basic\nmethods can sometimes discard valuable content, negatively affecting downstream\nperformance. In this paper, we introduce two methods-pattern-aware line-level\ndeduplication (PLD) and pattern-aware trailing punctuation filtering (PTF)-by\nenhancing the conventional filtering techniques. Our approach not only\nconsiders line-level signals but also takes into account their sequential\ndistribution across documents, enabling us to retain structurally important\ncontent that might otherwise be removed. We evaluate these proposed methods by\ntraining small language models (1 B parameters) in both English and Korean. The\nresults demonstrate that our methods consistently improve performance on\nmultiple-choice benchmarks and significantly enhance generative\nquestion-answering accuracy on both SQuAD v1 and KorQuAD v1.",
    "published": "2025-10-28T07:24:32Z",
    "updated": "2025-10-28T07:24:32Z",
    "link": "http://arxiv.org/pdf/2510.24139v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Chanwoo Park",
      "Suyoung Park",
      "Yelim Ahn",
      "Jongmin Kim",
      "Jongyeon Park",
      "Jaejin Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24134v1",
    "title": "VC4VG: Optimizing Video Captions for Text-to-Video Generation",
    "summary": "Recent advances in text-to-video (T2V) generation highlight the critical role\nof high-quality video-text pairs in training models capable of producing\ncoherent and instruction-aligned videos. However, strategies for optimizing\nvideo captions specifically for T2V training remain underexplored. In this\npaper, we introduce VC4VG (Video Captioning for Video Generation), a\ncomprehensive caption optimization framework tailored to the needs of T2V\nmodels.We begin by analyzing caption content from a T2V perspective,\ndecomposing the essential elements required for video reconstruction into\nmultiple dimensions, and proposing a principled caption design methodology. To\nsupport evaluation, we construct VC4VG-Bench, a new benchmark featuring\nfine-grained, multi-dimensional, and necessity-graded metrics aligned with\nT2V-specific requirements.Extensive T2V fine-tuning experiments demonstrate a\nstrong correlation between improved caption quality and video generation\nperformance, validating the effectiveness of our approach. We release all\nbenchmark tools and code at https://github.com/qyr0403/VC4VG to support further\nresearch.",
    "published": "2025-10-28T07:19:01Z",
    "updated": "2025-10-28T07:19:01Z",
    "link": "http://arxiv.org/pdf/2510.24134v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Yang Du",
      "Zhuoran Lin",
      "Kaiqiang Song",
      "Biao Wang",
      "Zhicheng Zheng",
      "Tiezheng Ge",
      "Bo Zheng",
      "Qin Jin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24133v1",
    "title": "Compositional Image Synthesis with Inference-Time Scaling",
    "summary": "Despite their impressive realism, modern text-to-image models still struggle\nwith compositionality, often failing to render accurate object counts,\nattributes, and spatial relations. To address this challenge, we present a\ntraining-free framework that combines an object-centric approach with\nself-refinement to improve layout faithfulness while preserving aesthetic\nquality. Specifically, we leverage large language models (LLMs) to synthesize\nexplicit layouts from input prompts, and we inject these layouts into the image\ngeneration process, where a object-centric vision-language model (VLM) judge\nreranks multiple candidates to select the most prompt-aligned outcome\niteratively. By unifying explicit layout-grounding with self-refine-based\ninference-time scaling, our framework achieves stronger scene alignment with\nprompts compared to recent text-to-image models. The code are available at\nhttps://github.com/gcl-inha/ReFocus.",
    "published": "2025-10-28T07:16:21Z",
    "updated": "2025-10-28T07:16:21Z",
    "link": "http://arxiv.org/pdf/2510.24133v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Minsuk Ji",
      "Sanghyeok Lee",
      "Namhyuk Ahn"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.14111v8",
    "title": "CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement\n  Learning",
    "summary": "The exponential growth in demand for GPU computing resources has created an\nurgent need for automated CUDA optimization strategies. While recent advances\nin LLMs show promise for code generation, current SOTA models achieve low\nsuccess rates in improving CUDA speed. In this paper, we introduce CUDA-L1, an\nautomated reinforcement learning framework for CUDA optimization that employs a\nnovel contrastive RL algorithm.\n  CUDA-L1 achieves significant performance improvements on the CUDA\noptimization task: trained on A100, it delivers an average speedup of x3.12\nwith a median speedup of x1.42 against default baselines over across all 250\nCUDA kernels of KernelBench, with peak speedups reaching x120. In addition to\nthe default baseline provided by KernelBench, CUDA-L1 demonstrates x2.77 over\nTorch Compile, x2.88 over Torch Compile with reduce overhead, x2.81 over CUDA\nGraph implementations, and remarkably x7.72 over cuDNN libraries. Furthermore,\nthe model also demonstrates portability across different GPU architectures.\n  Beyond these benchmark results, CUDA-L1 demonstrates several properties: it\n1) discovers a variety of CUDA optimization techniques and learns to combine\nthem strategically to achieve optimal performance; 2) uncovers fundamental\nprinciples of CUDA optimization, such as the multiplicative nature of\noptimizations; 3) identifies non-obvious performance bottlenecks and rejects\nseemingly beneficial optimizations that actually harm performance. The\ncapabilities demonstrate that, RL can transform an initially poor-performing\nLLM into an effective CUDA optimizer through speedup-based reward signals\nalone, without human expertise or domain knowledge. This paradigm opens\npossibilities for automated optimization of CUDA operations, and holds promise\nto substantially promote GPU efficiency and alleviate the rising pressure on\nGPU computing resources.",
    "published": "2025-07-18T17:43:56Z",
    "updated": "2025-10-28T07:04:44Z",
    "link": "http://arxiv.org/pdf/2507.14111v8.pdf",
    "category": [
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "authors": [
      "Xiaoya Li",
      "Xiaofei Sun",
      "Albert Wang",
      "Jiwei Li",
      "Chris Shum"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.05426v3",
    "title": "Mixture-of-Experts Meets In-Context Reinforcement Learning",
    "summary": "In-context reinforcement learning (ICRL) has emerged as a promising paradigm\nfor adapting RL agents to downstream tasks through prompt conditioning.\nHowever, two notable challenges remain in fully harnessing in-context learning\nwithin RL domains: the intrinsic multi-modality of the state-action-reward data\nand the diverse, heterogeneous nature of decision tasks. To tackle these\nchallenges, we propose T2MIR (Token- and Task-wise MoE for In-context RL), an\ninnovative framework that introduces architectural advances of\nmixture-of-experts (MoE) into transformer-based decision models. T2MIR\nsubstitutes the feedforward layer with two parallel layers: a token-wise MoE\nthat captures distinct semantics of input tokens across multiple modalities,\nand a task-wise MoE that routes diverse tasks to specialized experts for\nmanaging a broad task distribution with alleviated gradient conflicts. To\nenhance task-wise routing, we introduce a contrastive learning method that\nmaximizes the mutual information between the task and its router\nrepresentation, enabling more precise capture of task-relevant information. The\noutputs of two MoE components are concatenated and fed into the next layer.\nComprehensive experiments show that T2MIR significantly facilitates in-context\nlearning capacity and outperforms various types of baselines. We bring the\npotential and promise of MoE to ICRL, offering a simple and scalable\narchitectural enhancement to advance ICRL one step closer toward achievements\nin language and vision communities. Our code is available at\nhttps://github.com/NJU-RL/T2MIR.",
    "published": "2025-06-05T06:29:14Z",
    "updated": "2025-10-28T06:55:14Z",
    "link": "http://arxiv.org/pdf/2506.05426v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Wenhao Wu",
      "Fuhong Liu",
      "Haoru Li",
      "Zican Hu",
      "Daoyi Dong",
      "Chunlin Chen",
      "Zhi Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24118v1",
    "title": "LagMemo: Language 3D Gaussian Splatting Memory for Multi-modal\n  Open-vocabulary Multi-goal Visual Navigation",
    "summary": "Navigating to a designated goal using visual information is a fundamental\ncapability for intelligent robots. Most classical visual navigation methods are\nrestricted to single-goal, single-modality, and closed set goal settings. To\naddress the practical demands of multi-modal, open-vocabulary goal queries and\nmulti-goal visual navigation, we propose LagMemo, a navigation system that\nleverages a language 3D Gaussian Splatting memory. During exploration, LagMemo\nconstructs a unified 3D language memory. With incoming task goals, the system\nqueries the memory, predicts candidate goal locations, and integrates a local\nperception-based verification mechanism to dynamically match and validate goals\nduring navigation. For fair and rigorous evaluation, we curate GOAT-Core, a\nhigh-quality core split distilled from GOAT-Bench tailored to multi-modal\nopen-vocabulary multi-goal visual navigation. Experimental results show that\nLagMemo's memory module enables effective multi-modal open-vocabulary goal\nlocalization, and that LagMemo outperforms state-of-the-art methods in\nmulti-goal visual navigation. Project page:\nhttps://weekgoodday.github.io/lagmemo",
    "published": "2025-10-28T06:42:21Z",
    "updated": "2025-10-28T06:42:21Z",
    "link": "http://arxiv.org/pdf/2510.24118v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Haotian Zhou",
      "Xiaole Wang",
      "He Li",
      "Fusheng Sun",
      "Shengyu Guo",
      "Guolei Qi",
      "Jianghuan Xu",
      "Huijing Zhao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24115v1",
    "title": "HistoLens: An Interactive XAI Toolkit for Verifying and Mitigating Flaws\n  in Vision-Language Models for Histopathology",
    "summary": "For doctors to truly trust artificial intelligence, it can't be a black box.\nThey need to understand its reasoning, almost as if they were consulting a\ncolleague. We created HistoLens1 to be that transparent, collaborative partner.\nIt allows a pathologist to simply ask a question in plain English about a\ntissue slide--just as they would ask a trainee. Our system intelligently\ntranslates this question into a precise query for its AI engine, which then\nprovides a clear, structured report. But it doesn't stop there. If a doctor\never asks, \"Why?\", HistoLens can instantly provide a 'visual proof' for any\nfinding--a heatmap that points to the exact cells and regions the AI used for\nits analysis. We've also ensured the AI focuses only on the patient's tissue,\njust like a trained pathologist would, by teaching it to ignore distracting\nbackground noise. The result is a workflow where the pathologist remains the\nexpert in charge, using a trustworthy AI assistant to verify their insights and\nmake faster, more confident diagnoses.",
    "published": "2025-10-28T06:38:59Z",
    "updated": "2025-10-28T06:38:59Z",
    "link": "http://arxiv.org/pdf/2510.24115v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Sandeep Vissapragada",
      "Vikrant Sahu",
      "Gagan Raj Gupta",
      "Vandita Singh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.17939v2",
    "title": "GEMeX-RMCoT: An Enhanced Med-VQA Dataset for Region-Aware Multimodal\n  Chain-of-Thought Reasoning",
    "summary": "Medical visual question answering aims to support clinical decision-making by\nenabling models to answer natural language questions based on medical images.\nWhile recent advances in multi-modal learning have significantly improved\nperformance, current methods still suffer from limited answer reliability and\npoor interpretability, impairing the ability of clinicians and patients to\nunderstand and trust model outputs. To address these limitations, this work\nfirst proposes a Region-Aware Multimodal Chain-of-Thought (RMCoT) dataset, in\nwhich the process of producing an answer is preceded by a sequence of\nintermediate reasoning steps that explicitly ground relevant visual regions of\nthe medical image, thereby providing fine-grained explainability. Furthermore,\nwe introduce a novel verifiable reward mechanism for reinforcement learning to\nguide post-training, improving the alignment between the model's reasoning\nprocess and its final answer. Remarkably, our method achieves comparable\nperformance using only one-eighth of the training data, demonstrating the\nefficiency and effectiveness of the proposal. The dataset is available at\nhttps://www.med-vqa.com/GEMeX/.",
    "published": "2025-06-22T08:09:58Z",
    "updated": "2025-10-28T06:37:24Z",
    "link": "http://arxiv.org/pdf/2506.17939v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Bo Liu",
      "Xiangyu Zhao",
      "Along He",
      "Yidi Chen",
      "Huazhu Fu",
      "Xiao-Ming Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24113v1",
    "title": "Taming the Tail: NoI Topology Synthesis for Mixed DL Workloads on\n  Chiplet-Based Accelerators",
    "summary": "Heterogeneous chiplet-based systems improve scaling by disag-gregating\nCPUs/GPUs and emerging technologies (HBM/DRAM).However this on-package\ndisaggregation introduces a latency inNetwork-on-Interposer(NoI). We observe\nthat in modern large-modelinference, parameters and activations routinely move\nbackand forth from HBM/DRAM, injecting large, bursty flows into theinterposer.\nThese memory-driven transfers inflate tail latency andviolate Service Level\nAgreements (SLAs) across k-ary n-cube base-line NoI topologies. To address this\ngap we introduce an InterferenceScore (IS) that quantifies worst-case slowdown\nunder contention.We then formulate NoI synthesis as a multi-objective\noptimization(MOO) problem. We develop PARL (Partition-Aware\nReinforcementLearner), a topology generator that balances throughput,\nlatency,and power. PARL-generated topologies reduce contention at the memory\ncut, meet SLAs, and cut worst-case slowdown to 1.2 times while maintaining\ncompetitive mean throughput relative to link-rich meshes. Overall, this\nreframes NoI design for heterogeneouschiplet accelerators with workload-aware\nobjectives.",
    "published": "2025-10-28T06:36:44Z",
    "updated": "2025-10-28T06:36:44Z",
    "link": "http://arxiv.org/pdf/2510.24113v1.pdf",
    "category": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Arnav Shukla",
      "Harsh Sharma",
      "Srikant Bharadwaj",
      "Vinayak Abrol",
      "Sujay Deb"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24103v1",
    "title": "Model-Guided Dual-Role Alignment for High-Fidelity Open-Domain\n  Video-to-Audio Generation",
    "summary": "We present MGAudio, a novel flow-based framework for open-domain\nvideo-to-audio generation, which introduces model-guided dual-role alignment as\na central design principle. Unlike prior approaches that rely on\nclassifier-based or classifier-free guidance, MGAudio enables the generative\nmodel to guide itself through a dedicated training objective designed for\nvideo-conditioned audio generation. The framework integrates three main\ncomponents: (1) a scalable flow-based Transformer model, (2) a dual-role\nalignment mechanism where the audio-visual encoder serves both as a\nconditioning module and as a feature aligner to improve generation quality, and\n(3) a model-guided objective that enhances cross-modal coherence and audio\nrealism. MGAudio achieves state-of-the-art performance on VGGSound, reducing\nFAD to 0.40, substantially surpassing the best classifier-free guidance\nbaselines, and consistently outperforms existing methods across FD, IS, and\nalignment metrics. It also generalizes well to the challenging UnAV-100\nbenchmark. These results highlight model-guided dual-role alignment as a\npowerful and scalable paradigm for conditional video-to-audio generation. Code\nis available at: https://github.com/pantheon5100/mgaudio",
    "published": "2025-10-28T06:16:47Z",
    "updated": "2025-10-28T06:16:47Z",
    "link": "http://arxiv.org/pdf/2510.24103v1.pdf",
    "category": [
      "cs.SD",
      "cs.AI",
      "cs.MM",
      "eess.AS"
    ],
    "authors": [
      "Kang Zhang",
      "Trung X. Pham",
      "Suyeon Lee",
      "Axi Niu",
      "Arda Senocak",
      "Joon Son Chung"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.04242v4",
    "title": "A High-Dimensional Statistical Method for Optimizing Transfer Quantities\n  in Multi-Source Transfer Learning",
    "summary": "Multi-source transfer learning provides an effective solution to data\nscarcity in real- world supervised learning scenarios by leveraging multiple\nsource tasks. In this field, existing works typically use all available samples\nfrom sources in training, which constrains their training efficiency and may\nlead to suboptimal results. To address this, we propose a theoretical framework\nthat answers the question: what is the optimal quantity of source samples\nneeded from each source task to jointly train the target model? Specifically,\nwe introduce a generalization error measure based on K-L divergence, and\nminimize it based on high-dimensional statistical analysis to determine the\noptimal transfer quantity for each source task. Additionally, we develop an\narchitecture-agnostic and data-efficient algorithm OTQMS to implement our\ntheoretical results for target model training in multi- source transfer\nlearning. Experimental studies on diverse architectures and two real-world\nbenchmark datasets show that our proposed algorithm significantly outperforms\nstate-of-the-art approaches in both accuracy and data efficiency. The code and\nsupplementary materials are available in https://github.com/zqy0126/OTQMS.",
    "published": "2025-02-06T17:32:49Z",
    "updated": "2025-10-28T06:15:39Z",
    "link": "http://arxiv.org/pdf/2502.04242v4.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Qingyue Zhang",
      "Haohao Fu",
      "Guanbo Huang",
      "Yaoyuan Liang",
      "Chang Chu",
      "Tianren Peng",
      "Yanru Wu",
      "Qi Li",
      "Yang Li",
      "Shao-Lun Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.16989v2",
    "title": "PTQTP: Post-Training Quantization to Trit-Planes for Large Language\n  Models",
    "summary": "Post-training quantization (PTQ) of large language models (LLMs) to extremely\nlow bit-widths remains challenging due to the fundamental trade-off between\ncomputational efficiency and model expressiveness. While existing ultra-low-bit\nPTQ methods rely on binary approximations or complex compensation mechanisms,\nthey suffer from either limited representational capacity or computational\noverhead that undermines their efficiency gains. We introduce PTQ to\nTrit-Planes (PTQTP), the first ternary-weight PTQ framework that decomposes\nweight matrices into structured ternary {-1, 0, 1} trit-planes using 2x1.58-bit\nrepresentation. PTQTP achieves multiplication-free inference, identical to\n1-bit quantization, while maintaining superior expressiveness through its novel\nstructured decomposition. Our approach provides: (1) a theoretically grounded\nprogressive approximation algorithm ensuring global weight consistency; (2)\nmodel-agnostic deployment across diverse modern LLMs without architectural\nmodifications; and (3) uniform ternary operations that eliminate the need for\nmixed-precision or compensation schemes. Comprehensive experiments across\nLLaMA3.x and Qwen3 model families (0.6B-70B parameters) demonstrate that PTQTP\nsignificantly outperforms existing low-bit PTQ methods, achieving 82.4%\nmathematical reasoning retention versus 0% for competing approaches. PTQTP\napproaches and sometimes surpasses 1.58-bit quantization-aware training\nperformance while requiring only single-hour quantization compared to 10-14 GPU\ndays for training-based methods. These results establish PTQTP as a practical\nsolution for efficient LLM deployment in resource-constrained environments. The\ncode will be available at https://github.com/HeXiao-55/PTQTP.",
    "published": "2025-09-21T09:07:20Z",
    "updated": "2025-10-28T06:14:52Z",
    "link": "http://arxiv.org/pdf/2509.16989v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "He Xiao",
      "Runming Yang",
      "Qingyao Yang",
      "Wendong Xu",
      "Zhen Li",
      "Yupeng Su",
      "Zhengwu Liu",
      "Hongxia Yang",
      "Ngai Wong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24095v1",
    "title": "Learning Parameterized Skills from Demonstrations",
    "summary": "We present DEPS, an end-to-end algorithm for discovering parameterized skills\nfrom expert demonstrations. Our method learns parameterized skill policies\njointly with a meta-policy that selects the appropriate discrete skill and\ncontinuous parameters at each timestep. Using a combination of temporal\nvariational inference and information-theoretic regularization methods, we\naddress the challenge of degeneracy common in latent variable models, ensuring\nthat the learned skills are temporally extended, semantically meaningful, and\nadaptable. We empirically show that learning parameterized skills from\nmultitask expert demonstrations significantly improves generalization to unseen\ntasks. Our method outperforms multitask as well as skill learning baselines on\nboth LIBERO and MetaWorld benchmarks. We also demonstrate that DEPS discovers\ninterpretable parameterized skills, such as an object grasping skill whose\ncontinuous arguments define the grasp location.",
    "published": "2025-10-28T06:08:25Z",
    "updated": "2025-10-28T06:08:25Z",
    "link": "http://arxiv.org/pdf/2510.24095v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "authors": [
      "Vedant Gupta",
      "Haotian Fu",
      "Calvin Luo",
      "Yiding Jiang",
      "George Konidaris"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24085v1",
    "title": "Modeling Electric Vehicle Car-Following Behavior: Classical vs Machine\n  Learning Approach",
    "summary": "The increasing adoption of electric vehicles (EVs) necessitates an\nunderstanding of their driving behavior to enhance traffic safety and develop\nsmart driving systems. This study compares classical and machine learning\nmodels for EV car following behavior. Classical models include the Intelligent\nDriver Model (IDM), Optimum Velocity Model (OVM), Optimal Velocity Relative\nVelocity (OVRV), and a simplified CACC model, while the machine learning\napproach employs a Random Forest Regressor. Using a real world dataset of an EV\nfollowing an internal combustion engine (ICE) vehicle under varied driving\nconditions, we calibrated classical model parameters by minimizing the RMSE\nbetween predictions and real data. The Random Forest model predicts\nacceleration using spacing, speed, and gap type as inputs. Results demonstrate\nthe Random Forest's superior accuracy, achieving RMSEs of 0.0046 (medium gap),\n0.0016 (long gap), and 0.0025 (extra long gap). Among physics based models,\nCACC performed best, with an RMSE of 2.67 for long gaps. These findings\nhighlight the machine learning model's performance across all scenarios. Such\nmodels are valuable for simulating EV behavior and analyzing mixed autonomy\ntraffic dynamics in EV integrated environments.",
    "published": "2025-10-28T05:54:50Z",
    "updated": "2025-10-28T05:54:50Z",
    "link": "http://arxiv.org/pdf/2510.24085v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Md. Shihab Uddin",
      "Md Nazmus Shakib",
      "Rahul Bhadani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.23143v3",
    "title": "MathBode: Understanding LLM Reasoning with Dynamical Systems",
    "summary": "This paper presents MathBode, a dynamic diagnostic for mathematical reasoning\nin large language models (LLMs). Instead of one-shot accuracy, MathBode treats\neach parametric problem as a system: we drive a single parameter sinusoidally\nand fit first-harmonic responses of model outputs and exact solutions. This\nyields interpretable, frequency-resolved metrics -- gain (amplitude tracking)\nand phase (lag) -- that form Bode-style fingerprints. Across five closed-form\nfamilies (linear solve, ratio/saturation, compound interest, 2x2 linear\nsystems, similar triangles), the diagnostic surfaces systematic low-pass\nbehavior and growing phase lag that accuracy alone obscures. We compare several\nmodels against a symbolic baseline that calibrates the instrument ($G \\approx\n1$, $\\phi \\approx 0$). Results separate frontier from mid-tier models on\ndynamics, providing a compact, reproducible protocol that complements standard\nbenchmarks with actionable measurements of reasoning fidelity and consistency.\nWe open-source the dataset and code to enable further research and adoption.",
    "published": "2025-09-27T06:06:36Z",
    "updated": "2025-10-28T05:44:55Z",
    "link": "http://arxiv.org/pdf/2509.23143v3.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "authors": [
      "Charles L. Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24072v1",
    "title": "Covert Surveillance in Smart Devices: A SCOUR Framework Analysis of\n  Youth Privacy Implications",
    "summary": "This paper investigates how smart devices covertly capture private\nconversations and discusses in more in-depth the implications of this for youth\nprivacy. Using a structured review guided by the PRISMA methodology, the\nanalysis focuses on privacy concerns, data capture methods, data storage and\nsharing practices, and proposed technical mitigations. To structure and\nsynthesize findings, we introduce the SCOUR framework, encompassing\nSurveillance mechanisms, Consent and awareness, Operational data flow, Usage\nand exploitation, and Regulatory and technical safeguards. Findings reveal that\nsmart devices have been covertly capturing personal data, especially with smart\ntoys and voice-activated smart gadgets built for youth. These issues are\nworsened by unclear data collection practices and insufficient transparency in\nsmart device applications. Balancing privacy and utility in smart devices is\ncrucial, as youth are becoming more aware of privacy breaches and value their\npersonal data more. Strategies to improve regulatory and technical safeguards\nare also provided. The review identifies research gaps and suggests future\ndirections. The limitations of this literature review are also explained. The\nfindings have significant implications for policy development and the\ntransparency of data collection for smart devices.",
    "published": "2025-10-28T05:10:10Z",
    "updated": "2025-10-28T05:10:10Z",
    "link": "http://arxiv.org/pdf/2510.24072v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "authors": [
      "Austin Shouli",
      "Yulia Bobkova",
      "Ajay Kumar Shrestha"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.09060v2",
    "title": "Multimodal 3D Genome Pre-training",
    "summary": "Deep learning techniques have driven significant progress in various\nanalytical tasks within 3D genomics in computational biology. However, a\nholistic understanding of 3D genomics knowledge remains underexplored. Here, we\npropose MIX-HIC, the first multimodal foundation model of 3D genome that\nintegrates both 3D genome structure and epigenomic tracks, which obtains\nunified and comprehensive semantics. For accurate heterogeneous semantic\nfusion, we design the cross-modal interaction and mapping blocks for robust\nunified representation, yielding the accurate aggregation of 3D genome\nknowledge. Besides, we introduce the first large-scale dataset comprising over\n1 million pairwise samples of Hi-C contact maps and epigenomic tracks for\nhigh-quality pre-training, enabling the exploration of functional implications\nin 3D genomics. Extensive experiments show that MIX-HIC can significantly\nsurpass existing state-of-the-art methods in diverse downstream tasks. This\nwork provides a valuable resource for advancing 3D genomics research.",
    "published": "2025-04-12T03:31:03Z",
    "updated": "2025-10-28T05:01:44Z",
    "link": "http://arxiv.org/pdf/2504.09060v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "q-bio.GN"
    ],
    "authors": [
      "Minghao Yang",
      "Pengteng Li",
      "Yan Liang",
      "Qianyi Cai",
      "Zhihang Zheng",
      "Shichen Zhang",
      "Pengfei Zhang",
      "Zhi-An Huang",
      "Hui Xiong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.18383v2",
    "title": "MENTOR: A Reinforcement Learning Framework for Enabling Tool Use in\n  Small Models via Teacher-Optimized Rewards",
    "summary": "Distilling the tool-using capabilities of large language models (LLMs) into\nsmaller, more efficient small language models (SLMs) is a key challenge for\ntheir practical application. The predominant approach, supervised fine-tuning\n(SFT), suffers from poor generalization as it trains models to imitate a static\nset of teacher trajectories rather than learn a robust methodology. While\nreinforcement learning (RL) offers an alternative, the standard RL using sparse\nrewards fails to effectively guide SLMs, causing them to struggle with\ninefficient exploration and adopt suboptimal strategies. To address these\ndistinct challenges, we propose MENTOR, a framework that synergistically\ncombines RL with teacher-guided distillation. Instead of simple imitation,\nMENTOR employs an RL-based process to learn a more generalizable policy through\nexploration. In addition, to solve the problem of reward sparsity, it uses a\nteacher's reference trajectory to construct a dense, composite teacher-guided\nreward that provides fine-grained guidance. Extensive experiments demonstrate\nthat MENTOR significantly improves the cross-domain generalization and\nstrategic competence of SLMs compared to both SFT and standard sparse-reward RL\nbaselines.",
    "published": "2025-10-21T08:03:14Z",
    "updated": "2025-10-28T04:50:06Z",
    "link": "http://arxiv.org/pdf/2510.18383v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "ChangSu Choi",
      "Hoyun Song",
      "Dongyeon Kim",
      "WooHyeon Jung",
      "Minkyung Cho",
      "Sunjin Park",
      "NohHyeob Bae",
      "Seona Yu",
      "KyungTae Lim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.24085v2",
    "title": "PEARL: Peer-Enhanced Adaptive Radio via On-Device LLM",
    "summary": "We present PEARL (Peer-Enhanced Adaptive Radio via On-Device LLM), a\nframework for cooperative cross-layer optimization in device-to-device (D2D)\ncommunication. Building on our previous work on single-device on-device LLMs,\nPEARL extends the paradigm by leveraging both publisher and subscriber states\nto guide Wi-Fi Aware (WA) parameter selection. A context-aware reward, which\nnormalizes latency by application tolerances and modulates energy by device\nbattery states, provides richer supervision for KL-based finetuning. We study\ntwo lightweight variants: PEARL (Head + Low-Rank Adaptation (LoRA)) achieves\nthe best overall performance, while PEARL-Lite (Head-only) delivers sub-20 ms\ninference at near-identical objective scores. Across synthetic scenarios\ngrounded in real measurements, PEARL improves objective scores over heuristic\nand compact model baselines and reduces energy by up to 16% in cooperative\nlow-battery cases. These results demonstrate that peer-aware context,\nreward-aligned training, and head-based efficiency make LLMs practical for\nalways-on, on-device cross-layer control. Code, real-world demo, and dataset\nare available at https://github.com/abman23/pearl",
    "published": "2025-09-28T21:43:17Z",
    "updated": "2025-10-28T04:48:14Z",
    "link": "http://arxiv.org/pdf/2509.24085v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.NI",
      "eess.SP"
    ],
    "authors": [
      "Ju-Hyung Lee",
      "Yanqing Lu",
      "Klaus Doppler"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24061v1",
    "title": "FALQON: Accelerating LoRA Fine-tuning with Low-Bit Floating-Point\n  Arithmetic",
    "summary": "Low-bit floating-point (FP) formats, such as FP8, provide significant\nacceleration and memory savings in model training thanks to native hardware\nsupport on modern GPUs and NPUs. However, we analyze that FP8 quantization\noffers speedup primarily for large-dimensional matrix multiplications, while\ninherent quantization overheads diminish speedup when applied to low-rank\nadaptation (LoRA), which uses small-dimensional matrices for efficient\nfine-tuning of large language models (LLMs). To address this limitation, we\npropose FALQON, a novel framework that eliminates the quantization overhead\nfrom separate LoRA computational paths by directly merging LoRA adapters into\nan FP8-quantized backbone during fine-tuning. Furthermore, we reformulate the\nforward and backward computations for merged adapters to significantly reduce\nquantization overhead, and introduce a row-wise proxy update mechanism that\nefficiently integrates substantial updates into the quantized backbone.\nExperimental evaluations demonstrate that FALQON achieves approximately a\n3$\\times$ training speedup over existing quantized LoRA methods with a similar\nlevel of accuracy, providing a practical solution for efficient large-scale\nmodel fine-tuning. Moreover, FALQON's end-to-end FP8 workflow removes the need\nfor post-training quantization, facilitating efficient deployment. Code is\navailable at https://github.com/iamkanghyunchoi/falqon.",
    "published": "2025-10-28T04:44:49Z",
    "updated": "2025-10-28T04:44:49Z",
    "link": "http://arxiv.org/pdf/2510.24061v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Kanghyun Choi",
      "Hyeyoon Lee",
      "SunJong Park",
      "Dain Kwon",
      "Jinho Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24058v1",
    "title": "PULSE: Privileged Knowledge Transfer from Electrodermal Activity to\n  Low-Cost Sensors for Stress Monitoring",
    "summary": "Electrodermal activity (EDA), the primary signal for stress detection,\nrequires costly hardware often unavailable in real-world wearables. In this\npaper, we propose PULSE, a framework that utilizes EDA exclusively during\nself-supervised pretraining, while enabling inference without EDA but with more\nreadily available modalities such as ECG, BVP, ACC, and TEMP. Our approach\nseparates encoder outputs into shared and private embeddings. We align shared\nembeddings across modalities and fuse them into a modality-invariant\nrepresentation. The private embeddings carry modality-specific information to\nsupport the reconstruction objective. Pretraining is followed by knowledge\ntransfer where a frozen EDA teacher transfers sympathetic-arousal\nrepresentations into student encoders. On WESAD, our method achieves strong\nstress-detection performance, showing that representations of privileged EDA\ncan be transferred to low-cost sensors to improve accuracy while reducing\nhardware cost.",
    "published": "2025-10-28T04:35:05Z",
    "updated": "2025-10-28T04:35:05Z",
    "link": "http://arxiv.org/pdf/2510.24058v1.pdf",
    "category": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Zihan Zhao",
      "Masood Mortazavi",
      "Ning Yan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24052v1",
    "title": "SynAD: Enhancing Real-World End-to-End Autonomous Driving Models through\n  Synthetic Data Integration",
    "summary": "Recent advancements in deep learning and the availability of high-quality\nreal-world driving datasets have propelled end-to-end autonomous driving.\nDespite this progress, relying solely on real-world data limits the variety of\ndriving scenarios for training. Synthetic scenario generation has emerged as a\npromising solution to enrich the diversity of training data; however, its\napplication within E2E AD models remains largely unexplored. This is primarily\ndue to the absence of a designated ego vehicle and the associated sensor\ninputs, such as camera or LiDAR, typically provided in real-world scenarios. To\naddress this gap, we introduce SynAD, the first framework designed to enhance\nreal-world E2E AD models using synthetic data. Our method designates the agent\nwith the most comprehensive driving information as the ego vehicle in a\nmulti-agent synthetic scenario. We further project path-level scenarios onto\nmaps and employ a newly developed Map-to-BEV Network to derive bird's-eye-view\nfeatures without relying on sensor inputs. Finally, we devise a training\nstrategy that effectively integrates these map-based synthetic data with real\ndriving data. Experimental results demonstrate that SynAD effectively\nintegrates all components and notably enhances safety performance. By bridging\nsynthetic scenario generation and E2E AD, SynAD paves the way for more\ncomprehensive and robust autonomous driving models.",
    "published": "2025-10-28T04:22:02Z",
    "updated": "2025-10-28T04:22:02Z",
    "link": "http://arxiv.org/pdf/2510.24052v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Jongsuk Kim",
      "Jaeyoung Lee",
      "Gyojin Han",
      "Dongjae Lee",
      "Minki Jeong",
      "Junmo Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.20445v5",
    "title": "TrajAgent: An LLM-Agent Framework for Trajectory Modeling via\n  Large-and-Small Model Collaboration",
    "summary": "Trajectory modeling, which includes research on trajectory data pattern\nmining and future prediction, has widespread applications in areas such as life\nservices, urban transportation, and public administration. Numerous methods\nhave been proposed to address specific problems within trajectory modeling.\nHowever, the heterogeneity of data and the diversity of trajectory tasks make\neffective and reliable trajectory modeling an important yet highly challenging\nendeavor, even for domain experts. In this paper, we propose TrajAgent, an\nagent framework powered by large language models, designed to facilitate robust\nand efficient trajectory modeling through automation modeling. This framework\nleverages and optimizes diverse specialized models to address various\ntrajectory modeling tasks across different datasets effectively. In TrajAgent,\nwe first develop UniEnv, an execution environment with a unified data and model\ninterface, to support the execution and training of various models. Building on\nUniEnv, we introduce an agentic workflow designed for automatic trajectory\nmodeling across various trajectory tasks and data. Furthermore, we introduce\ncollaborative learning schema between LLM-based agents and small speciallized\nmodels, to enhance the performance of the whole framework effectively.\nExtensive experiments on five tasks using four real-world datasets demonstrate\nthe effectiveness of TrajAgent in automated trajectory modeling, achieving a\nperformance improvement of 2.38%-69.91% over baseline methods. The codes and\ndata can be accessed via https://github.com/tsinghua-fib-lab/TrajAgent.",
    "published": "2024-10-27T13:51:09Z",
    "updated": "2025-10-28T04:18:04Z",
    "link": "http://arxiv.org/pdf/2410.20445v5.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Yuwei Du",
      "Jie Feng",
      "Jie Zhao",
      "Yong Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24049v1",
    "title": "Learning from History: A Retrieval-Augmented Framework for\n  Spatiotemporal Prediction",
    "summary": "Accurate and long-term spatiotemporal prediction for complex physical systems\nremains a fundamental challenge in scientific computing. While deep learning\nmodels, as powerful parametric approximators, have shown remarkable success,\nthey suffer from a critical limitation: the accumulation of errors during\nlong-term autoregressive rollouts often leads to physically implausible\nartifacts. This deficiency arises from their purely parametric nature, which\nstruggles to capture the full constraints of a system's intrinsic dynamics. To\naddress this, we introduce a novel \\textbf{Retrieval-Augmented Prediction\n(RAP)} framework, a hybrid paradigm that synergizes the predictive power of\ndeep networks with the grounded truth of historical data. The core philosophy\nof RAP is to leverage historical evolutionary exemplars as a non-parametric\nestimate of the system's local dynamics. For any given state, RAP efficiently\nretrieves the most similar historical analog from a large-scale database. The\ntrue future evolution of this analog then serves as a \\textbf{reference\ntarget}. Critically, this target is not a hard constraint in the loss function\nbut rather a powerful conditional input to a specialized dual-stream\narchitecture. It provides strong \\textbf{dynamic guidance}, steering the\nmodel's predictions towards physically viable trajectories. In extensive\nbenchmarks across meteorology, turbulence, and fire simulation, RAP not only\nsurpasses state-of-the-art methods but also significantly outperforms a strong\n\\textbf{analog-only forecasting baseline}. More importantly, RAP generates\npredictions that are more physically realistic by effectively suppressing error\ndivergence in long-term rollouts.",
    "published": "2025-10-28T04:09:16Z",
    "updated": "2025-10-28T04:09:16Z",
    "link": "http://arxiv.org/pdf/2510.24049v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Hao Jia",
      "Penghao Zhao",
      "Hao Wu",
      "Yuan Gao",
      "Yangyu Tao",
      "Bin Cui"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24046v1",
    "title": "Causal-Aware Generative Adversarial Networks with Reinforcement Learning",
    "summary": "The utility of tabular data for tasks ranging from model training to\nlarge-scale data analysis is often constrained by privacy concerns or\nregulatory hurdles. While existing data generation methods, particularly those\nbased on Generative Adversarial Networks (GANs), have shown promise, they\nfrequently struggle with capturing complex causal relationship, maintaining\ndata utility, and providing provable privacy guarantees suitable for enterprise\ndeployment. We introduce CA-GAN, a novel generative framework specifically\nengineered to address these challenges for real-world tabular datasets. CA-GAN\nutilizes a two-step approach: causal graph extraction to learn a robust,\ncomprehensive causal relationship in the data's manifold, followed by a custom\nConditional WGAN-GP (Wasserstein GAN with Gradient Penalty) that operates\nexclusively as per the structure of nodes in the causal graph. More\nimportantly, the generator is trained with a new Reinforcement Learning-based\nobjective that aligns the causal graphs constructed from real and fake data,\nensuring the causal awareness in both training and sampling phases. We\ndemonstrate CA-GAN superiority over six SOTA methods across 14 tabular\ndatasets. Our evaluations, focused on core data engineering metrics: causal\npreservation, utility preservation, and privacy preservation. Our method offers\na practical, high-performance solution for data engineers seeking to create\nhigh-quality, privacy-compliant synthetic datasets to benchmark database\nsystems, accelerate software development, and facilitate secure data-driven\nresearch.",
    "published": "2025-10-28T04:02:49Z",
    "updated": "2025-10-28T04:02:49Z",
    "link": "http://arxiv.org/pdf/2510.24046v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Tu Anh Hoang Nguyen",
      "Dang Nguyen",
      "Tri-Nhan Vo",
      "Thuc Duy Le",
      "Sunil Gupta"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17281v2",
    "title": "MemoryBench: A Benchmark for Memory and Continual Learning in LLM\n  Systems",
    "summary": "Scaling up data, parameters, and test-time computation has been the\nmainstream methods to improve LLM systems (LLMsys), but their upper bounds are\nalmost reached due to the gradual depletion of high-quality data and marginal\ngains obtained from larger computational resource consumption. Inspired by the\nabilities of human and traditional AI systems in learning from practice,\nconstructing memory and continual learning frameworks for LLMsys has become an\nimportant and popular research direction in recent literature. Yet, existing\nbenchmarks for LLM memory often focus on evaluating the system on homogeneous\nreading comprehension tasks with long-form inputs rather than testing their\nabilities to learn from accumulated user feedback in service time. Therefore,\nwe propose a user feedback simulation framework and a comprehensive benchmark\ncovering multiple domains, languages, and types of tasks to evaluate the\ncontinual learning abilities of LLMsys. Experiments show that the effectiveness\nand efficiency of state-of-the-art baselines are far from satisfying, and we\nhope this benchmark could pave the way for future studies on LLM memory and\noptimization algorithms.",
    "published": "2025-10-20T08:16:12Z",
    "updated": "2025-10-28T04:01:30Z",
    "link": "http://arxiv.org/pdf/2510.17281v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "authors": [
      "Qingyao Ai",
      "Yichen Tang",
      "Changyue Wang",
      "Jianming Long",
      "Weihang Su",
      "Yiqun Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.05316v3",
    "title": "Improving Data Efficiency for LLM Reinforcement Fine-tuning Through\n  Difficulty-targeted Online Data Selection and Rollout Replay",
    "summary": "Reinforcement learning (RL) has become an effective approach for fine-tuning\nlarge language models (LLMs), particularly to enhance their reasoning\ncapabilities. However, RL fine-tuning remains highly resource-intensive, and\nexisting work has largely overlooked the problem of data efficiency. In this\npaper, we propose two techniques to improve data efficiency in LLM RL\nfine-tuning: difficulty-targeted online data selection and rollout replay. We\nintroduce the notion of adaptive difficulty to guide online data selection,\nprioritizing questions of moderate difficulty that are more likely to yield\ninformative learning signals. To estimate adaptive difficulty efficiently, we\ndevelop an attention-based framework that requires rollouts for only a small\nreference set of questions. The adaptive difficulty of the remaining questions\nis then estimated based on their similarity to this set. To further reduce\nrollout cost, we introduce a rollout replay mechanism inspired by experience\nreplay in traditional RL. This technique reuses recent rollouts, lowering\nper-step computation while maintaining stable updates. Experiments across 6\nLLM-dataset combinations show that our method reduces RL fine-tuning time by\n23% to 62% while reaching the same level of performance as the original GRPO\nalgorithm. Our code is available at\nhttps://github.com/ASTRAL-Group/data-efficient-llm-rl.",
    "published": "2025-06-05T17:55:43Z",
    "updated": "2025-10-28T03:50:11Z",
    "link": "http://arxiv.org/pdf/2506.05316v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Yifan Sun",
      "Jingyan Shen",
      "Yibin Wang",
      "Tianyu Chen",
      "Zhendong Wang",
      "Mingyuan Zhou",
      "Huan Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24039v1",
    "title": "Geometric Algorithms for Neural Combinatorial Optimization with\n  Constraints",
    "summary": "Self-Supervised Learning (SSL) for Combinatorial Optimization (CO) is an\nemerging paradigm for solving combinatorial problems using neural networks. In\nthis paper, we address a central challenge of SSL for CO: solving problems with\ndiscrete constraints. We design an end-to-end differentiable framework that\nenables us to solve discrete constrained optimization problems with neural\nnetworks. Concretely, we leverage algorithmic techniques from the literature on\nconvex geometry and Carath\\'eodory's theorem to decompose neural network\noutputs into convex combinations of polytope corners that correspond to\nfeasible sets. This decomposition-based approach enables self-supervised\ntraining but also ensures efficient quality-preserving rounding of the neural\nnet output into feasible solutions. Extensive experiments in\ncardinality-constrained optimization show that our approach can consistently\noutperform neural baselines. We further provide worked-out examples of how our\nmethod can be applied beyond cardinality-constrained problems to a diverse set\nof combinatorial optimization tasks, including finding independent sets in\ngraphs, and solving matroid-constrained problems.",
    "published": "2025-10-28T03:49:01Z",
    "updated": "2025-10-28T03:49:01Z",
    "link": "http://arxiv.org/pdf/2510.24039v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Nikolaos Karalias",
      "Akbar Rafiey",
      "Yifei Xu",
      "Zhishang Luo",
      "Behrooz Tahmasebi",
      "Connie Jiang",
      "Stefanie Jegelka"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24036v1",
    "title": "ResNet: Enabling Deep Convolutional Neural Networks through Residual\n  Learning",
    "summary": "Convolutional Neural Networks (CNNs) has revolutionized computer vision, but\ntraining very deep networks has been challenging due to the vanishing gradient\nproblem. This paper explores Residual Networks (ResNet), introduced by He et\nal. (2015), which overcomes this limitation by using skip connections. ResNet\nenables the training of networks with hundreds of layers by allowing gradients\nto flow directly through shortcut connections that bypass intermediate layers.\nIn our implementation on the CIFAR-10 dataset, ResNet-18 achieves 89.9%\naccuracy compared to 84.1% for a traditional deep CNN of similar depth, while\nalso converging faster and training more stably.",
    "published": "2025-10-28T03:36:15Z",
    "updated": "2025-10-28T03:36:15Z",
    "link": "http://arxiv.org/pdf/2510.24036v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Xingyu Liu",
      "Kun Ming Goh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23595v2",
    "title": "Multi-Agent Evolve: LLM Self-Improve through Co-evolution",
    "summary": "Reinforcement Learning (RL) has demonstrated significant potential in\nenhancing the reasoning capabilities of large language models (LLMs). However,\nthe success of RL for LLMs heavily relies on human-curated datasets and\nverifiable rewards, which limit their scalability and generality. Recent\nSelf-Play RL methods, inspired by the success of the paradigm in games and Go,\naim to enhance LLM reasoning capabilities without human-annotated data.\nHowever, their methods primarily depend on a grounded environment for feedback\n(e.g., a Python interpreter or a game engine); extending them to general\ndomains remains challenging. To address these challenges, we propose\nMulti-Agent Evolve (MAE), a framework that enables LLMs to self-evolve in\nsolving diverse tasks, including mathematics, reasoning, and general knowledge\nQ&A. The core design of MAE is based on a triplet of interacting agents\n(Proposer, Solver, Judge) that are instantiated from a single LLM, and applies\nreinforcement learning to optimize their behaviors. The Proposer generates\nquestions, the Solver attempts solutions, and the Judge evaluates both while\nco-evolving. Experiments on Qwen2.5-3B-Instruct demonstrate that MAE achieves\nan average improvement of 4.54% on multiple benchmarks. These results highlight\nMAE as a scalable, data-efficient method for enhancing the general reasoning\nabilities of LLMs with minimal reliance on human-curated supervision.",
    "published": "2025-10-27T17:58:02Z",
    "updated": "2025-10-28T03:30:44Z",
    "link": "http://arxiv.org/pdf/2510.23595v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Yixing Chen",
      "Yiding Wang",
      "Siqi Zhu",
      "Haofei Yu",
      "Tao Feng",
      "Muhan Zhang",
      "Mostofa Patwary",
      "Jiaxuan You"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24031v1",
    "title": "LLMLogAnalyzer: A Clustering-Based Log Analysis Chatbot using Large\n  Language Models",
    "summary": "System logs are a cornerstone of cybersecurity, supporting proactive breach\nprevention and post-incident investigations. However, analyzing vast amounts of\ndiverse log data remains significantly challenging, as high costs, lack of\nin-house expertise, and time constraints make even basic analysis difficult for\nmany organizations. This study introduces LLMLogAnalyzer, a clustering-based\nlog analysis chatbot that leverages Large Language Models (LLMs) and Machine\nLearning (ML) algorithms to simplify and streamline log analysis processes.\nThis innovative approach addresses key LLM limitations, including context\nwindow constraints and poor structured text handling capabilities, enabling\nmore effective summarization, pattern extraction, and anomaly detection tasks.\nLLMLogAnalyzer is evaluated across four distinct domain logs and various tasks.\nResults demonstrate significant performance improvements over state-of-the-art\nLLM-based chatbots, including ChatGPT, ChatPDF, and NotebookLM, with consistent\ngains ranging from 39% to 68% across different tasks. The system also exhibits\nstrong robustness, achieving a 93% reduction in interquartile range (IQR) when\nusing ROUGE-1 scores, indicating significantly lower result variability. The\nframework's effectiveness stems from its modular architecture comprising a\nrouter, log recognizer, log parser, and search tools. This design enhances LLM\ncapabilities for structured text analysis while improving accuracy and\nrobustness, making it a valuable resource for both cybersecurity experts and\nnon-technical users.",
    "published": "2025-10-28T03:29:55Z",
    "updated": "2025-10-28T03:29:55Z",
    "link": "http://arxiv.org/pdf/2510.24031v1.pdf",
    "category": [
      "cs.AI",
      "cs.CR",
      "H.3.3, I.2.7, I.5.3, I.2.5,"
    ],
    "authors": [
      "Peng Cai",
      "Reza Ryan",
      "Nickson M. Karie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.01161v2",
    "title": "Prosperity before Collapse: How Far Can Off-Policy RL Reach with Stale\n  Data on LLMs?",
    "summary": "Reinforcement learning has been central to recent advances in large language\nmodel reasoning, but most algorithms rely on on-policy training that demands\nfresh rollouts at every update, limiting efficiency and scalability.\nAsynchronous RL systems alleviate this by decoupling rollout generation from\ntraining, yet their effectiveness hinges on tolerating large staleness in\nrollout data, a setting where existing methods either degrade in performance or\ncollapse. We revisit this challenge and uncover a prosperity-before-collapse\nphenomenon: stale data can be as informative as on-policy data if exploited\nproperly. Building on this insight, we introduce M2PO (Second-Moment Trust\nPolicy Optimization), which constrains the second moment of importance weights\nto suppress only extreme outliers while preserving informative updates.\nNotably, M2PO sharply reduces the fraction of clipped tokens under high\nstaleness (from 1.22% to 0.06% over training), precisely masking high-variance\ntokens while maintaining stable optimization. Extensive evaluation across six\nmodels (from 1.7B to 32B) and eight benchmarks shows that M2PO delivers stable\noff-policy training even with data stale by at least 256 model updates and\nmatches on-policy performance.",
    "published": "2025-10-01T17:48:23Z",
    "updated": "2025-10-28T03:28:48Z",
    "link": "http://arxiv.org/pdf/2510.01161v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Haizhong Zheng",
      "Jiawei Zhao",
      "Beidi Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24029v1",
    "title": "Improved Accuracy of Robot Localization Using 3-D LiDAR in a\n  Hippocampus-Inspired Model",
    "summary": "Boundary Vector Cells (BVCs) are a class of neurons in the brains of\nvertebrates that encode environmental boundaries at specific distances and\nallocentric directions, playing a central role in forming place fields in the\nhippocampus. Most computational BVC models are restricted to two-dimensional\n(2D) environments, making them prone to spatial ambiguities in the presence of\nhorizontal symmetries in the environment. To address this limitation, we\nincorporate vertical angular sensitivity into the BVC framework, thereby\nenabling robust boundary detection in three dimensions, and leading to\nsignificantly more accurate spatial localization in a biologically-inspired\nrobot model.\n  The proposed model processes LiDAR data to capture vertical contours, thereby\ndisambiguating locations that would be indistinguishable under a purely 2D\nrepresentation. Experimental results show that in environments with minimal\nvertical variation, the proposed 3D model matches the performance of a 2D\nbaseline; yet, as 3D complexity increases, it yields substantially more\ndistinct place fields and markedly reduces spatial aliasing. These findings\nshow that adding a vertical dimension to BVC-based localization can\nsignificantly enhance navigation and mapping in real-world 3D spaces while\nretaining performance parity in simpler, near-planar scenarios.",
    "published": "2025-10-28T03:24:02Z",
    "updated": "2025-10-28T03:24:02Z",
    "link": "http://arxiv.org/pdf/2510.24029v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY",
      "q-bio.NC",
      "I.2.9; I.2.6"
    ],
    "authors": [
      "Andrew Gerstenslager",
      "Bekarys Dukenbaev",
      "Ali A. Minai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24028v1",
    "title": "OneCast: Structured Decomposition and Modular Generation for\n  Cross-Domain Time Series Forecasting",
    "summary": "Cross-domain time series forecasting is a valuable task in various web\napplications. Despite its rapid advancement, achieving effective generalization\nacross heterogeneous time series data remains a significant challenge. Existing\nmethods have made progress by extending single-domain models, yet often fall\nshort when facing domain-specific trend shifts and inconsistent periodic\npatterns. We argue that a key limitation lies in treating temporal series as\nundifferentiated sequence, without explicitly decoupling their inherent\nstructural components. To address this, we propose OneCast, a structured and\nmodular forecasting framework that decomposes time series into seasonal and\ntrend components, each modeled through tailored generative pathways.\nSpecifically, the seasonal component is captured by a lightweight projection\nmodule that reconstructs periodic patterns via interpretable basis functions.\nIn parallel, the trend component is encoded into discrete tokens at segment\nlevel via a semantic-aware tokenizer, and subsequently inferred through a\nmasked discrete diffusion mechanism. The outputs from both branches are\ncombined to produce a final forecast that captures seasonal patterns while\ntracking domain-specific trends. Extensive experiments across eight domains\ndemonstrate that OneCast mostly outperforms state-of-the-art baselines.",
    "published": "2025-10-28T03:23:53Z",
    "updated": "2025-10-28T03:23:53Z",
    "link": "http://arxiv.org/pdf/2510.24028v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Tingyue Pan",
      "Mingyue Cheng",
      "Shilong Zhang",
      "Zhiding Liu",
      "Xiaoyu Tao",
      "Yucong Luo",
      "Jintao Zhang",
      "Qi Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23564v2",
    "title": "ReCode: Unify Plan and Action for Universal Granularity Control",
    "summary": "Real-world tasks require decisions at varying granularities, and humans excel\nat this by leveraging a unified cognitive representation where planning is\nfundamentally understood as a high-level form of action. However, current Large\nLanguage Model (LLM)-based agents lack this crucial capability to operate\nfluidly across decision granularities. This limitation stems from existing\nparadigms that enforce a rigid separation between high-level planning and\nlow-level action, which impairs dynamic adaptability and limits generalization.\nWe propose ReCode (Recursive Code Generation), a novel paradigm that addresses\nthis limitation by unifying planning and action within a single code\nrepresentation. In this representation, ReCode treats high-level plans as\nabstract placeholder functions, which the agent then recursively decomposes\ninto finer-grained sub-functions until reaching primitive actions. This\nrecursive approach dissolves the rigid boundary between plan and action,\nenabling the agent to dynamically control its decision granularity.\nFurthermore, the recursive structure inherently generates rich,\nmulti-granularity training data, enabling models to learn hierarchical\ndecision-making processes. Extensive experiments show ReCode significantly\nsurpasses advanced baselines in inference performance and demonstrates\nexceptional data efficiency in training, validating our core insight that\nunifying planning and action through recursive code generation is a powerful\nand effective approach to achieving universal granularity control. The code is\navailable at https://github.com/FoundationAgents/ReCode.",
    "published": "2025-10-27T17:35:15Z",
    "updated": "2025-10-28T03:22:35Z",
    "link": "http://arxiv.org/pdf/2510.23564v2.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Zhaoyang Yu",
      "Jiayi Zhang",
      "Huixue Su",
      "Yufan Zhao",
      "Yifan Wu",
      "Mingyi Deng",
      "Jinyu Xiang",
      "Yizhang Lin",
      "Lingxiao Tang",
      "Yingchao Li",
      "Yuyu Luo",
      "Bang Liu",
      "Chenglin Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24027v1",
    "title": "Spatio-temporal Multivariate Time Series Forecast with Chosen Variables",
    "summary": "Spatio-Temporal Multivariate time series Forecast (STMF) uses the time series\nof $n$ spatially distributed variables in a period of recent past to forecast\ntheir values in a period of near future. It has important applications in\nspatio-temporal sensing forecast such as road traffic prediction and air\npollution prediction. Recent papers have addressed a practical problem of\nmissing variables in the model input, which arises in the sensing applications\nwhere the number $m$ of sensors is far less than the number $n$ of locations to\nbe monitored, due to budget constraints. We observe that the state of the art\nassumes that the $m$ variables (i.e., locations with sensors) in the model\ninput are pre-determined and the important problem of how to choose the $m$\nvariables in the input has never been studied. This paper fills the gap by\nstudying a new problem of STMF with chosen variables, which optimally selects\n$m$-out-of-$n$ variables for the model input in order to maximize the forecast\naccuracy. We propose a unified framework that jointly performs variable\nselection and model optimization for both forecast accuracy and model\nefficiency. It consists of three novel technical components: (1) masked\nvariable-parameter pruning, which progressively prunes less informative\nvariables and attention parameters through quantile-based masking; (2)\nprioritized variable-parameter replay, which replays low-loss past samples to\npreserve learned knowledge for model stability; (3) dynamic extrapolation\nmechanism, which propagates information from variables selected for the input\nto all other variables via learnable spatial embeddings and adjacency\ninformation. Experiments on five real-world datasets show that our work\nsignificantly outperforms the state-of-the-art baselines in both accuracy and\nefficiency, demonstrating the effectiveness of joint variable selection and\nmodel optimization.",
    "published": "2025-10-28T03:19:06Z",
    "updated": "2025-10-28T03:19:06Z",
    "link": "http://arxiv.org/pdf/2510.24027v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Zibo Liu",
      "Zhe Jiang",
      "Zelin Xu",
      "Tingsong Xiao",
      "Yupu Zhang",
      "Zhengkun Xiao",
      "Haibo Wang",
      "Shigang Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24025v1",
    "title": "NeuroPathNet: Dynamic Path Trajectory Learning for Brain Functional\n  Connectivity Analysis",
    "summary": "Understanding the evolution of brain functional networks over time is of\ngreat significance for the analysis of cognitive mechanisms and the diagnosis\nof neurological diseases. Existing methods often have difficulty in capturing\nthe temporal evolution characteristics of connections between specific\nfunctional communities. To this end, this paper proposes a new path-level\ntrajectory modeling framework (NeuroPathNet) to characterize the dynamic\nbehavior of connection pathways between brain functional partitions. Based on\nmedically supported static partitioning schemes (such as Yeo and Smith ICA), we\nextract the time series of connection strengths between each pair of functional\npartitions and model them using a temporal neural network. We validate the\nmodel performance on three public functional Magnetic Resonance Imaging (fMRI)\ndatasets, and the results show that it outperforms existing mainstream methods\nin multiple indicators. This study can promote the development of dynamic graph\nlearning methods for brain network analysis, and provide possible clinical\napplications for the diagnosis of neurological diseases.",
    "published": "2025-10-28T03:07:06Z",
    "updated": "2025-10-28T03:07:06Z",
    "link": "http://arxiv.org/pdf/2510.24025v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Guo Tianqi Guo",
      "Chen Liping",
      "Peng Ciyuan",
      "Guo Jingjing",
      "Ren Jing"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.22379v2",
    "title": "TraceTrans: Translation and Spatial Tracing for Surgical Prediction",
    "summary": "Image-to-image translation models have achieved notable success in converting\nimages across visual domains and are increasingly used for medical tasks such\nas predicting post-operative outcomes and modeling disease progression.\nHowever, most existing methods primarily aim to match the target distribution\nand often neglect spatial correspondences between the source and translated\nimages. This limitation can lead to structural inconsistencies and\nhallucinations, undermining the reliability and interpretability of the\npredictions. These challenges are accentuated in clinical applications by the\nstringent requirement for anatomical accuracy. In this work, we present\nTraceTrans, a novel deformable image translation model designed for\npost-operative prediction that generates images aligned with the target\ndistribution while explicitly revealing spatial correspondences with the\npre-operative input. The framework employs an encoder for feature extraction\nand dual decoders for predicting spatial deformations and synthesizing the\ntranslated image. The predicted deformation field imposes spatial constraints\non the generated output, ensuring anatomical consistency with the source.\nExtensive experiments on medical cosmetology and brain MRI datasets demonstrate\nthat TraceTrans delivers accurate and interpretable post-operative predictions,\nhighlighting its potential for reliable clinical deployment.",
    "published": "2025-10-25T17:48:46Z",
    "updated": "2025-10-28T03:06:09Z",
    "link": "http://arxiv.org/pdf/2510.22379v2.pdf",
    "category": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Xiyu Luo",
      "Haodong Li",
      "Xinxing Cheng",
      "He Zhao",
      "Yang Hu",
      "Xuan Song",
      "Tianyang Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24021v1",
    "title": "SpecKD: Speculative Decoding for Effective Knowledge Distillation of\n  LLMs",
    "summary": "Knowledge Distillation (KD) has become a cornerstone technique for\ncompressing Large Language Models (LLMs) into smaller, more efficient student\nmodels. However, conventional KD approaches typically apply the distillation\nloss uniformly across all tokens, regardless of the teacher's confidence. This\nindiscriminate mimicry can introduce noise, as the student is forced to learn\nfrom the teacher's uncertain or high-entropy predictions, which may ultimately\nharm student performance-especially when the teacher is much larger and more\npowerful. To address this, we propose Speculative Knowledge Distillation\n(SpecKD), a novel, plug-and-play framework that introduces a dynamic,\ntoken-level gating mechanism inspired by the \"propose-and-verify\" paradigm of\nspeculative decoding. At each step, the student's token proposal is verified\nagainst the teacher's distribution; the distillation loss is selectively\napplied only to \"accepted\" tokens, while \"rejected\" tokens are masked out.\nExtensive experiments on diverse text generation tasks show that SpecKD\nconsistently and significantly outperforms strong KD baselines, leading to more\nstable training and more capable student models, and achieving state-of-the-art\nresults.",
    "published": "2025-10-28T03:02:22Z",
    "updated": "2025-10-28T03:02:22Z",
    "link": "http://arxiv.org/pdf/2510.24021v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Haiduo Huang",
      "Jiangcheng Song",
      "Yadong Zhang",
      "Pengju Ren"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24020v1",
    "title": "Teaching LLMs to Abstain via Fine-Grained Semantic Confidence Reward",
    "summary": "Mitigating hallucinations in Large Language Models (LLMs) is critical for\ntheir reliable deployment. Existing methods typically fine-tune LLMs to abstain\nfrom answering questions beyond their knowledge scope. However, these methods\noften rely on coarse-grained signals to guide LLMs to abstain, such as overall\nconfidence or uncertainty scores on multiple sampled answers, which may result\nin an imprecise awareness of the model's own knowledge boundaries. To this end,\nwe propose a novel reinforcement learning framework built on\n$\\textbf{\\underline{Fi}ne-grained \\underline{S}emantic \\underline{Co}nfidence\n\\underline{Re}ward (\\Ours)}$, which guides LLMs to abstain via sample-specific\nconfidence. Specifically, our method operates by sampling multiple candidate\nanswers and conducting semantic clustering, then training the LLM to retain\nanswers within high-confidence clusters and discard those within low-confidence\nones, thereby promoting accurate post-hoc abstention. Additionally, we propose\na new metric for evaluating the reliability of abstention fine-tuning tasks\nmore comprehensively. Our method significantly enhances reliability in both\nin-domain and out-of-distribution benchmarks.",
    "published": "2025-10-28T03:00:35Z",
    "updated": "2025-10-28T03:00:35Z",
    "link": "http://arxiv.org/pdf/2510.24020v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Hao An",
      "Yang Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24019v1",
    "title": "Lifecycle-Aware code generation: Leveraging Software Engineering Phases\n  in LLMs",
    "summary": "Recent progress in large language models (LLMs) has advanced automatic code\ngeneration, yet most approaches rely on direct, single-step translation from\nproblem descriptions to code, disregarding structured software engineering\npractices. We introduce a lifecycle-aware framework that systematically\nincorporates intermediate artifacts such as requirements analysis, state\nmachine modeling, and pseudocode into both the training and inference stages.\nThis design aligns code generation with standard software development phases\nand enables more structured reasoning. Experiments show that lifecycle-level\nfine-tuning improves code correctness by up to 75% over the same model before\nfine-tuning, with performance gains compounding across intermediate stages.\nMulti-step inference consistently surpasses single-step generation,\ndemonstrating the effectiveness of intermediate scaffolding. Notably,\nopen-source LLMs, once fine-tuned under our framework, match or slightly\noutperform models pretrained on code. When applied to DeepSeek-Coder-1.3B, our\nframework yields relative CodeBLEU improvements of 34.3%, 20.0%, 11.2%, and\n22.3% over ChatGPT-3.5, ChatGPT-4o-mini, DeepSeek-R1, and LLaMA-8B,\nrespectively. Our pipeline also proves robust with up to 80\\% less training\ndata, confirming its resilience. Ablation studies further reveal that each\nintermediate artifact contributes distinctly to final code quality, with state\nmachine modeling yielding the most substantial impact. Our source code and\ndetailed experimental data are available at\nhttps://anonymous.4open.science/r/Lifecycle-Aware-3CCB.",
    "published": "2025-10-28T02:54:02Z",
    "updated": "2025-10-28T02:54:02Z",
    "link": "http://arxiv.org/pdf/2510.24019v1.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Xing Xing",
      "Wei Wang",
      "Lipeng Ma",
      "Weidong Yang",
      "Junjie Zheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.19563v3",
    "title": "Robustness is Important: Limitations of LLMs for Data Fitting",
    "summary": "Large Language Models (LLMs) are being applied in a wide array of settings,\nwell beyond the typical language-oriented use cases. In particular, LLMs are\nincreasingly used as a plug-and-play method for fitting data and generating\npredictions. Prior work has shown that LLMs, via in-context learning or\nsupervised fine-tuning, can perform competitively with many tabular supervised\nlearning techniques in terms of predictive performance. However, we identify a\ncritical vulnerability of using LLMs for data fitting -- making changes to data\nrepresentation that are completely irrelevant to the underlying learning task\ncan drastically alter LLMs' predictions on the same data. For example, simply\nchanging variable names can sway the size of prediction error by as much as 82%\nin certain settings. Such prediction sensitivity with respect to\ntask-irrelevant variations manifests under both in-context learning and\nsupervised fine-tuning, for both close-weight and open-weight general-purpose\nLLMs. Moreover, by examining the attention scores of an open-weight LLM, we\ndiscover a non-uniform attention pattern: training examples and variable\nnames/values which happen to occupy certain positions in the prompt receive\nmore attention when output tokens are generated, even though different\npositions are expected to receive roughly the same attention. This partially\nexplains the sensitivity in the presence of task-irrelevant variations. We also\nconsider a state-of-the-art tabular foundation model (TabPFN) trained\nspecifically for data fitting. Despite being explicitly designed to achieve\nprediction robustness, TabPFN is still not immune to task-irrelevant\nvariations. Overall, despite LLMs' impressive predictive capabilities,\ncurrently they lack even the basic level of robustness to be used as a\nprincipled data-fitting tool.",
    "published": "2025-08-27T04:46:05Z",
    "updated": "2025-10-28T02:52:33Z",
    "link": "http://arxiv.org/pdf/2508.19563v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "stat.AP",
      "stat.ML"
    ],
    "authors": [
      "Hejia Liu",
      "Mochen Yang",
      "Gediminas Adomavicius"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.22917v2",
    "title": "HyPerNav: Hybrid Perception for Object-Oriented Navigation in Unknown\n  Environment",
    "summary": "Objective-oriented navigation(ObjNav) enables robot to navigate to target\nobject directly and autonomously in an unknown environment. Effective\nperception in navigation in unknown environment is critical for autonomous\nrobots. While egocentric observations from RGB-D sensors provide abundant local\ninformation, real-time top-down maps offer valuable global context for ObjNav.\nNevertheless, the majority of existing studies focus on a single source, seldom\nintegrating these two complementary perceptual modalities, despite the fact\nthat humans naturally attend to both. With the rapid advancement of\nVision-Language Models(VLMs), we propose Hybrid Perception Navigation\n(HyPerNav), leveraging VLMs' strong reasoning and vision-language understanding\ncapabilities to jointly perceive both local and global information to enhance\nthe effectiveness and intelligence of navigation in unknown environments. In\nboth massive simulation evaluation and real-world validation, our methods\nachieved state-of-the-art performance against popular baselines. Benefiting\nfrom hybrid perception approach, our method captures richer cues and finds the\nobjects more effectively, by simultaneously leveraging information\nunderstanding from egocentric observations and the top-down map. Our ablation\nstudy further proved that either of the hybrid perception contributes to the\nnavigation performance.",
    "published": "2025-10-27T01:43:56Z",
    "updated": "2025-10-28T02:49:09Z",
    "link": "http://arxiv.org/pdf/2510.22917v2.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Zecheng Yin",
      "Hao Zhao",
      "Zhen Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.18868v3",
    "title": "A Neuroscience-Inspired Dual-Process Model of Compositional\n  Generalization",
    "summary": "Deep learning models struggle with systematic compositional generalization, a\nhallmark of human cognition. We propose \\textsc{Mirage}, a neuro-inspired\ndual-process model that offers a processing account for this ability. It\ncombines a fast, intuitive ``System~1'' (a meta-trained Transformer) with a\ndeliberate, rule-based ``System~2'' (a Schema Engine), mirroring the brain's\nneocortical and hippocampal--prefrontal circuits. Trained to perform general,\nsingle-step decomposition on a stream of random grammars, Mirage achieves\n$>$99\\% accuracy on all splits of the SCAN benchmark in a task-agnostic\nsetting. Ablations confirm that the model's systematic behavior emerges from\nthe architectural interplay of its two systems, particularly its use of\nexplicit, prioritized schemas and iterative refinement. In line with recent\nprogress on recursive/recurrent Transformer approaches, Mirage preserves an\niterative neural update while externalizing declarative control into an\ninterpretable schema module. Our work provides a concrete computational model\nfor interpreting how compositional reasoning can arise from a modular cognitive\narchitecture.",
    "published": "2025-07-25T01:02:07Z",
    "updated": "2025-10-28T02:48:15Z",
    "link": "http://arxiv.org/pdf/2507.18868v3.pdf",
    "category": [
      "cs.AI",
      "cs.NE"
    ],
    "authors": [
      "Alex Noviello",
      "Claas Beger",
      "Jacob Groner",
      "Kevin Ellis",
      "Weinan Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.02787v2",
    "title": "Navigation with VLM framework: Towards Going to Any Language",
    "summary": "Navigating towards fully open language goals and exploring open scenes in an\nintelligent way have always raised significant challenges. Recently, Vision\nLanguage Models (VLMs) have demonstrated remarkable capabilities to reason with\nboth language and visual data. Although many works have focused on leveraging\nVLMs for navigation in open scenes, they often require high computational cost,\nrely on object-centric approaches, or depend on environmental priors in\ndetailed human instructions. We introduce Navigation with VLM (NavVLM), a\ntraining-free framework that harnesses open-source VLMs to enable robots to\nnavigate effectively, even for human-friendly language goal such as abstract\nplaces, actions, or specific objects in open scenes. NavVLM leverages the VLM\nas its cognitive core to perceive environmental information and constantly\nprovides exploration guidance achieving intelligent navigation with only a neat\ntarget rather than a detailed instruction with environment prior. We evaluated\nand validated NavVLM in both simulation and real-world experiments. In\nsimulation, our framework achieves state-of-the-art performance in Success\nweighted by Path Length (SPL) on object-specifc tasks in richly detailed\nenvironments from Matterport 3D (MP3D), Habitat Matterport 3D (HM3D) and\nGibson. With navigation episode reported, NavVLM demonstrates the capabilities\nto navigate towards any open-set languages. In real-world validation, we\nvalidated our framework's effectiveness in real-world robot at indoor scene.",
    "published": "2024-09-18T02:29:00Z",
    "updated": "2025-10-28T02:45:04Z",
    "link": "http://arxiv.org/pdf/2410.02787v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Zecheng Yin",
      "Chonghao Cheng",
      "and Yao Guo",
      "Zhen Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24013v1",
    "title": "Discovering Heuristics with Large Language Models (LLMs) for\n  Mixed-Integer Programs: Single-Machine Scheduling",
    "summary": "Our study contributes to the scheduling and combinatorial optimization\nliterature with new heuristics discovered by leveraging the power of Large\nLanguage Models (LLMs). We focus on the single-machine total tardiness (SMTT)\nproblem, which aims to minimize total tardiness by sequencing n jobs on a\nsingle processor without preemption, given processing times and due dates. We\ndevelop and benchmark two novel LLM-discovered heuristics, the EDD Challenger\n(EDDC) and MDD Challenger (MDDC), inspired by the well-known Earliest Due Date\n(EDD) and Modified Due Date (MDD) rules. In contrast to prior studies that\nemployed simpler rule-based heuristics, we evaluate our LLM-discovered\nalgorithms using rigorous criteria, including optimality gaps and solution time\nderived from a mixed-integer programming (MIP) formulation of SMTT. We compare\ntheir performance against state-of-the-art heuristics and exact methods across\nvarious job sizes (20, 100, 200, and 500 jobs). For instances with more than\n100 jobs, exact methods such as MIP and dynamic programming become\ncomputationally intractable. Up to 500 jobs, EDDC improves upon the classic EDD\nrule and another widely used algorithm in the literature. MDDC consistently\noutperforms traditional heuristics and remains competitive with exact\napproaches, particularly on larger and more complex instances. This study shows\nthat human-LLM collaboration can produce scalable, high-performing heuristics\nfor NP-hard constrained combinatorial optimization, even under limited\nresources when effectively configured.",
    "published": "2025-10-28T02:43:04Z",
    "updated": "2025-10-28T02:43:04Z",
    "link": "http://arxiv.org/pdf/2510.24013v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "cs.NE",
      "math.CO",
      "math.OC"
    ],
    "authors": [
      "Ä°brahim OÄuz Ãetinkaya",
      "Ä°. Esra BÃ¼yÃ¼ktahtakÄ±n",
      "Parshin Shojaee",
      "Chandan K. Reddy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24012v1",
    "title": "Training-Free Safe Text Embedding Guidance for Text-to-Image Diffusion\n  Models",
    "summary": "Text-to-image models have recently made significant advances in generating\nrealistic and semantically coherent images, driven by advanced diffusion models\nand large-scale web-crawled datasets. However, these datasets often contain\ninappropriate or biased content, raising concerns about the generation of\nharmful outputs when provided with malicious text prompts. We propose Safe Text\nembedding Guidance (STG), a training-free approach to improve the safety of\ndiffusion models by guiding the text embeddings during sampling. STG adjusts\nthe text embeddings based on a safety function evaluated on the expected final\ndenoised image, allowing the model to generate safer outputs without additional\ntraining. Theoretically, we show that STG aligns the underlying model\ndistribution with safety constraints, thereby achieving safer outputs while\nminimally affecting generation quality. Experiments on various safety\nscenarios, including nudity, violence, and artist-style removal, show that STG\nconsistently outperforms both training-based and training-free baselines in\nremoving unsafe content while preserving the core semantic intent of input\nprompts. Our code is available at https://github.com/aailab-kaist/STG.",
    "published": "2025-10-28T02:37:20Z",
    "updated": "2025-10-28T02:37:20Z",
    "link": "http://arxiv.org/pdf/2510.24012v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Byeonghu Na",
      "Mina Kang",
      "Jiseok Kwak",
      "Minsang Park",
      "Jiwoo Shin",
      "SeJoon Jun",
      "Gayoung Lee",
      "Jin-Hwa Kim",
      "Il-Chul Moon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23409v2",
    "title": "Eigen-Value: Efficient Domain-Robust Data Valuation via Eigenvalue-Based\n  Approach",
    "summary": "Data valuation has become central in the era of data-centric AI. It drives\nefficient training pipelines and enables objective pricing in data markets by\nassigning a numeric value to each data point. Most existing data valuation\nmethods estimate the effect of removing individual data points by evaluating\nchanges in model validation performance under in-distribution (ID) settings, as\nopposed to out-of-distribution (OOD) scenarios where data follow different\npatterns. Since ID and OOD data behave differently, data valuation methods\nbased on ID loss often fail to generalize to OOD settings, particularly when\nthe validation set contains no OOD data. Furthermore, although OOD-aware\nmethods exist, they involve heavy computational costs, which hinder practical\ndeployment. To address these challenges, we introduce \\emph{Eigen-Value} (EV),\na plug-and-play data valuation framework for OOD robustness that uses only an\nID data subset, including during validation. EV provides a new spectral\napproximation of domain discrepancy, which is the gap of loss between ID and\nOOD using ratios of eigenvalues of ID data's covariance matrix. EV then\nestimates the marginal contribution of each data point to this discrepancy via\nperturbation theory, alleviating the computational burden. Subsequently, EV\nplugs into ID loss-based methods by adding an EV term without any additional\ntraining loop. We demonstrate that EV achieves improved OOD robustness and\nstable value rankings across real-world datasets, while remaining\ncomputationally lightweight. These results indicate that EV is practical for\nlarge-scale settings with domain shift, offering an efficient path to\nOOD-robust data valuation.",
    "published": "2025-10-27T15:12:49Z",
    "updated": "2025-10-28T02:35:45Z",
    "link": "http://arxiv.org/pdf/2510.23409v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Youngjun Choi",
      "Joonseong Kang",
      "Sungjun Lim",
      "Kyungwoo Song"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24010v1",
    "title": "Mars-Bench: A Benchmark for Evaluating Foundation Models for Mars\n  Science Tasks",
    "summary": "Foundation models have enabled rapid progress across many specialized domains\nby leveraging large-scale pre-training on unlabeled data, demonstrating strong\ngeneralization to a variety of downstream tasks. While such models have gained\nsignificant attention in fields like Earth Observation, their application to\nMars science remains limited. A key enabler of progress in other domains has\nbeen the availability of standardized benchmarks that support systematic\nevaluation. In contrast, Mars science lacks such benchmarks and standardized\nevaluation frameworks, which have limited progress toward developing foundation\nmodels for Martian tasks. To address this gap, we introduce Mars-Bench, the\nfirst benchmark designed to systematically evaluate models across a broad range\nof Mars-related tasks using both orbital and surface imagery. Mars-Bench\ncomprises 20 datasets spanning classification, segmentation, and object\ndetection, focused on key geologic features such as craters, cones, boulders,\nand frost. We provide standardized, ready-to-use datasets and baseline\nevaluations using models pre-trained on natural images, Earth satellite data,\nand state-of-the-art vision-language models. Results from all analyses suggest\nthat Mars-specific foundation models may offer advantages over general-domain\ncounterparts, motivating further exploration of domain-adapted pre-training.\nMars-Bench aims to establish a standardized foundation for developing and\ncomparing machine learning models for Mars science. Our data, models, and code\nare available at: https://mars-bench.github.io/.",
    "published": "2025-10-28T02:34:08Z",
    "updated": "2025-10-28T02:34:08Z",
    "link": "http://arxiv.org/pdf/2510.24010v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Mirali Purohit",
      "Bimal Gajera",
      "Vatsal Malaviya",
      "Irish Mehta",
      "Kunal Kasodekar",
      "Jacob Adler",
      "Steven Lu",
      "Umaa Rebbapragada",
      "Hannah Kerner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.21727v2",
    "title": "Your Dense Retriever is Secretly an Expeditious Reasoner",
    "summary": "Dense retrievers enhance retrieval by encoding queries and documents into\ncontinuous vectors, but they often struggle with reasoning-intensive queries.\nAlthough Large Language Models (LLMs) can reformulate queries to capture\ncomplex reasoning, applying them universally incurs significant computational\ncost. In this work, we propose Adaptive Query Reasoning (AdaQR), a hybrid query\nrewriting framework. Within this framework, a Reasoner Router dynamically\ndirects each query to either fast dense reasoning or deep LLM reasoning. The\ndense reasoning is achieved by the Dense Reasoner, which performs LLM-style\nreasoning directly in the embedding space, enabling a controllable trade-off\nbetween efficiency and accuracy. Experiments on large-scale retrieval\nbenchmarks BRIGHT show that AdaQR reduces reasoning cost by 28% while\npreserving-or even improving-retrieval performance by 7%.",
    "published": "2025-09-27T16:50:03Z",
    "updated": "2025-10-28T02:31:06Z",
    "link": "http://arxiv.org/pdf/2510.21727v2.pdf",
    "category": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Yichi Zhang",
      "Jun Bai",
      "Zhixin Cai",
      "Shuhan Qin",
      "Zhuofan Chen",
      "Jinghua Guan",
      "Wenge Rong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23008v2",
    "title": "From Prompt Optimization to Multi-Dimensional Credibility Evaluation:\n  Enhancing Trustworthiness of Chinese LLM-Generated Liver MRI Reports",
    "summary": "Large language models (LLMs) have demonstrated promising performance in\ngenerating diagnostic conclusions from imaging findings, thereby supporting\nradiology reporting, trainee education, and quality control. However,\nsystematic guidance on how to optimize prompt design across different clinical\ncontexts remains underexplored. Moreover, a comprehensive and standardized\nframework for assessing the trustworthiness of LLM-generated radiology reports\nis yet to be established. This study aims to enhance the trustworthiness of\nLLM-generated liver MRI reports by introducing a Multi-Dimensional Credibility\nAssessment (MDCA) framework and providing guidance on institution-specific\nprompt optimization. The proposed framework is applied to evaluate and compare\nthe performance of several advanced LLMs, including Kimi-K2-Instruct-0905,\nQwen3-235B-A22B-Instruct-2507, DeepSeek-V3, and\nByteDance-Seed-OSS-36B-Instruct, using the SiliconFlow platform.",
    "published": "2025-10-27T04:57:20Z",
    "updated": "2025-10-28T02:12:09Z",
    "link": "http://arxiv.org/pdf/2510.23008v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Qiuli Wang",
      "Jie Chen",
      "Yongxu Liu",
      "Xingpeng Zhang",
      "Xiaoming Li",
      "Wei Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.19467v3",
    "title": "BRIDGE: Benchmarking Large Language Models for Understanding Real-world\n  Clinical Practice Text",
    "summary": "Large language models (LLMs) hold great promise for medical applications and\nare evolving rapidly, with new models being released at an accelerated pace.\nHowever, benchmarking on large-scale real-world data such as electronic health\nrecords (EHRs) is critical, as clinical decisions are directly informed by\nthese sources, yet current evaluations remain limited. Most existing benchmarks\nrely on medical exam-style questions or PubMed-derived text, failing to capture\nthe complexity of real-world clinical data. Others focus narrowly on specific\napplication scenarios, limiting their generalizability across broader clinical\nuse. To address this gap, we present BRIDGE, a comprehensive multilingual\nbenchmark comprising 87 tasks sourced from real-world clinical data sources\nacross nine languages. It covers eight major task types spanning the entire\ncontinuum of patient care across six clinical stages and 20 representative\napplications, including triage and referral, consultation, information\nextraction, diagnosis, prognosis, and billing coding, and involves 14 clinical\nspecialties. We systematically evaluated 95 LLMs (including DeepSeek-R1,\nGPT-4o, Gemini series, and Qwen3 series) under various inference strategies.\nOur results reveal substantial performance variation across model sizes,\nlanguages, natural language processing tasks, and clinical specialties.\nNotably, we demonstrate that open-source LLMs can achieve performance\ncomparable to proprietary models, while medically fine-tuned LLMs based on\nolder architectures often underperform versus updated general-purpose models.\nThe BRIDGE and its corresponding leaderboard serve as a foundational resource\nand a unique reference for the development and evaluation of new LLMs in\nreal-world clinical text understanding.\n  The BRIDGE leaderboard:\nhttps://huggingface.co/spaces/YLab-Open/BRIDGE-Medical-Leaderboard",
    "published": "2025-04-28T04:13:18Z",
    "updated": "2025-10-28T01:55:42Z",
    "link": "http://arxiv.org/pdf/2504.19467v3.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Jiageng Wu",
      "Bowen Gu",
      "Ren Zhou",
      "Kevin Xie",
      "Doug Snyder",
      "Yixing Jiang",
      "Valentina Carducci",
      "Richard Wyss",
      "Rishi J Desai",
      "Emily Alsentzer",
      "Leo Anthony Celi",
      "Adam Rodman",
      "Sebastian Schneeweiss",
      "Jonathan H. Chen",
      "Santiago Romero-Brufau",
      "Kueiyu Joshua Lin",
      "Jie Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23989v1",
    "title": "Learning Individual Movement Shifts After Urban Disruptions with Social\n  Infrastructure Reliance",
    "summary": "Shifts in individual movement patterns following disruptive events can reveal\nchanging demands for community resources. However, predicting such shifts\nbefore disruptive events remains challenging for several reasons. First,\nmeasures are lacking for individuals' heterogeneous social infrastructure\nresilience (SIR), which directly influences their movement patterns, and\ncommonly used features are often limited or unavailable at scale, e.g.,\nsociodemographic characteristics. Second, the complex interactions between\nindividual movement patterns and spatial contexts have not been sufficiently\ncaptured. Third, individual-level movement may be spatially sparse and not\nwell-suited to traditional decision-making methods for movement predictions.\nThis study incorporates individuals' SIR into a conditioned deep learning model\nto capture the complex relationships between individual movement patterns and\nlocal spatial context using large-scale, sparse individual-level data. Our\nexperiments demonstrate that incorporating individuals' SIR and spatial context\ncan enhance the model's ability to predict post-event individual movement\npatterns. The conditioned model can capture the divergent shifts in movement\npatterns among individuals who exhibit similar pre-event patterns but differ in\nSIR.",
    "published": "2025-10-28T01:44:55Z",
    "updated": "2025-10-28T01:44:55Z",
    "link": "http://arxiv.org/pdf/2510.23989v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Shangde Gao",
      "Zelin Xu",
      "Zhe Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23986v1",
    "title": "STNet: Spectral Transformation Network for Solving Operator Eigenvalue\n  Problem",
    "summary": "Operator eigenvalue problems play a critical role in various scientific\nfields and engineering applications, yet numerical methods are hindered by the\ncurse of dimensionality. Recent deep learning methods provide an efficient\napproach to address this challenge by iteratively updating neural networks.\nThese methods' performance relies heavily on the spectral distribution of the\ngiven operator: larger gaps between the operator's eigenvalues will improve\nprecision, thus tailored spectral transformations that leverage the spectral\ndistribution can enhance their performance. Based on this observation, we\npropose the Spectral Transformation Network (STNet). During each iteration,\nSTNet uses approximate eigenvalues and eigenfunctions to perform spectral\ntransformations on the original operator, turning it into an equivalent but\neasier problem. Specifically, we employ deflation projection to exclude the\nsubspace corresponding to already solved eigenfunctions, thereby reducing the\nsearch space and avoiding converging to existing eigenfunctions. Additionally,\nour filter transform magnifies eigenvalues in the desired region and suppresses\nthose outside, further improving performance. Extensive experiments demonstrate\nthat STNet consistently outperforms existing learning-based methods, achieving\nstate-of-the-art performance in accuracy.",
    "published": "2025-10-28T01:43:54Z",
    "updated": "2025-10-28T01:43:54Z",
    "link": "http://arxiv.org/pdf/2510.23986v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA"
    ],
    "authors": [
      "Hong Wang",
      "Jiang Yixuan",
      "Jie Wang",
      "Xinyi Li",
      "Jian Luo",
      "Huanshuo Dong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.23502v3",
    "title": "Boosting Omnidirectional Stereo Matching with a Pre-trained Depth\n  Foundation Model",
    "summary": "Omnidirectional depth perception is essential for mobile robotics\napplications that require scene understanding across a full 360{\\deg} field of\nview. Camera-based setups offer a cost-effective option by using stereo depth\nestimation to generate dense, high-resolution depth maps without relying on\nexpensive active sensing. However, existing omnidirectional stereo matching\napproaches achieve only limited depth accuracy across diverse environments,\ndepth ranges, and lighting conditions, due to the scarcity of real-world data.\nWe present DFI-OmniStereo, a novel omnidirectional stereo matching method that\nleverages a large-scale pre-trained foundation model for relative monocular\ndepth estimation within an iterative optimization-based stereo matching\narchitecture. We introduce a dedicated two-stage training strategy to utilize\nthe relative monocular depth features for our omnidirectional stereo matching\nbefore scale-invariant fine-tuning. DFI-OmniStereo achieves state-of-the-art\nresults on the real-world Helvipad dataset, reducing disparity MAE by\napproximately 16% compared to the previous best omnidirectional stereo method.",
    "published": "2025-03-30T16:24:22Z",
    "updated": "2025-10-28T01:42:48Z",
    "link": "http://arxiv.org/pdf/2503.23502v3.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "authors": [
      "Jannik Endres",
      "Oliver Hahn",
      "Charles CorbiÃ¨re",
      "Simone Schaub-Meyer",
      "Stefan Roth",
      "Alexandre Alahi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23980v1",
    "title": "HyperGraphX: Graph Transductive Learning with Hyperdimensional Computing\n  and Message Passing",
    "summary": "We present a novel algorithm, \\hdgc, that marries graph convolution with\nbinding and bundling operations in hyperdimensional computing for transductive\ngraph learning. For prediction accuracy \\hdgc outperforms major and popular\ngraph neural network implementations as well as state-of-the-art\nhyperdimensional computing implementations for a collection of homophilic\ngraphs and heterophilic graphs. Compared with the most accurate learning\nmethodologies we have tested, on the same target GPU platform, \\hdgc is on\naverage 9561.0 and 144.5 times faster than \\gcnii, a graph neural network\nimplementation and HDGL, a hyperdimensional computing implementation,\nrespectively. As the majority of the learning operates on binary vectors, we\nexpect outstanding energy performance of \\hdgc on neuromorphic and emerging\nprocess-in-memory devices.",
    "published": "2025-10-28T01:21:54Z",
    "updated": "2025-10-28T01:21:54Z",
    "link": "http://arxiv.org/pdf/2510.23980v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "authors": [
      "Guojing Cong",
      "Tom Potok",
      "Hamed Poursiami",
      "Maryam Parsa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.21143v2",
    "title": "PanicToCalm: A Proactive Counseling Agent for Panic Attacks",
    "summary": "Panic attacks are acute episodes of fear and distress, in which timely,\nappropriate intervention can significantly help individuals regain stability.\nHowever, suitable datasets for training such models remain scarce due to\nethical and logistical issues. To address this, we introduce PACE, which is a\ndataset that includes high-distress episodes constructed from first-person\nnarratives, and structured around the principles of Psychological First Aid\n(PFA). Using this data, we train PACER, a counseling model designed to provide\nboth empathetic and directive support, which is optimized through supervised\nlearning and simulated preference alignment. To assess its effectiveness, we\npropose PanicEval, a multi-dimensional framework covering general counseling\nquality and crisis-specific strategies. Experimental results show that PACER\noutperforms strong baselines in both counselor-side metrics and client affect\nimprovement. Human evaluations further confirm its practical value, with PACER\nconsistently preferred over general, CBT-based, and GPT-4-powered models in\npanic scenarios (Code is available at https://github.com/JihyunLee1/PanicToCalm\n).",
    "published": "2025-10-24T04:30:24Z",
    "updated": "2025-10-28T01:21:35Z",
    "link": "http://arxiv.org/pdf/2510.21143v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Jihyun Lee",
      "Yejin Min",
      "San Kim",
      "Yejin Jeon",
      "SungJun Yang",
      "Hyounghun Kim",
      "Gary Geunbae Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23974v1",
    "title": "Diffusion Adaptive Text Embedding for Text-to-Image Diffusion Models",
    "summary": "Text-to-image diffusion models rely on text embeddings from a pre-trained\ntext encoder, but these embeddings remain fixed across all diffusion timesteps,\nlimiting their adaptability to the generative process. We propose Diffusion\nAdaptive Text Embedding (DATE), which dynamically updates text embeddings at\neach diffusion timestep based on intermediate perturbed data. We formulate an\noptimization problem and derive an update rule that refines the text embeddings\nat each sampling step to improve alignment and preference between the mean\npredicted image and the text. This allows DATE to dynamically adapts the text\nconditions to the reverse-diffused images throughout diffusion sampling without\nrequiring additional model training. Through theoretical analysis and empirical\nresults, we show that DATE maintains the generative capability of the model\nwhile providing superior text-image alignment over fixed text embeddings across\nvarious tasks, including multi-concept generation and text-guided image\nediting. Our code is available at https://github.com/aailab-kaist/DATE.",
    "published": "2025-10-28T01:10:15Z",
    "updated": "2025-10-28T01:10:15Z",
    "link": "http://arxiv.org/pdf/2510.23974v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Byeonghu Na",
      "Minsang Park",
      "Gyuwon Sim",
      "Donghyeok Shin",
      "HeeSun Bae",
      "Mina Kang",
      "Se Jung Kwon",
      "Wanmo Kang",
      "Il-Chul Moon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23972v1",
    "title": "An efficient probabilistic hardware architecture for diffusion-like\n  models",
    "summary": "The proliferation of probabilistic AI has promoted proposals for specialized\nstochastic computers. Despite promising efficiency gains, these proposals have\nfailed to gain traction because they rely on fundamentally limited modeling\ntechniques and exotic, unscalable hardware. In this work, we address these\nshortcomings by proposing an all-transistor probabilistic computer that\nimplements powerful denoising models at the hardware level. A system-level\nanalysis indicates that devices based on our architecture could achieve\nperformance parity with GPUs on a simple image benchmark using approximately\n10,000 times less energy.",
    "published": "2025-10-28T01:09:19Z",
    "updated": "2025-10-28T01:09:19Z",
    "link": "http://arxiv.org/pdf/2510.23972v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "AndraÅ¾ JelinÄiÄ",
      "Owen Lockwood",
      "Akhil Garlapati",
      "Guillaume Verdon",
      "Trevor McCourt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.03490v2",
    "title": "SEER: The Span-based Emotion Evidence Retrieval Benchmark",
    "summary": "We introduce the SEER (Span-based Emotion Evidence Retrieval) Benchmark to\ntest Large Language Models' (LLMs) ability to identify the specific spans of\ntext that express emotion. Unlike traditional emotion recognition tasks that\nassign a single label to an entire sentence, SEER targets the underexplored\ntask of emotion evidence detection: pinpointing which exact phrases convey\nemotion. This span-level approach is crucial for applications like empathetic\ndialogue and clinical support, which need to know how emotion is expressed, not\njust what the emotion is. SEER includes two tasks: identifying emotion evidence\nwithin a single sentence, and identifying evidence across a short passage of\nfive consecutive sentences. It contains new annotations for both emotion and\nemotion evidence on 1200 real-world sentences. We evaluate 14 open-source LLMs\nand find that, while some models approach average human performance on\nsingle-sentence inputs, their accuracy degrades in longer passages. Our error\nanalysis reveals key failure modes, including overreliance on emotion keywords\nand false positives in neutral text.",
    "published": "2025-10-03T20:15:24Z",
    "updated": "2025-10-28T01:07:57Z",
    "link": "http://arxiv.org/pdf/2510.03490v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Aneesha Sampath",
      "Oya Aran",
      "Emily Mower Provost"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.15536v3",
    "title": "GRS: Generating Robotic Simulation Tasks from Real-World Images",
    "summary": "We introduce GRS (Generating Robotic Simulation tasks), a system addressing\nreal-to-sim for robotic simulations. GRS creates digital twin simulations from\nsingle RGB-D observations with solvable tasks for virtual agent training. Using\nvision-language models (VLMs), our pipeline operates in three stages: 1) scene\ncomprehension with SAM2 for segmentation and object description, 2) matching\nobjects with simulation-ready assets, and 3) generating appropriate tasks. We\nensure simulation-task alignment through generated test suites and introduce a\nrouter that iteratively refines both simulation and test code. Experiments\ndemonstrate our system's effectiveness in object correspondence and task\nenvironment generation through our novel router mechanism.",
    "published": "2024-10-20T23:33:06Z",
    "updated": "2025-10-28T01:05:53Z",
    "link": "http://arxiv.org/pdf/2410.15536v3.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Alex Zook",
      "Fan-Yun Sun",
      "Josef Spjut",
      "Valts Blukis",
      "Stan Birchfield",
      "Jonathan Tremblay"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.00481v2",
    "title": "PVP: An Image Dataset for Personalized Visual Persuasion with Persuasion\n  Strategies, Viewer Characteristics, and Persuasiveness Ratings",
    "summary": "Visual persuasion, which uses visual elements to influence cognition and\nbehaviors, is crucial in fields such as advertising and political\ncommunication. With recent advancements in artificial intelligence, there is\ngrowing potential to develop persuasive systems that automatically generate\npersuasive images tailored to individuals. However, a significant bottleneck in\nthis area is the lack of comprehensive datasets that connect the persuasiveness\nof images with the personal information about those who evaluated the images.\nTo address this gap and facilitate technological advancements in personalized\nvisual persuasion, we release the Personalized Visual Persuasion (PVP) dataset,\ncomprising 28,454 persuasive images across 596 messages and 9 persuasion\nstrategies. Importantly, the PVP dataset provides persuasiveness scores of\nimages evaluated by 2,521 human annotators, along with their demographic and\npsychological characteristics (personality traits and values). We demonstrate\nthe utility of our dataset by developing a persuasive image generator and an\nautomated evaluator, and establish benchmark baselines. Our experiments reveal\nthat incorporating psychological characteristics enhances the generation and\nevaluation of persuasive images, providing valuable insights for personalized\nvisual persuasion.",
    "published": "2025-05-31T09:21:57Z",
    "updated": "2025-10-28T00:59:36Z",
    "link": "http://arxiv.org/pdf/2506.00481v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Junseo Kim",
      "Jongwook Han",
      "Dongmin Choi",
      "Jongwook Yoon",
      "Eun-Ju Lee",
      "Yohan Jo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17191v2",
    "title": "SimpleVSF: VLM-Scoring Fusion for Trajectory Prediction of End-to-End\n  Autonomous Driving",
    "summary": "End-to-end autonomous driving has emerged as a promising paradigm for\nachieving robust and intelligent driving policies. However, existing end-to-end\nmethods still face significant challenges, such as suboptimal decision-making\nin complex scenarios. In this paper,we propose SimpleVSF (Simple VLM-Scoring\nFusion), a novel framework that enhances end-to-end planning by leveraging the\ncognitive capabilities of Vision-Language Models (VLMs) and advanced trajectory\nfusion techniques. We utilize the conventional scorers and the novel\nVLM-enhanced scorers. And we leverage a robust weight fusioner for quantitative\naggregation and a powerful VLM-based fusioner for qualitative, context-aware\ndecision-making. As the leading approach in the ICCV 2025 NAVSIM v2 End-to-End\nDriving Challenge, our SimpleVSF framework demonstrates state-of-the-art\nperformance, achieving a superior balance between safety, comfort, and\nefficiency.",
    "published": "2025-10-20T06:09:57Z",
    "updated": "2025-10-28T00:58:56Z",
    "link": "http://arxiv.org/pdf/2510.17191v2.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Peiru Zheng",
      "Yun Zhao",
      "Zhan Gong",
      "Hong Zhu",
      "Shaohua Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.22118v2",
    "title": "GRAID: Enhancing Spatial Reasoning of VLMs Through High-Fidelity Data\n  Generation",
    "summary": "Vision Language Models (VLMs) achieve strong performance on many\nvision-language tasks but often struggle with spatial\nreasoning$\\unicode{x2014}$a prerequisite for many applications. Empirically, we\nfind that a dataset produced by a current training data generation pipeline has\na 57.6% human validation rate. These rates stem from current limitations:\nsingle-image 3D reconstruction introduces cascading modeling errors and\nrequires wide answer tolerances, while caption-based methods require\nhyper-detailed annotations and suffer from generative hallucinations. We\npresent GRAID, built on the key insight that qualitative spatial relationships\ncan be reliably determined from 2D geometric primitives alone. By operating\nexclusively on 2D bounding boxes from standard object detectors, GRAID avoids\nboth 3D reconstruction errors and generative hallucinations, resulting in\ndatasets that are of higher quality than existing tools that produce similar\ndatasets as validated by human evaluations. We apply our framework to the\nBDD100k, NuImages, and Waymo datasets, generating over 8.5 million high-quality\nVQA pairs creating questions spanning spatial relations, counting, ranking, and\nsize comparisons. We evaluate one of the datasets and find it achieves 91.16%\nhuman-validated accuracy$\\unicode{x2014}$compared to 57.6% on a dataset\ngenerated by recent work. Critically, we demonstrate that when trained on GRAID\ndata, models learn spatial reasoning concepts that generalize: models\nfine-tuned on 6 question types improve on over 10 held-out types, with accuracy\ngains of 47.5% on BDD and 37.9% on NuImages for Llama 3.2B 11B, and when\ntrained on all questions types, achieve improvements on several existing\nbenchmarks such as BLINK. The GRAID framework, datasets, and additional\ninformation can be found $\\href{this https URL}{here}$.",
    "published": "2025-10-25T02:07:23Z",
    "updated": "2025-10-28T00:53:28Z",
    "link": "http://arxiv.org/pdf/2510.22118v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Karim Elmaaroufi",
      "Liheng Lai",
      "Justin Svegliato",
      "Yutong Bai",
      "Sanjit A. Seshia",
      "Matei Zaharia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23965v1",
    "title": "The Sign Estimator: LLM Alignment in the Face of Choice Heterogeneity",
    "summary": "Traditional LLM alignment methods are vulnerable to heterogeneity in human\npreferences. Fitting a na\\\"ive probabilistic model to pairwise comparison data\n(say over prompt-completion pairs) yields an inconsistent estimate of the\npopulation-average utility -a canonical measure of social welfare. We propose a\nnew method, dubbed the sign estimator, that provides a simple, provably\nconsistent, and efficient estimator by replacing cross-entropy with binary\nclassification loss in the aggregation step. This simple modification recovers\nconsistent ordinal alignment under mild assumptions and achieves the first\npolynomial finite-sample error bounds in this setting. In realistic simulations\nof LLM alignment using digital twins, the sign estimator substantially reduces\npreference distortion over a panel of simulated personas, cutting (angular)\nestimation error by nearly 35% and decreasing disagreement with true population\npreferences from 12% to 8% compared to standard RLHF. Our method also compares\nfavorably to panel data heuristics that explicitly model user heterogeneity and\nrequire tracking individual-level preference data-all while maintaining the\nimplementation simplicity of existing LLM alignment pipelines.",
    "published": "2025-10-28T00:42:38Z",
    "updated": "2025-10-28T00:42:38Z",
    "link": "http://arxiv.org/pdf/2510.23965v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Aymane El Gadarri",
      "Ali Aouad",
      "Vivek F. Farias"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23960v1",
    "title": "SafeVision: Efficient Image Guardrail with Robust Policy Adherence and\n  Explainability",
    "summary": "With the rapid proliferation of digital media, the need for efficient and\ntransparent safeguards against unsafe content is more critical than ever.\nTraditional image guardrail models, constrained by predefined categories, often\nmisclassify content due to their pure feature-based learning without semantic\nreasoning. Moreover, these models struggle to adapt to emerging threats,\nrequiring costly retraining for new threats. To address these limitations, we\nintroduce SafeVision, a novel image guardrail that integrates human-like\nreasoning to enhance adaptability and transparency. Our approach incorporates\nan effective data collection and generation framework, a policy-following\ntraining pipeline, and a customized loss function. We also propose a diverse QA\ngeneration and training strategy to enhance learning effectiveness. SafeVision\ndynamically aligns with evolving safety policies at inference time, eliminating\nthe need for retraining while ensuring precise risk assessments and\nexplanations. Recognizing the limitations of existing unsafe image benchmarks,\nwhich either lack granularity or cover limited risks, we introduce VisionHarm,\na high-quality dataset comprising two subsets: VisionHarm Third-party\n(VisionHarm-T) and VisionHarm Comprehensive(VisionHarm-C), spanning diverse\nharmful categories. Through extensive experiments, we show that SafeVision\nachieves state-of-the-art performance on different benchmarks. SafeVision\noutperforms GPT-4o by 8.6% on VisionHarm-T and by 15.5% on VisionHarm-C, while\nbeing over 16x faster. SafeVision sets a comprehensive, policy-following, and\nexplainable image guardrail with dynamic adaptation to emerging threats.",
    "published": "2025-10-28T00:35:59Z",
    "updated": "2025-10-28T00:35:59Z",
    "link": "http://arxiv.org/pdf/2510.23960v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "authors": [
      "Peiyang Xu",
      "Minzhou Pan",
      "Zhaorun Chen",
      "Shuang Yang",
      "Chaowei Xiao",
      "Bo Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.17323v2",
    "title": "Partner Modelling Emerges in Recurrent Agents (But Only When It Matters)",
    "summary": "Humans are remarkably adept at collaboration, able to infer the strengths and\nweaknesses of new partners in order to work successfully towards shared goals.\nTo build AI systems with this capability, we must first understand its building\nblocks: does such flexibility require explicit, dedicated mechanisms for\nmodelling others -- or can it emerge spontaneously from the pressures of\nopen-ended cooperative interaction? To investigate this question, we train\nsimple model-free RNN agents to collaborate with a population of diverse\npartners. Using the `Overcooked-AI' environment, we collect data from thousands\nof collaborative teams, and analyse agents' internal hidden states. Despite a\nlack of additional architectural features, inductive biases, or auxiliary\nobjectives, the agents nevertheless develop structured internal representations\nof their partners' task abilities, enabling rapid adaptation and generalisation\nto novel collaborators. We investigated these internal models through probing\ntechniques, and large-scale behavioural analysis. Notably, we find that\nstructured partner modelling emerges when agents can influence partner\nbehaviour by controlling task allocation. Our results show that partner\nmodelling can arise spontaneously in model-free agents -- but only under\nenvironmental conditions that impose the right kind of social pressure.",
    "published": "2025-05-22T22:24:12Z",
    "updated": "2025-10-28T00:28:59Z",
    "link": "http://arxiv.org/pdf/2505.17323v2.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Ruaridh Mon-Williams",
      "Max Taylor-Davies",
      "Elizabeth Mieczkowski",
      "Natalia Velez",
      "Neil R. Bramley",
      "Yanwei Wang",
      "Thomas L. Griffiths",
      "Christopher G. Lucas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23956v1",
    "title": "Neural USD: An object-centric framework for iterative editing and\n  control",
    "summary": "Amazing progress has been made in controllable generative modeling,\nespecially over the last few years. However, some challenges remain. One of\nthem is precise and iterative object editing. In many of the current methods,\ntrying to edit the generated image (for example, changing the color of a\nparticular object in the scene or changing the background while keeping other\nelements unchanged) by changing the conditioning signals often leads to\nunintended global changes in the scene. In this work, we take the first steps\nto address the above challenges. Taking inspiration from the Universal Scene\nDescriptor (USD) standard developed in the computer graphics community, we\nintroduce the \"Neural Universal Scene Descriptor\" or Neural USD. In this\nframework, we represent scenes and objects in a structured, hierarchical\nmanner. This accommodates diverse signals, minimizes model-specific\nconstraints, and enables per-object control over appearance, geometry, and\npose. We further apply a fine-tuning approach which ensures that the above\ncontrol signals are disentangled from one another. We evaluate several design\nconsiderations for our framework, demonstrating how Neural USD enables\niterative and incremental workflows. More information at:\nhttps://escontrela.me/neural_usd .",
    "published": "2025-10-28T00:19:42Z",
    "updated": "2025-10-28T00:19:42Z",
    "link": "http://arxiv.org/pdf/2510.23956v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Alejandro Escontrela",
      "Shrinu Kushagra",
      "Sjoerd van Steenkiste",
      "Yulia Rubanova",
      "Aleksander Holynski",
      "Kelsey Allen",
      "Kevin Murphy",
      "Thomas Kipf"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.11133v2",
    "title": "3D-Prover: Diversity Driven Theorem Proving With Determinantal Point\n  Processes",
    "summary": "A key challenge in automated formal reasoning is the intractable search\nspace, which grows exponentially with the depth of the proof. This branching is\ncaused by the large number of candidate proof tactics which can be applied to a\ngiven goal. Nonetheless, many of these tactics are semantically similar or lead\nto an execution error, wasting valuable resources in both cases. We address the\nproblem of effectively pruning this search, using only synthetic data generated\nfrom previous proof attempts. We first demonstrate that it is possible to\ngenerate semantically aware tactic representations which capture the effect on\nthe proving environment, likelihood of success, and execution time. We then\npropose a novel filtering mechanism which leverages these representations to\nselect semantically diverse and high quality tactics, using Determinantal Point\nProcesses. Our approach, 3D- Prover, is designed to be general, and to augment\nany underlying tactic generator. We demonstrate the effectiveness of 3D-Prover\non the miniF2F and LeanDojo benchmarks by augmenting popular open source\nproving LLMs. We show that our approach leads to an increase in the overall\nproof rate, as well as a significant improvement in the tactic success rate,\nexecution time and diversity. We make our code available at\nhttps://github.com/sean-lamont/3D-Prover.",
    "published": "2024-10-14T23:13:53Z",
    "updated": "2025-10-28T00:10:02Z",
    "link": "http://arxiv.org/pdf/2410.11133v2.pdf",
    "category": [
      "cs.AI",
      "cs.LO"
    ],
    "authors": [
      "Sean Lamont",
      "Christian Walder",
      "Amir Dezfouli",
      "Paul Montague",
      "Michael Norrish"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23949v1",
    "title": "Uncovering the Potential Risks in Unlearning: Danger of English-only\n  Unlearning in Multilingual LLMs",
    "summary": "There have been a couple of studies showing that attempting to erase\nmultilingual knowledge using only English data is insufficient for multilingual\nLLMs. However, their analyses remain highly performance-oriented. In this\npaper, we switch the point of view to evaluation, and address an additional\nblind spot which reveals itself when the multilingual LLM is fully finetuned\nwith parallel multilingual dataset before unlearning. Here, language confusion\noccurs whereby a model responds in language different from that of the input\nprompt. Language confusion is a problematic phenomenon in unlearning, causing\nthe standard reference-based metrics to fail. We tackle this phenomenon in\nthree steps: (1) introduce N-gram-based Language-Mix (N-Mix) score to\nquantitatively show the language confusion is pervasive and consistent in\nmultilingual LLMs, (2) demonstrate that reference-based metrics result in false\nnegatives when N-Mix score is high, and(3) suggest the need of new type of\nunlearning evaluation that can directly assess the content of the generated\nsentences. We call this type of metrics as semantic-based metric.",
    "published": "2025-10-28T00:05:00Z",
    "updated": "2025-10-28T00:05:00Z",
    "link": "http://arxiv.org/pdf/2510.23949v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Kyomin Hwang",
      "Hyeonjin Kim",
      "Seungyeon Kim",
      "Sunghyun Wee",
      "Nojun Kwak"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23948v1",
    "title": "ChessQA: Evaluating Large Language Models for Chess Understanding",
    "summary": "Chess provides an ideal testbed for evaluating the reasoning, modeling, and\nabstraction capabilities of large language models (LLMs), as it has\nwell-defined structure and objective ground truth while admitting a wide\nspectrum of skill levels. However, existing evaluations of LLM ability in chess\nare ad hoc and narrow in scope, making it difficult to accurately measure LLM\nchess understanding and how it varies with scale, post-training methodologies,\nor architecture choices. We present ChessQA, a comprehensive benchmark that\nassesses LLM chess understanding across five task categories (Structural,\nMotifs, Short Tactics, Position Judgment, and Semantic), which approximately\ncorrespond to the ascending abstractions that players master as they accumulate\nchess knowledge, from understanding basic rules and learning tactical motifs to\ncorrectly calculating tactics, evaluating positions, and semantically\ndescribing high-level concepts. In this way, ChessQA captures a more\ncomprehensive picture of chess ability and understanding, going significantly\nbeyond the simple move quality evaluations done previously, and offers a\ncontrolled, consistent setting for diagnosis and comparison. Furthermore,\nChessQA is inherently dynamic, with prompts, answer keys, and construction\nscripts that can evolve as models improve. Evaluating a range of contemporary\nLLMs, we find persistent weaknesses across all five categories and provide\nresults and error analyses by category. We will release the code, periodically\nrefreshed datasets, and a public leaderboard to support further research.",
    "published": "2025-10-28T00:02:52Z",
    "updated": "2025-10-28T00:02:52Z",
    "link": "http://arxiv.org/pdf/2510.23948v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Qianfeng Wen",
      "Zhenwei Tang",
      "Ashton Anderson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.05699v2",
    "title": "Evaluating AI-Powered Learning Assistants in Engineering Higher\n  Education: Student Engagement, Ethical Challenges, and Policy Implications",
    "summary": "As generative AI becomes increasingly integrated into higher education,\nunderstanding how students engage with these technologies is essential for\nresponsible adoption. This study evaluates the Educational AI Hub, an\nAI-powered learning framework, implemented in undergraduate civil and\nenvironmental engineering courses at a large R1 public university. Using a\nmixed-methods design combining pre- and post-surveys, system usage logs, and\nqualitative analysis of students' AI interactions, the research examines\nperceptions of trust, ethics, usability, and learning outcomes. Findings show\nthat students valued the AI assistant for its accessibility and comfort, with\nnearly half reporting greater ease using it than seeking help from instructors\nor teaching assistants. The tool was most helpful for completing homework and\nunderstanding concepts, though views on its instructional quality were mixed.\nEthical uncertainty, particularly around institutional policy and academic\nintegrity, emerged as a key barrier to full engagement. Overall, students\nregarded AI as a supplement rather than a replacement for human instruction.\nThe study highlights the importance of usability, ethical transparency, and\nfaculty guidance in promoting meaningful AI engagement. A total of 71 students\nparticipated across two courses, generating over 600 AI interactions and 100\nsurvey responses that provided both quantitative and contextual insights into\nlearning engagement.",
    "published": "2025-06-06T03:02:49Z",
    "updated": "2025-10-27T23:56:32Z",
    "link": "http://arxiv.org/pdf/2506.05699v2.pdf",
    "category": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "authors": [
      "Ramteja Sajja",
      "Yusuf Sermet",
      "Brian Fodale",
      "Ibrahim Demir"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23942v1",
    "title": "Decentralized Causal Discovery using Judo Calculus",
    "summary": "We describe a theory and implementation of an intuitionistic decentralized\nframework for causal discovery using judo calculus, which is formally defined\nas j-stable causal inference using j-do-calculus in a topos of sheaves. In\nreal-world applications -- from biology to medicine and social science --\ncausal effects depend on regime (age, country, dose, genotype, or lab\nprotocol). Our proposed judo calculus formalizes this context dependence\nformally as local truth: a causal claim is proven true on a cover of regimes,\nnot everywhere at once. The Lawvere-Tierney modal operator j chooses which\nregimes are relevant; j-stability means the claim holds constructively and\nconsistently across that family. We describe an algorithmic and implementation\nframework for judo calculus, combining it with standard score-based,\nconstraint-based, and gradient-based causal discovery methods. We describe\nexperimental results on a range of domains, from synthetic to real-world\ndatasets from biology and economics. Our experimental results show the\ncomputational efficiency gained by the decentralized nature of sheaf-theoretic\ncausal discovery, as well as improved performance over classical causal\ndiscovery methods.",
    "published": "2025-10-27T23:49:50Z",
    "updated": "2025-10-27T23:49:50Z",
    "link": "http://arxiv.org/pdf/2510.23942v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Sridhar Mahadevan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23941v1",
    "title": "Auto prompting without training labels: An LLM cascade for product\n  quality assessment in e-commerce catalogs",
    "summary": "We introduce a novel, training free cascade for auto-prompting Large Language\nModels (LLMs) to assess product quality in e-commerce. Our system requires no\ntraining labels or model fine-tuning, instead automatically generating and\nrefining prompts for evaluating attribute quality across tens of thousands of\nproduct category-attribute pairs. Starting from a seed of human-crafted\nprompts, the cascade progressively optimizes instructions to meet\ncatalog-specific requirements. This approach bridges the gap between general\nlanguage understanding and domain-specific knowledge at scale in complex\nindustrial catalogs. Our extensive empirical evaluations shows the auto-prompt\ncascade improves precision and recall by $8-10\\%$ over traditional\nchain-of-thought prompting. Notably, it achieves these gains while reducing\ndomain expert effort from 5.1 hours to 3 minutes per attribute - a $99\\%$\nreduction. Additionally, the cascade generalizes effectively across five\nlanguages and multiple quality assessment tasks, consistently maintaining\nperformance gains.",
    "published": "2025-10-27T23:49:31Z",
    "updated": "2025-10-27T23:49:31Z",
    "link": "http://arxiv.org/pdf/2510.23941v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Soham Satyadharma",
      "Fatemeh Sheikholeslami",
      "Swati Kaul",
      "Aziz Umit Batur",
      "Suleiman A. Khan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23940v1",
    "title": "Modeling Biological Multifunctionality with Echo State Networks",
    "summary": "In this work, a three-dimensional multicomponent reaction-diffusion model has\nbeen developed, combining excitable-system dynamics with diffusion processes\nand sharing conceptual features with the FitzHugh-Nagumo model. Designed to\ncapture the spatiotemporal behavior of biological systems, particularly\nelectrophysiological processes, the model was solved numerically to generate\ntime-series data. These data were subsequently used to train and evaluate an\nEcho State Network (ESN), which successfully reproduced the system's dynamic\nbehavior. The results demonstrate that simulating biological dynamics using\ndata-driven, multifunctional ESN models is both feasible and effective.",
    "published": "2025-10-27T23:47:51Z",
    "updated": "2025-10-27T23:47:51Z",
    "link": "http://arxiv.org/pdf/2510.23940v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Anastasia-Maria Leventi-Peetz",
      "JÃ¶rg-Volker Peetz",
      "Kai Weber",
      "Nikolaos Zacharis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23938v1",
    "title": "Scalable GPU-Based Integrity Verification for Large Machine Learning\n  Models",
    "summary": "We present a security framework that strengthens distributed machine learning\nby standardizing integrity protections across CPU and GPU platforms and\nsignificantly reducing verification overheads. Our approach co-locates\nintegrity verification directly with large ML model execution on GPU\naccelerators, resolving the fundamental mismatch between how large ML workloads\ntypically run (primarily on GPUs) and how security verifications traditionally\noperate (on separate CPU-based processes), delivering both immediate\nperformance benefits and long-term architectural consistency. By performing\ncryptographic operations natively on GPUs using dedicated compute units (e.g.,\nIntel Arc's XMX units, NVIDIA's Tensor Cores), our solution eliminates the\npotential architectural bottlenecks that could plague traditional CPU-based\nverification systems when dealing with large models. This approach leverages\nthe same GPU-based high-memory bandwidth and parallel processing primitives\nthat power ML workloads ensuring integrity checks keep pace with model\nexecution even for massive models exceeding 100GB. This framework establishes a\ncommon integrity verification mechanism that works consistently across\ndifferent GPU vendors and hardware configurations. By anticipating future\ncapabilities for creating secure channels between trusted execution\nenvironments and GPU accelerators, we provide a hardware-agnostic foundation\nthat enterprise teams can deploy regardless of their underlying CPU and GPU\ninfrastructures.",
    "published": "2025-10-27T23:45:21Z",
    "updated": "2025-10-27T23:45:21Z",
    "link": "http://arxiv.org/pdf/2510.23938v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Marcin Spoczynski",
      "Marcela S. Melara"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23934v1",
    "title": "MFiSP: A Multimodal Fire Spread Prediction Framework",
    "summary": "The 2019-2020 Black Summer bushfires in Australia devastated 19 million\nhectares, destroyed 3,000 homes, and lasted seven months, demonstrating the\nescalating scale and urgency of wildfire threats requiring better forecasting\nfor effective response. Traditional fire modeling relies on manual\ninterpretation by Fire Behaviour Analysts (FBAns) and static environmental\ndata, often leading to inaccuracies and operational limitations. Emerging data\nsources, such as NASA's FIRMS satellite imagery and Volunteered Geographic\nInformation, offer potential improvements by enabling dynamic fire spread\nprediction. This study proposes a Multimodal Fire Spread Prediction Framework\n(MFiSP) that integrates social media data and remote sensing observations to\nenhance forecast accuracy. By adapting fuel map manipulation strategies between\nassimilation cycles, the framework dynamically adjusts fire behavior\npredictions to align with the observed rate of spread. We evaluate the efficacy\nof MFiSP using synthetically generated fire event polygons across multiple\nscenarios, analyzing individual and combined impacts on forecast perimeters.\nResults suggest that our MFiSP integrating multimodal data can improve fire\nspread prediction beyond conventional methods reliant on FBAn expertise and\nstatic inputs.",
    "published": "2025-10-27T23:36:21Z",
    "updated": "2025-10-27T23:36:21Z",
    "link": "http://arxiv.org/pdf/2510.23934v1.pdf",
    "category": [
      "cs.CY",
      "cs.AI",
      "cs.ET"
    ],
    "authors": [
      "Alec Sathiyamoorthy",
      "Wenhao Zhou",
      "Xiangmin Zhou",
      "Xiaodong Li",
      "Iqbal Gondal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.23311v2",
    "title": "Seeing Symbols, Missing Cultures: Probing Vision-Language Models'\n  Reasoning on Fire Imagery and Cultural Meaning",
    "summary": "Vision-Language Models (VLMs) often appear culturally competent but rely on\nsuperficial pattern matching rather than genuine cultural understanding. We\nintroduce a diagnostic framework to probe VLM reasoning on fire-themed cultural\nimagery through both classification and explanation analysis. Testing multiple\nmodels on Western festivals, non-Western traditions, and emergency scenes\nreveals systematic biases: models correctly identify prominent Western\nfestivals but struggle with underrepresented cultural events, frequently\noffering vague labels or dangerously misclassifying emergencies as\ncelebrations. These failures expose the risks of symbolic shortcuts and\nhighlight the need for cultural evaluation beyond accuracy metrics to ensure\ninterpretable and fair multimodal systems.",
    "published": "2025-09-27T13:56:12Z",
    "updated": "2025-10-27T23:22:21Z",
    "link": "http://arxiv.org/pdf/2509.23311v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Haorui Yu",
      "Yang Zhao",
      "Yijia Chu",
      "Qiufeng Yi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.01374v2",
    "title": "REASONING COMPILER: LLM-Guided Optimizations for Efficient Model Serving",
    "summary": "While model serving has unlocked unprecedented capabilities, the high cost of\nserving large-scale models continues to be a significant barrier to widespread\naccessibility and rapid innovation. Compiler optimizations have long driven\nsubstantial performance improvements, but existing compilers struggle with\nneural workloads due to the exponentially large and highly interdependent space\nof possible transformations. Although existing stochastic search techniques can\nbe effective, they are often sample-inefficient and fail to leverage the\nstructural context underlying compilation decisions. We set out to investigate\nthe research question of whether reasoning with large language models (LLMs),\nwithout any retraining, can leverage the context-aware decision space of\ncompiler optimizations to significantly improve sample efficiency. To that end,\nwe introduce a novel compilation framework (dubbed Reasoning Compiler) that\nformulates optimization as a sequential, context-aware decision process guided\nby a large language model and structured Monte Carlo tree search (MCTS). The\nLLM acts as a proposal mechanism, suggesting hardware-informed transformations\nthat reflect the current program state and accumulated performance feedback.\nMCTS incorporates the LLM-generated proposals to balance exploration and\nexploitation, facilitating structured, context-sensitive traversal of the\nexpansive compiler optimization space. By achieving substantial speedups with\nmarkedly fewer samples than leading neural compilers, our approach demonstrates\nthe potential of LLM-guided reasoning to transform the landscape of compiler\noptimization.",
    "published": "2025-06-02T07:02:46Z",
    "updated": "2025-10-27T23:22:07Z",
    "link": "http://arxiv.org/pdf/2506.01374v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.PL"
    ],
    "authors": [
      "Sujun Tang",
      "Christopher Priebe",
      "Rohan Mahapatra",
      "Lianhui Qin",
      "Hadi Esmaeilzadeh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23925v1",
    "title": "Latent Chain-of-Thought for Visual Reasoning",
    "summary": "Chain-of-thought (CoT) reasoning is critical for improving the\ninterpretability and reliability of Large Vision-Language Models (LVLMs).\nHowever, existing training algorithms such as SFT, PPO, and GRPO may not\ngeneralize well across unseen reasoning tasks and heavily rely on a biased\nreward model. To address this challenge, we reformulate reasoning in LVLMs as\nposterior inference and propose a scalable training algorithm based on\namortized variational inference. By leveraging diversity-seeking reinforcement\nlearning algorithms, we introduce a novel sparse reward function for\ntoken-level learning signals that encourage diverse, high-likelihood latent\nCoT, overcoming deterministic sampling limitations and avoiding reward hacking.\nAdditionally, we implement a Bayesian inference-scaling strategy that replaces\ncostly Best-of-N and Beam Search with a marginal likelihood to efficiently rank\noptimal rationales and answers. We empirically demonstrate that the proposed\nmethod enhances the state-of-the-art LVLMs on seven reasoning benchmarks, in\nterms of effectiveness, generalization, and interpretability.",
    "published": "2025-10-27T23:10:06Z",
    "updated": "2025-10-27T23:10:06Z",
    "link": "http://arxiv.org/pdf/2510.23925v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Guohao Sun",
      "Hang Hua",
      "Jian Wang",
      "Jiebo Luo",
      "Sohail Dianat",
      "Majid Rabbani",
      "Raghuveer Rao",
      "Zhiqiang Tao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23924v1",
    "title": "Agent-based Automated Claim Matching with Instruction-following LLMs",
    "summary": "We present a novel agent-based approach for the automated claim matching task\nwith instruction-following LLMs. We propose a two-step pipeline that first\ngenerates prompts with LLMs, to then perform claim matching as a binary\nclassification task with LLMs. We demonstrate that LLM-generated prompts can\noutperform SOTA with human-generated prompts, and that smaller LLMs can do as\nwell as larger ones in the generation process, allowing to save computational\nresources. We also demonstrate the effectiveness of using different LLMs for\neach step of the pipeline, i.e. using an LLM for prompt generation, and another\nfor claim matching. Our investigation into the prompt generation process in\nturn reveals insights into the LLMs' understanding of claim matching.",
    "published": "2025-10-27T23:09:35Z",
    "updated": "2025-10-27T23:09:35Z",
    "link": "http://arxiv.org/pdf/2510.23924v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Dina Pisarevskaya",
      "Arkaitz Zubiaga"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.04536v3",
    "title": "NOBLE -- Neural Operator with Biologically-informed Latent Embeddings to\n  Capture Experimental Variability in Biological Neuron Models",
    "summary": "Characterizing the cellular properties of neurons is fundamental to\nunderstanding their function in the brain. In this quest, the generation of\nbio-realistic models is central towards integrating multimodal cellular data\nsets and establishing causal relationships. However, current modeling\napproaches remain constrained by the limited availability and intrinsic\nvariability of experimental neuronal data. The deterministic formalism of\nbio-realistic models currently precludes accounting for the natural variability\nobserved experimentally. While deep learning is becoming increasingly relevant\nin this space, it fails to capture the full biophysical complexity of neurons,\ntheir nonlinear voltage dynamics, and variability. To address these\nshortcomings, we introduce NOBLE, a neural operator framework that learns a\nmapping from a continuous frequency-modulated embedding of interpretable neuron\nfeatures to the somatic voltage response induced by current injection. Trained\non synthetic data generated from bio-realistic neuron models, NOBLE predicts\ndistributions of neural dynamics accounting for the intrinsic experimental\nvariability. Unlike conventional bio-realistic neuron models, interpolating\nwithin the embedding space offers models whose dynamics are consistent with\nexperimentally observed responses. NOBLE enables the efficient generation of\nsynthetic neurons that closely resemble experimental data and exhibit\ntrial-to-trial variability, offering a $4200\\times$ speedup over the numerical\nsolver. NOBLE is the first scaled-up deep learning framework that validates its\ngeneralization with real experimental data. To this end, NOBLE captures\nfundamental neural properties in a unique and emergent manner that opens the\ndoor to a better understanding of cellular composition and computations,\nneuromorphic architectures, large-scale brain circuits, and general neuroAI\napplications.",
    "published": "2025-06-05T01:01:18Z",
    "updated": "2025-10-27T22:48:13Z",
    "link": "http://arxiv.org/pdf/2506.04536v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "q-bio.NC"
    ],
    "authors": [
      "Luca Ghafourpour",
      "Valentin Duruisseaux",
      "Bahareh Tolooshams",
      "Philip H. Wong",
      "Costas A. Anastassiou",
      "Anima Anandkumar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.21923v2",
    "title": "FALCON: An ML Framework for Fully Automated Layout-Constrained Analog\n  Circuit Design",
    "summary": "Designing analog circuits from performance specifications is a complex,\nmulti-stage process encompassing topology selection, parameter inference, and\nlayout feasibility. We introduce FALCON, a unified machine learning framework\nthat enables fully automated, specification-driven analog circuit synthesis\nthrough topology selection and layout-constrained optimization. Given a target\nperformance, FALCON first selects an appropriate circuit topology using a\nperformance-driven classifier guided by human design heuristics. Next, it\nemploys a custom, edge-centric graph neural network trained to map circuit\ntopology and parameters to performance, enabling gradient-based parameter\ninference through the learned forward model. This inference is guided by a\ndifferentiable layout cost, derived from analytical equations capturing\nparasitic and frequency-dependent effects, and constrained by design rules. We\ntrain and evaluate FALCON on a large-scale custom dataset of 1M analog mm-wave\ncircuits, generated and simulated using Cadence Spectre across 20\nexpert-designed topologies. Through this evaluation, FALCON demonstrates >99%\naccuracy in topology inference, <10% relative error in performance prediction,\nand efficient layout-aware design that completes in under 1 second per\ninstance. Together, these results position FALCON as a practical and extensible\nfoundation model for end-to-end analog circuit design automation.",
    "published": "2025-05-28T03:16:08Z",
    "updated": "2025-10-27T22:42:49Z",
    "link": "http://arxiv.org/pdf/2505.21923v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.AR",
      "cs.CE"
    ],
    "authors": [
      "Asal Mehradfar",
      "Xuzhe Zhao",
      "Yilun Huang",
      "Emir Ceyani",
      "Yankai Yang",
      "Shihao Han",
      "Hamidreza Aghasi",
      "Salman Avestimehr"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23912v1",
    "title": "Key and Value Weights Are Probably All You Need: On the Necessity of the\n  Query, Key, Value weight Triplet in Decoder-Only Transformers",
    "summary": "The Query, Key, Value weight triplet is a building block of current attention\nmechanisms in state-of-the-art LLMs. We theoretically investigate whether this\ntriplet can be reduced, proving under simplifying assumptions that the Query\nweights are redundant, thereby reducing the number of non-embedding/lm-head\nparameters by over 8%. We validate the theory on full-complexity GPT-3 small\narchitectures (with layer normalization, skip connections, and weight decay)\ntrained from scratch, demonstrating that the reduced model achieves comparable\nvalidation loss to standard baselines. These findings motivate the\ninvestigation of the Query weight redundancy at scale.",
    "published": "2025-10-27T22:39:34Z",
    "updated": "2025-10-27T22:39:34Z",
    "link": "http://arxiv.org/pdf/2510.23912v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Marko Karbevski",
      "Antonij Mijoski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23907v1",
    "title": "DynaStride: Dynamic Stride Windowing with MMCoT for Instructional\n  Multi-Scene Captioning",
    "summary": "Scene-level captioning in instructional videos can enhance learning by\nrequiring an understanding of both visual cues and temporal structure. By\naligning visual cues with textual guidance, this understanding supports\nprocedural learning and multimodal reasoning, providing a richer context for\nskill acquisition. However, captions that fail to capture this structure may\nlack coherence and quality, which can create confusion and undermine the\nvideo's educational intent. To address this gap, we introduce DynaStride, a\npipeline to generate coherent, scene-level captions without requiring manual\nscene segmentation. Using the YouCookII dataset's scene annotations, DynaStride\nperforms adaptive frame sampling and multimodal windowing to capture key\ntransitions within each scene. It then employs a multimodal chain-of-thought\nprocess to produce multiple action-object pairs, which are refined and fused\nusing a dynamic stride window selection algorithm that adaptively balances\ntemporal context and redundancy. The final scene-level caption integrates\nvisual semantics and temporal reasoning in a single instructional caption.\nEmpirical evaluations against strong baselines, including VLLaMA3 and GPT-4o,\ndemonstrate consistent gains on both N-gram-based metrics (BLEU, METEOR) and\nsemantic similarity measures (BERTScore, CLIPScore). Qualitative analyses\nfurther show that DynaStride produces captions that are more temporally\ncoherent and informative, suggesting a promising direction for improving\nAI-powered instructional content generation.",
    "published": "2025-10-27T22:29:08Z",
    "updated": "2025-10-27T22:29:08Z",
    "link": "http://arxiv.org/pdf/2510.23907v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Eddison Pham",
      "Prisha Priyadarshini",
      "Adrian Maliackel",
      "Kanishk Bandi",
      "Cristian Meo",
      "Kevin Zhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23906v1",
    "title": "Group Interventions on Deep Networks for Causal Discovery in Subsystems",
    "summary": "Causal discovery uncovers complex relationships between variables, enhancing\npredictions, decision-making, and insights into real-world systems, especially\nin nonlinear multivariate time series. However, most existing methods primarily\nfocus on pairwise cause-effect relationships, overlooking interactions among\ngroups of variables, i.e., subsystems and their collective causal influence. In\nthis study, we introduce gCDMI, a novel multi-group causal discovery method\nthat leverages group-level interventions on trained deep neural networks and\nemploys model invariance testing to infer causal relationships. Our approach\ninvolves three key steps. First, we use deep learning to jointly model the\nstructural relationships among groups of all time series. Second, we apply\ngroup-wise interventions to the trained model. Finally, we conduct model\ninvariance testing to determine the presence of causal links among variable\ngroups. We evaluate our method on simulated datasets, demonstrating its\nsuperior performance in identifying group-level causal relationships compared\nto existing methods. Additionally, we validate our approach on real-world\ndatasets, including brain networks and climate ecosystems. Our results\nhighlight that applying group-level interventions to deep learning models,\ncombined with invariance testing, can effectively reveal complex causal\nstructures, offering valuable insights for domains such as neuroscience and\nclimate science.",
    "published": "2025-10-27T22:26:20Z",
    "updated": "2025-10-27T22:26:20Z",
    "link": "http://arxiv.org/pdf/2510.23906v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Wasim Ahmad",
      "Maha Shadaydeh",
      "Joachim Denzler"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23901v1",
    "title": "RS-ORT: A Reduced-Space Branch-and-Bound Algorithm for Optimal\n  Regression Trees",
    "summary": "Mixed-integer programming (MIP) has emerged as a powerful framework for\nlearning optimal decision trees. Yet, existing MIP approaches for regression\ntasks are either limited to purely binary features or become computationally\nintractable when continuous, large-scale data are involved. Naively binarizing\ncontinuous features sacrifices global optimality and often yields needlessly\ndeep trees. We recast the optimal regression-tree training as a two-stage\noptimization problem and propose Reduced-Space Optimal Regression Trees\n(RS-ORT) - a specialized branch-and-bound (BB) algorithm that branches\nexclusively on tree-structural variables. This design guarantees the\nalgorithm's convergence and its independence from the number of training\nsamples. Leveraging the model's structure, we introduce several bound\ntightening techniques - closed-form leaf prediction, empirical threshold\ndiscretization, and exact depth-1 subtree parsing - that combine with\ndecomposable upper and lower bounding strategies to accelerate the training.\nThe BB node-wise decomposition enables trivial parallel execution, further\nalleviating the computational intractability even for million-size datasets.\nBased on the empirical studies on several regression benchmarks containing both\nbinary and continuous features, RS-ORT also delivers superior training and\ntesting performance than state-of-the-art methods. Notably, on datasets with up\nto 2,000,000 samples with continuous features, RS-ORT can obtain guaranteed\ntraining performance with a simpler tree structure and a better generalization\nability in four hours.",
    "published": "2025-10-27T22:17:09Z",
    "updated": "2025-10-27T22:17:09Z",
    "link": "http://arxiv.org/pdf/2510.23901v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Cristobal Heredia",
      "Pedro Chumpitaz-Flores",
      "Kaixun Hua"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.00103v2",
    "title": "Pre-trained knowledge elevates large language models beyond traditional\n  chemical reaction optimizers",
    "summary": "Modern optimization in experimental chemistry employs algorithmic search\nthrough black-box parameter spaces. Here we demonstrate that pre-trained\nknowledge in large language models (LLMs) fundamentally changes this paradigm.\nUsing six fully enumerated categorical reaction datasets (768-5,684\nexperiments), we benchmark LLM-guided optimization (LLM-GO) against Bayesian\noptimization (BO) and random sampling. Frontier LLMs consistently match or\nexceed BO performance across five single-objective datasets, with advantages\ngrowing as parameter complexity increases and high-performing conditions become\nscarce (<5% of space). BO retains superiority only for explicit multi-objective\ntrade-offs. To understand these contrasting behaviors, we introduce a\ntopology-agnostic information theory framework quantifying sampling diversity\nthroughout optimization campaigns. This analysis reveals that LLMs maintain\nsystematically higher exploration Shannon entropy than BO across all datasets\nwhile achieving superior performance, with advantages most pronounced in\nsolution-scarce parameter spaces where high-entropy exploration typically\nfails-suggesting that pre-trained domain knowledge enables more effective\nnavigation of chemical parameter space rather than replacing structured\nexploration strategies. To enable transparent benchmarking and community\nvalidation, we release Iron Mind (https://gomes.andrew.cmu.edu/iron-mind), a\nno-code platform for side-by-side evaluation of human, algorithmic, and LLM\noptimization campaigns with public leaderboards and complete trajectories. Our\nfindings establish that LLM-GO excels precisely where traditional methods\nstruggle: complex categorical spaces requiring domain understanding rather than\nmathematical optimization.",
    "published": "2025-08-27T21:09:51Z",
    "updated": "2025-10-27T22:13:12Z",
    "link": "http://arxiv.org/pdf/2509.00103v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "physics.chem-ph"
    ],
    "authors": [
      "Robert MacKnight",
      "Jose Emilio Regio",
      "Jeffrey G. Ethier",
      "Luke A. Baldwin",
      "Gabe Gomes"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23893v1",
    "title": "Evaluating the effectiveness of LLM-based interoperability",
    "summary": "Background: Systems of systems are becoming increasingly dynamic and\nheterogeneous, and this adds pressure on the long-standing challenge of\ninteroperability. Besides its technical aspect, interoperability has also an\neconomic side, as development time efforts are required to build the\ninteroperability artifacts. Objectives: With the recent advances in the field\nof large language models (LLMs), we aim at analyzing the effectiveness of\nLLM-based strategies to make systems interoperate autonomously, at runtime,\nwithout human intervention. Method: We selected 13 open source LLMs and curated\nfour versions of a dataset in the agricultural interoperability use case. We\nperformed three runs of each model with each version of the dataset, using two\ndifferent strategies. Then we compared the effectiveness of the models and the\nconsistency of their results across multiple runs. Results: qwen2.5-coder:32b\nwas the most effective model using both strategies DIRECT (average pass@1 >=\n0.99) and CODEGEN (average pass@1 >= 0.89) in three out of four dataset\nversions. In the fourth dataset version, which included an unit conversion, all\nmodels using the strategy DIRECT failed, whereas using CODEGEN\nqwen2.5-coder:32b succeeded with an average pass@1 = 0.75. Conclusion: Some\nLLMs can make systems interoperate autonomously. Further evaluation in\ndifferent domains is recommended, and further research on reliability\nstrategies should be conducted.",
    "published": "2025-10-27T22:05:08Z",
    "updated": "2025-10-27T22:05:08Z",
    "link": "http://arxiv.org/pdf/2510.23893v1.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Rodrigo FalcÃ£o",
      "Stefan Schweitzer",
      "Julien Siebert",
      "Emily Calvet",
      "Frank Elberzhager"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23891v1",
    "title": "PRO: Enabling Precise and Robust Text Watermark for Open-Source LLMs",
    "summary": "Text watermarking for large language models (LLMs) enables model owners to\nverify text origin and protect intellectual property. While watermarking\nmethods for closed-source LLMs are relatively mature, extending them to\nopen-source models remains challenging, as developers cannot control the\ndecoding process. Consequently, owners of open-source LLMs lack practical means\nto verify whether text was generated by their models. A core difficulty lies in\nembedding watermarks directly into model weights without hurting detectability.\nA promising idea is to distill watermarks from a closed-source model into an\nopen one, but this suffers from (i) poor detectability due to mismatch between\nlearned and predefined patterns, and (ii) fragility to downstream modifications\nsuch as fine-tuning or model merging. To overcome these limitations, we propose\nPRO, a Precise and Robust text watermarking method for open-source LLMs. PRO\njointly trains a watermark policy model with the LLM, producing patterns that\nare easier for the model to learn and more consistent with detection criteria.\nA regularization term further simulates downstream perturbations and penalizes\ndegradation in watermark detectability, ensuring robustness under model edits.\nExperiments on open-source LLMs (e.g., LLaMA-3.2, LLaMA-3, Phi-2) show that PRO\nsubstantially improves both watermark detectability and resilience to model\nmodifications.",
    "published": "2025-10-27T22:00:49Z",
    "updated": "2025-10-27T22:00:49Z",
    "link": "http://arxiv.org/pdf/2510.23891v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Jiaqi Xue",
      "Yifei Zhao",
      "Mansour Al Ghanim",
      "Shangqian Gao",
      "Ruimin Sun",
      "Qian Lou",
      "Mengxin Zheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.14969v2",
    "title": "STree: Speculative Tree Decoding for Hybrid State-Space Models",
    "summary": "Speculative decoding is a technique to leverage hardware concurrency in order\nto enable multiple steps of token generation in a single forward pass, thus\nimproving the efficiency of large-scale autoregressive (AR) Transformer models.\nState-space models (SSMs) are already more efficient than AR Transformers,\nsince their state summarizes all past data with no need to cache or re-process\ntokens in the sliding window context. However, their state can also comprise\nthousands of tokens; so, speculative decoding has recently been extended to\nSSMs. Existing approaches, however, do not leverage the tree-based verification\nmethods, since current SSMs lack the means to compute a token tree efficiently.\nWe propose the first scalable algorithm to perform tree-based speculative\ndecoding in state-space models (SSMs) and hybrid architectures of SSMs and\nTransformer layers. We exploit the structure of accumulated state transition\nmatrices to facilitate tree-based speculative decoding with minimal overhead\nrelative to current SSM implementations. Along with the algorithm, we describe\na hardware-aware implementation that improves naive application of AR\nTransformer tree-based speculative decoding methods to SSMs. Furthermore, we\noutperform vanilla speculative decoding with SSMs even with a baseline drafting\nmodel and tree structure on three different benchmarks, opening up\nopportunities for further speed up with SSM and hybrid model inference. Code\ncan be found at: https://github.com/wyc1997/stree.",
    "published": "2025-05-20T23:12:16Z",
    "updated": "2025-10-27T21:48:48Z",
    "link": "http://arxiv.org/pdf/2505.14969v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Yangchao Wu",
      "Zongyue Qin",
      "Alex Wong",
      "Stefano Soatto"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23883v1",
    "title": "Agentic AI Security: Threats, Defenses, Evaluation, and Open Challenges",
    "summary": "Agentic AI systems powered by large language models (LLMs) and endowed with\nplanning, tool use, memory, and autonomy, are emerging as powerful, flexible\nplatforms for automation. Their ability to autonomously execute tasks across\nweb, software, and physical environments creates new and amplified security\nrisks, distinct from both traditional AI safety and conventional software\nsecurity. This survey outlines a taxonomy of threats specific to agentic AI,\nreviews recent benchmarks and evaluation methodologies, and discusses defense\nstrategies from both technical and governance perspectives. We synthesize\ncurrent research and highlight open challenges, aiming to support the\ndevelopment of secure-by-design agent systems.",
    "published": "2025-10-27T21:48:11Z",
    "updated": "2025-10-27T21:48:11Z",
    "link": "http://arxiv.org/pdf/2510.23883v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Shrestha Datta",
      "Shahriar Kabir Nahin",
      "Anshuman Chhabra",
      "Prasant Mohapatra"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23882v1",
    "title": "Hybrid Modeling, Sim-to-Real Reinforcement Learning, and Large Language\n  Model Driven Control for Digital Twins",
    "summary": "This work investigates the use of digital twins for dynamical system modeling\nand control, integrating physics-based, data-driven, and hybrid approaches with\nboth traditional and AI-driven controllers. Using a miniature greenhouse as a\ntest platform, four predictive models Linear, Physics-Based Modeling (PBM),\nLong Short Term Memory (LSTM), and Hybrid Analysis and Modeling (HAM) are\ndeveloped and compared under interpolation and extrapolation scenarios. Three\ncontrol strategies Model Predictive Control (MPC), Reinforcement Learning (RL),\nand Large Language Model (LLM) based control are also implemented to assess\ntrade-offs in precision, adaptability, and implementation effort. Results show\nthat in modeling HAM provides the most balanced performance across accuracy,\ngeneralization, and computational efficiency, while LSTM achieves high\nprecision at greater resource cost. Among controllers, MPC delivers robust and\npredictable performance, RL demonstrates strong adaptability, and LLM-based\ncontrollers offer flexible human-AI interaction when coupled with predictive\ntools.",
    "published": "2025-10-27T21:43:42Z",
    "updated": "2025-10-27T21:43:42Z",
    "link": "http://arxiv.org/pdf/2510.23882v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Adil Rasheed",
      "Oscar Ravik",
      "Omer San"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23881v1",
    "title": "Generating Creative Chess Puzzles",
    "summary": "While Generative AI rapidly advances in various domains, generating truly\ncreative, aesthetic, and counter-intuitive outputs remains a challenge. This\npaper presents an approach to tackle these difficulties in the domain of chess\npuzzles. We start by benchmarking Generative AI architectures, and then\nintroduce an RL framework with novel rewards based on chess engine search\nstatistics to overcome some of those shortcomings. The rewards are designed to\nenhance a puzzle's uniqueness, counter-intuitiveness, diversity, and realism.\nOur RL approach dramatically increases counter-intuitive puzzle generation by\n10x, from 0.22\\% (supervised) to 2.5\\%, surpassing existing dataset rates\n(2.1\\%) and the best Lichess-trained model (0.4\\%). Our puzzles meet novelty\nand diversity benchmarks, retain aesthetic themes, and are rated by human\nexperts as more creative, enjoyable, and counter-intuitive than composed book\npuzzles, even approaching classic compositions. Our final outcome is a curated\nbooklet of these AI-generated puzzles, which is acknowledged for creativity by\nthree world-renowned experts.",
    "published": "2025-10-27T21:43:39Z",
    "updated": "2025-10-27T21:43:39Z",
    "link": "http://arxiv.org/pdf/2510.23881v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Xidong Feng",
      "Vivek Veeriah",
      "Marcus Chiam",
      "Michael Dennis",
      "Ryan Pachauri",
      "Thomas Tumiel",
      "Federico Barbero",
      "Johan Obando-Ceron",
      "Jiaxin Shi",
      "Satinder Singh",
      "Shaobo Hou",
      "Nenad TomaÅ¡ev",
      "Tom Zahavy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23870v1",
    "title": "OraPlan-SQL: A Planning-Centric Framework for Complex Bilingual NL2SQL\n  Reasoning",
    "summary": "We present OraPlan-SQL, our system for the Archer NL2SQL Evaluation Challenge\n2025, a bilingual benchmark requiring complex reasoning such as arithmetic,\ncommonsense, and hypothetical inference. OraPlan-SQL ranked first, exceeding\nthe second-best system by more than 6% in execution accuracy (EX), with 55.0%\nin English and 56.7% in Chinese, while maintaining over 99% SQL validity (VA).\nOur system follows an agentic framework with two components: Planner agent that\ngenerates stepwise natural language plans, and SQL agent that converts these\nplans into executable SQL. Since SQL agent reliably adheres to the plan, our\nrefinements focus on the planner. Unlike prior methods that rely on multiple\nsub-agents for planning and suffer from orchestration overhead, we introduce a\nfeedback-guided meta-prompting strategy to refine a single planner. Failure\ncases from a held-out set are clustered with human input, and an LLM distills\nthem into corrective guidelines that are integrated into the planner's system\nprompt, improving generalization without added complexity. For the multilingual\nscenario, to address transliteration and entity mismatch issues, we incorporate\nentity-linking guidelines that generate alternative surface forms for entities\nand explicitly include them in the plan. Finally, we enhance reliability\nthrough plan diversification: multiple candidate plans are generated for each\nquery, with the SQL agent producing a query for each plan, and final output\nselected via majority voting over their executions.",
    "published": "2025-10-27T21:22:41Z",
    "updated": "2025-10-27T21:22:41Z",
    "link": "http://arxiv.org/pdf/2510.23870v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Marianne Menglin Liu",
      "Sai Ashish Somayajula",
      "Syed Fahad Allam Shah",
      "Sujith Ravi",
      "Dan Roth"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23866v1",
    "title": "A PDE-Informed Latent Diffusion Model for 2-m Temperature Downscaling",
    "summary": "This work presents a physics-conditioned latent diffusion model tailored for\ndynamical downscaling of atmospheric data, with a focus on reconstructing\nhigh-resolution 2-m temperature fields. Building upon a pre-existing diffusion\narchitecture and employing a residual formulation against a reference UNet, we\nintegrate a partial differential equation (PDE) loss term into the model's\ntraining objective. The PDE loss is computed in the full resolution (pixel)\nspace by decoding the latent representation and is designed to enforce physical\nconsistency through a finite-difference approximation of an effective\nadvection-diffusion balance. Empirical observations indicate that conventional\ndiffusion training already yields low PDE residuals, and we investigate how\nfine-tuning with this additional loss further regularizes the model and\nenhances the physical plausibility of the generated fields. The entirety of our\ncodebase is available on Github, for future reference and development.",
    "published": "2025-10-27T21:17:03Z",
    "updated": "2025-10-27T21:17:03Z",
    "link": "http://arxiv.org/pdf/2510.23866v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Paul Rosu",
      "Muchang Bahng",
      "Erick Jiang",
      "Rico Zhu",
      "Vahid Tarokh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23856v1",
    "title": "From Benchmarks to Business Impact: Deploying IBM Generalist Agent in\n  Enterprise Production",
    "summary": "Agents are rapidly advancing in automating digital work, but enterprises face\na harder challenge: moving beyond prototypes to deployed systems that deliver\nmeasurable business value. This path is complicated by fragmented frameworks,\nslow development, and the absence of standardized evaluation practices.\nGeneralist agents have emerged as a promising direction, excelling on academic\nbenchmarks and offering flexibility across task types, applications, and\nmodalities. Yet, evidence of their use in production enterprise settings\nremains limited. This paper reports IBM's experience developing and piloting\nthe Computer Using Generalist Agent (CUGA), which has been open-sourced for the\ncommunity (https://github.com/cuga-project/cuga-agent). CUGA adopts a\nhierarchical planner--executor architecture with strong analytical foundations,\nachieving state-of-the-art performance on AppWorld and WebArena. Beyond\nbenchmarks, it was evaluated in a pilot within the Business-Process-Outsourcing\ntalent acquisition domain, addressing enterprise requirements for scalability,\nauditability, safety, and governance. To support assessment, we introduce\nBPO-TA, a 26-task benchmark spanning 13 analytics endpoints. In preliminary\nevaluations, CUGA approached the accuracy of specialized agents while\nindicating potential for reducing development time and cost. Our contribution\nis twofold: presenting early evidence of generalist agents operating at\nenterprise scale, and distilling technical and organizational lessons from this\ninitial pilot. We outline requirements and next steps for advancing\nresearch-grade architectures like CUGA into robust, enterprise-ready systems.",
    "published": "2025-10-27T20:55:00Z",
    "updated": "2025-10-27T20:55:00Z",
    "link": "http://arxiv.org/pdf/2510.23856v1.pdf",
    "category": [
      "cs.AI",
      "68Txx"
    ],
    "authors": [
      "Segev Shlomov",
      "Alon Oved",
      "Sami Marreed",
      "Ido Levy",
      "Offer Akrabi",
      "Avi Yaeli",
      "Åukasz StrÄk",
      "Elizabeth Koumpan",
      "Yinon Goldshtein",
      "Eilam Shapira",
      "Nir Mashkif",
      "Asaf Adi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23854v1",
    "title": "Can LLMs Narrate Tabular Data? An Evaluation Framework for Natural\n  Language Representations of Text-to-SQL System Outputs",
    "summary": "In modern industry systems like multi-turn chat agents, Text-to-SQL\ntechnology bridges natural language (NL) questions and database (DB) querying.\nThe conversion of tabular DB results into NL representations (NLRs) enables the\nchat-based interaction. Currently, NLR generation is typically handled by large\nlanguage models (LLMs), but information loss or errors in presenting tabular\nresults in NL remains largely unexplored. This paper introduces a novel\nevaluation method - Combo-Eval - for judgment of LLM-generated NLRs that\ncombines the benefits of multiple existing methods, optimizing evaluation\nfidelity and achieving a significant reduction in LLM calls by 25-61%.\nAccompanying our method is NLR-BIRD, the first dedicated dataset for NLR\nbenchmarking. Through human evaluations, we demonstrate the superior alignment\nof Combo-Eval with human judgments, applicable across scenarios with and\nwithout ground truth references.",
    "published": "2025-10-27T20:52:19Z",
    "updated": "2025-10-27T20:52:19Z",
    "link": "http://arxiv.org/pdf/2510.23854v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Jyotika Singh",
      "Weiyi Sun",
      "Amit Agarwal",
      "Viji Krishnamurthy",
      "Yassine Benajiba",
      "Sujith Ravi",
      "Dan Roth"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23849v1",
    "title": "A Neural Model for Contextual Biasing Score Learning and Filtering",
    "summary": "Contextual biasing improves automatic speech recognition (ASR) by integrating\nexternal knowledge, such as user-specific phrases or entities, during decoding.\nIn this work, we use an attention-based biasing decoder to produce scores for\ncandidate phrases based on acoustic information extracted by an ASR encoder,\nwhich can be used to filter out unlikely phrases and to calculate bonus for\nshallow-fusion biasing. We introduce a per-token discriminative objective that\nencourages higher scores for ground-truth phrases while suppressing\ndistractors. Experiments on the Librispeech biasing benchmark show that our\nmethod effectively filters out majority of the candidate phrases, and\nsignificantly improves recognition accuracy under different biasing conditions\nwhen the scores are used in shallow fusion biasing. Our approach is modular and\ncan be used with any ASR system, and the filtering mechanism can potentially\nboost performance of other biasing methods.",
    "published": "2025-10-27T20:41:52Z",
    "updated": "2025-10-27T20:41:52Z",
    "link": "http://arxiv.org/pdf/2510.23849v1.pdf",
    "category": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.SD"
    ],
    "authors": [
      "Wanting Huang",
      "Weiran Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23845v1",
    "title": "CRADLE Bench: A Clinician-Annotated Benchmark for Multi-Faceted Mental\n  Health Crisis and Safety Risk Detection",
    "summary": "Detecting mental health crisis situations such as suicide ideation, rape,\ndomestic violence, child abuse, and sexual harassment is a critical yet\nunderexplored challenge for language models. When such situations arise during\nuser--model interactions, models must reliably flag them, as failure to do so\ncan have serious consequences. In this work, we introduce CRADLE BENCH, a\nbenchmark for multi-faceted crisis detection. Unlike previous efforts that\nfocus on a limited set of crisis types, our benchmark covers seven types\ndefined in line with clinical standards and is the first to incorporate\ntemporal labels. Our benchmark provides 600 clinician-annotated evaluation\nexamples and 420 development examples, together with a training corpus of\naround 4K examples automatically labeled using a majority-vote ensemble of\nmultiple language models, which significantly outperforms single-model\nannotation. We further fine-tune six crisis detection models on subsets defined\nby consensus and unanimous ensemble agreement, providing complementary models\ntrained under different agreement criteria.",
    "published": "2025-10-27T20:32:38Z",
    "updated": "2025-10-27T20:32:38Z",
    "link": "http://arxiv.org/pdf/2510.23845v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Grace Byun",
      "Rebecca Lipschutz",
      "Sean T. Minton",
      "Abigail Lott",
      "Jinho D. Choi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23824v1",
    "title": "Decentralized Multi-Agent Goal Assignment for Path Planning using Large\n  Language Models",
    "summary": "Coordinating multiple autonomous agents in shared environments under\ndecentralized conditions is a long-standing challenge in robotics and\nartificial intelligence. This work addresses the problem of decentralized goal\nassignment for multi-agent path planning, where agents independently generate\nranked preferences over goals based on structured representations of the\nenvironment, including grid visualizations and scenario data. After this\nreasoning phase, agents exchange their goal rankings, and assignments are\ndetermined by a fixed, deterministic conflict-resolution rule (e.g., agent\nindex ordering), without negotiation or iterative coordination. We\nsystematically compare greedy heuristics, optimal assignment, and large\nlanguage model (LLM)-based agents in fully observable grid-world settings. Our\nresults show that LLM-based agents, when provided with well-designed prompts\nand relevant quantitative information, can achieve near-optimal makespans and\nconsistently outperform traditional heuristics. These findings underscore the\npotential of language models for decentralized goal assignment in multi-agent\npath planning and highlight the importance of information structure in such\nsystems.",
    "published": "2025-10-27T20:05:56Z",
    "updated": "2025-10-27T20:05:56Z",
    "link": "http://arxiv.org/pdf/2510.23824v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Murad Ismayilov",
      "Edwin Meriaux",
      "Shuo Wen",
      "Gregory Dudek"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23822v1",
    "title": "ReCAP: Recursive Context-Aware Reasoning and Planning for Large Language\n  Model Agents",
    "summary": "Long-horizon tasks requiring multi-step reasoning and dynamic re-planning\nremain challenging for large language models (LLMs). Sequential prompting\nmethods are prone to context drift, loss of goal information, and recurrent\nfailure cycles, while hierarchical prompting methods often weaken cross-level\ncontinuity or incur substantial runtime overhead. We introduce ReCAP (Recursive\nContext-Aware Reasoning and Planning), a hierarchical framework with shared\ncontext for reasoning and planning in LLMs. ReCAP combines three key\nmechanisms: (i) plan-ahead decomposition, in which the model generates a full\nsubtask list, executes the first item, and refines the remainder; (ii)\nstructured re-injection of parent plans, maintaining consistent multi-level\ncontext during recursive return; and (iii) memory-efficient execution, bounding\nthe active prompt so costs scale linearly with task depth. Together these\nmechanisms align high-level goals with low-level actions, reduce redundant\nprompting, and preserve coherent context updates across recursion. Experiments\ndemonstrate that ReCAP substantially improves subgoal alignment and success\nrates on various long-horizon reasoning benchmarks, achieving a 32% gain on\nsynchronous Robotouille and a 29% improvement on asynchronous Robotouille under\nthe strict pass@1 protocol.",
    "published": "2025-10-27T20:03:55Z",
    "updated": "2025-10-27T20:03:55Z",
    "link": "http://arxiv.org/pdf/2510.23822v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Zhenyu Zhang",
      "Tianyi Chen",
      "Weiran Xu",
      "Alex Pentland",
      "Jiaxin Pei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.22366v5",
    "title": "One-Step is Enough: Sparse Autoencoders for Text-to-Image Diffusion\n  Models",
    "summary": "For large language models (LLMs), sparse autoencoders (SAEs) have been shown\nto decompose intermediate representations that often are not interpretable\ndirectly into sparse sums of interpretable features, facilitating better\ncontrol and subsequent analysis. However, similar analyses and approaches have\nbeen lacking for text-to-image models. We investigate the possibility of using\nSAEs to learn interpretable features for SDXL Turbo, a few-step text-to-image\ndiffusion model. To this end, we train SAEs on the updates performed by\ntransformer blocks within SDXL Turbo's denoising U-net in its 1-step setting.\nInterestingly, we find that they generalize to 4-step SDXL Turbo and even to\nthe multi-step SDXL base model (i.e., a different model) without additional\ntraining. In addition, we show that their learned features are interpretable,\ncausally influence the generation process, and reveal specialization among the\nblocks. We do so by creating RIEBench, a representation-based image editing\nbenchmark, for editing images while they are generated by turning on and off\nindividual SAE features. This allows us to track which transformer blocks'\nfeatures are the most impactful depending on the edit category. Our work is the\nfirst investigation of SAEs for interpretability in text-to-image diffusion\nmodels and our results establish SAEs as a promising approach for understanding\nand manipulating the internal mechanisms of text-to-image models.",
    "published": "2024-10-28T19:01:18Z",
    "updated": "2025-10-27T19:52:38Z",
    "link": "http://arxiv.org/pdf/2410.22366v5.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Viacheslav Surkov",
      "Chris Wendler",
      "Antonio Mari",
      "Mikhail Terekhov",
      "Justin Deschenaux",
      "Robert West",
      "Caglar Gulcehre",
      "David Bau"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23807v1",
    "title": "Why Foundation Models in Pathology Are Failing",
    "summary": "In non-medical domains, foundation models (FMs) have revolutionized computer\nvision and language processing through large-scale self-supervised and\nmultimodal learning. Consequently, their rapid adoption in computational\npathology was expected to deliver comparable breakthroughs in cancer diagnosis,\nprognostication, and multimodal retrieval. However, recent systematic\nevaluations reveal fundamental weaknesses: low diagnostic accuracy, poor\nrobustness, geometric instability, heavy computational demands, and concerning\nsafety vulnerabilities. This short paper examines these shortcomings and argues\nthat they stem from deeper conceptual mismatches between the assumptions\nunderlying generic foundation modeling in mainstream AI and the intrinsic\ncomplexity of human tissue. Seven interrelated causes are identified:\nbiological complexity, ineffective self-supervision, overgeneralization,\nexcessive architectural complexity, lack of domain-specific innovation,\ninsufficient data, and a fundamental design flaw related to tissue patch size.\nThese findings suggest that current pathology foundation models remain\nconceptually misaligned with the nature of tissue morphology and call for a\nfundamental rethinking of the paradigm itself.",
    "published": "2025-10-27T19:44:52Z",
    "updated": "2025-10-27T19:44:52Z",
    "link": "http://arxiv.org/pdf/2510.23807v1.pdf",
    "category": [
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Hamid R. Tizhoosh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.02937v2",
    "title": "FoGE: Fock Space inspired encoding for graph prompting",
    "summary": "Recent results show that modern Large Language Models (LLM) are indeed\ncapable of understanding and answering questions about structured data such as\ngraphs. This new paradigm can lead to solutions that require less supervision\nwhile, at the same time, providing a model that can generalize and answer\nquestions beyond the training labels. Existing proposals often use some\ndescription of the graph to create an ``augmented'' prompt fed to the LLM. For\na chosen class of graphs, if a well-tailored graph encoder is deployed to play\ntogether with a pre-trained LLM, the model can answer graph-related questions\nwell. Existing solutions to graph-based prompts range from graph serialization\nto graph transformers. In this work, we show that the use of a parameter-free\ngraph encoder based on Fock space representations, a concept borrowed from\nmathematical physics, is remarkably versatile in this problem setting. The\nsimple construction, inherited directly from the theory with a few small\nadjustments, can provide rich and informative graph encodings, for a wide range\nof different graphs. We investigate the use of this idea for prefix-tuned\nprompts leveraging the capabilities of a pre-trained, frozen LLM. The\nmodifications lead to a model that can answer graph-related questions -- from\nsimple graphs to proteins to hypergraphs -- effectively and with minimal, if\nany, adjustments to the architecture. Our work significantly simplifies\nexisting solutions and generalizes well to multiple different graph-based\nstructures effortlessly.",
    "published": "2025-06-26T23:48:03Z",
    "updated": "2025-10-27T19:36:33Z",
    "link": "http://arxiv.org/pdf/2507.02937v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Sotirios Panagiotis Chytas",
      "Rudrasis Chakraborty",
      "Vikas Singh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.03095v3",
    "title": "Distilled Protein Backbone Generation",
    "summary": "Diffusion- and flow-based generative models have recently demonstrated strong\nperformance in protein backbone generation tasks, offering unprecedented\ncapabilities for de novo protein design. However, while achieving notable\nperformance in generation quality, these models are limited by their generating\nspeed, often requiring hundreds of iterative steps in the reverse-diffusion\nprocess. This computational bottleneck limits their practical utility in\nlarge-scale protein discovery, where thousands to millions of candidate\nstructures are needed. To address this challenge, we explore the techniques of\nscore distillation, which has shown great success in reducing the number of\nsampling steps in the vision domain while maintaining high generation quality.\nHowever, a straightforward adaptation of these methods results in unacceptably\nlow designability. Through extensive study, we have identified how to\nappropriately adapt Score identity Distillation (SiD), a state-of-the-art score\ndistillation strategy, to train few-step protein backbone generators which\nsignificantly reduce sampling time, while maintaining comparable performance to\ntheir pretrained teacher model. In particular, multistep generation combined\nwith inference time noise modulation is key to the success. We demonstrate that\nour distilled few-step generators achieve more than a 20-fold improvement in\nsampling speed, while achieving similar levels of designability, diversity, and\nnovelty as the Proteina teacher model. This reduction in inference cost enables\nlarge-scale in silico protein design, thereby bringing diffusion-based models\ncloser to real-world protein engineering applications. The PyTorch\nimplementation is available at https://github.com/LY-Xie/SiD_Protein",
    "published": "2025-10-03T15:25:08Z",
    "updated": "2025-10-27T19:32:07Z",
    "link": "http://arxiv.org/pdf/2510.03095v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "authors": [
      "Liyang Xie",
      "Haoran Zhang",
      "Zhendong Wang",
      "Wesley Tansey",
      "Mingyuan Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23798v1",
    "title": "A geometric and deep learning reproducible pipeline for monitoring\n  floating anthropogenic debris in urban rivers using in situ cameras",
    "summary": "The proliferation of floating anthropogenic debris in rivers has emerged as a\npressing environmental concern, exerting a detrimental influence on\nbiodiversity, water quality, and human activities such as navigation and\nrecreation. The present study proposes a novel methodological framework for the\nmonitoring the aforementioned waste, utilising fixed, in-situ cameras. This\nstudy provides two key contributions: (i) the continuous quantification and\nmonitoring of floating debris using deep learning and (ii) the identification\nof the most suitable deep learning model in terms of accuracy and inference\nspeed under complex environmental conditions. These models are tested in a\nrange of environmental conditions and learning configurations, including\nexperiments on biases related to data leakage. Furthermore, a geometric model\nis implemented to estimate the actual size of detected objects from a 2D image.\nThis model takes advantage of both intrinsic and extrinsic characteristics of\nthe camera. The findings of this study underscore the significance of the\ndataset constitution protocol, particularly with respect to the integration of\nnegative images and the consideration of temporal leakage. In conclusion, the\nfeasibility of metric object estimation using projective geometry coupled with\nregression corrections is demonstrated. This approach paves the way for the\ndevelopment of robust, low-cost, automated monitoring systems for urban aquatic\nenvironments.",
    "published": "2025-10-27T19:29:14Z",
    "updated": "2025-10-27T19:29:14Z",
    "link": "http://arxiv.org/pdf/2510.23798v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Gauthier Grimmer",
      "Romain Wenger",
      "ClÃ©ment Flint",
      "Germain Forestier",
      "Gilles Rixhon",
      "Valentin Chardon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.16724v2",
    "title": "A Comprehensive Survey on Reinforcement Learning-based Agentic Search:\n  Foundations, Roles, Optimizations, Evaluations, and Applications",
    "summary": "The advent of large language models (LLMs) has transformed information access\nand reasoning through open-ended natural language interaction. However, LLMs\nremain limited by static knowledge, factual hallucinations, and the inability\nto retrieve real-time or domain-specific information. Retrieval-Augmented\nGeneration (RAG) mitigates these issues by grounding model outputs in external\nevidence, but traditional RAG pipelines are often single turn and heuristic,\nlacking adaptive control over retrieval and reasoning. Recent advances in\nagentic search address these limitations by enabling LLMs to plan, retrieve,\nand reflect through multi-step interaction with search environments. Within\nthis paradigm, reinforcement learning (RL) offers a powerful mechanism for\nadaptive and self-improving search behavior. This survey provides the first\ncomprehensive overview of \\emph{RL-based agentic search}, organizing the\nemerging field along three complementary dimensions: (i) What RL is for\n(functional roles), (ii) How RL is used (optimization strategies), and (iii)\nWhere RL is applied (scope of optimization). We summarize representative\nmethods, evaluation protocols, and applications, and discuss open challenges\nand future directions toward building reliable and scalable RL driven agentic\nsearch systems. We hope this survey will inspire future research on the\nintegration of RL and agentic search. Our repository is available at\nhttps://github.com/ventr1c/Awesome-RL-based-Agentic-Search-Papers.",
    "published": "2025-10-19T06:04:53Z",
    "updated": "2025-10-27T19:23:17Z",
    "link": "http://arxiv.org/pdf/2510.16724v2.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Minhua Lin",
      "Zongyu Wu",
      "Zhichao Xu",
      "Hui Liu",
      "Xianfeng Tang",
      "Qi He",
      "Charu Aggarwal",
      "Hui Liu",
      "Xiang Zhang",
      "Suhang Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23785v1",
    "title": "CountFormer: A Transformer Framework for Learning Visual Repetition and\n  Structure in Class-Agnostic Object Counting",
    "summary": "Humans can effortlessly count diverse objects by perceiving visual repetition\nand structural relationships rather than relying on class identity. However,\nmost existing counting models fail to replicate this ability; they often\nmiscount when objects exhibit complex shapes, internal symmetry, or overlapping\ncomponents. In this work, we introduce CountFormer, a transformer-based\nframework that learns to recognize repetition and structural coherence for\nclass-agnostic object counting. Built upon the CounTR architecture, our model\nreplaces its visual encoder with the self-supervised foundation model DINOv2,\nwhich produces richer and spatially consistent feature representations. We\nfurther incorporate positional embedding fusion to preserve geometric\nrelationships before decoding these features into density maps through a\nlightweight convolutional decoder. Evaluated on the FSC-147 dataset, our model\nachieves performance comparable to current state-of-the-art methods while\ndemonstrating superior accuracy on structurally intricate or densely packed\nscenes. Our findings indicate that integrating foundation models such as DINOv2\nenables counting systems to approach human-like structural perception,\nadvancing toward a truly general and exemplar-free counting paradigm.",
    "published": "2025-10-27T19:16:02Z",
    "updated": "2025-10-27T19:16:02Z",
    "link": "http://arxiv.org/pdf/2510.23785v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Md Tanvir Hossain",
      "Akif Islam",
      "Mohd Ruhul Ameen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.15870v2",
    "title": "OmniVinci: Enhancing Architecture and Data for Omni-Modal Understanding\n  LLM",
    "summary": "Advancing machine intelligence requires developing the ability to perceive\nacross multiple modalities, much as humans sense the world. We introduce\nOmniVinci, an initiative to build a strong, open-source, omni-modal LLM. We\ncarefully study the design choices across model architecture and data curation.\nFor model architecture, we present three key innovations: (i) OmniAlignNet for\nstrengthening alignment between vision and audio embeddings in a shared\nomni-modal latent space; (ii) Temporal Embedding Grouping for capturing\nrelative temporal alignment between vision and audio signals; and (iii)\nConstrained Rotary Time Embedding for encoding absolute temporal information in\nomni-modal embeddings. We introduce a curation and synthesis pipeline that\ngenerates 24M single-modal and omni-modal conversations. We find that\nmodalities reinforce one another in both perception and reasoning. Our model,\nOmniVinci, outperforms Qwen2.5-Omni with +19.05 on DailyOmni (cross-modal\nunderstanding), +1.7 on MMAR (audio), and +3.9 on Video-MME (vision), while\nusing just 0.2T training tokens - a 6 times reduction compared to\nQwen2.5-Omni's 1.2T. We finally demonstrate omni-modal advantages in downstream\napplications spanning robotics, medical AI, and smart factory.",
    "published": "2025-10-17T17:59:59Z",
    "updated": "2025-10-27T19:12:55Z",
    "link": "http://arxiv.org/pdf/2510.15870v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Hanrong Ye",
      "Chao-Han Huck Yang",
      "Arushi Goel",
      "Wei Huang",
      "Ligeng Zhu",
      "Yuanhang Su",
      "Sean Lin",
      "An-Chieh Cheng",
      "Zhen Wan",
      "Jinchuan Tian",
      "Yuming Lou",
      "Dong Yang",
      "Zhijian Liu",
      "Yukang Chen",
      "Ambrish Dantrey",
      "Ehsan Jahangiri",
      "Sreyan Ghosh",
      "Daguang Xu",
      "Ehsan Hosseini-Asl",
      "Danial Mohseni Taheri",
      "Vidya Murali",
      "Sifei Liu",
      "Yao Lu",
      "Oluwatobi Olabiyi",
      "Yu-Chiang Frank Wang",
      "Rafael Valle",
      "Bryan Catanzaro",
      "Andrew Tao",
      "Song Han",
      "Jan Kautz",
      "Hongxu Yin",
      "Pavlo Molchanov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23775v1",
    "title": "Explainable Detection of AI-Generated Images with Artifact Localization\n  Using Faster-Than-Lies and Vision-Language Models for Edge Devices",
    "summary": "The increasing realism of AI-generated imagery poses challenges for verifying\nvisual authenticity. We present an explainable image authenticity detection\nsystem that combines a lightweight convolutional classifier\n(\"Faster-Than-Lies\") with a Vision-Language Model (Qwen2-VL-7B) to classify,\nlocalize, and explain artifacts in 32x32 images. Our model achieves 96.5%\naccuracy on the extended CiFAKE dataset augmented with adversarial\nperturbations and maintains an inference time of 175ms on 8-core CPUs, enabling\ndeployment on local or edge devices. Using autoencoder-based reconstruction\nerror maps, we generate artifact localization heatmaps, which enhance\ninterpretability for both humans and the VLM. We further categorize 70 visual\nartifact types into eight semantic groups and demonstrate explainable text\ngeneration for each detected anomaly. This work highlights the feasibility of\ncombining visual and linguistic reasoning for interpretable authenticity\ndetection in low-resolution imagery and outlines potential cross-domain\napplications in forensics, industrial inspection, and social media moderation.",
    "published": "2025-10-27T19:01:24Z",
    "updated": "2025-10-27T19:01:24Z",
    "link": "http://arxiv.org/pdf/2510.23775v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "authors": [
      "Aryan Mathur",
      "Asaduddin Ahmed",
      "Pushti Amit Vasoya",
      "Simeon Kandan Sonar",
      "Yasir Z",
      "Madesh Kuppusamy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23772v1",
    "title": "Evaluating In Silico Creativity: An Expert Review of AI Chess\n  Compositions",
    "summary": "The rapid advancement of Generative AI has raised significant questions\nregarding its ability to produce creative and novel outputs. Our recent work\ninvestigates this question within the domain of chess puzzles and presents an\nAI system designed to generate puzzles characterized by aesthetic appeal,\nnovelty, counter-intuitive and unique solutions. We briefly discuss our method\nbelow and refer the reader to the technical paper for more details. To assess\nour system's creativity, we presented a curated booklet of AI-generated puzzles\nto three world-renowned experts: International Master for chess compositions\nAmatzia Avni, Grandmaster Jonathan Levitt, and Grandmaster Matthew Sadler. All\nthree are noted authors on chess aesthetics and the evolving role of computers\nin the game. They were asked to select their favorites and explain what made\nthem appealing, considering qualities such as their creativity, level of\nchallenge, or aesthetic design.",
    "published": "2025-10-27T19:00:02Z",
    "updated": "2025-10-27T19:00:02Z",
    "link": "http://arxiv.org/pdf/2510.23772v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Vivek Veeriah",
      "Federico Barbero",
      "Marcus Chiam",
      "Xidong Feng",
      "Michael Dennis",
      "Ryan Pachauri",
      "Thomas Tumiel",
      "Johan Obando-Ceron",
      "Jiaxin Shi",
      "Shaobo Hou",
      "Satinder Singh",
      "Nenad TomaÅ¡ev",
      "Tom Zahavy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.14571v2",
    "title": "Learned, Lagged, LLM-splained: LLM Responses to End User Security\n  Questions",
    "summary": "Answering end user security questions is challenging. While large language\nmodels (LLMs) like GPT, LLAMA, and Gemini are far from error-free, they have\nshown promise in answering a variety of questions outside of security. We\nstudied LLM performance in the area of end user security by qualitatively\nevaluating 3 popular LLMs on 900 systematically collected end user security\nquestions.\n  While LLMs demonstrate broad generalist ``knowledge'' of end user security\ninformation, there are patterns of errors and limitations across LLMs\nconsisting of stale and inaccurate answers, and indirect or unresponsive\ncommunication styles, all of which impacts the quality of information received.\nBased on these patterns, we suggest directions for model improvement and\nrecommend user strategies for interacting with LLMs when seeking assistance\nwith security.",
    "published": "2024-11-21T20:36:36Z",
    "updated": "2025-10-27T18:54:02Z",
    "link": "http://arxiv.org/pdf/2411.14571v2.pdf",
    "category": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "authors": [
      "Vijay Prakash",
      "Kevin Lee",
      "Arkaprabha Bhattacharya",
      "Danny Yuxing Huang",
      "Jessica Staddon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.00063v3",
    "title": "MolErr2Fix: Benchmarking LLM Trustworthiness in Chemistry via Modular\n  Error Detection, Localization, Explanation, and Revision",
    "summary": "Large Language Models (LLMs) have shown growing potential in molecular\nsciences, but they often produce chemically inaccurate descriptions and\nstruggle to recognize or justify potential errors. This raises important\nconcerns about their robustness and reliability in scientific applications. To\nsupport more rigorous evaluation of LLMs in chemical reasoning, we present the\nMolErr2Fix benchmark, designed to assess LLMs on error detection and correction\nin molecular descriptions. Unlike existing benchmarks focused on\nmolecule-to-text generation or property prediction, MolErr2Fix emphasizes\nfine-grained chemical understanding. It tasks LLMs with identifying,\nlocalizing, explaining, and revising potential structural and semantic errors\nin molecular descriptions. Specifically, MolErr2Fix consists of 1,193\nfine-grained annotated error instances. Each instance contains quadruple\nannotations, i.e,. (error type, span location, the explanation, and the\ncorrection). These tasks are intended to reflect the types of reasoning and\nverification required in real-world chemical communication. Evaluations of\ncurrent state-of-the-art LLMs reveal notable performance gaps, underscoring the\nneed for more robust chemical reasoning capabilities. MolErr2Fix provides a\nfocused benchmark for evaluating such capabilities and aims to support progress\ntoward more reliable and chemically informed language models. All annotations\nand an accompanying evaluation API will be publicly released to facilitate\nfuture research.",
    "published": "2025-08-26T05:43:45Z",
    "updated": "2025-10-27T18:51:42Z",
    "link": "http://arxiv.org/pdf/2509.00063v3.pdf",
    "category": [
      "physics.chem-ph",
      "cs.AI"
    ],
    "authors": [
      "Yuyang Wu",
      "Jinhui Ye",
      "Shuhao Zhang",
      "Lu Dai",
      "Yonatan Bisk",
      "Olexandr Isayev"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2404.02039v3",
    "title": "A Survey on Large Language Model-Based Game Agents",
    "summary": "Game environments provide rich, controllable settings that stimulate many\naspects of real-world complexity. As such, game agents offer a valuable testbed\nfor exploring capabilities relevant to Artificial General Intelligence.\nRecently, the emergence of Large Language Models (LLMs) provides new\nopportunities to endow these agents with generalizable reasoning, memory, and\nadaptability in complex game environments. This survey offers an up-to-date\nreview of LLM-based game agents (LLMGAs) through a unified reference\narchitecture. At the single-agent level, we synthesize existing studies around\nthree core components: memory, reasoning, and perception-action interfaces,\nwhich jointly characterize how language enables agents to perceive, think, and\nact. At the multi-agent level, we outline how communication protocols and\norganizational models support coordination, role differentiation, and\nlarge-scale social behaviors. To contextualize these designs, we introduce a\nchallenge-centered taxonomy linking six major game genres to their dominant\nagent requirements, from low-latency control in action games to open-ended goal\nformation in sandbox worlds. A curated list of related papers is available at\nhttps://github.com/git-disl/awesome-LLM-game-agent-papers",
    "published": "2024-04-02T15:34:18Z",
    "updated": "2025-10-27T18:50:51Z",
    "link": "http://arxiv.org/pdf/2404.02039v3.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Sihao Hu",
      "Tiansheng Huang",
      "Gaowen Liu",
      "Ramana Rao Kompella",
      "Fatih Ilhan",
      "Selim Furkan Tekin",
      "Yichang Xu",
      "Zachary Yahn",
      "Ling Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.14205v2",
    "title": "DPRF: A Generalizable Dynamic Persona Refinement Framework for\n  Optimizing Behavior Alignment Between Personalized LLM Role-Playing Agents\n  and Humans",
    "summary": "The emerging large language model role-playing agents (LLM RPAs) aim to\nsimulate individual human behaviors, but the persona fidelity is often\nundermined by manually-created profiles (e.g., cherry-picked information and\npersonality characteristics) without validating the alignment with the target\nindividuals. To address this limitation, our work introduces the Dynamic\nPersona Refinement Framework (DPRF).DPRF aims to optimize the alignment of LLM\nRPAs' behaviors with those of target individuals by iteratively identifying the\ncognitive divergence, either through free-form or theory-grounded, structured\nanalysis, between generated behaviors and human ground truth, and refining the\npersona profile to mitigate these divergences.We evaluate DPRF with five LLMs\non four diverse behavior-prediction scenarios: formal debates, social media\nposts with mental health issues, public interviews, and movie reviews.DPRF can\nconsistently improve behavioral alignment considerably over baseline personas\nand generalizes across models and scenarios.Our work provides a robust\nmethodology for creating high-fidelity persona profiles and enhancing the\nvalidity of downstream applications, such as user simulation, social studies,\nand personalized AI.",
    "published": "2025-10-16T01:26:38Z",
    "updated": "2025-10-27T18:45:42Z",
    "link": "http://arxiv.org/pdf/2510.14205v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Bingsheng Yao",
      "Bo Sun",
      "Yuanzhe Dong",
      "Yuxuan Lu",
      "Dakuo Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23761v1",
    "title": "TDFlow: Agentic Workflows for Test Driven Software Engineering",
    "summary": "We introduce TDFlow, a novel test-driven agentic workflow that frames\nrepository-scale software engineering as a test-resolution task, specifically\ndesigned to solve human-written tests. Given a set of tests, TDFlow repeatedly\nproposes, revises, and debugs repository-scale patches using precisely\nengineered sub-agents and tightly constrained tools. The workflow decomposes\nsoftware engineering program repair into four components governed by respective\nsub-agents. This simple, forced decoupling of patch proposing, debugging, patch\nrevision, and optional test generation (1) reduces long-context burden on any\nindividual sub-agent, (2) focuses each sub-agent on specific, pre-defined\nsub-tasks, and (3) allows for specialized performance improvement on specific\nsub-tasks. When provided human-written tests, TDFlow attains 88.8% pass rate on\nSWE-Bench Lite (an absolute improvement of 27.8% over the next best system) and\n94.3% on SWE-Bench Verified. Manual inspection of the 800 TDFlow runs within\nSWE-Bench Lite and Verified uncover only 7 instances of test hacking, which\nwere subsequently counted as failures. Furthermore, we show that the primary\nobstacle to human-level software engineering performance lies within writing\nsuccessful reproduction tests. We envision a human-LLM interactive system\npowered by TDFlow where human developers write tests solved by LLM systems.\nTogether, these results indicate that modern LLMs, when embedded in a narrowly\nengineered, test-driven workflow, already achieve human-level test resolution\n-- with the final frontier for fully autonomous repository repair being the\naccurate generation of valid reproduction tests.",
    "published": "2025-10-27T18:44:59Z",
    "updated": "2025-10-27T18:44:59Z",
    "link": "http://arxiv.org/pdf/2510.23761v1.pdf",
    "category": [
      "cs.SE",
      "cs.AI",
      "cs.MA"
    ],
    "authors": [
      "Kevin Han",
      "Siddharth Maddikayala",
      "Tim Knappe",
      "Om Patel",
      "Austen Liao",
      "Amir Barati Farimani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23756v1",
    "title": "Explaining Robustness to Catastrophic Forgetting Through Incremental\n  Concept Formation",
    "summary": "Catastrophic forgetting remains a central challenge in continual learning,\nwhere models are required to integrate new knowledge over time without losing\nwhat they have previously learned. In prior work, we introduced Cobweb/4V, a\nhierarchical concept formation model that exhibited robustness to catastrophic\nforgetting in visual domains. Motivated by this robustness, we examine three\nhypotheses regarding the factors that contribute to such stability: (1)\nadaptive structural reorganization enhances knowledge retention, (2) sparse and\nselective updates reduce interference, and (3) information-theoretic learning\nbased on sufficiency statistics provides advantages over gradient-based\nbackpropagation. To test these hypotheses, we compare Cobweb/4V with neural\nbaselines, including CobwebNN, a neural implementation of the Cobweb framework\nintroduced in this work. Experiments on datasets of varying complexity (MNIST,\nFashion-MNIST, MedMNIST, and CIFAR-10) show that adaptive restructuring\nenhances learning plasticity, sparse updates help mitigate interference, and\nthe information-theoretic learning process preserves prior knowledge without\nrevisiting past data. Together, these findings provide insight into mechanisms\nthat can mitigate catastrophic forgetting and highlight the potential of\nconcept-based, information-theoretic approaches for building stable and\nadaptive continual learning systems.",
    "published": "2025-10-27T18:41:25Z",
    "updated": "2025-10-27T18:41:25Z",
    "link": "http://arxiv.org/pdf/2510.23756v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Nicki Barari",
      "Edward Kim",
      "Christopher MacLellan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23751v1",
    "title": "Debiasing Reward Models by Representation Learning with Guarantees",
    "summary": "Recent alignment techniques, such as reinforcement learning from human\nfeedback, have been widely adopted to align large language models with human\npreferences by learning and leveraging reward models. In practice, these models\noften exploit spurious correlations, involving, e.g., response length,\ndiscrimination, sycophancy, and conceptual bias, which is a problem that has\nreceived increasing attention. In this work, we propose a principled framework\nthat mitigates these biases in reward models while preserving the underlying\nfactors that reflect intended preferences. We first provide a formulation of\nthe data-generating process, assuming that the observed data (e.g., text) is\ngenerated from both spurious and non-spurious latent variables. We show that,\ninterestingly, these non-spurious latent variables can be theoretically\nidentified from data, regardless of whether a surrogate for the spurious latent\nvariables is available. This further inspires a practical method that uses\nvariational inference to recover these variables and leverages them to train\nreward models. Experiments on synthetic and real-world datasets demonstrate\nthat our method effectively mitigates spurious correlation issues and yields\nmore robust reward models.",
    "published": "2025-10-27T18:37:57Z",
    "updated": "2025-10-27T18:37:57Z",
    "link": "http://arxiv.org/pdf/2510.23751v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "authors": [
      "Ignavier Ng",
      "Patrick BlÃ¶baum",
      "Siddharth Bhandari",
      "Kun Zhang",
      "Shiva Kasiviswanathan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23746v1",
    "title": "Test-Time Tuned Language Models Enable End-to-end De Novo Molecular\n  Structure Generation from MS/MS Spectra",
    "summary": "Tandem Mass Spectrometry enables the identification of unknown compounds in\ncrucial fields such as metabolomics, natural product discovery and\nenvironmental analysis. However, current methods rely on database matching from\npreviously observed molecules, or on multi-step pipelines that require\nintermediate fragment or fingerprint prediction. This makes finding the correct\nmolecule highly challenging, particularly for compounds absent from reference\ndatabases. We introduce a framework that, by leveraging test-time tuning,\nenhances the learning of a pre-trained transformer model to address this gap,\nenabling end-to-end de novo molecular structure generation directly from the\ntandem mass spectra and molecular formulae, bypassing manual annotations and\nintermediate steps. We surpass the de-facto state-of-the-art approach DiffMS on\ntwo popular benchmarks NPLIB1 and MassSpecGym by 100% and 20%, respectively.\nTest-time tuning on experimental spectra allows the model to dynamically adapt\nto novel spectra, and the relative performance gain over conventional\nfine-tuning is of 62% on MassSpecGym. When predictions deviate from the ground\ntruth, the generated molecular candidates remain structurally accurate,\nproviding valuable guidance for human interpretation and more reliable\nidentification.",
    "published": "2025-10-27T18:25:36Z",
    "updated": "2025-10-27T18:25:36Z",
    "link": "http://arxiv.org/pdf/2510.23746v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Laura Mismetti",
      "Marvin Alberts",
      "Andreas Krause",
      "Mara Graziani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23744v1",
    "title": "Multi-Environment POMDPs: Discrete Model Uncertainty Under Partial\n  Observability",
    "summary": "Multi-environment POMDPs (ME-POMDPs) extend standard POMDPs with discrete\nmodel uncertainty. ME-POMDPs represent a finite set of POMDPs that share the\nsame state, action, and observation spaces, but may arbitrarily vary in their\ntransition, observation, and reward models. Such models arise, for instance,\nwhen multiple domain experts disagree on how to model a problem. The goal is to\nfind a single policy that is robust against any choice of POMDP within the set,\ni.e., a policy that maximizes the worst-case reward across all POMDPs. We\ngeneralize and expand on existing work in the following way. First, we show\nthat ME-POMDPs can be generalized to POMDPs with sets of initial beliefs, which\nwe call adversarial-belief POMDPs (AB-POMDPs). Second, we show that any\narbitrary ME-POMDP can be reduced to a ME-POMDP that only varies in its\ntransition and reward functions or only in its observation and reward\nfunctions, while preserving (optimal) policies. We then devise exact and\napproximate (point-based) algorithms to compute robust policies for AB-POMDPs,\nand thus ME-POMDPs. We demonstrate that we can compute policies for standard\nPOMDP benchmarks extended to the multi-environment setting.",
    "published": "2025-10-27T18:24:11Z",
    "updated": "2025-10-27T18:24:11Z",
    "link": "http://arxiv.org/pdf/2510.23744v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Eline M. Bovy",
      "Caleb Probine",
      "Marnix Suilen",
      "Ufuk Topcu",
      "Nils Jansen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.02703v2",
    "title": "Data Leakage and Deceptive Performance: A Critical Examination of Credit\n  Card Fraud Detection Methodologies",
    "summary": "The art and science of Quranic recitation (Tajweed), a discipline governed by\nmeticulous phonetic, rhythmic, and theological principles, confronts\nsubstantial educational challenges in today's digital age. Although modern\ntechnology offers unparalleled opportunities for learning, existing automated\nsystems for evaluating recitation have struggled to gain broad acceptance or\ndemonstrate educational effectiveness. This literature review examines this\ncrucial disparity, offering a thorough analysis of scholarly research, digital\nplatforms, and commercial tools developed over the past twenty years. Our\nanalysis uncovers a fundamental flaw in current approaches that adapt Automatic\nSpeech Recognition (ASR) systems, which emphasize word identification over\nqualitative acoustic evaluation. These systems suffer from limitations such as\nreliance on biased datasets, demographic disparities, and an inability to\ndeliver meaningful feedback for improvement. Challenging these data-centric\nmethodologies, we advocate for a paradigm shift toward a knowledge-based\ncomputational framework. By leveraging the unchanging nature of the Quranic\ntext and the well-defined rules of Tajweed, we propose that an effective\nevaluation system should be built upon rule-based acoustic modeling centered on\ncanonical pronunciation principles and articulation points (Makhraj), rather\nthan depending on statistical patterns derived from flawed or biased data. The\nreview concludes that the future of automated Quranic recitation assessment\nlies in hybrid systems that combine linguistic expertise with advanced audio\nprocessing. Such an approach paves the way for developing reliable, fair, and\npedagogically effective tools that can authentically assist learners across the\nglobe.",
    "published": "2025-06-03T09:56:43Z",
    "updated": "2025-10-27T18:21:22Z",
    "link": "http://arxiv.org/pdf/2506.02703v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "authors": [
      "Mohammed Hilal Al-Kharusi",
      "Khizar Hayat",
      "Khalil Bader Al Ruqeishi",
      "Haroon Rashid Lone"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23734v1",
    "title": "AI and the Decentering of Disciplinary Creativity",
    "summary": "This paper examines the role of artificial intelligence in scientific\nproblem-solving, with a focus on its implications for disciplinary creativity.\nDrawing on recent work in the philosophy of creativity, I distinguish between\ncreative approaches and creative products, and introduce the concept of\ndisciplinary creativity -the creative application of discipline-specific\nexpertise to a valued problem within that field. Through two cases in\nmathematics, I show that while computation can extend disciplinary creativity,\ncertain approaches involving AI can serve to displace it. This displacement has\nthe potential to alter (and, perhaps, diminish) the value of scientific\npursuit.",
    "published": "2025-10-27T18:05:41Z",
    "updated": "2025-10-27T18:05:41Z",
    "link": "http://arxiv.org/pdf/2510.23734v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Eamon Duede"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24707v1",
    "title": "MetricX-25 and GemSpanEval: Google Translate Submissions to the WMT25\n  Evaluation Shared Task",
    "summary": "In this paper, we present our submissions to the unified WMT25 Translation\nEvaluation Shared Task. For the Quality Score Prediction subtask, we create a\nnew generation of MetricX with improvements in the input format and the\ntraining protocol, while for the Error Span Detection subtask we develop a new\nmodel, GemSpanEval, trained to predict error spans along with their severities\nand categories. Both systems are based on the state-of-the-art multilingual\nopen-weights model Gemma 3, fine-tuned on publicly available WMT data. We\ndemonstrate that MetricX-25, adapting Gemma 3 to an encoder-only architecture\nwith a regression head on top, can be trained to effectively predict both MQM\nand ESA quality scores, and significantly outperforms its predecessor. Our\ndecoder-only GemSpanEval model, on the other hand, we show to be competitive in\nerror span detection with xCOMET, a strong encoder-only sequence-tagging\nbaseline. With error span detection formulated as a generative task, we\ninstruct the model to also output the context for each predicted error span,\nthus ensuring that error spans are identified unambiguously.",
    "published": "2025-10-28T17:56:20Z",
    "updated": "2025-10-28T17:56:20Z",
    "link": "http://arxiv.org/pdf/2510.24707v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Juraj Juraska",
      "Tobias Domhan",
      "Mara Finkelstein",
      "Tetsuji Nakagawa",
      "Geza Kovacs",
      "Daniel Deutsch",
      "Pidong Wang",
      "Markus Freitag"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24697v1",
    "title": "WebLeaper: Empowering Efficiency and Efficacy in WebAgent via Enabling\n  Info-Rich Seeking",
    "summary": "Large Language Model (LLM)-based agents have emerged as a transformative\napproach for open-ended problem solving, with information seeking (IS) being a\ncore capability that enables autonomous reasoning and decision-making. While\nprior research has largely focused on improving retrieval depth, we observe\nthat current IS agents often suffer from low search efficiency, which in turn\nconstrains overall performance. A key factor underlying this inefficiency is\nthe sparsity of target entities in training tasks, which limits opportunities\nfor agents to learn and generalize efficient search behaviors. To address these\nchallenges, we propose WebLeaper, a framework for constructing high-coverage IS\ntasks and generating efficient solution trajectories. We formulate IS as a\ntree-structured reasoning problem, enabling a substantially larger set of\ntarget entities to be embedded within a constrained context. Leveraging curated\nWikipedia tables, we propose three variants for synthesizing IS tasks, Basic,\nUnion, and Reverse-Union, to systematically increase both IS efficiency and\nefficacy. Finally, we curate training trajectories by retaining only those that\nare simultaneously accurate and efficient, ensuring that the model is optimized\nfor both correctness and search performance. Extensive experiments on both\nbasic and comprehensive settings, conducted on five IS benchmarks, BrowserComp,\nGAIA, xbench-DeepSearch, WideSearch, and Seal-0, demonstrate that our method\nconsistently achieves improvements in both effectiveness and efficiency over\nstrong baselines.",
    "published": "2025-10-28T17:51:42Z",
    "updated": "2025-10-28T17:51:42Z",
    "link": "http://arxiv.org/pdf/2510.24697v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Zhengwei Tao",
      "Haiyang Shen",
      "Baixuan Li",
      "Wenbiao Yin",
      "Jialong Wu",
      "Kuan Li",
      "Zhongwang Zhang",
      "Huifeng Yin",
      "Rui Ye",
      "Liwen Zhang",
      "Xinyu Wang",
      "Pengjun Xie",
      "Jingren Zhou",
      "Yong Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24695v1",
    "title": "AgentFrontier: Expanding the Capability Frontier of LLM Agents with\n  ZPD-Guided Data Synthesis",
    "summary": "Training large language model agents on tasks at the frontier of their\ncapabilities is key to unlocking advanced reasoning. We introduce a data\nsynthesis approach inspired by the educational theory of the Zone of Proximal\nDevelopment (ZPD), which defines this frontier as tasks an LLM cannot solve\nalone but can master with guidance. To operationalize this, we present the\nAgentFrontier Engine, an automated pipeline that synthesizes high-quality,\nmultidisciplinary data situated precisely within the LLM's ZPD. This engine\nsupports both continued pre-training with knowledge-intensive data and targeted\npost-training on complex reasoning tasks. From the same framework, we derive\nthe ZPD Exam, a dynamic and automated benchmark designed to evaluate agent\ncapabilities on these frontier tasks. We train AgentFrontier-30B-A3B model on\nour synthesized data, which achieves state-of-the-art results on demanding\nbenchmarks like Humanity's Last Exam, even surpassing some leading proprietary\nagents. Our work demonstrates that a ZPD-guided approach to data synthesis\noffers a scalable and effective path toward building more capable LLM agents.",
    "published": "2025-10-28T17:50:47Z",
    "updated": "2025-10-28T17:50:47Z",
    "link": "http://arxiv.org/pdf/2510.24695v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Xuanzhong Chen",
      "Zile Qiao",
      "Guoxin Chen",
      "Liangcai Su",
      "Zhen Zhang",
      "Xinyu Wang",
      "Pengjun Xie",
      "Fei Huang",
      "Jingren Zhou",
      "Yong Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24693v1",
    "title": "STAR-Bench: Probing Deep Spatio-Temporal Reasoning as Audio 4D\n  Intelligence",
    "summary": "Despite rapid progress in Multi-modal Large Language Models and Large\nAudio-Language Models, existing audio benchmarks largely test semantics that\ncan be recovered from text captions, masking deficits in fine-grained\nperceptual reasoning. We formalize audio 4D intelligence that is defined as\nreasoning over sound dynamics in time and 3D space, and introduce STAR-Bench to\nmeasure it. STAR-Bench combines a Foundational Acoustic Perception setting (six\nattributes under absolute and relative regimes) with a Holistic Spatio-Temporal\nReasoning setting that includes segment reordering for continuous and discrete\nprocesses and spatial tasks spanning static localization, multi-source\nrelations, and dynamic trajectories. Our data curation pipeline uses two\nmethods to ensure high-quality samples. For foundational tasks, we use\nprocedurally synthesized and physics-simulated audio. For holistic data, we\nfollow a four-stage process that includes human annotation and final selection\nbased on human performance. Unlike prior benchmarks where caption-only\nanswering reduces accuracy slightly, STAR-Bench induces far larger drops\n(-31.5\\% temporal, -35.2\\% spatial), evidencing its focus on linguistically\nhard-to-describe cues. Evaluating 19 models reveals substantial gaps compared\nwith humans and a capability hierarchy: closed-source models are bottlenecked\nby fine-grained perception, while open-source models lag across perception,\nknowledge, and reasoning. Our STAR-Bench provides critical insights and a clear\npath forward for developing future models with a more robust understanding of\nthe physical world.",
    "published": "2025-10-28T17:50:34Z",
    "updated": "2025-10-28T17:50:34Z",
    "link": "http://arxiv.org/pdf/2510.24693v1.pdf",
    "category": [
      "cs.SD",
      "cs.CL",
      "eess.AS"
    ],
    "authors": [
      "Zihan Liu",
      "Zhikang Niu",
      "Qiuyang Xiao",
      "Zhisheng Zheng",
      "Ruoqi Yuan",
      "Yuhang Zang",
      "Yuhang Cao",
      "Xiaoyi Dong",
      "Jianze Liang",
      "Xie Chen",
      "Leilei Sun",
      "Dahua Lin",
      "Jiaqi Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24684v1",
    "title": "SPICE: Self-Play In Corpus Environments Improves Reasoning",
    "summary": "Self-improving systems require environmental interaction for continuous\nadaptation. We introduce SPICE (Self-Play In Corpus Environments), a\nreinforcement learning framework where a single model acts in two roles: a\nChallenger that mines documents from a large corpus to generate diverse\nreasoning tasks, and a Reasoner that solves them. Through adversarial dynamics,\nthe Challenger creates an automatic curriculum at the frontier of the\nReasoner's capability, while corpus grounding provides the rich,\nnear-inexhaustible external signal necessary for sustained improvement. Unlike\nexisting ungrounded self-play methods that offer more limited benefits, SPICE\nachieves consistent gains across mathematical (+8.9%) and general reasoning\n(+9.8%) benchmarks on multiple model families. Our analysis reveals how\ndocument grounding is a key ingredient in SPICE to continuously generate its\nown increasingly challenging goals and achieve them, enabling sustained\nself-improvement.",
    "published": "2025-10-28T17:46:16Z",
    "updated": "2025-10-28T17:46:16Z",
    "link": "http://arxiv.org/pdf/2510.24684v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Bo Liu",
      "Chuanyang Jin",
      "Seungone Kim",
      "Weizhe Yuan",
      "Wenting Zhao",
      "Ilia Kulikov",
      "Xian Li",
      "Sainbayar Sukhbaatar",
      "Jack Lanchantin",
      "Jason Weston"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24664v1",
    "title": "MQM Re-Annotation: A Technique for Collaborative Evaluation of Machine\n  Translation",
    "summary": "Human evaluation of machine translation is in an arms race with translation\nmodel quality: as our models get better, our evaluation methods need to be\nimproved to ensure that quality gains are not lost in evaluation noise. To this\nend, we experiment with a two-stage version of the current state-of-the-art\ntranslation evaluation paradigm (MQM), which we call MQM re-annotation. In this\nsetup, an MQM annotator reviews and edits a set of pre-existing MQM\nannotations, that may have come from themselves, another human annotator, or an\nautomatic MQM annotation system. We demonstrate that rater behavior in\nre-annotation aligns with our goals, and that re-annotation results in\nhigher-quality annotations, mostly due to finding errors that were missed\nduring the first pass.",
    "published": "2025-10-28T17:29:59Z",
    "updated": "2025-10-28T17:29:59Z",
    "link": "http://arxiv.org/pdf/2510.24664v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Parker Riley",
      "Daniel Deutsch",
      "Mara Finkelstein",
      "Colten DiIanni",
      "Juraj Juraska",
      "Markus Freitag"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24654v1",
    "title": "Evolving Diagnostic Agents in a Virtual Clinical Environment",
    "summary": "In this paper, we present a framework for training large language models\n(LLMs) as diagnostic agents with reinforcement learning, enabling them to\nmanage multi-turn diagnostic processes, adaptively select examinations, and\ncommit to final diagnoses. Unlike instruction-tuned models trained on static\ncase summaries, our method acquires diagnostic strategies through interactive\nexploration and outcome-based feedback. Our contributions are fourfold: (i) We\npresent DiagGym, a diagnostics world model trained with electronic health\nrecords that emits examination outcomes conditioned on patient history and\nrecommended examination, serving as a virtual clinical environment for\nrealistic diagnosis training and evaluation; (ii) We train DiagAgent via\nend-to-end, multi-turn reinforcement learning to learn diagnostic policies that\noptimize both information yield and diagnostic accuracy; (iii) We introduce\nDiagBench, a diagnostic benchmark comprising 750 cases with physician-validated\nexamination recommendations and 99 cases annotated with 973 physician-written\nrubrics on diagnosis process; (iv) we demonstrate superior performance across\ndiverse diagnostic settings. DiagAgent significantly outperforms 10\nstate-of-the-art LLMs, including DeepSeek-v3 and GPT-4o, as well as two\nprompt-engineered agents. In single-turn settings, DiagAgent achieves 9.34%\nhigher diagnostic accuracy and 44.03% improvement in examination recommendation\nhit ratio. In end-to-end settings, it delivers 15.12% increase in diagnostic\naccuracy and 23.09% boost in examination recommendation F1 score. In\nrubric-based evaluation, it surpasses the next-best model, Claude-sonnet-4, by\n7.1% in weighted rubric score. These findings indicate that learning policies\nin interactive clinical environments confers dynamic and clinically meaningful\ndiagnostic management abilities unattainable through passive training alone.",
    "published": "2025-10-28T17:19:47Z",
    "updated": "2025-10-28T17:19:47Z",
    "link": "http://arxiv.org/pdf/2510.24654v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Pengcheng Qiu",
      "Chaoyi Wu",
      "Junwei Liu",
      "Qiaoyu Zheng",
      "Yusheng Liao",
      "Haowen Wang",
      "Yun Yue",
      "Qianrui Fan",
      "Shuai Zhen",
      "Jian Wang",
      "Jinjie Gu",
      "Yanfeng Wang",
      "Ya Zhang",
      "Weidi Xie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24652v1",
    "title": "Optimizing Retrieval for RAG via Reinforced Contrastive Learning",
    "summary": "As retrieval-augmented generation (RAG) becomes increasingly widespread, the\nrole of information retrieval (IR) is shifting from retrieving information for\nhuman users to retrieving contextual knowledge for artificial intelligence (AI)\nsystems, where relevance becomes difficult to define or annotate beforehand. To\naddress this challenge, we propose R3, a Retrieval framework optimized for RAG\nthrough trialand-feedback Reinforced contrastive learning. Unlike prior\napproaches that rely on annotated or synthetic data for supervised fine-tuning,\nR3 enables the retriever to dynamically explore and optimize relevance within\nthe RAG environment. During training, the retrieved results interact with the\nenvironment to produce contrastive signals that automatically guide the\nretriever's self-improvement. Extensive experiments across diverse tasks\ndemonstrate that R3 improves RAG performance by 5.2% over the original\nretriever and surpasses state-of-the-art retrievers by 4.9%, while achieving\ncomparable results to LLM-augmented retrieval and RAG systems built on\npost-trained or instruction-tuned LLMs. It is both efficient and practical,\nrequiring only 4 GPUs and completing training within a single day.",
    "published": "2025-10-28T17:18:30Z",
    "updated": "2025-10-28T17:18:30Z",
    "link": "http://arxiv.org/pdf/2510.24652v1.pdf",
    "category": [
      "cs.CL",
      "cs.IR"
    ],
    "authors": [
      "Jiawei Zhou",
      "Lei Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24647v1",
    "title": "Quantifying the Effects of Word Length, Frequency, and Predictability on\n  Dyslexia",
    "summary": "We ask where, and under what conditions, dyslexic reading costs arise in a\nlarge-scale naturalistic reading dataset. Using eye-tracking aligned to\nword-level features (word length, frequency, and predictability), we model how\neach feature influences dyslexic time costs. We find that all three features\nrobustly change reading times in both typical and dyslexic readers, and that\ndyslexic readers show stronger sensitivities to each, especially\npredictability. Counterfactual manipulations of these features substantially\nnarrow the dyslexic-control gap by about one third, with predictability showing\nthe strongest effect, followed by length and frequency. These patterns align\nwith dyslexia theories that posit heightened demands on linguistic working\nmemory and phonological encoding, and they motivate further work on lexical\ncomplexity and parafoveal preview benefits to explain the remaining gap. In\nshort, we quantify when extra dyslexic costs arise, how large they are, and\noffer actionable guidance for interventions and computational models for\ndyslexics.",
    "published": "2025-10-28T17:15:31Z",
    "updated": "2025-10-28T17:15:31Z",
    "link": "http://arxiv.org/pdf/2510.24647v1.pdf",
    "category": [
      "cs.CL",
      "q-bio.NC"
    ],
    "authors": [
      "Hugo Rydel-Johnston",
      "Alex Kafkas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24636v1",
    "title": "OpenReward: Learning to Reward Long-form Agentic Tasks via Reinforcement\n  Learning",
    "summary": "Reward models (RMs) have become essential for aligning large language models\n(LLMs), serving as scalable proxies for human evaluation in both training and\ninference. However, existing RMs struggle on knowledge-intensive and long-form\ntasks, where evaluating correctness requires grounding beyond the model's\ninternal knowledge. This limitation hinders them from reliably discriminating\nsubtle quality differences, especially when external evidence is necessary. To\naddress this, we introduce OpenRM, a tool-augmented long-form reward model that\nsystematically judges open-ended responses by invoking external tools to gather\nrelevant evidence. We train OpenRM with Group Relative Policy Optimization\n(GRPO) on over 27K synthesized pairwise examples generated through a\ncontrollable data synthesis framework. The training objective jointly\nsupervises intermediate tool usage and final outcome accuracy, incentivizing\nour reward model to learn effective evidence-based judgment strategies.\nExtensive experiments on three newly-collected datasets and two widely-used\nbenchmarks demonstrate that OpenRM substantially outperforms existing reward\nmodeling approaches. As a further step, we integrate OpenRM into both\ninference-time response selection and training-time data selection. This yields\nconsistent gains in downstream LLM alignment tasks, highlighting the potential\nof tool-augmented reward models for scaling reliable long-form evaluation.",
    "published": "2025-10-28T17:02:46Z",
    "updated": "2025-10-28T17:02:46Z",
    "link": "http://arxiv.org/pdf/2510.24636v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Ziyou Hu",
      "Zhengliang Shi",
      "Minghang Zhu",
      "Haitao Li",
      "Teng Sun",
      "Pengjie Ren",
      "Suzan Verberne",
      "Zhaochun Ren"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24628v1",
    "title": "\"Mm, Wat?\" Detecting Other-initiated Repair Requests in Dialogue",
    "summary": "Maintaining mutual understanding is a key component in human-human\nconversation to avoid conversation breakdowns, in which repair, particularly\nOther-Initiated Repair (OIR, when one speaker signals trouble and prompts the\nother to resolve), plays a vital role. However, Conversational Agents (CAs)\nstill fail to recognize user repair initiation, leading to breakdowns or\ndisengagement. This work proposes a multimodal model to automatically detect\nrepair initiation in Dutch dialogues by integrating linguistic and prosodic\nfeatures grounded in Conversation Analysis. The results show that prosodic cues\ncomplement linguistic features and significantly improve the results of\npretrained text and audio embeddings, offering insights into how different\nfeatures interact. Future directions include incorporating visual cues,\nexploring multilingual and cross-context corpora to assess the robustness and\ngeneralizability.",
    "published": "2025-10-28T16:58:26Z",
    "updated": "2025-10-28T16:58:26Z",
    "link": "http://arxiv.org/pdf/2510.24628v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Anh Ngo",
      "Nicolas Rollet",
      "Catherine Pelachaud",
      "Chloe Clavel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24626v1",
    "title": "Relative Scaling Laws for LLMs",
    "summary": "Scaling laws describe how language models improve with additional data,\nparameters, and compute. While widely used, they are typically measured on\naggregate test sets. Aggregate evaluations yield clean trends but average over\nheterogeneous subpopulations, obscuring performance disparities. We introduce\nrelative scaling laws, which track how performance gaps between test\ndistributions evolve with scale rather than focusing solely on absolute error.\nUsing 255 decoder-only Transformers trained under matched-compute (IsoFLOP)\nbudgets from $10^{18}$--$10^{20}$ FLOPs on standard pretraining datasets, we\nfind diverse trajectories: academic domains on MMLU converge toward parity;\nregional English dialects shift depending on population size; and clusters of\nAI risk behaviours split, with capability- and influence-related risks\nincreasing during pretraining while adversarial risks do not. These results\nshow that although scaling improves overall performance, it is not a universal\nequalizer. To support further study, we release all model checkpoints from this\nwork to enable practitioners to measure relative alongside traditional scaling\nlaws, in order to better prioritize robustness challenges in light of the\nbitter lesson.",
    "published": "2025-10-28T16:55:22Z",
    "updated": "2025-10-28T16:55:22Z",
    "link": "http://arxiv.org/pdf/2510.24626v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "William Held",
      "David Hall",
      "Percy Liang",
      "Diyi Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2409.11390v3",
    "title": "Says Who? Effective Zero-Shot Annotation of Focalization",
    "summary": "Focalization describes the way in which access to narrative information is\nrestricted or controlled based on the knowledge available to knowledge of the\nnarrator. It is encoded via a wide range of lexico-grammatical features and is\nsubject to reader interpretation. Even trained annotators frequently disagree\non correct labels, suggesting this task is both qualitatively and\ncomputationally challenging. In this work, we test how well five contemporary\nlarge language model (LLM) families and two baselines perform when annotating\nshort literary excerpts for focalization. Despite the challenging nature of the\ntask, we find that LLMs show comparable performance to trained human\nannotators, with GPT-4o achieving an average F1 of 84.79%. Further, we\ndemonstrate that the log probabilities output by GPT-family models frequently\nreflect the difficulty of annotating particular excerpts. Finally, we provide a\ncase study analyzing sixteen Stephen King novels, demonstrating the usefulness\nof this approach for computational literary studies and the insights gleaned\nfrom examining focalization at scale.",
    "published": "2024-09-17T17:50:15Z",
    "updated": "2025-10-28T16:44:02Z",
    "link": "http://arxiv.org/pdf/2409.11390v3.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Rebecca M. M. Hicke",
      "Yuri Bizzoni",
      "Pascale Feldkamp",
      "Ross Deans Kristensen-McLachlan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24606v1",
    "title": "Long-Context Modeling with Dynamic Hierarchical Sparse Attention for\n  On-Device LLMs",
    "summary": "The quadratic cost of attention hinders the scalability of long-context LLMs,\nespecially in resource-constrained settings. Existing static sparse methods\nsuch as sliding windows or global tokens utilizes the sparsity of attention to\nreduce the cost of attention, but poorly adapts to the content-dependent\nvariations in attention due to their staticity. While previous work has\nproposed several dynamic approaches to improve flexibility, they still depend\non predefined templates or heuristic mechanisms. Such strategies reduce\ngenerality and prune tokens that remain contextually important, limiting their\naccuracy across diverse tasks. To tackle these bottlenecks of existing methods\nfor long-context modeling, we introduce Dynamic Hierarchical Sparse Attention\n(DHSA), a data-driven framework that dynamically predicts attention sparsity\nonline without retraining. Our proposed DHSA adaptively segments sequences into\nvariable-length chunks, then computes chunk representations by aggregating the\ntoken embeddings within each chunk. To avoid the bias introduced by varying\nchunk lengths, we apply length-normalized aggregation that scales the averaged\nembeddings by the square root of the chunk size. Finally, DHSA upsamples the\nchunk-level similarity scores to token level similarities to calculate\nimportance scores that determine which token-level interactions should be\npreserved. Our experiments on Gemma2 with Needle-in-a-Haystack Test and\nLongBench show that DHSA matches dense attention in accuracy, while reducing\nprefill latency by 20-60% and peak memory usage by 35%. Compared to other\nrepresentative baselines such as block sparse attention, DHSA achieves\nconsistently higher accuracy (6-18% relative gains) with comparable or lower\ncost, offering an efficient and adaptable solution for long-context on-device\nLLMs.",
    "published": "2025-10-28T16:34:18Z",
    "updated": "2025-10-28T16:34:18Z",
    "link": "http://arxiv.org/pdf/2510.24606v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Siheng Xiong",
      "Joe Zou",
      "Faramarz Fekri",
      "Yae Jee Cho"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24605v1",
    "title": "Diffusion LLM with Native Variable Generation Lengths: Let [EOS] Lead\n  the Way",
    "summary": "Diffusion-based large language models (dLLMs) have exhibited substantial\npotential for parallel text generation, which may enable more efficient\ngeneration compared to autoregressive models. However, current dLLMs suffer\nfrom fixed generation lengths, which indicates the generation lengths of dLLMs\nhave to be determined before decoding as a hyper-parameter, leading to issues\nin efficiency and flexibility. To solve these problems, in this work, we\npropose to train a diffusion LLM with native variable generation lengths,\nabbreviated as dLLM-Var. Concretely, we aim to train a model to accurately\npredict the [EOS] token in the generated text, which makes a dLLM be able to\nnatively infer in a block diffusion manner, while still maintaining the ability\nof global bi-directional (full) attention and high parallelism. Experiments on\nstandard benchmarks demonstrate that our method achieves a 30.1x speedup over\ntraditional dLLM inference paradigms and a 2.4x speedup relative to\nautoregressive models such as Qwen and Llama. Our method achieves higher\naccuracy and faster inference, elevating dLLMs beyond mere academic novelty and\nsupporting their practical use in real-world applications. Codes and models\nhave been released.",
    "published": "2025-10-28T16:32:43Z",
    "updated": "2025-10-28T16:32:43Z",
    "link": "http://arxiv.org/pdf/2510.24605v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yicun Yang",
      "Cong Wang",
      "Shaobo Wang",
      "Zichen Wen",
      "Biqing Qi",
      "Hanlin Xu",
      "Linfeng Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24592v1",
    "title": "ReForm: Reflective Autoformalization with Prospective Bounded Sequence\n  Optimization",
    "summary": "Autoformalization, which translates natural language mathematics into\nmachine-verifiable formal statements, is critical for using formal mathematical\nreasoning to solve math problems stated in natural language. While Large\nLanguage Models can generate syntactically correct formal statements, they\noften fail to preserve the original problem's semantic intent. This limitation\narises from the LLM approaches' treating autoformalization as a simplistic\ntranslation task which lacks mechanisms for self-reflection and iterative\nrefinement that human experts naturally employ. To address these issues, we\npropose ReForm, a Reflective Autoformalization method that tightly integrates\nsemantic consistency evaluation into the autoformalization process. This\nenables the model to iteratively generate formal statements, assess its\nsemantic fidelity, and self-correct identified errors through progressive\nrefinement. To effectively train this reflective model, we introduce\nProspective Bounded Sequence Optimization (PBSO), which employs different\nrewards at different sequence positions to ensure that the model develops both\naccurate autoformalization and correct semantic validations, preventing\nsuperficial critiques that would undermine the purpose of reflection. Extensive\nexperiments across four autoformalization benchmarks demonstrate that ReForm\nachieves an average improvement of 17.2 percentage points over the strongest\nbaselines. To further ensure evaluation reliability, we introduce\nConsistencyCheck, a benchmark of 859 expert-annotated items that not only\nvalidates LLMs as judges but also reveals that autoformalization is inherently\ndifficult: even human experts produce semantic errors in up to 38.5% of cases.",
    "published": "2025-10-28T16:22:54Z",
    "updated": "2025-10-28T16:22:54Z",
    "link": "http://arxiv.org/pdf/2510.24592v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Guoxin Chen",
      "Jing Wu",
      "Xinjie Chen",
      "Wayne Xin Zhao",
      "Ruihua Song",
      "Chengxi Li",
      "Kai Fan",
      "Dayiheng Liu",
      "Minpeng Liao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24591v1",
    "title": "ReplicationBench: Can AI Agents Replicate Astrophysics Research Papers?",
    "summary": "Frontier AI agents show increasing promise as scientific research assistants,\nand may eventually be useful for extended, open-ended research workflows.\nHowever, in order to use agents for novel research, we must first assess the\nunderlying faithfulness and correctness of their work. To evaluate agents as\nresearch assistants, we introduce ReplicationBench, an evaluation framework\nthat tests whether agents can replicate entire research papers drawn from the\nastrophysics literature. Astrophysics, where research relies heavily on\narchival data and computational study while requiring little real-world\nexperimentation, is a particularly useful testbed for AI agents in scientific\nresearch. We split each paper into tasks which require agents to replicate the\npaper's core contributions, including the experimental setup, derivations, data\nanalysis, and codebase. Each task is co-developed with the original paper\nauthors and targets a key scientific result, enabling objective evaluation of\nboth faithfulness (adherence to original methods) and correctness (technical\naccuracy of results). ReplicationBench is extremely challenging for current\nfrontier language models: even the best-performing language models score under\n20%. We analyze ReplicationBench trajectories in collaboration with domain\nexperts and find a rich, diverse set of failure modes for agents in scientific\nresearch. ReplicationBench establishes the first benchmark of paper-scale,\nexpert-validated astrophysics research tasks, reveals insights about agent\nperformance generalizable to other domains of data-driven science, and provides\na scalable framework for measuring AI agents' reliability in scientific\nresearch.",
    "published": "2025-10-28T16:21:19Z",
    "updated": "2025-10-28T16:21:19Z",
    "link": "http://arxiv.org/pdf/2510.24591v1.pdf",
    "category": [
      "cs.CL",
      "astro-ph.IM"
    ],
    "authors": [
      "Christine Ye",
      "Sihan Yuan",
      "Suchetha Cooray",
      "Steven Dillmann",
      "Ian L. V. Roque",
      "Dalya Baron",
      "Philipp Frank",
      "Sergio Martin-Alvarez",
      "Nolan Koblischke",
      "Frank J Qu",
      "Diyi Yang",
      "Risa Wechsler",
      "Ioana Ciuca"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.14617v3",
    "title": "The Hawthorne Effect in Reasoning Models: Evaluating and Steering Test\n  Awareness",
    "summary": "Reasoning-focused LLMs sometimes alter their behavior when they detect that\nthey are being evaluated, which can lead them to optimize for test-passing\nperformance or to comply more readily with harmful prompts if real-world\nconsequences appear absent. We present the first quantitative study of how such\n\"test awareness\" impacts model behavior, particularly its performance on\nsafety-related tasks. We introduce a white-box probing framework that (i)\nlinearly identifies awareness-related activations and (ii) steers models toward\nor away from test awareness while monitoring downstream performance. We apply\nour method to different state-of-the-art open-weight reasoning LLMs across both\nrealistic and hypothetical tasks (denoting tests or simulations). Our results\ndemonstrate that test awareness significantly impacts safety alignment (such as\ncompliance with harmful requests and conforming to stereotypes) with effects\nvarying in both magnitude and direction across models. By providing control\nover this latent effect, our work aims to provide a stress-test mechanism and\nincrease trust in how we perform safety evaluations.",
    "published": "2025-05-20T17:03:12Z",
    "updated": "2025-10-28T16:02:10Z",
    "link": "http://arxiv.org/pdf/2505.14617v3.pdf",
    "category": [
      "cs.CL",
      "cs.CY"
    ],
    "authors": [
      "Sahar Abdelnabi",
      "Ahmed Salem"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24570v1",
    "title": "BEST-RQ-Based Self-Supervised Learning for Whisper Domain Adaptation",
    "summary": "Automatic Speech Recognition (ASR) systems, despite large multilingual\ntraining, struggle in out-of-domain and low-resource scenarios where labeled\ndata is scarce. We propose BEARD (BEST-RQ Encoder Adaptation with Re-training\nand Distillation), a novel framework designed to adapt Whisper's encoder using\nunlabeled data. Unlike traditional self-supervised learning methods, BEARD\nuniquely combines a BEST-RQ objective with knowledge distillation from a frozen\nteacher encoder, ensuring the encoder's complementarity with the pre-trained\ndecoder. Our experiments focus on the ATCO2 corpus from the challenging Air\nTraffic Control (ATC) communications domain, characterized by non-native\nspeech, noise, and specialized phraseology. Using about 5,000 hours of\nuntranscribed speech for BEARD and 2 hours of transcribed speech for\nfine-tuning, the proposed approach significantly outperforms previous baseline\nand fine-tuned model, achieving a relative improvement of 12% compared to the\nfine-tuned model. To the best of our knowledge, this is the first work to use a\nself-supervised learning objective for domain adaptation of Whisper.",
    "published": "2025-10-28T16:01:24Z",
    "updated": "2025-10-28T16:01:24Z",
    "link": "http://arxiv.org/pdf/2510.24570v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "RaphaÃ«l Bagat",
      "Irina Illina",
      "Emmanuel Vincent"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24541v1",
    "title": "Open Korean Historical Corpus: A Millennia-Scale Diachronic Collection\n  of Public Domain Texts",
    "summary": "The history of the Korean language is characterized by a discrepancy between\nits spoken and written forms and a pivotal shift from Chinese characters to the\nHangul alphabet. However, this linguistic evolution has remained largely\nunexplored in NLP due to a lack of accessible historical corpora. To address\nthis gap, we introduce the Open Korean Historical Corpus, a large-scale, openly\nlicensed dataset spanning 1,300 years and 6 languages, as well as\nunder-represented writing systems like Korean-style Sinitic (Idu) and\nHanja-Hangul mixed script. This corpus contains 18 million documents and 5\nbillion tokens from 19 sources, ranging from the 7th century to 2025. We\nleverage this resource to quantitatively analyze major linguistic shifts: (1)\nIdu usage peaked in the 1860s before declining sharply; (2) the transition from\nHanja to Hangul was a rapid transformation starting around 1890; and (3) North\nKorea's lexical divergence causes modern tokenizers to produce up to 51 times\nhigher out-of-vocabulary rates. This work provides a foundational resource for\nquantitative diachronic analysis by capturing the history of the Korean\nlanguage. Moreover, it can serve as a pre-training corpus for large language\nmodels, potentially improving their understanding of Sino-Korean vocabulary in\nmodern Hangul as well as archaic writing systems.",
    "published": "2025-10-28T15:43:26Z",
    "updated": "2025-10-28T15:43:26Z",
    "link": "http://arxiv.org/pdf/2510.24541v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Seyoung Song",
      "Nawon Kim",
      "Songeun Chae",
      "Kiwoong Park",
      "Jiho Jin",
      "Haneul Yoo",
      "Kyunghyun Cho",
      "Alice Oh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24538v1",
    "title": "Dark & Stormy: Modeling Humor in the Worst Sentences Ever Written",
    "summary": "Textual humor is enormously diverse and computational studies need to account\nfor this range, including intentionally bad humor. In this paper, we curate and\nanalyze a novel corpus of sentences from the Bulwer-Lytton Fiction Contest to\nbetter understand \"bad\" humor in English. Standard humor detection models\nperform poorly on our corpus, and an analysis of literary devices finds that\nthese sentences combine features common in existing humor datasets (e.g., puns,\nirony) with metaphor, metafiction and simile. LLMs prompted to synthesize\ncontest-style sentences imitate the form but exaggerate the effect by\nover-using certain literary devices, and including far more novel\nadjective-noun bigrams than human writers. Data, code and analysis are\navailable at https://github.com/venkatasg/bulwer-lytton",
    "published": "2025-10-28T15:42:03Z",
    "updated": "2025-10-28T15:42:03Z",
    "link": "http://arxiv.org/pdf/2510.24538v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Venkata S Govindarajan",
      "Laura Biester"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24530v1",
    "title": "LevÃ©e d'ambiguÃ¯tÃ©s par grammaires locales",
    "summary": "Many words are ambiguous in terms of their part of speech (POS). However,\nwhen a word appears in a text, this ambiguity is generally much reduced.\nDisambiguating POS involves using context to reduce the number of POS\nassociated with words, and is one of the main challenges of lexical tagging.\nThe problem of labeling words by POS frequently arises in natural language\nprocessing, for example for spelling correction, grammar or style checking,\nexpression recognition, text-to-speech conversion, text corpus analysis, etc.\nLexical tagging systems are thus useful as an initial component of many natural\nlanguage processing systems. A number of recent lexical tagging systems produce\nmultiple solutions when the text is lexically ambiguous or the uniquely correct\nsolution cannot be found. These contributions aim to guarantee a zero silence\nrate: the correct tag(s) for a word must never be discarded. This objective is\nunrealistic for systems that tag each word uniquely. This article concerns a\nlexical disambiguation method adapted to the objective of a zero silence rate\nand implemented in Silberztein's INTEX system (1993). We present here a formal\ndescription of this method. We show that to verify a local disambiguation\ngrammar in this framework, it is not sufficient to consider the transducer\npaths separately: one needs to verify their interactions. Similarly, if a\ncombination of multiple transducers is used, the result cannot be predicted by\nconsidering them in isolation. Furthermore, when examining the initial labeling\nof a text as produced by INTEX, ideas for disambiguation rules come\nspontaneously, but grammatical intuitions may turn out to be inaccurate, often\ndue to an unforeseen construction or ambiguity. If a zero silence rate is\ntargeted, local grammars must be carefully tested. This is where a detailed\nspecification of what a grammar will do once applied to texts would be\nnecessary.",
    "published": "2025-10-28T15:38:22Z",
    "updated": "2025-10-28T15:38:22Z",
    "link": "http://arxiv.org/pdf/2510.24530v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Eric G. C. Laporte"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24514v1",
    "title": "Latent Sketchpad: Sketching Visual Thoughts to Elicit Multimodal\n  Reasoning in MLLMs",
    "summary": "While Multimodal Large Language Models (MLLMs) excel at visual understanding,\nthey often struggle in complex scenarios that require visual planning and\nimagination. Inspired by how humans use sketching as a form of visual thinking\nto develop and communicate ideas, we introduce Latent Sketchpad, a framework\nthat equips MLLMs with an internal visual scratchpad. The internal visual\nrepresentations of MLLMs have traditionally been confined to perceptual\nunderstanding. We repurpose them to support generative visual thought without\ncompromising reasoning ability. Building on frontier MLLMs, our approach\nintegrates visual generation directly into their native autoregressive\nreasoning process. It allows the model to interleave textual reasoning with the\ngeneration of visual latents. These latents guide the internal thought process\nand can be translated into sketch images for interpretability. To realize this,\nwe introduce two components: a Context-Aware Vision Head autoregressively\nproduces visual representations, and a pretrained Sketch Decoder renders these\ninto human-interpretable images. We evaluate the framework on our new dataset\nMazePlanning. Experiments across various MLLMs show that Latent Sketchpad\ndelivers comparable or even superior reasoning performance to their backbone.\nIt further generalizes across distinct frontier MLLMs, including Gemma3 and\nQwen2.5-VL. By extending model's textual reasoning to visual thinking, our\nframework opens new opportunities for richer human-computer interaction and\nbroader applications. More details and resources are available on our project\npage: https://latent-sketchpad.github.io/.",
    "published": "2025-10-28T15:26:20Z",
    "updated": "2025-10-28T15:26:20Z",
    "link": "http://arxiv.org/pdf/2510.24514v1.pdf",
    "category": [
      "cs.CV",
      "cs.CL"
    ],
    "authors": [
      "Huanyu Zhang",
      "Wenshan Wu",
      "Chengzu Li",
      "Ning Shang",
      "Yan Xia",
      "Yangyu Huang",
      "Yifan Zhang",
      "Li Dong",
      "Zhang Zhang",
      "Liang Wang",
      "Tieniu Tan",
      "Furu Wei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24505v1",
    "title": "CritiCal: Can Critique Help LLM Uncertainty or Confidence Calibration?",
    "summary": "Accurate confidence calibration in Large Language Models (LLMs) is critical\nfor safe use in high-stakes domains, where clear verbalized confidence enhances\nuser trust. Traditional methods that mimic reference confidence expressions\noften fail to capture the reasoning needed for accurate confidence assessment.\nWe propose natural language critiques as a solution, ideally suited for\nconfidence calibration, as precise gold confidence labels are hard to obtain\nand often require multiple generations. This paper studies how natural language\ncritiques can enhance verbalized confidence, addressing: (1) What to critique:\nuncertainty (question-focused) or confidence (answer-specific)? Analysis shows\nconfidence suits multiple-choice tasks, while uncertainty excels in open-ended\nscenarios. (2) How to critique: self-critique or critique calibration training?\nWe propose Self-Critique, enabling LLMs to critique and optimize their\nconfidence beyond mere accuracy, and CritiCal, a novel Critique Calibration\ntraining method that leverages natural language critiques to improve confidence\ncalibration, moving beyond direct numerical optimization. Experiments show that\nCritiCal significantly outperforms Self-Critique and other competitive\nbaselines, even surpassing its teacher model, GPT-4o, in complex reasoning\ntasks. CritiCal also shows robust generalization in out-of-distribution\nsettings, advancing LLM's reliability.",
    "published": "2025-10-28T15:16:06Z",
    "updated": "2025-10-28T15:16:06Z",
    "link": "http://arxiv.org/pdf/2510.24505v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Qing Zong",
      "Jiayu Liu",
      "Tianshi Zheng",
      "Chunyang Li",
      "Baixuan Xu",
      "Haochen Shi",
      "Weiqi Wang",
      "Zhaowei Wang",
      "Chunkit Chan",
      "Yangqiu Song"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24478v1",
    "title": "Talk2Ref: A Dataset for Reference Prediction from Scientific Talks",
    "summary": "Scientific talks are a growing medium for disseminating research, and\nautomatically identifying relevant literature that grounds or enriches a talk\nwould be highly valuable for researchers and students alike. We introduce\nReference Prediction from Talks (RPT), a new task that maps long, and\nunstructured scientific presentations to relevant papers. To support research\non RPT, we present Talk2Ref, the first large-scale dataset of its kind,\ncontaining 6,279 talks and 43,429 cited papers (26 per talk on average), where\nrelevance is approximated by the papers cited in the talk's corresponding\nsource publication. We establish strong baselines by evaluating\nstate-of-the-art text embedding models in zero-shot retrieval scenarios, and\npropose a dual-encoder architecture trained on Talk2Ref. We further explore\nstrategies for handling long transcripts, as well as training for domain\nadaptation. Our results show that fine-tuning on Talk2Ref significantly\nimproves citation prediction performance, demonstrating both the challenges of\nthe task and the effectiveness of our dataset for learning semantic\nrepresentations from spoken scientific content. The dataset and trained models\nare released under an open license to foster future research on integrating\nspoken scientific communication into citation recommendation systems.",
    "published": "2025-10-28T14:50:03Z",
    "updated": "2025-10-28T14:50:03Z",
    "link": "http://arxiv.org/pdf/2510.24478v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Frederik Broy",
      "Maike ZÃ¼fle",
      "Jan Niehues"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.22830v2",
    "title": "Exploration of Summarization by Generative Language Models for Automated\n  Scoring of Long Essays",
    "summary": "BERT and its variants are extensively explored for automated scoring.\nHowever, a limit of 512 tokens for these encoder-based models showed the\ndeficiency in automated scoring of long essays. Thus, this research explores\ngenerative language models for automated scoring of long essays via\nsummarization and prompting. The results revealed great improvement of scoring\naccuracy with QWK increased from 0.822 to 0.8878 for the Learning Agency Lab\nAutomated Essay Scoring 2.0 dataset.",
    "published": "2025-10-26T20:59:22Z",
    "updated": "2025-10-28T14:43:58Z",
    "link": "http://arxiv.org/pdf/2510.22830v2.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Haowei Hua",
      "Hong Jiao",
      "Xinyi Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.20039v3",
    "title": "AutoJudge: Judge Decoding Without Manual Annotation",
    "summary": "We introduce AutoJudge, a method that accelerates large language model (LLM)\ninference with task-specific lossy speculative decoding. Instead of matching\nthe original model output distribution token-by-token, we identify which of the\ngenerated tokens affect the downstream quality of the response, relaxing the\ndistribution match guarantee so that the \"unimportant\" tokens can be generated\nfaster. Our approach relies on a semi-greedy search algorithm to test which of\nthe mismatches between target and draft models should be corrected to preserve\nquality and which ones may be skipped. We then train a lightweight classifier\nbased on existing LLM embeddings to predict, at inference time, which\nmismatching tokens can be safely accepted without compromising the final answer\nquality. We evaluate the effectiveness of AutoJudge with multiple draft/target\nmodel pairs on mathematical reasoning and programming benchmarks, achieving\nsignificant speedups at the cost of a minor accuracy reduction. Notably, on\nGSM8k with the Llama 3.1 70B target model, our approach achieves up to\n$\\approx2\\times$ speedup over speculative decoding at the cost of $\\le 1\\%$\ndrop in accuracy. When applied to the LiveCodeBench benchmark, AutoJudge\nautomatically detects programming-specific important tokens, accepting $\\ge 25$\ntokens per speculation cycle at $2\\%$ drop in Pass@1. Our approach requires no\nhuman annotation and is easy to integrate with modern LLM inference frameworks.",
    "published": "2025-04-28T17:59:28Z",
    "updated": "2025-10-28T14:35:32Z",
    "link": "http://arxiv.org/pdf/2504.20039v3.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Roman Garipov",
      "Fedor Velikonivtsev",
      "Ivan Ermakov",
      "Ruslan Svirschevski",
      "Vage Egiazarian",
      "Max Ryabinin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.17336v2",
    "title": "Mano Technical Report",
    "summary": "Graphical user interfaces (GUIs) are the primary medium for human-computer\ninteraction, yet automating GUI interactions remains challenging due to the\ncomplexity of visual elements, dynamic environments, and the need for\nmulti-step reasoning. Existing methods based on vision-language models (VLMs)\noften suffer from limited resolution, domain mismatch, and insufficient\nsequential decisionmaking capability. To address these issues, we propose Mano,\na robust GUI agent built upon a multi-modal foundation model pre-trained on\nextensive web and computer system data. Our approach integrates a novel\nsimulated environment for high-fidelity data generation, a three-stage training\npipeline (supervised fine-tuning, offline reinforcement learning, and online\nreinforcement learning), and a verification module for error recovery. Mano\ndemonstrates state-of-the-art performance on multiple GUI benchmarks, including\nMind2Web and OSWorld, achieving significant improvements in success rate and\noperational accuracy. Our work provides new insights into the effective\nintegration of reinforcement learning with VLMs for practical GUI agent\ndeployment, highlighting the importance of domain-specific data, iterative\ntraining, and holistic reward design.",
    "published": "2025-09-22T03:13:58Z",
    "updated": "2025-10-28T14:31:14Z",
    "link": "http://arxiv.org/pdf/2509.17336v2.pdf",
    "category": [
      "cs.MM",
      "cs.CL",
      "cs.CV"
    ],
    "authors": [
      "Tianyu Fu",
      "Anyang Su",
      "Chenxu Zhao",
      "Hanning Wang",
      "Minghui Wu",
      "Zhe Yu",
      "Fei Hu",
      "Mingjia Shi",
      "Wei Dong",
      "Jiayao Wang",
      "Yuyang Chen",
      "Ruiyang Yu",
      "Siran Peng",
      "Menglin Li",
      "Nan Huang",
      "Haitian Wei",
      "Jiawei Yu",
      "Yi Xin",
      "Xilin Zhao",
      "Kai Gu",
      "Ping Jiang",
      "Sifan Zhou",
      "Shuo Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.22699v2",
    "title": "Are you sure? Measuring models bias in content moderation through\n  uncertainty",
    "summary": "Automatic content moderation is crucial to ensuring safety in social media.\nLanguage Model-based classifiers are being increasingly adopted for this task,\nbut it has been shown that they perpetuate racial and social biases. Even if\nseveral resources and benchmark corpora have been developed to challenge this\nissue, measuring the fairness of models in content moderation remains an open\nissue. In this work, we present an unsupervised approach that benchmarks models\non the basis of their uncertainty in classifying messages annotated by people\nbelonging to vulnerable groups. We use uncertainty, computed by means of the\nconformal prediction technique, as a proxy to analyze the bias of 11 models\nagainst women and non-white annotators and observe to what extent it diverges\nfrom metrics based on performance, such as the $F_1$ score. The results show\nthat some pre-trained models predict with high accuracy the labels coming from\nminority groups, even if the confidence in their prediction is low. Therefore,\nby measuring the confidence of models, we are able to see which groups of\nannotators are better represented in pre-trained models and lead the debiasing\nprocess of these models before their effective use.",
    "published": "2025-09-21T08:54:06Z",
    "updated": "2025-10-28T14:11:48Z",
    "link": "http://arxiv.org/pdf/2509.22699v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Alessandra Urbinati",
      "Mirko Lai",
      "Simona Frenda",
      "Marco Antonio Stranisci"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24446v1",
    "title": "SPARTA: Evaluating Reasoning Segmentation Robustness through Black-Box\n  Adversarial Paraphrasing in Text Autoencoder Latent Space",
    "summary": "Multimodal large language models (MLLMs) have shown impressive capabilities\nin vision-language tasks such as reasoning segmentation, where models generate\nsegmentation masks based on textual queries. While prior work has primarily\nfocused on perturbing image inputs, semantically equivalent textual\nparaphrases-crucial in real-world applications where users express the same\nintent in varied ways-remain underexplored. To address this gap, we introduce a\nnovel adversarial paraphrasing task: generating grammatically correct\nparaphrases that preserve the original query meaning while degrading\nsegmentation performance. To evaluate the quality of adversarial paraphrases,\nwe develop a comprehensive automatic evaluation protocol validated with human\nstudies. Furthermore, we introduce SPARTA-a black-box, sentence-level\noptimization method that operates in the low-dimensional semantic latent space\nof a text autoencoder, guided by reinforcement learning. SPARTA achieves\nsignificantly higher success rates, outperforming prior methods by up to 2x on\nboth the ReasonSeg and LLMSeg-40k datasets. We use SPARTA and competitive\nbaselines to assess the robustness of advanced reasoning segmentation models.\nWe reveal that they remain vulnerable to adversarial paraphrasing-even under\nstrict semantic and grammatical constraints. All code and data will be released\npublicly upon acceptance.",
    "published": "2025-10-28T14:09:05Z",
    "updated": "2025-10-28T14:09:05Z",
    "link": "http://arxiv.org/pdf/2510.24446v1.pdf",
    "category": [
      "cs.CL",
      "cs.CV"
    ],
    "authors": [
      "Viktoriia Zinkovich",
      "Anton Antonov",
      "Andrei Spiridonov",
      "Denis Shepelev",
      "Andrey Moskalenko",
      "Daria Pugacheva",
      "Elena Tutubalina",
      "Andrey Kuznetsov",
      "Vlad Shakhuro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24434v1",
    "title": "LuxIT: A Luxembourgish Instruction Tuning Dataset from Monolingual Seed\n  Data",
    "summary": "The effectiveness of instruction-tuned Large Language Models (LLMs) is often\nlimited in low-resource linguistic settings due to a lack of high-quality\ntraining data. We introduce LuxIT, a novel, monolingual instruction tuning\ndataset for Luxembourgish developed to mitigate this challenge. We synthesize\nthe dataset from a corpus of native Luxembourgish texts, utilizing\nDeepSeek-R1-0528, chosen for its shown proficiency in Luxembourgish. Following\ngeneration, we apply a quality assurance process, employing an LLM-as-a-judge\napproach. To investigate the practical utility of the dataset, we fine-tune\nseveral smaller-scale LLMs on LuxIT. Subsequent benchmarking against their base\nmodels on Luxembourgish language proficiency examinations, however, yields\nmixed results, with performance varying significantly across different models.\nLuxIT represents a critical contribution to Luxembourgish natural language\nprocessing and offers a replicable monolingual methodology, though our findings\nhighlight the need for further research to optimize its application.",
    "published": "2025-10-28T14:02:55Z",
    "updated": "2025-10-28T14:02:55Z",
    "link": "http://arxiv.org/pdf/2510.24434v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Julian Valline",
      "Cedric Lothritz",
      "Jordi Cabot"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.17281v2",
    "title": "From Language to Action: A Review of Large Language Models as Autonomous\n  Agents and Tool Users",
    "summary": "The pursuit of human-level artificial intelligence (AI) has significantly\nadvanced the development of autonomous agents and Large Language Models (LLMs).\nLLMs are now widely utilized as decision-making agents for their ability to\ninterpret instructions, manage sequential tasks, and adapt through feedback.\nThis review examines recent developments in employing LLMs as autonomous agents\nand tool users and comprises seven research questions. We only used the papers\npublished between 2023 and 2025 in conferences of the A* and A rank and Q1\njournals. A structured analysis of the LLM agents' architectural design\nprinciples, dividing their applications into single-agent and multi-agent\nsystems, and strategies for integrating external tools is presented. In\naddition, the cognitive mechanisms of LLM, including reasoning, planning, and\nmemory, and the impact of prompting methods and fine-tuning procedures on agent\nperformance are also investigated. Furthermore, we evaluated current benchmarks\nand assessment protocols and have provided an analysis of 68 publicly available\ndatasets to assess the performance of LLM-based agents in various tasks. In\nconducting this review, we have identified critical findings on verifiable\nreasoning of LLMs, the capacity for self-improvement, and the personalization\nof LLM-based agents. Finally, we have discussed ten future research directions\nto overcome these gaps.",
    "published": "2025-08-24T10:02:51Z",
    "updated": "2025-10-28T13:52:29Z",
    "link": "http://arxiv.org/pdf/2508.17281v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Sadia Sultana Chowa",
      "Riasad Alvi",
      "Subhey Sadi Rahman",
      "Md Abdur Rahman",
      "Mohaimenul Azam Khan Raiaan",
      "Md Rafiqul Islam",
      "Mukhtar Hussain",
      "Sami Azam"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24427v1",
    "title": "SynthWorlds: Controlled Parallel Worlds for Disentangling Reasoning and\n  Knowledge in Language Models",
    "summary": "Evaluating the reasoning ability of language models (LMs) is complicated by\ntheir extensive parametric world knowledge, where benchmark performance often\nreflects factual recall rather than genuine reasoning. Existing datasets and\napproaches (e.g., temporal filtering, paraphrasing, adversarial substitution)\ncannot cleanly separate the two. We present SynthWorlds, a framework that\ndisentangles task reasoning complexity from factual knowledge. In SynthWorlds,\nwe construct parallel corpora representing two worlds with identical\ninterconnected structure: a real-mapped world, where models may exploit\nparametric knowledge, and a synthetic-mapped world, where such knowledge is\nmeaningless. On top of these corpora, we design two mirrored tasks as case\nstudies: multi-hop question answering and page navigation, which maintain equal\nreasoning difficulty across worlds. Experiments in parametric-only (e.g.,\nclosed-book QA) and knowledge-augmented (e.g., retrieval-augmented) LM settings\nreveal a persistent knowledge advantage gap, defined as the performance boost\nmodels gain from memorized parametric world knowledge. Knowledge acquisition\nand integration mechanisms reduce but do not eliminate this gap, highlighting\nopportunities for system improvements. Fully automatic and scalable,\nSynthWorlds provides a controlled environment for evaluating LMs in ways that\nwere previously challenging, enabling precise and testable comparisons of\nreasoning and memorization.",
    "published": "2025-10-28T13:47:23Z",
    "updated": "2025-10-28T13:47:23Z",
    "link": "http://arxiv.org/pdf/2510.24427v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Ken Gu",
      "Advait Bhat",
      "Mike A Merrill",
      "Robert West",
      "Xin Liu",
      "Daniel McDuff",
      "Tim Althoff"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24425v1",
    "title": "Comprehensive and Efficient Distillation for Lightweight Sentiment\n  Analysis Models",
    "summary": "Recent efforts leverage knowledge distillation techniques to develop\nlightweight and practical sentiment analysis models. These methods are grounded\nin human-written instructions and large-scale user texts. Despite the promising\nresults, two key challenges remain: (1) manually written instructions are\nlimited in diversity and quantity, making them insufficient to ensure\ncomprehensive coverage of distilled knowledge; (2) large-scale user texts incur\nhigh computational cost, hindering the practicality of these methods. To this\nend, we introduce COMPEFFDIST, a comprehensive and efficient distillation\nframework for sentiment analysis. Our framework consists of two key modules:\nattribute-based automatic instruction construction and difficulty-based data\nfiltering, which correspondingly tackle the aforementioned challenges. Applying\nour method across multiple model series (Llama-3, Qwen-3, and Gemma-3), we\nenable 3B student models to match the performance of 20x larger teacher models\non most tasks. In addition, our approach greatly outperforms baseline methods\nin data efficiency, attaining the same performance level with only 10% of the\ndata.",
    "published": "2025-10-28T13:46:48Z",
    "updated": "2025-10-28T13:46:48Z",
    "link": "http://arxiv.org/pdf/2510.24425v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Guangyu Xie",
      "Yice Zhang",
      "Jianzhu Bao",
      "Qianlong Wang",
      "Yang Sun",
      "Bingbing Wang",
      "Ruifeng Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.11842v3",
    "title": "Video-SafetyBench: A Benchmark for Safety Evaluation of Video LVLMs",
    "summary": "The increasing deployment of Large Vision-Language Models (LVLMs) raises\nsafety concerns under potential malicious inputs. However, existing multimodal\nsafety evaluations primarily focus on model vulnerabilities exposed by static\nimage inputs, ignoring the temporal dynamics of video that may induce distinct\nsafety risks. To bridge this gap, we introduce Video-SafetyBench, the first\ncomprehensive benchmark designed to evaluate the safety of LVLMs under\nvideo-text attacks. It comprises 2,264 video-text pairs spanning 48\nfine-grained unsafe categories, each pairing a synthesized video with either a\nharmful query, which contains explicit malice, or a benign query, which appears\nharmless but triggers harmful behavior when interpreted alongside the video. To\ngenerate semantically accurate videos for safety evaluation, we design a\ncontrollable pipeline that decomposes video semantics into subject images (what\nis shown) and motion text (how it moves), which jointly guide the synthesis of\nquery-relevant videos. To effectively evaluate uncertain or borderline harmful\noutputs, we propose RJScore, a novel LLM-based metric that incorporates the\nconfidence of judge models and human-aligned decision threshold calibration.\nExtensive experiments show that benign-query video composition achieves average\nattack success rates of 67.2%, revealing consistent vulnerabilities to\nvideo-induced attacks. We believe Video-SafetyBench will catalyze future\nresearch into video-based safety evaluation and defense strategies.",
    "published": "2025-05-17T05:06:38Z",
    "updated": "2025-10-28T12:44:07Z",
    "link": "http://arxiv.org/pdf/2505.11842v3.pdf",
    "category": [
      "cs.CV",
      "cs.CL"
    ],
    "authors": [
      "Xuannan Liu",
      "Zekun Li",
      "Zheqi He",
      "Peipei Li",
      "Shuhan Xia",
      "Xing Cui",
      "Huaibo Huang",
      "Xi Yang",
      "Ran He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24365v1",
    "title": "Text Simplification with Sentence Embeddings",
    "summary": "Sentence embeddings can be decoded to give approximations of the original\ntexts used to create them. We explore this effect in the context of text\nsimplification, demonstrating that reconstructed text embeddings preserve\ncomplexity levels. We experiment with a small feed forward neural network to\neffectively learn a transformation between sentence embeddings representing\nhigh-complexity and low-complexity texts. We provide comparison to a Seq2Seq\nand LLM-based approach, showing encouraging results in our much smaller\nlearning setting. Finally, we demonstrate the applicability of our\ntransformation to an unseen simplification dataset (MedEASI), as well as\ndatasets from languages outside the training data (ES,DE). We conclude that\nlearning transformations in sentence embedding space is a promising direction\nfor future research and has potential to unlock the ability to develop small,\nbut powerful models for text simplification and other natural language\ngeneration tasks.",
    "published": "2025-10-28T12:41:10Z",
    "updated": "2025-10-28T12:41:10Z",
    "link": "http://arxiv.org/pdf/2510.24365v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Matthew Shardlow"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2405.07883v2",
    "title": "Zero-Shot Tokenizer Transfer",
    "summary": "Language models (LMs) are bound to their tokenizer, which maps raw text to a\nsequence of vocabulary items (tokens). This restricts their flexibility: for\nexample, LMs trained primarily on English may still perform well in other\nnatural and programming languages, but have vastly decreased efficiency due to\ntheir English-centric tokenizer. To mitigate this, we should be able to swap\nthe original LM tokenizer with an arbitrary one, on the fly, without degrading\nperformance. Hence, in this work we define a new problem: Zero-Shot Tokenizer\nTransfer (ZeTT). The challenge at the core of ZeTT is finding embeddings for\nthe tokens in the vocabulary of the new tokenizer. Since prior heuristics for\ninitializing embeddings often perform at chance level in a ZeTT setting, we\npropose a new solution: we train a hypernetwork taking a tokenizer as input and\npredicting the corresponding embeddings. We empirically demonstrate that the\nhypernetwork generalizes to new tokenizers both with encoder (e.g., XLM-R) and\ndecoder LLMs (e.g., Mistral-7B). Our method comes close to the original models'\nperformance in cross-lingual and coding tasks while markedly reducing the\nlength of the tokenized sequence. We also find that the remaining gap can be\nquickly closed by continued training on less than 1B tokens. Finally, we show\nthat a ZeTT hypernetwork trained for a base (L)LM can also be applied to\nfine-tuned variants without extra training. Overall, our results make\nsubstantial strides toward detaching LMs from their tokenizer.",
    "published": "2024-05-13T16:17:10Z",
    "updated": "2025-10-28T12:30:22Z",
    "link": "http://arxiv.org/pdf/2405.07883v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Benjamin Minixhofer",
      "Edoardo Maria Ponti",
      "Ivan VuliÄ"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24358v1",
    "title": "Automatically Benchmarking LLM Code Agents through Agent-Driven\n  Annotation and Evaluation",
    "summary": "Recent advances in code agents have enabled automated software development at\nthe project level, supported by large language models (LLMs) and widely adopted\ntools. However, existing benchmarks for code agent evaluation face two major\nlimitations: high annotation cost and expertise requirements, and rigid\nevaluation metrics that rely primarily on unit tests. To address these\nchallenges, we propose an agent-driven benchmark construction pipeline that\nleverages human supervision to efficiently generate diverse and challenging\nproject-level tasks. Based on this approach, we introduce PRDBench, a novel\nbenchmark comprising 50 real-world Python projects across 20 domains, each with\nstructured Product Requirement Document (PRD) requirements, comprehensive\nevaluation criteria, and reference implementations. PRDBench features rich data\nsources, high task complexity, and flexible metrics. We further employ an\nAgent-as-a-Judge paradigm to score agent outputs, enabling the evaluation of\nvarious test types beyond unit tests. Extensive experiments on PRDBench\ndemonstrate its effectiveness in assessing the capabilities of both code agents\nand evaluation agents, providing a scalable and robust framework for annotation\nand evaluation.",
    "published": "2025-10-28T12:26:45Z",
    "updated": "2025-10-28T12:26:45Z",
    "link": "http://arxiv.org/pdf/2510.24358v1.pdf",
    "category": [
      "cs.SE",
      "cs.CL"
    ],
    "authors": [
      "Lingyue Fu",
      "Bolun Zhang",
      "Hao Guan",
      "Yaoming Zhu",
      "Lin Qiu",
      "Weiwen Liu",
      "Xuezhi Cao",
      "Xunliang Cai",
      "Weinan Zhang",
      "Yong Yu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.15189v2",
    "title": "Face the Facts! Evaluating RAG-based Fact-checking Pipelines in\n  Realistic Settings",
    "summary": "Natural Language Processing and Generation systems have recently shown the\npotential to complement and streamline the costly and time-consuming job of\nprofessional fact-checkers. In this work, we lift several constraints of\ncurrent state-of-the-art pipelines for automated fact-checking based on the\nRetrieval-Augmented Generation (RAG) paradigm. Our goal is to benchmark, under\nmore realistic scenarios, RAG-based methods for the generation of verdicts -\ni.e., short texts discussing the veracity of a claim - evaluating them on\nstylistically complex claims and heterogeneous, yet reliable, knowledge bases.\nOur findings show a complex landscape, where, for example, LLM-based retrievers\noutperform other retrieval techniques, though they still struggle with\nheterogeneous knowledge bases; larger models excel in verdict faithfulness,\nwhile smaller models provide better context adherence, with human evaluations\nfavouring zero-shot and one-shot approaches for informativeness, and fine-tuned\nmodels for emotional alignment.",
    "published": "2024-12-19T18:57:11Z",
    "updated": "2025-10-28T12:02:14Z",
    "link": "http://arxiv.org/pdf/2412.15189v2.pdf",
    "category": [
      "cs.CL",
      "cs.CY"
    ],
    "authors": [
      "Daniel Russo",
      "Stefano Menini",
      "Jacopo Staiano",
      "Marco Guerini"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24302v1",
    "title": "Lookahead Tree-Based Rollouts for Enhanced Trajectory-Level Exploration\n  in Reinforcement Learning with Verifiable Rewards",
    "summary": "Reinforcement Learning with Verifiable Rewards (RLVR), particularly with\nalgorithms like Group Relative Policy Optimization (GRPO), has proven highly\neffective in enhancing the reasoning capabilities of large language models.\nHowever, a critical bottleneck in current pipelines lies in the limited\ndiversity of sampled trajectories during group rollouts. Homogeneous\ntrajectories and their associated rewards would diminish the return signals for\npolicy updates, thereby hindering effective policy learning. This lack of\ndiversity stems primarily from token-level stochastic sampling, where local\nvariations are likely to collapse into near-identical reasoning paths. To\naddress this limitation, we propose Lookahead Tree-Based Rollouts (LATR), a\nnovel rollout strategy designed to explicitly promotes trajectory-level\ndiversity by enforcing branching into different candidate tokens likely to\nyield distinct continuations. Specifically, LATR iteratively operates in three\nstages: (1) branching at high-uncertainty generation steps, (2) performing\nlookahead simulation for each new branch, and (3) pruning branches that\nexhibits prolonged similarity during simulation. Compared with stochastic\nSampling, LATR accelerates policy learning by 131% on average and improves\nfinal pass@1 performance by 4.2% on both GRPO and Dynamic sAmpling Policy\nOptimization (DAPO) algorithms across different reasoning tasks. Our code and\ndata are publicly available at https://github.com/starreeze/latr.",
    "published": "2025-10-28T11:12:02Z",
    "updated": "2025-10-28T11:12:02Z",
    "link": "http://arxiv.org/pdf/2510.24302v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Shangyu Xing",
      "Siyuan Wang",
      "Chenyuan Yang",
      "Xinyu Dai",
      "Xiang Ren"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24295v1",
    "title": "MERGE: Minimal Expression-Replacement GEneralization Test for Natural\n  Language Inference",
    "summary": "In recent years, many generalization benchmarks have shown language models'\nlack of robustness in natural language inference (NLI). However, manually\ncreating new benchmarks is costly, while automatically generating high-quality\nones, even by modifying existing benchmarks, is extremely difficult. In this\npaper, we propose a methodology for automatically generating high-quality\nvariants of original NLI problems by replacing open-class words, while\ncrucially preserving their underlying reasoning. We dub our generalization test\nas MERGE (Minimal Expression-Replacements GEneralization), which evaluates the\ncorrectness of models' predictions across reasoning-preserving variants of the\noriginal problem. Our results show that NLI models' perform 4-20% worse on\nvariants, suggesting low generalizability even on such minimally altered\nproblems. We also analyse how word class of the replacements, word probability,\nand plausibility influence NLI models' performance.",
    "published": "2025-10-28T10:58:59Z",
    "updated": "2025-10-28T10:58:59Z",
    "link": "http://arxiv.org/pdf/2510.24295v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "MÄdÄlina ZgreabÄn",
      "Tejaswini Deoskar",
      "Lasha Abzianidze"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24259v1",
    "title": "Can LLMs Translate Human Instructions into a Reinforcement Learning\n  Agent's Internal Emergent Symbolic Representation?",
    "summary": "Emergent symbolic representations are critical for enabling developmental\nlearning agents to plan and generalize across tasks. In this work, we\ninvestigate whether large language models (LLMs) can translate human natural\nlanguage instructions into the internal symbolic representations that emerge\nduring hierarchical reinforcement learning. We apply a structured evaluation\nframework to measure the translation performance of commonly seen LLMs -- GPT,\nClaude, Deepseek and Grok -- across different internal symbolic partitions\ngenerated by a hierarchical reinforcement learning algorithm in the Ant Maze\nand Ant Fall environments. Our findings reveal that although LLMs demonstrate\nsome ability to translate natural language into a symbolic representation of\nthe environment dynamics, their performance is highly sensitive to partition\ngranularity and task complexity. The results expose limitations in current LLMs\ncapacity for representation alignment, highlighting the need for further\nresearch on robust alignment between language and internal agent\nrepresentations.",
    "published": "2025-10-28T10:13:43Z",
    "updated": "2025-10-28T10:13:43Z",
    "link": "http://arxiv.org/pdf/2510.24259v1.pdf",
    "category": [
      "cs.CL",
      "cs.RO"
    ],
    "authors": [
      "Ziqi Ma",
      "Sao Mai Nguyen",
      "Philippe Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24256v1",
    "title": "From Memorization to Reasoning in the Spectrum of Loss Curvature",
    "summary": "We characterize how memorization is represented in transformer models and\nshow that it can be disentangled in the weights of both language models (LMs)\nand vision transformers (ViTs) using a decomposition based on the loss\nlandscape curvature. This insight is based on prior theoretical and empirical\nwork showing that the curvature for memorized training points is much sharper\nthan non memorized, meaning ordering weight components from high to low\ncurvature can reveal a distinction without explicit labels. This motivates a\nweight editing procedure that suppresses far more recitation of untargeted\nmemorized data more effectively than a recent unlearning method\n(BalancedSubnet), while maintaining lower perplexity. Since the basis of\ncurvature has a natural interpretation for shared structure in model weights,\nwe analyze the editing procedure extensively on its effect on downstream tasks\nin LMs, and find that fact retrieval and arithmetic are specifically and\nconsistently negatively affected, even though open book fact retrieval and\ngeneral logical reasoning is conserved. We posit these tasks rely heavily on\nspecialized directions in weight space rather than general purpose mechanisms,\nregardless of whether those individual datapoints are memorized. We support\nthis by showing a correspondence between task data's activation strength with\nlow curvature components that we edit out, and the drop in task performance\nafter the edit. Our work enhances the understanding of memorization in neural\nnetworks with practical applications towards removing it, and provides evidence\nfor idiosyncratic, narrowly-used structures involved in solving tasks like math\nand fact retrieval.",
    "published": "2025-10-28T10:09:35Z",
    "updated": "2025-10-28T10:09:35Z",
    "link": "http://arxiv.org/pdf/2510.24256v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Jack Merullo",
      "Srihita Vatsavaya",
      "Lucius Bushnaq",
      "Owen Lewis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24250v1",
    "title": "Evaluating LLMs on Generating Age-Appropriate Child-Like Conversations",
    "summary": "Large Language Models (LLMs), predominantly trained on adult conversational\ndata, face significant challenges when generating authentic, child-like\ndialogue for specialized applications. We present a comparative study\nevaluating five different LLMs (GPT-4, RUTER-LLAMA-2-13b, GPTSW, NorMistral-7b,\nand NorBloom-7b) to generate age-appropriate Norwegian conversations for\nchildren aged 5 and 9 years. Through a blind evaluation by eleven education\nprofessionals using both real child interview data and LLM-generated text\nsamples, we assessed authenticity and developmental appropriateness. Our\nresults show that evaluators achieved strong inter-rater reliability (ICC=0.75)\nand demonstrated higher accuracy in age prediction for younger children\n(5-year-olds) compared to older children (9-year-olds). While GPT-4 and\nNorBloom-7b performed relatively well, most models generated language perceived\nas more linguistically advanced than the target age groups. These findings\nhighlight critical data-related challenges in developing LLM systems for\nspecialized applications involving children, particularly in low-resource\nlanguages where comprehensive age-appropriate lexical resources are scarce.",
    "published": "2025-10-28T10:00:52Z",
    "updated": "2025-10-28T10:00:52Z",
    "link": "http://arxiv.org/pdf/2510.24250v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Syed Zohaib Hassan",
      "PÃ¥l Halvorsen",
      "Miriam S. Johnson",
      "Pierre Lison"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24247v1",
    "title": "Abjad AI at NADI 2025: CATT-Whisper: Multimodal Diacritic Restoration\n  Using Text and Speech Representations",
    "summary": "In this work, we tackle the Diacritic Restoration (DR) task for Arabic\ndialectal sentences using a multimodal approach that combines both textual and\nspeech information. We propose a model that represents the text modality using\nan encoder extracted from our own pre-trained model named CATT. The speech\ncomponent is handled by the encoder module of the OpenAI Whisper base model.\nOur solution is designed following two integration strategies. The former\nconsists of fusing the speech tokens with the input at an early stage, where\nthe 1500 frames of the audio segment are averaged over 10 consecutive frames,\nresulting in 150 speech tokens. To ensure embedding compatibility, these\naveraged tokens are processed through a linear projection layer prior to\nmerging them with the text tokens. Contextual encoding is guaranteed by the\nCATT encoder module. The latter strategy relies on cross-attention, where text\nand speech embeddings are fused. The cross-attention output is then fed to the\nCATT classification head for token-level diacritic prediction. To further\nimprove model robustness, we randomly deactivate the speech input during\ntraining, allowing the model to perform well with or without speech. Our\nexperiments show that the proposed approach achieves a word error rate (WER) of\n0.25 and a character error rate (CER) of 0.9 on the development set. On the\ntest set, our model achieved WER and CER scores of 0.55 and 0.13, respectively.",
    "published": "2025-10-28T09:58:18Z",
    "updated": "2025-10-28T09:58:18Z",
    "link": "http://arxiv.org/pdf/2510.24247v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Ahmad Ghannam",
      "Naif Alharthi",
      "Faris Alasmary",
      "Kholood Al Tabash",
      "Shouq Sadah",
      "Lahouari Ghouti"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24236v1",
    "title": "Towards Transparent Reasoning: What Drives Faithfulness in Large\n  Language Models?",
    "summary": "Large Language Models (LLMs) often produce explanations that do not\nfaithfully reflect the factors driving their predictions. In healthcare\nsettings, such unfaithfulness is especially problematic: explanations that omit\nsalient clinical cues or mask spurious shortcuts can undermine clinician trust\nand lead to unsafe decision support. We study how inference and training-time\nchoices shape explanation faithfulness, focusing on factors practitioners can\ncontrol at deployment. We evaluate three LLMs (GPT-4.1-mini, LLaMA 70B, LLaMA\n8B) on two datasets-BBQ (social bias) and MedQA (medical licensing questions),\nand manipulate the number and type of few-shot examples, prompting strategies,\nand training procedure. Our results show: (i) both the quantity and quality of\nfew-shot examples significantly impact model faithfulness; (ii) faithfulness is\nsensitive to prompting design; (iii) the instruction-tuning phase improves\nmeasured faithfulness on MedQA. These findings offer insights into strategies\nfor enhancing the interpretability and trustworthiness of LLMs in sensitive\ndomains.",
    "published": "2025-10-28T09:43:49Z",
    "updated": "2025-10-28T09:43:49Z",
    "link": "http://arxiv.org/pdf/2510.24236v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Teague McMillan",
      "Gabriele Dominici",
      "Martin Gjoreski",
      "Marc Langheinrich"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.06560v4",
    "title": "NeedleInATable: Exploring Long-Context Capability of Large Language\n  Models towards Long-Structured Tables",
    "summary": "Processing structured tabular data, particularly large and lengthy tables,\nconstitutes a fundamental yet challenging task for large language models\n(LLMs). However, existing long-context benchmarks like Needle-in-a-Haystack\nprimarily focus on unstructured text, neglecting the challenge of diverse\nstructured tables. Meanwhile, previous tabular benchmarks mainly consider\ndownstream tasks that require high-level reasoning abilities, and overlook\nmodels' underlying fine-grained perception of individual table cells, which is\ncrucial for practical and robust LLM-based table applications. To address this\ngap, we introduce \\textsc{NeedleInATable} (NIAT), a new long-context tabular\nbenchmark that treats each table cell as a ``needle'' and requires models to\nextract the target cell based on cell locations or lookup questions. Our\ncomprehensive evaluation of various LLMs and multimodal LLMs reveals a\nsubstantial performance gap between popular downstream tabular tasks and the\nsimpler NIAT task, suggesting that they may rely on dataset-specific\ncorrelations or shortcuts to obtain better benchmark results but lack truly\nrobust long-context understanding towards structured tables. Furthermore, we\ndemonstrate that using synthesized NIAT training data can effectively improve\nperformance on both NIAT task and downstream tabular tasks, which validates the\nimportance of NIAT capability for LLMs' genuine table understanding ability.",
    "published": "2025-04-09T03:46:56Z",
    "updated": "2025-10-28T09:42:41Z",
    "link": "http://arxiv.org/pdf/2504.06560v4.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Lanrui Wang",
      "Mingyu Zheng",
      "Hongyin Tang",
      "Zheng Lin",
      "Yanan Cao",
      "Jingang Wang",
      "Xunliang Cai",
      "Weiping Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24222v1",
    "title": "HACK: Hallucinations Along Certainty and Knowledge Axes",
    "summary": "Hallucinations in LLMs present a critical barrier to their reliable usage.\nExisting research usually categorizes hallucination by their external\nproperties rather than by the LLMs' underlying internal properties. This\nexternal focus overlooks that hallucinations may require tailored mitigation\nstrategies based on their underlying mechanism. We propose a framework for\ncategorizing hallucinations along two axes: knowledge and certainty. Since\nparametric knowledge and certainty may vary across models, our categorization\nmethod involves a model-specific dataset construction process that\ndifferentiates between those types of hallucinations. Along the knowledge axis,\nwe distinguish between hallucinations caused by a lack of knowledge and those\noccurring despite the model having the knowledge of the correct response. To\nvalidate our framework along the knowledge axis, we apply steering mitigation,\nwhich relies on the existence of parametric knowledge to manipulate model\nactivations. This addresses the lack of existing methods to validate knowledge\ncategorization by showing a significant difference between the two\nhallucination types. We further analyze the distinct knowledge and\nhallucination patterns between models, showing that different hallucinations do\noccur despite shared parametric knowledge. Turning to the certainty axis, we\nidentify a particularly concerning subset of hallucinations where models\nhallucinate with certainty despite having the correct knowledge internally. We\nintroduce a new evaluation metric to measure the effectiveness of mitigation\nmethods on this subset, revealing that while some methods perform well on\naverage, they fail disproportionately on these critical cases. Our findings\nhighlight the importance of considering both knowledge and certainty in\nhallucination analysis and call for targeted mitigation approaches that\nconsider the hallucination underlying factors.",
    "published": "2025-10-28T09:34:31Z",
    "updated": "2025-10-28T09:34:31Z",
    "link": "http://arxiv.org/pdf/2510.24222v1.pdf",
    "category": [
      "cs.CL",
      "I.2.7"
    ],
    "authors": [
      "Adi Simhi",
      "Jonathan Herzig",
      "Itay Itzhak",
      "Dana Arad",
      "Zorik Gekhman",
      "Roi Reichart",
      "Fazl Barez",
      "Gabriel Stanovsky",
      "Idan Szpektor",
      "Yonatan Belinkov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24208v1",
    "title": "Beyond Neural Incompatibility: Easing Cross-Scale Knowledge Transfer in\n  Large Language Models through Latent Semantic Alignment",
    "summary": "Large Language Models (LLMs) encode vast amounts of knowledge in their\nmassive parameters, which is accessible to locate, trace, and analyze. Despite\nadvances in neural interpretability, it is still not clear how to transfer\nknowledge in a fine-grained manner, namely parametric knowledge transfer (PKT).\nA key problem is enabling effective and efficient knowledge transfer across\nLLMs of different scales, which is essential for achieving greater flexibility\nand broader applicability in transferring knowledge between LLMs. Due to neural\nincompatibility, referring to the architectural and parametric differences\nbetween LLMs of varying scales, existing methods that directly reuse layer\nparameters are severely limited. In this paper, we identify the semantic\nalignment in latent space as the fundamental prerequisite for LLM cross-scale\nknowledge transfer. Instead of directly using the layer parameters, our\napproach takes activations as the medium of layer-wise knowledge transfer.\nLeveraging the semantics in latent space, our approach is simple and\noutperforms prior work, better aligning model behaviors across varying scales.\nEvaluations on four benchmarks demonstrate the efficacy of our method. Further\nanalysis reveals the key factors easing cross-scale knowledge transfer and\nprovides insights into the nature of latent semantic alignment.",
    "published": "2025-10-28T09:25:40Z",
    "updated": "2025-10-28T09:25:40Z",
    "link": "http://arxiv.org/pdf/2510.24208v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Jian Gu",
      "Aldeida Aleti",
      "Chunyang Chen",
      "Hongyu Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.09349v3",
    "title": "DrVoice: Parallel Speech-Text Voice Conversation Model via\n  Dual-Resolution Speech Representations",
    "summary": "Recent studies on end-to-end (E2E) speech generation with large language\nmodels (LLMs) have attracted significant community attention, with multiple\nworks extending text-based LLMs to generate discrete speech tokens. Existing\nE2E approaches primarily fall into two categories: (1) Methods that generate\ndiscrete speech tokens independently without incorporating them into the LLM's\nautoregressive process, resulting in text generation being unaware of\nconcurrent speech synthesis. (2) Models that generate interleaved or parallel\nspeech- text tokens through joint autoregressive modeling, enabling mutual\nmodality awareness during generation. This paper presents DrVoice, a parallel\nspeech- text voice conversation model based on joint autoregressive modeling,\nfeaturing dual-resolution speech representations. Notably, while current\nmethods utilize mainly 12.5Hz input audio representation, our proposed\ndual-resolution mechanism reduces the input frequency for the LLM to 5Hz,\nsignificantly reducing computational cost and alleviating the frequency\ndiscrepancy between speech and text tokens and in turn better exploiting LLMs'\ncapabilities. Experimental results demonstrate that DRVOICE-7B establishes new\nstate-of-the-art (SOTA) on OpenAudioBench and Big Bench Audio benchmarks, while\nachieving performance comparable to the SOTA on VoiceBench and UltraEval-Audio\nbenchmarks, making it a leading open-source speech foundation model in ~7B\nmodels.",
    "published": "2025-06-11T02:57:22Z",
    "updated": "2025-10-28T09:04:11Z",
    "link": "http://arxiv.org/pdf/2506.09349v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Chao-Hong Tan",
      "Qian Chen",
      "Wen Wang",
      "Chong Deng",
      "Qinglin Zhang",
      "Luyao Cheng",
      "Hai Yu",
      "Xin Zhang",
      "Xiang Lv",
      "Tianyu Zhao",
      "Chong Zhang",
      "Yukun Ma",
      "Yafeng Chen",
      "Hui Wang",
      "Jiaqing Liu",
      "Xiangang Li",
      "Jieping Ye"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2404.17401v2",
    "title": "Evaluation of Geographical Distortions in Language Models",
    "summary": "Language models now constitute essential tools for improving efficiency for\nmany professional tasks such as writing, coding, or learning. For this reason,\nit is imperative to identify inherent biases. In the field of Natural Language\nProcessing, five sources of bias are well-identified: data, annotation,\nrepresentation, models, and research design. This study focuses on biases\nrelated to geographical knowledge. We explore the connection between geography\nand language models by highlighting their tendency to misrepresent spatial\ninformation, thus leading to distortions in the representation of geographical\ndistances. This study introduces four indicators to assess these distortions,\nby comparing geographical and semantic distances. Experiments are conducted\nfrom these four indicators with ten widely used language models. Results\nunderscore the critical necessity of inspecting and rectifying spatial biases\nin language models to ensure accurate and equitable representations.",
    "published": "2024-04-26T13:22:28Z",
    "updated": "2025-10-28T08:44:48Z",
    "link": "http://arxiv.org/pdf/2404.17401v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "RÃ©my Decoupes",
      "Roberto Interdonato",
      "Mathieu Roche",
      "Maguelonne Teisseire",
      "Sarah Valentin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.22672v2",
    "title": "Look and Tell: A Dataset for Multimodal Grounding Across Egocentric and\n  Exocentric Views",
    "summary": "We introduce Look and Tell, a multimodal dataset for studying referential\ncommunication across egocentric and exocentric perspectives. Using Meta Project\nAria smart glasses and stationary cameras, we recorded synchronized gaze,\nspeech, and video as 25 participants instructed a partner to identify\ningredients in a kitchen. Combined with 3D scene reconstructions, this setup\nprovides a benchmark for evaluating how different spatial representations (2D\nvs. 3D; ego vs. exo) affect multimodal grounding. The dataset contains 3.67\nhours of recordings, including 2,707 richly annotated referential expressions,\nand is designed to advance the development of embodied agents that can\nunderstand and engage in situated dialogue.",
    "published": "2025-10-26T13:27:59Z",
    "updated": "2025-10-28T08:39:14Z",
    "link": "http://arxiv.org/pdf/2510.22672v2.pdf",
    "category": [
      "cs.CV",
      "cs.CL",
      "cs.RO",
      "I.2.10; I.2.9; I.2.7; H.5.2"
    ],
    "authors": [
      "Anna Deichler",
      "Jonas Beskow"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24179v1",
    "title": "Exploring the Influence of Relevant Knowledge for Natural Language\n  Generation Interpretability",
    "summary": "This paper explores the influence of external knowledge integration in\nNatural Language Generation (NLG), focusing on a commonsense generation task.\nWe extend the CommonGen dataset by creating KITGI, a benchmark that pairs input\nconcept sets with retrieved semantic relations from ConceptNet and includes\nmanually annotated outputs. Using the T5-Large model, we compare sentence\ngeneration under two conditions: with full external knowledge and with filtered\nknowledge where highly relevant relations were deliberately removed. Our\ninterpretability benchmark follows a three-stage method: (1) identifying and\nremoving key knowledge, (2) regenerating sentences, and (3) manually assessing\noutputs for commonsense plausibility and concept coverage. Results show that\nsentences generated with full knowledge achieved 91\\% correctness across both\ncriteria, while filtering reduced performance drastically to 6\\%. These\nfindings demonstrate that relevant external knowledge is critical for\nmaintaining both coherence and concept coverage in NLG. This work highlights\nthe importance of designing interpretable, knowledge-enhanced NLG systems and\ncalls for evaluation frameworks that capture the underlying reasoning beyond\nsurface-level metrics.",
    "published": "2025-10-28T08:34:01Z",
    "updated": "2025-10-28T08:34:01Z",
    "link": "http://arxiv.org/pdf/2510.24179v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "IvÃ¡n MartÃ­nez-Murillo",
      "Paloma Moreda",
      "Elena Lloret"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.10114v3",
    "title": "LinearRAG: Linear Graph Retrieval Augmented Generation on Large-scale\n  Corpora",
    "summary": "Retrieval-Augmented Generation (RAG) is widely used to mitigate\nhallucinations of Large Language Models (LLMs) by leveraging external\nknowledge. While effective for simple queries, traditional RAG systems struggle\nwith large-scale, unstructured corpora where information is fragmented. Recent\nadvances incorporate knowledge graphs to capture relational structures,\nenabling more comprehensive retrieval for complex, multi-hop reasoning tasks.\nHowever, existing graph-based RAG (GraphRAG) methods rely on unstable and\ncostly relation extraction for graph construction, often producing noisy graphs\nwith incorrect or inconsistent relations that degrade retrieval quality. In\nthis paper, we revisit the pipeline of existing GraphRAG systems and propose\nLinearRAG (Linear Graph-based Retrieval-Augmented Generation), an efficient\nframework that enables reliable graph construction and precise passage\nretrieval. Specifically, LinearRAG constructs a relation-free hierarchical\ngraph, termed Tri-Graph, using only lightweight entity extraction and semantic\nlinking, avoiding unstable relation modeling. This new paradigm of graph\nconstruction scales linearly with corpus size and incurs no extra token\nconsumption, providing an economical and reliable indexing of the original\npassages. For retrieval, LinearRAG adopts a two-stage strategy: (i) relevant\nentity activation via local semantic bridging, followed by (ii) passage\nretrieval through global importance aggregation. Extensive experiments on four\ndatasets demonstrate that LinearRAG significantly outperforms baseline models.\nOur code and datasets are available at https://github.com/DEEP-PolyU/LinearRAG.",
    "published": "2025-10-11T08:43:45Z",
    "updated": "2025-10-28T07:51:04Z",
    "link": "http://arxiv.org/pdf/2510.10114v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Luyao Zhuang",
      "Shengyuan Chen",
      "Yilin Xiao",
      "Huachi Zhou",
      "Yujing Zhang",
      "Hao Chen",
      "Qinggang Zhang",
      "Xiao Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23169v2",
    "title": "MATCH: Task-Driven Code Evaluation through Contrastive Learning",
    "summary": "AI-based code generation is increasingly prevalent, with GitHub Copilot\nestimated to generate 46% of the code on GitHub. Accurately evaluating how well\ngenerated code aligns with developer intent remains a critical challenge.\nTraditional evaluation methods, such as unit tests, are often unscalable and\ncostly. Syntactic similarity metrics (e.g., BLEU, ROUGE) fail to capture code\nfunctionality, and metrics like CodeBERTScore require reference code, which is\nnot always available. To address the gap in reference-free evaluation, with few\nalternatives such as ICE-Score, this paper introduces MATCH, a novel\nreference-free metric. MATCH uses Contrastive Learning to generate meaningful\nembeddings for code and natural language task descriptions, enabling similarity\nscoring that reflects how well generated code implements the task. We show that\nMATCH achieves stronger correlations with functional correctness and human\npreference than existing metrics across multiple programming languages.",
    "published": "2025-10-27T09:51:49Z",
    "updated": "2025-10-28T07:44:06Z",
    "link": "http://arxiv.org/pdf/2510.23169v2.pdf",
    "category": [
      "cs.CL",
      "cs.SE"
    ],
    "authors": [
      "Marah Ghoummaid",
      "Vladimir Tchuiev",
      "Ofek Glick",
      "Michal Moshkovitz",
      "Dotan Di Castro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.24494v2",
    "title": "GRPO-MA: Multi-Answer Generation in GRPO for Stable and Efficient\n  Chain-of-Thought Training",
    "summary": "Recent progress, such as DeepSeek-R1, has shown that the GRPO algorithm, a\nReinforcement Learning (RL) approach, can effectively train Chain-of-Thought\n(CoT) reasoning in Large Language Models (LLMs) and Vision-Language Models\n(VLMs). In this paper, we analyze three challenges of GRPO: gradient coupling\nbetween thoughts and answers, sparse reward signals caused by limited parallel\nsampling, and unstable advantage estimation. To mitigate these challenges, we\npropose GRPO-MA, a simple yet theoretically grounded method that leverages\nmulti-answer generation from each thought process, enabling more robust and\nefficient optimization. Theoretically, we show that the variance of thought\nadvantage decreases as the number of answers per thought increases.\nEmpirically, our gradient analysis confirms this effect, showing that GRPO-MA\nreduces gradient spikes compared to GRPO. Experiments on math, code, and\ndiverse multimodal tasks demonstrate that GRPO-MA substantially improves\nperformance and training efficiency. Our ablation studies further reveal that\nincreasing the number of answers per thought consistently enhances model\nperformance.",
    "published": "2025-09-29T09:07:45Z",
    "updated": "2025-10-28T07:36:45Z",
    "link": "http://arxiv.org/pdf/2509.24494v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Hongcheng Wang",
      "Yinuo Huang",
      "Sukai Wang",
      "Guanghui Ren",
      "Hao Dong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.22162v2",
    "title": "Surface Reading LLMs: Synthetic Text and its Styles",
    "summary": "Despite a potential plateau in ML advancement, the societal impact of large\nlanguage models lies not in approaching superintelligence but in generating\ntext surfaces indistinguishable from human writing. While Critical AI Studies\nprovides essential material and socio-technical critique, it risks overlooking\nhow LLMs phenomenologically reshape meaning-making. This paper proposes a\nsemiotics of \"surface integrity\" as attending to the immediate plane where LLMs\ninscribe themselves into human communication. I distinguish three knowledge\ninterests in ML research (epistemology, epist\\=em\\=e, and epistemics) and argue\nfor integrating surface-level stylistic analysis alongside depth-oriented\ncritique. Through two case studies examining stylistic markers of synthetic\ntext, I argue how attending to style as a semiotic phenomenon reveals LLMs as\ncultural actors that transform the conditions of meaning emergence and\ncirculation in contemporary discourse, independent of questions about machine\nconsciousness.",
    "published": "2025-10-25T05:17:45Z",
    "updated": "2025-10-28T07:27:11Z",
    "link": "http://arxiv.org/pdf/2510.22162v2.pdf",
    "category": [
      "cs.CY",
      "cs.CL"
    ],
    "authors": [
      "Hannes Bajohr"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.15355v2",
    "title": "SANSKRITI: A Comprehensive Benchmark for Evaluating Language Models'\n  Knowledge of Indian Culture",
    "summary": "Language Models (LMs) are indispensable tools shaping modern workflows, but\ntheir global effectiveness depends on understanding local socio-cultural\ncontexts. To address this, we introduce SANSKRITI, a benchmark designed to\nevaluate language models' comprehension of India's rich cultural diversity.\nComprising 21,853 meticulously curated question-answer pairs spanning 28 states\nand 8 union territories, SANSKRITI is the largest dataset for testing Indian\ncultural knowledge. It covers sixteen key attributes of Indian culture: rituals\nand ceremonies, history, tourism, cuisine, dance and music, costume, language,\nart, festivals, religion, medicine, transport, sports, nightlife, and\npersonalities, providing a comprehensive representation of India's cultural\ntapestry. We evaluate SANSKRITI on leading Large Language Models (LLMs), Indic\nLanguage Models (ILMs), and Small Language Models (SLMs), revealing significant\ndisparities in their ability to handle culturally nuanced queries, with many\nmodels struggling in region-specific contexts. By offering an extensive,\nculturally rich, and diverse dataset, SANSKRITI sets a new standard for\nassessing and improving the cultural understanding of LMs.",
    "published": "2025-06-18T11:19:25Z",
    "updated": "2025-10-28T07:12:22Z",
    "link": "http://arxiv.org/pdf/2506.15355v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Arijit Maji",
      "Raghvendra Kumar",
      "Akash Ghosh",
      " Anushka",
      "Sriparna Saha"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24126v1",
    "title": "Reinforcement Learning for Long-Horizon Multi-Turn Search Agents",
    "summary": "Large Language Model (LLM) agents can leverage multiple turns and tools to\nsolve complex tasks, with prompt-based approaches achieving strong performance.\nThis work demonstrates that Reinforcement Learning (RL) can push capabilities\nsignificantly further by learning from experience. Through experiments on a\nlegal document search benchmark, we show that our RL-trained 14 Billion\nparameter model outperforms frontier class models (85% vs 78% accuracy). In\naddition, we explore turn-restricted regimes, during training and at test-time,\nthat show these agents achieve better results if allowed to operate over longer\nmulti-turn horizons.",
    "published": "2025-10-28T07:00:42Z",
    "updated": "2025-10-28T07:00:42Z",
    "link": "http://arxiv.org/pdf/2510.24126v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Vivek Kalyan",
      "Martin Andrews"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24102v1",
    "title": "Squrve: A Unified and Modular Framework for Complex Real-World\n  Text-to-SQL Tasks",
    "summary": "Text-to-SQL technology has evolved rapidly, with diverse academic methods\nachieving impressive results. However, deploying these techniques in real-world\nsystems remains challenging due to limited integration tools. Despite these\nadvances, we introduce Squrve, a unified, modular, and extensive Text-to-SQL\nframework designed to bring together research advances and real-world\napplications. Squrve first establishes a universal execution paradigm that\nstandardizes invocation interfaces, then proposes a multi-actor collaboration\nmechanism based on seven abstracted effective atomic actor components.\nExperiments on widely adopted benchmarks demonstrate that the collaborative\nworkflows consistently outperform the original individual methods, thereby\nopening up a new effective avenue for tackling complex real-world queries. The\ncodes are available at https://github.com/Satissss/Squrve.",
    "published": "2025-10-28T06:16:38Z",
    "updated": "2025-10-28T06:16:38Z",
    "link": "http://arxiv.org/pdf/2510.24102v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yihan Wang",
      "Peiyu Liu",
      "Runyu Chen",
      "Jiaxing Pu",
      "Wei Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24096v1",
    "title": "RegSpeech12: A Regional Corpus of Bengali Spontaneous Speech Across\n  Dialects",
    "summary": "The Bengali language, spoken extensively across South Asia and among\ndiasporic communities, exhibits considerable dialectal diversity shaped by\ngeography, culture, and history. Phonological and pronunciation-based\nclassifications broadly identify five principal dialect groups: Eastern\nBengali, Manbhumi, Rangpuri, Varendri, and Rarhi. Within Bangladesh, further\ndistinctions emerge through variation in vocabulary, syntax, and morphology, as\nobserved in regions such as Chittagong, Sylhet, Rangpur, Rajshahi, Noakhali,\nand Barishal. Despite this linguistic richness, systematic research on the\ncomputational processing of Bengali dialects remains limited. This study seeks\nto document and analyze the phonetic and morphological properties of these\ndialects while exploring the feasibility of building computational models\nparticularly Automatic Speech Recognition (ASR) systems tailored to regional\nvarieties. Such efforts hold potential for applications in virtual assistants\nand broader language technologies, contributing to both the preservation of\ndialectal diversity and the advancement of inclusive digital tools for\nBengali-speaking communities. The dataset created for this study is released\nfor public use.",
    "published": "2025-10-28T06:08:42Z",
    "updated": "2025-10-28T06:08:42Z",
    "link": "http://arxiv.org/pdf/2510.24096v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Md. Rezuwan Hassan",
      "Azmol Hossain",
      "Kanij Fatema",
      "Rubayet Sabbir Faruque",
      "Tanmoy Shome",
      "Ruwad Naswan",
      "Trina Chakraborty",
      "Md. Foriduzzaman Zihad",
      "Tawsif Tashwar Dipto",
      "Nazia Tasnim",
      "Nazmuddoha Ansary",
      "Md. Mehedi Hasan Shawon",
      "Ahmed Imtiaz Humayun",
      "Md. Golam Rabiul Alam",
      "Farig Sadeque",
      "Asif Sushmit"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24081v1",
    "title": "Global PIQA: Evaluating Physical Commonsense Reasoning Across 100+\n  Languages and Cultures",
    "summary": "To date, there exist almost no culturally-specific evaluation benchmarks for\nlarge language models (LLMs) that cover a large number of languages and\ncultures. In this paper, we present Global PIQA, a participatory commonsense\nreasoning benchmark for over 100 languages, constructed by hand by 335\nresearchers from 65 countries around the world. The 116 language varieties in\nGlobal PIQA cover five continents, 14 language families, and 23 writing\nsystems. In the non-parallel split of Global PIQA, over 50% of examples\nreference local foods, customs, traditions, or other culturally-specific\nelements. We find that state-of-the-art LLMs perform well on Global PIQA in\naggregate, but they exhibit weaker performance in lower-resource languages (up\nto a 37% accuracy gap, despite random chance at 50%). Open models generally\nperform worse than proprietary models. Global PIQA highlights that in many\nlanguages and cultures, everyday knowledge remains an area for improvement,\nalongside more widely-discussed capabilities such as complex reasoning and\nexpert knowledge. Beyond its uses for LLM evaluation, we hope that Global PIQA\nprovides a glimpse into the wide diversity of cultures in which human language\nis embedded.",
    "published": "2025-10-28T05:46:25Z",
    "updated": "2025-10-28T05:46:25Z",
    "link": "http://arxiv.org/pdf/2510.24081v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Tyler A. Chang",
      "Catherine Arnett",
      "Abdelrahman Eldesokey",
      "Abdelrahman Sadallah",
      "Abeer Kashar",
      "Abolade Daud",
      "Abosede Grace Olanihun",
      "Adamu Labaran Mohammed",
      "Adeyemi Praise",
      "Adhikarinayum Meerajita Sharma",
      "Aditi Gupta",
      "Afitab Iyigun",
      "Afonso SimplÃ­cio",
      "Ahmed Essouaied",
      "Aicha Chorana",
      "Akhil Eppa",
      "Akintunde Oladipo",
      "Akshay Ramesh",
      "Aleksei Dorkin",
      "Alfred Malengo Kondoro",
      "Alham Fikri Aji",
      "Ali Eren ÃetintaÅ",
      "Allan Hanbury",
      "Alou Dembele",
      "Alp Niksarli",
      "Ãlvaro Arroyo",
      "Amin Bajand",
      "Amol Khanna",
      "Ana Chkhaidze",
      "Ana Condez",
      "Andiswa Mkhonto",
      "Andrew Hoblitzell",
      "Andrew Tran",
      "Angelos Poulis",
      "Anirban Majumder",
      "Anna Vacalopoulou",
      "Annette Kuuipolani Kanahele Wong",
      "Annika Simonsen",
      "Anton Kovalev",
      "Ashvanth. S",
      "Ayodeji Joseph Lana",
      "Barkin Kinay",
      "Bashar Alhafni",
      "Benedict Cibalinda Busole",
      "Bernard Ghanem",
      "Bharti Nathani",
      "Biljana Stojanovska ÄuriÄ",
      "Bola Agbonile",
      "Bragi Bergsson",
      "Bruce Torres Fischer",
      "Burak Tutar",
      "Burcu AlakuÅ ÃÄ±nar",
      "Cade J. Kanoniakapueo Kane",
      "Can Udomcharoenchaikit",
      "Catherine Arnett",
      "Chadi Helwe",
      "Chaithra Reddy Nerella",
      "Chen Cecilia Liu",
      "Chiamaka Glory Nwokolo",
      "Cristina EspaÃ±a-Bonet",
      "Cynthia Amol",
      "DaeYeop Lee",
      "Dana Arad",
      "Daniil Dzenhaliou",
      "Daria Pugacheva",
      "Dasol Choi",
      "Daud Abolade",
      "David Liu",
      "David Semedo",
      "Deborah Popoola",
      "Deividas Mataciunas",
      "Delphine Nyaboke",
      "Dhyuthy Krishna Kumar",
      "Diogo GlÃ³ria-Silva",
      "Diogo Tavares",
      "Divyanshu Goyal",
      "DongGeon Lee",
      "Ebele Nwamaka Anajemba",
      "Egonu Ngozi Grace",
      "Elena Mickel",
      "Elena Tutubalina",
      "Elias Herranen",
      "Emile Anand",
      "Emmanuel Habumuremyi",
      "Emuobonuvie Maria Ajiboye",
      "Eryawan Presma Yulianrifat",
      "Esther Adenuga",
      "Ewa Rudnicka",
      "Faith Olabisi Itiola",
      "Faran Taimoor Butt",
      "Fathima Thekkekara",
      "Fatima Haouari",
      "Filbert Aurelian Tjiaranata",
      "Firas Laakom",
      "Francesca Grasso",
      "Francesco Orabona",
      "Francesco Periti",
      "Gbenga Kayode Solomon",
      "Gia Nghia Ngo",
      "Gloria Udhehdhe-oze",
      "GonÃ§alo Martins",
      "Gopi Naga Sai Ram Challagolla",
      "Guijin Son",
      "Gulnaz Abdykadyrova",
      "Hafsteinn Einarsson",
      "Hai Hu",
      "Hamidreza Saffari",
      "Hamza Zaidi",
      "Haopeng Zhang",
      "Harethah Abu Shairah",
      "Harry Vuong",
      "Hele-Andra Kuulmets",
      "Houda Bouamor",
      "Hwanjo Yu",
      "Iben Nyholm Debess",
      "Ä°brahim Ethem Deveci",
      "Ikhlasul Akmal Hanif",
      "Ikhyun Cho",
      "InÃªs Calvo",
      "InÃªs Vieira",
      "Isaac Manzi",
      "Ismail Daud",
      "Itay Itzhak",
      " Iuliia",
      " Alekseenko",
      "Ivan Belashkin",
      "Ivan Spada",
      "Ivan Zhelyazkov",
      "Jacob Brinton",
      "Jafar Isbarov",
      "Jaka Äibej",
      "Jan Äuhel",
      "Jan KocoÅ",
      "Jauza Akbar Krito",
      "Jebish Purbey",
      "Jennifer Mickel",
      "Jennifer Za",
      "Jenny Kunz",
      "Jihae Jeong",
      "Jimena Tena DÃ¡valos",
      "Jinu Lee",
      "JoÃ£o MagalhÃ£es",
      "John Yi",
      "Jongin Kim",
      "Joseph Chataignon",
      "Joseph Marvin Imperial",
      "Jubeerathan Thevakumar",
      "Judith Land",
      "Junchen Jiang",
      "Jungwhan Kim",
      "Kairit Sirts",
      "Kamesh R",
      "Kamesh V",
      "Kanda Patrick Tshinu",
      "KÃ¤triin Kukk",
      "Kaustubh Ponkshe",
      "Kavsar Huseynova",
      "Ke He",
      "Kelly Buchanan",
      "Kengatharaiyer Sarveswaran",
      "Kerem Zaman",
      "Khalil Mrini",
      "Kian Kyars",
      "Krister Kruusmaa",
      "Kusum Chouhan",
      "Lainitha Krishnakumar",
      "Laura Castro SÃ¡nchez",
      "Laura Porrino Moscoso",
      "Leshem Choshen",
      "Levent Sencan",
      "Lilja Ãvrelid",
      "Lisa Alazraki",
      "Lovina Ehimen-Ugbede",
      "Luheerathan Thevakumar",
      "Luxshan Thavarasa",
      "Mahnoor Malik",
      "Mamadou K. Keita",
      "Mansi Jangid",
      "Marco De Santis",
      "Marcos GarcÃ­a",
      "Marek Suppa",
      "Mariam D'Ciofalo",
      "Marii Ojastu",
      "Maryam Sikander",
      "Mausami Narayan",
      "Maximos Skandalis",
      "Mehak Mehak",
      "Mehmet Ä°lteriÅ Bozkurt",
      "Melaku Bayu Workie",
      "Menan Velayuthan",
      "Michael Leventhal",
      "MichaÅ MarciÅczuk",
      "Mirna PotoÄnjak",
      "Mohammadamin Shafiei",
      "Mridul Sharma",
      "Mrityunjaya Indoria",
      "Muhammad Ravi Shulthan Habibi",
      "Murat KoliÄ",
      "Nada Galant",
      "Naphat Permpredanun",
      "Narada Maugin",
      "Nicholas Kluge CorrÃªa",
      "Nikola LjubeÅ¡iÄ",
      "Nirmal Thomas",
      "Nisansa de Silva",
      "Nisheeth Joshi",
      "Nitish Ponkshe",
      "Nizar Habash",
      "Nneoma C. Udeze",
      "Noel Thomas",
      "NoÃ©mi Ligeti-Nagy",
      "Nouhoum Coulibaly",
      "Nsengiyumva Faustin",
      "Odunayo Kareemat Buliaminu",
      "Odunayo Ogundepo",
      "Oghojafor Godswill Fejiro",
      "Ogundipe Blessing Funmilola",
      "Okechukwu God'spraise",
      "Olanrewaju Samuel",
      "Olaoye Deborah Oluwaseun",
      "Olasoji Akindejoye",
      "Olga Popova",
      "Olga Snissarenko",
      "Onyinye Anulika Chiemezie",
      "Orkun Kinay",
      "Osman Tursun",
      "Owoeye Tobiloba Moses",
      "Oyelade Oluwafemi Joshua",
      "Oyesanmi Fiyinfoluwa",
      "Pablo Gamallo",
      "Pablo RodrÃ­guez FernÃ¡ndez",
      "Palak Arora",
      "Pedro Valente",
      "Peter Rupnik",
      "Philip Oghenesuowho Ekiugbo",
      "Pramit Sahoo",
      "Prokopis Prokopidis",
      "Pua Niau-Puhipau",
      "Quadri Yahya",
      "Rachele Mignone",
      "Raghav Singhal",
      "Ram Mohan Rao Kadiyala",
      "Raphael Merx",
      "Rapheal Afolayan",
      "Ratnavel Rajalakshmi",
      "Rishav Ghosh",
      "Romina Oji",
      "Ron Kekeha Solis",
      "Rui Guerra",
      "Rushikesh Zawar",
      "Sa'ad Nasir Bashir",
      "Saeed Alzaabi",
      "Sahil Sandeep",
      "Sai Pavan Batchu",
      "SaiSandeep Kantareddy",
      "Salsabila Zahirah Pranida",
      "Sam Buchanan",
      "Samuel Rutunda",
      "Sander Land",
      "Sarah Sulollari",
      "Sardar Ali",
      "Saroj Sapkota",
      "Saulius Tautvaisas",
      "Sayambhu Sen",
      "Sayantani Banerjee",
      "Sebastien Diarra",
      "SenthilNathan. M",
      "Sewoong Lee",
      "Shaan Shah",
      "Shankar Venkitachalam",
      "Sharifa Djurabaeva",
      "Sharon Ibejih",
      "Shivanya Shomir Dutta",
      "Siddhant Gupta",
      "Silvia Paniagua SuÃ¡rez",
      "Sina Ahmadi",
      "Sivasuthan Sukumar",
      "Siyuan Song",
      "Snegha A.",
      "Sokratis Sofianopoulos",
      "Sona Elza Simon",
      "Sonja BenÄina",
      "Sophie Gvasalia",
      "Sphurti Kirit More",
      "Spyros Dragazis",
      "Stephan P. Kaufhold",
      "Suba. S",
      "Sultan AlRashed",
      "Surangika Ranathunga",
      "Taiga Someya",
      "Taja Kuzman PungerÅ¡ek",
      "Tal Haklay",
      "Tasi'u Jibril",
      "Tatsuya Aoyama",
      "Tea Abashidze",
      "Terenz Jomar Dela Cruz",
      "Terra Blevins",
      "Themistoklis Nikas",
      "Theresa Dora Idoko",
      "Thu Mai Do",
      "Tilek Chubakov",
      "Tommaso Gargiani",
      "Uma Rathore",
      "Uni Johannesen",
      "Uwuma Doris Ugwu",
      "Vallerie Alexandra Putra",
      "Vanya Bannihatti Kumar",
      "Varsha Jeyarajalingam",
      "Varvara Arzt",
      "Vasudevan Nedumpozhimana",
      "Viktoria Ondrejova",
      "Viktoryia Horbik",
      "Vishnu Vardhan Reddy Kummitha",
      "Vuk DiniÄ",
      "Walelign Tewabe Sewunetie",
      "Winston Wu",
      "Xiaojing Zhao",
      "Yacouba Diarra",
      "Yaniv Nikankin",
      "Yash Mathur",
      "Yixi Chen",
      "Yiyuan Li",
      "Yolanda Xavier",
      "Yonatan Belinkov",
      "Yusuf Ismail Abayomi",
      "Zaid Alyafeai",
      "Zhengyang Shan",
      "Zhi Rui Tam",
      "Zilu Tang",
      "Zuzana Nadova",
      "Baber Abbasi",
      "Stella Biderman",
      "David Stap",
      "Duygu Ataman",
      "Fabian Schmidt",
      "Hila Gonen",
      "Jiayi Wang",
      "David Ifeoluwa Adelani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24073v1",
    "title": "Challenging Multilingual LLMs: A New Taxonomy and Benchmark for\n  Unraveling Hallucination in Translation",
    "summary": "Large Language Models (LLMs) have advanced machine translation but remain\nvulnerable to hallucinations. Unfortunately, existing MT benchmarks are not\ncapable of exposing failures in multilingual LLMs. To disclose hallucination in\nmultilingual LLMs, we introduce a diagnostic framework with a taxonomy that\nseparates Instruction Detachment from Source Detachment. Guided by this\ntaxonomy, we create HalloMTBench, a multilingual, human-verified benchmark\nacross 11 English-to-X directions. We employed 4 frontier LLMs to generate\ncandidates and scrutinize these candidates with an ensemble of LLM judges, and\nexpert validation. In this way, we curate 5,435 high-quality instances. We have\nevaluated 17 LLMs on HalloMTBench. Results reveal distinct ``hallucination\ntriggers'' -- unique failure patterns reflecting model scale, source length\nsensitivity, linguistic biases, and Reinforcement-Learning (RL) amplified\nlanguage mixing. HalloMTBench offers a forward-looking testbed for diagnosing\nLLM translation failures. HalloMTBench is available in\nhttps://huggingface.co/collections/AIDC-AI/marco-mt.",
    "published": "2025-10-28T05:17:18Z",
    "updated": "2025-10-28T05:17:18Z",
    "link": "http://arxiv.org/pdf/2510.24073v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Xinwei Wu",
      "Heng Liu",
      "Jiang Zhou",
      "Xiaohu Zhao",
      "Linlong Xu",
      "Longyue Wang",
      "Weihua Luo",
      "Kaifu Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24051v1",
    "title": "Pie: A Programmable Serving System for Emerging LLM Applications",
    "summary": "Emerging large language model (LLM) applications involve diverse reasoning\nstrategies and agentic workflows, straining the capabilities of existing\nserving systems built on a monolithic token generation loop. This paper\nintroduces Pie, a programmable LLM serving system designed for flexibility and\nefficiency. Pie decomposes the traditional generation loop into fine-grained\nservice handlers exposed via an API and delegates control of the generation\nprocess to user-provided programs, called inferlets. This enables applications\nto implement new KV cache strategies, bespoke generation logic, and seamlessly\nintegrate computation and I/O-entirely within the application, without\nrequiring modifications to the serving system. Pie executes inferlets using\nWebAssembly, benefiting from its lightweight sandboxing. Our evaluation shows\nPie matches state-of-the-art performance on standard tasks (3-12% latency\noverhead) while significantly improving latency and throughput (1.3x-3.4x\nhigher) on agentic workflows by enabling application-specific optimizations.",
    "published": "2025-10-28T04:17:55Z",
    "updated": "2025-10-28T04:17:55Z",
    "link": "http://arxiv.org/pdf/2510.24051v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "In Gim",
      "Zhiyao Ma",
      "Seung-seob Lee",
      "Lin Zhong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.24958v2",
    "title": "The Dialogue That Heals: A Comprehensive Evaluation of Doctor Agents'\n  Inquiry Capability",
    "summary": "An effective physician should possess a combination of empathy, expertise,\npatience, and clear communication when treating a patient. Recent advances have\nsuccessfully endowed AI doctors with expert diagnostic skills, particularly the\nability to actively seek information through inquiry. However, other essential\nqualities of a good doctor remain overlooked. To bridge this gap, we present\nMAQuE(Medical Agent Questioning Evaluation), the largest-ever benchmark for the\nautomatic and comprehensive evaluation of medical multi-turn questioning. It\nfeatures 3,000 realistically simulated patient agents that exhibit diverse\nlinguistic patterns, cognitive limitations, emotional responses, and tendencies\nfor passive disclosure. We also introduce a multi-faceted evaluation framework,\ncovering task success, inquiry proficiency, dialogue competence, inquiry\nefficiency, and patient experience. Experiments on different LLMs reveal\nsubstantial challenges across the evaluation aspects. Even state-of-the-art\nmodels show significant room for improvement in their inquiry capabilities.\nThese models are highly sensitive to variations in realistic patient behavior,\nwhich considerably impacts diagnostic accuracy. Furthermore, our fine-grained\nmetrics expose trade-offs between different evaluation perspectives,\nhighlighting the challenge of balancing performance and practicality in\nreal-world clinical settings.",
    "published": "2025-09-29T15:52:36Z",
    "updated": "2025-10-28T04:02:58Z",
    "link": "http://arxiv.org/pdf/2509.24958v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Linlu Gong",
      "Ante Wang",
      "Yunghwei Lai",
      "Weizhi Ma",
      "Yang Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.01068v4",
    "title": "FastKV: KV Cache Compression for Fast Long-Context Processing with\n  Token-Selective Propagation",
    "summary": "While large language models (LLMs) excel at handling long-context sequences,\nthey require substantial prefill computation and key-value (KV) cache, which\ncan heavily burden computational efficiency and memory usage in both prefill\nand decoding stages. Recent works that compress KV caches with prefill\nacceleration reduce this cost but inadvertently tie the prefill compute\nreduction to the decoding KV budget. This coupling arises from overlooking the\nlayer-dependent variation of critical context, often leading to accuracy\ndegradation. To address this issue, we introduce FastKV, a KV cache compression\nframework designed to reduce latency in both prefill and decoding by leveraging\nthe stabilization of token importance in later layers. FastKV performs\nfull-context computation until a Token-Selective Propagation (TSP) layer, which\nforwards only the most informative tokens to subsequent layers. From these\npropagated tokens, FastKV independently selects salient KV entries for caching,\nthereby decoupling KV budget from the prefill compute reduction based on the\nTSP decision. This independent control of the TSP rate and KV retention rate\nenables flexible optimization of efficiency and accuracy. Experimental results\nshow that FastKV achieves speedups of up to 1.82$\\times$ in prefill and\n2.87$\\times$ in decoding compared to the full-context baseline, while matching\nthe accuracy of the baselines that only accelerate the decoding stage. Our code\nis available at https://github.com/dongwonjo/FastKV.",
    "published": "2025-02-03T05:25:09Z",
    "updated": "2025-10-28T04:00:18Z",
    "link": "http://arxiv.org/pdf/2502.01068v4.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Dongwon Jo",
      "Jiwon Song",
      "Yulhwa Kim",
      "Jae-Joon Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24035v1",
    "title": "GraphNet: A Large-Scale Computational Graph Dataset for Tensor Compiler\n  Research",
    "summary": "We introduce GraphNet, a dataset of 2.7K real-world deep learning\ncomputational graphs with rich metadata, spanning six major task categories\nacross multiple deep learning frameworks. To evaluate tensor compiler\nperformance on these samples, we propose the benchmark metric Speedup Score\nS(t), which jointly considers runtime speedup and execution correctness under\ntunable tolerance levels, offering a reliable measure of general optimization\ncapability. Furthermore, we extend S(t) to the Error-aware Speedup Score ES(t),\nwhich incorporates error information and helps compiler developers identify key\nperformance bottlenecks. In this report, we benchmark the default tensor\ncompilers, CINN for PaddlePaddle and TorchInductor for PyTorch, on computer\nvision (CV) and natural language processing (NLP) samples to demonstrate the\npracticality of GraphNet. The full construction pipeline with graph extraction\nand compiler evaluation tools is available at\nhttps://github.com/PaddlePaddle/GraphNet .",
    "published": "2025-10-28T03:36:05Z",
    "updated": "2025-10-28T03:36:05Z",
    "link": "http://arxiv.org/pdf/2510.24035v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Xinqi Li",
      "Yiqun Liu",
      "Shan Jiang",
      "Enrong Zheng",
      "Huaijin Zheng",
      "Wenhao Dai",
      "Haodong Deng",
      "Dianhai Yu",
      "Yanjun Ma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.01381v2",
    "title": "AdaRewriter: Unleashing the Power of Prompting-based Conversational\n  Query Reformulation via Test-Time Adaptation",
    "summary": "Prompting-based conversational query reformulation has emerged as a powerful\napproach for conversational search, refining ambiguous user queries into\nstandalone search queries. Best-of-N reformulation over the generated\ncandidates via prompting shows impressive potential scaling capability.\nHowever, both the previous tuning methods (training time) and adaptation\napproaches (test time) can not fully unleash their benefits. In this paper, we\npropose AdaRewriter, a novel framework for query reformulation using an\noutcome-supervised reward model via test-time adaptation. By training a\nlightweight reward model with contrastive ranking loss, AdaRewriter selects the\nmost promising reformulation during inference. Notably, it can operate\neffectively in black-box systems, including commercial LLM APIs. Experiments on\nfive conversational search datasets show that AdaRewriter significantly\noutperforms the existing methods across most settings, demonstrating the\npotential of test-time adaptation for conversational query reformulation.",
    "published": "2025-06-02T07:18:26Z",
    "updated": "2025-10-28T03:11:09Z",
    "link": "http://arxiv.org/pdf/2506.01381v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yilong Lai",
      "Jialong Wu",
      "Zhenglin Wang",
      "Deyu Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.19457v2",
    "title": "MINED: Probing and Updating with Multimodal Time-Sensitive Knowledge for\n  Large Multimodal Models",
    "summary": "Large Multimodal Models (LMMs) encode rich factual knowledge via cross-modal\npre-training, yet their static representations struggle to maintain an accurate\nunderstanding of time-sensitive factual knowledge. Existing benchmarks remain\nconstrained by static designs, inadequately evaluating LMMs' ability to\nunderstand time-sensitive knowledge. To address this gap, we propose MINED, a\ncomprehensive benchmark that evaluates temporal awareness along 6 key\ndimensions and 11 challenging tasks: cognition, awareness, trustworthiness,\nunderstanding, reasoning, and robustness. MINED is constructed from Wikipedia\nby two professional annotators, containing 2,104 time-sensitive knowledge\nsamples spanning six knowledge types. Evaluating 15 widely used LMMs on MINED\nshows that Gemini-2.5-Pro achieves the highest average CEM score of 63.07,\nwhile most open-source LMMs still lack time understanding ability. Meanwhile,\nLMMs perform best on organization knowledge, whereas their performance is\nweakest on sport. To address these challenges, we investigate the feasibility\nof updating time-sensitive knowledge in LMMs through knowledge editing methods\nand observe that LMMs can effectively update knowledge via knowledge editing\nmethods in single editing scenarios.",
    "published": "2025-10-22T10:41:57Z",
    "updated": "2025-10-28T03:06:40Z",
    "link": "http://arxiv.org/pdf/2510.19457v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Kailin Jiang",
      "Ning Jiang",
      "Yuntao Du",
      "Yuchen Ren",
      "Yuchen Li",
      "Yifan Gao",
      "Jinhe Bi",
      "Yunpu Ma",
      "Qingqing Liu",
      "Xianhao Wang",
      "Yifan Jia",
      "Hongbo Jiang",
      "Yaocong Hu",
      "Bin Li",
      "Lei Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24023v1",
    "title": "Success and Cost Elicit Convention Formation for Efficient Communication",
    "summary": "Humans leverage shared conversational context to become increasingly\nsuccessful and efficient at communicating over time. One manifestation of this\nis the formation of ad hoc linguistic conventions, which allow people to\ncoordinate on short, less costly utterances that are understood using shared\nconversational context. We present a method to train large multimodal models to\nform conventions, enabling efficient communication. Our approach uses simulated\nreference games between models, and requires no additional human-produced data.\nIn repeated reference games involving photographs and tangram images, our\nmethod enables models to communicate efficiently with people: reducing the\nmessage length by up to 41% while increasing success by 15% over the course of\nthe interaction. Human listeners respond faster when interacting with our model\nthat forms conventions. We also show that training based on success or cost\nalone is insufficient - both are necessary to elicit convention formation.",
    "published": "2025-10-28T03:06:07Z",
    "updated": "2025-10-28T03:06:07Z",
    "link": "http://arxiv.org/pdf/2510.24023v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Saujas Vaduguru",
      "Yilun Hua",
      "Yoav Artzi",
      "Daniel Fried"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24014v1",
    "title": "TEXT2DB: Integration-Aware Information Extraction with Large Language\n  Model Agents",
    "summary": "The task of information extraction (IE) is to extract structured knowledge\nfrom text. However, it is often not straightforward to utilize IE output due to\nthe mismatch between the IE ontology and the downstream application needs. We\npropose a new formulation of IE TEXT2DB that emphasizes the integration of IE\noutput and the target database (or knowledge base). Given a user instruction, a\ndocument set, and a database, our task requires the model to update the\ndatabase with values from the document set to satisfy the user instruction.\nThis task requires understanding user instructions for what to extract and\nadapting to the given DB/KB schema for how to extract on the fly. To evaluate\nthis new task, we introduce a new benchmark featuring common demands such as\ndata infilling, row population, and column addition. In addition, we propose an\nLLM agent framework OPAL (Observe-PlanAnalyze LLM) which includes an Observer\ncomponent that interacts with the database, the Planner component that\ngenerates a code-based plan with calls to IE models, and the Analyzer component\nthat provides feedback regarding code quality before execution. Experiments\nshow that OPAL can successfully adapt to diverse database schemas by generating\ndifferent code plans and calling the required IE models. We also highlight\ndifficult cases such as dealing with large databases with complex dependencies\nand extraction hallucination, which we believe deserve further investigation.\nSource code: https://github.com/yzjiao/Text2DB",
    "published": "2025-10-28T02:49:40Z",
    "updated": "2025-10-28T02:49:40Z",
    "link": "http://arxiv.org/pdf/2510.24014v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yizhu Jiao",
      "Sha Li",
      "Sizhe Zhou",
      "Heng Ji",
      "Jiawei Han"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.12679v2",
    "title": "Discourse Features Enhance Detection of Document-Level Machine-Generated\n  Content",
    "summary": "The availability of high-quality APIs for Large Language Models (LLMs) has\nfacilitated the widespread creation of Machine-Generated Content (MGC), posing\nchallenges such as academic plagiarism and the spread of misinformation.\nExisting MGC detectors often focus solely on surface-level information,\noverlooking implicit and structural features. This makes them susceptible to\ndeception by surface-level sentence patterns, particularly for longer texts and\nin texts that have been subsequently paraphrased. To overcome these challenges,\nwe introduce novel methodologies and datasets. Besides the publicly available\ndataset Plagbench, we developed the paraphrased Long-Form Question and Answer\n(paraLFQA) and paraphrased Writing Prompts (paraWP) datasets using GPT and\nDIPPER, a discourse paraphrasing tool, by extending artifacts from their\noriginal versions. To better capture the structure of longer texts at document\nlevel, we propose DTransformer, a model that integrates discourse analysis\nthrough PDTB preprocessing to encode structural features. It results in\nsubstantial performance gains across both datasets - 15.5% absolute improvement\non paraLFQA, 4% absolute improvement on paraWP, and 1.5% absolute improvemene\non M4 compared to SOTA approaches. The data and code are available at:\nhttps://github.com/myxp-lyp/Discourse-Features-Enhance-Detection-of-Document-Level-Machine-Generated-Content.git.",
    "published": "2024-12-17T08:47:41Z",
    "updated": "2025-10-28T02:20:41Z",
    "link": "http://arxiv.org/pdf/2412.12679v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yupei Li",
      "Manuel Milling",
      "Lucia Specia",
      "BjÃ¶rn W. Schuller"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24003v1",
    "title": "META-RAG: Meta-Analysis-Inspired Evidence-Re-Ranking Method for\n  Retrieval-Augmented Generation in Evidence-Based Medicine",
    "summary": "Evidence-based medicine (EBM) holds a crucial role in clinical application.\nGiven suitable medical articles, doctors effectively reduce the incidence of\nmisdiagnoses. Researchers find it efficient to use large language models (LLMs)\ntechniques like RAG for EBM tasks. However, the EBM maintains stringent\nrequirements for evidence, and RAG applications in EBM struggle to efficiently\ndistinguish high-quality evidence. Therefore, inspired by the meta-analysis\nused in EBM, we provide a new method to re-rank and filter the medical\nevidence. This method presents multiple principles to filter the best evidence\nfor LLMs to diagnose. We employ a combination of several EBM methods to emulate\nthe meta-analysis, which includes reliability analysis, heterogeneity analysis,\nand extrapolation analysis. These processes allow the users to retrieve the\nbest medical evidence for the LLMs. Ultimately, we evaluate these high-quality\narticles and show an accuracy improvement of up to 11.4% in our experiments and\nresults. Our method successfully enables RAG to extract higher-quality and more\nreliable evidence from the PubMed dataset. This work can reduce the infusion of\nincorrect knowledge into responses and help users receive more effective\nreplies.",
    "published": "2025-10-28T02:18:09Z",
    "updated": "2025-10-28T02:18:09Z",
    "link": "http://arxiv.org/pdf/2510.24003v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Mengzhou Sun",
      "Sendong Zhao",
      "Jianyu Chen",
      "Haochun Wang",
      "Bin Qin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23998v1",
    "title": "PICOs-RAG: PICO-supported Query Rewriting for Retrieval-Augmented\n  Generation in Evidence-Based Medicine",
    "summary": "Evidence-based medicine (EBM) research has always been of paramount\nimportance. It is important to find appropriate medical theoretical support for\nthe needs from physicians or patients to reduce the occurrence of medical\naccidents. This process is often carried out by human querying relevant\nliterature databases, which lacks objectivity and efficiency. Therefore,\nresearchers utilize retrieval-augmented generation (RAG) to search for evidence\nand generate responses automatically. However, current RAG methods struggle to\nhandle complex queries in real-world clinical scenarios. For example, when\nqueries lack certain information or use imprecise language, the model may\nretrieve irrelevant evidence and generate unhelpful answers. To address this\nissue, we present the PICOs-RAG to expand the user queries into a better\nformat. Our method can expand and normalize the queries into professional ones\nand use the PICO format, a search strategy tool present in EBM, to extract the\nmost important information used for retrieval. This approach significantly\nenhances retrieval efficiency and relevance, resulting in up to an 8.8\\%\nimprovement compared to the baseline evaluated by our method. Thereby the\nPICOs-RAG improves the performance of the large language models into a helpful\nand reliable medical assistant in EBM.",
    "published": "2025-10-28T02:01:05Z",
    "updated": "2025-10-28T02:01:05Z",
    "link": "http://arxiv.org/pdf/2510.23998v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Mengzhou Sun",
      "Sendong Zhao",
      "Jianyu Chen",
      "Bin Qin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23995v1",
    "title": "M-Eval: A Heterogeneity-Based Framework for Multi-evidence Validation in\n  Medical RAG Systems",
    "summary": "Retrieval-augmented Generation (RAG) has demonstrated potential in enhancing\nmedical question-answering systems through the integration of large language\nmodels (LLMs) with external medical literature. LLMs can retrieve relevant\nmedical articles to generate more professional responses efficiently. However,\ncurrent RAG applications still face problems. They generate incorrect\ninformation, such as hallucinations, and they fail to use external knowledge\ncorrectly. To solve these issues, we propose a new method named M-Eval. This\nmethod is inspired by the heterogeneity analysis approach used in\nEvidence-Based Medicine (EBM). Our approach can check for factual errors in RAG\nresponses using evidence from multiple sources. First, we extract additional\nmedical literature from external knowledge bases. Then, we retrieve the\nevidence documents generated by the RAG system. We use heterogeneity analysis\nto check whether the evidence supports different viewpoints in the response. In\naddition to verifying the accuracy of the response, we also assess the\nreliability of the evidence provided by the RAG system. Our method shows an\nimprovement of up to 23.31% accuracy across various LLMs. This work can help\ndetect errors in current RAG-based medical systems. It also makes the\napplications of LLMs more reliable and reduces diagnostic errors.",
    "published": "2025-10-28T01:57:40Z",
    "updated": "2025-10-28T01:57:40Z",
    "link": "http://arxiv.org/pdf/2510.23995v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Mengzhou Sun",
      "Sendong Zhao",
      "Jianyu Chen",
      "Haochun Wang",
      "Bin Qin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23969v1",
    "title": "emg2speech: synthesizing speech from electromyography using\n  self-supervised speech models",
    "summary": "We present a neuromuscular speech interface that translates electromyographic\n(EMG) signals collected from orofacial muscles during speech articulation\ndirectly into audio. We show that self-supervised speech (SS) representations\nexhibit a strong linear relationship with the electrical power of muscle action\npotentials: SS features can be linearly mapped to EMG power with a correlation\nof $r = 0.85$. Moreover, EMG power vectors corresponding to different\narticulatory gestures form structured and separable clusters in feature space.\nThis relationship: $\\text{SS features}$ $\\xrightarrow{\\texttt{linear mapping}}$\n$\\text{EMG power}$ $\\xrightarrow{\\texttt{gesture-specific clustering}}$\n$\\text{articulatory movements}$, highlights that SS models implicitly encode\narticulatory mechanisms. Leveraging this property, we directly map EMG signals\nto SS feature space and synthesize speech, enabling end-to-end EMG-to-speech\ngeneration without explicit articulatory models and vocoder training.",
    "published": "2025-10-28T00:50:15Z",
    "updated": "2025-10-28T00:50:15Z",
    "link": "http://arxiv.org/pdf/2510.23969v1.pdf",
    "category": [
      "cs.SD",
      "cs.CL",
      "eess.AS"
    ],
    "authors": [
      "Harshavardhana T. Gowda",
      "Lee M. Miller"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23946v1",
    "title": "Leveraging LLMs for Early Alzheimer's Prediction",
    "summary": "We present a connectome-informed LLM framework that encodes dynamic fMRI\nconnectivity as temporal sequences, applies robust normalization, and maps\nthese data into a representation suitable for a frozen pre-trained LLM for\nclinical prediction. Applied to early Alzheimer's detection, our method\nachieves sensitive prediction with error rates well below clinically recognized\nmargins, with implications for timely Alzheimer's intervention.",
    "published": "2025-10-27T23:59:03Z",
    "updated": "2025-10-27T23:59:03Z",
    "link": "http://arxiv.org/pdf/2510.23946v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Tananun Songdechakraiwut"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.21080v6",
    "title": "EQ-Negotiator: Emotion Policing Personas for Anti-Manipulation in Credit\n  Collection Dialogues",
    "summary": "Persona modeling in large language models typically focuses on static\ncharacter traits, but overlooks the dynamic emotional intelligence required for\nreal-time adversarial negotiations. In financial dialogues, this limitation\ncreates critical vulnerabilities: debtors exploit predictable empathetic\nresponses through emotional manipulation tactics like aggression, feigned\ndistress, and guilt-tripping. To bridge this gap, we present EQ-Negotiator, a\nnovel framework that grounds persona behavior in emotion dynamics rather than\nstatic personality profiles. Unlike naive empathy-centric agents, EQ-Negotiator\nintegrates emotion memory and game-theoretic reasoning, powered by a Hidden\nMarkov Model (HMM) to track and predict debtor emotional states. By analyzing\nboth real-time and historical emotional cues, EQ-Negotiator strategically\ncounters negative emotions (e.g., aggression, feigned distress) while\npreserving productive debtor relationships. This work advances persona modeling\nfrom descriptive character profiles to functional emotional architectures,\nestablishing emotion as the critical link between persona design and tactical\nexecution. Through agent-to-agent validation across 20 credit negotiation\nscenarios, we demonstrate that emotion-driven personas enable robust defensive\ncapabilities against manipulation while maintaining strategic effectiveness.",
    "published": "2025-03-27T01:41:34Z",
    "updated": "2025-10-27T23:31:13Z",
    "link": "http://arxiv.org/pdf/2503.21080v6.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yunbo Long",
      "Yuhan Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23921v1",
    "title": "Breaking the Benchmark: Revealing LLM Bias via Minimal Contextual\n  Augmentation",
    "summary": "Large Language Models have been shown to demonstrate stereotypical biases in\ntheir representations and behavior due to the discriminative nature of the data\nthat they have been trained on. Despite significant progress in the development\nof methods and models that refrain from using stereotypical information in\ntheir decision-making, recent work has shown that approaches used for bias\nalignment are brittle. In this work, we introduce a novel and general\naugmentation framework that involves three plug-and-play steps and is\napplicable to a number of fairness evaluation benchmarks. Through application\nof augmentation to a fairness evaluation dataset (Bias Benchmark for Question\nAnswering (BBQ)), we find that Large Language Models (LLMs), including\nstate-of-the-art open and closed weight models, are susceptible to\nperturbations to their inputs, showcasing a higher likelihood to behave\nstereotypically. Furthermore, we find that such models are more likely to have\nbiased behavior in cases where the target demographic belongs to a community\nless studied by the literature, underlining the need to expand the fairness and\nsafety research to include more diverse communities.",
    "published": "2025-10-27T23:05:12Z",
    "updated": "2025-10-27T23:05:12Z",
    "link": "http://arxiv.org/pdf/2510.23921v1.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Kaveh Eskandari Miandoab",
      "Mahammed Kamruzzaman",
      "Arshia Gharooni",
      "Gene Louis Kim",
      "Vasanth Sarathy",
      "Ninareh Mehrabi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.17100v2",
    "title": "Any Large Language Model Can Be a Reliable Judge: Debiasing with a\n  Reasoning-based Bias Detector",
    "summary": "LLM-as-a-Judge has emerged as a promising tool for automatically evaluating\ngenerated outputs, but its reliability is often undermined by potential biases\nin judgment. Existing efforts to mitigate these biases face key limitations:\nin-context learning-based methods fail to address rooted biases due to the\nevaluator's limited capacity for self-reflection, whereas fine-tuning is not\napplicable to all evaluator types, especially closed-source models. To address\nthis challenge, we introduce the Reasoning-based Bias Detector (RBD), which is\na plug-in module that identifies biased evaluations and generates structured\nreasoning to guide evaluator self-correction. Rather than modifying the\nevaluator itself, RBD operates externally and engages in an iterative process\nof bias detection and feedback-driven revision. To support its development, we\ndesign a complete pipeline consisting of biased dataset construction,\nsupervision collection, distilled reasoning-based fine-tuning of RBD, and\nintegration with LLM evaluators. We fine-tune four sizes of RBD models, ranging\nfrom 1.5B to 14B, and observe consistent performance improvements across all\nscales. Experimental results on 4 bias types--verbosity, position, bandwagon,\nand sentiment--evaluated using 8 LLM evaluators demonstrate RBD's strong\neffectiveness. For example, the RBD-8B model improves evaluation accuracy by an\naverage of 18.5% and consistency by 10.9%, and surpasses prompting-based\nbaselines and fine-tuned judges by 12.8% and 17.2%, respectively. These results\nhighlight RBD's effectiveness and scalability. Additional experiments further\ndemonstrate its strong generalization across biases and domains, as well as its\nefficiency.",
    "published": "2025-05-21T07:23:05Z",
    "updated": "2025-10-27T22:09:54Z",
    "link": "http://arxiv.org/pdf/2505.17100v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Haoyan Yang",
      "Runxue Bao",
      "Cao Xiao",
      "Jun Ma",
      "Parminder Bhatia",
      "Shangqian Gao",
      "Taha Kass-Hout"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23896v1",
    "title": "AfriMTEB and AfriE5: Benchmarking and Adapting Text Embedding Models for\n  African Languages",
    "summary": "Text embeddings are an essential building component of several NLP tasks such\nas retrieval-augmented generation which is crucial for preventing\nhallucinations in LLMs. Despite the recent release of massively multilingual\nMTEB (MMTEB), African languages remain underrepresented, with existing tasks\noften repurposed from translation benchmarks such as FLORES clustering or\nSIB-200. In this paper, we introduce AfriMTEB -- a regional expansion of MMTEB\ncovering 59 languages, 14 tasks, and 38 datasets, including six newly added\ndatasets. Unlike many MMTEB datasets that include fewer than five languages,\nthe new additions span 14 to 56 African languages and introduce entirely new\ntasks, such as hate speech detection, intent detection, and emotion\nclassification, which were not previously covered. Complementing this, we\npresent AfriE5, an adaptation of the instruction-tuned mE5 model to African\nlanguages through cross-lingual contrastive distillation. Our evaluation shows\nthat AfriE5 achieves state-of-the-art performance, outperforming strong\nbaselines such as Gemini-Embeddings and mE5.",
    "published": "2025-10-27T22:06:43Z",
    "updated": "2025-10-27T22:06:43Z",
    "link": "http://arxiv.org/pdf/2510.23896v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Kosei Uemura",
      "Miaoran Zhang",
      "David Ifeoluwa Adelani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23884v1",
    "title": "Language Models for Longitudinal Clinical Prediction",
    "summary": "We explore a lightweight framework that adapts frozen large language models\nto analyze longitudinal clinical data. The approach integrates patient history\nand context within the language model space to generate accurate forecasts\nwithout model fine-tuning. Applied to neuropsychological assessments, it\nachieves accurate and reliable performance even with minimal training data,\nshowing promise for early-stage Alzheimer's monitoring.",
    "published": "2025-10-27T21:49:03Z",
    "updated": "2025-10-27T21:49:03Z",
    "link": "http://arxiv.org/pdf/2510.23884v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Tananun Songdechakraiwut",
      "Michael Lutz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23868v1",
    "title": "GIFT: Group-relative Implicit Fine Tuning Integrates GRPO with DPO and\n  UNA",
    "summary": "I propose \\textbf{G}roup-relative \\textbf{I}mplicit \\textbf{F}ine\n\\textbf{T}uning (GIFT), a novel reinforcement learning framework for aligning\nLLMs. Instead of directly maximizing cumulative rewards like PPO or GRPO, GIFT\nminimizes the discrepancy between implicit and explicit reward models. It\ncombines three key ideas: (1) the online multi-response generation and\nnormalization of GRPO, (2) the implicit reward formulation of DPO, and (3) the\nimplicit-explicit reward alignment principle of UNA. By jointly normalizing the\nimplicit and explicit rewards, GIFT eliminates an otherwise intractable term\nthat prevents effective use of implicit rewards. This normalization transforms\nthe complex reward maximization objective into a simple mean squared error\n(MSE) loss between the normalized reward functions, converting a non-convex\noptimization problem into a convex, stable, and analytically differentiable\nformulation. Unlike offline methods such as DPO and UNA, GIFT remains on-policy\nand thus retains exploration capability. Compared to GRPO, it requires fewer\nhyperparameters, converges faster, and generalizes better with significantly\nreduced training overfitting. Empirically, GIFT achieves superior reasoning and\nalignment performance on mathematical benchmarks while remaining\ncomputationally efficient.",
    "published": "2025-10-27T21:18:19Z",
    "updated": "2025-10-27T21:18:19Z",
    "link": "http://arxiv.org/pdf/2510.23868v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Zhichao Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23853v1",
    "title": "Temporal Blindness in Multi-Turn LLM Agents: Misaligned Tool Use vs.\n  Human Time Perception",
    "summary": "Large language model agents are increasingly used in multi-turn\nconversational settings to interact with and execute tasks in dynamic\nenvironments. However, a key limitation is their temporal blindness: they, by\ndefault, operate with a stationary context, failing to account for the\nreal-world time elapsed between messages. This becomes a critical liability\nwhen an agent must decide whether to invoke a tool based on how much time has\npassed since the last observation. Without temporal awareness, agents often\neither over-rely on previous context (skipping necessary tool calls), or\nunder-rely on it (unnecessarily repeating tool calls). To study this challenge,\nwe introduce TicToc-v1, a test set of multi-turn user-agent trajectories across\n34 scenarios with varying time sensitivity. Each trajectory ends with a user\nquestion, where the need for a tool call depends on the amount of time elapsed\nsince the last message. To give LLMs temporal context, we augment dialogue\nmessages with explicit timestamps, bridging the gap between static dialogue and\nevolving environments. We then collected human preferences for these samples,\ncreating two subsets: one where humans preferred relying on the previous\nobservation (prefer-noTool), and another where they preferred a new tool call\n(prefer-Tool). We evaluated how well LLM tool-calling decisions align with\nhuman preferences under varying time intervals on TicToc-v1. Our analysis show\nthat without time information, most models perform only slightly better than\nrandom, with the top alignment rate being just over 60%. While adding\ntimestamps leads to a slight improvement, particularly for larger models, the\nimprovement is modest, peaking at around 65%. We also show that naive,\nprompt-based alignment have limited effectiveness. Our findings highlight the\nneed for specific post-training alignment to align multi-turn LLM tool use with\nhuman temporal perception.",
    "published": "2025-10-27T20:51:58Z",
    "updated": "2025-10-27T20:51:58Z",
    "link": "http://arxiv.org/pdf/2510.23853v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yize Cheng",
      "Arshia Soltani Moakhar",
      "Chenrui Fan",
      "Kazem Faghih",
      "Parsa Hosseini",
      "Wenxiao Wang",
      "Soheil Feizi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23842v1",
    "title": "How Pragmatics Shape Articulation: A Computational Case Study in STEM\n  ASL Discourse",
    "summary": "Most state-of-the-art sign language models are trained on interpreter or\nisolated vocabulary data, which overlooks the variability that characterizes\nnatural dialogue. However, human communication dynamically adapts to contexts\nand interlocutors through spatiotemporal changes and articulation style. This\nspecifically manifests itself in educational settings, where novel vocabularies\nare used by teachers, and students. To address this gap, we collect a motion\ncapture dataset of American Sign Language (ASL) STEM (Science, Technology,\nEngineering, and Mathematics) dialogue that enables quantitative comparison\nbetween dyadic interactive signing, solo signed lecture, and interpreted\narticles. Using continuous kinematic features, we disentangle dialogue-specific\nentrainment from individual effort reduction and show spatiotemporal changes\nacross repeated mentions of STEM terms. On average, dialogue signs are\n24.6%-44.6% shorter in duration than the isolated signs, and show significant\nreductions absent in monologue contexts. Finally, we evaluate sign embedding\nmodels on their ability to recognize STEM signs and approximate how entrained\nthe participants become over time. Our study bridges linguistic analysis and\ncomputational modeling to understand how pragmatics shape sign articulation and\nits representation in sign language technologies.",
    "published": "2025-10-27T20:29:46Z",
    "updated": "2025-10-27T20:29:46Z",
    "link": "http://arxiv.org/pdf/2510.23842v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Saki Imai",
      "Lee Kezar",
      "Laurel Aichler",
      "Mert Inan",
      "Erin Walker",
      "Alicia Wooten",
      "Lorna Quandt",
      "Malihe Alikhani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23828v1",
    "title": "Beyond Understanding: Evaluating the Pragmatic Gap in LLMs' Cultural\n  Processing of Figurative Language",
    "summary": "We present a comprehensive evaluation of the ability of large language models\n(LLMs) to process culturally grounded language, specifically to understand and\npragmatically use figurative expressions that encode local knowledge and\ncultural nuance. Using figurative language as a proxy for cultural nuance and\nlocal knowledge, we design evaluation tasks for contextual understanding,\npragmatic use, and connotation interpretation in Arabic and English. We\nevaluate 22 open- and closed-source LLMs on Egyptian Arabic idioms,\nmultidialectal Arabic proverbs, and English proverbs. Our results show a\nconsistent hierarchy: the average accuracy for Arabic proverbs is 4.29% lower\nthan for English proverbs, and performance for Egyptian idioms is 10.28% lower\nthan for Arabic proverbs. For the pragmatic use task, accuracy drops by 14.07%\nrelative to understanding, though providing contextual idiomatic sentences\nimproves accuracy by 10.66%. Models also struggle with connotative meaning,\nreaching at most 85.58% agreement with human annotators on idioms with 100%\ninter-annotator agreement. These findings demonstrate that figurative language\nserves as an effective diagnostic for cultural reasoning: while LLMs can often\ninterpret figurative meaning, they face challenges in using it appropriately.\nTo support future research, we release Kinayat, the first dataset of Egyptian\nArabic idioms designed for both figurative understanding and pragmatic use\nevaluation.",
    "published": "2025-10-27T20:13:32Z",
    "updated": "2025-10-27T20:13:32Z",
    "link": "http://arxiv.org/pdf/2510.23828v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Mena Attia",
      "Aashiq Muhamed",
      "Mai Alkhamissi",
      "Thamar Solorio",
      "Mona Diab"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.13834v6",
    "title": "Science Hierarchography: Hierarchical Organization of Science Literature",
    "summary": "Scientific knowledge is growing rapidly, making it difficult to track\nprogress and high-level conceptual links across broad disciplines. While tools\nlike citation networks and search engines help retrieve related papers, they\nlack the abstraction needed to capture the needed to represent the density and\nstructure of activity across subfields.\n  We motivate SCIENCE HIERARCHOGRAPHY, the goal of organizing scientific\nliterature into a high-quality hierarchical structure that spans multiple\nlevels of abstraction -- from broad domains to specific studies. Such a\nrepresentation can provide insights into which fields are well-explored and\nwhich are under-explored. To achieve this goal, we develop a hybrid approach\nthat combines efficient embedding-based clustering with LLM-based prompting,\nstriking a balance between scalability and semantic precision. Compared to\nLLM-heavy methods like iterative tree construction, our approach achieves\nsuperior quality-speed trade-offs. Our hierarchies capture different dimensions\nof research contributions, reflecting the interdisciplinary and multifaceted\nnature of modern science. We evaluate its utility by measuring how effectively\nan LLM-based agent can navigate the hierarchy to locate target papers. Results\nshow that our method improves interpretability and offers an alternative\npathway for exploring scientific literature beyond traditional search methods.\nCode, data and demo are available:\nhttps://github.com/JHU-CLSP/science-hierarchography",
    "published": "2025-04-18T17:59:29Z",
    "updated": "2025-10-27T19:17:31Z",
    "link": "http://arxiv.org/pdf/2504.13834v6.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Muhan Gao",
      "Jash Shah",
      "Weiqi Wang",
      "Kuan-Hao Huang",
      "Daniel Khashabi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.21837v3",
    "title": "Semantic Agreement Enables Efficient Open-Ended LLM Cascades",
    "summary": "Cascade systems route computational requests to smaller models when possible\nand defer to larger models only when necessary, offering a promising approach\nto balance cost and quality in LLM deployment. However, they face a fundamental\nchallenge in open-ended text generation: determining output reliability when\ngeneration quality lies on a continuous spectrum, often with multiple valid\nresponses. To address this, we propose semantic agreement -- meaning-level\nconsensus between ensemble outputs -- as a training-free signal for reliable\ndeferral. We show that when diverse model outputs agree semantically, their\nconsensus is a stronger reliability signal than token-level confidence.\nEvaluated from 500M to 70B-parameter models, we find that semantic cascades\nmatch or surpass target-model quality at 40% of the cost and reduce latency by\nup to 60%. Our method requires no model internals, works across black-box APIs,\nand remains robust to model updates, making it a practical baseline for\nreal-world LLM deployment.",
    "published": "2025-09-26T03:51:28Z",
    "updated": "2025-10-27T18:59:37Z",
    "link": "http://arxiv.org/pdf/2509.21837v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Duncan Soiffer",
      "Steven Kolawole",
      "Virginia Smith"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.06964v2",
    "title": "Offline RL by Reward-Weighted Fine-Tuning for Conversation Optimization",
    "summary": "Offline reinforcement learning (RL) is a variant of RL where the policy is\nlearned from a previously collected dataset of trajectories and rewards. In our\nwork, we propose a practical approach to offline RL with large language models\n(LLMs). We recast the problem as reward-weighted fine-tuning, which can be\nsolved using similar techniques to supervised fine-tuning (SFT). To showcase\nthe value of our approach, we apply it to learning short-horizon\nquestion-answering policies of a fixed length, where the agent reasons about\npotential answers or asks clarifying questions. Our work stands in a stark\ncontrast to state-of-the-art methods in this domain, based on SFT and direct\npreference optimization, which have additional hyper-parameters and do not\ndirectly optimize for rewards. We compare to them empirically, and report major\ngains in both optimized rewards and language quality.",
    "published": "2025-06-08T01:59:30Z",
    "updated": "2025-10-27T18:56:23Z",
    "link": "http://arxiv.org/pdf/2506.06964v2.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Subhojyoti Mukherjee",
      "Viet Dac Lai",
      "Raghavendra Addanki",
      "Ryan Rossi",
      "Seunghyun Yoon",
      "Trung Bui",
      "Anup Rao",
      "Jayakumar Subramanian",
      "Branislav Kveton"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23766v1",
    "title": "BitSkip: An Empirical Analysis of Quantization and Early Exit\n  Composition",
    "summary": "The pursuit of efficient Large Language Models (LLMs) has led to increasingly\ncomplex techniques like extreme quantization and dynamic routing. While\nindividual benefits of these methods are well-documented, their compositional\neffects remain poorly understood. This paper introduces BitSkip, a hybrid\narchitectural framework for systematically explor- ing these interactions.\nCounter-intuitively, our findings reveal that a simple 8-bit quantized model\nwithout Hadamard transform (BitSkip-V1) not only outperforms its more complex\n4-bit and Hadamard-enhanced counterparts but also competes the full-precision\nbaseline in quality (perplexity of 1.13 vs 1.19) . The introduction of Hadamard\ntransforms, even at 8- bit precision, catastrophically degraded performance by\nover 37,000%, tracing fundamental training instability. Our BitSkip-V1 recipe\ndemonstrates superior early-exit characteristics, with layer 18 providing\noptimal 32.5% speed gain for minimal 4% quality loss.",
    "published": "2025-10-27T18:53:08Z",
    "updated": "2025-10-27T18:53:08Z",
    "link": "http://arxiv.org/pdf/2510.23766v1.pdf",
    "category": [
      "cs.CL",
      "68T05",
      "I.2.6; I.2.7"
    ],
    "authors": [
      "Ramshankar Bhuvaneswaran",
      "Handan Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23763v1",
    "title": "RoboOmni: Proactive Robot Manipulation in Omni-modal Context",
    "summary": "Recent advances in Multimodal Large Language Models (MLLMs) have driven rapid\nprogress in Vision-Language-Action (VLA) models for robotic manipulation.\nAlthough effective in many scenarios, current approaches largely rely on\nexplicit instructions, whereas in real-world interactions, humans rarely issue\ninstructions directly. Effective collaboration requires robots to infer user\nintentions proactively. In this work, we introduce cross-modal contextual\ninstructions, a new setting where intent is derived from spoken dialogue,\nenvironmental sounds, and visual cues rather than explicit commands. To address\nthis new setting, we present RoboOmni, a Perceiver-Thinker-Talker-Executor\nframework based on end-to-end omni-modal LLMs that unifies intention\nrecognition, interaction confirmation, and action execution. RoboOmni fuses\nauditory and visual signals spatiotemporally for robust intention recognition,\nwhile supporting direct speech interaction. To address the absence of training\ndata for proactive intention recognition in robotic manipulation, we build\nOmniAction, comprising 140k episodes, 5k+ speakers, 2.4k event sounds, 640\nbackgrounds, and six contextual instruction types. Experiments in simulation\nand real-world settings show that RoboOmni surpasses text- and ASR-based\nbaselines in success rate, inference speed, intention recognition, and\nproactive assistance.",
    "published": "2025-10-27T18:49:03Z",
    "updated": "2025-10-27T18:49:03Z",
    "link": "http://arxiv.org/pdf/2510.23763v1.pdf",
    "category": [
      "cs.RO",
      "cs.CL",
      "cs.CV"
    ],
    "authors": [
      "Siyin Wang",
      "Jinlan Fu",
      "Feihong Liu",
      "Xinzhe He",
      "Huangxuan Wu",
      "Junhao Shi",
      "Kexin Huang",
      "Zhaoye Fei",
      "Jingjing Gong",
      "Zuxuan Wu",
      "Yugang Jiang",
      "See-Kiong Ng",
      "Tat-Seng Chua",
      "Xipeng Qiu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.00789v3",
    "title": "RARE: Retrieval-Aware Robustness Evaluation for Retrieval-Augmented\n  Generation Systems",
    "summary": "Retrieval-Augmented Generation (RAG) enhances recency and factuality in\nanswers. However, existing evaluations rarely test how well these systems cope\nwith real-world noise, conflicting between internal and external retrieved\ncontexts, or fast-changing facts. We introduce Retrieval-Aware Robustness\nEvaluation (RARE), a unified framework and large-scale benchmark that jointly\nstress-tests query and document perturbations over dynamic, time-sensitive\ncorpora. One of the central features of RARE is a knowledge-graph-driven\nsynthesis pipeline (RARE-Get) that automatically extracts single and multi-hop\nrelations from the customized corpus and generates multi-level question sets\nwithout manual intervention. Leveraging this pipeline, we construct a dataset\n(RARE-Set) spanning 527 expert-level time-sensitive finance, economics, and\npolicy documents and 48295 questions whose distribution evolves as the\nunderlying sources change. To quantify resilience, we formalize\nretrieval-conditioned robustness metrics (RARE-Met) that capture a model's\nability to remain correct or recover when queries, documents, or real-world\nretrieval results are systematically altered. Our findings reveal that RAG\nsystems are unexpectedly sensitive to perturbations. Moreover, they\nconsistently demonstrate lower robustness on multi-hop queries compared to\nsingle-hop queries across all domains.",
    "published": "2025-06-01T02:42:36Z",
    "updated": "2025-10-27T18:46:06Z",
    "link": "http://arxiv.org/pdf/2506.00789v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yixiao Zeng",
      "Tianyu Cao",
      "Danqing Wang",
      "Xinran Zhao",
      "Zimeng Qiu",
      "Morteza Ziyadi",
      "Tongshuang Wu",
      "Lei Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23730v1",
    "title": "Evaluating Long-Term Memory for Long-Context Question Answering",
    "summary": "In order for large language models to achieve true conversational continuity\nand benefit from experiential learning, they need memory. While research has\nfocused on the development of complex memory systems, it remains unclear which\ntypes of memory are most effective for long-context conversational tasks. We\npresent a systematic evaluation of memory-augmented methods using LoCoMo, a\nbenchmark of synthetic long-context dialogues annotated for question-answering\ntasks that require diverse reasoning strategies. We analyse full-context\nprompting, semantic memory through retrieval-augmented generation and agentic\nmemory, episodic memory through in-context learning, and procedural memory\nthrough prompt optimization. Our findings show that memory-augmented approaches\nreduce token usage by over 90% while maintaining competitive accuracy. Memory\narchitecture complexity should scale with model capability, with small\nfoundation models benefitting most from RAG, and strong instruction-tuned\nreasoning model gaining from episodic learning through reflections and more\ncomplex agentic semantic memory. In particular, episodic memory can help LLMs\nrecognise the limits of their own knowledge.",
    "published": "2025-10-27T18:03:50Z",
    "updated": "2025-10-27T18:03:50Z",
    "link": "http://arxiv.org/pdf/2510.23730v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Alessandra Terranova",
      "BjÃ¶rn Ross",
      "Alexandra Birch"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23727v1",
    "title": "MUStReason: A Benchmark for Diagnosing Pragmatic Reasoning in Video-LMs\n  for Multimodal Sarcasm Detection",
    "summary": "Sarcasm is a specific type of irony which involves discerning what is said\nfrom what is meant. Detecting sarcasm depends not only on the literal content\nof an utterance but also on non-verbal cues such as speaker's tonality, facial\nexpressions and conversational context. However, current multimodal models\nstruggle with complex tasks like sarcasm detection, which require identifying\nrelevant cues across modalities and pragmatically reasoning over them to infer\nthe speaker's intention. To explore these limitations in VideoLMs, we introduce\nMUStReason, a diagnostic benchmark enriched with annotations of\nmodality-specific relevant cues and underlying reasoning steps to identify\nsarcastic intent. In addition to benchmarking sarcasm classification\nperformance in VideoLMs, using MUStReason we quantitatively and qualitatively\nevaluate the generated reasoning by disentangling the problem into perception\nand reasoning, we propose PragCoT, a framework that steers VideoLMs to focus on\nimplied intentions over literal meaning, a property core to detecting sarcasm.",
    "published": "2025-10-27T18:03:11Z",
    "updated": "2025-10-27T18:03:11Z",
    "link": "http://arxiv.org/pdf/2510.23727v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Anisha Saha",
      "Varsha Suresh",
      "Timothy Hospedales",
      "Vera Demberg"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24718v1",
    "title": "Generative View Stitching",
    "summary": "Autoregressive video diffusion models are capable of long rollouts that are\nstable and consistent with history, but they are unable to guide the current\ngeneration with conditioning from the future. In camera-guided video generation\nwith a predefined camera trajectory, this limitation leads to collisions with\nthe generated scene, after which autoregression quickly collapses. To address\nthis, we propose Generative View Stitching (GVS), which samples the entire\nsequence in parallel such that the generated scene is faithful to every part of\nthe predefined camera trajectory. Our main contribution is a sampling algorithm\nthat extends prior work on diffusion stitching for robot planning to video\ngeneration. While such stitching methods usually require a specially trained\nmodel, GVS is compatible with any off-the-shelf video model trained with\nDiffusion Forcing, a prevalent sequence diffusion framework that we show\nalready provides the affordances necessary for stitching. We then introduce\nOmni Guidance, a technique that enhances the temporal consistency in stitching\nby conditioning on both the past and future, and that enables our proposed\nloop-closing mechanism for delivering long-range coherence. Overall, GVS\nachieves camera-guided video generation that is stable, collision-free,\nframe-to-frame consistent, and closes loops for a variety of predefined camera\npaths, including Oscar Reutersv\\\"ard's Impossible Staircase. Results are best\nviewed as videos at https://andrewsonga.github.io/gvs.",
    "published": "2025-10-28T17:59:58Z",
    "updated": "2025-10-28T17:59:58Z",
    "link": "http://arxiv.org/pdf/2510.24718v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Chonghyuk Song",
      "Michal Stary",
      "Boyuan Chen",
      "George Kopanas",
      "Vincent Sitzmann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24717v1",
    "title": "Uniform Discrete Diffusion with Metric Path for Video Generation",
    "summary": "Continuous-space video generation has advanced rapidly, while discrete\napproaches lag behind due to error accumulation and long-context inconsistency.\nIn this work, we revisit discrete generative modeling and present Uniform\ndiscRete diffuSion with metric pAth (URSA), a simple yet powerful framework\nthat bridges the gap with continuous approaches for the scalable video\ngeneration. At its core, URSA formulates the video generation task as an\niterative global refinement of discrete spatiotemporal tokens. It integrates\ntwo key designs: a Linearized Metric Path and a Resolution-dependent Timestep\nShifting mechanism. These designs enable URSA to scale efficiently to\nhigh-resolution image synthesis and long-duration video generation, while\nrequiring significantly fewer inference steps. Additionally, we introduce an\nasynchronous temporal fine-tuning strategy that unifies versatile tasks within\na single model, including interpolation and image-to-video generation.\nExtensive experiments on challenging video and image generation benchmarks\ndemonstrate that URSA consistently outperforms existing discrete methods and\nachieves performance comparable to state-of-the-art continuous diffusion\nmethods. Code and models are available at https://github.com/baaivision/URSA",
    "published": "2025-10-28T17:59:57Z",
    "updated": "2025-10-28T17:59:57Z",
    "link": "http://arxiv.org/pdf/2510.24717v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Haoge Deng",
      "Ting Pan",
      "Fan Zhang",
      "Yang Liu",
      "Zhuoyan Luo",
      "Yufeng Cui",
      "Wenxuan Wang",
      "Chunhua Shen",
      "Shiguang Shan",
      "Zhaoxiang Zhang",
      "Xinlong Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24711v1",
    "title": "Routing Matters in MoE: Scaling Diffusion Transformers with Explicit\n  Routing Guidance",
    "summary": "Mixture-of-Experts (MoE) has emerged as a powerful paradigm for scaling model\ncapacity while preserving computational efficiency. Despite its notable success\nin large language models (LLMs), existing attempts to apply MoE to Diffusion\nTransformers (DiTs) have yielded limited gains. We attribute this gap to\nfundamental differences between language and visual tokens. Language tokens are\nsemantically dense with pronounced inter-token variation, while visual tokens\nexhibit spatial redundancy and functional heterogeneity, hindering expert\nspecialization in vision MoE. To this end, we present ProMoE, an MoE framework\nfeaturing a two-step router with explicit routing guidance that promotes expert\nspecialization. Specifically, this guidance encourages the router to partition\nimage tokens into conditional and unconditional sets via conditional routing\naccording to their functional roles, and refine the assignments of conditional\nimage tokens through prototypical routing with learnable prototypes based on\nsemantic content. Moreover, the similarity-based expert allocation in latent\nspace enabled by prototypical routing offers a natural mechanism for\nincorporating explicit semantic guidance, and we validate that such guidance is\ncrucial for vision MoE. Building on this, we propose a routing contrastive loss\nthat explicitly enhances the prototypical routing process, promoting\nintra-expert coherence and inter-expert diversity. Extensive experiments on\nImageNet benchmark demonstrate that ProMoE surpasses state-of-the-art methods\nunder both Rectified Flow and DDPM training objectives. Code and models will be\nmade publicly available.",
    "published": "2025-10-28T17:59:02Z",
    "updated": "2025-10-28T17:59:02Z",
    "link": "http://arxiv.org/pdf/2510.24711v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yujie Wei",
      "Shiwei Zhang",
      "Hangjie Yuan",
      "Yujin Han",
      "Zhekai Chen",
      "Jiayu Wang",
      "Difan Zou",
      "Xihui Liu",
      "Yingya Zhang",
      "Yu Liu",
      "Hongming Shan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24688v1",
    "title": "MIC-BEV: Multi-Infrastructure Camera Bird's-Eye-View Transformer with\n  Relation-Aware Fusion for 3D Object Detection",
    "summary": "Infrastructure-based perception plays a crucial role in intelligent\ntransportation systems, offering global situational awareness and enabling\ncooperative autonomy. However, existing camera-based detection models often\nunderperform in such scenarios due to challenges such as multi-view\ninfrastructure setup, diverse camera configurations, degraded visual inputs,\nand various road layouts. We introduce MIC-BEV, a Transformer-based\nbird's-eye-view (BEV) perception framework for infrastructure-based\nmulti-camera 3D object detection. MIC-BEV flexibly supports a variable number\nof cameras with heterogeneous intrinsic and extrinsic parameters and\ndemonstrates strong robustness under sensor degradation. The proposed\ngraph-enhanced fusion module in MIC-BEV integrates multi-view image features\ninto the BEV space by exploiting geometric relationships between cameras and\nBEV cells alongside latent visual cues. To support training and evaluation, we\nintroduce M2I, a synthetic dataset for infrastructure-based object detection,\nfeaturing diverse camera configurations, road layouts, and environmental\nconditions. Extensive experiments on both M2I and the real-world dataset\nRoScenes demonstrate that MIC-BEV achieves state-of-the-art performance in 3D\nobject detection. It also remains robust under challenging conditions,\nincluding extreme weather and sensor degradation. These results highlight the\npotential of MIC-BEV for real-world deployment. The dataset and source code are\navailable at: https://github.com/HandsomeYun/MIC-BEV.",
    "published": "2025-10-28T17:49:42Z",
    "updated": "2025-10-28T17:49:42Z",
    "link": "http://arxiv.org/pdf/2510.24688v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yun Zhang",
      "Zhaoliang Zheng",
      "Johnson Liu",
      "Zhiyu Huang",
      "Zewei Zhou",
      "Zonglin Meng",
      "Tianhui Cai",
      "Jiaqi Ma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.20426v3",
    "title": "MMPerspective: Do MLLMs Understand Perspective? A Comprehensive\n  Benchmark for Perspective Perception, Reasoning, and Robustness",
    "summary": "Understanding perspective is fundamental to human visual perception, yet the\nextent to which multimodal large language models (MLLMs) internalize\nperspective geometry remains unclear. We introduce MMPerspective, the first\nbenchmark specifically designed to systematically evaluate MLLMs' understanding\nof perspective through 10 carefully crafted tasks across three complementary\ndimensions: Perspective Perception, Reasoning, and Robustness. Our benchmark\ncomprises 2,711 real-world and synthetic image instances with 5,083\nquestion-answer pairs that probe key capabilities, such as vanishing point\nperception and counting, perspective type reasoning, line relationship\nunderstanding in 3D space, invariance to perspective-preserving\ntransformations, etc. Through a comprehensive evaluation of 43 state-of-the-art\nMLLMs, we uncover significant limitations: while models demonstrate competence\non surface-level perceptual tasks, they struggle with compositional reasoning\nand maintaining spatial consistency under perturbations. Our analysis further\nreveals intriguing patterns between model architecture, scale, and perspective\ncapabilities, highlighting both robustness bottlenecks and the benefits of\nchain-of-thought prompting. MMPerspective establishes a valuable testbed for\ndiagnosing and advancing spatial understanding in vision-language systems.\nResources available at: https://yunlong10.github.io/MMPerspective/",
    "published": "2025-05-26T18:20:22Z",
    "updated": "2025-10-28T17:35:54Z",
    "link": "http://arxiv.org/pdf/2505.20426v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yolo Yunlong Tang",
      "Pinxin Liu",
      "Zhangyun Tan",
      "Mingqian Feng",
      "Rui Mao",
      "Chao Huang",
      "Jing Bi",
      "Yunzhong Xiao",
      "Susan Liang",
      "Hang Hua",
      "Ali Vosoughi",
      "Luchuan Song",
      "Zeliang Zhang",
      "Chenliang Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24667v1",
    "title": "SAGE: Structure-Aware Generative Video Transitions between Diverse Clips",
    "summary": "Video transitions aim to synthesize intermediate frames between two clips,\nbut naive approaches such as linear blending introduce artifacts that limit\nprofessional use or break temporal coherence. Traditional techniques\n(cross-fades, morphing, frame interpolation) and recent generative inbetweening\nmethods can produce high-quality plausible intermediates, but they struggle\nwith bridging diverse clips involving large temporal gaps or significant\nsemantic differences, leaving a gap for content-aware and visually coherent\ntransitions. We address this challenge by drawing on artistic workflows,\ndistilling strategies such as aligning silhouettes and interpolating salient\nfeatures to preserve structure and perceptual continuity. Building on this, we\npropose SAGE (Structure-Aware Generative vidEo transitions) as a zeroshot\napproach that combines structural guidance, provided via line maps and motion\nflow, with generative synthesis, enabling smooth, semantically consistent\ntransitions without fine-tuning. Extensive experiments and comparison with\ncurrent alternatives, namely [FILM, TVG, DiffMorpher, VACE, GI], demonstrate\nthat SAGE outperforms both classical and generative baselines on quantitative\nmetrics and user studies for producing transitions between diverse clips. Code\nto be released on acceptance.",
    "published": "2025-10-28T17:35:02Z",
    "updated": "2025-10-28T17:35:02Z",
    "link": "http://arxiv.org/pdf/2510.24667v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Mia Kan",
      "Yilin Liu",
      "Niloy Mitra"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24657v1",
    "title": "Group Relative Attention Guidance for Image Editing",
    "summary": "Recently, image editing based on Diffusion-in-Transformer models has\nundergone rapid development. However, existing editing methods often lack\neffective control over the degree of editing, limiting their ability to achieve\nmore customized results. To address this limitation, we investigate the\nMM-Attention mechanism within the DiT model and observe that the Query and Key\ntokens share a bias vector that is only layer-dependent. We interpret this bias\nas representing the model's inherent editing behavior, while the delta between\neach token and its corresponding bias encodes the content-specific editing\nsignals. Based on this insight, we propose Group Relative Attention Guidance, a\nsimple yet effective method that reweights the delta values of different tokens\nto modulate the focus of the model on the input image relative to the editing\ninstruction, enabling continuous and fine-grained control over editing\nintensity without any tuning. Extensive experiments conducted on existing image\nediting frameworks demonstrate that GRAG can be integrated with as few as four\nlines of code, consistently enhancing editing quality. Moreover, compared to\nthe commonly used Classifier-Free Guidance, GRAG achieves smoother and more\nprecise control over the degree of editing. Our code will be released at\nhttps://github.com/little-misfit/GRAG-Image-Editing.",
    "published": "2025-10-28T17:22:44Z",
    "updated": "2025-10-28T17:22:44Z",
    "link": "http://arxiv.org/pdf/2510.24657v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xuanpu Zhang",
      "Xuesong Niu",
      "Ruidong Chen",
      "Dan Song",
      "Jianhao Zeng",
      "Penghui Du",
      "Haoxiang Cao",
      "Kai Wu",
      "An-an Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24653v1",
    "title": "Eye-Tracking, Mouse Tracking, Stimulus Tracking,and Decision-Making\n  Datasets in Digital Pathology",
    "summary": "Interpretation of giga-pixel whole-slide images (WSIs) is an important but\ndifficult task for pathologists. Their diagnostic accuracy is estimated to\naverage around 70%. Adding a second pathologist does not substantially improve\ndecision consistency. The field lacks adequate behavioral data to explain\ndiagnostic errors and inconsistencies. To fill in this gap, we present\nPathoGaze1.0, a comprehensive behavioral dataset capturing the dynamic visual\nsearch and decision-making processes of the full diagnostic workflow during\ncancer diagnosis. The dataset comprises 18.69 hours of eye-tracking, mouse\ninteraction, stimulus tracking, viewport navigation, and diagnostic decision\ndata (EMSVD) collected from 19 pathologists interpreting 397 WSIs. The data\ncollection process emphasizes ecological validity through an\napplication-grounded testbed, called PTAH. In total, we recorded 171,909\nfixations, 263,320 saccades, and 1,867,362 mouse interaction events. In\naddition, such data could also be used to improve the training of both\npathologists and AI systems that might support human experts. All experiments\nwere preregistered at https://osf.io/hj9a7, and the complete dataset along with\nanalysis code is available at https://go.osu.edu/pathogaze.",
    "published": "2025-10-28T17:18:43Z",
    "updated": "2025-10-28T17:18:43Z",
    "link": "http://arxiv.org/pdf/2510.24653v1.pdf",
    "category": [
      "cs.CV",
      "cs.HC",
      "J.3"
    ],
    "authors": [
      "Veronica Thai",
      "Rui Li",
      "Meng Ling",
      "Shuning Jiang",
      "Jeremy Wolfe",
      "Raghu Machiraju",
      "Yan Hu",
      "Zaibo Li",
      "Anil Parwani",
      "Jian Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24640v1",
    "title": "A Dual-Branch CNN for Robust Detection of AI-Generated Facial Forgeries",
    "summary": "The rapid advancement of generative AI has enabled the creation of highly\nrealistic forged facial images, posing significant threats to AI security,\ndigital media integrity, and public trust. Face forgery techniques, ranging\nfrom face swapping and attribute editing to powerful diffusion-based image\nsynthesis, are increasingly being used for malicious purposes such as\nmisinformation, identity fraud, and defamation. This growing challenge\nunderscores the urgent need for robust and generalizable face forgery detection\nmethods as a critical component of AI security infrastructure. In this work, we\npropose a novel dual-branch convolutional neural network for face forgery\ndetection that leverages complementary cues from both spatial and frequency\ndomains. The RGB branch captures semantic information, while the frequency\nbranch focuses on high-frequency artifacts that are difficult for generative\nmodels to suppress. A channel attention module is introduced to adaptively fuse\nthese heterogeneous features, highlighting the most informative channels for\nforgery discrimination. To guide the network's learning process, we design a\nunified loss function, FSC Loss, that combines focal loss, supervised\ncontrastive loss, and a frequency center margin loss to enhance class\nseparability and robustness. We evaluate our model on the DiFF benchmark, which\nincludes forged images generated from four representative methods:\ntext-to-image, image-to-image, face swap, and face edit. Our method achieves\nstrong performance across all categories and outperforms average human\naccuracy. These results demonstrate the model's effectiveness and its potential\ncontribution to safeguarding AI ecosystems against visual forgery attacks.",
    "published": "2025-10-28T17:06:40Z",
    "updated": "2025-10-28T17:06:40Z",
    "link": "http://arxiv.org/pdf/2510.24640v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xin Zhang",
      "Yuqi Song",
      "Fei Zuo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.22693v2",
    "title": "VADTree: Explainable Training-Free Video Anomaly Detection via\n  Hierarchical Granularity-Aware Tree",
    "summary": "Video anomaly detection (VAD) focuses on identifying anomalies in videos.\nSupervised methods demand substantial in-domain training data and fail to\ndeliver clear explanations for anomalies. In contrast, training-free methods\nleverage the knowledge reserves and language interactivity of large pre-trained\nmodels to detect anomalies. However, the current fixed-length temporal window\nsampling approaches struggle to accurately capture anomalies with varying\ntemporal spans. Therefore, we propose VADTree that utilizes a Hierarchical\nGranularityaware Tree (HGTree) structure for flexible sampling in VAD. VADTree\nleverages the knowledge embedded in a pre-trained Generic Event Boundary\nDetection (GEBD) model to characterize potential anomaly event boundaries.\nSpecifically, VADTree decomposes the video into generic event nodes based on\nboundary confidence, and performs adaptive coarse-fine hierarchical structuring\nand redundancy removal to construct the HGTree. Then, the multi-dimensional\npriors are injected into the visual language models (VLMs) to enhance the\nnode-wise anomaly perception, and anomaly reasoning for generic event nodes is\nachieved via large language models (LLMs). Finally, an inter-cluster node\ncorrelation method is used to integrate the multi-granularity anomaly scores.\nExtensive experiments on three challenging datasets demonstrate that VADTree\nachieves state-of-the-art performance in training-free settings while\ndrastically reducing the number of sampled video segments. The code will be\navailable at https://github.com/wenlongli10/VADTree.",
    "published": "2025-10-26T14:36:15Z",
    "updated": "2025-10-28T16:57:22Z",
    "link": "http://arxiv.org/pdf/2510.22693v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Wenlong Li",
      "Yifei Xu",
      "Yuan Rao",
      "Zhenhua Wang",
      "Shuiguang Deng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24623v1",
    "title": "GroundLoc: Efficient Large-Scale Outdoor LiDAR-Only Localization",
    "summary": "In this letter, we introduce GroundLoc, a LiDAR-only localization pipeline\ndesigned to localize a mobile robot in large-scale outdoor environments using\nprior maps. GroundLoc employs a Bird's-Eye View (BEV) image projection focusing\non the perceived ground area and utilizes the place recognition network R2D2,\nor alternatively, the non-learning approach Scale-Invariant Feature Transform\n(SIFT), to identify and select keypoints for BEV image map registration. Our\nresults demonstrate that GroundLoc outperforms state-of-the-art methods on the\nSemanticKITTI and HeLiPR datasets across various sensors. In the multi-session\nlocalization evaluation, GroundLoc reaches an Average Trajectory Error (ATE)\nwell below 50 cm on all Ouster OS2 128 sequences while meeting online runtime\nrequirements. The system supports various sensor models, as evidenced by\nevaluations conducted with Velodyne HDL-64E, Ouster OS2 128, Aeva Aeries II,\nand Livox Avia sensors. The prior maps are stored as 2D raster image maps,\nwhich can be created from a single drive and require only 4 MB of storage per\nsquare kilometer. The source code is available at\nhttps://github.com/dcmlr/groundloc.",
    "published": "2025-10-28T16:51:50Z",
    "updated": "2025-10-28T16:51:50Z",
    "link": "http://arxiv.org/pdf/2510.24623v1.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Nicolai Steinke",
      "Daniel Goehring"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.18513v2",
    "title": "DWaste: Greener AI for Waste Sorting using Mobile and Edge Devices",
    "summary": "The rise of convenience packaging has led to generation of enormous waste,\nmaking efficient waste sorting crucial for sustainable waste management. To\naddress this, we developed DWaste, a computer vision-powered platform designed\nfor real-time waste sorting on resource-constrained smartphones and edge\ndevices, including offline functionality. We benchmarked various image\nclassification models (EfficientNetV2S/M, ResNet50/101, MobileNet) and object\ndetection (YOLOv8n, YOLOv11n) including our purposed YOLOv8n-CBAM model using\nour annotated dataset designed for recycling. We found a clear trade-off\nbetween accuracy and resource consumption: the best classifier,\nEfficientNetV2S, achieved high accuracy(~ 96%) but suffered from high latency\n(~ 0.22s) and elevated carbon emissions. In contrast, lightweight object\ndetection models delivered strong performance (up to 80% mAP) with ultra-fast\ninference (~ 0.03s) and significantly smaller model sizes (< 7MB ), making them\nideal for real-time, low-power use. Model quantization further maximized\nefficiency, substantially reducing model size and VRAM usage by up to 75%. Our\nwork demonstrates the successful implementation of \"Greener AI\" models to\nsupport real-time, sustainable waste sorting on edge devices.",
    "published": "2025-10-21T10:55:32Z",
    "updated": "2025-10-28T16:44:35Z",
    "link": "http://arxiv.org/pdf/2510.18513v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Suman Kunwar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2405.07046v3",
    "title": "RETTA: Retrieval-Enhanced Test-Time Adaptation for Zero-Shot Video\n  Captioning",
    "summary": "Despite the significant progress of fully-supervised video captioning,\nzero-shot methods remain much less explored. In this paper, we propose a novel\nzero-shot video captioning framework named Retrieval-Enhanced Test-Time\nAdaptation (RETTA), which takes advantage of existing pretrained large-scale\nvision and language models to directly generate captions with test-time\nadaptation. Specifically, we bridge video and text using four key models: a\ngeneral video-text retrieval model XCLIP, a general image-text matching model\nCLIP, a text alignment model AnglE, and a text generation model GPT-2, due to\ntheir source-code availability. The main challenge is how to enable the text\ngeneration model to be sufficiently aware of the content in a given video so as\nto generate corresponding captions. To address this problem, we propose using\nlearnable tokens as a communication medium among these four frozen models\nGPT-2, XCLIP, CLIP, and AnglE. Different from the conventional way that trains\nthese tokens with training data, we propose to learn these tokens with soft\ntargets of the inference data under several carefully crafted loss functions,\nwhich enable the tokens to absorb video information catered for GPT-2. This\nprocedure can be efficiently done in just a few iterations (we use 16\niterations in the experiments) and does not require ground truth data.\nExtensive experimental results on three widely used datasets, MSR-VTT, MSVD,\nand VATEX, show absolute 5.1%-32.4% improvements in terms of the main metric\nCIDEr compared to several state-of-the-art zero-shot video captioning methods.",
    "published": "2024-05-11T16:22:00Z",
    "updated": "2025-10-28T16:43:19Z",
    "link": "http://arxiv.org/pdf/2405.07046v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yunchuan Ma",
      "Laiyun Qing",
      "Guorong Li",
      "Yuankai Qi",
      "Amin Beheshti",
      "Quan Z. Sheng",
      "Qingming Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24579v1",
    "title": "Physics-Inspired Gaussian Kolmogorov-Arnold Networks for X-ray Scatter\n  Correction in Cone-Beam CT",
    "summary": "Cone-beam CT (CBCT) employs a flat-panel detector to achieve\nthree-dimensional imaging with high spatial resolution. However, CBCT is\nsusceptible to scatter during data acquisition, which introduces CT value bias\nand reduced tissue contrast in the reconstructed images, ultimately degrading\ndiagnostic accuracy. To address this issue, we propose a deep learning-based\nscatter artifact correction method inspired by physical prior knowledge.\nLeveraging the fact that the observed point scatter probability density\ndistribution exhibits rotational symmetry in the projection domain. The method\nuses Gaussian Radial Basis Functions (RBF) to model the point scatter function\nand embeds it into the Kolmogorov-Arnold Networks (KAN) layer, which provides\nefficient nonlinear mapping capabilities for learning high-dimensional scatter\nfeatures. By incorporating the physical characteristics of the scattered photon\ndistribution together with the complex function mapping capacity of KAN, the\nmodel improves its ability to accurately represent scatter. The effectiveness\nof the method is validated through both synthetic and real-scan experiments.\nExperimental results show that the model can effectively correct the scatter\nartifacts in the reconstructed images and is superior to the current methods in\nterms of quantitative metrics.",
    "published": "2025-10-28T16:13:14Z",
    "updated": "2025-10-28T16:13:14Z",
    "link": "http://arxiv.org/pdf/2510.24579v1.pdf",
    "category": [
      "cs.CV",
      "I.4.5; I.5"
    ],
    "authors": [
      "Xu Jiang",
      "Huiying Pan",
      "Ligen Shi",
      "Jianing Sun",
      "Wenfeng Xu",
      "Xing Zhao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.12427v4",
    "title": "Frequency-Aware Vision Transformers for High-Fidelity Super-Resolution\n  of Earth System Models",
    "summary": "Super-resolution (SR) is crucial for enhancing the spatial fidelity of Earth\nSystem Model (ESM) outputs, allowing fine-scale structures vital to climate\nscience to be recovered from coarse simulations. However, traditional deep\nsuper-resolution methods, including convolutional and transformer-based models,\ntend to exhibit spectral bias, reconstructing low-frequency content more\nreadily than valuable high-frequency details. In this work, we introduce two\nfrequency-aware frameworks: the Vision Transformer-Tuned Sinusoidal Implicit\nRepresentation (ViSIR), combining Vision Transformers and sinusoidal\nactivations to mitigate spectral bias, and the Vision Transformer Fourier\nRepresentation Network (ViFOR), which integrates explicit Fourier-based\nfiltering for independent low- and high-frequency learning. Evaluated on the\nE3SM-HR Earth system dataset across surface temperature, shortwave, and\nlongwave fluxes, these models outperform leading CNN, GAN, and vanilla\ntransformer baselines, with ViFOR demonstrating up to 2.6~dB improvements in\nPSNR and significantly higher SSIM. Detailed ablation and scaling studies\nhighlight the benefit of full-field training, the impact of frequency\nhyperparameters, and the potential for generalization. The results establish\nViFOR as a state-of-the-art, scalable solution for climate data downscaling.\nFuture extensions will address temporal super-resolution, multimodal climate\nvariables, automated parameter selection, and integration of physical\nconservation constraints to broaden scientific applicability.",
    "published": "2025-02-18T01:52:41Z",
    "updated": "2025-10-28T16:06:34Z",
    "link": "http://arxiv.org/pdf/2502.12427v4.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ehsan Zeraatkar",
      "Salah A Faroughi",
      "Jelena TeÅ¡iÄ"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.06415v2",
    "title": "Polygonal network disorder and the turning distance",
    "summary": "The turning distance is a well-studied metric for measuring the similarity\nbetween two polygons. This metric is constructed by taking an $L^p$ distance\nbetween step functions which track each shape's tangent angle of a path tracing\nits boundary. In this study, we introduce \\textit{turning disorders} for\npolygonal planar networks, defined by averaging turning distances between\nnetwork faces and \"ordered\" shapes (regular polygons or circles). We derive\nclosed-form expressions of turning distances for special classes of regular\npolygons, related to the divisibility of $m$ and $n$, and also between regular\npolygons and circles. These formulas are used to show that the time for\ncomputing the 2-turning distances reduces to $O((m+n) \\log(m+n))$ when both\nshapes are regular polygons, an improvement from $O(mn\\log(mn))$ operations\nneeded to compute distances between general polygons of $n$ and $m$ sides. We\nalso apply these formulas to several examples of network microstructure with\nvarying disorder. For Archimedean lattices, a class of regular tilings, we can\nexpress turning disorders with exact expressions. We also consider turning\ndisorders applied to two examples of stochastic processes on networks: spring\nnetworks evolving under T1 moves and polygonal rupture processes. We find that\nthe two aspects of defining different turning disorders, the choice of ordered\nshape and whether to apply area-weighting, can capture different notions of\nnetwork disorder.",
    "published": "2025-03-09T03:17:28Z",
    "updated": "2025-10-28T16:04:58Z",
    "link": "http://arxiv.org/pdf/2503.06415v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Alex Dolce",
      "Ryan Lavelle",
      "Bernard Scott",
      "Ashlyn Urbanski",
      "Joseph Klobusicky"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.05177v3",
    "title": "Long-VITA: Scaling Large Multi-modal Models to 1 Million Tokens with\n  Leading Short-Context Accuracy",
    "summary": "We introduce Long-VITA, a simple yet effective large multi-modal model for\nlong-context visual-language understanding tasks. It is adept at concurrently\nprocessing and analyzing modalities of image, video, and text over 4K frames or\n1M tokens while delivering advanced performances on short-context multi-modal\ntasks. We propose an effective multi-modal training schema that starts with\nlarge language models and proceeds through vision-language alignment, general\nknowledge learning, and two sequential stages of long-sequence fine-tuning. We\nfurther implement context-parallelism distributed inference and logits-masked\nlanguage modeling head to scale Long-VITA to infinitely long inputs of images\nand texts during model inference. Regarding training data, Long-VITA is built\non a mix of 17M samples from public datasets only and demonstrates\nstate-of-the-art performance on various multi-modal benchmarks, compared\nagainst recent cutting-edge models with internal data. Long-VITA is fully\nopen-source and reproducible.. By leveraging our inference designs, Long-VITA\nmodels achieve a remarkable 2x prefill speedup and 4x context length extension\nin a single node with 8 GPUs. We hope Long-VITA can serve as a competitive\nbaseline and offer valuable insights for the open-source community in advancing\nlong-context multi-modal understanding.",
    "published": "2025-02-07T18:59:56Z",
    "updated": "2025-10-28T16:02:48Z",
    "link": "http://arxiv.org/pdf/2502.05177v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yunhang Shen",
      "Chaoyou Fu",
      "Shaoqi Dong",
      "Xiong Wang",
      "Yi-Fan Zhang",
      "Peixian Chen",
      "Mengdan Zhang",
      "Haoyu Cao",
      "Ke Li",
      "Shaohui Lin",
      "Xiawu Zheng",
      "Yan Zhang",
      "Yiyi Zhou",
      "Ran He",
      "Caifeng Shan",
      "Rongrong Ji",
      "Xing Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24563v1",
    "title": "OSWorld-MCP: Benchmarking MCP Tool Invocation In Computer-Use Agents",
    "summary": "With advances in decision-making and reasoning capabilities, multimodal\nagents show strong potential in computer application scenarios. Past\nevaluations have mainly assessed GUI interaction skills, while tool invocation\nabilities, such as those enabled by the Model Context Protocol (MCP), have been\nlargely overlooked. Comparing agents with integrated tool invocation to those\nevaluated only on GUI interaction is inherently unfair. We present OSWorld-MCP,\nthe first comprehensive and fair benchmark for assessing computer-use agents'\ntool invocation, GUI operation, and decision-making abilities in a real-world\nenvironment. We design a novel automated code-generation pipeline to create\ntools and combine them with a curated selection from existing tools. Rigorous\nmanual validation yields 158 high-quality tools (covering 7 common\napplications), each verified for correct functionality, practical\napplicability, and versatility. Extensive evaluations of state-of-the-art\nmultimodal agents on OSWorld-MCP show that MCP tools generally improve task\nsuccess rates (e.g., from 8.3% to 20.4% for OpenAI o3 at 15 steps, from 40.1%\nto 43.3% for Claude 4 Sonnet at 50 steps), underscoring the importance of\nassessing tool invocation capabilities. However, even the strongest models have\nrelatively low tool invocation rates, Only 36.3%, indicating room for\nimprovement and highlighting the benchmark's challenge. By explicitly measuring\nMCP tool usage skills, OSWorld-MCP deepens understanding of multimodal agents\nand sets a new standard for evaluating performance in complex, tool-assisted\nenvironments. Our code, environment, and data are publicly available at\nhttps://osworld-mcp.github.io.",
    "published": "2025-10-28T15:56:36Z",
    "updated": "2025-10-28T15:56:36Z",
    "link": "http://arxiv.org/pdf/2510.24563v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Hongrui Jia",
      "Jitong Liao",
      "Xi Zhang",
      "Haiyang Xu",
      "Tianbao Xie",
      "Chaoya Jiang",
      "Ming Yan",
      "Si Liu",
      "Wei Ye",
      "Fei Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.02293v2",
    "title": "Towards Real Unsupervised Anomaly Detection Via Confident Meta-Learning",
    "summary": "So-called unsupervised anomaly detection is better described as\nsemi-supervised, as it assumes all training data are nominal. This assumption\nsimplifies training but requires manual data curation, introducing bias and\nlimiting adaptability. We propose Confident Meta-learning (CoMet), a novel\ntraining strategy that enables deep anomaly detection models to learn from\nuncurated datasets where nominal and anomalous samples coexist, eliminating the\nneed for explicit filtering. Our approach integrates Soft Confident Learning,\nwhich assigns lower weights to low-confidence samples, and Meta-Learning, which\nstabilizes training by regularizing updates based on training validation loss\ncovariance. This prevents overfitting and enhances robustness to noisy data.\nCoMet is model-agnostic and can be applied to any anomaly detection method\ntrainable via gradient descent. Experiments on MVTec-AD, VIADUCT, and KSDD2\nwith two state-of-the-art models demonstrate the effectiveness of our approach,\nconsistently improving over the baseline methods, remaining insensitive to\nanomalies in the training set, and setting a new state-of-the-art across all\ndatasets. Code is available at https://github.com/aqeeelmirza/CoMet",
    "published": "2025-08-04T11:03:12Z",
    "updated": "2025-10-28T15:28:13Z",
    "link": "http://arxiv.org/pdf/2508.02293v2.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Muhammad Aqeel",
      "Shakiba Sharifi",
      "Marco Cristani",
      "Francesco Setti"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.17071v2",
    "title": "Superpowering Open-Vocabulary Object Detectors for X-ray Vision",
    "summary": "Open-vocabulary object detection (OvOD) is set to revolutionize security\nscreening by enabling systems to recognize any item in X-ray scans. However,\ndeveloping effective OvOD models for X-ray imaging presents unique challenges\ndue to data scarcity and the modality gap that prevents direct adoption of\nRGB-based solutions. To overcome these limitations, we propose RAXO, a\ntraining-free framework that repurposes off-the-shelf RGB OvOD detectors for\nrobust X-ray detection. RAXO builds high-quality X-ray class descriptors using\na dual-source retrieval strategy. It gathers relevant RGB images from the web\nand enriches them via a novel X-ray material transfer mechanism, eliminating\nthe need for labeled databases. These visual descriptors replace text-based\nclassification in OvOD, leveraging intra-modal feature distances for robust\ndetection. Extensive experiments demonstrate that RAXO consistently improves\nOvOD performance, providing an average mAP increase of up to 17.0 points over\nbase detectors. To further support research in this emerging field, we also\nintroduce DET-COMPASS, a new benchmark featuring bounding box annotations for\nover 300 object categories, enabling large-scale evaluation of OvOD in X-ray.\nCode and dataset available at: https://github.com/PAGF188/RAXO.",
    "published": "2025-03-21T11:54:16Z",
    "updated": "2025-10-28T15:20:36Z",
    "link": "http://arxiv.org/pdf/2503.17071v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Pablo Garcia-Fernandez",
      "Lorenzo Vaquero",
      "Mingxuan Liu",
      "Feng Xue",
      "Daniel Cores",
      "Nicu Sebe",
      "Manuel Mucientes",
      "Elisa Ricci"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24486v1",
    "title": "Fast and accurate neural reflectance transformation imaging through\n  knowledge distillation",
    "summary": "Reflectance Transformation Imaging (RTI) is very popular for its ability to\nvisually analyze surfaces by enhancing surface details through interactive\nrelighting, starting from only a few tens of photographs taken with a fixed\ncamera and variable illumination. Traditional methods like Polynomial Texture\nMaps (PTM) and Hemispherical Harmonics (HSH) are compact and fast, but struggle\nto accurately capture complex reflectance fields using few per-pixel\ncoefficients and fixed bases, leading to artifacts, especially in highly\nreflective or shadowed areas. The NeuralRTI approach, which exploits a neural\nautoencoder to learn a compact function that better approximates the local\nreflectance as a function of light directions, has been shown to produce\nsuperior quality at comparable storage cost. However, as it performs\ninteractive relighting with custom decoder networks with many parameters, the\nrendering step is computationally expensive and not feasible at full resolution\nfor large images on limited hardware. Earlier attempts to reduce costs by\ndirectly training smaller networks have failed to produce valid results. For\nthis reason, we propose to reduce its computational cost through a novel\nsolution based on Knowledge Distillation (DisK-NeuralRTI). ...",
    "published": "2025-10-28T15:00:07Z",
    "updated": "2025-10-28T15:00:07Z",
    "link": "http://arxiv.org/pdf/2510.24486v1.pdf",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "Tinsae G. Dulecha",
      "Leonardo Righetto",
      "Ruggero Pintus",
      "Enrico Gobbetti",
      "Andrea Giachetti"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.14383v2",
    "title": "DRBD-Mamba for Robust and Efficient Brain Tumor Segmentation with\n  Analytical Insights",
    "summary": "Accurate brain tumor segmentation is significant for clinical diagnosis and\ntreatment but remains challenging due to tumor heterogeneity. Mamba-based State\nSpace Models have demonstrated promising performance. However, despite their\ncomputational efficiency over other neural architectures, they incur\nconsiderable overhead for this task due to their sequential feature computation\nacross multiple spatial axes. Moreover, their robustness across diverse BraTS\ndata partitions remains largely unexplored, leaving a critical gap in reliable\nevaluation. To address this, we first propose a dual-resolution bi-directional\nMamba (DRBD-Mamba), an efficient 3D segmentation model that captures\nmulti-scale long-range dependencies with minimal computational overhead. We\nleverage a space-filling curve to preserve spatial locality during 3D-to-1D\nfeature mapping, thereby reducing reliance on computationally expensive\nmulti-axial feature scans. To enrich feature representation, we propose a gated\nfusion module that adaptively integrates forward and reverse contexts, along\nwith a quantization block that improves robustness. We further propose five\nsystematic folds on BraTS2023 for rigorous evaluation of segmentation\ntechniques under diverse conditions and present analysis of common failure\nscenarios. On the 20% test set used by recent methods, our model achieves Dice\nimprovements of 0.10% for whole tumor, 1.75% for tumor core, and 0.93% for\nenhancing tumor. Evaluations on the proposed systematic folds demonstrate that\nour model maintains competitive whole tumor accuracy while achieving clear\naverage Dice gains of 1.16% for tumor core and 1.68% for enhancing tumor over\nexisting state-of-the-art. Furthermore, our model achieves a 15x efficiency\nimprovement while maintaining high segmentation accuracy, highlighting its\nrobustness and computational advantage over existing methods.",
    "published": "2025-10-16T07:31:21Z",
    "updated": "2025-10-28T14:50:18Z",
    "link": "http://arxiv.org/pdf/2510.14383v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Danish Ali",
      "Ajmal Mian",
      "Naveed Akhtar",
      "Ghulam Mubashar Hassan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.26386v2",
    "title": "PANDA: Towards Generalist Video Anomaly Detection via Agentic AI\n  Engineer",
    "summary": "Video anomaly detection (VAD) is a critical yet challenging task due to the\ncomplex and diverse nature of real-world scenarios. Previous methods typically\nrely on domain-specific training data and manual adjustments when applying to\nnew scenarios and unseen anomaly types, suffering from high labor costs and\nlimited generalization. Therefore, we aim to achieve generalist VAD, \\ie,\nautomatically handle any scene and any anomaly types without training data or\nhuman involvement. In this work, we propose PANDA, an agentic AI engineer based\non MLLMs. Specifically, we achieve PANDA by comprehensively devising four key\ncapabilities: (1) self-adaptive scene-aware strategy planning, (2) goal-driven\nheuristic reasoning, (3) tool-augmented self-reflection, and (4) self-improving\nchain-of-memory. Concretely, we develop a self-adaptive scene-aware RAG\nmechanism, enabling PANDA to retrieve anomaly-specific knowledge for anomaly\ndetection strategy planning. Next, we introduce a latent anomaly-guided\nheuristic prompt strategy to enhance reasoning precision. Furthermore, PANDA\nemploys a progressive reflection mechanism alongside a suite of context-aware\ntools to iteratively refine decision-making in complex scenarios. Finally, a\nchain-of-memory mechanism enables PANDA to leverage historical experiences for\ncontinual performance improvement. Extensive experiments demonstrate that PANDA\nachieves state-of-the-art performance in multi-scenario, open-set, and complex\nscenario settings without training and manual involvement, validating its\ngeneralizable and robust anomaly detection capability. Code is released at\nhttps://github.com/showlab/PANDA.",
    "published": "2025-09-30T15:19:43Z",
    "updated": "2025-10-28T14:48:45Z",
    "link": "http://arxiv.org/pdf/2509.26386v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhiwei Yang",
      "Chen Gao",
      "Mike Zheng Shou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24474v1",
    "title": "Decoupled MeanFlow: Turning Flow Models into Flow Maps for Accelerated\n  Sampling",
    "summary": "Denoising generative models, such as diffusion and flow-based models, produce\nhigh-quality samples but require many denoising steps due to discretization\nerror. Flow maps, which estimate the average velocity between timesteps,\nmitigate this error and enable faster sampling. However, their training\ntypically demands architectural changes that limit compatibility with\npretrained flow models. We introduce Decoupled MeanFlow, a simple decoding\nstrategy that converts flow models into flow map models without architectural\nmodifications. Our method conditions the final blocks of diffusion transformers\non the subsequent timestep, allowing pretrained flow models to be directly\nrepurposed as flow maps. Combined with enhanced training techniques, this\ndesign enables high-quality generation in as few as 1 to 4 steps. Notably, we\nfind that training flow models and subsequently converting them is more\nefficient and effective than training flow maps from scratch. On ImageNet\n256x256 and 512x512, our models attain 1-step FID of 2.16 and 2.12,\nrespectively, surpassing prior art by a large margin. Furthermore, we achieve\nFID of 1.51 and 1.68 when increasing the steps to 4, which nearly matches the\nperformance of flow models while delivering over 100x faster inference.",
    "published": "2025-10-28T14:43:48Z",
    "updated": "2025-10-28T14:43:48Z",
    "link": "http://arxiv.org/pdf/2510.24474v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Kyungmin Lee",
      "Sihyun Yu",
      "Jinwoo Shin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24464v1",
    "title": "Kineo: Calibration-Free Metric Motion Capture From Sparse RGB Cameras",
    "summary": "Markerless multiview motion capture is often constrained by the need for\nprecise camera calibration, limiting accessibility for non-experts and\nin-the-wild captures. Existing calibration-free approaches mitigate this\nrequirement but suffer from high computational cost and reduced reconstruction\naccuracy.\n  We present Kineo, a fully automatic, calibration-free pipeline for markerless\nmotion capture from videos captured by unsynchronized, uncalibrated,\nconsumer-grade RGB cameras. Kineo leverages 2D keypoints from off-the-shelf\ndetectors to simultaneously calibrate cameras, including Brown-Conrady\ndistortion coefficients, and reconstruct 3D keypoints and dense scene point\nmaps at metric scale. A confidence-driven spatio-temporal keypoint sampling\nstrategy, combined with graph-based global optimization, ensures robust\ncalibration at a fixed computational cost independent of sequence length. We\nfurther introduce a pairwise reprojection consensus score to quantify 3D\nreconstruction reliability for downstream tasks.\n  Evaluations on EgoHumans and Human3.6M demonstrate substantial improvements\nover prior calibration-free methods. Compared to previous state-of-the-art\napproaches, Kineo reduces camera translation error by approximately 83-85%,\ncamera angular error by 86-92%, and world mean-per-joint error (W-MPJPE) by\n83-91%.\n  Kineo is also efficient in real-world scenarios, processing multi-view\nsequences faster than their duration in specific configuration (e.g., 36min to\nprocess 1h20min of footage). The full pipeline and evaluation code are openly\nreleased to promote reproducibility and practical adoption at\nhttps://liris-xr.github.io/kineo/.",
    "published": "2025-10-28T14:30:47Z",
    "updated": "2025-10-28T14:30:47Z",
    "link": "http://arxiv.org/pdf/2510.24464v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Charles Javerliat",
      "Pierre Raimbaud",
      "Guillaume LavouÃ©"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24456v1",
    "title": "A Critical Study towards the Detection of Parkinsons Disease using ML\n  Technologies",
    "summary": "The proposed solution is Deep Learning Technique that will be able classify\nthree types of tea leaves diseases from which two diseases are caused by the\npests and one due to pathogens (infectious organisms) and environmental\nconditions and also show the area damaged by a disease in leaves. Namely Red\nRust, Helopeltis and Red spider mite respectively. In this paper we have\nevaluated two models namely SSD MobileNet V2 and Faster R-CNN ResNet50 V1 for\nthe object detection. The SSD MobileNet V2 gave precision of 0.209 for IOU\nrange of 0.50:0.95 with recall of 0.02 on IOU 0.50:0.95 and final mAP of 20.9%.\nWhile Faster R-CNN ResNet50 V1 has precision of 0.252 on IOU range of 0.50:0.95\nand recall of 0.044 on IOU of 0.50:0.95 with a mAP of 25%, which is better than\nSSD. Also used Mask R-CNN for Object Instance Segmentation where we have\nimplemented our custom method to calculate the damaged diseased portion of\nleaves. Keywords: Tea Leaf Disease, Deep Learning, Red Rust, Helopeltis and Red\nSpider Mite, SSD MobileNet V2, Faster R-CNN ResNet50 V1 and Mask RCNN.",
    "published": "2025-10-28T14:24:34Z",
    "updated": "2025-10-28T14:24:34Z",
    "link": "http://arxiv.org/pdf/2510.24456v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Vivek Chetia",
      "Abdul Taher Khan",
      "Rahish Gogoi",
      "David Kapsian Khual",
      "Purnendu Bikash",
      "Sajal Saha"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.20072v2",
    "title": "Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding\n  in Vision-Language-Action Policies",
    "summary": "Vision-Language-Action (VLA) models adapt large vision-language backbones to\nmap images and instructions into robot actions. However, prevailing VLAs either\ngenerate actions auto-regressively in a fixed left-to-right order or attach\nseparate MLP or diffusion heads outside the backbone, leading to fragmented\ninformation pathways and specialized training requirements that hinder a\nunified, scalable architecture. We present Discrete Diffusion VLA, a\nunified-transformer policy that models discretized action chunks with discrete\ndiffusion. The design retains diffusion's progressive refinement paradigm while\nremaining natively compatible with the discrete token interface of VLMs. Our\nmethod achieves an adaptive decoding order that resolves easy action elements\nbefore harder ones and uses secondary re-masking to revisit uncertain\npredictions across refinement rounds, which improves consistency and enables\nrobust error correction. This unified decoder preserves pre-trained\nvision-language priors, supports parallel decoding, breaks the autoregressive\nbottleneck, and reduces the number of function evaluations. Discrete Diffusion\nVLA achieves 96.3% avg. success rates on LIBERO, 71.2% visual matching on\nSimplerEnv-Fractal and 54.2% overall on SimplerEnv-Bridge, improving over\nautoregressive, MLP decoder and continuous diffusion baselines. These findings\nindicate that discrete-diffusion VLA supports precise action modeling and\nconsistent training, laying groundwork for scaling VLA to larger models and\ndatasets. Our project page is https://github.com/Liang-ZX/DiscreteDiffusionVLA",
    "published": "2025-08-27T17:39:11Z",
    "updated": "2025-10-28T14:22:20Z",
    "link": "http://arxiv.org/pdf/2508.20072v2.pdf",
    "category": [
      "cs.CV",
      "cs.LG",
      "cs.RO"
    ],
    "authors": [
      "Zhixuan Liang",
      "Yizhuo Li",
      "Tianshuo Yang",
      "Chengyue Wu",
      "Sitong Mao",
      "Tian Nian",
      "Liuao Pei",
      "Shunbo Zhou",
      "Xiaokang Yang",
      "Jiangmiao Pang",
      "Yao Mu",
      "Ping Luo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.22200v2",
    "title": "LongCat-Video Technical Report",
    "summary": "Video generation is a critical pathway toward world models, with efficient\nlong video inference as a key capability. Toward this end, we introduce\nLongCat-Video, a foundational video generation model with 13.6B parameters,\ndelivering strong performance across multiple video generation tasks. It\nparticularly excels in efficient and high-quality long video generation,\nrepresenting our first step toward world models. Key features include: Unified\narchitecture for multiple tasks: Built on the Diffusion Transformer (DiT)\nframework, LongCat-Video supports Text-to-Video, Image-to-Video, and\nVideo-Continuation tasks with a single model; Long video generation:\nPretraining on Video-Continuation tasks enables LongCat-Video to maintain high\nquality and temporal coherence in the generation of minutes-long videos;\nEfficient inference: LongCat-Video generates 720p, 30fps videos within minutes\nby employing a coarse-to-fine generation strategy along both the temporal and\nspatial axes. Block Sparse Attention further enhances efficiency, particularly\nat high resolutions; Strong performance with multi-reward RLHF: Multi-reward\nRLHF training enables LongCat-Video to achieve performance on par with the\nlatest closed-source and leading open-source models. Code and model weights are\npublicly available to accelerate progress in the field.",
    "published": "2025-10-25T07:41:02Z",
    "updated": "2025-10-28T14:19:57Z",
    "link": "http://arxiv.org/pdf/2510.22200v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      " Meituan LongCat Team",
      "Xunliang Cai",
      "Qilong Huang",
      "Zhuoliang Kang",
      "Hongyu Li",
      "Shijun Liang",
      "Liya Ma",
      "Siyu Ren",
      "Xiaoming Wei",
      "Rixu Xie",
      "Tong Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.14643v2",
    "title": "Multispectral State-Space Feature Fusion: Bridging Shared and\n  Cross-Parametric Interactions for Object Detection",
    "summary": "Modern multispectral feature fusion for object detection faces two critical\nlimitations: (1) Excessive preference for local complementary features over\ncross-modal shared semantics adversely affects generalization performance; and\n(2) The trade-off between the receptive field size and computational complexity\npresent critical bottlenecks for scalable feature modeling. Addressing these\nissues, a novel Multispectral State-Space Feature Fusion framework, dubbed\nMS2Fusion, is proposed based on the state space model (SSM), achieving\nefficient and effective fusion through a dual-path parametric interaction\nmechanism. More specifically, the first cross-parameter interaction branch\ninherits the advantage of cross-attention in mining complementary information\nwith cross-modal hidden state decoding in SSM. The second shared-parameter\nbranch explores cross-modal alignment with joint embedding to obtain\ncross-modal similar semantic features and structures through parameter sharing\nin SSM. Finally, these two paths are jointly optimized with SSM for fusing\nmultispectral features in a unified framework, allowing our MS2Fusion to enjoy\nboth functional complementarity and shared semantic space. In our extensive\nexperiments on mainstream benchmarks including FLIR, M3FD and LLVIP, our\nMS2Fusion significantly outperforms other state-of-the-art multispectral object\ndetection methods, evidencing its superiority. Moreover, MS2Fusion is general\nand applicable to other multispectral perception tasks. We show that, even\nwithout specific design, MS2Fusion achieves state-of-the-art results on RGB-T\nsemantic segmentation and RGBT salient object detection, showing its\ngenerality. The source code will be available at\nhttps://github.com/61s61min/MS2Fusion.git.",
    "published": "2025-07-19T14:38:03Z",
    "updated": "2025-10-28T14:09:59Z",
    "link": "http://arxiv.org/pdf/2507.14643v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jifeng Shen",
      "Haibo Zhan",
      "Shaohua Dong",
      "Xin Zuo",
      "Wankou Yang",
      "Haibin Ling"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24437v1",
    "title": "Deeply-Conditioned Image Compression via Self-Generated Priors",
    "summary": "Learned image compression (LIC) has shown great promise for achieving high\nrate-distortion performance. However, current LIC methods are often limited in\ntheir capability to model the complex correlation structures inherent in\nnatural images, particularly the entanglement of invariant global structures\nwith transient local textures within a single monolithic representation. This\nlimitation precipitates severe geometric deformation at low bitrates. To\naddress this, we introduce a framework predicated on functional decomposition,\nwhich we term Deeply-Conditioned Image Compression via self-generated priors\n(DCIC-sgp). Our central idea is to first encode a potent, self-generated prior\nto encapsulate the image's structural backbone. This prior is subsequently\nutilized not as mere side-information, but to holistically modulate the entire\ncompression pipeline. This deep conditioning, most critically of the analysis\ntransform, liberates it to dedicate its representational capacity to the\nresidual, high-entropy details. This hierarchical, dependency-driven approach\nachieves an effective disentanglement of information streams. Our extensive\nexperiments validate this assertion; visual analysis demonstrates that our\nmethod substantially mitigates the geometric deformation artifacts that plague\nconventional codecs at low bitrates. Quantitatively, our framework establishes\nhighly competitive performance, achieving significant BD-rate reductions of\n14.4%, 15.7%, and 15.1% against the VVC test model VTM-12.1 on the Kodak, CLIC,\nand Tecnick datasets.",
    "published": "2025-10-28T14:04:19Z",
    "updated": "2025-10-28T14:04:19Z",
    "link": "http://arxiv.org/pdf/2510.24437v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhineng Zhao",
      "Zhihai He",
      "Zikun Zhou",
      "Siwei Ma",
      "Yaowei Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.08423v4",
    "title": "DArFace: Deformation Aware Robustness for Low Quality Face Recognition",
    "summary": "Facial recognition systems have achieved remarkable success by leveraging\ndeep neural networks, advanced loss functions, and large-scale datasets.\nHowever, their performance often deteriorates in real-world scenarios involving\nlow-quality facial images. Such degradations, common in surveillance footage or\nstandoff imaging include low resolution, motion blur, and various distortions,\nresulting in a substantial domain gap from the high-quality data typically used\nduring training. While existing approaches attempt to address robustness by\nmodifying network architectures or modeling global spatial transformations,\nthey frequently overlook local, non-rigid deformations that are inherently\npresent in real-world settings. In this work, we introduce \\textbf{DArFace}, a\n\\textbf{D}eformation-\\textbf{A}ware \\textbf{r}obust \\textbf{Face} recognition\nframework that enhances robustness to such degradations without requiring\npaired high- and low-quality training samples. Our method adversarially\nintegrates both global transformations (e.g., rotation, translation) and local\nelastic deformations during training to simulate realistic low-quality\nconditions. Moreover, we introduce a contrastive objective to enforce identity\nconsistency across different deformed views. Extensive evaluations on\nlow-quality benchmarks including TinyFace, IJB-B, and IJB-C demonstrate that\nDArFace surpasses state-of-the-art methods, with significant gains attributed\nto the inclusion of local deformation modeling.",
    "published": "2025-05-13T10:35:57Z",
    "updated": "2025-10-28T13:53:29Z",
    "link": "http://arxiv.org/pdf/2505.08423v4.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Sadaf Gulshad",
      "Abdullah Aldahlawi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.05900v2",
    "title": "MTFL: Multi-Timescale Feature Learning for Weakly-Supervised Anomaly\n  Detection in Surveillance Videos",
    "summary": "Detection of anomaly events is relevant for public safety and requires a\ncombination of fine-grained motion information and contextual events at\nvariable time-scales. To this end, we propose a Multi-Timescale Feature\nLearning (MTFL) method to enhance the representation of anomaly features.\nShort, medium, and long temporal tubelets are employed to extract\nspatio-temporal video features using a Video Swin Transformer. Experimental\nresults demonstrate that MTFL outperforms state-of-the-art methods on the\nUCF-Crime dataset, achieving an anomaly detection performance 89.78% AUC.\nMoreover, it performs complementary to SotA with 95.32% AUC on the ShanghaiTech\nand 84.57% AP on the XD-Violence dataset. Furthermore, we generate an extended\ndataset of the UCF-Crime for development and evaluation on a wider range of\nanomalies, namely Video Anomaly Detection Dataset (VADD), involving 2,591\nvideos in 18 classes with extensive coverage of realistic anomalies.",
    "published": "2024-10-08T10:57:33Z",
    "updated": "2025-10-28T13:30:55Z",
    "link": "http://arxiv.org/pdf/2410.05900v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yiling Zhang",
      "Erkut Akdag",
      "Egor Bondarev",
      "Peter H. N. De With"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24414v1",
    "title": "XAI Evaluation Framework for Semantic Segmentation",
    "summary": "Ensuring transparency and trust in artificial intelligence (AI) models is\nessential, particularly as they are increasingly applied in safety-critical and\nhigh-stakes domains. Explainable AI (XAI) has emerged as a promising approach\nto address this challenge, yet the rigorous evaluation of XAI methods remains\ncrucial for optimizing the trade-offs between model complexity, predictive\nperformance, and interpretability. While extensive progress has been achieved\nin evaluating XAI techniques for classification tasks, evaluation strategies\ntailored to semantic segmentation remain relatively underexplored. This work\nintroduces a comprehensive and systematic evaluation framework specifically\ndesigned for assessing XAI in semantic segmentation, explicitly accounting for\nboth spatial and contextual task complexities. The framework employs\npixel-level evaluation strategies and carefully designed metrics to provide\nfine-grained interpretability insights. Simulation results using recently\nadapted class activation mapping (CAM)-based XAI schemes demonstrate the\nefficiency, robustness, and reliability of the proposed methodology. These\nfindings contribute to advancing transparent, trustworthy, and accountable\nsemantic segmentation models.",
    "published": "2025-10-28T13:27:38Z",
    "updated": "2025-10-28T13:27:38Z",
    "link": "http://arxiv.org/pdf/2510.24414v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Reem Hammoud",
      "Abdul karim Gizzini",
      "Ali J. Ghandour"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24413v1",
    "title": "50 Years of Water Body Monitoring: The Case of Qaraaoun Reservoir,\n  Lebanon",
    "summary": "The sustainable management of the Qaraaoun Reservoir, the largest surface\nwater body in Lebanon located in the Bekaa Plain, depends on reliable\nmonitoring of its storage volume despite frequent sensor malfunctions and\nlimited maintenance capacity. This study introduces a sensor-free approach that\nintegrates open-source satellite imagery, advanced water-extent segmentation,\nand machine learning to estimate the reservoir surface area and volume in near\nreal time. Sentinel-2 and Landsat images are processed, where surface water is\ndelineated using a newly proposed water segmentation index. A machine learning\nmodel based on Support Vector Regression (SVR) is trained on a curated dataset\nthat includes water surface area, water level, and water volume calculations\nusing a reservoir bathymetry survey. The model is then able to estimate\nreservoir volume relying solely on surface area extracted from satellite\nimagery, without the need for ground measurements. Water segmentation using the\nproposed index aligns with ground truth for more than 95 percent of the\nshoreline. Hyperparameter tuning with GridSearchCV yields an optimized SVR\nperformance with error under 1.5 percent of full reservoir capacity and\ncoefficients of determination exceeding 0.98. These results demonstrate the\nrobustness and cost-effectiveness of the method, offering a practical solution\nfor continuous, sensor-independent monitoring of reservoir storage. The\nproposed methodology can be replicated for other water bodies, and the\nresulting 50 years of time-series data is valuable for research on climate\nchange and environmental patterns.",
    "published": "2025-10-28T13:23:32Z",
    "updated": "2025-10-28T13:23:32Z",
    "link": "http://arxiv.org/pdf/2510.24413v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ali Ahmad Faour",
      "Nabil Amacha",
      "Ali J. Ghandour"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24410v1",
    "title": "A Hybrid Approach for Visual Multi-Object Tracking",
    "summary": "This paper proposes a visual multi-object tracking method that jointly\nemploys stochastic and deterministic mechanisms to ensure identifier\nconsistency for unknown and time-varying target numbers under nonlinear\ndynamics. A stochastic particle filter addresses nonlinear dynamics and\nnon-Gaussian noise, with support from particle swarm optimization (PSO) to\nguide particles toward state distribution modes and mitigate divergence through\nproposed fitness measures incorporating motion consistency, appearance\nsimilarity, and social-interaction cues with neighboring targets. Deterministic\nassociation further enforces identifier consistency via a proposed cost matrix\nincorporating spatial consistency between particles and current detections,\ndetection confidences, and track penalties. Subsequently, a novel scheme is\nproposed for the smooth updating of target states while preserving their\nidentities, particularly for weak tracks during interactions with other targets\nand prolonged occlusions. Moreover, velocity regression over past states\nprovides trend-seed velocities, enhancing particle sampling and state updates.\nThe proposed tracker is designed to operate flexibly for both pre-recorded\nvideos and camera live streams, where future frames are unavailable.\nExperimental results confirm superior performance compared to state-of-the-art\ntrackers. The source-code reference implementations of both the proposed method\nand compared-trackers are provided on GitHub:\nhttps://github.com/SDU-VelKoTek/GenTrack2",
    "published": "2025-10-28T13:22:24Z",
    "updated": "2025-10-28T13:22:24Z",
    "link": "http://arxiv.org/pdf/2510.24410v1.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Toan Van Nguyen",
      "Rasmus G. K. Christiansen",
      "Dirk Kraft",
      "Leon Bodenhagen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24399v1",
    "title": "GenTrack: A New Generation of Multi-Object Tracking",
    "summary": "This paper introduces a novel multi-object tracking (MOT) method, dubbed\nGenTrack, whose main contributions include: a hybrid tracking approach\nemploying both stochastic and deterministic manners to robustly handle unknown\nand time-varying numbers of targets, particularly in maintaining target\nidentity (ID) consistency and managing nonlinear dynamics, leveraging particle\nswarm optimization (PSO) with some proposed fitness measures to guide\nstochastic particles toward their target distribution modes, enabling effective\ntracking even with weak and noisy object detectors, integration of social\ninteractions among targets to enhance PSO-guided particles as well as improve\ncontinuous updates of both strong (matched) and weak (unmatched) tracks,\nthereby reducing ID switches and track loss, especially during occlusions, a\nGenTrack-based redefined visual MOT baseline incorporating a comprehensive\nstate and observation model based on space consistency, appearance, detection\nconfidence, track penalties, and social scores for systematic and efficient\ntarget updates, and the first-ever publicly available source-code reference\nimplementation with minimal dependencies, featuring three variants, including\nGenTrack Basic, PSO, and PSO-Social, facilitating flexible reimplementation.\nExperimental results have shown that GenTrack provides superior performance on\nstandard benchmarks and real-world scenarios compared to state-of-the-art\ntrackers, with integrated implementations of baselines for fair comparison.\nPotential directions for future work are also discussed. The source-code\nreference implementations of both the proposed method and compared-trackers are\nprovided on GitHub: https://github.com/SDU-VelKoTek/GenTrack",
    "published": "2025-10-28T13:13:20Z",
    "updated": "2025-10-28T13:13:20Z",
    "link": "http://arxiv.org/pdf/2510.24399v1.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Toan Van Nguyen",
      "Rasmus G. K. Christiansen",
      "Dirk Kraft",
      "Leon Bodenhagen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24398v1",
    "title": "Unsupervised Detection of Post-Stroke Brain Abnormalities",
    "summary": "Post-stroke MRI not only delineates focal lesions but also reveals secondary\nstructural changes, such as atrophy and ventricular enlargement. These\nabnormalities, increasingly recognised as imaging biomarkers of recovery and\noutcome, remain poorly captured by supervised segmentation methods. We evaluate\nREFLECT, a flow-based generative model, for unsupervised detection of both\nfocal and non-lesional abnormalities in post-stroke patients. Using dual-expert\ncentral-slice annotations on ATLAS data, performance was assessed at the object\nlevel with Free-Response ROC analysis for anomaly maps. Two models were trained\non lesion-free slices from stroke patients (ATLAS) and on healthy controls\n(IXI) to test the effect of training data. On ATLAS test subjects, the\nIXI-trained model achieved higher lesion segmentation (Dice = 0.37 vs 0.27) and\nimproved sensitivity to non-lesional abnormalities (FROC = 0.62 vs 0.43).\nTraining on fully healthy anatomy improves the modelling of normal variability,\nenabling broader and more reliable detection of structural abnormalities.",
    "published": "2025-10-28T13:13:01Z",
    "updated": "2025-10-28T13:13:01Z",
    "link": "http://arxiv.org/pdf/2510.24398v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Youwan MahÃ©",
      "Elise Bannier",
      "StÃ©phanie Leplaideur",
      "Elisa Fromont",
      "Francesca Galassi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2405.03520v2",
    "title": "Is Sora a World Simulator? A Comprehensive Survey on General World\n  Models and Beyond",
    "summary": "General world models represent a crucial pathway toward achieving Artificial\nGeneral Intelligence (AGI), serving as the cornerstone for various applications\nranging from virtual environments to decision-making systems. Recently, the\nemergence of the Sora model has attained significant attention due to its\nremarkable simulation capabilities, which exhibits an incipient comprehension\nof physical laws. In this survey, we embark on a comprehensive exploration of\nthe latest advancements in world models. Our analysis navigates through the\nforefront of generative methodologies in video generation, where world models\nstand as pivotal constructs facilitating the synthesis of highly realistic\nvisual content. Additionally, we scrutinize the burgeoning field of\nautonomous-driving world models, meticulously delineating their indispensable\nrole in reshaping transportation and urban mobility. Furthermore, we delve into\nthe intricacies inherent in world models deployed within autonomous agents,\nshedding light on their profound significance in enabling intelligent\ninteractions within dynamic environmental contexts. At last, we examine\nchallenges and limitations of world models, and discuss their potential future\ndirections. We hope this survey can serve as a foundational reference for the\nresearch community and inspire continued innovation. This survey will be\nregularly updated at:\nhttps://github.com/GigaAI-research/General-World-Models-Survey.",
    "published": "2024-05-06T14:37:07Z",
    "updated": "2025-10-28T13:04:23Z",
    "link": "http://arxiv.org/pdf/2405.03520v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zheng Zhu",
      "Xiaofeng Wang",
      "Wangbo Zhao",
      "Chen Min",
      "Bohan Li",
      "Nianchen Deng",
      "Min Dou",
      "Yuqi Wang",
      "Botian Shi",
      "Kai Wang",
      "Chi Zhang",
      "Yang You",
      "Zhaoxiang Zhang",
      "Dawei Zhao",
      "Liang Xiao",
      "Jian Zhao",
      "Jiwen Lu",
      "Guan Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24385v1",
    "title": "When are radiology reports useful for training medical image\n  classifiers?",
    "summary": "Medical images used to train machine learning models are often accompanied by\nradiology reports containing rich expert annotations. However, relying on these\nreports as inputs for clinical prediction requires the timely manual work of a\ntrained radiologist. This raises a natural question: when can radiology reports\nbe leveraged during training to improve image-only classification? Prior works\nare limited to evaluating pre-trained image representations by fine-tuning them\nto predict diagnostic labels, often extracted from reports, ignoring tasks with\nlabels that are weakly associated with the text. To address this gap, we\nconduct a systematic study of how radiology reports can be used during both\npre-training and fine-tuning, across diagnostic and prognostic tasks (e.g.,\n12-month readmission), and under varying training set sizes. Our findings\nreveal that: (1) Leveraging reports during pre-training is beneficial for\ndownstream classification tasks where the label is well-represented in the\ntext; however, pre-training through explicit image-text alignment can be\ndetrimental in settings where it's not; (2) Fine-tuning with reports can lead\nto significant improvements and even have a larger impact than the pre-training\nmethod in certain settings. These results provide actionable insights into when\nand how to leverage privileged text data to train medical image classifiers\nwhile highlighting gaps in current research.",
    "published": "2025-10-28T13:01:42Z",
    "updated": "2025-10-28T13:01:42Z",
    "link": "http://arxiv.org/pdf/2510.24385v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Herman BergstrÃ¶m",
      "Zhongqi Yue",
      "Fredrik D. Johansson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24379v1",
    "title": "A Luminance-Aware Multi-Scale Network for Polarization Image Fusion with\n  a Multi-Scene Dataset",
    "summary": "Polarization image fusion combines S0 and DOLP images to reveal surface\nroughness and material properties through complementary texture features, which\nhas important applications in camouflage recognition, tissue pathology\nanalysis, surface defect detection and other fields. To intergrate\ncoL-Splementary information from different polarized images in complex\nluminance environment, we propose a luminance-aware multi-scale network (MLSN).\nIn the encoder stage, we propose a multi-scale spatial weight matrix through a\nbrightness-branch , which dynamically weighted inject the luminance into the\nfeature maps, solving the problem of inherent contrast difference in polarized\nimages. The global-local feature fusion mechanism is designed at the bottleneck\nlayer to perform windowed self-attention computation, to balance the global\ncontext and local details through residual linking in the feature dimension\nrestructuring stage. In the decoder stage, to further improve the adaptability\nto complex lighting, we propose a Brightness-Enhancement module, establishing\nthe mapping relationship between luminance distribution and texture features,\nrealizing the nonlinear luminance correction of the fusion result. We also\npresent MSP, an 1000 pairs of polarized images that covers 17 types of indoor\nand outdoor complex lighting scenes. MSP provides four-direction polarization\nraw maps, solving the scarcity of high-quality datasets in polarization image\nfusion. Extensive experiment on MSP, PIF and GAND datasets verify that the\nproposed MLSN outperms the state-of-the-art methods in subjective and objective\nevaluations, and the MS-SSIM and SD metircs are higher than the average values\nof other methods by 8.57%, 60.64%, 10.26%, 63.53%, 22.21%, and 54.31%,\nrespectively. The source code and dataset is avalable at\nhttps://github.com/1hzf/MLS-UNet.",
    "published": "2025-10-28T12:57:42Z",
    "updated": "2025-10-28T12:57:42Z",
    "link": "http://arxiv.org/pdf/2510.24379v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhuangfan Huang",
      "Xiaosong Li",
      "Gao Wang",
      "Tao Ye",
      "Haishu Tan",
      "Huafeng Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24378v1",
    "title": "Stroke Lesion Segmentation in Clinical Workflows: A Modular,\n  Lightweight, and Deployment-Ready Tool",
    "summary": "Deep learning frameworks such as nnU-Net achieve state-of-the-art performance\nin brain lesion segmentation but remain difficult to deploy clinically due to\nheavy dependencies and monolithic design. We introduce \\textit{StrokeSeg}, a\nmodular and lightweight framework that translates research-grade stroke lesion\nsegmentation models into deployable applications. Preprocessing, inference, and\npostprocessing are decoupled: preprocessing relies on the Anima toolbox with\nBIDS-compliant outputs, and inference uses ONNX Runtime with \\texttt{Float16}\nquantisation, reducing model size by about 50\\%. \\textit{StrokeSeg} provides\nboth graphical and command-line interfaces and is distributed as Python scripts\nand as a standalone Windows executable. On a held-out set of 300 sub-acute and\nchronic stroke subjects, segmentation performance was equivalent to the\noriginal PyTorch pipeline (Dice difference $<10^{-3}$), demonstrating that\nhigh-performing research pipelines can be transformed into portable, clinically\nusable tools.",
    "published": "2025-10-28T12:56:48Z",
    "updated": "2025-10-28T12:56:48Z",
    "link": "http://arxiv.org/pdf/2510.24378v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yann Kerverdo",
      "Florent Leray",
      "Youwan MahÃ©",
      "StÃ©phanie Leplaideur",
      "Francesca Galassi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24374v1",
    "title": "Decoupling What to Count and Where to See for Referring Expression\n  Counting",
    "summary": "Referring Expression Counting (REC) extends class-level object counting to\nthe fine-grained subclass-level, aiming to enumerate objects matching a textual\nexpression that specifies both the class and distinguishing attribute. A\nfundamental challenge, however, has been overlooked: annotation points are\ntypically placed on class-representative locations (e.g., heads), forcing\nmodels to focus on class-level features while neglecting attribute information\nfrom other visual regions (e.g., legs for \"walking\"). To address this, we\npropose W2-Net, a novel framework that explicitly decouples the problem into\n\"what to count\" and \"where to see\" via a dual-query mechanism. Specifically,\nalongside the standard what-to-count (w2c) queries that localize the object, we\nintroduce dedicated where-to-see (w2s) queries. The w2s queries are guided to\nseek and extract features from attribute-specific visual regions, enabling\nprecise subclass discrimination. Furthermore, we introduce Subclass Separable\nMatching (SSM), a novel matching strategy that incorporates a repulsive force\nto enhance inter-subclass separability during label assignment. W2-Net\nsignificantly outperforms the state-of-the-art on the REC-8K dataset, reducing\ncounting error by 22.5% (validation) and 18.0% (test), and improving\nlocalization F1 by 7% and 8%, respectively. Code will be available.",
    "published": "2025-10-28T12:51:53Z",
    "updated": "2025-10-28T12:51:53Z",
    "link": "http://arxiv.org/pdf/2510.24374v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yuda Zou",
      "Zijian Zhang",
      "Yongchao Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24366v1",
    "title": "Adaptive Knowledge Transferring with Switching Dual-Student Framework\n  for Semi-Supervised Medical Image Segmentation",
    "summary": "Teacher-student frameworks have emerged as a leading approach in\nsemi-supervised medical image segmentation, demonstrating strong performance\nacross various tasks. However, the learning effects are still limited by the\nstrong correlation and unreliable knowledge transfer process between teacher\nand student networks. To overcome this limitation, we introduce a novel\nswitching Dual-Student architecture that strategically selects the most\nreliable student at each iteration to enhance dual-student collaboration and\nprevent error reinforcement. We also introduce a strategy of Loss-Aware\nExponential Moving Average to dynamically ensure that the teacher absorbs\nmeaningful information from students, improving the quality of pseudo-labels.\nOur plug-and-play framework is extensively evaluated on 3D medical image\nsegmentation datasets, where it outperforms state-of-the-art semi-supervised\nmethods, demonstrating its effectiveness in improving segmentation accuracy\nunder limited supervision.",
    "published": "2025-10-28T12:42:33Z",
    "updated": "2025-10-28T12:42:33Z",
    "link": "http://arxiv.org/pdf/2510.24366v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Thanh-Huy Nguyen",
      "Hoang-Thien Nguyen",
      "Ba-Thinh Lam",
      "Vi Vu",
      "Bach X. Nguyen",
      "Jianhua Xing",
      "Tianyang Wang",
      "Xingjian Li",
      "Min Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.24424v2",
    "title": "Advancing Compositional Awareness in CLIP with Efficient Fine-Tuning",
    "summary": "Vision-language models like CLIP have demonstrated remarkable zero-shot\ncapabilities in classification and retrieval. However, these models often\nstruggle with compositional reasoning - the ability to understand the\nrelationships between concepts. A recent benchmark, SugarCrepe++, reveals that\nprevious works on improving compositionality have mainly improved lexical\nsensitivity but neglected semantic understanding. In addition, downstream\nretrieval performance often deteriorates, although one would expect that\nimproving compositionality should enhance retrieval. In this work, we introduce\nCLIC (Compositionally-aware Learning in CLIP), a fine-tuning method based on a\nnovel training technique combining multiple images and their associated\ncaptions. CLIC improves compositionality across architectures as well as\ndifferently pre-trained CLIP models, both in terms of lexical and semantic\nunderstanding, and achieves consistent gains in retrieval performance. This\neven applies to the recent CLIPS, which achieves SOTA retrieval performance.\nNevertheless, the short fine-tuning with CLIC leads to an improvement in\nretrieval and to the best compositional CLIP model on SugarCrepe++. All our\nmodels and code are available at https://clic-compositional-clip.github.io",
    "published": "2025-05-30T10:04:00Z",
    "updated": "2025-10-28T12:08:40Z",
    "link": "http://arxiv.org/pdf/2505.24424v2.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Amit Peleg",
      "Naman Deep Singh",
      "Matthias Hein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24335v1",
    "title": "NVSim: Novel View Synthesis Simulator for Large Scale Indoor Navigation",
    "summary": "We present NVSim, a framework that automatically constructs large-scale,\nnavigable indoor simulators from only common image sequences, overcoming the\ncost and scalability limitations of traditional 3D scanning. Our approach\nadapts 3D Gaussian Splatting to address visual artifacts on sparsely observed\nfloors a common issue in robotic traversal data. We introduce Floor-Aware\nGaussian Splatting to ensure a clean, navigable ground plane, and a novel\nmesh-free traversability checking algorithm that constructs a topological graph\nby directly analyzing rendered views. We demonstrate our system's ability to\ngenerate valid, large-scale navigation graphs from real-world data. A video\ndemonstration is avilable at https://youtu.be/tTiIQt6nXC8",
    "published": "2025-10-28T11:57:33Z",
    "updated": "2025-10-28T11:57:33Z",
    "link": "http://arxiv.org/pdf/2510.24335v1.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Mingyu Jeong",
      "Eunsung Kim",
      "Sehun Park",
      "Andrew Jaeyong Choi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24332v1",
    "title": "Sound Source Localization for Spatial Mapping of Surgical Actions in\n  Dynamic Scenes",
    "summary": "Purpose: Surgical scene understanding is key to advancing computer-aided and\nintelligent surgical systems. Current approaches predominantly rely on visual\ndata or end-to-end learning, which limits fine-grained contextual modeling.\nThis work aims to enhance surgical scene representations by integrating 3D\nacoustic information, enabling temporally and spatially aware multimodal\nunderstanding of surgical environments.\n  Methods: We propose a novel framework for generating 4D audio-visual\nrepresentations of surgical scenes by projecting acoustic localization\ninformation from a phased microphone array onto dynamic point clouds from an\nRGB-D camera. A transformer-based acoustic event detection module identifies\nrelevant temporal segments containing tool-tissue interactions which are\nspatially localized in the audio-visual scene representation. The system was\nexperimentally evaluated in a realistic operating room setup during simulated\nsurgical procedures performed by experts.\n  Results: The proposed method successfully localizes surgical acoustic events\nin 3D space and associates them with visual scene elements. Experimental\nevaluation demonstrates accurate spatial sound localization and robust fusion\nof multimodal data, providing a comprehensive, dynamic representation of\nsurgical activity.\n  Conclusion: This work introduces the first approach for spatial sound\nlocalization in dynamic surgical scenes, marking a significant advancement\ntoward multimodal surgical scene representations. By integrating acoustic and\nvisual data, the proposed framework enables richer contextual understanding and\nprovides a foundation for future intelligent and autonomous surgical systems.",
    "published": "2025-10-28T11:55:45Z",
    "updated": "2025-10-28T11:55:45Z",
    "link": "http://arxiv.org/pdf/2510.24332v1.pdf",
    "category": [
      "cs.SD",
      "cs.CV",
      "eess.AS",
      "eess.IV"
    ],
    "authors": [
      "Jonas Hein",
      "Lazaros Vlachopoulos",
      "Maurits Geert Laurent Olthof",
      "Bastian Sigrist",
      "Philipp FÃ¼rnstahl",
      "Matthias Seibold"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24331v1",
    "title": "What do vision-language models see in the context? Investigating\n  multimodal in-context learning",
    "summary": "In-context learning (ICL) enables Large Language Models (LLMs) to learn tasks\nfrom demonstration examples without parameter updates. Although it has been\nextensively studied in LLMs, its effectiveness in Vision-Language Models (VLMs)\nremains underexplored. In this work, we present a systematic study of ICL in\nVLMs, evaluating seven models spanning four architectures on three image\ncaptioning benchmarks. We analyze how prompt design, architectural choices, and\ntraining strategies influence multimodal ICL. To our knowledge, we are the\nfirst to analyze how attention patterns in VLMs vary with an increasing number\nof in-context demonstrations. Our results reveal that training on imag-text\ninterleaved data enhances ICL performance but does not imply effective\nintegration of visual and textual information from demonstration examples. In\ncontrast, instruction tuning improves instruction-following but can reduce\nreliance on in-context demonstrations, suggesting a trade-off between\ninstruction alignment and in-context adaptation. Attention analyses further\nshow that current VLMs primarily focus on textual cues and fail to leverage\nvisual information, suggesting a limited capacity for multimodal integration.\nThese findings highlight key limitations in the ICL abilities of current VLMs\nand provide insights for enhancing their ability to learn from multimodal\nin-context examples.",
    "published": "2025-10-28T11:55:24Z",
    "updated": "2025-10-28T11:55:24Z",
    "link": "http://arxiv.org/pdf/2510.24331v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Gabriel O. dos Santos",
      "Esther Colombini",
      "Sandra Avila"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23497v2",
    "title": "VOLD: Reasoning Transfer from LLMs to Vision-Language Models via\n  On-Policy Distillation",
    "summary": "Training vision-language models (VLMs) for complex reasoning remains a\nchallenging task, i.a. due to the scarcity of high-quality image-text reasoning\ndata. Conversely, text-based reasoning resources are abundant and scalable, but\nit is still an open question how to leveraging them for VLM reasoning. To\naddress this problem, we propose VOLD, a framework to transfer reasoning\ncapabilities from text-only teacher models to VLM student models. To this end,\nVOLD combines reinforcement learning via Group Relative Policy Optimization\n(GRPO) with on-policy distillation, which allows the student reasoning traces\nto be guided by the teacher model, resulting in a significant gain over using\nGRPO alone. We further show that a cold-start alignment is essential for an\neffective transfer during the online training phase in this scenario and that\nwithout sufficient distributional alignment between teacher and student,\non-policy distillation fails to provide meaningful guidance. We evaluate VOLD\nacross diverse benchmarks including MMMU-Pro, MathVision, MathVista, and\nLogicVista, showing that VOLD outperforms the baseline model significantly and\nimproves over the state of the art by a margin. Our ablation shows the\nimportance of a cold-start alignment via SFT for on-policy distillation with a\ntext-only teacher.",
    "published": "2025-10-27T16:32:12Z",
    "updated": "2025-10-28T11:09:37Z",
    "link": "http://arxiv.org/pdf/2510.23497v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Walid Bousselham",
      "Hilde Kuehne",
      "Cordelia Schmid"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.00129v2",
    "title": "Geo-Sign: Hyperbolic Contrastive Regularisation for Geometrically Aware\n  Sign Language Translation",
    "summary": "Recent progress in Sign Language Translation (SLT) has focussed primarily on\nimproving the representational capacity of large language models to incorporate\nSign Language features. This work explores an alternative direction: enhancing\nthe geometric properties of skeletal representations themselves. We propose\nGeo-Sign, a method that leverages the properties of hyperbolic geometry to\nmodel the hierarchical structure inherent in sign language kinematics. By\nprojecting skeletal features derived from Spatio-Temporal Graph Convolutional\nNetworks (ST-GCNs) into the Poincar\\'e ball model, we aim to create more\ndiscriminative embeddings, particularly for fine-grained motions like finger\narticulations. We introduce a hyperbolic projection layer, a weighted Fr\\'echet\nmean aggregation scheme, and a geometric contrastive loss operating directly in\nhyperbolic space. These components are integrated into an end-to-end\ntranslation framework as a regularisation function, to enhance the\nrepresentations within the language model. This work demonstrates the potential\nof hyperbolic geometry to improve skeletal representations for Sign Language\nTranslation, improving on SOTA RGB methods while preserving privacy and\nimproving computational efficiency. Code available here:\nhttps://github.com/ed-fish/geo-sign.",
    "published": "2025-05-30T18:05:33Z",
    "updated": "2025-10-28T10:56:55Z",
    "link": "http://arxiv.org/pdf/2506.00129v2.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Edward Fish",
      "Richard Bowden"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.18833v2",
    "title": "Federated Learning with Partially Labeled Data: A Conditional\n  Distillation Approach",
    "summary": "In medical imaging, developing generalized segmentation models that can\nhandle multiple organs and lesions is crucial. However, the scarcity of fully\nannotated datasets and strict privacy regulations present significant barriers\nto data sharing. Federated Learning (FL) allows decentralized model training,\nbut existing FL methods often struggle with partial labeling, leading to model\ndivergence and catastrophic forgetting. We propose ConDistFL, a novel FL\nframework incorporating conditional distillation to address these challenges.\nConDistFL enables effective learning from partially labeled datasets,\nsignificantly improving segmentation accuracy across distributed and\nnon-uniform datasets. In addition to its superior segmentation performance,\nConDistFL maintains computational and communication efficiency, ensuring its\nscalability for real-world applications. Furthermore, ConDistFL demonstrates\nremarkable generalizability, significantly outperforming existing FL methods in\nout-of-federation tests, even adapting to unseen contrast phases (e.g.,\nnon-contrast CT images) in our experiments. Extensive evaluations on 3D CT and\n2D chest X-ray datasets show that ConDistFL is an efficient, adaptable solution\nfor collaborative medical image segmentation in privacy-constrained settings.",
    "published": "2024-12-25T08:40:03Z",
    "updated": "2025-10-28T10:38:37Z",
    "link": "http://arxiv.org/pdf/2412.18833v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Pochuan Wang",
      "Chen Shen",
      "Masahiro Oda",
      "Chiou-Shann Fuh",
      "Kensaku Mori",
      "Weichung Wang",
      "Holger R. Roth"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23225v2",
    "title": "Through the Lens: Benchmarking Deepfake Detectors Against\n  MoirÃ©-Induced Distortions",
    "summary": "Deepfake detection remains a pressing challenge, particularly in real-world\nsettings where smartphone-captured media from digital screens often introduces\nMoir\\'e artifacts that can distort detection outcomes. This study\nsystematically evaluates state-of-the-art (SOTA) deepfake detectors on\nMoir\\'e-affected videos, an issue that has received little attention. We\ncollected a dataset of 12,832 videos, spanning 35.64 hours, from the Celeb-DF,\nDFD, DFDC, UADFV, and FF++ datasets, capturing footage under diverse real-world\nconditions, including varying screens, smartphones, lighting setups, and camera\nangles. To further examine the influence of Moir\\'e patterns on deepfake\ndetection, we conducted additional experiments using our DeepMoir\\'eFake,\nreferred to as (DMF) dataset and two synthetic Moir\\'e generation techniques.\nAcross 15 top-performing detectors, our results show that Moir\\'e artifacts\ndegrade performance by as much as 25.4%, while synthetically generated Moir\\'e\npatterns lead to a 21.4% drop in accuracy. Surprisingly, demoir\\'eing methods,\nintended as a mitigation approach, instead worsened the problem, reducing\naccuracy by up to 17.2%. These findings underscore the urgent need for\ndetection models that can robustly handle Moir\\'e distortions alongside other\nrealworld challenges, such as compression, sharpening, and blurring. By\nintroducing the DMF dataset, we aim to drive future research toward closing the\ngap between controlled experiments and practical deepfake detection.",
    "published": "2025-10-27T11:23:04Z",
    "updated": "2025-10-28T10:25:00Z",
    "link": "http://arxiv.org/pdf/2510.23225v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Razaib Tariq",
      "Minji Heo",
      "Simon S. Woo",
      "Shahroz Tariq"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24262v1",
    "title": "UtilGen: Utility-Centric Generative Data Augmentation with Dual-Level\n  Task Adaptation",
    "summary": "Data augmentation using generative models has emerged as a powerful paradigm\nfor enhancing performance in computer vision tasks. However, most existing\naugmentation approaches primarily focus on optimizing intrinsic data attributes\n-- such as fidelity and diversity -- to generate visually high-quality\nsynthetic data, while often neglecting task-specific requirements. Yet, it is\nessential for data generators to account for the needs of downstream tasks, as\ntraining data requirements can vary significantly across different tasks and\nnetwork architectures. To address these limitations, we propose UtilGen, a\nnovel utility-centric data augmentation framework that adaptively optimizes the\ndata generation process to produce task-specific, high-utility training data\nvia downstream task feedback. Specifically, we first introduce a weight\nallocation network to evaluate the task-specific utility of each synthetic\nsample. Guided by these evaluations, UtilGen iteratively refines the data\ngeneration process using a dual-level optimization strategy to maximize the\nsynthetic data utility: (1) model-level optimization tailors the generative\nmodel to the downstream task, and (2) instance-level optimization adjusts\ngeneration policies -- such as prompt embeddings and initial noise -- at each\ngeneration round. Extensive experiments on eight benchmark datasets of varying\ncomplexity and granularity demonstrate that UtilGen consistently achieves\nsuperior performance, with an average accuracy improvement of 3.87% over\nprevious SOTA. Further analysis of data influence and distribution reveals that\nUtilGen produces more impactful and task-relevant synthetic data, validating\nthe effectiveness of the paradigm shift from visual characteristics-centric to\ntask utility-centric data augmentation.",
    "published": "2025-10-28T10:17:11Z",
    "updated": "2025-10-28T10:17:11Z",
    "link": "http://arxiv.org/pdf/2510.24262v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Jiyu Guo",
      "Shuo Yang",
      "Yiming Huang",
      "Yancheng Long",
      "Xiaobo Xia",
      "Xiu Su",
      "Bo Zhao",
      "Zeke Xie",
      "Liqiang Nie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24260v1",
    "title": "DeshadowMamba: Deshadowing as 1D Sequential Similarity",
    "summary": "Recent deep models for image shadow removal often rely on attention-based\narchitectures to capture long-range dependencies. However, their fixed\nattention patterns tend to mix illumination cues from irrelevant regions,\nleading to distorted structures and inconsistent colors. In this work, we\nrevisit shadow removal from a sequence modeling perspective and explore the use\nof Mamba, a selective state space model that propagates global context through\ndirectional state transitions. These transitions yield an efficient global\nreceptive field while preserving positional continuity. Despite its potential,\ndirectly applying Mamba to image data is suboptimal, since it lacks awareness\nof shadow-non-shadow semantics and remains susceptible to color interference\nfrom nearby regions. To address these limitations, we propose CrossGate, a\ndirectional modulation mechanism that injects shadow-aware similarity into\nMamba's input gate, allowing selective integration of relevant context along\ntransition axes. To further ensure appearance fidelity, we introduce ColorShift\nregularization, a contrastive learning objective driven by global color\nstatistics. By synthesizing structured informative negatives, it guides the\nmodel to suppress color contamination and achieve robust color restoration.\nTogether, these components adapt sequence modeling to the structural integrity\nand chromatic consistency required for shadow removal. Extensive experiments on\npublic benchmarks demonstrate that DeshadowMamba achieves state-of-the-art\nvisual quality and strong quantitative performance.",
    "published": "2025-10-28T10:14:23Z",
    "updated": "2025-10-28T10:14:23Z",
    "link": "http://arxiv.org/pdf/2510.24260v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhaotong Yang",
      "Yi Chen",
      "Yanying Li",
      "Shengfeng He",
      "Yangyang Xu",
      "Junyu Dong",
      "Jian Yang",
      "Yong Du"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24232v1",
    "title": "Delving into Cascaded Instability: A Lipschitz Continuity View on Image\n  Restoration and Object Detection Synergy",
    "summary": "To improve detection robustness in adverse conditions (e.g., haze and low\nlight), image restoration is commonly applied as a pre-processing step to\nenhance image quality for the detector. However, the functional mismatch\nbetween restoration and detection networks can introduce instability and hinder\neffective integration -- an issue that remains underexplored. We revisit this\nlimitation through the lens of Lipschitz continuity, analyzing the functional\ndifferences between restoration and detection networks in both the input space\nand the parameter space. Our analysis shows that restoration networks perform\nsmooth, continuous transformations, while object detectors operate with\ndiscontinuous decision boundaries, making them highly sensitive to minor\nperturbations. This mismatch introduces instability in traditional cascade\nframeworks, where even imperceptible noise from restoration is amplified during\ndetection, disrupting gradient flow and hindering optimization. To address\nthis, we propose Lipschitz-regularized object detection (LROD), a simple yet\neffective framework that integrates image restoration directly into the\ndetector's feature learning, harmonizing the Lipschitz continuity of both tasks\nduring training. We implement this framework as Lipschitz-regularized YOLO\n(LR-YOLO), extending seamlessly to existing YOLO detectors. Extensive\nexperiments on haze and low-light benchmarks demonstrate that LR-YOLO\nconsistently improves detection stability, optimization smoothness, and overall\naccuracy.",
    "published": "2025-10-28T09:41:42Z",
    "updated": "2025-10-28T09:41:42Z",
    "link": "http://arxiv.org/pdf/2510.24232v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Qing Zhao",
      "Weijian Deng",
      "Pengxu Wei",
      "ZiYi Dong",
      "Hannan Lu",
      "Xiangyang Ji",
      "Liang Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24231v1",
    "title": "Benchmarking Microsaccade Recognition with Event Cameras: A Novel\n  Dataset and Evaluation",
    "summary": "Microsaccades are small, involuntary eye movements vital for visual\nperception and neural processing. Traditional microsaccade studies typically\nuse eye trackers or frame-based analysis, which, while precise, are costly and\nlimited in scalability and temporal resolution. Event-based sensing offers a\nhigh-speed, low-latency alternative by capturing fine-grained spatiotemporal\nchanges efficiently. This work introduces a pioneering event-based microsaccade\ndataset to support research on small eye movement dynamics in cognitive\ncomputing. Using Blender, we render high-fidelity eye movement scenarios and\nsimulate microsaccades with angular displacements from 0.5 to 2.0 degrees,\ndivided into seven distinct classes. These are converted to event streams using\nv2e, preserving the natural temporal dynamics of microsaccades, with durations\nranging from 0.25 ms to 2.25 ms. We evaluate the dataset using Spiking-VGG11,\nSpiking-VGG13, and Spiking-VGG16, and propose Spiking-VGG16Flow, an\noptical-flow-enhanced variant implemented in SpikingJelly. The models achieve\naround 90 percent average accuracy, successfully classifying microsaccades by\nangular displacement, independent of event count or duration. These results\ndemonstrate the potential of spiking neural networks for fine motion\nrecognition and establish a benchmark for event-based vision research. The\ndataset, code, and trained models will be publicly available at\nhttps://waseemshariff126.github.io/microsaccades/ .",
    "published": "2025-10-28T09:41:30Z",
    "updated": "2025-10-28T09:41:30Z",
    "link": "http://arxiv.org/pdf/2510.24231v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Waseem Shariff",
      "Timothy Hanley",
      "Maciej Stec",
      "Hossein Javidnia",
      "Peter Corcoran"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.20510v2",
    "title": "CPathAgent: An Agent-based Foundation Model for Interpretable\n  High-Resolution Pathology Image Analysis Mimicking Pathologists' Diagnostic\n  Logic",
    "summary": "Recent advances in computational pathology have led to the emergence of\nnumerous foundation models. These models typically rely on general-purpose\nencoders with multi-instance learning for whole slide image (WSI)\nclassification or apply multimodal approaches to generate reports directly from\nimages. However, these models cannot emulate the diagnostic approach of\npathologists, who systematically examine slides at low magnification to obtain\nan overview before progressively zooming in on suspicious regions to formulate\ncomprehensive diagnoses. Instead, existing models directly output final\ndiagnoses without revealing the underlying reasoning process. To address this\ngap, we introduce CPathAgent, an innovative agent-based approach that mimics\npathologists' diagnostic workflow by autonomously navigating across WSI based\non observed visual features, thereby generating substantially more transparent\nand interpretable diagnostic summaries. To achieve this, we develop a\nmulti-stage training strategy that unifies patch-level, region-level, and\nWSI-level capabilities within a single model, which is essential for\nreplicating how pathologists understand and reason across diverse image scales.\nAdditionally, we construct PathMMU-HR2, the first expert-validated benchmark\nfor large region analysis. This represents a critical intermediate scale\nbetween patches and whole slides, reflecting a key clinical reality where\npathologists typically examine several key large regions rather than entire\nslides at once. Extensive experiments demonstrate that CPathAgent consistently\noutperforms existing approaches across benchmarks at three different image\nscales, validating the effectiveness of our agent-based diagnostic approach and\nhighlighting a promising direction for computational pathology.",
    "published": "2025-05-26T20:22:19Z",
    "updated": "2025-10-28T09:39:55Z",
    "link": "http://arxiv.org/pdf/2505.20510v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yuxuan Sun",
      "Yixuan Si",
      "Chenglu Zhu",
      "Kai Zhang",
      "Zhongyi Shui",
      "Bowen Ding",
      "Tao Lin",
      "Lin Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24214v1",
    "title": "SCOPE: Saliency-Coverage Oriented Token Pruning for Efficient Multimodel\n  LLMs",
    "summary": "Multimodal Large Language Models (MLLMs) typically process a large number of\nvisual tokens, leading to considerable computational overhead, even though many\nof these tokens are redundant. Existing visual token pruning methods primarily\nfocus on selecting the most salient tokens based on attention scores, resulting\nin the semantic incompleteness of the selected tokens. In this paper, we\npropose a novel visual token pruning strategy, called\n\\textbf{S}aliency-\\textbf{C}overage \\textbf{O}riented token \\textbf{P}runing\nfor \\textbf{E}fficient MLLMs (SCOPE), to jointly model both the saliency and\ncoverage of the selected visual tokens to better preserve semantic\ncompleteness. Specifically, we introduce a set-coverage for a given set of\nselected tokens, computed based on the token relationships. We then define a\ntoken-coverage gain for each unselected token, quantifying how much additional\ncoverage would be obtained by including it. By integrating the saliency score\ninto the token-coverage gain, we propose our SCOPE score and iteratively select\nthe token with the highest SCOPE score. We conduct extensive experiments on\nmultiple vision-language understanding benchmarks using the LLaVA-1.5 and\nLLaVA-Next models. Experimental results demonstrate that our method\nconsistently outperforms prior approaches. Our code is available at\n\\href{https://github.com/kinredon/SCOPE}{https://github.com/kinredon/SCOPE}.",
    "published": "2025-10-28T09:29:37Z",
    "updated": "2025-10-28T09:29:37Z",
    "link": "http://arxiv.org/pdf/2510.24214v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jinhong Deng",
      "Wen Li",
      "Joey Tianyi Zhou",
      "Yang He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24213v1",
    "title": "Beyond Inference Intervention: Identity-Decoupled Diffusion for Face\n  Anonymization",
    "summary": "Face anonymization aims to conceal identity information while preserving\nnon-identity attributes. Mainstream diffusion models rely on inference-time\ninterventions such as negative guidance or energy-based optimization, which are\napplied post-training to suppress identity features. These interventions often\nintroduce distribution shifts and entangle identity with non-identity\nattributes, degrading visual fidelity and data utility. To address this, we\npropose \\textbf{ID\\textsuperscript{2}Face}, a training-centric anonymization\nframework that removes the need for inference-time optimization. The rationale\nof our method is to learn a structured latent space where identity and\nnon-identity information are explicitly disentangled, enabling direct and\ncontrollable anonymization at inference. To this end, we design a conditional\ndiffusion model with an identity-masked learning scheme. An Identity-Decoupled\nLatent Recomposer uses an Identity Variational Autoencoder to model identity\nfeatures, while non-identity attributes are extracted from same-identity pairs\nand aligned through bidirectional latent alignment. An Identity-Guided Latent\nHarmonizer then fuses these representations via soft-gating conditioned on\nnoisy feature prediction. The model is trained with a recomposition-based\nreconstruction loss to enforce disentanglement. At inference, anonymization is\nachieved by sampling a random identity vector from the learned identity space.\nTo further suppress identity leakage, we introduce an Orthogonal Identity\nMapping strategy that enforces orthogonality between sampled and source\nidentity vectors. Experiments demonstrate that ID\\textsuperscript{2}Face\noutperforms existing methods in visual quality, identity suppression, and\nutility preservation.",
    "published": "2025-10-28T09:28:12Z",
    "updated": "2025-10-28T09:28:12Z",
    "link": "http://arxiv.org/pdf/2510.24213v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Haoxin Yang",
      "Yihong Lin",
      "Jingdan Kang",
      "Xuemiao Xu",
      "Yue Li",
      "Cheng Xu",
      "Shengfeng He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24211v1",
    "title": "MC-SJD : Maximal Coupling Speculative Jacobi Decoding for Autoregressive\n  Visual Generation Acceleration",
    "summary": "While autoregressive (AR) modeling has recently emerged as a new paradigm in\nvisual generation, its practical adoption is severely constrained by the slow\ninference speed of per-token generation, which often requires thousands of\nsteps to produce a single sample. To address this challenge, we propose MC-SJD,\na training-free, lossless parallel decoding framework designed to accelerate AR\nvisual generation by extending the recently introduced Speculative Jacobi\nDecoding (SJD). Although SJD shows strong potential for accelerating AR\ngeneration, we demonstrate that token instability across iterations\nsignificantly reduces the acceptance rate, a limitation that primarily arises\nfrom the independent sampling process used during draft token generation. To\novercome this, we introduce MC-SJD, an information-theoretic approach based on\ncoupling, which substantially accelerates standard SJD by maximizing the\nprobability of sampling identical draft tokens across consecutive iterations,\nall while preserving its lossless property. Remarkably, this method requires\nonly a single-line modification to the existing algorithm, yet achieves\nsubstantial performance gains, delivering up to a ~4.2x acceleration in image\ngeneration and ~13.3x acceleration in video generation compared to standard AR\ndecoding, without any degradation in output quality.",
    "published": "2025-10-28T09:26:27Z",
    "updated": "2025-10-28T09:26:27Z",
    "link": "http://arxiv.org/pdf/2510.24211v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Junhyuk So",
      "Hyunho Kook",
      "Chaeyeon Jang",
      "Eunhyeok Park"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24202v1",
    "title": "CLFSeg: A Fuzzy-Logic based Solution for Boundary Clarity and\n  Uncertainty Reduction in Medical Image Segmentation",
    "summary": "Accurate polyp and cardiac segmentation for early detection and treatment is\nessential for the diagnosis and treatment planning of cancer-like diseases.\nTraditional convolutional neural network (CNN) based models have represented\nlimited generalizability, robustness, and inability to handle uncertainty,\nwhich affects the segmentation performance. To solve these problems, this paper\nintroduces CLFSeg, an encoder-decoder based framework that aggregates the\nFuzzy-Convolutional (FC) module leveraging convolutional layers and fuzzy\nlogic. This module enhances the segmentation performance by identifying local\nand global features while minimizing the uncertainty, noise, and ambiguity in\nboundary regions, ensuring computing efficiency. In order to handle class\nimbalance problem while focusing on the areas of interest with tiny and\nboundary regions, binary cross-entropy (BCE) with dice loss is incorporated.\nOur proposed model exhibits exceptional performance on four publicly available\ndatasets, including CVC-ColonDB, CVC-ClinicDB, EtisLaribPolypDB, and ACDC.\nExtensive experiments and visual studies show CLFSeg surpasses the existing\nSOTA performance and focuses on relevant regions of interest in anatomical\nstructures. The proposed CLFSeg improves performance while ensuring computing\nefficiency, which makes it a potential solution for real-world medical\ndiagnostic scenarios. Project page is available at\nhttps://visdomlab.github.io/CLFSeg/",
    "published": "2025-10-28T09:06:27Z",
    "updated": "2025-10-28T09:06:27Z",
    "link": "http://arxiv.org/pdf/2510.24202v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Anshul Kaushal",
      "Kunal Jangid",
      "Vinod K. Kurmi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24195v1",
    "title": "Vanish into Thin Air: Cross-prompt Universal Adversarial Attacks for\n  SAM2",
    "summary": "Recent studies reveal the vulnerability of the image segmentation foundation\nmodel SAM to adversarial examples. Its successor, SAM2, has attracted\nsignificant attention due to its strong generalization capability in video\nsegmentation. However, its robustness remains unexplored, and it is unclear\nwhether existing attacks on SAM can be directly transferred to SAM2. In this\npaper, we first analyze the performance gap of existing attacks between SAM and\nSAM2 and highlight two key challenges arising from their architectural\ndifferences: directional guidance from the prompt and semantic entanglement\nacross consecutive frames. To address these issues, we propose UAP-SAM2, the\nfirst cross-prompt universal adversarial attack against SAM2 driven by dual\nsemantic deviation. For cross-prompt transferability, we begin by designing a\ntarget-scanning strategy that divides each frame into k regions, each randomly\nassigned a prompt, to reduce prompt dependency during optimization. For\neffectiveness, we design a dual semantic deviation framework that optimizes a\nUAP by distorting the semantics within the current frame and disrupting the\nsemantic consistency across consecutive frames. Extensive experiments on six\ndatasets across two segmentation tasks demonstrate the effectiveness of the\nproposed method for SAM2. The comparative results show that UAP-SAM2\nsignificantly outperforms state-of-the-art (SOTA) attacks by a large margin.",
    "published": "2025-10-28T08:59:11Z",
    "updated": "2025-10-28T08:59:11Z",
    "link": "http://arxiv.org/pdf/2510.24195v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ziqi Zhou",
      "Yifan Hu",
      "Yufei Song",
      "Zijing Li",
      "Shengshan Hu",
      "Leo Yu Zhang",
      "Dezhong Yao",
      "Long Zheng",
      "Hai Jin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.12841v2",
    "title": "AnyCap Project: A Unified Framework, Dataset, and Benchmark for\n  Controllable Omni-modal Captioning",
    "summary": "Controllable captioning is essential for precise multimodal alignment and\ninstruction following, yet existing models often lack fine-grained control and\nreliable evaluation protocols. To address this gap, we present the AnyCap\nProject, an integrated solution spanning model, dataset, and evaluation. We\nintroduce AnyCapModel (ACM), a lightweight plug-and-play framework that\nenhances the controllability of existing foundation models for omni-modal\ncaptioning without retraining the base model. ACM reuses the original captions\nfrom base models while incorporating user instructions and modality features to\ngenerate improved captions. To remedy the data scarcity in controllable\nmultimodal captioning, we build AnyCapDataset (ACD), covering three modalities,\n28 user-instruction types, and 300\\,k high-quality data entries. We further\npropose AnyCapEval, a new benchmark that provides more reliable evaluation\nmetrics for controllable captioning by decoupling content accuracy and\nstylistic fidelity. ACM markedly improves caption quality across a diverse set\nof base models on AnyCapEval. Notably, ACM-8B raises GPT-4o\\'s content scores\nby 45\\% and style scores by 12\\%, and it also achieves substantial gains on\nwidely used benchmarks such as MIA-Bench and VidCapBench.",
    "published": "2025-07-17T07:04:05Z",
    "updated": "2025-10-28T08:46:18Z",
    "link": "http://arxiv.org/pdf/2507.12841v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yiming Ren",
      "Zhiqiang Lin",
      "Yu Li",
      "Gao Meng",
      "Weiyun Wang",
      "Junjie Wang",
      "Zicheng Lin",
      "Jifeng Dai",
      "Yujiu Yang",
      "Wenhai Wang",
      "Ruihang Chu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.08930v2",
    "title": "Acoustic Neural 3D Reconstruction Under Pose Drift",
    "summary": "We consider the problem of optimizing neural implicit surfaces for 3D\nreconstruction using acoustic images collected with drifting sensor poses. The\naccuracy of current state-of-the-art 3D acoustic modeling algorithms is highly\ndependent on accurate pose estimation; small errors in sensor pose can lead to\nsevere reconstruction artifacts. In this paper, we propose an algorithm that\njointly optimizes the neural scene representation and sonar poses. Our\nalgorithm does so by parameterizing the 6DoF poses as learnable parameters and\nbackpropagating gradients through the neural renderer and implicit\nrepresentation. We validated our algorithm on both real and simulated datasets.\nIt produces high-fidelity 3D reconstructions even under significant pose drift.",
    "published": "2025-03-11T22:18:57Z",
    "updated": "2025-10-28T08:30:20Z",
    "link": "http://arxiv.org/pdf/2503.08930v2.pdf",
    "category": [
      "eess.SP",
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Tianxiang Lin",
      "Mohamad Qadri",
      "Kevin Zhang",
      "Adithya Pediredla",
      "Christopher A. Metzler",
      "Michael Kaess"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.09336v3",
    "title": "Stealthy Patch-Wise Backdoor Attack in 3D Point Cloud via Curvature\n  Awareness",
    "summary": "Backdoor attacks pose a severe threat to deep neural networks (DNNs) by\nimplanting hidden backdoors that can be activated with predefined triggers to\nmanipulate model behaviors maliciously. Existing 3D point cloud backdoor\nattacks primarily rely on sample-wise global modifications, which suffer from\nlow imperceptibility. Although optimization can improve stealthiness,\noptimizing sample-wise triggers significantly increases computational cost. To\naddress these limitations, we propose the Stealthy Patch-Wise Backdoor Attack\n(SPBA), the first patch-wise backdoor attack framework for 3D point clouds.\nSpecifically, SPBA decomposes point clouds into local patches and employs a\ncurvature-based imperceptibility score to guide trigger injection into visually\nless sensitive patches. By optimizing a unified patch-wise trigger that\nperturbs spectral features of selected patches, SPBA significantly enhances\noptimization efficiency while maintaining high stealthiness. Extensive\nexperiments on ModelNet40 and ShapeNetPart further demonstrate that SPBA\nsurpasses prior state-of-the-art backdoor attacks in both attack effectiveness\nand resistance to defense methods. The code is available at\nhttps://github.com/HazardFY/SPBA.",
    "published": "2025-03-12T12:30:59Z",
    "updated": "2025-10-28T08:24:48Z",
    "link": "http://arxiv.org/pdf/2503.09336v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yu Feng",
      "Dingxin Zhang",
      "Runkai Zhao",
      "Yong Xia",
      "Heng Huang",
      "Weidong Cai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.15256v2",
    "title": "Normal and Abnormal Pathology Knowledge-Augmented Vision-Language Model\n  for Anomaly Detection in Pathology Images",
    "summary": "Anomaly detection in computational pathology aims to identify rare and scarce\nanomalies where disease-related data are often limited or missing. Existing\nanomaly detection methods, primarily designed for industrial settings, face\nlimitations in pathology due to computational constraints, diverse tissue\nstructures, and lack of interpretability. To address these challenges, we\npropose Ano-NAViLa, a Normal and Abnormal pathology knowledge-augmented\nVision-Language model for Anomaly detection in pathology images. Ano-NAViLa is\nbuilt on a pre-trained vision-language model with a lightweight trainable MLP.\nBy incorporating both normal and abnormal pathology knowledge, Ano-NAViLa\nenhances accuracy and robustness to variability in pathology images and\nprovides interpretability through image-text associations. Evaluated on two\nlymph node datasets from different organs, Ano-NAViLa achieves the\nstate-of-the-art performance in anomaly detection and localization,\noutperforming competing models.",
    "published": "2025-08-21T05:40:23Z",
    "updated": "2025-10-28T08:08:14Z",
    "link": "http://arxiv.org/pdf/2508.15256v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jinsol Song",
      "Jiamu Wang",
      "Anh Tien Nguyen",
      "Keunho Byeon",
      "Sangjeong Ahn",
      "Sung Hak Lee",
      "Jin Tae Kwak"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.05229v2",
    "title": "Does CLIP perceive art the same way we do?",
    "summary": "CLIP has emerged as a powerful multimodal model capable of connecting images\nand text through joint embeddings, but to what extent does it 'see' the same\nway humans do - especially when interpreting artworks? In this paper, we\ninvestigate CLIP's ability to extract high-level semantic and stylistic\ninformation from paintings, including both human-created and AI-generated\nimagery. We evaluate its perception across multiple dimensions: content, scene\nunderstanding, artistic style, historical period, and the presence of visual\ndeformations or artifacts. By designing targeted probing tasks and comparing\nCLIP's responses to human annotations and expert benchmarks, we explore its\nalignment with human perceptual and contextual understanding. Our findings\nreveal both strengths and limitations in CLIP's visual representations,\nparticularly in relation to aesthetic cues and artistic intent. We further\ndiscuss the implications of these insights for using CLIP as a guidance\nmechanism during generative processes, such as style transfer or prompt-based\nimage synthesis. Our work highlights the need for deeper interpretability in\nmultimodal systems, especially when applied to creative domains where nuance\nand subjectivity play a central role.",
    "published": "2025-05-08T13:21:10Z",
    "updated": "2025-10-28T08:05:02Z",
    "link": "http://arxiv.org/pdf/2505.05229v2.pdf",
    "category": [
      "cs.CV",
      "cs.MM",
      "68T45, 68T07 (Primary) 68T50, 68U10 (Secondary)",
      "I.2.7; I.2.10"
    ],
    "authors": [
      "Andrea Asperti",
      "Leonardo DessÃ¬",
      "Maria Chiara Tonetti",
      "Nico Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.22035v2",
    "title": "Caption-Driven Explainability: Probing CNNs for Bias via CLIP",
    "summary": "Robustness has become one of the most critical problems in machine learning\n(ML). The science of interpreting ML models to understand their behavior and\nimprove their robustness is referred to as explainable artificial intelligence\n(XAI). One of the state-of-the-art XAI methods for computer vision problems is\nto generate saliency maps. A saliency map highlights the pixel space of an\nimage that excites the ML model the most. However, this property could be\nmisleading if spurious and salient features are present in overlapping pixel\nspaces. In this paper, we propose a caption-based XAI method, which integrates\na standalone model to be explained into the contrastive language-image\npre-training (CLIP) model using a novel network surgery approach. The resulting\ncaption-based XAI model identifies the dominant concept that contributes the\nmost to the models prediction. This explanation minimizes the risk of the\nstandalone model falling for a covariate shift and contributes significantly\ntowards developing robust ML models. Our code is available at\n<https://github.com/patch0816/caption-driven-xai>.",
    "published": "2025-10-24T21:41:32Z",
    "updated": "2025-10-28T07:52:08Z",
    "link": "http://arxiv.org/pdf/2510.22035v2.pdf",
    "category": [
      "cs.CV",
      "eess.IV",
      "I.2.6; I.2.8; I.2.10; I.4.8"
    ],
    "authors": [
      "Patrick Koller",
      "Amil V. Dravid",
      "Guido M. Schuster",
      "Aggelos K. Katsaggelos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2401.09962v3",
    "title": "CustomVideo: Customizing Text-to-Video Generation with Multiple Subjects",
    "summary": "Customized text-to-video generation aims to generate high-quality videos\nguided by text prompts and subject references. Current approaches for\npersonalizing text-to-video generation suffer from tackling multiple subjects,\nwhich is a more challenging and practical scenario. In this work, our aim is to\npromote multi-subject guided text-to-video customization. We propose\nCustomVideo, a novel framework that can generate identity-preserving videos\nwith the guidance of multiple subjects. To be specific, firstly, we encourage\nthe co-occurrence of multiple subjects via composing them in a single image.\nFurther, upon a basic text-to-video diffusion model, we design a simple yet\neffective attention control strategy to disentangle different subjects in the\nlatent space of diffusion model. Moreover, to help the model focus on the\nspecific area of the object, we segment the object from given reference images\nand provide a corresponding object mask for attention learning. Also, we\ncollect a multi-subject text-to-video generation dataset as a comprehensive\nbenchmark. Extensive qualitative, quantitative, and user study results\ndemonstrate the superiority of our method compared to previous state-of-the-art\napproaches. The project page is https://kyfafyd.wang/projects/customvideo.",
    "published": "2024-01-18T13:23:51Z",
    "updated": "2025-10-28T07:47:22Z",
    "link": "http://arxiv.org/pdf/2401.09962v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhao Wang",
      "Aoxue Li",
      "Lingting Zhu",
      "Yong Guo",
      "Qi Dou",
      "Zhenguo Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.18384v2",
    "title": "LiDAR Remote Sensing Meets Weak Supervision: Concepts, Methods, and\n  Perspectives",
    "summary": "Light detection and ranging (LiDAR) remote sensing encompasses two major\ndirections: data interpretation and parameter inversion. However, both\ndirections rely heavily on costly and labor-intensive labeled data and field\nmeasurements, which constrains their scalability and spatiotemporal\nadaptability. Weakly Supervised Learning (WSL) provides a unified framework to\naddress these limitations. This paper departs from the traditional view that\ntreats interpretation and inversion as separate tasks and offers a systematic\nreview of recent advances in LiDAR remote sensing from a unified WSL\nperspective. We cover typical WSL settings including incomplete\nsupervision(e.g., sparse point labels), inexact supervision (e.g., scene-level\ntags), inaccurate supervision (e.g., noisy labels), and cross-domain\nsupervision (e.g., domain adaptation/generalization) and corresponding\ntechniques such as pseudo-labeling, consistency regularization, self-training,\nand label refinement, which collectively enable robust learning from limited\nand weak annotations.We further analyze LiDAR-specific challenges (e.g.,\nirregular geometry, data sparsity, domain heterogeneity) that require tailored\nweak supervision, and examine how sparse LiDAR observations can guide joint\nlearning with other remote-sensing data for continuous surface-parameter\nretrieval. Finally, we highlight future directions where WSL acts as a bridge\nbetween LiDAR and foundation models to leverage large-scale multimodal datasets\nand reduce labeling costs, while also enabling broader WSL-driven advances in\ngeneralization, open-world adaptation, and scalable LiDAR remote sensing.",
    "published": "2025-03-24T06:51:38Z",
    "updated": "2025-10-28T07:24:00Z",
    "link": "http://arxiv.org/pdf/2503.18384v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yuan Gao",
      "Shaobo Xia",
      "Pu Wang",
      "Xiaohuan Xi",
      "Sheng Nie",
      "Cheng Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24136v1",
    "title": "MSRANetV2: An Explainable Deep Learning Architecture for Multi-class\n  Classification of Colorectal Histopathological Images",
    "summary": "Colorectal cancer (CRC) is a leading worldwide cause of cancer-related\nmortality, and the role of prompt precise detection is of paramount interest in\nimproving patient outcomes. Conventional diagnostic methods such as colonoscopy\nand histological examination routinely exhibit subjectivity, are extremely\ntime-consuming, and are susceptible to variation. Through the development of\ndigital pathology, deep learning algorithms have become a powerful approach in\nenhancing diagnostic precision and efficiency. In our work, we proposed a\nconvolutional neural network architecture named MSRANetV2, specially optimized\nfor the classification of colorectal tissue images. The model employs a\nResNet50V2 backbone, extended with residual attention mechanisms and\nsqueeze-and-excitation (SE) blocks, to extract deep semantic and fine-grained\nspatial features. With channel alignment and upsampling operations, MSRANetV2\neffectively fuses multi-scale representations, thereby enhancing the robustness\nof the classification. We evaluated our model on a five-fold stratified\ncross-validation strategy on two publicly available datasets: CRC-VAL-HE-7K and\nNCT-CRC-HE-100K. The proposed model achieved remarkable average Precision,\nrecall, F1-score, AUC, and test accuracy were 0.9884 plus-minus 0.0151, 0.9900\nplus-minus 0.0151, 0.9900 plus-minus 0.0145, 0.9999 plus-minus 0.00006, and\n0.9905 plus-minus 0.0025 on the 7K dataset. On the 100K dataset, they were\n0.9904 plus-minus 0.0091, 0.9900 plus-minus 0.0071, 0.9900 plus-minus 0.0071,\n0.9997 plus-minus 0.00016, and 0.9902 plus-minus 0.0006. Additionally, Grad-CAM\nvisualizations were incorporated to enhance model interpretability by\nhighlighting tissue areas that are medically relevant. These findings validate\nthat MSRANetV2 is a reliable, interpretable, and high-performing architectural\nmodel for classifying CRC tissues.",
    "published": "2025-10-28T07:22:34Z",
    "updated": "2025-10-28T07:22:34Z",
    "link": "http://arxiv.org/pdf/2510.24136v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ovi Sarkar",
      "Md Shafiuzzaman",
      "Md. Faysal Ahamed",
      "Golam Mahmud",
      "Muhammad E. H. Chowdhury"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.14431v2",
    "title": "Real-Time Neural Video Compression with Unified Intra and Inter Coding",
    "summary": "Neural video compression (NVC) technologies have advanced rapidly in recent\nyears, yielding state-of-the-art schemes such as DCVC-RT that offer superior\ncompression efficiency to H.266/VVC and real-time encoding/decoding\ncapabilities. Nonetheless, existing NVC schemes have several limitations,\nincluding inefficiency in dealing with disocclusion and new content, interframe\nerror propagation and accumulation, among others. To eliminate these\nlimitations, we borrow the idea from classic video coding schemes, which allow\nintra coding within inter-coded frames. With the intra coding tool enabled,\ndisocclusion and new content are properly handled, and interframe error\npropagation is naturally intercepted without the need for manual refresh\nmechanisms. We present an NVC framework with unified intra and inter coding,\nwhere every frame is processed by a single model that is trained to perform\nintra/inter coding adaptively. Moreover, we propose a simultaneous two-frame\ncompression design to exploit interframe redundancy not only forwardly but also\nbackwardly. Experimental results show that our scheme outperforms DCVC-RT by an\naverage of 10.7\\% BD-rate reduction, delivers more stable bitrate and quality\nper frame, and retains real-time encoding/decoding performances. Code and\nmodels will be released.",
    "published": "2025-10-16T08:31:44Z",
    "updated": "2025-10-28T07:17:14Z",
    "link": "http://arxiv.org/pdf/2510.14431v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Hui Xiang",
      "Yifan Bian",
      "Li Li",
      "Jingran Wu",
      "Xianguo Zhang",
      "Dong Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24129v1",
    "title": "ETC: training-free diffusion models acceleration with Error-aware Trend\n  Consistency",
    "summary": "Diffusion models have achieved remarkable generative quality but remain\nbottlenecked by costly iterative sampling. Recent training-free methods\naccelerate diffusion process by reusing model outputs. However, these methods\nignore denoising trends and lack error control for model-specific tolerance,\nleading to trajectory deviations under multi-step reuse and exacerbating\ninconsistencies in the generated results. To address these issues, we introduce\nError-aware Trend Consistency (ETC), a framework that (1) introduces a\nconsistent trend predictor that leverages the smooth continuity of diffusion\ntrajectories, projecting historical denoising patterns into stable future\ndirections and progressively distributing them across multiple approximation\nsteps to achieve acceleration without deviating; (2) proposes a model-specific\nerror tolerance search mechanism that derives corrective thresholds by\nidentifying transition points from volatile semantic planning to stable quality\nrefinement. Experiments show that ETC achieves a 2.65x acceleration over FLUX\nwith negligible (-0.074 SSIM score) degradation of consistency.",
    "published": "2025-10-28T07:08:09Z",
    "updated": "2025-10-28T07:08:09Z",
    "link": "http://arxiv.org/pdf/2510.24129v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jiajian Xie",
      "Hubery Yin",
      "Chen Li",
      "Zhou Zhao",
      "Shengyu Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2402.02096v2",
    "title": "UMCFuse: A Unified Multiple Complex Scenes Infrared and Visible Image\n  Fusion Framework",
    "summary": "Infrared and visible image fusion has emerged as a prominent research area in\ncomputer vision. However, little attention has been paid to the fusion task in\ncomplex scenes, leading to sub-optimal results under interference. To fill this\ngap, we propose a unified framework for infrared and visible images fusion in\ncomplex scenes, termed UMCFuse. Specifically, we classify the pixels of visible\nimages from the degree of scattering of light transmission, allowing us to\nseparate fine details from overall intensity. Maintaining a balance between\ninterference removal and detail preservation is essential for the\ngeneralization capacity of the proposed method. Therefore, we propose an\nadaptive denoising strategy for the fusion of detail layers. Meanwhile, we fuse\nthe energy features from different modalities by analyzing them from multiple\ndirections. Extensive fusion experiments on real and synthetic complex scenes\ndatasets cover adverse weather conditions, noise, blur, overexposure, fire, as\nwell as downstream tasks including semantic segmentation, object detection,\nsalient object detection, and depth estimation, consistently indicate the\nsuperiority of the proposed method compared with the recent representative\nmethods. Our code is available at https://github.com/ixilai/UMCFuse.",
    "published": "2024-02-03T09:27:33Z",
    "updated": "2025-10-28T06:51:19Z",
    "link": "http://arxiv.org/pdf/2402.02096v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xilai Li",
      "Xiaosong Li",
      "Tianshu Tan",
      "Huafeng Li",
      "Tao Ye"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24117v1",
    "title": "DogMo: A Large-Scale Multi-View RGB-D Dataset for 4D Canine Motion\n  Recovery",
    "summary": "We present DogMo, a large-scale multi-view RGB-D video dataset capturing\ndiverse canine movements for the task of motion recovery from images. DogMo\ncomprises 1.2k motion sequences collected from 10 unique dogs, offering rich\nvariation in both motion and breed. It addresses key limitations of existing\ndog motion datasets, including the lack of multi-view and real 3D data, as well\nas limited scale and diversity. Leveraging DogMo, we establish four motion\nrecovery benchmark settings that support systematic evaluation across monocular\nand multi-view, RGB and RGB-D inputs. To facilitate accurate motion recovery,\nwe further introduce a three-stage, instance-specific optimization pipeline\nthat fits the SMAL model to the motion sequences. Our method progressively\nrefines body shape and pose through coarse alignment, dense correspondence\nsupervision, and temporal regularization. Our dataset and method provide a\nprincipled foundation for advancing research in dog motion recovery and open up\nnew directions at the intersection of computer vision, computer graphics, and\nanimal behavior modeling.",
    "published": "2025-10-28T06:41:49Z",
    "updated": "2025-10-28T06:41:49Z",
    "link": "http://arxiv.org/pdf/2510.24117v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zan Wang",
      "Siyu Chen",
      "Luya Mo",
      "Xinfeng Gao",
      "Yuxin Shen",
      "Lebin Ding",
      "Wei Liang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24116v1",
    "title": "UHKD: A Unified Framework for Heterogeneous Knowledge Distillation via\n  Frequency-Domain Representations",
    "summary": "Knowledge distillation (KD) is an effective model compression technique that\ntransfers knowledge from a high-performance teacher to a lightweight student,\nreducing cost while maintaining accuracy. In visual applications, where\nlarge-scale image models are widely used, KD enables efficient deployment.\nHowever, architectural diversity introduces semantic discrepancies that hinder\nthe use of intermediate representations. Most existing KD methods are designed\nfor homogeneous models and degrade in heterogeneous scenarios, especially when\nintermediate features are involved. Prior studies mainly focus on the logits\nspace, making limited use of the semantic information in intermediate layers.\nTo address this limitation, Unified Heterogeneous Knowledge Distillation (UHKD)\nis proposed as a framework that leverages intermediate features in the\nfrequency domain for cross-architecture transfer. Fourier transform is applied\nto capture global feature information, alleviating representational\ndiscrepancies between heterogeneous teacher-student pairs. A Feature\nTransformation Module (FTM) produces compact frequency-domain representations\nof teacher features, while a learnable Feature Alignment Module (FAM) projects\nstudent features and aligns them via multi-level matching. Training is guided\nby a joint objective combining mean squared error on intermediate features with\nKullback-Leibler divergence on logits. Experiments on CIFAR-100 and ImageNet-1K\ndemonstrate gains of 5.59% and 0.83% over the latest method, highlighting UHKD\nas an effective approach for unifying heterogeneous representations and\nenabling efficient utilization of visual knowledge",
    "published": "2025-10-28T06:41:43Z",
    "updated": "2025-10-28T06:41:43Z",
    "link": "http://arxiv.org/pdf/2510.24116v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Fengming Yu",
      "Haiwei Pan",
      "Kejia Zhang",
      "Jian Guan",
      "Haiying Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.12758v4",
    "title": "Global urban visual perception varies across demographics and\n  personalities",
    "summary": "Understanding people's preferences is crucial for urban planning, yet current\napproaches often combine responses from multi-cultural populations, obscuring\ndemographic differences and risking amplifying biases. We conducted a\nlargescale urban visual perception survey of streetscapes worldwide using\nstreet view imagery, examining how demographics -- including gender, age,\nincome, education, race and ethnicity, and personality traits -- shape\nperceptions among 1,000 participants with balanced demographics from five\ncountries and 45 nationalities. This dataset, Street Perception Evaluation\nConsidering Socioeconomics (SPECS), reveals demographic- and personality-based\ndifferences across six traditional indicators -- safe, lively, wealthy,\nbeautiful, boring, depressing -- and four new ones -- live nearby, walk, cycle,\ngreen. Location-based sentiments further shape these preferences. Machine\nlearning models trained on existing global datasets tend to overestimate\npositive indicators and underestimate negative ones compared to human\nresponses, underscoring the need for local context. Our study aspires to\nrectify the myopic treatment of street perception, which rarely considers\ndemographics or personality traits.",
    "published": "2025-05-19T06:35:11Z",
    "updated": "2025-10-28T06:27:55Z",
    "link": "http://arxiv.org/pdf/2505.12758v4.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Matias Quintana",
      "Youlong Gu",
      "Xiucheng Liang",
      "Yujun Hou",
      "Koichi Ito",
      "Yihan Zhu",
      "Mahmoud Abdelrahman",
      "Filip Biljecki"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24108v1",
    "title": "ZTRS: Zero-Imitation End-to-end Autonomous Driving with Trajectory\n  Scoring",
    "summary": "End-to-end autonomous driving maps raw sensor inputs directly into\nego-vehicle trajectories to avoid cascading errors from perception modules and\nto leverage rich semantic cues. Existing frameworks largely rely on Imitation\nLearning (IL), which can be limited by sub-optimal expert demonstrations and\ncovariate shift during deployment. On the other hand, Reinforcement Learning\n(RL) has recently shown potential in scaling up with simulations, but is\ntypically confined to low-dimensional symbolic inputs (e.g. 3D objects and\nmaps), falling short of full end-to-end learning from raw sensor data. We\nintroduce ZTRS (Zero-Imitation End-to-End Autonomous Driving with Trajectory\nScoring), a framework that combines the strengths of both worlds: sensor inputs\nwithout losing information and RL training for robust planning. To the best of\nour knowledge, ZTRS is the first framework that eliminates IL entirely by only\nlearning from rewards while operating directly on high-dimensional sensor data.\nZTRS utilizes offline reinforcement learning with our proposed Exhaustive\nPolicy Optimization (EPO), a variant of policy gradient tailored for enumerable\nactions and rewards. ZTRS demonstrates strong performance across three\nbenchmarks: Navtest (generic real-world open-loop planning), Navhard (open-loop\nplanning in challenging real-world and synthetic scenarios), and HUGSIM\n(simulated closed-loop driving). Specifically, ZTRS achieves the\nstate-of-the-art result on Navhard and outperforms IL-based baselines on\nHUGSIM. Code will be available at https://github.com/woxihuanjiangguo/ZTRS.",
    "published": "2025-10-28T06:26:36Z",
    "updated": "2025-10-28T06:26:36Z",
    "link": "http://arxiv.org/pdf/2510.24108v1.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Zhenxin Li",
      "Wenhao Yao",
      "Zi Wang",
      "Xinglong Sun",
      "Jingde Chen",
      "Nadine Chang",
      "Maying Shen",
      "Jingyu Song",
      "Zuxuan Wu",
      "Shiyi Lan",
      "Jose M. Alvarez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24105v1",
    "title": "Enhancing Pre-trained Representation Classifiability can Boost its\n  Interpretability",
    "summary": "The visual representation of a pre-trained model prioritizes the\nclassifiability on downstream tasks, while the widespread applications for\npre-trained visual models have posed new requirements for representation\ninterpretability. However, it remains unclear whether the pre-trained\nrepresentations can achieve high interpretability and classifiability\nsimultaneously. To answer this question, we quantify the representation\ninterpretability by leveraging its correlation with the ratio of interpretable\nsemantics within the representations. Given the pre-trained representations,\nonly the interpretable semantics can be captured by interpretations, whereas\nthe uninterpretable part leads to information loss. Based on this fact, we\npropose the Inherent Interpretability Score (IIS) that evaluates the\ninformation loss, measures the ratio of interpretable semantics, and quantifies\nthe representation interpretability. In the evaluation of the representation\ninterpretability with different classifiability, we surprisingly discover that\nthe interpretability and classifiability are positively correlated, i.e.,\nrepresentations with higher classifiability provide more interpretable\nsemantics that can be captured in the interpretations. This observation further\nsupports two benefits to the pre-trained representations. First, the\nclassifiability of representations can be further improved by fine-tuning with\ninterpretability maximization. Second, with the classifiability improvement for\nthe representations, we obtain predictions based on their interpretations with\nless accuracy degradation. The discovered positive correlation and\ncorresponding applications show that practitioners can unify the improvements\nin interpretability and classifiability for pre-trained vision models. Codes\nare available at https://github.com/ssfgunner/IIS.",
    "published": "2025-10-28T06:21:06Z",
    "updated": "2025-10-28T06:21:06Z",
    "link": "http://arxiv.org/pdf/2510.24105v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Shufan Shen",
      "Zhaobo Qi",
      "Junshu Sun",
      "Qingming Huang",
      "Qi Tian",
      "Shuhui Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23118v2",
    "title": "Task-Agnostic Fusion of Time Series and Imagery for Earth Observation",
    "summary": "We propose a task-agnostic framework for multimodal fusion of time series and\nsingle timestamp images, enabling cross-modal generation and robust downstream\nperformance. Our approach explores deterministic and learned strategies for\ntime series quantization and then leverages a masked correlation learning\nobjective, aligning discrete image and time series tokens in a unified\nrepresentation space. Instantiated in the Earth observation domain, the\npretrained model generates consistent global temperature profiles from\nsatellite imagery and is validated through counterfactual experiments. Across\ndownstream tasks, our task-agnostic pretraining outperforms task-specific\nfusion by 6% in R^2 and 2% in RMSE on average, and exceeds baseline methods by\n50\\% in R$^2$ and 12\\% in RMSE. Finally, we analyze gradient sensitivity across\nmodalities, providing insights into model robustness. Code, data, and weights\nwill be released under a permissive license.",
    "published": "2025-10-27T08:38:52Z",
    "updated": "2025-10-28T06:10:07Z",
    "link": "http://arxiv.org/pdf/2510.23118v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Gianfranco Basile",
      "Johannes Jakubik",
      "Benedikt Blumenstiel",
      "Thomas Brunschwiler",
      "Juan Bernabe Moreno"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24093v1",
    "title": "OmniText: A Training-Free Generalist for Controllable Text-Image\n  Manipulation",
    "summary": "Recent advancements in diffusion-based text synthesis have demonstrated\nsignificant performance in inserting and editing text within images via\ninpainting. However, despite the potential of text inpainting methods, three\nkey limitations hinder their applicability to broader Text Image Manipulation\n(TIM) tasks: (i) the inability to remove text, (ii) the lack of control over\nthe style of rendered text, and (iii) a tendency to generate duplicated\nletters. To address these challenges, we propose OmniText, a training-free\ngeneralist capable of performing a wide range of TIM tasks. Specifically, we\ninvestigate two key properties of cross- and self-attention mechanisms to\nenable text removal and to provide control over both text styles and content.\nOur findings reveal that text removal can be achieved by applying\nself-attention inversion, which mitigates the model's tendency to focus on\nsurrounding text, thus reducing text hallucinations. Additionally, we\nredistribute cross-attention, as increasing the probability of certain text\ntokens reduces text hallucination. For controllable inpainting, we introduce\nnovel loss functions in a latent optimization framework: a cross-attention\ncontent loss to improve text rendering accuracy and a self-attention style loss\nto facilitate style customization. Furthermore, we present OmniText-Bench, a\nbenchmark dataset for evaluating diverse TIM tasks. It includes input images,\ntarget text with masks, and style references, covering diverse applications\nsuch as text removal, rescaling, repositioning, and insertion and editing with\nvarious styles. Our OmniText framework is the first generalist method capable\nof performing diverse TIM tasks. It achieves state-of-the-art performance\nacross multiple tasks and metrics compared to other text inpainting methods and\nis comparable with specialist methods.",
    "published": "2025-10-28T06:06:52Z",
    "updated": "2025-10-28T06:06:52Z",
    "link": "http://arxiv.org/pdf/2510.24093v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Agus Gunawan",
      "Samuel Teodoro",
      "Yun Chen",
      "Soo Ye Kim",
      "Jihyong Oh",
      "Munchurl Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.17102v2",
    "title": "GRASP: Geospatial pixel Reasoning viA Structured Policy learning",
    "summary": "Geospatial pixel reasoning aims to generate segmentation masks in remote\nsensing imagery directly from natural-language instructions. Most existing\napproaches follow a paradigm that fine-tunes multimodal large language models\nunder supervision with dense pixel-level masks as ground truth. While effective\nwithin the training data distribution, this design suffers from two main\ndrawbacks: (1) the high cost of large-scale dense mask annotation, and (2) the\nlimited generalization capability of supervised fine-tuning in out-of-domain\nscenarios. To address these issues, we propose GRASP, a structured\npolicy-learning framework that integrates a multimodal large language model\nwith a pretrained segmentation model in a cascaded manner. To enhance\ngeneralization, we introduce PRIME, a training paradigm that replaces\nsupervised fine-tuning with reinforcement learning to better align reasoning\nand grounding behaviors with task objectives. To reduce annotation costs, we\ndesign BoP-Rewards, which substitutes dense mask labels with bounding box and\npositive points. It further verifies outputs through two complementary signals:\nformat, which constrains the reasoning and grounding structure to remain\nsyntactically parsable, and accuracy, which evaluates the quality of predicted\nboxes and points. For evaluation, we train our method and all baselines on\nEarthReason and GeoPixInstruct, constructing an in-domain benchmark by merging\ntheir test sets. We further release GRASP-1k, a fully out-of-domain benchmark\nwith reasoning-intensive queries, reasoning traces, and fine-grained masks.\nExperimental results demonstrate state-of-the-art (SOTA) in-domain performance\nand up to 54\\% improvement in out-of-domain scenarios, confirming that\nreinforcement learning with cost-aware rewards provides a robust and scalable\nparadigm for geospatial pixel reasoning. All code and datasets will be released\npublicly.",
    "published": "2025-08-23T18:05:06Z",
    "updated": "2025-10-28T06:06:16Z",
    "link": "http://arxiv.org/pdf/2508.17102v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Chengjie Jiang",
      "Yunqi Zhou",
      "Jiafeng Yan",
      "Jing Li",
      "Jiayang Li",
      "Yue Zhou",
      "Hongjie He",
      "Jonathan Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.22943v2",
    "title": "Switchable Token-Specific Codebook Quantization For Face Image\n  Compression",
    "summary": "With the ever-increasing volume of visual data, the efficient and lossless\ntransmission, along with its subsequent interpretation and understanding, has\nbecome a critical bottleneck in modern information systems. The emerged\ncodebook-based solution utilize a globally shared codebook to quantize and\ndequantize each token, controlling the bpp by adjusting the number of tokens or\nthe codebook size. However, for facial images, which are rich in attributes,\nsuch global codebook strategies overlook both the category-specific\ncorrelations within images and the semantic differences among tokens, resulting\nin suboptimal performance, especially at low bpp. Motivated by these\nobservations, we propose a Switchable Token-Specific Codebook Quantization for\nface image compression, which learns distinct codebook groups for different\nimage categories and assigns an independent codebook to each token. By\nrecording the codebook group to which each token belongs with a small number of\nbits, our method can reduce the loss incurred when decreasing the size of each\ncodebook group. This enables a larger total number of codebooks under a lower\noverall bpp, thereby enhancing the expressive capability and improving\nreconstruction performance. Owing to its generalizable design, our method can\nbe integrated into any existing codebook-based representation learning approach\nand has demonstrated its effectiveness on face recognition datasets, achieving\nan average accuracy of 93.51% for reconstructed images at 0.05 bpp.",
    "published": "2025-10-27T02:56:17Z",
    "updated": "2025-10-28T05:57:57Z",
    "link": "http://arxiv.org/pdf/2510.22943v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yongbo Wang",
      "Haonan Wang",
      "Guodong Mu",
      "Ruixin Zhang",
      "Jiaqi Chen",
      "Jingyun Zhang",
      "Jun Wang",
      "Yuan Xie",
      "Zhizhong Zhang",
      "Shouhong Ding"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.12702v2",
    "title": "Long-RVOS: A Comprehensive Benchmark for Long-term Referring Video\n  Object Segmentation",
    "summary": "Referring video object segmentation (RVOS) aims to identify, track and\nsegment the objects in a video based on language descriptions, which has\nreceived great attention in recent years. However, existing datasets remain\nfocus on short video clips within several seconds, with salient objects visible\nin most frames. To advance the task towards more practical scenarios, we\nintroduce \\textbf{Long-RVOS}, a large-scale benchmark for long-term referring\nvideo object segmentation. Long-RVOS contains 2,000+ videos of an average\nduration exceeding 60 seconds, covering a variety of objects that undergo\nocclusion, disappearance-reappearance and shot changing. The objects are\nmanually annotated with three different types of descriptions to individually\nevaluate the understanding of static attributes, motion patterns and\nspatiotemporal relationships. Moreover, unlike previous benchmarks that rely\nsolely on the per-frame spatial evaluation, we introduce two new metrics to\nassess the temporal and spatiotemporal consistency. We benchmark 6\nstate-of-the-art methods on Long-RVOS. The results show that current approaches\nstruggle severely with the long-video challenges. To address this, we further\npropose ReferMo, a promising baseline method that integrates motion information\nto expand the temporal receptive field, and employs a local-to-global\narchitecture to capture both short-term dynamics and long-term dependencies.\nDespite simplicity, ReferMo achieves significant improvements over current\nmethods in long-term scenarios. We hope that Long-RVOS and our baseline can\ndrive future RVOS research towards tackling more realistic and long-form\nvideos.",
    "published": "2025-05-19T04:52:31Z",
    "updated": "2025-10-28T05:41:49Z",
    "link": "http://arxiv.org/pdf/2505.12702v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Tianming Liang",
      "Haichao Jiang",
      "Yuting Yang",
      "Chaolei Tan",
      "Shuai Li",
      "Wei-Shi Zheng",
      "Jian-Fang Hu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24078v1",
    "title": "Beyond Objects: Contextual Synthetic Data Generation for Fine-Grained\n  Classification",
    "summary": "Text-to-image (T2I) models are increasingly used for synthetic dataset\ngeneration, but generating effective synthetic training data for classification\nremains challenging. Fine-tuning a T2I model with a few real examples can help\nimprove the quality of synthetic training data; however, it may also cause\noverfitting and reduce diversity in the generated samples. We propose a\nfine-tuning strategy BOB (BeyondOBjects) to mitigate these concerns for\nfine-grained classification. Given a small set of real examples, we first\nextract class-agnostic attributes such as scene background and object pose. We\nthen explicitly condition on these attributes during fine-tuning of the T2I\nmodel and marginalize them out during generation. This design mitigates\noverfitting, preserves the T2I model's generative prior, reduces estimation\nerrors, and further minimizes unintended inter-class associations. Extensive\nexperiments across multiple T2I models, backbones, and datasets show that our\nmethod achieves state-of-the-art performance in low-shot fine-grained\nclassification when augmented with synthetic data. Concretely, BOB outperforms\nDataDream by 7.4% on the Aircraft dataset (from 50.0% to 57.4% when fine-tuning\na CLIP classifier with five real images augmented with 100 synthetic images).\nIn three of the four benchmarks, fine-tuning downstream models with 5 real\nimages augmented with BOB achieves better performance than fine-tuning with 10\nreal images. Collectively, BOB outperforms prior art in 18 of 24 experimental\nsettings, with 2+% accuracy improvements in 14 of these settings.",
    "published": "2025-10-28T05:40:14Z",
    "updated": "2025-10-28T05:40:14Z",
    "link": "http://arxiv.org/pdf/2510.24078v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "William Yang",
      "Xindi Wu",
      "Zhiwei Deng",
      "Esin Tureci",
      "Olga Russakovsky"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.06517v2",
    "title": "GS4: Generalizable Sparse Splatting Semantic SLAM",
    "summary": "Traditional SLAM algorithms excel at camera tracking, but typically produce\nincomplete and low-resolution maps that are not tightly integrated with\nsemantics prediction. Recent work integrates Gaussian Splatting (GS) into SLAM\nto enable dense, photorealistic 3D mapping, yet existing GS-based SLAM methods\nrequire per-scene optimization that is slow and consumes an excessive number of\nGaussians. We present GS4, the first generalizable GS-based semantic SLAM\nsystem. Compared with prior approaches, GS4 runs 10x faster, uses 10x fewer\nGaussians, and achieves state-of-the-art performance across color, depth,\nsemantic mapping and camera tracking. From an RGB-D video stream, GS4\nincrementally builds and updates a set of 3D Gaussians using a feed-forward\nnetwork. First, the Gaussian Prediction Model estimates a sparse set of\nGaussian parameters from input frame, which integrates both color and semantic\nprediction with the same backbone. Then, the Gaussian Refinement Network merges\nnew Gaussians with the existing set while avoiding redundancy. Finally, we\npropose to optimize GS for only 1-5 iterations that corrects drift and floaters\nwhen significant pose changes are detected. Experiments on the real-world\nScanNet and ScanNet++ benchmarks demonstrate state-of-the-art semantic SLAM\nperformance, with strong generalization capability shown through zero-shot\ntransfer to the NYUv2 and TUM RGB-D datasets.",
    "published": "2025-06-06T20:28:37Z",
    "updated": "2025-10-28T05:40:02Z",
    "link": "http://arxiv.org/pdf/2506.06517v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Mingqi Jiang",
      "Chanho Kim",
      "Chen Ziwen",
      "Li Fuxin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.21412v2",
    "title": "Bridging the gap to real-world language-grounded visual concept learning",
    "summary": "Human intelligence effortlessly interprets visual scenes along a rich\nspectrum of semantic dimensions. However, existing approaches to\nlanguage-grounded visual concept learning are limited to a few predefined\nprimitive axes, such as color and shape, and are typically explored in\nsynthetic datasets. In this work, we propose a scalable framework that\nadaptively identifies image-related concept axes and grounds visual concepts\nalong these axes in real-world scenes. Leveraging a pretrained vision-language\nmodel and our universal prompting strategy, our framework identifies a diverse\nimage-related axes without any prior knowledge. Our universal concept encoder\nadaptively binds visual features to the discovered axes without introducing\nadditional model parameters for each concept. To ground visual concepts along\nthe discovered axes, we optimize a compositional anchoring objective, which\nensures that each axis can be independently manipulated without affecting\nothers. We demonstrate the effectiveness of our framework on subsets of\nImageNet, CelebA-HQ, and AFHQ, showcasing superior editing capabilities across\ndiverse real-world concepts that are too varied to be manually predefined. Our\nmethod also exhibits strong compositional generalization, outperforming\nexisting visual concept learning and text-based editing methods. The code is\navailable at https://github.com/whieya/Language-grounded-VCL.",
    "published": "2025-10-24T12:54:13Z",
    "updated": "2025-10-28T05:32:23Z",
    "link": "http://arxiv.org/pdf/2510.21412v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Whie Jung",
      "Semin Kim",
      "Junee Kim",
      "Seunghoon Hong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.18672v8",
    "title": "CalFuse: Multi-Modal Continual Learning via Feature Calibration and\n  Parameter Fusion",
    "summary": "With the proliferation of multi-modal data in large-scale visual recognition\nsystems, enabling models to continuously acquire knowledge from evolving data\nstreams while preserving prior information has become increasingly critical.\nClass-Continual Learning (CCL) addresses this challenge by incrementally\nincorporating new class knowledge without revisiting historical data, making it\nessential for real-world big data applications. While traditional CCL methods\nrely solely on visual features, recent advances in Vision-Language Models\n(VLMs) such as CLIP demonstrate significant potential for CCL by leveraging\npre-trained multi-modal knowledge. However, existing approaches face challenges\nin mitigating catastrophic forgetting while maintaining the cross-modal\ngeneralization capabilities of VLMs. To address these limitations, we propose\nCalFuse, a framework that synergizes feature Calibration with parameter Fusion\nto enable effective multi-modal knowledge integration in continual learning\nscenarios. CalFuse introduces a dynamic feature calibration mechanism that\nadaptively balances original CLIP visual representations with task-specific\nfeatures, preserving the model's intrinsic cross-modal generalization while\nadapting to new classes. Concurrently, a QR decomposition-based parameter\nfusion strategy progressively integrates newly acquired knowledge with\nhistorical task parameters, maintaining equilibrium between learning new class\nrepresentations and retaining prior knowledge across sequential tasks.\nExtensive experiments on benchmark datasets validate the effectiveness of our\napproach in large-scale multi-modal continual learning settings, demonstrating\nsuperior performance over state-of-the-art methods in both average accuracy and\nfinal task retention.",
    "published": "2025-03-24T13:44:12Z",
    "updated": "2025-10-28T05:22:48Z",
    "link": "http://arxiv.org/pdf/2503.18672v8.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Juncen Guo",
      "Siao Liu",
      "Xiaoguang Zhu",
      "Lianlong Sun",
      "Liangyu Teng",
      "Jingyi Wu",
      "Di Li",
      "Linxiao Gong",
      "Weiwei Jiang",
      "Wei Zhou",
      "Liang Song"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.09282v4",
    "title": "MsEdF: A Multi-stream Encoder-decoder Framework for Remote Sensing Image\n  Captioning",
    "summary": "Remote sensing images contain complex spatial patterns and semantic\nstructures, which makes the captioning model difficult to accurately describe.\nEncoder-decoder architectures have become the widely used approach for RSIC by\ntranslating visual content into descriptive text. However, many existing\nmethods rely on a single-stream architecture, which weakens the model to\naccurately describe the image. Such single-stream architectures typically\nstruggle to extract diverse spatial features or capture complex semantic\nrelationships, limiting their effectiveness in scenes with high intraclass\nsimilarity or contextual ambiguity. In this work, we propose a novel\nMulti-stream Encoder-decoder Framework (MsEdF) which improves the performance\nof RSIC by optimizing both the spatial representation and language generation\nof encoder-decoder architecture. The encoder fuses information from two\ncomplementary image encoders, thereby promoting feature diversity through the\nintegration of multiscale and structurally distinct cues. To improve the\ncapture of context-aware descriptions, we refine the input sequence's semantic\nmodeling on the decoder side using a stacked GRU architecture with an\nelement-wise aggregation scheme. Experiments on three benchmark RSIC datasets\nshow that MsEdF outperforms several baseline models.",
    "published": "2025-02-13T12:54:13Z",
    "updated": "2025-10-28T04:40:41Z",
    "link": "http://arxiv.org/pdf/2502.09282v4.pdf",
    "category": [
      "cs.CV",
      "cs.HC",
      "cs.LG"
    ],
    "authors": [
      "Swadhin Das",
      "Raksha Sharma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.02885v2",
    "title": "MDP3: A Training-free Approach for List-wise Frame Selection in\n  Video-LLMs",
    "summary": "Video large language models (Video-LLMs) have made significant progress in\nunderstanding videos. However, processing multiple frames leads to lengthy\nvisual token sequences, presenting challenges such as the limited context\nlength cannot accommodate the entire video, and the inclusion of irrelevant\nframes hinders visual perception. Hence, effective frame selection is crucial.\nThis paper emphasizes that frame selection should follow three key principles:\nquery relevance, list-wise diversity, and sequentiality. Existing methods, such\nas uniform frame sampling and query-frame matching, do not capture all of these\nprinciples. Thus, we propose Markov decision determinantal point process with\ndynamic programming (MDP3) for frame selection, a training-free and\nmodel-agnostic method that can be seamlessly integrated into existing\nVideo-LLMs. Our method first estimates frame similarities conditioned on the\nquery using a conditional Gaussian kernel within the reproducing kernel Hilbert\nspace~(RKHS). We then apply the determinantal point process~(DPP) to the\nsimilarity matrix to capture both query relevance and list-wise diversity. To\nincorporate sequentiality, we segment the video and apply DPP within each\nsegment, conditioned on the preceding segment selection, modeled as a Markov\ndecision process~(MDP) for allocating selection sizes across segments.\nTheoretically, MDP3 provides a \\((1 - 1/e)\\)-approximate solution to the\nNP-hard list-wise frame selection problem with pseudo-polynomial time\ncomplexity, demonstrating its efficiency. Empirically, MDP3 significantly\noutperforms existing methods, verifying its effectiveness and robustness.",
    "published": "2025-01-06T09:55:55Z",
    "updated": "2025-10-28T04:18:29Z",
    "link": "http://arxiv.org/pdf/2501.02885v2.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Hui Sun",
      "Shiyin Lu",
      "Huanyu Wang",
      "Qing-Guo Chen",
      "Zhao Xu",
      "Weihua Luo",
      "Kaifu Zhang",
      "Ming Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.22706v2",
    "title": "IGGT: Instance-Grounded Geometry Transformer for Semantic 3D\n  Reconstruction",
    "summary": "Humans naturally perceive the geometric structure and semantic content of a\n3D world as intertwined dimensions, enabling coherent and accurate\nunderstanding of complex scenes. However, most prior approaches prioritize\ntraining large geometry models for low-level 3D reconstruction and treat\nhigh-level spatial understanding in isolation, overlooking the crucial\ninterplay between these two fundamental aspects of 3D-scene analysis, thereby\nlimiting generalization and leading to poor performance in downstream 3D\nunderstanding tasks. Recent attempts have mitigated this issue by simply\naligning 3D models with specific language models, thus restricting perception\nto the aligned model's capacity and limiting adaptability to downstream tasks.\nIn this paper, we propose InstanceGrounded Geometry Transformer (IGGT), an\nend-to-end large unified transformer to unify the knowledge for both spatial\nreconstruction and instance-level contextual understanding. Specifically, we\ndesign a 3D-Consistent Contrastive Learning strategy that guides IGGT to encode\na unified representation with geometric structures and instance-grounded\nclustering through only 2D visual inputs. This representation supports\nconsistent lifting of 2D visual inputs into a coherent 3D scene with explicitly\ndistinct object instances. To facilitate this task, we further construct\nInsScene-15K, a large-scale dataset with high-quality RGB images, poses, depth\nmaps, and 3D-consistent instance-level mask annotations with a novel data\ncuration pipeline.",
    "published": "2025-10-26T14:57:44Z",
    "updated": "2025-10-28T04:16:45Z",
    "link": "http://arxiv.org/pdf/2510.22706v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Hao Li",
      "Zhengyu Zou",
      "Fangfu Liu",
      "Xuanyang Zhang",
      "Fangzhou Hong",
      "Yukang Cao",
      "Yushi Lan",
      "Manyuan Zhang",
      "Gang Yu",
      "Dingwen Zhang",
      "Ziwei Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.13389v5",
    "title": "VSA: Faster Video Diffusion with Trainable Sparse Attention",
    "summary": "Scaling video diffusion transformers (DiTs) is limited by their quadratic 3D\nattention, even though most of the attention mass concentrates on a small\nsubset of positions. We turn this observation into VSA, a trainable,\nhardware-efficient sparse attention that replaces full attention at \\emph{both}\ntraining and inference. In VSA, a lightweight coarse stage pools tokens into\ntiles and identifies high-weight \\emph{critical tokens}; a fine stage computes\ntoken-level attention only inside those tiles subjecting to block computing\nlayout to ensure hard efficiency. This leads to a single differentiable kernel\nthat trains end-to-end, requires no post-hoc profiling, and sustains 85\\% of\nFlashAttention3 MFU. We perform a large sweep of ablation studies and\nscaling-law experiments by pretraining DiTs from 60M to 1.4B parameters. VSA\nreaches a Pareto point that cuts training FLOPS by 2.53$\\times$ with no drop in\ndiffusion loss. Retrofitting the open-source Wan-2.1 model speeds up attention\ntime by 6$\\times$ and lowers end-to-end generation time from 31s to 18s with\ncomparable quality. These results establish trainable sparse attention as a\npractical alternative to full attention and a key enabler for further scaling\nof video diffusion models. Code will be available at\nhttps://github.com/hao-ai-lab/FastVideo.",
    "published": "2025-05-19T17:30:13Z",
    "updated": "2025-10-28T04:13:18Z",
    "link": "http://arxiv.org/pdf/2505.13389v5.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Peiyuan Zhang",
      "Yongqi Chen",
      "Haofeng Huang",
      "Will Lin",
      "Zhengzhong Liu",
      "Ion Stoica",
      "Eric Xing",
      "Hao Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.22802v2",
    "title": "Riemannian-Geometric Fingerprints of Generative Models",
    "summary": "Recent breakthroughs and rapid integration of generative models (GMs) have\nsparked interest in the problem of model attribution and their fingerprints.\nFor instance, service providers need reliable methods of authenticating their\nmodels to protect their IP, while users and law enforcement seek to verify the\nsource of generated content for accountability and trust. In addition, a\ngrowing threat of model collapse is arising, as more model-generated data are\nbeing fed back into sources (e.g., YouTube) that are often harvested for\ntraining (\"regurgitative training\"), heightening the need to differentiate\nsynthetic from human data. Yet, a gap still exists in understanding generative\nmodels' fingerprints, we believe, stemming from the lack of a formal framework\nthat can define, represent, and analyze the fingerprints in a principled way.\nTo address this gap, we take a geometric approach and propose a new definition\nof artifact and fingerprint of GMs using Riemannian geometry, which allows us\nto leverage the rich theory of differential geometry. Our new definition\ngeneralizes previous work (Song et al., 2024) to non-Euclidean manifolds by\nlearning Riemannian metrics from data and replacing the Euclidean distances and\nnearest-neighbor search with geodesic distances and kNN-based Riemannian center\nof mass. We apply our theory to a new gradient-based algorithm for computing\nthe fingerprints in practice. Results show that it is more effective in\ndistinguishing a large array of GMs, spanning across 4 different datasets in 2\ndifferent resolutions (64 by 64, 256 by 256), 27 model architectures, and 2\nmodalities (Vision, Vision-Language). Using our proposed definition\nsignificantly improves the performance on model attribution, as well as a\ngeneralization to unseen datasets, model types, and modalities, suggesting its\npractical efficacy.",
    "published": "2025-06-28T08:08:16Z",
    "updated": "2025-10-28T03:55:35Z",
    "link": "http://arxiv.org/pdf/2506.22802v2.pdf",
    "category": [
      "cs.LG",
      "cs.CR",
      "cs.CV",
      "I.2.6"
    ],
    "authors": [
      "Hae Jin Song",
      "Laurent Itti"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24038v1",
    "title": "Enhancing CLIP Robustness via Cross-Modality Alignment",
    "summary": "Vision-language models (VLMs) such as CLIP demonstrate strong generalization\nin zero-shot classification but remain highly vulnerable to adversarial\nperturbations. Existing methods primarily focus on adversarial fine-tuning or\nprompt optimization; they often overlook the gaps in CLIP's encoded features,\nwhich is shown as the text and image features lie far apart from each other.\nThis misalignment is significantly amplified under adversarial perturbations,\nleading to severe degradation in classification performance. To address this\nproblem, we propose Cross-modality Alignment, dubbed COLA, an optimal\ntransport-based framework that explicitly addresses adversarial misalignment by\nrestoring both global image-text alignment and local structural consistency in\nthe feature space. (1) COLA first projects adversarial image embeddings onto a\nsubspace spanned by class text features, effectively filtering out non-semantic\ndistortions while preserving discriminative information. (2) It then models\nimages and texts as discrete distributions over multiple augmented views and\nrefines their alignment via OT, with the subspace projection seamlessly\nintegrated into the cost computation. This design ensures stable cross-modal\nalignment even under adversarial conditions. COLA is training-free and\ncompatible with existing fine-tuned models. Extensive evaluations across 14\nzero-shot classification benchmarks demonstrate the effectiveness of COLA,\nespecially with an average improvement of 6.7% on ImageNet and its variants\nunder PGD adversarial attacks, while maintaining high accuracy on clean\nsamples.",
    "published": "2025-10-28T03:47:44Z",
    "updated": "2025-10-28T03:47:44Z",
    "link": "http://arxiv.org/pdf/2510.24038v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xingyu Zhu",
      "Beier Zhu",
      "Shuo Wang",
      "Kesen Zhao",
      "Hanwang Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24037v1",
    "title": "Kernelized Sparse Fine-Tuning with Bi-level Parameter Competition for\n  Vision Models",
    "summary": "Parameter-efficient fine-tuning (PEFT) aims to adapt pre-trained vision\nmodels to downstream tasks. Among PEFT paradigms, sparse tuning achieves\nremarkable performance by adjusting only the weights most relevant to\ndownstream tasks, rather than densely tuning the entire weight matrix. Current\nmethods follow a two-stage paradigm. First, it locates task-relevant weights by\ngradient information, which overlooks the parameter adjustments during\nfine-tuning and limits the performance. Second, it updates only the located\nweights by applying a sparse mask to the gradient of the weight matrix, which\nresults in high memory usage due to the storage of all weight matrices in the\noptimizer. In this paper, we propose a one-stage method named SNELLA to\novercome the above limitations. For memory usage, SNELLA selectively updates\nthe weight matrix by adding it to another sparse matrix that is merged by two\nlow-rank learnable matrices. We extend the low-rank decomposition by\nintroducing nonlinear kernel functions, thereby increasing the rank of the\nresulting merged matrix to prevent the interdependency among weight updates,\nenabling better adaptation to downstream tasks. For locating task-relevant\nweights, we propose an adaptive bi-level sparsity allocation mechanism that\nencourages weights to compete across and inside layers based on their\nimportance scores in an end-to-end manner. Extensive experiments are conducted\non classification, segmentation, and generation tasks using different\npre-trained vision models. The results show that SNELLA achieves SOTA\nperformance with low memory usage. Notably, SNELLA obtains 1.8% (91.9% v.s.\n90.1%) higher Top-1 accuracy on the FGVC benchmark compared to SPT-LoRA.\nCompared to previous methods, SNELLA achieves a memory reduction of 31.1%-39.9%\nacross models with parameter scales from 86M to 632M. Our source codes are\navailable at https://github.com/ssfgunner/SNELL.",
    "published": "2025-10-28T03:39:18Z",
    "updated": "2025-10-28T03:39:18Z",
    "link": "http://arxiv.org/pdf/2510.24037v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Shufan Shen",
      "Junshu Sun",
      "Shuhui Wang",
      "Qingming Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.16691v2",
    "title": "InstanceAssemble: Layout-Aware Image Generation via Instance Assembling\n  Attention",
    "summary": "Diffusion models have demonstrated remarkable capabilities in generating\nhigh-quality images. Recent advancements in Layout-to-Image (L2I) generation\nhave leveraged positional conditions and textual descriptions to facilitate\nprecise and controllable image synthesis. Despite overall progress, current L2I\nmethods still exhibit suboptimal performance. Therefore, we propose\nInstanceAssemble, a novel architecture that incorporates layout conditions via\ninstance-assembling attention, enabling position control with bounding boxes\n(bbox) and multimodal content control including texts and additional visual\ncontent. Our method achieves flexible adaption to existing DiT-based T2I models\nthrough light-weighted LoRA modules. Additionally, we propose a Layout-to-Image\nbenchmark, Denselayout, a comprehensive benchmark for layout-to-image\ngeneration, containing 5k images with 90k instances in total. We further\nintroduce Layout Grounding Score (LGS), an interpretable evaluation metric to\nmore precisely assess the accuracy of L2I generation. Experiments demonstrate\nthat our InstanceAssemble method achieves state-of-the-art performance under\ncomplex layout conditions, while exhibiting strong compatibility with diverse\nstyle LoRA modules. The code and pretrained models are publicly available at\nhttps://github.com/FireRedTeam/InstanceAssemble.",
    "published": "2025-09-20T13:37:37Z",
    "updated": "2025-10-28T03:37:32Z",
    "link": "http://arxiv.org/pdf/2509.16691v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Qiang Xiang",
      "Shuang Sun",
      "Binglei Li",
      "Dejia Song",
      "Huaxia Li",
      "Nemo Chen",
      "Xu Tang",
      "Yao Hu",
      "Junping Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.20744v2",
    "title": "MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity\n  Recognition",
    "summary": "Human Activity Recognition (HAR) with wearable sensors is challenged by\nlimited interpretability, which significantly impacts cross-dataset\ngeneralization. To address this challenge, we propose Motion-Primitive\nTransformer (MoPFormer), a novel self-supervised framework that enhances\ninterpretability by tokenizing inertial measurement unit signals into\nsemantically meaningful motion primitives and leverages a Transformer\narchitecture to learn rich temporal representations. MoPFormer comprises two\nstages. The first stage is to partition multi-channel sensor streams into short\nsegments and quantize them into discrete ``motion primitive'' codewords, while\nthe second stage enriches those tokenized sequences through a context-aware\nembedding module and then processes them with a Transformer encoder. The\nproposed MoPFormer can be pre-trained using a masked motion-modeling objective\nthat reconstructs missing primitives, enabling it to develop robust\nrepresentations across diverse sensor configurations. Experiments on six HAR\nbenchmarks demonstrate that MoPFormer not only outperforms state-of-the-art\nmethods but also successfully generalizes across multiple datasets. More\nimportantly, the learned motion primitives significantly enhance both\ninterpretability and cross-dataset performance by capturing fundamental\nmovement patterns that remain consistent across similar activities, regardless\nof dataset origin.",
    "published": "2025-05-27T05:34:56Z",
    "updated": "2025-10-28T03:32:37Z",
    "link": "http://arxiv.org/pdf/2505.20744v2.pdf",
    "category": [
      "cs.CV",
      "I.5.4; I.2.6; C.3"
    ],
    "authors": [
      "Hao Zhang",
      "Zhan Zhuang",
      "Xuehao Wang",
      "Xiaodong Yang",
      "Yu Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24034v1",
    "title": "AutoPrompt: Automated Red-Teaming of Text-to-Image Models via LLM-Driven\n  Adversarial Prompts",
    "summary": "Despite rapid advancements in text-to-image (T2I) models, their safety\nmechanisms are vulnerable to adversarial prompts, which maliciously generate\nunsafe images. Current red-teaming methods for proactively assessing such\nvulnerabilities usually require white-box access to T2I models, and rely on\ninefficient per-prompt optimization, as well as inevitably generate\nsemantically meaningless prompts easily blocked by filters. In this paper, we\npropose APT (AutoPrompT), a black-box framework that leverages large language\nmodels (LLMs) to automatically generate human-readable adversarial suffixes for\nbenign prompts. We first introduce an alternating optimization-finetuning\npipeline between adversarial suffix optimization and fine-tuning the LLM\nutilizing the optimized suffix. Furthermore, we integrates a dual-evasion\nstrategy in optimization phase, enabling the bypass of both perplexity-based\nfilter and blacklist word filter: (1) we constrain the LLM generating\nhuman-readable prompts through an auxiliary LLM perplexity scoring, which\nstarkly contrasts with prior token-level gibberish, and (2) we also introduce\nbanned-token penalties to suppress the explicit generation of banned-tokens in\nblacklist. Extensive experiments demonstrate the excellent red-teaming\nperformance of our human-readable, filter-resistant adversarial prompts, as\nwell as superior zero-shot transferability which enables instant adaptation to\nunseen prompts and exposes critical vulnerabilities even in commercial APIs\n(e.g., Leonardo.Ai.).",
    "published": "2025-10-28T03:32:14Z",
    "updated": "2025-10-28T03:32:14Z",
    "link": "http://arxiv.org/pdf/2510.24034v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yufan Liu",
      "Wanqian Zhang",
      "Huashan Chen",
      "Lin Wang",
      "Xiaojun Jia",
      "Zheng Lin",
      "Weiping Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.05186v3",
    "title": "Learning to See and Act: Task-Aware View Planning for Robotic\n  Manipulation",
    "summary": "Recent vision-language-action (VLA) models for multi-task robotic\nmanipulation commonly rely on static viewpoints and shared visual encoders,\nwhich limit 3D perception and cause task interference, hindering robustness and\ngeneralization. In this work, we propose Task-Aware View Planning (TAVP), a\nframework designed to overcome these challenges by integrating active view\nplanning with task-specific representation learning. TAVP employs an efficient\nexploration policy, accelerated by a novel pseudo-environment, to actively\nacquire informative views. Furthermore, we introduce a Mixture-of-Experts (MoE)\nvisual encoder to disentangle features across different tasks, boosting both\nrepresentation fidelity and task generalization. By learning to see the world\nin a task-aware way, TAVP generates more complete and discriminative visual\nrepresentations, demonstrating significantly enhanced action prediction across\na wide array of manipulation challenges. Extensive experiments on RLBench tasks\nshow that our proposed TAVP model achieves superior performance over\nstate-of-the-art fixed-view approaches. Visual results and code are provided\nat: https://hcplab-sysu.github.io/TAVP.",
    "published": "2025-08-07T09:21:20Z",
    "updated": "2025-10-28T03:21:38Z",
    "link": "http://arxiv.org/pdf/2508.05186v3.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Yongjie Bai",
      "Zhouxia Wang",
      "Yang Liu",
      "Weixing Chen",
      "Ziliang Chen",
      "Mingtong Dai",
      "Yongsen Zheng",
      "Lingbo Liu",
      "Guanbin Li",
      "Liang Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.02542v3",
    "title": "Unveiling Concept Attribution in Diffusion Models",
    "summary": "Diffusion models have shown remarkable abilities in generating realistic and\nhigh-quality images from text prompts. However, a trained model remains largely\nblack-box; little do we know about the roles of its components in exhibiting a\nconcept such as objects or styles. Recent works employ causal tracing to\nlocalize knowledge-storing layers in generative models without showing how\nother layers contribute to the target concept. In this work, we approach\ndiffusion models' interpretability problem from a more general perspective and\npose a question: \\textit{``How do model components work jointly to demonstrate\nknowledge?''}. To answer this question, we decompose diffusion models using\ncomponent attribution, systematically unveiling the importance of each\ncomponent (specifically the model parameter) in generating a concept. The\nproposed framework, called \\textbf{C}omponent \\textbf{A}ttribution for\n\\textbf{D}iffusion Model (CAD), discovers the localization of concept-inducing\n(positive) components, while interestingly uncovers another type of components\nthat contribute negatively to generating a concept, which is missing in the\nprevious knowledge localization work. Based on this holistic understanding of\ndiffusion models, we introduce two fast, inference-time model editing\nalgorithms, CAD-Erase and CAD-Amplify; in particular, CAD-Erase enables erasure\nand CAD-Amplify allows amplification of a generated concept by ablating the\npositive and negative components, respectively, while retaining knowledge of\nother concepts. Extensive experimental results validate the significance of\nboth positive and negative components pinpointed by our framework,\ndemonstrating the potential of providing a complete view of interpreting\ngenerative models. Our code is available\n\\href{https://github.com/mail-research/CAD-attribution4diffusion}{here}.",
    "published": "2024-12-03T16:34:49Z",
    "updated": "2025-10-28T03:07:50Z",
    "link": "http://arxiv.org/pdf/2412.02542v3.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Quang H. Nguyen",
      "Hoang Phan",
      "Khoa D. Doan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24024v1",
    "title": "Listening without Looking: Modality Bias in Audio-Visual Captioning",
    "summary": "Audio-visual captioning aims to generate holistic scene descriptions by\njointly modeling sound and vision. While recent methods have improved\nperformance through sophisticated modality fusion, it remains unclear to what\nextent the two modalities are complementary in current audio-visual captioning\nmodels and how robust these models are when one modality is degraded. We\naddress these questions by conducting systematic modality robustness tests on\nLAVCap, a state-of-the-art audio-visual captioning model, in which we\nselectively suppress or corrupt the audio or visual streams to quantify\nsensitivity and complementarity. The analysis reveals a pronounced bias toward\nthe audio stream in LAVCap. To evaluate how balanced audio-visual captioning\nmodels are in their use of both modalities, we augment AudioCaps with textual\nannotations that jointly describe the audio and visual streams, yielding the\nAudioVisualCaps dataset. In our experiments, we report LAVCap baseline results\non AudioVisualCaps. We also evaluate the model under modality robustness tests\non AudioVisualCaps and the results indicate that LAVCap trained on\nAudioVisualCaps exhibits less modality bias than when trained on AudioCaps.",
    "published": "2025-10-28T03:06:28Z",
    "updated": "2025-10-28T03:06:28Z",
    "link": "http://arxiv.org/pdf/2510.24024v1.pdf",
    "category": [
      "eess.AS",
      "cs.CV",
      "eess.IV"
    ],
    "authors": [
      "Yuchi Ishikawa",
      "Toranosuke Manabe",
      "Tatsuya Komatsu",
      "Yoshimitsu Aoki"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.04897v3",
    "title": "From Objects to Anywhere: A Holistic Benchmark for Multi-level Visual\n  Grounding in 3D Scenes",
    "summary": "3D visual grounding has made notable progress in localizing objects within\ncomplex 3D scenes. However, grounding referring expressions beyond objects in\n3D scenes remains unexplored. In this paper, we introduce Anywhere3D-Bench, a\nholistic 3D visual grounding benchmark consisting of 2,886 referring\nexpression-3D bounding box pairs spanning four different grounding levels:\nhuman-activity areas, unoccupied space beyond objects, individual objects in\nthe scene, and fine-grained object parts. We assess a range of state-of-the-art\n3D visual grounding methods alongside large language models (LLMs) and\nmultimodal LLMs (MLLMs) on Anywhere3D-Bench. Experimental results reveal that\nspace-level and part-level visual grounding pose the greatest challenges:\nspace-level tasks require a more comprehensive spatial reasoning ability, for\nexample, modeling distances and spatial relations within 3D space, while\npart-level tasks demand fine-grained perception of object composition. Even the\nbest-performing models, Google Gemini-2.5-Pro and OpenAI o3, achieve just\naround 30% accuracy on space-level tasks and around 40% on part-level tasks,\nsignificantly lower than its performance on area-level and object-level tasks.\nThese findings underscore a critical gap in current models' capacity to\nunderstand and reason about 3D scenes beyond object-level semantics.",
    "published": "2025-06-05T11:28:02Z",
    "updated": "2025-10-28T02:59:19Z",
    "link": "http://arxiv.org/pdf/2506.04897v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Tianxu Wang",
      "Zhuofan Zhang",
      "Ziyu Zhu",
      "Yue Fan",
      "Jing Xiong",
      "Pengxiang Li",
      "Xiaojian Ma",
      "Qing Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2406.09782v3",
    "title": "Unsupervised Monocular Depth Estimation Based on Hierarchical\n  Feature-Guided Diffusion",
    "summary": "Unsupervised monocular depth estimation has received widespread attention\nbecause of its capability to train without ground truth. In real-world\nscenarios, the images may be blurry or noisy due to the influence of weather\nconditions and inherent limitations of the camera. Therefore, it is\nparticularly important to develop a robust depth estimation model. Benefiting\nfrom the training strategies of generative networks, generative-based methods\noften exhibit enhanced robustness. In light of this, we employ a\nwell-converging diffusion model among generative networks for unsupervised\nmonocular depth estimation. Additionally, we propose a hierarchical\nfeature-guided denoising module. This model significantly enriches the model's\ncapacity for learning and interpreting depth distribution by fully leveraging\nimage features to guide the denoising process. Furthermore, we explore the\nimplicit depth within reprojection and design an implicit depth consistency\nloss. This loss function serves to enhance the performance of the model and\nensure the scale consistency of depth within a video sequence. We conduct\nexperiments on the KITTI, Make3D, and our self-collected SIMIT datasets. The\nresults indicate that our approach stands out among generative-based models,\nwhile also showcasing remarkable robustness.",
    "published": "2024-06-14T07:31:20Z",
    "updated": "2025-10-28T02:46:13Z",
    "link": "http://arxiv.org/pdf/2406.09782v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Runze Liu",
      "Dongchen Zhu",
      "Guanghui Zhang",
      "Yue Xu",
      "Wenjun Shi",
      "Xiaolin Zhang",
      "Lei Wang",
      "Jiamao Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24009v1",
    "title": "Towards the Automatic Segmentation, Modeling and Meshing of the Aortic\n  Vessel Tree from Multicenter Acquisitions: An Overview of the SEG.A. 2023\n  Segmentation of the Aorta Challenge",
    "summary": "The automated analysis of the aortic vessel tree (AVT) from computed\ntomography angiography (CTA) holds immense clinical potential, but its\ndevelopment has been impeded by a lack of shared, high-quality data. We\nlaunched the SEG.A. challenge to catalyze progress in this field by introducing\na large, publicly available, multi-institutional dataset for AVT segmentation.\nThe challenge benchmarked automated algorithms on a hidden test set, with\nsubsequent optional tasks in surface meshing for computational simulations. Our\nfindings reveal a clear convergence on deep learning methodologies, with 3D\nU-Net architectures dominating the top submissions. A key result was that an\nensemble of the highest-ranking algorithms significantly outperformed\nindividual models, highlighting the benefits of model fusion. Performance was\nstrongly linked to algorithmic design, particularly the use of customized\npost-processing steps, and the characteristics of the training data. This\ninitiative not only establishes a new performance benchmark but also provides a\nlasting resource to drive future innovation toward robust, clinically\ntranslatable tools.",
    "published": "2025-10-28T02:33:45Z",
    "updated": "2025-10-28T02:33:45Z",
    "link": "http://arxiv.org/pdf/2510.24009v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yuan Jin",
      "Antonio Pepe",
      "Gian Marco Melito",
      "Yuxuan Chen",
      "Yunsu Byeon",
      "Hyeseong Kim",
      "Kyungwon Kim",
      "Doohyun Park",
      "Euijoon Choi",
      "Dosik Hwang",
      "Andriy Myronenko",
      "Dong Yang",
      "Yufan He",
      "Daguang Xu",
      "Ayman El-Ghotni",
      "Mohamed Nabil",
      "Hossam El-Kady",
      "Ahmed Ayyad",
      "Amr Nasr",
      "Marek Wodzinski",
      "Henning MÃ¼ller",
      "Hyeongyu Kim",
      "Yejee Shin",
      "Abbas Khan",
      "Muhammad Asad",
      "Alexander Zolotarev",
      "Caroline Roney",
      "Anthony Mathur",
      "Martin Benning",
      "Gregory Slabaugh",
      "Theodoros Panagiotis Vagenas",
      "Konstantinos Georgas",
      "George K. Matsopoulos",
      "Jihan Zhang",
      "Zhen Zhang",
      "Liqin Huang",
      "Christian Mayer",
      "Heinrich MÃ¤chler",
      "Jan Egger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.00034v2",
    "title": "GaussianFusion: Gaussian-Based Multi-Sensor Fusion for End-to-End\n  Autonomous Driving",
    "summary": "Multi-sensor fusion is crucial for improving the performance and robustness\nof end-to-end autonomous driving systems. Existing methods predominantly adopt\neither attention-based flatten fusion or bird's eye view fusion through\ngeometric transformations. However, these approaches often suffer from limited\ninterpretability or dense computational overhead. In this paper, we introduce\nGaussianFusion, a Gaussian-based multi-sensor fusion framework for end-to-end\nautonomous driving. Our method employs intuitive and compact Gaussian\nrepresentations as intermediate carriers to aggregate information from diverse\nsensors. Specifically, we initialize a set of 2D Gaussians uniformly across the\ndriving scene, where each Gaussian is parameterized by physical attributes and\nequipped with explicit and implicit features. These Gaussians are progressively\nrefined by integrating multi-modal features. The explicit features capture rich\nsemantic and spatial information about the traffic scene, while the implicit\nfeatures provide complementary cues beneficial for trajectory planning. To\nfully exploit rich spatial and semantic information in Gaussians, we design a\ncascade planning head that iteratively refines trajectory predictions through\ninteractions with Gaussians. Extensive experiments on the NAVSIM and\nBench2Drive benchmarks demonstrate the effectiveness and robustness of the\nproposed GaussianFusion framework. The source code will be released at\nhttps://github.com/Say2L/GaussianFusion.",
    "published": "2025-05-27T01:43:02Z",
    "updated": "2025-10-28T02:15:21Z",
    "link": "http://arxiv.org/pdf/2506.00034v2.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Shuai Liu",
      "Quanmin Liang",
      "Zefeng Li",
      "Boyang Li",
      "Kai Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24000v1",
    "title": "AdvBlur: Adversarial Blur for Robust Diabetic Retinopathy Classification\n  and Cross-Domain Generalization",
    "summary": "Diabetic retinopathy (DR) is a leading cause of vision loss worldwide, yet\nearly and accurate detection can significantly improve treatment outcomes.\nWhile numerous Deep learning (DL) models have been developed to predict DR from\nfundus images, many face challenges in maintaining robustness due to\ndistributional variations caused by differences in acquisition devices,\ndemographic disparities, and imaging conditions. This paper addresses this\ncritical limitation by proposing a novel DR classification approach, a method\ncalled AdvBlur. Our method integrates adversarial blurred images into the\ndataset and employs a dual-loss function framework to address domain\ngeneralization. This approach effectively mitigates the impact of unseen\ndistributional variations, as evidenced by comprehensive evaluations across\nmultiple datasets. Additionally, we conduct extensive experiments to explore\nthe effects of factors such as camera type, low-quality images, and dataset\nsize. Furthermore, we perform ablation studies on blurred images and the loss\nfunction to ensure the validity of our choices. The experimental results\ndemonstrate the effectiveness of our proposed method, achieving competitive\nperformance compared to state-of-the-art domain generalization DR models on\nunseen external datasets.",
    "published": "2025-10-28T02:10:54Z",
    "updated": "2025-10-28T02:10:54Z",
    "link": "http://arxiv.org/pdf/2510.24000v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Heethanjan Kanagalingam",
      "Thenukan Pathmanathan",
      "Mokeeshan Vathanakumar",
      "Tharmakulasingam Mukunthan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23594v2",
    "title": "PRISM-Bench: A Benchmark of Puzzle-Based Visual Tasks with CoT Error\n  Detection",
    "summary": "Multimodal large language models (MLLMs) have achieved remarkable progress on\nvision-language tasks, yet their reasoning processes remain sometimes\nunreliable. We introduce PRISM-Bench, a benchmark of puzzle-based visual\nchallenges designed to evaluate not only whether models can solve problems, but\nhow their reasoning unfolds. Unlike prior evaluations that measure only\nfinal-answer accuracy, PRISM-Bench introduces a diagnostic task: given a visual\npuzzle and a step-by-step chain-of-thought (CoT) containing exactly one error,\nmodels must identify the first incorrect step. This setting enables\nfine-grained assessment of logical consistency, error detection, and visual\nreasoning. The puzzles in PRISM-Bench require multi-step symbolic, geometric,\nand analogical reasoning, resisting shortcuts based on superficial pattern\nmatching. Evaluations across state-of-the-art MLLMs reveal a persistent gap\nbetween fluent generation and faithful reasoning: models that produce plausible\nCoTs often fail to locate simple logical faults. By disentangling answer\ngeneration from reasoning verification, PRISM-Bench offers a sharper lens on\nmultimodal reasoning competence and underscores the need for diagnostic\nevaluation protocols in the development of trustworthy MLLMs.",
    "published": "2025-10-27T17:57:52Z",
    "updated": "2025-10-28T02:07:50Z",
    "link": "http://arxiv.org/pdf/2510.23594v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yusu Qian",
      "Cheng Wan",
      "Chao Jia",
      "Yinfei Yang",
      "Qingyu Zhao",
      "Zhe Gan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.18443v2",
    "title": "Radar and Event Camera Fusion for Agile Robot Ego-Motion Estimation",
    "summary": "Achieving reliable ego motion estimation for agile robots, e.g., aerobatic\naircraft, remains challenging because most robot sensors fail to respond timely\nand clearly to highly dynamic robot motions, often resulting in measurement\nblurring, distortion, and delays. In this paper, we propose an IMU-free and\nfeature-association-free framework to achieve aggressive ego-motion velocity\nestimation of a robot platform in highly dynamic scenarios by combining two\ntypes of exteroceptive sensors, an event camera and a millimeter wave radar,\nFirst, we used instantaneous raw events and Doppler measurements to derive\nrotational and translational velocities directly. Without a sophisticated\nassociation process between measurement frames, the proposed method is more\nrobust in texture-less and structureless environments and is more\ncomputationally efficient for edge computing devices. Then, in the back-end, we\npropose a continuous-time state-space model to fuse the hybrid time-based and\nevent-based measurements to estimate the ego-motion velocity in a fixed-lagged\nsmoother fashion. In the end, we validate our velometer framework extensively\nin self-collected experiment datasets. The results indicate that our IMU-free\nand association-free ego motion estimation framework can achieve reliable and\nefficient velocity output in challenging environments. The source code,\nillustrative video and dataset are available at\nhttps://github.com/ZzhYgwh/TwistEstimator.",
    "published": "2025-06-23T09:27:22Z",
    "updated": "2025-10-28T01:59:34Z",
    "link": "http://arxiv.org/pdf/2506.18443v2.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Yang Lyu",
      "Zhenghao Zou",
      "Yanfeng Li",
      "Xiaohu Guo",
      "Chunhui Zhao",
      "Quan Pan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.04852v2",
    "title": "CAUSAL3D: A Comprehensive Benchmark for Causal Learning from Visual Data",
    "summary": "True intelligence hinges on the ability to uncover and leverage hidden causal\nrelations. Despite significant progress in AI and computer vision (CV), there\nremains a lack of benchmarks for assessing models' abilities to infer latent\ncausality from complex visual data. In this paper, we introduce\n\\textsc{\\textbf{Causal3D}}, a novel and comprehensive benchmark that integrates\nstructured data (tables) with corresponding visual representations (images) to\nevaluate causal reasoning. Designed within a systematic framework, Causal3D\ncomprises 19 3D-scene datasets capturing diverse causal relations, views, and\nbackgrounds, enabling evaluations across scenes of varying complexity. We\nassess multiple state-of-the-art methods, including classical causal discovery,\ncausal representation learning, and large/vision-language models (LLMs/VLMs).\nOur experiments show that as causal structures grow more complex without prior\nknowledge, performance declines significantly, highlighting the challenges even\nadvanced methods face in complex causal scenarios. Causal3D serves as a vital\nresource for advancing causal reasoning in CV and fostering trustworthy AI in\ncritical domains.",
    "published": "2025-03-06T03:40:01Z",
    "updated": "2025-10-28T01:41:35Z",
    "link": "http://arxiv.org/pdf/2503.04852v2.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Disheng Liu",
      "Yiran Qiao",
      "Wuche Liu",
      "Yiren Lu",
      "Yunlai Zhou",
      "Tuo Liang",
      "Yu Yin",
      "Jing Ma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23981v1",
    "title": "TeleEgo: Benchmarking Egocentric AI Assistants in the Wild",
    "summary": "Egocentric AI assistants in real-world settings must process multi-modal\ninputs (video, audio, text), respond in real time, and retain evolving\nlong-term memory. However, existing benchmarks typically evaluate these\nabilities in isolation, lack realistic streaming scenarios, or support only\nshort-term tasks. We introduce \\textbf{TeleEgo}, a long-duration, streaming,\nomni-modal benchmark for evaluating egocentric AI assistants in realistic daily\ncontexts. The dataset features over 14 hours per participant of synchronized\negocentric video, audio, and text across four domains: work \\& study, lifestyle\n\\& routines, social activities, and outings \\& culture. All data is aligned on\na unified global timeline and includes high-quality visual narrations and\nspeech transcripts, curated through human refinement.TeleEgo defines 12\ndiagnostic subtasks across three core capabilities: Memory (recalling past\nevents), Understanding (interpreting the current moment), and Cross-Memory\nReasoning (linking distant events). It contains 3,291 human-verified QA items\nspanning multiple question formats (single-choice, binary, multi-choice, and\nopen-ended), evaluated strictly in a streaming setting. We propose two key\nmetrics -- Real-Time Accuracy and Memory Persistence Time -- to jointly assess\ncorrectness, temporal responsiveness, and long-term retention. TeleEgo provides\na realistic and comprehensive evaluation to advance the development of\npractical AI assistants.",
    "published": "2025-10-28T01:24:24Z",
    "updated": "2025-10-28T01:24:24Z",
    "link": "http://arxiv.org/pdf/2510.23981v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jiaqi Yan",
      "Ruilong Ren",
      "Jingren Liu",
      "Shuning Xu",
      "Ling Wang",
      "Yiheng Wang",
      "Yun Wang",
      "Long Zhang",
      "Xiangyu Chen",
      "Changzhi Sun",
      "Jixiang Luo",
      "Dell Zhang",
      "Hao Sun",
      "Chi Zhang",
      "Xuelong Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23978v1",
    "title": "Efficient Cost-and-Quality Controllable Arbitrary-scale Super-resolution\n  with Fourier Constraints",
    "summary": "Cost-and-Quality (CQ) controllability in arbitrary-scale super-resolution is\ncrucial. Existing methods predict Fourier components one by one using a\nrecurrent neural network. However, this approach leads to performance\ndegradation and inefficiency due to independent prediction. This paper proposes\npredicting multiple components jointly to improve both quality and efficiency.",
    "published": "2025-10-28T01:19:54Z",
    "updated": "2025-10-28T01:19:54Z",
    "link": "http://arxiv.org/pdf/2510.23978v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Kazutoshi Akita",
      "Norimichi Ukita"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23977v1",
    "title": "Synergistic Neural Forecasting of Air Pollution with Stochastic Sampling",
    "summary": "Air pollution remains a leading global health and environmental risk,\nparticularly in regions vulnerable to episodic air pollution spikes due to\nwildfires, urban haze and dust storms. Accurate forecasting of particulate\nmatter (PM) concentrations is essential to enable timely public health warnings\nand interventions, yet existing models often underestimate rare but hazardous\npollution events. Here, we present SynCast, a high-resolution neural\nforecasting model that integrates meteorological and air composition data to\nimprove predictions of both average and extreme pollution levels. Built on a\nregionally adapted transformer backbone and enhanced with a diffusion-based\nstochastic refinement module, SynCast captures the nonlinear dynamics driving\nPM spikes more accurately than existing approaches. Leveraging on harmonized\nERA5 and CAMS datasets, our model shows substantial gains in forecasting\nfidelity across multiple PM variables (PM$_1$, PM$_{2.5}$, PM$_{10}$),\nespecially under extreme conditions. We demonstrate that conventional loss\nfunctions underrepresent distributional tails (rare pollution events) and show\nthat SynCast, guided by domain-aware objectives and extreme value theory,\nsignificantly enhances performance in highly impacted regions without\ncompromising global accuracy. This approach provides a scalable foundation for\nnext-generation air quality early warning systems and supports climate-health\nrisk mitigation in vulnerable regions.",
    "published": "2025-10-28T01:18:00Z",
    "updated": "2025-10-28T01:18:00Z",
    "link": "http://arxiv.org/pdf/2510.23977v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Yohan Abeysinghe",
      "Muhammad Akhtar Munir",
      "Sanoojan Baliah",
      "Ron Sarafian",
      "Fahad Shahbaz Khan",
      "Yinon Rudich",
      "Salman Khan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23968v1",
    "title": "Reasoning Visual Language Model for Chest X-Ray Analysis",
    "summary": "Vision-language models (VLMs) have shown strong promise for medical image\nanalysis, but most remain opaque, offering predictions without the transparent,\nstepwise reasoning clinicians rely on. We present a framework that brings\nchain-of-thought (CoT) reasoning to chest X-ray interpretation. Inspired by\nreasoning-first training paradigms, our approach is designed to learn how\nexperts reason, not just what they conclude, by aligning intermediate steps\nwith observable image evidence and radiology workflow. Beyond accuracy, the\nexplicit reasoning traces support clinical auditability: they reveal why a\nconclusion was reached, which alternatives were considered, and where\nuncertainty remains, enabling quality assurance, error analysis, and safer\nhuman-AI collaboration.\n  Our model couples high-fidelity visual encoding with a two-stage training\nrecipe: a reasoning-style supervised fine-tuning (SFT) followed by\nreinforcement learning (RL) that uses verifiable rewards over a list of X-ray\nabnormalities. The model outputs reasoning that mirrors radiologists systematic\nthought process, uncertainty, and differential diagnosis. In\nout-of-distribution evaluation, the approach achieves competitive multi-label\nclassification while improving interpretability. In a reader study with expert\nradiologists, full reasoning traces increased confidence, supported error\nauditing, and reduced time to finalize reports. We release code and the model\nNV-Reason-CXR-3B to support community progress toward trustworthy, explainable\nAI in chest radiography and other medical imaging tasks where reasoning quality\nis as critical as prediction quality.",
    "published": "2025-10-28T00:48:00Z",
    "updated": "2025-10-28T00:48:00Z",
    "link": "http://arxiv.org/pdf/2510.23968v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Andriy Myronenko",
      "Dong Yang",
      "Baris Turkbey",
      "Mariam Aboian",
      "Sena Azamat",
      "Esra Akcicek",
      "Hongxu Yin",
      "Pavlo Molchanov",
      "Marc Edgar",
      "Yufan He",
      "Pengfei Guo",
      "Yucheng Tang",
      "Daguang Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23943v1",
    "title": "Adaptive Training of INRs via Pruning and Densification",
    "summary": "Encoding input coordinates with sinusoidal functions into multilayer\nperceptrons (MLPs) has proven effective for implicit neural representations\n(INRs) of low-dimensional signals, enabling the modeling of high-frequency\ndetails. However, selecting appropriate input frequencies and architectures\nwhile managing parameter redundancy remains an open challenge, often addressed\nthrough heuristics and heavy hyperparameter optimization schemes. In this\npaper, we introduce AIRe ($\\textbf{A}$daptive $\\textbf{I}$mplicit neural\n$\\textbf{Re}$presentation), an adaptive training scheme that refines the INR\narchitecture over the course of optimization. Our method uses a neuron pruning\nmechanism to avoid redundancy and input frequency densification to improve\nrepresentation capacity, leading to an improved trade-off between network size\nand reconstruction quality. For pruning, we first identify less-contributory\nneurons and apply a targeted weight decay to transfer their information to the\nremaining neurons, followed by structured pruning. Next, the densification\nstage adds input frequencies to spectrum regions where the signal underfits,\nexpanding the representational basis. Through experiments on images and SDFs,\nwe show that AIRe reduces model size while preserving, or even improving,\nreconstruction quality. Code and pretrained models will be released for public\nuse.",
    "published": "2025-10-27T23:52:46Z",
    "updated": "2025-10-27T23:52:46Z",
    "link": "http://arxiv.org/pdf/2510.23943v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Diana Aldana",
      "JoÃ£o Paulo Lima",
      "Daniel Csillag",
      "Daniel Perazzo",
      "Haoan Feng",
      "Luiz Velho",
      "Tiago Novello"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.06456v3",
    "title": "DynCIM: Dynamic Curriculum for Imbalanced Multimodal Learning",
    "summary": "Multimodal learning integrates complementary information from diverse\nmodalities to enhance the decision-making process. However, the potential of\nmultimodal collaboration remains under-exploited due to disparities in data\nquality and modality representation capabilities. To address this, we introduce\nDynCIM, a novel dynamic curriculum learning framework designed to quantify the\ninherent imbalances from both sample and modality perspectives. DynCIM employs\na sample-level curriculum to dynamically assess each sample's difficulty\naccording to prediction deviation, consistency, and stability, while a\nmodality-level curriculum measures modality contributions from global and\nlocal. Furthermore, a gating-based dynamic fusion mechanism is introduced to\nadaptively adjust modality contributions, minimizing redundancy and optimizing\nfusion effectiveness. Extensive experiments on six multimodal benchmarking\ndatasets, spanning both bimodal and trimodal scenarios, demonstrate that DynCIM\nconsistently outperforms state-of-the-art methods. Our approach effectively\nmitigates modality and sample imbalances while enhancing adaptability and\nrobustness in multimodal learning tasks. Our code is available at\nhttps://github.com/Raymond-Qiancx/DynCIM.",
    "published": "2025-03-09T05:30:15Z",
    "updated": "2025-10-27T23:40:26Z",
    "link": "http://arxiv.org/pdf/2503.06456v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Chengxuan Qian",
      "Kai Han",
      "Jiaxin Liu",
      "Zhenlong Yuan",
      "Zhengzhong Zhu",
      "Jingchao Wang",
      "Chongwen Lyu",
      "Jun Chen",
      "Zhe Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.11049v2",
    "title": "Faces of Fairness: Examining Bias in Facial Expression Recognition\n  Datasets and Models",
    "summary": "Building AI systems, including Facial Expression Recognition (FER), involves\ntwo critical aspects: data and model design. Both components significantly\ninfluence bias and fairness in FER tasks. Issues related to bias and fairness\nin FER datasets and models remain underexplored. This study investigates bias\nsources in FER datasets and models. Four common FER datasets--AffectNet, ExpW,\nFer2013, and RAF-DB--are analyzed. The findings demonstrate that AffectNet and\nExpW exhibit high generalizability despite data imbalances. Additionally, this\nresearch evaluates the bias and fairness of six deep models, including three\nstate-of-the-art convolutional neural network (CNN) models: MobileNet, ResNet,\nXceptionNet, as well as three transformer-based models: ViT, CLIP, and\nGPT-4o-mini. Experimental results reveal that while GPT-4o-mini and ViT achieve\nthe highest accuracy scores, they also display the highest levels of bias.\nThese findings underscore the urgent need for developing new methodologies to\nmitigate bias and ensure fairness in datasets and models, particularly in\naffective computing applications. See our implementation details at\nhttps://github.com/MMHosseini/bias_in_FER.",
    "published": "2025-02-16T09:23:16Z",
    "updated": "2025-10-27T23:33:48Z",
    "link": "http://arxiv.org/pdf/2502.11049v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Mohammad Mehdi Hosseini",
      "Ali Pourramezan Fard",
      "Mohammad H. Mahoor"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23930v1",
    "title": "PlanarGS: High-Fidelity Indoor 3D Gaussian Splatting Guided by\n  Vision-Language Planar Priors",
    "summary": "Three-dimensional Gaussian Splatting (3DGS) has recently emerged as an\nefficient representation for novel-view synthesis, achieving impressive visual\nquality. However, in scenes dominated by large and low-texture regions, common\nin indoor environments, the photometric loss used to optimize 3DGS yields\nambiguous geometry and fails to recover high-fidelity 3D surfaces. To overcome\nthis limitation, we introduce PlanarGS, a 3DGS-based framework tailored for\nindoor scene reconstruction. Specifically, we design a pipeline for\nLanguage-Prompted Planar Priors (LP3) that employs a pretrained vision-language\nsegmentation model and refines its region proposals via cross-view fusion and\ninspection with geometric priors. 3D Gaussians in our framework are optimized\nwith two additional terms: a planar prior supervision term that enforces planar\nconsistency, and a geometric prior supervision term that steers the Gaussians\ntoward the depth and normal cues. We have conducted extensive experiments on\nstandard indoor benchmarks. The results show that PlanarGS reconstructs\naccurate and detailed 3D surfaces, consistently outperforming state-of-the-art\nmethods by a large margin. Project page: https://planargs.github.io",
    "published": "2025-10-27T23:32:19Z",
    "updated": "2025-10-27T23:32:19Z",
    "link": "http://arxiv.org/pdf/2510.23930v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xirui Jin",
      "Renbiao Jin",
      "Boying Li",
      "Danping Zou",
      "Wenxian Yu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23929v1",
    "title": "TurboPortrait3D: Single-step diffusion-based fast portrait novel-view\n  synthesis",
    "summary": "We introduce TurboPortrait3D: a method for low-latency novel-view synthesis\nof human portraits. Our approach builds on the observation that existing\nimage-to-3D models for portrait generation, while capable of producing\nrenderable 3D representations, are prone to visual artifacts, often lack of\ndetail, and tend to fail at fully preserving the identity of the subject. On\nthe other hand, image diffusion models excel at generating high-quality images,\nbut besides being computationally expensive, are not grounded in 3D and thus\nare not directly capable of producing multi-view consistent outputs. In this\nwork, we demonstrate that image-space diffusion models can be used to\nsignificantly enhance the quality of existing image-to-avatar methods, while\nmaintaining 3D-awareness and running with low-latency. Our method takes a\nsingle frontal image of a subject as input, and applies a feedforward\nimage-to-avatar generation pipeline to obtain an initial 3D representation and\ncorresponding noisy renders. These noisy renders are then fed to a single-step\ndiffusion model which is conditioned on input image(s), and is specifically\ntrained to refine the renders in a multi-view consistent way. Moreover, we\nintroduce a novel effective training strategy that includes pre-training on a\nlarge corpus of synthetic multi-view data, followed by fine-tuning on\nhigh-quality real images. We demonstrate that our approach both qualitatively\nand quantitatively outperforms current state-of-the-art for portrait novel-view\nsynthesis, while being efficient in time.",
    "published": "2025-10-27T23:28:11Z",
    "updated": "2025-10-27T23:28:11Z",
    "link": "http://arxiv.org/pdf/2510.23929v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Emily Kim",
      "Julieta Martinez",
      "Timur Bagautdinov",
      "Jessica Hodgins"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23928v1",
    "title": "Adaptive Keyframe Selection for Scalable 3D Scene Reconstruction in\n  Dynamic Environments",
    "summary": "In this paper, we propose an adaptive keyframe selection method for improved\n3D scene reconstruction in dynamic environments. The proposed method integrates\ntwo complementary modules: an error-based selection module utilizing\nphotometric and structural similarity (SSIM) errors, and a momentum-based\nupdate module that dynamically adjusts keyframe selection thresholds according\nto scene motion dynamics. By dynamically curating the most informative frames,\nour approach addresses a key data bottleneck in real-time perception. This\nallows for the creation of high-quality 3D world representations from a\ncompressed data stream, a critical step towards scalable robot learning and\ndeployment in complex, dynamic environments. Experimental results demonstrate\nsignificant improvements over traditional static keyframe selection strategies,\nsuch as fixed temporal intervals or uniform frame skipping. These findings\nhighlight a meaningful advancement toward adaptive perception systems that can\ndynamically respond to complex and evolving visual scenes. We evaluate our\nproposed adaptive keyframe selection module on two recent state-of-the-art 3D\nreconstruction networks, Spann3r and CUT3R, and observe consistent improvements\nin reconstruction quality across both frameworks. Furthermore, an extensive\nablation study confirms the effectiveness of each individual component in our\nmethod, underlining their contribution to the overall performance gains.",
    "published": "2025-10-27T23:25:57Z",
    "updated": "2025-10-27T23:25:57Z",
    "link": "http://arxiv.org/pdf/2510.23928v1.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Raman Jha",
      "Yang Zhou",
      "Giuseppe Loianno"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.02076v3",
    "title": "Topology-Preserving Image Segmentation with Spatial-Aware Persistent\n  Feature Matching",
    "summary": "Topological correctness is critical for segmentation of tubular structures,\nwhich pervade in biomedical images. Existing topological segmentation loss\nfunctions are primarily based on the persistent homology of the image. They\nmatch the persistent features from the segmentation with the persistent\nfeatures from the ground truth and minimize the difference between them.\nHowever, these methods suffer from an ambiguous matching problem since the\nmatching only relies on the information in the topological space. In this work,\nwe propose an effective and efficient Spatial-Aware Topological Loss Function\nthat further leverages the information in the original spatial domain of the\nimage to assist the matching of persistent features. Extensive experiments on\nimages of various types of tubular structures show that the proposed method has\nsuperior performance in improving the topological accuracy of the segmentation\ncompared with state-of-the-art methods. Code is available at\nhttps://github.com/JRC-VPLab/SATLoss.",
    "published": "2024-12-03T01:38:15Z",
    "updated": "2025-10-27T22:59:21Z",
    "link": "http://arxiv.org/pdf/2412.02076v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Bo Wen",
      "Haochen Zhang",
      "Dirk-Uwe G. Bartsch",
      "William R. Freeman",
      "Truong Q. Nguyen",
      "Cheolhong An"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2405.20336v2",
    "title": "RapVerse: Coherent Vocals and Whole-Body Motions Generations from Text",
    "summary": "In this work, we introduce a challenging task for simultaneously generating\n3D holistic body motions and singing vocals directly from textual lyrics\ninputs, advancing beyond existing works that typically address these two\nmodalities in isolation. To facilitate this, we first collect the RapVerse\ndataset, a large dataset containing synchronous rapping vocals, lyrics, and\nhigh-quality 3D holistic body meshes. With the RapVerse dataset, we investigate\nthe extent to which scaling autoregressive multimodal transformers across\nlanguage, audio, and motion can enhance the coherent and realistic generation\nof vocals and whole-body human motions. For modality unification, a\nvector-quantized variational autoencoder is employed to encode whole-body\nmotion sequences into discrete motion tokens, while a vocal-to-unit model is\nleveraged to obtain quantized audio tokens preserving content, prosodic\ninformation and singer identity. By jointly performing transformer modeling on\nthese three modalities in a unified way, our framework ensures a seamless and\nrealistic blend of vocals and human motions. Extensive experiments demonstrate\nthat our unified generation framework not only produces coherent and realistic\nsinging vocals alongside human motions directly from textual inputs, but also\nrivals the performance of specialized single-modality generation systems,\nestablishing new benchmarks for joint vocal-motion generation.",
    "published": "2024-05-30T17:59:39Z",
    "updated": "2025-10-27T22:19:03Z",
    "link": "http://arxiv.org/pdf/2405.20336v2.pdf",
    "category": [
      "cs.CV",
      "cs.SD",
      "eess.AS"
    ],
    "authors": [
      "Jiaben Chen",
      "Xin Yan",
      "Yihang Chen",
      "Siyuan Cen",
      "Zixin Wang",
      "Qinwei Ma",
      "Haoyu Zhen",
      "Kaizhi Qian",
      "Lie Lu",
      "Chuang Gan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23894v1",
    "title": "Improving Visual Discriminability of CLIP for Training-Free\n  Open-Vocabulary Semantic Segmentation",
    "summary": "Extending CLIP models to semantic segmentation remains challenging due to the\nmisalignment between their image-level pre-training objectives and the\npixel-level visual understanding required for dense prediction. While prior\nefforts have achieved encouraging results by reorganizing the final layer and\nfeatures, they often inherit the global alignment bias of preceding layers,\nleading to suboptimal segmentation performance. In this work, we propose\nLHT-CLIP, a novel training-free framework that systematically exploits the\nvisual discriminability of CLIP across layer, head, and token levels. Through\ncomprehensive analysis, we reveal three key insights: (i) the final layers\nprimarily strengthen image-text alignment with sacrifice of visual\ndiscriminability (e.g., last 3 layers in ViT-B/16 and 8 layers in ViT-L/14),\npartly due to the emergence of anomalous tokens; (ii) a subset of attention\nheads (e.g., 10 out of 144 in ViT-B/16) display consistently strong visual\ndiscriminability across datasets; (iii) abnormal tokens display sparse and\nconsistent activation pattern compared to normal tokens. Based on these\nfindings, we propose three complementary techniques: semantic-spatial\nreweighting, selective head enhancement, and abnormal token replacement to\neffectively restore visual discriminability and improve segmentation\nperformance without any additional training, auxiliary pre-trained networks, or\nextensive hyperparameter tuning. Extensive experiments on 8 common semantic\nsegmentation benchmarks demonstrate that LHT-CLIP achieves state-of-the-art\nperformance across diverse scenarios, highlighting its effectiveness and\npracticality for real-world deployment.",
    "published": "2025-10-27T22:05:08Z",
    "updated": "2025-10-27T22:05:08Z",
    "link": "http://arxiv.org/pdf/2510.23894v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jinxin Zhou",
      "Jiachen Jiang",
      "Zhihui Zhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23880v1",
    "title": "TRELLISWorld: Training-Free World Generation from Object Generators",
    "summary": "Text-driven 3D scene generation holds promise for a wide range of\napplications, from virtual prototyping to AR/VR and simulation. However,\nexisting methods are often constrained to single-object generation, require\ndomain-specific training, or lack support for full 360-degree viewability. In\nthis work, we present a training-free approach to 3D scene synthesis by\nrepurposing general-purpose text-to-3D object diffusion models as modular tile\ngenerators. We reformulate scene generation as a multi-tile denoising problem,\nwhere overlapping 3D regions are independently generated and seamlessly blended\nvia weighted averaging. This enables scalable synthesis of large, coherent\nscenes while preserving local semantic control. Our method eliminates the need\nfor scene-level datasets or retraining, relies on minimal heuristics, and\ninherits the generalization capabilities of object-level priors. We demonstrate\nthat our approach supports diverse scene layouts, efficient generation, and\nflexible editing, establishing a simple yet powerful foundation for\ngeneral-purpose, language-driven 3D scene construction.",
    "published": "2025-10-27T21:40:31Z",
    "updated": "2025-10-27T21:40:31Z",
    "link": "http://arxiv.org/pdf/2510.23880v1.pdf",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "Hanke Chen",
      "Yuan Liu",
      "Minchen Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2304.07647v7",
    "title": "LASER: A Neuro-Symbolic Framework for Learning Spatial-Temporal Scene\n  Graphs with Weak Supervision",
    "summary": "Supervised approaches for learning spatio-temporal scene graphs (STSG) from\nvideo are greatly hindered due to their reliance on STSG-annotated videos,\nwhich are labor-intensive to construct at scale. Is it feasible to instead use\nreadily available video captions as weak supervision? To address this question,\nwe propose LASER, a neuro-symbolic framework to enable training STSG generators\nusing only video captions. LASER employs large language models to first extract\nlogical specifications with rich spatio-temporal semantic information from\nvideo captions. LASER then trains the underlying STSG generator to align the\npredicted STSG with the specification. The alignment algorithm overcomes the\nchallenges of weak supervision by leveraging a differentiable symbolic reasoner\nand using a combination of contrastive, temporal, and semantics losses. The\noverall approach efficiently trains low-level perception models to extract a\nfine-grained STSG that conforms to the video caption. In doing so, it enables a\nnovel methodology for learning STSGs without tedious annotations. We evaluate\nour method on three video datasets: OpenPVSG, 20BN, and MUGEN. Our approach\ndemonstrates substantial improvements over fully-supervised baselines,\nachieving a unary predicate prediction accuracy of 27.78% (+12.65%) and a\nbinary recall@5 of 0.42 (+0.22) on OpenPVSG. Additionally, LASER exceeds\nbaselines by 7% on 20BN and 5.2% on MUGEN in terms of overall predicate\nprediction accuracy.",
    "published": "2023-04-15T22:24:05Z",
    "updated": "2025-10-27T20:14:22Z",
    "link": "http://arxiv.org/pdf/2304.07647v7.pdf",
    "category": [
      "cs.CV",
      "cs.LG",
      "cs.LO"
    ],
    "authors": [
      "Jiani Huang",
      "Ziyang Li",
      "Mayur Naik",
      "Ser-Nam Lim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23816v1",
    "title": "RareFlow: Physics-Aware Flow-Matching for Cross-Sensor Super-Resolution\n  of Rare-Earth Features",
    "summary": "Super-resolution (SR) for remote sensing imagery often fails under\nout-of-distribution (OOD) conditions, such as rare geomorphic features captured\nby diverse sensors, producing visually plausible but physically inaccurate\nresults. We present RareFlow, a physics-aware SR framework designed for OOD\nrobustness. RareFlow's core is a dual-conditioning architecture. A Gated\nControlNet preserves fine-grained geometric fidelity from the low-resolution\ninput, while textual prompts provide semantic guidance for synthesizing complex\nfeatures. To ensure physically sound outputs, we introduce a multifaceted loss\nfunction that enforces both spectral and radiometric consistency with sensor\nproperties. Furthermore, the framework quantifies its own predictive\nuncertainty by employing a stochastic forward pass approach; the resulting\noutput variance directly identifies unfamiliar inputs, mitigating feature\nhallucination. We validate RareFlow on a new, curated benchmark of multi-sensor\nsatellite imagery. In blind evaluations, geophysical experts rated our model's\noutputs as approaching the fidelity of ground truth imagery, significantly\noutperforming state-of-the-art baselines. This qualitative superiority is\ncorroborated by quantitative gains in perceptual metrics, including a nearly\n40\\% reduction in FID. RareFlow provides a robust framework for high-fidelity\nsynthesis in data-scarce scientific domains and offers a new paradigm for\ncontrolled generation under severe domain shift.",
    "published": "2025-10-27T19:56:43Z",
    "updated": "2025-10-27T19:56:43Z",
    "link": "http://arxiv.org/pdf/2510.23816v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Forouzan Fallah",
      "Wenwen Li",
      "Chia-Yu Hsu",
      "Hyunho Lee",
      "Yezhou Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.15710v2",
    "title": "UniMedVL: Unifying Medical Multimodal Understanding And Generation\n  Through Observation-Knowledge-Analysis",
    "summary": "Medical diagnostic applications require models that can process multimodal\nmedical inputs (images, patient histories, lab results) and generate diverse\noutputs including both textual reports and visual content (annotations,\nsegmentation masks, and images). Despite this need, existing medical AI systems\ndisrupt this unified process: medical image understanding models interpret\nimages but cannot generate visual outputs, while medical image generation\nmodels synthesize images but cannot provide textual explanations. This leads to\ngaps in data representation, feature integration, and task-level multimodal\ncapabilities. To this end, we propose a multi-level framework that draws\ninspiration from diagnostic workflows through the\nObservation-Knowledge-Analysis (OKA) paradigm. Specifically, at the observation\nlevel, we construct UniMed-5M, a dataset comprising over 5.6M samples that\nreformat diverse unimodal data into multimodal pairs for foundational\nobservation. At the knowledge level, we propose Progressive Curriculum Learning\nthat systematically introduces medical multimodal knowledge. At the analysis\nlevel, we introduce UniMedVL, the first medical unified multimodal model for\nthe simultaneous analysis of image understanding and generation tasks within a\nsingle architecture. UniMedVL achieves superior performance on five medical\nimage understanding benchmarks, while matching specialized models in generation\nquality across eight medical imaging modalities. Crucially, our unified\narchitecture enables bidirectional knowledge sharing: generation tasks enhance\nvisual understanding features, demonstrating that integrating traditionally\nseparate capabilities within a single medical framework unlocks improvements\nacross diverse medical vision-language tasks. Code is available at\nhttps://github.com/uni-medical/UniMedVL.",
    "published": "2025-10-17T14:54:58Z",
    "updated": "2025-10-27T19:55:52Z",
    "link": "http://arxiv.org/pdf/2510.15710v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Junzhi Ning",
      "Wei Li",
      "Cheng Tang",
      "Jiashi Lin",
      "Chenglong Ma",
      "Chaoyang Zhang",
      "Jiyao Liu",
      "Ying Chen",
      "Shujian Gao",
      "Lihao Liu",
      "Yuandong Pu",
      "Huihui Xu",
      "Chenhui Gou",
      "Ziyan Huang",
      "Yi Xin",
      "Qi Qin",
      "Zhongying Deng",
      "Diping Song",
      "Bin Fu",
      "Guang Yang",
      "Yuanfeng Ji",
      "Tianbin Li",
      "Yanzhou Su",
      "Jin Ye",
      "Shixiang Tang",
      "Ming Hu",
      "Junjun He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.06131v2",
    "title": "FaceCloak: Learning to Protect Face Templates",
    "summary": "Generative models can reconstruct face images from encoded representations\n(templates) bearing remarkable likeness to the original face, raising security\nand privacy concerns. We present \\textsc{FaceCloak}, a neural network framework\nthat protects face templates by generating smart, renewable binary cloaks. Our\nmethod proactively thwarts inversion attacks by cloaking face templates with\nunique disruptors synthesized from a single face template on the fly while\nprovably retaining biometric utility and unlinkability. Our cloaked templates\ncan suppress sensitive attributes while generalizing to novel feature\nextraction schemes and outperform leading baselines in terms of biometric\nmatching and resiliency to reconstruction attacks. \\textsc{FaceCloak}-based\nmatching is extremely fast (inference time =0.28 ms) and light (0.57 MB). We\nhave released our \\href{https://github.com/sudban3089/FaceCloak.git}{code} for\nreproducible research.",
    "published": "2025-04-08T15:23:21Z",
    "updated": "2025-10-27T18:41:08Z",
    "link": "http://arxiv.org/pdf/2504.06131v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Sudipta Banerjee",
      "Anubhav Jain",
      "Chinmay Hegde",
      "Nasir Memon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.08428v3",
    "title": "Physics-Informed Latent Neural Operator for Real-time Predictions of\n  time-dependent parametric PDEs",
    "summary": "Deep operator network (DeepONet) has shown significant promise as surrogate\nmodels for systems governed by partial differential equations (PDEs), enabling\naccurate mappings between infinite-dimensional function spaces. However, when\napplied to systems with high-dimensional input-output mappings arising from\nlarge numbers of spatial and temporal collocation points, these models often\nrequire heavily overparameterized networks, leading to long training times.\nLatent DeepONet addresses some of these challenges by introducing a two-step\napproach: first learning a reduced latent space using a separate model,\nfollowed by operator learning within this latent space. While efficient, this\nmethod is inherently data-driven and lacks mechanisms for incorporating\nphysical laws, limiting its robustness and generalizability in data-scarce\nsettings. In this work, we propose PI-Latent-NO, a physics-informed latent\nneural operator framework that integrates governing physics directly into the\nlearning process. Our architecture features two coupled DeepONets trained\nend-to-end: a Latent-DeepONet that learns a low-dimensional representation of\nthe solution, and a Reconstruction-DeepONet that maps this latent\nrepresentation back to the physical space. By embedding PDE constraints into\nthe training via automatic differentiation, our method eliminates the need for\nlabeled training data and ensures physics-consistent predictions. The proposed\nframework is both memory and compute-efficient, exhibiting near-constant\nscaling with problem size and demonstrating significant speedups over\ntraditional physics-informed operator models. We validate our approach on a\nrange of parametric PDEs, showcasing its accuracy, scalability, and suitability\nfor real-time prediction in complex physical systems.",
    "published": "2025-01-14T20:38:30Z",
    "updated": "2025-10-28T17:58:31Z",
    "link": "http://arxiv.org/pdf/2501.08428v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Sharmila Karumuri",
      "Lori Graham-Brady",
      "Somdatta Goswami"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24710v1",
    "title": "A Single-Loop First-Order Algorithm for Linearly Constrained Bilevel\n  Optimization",
    "summary": "We study bilevel optimization problems where the lower-level problems are\nstrongly convex and have coupled linear constraints. To overcome the potential\nnon-smoothness of the hyper-objective and the computational challenges\nassociated with the Hessian matrix, we utilize penalty and augmented Lagrangian\nmethods to reformulate the original problem as a single-level one. Especially,\nwe establish a strong theoretical connection between the reformulated function\nand the original hyper-objective by characterizing the closeness of their\nvalues and derivatives. Based on this reformulation, we propose a single-loop,\nfirst-order algorithm for linearly constrained bilevel optimization (SFLCB). We\nprovide rigorous analyses of its non-asymptotic convergence rates, showing an\nimprovement over prior double-loop algorithms -- form\n$O(\\epsilon^{-3}\\log(\\epsilon^{-1}))$ to $O(\\epsilon^{-3})$. The experiments\ncorroborate our theoretical findings and demonstrate the practical efficiency\nof the proposed SFLCB algorithm. Simulation code is provided at\nhttps://github.com/ShenGroup/SFLCB.",
    "published": "2025-10-28T17:58:17Z",
    "updated": "2025-10-28T17:58:17Z",
    "link": "http://arxiv.org/pdf/2510.24710v1.pdf",
    "category": [
      "math.OC",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "stat.ML"
    ],
    "authors": [
      "Wei Shen",
      "Jiawei Zhang",
      "Minhui Huang",
      "Cong Shen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2406.09795v2",
    "title": "DeltaPhi: Physical States Residual Learning for Neural Operators in\n  Data-Limited PDE Solving",
    "summary": "The limited availability of high-quality training data poses a major obstacle\nin data-driven PDE solving, where expensive data collection and resolution\nconstraints severely impact the ability of neural operator networks to learn\nand generalize the underlying physical system. To address this challenge, we\npropose DeltaPhi, a novel learning framework that transforms the PDE solving\ntask from learning direct input-output mappings to learning the residuals\nbetween similar physical states, a fundamentally different approach to neural\noperator learning. This reformulation provides implicit data augmentation by\nexploiting the inherent stability of physical systems where closer initial\nstates lead to closer evolution trajectories. DeltaPhi is architecture-agnostic\nand can be seamlessly integrated with existing neural operators to enhance\ntheir performance. Extensive experiments demonstrate consistent and significant\nimprovements across diverse physical systems including regular and irregular\ndomains, different neural architectures, multiple training data amount, and\ncross-resolution scenarios, confirming its effectiveness as a general\nenhancement for neural operators in data-limited PDE solving.",
    "published": "2024-06-14T07:45:07Z",
    "updated": "2025-10-28T17:56:59Z",
    "link": "http://arxiv.org/pdf/2406.09795v2.pdf",
    "category": [
      "cs.LG",
      "cs.NA",
      "math.NA"
    ],
    "authors": [
      "Xihang Yue",
      "Yi Yang",
      "Linchao Zhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2306.08848v4",
    "title": "Datasheets for Machine Learning Sensors",
    "summary": "Machine learning (ML) is becoming prevalent in embedded AI sensing systems.\nThese \"ML sensors\" enable context-sensitive, real-time data collection and\ndecision-making across diverse applications ranging from anomaly detection in\nindustrial settings to wildlife tracking for conservation efforts. As such,\nthere is a need to provide transparency in the operation of such ML-enabled\nsensing systems through comprehensive documentation. This is needed to enable\ntheir reproducibility, to address new compliance and auditing regimes mandated\nin regulation and industry-specific policy, and to verify and validate the\nresponsible nature of their operation. To address this gap, we introduce the\ndatasheet for ML sensors framework. We provide a comprehensive template,\ncollaboratively developed in academia-industry partnerships, that captures the\ndistinct attributes of ML sensors, including hardware specifications, ML model\nand dataset characteristics, end-to-end performance metrics, and environmental\nimpacts. Our framework addresses the continuous streaming nature of sensor\ndata, real-time processing requirements, and embeds benchmarking methodologies\nthat reflect real-world deployment conditions, ensuring practical viability.\nAligned with the FAIR principles (Findability, Accessibility, Interoperability,\nand Reusability), our approach enhances the transparency and reusability of ML\nsensor documentation across academic, industrial, and regulatory domains. To\nshow the application of our approach, we present two datasheets: the first for\nan open-source ML sensor designed in-house and the second for a commercial ML\nsensor developed by industry collaborators, both performing computer\nvision-based person detection.",
    "published": "2023-06-15T04:24:13Z",
    "updated": "2025-10-28T17:53:16Z",
    "link": "http://arxiv.org/pdf/2306.08848v4.pdf",
    "category": [
      "cs.LG",
      "cs.CY",
      "cs.HC"
    ],
    "authors": [
      "Matthew Stewart",
      "Yuke Zhang",
      "Pete Warden",
      "Yasmine Omri",
      "Shvetank Prakash",
      "Jacob Huckelberry",
      "Joao Henrique Santos",
      "Shawn Hymel",
      "Benjamin Yeager Brown",
      "Jim MacArthur",
      "Nat Jeffries",
      "Emanuel Moss",
      "Mona Sloane",
      "Brian Plancher",
      "Vijay Janapa Reddi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24672v1",
    "title": "Eigenfunction Extraction for Ordered Representation Learning",
    "summary": "Recent advances in representation learning reveal that widely used\nobjectives, such as contrastive and non-contrastive, implicitly perform\nspectral decomposition of a contextual kernel, induced by the relationship\nbetween inputs and their contexts. Yet, these methods recover only the linear\nspan of top eigenfunctions of the kernel, whereas exact spectral decomposition\nis essential for understanding feature ordering and importance. In this work,\nwe propose a general framework to extract ordered and identifiable\neigenfunctions, based on modular building blocks designed to satisfy key\ndesiderata, including compatibility with the contextual kernel and scalability\nto modern settings. We then show how two main methodological paradigms,\nlow-rank approximation and Rayleigh quotient optimization, align with this\nframework for eigenfunction extraction. Finally, we validate our approach on\nsynthetic kernels and demonstrate on real-world image datasets that the\nrecovered eigenvalues act as effective importance scores for feature selection,\nenabling principled efficiency-accuracy tradeoffs via adaptive-dimensional\nrepresentations.",
    "published": "2025-10-28T17:37:12Z",
    "updated": "2025-10-28T17:37:12Z",
    "link": "http://arxiv.org/pdf/2510.24672v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Burak VarÄ±cÄ±",
      "Che-Ping Tsai",
      "Ritabrata Ray",
      "Nicholas M. Boffi",
      "Pradeep Ravikumar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24670v1",
    "title": "Pearl: A Foundation Model for Placing Every Atom in the Right Location",
    "summary": "Accurately predicting the three-dimensional structures of protein-ligand\ncomplexes remains a fundamental challenge in computational drug discovery that\nlimits the pace and success of therapeutic design. Deep learning methods have\nrecently shown strong potential as structural prediction tools, achieving\npromising accuracy across diverse biomolecular systems. However, their\nperformance and utility are constrained by scarce experimental data,\ninefficient architectures, physically invalid poses, and the limited ability to\nexploit auxiliary information available at inference. To address these issues,\nwe introduce Pearl (Placing Every Atom in the Right Location), a foundation\nmodel for protein-ligand cofolding at scale. Pearl addresses these challenges\nwith three key innovations: (1) training recipes that include large-scale\nsynthetic data to overcome data scarcity; (2) architectures that incorporate an\nSO(3)-equivariant diffusion module to inherently respect 3D rotational\nsymmetries, improving generalization and sample efficiency, and (3)\ncontrollable inference, including a generalized multi-chain templating system\nsupporting both protein and non-polymeric components as well as dual\nunconditional/conditional modes. Pearl establishes a new state-of-the-art\nperformance in protein-ligand cofolding. On the key metric of generating\naccurate (RMSD < 2 \\r{A}) and physically valid poses, Pearl surpasses AlphaFold\n3 and other open source baselines on the public Runs N' Poses and PoseBusters\nbenchmarks, delivering 14.5% and 14.2% improvements, respectively, over the\nnext best model. In the pocket-conditional cofolding regime, Pearl delivers\n$3.6\\times$ improvement on a proprietary set of challenging, real-world drug\ntargets at the more rigorous RMSD < 1 \\r{A} threshold. Finally, we demonstrate\nthat model performance correlates directly with synthetic dataset size used in\ntraining.",
    "published": "2025-10-28T17:36:51Z",
    "updated": "2025-10-28T17:36:51Z",
    "link": "http://arxiv.org/pdf/2510.24670v1.pdf",
    "category": [
      "cs.LG",
      "q-bio.QM"
    ],
    "authors": [
      " Genesis Research Team",
      "Alejandro Dobles",
      "Nina Jovic",
      "Kenneth Leidal",
      "Pranav Murugan",
      "David C. Williams",
      "Drausin Wulsin",
      "Nate Gruver",
      "Christina X. Ji",
      "Korrawat Pruegsanusak",
      "Gianluca Scarpellini",
      "Ansh Sharma",
      "Wojciech Swiderski",
      "Andrea Bootsma",
      "Richard Strong Bowen",
      "Charlotte Chen",
      "Jamin Chen",
      "Marc AndrÃ© DÃ¤mgen",
      "Roy Tal Dew",
      "Benjamin DiFrancesco",
      "J. D. Fishman",
      "Alla Ivanova",
      "Zach Kagin",
      "David Li-Bland",
      "Zuli Liu",
      "Igor Morozov",
      "Jeffrey Ouyang-Zhang",
      "Frank C. Pickard IV",
      "Kushal S. Shah",
      "Ben Shor",
      "Gabriel Monteiro da Silva",
      "Maxx Tessmer",
      "Carl Tilbury",
      "Cyr Vetcher",
      "Daniel Zeng",
      "Maruan Al-Shedivat",
      "Aleksandra Faust",
      "Evan N. Feinberg",
      "Michael V. LeVine",
      "Matteus Pan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23455v2",
    "title": "SGFusion: Stochastic Geographic Gradient Fusion in Federated Learning",
    "summary": "This paper proposes Stochastic Geographic Gradient Fusion (SGFusion), a novel\ntraining algorithm to leverage the geographic information of mobile users in\nFederated Learning (FL). SGFusion maps the data collected by mobile devices\nonto geographical zones and trains one FL model per zone, which adapts well to\nthe data and behaviors of users in that zone. SGFusion models the local\ndata-based correlation among geographical zones as a hierarchical random graph\n(HRG) optimized by Markov Chain Monte Carlo sampling. At each training step,\nevery zone fuses its local gradient with gradients derived from a small set of\nother zones sampled from the HRG. This approach enables knowledge fusion and\nsharing among geographical zones in a probabilistic and stochastic gradient\nfusion process with self-attention weights, such that \"more similar\" zones have\n\"higher probabilities\" of sharing gradients with \"larger attention weights.\"\nSGFusion remarkably improves model utility without introducing undue\ncomputational cost. Extensive theoretical and empirical results using a\nheart-rate prediction dataset collected across 6 countries show that models\ntrained with SGFusion converge with upper-bounded expected errors and\nsignificantly improve utility in all countries compared to existing approaches\nwithout notable cost in system scalability.",
    "published": "2025-10-27T15:56:19Z",
    "updated": "2025-10-28T17:15:50Z",
    "link": "http://arxiv.org/pdf/2510.23455v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Khoa Nguyen",
      "Khang Tran",
      "NhatHai Phan",
      "Cristian Borcea",
      "Rouming Jin",
      "Issa Khalil"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.13883v3",
    "title": "Hybrid Deep Learning Model to Estimate Cognitive Effort from fNIRS\n  Signals",
    "summary": "This study estimates cognitive effort based on functional near-infrared\nspectroscopy data and performance scores using a hybrid DeepNet model. The\nestimation of cognitive effort enables educators to modify material to enhance\nlearning effectiveness and student engagement. In this study, we collected\noxygenated hemoglobin using functional near-infrared spectroscopy during an\neducational quiz game. Participants (n=16) responded to 16 questions in a\nUnity-based educational game, each within a 30-second response time limit. We\nused DeepNet models to predict the performance score from the oxygenated\nhemoglobin, and compared traditional machine learning and DeepNet models to\ndetermine which approach provides better accuracy in predicting performance\nscores. The result shows that the proposed CNN-GRU gives better performance\nwith 73% than other models. After the prediction, we used the predicted score\nand the oxygenated hemoglobin to observe cognitive effort by calculating\nrelative neural efficiency and involvement in our test cases. Our result shows\nthat even with moderate accuracy, the predicted cognitive effort closely follow\nthe actual trends. This findings can be helpful in designing and improving\nlearning environments and provide valuable insights into learning materials.",
    "published": "2025-04-03T17:54:59Z",
    "updated": "2025-10-28T17:05:46Z",
    "link": "http://arxiv.org/pdf/2504.13883v3.pdf",
    "category": [
      "cs.HC",
      "cs.LG"
    ],
    "authors": [
      "Shayla Sharmin",
      "Roghayeh Leila Barmaki"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24633v1",
    "title": "Symbolic Snapshot Ensembles",
    "summary": "Inductive logic programming (ILP) is a form of logical machine learning. Most\nILP algorithms learn a single hypothesis from a single training run. Ensemble\nmethods train an ILP algorithm multiple times to learn multiple hypotheses. In\nthis paper, we train an ILP algorithm only once and save intermediate\nhypotheses. We then combine the hypotheses using a minimum description length\nweighting scheme. Our experiments on multiple benchmarks, including game\nplaying and visual reasoning, show that our approach improves predictive\naccuracy by 4% with less than 1% computational overhead.",
    "published": "2025-10-28T17:01:38Z",
    "updated": "2025-10-28T17:01:38Z",
    "link": "http://arxiv.org/pdf/2510.24633v1.pdf",
    "category": [
      "cs.LG",
      "cs.LO"
    ],
    "authors": [
      "Mingyue Liu",
      "Andrew Cropper"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24621v1",
    "title": "Coreset for Robust Geometric Median: Eliminating Size Dependency on\n  Outliers",
    "summary": "We study the robust geometric median problem in Euclidean space\n$\\mathbb{R}^d$, with a focus on coreset construction.A coreset is a compact\nsummary of a dataset $P$ of size $n$ that approximates the robust cost for all\ncenters $c$ within a multiplicative error $\\varepsilon$. Given an outlier count\n$m$, we construct a coreset of size $\\tilde{O}(\\varepsilon^{-2} \\cdot\n\\min\\{\\varepsilon^{-2}, d\\})$ when $n \\geq 4m$, eliminating the $O(m)$\ndependency present in prior work [Huang et al., 2022 & 2023]. For the special\ncase of $d = 1$, we achieve an optimal coreset size of\n$\\tilde{\\Theta}(\\varepsilon^{-1/2} + \\frac{m}{n} \\varepsilon^{-1})$, revealing\na clear separation from the vanilla case studied in [Huang et al., 2023;\nAfshani and Chris, 2024]. Our results further extend to robust\n$(k,z)$-clustering in various metric spaces, eliminating the $m$-dependence\nunder mild data assumptions. The key technical contribution is a novel\nnon-component-wise error analysis, enabling substantial reduction of outlier\ninfluence, unlike prior methods that retain them.Empirically, our algorithms\nconsistently outperform existing baselines in terms of size-accuracy tradeoffs\nand runtime, even when data assumptions are violated across a wide range of\ndatasets.",
    "published": "2025-10-28T16:49:03Z",
    "updated": "2025-10-28T16:49:03Z",
    "link": "http://arxiv.org/pdf/2510.24621v1.pdf",
    "category": [
      "cs.DS",
      "cs.CG",
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Ziyi Fang",
      "Lingxiao Huang",
      "Runkai Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.16893v2",
    "title": "Global Optimization of Gaussian Process Acquisition Functions Using a\n  Piecewise-Linear Kernel Approximation",
    "summary": "Bayesian optimization relies on iteratively constructing and optimizing an\nacquisition function. The latter turns out to be a challenging, non-convex\noptimization problem itself. Despite the relative importance of this step, most\nalgorithms employ sampling- or gradient-based methods, which do not provably\nconverge to global optima. This work investigates mixed-integer programming\n(MIP) as a paradigm for global acquisition function optimization. Specifically,\nour Piecewise-linear Kernel Mixed Integer Quadratic Programming (PK-MIQP)\nformulation introduces a piecewise-linear approximation for Gaussian process\nkernels and admits a corresponding MIQP representation for acquisition\nfunctions. The proposed method is applicable to uncertainty-based acquisition\nfunctions for any stationary or dot-product kernel. We analyze the theoretical\nregret bounds of the proposed approximation, and empirically demonstrate the\nframework on synthetic functions, constrained benchmarks, and a hyperparameter\ntuning task.",
    "published": "2024-10-22T10:56:52Z",
    "updated": "2025-10-28T16:44:42Z",
    "link": "http://arxiv.org/pdf/2410.16893v2.pdf",
    "category": [
      "math.OC",
      "cs.LG"
    ],
    "authors": [
      "Yilin Xie",
      "Shiqiang Zhang",
      "Joel A. Paulson",
      "Calvin Tsay"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24616v1",
    "title": "Statistical physics of deep learning: Optimal learning of a multi-layer\n  perceptron near interpolation",
    "summary": "For three decades statistical physics has been providing a framework to\nanalyse neural networks. A long-standing question remained on its capacity to\ntackle deep learning models capturing rich feature learning effects, thus going\nbeyond the narrow networks or kernel methods analysed until now. We positively\nanswer through the study of the supervised learning of a multi-layer\nperceptron. Importantly, (i) its width scales as the input dimension, making it\nmore prone to feature learning than ultra wide networks, and more expressive\nthan narrow ones or with fixed embedding layers; and (ii) we focus on the\nchallenging interpolation regime where the number of trainable parameters and\ndata are comparable, which forces the model to adapt to the task. We consider\nthe matched teacher-student setting. It provides the fundamental limits of\nlearning random deep neural network targets and helps in identifying the\nsufficient statistics describing what is learnt by an optimally trained network\nas the data budget increases. A rich phenomenology emerges with various\nlearning transitions. With enough data optimal performance is attained through\nmodel's \"specialisation\" towards the target, but it can be hard to reach for\ntraining algorithms which get attracted by sub-optimal solutions predicted by\nthe theory. Specialisation occurs inhomogeneously across layers, propagating\nfrom shallow towards deep ones, but also across neurons in each layer.\nFurthermore, deeper targets are harder to learn. Despite its simplicity, the\nBayesian-optimal setting provides insights on how the depth, non-linearity and\nfinite (proportional) width influence neural networks in the feature learning\nregime that are potentially relevant way beyond it.",
    "published": "2025-10-28T16:44:34Z",
    "updated": "2025-10-28T16:44:34Z",
    "link": "http://arxiv.org/pdf/2510.24616v1.pdf",
    "category": [
      "stat.ML",
      "cond-mat.dis-nn",
      "cond-mat.stat-mech",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "authors": [
      "Jean Barbier",
      "Francesco Camilli",
      "Minh-Toan Nguyen",
      "Mauro Pastore",
      "Rudy Skerk"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24614v1",
    "title": "Semi-supervised and unsupervised learning for health indicator\n  extraction from guided waves in aerospace composite structures",
    "summary": "Health indicators (HIs) are central to diagnosing and prognosing the\ncondition of aerospace composite structures, enabling efficient maintenance and\noperational safety. However, extracting reliable HIs remains challenging due to\nvariability in material properties, stochastic damage evolution, and diverse\ndamage modes. Manufacturing defects (e.g., disbonds) and in-service incidents\n(e.g., bird strikes) further complicate this process. This study presents a\ncomprehensive data-driven framework that learns HIs via two learning approaches\nintegrated with multi-domain signal processing. Because ground-truth HIs are\nunavailable, a semi-supervised and an unsupervised approach are proposed: (i) a\ndiversity deep semi-supervised anomaly detection (Diversity-DeepSAD) approach\naugmented with continuous auxiliary labels used as hypothetical damage proxies,\nwhich overcomes the limitation of prior binary labels that only distinguish\nhealthy and failed states while neglecting intermediate degradation, and (ii) a\ndegradation-trend-constrained variational autoencoder (DTC-VAE), in which the\nmonotonicity criterion is embedded via an explicit trend constraint. Guided\nwaves with multiple excitation frequencies are used to monitor single-stiffener\ncomposite structures under fatigue loading. Time, frequency, and time-frequency\nrepresentations are explored, and per-frequency HIs are fused via unsupervised\nensemble learning to mitigate frequency dependence and reduce variance. Using\nfast Fourier transform features, the augmented Diversity-DeepSAD model achieved\n81.6% performance, while DTC-VAE delivered the most consistent HIs with 92.3%\nperformance, outperforming existing baselines.",
    "published": "2025-10-28T16:44:11Z",
    "updated": "2025-10-28T16:44:11Z",
    "link": "http://arxiv.org/pdf/2510.24614v1.pdf",
    "category": [
      "cs.LG",
      "cs.CE",
      "eess.SP"
    ],
    "authors": [
      "James Josep Perry",
      "Pablo Garcia-Conde Ortiz",
      "George Konstantinou",
      "Cornelie Vergouwen",
      "Edlyn Santha Kumaran",
      "Morteza Moradi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24601v1",
    "title": "Comparison of generalised additive models and neural networks in\n  applications: A systematic review",
    "summary": "Neural networks have become a popular tool in predictive modelling, more\ncommonly associated with machine learning and artificial intelligence than with\nstatistics. Generalised Additive Models (GAMs) are flexible non-linear\nstatistical models that retain interpretability. Both are state-of-the-art in\ntheir own right, with their respective advantages and disadvantages. This paper\nanalyses how these two model classes have performed on real-world tabular data.\nFollowing PRISMA guidelines, we conducted a systematic review of papers that\nperformed empirical comparisons of GAMs and neural networks. Eligible papers\nwere identified, yielding 143 papers, with 430 datasets. Key attributes at both\npaper and dataset levels were extracted and reported. Beyond summarising\ncomparisons, we analyse reported performance metrics using mixed-effects\nmodelling to investigate potential characteristics that can explain and\nquantify observed differences, including application area, study year, sample\nsize, number of predictors, and neural network complexity. Across datasets, no\nconsistent evidence of superiority was found for either GAMs or neural networks\nwhen considering the most frequently reported metrics (RMSE, $R^2$, and AUC).\nNeural networks tended to outperform in larger datasets and in those with more\npredictors, but this advantage narrowed over time. Conversely, GAMs remained\ncompetitive, particularly in smaller data settings, while retaining\ninterpretability. Reporting of dataset characteristics and neural network\ncomplexity was incomplete in much of the literature, limiting transparency and\nreproducibility. This review highlights that GAMs and neural networks should be\nviewed as complementary approaches rather than competitors. For many tabular\napplications, the performance trade-off is modest, and interpretability may\nfavour GAMs.",
    "published": "2025-10-28T16:28:42Z",
    "updated": "2025-10-28T16:28:42Z",
    "link": "http://arxiv.org/pdf/2510.24601v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "68T07, 62J02"
    ],
    "authors": [
      "Jessica Doohan",
      "Lucas Kook",
      "Kevin Burke"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24598v1",
    "title": "A Novel XAI-Enhanced Quantum Adversarial Networks for Velocity\n  Dispersion Modeling in MaNGA Galaxies",
    "summary": "Current quantum machine learning approaches often face challenges balancing\npredictive accuracy, robustness, and interpretability. To address this, we\npropose a novel quantum adversarial framework that integrates a hybrid quantum\nneural network (QNN) with classical deep learning layers, guided by an\nevaluator model with LIME-based interpretability, and extended through quantum\nGAN and self-supervised variants. In the proposed model, an adversarial\nevaluator concurrently guides the QNN by computing feedback loss, thereby\noptimizing both prediction accuracy and model explainability. Empirical\nevaluations show that the Vanilla model achieves RMSE = 0.27, MSE = 0.071, MAE\n= 0.21, and R^2 = 0.59, delivering the most consistent performance across\nregression metrics compared to adversarial counterparts. These results\ndemonstrate the potential of combining quantum-inspired methods with classical\narchitectures to develop lightweight, high-performance, and interpretable\npredictive models, advancing the applicability of QML beyond current\nlimitations.",
    "published": "2025-10-28T16:27:10Z",
    "updated": "2025-10-28T16:27:10Z",
    "link": "http://arxiv.org/pdf/2510.24598v1.pdf",
    "category": [
      "cs.LG",
      "cs.CR"
    ],
    "authors": [
      "Sathwik Narkedimilli",
      "N V Saran Kumar",
      "Aswath Babu H",
      "Manjunath K Vanahalli",
      "Manish M",
      "Vinija Jain",
      "Aman Chadha"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2405.19000v2",
    "title": "FedMAP: Personalised Federated Learning for Real Large-Scale Healthcare\n  Systems",
    "summary": "Federated learning (FL) promises to enable collaborative machine learning\nacross healthcare sites whilst preserving data privacy. Practical deployment\nremains limited by statistical heterogeneity arising from differences in\npatient demographics, treatments, and outcomes, and infrastructure constraints.\nWe introduce FedMAP, a personalised FL (PFL) framework that addresses\nheterogeneity through local Maximum a Posteriori (MAP) estimation with Input\nConvex Neural Network priors. These priors represent global knowledge gathered\nfrom other sites that guides the model while adapting to local data, and we\nprovide a formal proof of convergence. Unlike many PFL methods that rely on\nfixed regularisation, FedMAP's prior adaptively learns patterns that capture\ncomplex inter-site relationships. We demonstrate improved performance compared\nto local training, FedAvg, and several PFL methods across three large-scale\nclinical datasets: 10-year cardiovascular risk prediction (CPRD, 387 general\npractitioner practices, 258,688 patients), iron deficiency detection (INTERVAL,\n4 donor centres, 31,949 blood donors), and mortality prediction (eICU, 150\nhospitals, 44,842 patients). FedMAP incorporates a three-tier design that\nenables participation across healthcare sites with varying infrastructure and\ntechnical capabilities, from full federated training to inference-only\ndeployment. Geographical analysis reveals substantial equity improvements, with\nunderperforming regions achieving up to 14.3% performance gains. This framework\nprovides the first practical pathway for large-scale healthcare FL deployment,\nwhich ensures clinical sites at all scales can benefit, equity is enhanced, and\nprivacy is retained.",
    "published": "2024-05-29T11:28:06Z",
    "updated": "2025-10-28T16:16:00Z",
    "link": "http://arxiv.org/pdf/2405.19000v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Fan Zhang",
      "Daniel Kreuter",
      "Carlos Esteve-YagÃ¼e",
      "SÃ¶ren Dittmer",
      "Javier Fernandez-Marques",
      "Samantha Ip",
      "BloodCounts! Consortium",
      "Norbert C. J. de Wit",
      "Angela Wood",
      "James HF Rudd",
      "Nicholas Lane",
      "Nicholas S Gleadall",
      "Carola-Bibiane SchÃ¶nlieb",
      "Michael Roberts"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24577v1",
    "title": "Physics-Informed Extreme Learning Machine (PIELM): Opportunities and\n  Challenges",
    "summary": "We are very delighted to see the fast development of physics-informed extreme\nlearning machine (PIELM) in recent years for higher computation efficiency and\naccuracy in physics-informed machine learning. As a summary or review on PIELM\nis currently not available, we would like to take this opportunity to show our\nperspective and experience for this promising research direction. We can see\nmany efforts are made to solve PDEs with sharp gradients, nonlinearities,\nhigh-frequency behavior, hard constraints, uncertainty, multiphysics coupling.\nDespite the success, many urgent challenges remain to be tackled, which also\nprovides us opportunities to develop more robust, interpretable, and\ngeneralizable PIELM frameworks with applications in science and engineering.",
    "published": "2025-10-28T16:11:16Z",
    "updated": "2025-10-28T16:11:16Z",
    "link": "http://arxiv.org/pdf/2510.24577v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "He Yang",
      "Fei Ren",
      "Hai-Sui Yu",
      "Xiaohui Chen",
      "Pei-Zhi Zhuang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.05295v2",
    "title": "GST-UNet: A Neural Framework for Spatiotemporal Causal Inference with\n  Time-Varying Confounding",
    "summary": "Estimating causal effects from spatiotemporal observational data is essential\nin public health, environmental science, and policy evaluation, where\nrandomized experiments are often infeasible. Existing approaches, however,\neither rely on strong structural assumptions or fail to handle key challenges\nsuch as interference, spatial confounding, temporal carryover, and time-varying\nconfounding -- where covariates are influenced by past treatments and, in turn,\naffect future ones. We introduce GST-UNet (G-computation Spatio-Temporal UNet),\na theoretically grounded neural framework that combines a U-Net-based\nspatiotemporal encoder with regression-based iterative G-computation to\nestimate location-specific potential outcomes under complex intervention\nsequences. GST-UNet explicitly adjusts for time-varying confounders and\ncaptures non-linear spatial and temporal dependencies, enabling valid causal\ninference from a single observed trajectory in data-scarce settings. We\nvalidate its effectiveness in synthetic experiments and in a real-world\nanalysis of wildfire smoke exposure and respiratory hospitalizations during the\n2018 California Camp Fire. Together, these results position GST-UNet as a\nprincipled and ready-to-use framework for spatiotemporal causal inference,\nadvancing reliable estimation in policy-relevant and scientific domains.",
    "published": "2025-02-07T19:56:01Z",
    "updated": "2025-10-28T16:01:40Z",
    "link": "http://arxiv.org/pdf/2502.05295v2.pdf",
    "category": [
      "cs.LG",
      "stat.ME"
    ],
    "authors": [
      "Miruna Oprescu",
      "David K. Park",
      "Xihaier Luo",
      "Shinjae Yoo",
      "Nathan Kallus"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2409.11529v3",
    "title": "Adaptive Anomaly Detection in Network Flows with Low-Rank Tensor\n  Decompositions and Deep Unrolling",
    "summary": "Anomaly detection (AD) is increasingly recognized as a key component for\nensuring the resilience of future communication systems. While deep learning\nhas shown state-of-the-art AD performance, its application in critical systems\nis hindered by concerns regarding training data efficiency, domain adaptation\nand interpretability. This work considers AD in network flows using incomplete\nmeasurements, leveraging a robust tensor decomposition approach and deep\nunrolling techniques to address these challenges. We first propose a novel\nblock-successive convex approximation algorithm based on a regularized\nmodel-fitting objective where the normal flows are modeled as low-rank tensors\nand anomalies as sparse. An augmentation of the objective is introduced to\ndecrease the computational cost. We apply deep unrolling to derive a novel deep\nnetwork architecture based on our proposed algorithm, treating the\nregularization parameters as learnable weights. Inspired by Bayesian\napproaches, we extend the model architecture to perform online adaptation to\nper-flow and per-time-step statistics, improving AD performance while\nmaintaining a low parameter count and preserving the problem's permutation\nequivariances. To optimize the deep network weights for detection performance,\nwe employ a homotopy optimization approach based on an efficient approximation\nof the area under the receiver operating characteristic curve. Extensive\nexperiments on synthetic and real-world data demonstrate that our proposed deep\nnetwork architecture exhibits a high training data efficiency, outperforms\nreference methods, and adapts seamlessly to varying network topologies.",
    "published": "2024-09-17T19:59:57Z",
    "updated": "2025-10-28T15:59:49Z",
    "link": "http://arxiv.org/pdf/2409.11529v3.pdf",
    "category": [
      "cs.LG",
      "eess.SP"
    ],
    "authors": [
      "Lukas Schynol",
      "Marius Pesavento"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24557v1",
    "title": "Enforcing boundary conditions for physics-informed neural operators",
    "summary": "Machine-learning based methods like physics-informed neural networks and\nphysics-informed neural operators are becoming increasingly adept at solving\neven complex systems of partial differential equations. Boundary conditions can\nbe enforced either weakly by penalizing deviations in the loss function or\nstrongly by training a solution structure that inherently matches the\nprescribed values and derivatives. The former approach is easy to implement but\nthe latter can provide benefits with respect to accuracy and training times.\nHowever, previous approaches to strongly enforcing Neumann or Robin boundary\nconditions require a domain with a fully $C^1$ boundary and, as we demonstrate,\ncan lead to instability if those boundary conditions are posed on a segment of\nthe boundary that is piecewise $C^1$ but only $C^0$ globally. We introduce a\ngeneralization of the approach by Sukumar \\& Srivastava (doi:\n10.1016/j.cma.2021.114333), and a new approach based on orthogonal projections\nthat overcome this limitation. The performance of these new techniques is\ncompared against weakly and semi-weakly enforced boundary conditions for the\nscalar Darcy flow equation and the stationary Navier-Stokes equations.",
    "published": "2025-10-28T15:51:48Z",
    "updated": "2025-10-28T15:51:48Z",
    "link": "http://arxiv.org/pdf/2510.24557v1.pdf",
    "category": [
      "math.NA",
      "cs.LG",
      "cs.NA",
      "65N99, 68T07"
    ],
    "authors": [
      "Niklas GÃ¶schel",
      "Sebastian GÃ¶tschel",
      "Daniel Ruprecht"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24546v1",
    "title": "Dual-Mind World Models: A General Framework for Learning in Dynamic\n  Wireless Networks",
    "summary": "Despite the popularity of reinforcement learning (RL) in wireless networks,\nexisting approaches that rely on model-free RL (MFRL) and model-based RL (MBRL)\nare data inefficient and short-sighted. Such RL-based solutions cannot\ngeneralize to novel network states since they capture only statistical patterns\nrather than the underlying physics and logic from wireless data. These\nlimitations become particularly challenging in complex wireless networks with\nhigh dynamics and long-term planning requirements. To address these\nlimitations, in this paper, a novel dual-mind world model-based learning\nframework is proposed with the goal of optimizing completeness-weighted age of\ninformation (CAoI) in a challenging mmWave V2X scenario. Inspired by cognitive\npsychology, the proposed dual-mind world model encompasses a pattern-driven\nSystem 1 component and a logic-driven System 2 component to learn dynamics and\nlogic of the wireless network, and to provide long-term link scheduling over\nreliable imagined trajectories. Link scheduling is learned through end-to-end\ndifferentiable imagined trajectories with logical consistency over an extended\nhorizon rather than relying on wireless data obtained from environment\ninteractions. Moreover, through imagination rollouts, the proposed world model\ncan jointly reason network states and plan link scheduling. During intervals\nwithout observations, the proposed method remains capable of making efficient\ndecisions. Extensive experiments are conducted on a realistic simulator based\non Sionna with real-world physical channel, ray-tracing, and scene objects with\nmaterial properties. Simulation results show that the proposed world model\nachieves a significant improvement in data efficiency and achieves strong\ngeneralization and adaptation to unseen environments, compared to the\nstate-of-the-art RL baselines, and the world model approach with only System 1.",
    "published": "2025-10-28T15:45:15Z",
    "updated": "2025-10-28T15:45:15Z",
    "link": "http://arxiv.org/pdf/2510.24546v1.pdf",
    "category": [
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "authors": [
      "Lingyi Wang",
      "Rashed Shelim",
      "Walid Saad",
      "Naren Ramakrishnan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2301.07530v3",
    "title": "Online (Non-)Convex Learning via Tempered Optimism",
    "summary": "Optimistic Online Learning aims to exploit experts conveying reliable\ninformation to predict the future. However, such implicit optimism may be\nchallenged when it comes to practical crafting of such experts. A fundamental\nexample consists in approximating a minimiser of the current problem and use it\nas expert. In the context of dynamic environments, such an expert only conveys\npartially relevant information as it may lead to overfitting. To tackle this\nissue, we introduce in this work the \\emph{optimistically tempered} (OT) online\nlearning framework designed to handle such imperfect experts. As a first\ncontribution, we show that tempered optimism is a fruitful paradigm for Online\nNon-Convex Learning by proposing simple, yet powerful modification of Online\nGradient and Mirror Descent. Second, we derive a second OT algorithm for convex\nlosses and third, evaluate the practical efficiency of tempered optimism on\nreal-life datasets and a toy experiment.",
    "published": "2023-01-18T13:48:20Z",
    "updated": "2025-10-28T15:36:36Z",
    "link": "http://arxiv.org/pdf/2301.07530v3.pdf",
    "category": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "authors": [
      "Maxime Haddouche",
      "Olivier Wintenberger",
      "Benjamin Guedj"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24523v1",
    "title": "Unsupervised Machine-Learning Pipeline for Data-Driven Defect Detection\n  and Characterisation: Application to Displacement Cascades",
    "summary": "Neutron irradiation produces, within a few picoseconds, displacement cascades\nthat are sequences of atomic collisions generating point and extended defects\nwhich subsequently affects the long-term evolution of materials. The diversity\nof these defects, characterized morphologically and statistically, defines what\nis called the \"primary damage\". In this work, we present a fully unsupervised\nmachine learning (ML) workflow that detects and classifies these defects\ndirectly from molecular dynamics data. Local environments are encoded by the\nSmooth Overlap of Atomic Positions (SOAP) vector, anomalous atoms are isolated\nwith autoencoder neural networks (AE), embedded with Uniform Man- ifold\nApproximation and Projection (UMAP) and clustered using Hierarchical\nDensity-Based Spatial Clustering of Applications with Noise (HDBSCAN). Applied\nto 80 keV displacement cascades in Ni, Fe70Ni10Cr20, and Zr, the AE\nsuccessfully identify the small fraction of outlier atoms that participate in\ndefect formation. HDBSCAN then partitions the UMAP latent space of AE-flagged\nSOAP de- scriptors into well defined groups representing vacancy- and\ninterstitial-dominated regions and, within each, separates small from large\naggregates, assigning 99.7 % of outliers to compact physical motifs. A signed\ncluster-identification score confirms this separation, and cluster size scales\nwith net defect counts (R2 > 0.89). Statistical cross analyses between the ML\noutlier map and several conventional detectors (centrosymmetry, dislocation\nextraction, etc.) reveal strong overlap and complementary coverage, all\nachieved without template or threshold tuning. This ML workflow thus provides\nan efficient tool for the quantitative mapping of structural anomalies in\nmaterials, particularly those arising from irradiation damage in displacement\ncascades.",
    "published": "2025-10-28T15:34:23Z",
    "updated": "2025-10-28T15:34:23Z",
    "link": "http://arxiv.org/pdf/2510.24523v1.pdf",
    "category": [
      "cond-mat.mtrl-sci",
      "cs.LG"
    ],
    "authors": [
      "Samuel Del FrÃ©",
      "AndrÃ©e de Backer",
      "Christophe Domain",
      "Ludovic Thuinet",
      "Charlotte S. Becquart"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.00799v3",
    "title": "Uni-LoRA: One Vector is All You Need",
    "summary": "Low-Rank Adaptation (LoRA) has become the de facto parameter-efficient\nfine-tuning (PEFT) method for large language models (LLMs) by constraining\nweight updates to low-rank matrices. Recent works such as Tied-LoRA, VeRA, and\nVB-LoRA push efficiency further by introducing additional constraints to reduce\nthe trainable parameter space. In this paper, we show that the parameter space\nreduction strategies employed by these LoRA variants can be formulated within a\nunified framework, Uni-LoRA, where the LoRA parameter space, flattened as a\nhigh-dimensional vector space $R^D$, can be reconstructed through a projection\nfrom a subspace R^d, with $d \\ll D$. We demonstrate that the fundamental\ndifference among various LoRA methods lies in the choice of the projection\nmatrix, $P \\in R^{D \\times d}$.Most existing LoRA variants rely on layer-wise\nor structure-specific projections that limit cross-layer parameter sharing,\nthereby compromising parameter efficiency. In light of this, we introduce an\nefficient and theoretically grounded projection matrix that is isometric,\nenabling global parameter sharing and reducing computation overhead.\nFurthermore, under the unified view of Uni-LoRA, this design requires only a\nsingle trainable vector to reconstruct LoRA parameters for the entire LLM -\nmaking Uni-LoRA both a unified framework and a \"one-vector-only\" solution.\nExtensive experiments on GLUE, mathematical reasoning, and instruction tuning\nbenchmarks demonstrate that Uni-LoRA achieves state-of-the-art parameter\nefficiency while outperforming or matching prior approaches in predictive\nperformance. Our code is available at\nhttps://github.com/KaiyangLi1992/Uni-LoRA.",
    "published": "2025-06-01T03:00:09Z",
    "updated": "2025-10-28T15:20:47Z",
    "link": "http://arxiv.org/pdf/2506.00799v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Kaiyang Li",
      "Shaobo Han",
      "Qing Su",
      "Wei Li",
      "Zhipeng Cai",
      "Shihao Ji"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24500v1",
    "title": "MIMIC-Sepsis: A Curated Benchmark for Modeling and Learning from Sepsis\n  Trajectories in the ICU",
    "summary": "Sepsis is a leading cause of mortality in intensive care units (ICUs), yet\nexisting research often relies on outdated datasets, non-reproducible\npreprocessing pipelines, and limited coverage of clinical interventions. We\nintroduce MIMIC-Sepsis, a curated cohort and benchmark framework derived from\nthe MIMIC-IV database, designed to support reproducible modeling of sepsis\ntrajectories. Our cohort includes 35,239 ICU patients with time-aligned\nclinical variables and standardized treatment data, including vasopressors,\nfluids, mechanical ventilation and antibiotics. We describe a transparent\npreprocessing pipeline-based on Sepsis-3 criteria, structured imputation\nstrategies, and treatment inclusion-and release it alongside benchmark tasks\nfocused on early mortality prediction, length-of-stay estimation, and shock\nonset classification. Empirical results demonstrate that incorporating\ntreatment variables substantially improves model performance, particularly for\nTransformer-based architectures. MIMIC-Sepsis serves as a robust platform for\nevaluating predictive and sequential models in critical care research.",
    "published": "2025-10-28T15:13:38Z",
    "updated": "2025-10-28T15:13:38Z",
    "link": "http://arxiv.org/pdf/2510.24500v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Yong Huang",
      "Zhongqi Yang",
      "Amir Rahmani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2406.04378v3",
    "title": "TIDMAD: Time Series Dataset for Discovering Dark Matter with AI\n  Denoising",
    "summary": "Dark matter makes up approximately 85% of total matter in our universe, yet\nit has never been directly observed in any laboratory on Earth. The origin of\ndark matter is one of the most important questions in contemporary physics, and\na convincing detection of dark matter would be a Nobel-Prize-level breakthrough\nin fundamental science. The ABRACADABRA experiment was specifically designed to\nsearch for dark matter. Although it has not yet made a discovery, ABRACADABRA\nhas produced several dark matter search results widely endorsed by the physics\ncommunity. The experiment generates ultra-long time-series data at a rate of 10\nmillion samples per second, where the dark matter signal would manifest itself\nas a sinusoidal oscillation mode within the ultra-long time series. In this\npaper, we present the TIDMAD -- a comprehensive data release from the\nABRACADABRA experiment including three key components: an ultra-long time\nseries dataset divided into training, validation, and science subsets; a\ncarefully-designed denoising score for direct model benchmarking; and a\ncomplete analysis framework which produces a community-standard dark matter\nsearch result suitable for publication as a physics paper. This data release\nenables core AI algorithms to extract the dark matter signal and produce real\nphysics results thereby advancing fundamental science. The data downloading and\nassociated analysis scripts are available at\nhttps://github.com/jessicafry/TIDMAD",
    "published": "2024-06-05T22:18:36Z",
    "updated": "2025-10-28T15:03:25Z",
    "link": "http://arxiv.org/pdf/2406.04378v3.pdf",
    "category": [
      "cs.LG",
      "hep-ex"
    ],
    "authors": [
      "J. T. Fry",
      "Xinyi Hope Fu",
      "Zhenghao Fu",
      "Kaliroe M. W. Pappas",
      "Lindley Winslow",
      "Aobo Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.03534v2",
    "title": "Long-Term Mapping of the Douro River Plume with Multi-Agent\n  Reinforcement Learning",
    "summary": "We study the problem of long-term (multiple days) mapping of a river plume\nusing multiple autonomous underwater vehicles (AUVs), focusing on the Douro\nriver representative use-case. We propose an energy - and communication -\nefficient multi-agent reinforcement learning approach in which a central\ncoordinator intermittently communicates with the AUVs, collecting measurements\nand issuing commands. Our approach integrates spatiotemporal Gaussian process\nregression (GPR) with a multi-head Q-network controller that regulates\ndirection and speed for each AUV. Simulations using the Delft3D ocean model\ndemonstrate that our method consistently outperforms both single- and\nmulti-agent benchmarks, with scaling the number of agents both improving mean\nsquared error (MSE) and operational endurance. In some instances, our algorithm\ndemonstrates that doubling the number of AUVs can more than double endurance\nwhile maintaining or improving accuracy, underscoring the benefits of\nmulti-agent coordination. Our learned policies generalize across unseen\nseasonal regimes over different months and years, demonstrating promise for\nfuture developments of data-driven long-term monitoring of dynamic plume\nenvironments.",
    "published": "2025-10-03T22:08:08Z",
    "updated": "2025-10-28T14:48:21Z",
    "link": "http://arxiv.org/pdf/2510.03534v2.pdf",
    "category": [
      "cs.MA",
      "cs.LG",
      "cs.SY",
      "eess.SY",
      "stat.ML"
    ],
    "authors": [
      "NicolÃ² Dal Fabbro",
      "Milad Mesbahi",
      "Renato Mendes",
      "JoÃ£o Borges de Sousa",
      "George J. Pappas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24473v1",
    "title": "Methodology for Comparing Machine Learning Algorithms for Survival\n  Analysis",
    "summary": "This study presents a comparative methodological analysis of six machine\nlearning models for survival analysis (MLSA). Using data from nearly 45,000\ncolorectal cancer patients in the Hospital-Based Cancer Registries of S\\~ao\nPaulo, we evaluated Random Survival Forest (RSF), Gradient Boosting for\nSurvival Analysis (GBSA), Survival SVM (SSVM), XGBoost-Cox (XGB-Cox),\nXGBoost-AFT (XGB-AFT), and LightGBM (LGBM), capable of predicting survival\nconsidering censored data. Hyperparameter optimization was performed with\ndifferent samplers, and model performance was assessed using the Concordance\nIndex (C-Index), C-Index IPCW, time-dependent AUC, and Integrated Brier Score\n(IBS). Survival curves produced by the models were compared with predictions\nfrom classification algorithms, and predictor interpretation was conducted\nusing SHAP and permutation importance. XGB-AFT achieved the best performance\n(C-Index = 0.7618; IPCW = 0.7532), followed by GBSA and RSF. The results\nhighlight the potential and applicability of MLSA to improve survival\nprediction and support decision making.",
    "published": "2025-10-28T14:42:28Z",
    "updated": "2025-10-28T14:42:28Z",
    "link": "http://arxiv.org/pdf/2510.24473v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Lucas Buk Cardoso",
      "Simone Aldrey Angelo",
      "Yasmin Pacheco Gil Bonilha",
      "Fernando Maia",
      "Adeylson GuimarÃ£es Ribeiro",
      "Maria Paula Curado",
      "Gisele Aparecida Fernandes",
      "Vanderlei Cunha Parro",
      "FlÃ¡vio Almeida de MagalhÃ£es Cipparrone",
      "Alexandre Dias Porto Chiavegatto Filho",
      "Tatiana Natasha Toporcov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24466v1",
    "title": "Non-Singularity of the Gradient Descent map for Neural Networks with\n  Piecewise Analytic Activations",
    "summary": "The theory of training deep networks has become a central question of modern\nmachine learning and has inspired many practical advancements. In particular,\nthe gradient descent (GD) optimization algorithm has been extensively studied\nin recent years. A key assumption about GD has appeared in several recent\nworks: the \\emph{GD map is non-singular} -- it preserves sets of measure zero\nunder preimages. Crucially, this assumption has been used to prove that GD\navoids saddle points and maxima, and to establish the existence of a computable\nquantity that determines the convergence to global minima (both for GD and\nstochastic GD). However, the current literature either assumes the\nnon-singularity of the GD map or imposes restrictive assumptions, such as\nLipschitz smoothness of the loss (for example, Lipschitzness does not hold for\ndeep ReLU networks with the cross-entropy loss) and restricts the analysis to\nGD with small step-sizes. In this paper, we investigate the neural network map\nas a function on the space of weights and biases. We also prove, for the first\ntime, the non-singularity of the gradient descent (GD) map on the loss\nlandscape of realistic neural network architectures (with fully connected,\nconvolutional, or softmax attention layers) and piecewise analytic activations\n(which includes sigmoid, ReLU, leaky ReLU, etc.) for almost all step-sizes. Our\nwork significantly extends the existing results on the convergence of GD and\nSGD by guaranteeing that they apply to practical neural network settings and\nhas the potential to unlock further exploration of learning dynamics.",
    "published": "2025-10-28T14:34:33Z",
    "updated": "2025-10-28T14:34:33Z",
    "link": "http://arxiv.org/pdf/2510.24466v1.pdf",
    "category": [
      "math.OC",
      "cs.LG"
    ],
    "authors": [
      "Alexandru CrÄciun",
      "Debarghya Ghoshdastidar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.22911v2",
    "title": "Towards Personalized Treatment Plan: Geometrical Model-Agnostic Approach\n  to Counterfactual Explanations",
    "summary": "In our article, we describe a method for generating counterfactual\nexplanations in high-dimensional spaces using four steps that involve fitting\nour dataset to a model, finding the decision boundary, determining constraints\non the problem, and computing the closest point (counterfactual explanation)\nfrom that boundary. We propose a discretized approach where we find many\ndiscrete points on the boundary and then identify the closest feasible\ncounterfactual explanation. This method, which we later call $\\textit{Segmented\nSampling for Boundary Approximation}$ (SSBA), applies binary search to find\ndecision boundary points and then searches for the closest boundary point.\nAcross four datasets of varying dimensionality, we show that our method can\noutperform current methods for counterfactual generation with reductions in\ndistance between $5\\%$ to $50\\%$ in terms of the $L_2$ norm. Our method can\nalso handle real-world constraints by restricting changes to immutable and\ncategorical features, such as age, gender, sex, height, and other related\ncharacteristics such as the case for a health-based dataset. In terms of\nruntime, the SSBA algorithm generates decision boundary points on multiple\norders of magnitude in the same given time when we compare to a grid-based\napproach. In general, our method provides a simple and effective model-agnostic\nmethod that can compute nearest feasible (i.e. realistic with constraints)\ncounterfactual explanations. All of our results and code are available at:\nhttps://github.com/dsin85691/SSBA_For_Counterfactuals",
    "published": "2025-10-27T01:28:57Z",
    "updated": "2025-10-28T14:33:37Z",
    "link": "http://arxiv.org/pdf/2510.22911v2.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Daniel Sin",
      "Milad Toutounchian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.06923v4",
    "title": "The Importance of Being Discrete: Measuring the Impact of Discretization\n  in End-to-End Differentially Private Synthetic Data",
    "summary": "Differentially Private (DP) generative marginal models are often used in the\nwild to release synthetic tabular datasets in lieu of sensitive data while\nproviding formal privacy guarantees. These models approximate low-dimensional\nmarginals or query workloads; crucially, they require the training data to be\npre-discretized, i.e., continuous values need to first be partitioned into\nbins. However, as the range of values (or their domain) is often inferred\ndirectly from the training data, with the number of bins and bin edges\ntypically defined arbitrarily, this approach can ultimately break end-to-end DP\nguarantees and may not always yield optimal utility.\n  In this paper, we present an extensive measurement study of four\ndiscretization strategies in the context of DP marginal generative models. More\nprecisely, we design DP versions of three discretizers (uniform, quantile, and\nk-means) and reimplement the PrivTree algorithm. We find that optimizing both\nthe choice of discretizer and bin count can improve utility, on average, by\nalmost 30% across six DP marginal models, compared to the default strategy and\nnumber of bins, with PrivTree being the best-performing discretizer in the\nmajority of cases. We demonstrate that, while DP generative models with\nnon-private discretization remain vulnerable to membership inference attacks,\napplying DP during discretization effectively mitigates this risk. Finally, we\nimprove on an existing approach for automatically selecting the optimal number\nof bins, and achieve high utility while reducing both privacy budget\nconsumption and computational overhead.",
    "published": "2025-04-09T14:30:30Z",
    "updated": "2025-10-28T14:21:34Z",
    "link": "http://arxiv.org/pdf/2504.06923v4.pdf",
    "category": [
      "cs.CR",
      "cs.LG"
    ],
    "authors": [
      "Georgi Ganev",
      "Meenatchi Sundaram Muthu Selva Annamalai",
      "Sofiane Mahiou",
      "Emiliano De Cristofaro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24452v1",
    "title": "ARIMA_PLUS: Large-scale, Accurate, Automatic and Interpretable\n  In-Database Time Series Forecasting and Anomaly Detection in Google BigQuery",
    "summary": "Time series forecasting and anomaly detection are common tasks for\npractitioners in industries such as retail, manufacturing, advertising and\nenergy. Two unique challenges stand out: (1) efficiently and accurately\nforecasting time series or detecting anomalies in large volumes automatically;\nand (2) ensuring interpretability of results to effectively incorporate\nbusiness insights. We present ARIMA_PLUS, a novel framework to overcome these\ntwo challenges by a unique combination of (a) accurate and interpretable time\nseries models and (b) scalable and fully managed system infrastructure. The\nmodel has a sequential and modular structure to handle different components of\nthe time series, including holiday effects, seasonality, trend, and anomalies,\nwhich enables high interpretability of the results. Novel enhancements are made\nto each module, and a unified framework is established to address both\nforecasting and anomaly detection tasks simultaneously. In terms of accuracy,\nits comprehensive benchmark on the 42 public datasets in the Monash forecasting\nrepository shows superior performance over not only well-established\nstatistical alternatives (such as ETS, ARIMA, TBATS, Prophet) but also newer\nneural network models (such as DeepAR, N-BEATS, PatchTST, TimeMixer). In terms\nof infrastructure, it is directly built into the query engine of BigQuery in\nGoogle Cloud. It uses a simple SQL interface and automates tedious\ntechnicalities such as data cleaning and model selection. It automatically\nscales with managed cloud computational and storage resources, making it\npossible to forecast 100 million time series using only 1.5 hours with a\nthroughput of more than 18000 time series per second. In terms of\ninterpretability, we present several case studies to demonstrate time series\ninsights it generates and customizability it offers.",
    "published": "2025-10-28T14:18:50Z",
    "updated": "2025-10-28T14:18:50Z",
    "link": "http://arxiv.org/pdf/2510.24452v1.pdf",
    "category": [
      "cs.DC",
      "cs.LG"
    ],
    "authors": [
      "Xi Cheng",
      "Weijie Shen",
      "Haoming Chen",
      "Chaoyi Shen",
      "Jean Ortega",
      "Jiashang Liu",
      "Steve Thomas",
      "Honglin Zheng",
      "Haoyun Wu",
      "Yuxiang Li",
      "Casey Lichtendahl",
      "Jenny Ortiz",
      "Gang Liu",
      "Haiyang Qi",
      "Omid Fatemieh",
      "Chris Fry",
      "Jing Jing Long"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24433v1",
    "title": "Nearest Neighbor Matching as Least Squares Density Ratio Estimation and\n  Riesz Regression",
    "summary": "This study proves that Nearest Neighbor (NN) matching can be interpreted as\nan instance of Riesz regression for automatic debiased machine learning. Lin et\nal. (2023) shows that NN matching is an instance of density-ratio estimation\nwith their new density-ratio estimator. Chernozhukov et al. (2024) develops\nRiesz regression for automatic debiased machine learning, which directly\nestimates the Riesz representer (or equivalently, the bias-correction term) by\nminimizing the mean squared error. In this study, we first prove that the\ndensity-ratio estimation method proposed in Lin et al. (2023) is essentially\nequivalent to Least-Squares Importance Fitting (LSIF) proposed in Kanamori et\nal. (2009) for direct density-ratio estimation. Furthermore, we derive Riesz\nregression using the LSIF framework. Based on these results, we derive NN\nmatching from Riesz regression. This study is based on our work Kato (2025a)\nand Kato (2025b).",
    "published": "2025-10-28T14:01:51Z",
    "updated": "2025-10-28T14:01:51Z",
    "link": "http://arxiv.org/pdf/2510.24433v1.pdf",
    "category": [
      "econ.EM",
      "cs.LG",
      "math.ST",
      "stat.ME",
      "stat.ML",
      "stat.TH"
    ],
    "authors": [
      "Masahiro Kato"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24432v1",
    "title": "Fill in the Blanks: Accelerating Q-Learning with a Handful of\n  Demonstrations in Sparse Reward Settings",
    "summary": "Reinforcement learning (RL) in sparse-reward environments remains a\nsignificant challenge due to the lack of informative feedback. We propose a\nsimple yet effective method that uses a small number of successful\ndemonstrations to initialize the value function of an RL agent. By precomputing\nvalue estimates from offline demonstrations and using them as targets for early\nlearning, our approach provides the agent with a useful prior over promising\nactions. The agent then refines these estimates through standard online\ninteraction. This hybrid offline-to-online paradigm significantly reduces the\nexploration burden and improves sample efficiency in sparse-reward settings.\nExperiments on benchmark tasks demonstrate that our method accelerates\nconvergence and outperforms standard baselines, even with minimal or suboptimal\ndemonstration data.",
    "published": "2025-10-28T14:01:13Z",
    "updated": "2025-10-28T14:01:13Z",
    "link": "http://arxiv.org/pdf/2510.24432v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Seyed Mahdi Basiri Azad",
      "Joschka Boedecker"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.17638v2",
    "title": "Why Diffusion Models Don't Memorize: The Role of Implicit Dynamical\n  Regularization in Training",
    "summary": "Diffusion models have achieved remarkable success across a wide range of\ngenerative tasks. A key challenge is understanding the mechanisms that prevent\ntheir memorization of training data and allow generalization. In this work, we\ninvestigate the role of the training dynamics in the transition from\ngeneralization to memorization. Through extensive experiments and theoretical\nanalysis, we identify two distinct timescales: an early time\n$\\tau_\\mathrm{gen}$ at which models begin to generate high-quality samples, and\na later time $\\tau_\\mathrm{mem}$ beyond which memorization emerges. Crucially,\nwe find that $\\tau_\\mathrm{mem}$ increases linearly with the training set size\n$n$, while $\\tau_\\mathrm{gen}$ remains constant. This creates a growing window\nof training times with $n$ where models generalize effectively, despite showing\nstrong memorization if training continues beyond it. It is only when $n$\nbecomes larger than a model-dependent threshold that overfitting disappears at\ninfinite training times. These findings reveal a form of implicit dynamical\nregularization in the training dynamics, which allow to avoid memorization even\nin highly overparameterized settings. Our results are supported by numerical\nexperiments with standard U-Net architectures on realistic and synthetic\ndatasets, and by a theoretical analysis using a tractable random features model\nstudied in the high-dimensional limit.",
    "published": "2025-05-23T08:58:47Z",
    "updated": "2025-10-28T13:54:07Z",
    "link": "http://arxiv.org/pdf/2505.17638v2.pdf",
    "category": [
      "cs.LG",
      "cond-mat.dis-nn",
      "stat.ML"
    ],
    "authors": [
      "Tony Bonnaire",
      "RaphaÃ«l Urfin",
      "Giulio Biroli",
      "Marc MÃ©zard"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.10856v4",
    "title": "RWKV-edge: Deeply Compressed RWKV for Resource-Constrained Devices",
    "summary": "To deploy LLMs on resource-contained platforms such as mobile robots and\nsmartphones, non-transformers LLMs have achieved major breakthroughs. Recently,\na novel RNN-based LLM family, Repentance Weighted Key Value (RWKV) has shown\nstrong computational efficiency; nevertheless, RWKV models still have high\nparameter counts which limited their deployment. In this paper, we propose a\nsuite of compression techniques, ranging from model architecture optimizations\nto post-training compression, tailored to the RWKV architecture. Combined, our\ntechniques reduce the memory footprint of RWKV models by 3.4x -- 5x with only\nnegligible degradation in accuracy; compared to transformer LLMs with similar\naccuracy, our models require 4x less memory footprint.",
    "published": "2024-12-14T15:11:07Z",
    "updated": "2025-10-28T13:45:25Z",
    "link": "http://arxiv.org/pdf/2412.10856v4.pdf",
    "category": [
      "cs.LG",
      "cs.PF"
    ],
    "authors": [
      "Wonkyo Choe",
      "Yangfeng Ji",
      "Felix Xiaozhu Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24422v1",
    "title": "Attack on a PUF-based Secure Binary Neural Network",
    "summary": "Binarized Neural Networks (BNNs) deployed on memristive crossbar arrays\nprovide energy-efficient solutions for edge computing but are susceptible to\nphysical attacks due to memristor nonvolatility. Recently, Rajendran et al.\n(IEEE Embedded Systems Letter 2025) proposed a Physical Unclonable Function\n(PUF)-based scheme to secure BNNs against theft attacks. Specifically, the\nweight and bias matrices of the BNN layers were secured by swapping columns\nbased on device's PUF key bits.\n  In this paper, we demonstrate that this scheme to secure BNNs is vulnerable\nto PUF-key recovery attack. As a consequence of our attack, we recover the\nsecret weight and bias matrices of the BNN. Our approach is motivated by\ndifferential cryptanalysis and reconstructs the PUF key bit-by-bit by observing\nthe change in model accuracy, and eventually recovering the BNN model\nparameters. Evaluated on a BNN trained on the MNIST dataset, our attack could\nrecover 85% of the PUF key, and recover the BNN model up to 93% classification\naccuracy compared to the original model's 96% accuracy. Our attack is very\nefficient and it takes a couple of minutes to recovery the PUF key and the\nmodel parameters.",
    "published": "2025-10-28T13:43:00Z",
    "updated": "2025-10-28T13:43:00Z",
    "link": "http://arxiv.org/pdf/2510.24422v1.pdf",
    "category": [
      "cs.CR",
      "cs.AR",
      "cs.LG"
    ],
    "authors": [
      "Bijeet Basak",
      "Nupur Patil",
      "Kurian Polachan",
      "Srinivas Vivek"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.07297v2",
    "title": "Data Fusion of Deep Learned Molecular Embeddings for Property Prediction",
    "summary": "Data-driven approaches such as deep learning can result in predictive models\nfor material properties with exceptional accuracy and efficiency. However, in\nmany applications, data is sparse, severely limiting their accuracy and\napplicability. To improve predictions, techniques such as transfer learning and\nmultitask learning have been used. The performance of multitask learning models\ndepends on the strength of the underlying correlations between tasks and the\ncompleteness of the data set. Standard multitask models tend to underperform\nwhen trained on sparse data sets with weakly correlated properties. To address\nthis gap, we fuse deep-learned embeddings generated by independent pretrained\nsingle-task models, resulting in a multitask model that inherits rich,\nproperty-specific representations. By reusing (rather than retraining) these\nembeddings, the resulting fused model outperforms standard multitask models and\ncan be extended with fewer trainable parameters. We demonstrate this technique\non a widely used benchmark data set of quantum chemistry data for small\nmolecules as well as a newly compiled sparse data set of experimental data\ncollected from literature and our own quantum chemistry and thermochemical\ncalculations.",
    "published": "2025-04-09T21:40:15Z",
    "updated": "2025-10-28T13:27:06Z",
    "link": "http://arxiv.org/pdf/2504.07297v2.pdf",
    "category": [
      "cs.LG",
      "cond-mat.mtrl-sci"
    ],
    "authors": [
      "Robert J Appleton",
      "Brian C Barnes",
      "Alejandro Strachan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2310.06328v5",
    "title": "UniCrossFi: A Unified Framework For Cross-Domain Wi-Fi-based Gesture\n  Recognition",
    "summary": "Wi-Fi sensing systems are severely hindered by cross domain problem when\ndeployed in unseen real-world environments. Existing methods typically design\nseparate frameworks for either domain adaptation or domain generalization,\noften relying on extensive labeled data. Existing methods that designed for\ndomain generalization is often relying on extensive labeled data. However,\nreal-world scenarios are far more complex, where the deployed model must be\ncapable of handling generalization under limited labeled source data. To this\nend, we propose UniCrossFi, a unified framework designed to mitigate\nperformance drop in CSI-based sensing across diverse deployment settings. Our\nframework not only extends conventional Domain Generalization (DG) to a more\npractical Semi-Supervised Domain Generalization (SSDG) setting, where only\npartially labeled source data are available, but also introduces a\nphysics-informed data augmentation strategy, Antenna Response Consistency\n(ARC). ARC mitigates the risk of learning superficial shortcuts by exploiting\nthe intrinsic spatial diversity of multi-antenna systems, treating signals from\ndifferent antennas as naturally augmented views of the same event. In addition,\nwe design a Unified Contrastive Objective to prevent conventional contrastive\nlearning from pushing apart samples from different domains that share the same\nclass. We conduct extensive experiments on the public Widar and CSIDA datasets.\nThe results demonstrate that UniCrossFi consistently establishes a new\nstate-of-the-art, significantly outperforming existing methods across all\nunsupervised domain adaptation, DG, and SSDG benchmarks. UniCrossFi provides a\nprincipled and practical solution to the domain shift challenge, advancing the\nfeasibility of robust, real-world Wi-Fi sensing systems that can operate\neffectively with limited labeled data.",
    "published": "2023-10-10T05:54:00Z",
    "updated": "2025-10-28T13:10:33Z",
    "link": "http://arxiv.org/pdf/2310.06328v5.pdf",
    "category": [
      "cs.LG",
      "eess.SP"
    ],
    "authors": [
      "Ke Xu",
      "Zhiyong Zheng",
      "Hongyuan Zhu",
      "Lei Wang",
      "Jiangtao Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24380v1",
    "title": "APEX: Approximate-but-exhaustive search for ultra-large combinatorial\n  synthesis libraries",
    "summary": "Make-on-demand combinatorial synthesis libraries (CSLs) like Enamine REAL\nhave significantly enabled drug discovery efforts. However, their large size\npresents a challenge for virtual screening, where the goal is to identify the\ntop compounds in a library according to a computational objective (e.g.,\noptimizing docking score) subject to computational constraints under a limited\ncomputational budget. For current library sizes -- numbering in the tens of\nbillions of compounds -- and scoring functions of interest, a routine virtual\nscreening campaign may be limited to scoring fewer than 0.1% of the available\ncompounds, leaving potentially many high scoring compounds undiscovered.\nFurthermore, as constraints (and sometimes objectives) change during the course\nof a virtual screening campaign, existing virtual screening algorithms\ntypically offer little room for amortization. We propose the\napproximate-but-exhaustive search protocol for CSLs, or APEX. APEX utilizes a\nneural network surrogate that exploits the structure of CSLs in the prediction\nof objectives and constraints to make full enumeration on a consumer GPU\npossible in under a minute, allowing for exact retrieval of approximate top-$k$\nsets. To demonstrate APEX's capabilities, we develop a benchmark CSL comprised\nof more than 10 million compounds, all of which have been annotated with their\ndocking scores on five medically relevant targets along with physicohemical\nproperties measured with RDKit such that, for any objective and set of\nconstraints, the ground truth top-$k$ compounds can be identified and compared\nagainst the retrievals from any virtual screening algorithm. We show APEX's\nconsistently strong performance both in retrieval accuracy and runtime compared\nto alternative methods.",
    "published": "2025-10-28T12:57:59Z",
    "updated": "2025-10-28T12:57:59Z",
    "link": "http://arxiv.org/pdf/2510.24380v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Aryan Pedawi",
      "Jordi Silvestre-Ryan",
      "Bradley Worley",
      "Darren J Hsu",
      "Kushal S Shah",
      "Elias Stehle",
      "Jingrong Zhang",
      "Izhar Wallach"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.20641v4",
    "title": "Telegrapher's Generative Model via Kac Flows",
    "summary": "We break the mold in flow-based generative modeling by proposing a new model\nbased on the damped wave equation, also known as telegrapher's equation.\nSimilar to the diffusion equation and Brownian motion, there is a Feynman-Kac\ntype relation between the telegrapher's equation and the stochastic Kac process\nin 1D. The Kac flow evolves stepwise linearly in time, so that the probability\nflow is Lipschitz continuous in the Wasserstein distance and, in contrast to\ndiffusion flows, the norm of the velocity is globally bounded. Furthermore, the\nKac model has the diffusion model as its asymptotic limit. We extend these\nconsiderations to a multi-dimensional stochastic process which consists of\nindependent 1D Kac processes in each spatial component. We show that this\nprocess gives rise to an absolutely continuous curve in the Wasserstein space\nand compute the conditional velocity field starting in a Dirac point\nanalytically. Using the framework of flow matching, we train a neural network\nthat approximates the velocity field and use it for sample generation. Our\nnumerical experiments demonstrate the scalability of our approach, and show its\nadvantages over diffusion models.",
    "published": "2025-06-25T17:37:21Z",
    "updated": "2025-10-28T12:57:51Z",
    "link": "http://arxiv.org/pdf/2506.20641v4.pdf",
    "category": [
      "math.AP",
      "cs.LG",
      "math.PR"
    ],
    "authors": [
      "Richard Duong",
      "Jannis Chemseddine",
      "Peter K. Friz",
      "Gabriele Steidl"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24375v1",
    "title": "A Comprehensive Evaluation Framework for Synthetic Trip Data Generation\n  in Public Transport",
    "summary": "Synthetic data offers a promising solution to the privacy and accessibility\nchallenges of using smart card data in public transport research. Despite rapid\nprogress in generative modeling, there is limited attention to comprehensive\nevaluation, leaving unclear how reliable, safe, and useful synthetic data truly\nare. Existing evaluations remain fragmented, typically limited to\npopulation-level representativeness or record-level privacy, without\nconsidering group-level variations or task-specific utility. To address this\ngap, we propose a Representativeness-Privacy-Utility (RPU) framework that\nsystematically evaluates synthetic trip data across three complementary\ndimensions and three hierarchical levels (record, group, population). The\nframework integrates a consistent set of metrics to quantify similarity,\ndisclosure risk, and practical usefulness, enabling transparent and balanced\nassessment of synthetic data quality. We apply the framework to benchmark\ntwelve representative generation methods, spanning conventional statistical\nmodels, deep generative networks, and privacy-enhanced variants. Results show\nthat synthetic data do not inherently guarantee privacy and there is no\n\"one-size-fits-all\" model, the trade-off between privacy and\nrepresentativeness/utility is obvious. Conditional Tabular generative\nadversarial network (CTGAN) provide the most balanced trade-off and is\nsuggested for practical applications. The RPU framework provides a systematic\nand reproducible basis for researchers and practitioners to compare synthetic\ndata generation techniques and select appropriate methods in public transport\napplications.",
    "published": "2025-10-28T12:52:47Z",
    "updated": "2025-10-28T12:52:47Z",
    "link": "http://arxiv.org/pdf/2510.24375v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Yuanyuan Wu",
      "Zhenlin Qin",
      "Zhenliang Ma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.01143v2",
    "title": "Linear regression with overparameterized linear neural networks: Tight\n  upper and lower bounds for implicit $\\ell^1$-regularization",
    "summary": "Modern machine learning models are often trained in a setting where the\nnumber of parameters exceeds the number of training samples. To understand the\nimplicit bias of gradient descent in such overparameterized models, prior work\nhas studied diagonal linear neural networks in the regression setting. These\nstudies have shown that, when initialized with small weights, gradient descent\ntends to favor solutions with minimal $\\ell^1$-norm - an effect known as\nimplicit regularization. In this paper, we investigate implicit regularization\nin diagonal linear neural networks of depth $D\\ge 2$ for overparameterized\nlinear regression problems. We focus on analyzing the approximation error\nbetween the limit point of gradient flow trajectories and the solution to the\n$\\ell^1$-minimization problem. By deriving tight upper and lower bounds on the\napproximation error, we precisely characterize how the approximation error\ndepends on the scale of initialization $\\alpha$. Our results reveal a\nqualitative difference between depths: for $D \\ge 3$, the error decreases\nlinearly with $\\alpha$, whereas for $D=2$, it decreases at rate\n$\\alpha^{1-\\varrho}$, where the parameter $\\varrho \\in [0,1)$ can be explicitly\ncharacterized. Interestingly, this parameter is closely linked to so-called\nnull space property constants studied in the sparse recovery literature. We\ndemonstrate the asymptotic tightness of our bounds through explicit examples.\nNumerical experiments corroborate our theoretical findings and suggest that\ndeeper networks, i.e., $D \\ge 3$, may lead to better generalization,\nparticularly for realistic initialization scales.",
    "published": "2025-06-01T19:55:31Z",
    "updated": "2025-10-28T12:49:08Z",
    "link": "http://arxiv.org/pdf/2506.01143v2.pdf",
    "category": [
      "stat.ML",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "math.OC"
    ],
    "authors": [
      "Hannes Matt",
      "Dominik StÃ¶ger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.13397v2",
    "title": "Assessing the robustness of heterogeneous treatment effects in survival\n  analysis under informative censoring",
    "summary": "Dropout is common in clinical studies, with up to half of patients leaving\nearly due to side effects or other reasons. When dropout is informative (i.e.,\ndependent on survival time), it introduces censoring bias, because of which\ntreatment effect estimates are also biased. In this paper, we propose an\nassumption-lean framework to assess the robustness of conditional average\ntreatment effect (CATE) estimates in survival analysis when facing censoring\nbias. Unlike existing works that rely on strong assumptions, such as\nnon-informative censoring, to obtain point estimation, we use partial\nidentification to derive informative bounds on the CATE. Thereby, our framework\nhelps to identify patient subgroups where treatment is effective despite\ninformative censoring. We further develop a novel meta-learner that estimates\nthe bounds using arbitrary machine learning models and with favorable\ntheoretical properties, including double robustness and quasi-oracle\nefficiency. We demonstrate the practical value of our meta-learner through\nnumerical experiments and in an application to a cancer drug trial. Together,\nour framework offers a practical tool for assessing the robustness of estimated\ntreatment effects in the presence of censoring and thus promotes the reliable\nuse of survival data for evidence generation in medicine and epidemiology.",
    "published": "2025-10-15T10:51:17Z",
    "updated": "2025-10-28T12:46:53Z",
    "link": "http://arxiv.org/pdf/2510.13397v2.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Yuxin Wang",
      "Dennis Frauen",
      "Jonas Schweisthal",
      "Maresa SchrÃ¶der",
      "Stefan Feuerriegel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24368v1",
    "title": "Filtering instances and rejecting predictions to obtain reliable models\n  in healthcare",
    "summary": "Machine Learning (ML) models are widely used in high-stakes domains such as\nhealthcare, where the reliability of predictions is critical. However, these\nmodels often fail to account for uncertainty, providing predictions even with\nlow confidence. This work proposes a novel two-step data-centric approach to\nenhance the performance of ML models by improving data quality and filtering\nlow-confidence predictions. The first step involves leveraging Instance\nHardness (IH) to filter problematic instances during training, thereby refining\nthe dataset. The second step introduces a confidence-based rejection mechanism\nduring inference, ensuring that only reliable predictions are retained. We\nevaluate our approach using three real-world healthcare datasets, demonstrating\nits effectiveness at improving model reliability while balancing predictive\nperformance and rejection rate. Additionally, we use alternative criteria -\ninfluence values for filtering and uncertainty for rejection - as baselines to\nevaluate the efficiency of the proposed method. The results demonstrate that\nintegrating IH filtering with confidence-based rejection effectively enhances\nmodel performance while preserving a large proportion of instances. This\napproach provides a practical method for deploying ML systems in\nsafety-critical applications.",
    "published": "2025-10-28T12:45:20Z",
    "updated": "2025-10-28T12:45:20Z",
    "link": "http://arxiv.org/pdf/2510.24368v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Maria Gabriela Valeriano",
      "David Kohan MarzagÃ£o",
      "Alfredo Montelongo",
      "Carlos Roberto Veiga Kiffer",
      "Natan Katz",
      "Ana Carolina Lorena"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.20974v2",
    "title": "Robust Point Cloud Reinforcement Learning via PCA-Based Canonicalization",
    "summary": "Reinforcement Learning (RL) from raw visual input has achieved impressive\nsuccesses in recent years, yet it remains fragile to out-of-distribution\nvariations such as changes in lighting, color, and viewpoint. Point Cloud\nReinforcement Learning (PC-RL) offers a promising alternative by mitigating\nappearance-based brittleness, but its sensitivity to camera pose mismatches\ncontinues to undermine reliability in realistic settings. To address this\nchallenge, we propose PCA Point Cloud (PPC), a canonicalization framework\nspecifically tailored for downstream robotic control. PPC maps point clouds\nunder arbitrary rigid-body transformations to a unique canonical pose, aligning\nobservations to a consistent frame, thereby substantially decreasing\nviewpoint-induced inconsistencies. In our experiments, we show that PPC\nimproves robustness to unseen camera poses across challenging robotic tasks,\nproviding a principled alternative to domain randomization.",
    "published": "2025-10-23T20:06:29Z",
    "updated": "2025-10-28T11:58:54Z",
    "link": "http://arxiv.org/pdf/2510.20974v2.pdf",
    "category": [
      "cs.RO",
      "cs.LG"
    ],
    "authors": [
      "Michael Bezick",
      "Vittorio Giammarino",
      "Ahmed H. Qureshi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.23712v2",
    "title": "FraudTransformer: Time-Aware GPT for Transaction Fraud Detection",
    "summary": "Detecting payment fraud in real-world banking streams requires models that\ncan exploit both the order of events and the irregular time gaps between them.\nWe introduce FraudTransformer, a sequence model that augments a vanilla\nGPT-style architecture with (i) a dedicated time encoder that embeds either\nabsolute timestamps or inter-event values, and (ii) a learned positional\nencoder that preserves relative order. Experiments on a large industrial\ndataset -- tens of millions of transactions and auxiliary events -- show that\nFraudTransformer surpasses four strong classical baselines (Logistic\nRegression, XGBoost and LightGBM) as well as transformer ablations that omit\neither the time or positional component. On the held-out test set it delivers\nthe highest AUROC and PRAUC.",
    "published": "2025-09-28T07:53:41Z",
    "updated": "2025-10-28T11:34:23Z",
    "link": "http://arxiv.org/pdf/2509.23712v2.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Gholamali Aminian",
      "Andrew Elliott",
      "Tiger Li",
      "Timothy Cheuk Hin Wong",
      "Victor Claude Dehon",
      "Lukasz Szpruch",
      "Carsten Maple",
      "Christopher Read",
      "Martin Brown",
      "Gesine Reinert",
      "Mo Mamouei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24310v1",
    "title": "EDC: Equation Discovery for Classification",
    "summary": "Equation Discovery techniques have shown considerable success in regression\ntasks, where they are used to discover concise and interpretable models\n(\\textit{Symbolic Regression}). In this paper, we propose a new ED-based binary\nclassification framework. Our proposed method EDC finds analytical functions of\nmanageable size that specify the location and shape of the decision boundary.\nIn extensive experiments on artificial and real-life data, we demonstrate how\nEDC is able to discover both the structure of the target equation as well as\nthe value of its parameters, outperforming the current state-of-the-art\nED-based classification methods in binary classification and achieving\nperformance comparable to the state of the art in binary classification. We\nsuggest a grammar of modest complexity that appears to work well on the tested\ndatasets but argue that the exact grammar -- and thus the complexity of the\nmodels -- is configurable, and especially domain-specific expressions can be\nincluded in the pattern language, where that is required. The presented grammar\nconsists of a series of summands (additive terms) that include linear,\nquadratic and exponential terms, as well as products of two features (producing\nhyperbolic curves ideal for capturing XOR-like dependencies). The experiments\ndemonstrate that this grammar allows fairly flexible decision boundaries while\nnot so rich to cause overfitting.",
    "published": "2025-10-28T11:20:06Z",
    "updated": "2025-10-28T11:20:06Z",
    "link": "http://arxiv.org/pdf/2510.24310v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Guus Toussaint",
      "Arno Knobbe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.01855v2",
    "title": "Trade-offs in Data Memorization via Strong Data Processing Inequalities",
    "summary": "Recent research demonstrated that training large language models involves\nmemorization of a significant fraction of training data. Such memorization can\nlead to privacy violations when training on sensitive user data and thus\nmotivates the study of data memorization's role in learning. In this work, we\ndevelop a general approach for proving lower bounds on excess data\nmemorization, that relies on a new connection between strong data processing\ninequalities and data memorization. We then demonstrate that several simple and\nnatural binary classification problems exhibit a trade-off between the number\nof samples available to a learning algorithm, and the amount of information\nabout the training data that a learning algorithm needs to memorize to be\naccurate. In particular, $\\Omega(d)$ bits of information about the training\ndata need to be memorized when $O(1)$ $d$-dimensional examples are available,\nwhich then decays as the number of examples grows at a problem-specific rate.\nFurther, our lower bounds are generally matched (up to logarithmic factors) by\nsimple learning algorithms. We also extend our lower bounds to more general\nmixture-of-clusters models. Our definitions and results build on the work of\nBrown et al. (2021) and address several limitations of the lower bounds in\ntheir work.",
    "published": "2025-06-02T16:41:49Z",
    "updated": "2025-10-28T10:53:56Z",
    "link": "http://arxiv.org/pdf/2506.01855v2.pdf",
    "category": [
      "cs.LG",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ],
    "authors": [
      "Vitaly Feldman",
      "Guy Kornowski",
      "Xin Lyu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24288v1",
    "title": "Problem-Parameter-Free Decentralized Bilevel Optimization",
    "summary": "Decentralized bilevel optimization has garnered significant attention due to\nits critical role in solving large-scale machine learning problems. However,\nexisting methods often rely on prior knowledge of problem parameters-such as\nsmoothness, convexity, or communication network topologies-to determine\nappropriate stepsizes. In practice, these problem parameters are typically\nunavailable, leading to substantial manual effort for hyperparameter tuning. In\nthis paper, we propose AdaSDBO, a fully problem-parameter-free algorithm for\ndecentralized bilevel optimization with a single-loop structure. AdaSDBO\nleverages adaptive stepsizes based on cumulative gradient norms to update all\nvariables simultaneously, dynamically adjusting its progress and eliminating\nthe need for problem-specific hyperparameter tuning. Through rigorous\ntheoretical analysis, we establish that AdaSDBO achieves a convergence rate of\n$\\widetilde{\\mathcal{O}}\\left(\\frac{1}{T}\\right)$, matching the performance of\nwell-tuned state-of-the-art methods up to polylogarithmic factors. Extensive\nnumerical experiments demonstrate that AdaSDBO delivers competitive performance\ncompared to existing decentralized bilevel optimization methods while\nexhibiting remarkable robustness across diverse stepsize configurations.",
    "published": "2025-10-28T10:50:04Z",
    "updated": "2025-10-28T10:50:04Z",
    "link": "http://arxiv.org/pdf/2510.24288v1.pdf",
    "category": [
      "math.OC",
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Zhiwei Zhai",
      "Wenjing Yan",
      "Ying-Jun Angela Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24287v1",
    "title": "Towards actionable hypotension prediction- predicting catecholamine\n  therapy initiation in the intensive care unit",
    "summary": "Hypotension in critically ill ICU patients is common and life-threatening.\nEscalation to catecholamine therapy marks a key management step, with both\nundertreatment and overtreatment posing risks. Most machine learning (ML)\nmodels predict hypotension using fixed MAP thresholds or MAP forecasting,\noverlooking the clinical decision behind treatment escalation. Predicting\ncatecholamine initiation, the start of vasoactive or inotropic agent\nadministration offers a more clinically actionable target reflecting real\ndecision-making. Using the MIMIC-III database, we modeled catecholamine\ninitiation as a binary event within a 15-minute prediction window. Input\nfeatures included statistical descriptors from a two-hour sliding MAP context\nwindow, along with demographics, biometrics, comorbidities, and ongoing\ntreatments. An Extreme Gradient Boosting (XGBoost) model was trained and\ninterpreted via SHapley Additive exPlanations (SHAP). The model achieved an\nAUROC of 0.822 (0.813-0.830), outperforming the hypotension baseline (MAP < 65,\nAUROC 0.686 [0.675-0.699]). SHAP analysis highlighted recent MAP values, MAP\ntrends, and ongoing treatments (e.g., sedatives, electrolytes) as dominant\npredictors. Subgroup analysis showed higher performance in males, younger\npatients (<53 years), those with higher BMI (>32), and patients without\ncomorbidities or concurrent medications. Predicting catecholamine initiation\nbased on MAP dynamics, treatment context, and patient characteristics supports\nthe critical decision of when to escalate therapy, shifting focus from\nthreshold-based alarms to actionable decision support. This approach is\nfeasible across a broad ICU cohort under natural event imbalance. Future work\nshould enrich temporal and physiological context, extend label definitions to\ninclude therapy escalation, and benchmark against existing hypotension\nprediction systems.",
    "published": "2025-10-28T10:49:42Z",
    "updated": "2025-10-28T10:49:42Z",
    "link": "http://arxiv.org/pdf/2510.24287v1.pdf",
    "category": [
      "eess.SP",
      "cs.LG"
    ],
    "authors": [
      "Richard Koebe",
      "Noah Saibel",
      "Juan Miguel Lopez Alcaraz",
      "Simon SchÃ¤fer",
      "Nils Strodthoff"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24279v1",
    "title": "HergNet: a Fast Neural Surrogate Model for Sound Field Predictions via\n  Superposition of Plane Waves",
    "summary": "We present a novel neural network architecture for the efficient prediction\nof sound fields in two and three dimensions. The network is designed to\nautomatically satisfy the Helmholtz equation, ensuring that the outputs are\nphysically valid. Therefore, the method can effectively learn solutions to\nboundary-value problems in various wave phenomena, such as acoustics, optics,\nand electromagnetism. Numerical experiments show that the proposed strategy can\npotentially outperform state-of-the-art methods in room acoustics simulation,\nin particular in the range of mid to high frequencies.",
    "published": "2025-10-28T10:39:10Z",
    "updated": "2025-10-28T10:39:10Z",
    "link": "http://arxiv.org/pdf/2510.24279v1.pdf",
    "category": [
      "cs.SD",
      "cs.CE",
      "cs.LG",
      "eess.AS"
    ],
    "authors": [
      "Matteo CalafÃ ",
      "Yuanxin Xia",
      "Cheol-Ho Jeong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24273v1",
    "title": "SALS: Sparse Attention in Latent Space for KV cache Compression",
    "summary": "Large Language Models capable of handling extended contexts are in high\ndemand, yet their inference remains challenging due to substantial Key-Value\ncache size and high memory bandwidth requirements. Previous research has\ndemonstrated that KV cache exhibits low-rank characteristics within the hidden\ndimension, suggesting the potential for effective compression. However, due to\nthe widely adopted Rotary Position Embedding mechanism in modern LLMs, naive\nlow-rank compression suffers severe accuracy degradation or creates a new speed\nbottleneck, as the low-rank cache must first be reconstructed in order to apply\nRoPE. In this paper, we introduce two key insights: first, the application of\nRoPE to the key vectors increases their variance, which in turn results in a\nhigher rank; second, after the key vectors are transformed into the latent\nspace, they largely maintain their representation across most layers. Based on\nthese insights, we propose the Sparse Attention in Latent Space framework. SALS\nprojects the KV cache into a compact latent space via low-rank projection, and\nperforms sparse token selection using RoPE-free query-key interactions in this\nspace. By reconstructing only a small subset of important tokens, it avoids the\noverhead of full KV cache reconstruction. We comprehensively evaluate SALS on\nvarious tasks using two large-scale models: LLaMA2-7b-chat and Mistral-7b, and\nadditionally verify its scalability on the RULER-128k benchmark with\nLLaMA3.1-8B-Instruct. Experimental results demonstrate that SALS achieves SOTA\nperformance by maintaining competitive accuracy. Under different settings, SALS\nachieves 6.4-fold KV cache compression and 5.7-fold speed-up in the attention\noperator compared to FlashAttention2 on the 4K sequence. For the end-to-end\nthroughput performance, we achieves 1.4-fold and 4.5-fold improvement compared\nto GPT-fast on 4k and 32K sequences, respectively.",
    "published": "2025-10-28T10:32:52Z",
    "updated": "2025-10-28T10:32:52Z",
    "link": "http://arxiv.org/pdf/2510.24273v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Junlin Mu",
      "Hantao Huang",
      "Jihang Zhang",
      "Minghui Yu",
      "Tao Wang",
      "Yidong Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24254v1",
    "title": "Forecasting precipitation in the Arctic using probabilistic machine\n  learning informed by causal climate drivers",
    "summary": "Understanding and forecasting precipitation events in the Arctic maritime\nenvironments, such as Bear Island and Ny-{\\AA}lesund, is crucial for assessing\nclimate risk and developing early warning systems in vulnerable marine regions.\nThis study proposes a probabilistic machine learning framework for modeling and\npredicting the dynamics and severity of precipitation. We begin by analyzing\nthe scale-dependent relationships between precipitation and key atmospheric\ndrivers (e.g., temperature, relative humidity, cloud cover, and air pressure)\nusing wavelet coherence, which captures localized dependencies across time and\nfrequency domains. To assess joint causal influences, we employ\nSynergistic-Unique-Redundant Decomposition, which quantifies the impact of\ninteraction effects among each variable on future precipitation dynamics. These\ninsights inform the development of data-driven forecasting models that\nincorporate both historical precipitation and causal climate drivers. To\naccount for uncertainty, we employ the conformal prediction method, which\nenables the generation of calibrated non-parametric prediction intervals. Our\nresults underscore the importance of utilizing a comprehensive framework that\ncombines causal analysis with probabilistic forecasting to enhance the\nreliability and interpretability of precipitation predictions in Arctic marine\nenvironments.",
    "published": "2025-10-28T10:05:34Z",
    "updated": "2025-10-28T10:05:34Z",
    "link": "http://arxiv.org/pdf/2510.24254v1.pdf",
    "category": [
      "physics.ao-ph",
      "cs.LG",
      "physics.data-an"
    ],
    "authors": [
      "Madhurima Panja",
      "Dhiman Das",
      "Tanujit Chakraborty",
      "Arnob Ray",
      "R. Athulya",
      "Chittaranjan Hens",
      "Syamal K. Dana",
      "Nuncio Murukesh",
      "Dibakar Ghosh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.18195v2",
    "title": "Acoustic and Machine Learning Methods for Speech-Based Suicide Risk\n  Assessment: A Systematic Review",
    "summary": "Suicide remains a public health challenge, necessitating improved detection\nmethods to facilitate timely intervention and treatment. This systematic review\nevaluates the role of Artificial Intelligence (AI) and Machine Learning (ML) in\nassessing suicide risk through acoustic analysis of speech. Following PRISMA\nguidelines, we analyzed 33 articles selected from PubMed, Cochrane, Scopus, and\nWeb of Science databases. The last search was conducted in February 2025. Risk\nof bias was assessed using the PROBAST tool. Studies analyzing acoustic\nfeatures between individuals at risk of suicide (RS) and those not at risk\n(NRS) were included, while studies lacking acoustic data, a suicide-related\nfocus, or sufficient methodological details were excluded. Sample sizes varied\nwidely and were reported in terms of participants or speech segments, depending\non the study. Results were synthesized narratively based on acoustic features\nand classifier performance. Findings consistently showed significant acoustic\nfeature variations between RS and NRS populations, particularly involving\njitter, fundamental frequency (F0), Mel-frequency cepstral coefficients (MFCC),\nand power spectral density (PSD). Classifier performance varied based on\nalgorithms, modalities, and speech elicitation methods, with multimodal\napproaches integrating acoustic, linguistic, and metadata features\ndemonstrating superior performance. Among the 29 classifier-based studies,\nreported AUC values ranged from 0.62 to 0.985 and accuracies from 60% to\n99.85%. Most datasets were imbalanced in favor of NRS, and performance metrics\nwere rarely reported separately by group, limiting clear identification of\ndirection of effect.",
    "published": "2025-05-20T09:05:30Z",
    "updated": "2025-10-28T10:02:13Z",
    "link": "http://arxiv.org/pdf/2505.18195v2.pdf",
    "category": [
      "eess.AS",
      "cs.LG",
      "cs.SD"
    ],
    "authors": [
      "Ambre Marie",
      "Marine Garnier",
      "Thomas Bertin",
      "Laura Machart",
      "Guillaume Dardenne",
      "GwenolÃ© Quellec",
      "Sofian Berrouiguet"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.20362v3",
    "title": "MH-GIN: Multi-scale Heterogeneous Graph-based Imputation Network for AIS\n  Data (Extended Version)",
    "summary": "Location-tracking data from the Automatic Identification System, much of\nwhich is publicly available, plays a key role in a range of maritime safety and\nmonitoring applications. However, the data suffers from missing values that\nhamper downstream applications. Imputing the missing values is challenging\nbecause the values of different heterogeneous attributes are updated at diverse\nrates, resulting in the occurrence of multi-scale dependencies among\nattributes. Existing imputation methods that assume similar update rates across\nattributes are unable to capture and exploit such dependencies, limiting their\nimputation accuracy. We propose MH-GIN, a Multi-scale Heterogeneous Graph-based\nImputation Network that aims improve imputation accuracy by capturing\nmulti-scale dependencies. Specifically, MH-GIN first extracts multi-scale\ntemporal features for each attribute while preserving their intrinsic\nheterogeneous characteristics. Then, it constructs a multi-scale heterogeneous\ngraph to explicitly model dependencies between heterogeneous attributes to\nenable more accurate imputation of missing values through graph propagation.\nExperimental results on two real-world datasets find that MH-GIN is capable of\nan average 57% reduction in imputation errors compared to state-of-the-art\nmethods, while maintaining computational efficiency. The source code and\nimplementation details of MH-GIN are publicly available\nhttps://github.com/hyLiu1994/MH-GIN.",
    "published": "2025-07-27T17:31:47Z",
    "updated": "2025-10-28T09:58:09Z",
    "link": "http://arxiv.org/pdf/2507.20362v3.pdf",
    "category": [
      "cs.LG",
      "cs.DB"
    ],
    "authors": [
      "Hengyu Liu",
      "Tianyi Li",
      "Yuqiang He",
      "Kristian Torp",
      "Yushuai Li",
      "Christian S. Jensen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24240v1",
    "title": "Temporal Knowledge Graph Hyperedge Forecasting: Exploring\n  Entity-to-Category Link Prediction",
    "summary": "Temporal Knowledge Graphs have emerged as a powerful way of not only modeling\nstatic relationships between entities but also the dynamics of how relations\nevolve over time. As these informational structures can be used to store\ninformation from a real-world setting, such as a news flow, predicting future\ngraph components to a certain extent equates predicting real-world events. Most\nof the research in this field focuses on embedding-based methods, often\nleveraging convolutional neural net architectures. These solutions act as black\nboxes, limiting insight. In this paper, we explore an extension to an\nestablished rule-based framework, TLogic, that yields a high accuracy in\ncombination with explainable predictions. This offers transparency and allows\nthe end-user to critically evaluate the rules applied at the end of the\nprediction stage. The new rule format incorporates entity category as a key\ncomponent with the purpose of limiting rule application only to relevant\nentities. When categories are unknown for building the graph, we propose a\ndata-driven method to generate them with an LLM-based approach. Additionally,\nwe investigate the choice of aggregation method for scores of retrieved\nentities when performing category prediction.",
    "published": "2025-10-28T09:47:38Z",
    "updated": "2025-10-28T09:47:38Z",
    "link": "http://arxiv.org/pdf/2510.24240v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Edward Markai",
      "Sina Molavipour"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24234v1",
    "title": "Sparse Optimistic Information Directed Sampling",
    "summary": "Many high-dimensional online decision-making problems can be modeled as\nstochastic sparse linear bandits. Most existing algorithms are designed to\nachieve optimal worst-case regret in either the data-rich regime, where\npolynomial depen- dence on the ambient dimension is unavoidable, or the\ndata-poor regime, where dimension-independence is possible at the cost of worse\ndependence on the num- ber of rounds. In contrast, the sparse Information\nDirected Sampling (IDS) algo- rithm satisfies a Bayesian regret bound that has\nthe optimal rate in both regimes simultaneously. In this work, we explore the\nuse of Sparse Optimistic Informa- tion Directed Sampling (SOIDS) to achieve the\nsame adaptivity in the worst-case setting, without Bayesian assumptions.\nThrough a novel analysis that enables the use of a time-dependent learning\nrate, we show that SOIDS can optimally balance information and regret. Our\nresults extend the theoretical guarantees of IDS, pro- viding the first\nalgorithm that simultaneously achieves optimal worst-case regret in both the\ndata-rich and data-poor regimes. We empirically demonstrate the good\nperformance of SOIDS.",
    "published": "2025-10-28T09:42:15Z",
    "updated": "2025-10-28T09:42:15Z",
    "link": "http://arxiv.org/pdf/2510.24234v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Ludovic Schwartz",
      "Hamish Flynn",
      "Gergely Neu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24233v1",
    "title": "PRIVET: Privacy Metric Based on Extreme Value Theory",
    "summary": "Deep generative models are often trained on sensitive data, such as genetic\nsequences, health data, or more broadly, any copyrighted, licensed or protected\ncontent. This raises critical concerns around privacy-preserving synthetic\ndata, and more specifically around privacy leakage, an issue closely tied to\noverfitting. Existing methods almost exclusively rely on global criteria to\nestimate the risk of privacy failure associated to a model, offering only\nquantitative non interpretable insights. The absence of rigorous evaluation\nmethods for data privacy at the sample-level may hinder the practical\ndeployment of synthetic data in real-world applications. Using extreme value\nstatistics on nearest-neighbor distances, we propose PRIVET, a generic\nsample-based, modality-agnostic algorithm that assigns an individual privacy\nleak score to each synthetic sample. We empirically demonstrate that PRIVET\nreliably detects instances of memorization and privacy leakage across diverse\ndata modalities, including settings with very high dimensionality, limited\nsample sizes such as genetic data and even under underfitting regimes. We\ncompare our method to existing approaches under controlled settings and show\nits advantage in providing both dataset level and sample level assessments\nthrough qualitative and quantitative outputs. Additionally, our analysis\nreveals limitations in existing computer vision embeddings to yield\nperceptually meaningful distances when identifying near-duplicate samples.",
    "published": "2025-10-28T09:42:03Z",
    "updated": "2025-10-28T09:42:03Z",
    "link": "http://arxiv.org/pdf/2510.24233v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Antoine Szatkownik",
      "AurÃ©lien Decelle",
      "Beatriz Seoane",
      "Nicolas Bereux",
      "LÃ©o Planche",
      "Guillaume Charpiat",
      "Burak Yelmen",
      "Flora Jay",
      "Cyril Furtlehner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.22777v2",
    "title": "SeeDNorm: Self-Rescaled Dynamic Normalization",
    "summary": "Normalization layer constitutes an essential component in neural networks. In\ntransformers, the predominantly used RMSNorm constrains vectors to a unit\nhypersphere, followed by dimension-wise rescaling through a learnable scaling\ncoefficient $\\gamma$ to maintain the representational capacity of the model.\nHowever, RMSNorm discards the input norm information in forward pass and a\nstatic scaling factor $\\gamma$ may be insufficient to accommodate the wide\nvariability of input data and distributional shifts, thereby limiting further\nperformance improvements, particularly in zero-shot scenarios that large\nlanguage models routinely encounter. To address this limitation, we propose\nSeeDNorm, which enhances the representational capability of the model by\ndynamically adjusting the scaling coefficient based on the current input,\nthereby preserving the input norm information and enabling data-dependent,\nself-rescaled dynamic normalization. During backpropagation, SeeDNorm retains\nthe ability of RMSNorm to dynamically adjust gradient according to the input\nnorm. We provide a detailed analysis of the training optimization for SeedNorm\nand proposed corresponding solutions to address potential instability issues\nthat may arise when applying SeeDNorm. We validate the effectiveness of\nSeeDNorm across models of varying sizes in large language model pre-training as\nwell as supervised and unsupervised computer vision tasks. By introducing a\nminimal number of parameters and with neglligible impact on model efficiency,\nSeeDNorm achieves consistently superior performance compared to previously\ncommonly used normalization layers such as RMSNorm and LayerNorm, as well as\nelement-wise activation alternatives to normalization layers like DyT.",
    "published": "2025-10-26T18:01:32Z",
    "updated": "2025-10-28T09:39:42Z",
    "link": "http://arxiv.org/pdf/2510.22777v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Wenrui Cai",
      "Defa Zhu",
      "Qingjie Liu",
      "Qiyang Min"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24228v1",
    "title": "A comparison between joint and dual UKF implementations for state\n  estimation and leak localization in water distribution networks",
    "summary": "The sustainability of modern cities highly depends on efficient water\ndistribution management, including effective pressure control and leak\ndetection and localization. Accurate information about the network hydraulic\nstate is therefore essential. This article presents a comparison between two\ndata-driven state estimation methods based on the Unscented Kalman Filter\n(UKF), fusing pressure, demand and flow data for head and flow estimation. One\napproach uses a joint state vector with a single estimator, while the other\nuses a dual-estimator scheme. We analyse their main characteristics, discussing\ndifferences, advantages and limitations, and compare them theoretically in\nterms of accuracy and complexity. Finally, we show several estimation results\nfor the L-TOWN benchmark, allowing to discuss their properties in a real\nimplementation.",
    "published": "2025-10-28T09:39:41Z",
    "updated": "2025-10-28T09:39:41Z",
    "link": "http://arxiv.org/pdf/2510.24228v1.pdf",
    "category": [
      "eess.SY",
      "cs.LG",
      "cs.NA",
      "cs.SY",
      "math.NA"
    ],
    "authors": [
      "Luis Romero-Ben",
      "Paul Irofti",
      "Florin Stoican",
      "VicenÃ§ Puig"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2310.13966v2",
    "title": "Minimax Optimal Transfer Learning for Kernel-based Nonparametric\n  Regression",
    "summary": "In recent years, transfer learning has garnered significant attention in the\nmachine learning community. Its ability to leverage knowledge from related\nstudies to improve generalization performance in a target study has made it\nhighly appealing. This paper focuses on investigating the transfer learning\nproblem within the context of nonparametric regression over a reproducing\nkernel Hilbert space. The aim is to bridge the gap between practical\neffectiveness and theoretical guarantees. We specifically consider two\nscenarios: one where the transferable sources are known and another where they\nare unknown. For the known transferable source case, we propose a two-step\nkernel-based estimator by solely using kernel ridge regression. For the unknown\ncase, we develop a novel method based on an efficient aggregation algorithm,\nwhich can automatically detect and alleviate the effects of negative sources.\nThis paper provides the statistical properties of the desired estimators and\nestablishes the minimax optimal rate. Through extensive numerical experiments\non synthetic data and real examples, we validate our theoretical findings and\ndemonstrate the effectiveness of our proposed method.",
    "published": "2023-10-21T10:55:31Z",
    "updated": "2025-10-28T09:32:53Z",
    "link": "http://arxiv.org/pdf/2310.13966v2.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "authors": [
      "Chao Wang",
      "Caixing Wang",
      "Xin He",
      "Xingdong Feng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.08256v2",
    "title": "Clustering-Based Low-Rank Matrix Approximation for Medical Image\n  Compression",
    "summary": "Medical images are inherently high-resolution and contain locally varying\nstructures crucial for diagnosis. Efficient compression must preserve\ndiagnostic fidelity while minimizing redundancy. Low-rank matrix approximation\n(LoRMA) techniques have shown strong potential for image compression by\ncapturing global correlations; however, they often fail to adapt to local\nstructural variations across regions of interest. To address this, we introduce\nan adaptive LoRMA, which partitions a medical image into overlapping patches,\ngroups structurally similar patches into clusters using k-means, and performs\nSVD within each cluster. We derive the overall compression factor accounting\nfor patch overlap and analyze how patch size influences compression efficiency\nand computational cost. While applicable to any data with high local variation,\nwe focus on medical imaging due to its pronounced local variability. We\nevaluate and compare our adaptive LoRMA against global SVD across four imaging\nmodalities: MRI, ultrasound, CT scan, and chest X-ray. Results demonstrate that\nadaptive LoRMA effectively preserves structural integrity, edge details, and\ndiagnostic relevance, measured by PSNR, SSIM, MSE, IoU, and EPI. Adaptive LoRMA\nminimizes block artifacts and residual errors, particularly in pathological\nregions, consistently outperforming global SVD in PSNR, SSIM, IoU, EPI, and\nachieving lower MSE. It prioritizes clinically salient regions while allowing\naggressive compression in non-critical regions, optimizing storage efficiency.\nAlthough adaptive LoRMA requires higher processing time, its diagnostic\nfidelity justifies the overhead for high-compression applications.",
    "published": "2025-05-13T06:10:05Z",
    "updated": "2025-10-28T09:31:26Z",
    "link": "http://arxiv.org/pdf/2505.08256v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Sisipho Hamlomo",
      "Marcellin Atemkeng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24216v1",
    "title": "Unlocking Out-of-Distribution Generalization in Dynamics through\n  Physics-Guided Augmentation",
    "summary": "In dynamical system modeling, traditional numerical methods are limited by\nhigh computational costs, while modern data-driven approaches struggle with\ndata scarcity and distribution shifts. To address these fundamental\nlimitations, we first propose SPARK, a physics-guided quantitative augmentation\nplugin. Specifically, SPARK utilizes a reconstruction autoencoder to integrate\nphysical parameters into a physics-rich discrete state dictionary. This state\ndictionary then acts as a structured dictionary of physical states, enabling\nthe creation of new, physically-plausible training samples via principled\ninterpolation in the latent space. Further, for downstream prediction, these\naugmented representations are seamlessly integrated with a Fourier-enhanced\nGraph ODE, a combination designed to robustly model the enriched data\ndistribution while capturing long-term temporal dependencies. Extensive\nexperiments on diverse benchmarks demonstrate that SPARK significantly\noutperforms state-of-the-art baselines, particularly in challenging\nout-of-distribution scenarios and data-scarce regimes, proving the efficacy of\nour physics-guided augmentation paradigm.",
    "published": "2025-10-28T09:30:35Z",
    "updated": "2025-10-28T09:30:35Z",
    "link": "http://arxiv.org/pdf/2510.24216v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Fan Xu",
      "Hao Wu",
      "Kun Wang",
      "Nan Wang",
      "Qingsong Wen",
      "Xian Wu",
      "Wei Gong",
      "Xibin Zhao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24215v1",
    "title": "What Can Be Recovered Under Sparse Adversarial Corruption?\n  Assumption-Free Theory for Linear Measurements",
    "summary": "Let \\(\\bm{A} \\in \\mathbb{R}^{m \\times n}\\) be an arbitrary, known matrix and\n\\(\\bm{e}\\) a \\(q\\)-sparse adversarial vector. Given \\(\\bm{y} = \\bm{A} x^* +\n\\bm{e}\\) and \\(q\\), we seek the smallest set containing \\(x^*\\)-hence the one\nconveying maximal information about \\(x^*\\)-that is uniformly recoverable from\n\\(\\bm{y}\\) without knowing \\(\\bm{e}\\). While exact recovery of \\(x^*\\) via\nstrong (and often impractical) structural assumptions on \\(\\bm{A}\\) or \\(x^*\\)\n(for example, restricted isometry, sparsity) is well studied, recoverability\nfor arbitrary \\(\\bm{A}\\) and \\(x^*\\) remains open. Our main result shows that\nthe best that one can hope to recover is \\(x^* + \\ker(\\bm{U})\\), where\n\\(\\bm{U}\\) is the unique projection matrix onto the intersection of rowspaces\nof all possible submatrices of \\(\\bm{A}\\) obtained by deleting \\(2q\\) rows.\nMoreover, we prove that every \\(x\\) that minimizes the \\(\\ell\\_0\\)-norm of\n\\(\\bm{y} - \\bm{A} x\\) lies in \\(x^* + \\ker(\\bm{U})\\), which then gives a\nconstructive approach to recover this set.",
    "published": "2025-10-28T09:29:46Z",
    "updated": "2025-10-28T09:29:46Z",
    "link": "http://arxiv.org/pdf/2510.24215v1.pdf",
    "category": [
      "cs.IT",
      "cs.LG",
      "eess.SP",
      "math.IT"
    ],
    "authors": [
      "Vishal Halder",
      "Alexandre Reiffers-Masson",
      "Abdeldjalil AÃ¯ssa-El-Bey",
      "Gugan Thoppe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.21800v2",
    "title": "MARS-M: When Variance Reduction Meets Matrices",
    "summary": "Matrix-based preconditioned optimizers, such as Muon, have recently been\nshown to be more efficient than scalar-based optimizers for training\nlarge-scale neural networks, including large language models (LLMs). On the\nother hand, recent benchmarks on optimizers for LLM pre-training have\ndemonstrated that variance-reduction techniques such as MARS can achieve\nsubstantial speedups over standard optimizers that do not employ variance\nreduction. In this paper, to achieve the best of both worlds, we introduce\nMARS-M, a new optimizer that integrates the variance reduction technique in\nMARS with Muon. Under standard regularity conditions, we prove that Muon-M\nconverges to a first-order stationary point at a rate of\n$\\tilde{\\mathcal{O}}(T^{-1/3})$, which improves upon\n$\\tilde{\\mathcal{O}}(T^{-1/4})$ rate attained by Muon. Our empirical results on\nlanguage modeling and computer vision tasks demonstrate that MARS-M\nconsistently yields lower losses and improved performance across various\ndownstream benchmarks. The implementation of MARS-M is available at\nhttps://github.com/AGI-Arena/MARS/tree/main/MARS_M.",
    "published": "2025-10-20T16:49:22Z",
    "updated": "2025-10-28T09:27:41Z",
    "link": "http://arxiv.org/pdf/2510.21800v2.pdf",
    "category": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "authors": [
      "Yifeng Liu",
      "Angela Yuan",
      "Quanquan Gu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.15403v2",
    "title": "Geometric Mixture Models for Electrolyte Conductivity Prediction",
    "summary": "Accurate prediction of ionic conductivity in electrolyte systems is crucial\nfor advancing numerous scientific and technological applications. While\nsignificant progress has been made, current research faces two fundamental\nchallenges: (1) the lack of high-quality standardized benchmarks, and (2)\ninadequate modeling of geometric structure and intermolecular interactions in\nmixture systems. To address these limitations, we first reorganize and enhance\nthe CALiSol and DiffMix electrolyte datasets by incorporating geometric graph\nrepresentations of molecules. We then propose GeoMix, a novel geometry-aware\nframework that preserves Set-SE(3) equivariance-an essential but challenging\nproperty for mixture systems. At the heart of GeoMix lies the Geometric\nInteraction Network (GIN), an equivariant module specifically designed for\nintermolecular geometric message passing. Comprehensive experiments demonstrate\nthat GeoMix consistently outperforms diverse baselines (including MLPs, GNNs,\nand geometric GNNs) across both datasets, validating the importance of\ncross-molecular geometric interactions and equivariant message passing for\naccurate property prediction. This work not only establishes new benchmarks for\nelectrolyte research but also provides a general geometric learning framework\nthat advances modeling of mixture systems in energy materials, pharmaceutical\ndevelopment, and beyond.",
    "published": "2025-10-17T07:56:15Z",
    "updated": "2025-10-28T09:19:23Z",
    "link": "http://arxiv.org/pdf/2510.15403v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Anyi Li",
      "Jiacheng Cen",
      "Songyou Li",
      "Mingze Li",
      "Yang Yu",
      "Wenbing Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.21758v2",
    "title": "Taxonomy and Trends in Reinforcement Learning for Robotics and Control\n  Systems: A Structured Review",
    "summary": "Reinforcement learning (RL) has become a foundational approach for enabling\nintelligent robotic behavior in dynamic and uncertain environments. This work\npresents an in-depth review of RL principles, advanced deep reinforcement\nlearning (DRL) algorithms, and their integration into robotic and control\nsystems. Beginning with the formalism of Markov Decision Processes (MDPs), the\nstudy outlines essential elements of the agent-environment interaction and\nexplores core algorithmic strategies including actor-critic methods,\nvalue-based learning, and policy gradients. Emphasis is placed on modern DRL\ntechniques such as DDPG, TD3, PPO, and SAC, which have shown promise in solving\nhigh-dimensional, continuous control tasks. A structured taxonomy is introduced\nto categorize RL applications across domains such as locomotion, manipulation,\nmulti-agent coordination, and human-robot interaction, along with training\nmethodologies and deployment readiness levels. The review synthesizes recent\nresearch efforts, highlighting technical trends, design patterns, and the\ngrowing maturity of RL in real-world robotics. Overall, this work aims to\nbridge theoretical advances with practical implementations, providing a\nconsolidated perspective on the evolving role of RL in autonomous robotic\nsystems.",
    "published": "2025-10-11T20:16:32Z",
    "updated": "2025-10-28T09:14:57Z",
    "link": "http://arxiv.org/pdf/2510.21758v2.pdf",
    "category": [
      "cs.RO",
      "cs.LG"
    ],
    "authors": [
      "Kumater Ter",
      "Ore-Ofe Ajayi",
      "Daniel Udekwe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.17734v2",
    "title": "URB - Urban Routing Benchmark for RL-equipped Connected Autonomous\n  Vehicles",
    "summary": "Connected Autonomous Vehicles (CAVs) promise to reduce congestion in future\nurban networks, potentially by optimizing their routing decisions. Unlike for\nhuman drivers, these decisions can be made with collective, data-driven\npolicies, developed using machine learning algorithms. Reinforcement learning\n(RL) can facilitate the development of such collective routing strategies, yet\nstandardized and realistic benchmarks are missing. To that end, we present URB:\nUrban Routing Benchmark for RL-equipped Connected Autonomous Vehicles. URB is a\ncomprehensive benchmarking environment that unifies evaluation across 29\nreal-world traffic networks paired with realistic demand patterns. URB comes\nwith a catalog of predefined tasks, multi-agent RL (MARL) algorithm\nimplementations, three baseline methods, domain-specific performance metrics,\nand a modular configuration scheme. Our results show that, despite the lengthy\nand costly training, state-of-the-art MARL algorithms rarely outperformed\nhumans. The experimental results reported in this paper initiate the first\nleaderboard for MARL in large-scale urban routing optimization. They reveal\nthat current approaches struggle to scale, emphasizing the urgent need for\nadvancements in this domain.",
    "published": "2025-05-23T10:54:53Z",
    "updated": "2025-10-28T09:06:30Z",
    "link": "http://arxiv.org/pdf/2505.17734v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Ahmet Onur Akman",
      "Anastasia Psarou",
      "MichaÅ Hoffmann",
      "Åukasz Gorczyca",
      "Åukasz Kowalski",
      "PaweÅ Gora",
      "Grzegorz JamrÃ³z",
      "RafaÅ Kucharski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24200v1",
    "title": "SPEAR++: Scaling Gradient Inversion via Sparsely-Used Dictionary\n  Learning",
    "summary": "Federated Learning has seen an increased deployment in real-world scenarios\nrecently, as it enables the distributed training of machine learning models\nwithout explicit data sharing between individual clients. Yet, the introduction\nof the so-called gradient inversion attacks has fundamentally challenged its\nprivacy-preserving properties. Unfortunately, as these attacks mostly rely on\ndirect data optimization without any formal guarantees, the vulnerability of\nreal-world systems remains in dispute and requires tedious testing for each new\nfederated deployment. To overcome these issues, recently the SPEAR attack was\nintroduced, which is based on a theoretical analysis of the gradients of linear\nlayers with ReLU activations. While SPEAR is an important theoretical\nbreakthrough, the attack's practicality was severely limited by its exponential\nruntime in the batch size b. In this work, we fill this gap by applying\nState-of-the-Art techniques from Sparsely-Used Dictionary Learning to make the\nproblem of gradient inversion on linear layers with ReLU activations tractable.\nOur experiments demonstrate that our new attack, SPEAR++, retains all desirable\nproperties of SPEAR, such as robustness to DP noise and FedAvg aggregation,\nwhile being applicable to 10x bigger batch sizes.",
    "published": "2025-10-28T09:06:19Z",
    "updated": "2025-10-28T09:06:19Z",
    "link": "http://arxiv.org/pdf/2510.24200v1.pdf",
    "category": [
      "cs.LG",
      "cs.CR",
      "cs.DC",
      "I.2.11"
    ],
    "authors": [
      "Alexander Bakarsky",
      "Dimitar I. Dimitrov",
      "Maximilian Baader",
      "Martin Vechev"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24194v1",
    "title": "Blindfolded Experts Generalize Better: Insights from Robotic\n  Manipulation and Videogames",
    "summary": "Behavioral cloning is a simple yet effective technique for learning\nsequential decision-making from demonstrations. Recently, it has gained\nprominence as the core of foundation models for the physical world, where\nachieving generalization requires countless demonstrations of a multitude of\ntasks. Typically, a human expert with full information on the task demonstrates\na (nearly) optimal behavior. In this paper, we propose to hide some of the\ntask's information from the demonstrator. This ``blindfolded'' expert is\ncompelled to employ non-trivial exploration to solve the task. We show that\ncloning the blindfolded expert generalizes better to unseen tasks than its\nfully-informed counterpart. We conduct experiments of real-world robot peg\ninsertion tasks with (limited) human demonstrations, alongside videogames from\nthe Procgen benchmark. Additionally, we support our findings with theoretical\nanalysis, which confirms that the generalization error scales with\n$\\sqrt{I/m}$, where $I$ measures the amount of task information available to\nthe demonstrator, and $m$ is the number of demonstrated tasks. Both theory and\npractice indicate that cloning blindfolded experts generalizes better with\nfewer demonstrated tasks. Project page with videos and code:\nhttps://sites.google.com/view/blindfoldedexperts/home",
    "published": "2025-10-28T08:57:27Z",
    "updated": "2025-10-28T08:57:27Z",
    "link": "http://arxiv.org/pdf/2510.24194v1.pdf",
    "category": [
      "cs.RO",
      "cs.LG"
    ],
    "authors": [
      "Ev Zisselman",
      "Mirco Mutti",
      "Shelly Francis-Meretzki",
      "Elisei Shafer",
      "Aviv Tamar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.12730v2",
    "title": "Unlearning Comparator: A Visual Analytics System for Comparative\n  Evaluation of Machine Unlearning Methods",
    "summary": "Machine Unlearning (MU) aims to remove target training data from a trained\nmodel so that the removed data no longer influences the model's behavior,\nfulfilling \"right to be forgotten\" obligations under data privacy laws. Yet, we\nobserve that researchers in this rapidly emerging field face challenges in\nanalyzing and understanding the behavior of different MU methods, especially in\nterms of three fundamental principles in MU: accuracy, efficiency, and privacy.\nConsequently, they often rely on aggregate metrics and ad-hoc evaluations,\nmaking it difficult to accurately assess the trade-offs between methods. To\nfill this gap, we introduce a visual analytics system, Unlearning Comparator,\ndesigned to facilitate the systematic evaluation of MU methods. Our system\nsupports two important tasks in the evaluation process: model comparison and\nattack simulation. First, it allows the user to compare the behaviors of two\nmodels, such as a model generated by a certain method and a retrained baseline,\nat class-, instance-, and layer-levels to better understand the changes made\nafter unlearning. Second, our system simulates membership inference attacks\n(MIAs) to evaluate the privacy of a method, where an attacker attempts to\ndetermine whether specific data samples were part of the original training set.\nWe evaluate our system through a case study visually analyzing prominent MU\nmethods and demonstrate that it helps the user not only understand model\nbehaviors but also gain insights that can inform the improvement of MU methods.\nThe source code is publicly available at\nhttps://github.com/gnueaj/Machine-Unlearning-Comparator.",
    "published": "2025-08-18T08:53:53Z",
    "updated": "2025-10-28T08:47:58Z",
    "link": "http://arxiv.org/pdf/2508.12730v2.pdf",
    "category": [
      "cs.CR",
      "cs.HC",
      "cs.LG",
      "H.5.2; I.3.6"
    ],
    "authors": [
      "Jaeung Lee",
      "Suhyeon Yu",
      "Yurim Jang",
      "Simon S. Woo",
      "Jaemin Jo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24187v1",
    "title": "Self-Concordant Perturbations for Linear Bandits",
    "summary": "We study the adversarial linear bandits problem and present a unified\nalgorithmic framework that bridges Follow-the-Regularized-Leader (FTRL) and\nFollow-the-Perturbed-Leader (FTPL) methods, extending the known connection\nbetween them from the full-information setting. Within this framework, we\nintroduce self-concordant perturbations, a family of probability distributions\nthat mirror the role of self-concordant barriers previously employed in the\nFTRL-based SCRiBLe algorithm. Using this idea, we design a novel FTPL-based\nalgorithm that combines self-concordant regularization with efficient\nstochastic exploration. Our approach achieves a regret of $O(d\\sqrt{n \\ln n})$\non both the $d$-dimensional hypercube and the Euclidean ball. On the Euclidean\nball, this matches the rate attained by existing self-concordant FTRL methods.\nFor the hypercube, this represents a $\\sqrt{d}$ improvement over these methods\nand matches the optimal bound up to logarithmic factors.",
    "published": "2025-10-28T08:47:15Z",
    "updated": "2025-10-28T08:47:15Z",
    "link": "http://arxiv.org/pdf/2510.24187v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Lucas LÃ©vy",
      "Jean-Lou Valeau",
      "Arya Akhavan",
      "Patrick Rebeschini"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.01356v2",
    "title": "Two-Stage Learning of Stabilizing Neural Controllers via Zubov Sampling\n  and Iterative Domain Expansion",
    "summary": "Learning-based neural network (NN) control policies have shown impressive\nempirical performance. However, obtaining stability guarantees and estimates of\nthe region of attraction of these learned neural controllers is challenging due\nto the lack of stable and scalable training and verification algorithms.\nAlthough previous works in this area have achieved great success, much\nconservatism remains in their frameworks. In this work, we propose a novel\ntwo-stage training framework to jointly synthesize a controller and a Lyapunov\nfunction for continuous-time systems. By leveraging a Zubov-inspired region of\nattraction characterization to directly estimate stability boundaries, we\npropose a novel training-data sampling strategy and a domain-updating mechanism\nthat significantly reduces the conservatism in training. Moreover, unlike\nexisting works on continuous-time systems that rely on an SMT solver to\nformally verify the Lyapunov condition, we extend state-of-the-art neural\nnetwork verifier $\\alpha,\\!\\beta$-CROWN with the capability of performing\nautomatic bound propagation through the Jacobian of dynamical systems and a\nnovel verification scheme that avoids expensive bisection. To demonstrate the\neffectiveness of our approach, we conduct numerical experiments by synthesizing\nand verifying controllers on several challenging nonlinear systems across\nmultiple dimensions. We show that our training can yield region of attractions\nwith volume $5 - 1.5\\cdot 10^{5}$ times larger compared to the baselines, and\nour verification on continuous systems can be up to $40-10{,}000$ times faster\ncompared to the traditional SMT solver dReal. Our code is available at\nhttps://github.com/Verified-Intelligence/Two-Stage_Neural_Controller_Training.",
    "published": "2025-06-02T06:20:09Z",
    "updated": "2025-10-28T08:42:04Z",
    "link": "http://arxiv.org/pdf/2506.01356v2.pdf",
    "category": [
      "cs.LG",
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "authors": [
      "Haoyu Li",
      "Xiangru Zhong",
      "Bin Hu",
      "Huan Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24180v1",
    "title": "V-SAT: Video Subtitle Annotation Tool",
    "summary": "The surge of audiovisual content on streaming platforms and social media has\nheightened the demand for accurate and accessible subtitles. However, existing\nsubtitle generation methods primarily speech-based transcription or OCR-based\nextraction suffer from several shortcomings, including poor synchronization,\nincorrect or harmful text, inconsistent formatting, inappropriate reading\nspeeds, and the inability to adapt to dynamic audio-visual contexts. Current\napproaches often address isolated issues, leaving post-editing as a\nlabor-intensive and time-consuming process. In this paper, we introduce V-SAT\n(Video Subtitle Annotation Tool), a unified framework that automatically\ndetects and corrects a wide range of subtitle quality issues. By combining\nLarge Language Models(LLMs), Vision-Language Models (VLMs), Image Processing,\nand Automatic Speech Recognition (ASR), V-SAT leverages contextual cues from\nboth audio and video. Subtitle quality improved, with the SUBER score reduced\nfrom 9.6 to 3.54 after resolving all language mode issues and F1-scores of\n~0.80 for image mode issues. Human-in-the-loop validation ensures high-quality\nresults, providing the first comprehensive solution for robust subtitle\nannotation.",
    "published": "2025-10-28T08:34:27Z",
    "updated": "2025-10-28T08:34:27Z",
    "link": "http://arxiv.org/pdf/2510.24180v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Arpita Kundu",
      "Joyita Chakraborty",
      "Anindita Desarkar",
      "Aritra Sen",
      "Srushti Anil Patil",
      "Vishwanathan Raman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.03188v4",
    "title": "Pairwise Optimal Transports for Training All-to-All Flow-Based Condition\n  Transfer Model",
    "summary": "In this paper, we propose a flow-based method for learning all-to-all\ntransfer maps among conditional distributions that approximates pairwise\noptimal transport. The proposed method addresses the challenge of handling the\ncase of continuous conditions, which often involve a large set of conditions\nwith sparse empirical observations per condition. We introduce a novel cost\nfunction that enables simultaneous learning of optimal transports for all pairs\nof conditional distributions. Our method is supported by a theoretical\nguarantee that, in the limit, it converges to the pairwise optimal transports\namong infinite pairs of conditional distributions. The learned transport maps\nare subsequently used to couple data points in conditional flow matching. We\ndemonstrate the effectiveness of this method on synthetic and benchmark\ndatasets, as well as on chemical datasets in which continuous physical\nproperties are defined as conditions. The code for this project can be found at\nhttps://github.com/kotatumuri-room/A2A-FM",
    "published": "2025-04-04T05:32:54Z",
    "updated": "2025-10-28T08:28:52Z",
    "link": "http://arxiv.org/pdf/2504.03188v4.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Kotaro Ikeda",
      "Masanori Koyama",
      "Jinzhe Zhang",
      "Kohei Hayashi",
      "Kenji Fukumizu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24173v1",
    "title": "EddyFormer: Accelerated Neural Simulations of Three-Dimensional\n  Turbulence at Scale",
    "summary": "Computationally resolving turbulence remains a central challenge in fluid\ndynamics due to its multi-scale interactions. Fully resolving large-scale\nturbulence through direct numerical simulation (DNS) is computationally\nprohibitive, motivating data-driven machine learning alternatives. In this\nwork, we propose EddyFormer, a Transformer-based spectral-element (SEM)\narchitecture for large-scale turbulence simulation that combines the accuracy\nof spectral methods with the scalability of the attention mechanism. We\nintroduce an SEM tokenization that decomposes the flow into grid-scale and\nsubgrid-scale components, enabling capture of both local and global features.\nWe create a new three-dimensional isotropic turbulence dataset and train\nEddyFormer to achieves DNS-level accuracy at 256^3 resolution, providing a 30x\nspeedup over DNS. When applied to unseen domains up to 4x larger than in\ntraining, EddyFormer preserves accuracy on physics-invariant metrics-energy\nspectra, correlation functions, and structure functions-showing domain\ngeneralization. On The Well benchmark suite of diverse turbulent flows,\nEddyFormer resolves cases where prior ML models fail to converge, accurately\nreproducing complex dynamics across a wide range of physical conditions.",
    "published": "2025-10-28T08:27:37Z",
    "updated": "2025-10-28T08:27:37Z",
    "link": "http://arxiv.org/pdf/2510.24173v1.pdf",
    "category": [
      "cs.LG",
      "cs.NA",
      "math.DS",
      "math.NA",
      "physics.flu-dyn"
    ],
    "authors": [
      "Yiheng Du",
      "Aditi S. Krishnapriyan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.17637v2",
    "title": "Causal Spatio-Temporal Prediction: An Effective and Efficient\n  Multi-Modal Approach",
    "summary": "Spatio-temporal prediction plays a crucial role in intelligent\ntransportation, weather forecasting, and urban planning. While integrating\nmulti-modal data has shown potential for enhancing prediction accuracy, key\nchallenges persist: (i) inadequate fusion of multi-modal information, (ii)\nconfounding factors that obscure causal relations, and (iii) high computational\ncomplexity of prediction models. To address these challenges, we propose\nE^2-CSTP, an Effective and Efficient Causal multi-modal Spatio-Temporal\nPrediction framework. E^2-CSTP leverages cross-modal attention and gating\nmechanisms to effectively integrate multi-modal data. Building on this, we\ndesign a dual-branch causal inference approach: the primary branch focuses on\nspatio-temporal prediction, while the auxiliary branch mitigates bias by\nmodeling additional modalities and applying causal interventions to uncover\ntrue causal dependencies. To improve model efficiency, we integrate GCN with\nthe Mamba architecture for accelerated spatio-temporal encoding. Extensive\nexperiments on 4 real-world datasets show that E^2-CSTP significantly\noutperforms 9 state-of-the-art methods, achieving up to 9.66% improvements in\naccuracy as well as 17.37%-56.11% reductions in computational overhead.",
    "published": "2025-05-23T08:58:38Z",
    "updated": "2025-10-28T07:57:56Z",
    "link": "http://arxiv.org/pdf/2505.17637v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Yuting Huang",
      "Ziquan Fang",
      "Zhihao Zeng",
      "Lu Chen",
      "Yunjun Gao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.10101v3",
    "title": "Rademacher Meets Colors: More Expressivity, but at What Cost ?",
    "summary": "The expressive power of graph neural networks (GNNs) is typically understood\nthrough their correspondence with graph isomorphism tests such as the\nWeisfeiler-Leman (WL) hierarchy. While more expressive GNNs can distinguish a\nricher set of graphs, they are also observed to suffer from higher\ngeneralization error. This work provides a theoretical explanation for this\ntrade-off by linking expressivity and generalization through the lens of\ncoloring algorithms. Specifically, we show that the number of equivalence\nclasses induced by WL colorings directly bounds the GNNs Rademacher complexity\n-- a key data-dependent measure of generalization. Our analysis reveals that\ngreater expressivity leads to higher complexity and thus weaker generalization\nguarantees. Furthermore, we prove that the Rademacher complexity is stable\nunder perturbations in the color counts across different samples, ensuring\nrobustness to sampling variability across datasets. Importantly, our framework\nis not restricted to message-passing GNNs or 1-WL, but extends to arbitrary GNN\narchitectures and expressivity measures that partition graphs into equivalence\nclasses. These results unify the study of expressivity and generalization in\nGNNs, providing a principled understanding of why increasing expressive power\noften comes at the cost of generalization.",
    "published": "2025-10-11T08:24:07Z",
    "updated": "2025-10-28T07:57:39Z",
    "link": "http://arxiv.org/pdf/2510.10101v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Martin Carrasco",
      "Caio F. Deberaldini Netto",
      "Vahan A. Martirosyan",
      "Aneeqa Mehrab",
      "Ehimare Okoyomon",
      "Caterina Graziani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24160v1",
    "title": "Identifiable learning of dissipative dynamics",
    "summary": "Complex dissipative systems appear across science and engineering, from\npolymers and active matter to learning algorithms. These systems operate far\nfrom equilibrium, where energy dissipation and time irreversibility are key to\ntheir behavior, but are difficult to quantify from data. Learning accurate and\ninterpretable models of such dynamics remains a major challenge: the models\nmust be expressive enough to describe diverse processes, yet constrained enough\nto remain physically meaningful and mathematically identifiable. Here, we\nintroduce I-OnsagerNet, a neural framework that learns dissipative stochastic\ndynamics directly from trajectories while ensuring both interpretability and\nuniqueness. I-OnsagerNet extends the Onsager principle to guarantee that the\nlearned potential is obtained from the stationary density and that the drift\ndecomposes cleanly into time-reversible and time-irreversible components, as\ndictated by the Helmholtz decomposition. Our approach enables us to calculate\nthe entropy production and to quantify irreversibility, offering a principled\nway to detect and quantify deviations from equilibrium. Applications to polymer\nstretching in elongational flow and to stochastic gradient Langevin dynamics\nreveal new insights, including super-linear scaling of barrier heights and\nsub-linear scaling of entropy production rates with the strain rate, and the\nsuppression of irreversibility with increasing batch size. I-OnsagerNet thus\nestablishes a general, data-driven framework for discovering and interpreting\nnon-equilibrium dynamics.",
    "published": "2025-10-28T07:57:14Z",
    "updated": "2025-10-28T07:57:14Z",
    "link": "http://arxiv.org/pdf/2510.24160v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Aiqing Zhu",
      "Beatrice W. Soh",
      "Grigorios A. Pavliotis",
      "Qianxiao Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.04415v2",
    "title": "Interpretable Clustering with Adaptive Heterogeneous Causal Structure\n  Learning in Mixed Observational Data",
    "summary": "Understanding causal heterogeneity is essential for scientific discovery in\ndomains such as biology and medicine. However, existing methods lack causal\nawareness, with insufficient modeling of heterogeneity, confounding, and\nobservational constraints, leading to poor interpretability and difficulty\ndistinguishing true causal heterogeneity from spurious associations. We propose\nan unsupervised framework, HCL (Interpretable Causal Mechanism-Aware Clustering\nwith Adaptive Heterogeneous Causal Structure Learning), that jointly infers\nlatent clusters and their associated causal structures from mixed-type\nobservational data without requiring temporal ordering, environment labels,\ninterventions or other prior knowledge. HCL relaxes the homogeneity and\nsufficiency assumptions by introducing an equivalent representation that\nencodes both structural heterogeneity and confounding. It further develops a\nbi-directional iterative strategy to alternately refine causal clustering and\nstructure learning, along with a self-supervised regularization that balance\ncross-cluster universality and specificity. Together, these components enable\nconvergence toward interpretable, heterogeneous causal patterns. Theoretically,\nwe show identifiability of heterogeneous causal structures under mild\nconditions. Empirically, HCL achieves superior performance in both clustering\nand structure learning tasks, and recovers biologically meaningful mechanisms\nin real-world single-cell perturbation data, demonstrating its utility for\ndiscovering interpretable, mechanism-level causal heterogeneity.",
    "published": "2025-09-04T17:37:35Z",
    "updated": "2025-10-28T07:32:34Z",
    "link": "http://arxiv.org/pdf/2509.04415v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Wenrui Li",
      "Qinghao Zhang",
      "Xiaowo Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24135v1",
    "title": "Fixed Point Neural Acceleration and Inverse Surrogate Model for Battery\n  Parameter Identification",
    "summary": "The rapid expansion of electric vehicles has intensified the need for\naccurate and efficient diagnosis of lithium-ion batteries. Parameter\nidentification of electrochemical battery models is widely recognized as a\npowerful method for battery health assessment. However, conventional\nmetaheuristic approaches suffer from high computational cost and slow\nconvergence, and recent machine learning methods are limited by their reliance\non constant current data, which may not be available in practice. To overcome\nthese challenges, we propose deep learning-based framework for parameter\nidentification of electrochemical battery models. The proposed framework\ncombines a neural surrogate model of the single particle model with electrolyte\n(NeuralSPMe) and a deep learning-based fixed-point iteration method. NeuralSPMe\nis trained on realistic EV load profiles to accurately predict lithium\nconcentration dynamics under dynamic operating conditions while a parameter\nupdate network (PUNet) performs fixed-point iterative updates to significantly\nreduce both the evaluation time per sample and the overall number of iterations\nrequired for convergence. Experimental evaluations demonstrate that the\nproposed framework accelerates the parameter identification by more than 2000\ntimes, achieves superior sample efficiency and more than 10 times higher\naccuracy compared to conventional metaheuristic algorithms, particularly under\ndynamic load scenarios encountered in practical applications.",
    "published": "2025-10-28T07:20:38Z",
    "updated": "2025-10-28T07:20:38Z",
    "link": "http://arxiv.org/pdf/2510.24135v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Hojin Cheon",
      "Hyeongseok Seo",
      "Jihun Jeon",
      "Wooju Lee",
      "Dohyun Jeong",
      "Hongseok Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24125v1",
    "title": "Causal Convolutional Neural Networks as Finite Impulse Response Filters",
    "summary": "This study investigates the behavior of Causal Convolutional Neural Networks\n(CNNs) with quasi-linear activation functions when applied to time-series data\ncharacterized by multimodal frequency content. We demonstrate that, once\ntrained, such networks exhibit properties analogous to Finite Impulse Response\n(FIR) filters, particularly when the convolutional kernels are of extended\nlength exceeding those typically employed in standard CNN architectures. Causal\nCNNs are shown to capture spectral features both implicitly and explicitly,\noffering enhanced interpretability for tasks involving dynamic systems.\nLeveraging the associative property of convolution, we further show that the\nentire network can be reduced to an equivalent single-layer filter resembling\nan FIR filter optimized via least-squares criteria. This equivalence yields new\ninsights into the spectral learning behavior of CNNs trained on signals with\nsparse frequency content. The approach is validated on both simulated beam\ndynamics and real-world bridge vibration datasets, underlining its relevance\nfor modeling and identifying physical systems governed by dynamic responses.",
    "published": "2025-10-28T06:57:14Z",
    "updated": "2025-10-28T06:57:14Z",
    "link": "http://arxiv.org/pdf/2510.24125v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Kiran Bacsa",
      "Wei Liu",
      "Xudong Jian",
      "Huangbin Liang",
      "Eleni Chatzi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24120v1",
    "title": "Graph-Guided Concept Selection for Efficient Retrieval-Augmented\n  Generation",
    "summary": "Graph-based RAG constructs a knowledge graph (KG) from text chunks to enhance\nretrieval in Large Language Model (LLM)-based question answering. It is\nespecially beneficial in domains such as biomedicine, law, and political\nscience, where effective retrieval often involves multi-hop reasoning over\nproprietary documents. However, these methods demand numerous LLM calls to\nextract entities and relations from text chunks, incurring prohibitive costs at\nscale. Through a carefully designed ablation study, we observe that certain\nwords (termed concepts) and their associated documents are more important.\nBased on this insight, we propose Graph-Guided Concept Selection (G2ConS). Its\ncore comprises a chunk selection method and an LLM-independent concept graph.\nThe former selects salient document chunks to reduce KG construction costs; the\nlatter closes knowledge gaps introduced by chunk selection at zero cost.\nEvaluations on multiple real-world datasets show that G2ConS outperforms all\nbaselines in construction cost, retrieval effectiveness, and answering quality.",
    "published": "2025-10-28T06:47:30Z",
    "updated": "2025-10-28T06:47:30Z",
    "link": "http://arxiv.org/pdf/2510.24120v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Ziyu Liu",
      "Yijing Liu",
      "Jianfei Yuan",
      "Minzhi Yan",
      "Le Yue",
      "Honghui Xiong",
      "Yi Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.21582v2",
    "title": "An unsupervised tour through the hidden pathways of deep neural networks",
    "summary": "The goal of this thesis is to improve our understanding of the internal\nmechanisms by which deep artificial neural networks create meaningful\nrepresentations and are able to generalize. We focus on the challenge of\ncharacterizing the semantic content of the hidden representations with\nunsupervised learning tools, partially developed by us and described in this\nthesis, which allow harnessing the low-dimensional structure of the data.\nChapter 2. introduces Gride, a method that allows estimating the intrinsic\ndimension of the data as an explicit function of the scale without performing\nany decimation of the data set. Our approach is based on rigorous\ndistributional results that enable the quantification of uncertainty of the\nestimates. Moreover, our method is simple and computationally efficient since\nit relies only on the distances among nearest data points. In Chapter 3, we\nstudy the evolution of the probability density across the hidden layers in some\nstate-of-the-art deep neural networks. We find that the initial layers generate\na unimodal probability density getting rid of any structure irrelevant to\nclassification. In subsequent layers, density peaks arise in a hierarchical\nfashion that mirrors the semantic hierarchy of the concepts. This process\nleaves a footprint in the probability density of the output layer, where the\ntopography of the peaks allows reconstructing the semantic relationships of the\ncategories. In Chapter 4, we study the problem of generalization in deep neural\nnetworks: adding parameters to a network that interpolates its training data\nwill typically improve its generalization performance, at odds with the\nclassical bias-variance trade-off. We show that wide neural networks learn\nredundant representations instead of overfitting to spurious correlation and\nthat redundant neurons appear only if the network is regularized and the\ntraining error is zero.",
    "published": "2025-10-24T15:50:31Z",
    "updated": "2025-10-28T06:37:16Z",
    "link": "http://arxiv.org/pdf/2510.21582v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Diego Doimo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24088v1",
    "title": "Information-Theoretic Discrete Diffusion",
    "summary": "We present an information-theoretic framework for discrete diffusion models\nthat yields principled estimators of log-likelihood using score-matching\nlosses. Inspired by the I-MMSE identity for the Gaussian setup, we derive\nanalogous results for the discrete setting. Specifically, we introduce the\nInformation-Minimum Denoising Score Entropy (I-MDSE) relation, which links\nmutual information between data and its diffused version to the minimum\ndenoising score entropy (DSE) loss. We extend this theory to masked diffusion\nand establish the Information-Minimum Denoising Cross-Entropy (I-MDCE)\nrelation, connecting cross-entropy losses to mutual information in discrete\nmasked processes. These results provide a time-integral decomposition of the\nlog-likelihood of the data in terms of optimal score-based losses, showing that\ncommonly used losses such as DSE and DCE are not merely variational bounds but\ntight and principled estimators of log-likelihood. The I-MDCE decomposition\nfurther enables practical extensions, including time-free formula, conditional\nlikelihood estimation in prompt-response tasks, and coupled Monte Carlo\nestimation of likelihood ratios. Experiments on synthetic and real-world data\nconfirm the accuracy, variance stability, and utility of our estimators. The\ncode is publicly available at https://github.com/Dongjae0324/infodis.",
    "published": "2025-10-28T05:59:05Z",
    "updated": "2025-10-28T05:59:05Z",
    "link": "http://arxiv.org/pdf/2510.24088v1.pdf",
    "category": [
      "cs.LG",
      "cs.IT",
      "math.IT"
    ],
    "authors": [
      "Moongyu Jeon",
      "Sangwoo Shin",
      "Dongjae Jeon",
      "Albert No"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.14118v2",
    "title": "Selecting Critical Scenarios of DER Adoption in Distribution Grids Using\n  Bayesian Optimization",
    "summary": "We develop a new methodology to select scenarios of DER adoption most\ncritical for distribution grids. Anticipating risks of future voltage and line\nflow violations due to additional PV adopters is central for utility investment\nplanning but continues to rely on deterministic or ad hoc scenario selection.\nWe propose a highly efficient search framework based on multi-objective\nBayesian Optimization. We treat underlying grid stress metrics as\ncomputationally expensive black-box functions, approximated via Gaussian\nProcess surrogates and design an acquisition function based on probability of\nscenarios being Pareto-critical across a collection of line- and bus-based\nviolation objectives. Our approach provides a statistical guarantee and offers\nan order of magnitude speed-up relative to a conservative exhaustive search.\nCase studies on realistic feeders with 200-400 buses demonstrate the\neffectiveness and accuracy of our approach.",
    "published": "2025-01-23T22:20:30Z",
    "updated": "2025-10-28T05:52:26Z",
    "link": "http://arxiv.org/pdf/2501.14118v2.pdf",
    "category": [
      "cs.LG",
      "stat.AP",
      "stat.ML"
    ],
    "authors": [
      "Olivier Mulkin",
      "Miguel Heleno",
      "Mike Ludkovski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.23190v3",
    "title": "DeepRTE: Pre-trained Attention-based Neural Network for Radiative\n  Transfer",
    "summary": "In this paper, we propose a novel neural network approach, termed DeepRTE, to\naddress the steady-state Radiative Transfer Equation (RTE). The RTE is a\ndifferential-integral equation that governs the propagation of radiation\nthrough a participating medium, with applications spanning diverse domains such\nas neutron transport, atmospheric radiative transfer, heat transfer, and\noptical imaging. Our DeepRTE framework demonstrates superior computational\nefficiency for solving the steady-state RTE, surpassing traditional methods and\nexisting neural network approaches. This efficiency is achieved by embedding\nphysical information through derivation of the RTE and mathematically-informed\nnetwork architecture. Concurrently, DeepRTE achieves high accuracy with\nsignificantly fewer parameters, largely due to its incorporation of mechanisms\nsuch as multi-head attention. Furthermore, DeepRTE is a mesh-free neural\noperator framework with inherent zero-shot capability. This is achieved by\nincorporating Green's function theory and pre-training with delta-function\ninflow boundary conditions into both its architecture design and training data\nconstruction. The efficacy of the proposed approach is substantiated through\ncomprehensive numerical experiments.",
    "published": "2025-05-29T07:28:36Z",
    "updated": "2025-10-28T05:36:40Z",
    "link": "http://arxiv.org/pdf/2505.23190v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Yekun Zhu",
      "Min Tang",
      "Zheng Ma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24074v1",
    "title": "Deep Learning-Enhanced Calibration of the Heston Model: A Unified\n  Framework",
    "summary": "The Heston stochastic volatility model is a widely used tool in financial\nmathematics for pricing European options. However, its calibration remains\ncomputationally intensive and sensitive to local minima due to the model's\nnonlinear structure and high-dimensional parameter space. This paper introduces\na hybrid deep learning-based framework that enhances both the computational\nefficiency and the accuracy of the calibration procedure. The proposed approach\nintegrates two supervised feedforward neural networks: the Price Approximator\nNetwork (PAN), which approximates the option price surface based on strike and\nmoneyness inputs, and the Calibration Correction Network (CCN), which refines\nthe Heston model's output by correcting systematic pricing errors. Experimental\nresults on real S\\&P 500 option data demonstrate that the deep learning\napproach outperforms traditional calibration techniques across multiple error\nmetrics, achieving faster convergence and superior generalization in both\nin-sample and out-of-sample settings. This framework offers a practical and\nrobust solution for real-time financial model calibration.",
    "published": "2025-10-28T05:21:55Z",
    "updated": "2025-10-28T05:21:55Z",
    "link": "http://arxiv.org/pdf/2510.24074v1.pdf",
    "category": [
      "math.AP",
      "cs.LG"
    ],
    "authors": [
      "Arman Zadgar",
      "Somayeh Fallah",
      "Farshid Mehrdoust"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.01360v2",
    "title": "RDB2G-Bench: A Comprehensive Benchmark for Automatic Graph Modeling of\n  Relational Databases",
    "summary": "Recent advances have demonstrated the effectiveness of graph-based learning\non relational databases (RDBs) for predictive tasks. Such approaches require\ntransforming RDBs into graphs, a process we refer to as RDB-to-graph modeling,\nwhere rows of tables are represented as nodes and foreign-key relationships as\nedges. Yet, effective modeling of RDBs into graphs remains challenging.\nSpecifically, there exist numerous ways to model RDBs into graphs, and\nperformance on predictive tasks varies significantly depending on the chosen\ngraph model of RDBs. In our analysis, we find that the best-performing graph\nmodel can yield up to a 10% higher performance compared to the common heuristic\nrule for graph modeling, which remains non-trivial to identify. To foster\nresearch on intelligent RDB-to-graph modeling, we introduce RDB2G-Bench, the\nfirst benchmark framework for evaluating such methods. We construct extensive\ndatasets covering 5 real-world RDBs and 12 predictive tasks, resulting in\naround 50k graph model-performance pairs for efficient and reproducible\nevaluations. Thanks to our precomputed datasets, we were able to benchmark 10\nautomatic RDB-to-graph modeling methods on the 12 tasks about 380x faster than\non-the-fly evaluation, which requires repeated GNN training. Our analysis of\nthe datasets and benchmark results reveals key structural patterns affecting\ngraph model effectiveness, along with practical implications for effective\ngraph modeling. Our datasets and code are available at\nhttps://github.com/chlehdwon/RDB2G-Bench.",
    "published": "2025-06-02T06:34:10Z",
    "updated": "2025-10-28T05:17:40Z",
    "link": "http://arxiv.org/pdf/2506.01360v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Dongwon Choi",
      "Sunwoo Kim",
      "Juyeon Kim",
      "Kyungho Kim",
      "Geon Lee",
      "Shinhwan Kang",
      "Myunghwan Kim",
      "Kijung Shin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.14137v2",
    "title": "Learning Wireless Interference Patterns: Decoupled GNN for Throughput\n  Prediction in Heterogeneous Multi-Hop p-CSMA Networks",
    "summary": "The p-persistent CSMA protocol is central to random-access MAC analysis, but\npredicting saturation throughput in heterogeneous multi-hop wireless networks\nremains a hard problem. Simplified models that assume a single, shared\ninterference domain can underestimate throughput by 48-62% in sparse\ntopologies. Exact Markov-chain analyses are accurate but scale exponentially in\ncomputation time, making them impractical for large networks. These\ncomputational barriers motivate structural machine learning approaches like\nGNNs for scalable throughput prediction in general network topologies. Yet\noff-the-shelf GNNs struggle here: a standard GCN yields 63.94% normalized mean\nabsolute error (NMAE) on heterogeneous networks because symmetric normalization\nconflates a node's direct interference with higher-order, cascading effects\nthat pertain to how interference propagates over the network graph.\n  Building on these insights, we propose the Decoupled Graph Convolutional\nNetwork (D-GCN), a novel architecture that explicitly separates processing of a\nnode's own transmission probability from neighbor interference effects. D-GCN\nreplaces mean aggregation with learnable attention, yielding interpretable,\nper-neighbor contribution weights while capturing complex multihop interference\npatterns. D-GCN attains 3.3% NMAE, outperforms strong baselines, remains\ntractable even when exact analytical methods become computationally infeasible,\nand enables gradient-based network optimization that achieves within 1% of\ntheoretical optima.",
    "published": "2025-10-15T22:13:59Z",
    "updated": "2025-10-28T05:11:02Z",
    "link": "http://arxiv.org/pdf/2510.14137v2.pdf",
    "category": [
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "authors": [
      "Faezeh Dehghan Tarzjani",
      "Bhaskar Krishnamachari"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.23981v3",
    "title": "Federated Structured Sparse PCA for Anomaly Detection in IoT Networks",
    "summary": "Although federated learning has gained prominence as a privacy-preserving\nframework tailored for distributed Internet of Things (IoT) environments,\ncurrent federated principal component analysis (PCA) methods lack integration\nof sparsity, a critical feature for robust anomaly detection. To address this\nlimitation, we propose a novel federated structured sparse PCA (FedSSP)\napproach for anomaly detection in IoT networks. The proposed model uniquely\nintegrates double sparsity regularization: (1) row-wise sparsity governed by\n$\\ell_{2,p}$-norm with $p\\in [0,1)$ to eliminate redundant feature dimensions,\nand (2) element-wise sparsity via $\\ell_{q}$-norm with $q\\in [0,1)$ to suppress\nnoise-sensitive components. To solve this nonconvex problem in a distributed\nsetting, we devise an efficient optimization algorithm based on the proximal\nalternating minimization (PAM). Numerical experiments validate that\nincorporating structured sparsity enhances both model interpretability and\ndetection accuracy. Our code is available at\nhttps://github.com/xianchaoxiu/FedSSP.",
    "published": "2025-03-31T11:50:21Z",
    "updated": "2025-10-28T04:55:22Z",
    "link": "http://arxiv.org/pdf/2503.23981v3.pdf",
    "category": [
      "cs.LG",
      "math.OC"
    ],
    "authors": [
      "Chenyi Huang",
      "Xianchao Xiu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.03520v3",
    "title": "Forecasting Outside the Box: Application-Driven Optimal Pointwise\n  Forecasts for Stochastic Optimization",
    "summary": "We study a class of two-stage stochastic programs, namely, those with fixed\nrecourse matrix and fixed costs, and linear second stage. We show that, under\nmild assumptions, the problem can be solved with just one scenario, which we\ncall an ``optimal scenario.'' Such a scenario does not have to be unique and\nmay fall outside the support of the underlying distribution. Although finding\nan optimal scenario in general might be hard, we show that the result can be\nparticularly useful in the case of stochastic optimization problems with\ncontextual information, where the goal is to optimize the expected value of a\ncertain function given some contextual information (e.g., previous demand,\ncustomer type, etc.) that accompany the main data of interest. The contextual\ninformation allows for a better estimation of the quantity of interest via\nmachine learning methods. We focus on a class of learning methods -- sometimes\ncalled in the literature decision-focused learning -- that integrate the\nlearning and optimization procedures by means of a bilevel optimization\nformulation, which determines the parameters for pointwise forecasts. By using\nthe optimal scenario result, we prove that when such models are applied to the\nclass of contextual two-stage problems considered in this paper, the pointwise\nforecasts computed from the bilevel optimization formulation actually yield\nasymptotically the best approximation of an optimal scenario within the\nmodeler's pre-specified set of parameterized forecast functions. Numerical\nresults conducted with inventory problems from the literature (with synthetic\ndata) as well as a bike-sharing problem with real data demonstrate that the\nproposed approach performs well when compared to benchmark methods from the\nliterature.",
    "published": "2024-11-05T21:54:50Z",
    "updated": "2025-10-28T04:54:54Z",
    "link": "http://arxiv.org/pdf/2411.03520v3.pdf",
    "category": [
      "math.OC",
      "cs.LG",
      "90C15"
    ],
    "authors": [
      "Tito Homem-de-Mello",
      "Juan Valencia",
      "Felipe Lagos",
      "Guido Lagos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24056v1",
    "title": "Copula-Stein Discrepancy: A Generator-Based Stein Operator for\n  Archimedean Dependence",
    "summary": "Kernel Stein discrepancies (KSDs) have become a principal tool for\ngoodness-of-fit testing, but standard KSDs are often insensitive to\nhigher-order dependency structures, such as tail dependence, which are critical\nin many scientific and financial domains. We address this gap by introducing\nthe Copula-Stein Discrepancy (CSD), a novel class of discrepancies tailored to\nthe geometry of statistical dependence. By defining a Stein operator directly\non the copula density, CSD leverages the generative structure of dependence,\nrather than relying on the joint density's score function. For the broad class\nof Archimedean copulas, this approach yields a closed-form Stein kernel derived\nfrom the scalar generator function. We provide a comprehensive theoretical\nanalysis, proving that CSD (i) metrizes weak convergence of copula\ndistributions, ensuring it detects any mismatch in dependence; (ii) has an\nempirical estimator that converges at the minimax optimal rate of\n$O_P(n^{-1/2})$; and (iii) is provably sensitive to differences in tail\ndependence coefficients. The framework is extended to general non-Archimedean\ncopulas, including elliptical and vine copulas. Computationally, the exact CSD\nkernel evaluation scales linearly in dimension, while a novel random feature\napproximation reduces the $n$-dependence from quadratic $O(n^2)$ to near-linear\n$\\tilde{O}(n)$, making CSD a practical and theoretically principled tool for\ndependence-aware inference.",
    "published": "2025-10-28T04:33:57Z",
    "updated": "2025-10-28T04:33:57Z",
    "link": "http://arxiv.org/pdf/2510.24056v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Agnideep Aich",
      "Ashit Baran Aich"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24055v1",
    "title": "Language-Conditioned Representations and Mixture-of-Experts Policy for\n  Robust Multi-Task Robotic Manipulation",
    "summary": "Perceptual ambiguity and task conflict limit multitask robotic manipulation\nvia imitation learning. We propose a framework combining a Language-Conditioned\nVisual Representation (LCVR) module and a Language-conditioned\nMixture-ofExperts Density Policy (LMoE-DP). LCVR resolves perceptual\nambiguities by grounding visual features with language instructions, enabling\ndifferentiation between visually similar tasks. To mitigate task conflict,\nLMoE-DP uses a sparse expert architecture to specialize in distinct, multimodal\naction distributions, stabilized by gradient modulation. On real-robot\nbenchmarks, LCVR boosts Action Chunking with Transformers (ACT) and Diffusion\nPolicy (DP) success rates by 33.75% and 25%, respectively. The full framework\nachieves a 79% average success, outperforming the advanced baseline by 21%. Our\nwork shows that combining semantic grounding and expert specialization enables\nrobust, efficient multi-task manipulation",
    "published": "2025-10-28T04:27:03Z",
    "updated": "2025-10-28T04:27:03Z",
    "link": "http://arxiv.org/pdf/2510.24055v1.pdf",
    "category": [
      "cs.RO",
      "cs.LG"
    ],
    "authors": [
      "Xiucheng Zhang",
      "Yang Jiang",
      "Hongwei Qing",
      "Jiashuo Bai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24053v1",
    "title": "Low-N Protein Activity Optimization with FolDE",
    "summary": "Proteins are traditionally optimized through the costly construction and\nmeasurement of many mutants. Active Learning-assisted Directed Evolution (ALDE)\nalleviates that cost by predicting the best improvements and iteratively\ntesting mutants to inform predictions. However, existing ALDE methods face a\ncritical limitation: selecting the highest-predicted mutants in each round\nyields homogeneous training data insufficient for accurate prediction models in\nsubsequent rounds. Here we present FolDE, an ALDE method designed to maximize\nend-of-campaign success. In simulations across 20 protein targets, FolDE\ndiscovers 23% more top 10% mutants than the best baseline ALDE method (p=0.005)\nand is 55% more likely to find top 1% mutants. FolDE achieves this primarily\nthrough naturalness-based warm-starting, which augments limited activity\nmeasurements with protein language model outputs to improve activity\nprediction. We also introduce a constant-liar batch selector, which improves\nbatch diversity; this is important in multi-mutation campaigns but had limited\neffect in our benchmarks. The complete workflow is freely available as\nopen-source software, making efficient protein optimization accessible to any\nlaboratory.",
    "published": "2025-10-28T04:24:39Z",
    "updated": "2025-10-28T04:24:39Z",
    "link": "http://arxiv.org/pdf/2510.24053v1.pdf",
    "category": [
      "cs.LG",
      "q-bio.QM"
    ],
    "authors": [
      "Jacob B. Roberts",
      "Catherine R. Ji",
      "Isaac Donnell",
      "Thomas D. Young",
      "Allison N. Pearson",
      "Graham A. Hudson",
      "Leah S. Keiser",
      "Mia Wesselkamper",
      "Peter H. Winegar",
      "Janik Ludwig",
      "Sarah H. Klass",
      "Isha V. Sheth",
      "Ezechinyere C. Ukabiala",
      "Maria C. T. Astolfi",
      "Benjamin Eysenbach",
      "Jay D. Keasling"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.11829v2",
    "title": "SchrÃ¶dinger bridge for generative AI: Soft-constrained formulation and\n  convergence analysis",
    "summary": "Generative AI can be framed as the problem of learning a model that maps\nsimple reference measures into complex data distributions, and it has recently\nfound a strong connection to the classical theory of the Schr\\\"odinger bridge\nproblems (SBPs) due partly to their common nature of interpolating between\nprescribed marginals via entropy-regularized stochastic dynamics. However, the\nclassical SBP enforces hard terminal constraints, which often leads to\ninstability in practical implementations, especially in high-dimensional or\ndata-scarce regimes. To address this challenge, we follow the idea of the\nso-called soft-constrained Schr\\\"odinger bridge problem (SCSBP), in which the\nterminal constraint is replaced by a general penalty function. This relaxation\nleads to a more flexible stochastic control formulation of McKean-Vlasov type.\n  We establish the existence of optimal solutions for all penalty levels and\nprove that, as the penalty grows, both the controls and value functions\nconverge to those of the classical SBP at a linear rate. Our analysis builds on\nDoob's h-transform representations, the stability results of Schr\\\"odinger\npotentials, Gamma-convergence, and a novel fixed-point argument that couples an\noptimization problem over the space of measures with an auxiliary entropic\noptimal transport problem. These results not only provide the first\nquantitative convergence guarantees for soft-constrained bridges but also shed\nlight on how penalty regularization enables robust generative modeling,\nfine-tuning, and transfer learning.",
    "published": "2025-10-13T18:29:15Z",
    "updated": "2025-10-28T03:59:44Z",
    "link": "http://arxiv.org/pdf/2510.11829v2.pdf",
    "category": [
      "cs.LG",
      "math.DS",
      "math.OC",
      "q-fin.MF"
    ],
    "authors": [
      "Jin Ma",
      "Ying Tan",
      "Renyuan Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24044v1",
    "title": "Mitigating Negative Transfer via Reducing Environmental Disagreement",
    "summary": "Unsupervised Domain Adaptation~(UDA) focuses on transferring knowledge from a\nlabeled source domain to an unlabeled target domain, addressing the challenge\nof \\emph{domain shift}. Significant domain shifts hinder effective knowledge\ntransfer, leading to \\emph{negative transfer} and deteriorating model\nperformance. Therefore, mitigating negative transfer is essential. This study\nrevisits negative transfer through the lens of causally disentangled learning,\nemphasizing cross-domain discriminative disagreement on non-causal\nenvironmental features as a critical factor. Our theoretical analysis reveals\nthat overreliance on non-causal environmental features as the environment\nevolves can cause discriminative disagreements~(termed \\emph{environmental\ndisagreement}), thereby resulting in negative transfer. To address this, we\npropose Reducing Environmental Disagreement~(RED), which disentangles each\nsample into domain-invariant causal features and domain-specific non-causal\nenvironmental features via adversarially training domain-specific environmental\nfeature extractors in the opposite domains. Subsequently, RED estimates and\nreduces environmental disagreement based on domain-specific non-causal\nenvironmental features. Experimental results confirm that RED effectively\nmitigates negative transfer and achieves state-of-the-art performance.",
    "published": "2025-10-28T03:56:20Z",
    "updated": "2025-10-28T03:56:20Z",
    "link": "http://arxiv.org/pdf/2510.24044v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Hui Sun",
      "Zheng Xie",
      "Hao-Yuan He",
      "Ming Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24043v1",
    "title": "Localized Kernel Projection Outlyingness: A Two-Stage Approach for\n  Multi-Modal Outlier Detection",
    "summary": "This paper presents Two-Stage LKPLO, a novel multi-stage outlier detection\nframework that overcomes the coexisting limitations of conventional\nprojection-based methods: their reliance on a fixed statistical metric and\ntheir assumption of a single data structure. Our framework uniquely synthesizes\nthree key concepts: (1) a generalized loss-based outlyingness measure (PLO)\nthat replaces the fixed metric with flexible, adaptive loss functions like our\nproposed SVM-like loss; (2) a global kernel PCA stage to linearize non-linear\ndata structures; and (3) a subsequent local clustering stage to handle\nmulti-modal distributions. Comprehensive 5-fold cross-validation experiments on\n10 benchmark datasets, with automated hyperparameter optimization, demonstrate\nthat Two-Stage LKPLO achieves state-of-the-art performance. It significantly\noutperforms strong baselines on datasets with challenging structures where\nexisting methods fail, most notably on multi-cluster data (Optdigits) and\ncomplex, high-dimensional data (Arrhythmia). Furthermore, an ablation study\nempirically confirms that the synergistic combination of both the kernelization\nand localization stages is indispensable for its superior performance. This\nwork contributes a powerful new tool for a significant class of outlier\ndetection problems and underscores the importance of hybrid, multi-stage\narchitectures.",
    "published": "2025-10-28T03:53:46Z",
    "updated": "2025-10-28T03:53:46Z",
    "link": "http://arxiv.org/pdf/2510.24043v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Akira Tamamori"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.17257v4",
    "title": "JanusDNA: A Powerful Bi-directional Hybrid DNA Foundation Model",
    "summary": "Large language models (LLMs) have revolutionized natural language processing\nand are increasingly applied to other sequential data types, including genetic\nsequences. However, adapting LLMs to genomics presents significant challenges.\nCapturing complex genomic interactions requires modeling long-range\ndependencies within DNA sequences, where interactions often span over 10,000\nbase pairs, even within a single gene, posing substantial computational burdens\nunder conventional model architectures and training paradigms. Moreover,\nstandard LLM training approaches are suboptimal for DNA: autoregressive\ntraining, while efficient, supports only unidirectional understanding. However,\nDNA is inherently bidirectional, e.g., bidirectional promoters regulate\ntranscription in both directions and account for nearly 11% of human gene\nexpression. Masked language models (MLMs) allow bidirectional understanding but\nare inefficient, as only masked tokens contribute to the loss per step. To\naddress these limitations, we introduce JanusDNA, the first bidirectional DNA\nfoundation model built upon a novel pretraining paradigm that combines the\noptimization efficiency of autoregressive modeling with the bidirectional\ncomprehension of masked modeling. JanusDNA adopts a hybrid Mamba, Attention and\nMixture of Experts (MoE) architecture, combining long-range modeling of\nAttention with efficient sequential learning of Mamba. MoE layers further scale\nmodel capacity via sparse activation while keeping computational cost low.\nNotably, JanusDNA processes up to 1 million base pairs at single nucleotide\nresolution on a single 80GB GPU. Extensive experiments and ablations show\nJanusDNA achieves new SOTA results on three genomic representation benchmarks,\noutperforming models with 250x more activated parameters. Code:\nhttps://github.com/Qihao-Duan/JanusDNA",
    "published": "2025-05-22T20:10:55Z",
    "updated": "2025-10-28T03:53:33Z",
    "link": "http://arxiv.org/pdf/2505.17257v4.pdf",
    "category": [
      "cs.LG",
      "q-bio.GN"
    ],
    "authors": [
      "Qihao Duan",
      "Bingding Huang",
      "Zhenqiao Song",
      "Irina Lehmann",
      "Lei Gu",
      "Roland Eils",
      "Benjamin Wild"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24026v1",
    "title": "Efficient Global-Local Fusion Sampling for Physics-Informed Neural\n  Networks",
    "summary": "The accuracy of Physics-Informed Neural Networks (PINNs) critically depends\non the placement of collocation points, as the PDE loss is approximated through\nsampling over the solution domain. Global sampling ensures stability by\ncovering the entire domain but requires many samples and is computationally\nexpensive, whereas local sampling improves efficiency by focusing on\nhigh-residual regions but may neglect well-learned areas, reducing robustness.\nWe propose a Global-Local Fusion (GLF) Sampling Strategy that combines the\nstrengths of both approaches. Specifically, new collocation points are\ngenerated by perturbing training points with Gaussian noise scaled inversely to\nthe residual, thereby concentrating samples in difficult regions while\npreserving exploration. To further reduce computational overhead, a lightweight\nlinear surrogate is introduced to approximate the global residual-based\ndistribution, achieving similar effectiveness at a fraction of the cost.\nTogether, these components, residual-adaptive sampling and residual-based\napproximation, preserve the stability of global methods while retaining the\nefficiency of local refinement. Extensive experiments on benchmark PDEs\ndemonstrate that GLF consistently improves both accuracy and efficiency\ncompared with global and local sampling strategies. This study provides a\npractical and scalable framework for enhancing the reliability and efficiency\nof PINNs in solving complex and high-dimensional PDEs.",
    "published": "2025-10-28T03:10:54Z",
    "updated": "2025-10-28T03:10:54Z",
    "link": "http://arxiv.org/pdf/2510.24026v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Jiaqi Luo",
      "Shixin Xu",
      "Zhouwang Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.08312v2",
    "title": "CFM-GP: Unified Conditional Flow Matching to Learn Gene Perturbation\n  Across Cell Types",
    "summary": "Understanding gene perturbation effects across diverse cellular contexts is a\ncentral challenge in functional genomics, with important implications for\ntherapeutic discovery and precision medicine. Single-cell technologies enable\nhigh-resolution measurement of transcriptional responses, but collecting such\ndata is costly and time-consuming, especially when repeated for each cell type.\nExisting computational methods often require separate models per cell type,\nlimiting scalability and generalization. We present CFM-GP, a method for cell\ntype-agnostic gene perturbation prediction. CFM-GP learns a continuous,\ntime-dependent transformation between unperturbed and perturbed gene expression\ndistributions, conditioned on cell type, allowing a single model to predict\nacross all cell types. Unlike prior approaches that use discrete modeling,\nCFM-GP employs a flow matching objective to capture perturbation dynamics in a\nscalable manner. We evaluate on five datasets: SARS-CoV-2 infection, IFN-beta\nstimulated PBMCs, glioblastoma treated with Panobinostat, lupus under IFN-beta\nstimulation, and Statefate progenitor fate mapping. CFM-GP consistently\noutperforms state-of-the-art baselines in R-squared and Spearman correlation,\nand pathway enrichment analysis confirms recovery of key biological pathways.\nThese results demonstrate the robustness and biological fidelity of CFM-GP as a\nscalable solution for cross-cell type gene perturbation prediction.",
    "published": "2025-08-09T00:00:17Z",
    "updated": "2025-10-28T02:55:43Z",
    "link": "http://arxiv.org/pdf/2508.08312v2.pdf",
    "category": [
      "q-bio.GN",
      "cs.LG"
    ],
    "authors": [
      "Abrar Rahman Abir",
      "Sajib Acharjee Dip",
      "Liqing Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.22940v2",
    "title": "RL-AUX: Reinforcement Learning for Auxiliary Task Generation",
    "summary": "Auxiliary Learning (AL) is a special case of Multi-task Learning (MTL) in\nwhich a network trains on auxiliary tasks to improve performance on its main\ntask. This technique is used to improve generalization and, ultimately,\nperformance on the network's main task. AL has been demonstrated to improve\nperformance across multiple domains, including navigation, image\nclassification, and natural language processing. One weakness of AL is the need\nfor labeled auxiliary tasks, which can require human effort and domain\nexpertise to generate. Meta Learning techniques have been used to solve this\nissue by learning an additional auxiliary task generation network that can\ncreate helpful tasks for the primary network. The most prominent techniques\nrely on Bi-Level Optimization, which incurs computational cost and increased\ncode complexity. To avoid the need for Bi-Level Optimization, we present an\nRL-based approach to dynamically create auxiliary tasks. In this framework, an\nRL agent is tasked with selecting auxiliary labels for every data point in a\ntraining set. The agent is rewarded when their selection improves the\nperformance on the primary task. We also experiment with learning optimal\nstrategies for weighing the auxiliary loss per data point. On the 20-Superclass\nCIFAR100 problem, our RL approach outperforms human-labeled auxiliary tasks and\nperforms as well as a prominent Bi-Level Optimization technique. Our weight\nlearning approaches significantly outperform all of these benchmarks. For\nexample, a Weight-Aware RL-based approach helps the VGG16 architecture achieve\n80.9% test accuracy while the human-labeled auxiliary task setup achieved\n75.53%. The goal of this work is to (1) prove that RL is a viable approach to\ndynamically generate auxiliary tasks and (2) demonstrate that per-sample\nauxiliary task weights can be learned alongside the auxiliary task labels and\ncan achieve strong results.",
    "published": "2025-10-27T02:51:51Z",
    "updated": "2025-10-28T02:44:02Z",
    "link": "http://arxiv.org/pdf/2510.22940v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Judah Goldfeder",
      "Matthew So",
      "Hod Lipson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.18092v5",
    "title": "Learning Provably Improves the Convergence of Gradient Descent",
    "summary": "Learn to Optimize (L2O) trains deep neural network-based solvers for\noptimization, achieving success in accelerating convex problems and improving\nnon-convex solutions. However, L2O lacks rigorous theoretical backing for its\nown training convergence, as existing analyses often use unrealistic\nassumptions -- a gap this work highlights empirically. We bridge this gap by\nproving the training convergence of L2O models that learn Gradient Descent (GD)\nhyperparameters for quadratic programming, leveraging the Neural Tangent Kernel\n(NTK) theory. We propose a deterministic initialization strategy to support our\ntheoretical results and promote stable training over extended optimization\nhorizons by mitigating gradient explosion. Our L2O framework demonstrates over\n50% better optimality than GD and superior robustness over state-of-the-art L2O\nmethods on synthetic datasets. The code of our method can be found from\nhttps://github.com/NetX-lab/MathL2OProof-Official.",
    "published": "2025-01-30T02:03:30Z",
    "updated": "2025-10-28T02:24:55Z",
    "link": "http://arxiv.org/pdf/2501.18092v5.pdf",
    "category": [
      "cs.LG",
      "math.OC"
    ],
    "authors": [
      "Qingyu Song",
      "Wei Lin",
      "Hong Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.08078v3",
    "title": "Detecting and Mitigating Insertion Hallucination in Video-to-Audio\n  Generation",
    "summary": "Video-to-Audio generation has made remarkable strides in automatically\nsynthesizing sound for video. However, existing evaluation metrics, which focus\non semantic and temporal alignment, overlook a critical failure mode: models\noften generate acoustic events, particularly speech and music, that have no\ncorresponding visual source. We term this phenomenon Insertion Hallucination\nand identify it as a systemic risk driven by dataset biases, such as the\nprevalence of off-screen sounds, that remains completely undetected by current\nmetrics. To address this challenge, we first develop a systematic evaluation\nframework that employs a majority-voting ensemble of multiple audio event\ndetectors. We also introduce two novel metrics to quantify the prevalence and\nseverity of this issue: IH@vid (the fraction of videos with hallucinations) and\nIH@dur (the fraction of hallucinated duration). Building on this, we propose\nPosterior Feature Correction, a novel training-free inference-time method that\nmitigates IH. PFC operates in a two-pass process: it first generates an initial\naudio output to detect hallucinated segments, and then regenerates the audio\nafter masking the corresponding video features at those timestamps. Experiments\non several mainstream V2A benchmarks first reveal that state-of-the-art models\nsuffer from severe IH. In contrast, our PFC method reduces both the prevalence\nand duration of hallucinations by over 50\\% on average, without degrading, and\nin some cases even improving, conventional metrics for audio quality and\ntemporal synchronization. Our work is the first to formally define,\nsystematically measure, and effectively mitigate Insertion Hallucination,\npaving the way for more reliable and faithful V2A models.",
    "published": "2025-10-09T11:08:07Z",
    "updated": "2025-10-28T02:16:25Z",
    "link": "http://arxiv.org/pdf/2510.08078v3.pdf",
    "category": [
      "cs.SD",
      "cs.LG"
    ],
    "authors": [
      "Liyang Chen",
      "Hongkai Chen",
      "Yujun Cai",
      "Sifan Li",
      "Qingwen Ye",
      "Yiwei Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.17354v2",
    "title": "CT-OT Flow: Estimating Continuous-Time Dynamics from Discrete Temporal\n  Snapshots",
    "summary": "In many real-world settings--e.g., single-cell RNA sequencing, mobility\nsensing, and environmental monitoring--data are observed only as temporally\naggregated snapshots collected over finite time windows, often with noisy or\nuncertain timestamps, and without access to continuous trajectories. We study\nthe problem of estimating continuous-time dynamics from such snapshots. We\npresent Continuous-Time Optimal Transport Flow (CT-OT Flow), a two-stage\nframework that (i) infers high-resolution time labels by aligning neighboring\nintervals via partial optimal transport (POT) and (ii) reconstructs a\ncontinuous-time data distribution through temporal kernel smoothing, from which\nwe sample pairs of nearby times to train standard ODE/SDE models. Our\nformulation explicitly accounts for snapshot aggregation and time-label\nuncertainty and uses practical accelerations (screening and mini-batch POT),\nmaking it applicable to large datasets. Across synthetic benchmarks and two\nreal datasets (scRNA-seq and typhoon tracks), CT-OT Flow reduces distributional\nand trajectory errors compared with OT-CFM, [SF]\\(^{2}\\)M, TrajectoryNet, MFM,\nand ENOT.",
    "published": "2025-05-23T00:12:49Z",
    "updated": "2025-10-28T02:08:49Z",
    "link": "http://arxiv.org/pdf/2505.17354v2.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Keisuke Kawano",
      "Takuro Kutsuna",
      "Naoki Hayashi",
      "Yasushi Esaki",
      "Hidenori Tanaka"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23999v1",
    "title": "Auto-Adaptive PINNs with Applications to Phase Transitions",
    "summary": "We propose an adaptive sampling method for the training of Physics Informed\nNeural Networks (PINNs) which allows for sampling based on an arbitrary\nproblem-specific heuristic which may depend on the network and its gradients.\nIn particular we focus our analysis on the Allen-Cahn equations, attempting to\naccurately resolve the characteristic interfacial regions using a PINN without\nany post-hoc resampling. In experiments, we show the effectiveness of these\nmethods over residual-adaptive frameworks.",
    "published": "2025-10-28T02:03:39Z",
    "updated": "2025-10-28T02:03:39Z",
    "link": "http://arxiv.org/pdf/2510.23999v1.pdf",
    "category": [
      "math.NA",
      "cs.LG",
      "cs.NA"
    ],
    "authors": [
      "Kevin Buck",
      "Woojeong Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.13723v2",
    "title": "Turbocharging Gaussian Process Inference with Approximate\n  Sketch-and-Project",
    "summary": "Gaussian processes (GPs) play an essential role in biostatistics, scientific\nmachine learning, and Bayesian optimization for their ability to provide\nprobabilistic predictions and model uncertainty. However, GP inference\nstruggles to scale to large datasets (which are common in modern applications),\nsince it requires the solution of a linear system whose size scales\nquadratically with the number of samples in the dataset. We propose an\napproximate, distributed, accelerated sketch-and-project algorithm\n($\\texttt{ADASAP}$) for solving these linear systems, which improves\nscalability. We use the theory of determinantal point processes to show that\nthe posterior mean induced by sketch-and-project rapidly converges to the true\nposterior mean. In particular, this yields the first efficient, condition\nnumber-free algorithm for estimating the posterior mean along the top spectral\nbasis functions, showing that our approach is principled for GP inference.\n$\\texttt{ADASAP}$ outperforms state-of-the-art solvers based on conjugate\ngradient and coordinate descent across several benchmark datasets and a\nlarge-scale Bayesian optimization task. Moreover, $\\texttt{ADASAP}$ scales to a\ndataset with $> 3 \\cdot 10^8$ samples, a feat which has not been accomplished\nin the literature.",
    "published": "2025-05-19T20:46:26Z",
    "updated": "2025-10-28T01:57:58Z",
    "link": "http://arxiv.org/pdf/2505.13723v2.pdf",
    "category": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "authors": [
      "Pratik Rathore",
      "Zachary Frangella",
      "Sachin Garg",
      "Shaghayegh Fazliani",
      "MichaÅ DereziÅski",
      "Madeleine Udell"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23994v1",
    "title": "Predicting Barge Tow Size on Inland Waterways Using Vessel Trajectory\n  Derived Features: Proof of Concept",
    "summary": "Accurate, real-time estimation of barge quantity on inland waterways remains\na critical challenge due to the non-self-propelled nature of barges and the\nlimitations of existing monitoring systems. This study introduces a novel\nmethod to use Automatic Identification System (AIS) vessel tracking data to\npredict the number of barges in tow using Machine Learning (ML). To train and\ntest the model, barge instances were manually annotated from satellite scenes\nacross the Lower Mississippi River. Labeled images were matched to AIS vessel\ntracks using a spatiotemporal matching procedure. A comprehensive set of 30\nAIS-derived features capturing vessel geometry, dynamic movement, and\ntrajectory patterns were created and evaluated using Recursive Feature\nElimination (RFE) to identify the most predictive variables. Six regression\nmodels, including ensemble, kernel-based, and generalized linear approaches,\nwere trained and evaluated. The Poisson Regressor model yielded the best\nperformance, achieving a Mean Absolute Error (MAE) of 1.92 barges using 12 of\nthe 30 features. The feature importance analysis revealed that metrics\ncapturing vessel maneuverability such as course entropy, speed variability and\ntrip length were most predictive of barge count. The proposed approach provides\na scalable, readily implementable method for enhancing Maritime Domain\nAwareness (MDA), with strong potential applications in lock scheduling, port\nmanagement, and freight planning. Future work will expand the proof of concept\npresented here to explore model transferability to other inland rivers with\ndiffering operational and environmental conditions.",
    "published": "2025-10-28T01:51:23Z",
    "updated": "2025-10-28T01:51:23Z",
    "link": "http://arxiv.org/pdf/2510.23994v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Geoffery Agorku",
      "Sarah Hernandez",
      "Hayley Hames",
      "Cade Wagner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23992v1",
    "title": "Optimal Arm Elimination Algorithms for Combinatorial Bandits",
    "summary": "Combinatorial bandits extend the classical bandit framework to settings where\nthe learner selects multiple arms in each round, motivated by applications such\nas online recommendation and assortment optimization. While extensions of upper\nconfidence bound (UCB) algorithms arise naturally in this context, adapting arm\nelimination methods has proved more challenging. We introduce a novel\nelimination scheme that partitions arms into three categories (confirmed,\nactive, and eliminated), and incorporates explicit exploration to update these\nsets. We demonstrate the efficacy of our algorithm in two settings: the\ncombinatorial multi-armed bandit with general graph feedback, and the\ncombinatorial linear contextual bandit. In both cases, our approach achieves\nnear-optimal regret, whereas UCB-based methods can provably fail due to\ninsufficient explicit exploration. Matching lower bounds are also provided.",
    "published": "2025-10-28T01:50:24Z",
    "updated": "2025-10-28T01:50:24Z",
    "link": "http://arxiv.org/pdf/2510.23992v1.pdf",
    "category": [
      "cs.LG",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ],
    "authors": [
      "Yuxiao Wen",
      "Yanjun Han",
      "Zhengyuan Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.12630v2",
    "title": "High-Energy Concentration for Federated Learning in Frequency Domain",
    "summary": "Federated Learning (FL) presents significant potential for collaborative\noptimization without data sharing. Since synthetic data is sent to the server,\nleveraging the popular concept of dataset distillation, this FL framework\nprotects real data privacy while alleviating data heterogeneity. However, such\nmethods are still challenged by the redundant information and noise in entire\nspatial-domain designs, which inevitably increases the communication burden. In\nthis paper, we propose a novel Frequency-Domain aware FL method with\nhigh-energy concentration (FedFD) to address this problem. Our FedFD is\ninspired by the discovery that the discrete cosine transform predominantly\ndistributes energy to specific regions, referred to as high-energy\nconcentration. The principle behind FedFD is that low-energy like\nhigh-frequency components usually contain redundant information and noise, thus\nfiltering them helps reduce communication costs and optimize performance. Our\nFedFD is mathematically formulated to preserve the low-frequency components\nusing a binary mask, facilitating an optimal solution through frequency-domain\ndistribution alignment. In particular, real data-driven synthetic\nclassification is imposed into the loss to enhance the quality of the\nlow-frequency components. On five image and speech datasets, FedFD achieves\nsuperior performance than state-of-the-art methods while reducing communication\ncosts. For example, on the CIFAR-10 dataset with Dirichlet coefficient $\\alpha\n= 0.01$, FedFD achieves a minimum reduction of 37.78\\% in the communication\ncost, while attaining a 10.88\\% performance gain.",
    "published": "2025-09-16T03:49:26Z",
    "updated": "2025-10-28T01:41:54Z",
    "link": "http://arxiv.org/pdf/2509.12630v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Haozhi Shi",
      "Weiying Xie",
      "Hangyu Ye",
      "Daixun Li",
      "Jitao Ma",
      "Yunsong Li",
      "Leyuan Fang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23985v1",
    "title": "Score-based constrained generative modeling via Langevin diffusions with\n  boundary conditions",
    "summary": "Score-based generative models based on stochastic differential equations\n(SDEs) achieve impressive performance in sampling from unknown distributions,\nbut often fail to satisfy underlying constraints. We propose a constrained\ngenerative model using kinetic (underdamped) Langevin dynamics with specular\nreflection of velocity on the boundary defining constraints. This results in\npiecewise continuously differentiable noising and denoising process where the\nlatter is characterized by a time-reversed dynamics restricted to a domain with\nboundary due to specular boundary condition. In addition, we also contribute to\nexisting reflected SDEs based constrained generative models, where the\nstochastic dynamics is restricted through an abstract local time term. By\npresenting efficient numerical samplers which converge with optimal rate in\nterms of discretizations step, we provide a comprehensive comparison of models\nbased on confined (specularly reflected kinetic) Langevin diffusion with models\nbased on reflected diffusion with local time.",
    "published": "2025-10-28T01:36:54Z",
    "updated": "2025-10-28T01:36:54Z",
    "link": "http://arxiv.org/pdf/2510.23985v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "cs.NA",
      "math.NA",
      "68T07, 60H35, 65C30, 60H10"
    ],
    "authors": [
      "Adam NordenhÃ¶g",
      "Akash Sharma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.14291v5",
    "title": "Equivariance Everywhere All At Once: A Recipe for Graph Foundation\n  Models",
    "summary": "Graph machine learning architectures are typically tailored to specific tasks\non specific datasets, which hinders their broader applicability. This has led\nto a new quest in graph machine learning: how to build graph foundation models\ncapable of generalizing across arbitrary graphs and features? In this work, we\npresent a recipe for designing graph foundation models for node-level tasks\nfrom first principles. The key ingredient underpinning our study is a\nsystematic investigation of the symmetries that a graph foundation model must\nrespect. In a nutshell, we argue that label permutation-equivariance alongside\nfeature permutation-invariance are necessary in addition to the common node\npermutation-equivariance on each local neighborhood of the graph. To this end,\nwe first characterize the space of linear transformations that are equivariant\nto permutations of nodes and labels, and invariant to permutations of features.\nWe then prove that the resulting network is a universal approximator on\nmultisets that respect the aforementioned symmetries. Our recipe uses such\nlayers on the multiset of features induced by the local neighborhood of the\ngraph to obtain a class of graph foundation models for node property\nprediction. We validate our approach through extensive experiments on 29\nreal-world node classification datasets, demonstrating both strong zero-shot\nempirical performance and consistent improvement as the number of training\ngraphs increases.",
    "published": "2025-06-17T08:05:08Z",
    "updated": "2025-10-28T00:48:13Z",
    "link": "http://arxiv.org/pdf/2506.14291v5.pdf",
    "category": [
      "cs.LG",
      "cs.SI",
      "stat.ML"
    ],
    "authors": [
      "Ben Finkelshtein",
      "Ä°smail Ä°lkan Ceylan",
      "Michael Bronstein",
      "Ron Levie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23966v1",
    "title": "A Pragmatic Way to Measure Chain-of-Thought Monitorability",
    "summary": "While Chain-of-Thought (CoT) monitoring offers a unique opportunity for AI\nsafety, this opportunity could be lost through shifts in training practices or\nmodel architecture. To help preserve monitorability, we propose a pragmatic way\nto measure two components of it: legibility (whether the reasoning can be\nfollowed by a human) and coverage (whether the CoT contains all the reasoning\nneeded for a human to also produce the final output). We implement these\nmetrics with an autorater prompt that enables any capable LLM to compute the\nlegibility and coverage of existing CoTs. After sanity-checking our prompted\nautorater with synthetic CoT degradations, we apply it to several frontier\nmodels on challenging benchmarks, finding that they exhibit high\nmonitorability. We present these metrics, including our complete autorater\nprompt, as a tool for developers to track how design decisions impact\nmonitorability. While the exact prompt we share is still a preliminary version\nunder ongoing development, we are sharing it now in the hopes that others in\nthe community will find it useful. Our method helps measure the default\nmonitorability of CoT - it should be seen as a complement, not a replacement,\nfor the adversarial stress-testing needed to test robustness against\ndeliberately evasive models.",
    "published": "2025-10-28T00:44:25Z",
    "updated": "2025-10-28T00:44:25Z",
    "link": "http://arxiv.org/pdf/2510.23966v1.pdf",
    "category": [
      "cs.LG",
      "cs.SE"
    ],
    "authors": [
      "Scott Emmons",
      "Roland S. Zimmermann",
      "David K. Elson",
      "Rohin Shah"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.23550v3",
    "title": "Seeding neural network quantum states with tensor network states",
    "summary": "We find an efficient approach to approximately convert matrix product states\n(MPSs) into restricted Boltzmann machine wave functions consisting of a\nmultinomial hidden unit through a canonical polyadic (CP) decomposition of the\nMPSs. This method allows us to generate well-behaved initial neural network\nquantum states for quantum many-body ground-state calculations in polynomial\ntime of the number of variational parameters and systematically shorten the\ndistance between the initial states and the ground states while increasing the\nrank of the CP decomposition. We demonstrate the efficiency of our method by\ntaking the transverse-field Ising model as an example and discuss possible\napplications of our method to more general quantum many-body systems in which\nthe ground-state wave functions possess complex nodal structures.",
    "published": "2025-06-30T06:49:31Z",
    "updated": "2025-10-28T00:43:01Z",
    "link": "http://arxiv.org/pdf/2506.23550v3.pdf",
    "category": [
      "cond-mat.str-el",
      "cs.LG",
      "cs.NA",
      "math.NA",
      "quant-ph"
    ],
    "authors": [
      "Ryui Kaneko",
      "Shimpei Goto"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.22138v2",
    "title": "Tractable Shapley Values and Interactions via Tensor Networks",
    "summary": "We show how to replace the O(2^n) coalition enumeration over n features\nbehind Shapley values and Shapley-style interaction indices with a\nfew-evaluation scheme on a tensor-network (TN) surrogate: TN-SHAP. The key idea\nis to represent a predictor's local behavior as a factorized multilinear map,\nso that coalitional quantities become linear probes of a coefficient tensor.\nTN-SHAP replaces exhaustive coalition sweeps with just a small number of\ntargeted evaluations to extract order-k Shapley interactions. In particular,\nboth order-1 (single-feature) and order-2 (pairwise) computations have cost\nO(n*poly(chi) + n^2), where chi is the TN's maximal cut rank. We provide\ntheoretical guarantees on the approximation error and tractability of TN-SHAP.\nOn UCI datasets, our method matches enumeration on the fitted surrogate while\nreducing evaluation by orders of magnitude and achieves 25-1000x wall-clock\nspeedups over KernelSHAP-IQ at comparable accuracy, while amortizing training\nacross local cohorts.",
    "published": "2025-10-25T03:21:20Z",
    "updated": "2025-10-28T00:35:27Z",
    "link": "http://arxiv.org/pdf/2510.22138v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Farzaneh Heidari",
      "Chao Li",
      "Guillaume Rabusseau"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.20958v2",
    "title": "NeuroPilot: A Realtime Brain-Computer Interface system to enhance\n  concentration of students in online learning",
    "summary": "The prevalence of online learning poses a vital challenge in real-time\nmonitoring of students' concentration. Traditional methods such as\nquestionnaire assessments require manual intervention, and webcam-based\nmonitoring fails to provide accurate insights about learners' mental focus as\nit is deceived by mere screen fixation without cognitive engagement. Existing\nBCI-based approaches lack real-time validation and evaluation procedures. To\naddress these limitations, a Brain-Computer Interface (BCI) system is developed\nusing a non-invasive Electroencephalogram (EEG) headband, FocusCalm, to record\nbrainwave activity under attentive and non-attentive states. 20 minutes of data\nwere collected from each of 20 participants watching a pre-recorded educational\nvideo. The data validation employed a novel intra-video questionnaire\nassessment. Subsequently, collected signals were segmented (sliding window),\nfiltered (Butterworth bandpass), and cleaned (removal of high- amplitude and\nEOG artifacts such as eye blinks). Time, frequency, wavelet, and statistical\nfeatures were extracted, followed by recursive feature elimination (RFE) with\nsupport vector machines (SVMs) to classify attention and non-attention states.\nThe leave-one-subject-out (LOSO) cross-validation accuracy was found to be\n88.77%. The system provides feedback alerts upon detection of a non-attention\nstate and maintains focus profile logs. A pilot study was conducted to evaluate\nthe effectiveness of real-time feedback. Five participants underwent a\n10-minute session comprising a 5-minute baseline phase devoid of feedback,\nsucceeded by a 5-minute feedback phase, during which alerts were activated if\nparticipants exhibited inattention for approximately 8 consecutive seconds. A\npaired t-test (t = 5.73, p = 0.007) indicated a statistically significant\nimprovement in concentration during the feedback phase.",
    "published": "2025-10-23T19:36:59Z",
    "updated": "2025-10-28T00:13:13Z",
    "link": "http://arxiv.org/pdf/2510.20958v2.pdf",
    "category": [
      "cs.HC",
      "cs.LG",
      "eess.SP",
      "q-bio.NC"
    ],
    "authors": [
      "Asif Islam",
      "Farhan Ishtiaque",
      "Md. Muhyminul Haque",
      "Farhana Sarker",
      "Ravi Vaidyanathan",
      "Khondaker A. Mamun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23936v1",
    "title": "A data free neural operator enabling fast inference of 2D and 3D Navier\n  Stokes equations",
    "summary": "Ensemble simulations of high-dimensional flow models (e.g., Navier Stokes\ntype PDEs) are computationally prohibitive for real time applications. Neural\noperators enable fast inference but are limited by costly data requirements and\npoor generalization to 3D flows. We present a data-free operator network for\nthe Navier Stokes equations that eliminates the need for paired solution data\nand enables robust, real time inference for large ensemble forecasting. The\nphysics-grounded architecture takes initial and boundary conditions as well as\nforcing functions, yielding solutions robust to high variability and\nperturbations. Across 2D benchmarks and 3D test cases, the method surpasses\nprior neural operators in accuracy and, for ensembles, achieves greater\nefficiency than conventional numerical solvers. Notably, it delivers accurate\nsolutions of the three dimensional Navier Stokes equations, a regime not\npreviously demonstrated for data free neural operators. By uniting a\nnumerically grounded architecture with the scalability of machine learning,\nthis approach establishes a practical pathway toward data free, high fidelity\nPDE surrogates for end to end scientific simulation and prediction.",
    "published": "2025-10-27T23:41:42Z",
    "updated": "2025-10-27T23:41:42Z",
    "link": "http://arxiv.org/pdf/2510.23936v1.pdf",
    "category": [
      "cs.LG",
      "physics.flu-dyn"
    ],
    "authors": [
      "Junho Choi",
      "Teng-Yuan Chang",
      "Namjung Kim",
      "Youngjoon Hong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23935v1",
    "title": "Understanding Fairness and Prediction Error through Subspace\n  Decomposition and Influence Analysis",
    "summary": "Machine learning models have achieved widespread success but often inherit\nand amplify historical biases, resulting in unfair outcomes. Traditional\nfairness methods typically impose constraints at the prediction level, without\naddressing underlying biases in data representations. In this work, we propose\na principled framework that adjusts data representations to balance predictive\nutility and fairness. Using sufficient dimension reduction, we decompose the\nfeature space into target-relevant, sensitive, and shared components, and\ncontrol the fairness-utility trade-off by selectively removing sensitive\ninformation. We provide a theoretical analysis of how prediction error and\nfairness gaps evolve as shared subspaces are added, and employ influence\nfunctions to quantify their effects on the asymptotic behavior of parameter\nestimates. Experiments on both synthetic and real-world datasets validate our\ntheoretical insights and show that the proposed method effectively improves\nfairness while preserving predictive performance.",
    "published": "2025-10-27T23:38:00Z",
    "updated": "2025-10-27T23:38:00Z",
    "link": "http://arxiv.org/pdf/2510.23935v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Enze Shi",
      "Pankaj Bhagwat",
      "Zhixian Yang",
      "Linglong Kong",
      "Bei Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23931v1",
    "title": "Differential Privacy: Gradient Leakage Attacks in Federated Learning\n  Environments",
    "summary": "Federated Learning (FL) allows for the training of Machine Learning models in\na collaborative manner without the need to share sensitive data. However, it\nremains vulnerable to Gradient Leakage Attacks (GLAs), which can reveal private\ninformation from the shared model updates. In this work, we investigate the\neffectiveness of Differential Privacy (DP) mechanisms - specifically, DP-SGD\nand a variant based on explicit regularization (PDP-SGD) - as defenses against\nGLAs. To this end, we evaluate the performance of several computer vision\nmodels trained under varying privacy levels on a simple classification task,\nand then analyze the quality of private data reconstructions obtained from the\nintercepted gradients in a simulated FL environment. Our results demonstrate\nthat DP-SGD significantly mitigates the risk of gradient leakage attacks,\nalbeit with a moderate trade-off in model utility. In contrast, PDP-SGD\nmaintains strong classification performance but proves ineffective as a\npractical defense against reconstruction attacks. These findings highlight the\nimportance of empirically evaluating privacy mechanisms beyond their\ntheoretical guarantees, particularly in distributed learning scenarios where\ninformation leakage may represent an unassumable critical threat to data\nsecurity and privacy.",
    "published": "2025-10-27T23:33:21Z",
    "updated": "2025-10-27T23:33:21Z",
    "link": "http://arxiv.org/pdf/2510.23931v1.pdf",
    "category": [
      "cs.LG",
      "cs.CR",
      "cs.DC",
      "68T07 (Primary) 68M14, 68P27, 68Q32, 94A16, 62H35 (Secondary)",
      "I.2.11; I.2.6; C.2.4; D.4.6; K.4.1"
    ],
    "authors": [
      "Miguel Fernandez-de-Retana",
      "Unai Zulaika",
      "RubÃ©n SÃ¡nchez-Corcuera",
      "Aitor Almeida"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.02089v2",
    "title": "Sample Complexity Bounds for Linear Constrained MDPs with a Generative\n  Model",
    "summary": "We consider infinite-horizon $\\gamma$-discounted (linear) constrained Markov\ndecision processes (CMDPs) where the objective is to find a policy that\nmaximizes the expected cumulative reward subject to expected cumulative\nconstraints. Given access to a generative model, we propose to solve CMDPs with\na primal-dual framework that can leverage any black-box unconstrained MDP\nsolver. For linear CMDPs with feature dimension $d$, we instantiate the\nframework by using mirror descent value iteration\n(\\texttt{MDVI})~\\citep{kitamura2023regularization} an example MDP solver. We\nprovide sample complexity bounds for the resulting CMDP algorithm in two cases:\n(i) relaxed feasibility, where small constraint violations are allowed, and\n(ii) strict feasibility, where the output policy is required to exactly satisfy\nthe constraint. For (i), we prove that the algorithm can return an\n$\\epsilon$-optimal policy with high probability by using\n$\\tilde{O}\\left(\\frac{d^2}{(1-\\gamma)^4\\epsilon^2}\\right)$ samples. For (ii),\nwe show that the algorithm requires\n$\\tilde{O}\\left(\\frac{d^2}{(1-\\gamma)^6\\epsilon^2\\zeta^2}\\right)$ samples,\nwhere $\\zeta$ is the problem-dependent Slater constant that characterizes the\nsize of the feasible region. Furthermore, we prove a lower-bound of\n$\\Omega\\left(\\frac{d^2}{(1-\\gamma)^5\\epsilon^2\\zeta^2}\\right)$ for the strict\nfeasibility setting. We note that our upper bounds under both settings exhibit\na near-optimal dependence on $d$, $\\epsilon$, and $\\zeta$. Finally, we\ninstantiate our framework for tabular CMDPs and show that it can be used to\nrecover near-optimal sample complexities in this setting.",
    "published": "2025-07-02T19:07:37Z",
    "updated": "2025-10-27T23:20:30Z",
    "link": "http://arxiv.org/pdf/2507.02089v2.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Xingtu Liu",
      "Lin F. Yang",
      "Sharan Vaswani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23926v1",
    "title": "Improving the Straight-Through Estimator with Zeroth-Order Information",
    "summary": "We study the problem of training neural networks with quantized parameters.\nLearning low-precision quantized parameters by enabling computation of\ngradients via the Straight-Through Estimator (STE) can be challenging. While\nthe STE enables back-propagation, which is a first-order method, recent works\nhave explored the use of zeroth-order (ZO) gradient descent for fine-tuning. We\nnote that the STE provides high-quality biased gradients, and ZO gradients are\nunbiased but can be expensive. We thus propose First-Order-Guided Zeroth-Order\nGradient Descent (FOGZO) that reduces STE bias while reducing computations\nrelative to ZO methods. Empirically, we show FOGZO improves the tradeoff\nbetween quality and training time in Quantization-Aware Pre-Training.\nSpecifically, versus STE at the same number of iterations, we show a 1-8\\%\naccuracy improvement for DeiT Tiny/Small, 1-2\\% accuracy improvement on ResNet\n18/50, and 1-22 perplexity point improvement for LLaMA models with up to 0.3\nbillion parameters. For the same loss, FOGZO yields a 796$\\times$ reduction in\ncomputation versus n-SPSA for a 2-layer MLP on MNIST. Code is available at\nhttps://github.com/1733116199/fogzo.",
    "published": "2025-10-27T23:14:59Z",
    "updated": "2025-10-27T23:14:59Z",
    "link": "http://arxiv.org/pdf/2510.23926v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Ningfeng Yang",
      "Tor M. Aamodt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.15141v2",
    "title": "Beyond PCA: Manifold Dimension Estimation via Local Graph Structure",
    "summary": "Local principal component analysis (Local PCA) has proven to be an effective\ntool for estimating the intrinsic dimension of a manifold. More recently,\ncurvature-adjusted PCA (CA-PCA) has improved upon this approach by explicitly\naccounting for the curvature of the underlying manifold, rather than assuming\nlocal flatness. Building on these insights, we propose a general framework for\nmanifold dimension estimation that captures the manifold's local graph\nstructure by integrating PCA with regression-based techniques. Within this\nframework, we introduce two representative estimators: quadratic embedding (QE)\nand total least squares (TLS). Experiments on both synthetic and real-world\ndatasets demonstrate that these methods perform competitively with, and often\noutperform, state-of-the-art alternatives.",
    "published": "2025-10-16T20:59:46Z",
    "updated": "2025-10-27T23:02:56Z",
    "link": "http://arxiv.org/pdf/2510.15141v2.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "stat.AP"
    ],
    "authors": [
      "Zelong Bi",
      "Pierre Lafaye de Micheaux"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.02793v2",
    "title": "Doubly-Robust Estimation of Counterfactual Policy Mean Embeddings",
    "summary": "Estimating the distribution of outcomes under counterfactual policies is\ncritical for decision-making in domains such as recommendation, advertising,\nand healthcare. We propose and analyze a novel framework-Counterfactual Policy\nMean Embedding (CPME)-that represents the entire counterfactual outcome\ndistribution in a reproducing kernel Hilbert space (RKHS), enabling flexible\nand nonparametric distributional off-policy evaluation. We introduce both a\nplug-in estimator and a doubly robust estimator; the latter enjoys improved\nconvergence rates by correcting for bias in both the outcome embedding and\npropensity models. Building on this, we develop a doubly robust kernel test\nstatistic for hypothesis testing, which achieves asymptotic normality and thus\nenables computationally efficient testing and straightforward construction of\nconfidence intervals. Our framework also supports sampling from the\ncounterfactual distribution. Numerical simulations illustrate the practical\nbenefits of CPME over existing methods.",
    "published": "2025-06-03T12:16:46Z",
    "updated": "2025-10-27T23:02:35Z",
    "link": "http://arxiv.org/pdf/2506.02793v2.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Houssam Zenati",
      "Bariscan Bozkurt",
      "Arthur Gretton"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23914v1",
    "title": "Geometry-Inspired Unified Framework for Discounted and Average Reward\n  MDPs",
    "summary": "The theoretical analysis of Markov Decision Processes (MDPs) is commonly\nsplit into two cases - the average-reward case and the discounted-reward case -\nwhich, while sharing similarities, are typically analyzed separately. In this\nwork, we extend a recently introduced geometric interpretation of MDPs for the\ndiscounted-reward case to the average-reward case, thereby unifying both. This\nallows us to extend a major result known for the discounted-reward case to the\naverage-reward case: under a unique and ergodic optimal policy, the Value\nIteration algorithm achieves a geometric convergence rate.",
    "published": "2025-10-27T22:42:53Z",
    "updated": "2025-10-27T22:42:53Z",
    "link": "http://arxiv.org/pdf/2510.23914v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Arsenii Mustafin",
      "Xinyi Sheng",
      "Dominik Baumann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23905v1",
    "title": "Inferring Group Intent as a Cooperative Game. An NLP-based Framework for\n  Trajectory Analysis using Graph Transformer Neural Network",
    "summary": "This paper studies group target trajectory intent as the outcome of a\ncooperative game where the complex-spatio trajectories are modeled using an\nNLP-based generative model. In our framework, the group intent is specified by\nthe characteristic function of a cooperative game, and allocations for players\nin the cooperative game are specified by either the core, the Shapley value, or\nthe nucleolus. The resulting allocations induce probability distributions that\ngovern the coordinated spatio-temporal trajectories of the targets that reflect\nthe group's underlying intent. We address two key questions: (1) How can the\nintent of a group trajectory be optimally formalized as the characteristic\nfunction of a cooperative game? (2) How can such intent be inferred from noisy\nobservations of the targets? To answer the first question, we introduce a\nFisher-information-based characteristic function of the cooperative game, which\nyields probability distributions that generate coordinated spatio-temporal\npatterns. As a generative model for these patterns, we develop an NLP-based\ngenerative model built on formal grammar, enabling the creation of realistic\nmulti-target trajectory data. To answer the second question, we train a Graph\nTransformer Neural Network (GTNN) to infer group trajectory intent-expressed as\nthe characteristic function of the cooperative game-from observational data\nwith high accuracy. The self-attention function of the GTNN depends on the\ntrack estimates. Thus, the formulation and algorithms provide a multi-layer\napproach that spans target tracking (Bayesian signal processing) and the GTNN\n(for group intent inference).",
    "published": "2025-10-27T22:23:53Z",
    "updated": "2025-10-27T22:23:53Z",
    "link": "http://arxiv.org/pdf/2510.23905v1.pdf",
    "category": [
      "eess.SP",
      "cs.LG"
    ],
    "authors": [
      "Yiming Zhang",
      "Vikram Krishnamurthy",
      "Shashwat Jain"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.10712v2",
    "title": "MinatoLoader: Accelerating Machine Learning Training Through Efficient\n  Data Preprocessing",
    "summary": "Data loaders are used by Machine Learning (ML) frameworks like PyTorch and\nTensorFlow to apply transformations to data before feeding it into the\naccelerator. This operation is called data preprocessing. Data preprocessing\nplays an important role in the ML training workflow because if it is\ninefficiently pipelined with the training, it can yield high GPU idleness,\nresulting in important training delays. Unfortunately, existing data loaders\nturn out to waste GPU resources, with $76\\%$ GPU idleness when using the\nPyTorch data loader, for example. One key source of inefficiency is the\nvariability in preprocessing time across samples within the same dataset.\nExisting data loaders are oblivious to this variability, and they construct\nbatches without any consideration of slow or fast samples. In this case, the\nentire batch is delayed by a single slow sample, stalling the training pipeline\nand resulting in head-of-line blocking.\n  To address these inefficiencies, we present MinatoLoader, a general-purpose\ndata loader for PyTorch that accelerates training and improves GPU utilization.\nMinatoLoader is designed for a single-server setup, containing multiple GPUs.\nIt continuously prepares data in the background and actively constructs batches\nby prioritizing fast-to-preprocess samples, while slower samples are processed\nin parallel.\n  We evaluate MinatoLoader on servers with V100 and A100 GPUs. On a machine\nwith four A100 GPUs, MinatoLoader improves the training time of a wide range of\nworkloads by up to $7.5\\times$ ($3.6\\times$ on average) over PyTorch DataLoader\nand Pecan, and up to $3\\times$ ($2.2\\times$ on average) over DALI. It also\nincreases average GPU utilization from 46.4\\% with PyTorch to 90.45\\%, while\npreserving model accuracy and enabling faster convergence.",
    "published": "2025-09-12T22:06:57Z",
    "updated": "2025-10-27T21:57:37Z",
    "link": "http://arxiv.org/pdf/2509.10712v2.pdf",
    "category": [
      "cs.DC",
      "cs.LG"
    ],
    "authors": [
      "Rahma Nouaji",
      "Stella Bitchebe",
      "Ricardo Macedo",
      "Oana Balmau"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23879v1",
    "title": "Artificial Intelligence Based Predictive Maintenance for Electric Buses",
    "summary": "Predictive maintenance (PdM) is crucial for optimizing efficiency and\nminimizing downtime of electric buses. While these vehicles provide\nenvironmental benefits, they pose challenges for PdM due to complex electric\ntransmission and battery systems. Traditional maintenance, often based on\nscheduled inspections, struggles to capture anomalies in multi-dimensional\nreal-time CAN Bus data. This study employs a graph-based feature selection\nmethod to analyze relationships among CAN Bus parameters of electric buses and\ninvestigates the prediction performance of targeted alarms using artificial\nintelligence techniques. The raw data collected over two years underwent\nextensive preprocessing to ensure data quality and consistency. A hybrid\ngraph-based feature selection tool was developed by combining statistical\nfiltering (Pearson correlation, Cramer's V, ANOVA F-test) with\noptimization-based community detection algorithms (InfoMap, Leiden, Louvain,\nFast Greedy). Machine learning models, including SVM, Random Forest, and\nXGBoost, were optimized through grid and random search with data balancing via\nSMOTEEN and binary search-based down-sampling. Model interpretability was\nachieved using LIME to identify the features influencing predictions. The\nresults demonstrate that the developed system effectively predicts vehicle\nalarms, enhances feature interpretability, and supports proactive maintenance\nstrategies aligned with Industry 4.0 principles.",
    "published": "2025-10-27T21:39:25Z",
    "updated": "2025-10-27T21:39:25Z",
    "link": "http://arxiv.org/pdf/2510.23879v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Ayse Irmak Ercevik",
      "Ahmet Murat Ozbayoglu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.09583v2",
    "title": "Learning to Coordinate with Experts",
    "summary": "When deployed in the real world, AI agents will inevitably face challenges\nthat exceed their individual capabilities. Leveraging assistance from experts,\nwhether humans or highly capable AI systems, can significantly improve both\nsafety and performance in such situations. Since expert assistance is costly, a\ncentral challenge is determining when to consult an expert. In this paper, we\nexplore a novel variant of this problem, termed YRC-0, in which an agent must\nlearn to collaborate with an expert in new environments in an unsupervised\nmanner--that is, without interacting with the expert during training. This\nsetting motivates the development of low-cost, robust approaches for training\nexpert-leveraging agents. To support research in this area, we introduce\nYRC-Bench, an open-source benchmark that instantiates YRC-0 across diverse\nenvironments. YRC-Bench provides a standardized Gym-like API, simulated\nexperts, an evaluation pipeline, and implementations of popular baselines.\nToward tackling YRC-0, we propose a validation strategy and evaluate a range of\nlearning methods, offering insights that can inform future research. Codebase:\ngithub.com/modanesh/YRC-Bench",
    "published": "2025-02-13T18:41:55Z",
    "updated": "2025-10-27T21:37:51Z",
    "link": "http://arxiv.org/pdf/2502.09583v2.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Mohamad H. Danesh",
      "Nguyen X. Khanh",
      "Tu Trinh",
      "Benjamin Plaut"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.18239v2",
    "title": "LIME: Link-based user-item Interaction Modeling with decoupled xor\n  attention for Efficient test time scaling",
    "summary": "Scaling large recommendation systems requires advancing three major\nfrontiers: processing longer user histories, expanding candidate sets, and\nincreasing model capacity. While promising, transformers' computational cost\nscales quadratically with the user sequence length and linearly with the number\nof candidates. This trade-off makes it prohibitively expensive to expand\ncandidate sets or increase sequence length at inference, despite the\nsignificant performance improvements.\n  We introduce \\textbf{LIME}, a novel architecture that resolves this\ntrade-off. Through two key innovations, LIME fundamentally reduces\ncomputational complexity. First, low-rank ``link embeddings\" enable\npre-computation of attention weights by decoupling user and candidate\ninteractions, making the inference cost nearly independent of candidate set\nsize. Second, a linear attention mechanism, \\textbf{LIME-XOR}, reduces the\ncomplexity with respect to user sequence length from quadratic ($O(N^2)$) to\nlinear ($O(N)$).\n  Experiments on public and industrial datasets show LIME achieves near-parity\nwith state-of-the-art transformers but with a 10$\\times$ inference speedup on\nlarge candidate sets or long sequence lengths. When tested on a major\nrecommendation platform, LIME improved user engagement while maintaining\nminimal inference costs with respect to candidate set size and user history\nlength, establishing a new paradigm for efficient and expressive recommendation\nsystems.",
    "published": "2025-10-21T02:53:17Z",
    "updated": "2025-10-27T21:18:47Z",
    "link": "http://arxiv.org/pdf/2510.18239v2.pdf",
    "category": [
      "cs.IR",
      "cs.LG"
    ],
    "authors": [
      "Yunjiang Jiang",
      "Ayush Agarwal",
      "Yang Liu",
      "Bi Xue"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.05024v3",
    "title": "Inoculation Prompting: Instructing LLMs to misbehave at train-time\n  improves test-time alignment",
    "summary": "Large language models are sometimes trained with imperfect oversight signals,\nleading to undesired behaviors such as reward hacking and sycophancy. Improving\noversight quality can be expensive or infeasible, motivating methods that\nimprove learned behavior despite an imperfect training signal. We introduce\nInoculation Prompting (IP), a simple but counterintuitive technique that\nprevents learning of an undesired behavior by modifying training prompts to\nexplicitly request it. For example, to inoculate against reward hacking, we\nmodify the prompts used in supervised fine-tuning to request code that only\nworks on provided test cases but fails on other inputs. Across four settings we\nfind that IP reduces the learning of undesired behavior without substantially\nreducing the learning of desired capabilities. We also show that prompts which\nmore strongly elicit the undesired behavior prior to fine-tuning more\neffectively inoculate against the behavior when used during training; this\nserves as a heuristic to identify promising inoculation prompts. Overall, IP is\na simple yet effective way to control how models generalize from fine-tuning,\npreventing learning of undesired behaviors without substantially disrupting\ndesired capabilities.",
    "published": "2025-10-06T17:02:59Z",
    "updated": "2025-10-27T21:05:19Z",
    "link": "http://arxiv.org/pdf/2510.05024v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Nevan Wichers",
      "Aram Ebtekar",
      "Ariana Azarbal",
      "Victor Gillioz",
      "Christine Ye",
      "Emil Ryd",
      "Neil Rathi",
      "Henry Sleight",
      "Alex Mallen",
      "Fabien Roger",
      "Samuel Marks"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.10959v3",
    "title": "Program Evaluation with Remotely Sensed Outcomes",
    "summary": "Economists often estimate treatment effects in experiments using remotely\nsensed variables (RSVs), e.g., satellite images or mobile phone activity, in\nplace of directly measured economic outcomes. A common practice is to use an\nobservational sample to train a predictor of the economic outcome from the RSV,\nand then use these predictions as the outcomes in the experiment. We show that\nthis method is biased whenever the RSV is a post-outcome variable, meaning that\nvariation in the economic outcome causes variation in the RSV. For example,\nchanges in poverty or environmental quality cause changes in satellite images,\nbut not vice versa. As our main result, we nonparametrically identify the\ntreatment effect by formalizing the intuition underlying common practice: the\nconditional distribution of the RSV given the outcome and treatment is stable\nacross samples. Our identifying formula reveals that efficient inference\nrequires predictions of three quantities from the RSV -- the outcome,\ntreatment, and sample indicator -- whereas common practice only predicts the\noutcome. Valid inference does not require any rate conditions on RSV\npredictions, justifying the use of complex deep learning algorithms with\nunknown statistical properties. We reanalyze the effect of an anti-poverty\nprogram in India using satellite images.",
    "published": "2024-11-17T04:43:04Z",
    "updated": "2025-10-27T20:57:45Z",
    "link": "http://arxiv.org/pdf/2411.10959v3.pdf",
    "category": [
      "econ.EM",
      "cs.LG",
      "math.ST",
      "stat.AP",
      "stat.ME",
      "stat.ML",
      "stat.TH"
    ],
    "authors": [
      "Ashesh Rambachan",
      "Rahul Singh",
      "Davide Viviano"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.14527v2",
    "title": "Inter-turbine Modelling of Wind-Farm Power using Multi-task Learning",
    "summary": "Because of the global need to increase power production from renewable energy\nresources, developments in the online monitoring of the associated\ninfrastructure is of interest to reduce operation and maintenance costs.\nHowever, challenges exist for data-driven approaches to this problem, such as\nincomplete or limited histories of labelled damage-state data, operational and\nenvironmental variability, or the desire for the quantification of uncertainty\nto support risk management.\n  This work first introduces a probabilistic regression model for predicting\nwind-turbine power, which adjusts for wake effects learnt from data. Spatial\ncorrelations in the learned model parameters for different tasks (turbines) are\nthen leveraged in a hierarchical Bayesian model (an approach to multi-task\nlearning) to develop a \"metamodel\", which can be used to make power-predictions\nwhich adjust for turbine location - including on previously unobserved turbines\nnot included in the training data. The results show that the metamodel is able\nto outperform a series of benchmark models, and demonstrates a novel strategy\nfor making efficient use of data for inference in populations of structures, in\nparticular where correlations exist in the variable(s) of interest (such as\nthose from wind-turbine wake-effects).",
    "published": "2025-02-20T13:01:07Z",
    "updated": "2025-10-27T20:50:49Z",
    "link": "http://arxiv.org/pdf/2502.14527v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Simon M. Brealy",
      "Lawrence A. Bull",
      "Pauline Beltrando",
      "Anders Sommer",
      "Nikolaos Dervilis",
      "Keith Worden"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23831v1",
    "title": "Testing-driven Variable Selection in Bayesian Modal Regression",
    "summary": "We propose a Bayesian variable selection method in the framework of modal\nregression for heavy-tailed responses. An efficient expectation-maximization\nalgorithm is employed to expedite parameter estimation. A test statistic is\nconstructed to exploit the shape of the model error distribution to effectively\nseparate informative covariates from unimportant ones. Through simulations, we\ndemonstrate and evaluate the efficacy of the proposed method in identifying\nimportant covariates in the presence of non-Gaussian model errors. Finally, we\napply the proposed method to analyze two datasets arising in genetic and\nepigenetic studies.",
    "published": "2025-10-27T20:17:34Z",
    "updated": "2025-10-27T20:17:34Z",
    "link": "http://arxiv.org/pdf/2510.23831v1.pdf",
    "category": [
      "stat.ME",
      "cs.LG",
      "stat.CO",
      "stat.ML",
      "62J05, 62J07, 62F15, 62F40"
    ],
    "authors": [
      "Jiasong Duan",
      "Hongmei Zhang",
      "Xianzheng Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.06549v3",
    "title": "GeoClip: Geometry-Aware Clipping for Differentially Private SGD",
    "summary": "Differentially private stochastic gradient descent (DP-SGD) is the most\nwidely used method for training machine learning models with provable privacy\nguarantees. A key challenge in DP-SGD is setting the per-sample gradient\nclipping threshold, which significantly affects the trade-off between privacy\nand utility. While recent adaptive methods improve performance by adjusting\nthis threshold during training, they operate in the standard coordinate system\nand fail to account for correlations across the coordinates of the gradient. We\npropose GeoClip, a geometry-aware framework that clips and perturbs gradients\nin a transformed basis aligned with the geometry of the gradient distribution.\nGeoClip adaptively estimates this transformation using only previously released\nnoisy gradients, incurring no additional privacy cost. We provide convergence\nguarantees for GeoClip and derive a closed-form solution for the optimal\ntransformation that minimizes the amount of noise added while keeping the\nprobability of gradient clipping under control. Experiments on both tabular and\nimage datasets demonstrate that GeoClip consistently outperforms existing\nadaptive clipping methods under the same privacy budget.",
    "published": "2025-06-06T21:41:17Z",
    "updated": "2025-10-27T20:00:10Z",
    "link": "http://arxiv.org/pdf/2506.06549v3.pdf",
    "category": [
      "cs.LG",
      "cs.CR",
      "cs.IT",
      "math.IT"
    ],
    "authors": [
      "Atefeh Gilani",
      "Naima Tasnim",
      "Lalitha Sankar",
      "Oliver Kosut"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23818v1",
    "title": "ScaLoRA: Optimally Scaled Low-Rank Adaptation for Efficient High-Rank\n  Fine-Tuning",
    "summary": "As large language models (LLMs) continue to scale in size, the computational\noverhead has become a major bottleneck for task-specific fine-tuning. While\nlow-rank adaptation (LoRA) effectively curtails this cost by confining the\nweight updates to a low-dimensional subspace, such a restriction can hinder\neffectiveness and slow convergence. This contribution deals with these\nlimitations by accumulating progressively a high-rank weight update from\nconsecutive low-rank increments. Specifically, the per update optimal low-rank\nmatrix is identified to minimize the loss function and closely approximate full\nfine-tuning. To endow efficient and seamless optimization without restarting,\nthis optimal choice is formed by appropriately scaling the columns of the\noriginal low-rank matrix. Rigorous performance guarantees reveal that the\noptimal scaling can be found analytically. Extensive numerical tests with\npopular LLMs scaling up to 12 billion parameters demonstrate a consistent\nperformance gain and fast convergence relative to state-of-the-art LoRA\nvariants on diverse tasks including natural language understanding, commonsense\nreasoning, and mathematical problem solving.",
    "published": "2025-10-27T19:59:46Z",
    "updated": "2025-10-27T19:59:46Z",
    "link": "http://arxiv.org/pdf/2510.23818v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Yilang Zhang",
      "Xiaodong Yang",
      "Yiwei Cai",
      "Georgios B. Giannakis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23817v1",
    "title": "Combining SHAP and Causal Analysis for Interpretable Fault Detection in\n  Industrial Processes",
    "summary": "Industrial processes generate complex data that challenge fault detection\nsystems, often yielding opaque or underwhelming results despite advanced\nmachine learning techniques. This study tackles such difficulties using the\nTennessee Eastman Process, a well-established benchmark known for its intricate\ndynamics, to develop an innovative fault detection framework. Initial attempts\nwith standard models revealed limitations in both performance and\ninterpretability, prompting a shift toward a more tractable approach. By\nemploying SHAP (SHapley Additive exPlanations), we transform the problem into a\nmore manageable and transparent form, pinpointing the most critical process\nfeatures driving fault predictions. This reduction in complexity unlocks the\nability to apply causal analysis through Directed Acyclic Graphs, generated by\nmultiple algorithms, to uncover the underlying mechanisms of fault propagation.\nThe resulting causal structures align strikingly with SHAP findings,\nconsistently highlighting key process elements-like cooling and separation\nsystems-as pivotal to fault development. Together, these methods not only\nenhance detection accuracy but also provide operators with clear, actionable\ninsights into fault origins, a synergy that, to our knowledge, has not been\npreviously explored in this context. This dual approach bridges predictive\npower with causal understanding, offering a robust tool for monitoring complex\nmanufacturing environments and paving the way for smarter, more interpretable\nfault detection in industrial systems.",
    "published": "2025-10-27T19:56:46Z",
    "updated": "2025-10-27T19:56:46Z",
    "link": "http://arxiv.org/pdf/2510.23817v1.pdf",
    "category": [
      "cs.LG",
      "stat.ME"
    ],
    "authors": [
      "Pedro Cortes dos Santos",
      "Matheus Becali Rocha",
      "Renato A Krohling"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.03727v3",
    "title": "Detecting Neurocognitive Disorders through Analyses of Topic Evolution\n  and Cross-modal Consistency in Visual-Stimulated Narratives",
    "summary": "Early detection of neurocognitive disorders (NCDs) is crucial for timely\nintervention and disease management. Given that language impairments manifest\nearly in NCD progression, visual-stimulated narrative (VSN)-based analysis\noffers a promising avenue for NCD detection. Current VSN-based NCD detection\nmethods primarily focus on linguistic microstructures (e.g., lexical diversity)\nthat are closely tied to bottom-up, stimulus-driven cognitive processes. While\nthese features illuminate basic language abilities, the higher-order linguistic\nmacrostructures (e.g., topic development) that may reflect top-down,\nconcept-driven cognitive abilities remain underexplored. These macrostructural\npatterns are crucial for NCD detection, yet challenging to quantify due to\ntheir abstract and complex nature. To bridge this gap, we propose two novel\nmacrostructural approaches: (1) a Dynamic Topic Model (DTM) to track topic\nevolution over time, and (2) a Text-Image Temporal Alignment Network (TITAN) to\nmeasure cross-modal consistency between narrative and visual stimuli.\nExperimental results show the effectiveness of the proposed approaches in NCD\ndetection, with TITAN achieving superior performance across three corpora:\nADReSS (F1=0.8889), ADReSSo (F1=0.8504), and CU-MARVEL-RABBIT (F1=0.7238).\nFeature contribution analysis reveals that macrostructural features (e.g.,\ntopic variability, topic change rate, and topic consistency) constitute the\nmost significant contributors to the model's decision pathways, outperforming\nthe investigated microstructural features. These findings underscore the value\nof macrostructural analysis for understanding linguistic-cognitive interactions\nassociated with NCDs.",
    "published": "2025-01-07T12:16:26Z",
    "updated": "2025-10-27T19:54:43Z",
    "link": "http://arxiv.org/pdf/2501.03727v3.pdf",
    "category": [
      "eess.AS",
      "cs.LG"
    ],
    "authors": [
      "Jinchao Li",
      "Yuejiao Wang",
      "Junan Li",
      "Jiawen Kang",
      "Bo Zheng",
      "Ka Ho Wong",
      "Brian Mak",
      "Helene H. Fung",
      "Jean Woo",
      "Man-Wai Mak",
      "Timothy Kwok",
      "Vincent Mok",
      "Xianmin Gong",
      "Xixin Wu",
      "Xunying Liu",
      "Patrick C. M. Wong",
      "Helen Meng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23810v1",
    "title": "A Physics-informed Multi-resolution Neural Operator",
    "summary": "The predictive accuracy of operator learning frameworks depends on the\nquality and quantity of available training data (input-output function pairs),\noften requiring substantial amounts of high-fidelity data, which can be\nchallenging to obtain in some real-world engineering applications. These\ndatasets may be unevenly discretized from one realization to another, with the\ngrid resolution varying across samples. In this study, we introduce a\nphysics-informed operator learning approach by extending the Resolution\nIndependent Neural Operator (RINO) framework to a fully data-free setup,\naddressing both challenges simultaneously. Here, the arbitrarily (but\nsufficiently finely) discretized input functions are projected onto a latent\nembedding space (i.e., a vector space of finite dimensions), using pre-trained\nbasis functions. The operator associated with the underlying partial\ndifferential equations (PDEs) is then approximated by a simple multi-layer\nperceptron (MLP), which takes as input a latent code along with spatiotemporal\ncoordinates to produce the solution in the physical space. The PDEs are\nenforced via a finite difference solver in the physical space. The validation\nand performance of the proposed method are benchmarked on several numerical\nexamples with multi-resolution data, where input functions are sampled at\nvarying resolutions, including both coarse and fine discretizations.",
    "published": "2025-10-27T19:50:02Z",
    "updated": "2025-10-27T19:50:02Z",
    "link": "http://arxiv.org/pdf/2510.23810v1.pdf",
    "category": [
      "cs.LG",
      "math.AP",
      "physics.comp-ph",
      "stat.ML"
    ],
    "authors": [
      "Sumanta Roy",
      "Bahador Bahmani",
      "Ioannis G. Kevrekidis",
      "Michael D. Shields"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23804v1",
    "title": "How do simple rotations affect the implicit bias of Adam?",
    "summary": "Adaptive gradient methods such as Adam and Adagrad are widely used in machine\nlearning, yet their effect on the generalization of learned models -- relative\nto methods like gradient descent -- remains poorly understood. Prior work on\nbinary classification suggests that Adam exhibits a ``richness bias,'' which\ncan help it learn nonlinear decision boundaries closer to the Bayes-optimal\ndecision boundary relative to gradient descent. However, the coordinate-wise\npreconditioning scheme employed by Adam renders the overall method sensitive to\northogonal transformations of feature space. We show that this sensitivity can\nmanifest as a reversal of Adam's competitive advantage: even small rotations of\nthe underlying data distribution can make Adam forfeit its richness bias and\nconverge to a linear decision boundary that is farther from the Bayes-optimal\ndecision boundary than the one learned by gradient descent. To alleviate this\nissue, we show that a recently proposed reparameterization method -- which\napplies an orthogonal transformation to the optimization objective -- endows\nany first-order method with equivariance to data rotations, and we empirically\ndemonstrate its ability to restore Adam's bias towards rich decision\nboundaries.",
    "published": "2025-10-27T19:38:46Z",
    "updated": "2025-10-27T19:38:46Z",
    "link": "http://arxiv.org/pdf/2510.23804v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Adela DePavia",
      "Vasileios Charisopoulos",
      "Rebecca Willett"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.07918v2",
    "title": "CausalPFN: Amortized Causal Effect Estimation via In-Context Learning",
    "summary": "Causal effect estimation from observational data is fundamental across\nvarious applications. However, selecting an appropriate estimator from dozens\nof specialized methods demands substantial manual effort and domain expertise.\nWe present CausalPFN, a single transformer that amortizes this workflow:\ntrained once on a large library of simulated data-generating processes that\nsatisfy ignorability, it infers causal effects for new observational datasets\nout of the box. CausalPFN combines ideas from Bayesian causal inference with\nthe large-scale training protocol of prior-fitted networks (PFNs), learning to\nmap raw observations directly to causal effects without any task-specific\nadjustment. Our approach achieves superior average performance on heterogeneous\nand average treatment effect estimation benchmarks (IHDP, Lalonde, ACIC).\nMoreover, it shows competitive performance for real-world policy making on\nuplift modeling tasks. CausalPFN provides calibrated uncertainty estimates to\nsupport reliable decision-making based on Bayesian principles. This\nready-to-use model requires no further training or tuning and takes a step\ntoward automated causal inference (https://github.com/vdblm/CausalPFN/).",
    "published": "2025-06-09T16:31:06Z",
    "updated": "2025-10-27T19:38:29Z",
    "link": "http://arxiv.org/pdf/2506.07918v2.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Vahid Balazadeh",
      "Hamidreza Kamkari",
      "Valentin Thomas",
      "Benson Li",
      "Junwei Ma",
      "Jesse C. Cresswell",
      "Rahul G. Krishnan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23802v1",
    "title": "Learning Interpretable Features in Audio Latent Spaces via Sparse\n  Autoencoders",
    "summary": "While sparse autoencoders (SAEs) successfully extract interpretable features\nfrom language models, applying them to audio generation faces unique\nchallenges: audio's dense nature requires compression that obscures semantic\nmeaning, and automatic feature characterization remains limited. We propose a\nframework for interpreting audio generative models by mapping their latent\nrepresentations to human-interpretable acoustic concepts. We train SAEs on\naudio autoencoder latents, then learn linear mappings from SAE features to\ndiscretized acoustic properties (pitch, amplitude, and timbre). This enables\nboth controllable manipulation and analysis of the AI music generation process,\nrevealing how acoustic properties emerge during synthesis. We validate our\napproach on continuous (DiffRhythm-VAE) and discrete (EnCodec, WavTokenizer)\naudio latent spaces, and analyze DiffRhythm, a state-of-the-art text-to-music\nmodel, to demonstrate how pitch, timbre, and loudness evolve throughout\ngeneration. While our work is only done on audio modality, our framework can be\nextended to interpretable analysis of visual latent space generation models.",
    "published": "2025-10-27T19:35:39Z",
    "updated": "2025-10-27T19:35:39Z",
    "link": "http://arxiv.org/pdf/2510.23802v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Nathan Paek",
      "Yongyi Zang",
      "Qihui Yang",
      "Randal Leistikow"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23794v1",
    "title": "Revealing the Potential of Learnable Perturbation Ensemble Forecast\n  Model for Tropical Cyclone Prediction",
    "summary": "Tropical cyclones (TCs) are highly destructive and inherently uncertain\nweather systems. Ensemble forecasting helps quantify these uncertainties, yet\ntraditional systems are constrained by high computational costs and limited\ncapability to fully represent atmospheric nonlinearity. FuXi-ENS introduces a\nlearnable perturbation scheme for ensemble generation, representing a novel\nAI-based forecasting paradigm. Here, we systematically compare FuXi-ENS with\nECMWF-ENS using all 90 global TCs in 2018, examining their performance in\nTC-related physical variables, track and intensity forecasts, and the\nassociated dynamical and thermodynamical fields. FuXi-ENS demonstrates clear\nadvantages in predicting TC-related physical variables, and achieves more\naccurate track forecasts with reduced ensemble spread, though it still\nunderestimates intensity relative to observations. Further dynamical and\nthermodynamical analyses reveal that FuXi-ENS better captures large-scale\ncirculation, with moisture turbulent energy more tightly concentrated around\nthe TC warm core, whereas ECMWF-ENS exhibits a more dispersed distribution.\nThese findings highlight the potential of learnable perturbations to improve TC\nforecasting skill and provide valuable insights for advancing AI-based ensemble\nprediction of extreme weather events that have significant societal impacts.",
    "published": "2025-10-27T19:27:04Z",
    "updated": "2025-10-27T19:27:04Z",
    "link": "http://arxiv.org/pdf/2510.23794v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Jun Liu",
      "Tao Zhou",
      "Jiarui Li",
      "Xiaohui Zhong",
      "Peng Zhang",
      "Jie Feng",
      "Lei Chen",
      "Hao Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.14323v2",
    "title": "Securing Transfer-Learned Networks with Reverse Homomorphic Encryption",
    "summary": "The growing body of literature on training-data reconstruction attacks raises\nsignificant concerns about deploying neural network classifiers trained on\nsensitive data. However, differentially private (DP) training (e.g. using\nDP-SGD) can defend against such attacks with large training datasets causing\nonly minimal loss of network utility. Folklore, heuristics, and (albeit\npessimistic) DP bounds suggest this fails for networks trained with small\nper-class datasets, yet to the best of our knowledge the literature offers no\ncompelling evidence. We directly demonstrate this vulnerability by\nsignificantly extending reconstruction attack capabilities under a realistic\nadversary threat model for few-shot transfer learned image classifiers. We\ndesign new white-box and black-box attacks and find that DP-SGD is unable to\ndefend against these without significant classifier utility loss. To address\nthis, we propose a novel homomorphic encryption (HE) method that protects\ntraining data without degrading model's accuracy. Conventional HE secures\nmodel's input data and requires costly homomorphic implementation of the entire\nclassifier. In contrast, our new scheme is computationally efficient and\nprotects training data rather than input data. This is achieved by means of a\nsimple role-reversal where classifier input data is unencrypted but\ntransfer-learned weights are encrypted. Classifier outputs remain encrypted,\nthus preventing both white-box and black-box (and any other) training-data\nreconstruction attacks. Under this new scheme only a trusted party with a\nprivate decryption key can obtain the classifier class decisions.",
    "published": "2025-05-20T13:09:22Z",
    "updated": "2025-10-27T19:24:41Z",
    "link": "http://arxiv.org/pdf/2505.14323v2.pdf",
    "category": [
      "cs.CR",
      "cs.LG"
    ],
    "authors": [
      "Robert Allison",
      "Tomasz MaciÄÅ¼ek",
      "Henry Bourne"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.09923v2",
    "title": "Apollo: A Posteriori Label-Only Membership Inference Attack Towards\n  Machine Unlearning",
    "summary": "Machine Unlearning (MU) aims to update Machine Learning (ML) models following\nrequests to remove training samples and their influences on a trained model\nefficiently without retraining the original ML model from scratch. While MU\nitself has been employed to provide privacy protection and regulatory\ncompliance, it can also increase the attack surface of the model. Existing\nprivacy inference attacks towards MU that aim to infer properties of the\nunlearned set rely on the weaker threat model that assumes the attacker has\naccess to both the unlearned model and the original model, limiting their\nfeasibility toward real-life scenarios. We propose a novel privacy attack, A\nPosteriori Label-Only Membership Inference Attack towards MU, Apollo, that\ninfers whether a data sample has been unlearned, following a strict threat\nmodel where an adversary has access to the label-output of the unlearned model\nonly. We demonstrate that our proposed attack, while requiring less access to\nthe target model compared to previous attacks, can achieve relatively high\nprecision on the membership status of the unlearned samples.",
    "published": "2025-06-11T16:43:36Z",
    "updated": "2025-10-27T19:22:43Z",
    "link": "http://arxiv.org/pdf/2506.09923v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Liou Tang",
      "James Joshi",
      "Ashish Kundu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23786v1",
    "title": "Relaxed Sequence Sampling for Diverse Protein Design",
    "summary": "Protein design using structure prediction models such as AlphaFold2 has shown\nremarkable success, but existing approaches like relaxed sequence optimization\n(RSO) rely on single-path gradient descent and ignore sequence-space\nconstraints, limiting diversity and designability. We introduce Relaxed\nSequence Sampling (RSS), a Markov chain Monte Carlo (MCMC) framework that\nintegrates structural and evolutionary information for protein design. RSS\noperates in continuous logit space, combining gradient-guided exploration with\nprotein language model-informed jumps. Its energy function couples\nAlphaFold2-derived structural objectives with ESM2-derived sequence priors,\nbalancing accuracy and biological plausibility. In an in silico protein binder\ndesign task, RSS produces 5$\\times$ more designable structures and 2-3$\\times$\ngreater structural diversity than RSO baselines, at equal computational cost.\nThese results highlight RSS as a principled approach for efficiently exploring\nthe protein design landscape.",
    "published": "2025-10-27T19:18:36Z",
    "updated": "2025-10-27T19:18:36Z",
    "link": "http://arxiv.org/pdf/2510.23786v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Joohwan Ko",
      "Aristofanis Rontogiannis",
      "Yih-En Andrew Ban",
      "Axel Elaldi",
      "Nicholas Franklin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.00230v3",
    "title": "PPFL-RDSN: Privacy-Preserving Federated Learning-based Residual Dense\n  Spatial Networks for Encrypted Lossy Image Reconstruction",
    "summary": "Reconstructing high-quality images from low-resolution inputs using Residual\nDense Spatial Networks (RDSNs) is crucial yet challenging. It is even more\nchallenging in centralized training where multiple collaborating parties are\ninvolved, as it poses significant privacy risks, including data leakage and\ninference attacks, as well as high computational and communication costs. We\npropose a novel Privacy-Preserving Federated Learning-based RDSN (PPFL-RDSN)\nframework specifically tailored for encrypted lossy image reconstruction.\nPPFL-RDSN integrates Federated Learning (FL), local differential privacy, and\nrobust model watermarking techniques to ensure that data remains secure on\nlocal clients/devices, safeguards privacy-sensitive information, and maintains\nmodel authenticity without revealing underlying data. Empirical evaluations\nshow that PPFL-RDSN achieves comparable performance to the state-of-the-art\ncentralized methods while reducing computational burdens, and effectively\nmitigates security and privacy vulnerabilities, making it a practical solution\nfor secure and privacy-preserving collaborative computer vision applications.",
    "published": "2025-06-30T19:54:34Z",
    "updated": "2025-10-27T19:09:31Z",
    "link": "http://arxiv.org/pdf/2507.00230v3.pdf",
    "category": [
      "cs.LG",
      "cs.CR"
    ],
    "authors": [
      "Peilin He",
      "James Joshi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.24089v2",
    "title": "Practical Bayes-Optimal Membership Inference Attacks",
    "summary": "We develop practical and theoretically grounded membership inference attacks\n(MIAs) against both independent and identically distributed (i.i.d.) data and\ngraph-structured data. Building on the Bayesian decision-theoretic framework of\nSablayrolles et al., we derive the Bayes-optimal membership inference rule for\nnode-level MIAs against graph neural networks, addressing key open questions\nabout optimal query strategies in the graph setting. We introduce BASE and\nG-BASE, tractable approximations of the Bayes-optimal membership inference.\nG-BASE achieves superior performance compared to previously proposed\nclassifier-based node-level MIA attacks. BASE, which is also applicable to\nnon-graph data, matches or exceeds the performance of prior state-of-the-art\nMIAs, such as LiRA and RMIA, at a significantly lower computational cost.\nFinally, we show that BASE and RMIA are equivalent under a specific\nhyperparameter setting, providing a principled, Bayes-optimal justification for\nthe RMIA attack.",
    "published": "2025-05-30T00:23:01Z",
    "updated": "2025-10-27T18:58:38Z",
    "link": "http://arxiv.org/pdf/2505.24089v2.pdf",
    "category": [
      "cs.LG",
      "cs.CR"
    ],
    "authors": [
      "Marcus Lassila",
      "Johan Ãstman",
      "Khac-Hoang Ngo",
      "Alexandre Graell i Amat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23749v1",
    "title": "Re-envisioning Euclid Galaxy Morphology: Identifying and Interpreting\n  Features with Sparse Autoencoders",
    "summary": "Sparse Autoencoders (SAEs) can efficiently identify candidate monosemantic\nfeatures from pretrained neural networks for galaxy morphology. We demonstrate\nthis on Euclid Q1 images using both supervised (Zoobot) and new self-supervised\n(MAE) models. Our publicly released MAE achieves superhuman image\nreconstruction performance. While a Principal Component Analysis (PCA) on the\nsupervised model primarily identifies features already aligned with the Galaxy\nZoo decision tree, SAEs can identify interpretable features outside of this\nframework. SAE features also show stronger alignment than PCA with Galaxy Zoo\nlabels. Although challenges in interpretability remain, SAEs provide a powerful\nengine for discovering astrophysical phenomena beyond the confines of\nhuman-defined classification.",
    "published": "2025-10-27T18:28:56Z",
    "updated": "2025-10-27T18:28:56Z",
    "link": "http://arxiv.org/pdf/2510.23749v1.pdf",
    "category": [
      "astro-ph.IM",
      "cs.LG"
    ],
    "authors": [
      "John F. Wu",
      "Michael Walmsley"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23745v1",
    "title": "Bayesian neural networks with interpretable priors from Mercer kernels",
    "summary": "Quantifying the uncertainty in the output of a neural network is essential\nfor deployment in scientific or engineering applications where decisions must\nbe made under limited or noisy data. Bayesian neural networks (BNNs) provide a\nframework for this purpose by constructing a Bayesian posterior distribution\nover the network parameters. However, the prior, which is of key importance in\nany Bayesian setting, is rarely meaningful for BNNs. This is because the\ncomplexity of the input-to-output map of a BNN makes it difficult to understand\nhow certain distributions enforce any interpretable constraint on the output\nspace. Gaussian processes (GPs), on the other hand, are often preferred in\nuncertainty quantification tasks due to their interpretability. The drawback is\nthat GPs are limited to small datasets without advanced techniques, which often\nrely on the covariance kernel having a specific structure. To address these\nchallenges, we introduce a new class of priors for BNNs, called Mercer priors,\nsuch that the resulting BNN has samples which approximate that of a specified\nGP. The method works by defining a prior directly over the network parameters\nfrom the Mercer representation of the covariance kernel, and does not rely on\nthe network having a specific structure. In doing so, we can exploit the\nscalability of BNNs in a meaningful Bayesian way.",
    "published": "2025-10-27T18:25:21Z",
    "updated": "2025-10-27T18:25:21Z",
    "link": "http://arxiv.org/pdf/2510.23745v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Alex Alberts",
      "Ilias Bilionis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.19053v2",
    "title": "Structured Reinforcement Learning for Combinatorial Decision-Making",
    "summary": "Reinforcement learning (RL) is increasingly applied to real-world problems\ninvolving complex and structured decisions, such as routing, scheduling, and\nassortment planning. These settings challenge standard RL algorithms, which\nstruggle to scale, generalize, and exploit structure in the presence of\ncombinatorial action spaces. We propose Structured Reinforcement Learning\n(SRL), a novel actor-critic paradigm that embeds combinatorial\noptimization-layers into the actor neural network. We enable end-to-end\nlearning of the actor via Fenchel-Young losses and provide a geometric\ninterpretation of SRL as a primal-dual algorithm in the dual of the moment\npolytope. Across six environments with exogenous and endogenous uncertainty,\nSRL matches or surpasses the performance of unstructured RL and imitation\nlearning on static tasks and improves over these baselines by up to 92% on\ndynamic problems, with improved stability and convergence speed.",
    "published": "2025-05-25T09:17:10Z",
    "updated": "2025-10-27T18:03:20Z",
    "link": "http://arxiv.org/pdf/2505.19053v2.pdf",
    "category": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "authors": [
      "Heiko Hoppe",
      "LÃ©o Baty",
      "Louis Bouvier",
      "Axel Parmentier",
      "Maximilian Schiffer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.00919v2",
    "title": "Geometry matters: insights from Ollivier Ricci Curvature and Ricci Flow\n  into representational alignment through Ollivier-Ricci Curvature and Ricci\n  Flow",
    "summary": "Representational similarity analysis (RSA) is widely used to analyze the\nalignment between humans and neural networks; however, conclusions based on\nthis approach can be misleading without considering the underlying\nrepresentational geometry. Our work introduces a framework using Ollivier Ricci\nCurvature and Ricci Flow to analyze the fine-grained local structure of\nrepresentations. This approach is agnostic to the source of the\nrepresentational space, enabling a direct geometric comparison between human\nbehavioral judgments and a model's vector embeddings. We apply it to compare\nhuman similarity judgments for 2D and 3D face stimuli with a baseline 2D native\nnetwork (VGG-Face) and a variant of it aligned to human behavior. Our results\nsuggest that geometry-aware analysis provides a more sensitive characterization\nof discrepancies and geometric dissimilarities in the underlying\nrepresentations that remain only partially captured by RSA. Notably, we reveal\ngeometric inconsistencies in the alignment when moving from 2D to 3D viewing\nconditions.This highlights how incorporating geometric information can expose\nalignment differences missed by traditional metrics, offering deeper insight\ninto representational organization.",
    "published": "2025-01-01T18:33:48Z",
    "updated": "2025-10-27T18:01:43Z",
    "link": "http://arxiv.org/pdf/2501.00919v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Nahid Torbati",
      "Michael Gaebler",
      "Simon M. Hofmann",
      "Nico Scherf"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23702v1",
    "title": "In Search of the Unknown Unknowns: A Multi-Metric Distance Ensemble for\n  Out of Distribution Anomaly Detection in Astronomical Surveys",
    "summary": "Distance-based methods involve the computation of distance values between\nfeatures and are a well-established paradigm in machine learning. In anomaly\ndetection, anomalies are identified by their large distance from normal data\npoints. However, the performance of these methods often hinges on a single,\nuser-selected distance metric (e.g., Euclidean), which may not be optimal for\nthe complex, high-dimensional feature spaces common in astronomy. Here, we\nintroduce a novel anomaly detection method, Distance Multi-Metric Anomaly\nDetection (DiMMAD), which uses an ensemble of distance metrics to find\nnovelties.\n  Using multiple distance metrics is effectively equivalent to using different\ngeometries in the feature space. By using a robust ensemble of diverse distance\nmetrics, we overcome the metric-selection problem, creating an anomaly score\nthat is not reliant on any single definition of distance. We demonstrate this\nmulti-metric approach as a tool for simple, interpretable scientific discovery\non astronomical time series -- (1) with simulated data for the upcoming Vera C.\nRubin Observatory Legacy Survey of Space and Time, and (2) real data from the\nZwicky Transient Facility.\n  We find that DiMMAD excels at out-of-distribution anomaly detection --\nanomalies in the data that might be new classes -- and beats other\nstate-of-the-art methods in the goal of maximizing the diversity of new classes\ndiscovered. For rare in-distribution anomaly detection, DiMMAD performs\nsimilarly to other methods, but may allow for improved interpretability. All\nour code is open source: DiMMAD is implemented within DistClassiPy:\nhttps://github.com/sidchaini/distclassipy/, while all code to reproduce the\nresults of this paper is available here: https://github.com/sidchaini/dimmad/.",
    "published": "2025-10-27T18:00:00Z",
    "updated": "2025-10-27T18:00:00Z",
    "link": "http://arxiv.org/pdf/2510.23702v1.pdf",
    "category": [
      "astro-ph.IM",
      "cs.LG"
    ],
    "authors": [
      "Siddharth Chaini",
      "Federica B. Bianco",
      "Ashish Mahabal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2209.08884v2",
    "title": "Adaptive 3D Mesh Steganography Based on Feature-Preserving Distortion",
    "summary": "Current 3D mesh steganography algorithms relying on geometric modification\nare prone to detection by steganalyzers. In traditional steganography, adaptive\nsteganography has proven to be an efficient means of enhancing steganography\nsecurity. Taking inspiration from this, we propose a highly adaptive embedding\nalgorithm, guided by the principle of minimizing a carefully crafted distortion\nthrough efficient steganography codes. Specifically, we tailor a\npayload-limited embedding optimization problem for 3D settings and devise a\nfeature-preserving distortion (FPD) to measure the impact of message embedding.\nThe distortion takes on an additive form and is defined as a weighted\ndifference of the effective steganalytic subfeatures utilized by the current 3D\nsteganalyzers. With practicality in mind, we refine the distortion to enhance\nrobustness and computational efficiency. By minimizing the FPD, our algorithm\ncan preserve mesh features to a considerable extent, including steganalytic and\ngeometric features, while achieving a high embedding capacity. During the\npractical embedding phase, we employ the Q-layered syndrome trellis code (STC).\nHowever, calculating the bit modification probability (BMP) for each layer of\nthe Q-layered STC, given the variation of Q, can be cumbersome. To address this\nissue, we design a universal and automatic approach for the BMP calculation.\nThe experimental results demonstrate that our algorithm achieves\nstate-of-the-art performance in countering 3D steganalysis. Code is available\nat https://github.com/zjhJOJO/3D-steganography-based-on-FPD.git.",
    "published": "2022-09-19T09:39:29Z",
    "updated": "2025-10-27T23:54:59Z",
    "link": "http://arxiv.org/pdf/2209.08884v2.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Yushu Zhang",
      "Jiahao Zhu",
      "Mignfu Xue",
      "Xinpeng Zhang",
      "Xiaochun Cao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.10755v3",
    "title": "Procedural Generation of Articulated Simulation-Ready Assets",
    "summary": "We introduce Infinigen-Articulated, a toolkit for generating realistic,\nprocedurally generated articulated assets for robotics simulation. We include\nprocedural generators for 18 common articulated object categories along with\nhigh-level utilities for use creating custom articulated assets in Blender. We\nalso provide an export pipeline to integrate the resulting assets along with\ntheir physical properties into common robotics simulators. Experiments\ndemonstrate that assets sampled from these generators are effective for movable\nobject segmentation, training generalizable reinforcement learning policies,\nand sim-to-real transfer of imitation learning policies.",
    "published": "2025-05-15T23:47:58Z",
    "updated": "2025-10-28T11:05:00Z",
    "link": "http://arxiv.org/pdf/2505.10755v3.pdf",
    "category": [
      "cs.RO",
      "cs.GR"
    ],
    "authors": [
      "Abhishek Joshi",
      "Beining Han",
      "Jack Nugent",
      "Max Gonzalez Saez-Diez",
      "Yiming Zuo",
      "Jonathan Liu",
      "Hongyu Wen",
      "Stamatis Alexandropoulos",
      "Karhan Kayan",
      "Anna Calveri",
      "Tao Sun",
      "Gaowen Liu",
      "Yi Shao",
      "Alexander Raistrick",
      "Jia Deng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.03099v3",
    "title": "Capturing Non-Linear Human Perspective in Line Drawings",
    "summary": "Artist-drawn sketches only loosely conform to analytical models of\nperspective projection; the deviation of human-drawn perspective from\nanalytical perspective models is persistent and well documented, but has yet to\nbe algorithmically replicated. We encode this deviation between human and\nanalytic perspectives as a continuous function in 3D space and develop a method\nto learn it. We seek deviation functions that (i)mimic artist deviation on our\ntraining data; (ii)generalize to other shapes; (iii)are consistent across\ndifferent views of the same shape; and (iv)produce outputs that appear\nhuman-drawn. The natural data for learning this deviation is pairs of artist\nsketches of 3D shapes and best-matching analytical camera views of the same\nshapes. However, a core challenge in learning perspective deviation is the\nheterogeneity of human drawing choices, combined with relative data paucity\n(the datasets we rely on have only a few dozen training pairs). We sidestep\nthis challenge by learning perspective deviation from an individual pair of an\nartist sketch of a 3D shape and the contours of the same shape rendered from a\nbest-matching analytical camera view. We first match contours of the depicted\nshape to artist strokes, then learn a spatially continuous local perspective\ndeviation function that modifies the camera perspective projecting the contours\nto their corresponding strokes. This function retains key geometric properties\nthat artists strive to preserve when depicting 3D content, thus satisfying (i)\nand (iv) above. We generalize our method to alternative shapes and views (ii,\niii) via a self-augmentation approach that algorithmically generates training\ndata for nearby views, and enforces spatial smoothness and consistency across\nall views. We compare our results to potential alternatives, demonstrating the\nsuperiority of the proposed approach.",
    "published": "2025-04-04T00:57:48Z",
    "updated": "2025-10-27T23:53:18Z",
    "link": "http://arxiv.org/pdf/2504.03099v3.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Jinfan Yang",
      "Leo Foord-Kelcey",
      "Suzuran Takikawa",
      "Nicholas Vining",
      "Niloy Mitra",
      "Alla Sheffer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24692v1",
    "title": "Embodying Physical Computing into Soft Robots",
    "summary": "Softening and onboarding computers and controllers is one of the final\nfrontiers in soft robotics towards their robustness and intelligence for\neveryday use. In this regard, embodying soft and physical computing presents\nexciting potential. Physical computing seeks to encode inputs into a mechanical\ncomputing kernel and leverage the internal interactions among this kernel's\nconstituent elements to compute the output. Moreover, such input-to-output\nevolution can be re-programmable. This perspective paper proposes a framework\nfor embodying physical computing into soft robots and discusses three unique\nstrategies in the literature: analog oscillators, physical reservoir computing,\nand physical algorithmic computing. These embodied computers enable the soft\nrobot to perform complex behaviors that would otherwise require CMOS-based\nelectronics -- including coordinated locomotion with obstacle avoidance,\npayload weight and orientation classification, and programmable operation based\non logical rules. This paper will detail the working principles of these\nembodied physical computing methods, survey the current state-of-the-art, and\npresent a perspective for future development.",
    "published": "2025-10-28T17:50:30Z",
    "updated": "2025-10-28T17:50:30Z",
    "link": "http://arxiv.org/pdf/2510.24692v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Jun Wang",
      "Ziyang Zhou",
      "Ardalan Kahak",
      "Suyi Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24683v1",
    "title": "A Framework for the Systematic Evaluation of Obstacle Avoidance and\n  Object-Aware Controllers",
    "summary": "Real-time control is an essential aspect of safe robot operation in the real\nworld with dynamic objects. We present a framework for the analysis of\nobject-aware controllers, methods for altering a robot's motion to anticipate\nand avoid possible collisions. This framework is focused on three design\nconsiderations: kinematics, motion profiles, and virtual constraints.\nAdditionally, the analysis in this work relies on verification of robot\nbehaviors using fundamental robot-obstacle experimental scenarios. To showcase\nthe effectiveness of our method we compare three representative object-aware\ncontrollers. The comparison uses metrics originating from the design\nconsiderations. From the analysis, we find that the design of object-aware\ncontrollers often lacks kinematic considerations, continuity of control points,\nand stability in movement profiles. We conclude that this framework can be used\nin the future to design, compare, and benchmark obstacle avoidance methods.",
    "published": "2025-10-28T17:46:06Z",
    "updated": "2025-10-28T17:46:06Z",
    "link": "http://arxiv.org/pdf/2510.24683v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Caleb Escobedo",
      "Nataliya Nechyporenko",
      "Shreyas Kadekodi",
      "Alessandro Roncone"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24680v1",
    "title": "Fare: Failure Resilience in Learned Visual Navigation Control",
    "summary": "While imitation learning (IL) enables effective visual navigation, IL\npolicies are prone to unpredictable failures in out-of-distribution (OOD)\nscenarios. We advance the notion of failure-resilient policies, which not only\ndetect failures but also recover from them automatically. Failure recognition\nthat identifies the factors causing failure is key to informing recovery: e.g.\npinpointing image regions triggering failure detections can provide cues to\nguide recovery. We present Fare, a framework to construct failure-resilient IL\npolicies, embedding OOD-detection and recognition in them without using\nexplicit failure data, and pairing them with recovery heuristics. Real-world\nexperiments show that Fare enables failure recovery across two different policy\narchitectures, enabling robust long-range navigation in complex environments.",
    "published": "2025-10-28T17:45:26Z",
    "updated": "2025-10-28T17:45:26Z",
    "link": "http://arxiv.org/pdf/2510.24680v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Zishuo Wang",
      "Joel Loo",
      "David Hsu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24676v1",
    "title": "Feature Matching-Based Gait Phase Prediction for Obstacle Crossing\n  Control of Powered Transfemoral Prosthesis",
    "summary": "For amputees with powered transfemoral prosthetics, navigating obstacles or\ncomplex terrain remains challenging. This study addresses this issue by using\nan inertial sensor on the sound ankle to guide obstacle-crossing movements. A\ngenetic algorithm computes the optimal neural network structure to predict the\nrequired angles of the thigh and knee joints. A gait progression prediction\nalgorithm determines the actuation angle index for the prosthetic knee motor,\nultimately defining the necessary thigh and knee angles and gait progression.\nResults show that when the standard deviation of Gaussian noise added to the\nthigh angle data is less than 1, the method can effectively eliminate noise\ninterference, achieving 100\\% accuracy in gait phase estimation under 150 Hz,\nwith thigh angle prediction error being 8.71\\% and knee angle prediction error\nbeing 6.78\\%. These findings demonstrate the method's ability to accurately\npredict gait progression and joint angles, offering significant practical value\nfor obstacle negotiation in powered transfemoral prosthetics.",
    "published": "2025-10-28T17:40:52Z",
    "updated": "2025-10-28T17:40:52Z",
    "link": "http://arxiv.org/pdf/2510.24676v1.pdf",
    "category": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "authors": [
      "Jiaxuan Zhang",
      "Yuquan Leng",
      "Yixuan Guo",
      "Chenglong Fu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24584v1",
    "title": "Towards Quadrupedal Jumping and Walking for Dynamic Locomotion using\n  Reinforcement Learning",
    "summary": "This paper presents a curriculum-based reinforcement learning framework for\ntraining precise and high-performance jumping policies for the robot `Olympus'.\nSeparate policies are developed for vertical and horizontal jumps, leveraging a\nsimple yet effective strategy. First, we densify the inherently sparse jumping\nreward using the laws of projectile motion. Next, a reference state\ninitialization scheme is employed to accelerate the exploration of dynamic\njumping behaviors without reliance on reference trajectories. We also present a\nwalking policy that, when combined with the jumping policies, unlocks versatile\nand dynamic locomotion capabilities. Comprehensive testing validates walking on\nvaried terrain surfaces and jumping performance that exceeds previous works,\neffectively crossing the Sim2Real gap. Experimental validation demonstrates\nhorizontal jumps up to 1.25 m with centimeter accuracy and vertical jumps up to\n1.0 m. Additionally, we show that with only minor modifications, the proposed\nmethod can be used to learn omnidirectional jumping.",
    "published": "2025-10-28T16:16:31Z",
    "updated": "2025-10-28T16:16:31Z",
    "link": "http://arxiv.org/pdf/2510.24584v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "JÃ¸rgen Anker Olsen",
      "Lars RÃ¸nhaug Pettersen",
      "Kostas Alexis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24571v1",
    "title": "Spatiotemporal Calibration of Doppler Velocity Logs for Underwater\n  Robots",
    "summary": "The calibration of extrinsic parameters and clock offsets between sensors for\nhigh-accuracy performance in underwater SLAM systems remains insufficiently\nexplored. Existing methods for Doppler Velocity Log (DVL) calibration are\neither constrained to specific sensor configurations or rely on oversimplified\nassumptions, and none jointly estimate translational extrinsics and time\noffsets. We propose a Unified Iterative Calibration (UIC) framework for general\nDVL sensor setups, formulated as a Maximum A Posteriori (MAP) estimation with a\nGaussian Process (GP) motion prior for high-fidelity motion interpolation. UIC\nalternates between efficient GP-based motion state updates and gradient-based\ncalibration variable updates, supported by a provably statistically consistent\nsequential initialization scheme. The proposed UIC can be applied to IMU,\ncameras and other modalities as co-sensors. We release an open-source\nDVL-camera calibration toolbox. Beyond underwater applications, several aspects\nof UIC-such as the integration of GP priors for MAP-based calibration and the\ndesign of provably reliable initialization procedures-are broadly applicable to\nother multi-sensor calibration problems. Finally, simulations and real-world\ntests validate our approach.",
    "published": "2025-10-28T16:07:39Z",
    "updated": "2025-10-28T16:07:39Z",
    "link": "http://arxiv.org/pdf/2510.24571v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Hongxu Zhao",
      "Guangyang Zeng",
      "Yunling Shao",
      "Tengfei Zhang",
      "Junfeng Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24554v1",
    "title": "An Adaptive Inspection Planning Approach Towards Routine Monitoring in\n  Uncertain Environments",
    "summary": "In this work, we present a hierarchical framework designed to support robotic\ninspection under environment uncertainty. By leveraging a known environment\nmodel, existing methods plan and safely track inspection routes to visit points\nof interest. However, discrepancies between the model and actual site\nconditions, caused by either natural or human activities, can alter the surface\nmorphology or introduce path obstructions. To address this challenge, the\nproposed framework divides the inspection task into: (a) generating the initial\nglobal view-plan for region of interests based on a historical map and (b)\nlocal view replanning to adapt to the current morphology of the inspection\nscene. The proposed hierarchy preserves global coverage objectives while\nenabling reactive adaptation to the local surface morphology. This enables the\nlocal autonomy to remain robust against environment uncertainty and complete\nthe inspection tasks. We validate the approach through deployments in\nreal-world subterranean mines using quadrupedal robot.",
    "published": "2025-10-28T15:51:14Z",
    "updated": "2025-10-28T15:51:14Z",
    "link": "http://arxiv.org/pdf/2510.24554v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Vignesh Kottayam Viswanathan",
      "Yifan Bai",
      "Scott Fredriksson",
      "Sumeet Satpute",
      "Christoforos Kanellakis",
      "George Nikolakopoulos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24533v1",
    "title": "GeVI-SLAM: Gravity-Enhanced Stereo Visua Inertial SLAM for Underwater\n  Robots",
    "summary": "Accurate visual inertial simultaneous localization and mapping (VI SLAM) for\nunderwater robots remains a significant challenge due to frequent visual\ndegeneracy and insufficient inertial measurement unit (IMU) motion excitation.\nIn this paper, we present GeVI-SLAM, a gravity-enhanced stereo VI SLAM system\ndesigned to address these issues. By leveraging the stereo camera's direct\ndepth estimation ability, we eliminate the need to estimate scale during IMU\ninitialization, enabling stable operation even under low acceleration dynamics.\nWith precise gravity initialization, we decouple the pitch and roll from the\npose estimation and solve a 4 degrees of freedom (DOF) Perspective-n-Point\n(PnP) problem for pose tracking. This allows the use of a minimal 3-point\nsolver, which significantly reduces computational time to reject outliers\nwithin a Random Sample Consensus framework. We further propose a\nbias-eliminated 4-DOF PnP estimator with provable consistency, ensuring the\nrelative pose converges to the true value as the feature number increases. To\nhandle dynamic motion, we refine the full 6-DOF pose while jointly estimating\nthe IMU covariance, enabling adaptive weighting of the gravity prior. Extensive\nexperiments on simulated and real-world data demonstrate that GeVI-SLAM\nachieves higher accuracy and greater stability compared to state-of-the-art\nmethods.",
    "published": "2025-10-28T15:39:07Z",
    "updated": "2025-10-28T15:39:07Z",
    "link": "http://arxiv.org/pdf/2510.24533v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Yuan Shen",
      "Yuze Hong",
      "Guangyang Zeng",
      "Tengfei Zhang",
      "Pui Yi Chui",
      "Ziyang Hong",
      "Junfeng Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24515v1",
    "title": "Stochastic Prize-Collecting Games: Strategic Planning in Multi-Robot\n  Systems",
    "summary": "The Team Orienteering Problem (TOP) generalizes many real-world multi-robot\nscheduling and routing tasks that occur in autonomous mobility, aerial\nlogistics, and surveillance applications. While many flavors of the TOP exist\nfor planning in multi-robot systems, they assume that all the robots cooperate\ntoward a single objective; thus, they do not extend to settings where the\nrobots compete in reward-scarce environments. We propose Stochastic\nPrize-Collecting Games (SPCG) as an extension of the TOP to plan in the\npresence of self-interested robots operating on a graph, under energy\nconstraints and stochastic transitions. A theoretical study on complete and\nstar graphs establishes that there is a unique pure Nash equilibrium in SPCGs\nthat coincides with the optimal routing solution of an equivalent TOP given a\nrank-based conflict resolution rule. This work proposes two algorithms: Ordinal\nRank Search (ORS) to obtain the ''ordinal rank'' --one's effective rank in\ntemporarily-formed local neighborhoods during the games' stages, and Fictitious\nOrdinal Response Learning (FORL) to obtain best-response policies against one's\nsenior-rank opponents. Empirical evaluations conducted on road networks and\nsynthetic graphs under both dynamic and stationary prize distributions show\nthat 1) the state-aliasing induced by OR-conditioning enables learning policies\nthat scale more efficiently to large team sizes than those trained with the\nglobal index, and 2) Policies trained with FORL generalize better to imbalanced\nprize distributions than those with other multi-agent training methods.\nFinally, the learned policies in the SPCG achieved between 87% and 95%\noptimality compared to an equivalent TOP solution obtained by mixed-integer\nlinear programming.",
    "published": "2025-10-28T15:27:26Z",
    "updated": "2025-10-28T15:27:26Z",
    "link": "http://arxiv.org/pdf/2510.24515v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Malintha Fernando",
      "Petter Ãgren",
      "Silun Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24508v1",
    "title": "Supervisory Measurement-Guided Noise Covariance Estimation",
    "summary": "Reliable state estimation hinges on accurate specification of sensor noise\ncovariances, which weigh heterogeneous measurements. In practice, these\ncovariances are difficult to identify due to environmental variability,\nfront-end preprocessing, and other reasons. We address this by formulating\nnoise covariance estimation as a bilevel optimization that, from a Bayesian\nperspective, factorizes the joint likelihood of so-called odometry and\nsupervisory measurements, thereby balancing information utilization with\ncomputational efficiency. The factorization converts the nested Bayesian\ndependency into a chain structure, enabling efficient parallel computation: at\nthe lower level, an invariant extended Kalman filter with state augmentation\nestimates trajectories, while a derivative filter computes analytical gradients\nin parallel for upper-level gradient updates. The upper level refines the\ncovariance to guide the lower-level estimation. Experiments on synthetic and\nreal-world datasets show that our method achieves higher efficiency over\nexisting baselines.",
    "published": "2025-10-28T15:19:14Z",
    "updated": "2025-10-28T15:19:14Z",
    "link": "http://arxiv.org/pdf/2510.24508v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Haoying Li",
      "Yifan Peng",
      "Junfeng Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.11607v3",
    "title": "Performance evaluation of a ROS2 based Automated Driving System",
    "summary": "Automated driving is currently a prominent area of scientific work. In the\nfuture, highly automated driving and new Advanced Driver Assistance Systems\nwill become reality. While Advanced Driver Assistance Systems and automated\ndriving functions for certain domains are already commercially available,\nubiquitous automated driving in complex scenarios remains a subject of ongoing\nresearch. Contrarily to single-purpose Electronic Control Units, the software\nfor automated driving is often executed on high performance PCs. The Robot\nOperating System 2 (ROS2) is commonly used to connect components in an\nautomated driving system. Due to the time critical nature of automated driving\nsystems, the performance of the framework is especially important. In this\npaper, a thorough performance evaluation of ROS2 is conducted, both in terms of\ntimeliness and error rate. The results show that ROS2 is a suitable framework\nfor automated driving systems.",
    "published": "2024-11-18T14:29:22Z",
    "updated": "2025-10-28T15:15:35Z",
    "link": "http://arxiv.org/pdf/2411.11607v3.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Jorin Kouril",
      "Bernd SchÃ¤ufele",
      "Ilja Radusch",
      "Bettina Schnor"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24457v1",
    "title": "Flatness-based trajectory planning for 3D overhead cranes with friction\n  compensation and collision avoidance",
    "summary": "This paper presents an optimal trajectory generation method for 3D overhead\ncranes by leveraging differential flatness. This framework enables the direct\ninclusion of complex physical and dynamic constraints, such as nonlinear\nfriction and collision avoidance for both payload and rope. Our approach allows\nfor aggressive movements by constraining payload swing only at the final point.\nA comparative simulation study validates our approach, demonstrating that\nneglecting dry friction leads to actuator saturation and collisions. The\nresults show that friction modeling is a fundamental requirement for fast and\nsafe crane trajectories.",
    "published": "2025-10-28T14:24:47Z",
    "updated": "2025-10-28T14:24:47Z",
    "link": "http://arxiv.org/pdf/2510.24457v1.pdf",
    "category": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "authors": [
      "Jorge Vicente-Martinez",
      "Edgar Ramirez-Laboreo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24315v1",
    "title": "Global-State-Free Obstacle Avoidance for Quadrotor Control in Air-Ground\n  Cooperation",
    "summary": "CoNi-MPC provides an efficient framework for UAV control in air-ground\ncooperative tasks by relying exclusively on relative states, eliminating the\nneed for global state estimation. However, its lack of environmental\ninformation poses significant challenges for obstacle avoidance. To address\nthis issue, we propose a novel obstacle avoidance algorithm, Cooperative\nNon-inertial frame-based Obstacle Avoidance (CoNi-OA), designed explicitly for\nUAV-UGV cooperative scenarios without reliance on global state estimation or\nobstacle prediction. CoNi-OA uniquely utilizes a single frame of raw LiDAR data\nfrom the UAV to generate a modulation matrix, which directly adjusts the\nquadrotor's velocity to achieve obstacle avoidance. This modulation-based\nmethod enables real-time generation of collision-free trajectories within the\nUGV's non-inertial frame, significantly reducing computational demands (less\nthan 5 ms per iteration) while maintaining safety in dynamic and unpredictable\nenvironments. The key contributions of this work include: (1) a\nmodulation-based obstacle avoidance algorithm specifically tailored for UAV-UGV\ncooperation in non-inertial frames without global states; (2) rapid, real-time\ntrajectory generation based solely on single-frame LiDAR data, removing the\nneed for obstacle modeling or prediction; and (3) adaptability to both static\nand dynamic environments, thus extending applicability to featureless or\nunknown scenarios.",
    "published": "2025-10-28T11:24:58Z",
    "updated": "2025-10-28T11:24:58Z",
    "link": "http://arxiv.org/pdf/2510.24315v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Baozhe Zhang",
      "Xinwei Chen",
      "Qingcheng Chen",
      "Chao Xu",
      "Fei Gao",
      "Yanjun Cao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.09230v2",
    "title": "Concurrent-Allocation Task Execution for Multi-Robot\n  Path-Crossing-Minimal Navigation in Obstacle Environments",
    "summary": "Reducing undesirable path crossings among trajectories of different robots is\nvital in multi-robot navigation missions, which not only reduces detours and\nconflict scenarios, but also enhances navigation efficiency and boosts\nproductivity. Despite recent progress in multi-robot path-crossing-minimal\n(MPCM) navigation, the majority of approaches depend on the minimal\nsquared-distance reassignment of suitable desired points to robots directly.\nHowever, if obstacles occupy the passing space, calculating the actual\nrobot-point distances becomes complex or intractable, which may render the MPCM\nnavigation in obstacle environments inefficient or even infeasible.\n  In this paper, the concurrent-allocation task execution (CATE) algorithm is\npresented to address this problem (i.e., MPCM navigation in obstacle\nenvironments). First, the path-crossing-related elements in terms of (i) robot\nallocation, (ii) desired-point convergence, and (iii) collision and obstacle\navoidance are encoded into integer and control barrier function (CBF)\nconstraints. Then, the proposed constraints are used in an online constrained\noptimization framework, which implicitly yet effectively minimizes the possible\npath crossings and trajectory length in obstacle environments by minimizing the\ndesired point allocation cost and slack variables in CBF constraints\nsimultaneously. In this way, the MPCM navigation in obstacle environments can\nbe achieved with flexible spatial orderings. Note that the feasibility of\nsolutions and the asymptotic convergence property of the proposed CATE\nalgorithm in obstacle environments are both guaranteed, and the calculation\nburden is also reduced by concurrently calculating the optimal allocation and\nthe control input directly without the path planning process.",
    "published": "2025-04-12T14:15:27Z",
    "updated": "2025-10-28T10:58:38Z",
    "link": "http://arxiv.org/pdf/2504.09230v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Bin-Bin Hu",
      "Weijia Yao",
      "Yanxin Zhou",
      "Henglai Wei",
      "Chen Lv"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.01484v2",
    "title": "Robot Cell Modeling via Exploratory Robot Motions: A Novel and\n  Accessible Data-Driven Approach",
    "summary": "Generating a collision-free robot motion is crucial for safe applications in\nreal-world settings. This requires an accurate model of all obstacle shapes\nwithin the constrained robot cell, which is particularly challenging and\ntime-consuming. The difficulty is heightened in flexible production lines,\nwhere the environment model must be updated each time the robot cell is\nmodified. Furthermore, sensor-based methods often necessitate costly hardware\nand calibration procedures and can be influenced by environmental factors\n(e.g., light conditions or reflections). To address these challenges, we\npresent a novel data-driven approach to modeling a cluttered workspace,\nleveraging solely the robot internal joint encoders to capture exploratory\nmotions. By computing the corresponding swept volume (SV), we generate a\n(conservative) mesh of the environment that is subsequently used for collision\nchecking within established path planning and control methods. Our method\nsignificantly reduces the complexity and cost of classical environment modeling\nby removing the need for computer-aided design (CAD) files and external\nsensors. We validate the approach with the KUKA LBR iisy collaborative robot in\na pick-and-place scenario. In less than three minutes of exploratory robot\nmotions and less than four additional minutes of computation time, we obtain an\naccurate model that enables collision-free motions. Our approach is intuitive\nand easy to use, making it accessible to users without specialized technical\nknowledge. It is applicable to all types of industrial robots or cobots.",
    "published": "2025-02-03T16:20:03Z",
    "updated": "2025-10-28T10:26:35Z",
    "link": "http://arxiv.org/pdf/2502.01484v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Gaetano Meli",
      "Niels Dehio"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24257v1",
    "title": "Manipulate as Human: Learning Task-oriented Manipulation Skills by\n  Adversarial Motion Priors",
    "summary": "In recent years, there has been growing interest in developing robots and\nautonomous systems that can interact with human in a more natural and intuitive\nway. One of the key challenges in achieving this goal is to enable these\nsystems to manipulate objects and tools in a manner that is similar to that of\nhumans. In this paper, we propose a novel approach for learning human-style\nmanipulation skills by using adversarial motion priors, which we name HMAMP.\nThe approach leverages adversarial networks to model the complex dynamics of\ntool and object manipulation, as well as the aim of the manipulation task. The\ndiscriminator is trained using a combination of real-world data and simulation\ndata executed by the agent, which is designed to train a policy that generates\nrealistic motion trajectories that match the statistical properties of human\nmotion. We evaluated HMAMP on one challenging manipulation task: hammering, and\nthe results indicate that HMAMP is capable of learning human-style manipulation\nskills that outperform current baseline methods. Additionally, we demonstrate\nthat HMAMP has potential for real-world applications by performing real robot\narm hammering tasks. In general, HMAMP represents a significant step towards\ndeveloping robots and autonomous systems that can interact with humans in a\nmore natural and intuitive way, by learning to manipulate tools and objects in\na manner similar to how humans do.",
    "published": "2025-10-28T10:10:59Z",
    "updated": "2025-10-28T10:10:59Z",
    "link": "http://arxiv.org/pdf/2510.24257v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Ziqi Ma",
      "Changda Tian",
      "Yue Gao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.15806v2",
    "title": "Autonomous Horizon-based Asteroid Navigation With\n  Observability-constrained Maneuvers",
    "summary": "Small body exploration is a pertinent challenge due to low gravity\nenvironments and strong sensitivity to perturbations like Solar Radiation\nPressure (SRP). Thus, autonomous methods are being developed to enable safe\nnavigation and control around small bodies. These methods often involve using\nOptical Navigation (OpNav) to determine the spacecraft's location. Ensuring\nOpNav reliability would allow the spacecraft to maintain an accurate state\nestimate throughout its mission. This research presents an\nobservability-constrained Lyapunov controller that steers a spacecraft to a\ndesired target orbit while guaranteeing continuous OpNav observability. We\ndesign observability path constraints to avoid regions where horizon-based\nOpNav methods exhibit poor performance, ensuring control input that maintains\ngood observability. This controller is implemented with a framework that\nsimulates small body dynamics, synthetic image generation, edge detection,\nhorizon-based OpNav, and filtering. We evaluate the approach in two\nrepresentative scenarios, orbit maintenance and approach with circularization,\naround spherical and ellipsoidal target bodies. In Monte Carlo simulations, the\nproposed approach improves the rate of attaining target orbits without\nobservability violations by up to 94% compared to an unconstrained Lyapunov\nbaseline, demonstrating improved robustness over conventional methods.",
    "published": "2025-01-27T06:28:29Z",
    "updated": "2025-10-28T08:19:30Z",
    "link": "http://arxiv.org/pdf/2501.15806v2.pdf",
    "category": [
      "cs.RO",
      "math.OC"
    ],
    "authors": [
      "Aditya Arjun Anibha",
      "Kenshiro Oguri"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24109v1",
    "title": "PFEA: An LLM-based High-Level Natural Language Planning and Feedback\n  Embodied Agent for Human-Centered AI",
    "summary": "The rapid advancement of Large Language Models (LLMs) has marked a\nsignificant breakthrough in Artificial Intelligence (AI), ushering in a new era\nof Human-centered Artificial Intelligence (HAI). HAI aims to better serve human\nwelfare and needs, thereby placing higher demands on the intelligence level of\nrobots, particularly in aspects such as natural language interaction, complex\ntask planning, and execution. Intelligent agents powered by LLMs have opened up\nnew pathways for realizing HAI. However, existing LLM-based embodied agents\noften lack the ability to plan and execute complex natural language control\ntasks online. This paper explores the implementation of intelligent robotic\nmanipulating agents based on Vision-Language Models (VLMs) in the physical\nworld. We propose a novel embodied agent framework for robots, which comprises\na human-robot voice interaction module, a vision-language agent module and an\naction execution module. The vision-language agent itself includes a\nvision-based task planner, a natural language instruction converter, and a task\nperformance feedback evaluator. Experimental results demonstrate that our agent\nachieves a 28\\% higher average task success rate in both simulated and real\nenvironments compared to approaches relying solely on LLM+CLIP, significantly\nimproving the execution success rate of high-level natural language instruction\ntasks.",
    "published": "2025-10-28T06:28:21Z",
    "updated": "2025-10-28T06:28:21Z",
    "link": "http://arxiv.org/pdf/2510.24109v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Wenbin Ding",
      "Jun Chen",
      "Mingjia Chen",
      "Fei Xie",
      "Qi Mao",
      "Philip Dames"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24069v1",
    "title": "Dynamically-Consistent Trajectory Optimization for Legged Robots via\n  Contact Point Decomposition",
    "summary": "To generate reliable motion for legged robots through trajectory\noptimization, it is crucial to simultaneously compute the robot's path and\ncontact sequence, as well as accurately consider the dynamics in the problem\nformulation. In this paper, we present a phase-based trajectory optimization\nthat ensures the feasibility of translational dynamics and friction cone\nconstraints throughout the entire trajectory. Specifically, our approach\nleverages the superposition properties of linear differential equations to\ndecouple the translational dynamics for each contact point, which operates\nunder different phase sequences. Furthermore, we utilize the differentiation\nmatrix of B{\\'e}zier polynomials to derive an analytical relationship between\nthe robot's position and force, thereby ensuring the consistent satisfaction of\ntranslational dynamics. Additionally, by exploiting the convex closure property\nof B{\\'e}zier polynomials, our method ensures compliance with friction cone\nconstraints. Using the aforementioned approach, the proposed trajectory\noptimization framework can generate dynamically reliable motions with various\ngait sequences for legged robots. We validate our framework using a quadruped\nrobot model, focusing on the feasibility of dynamics and motion generation.",
    "published": "2025-10-28T05:03:39Z",
    "updated": "2025-10-28T05:03:39Z",
    "link": "http://arxiv.org/pdf/2510.24069v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Sangmin Kim",
      "Hajun Kim",
      "Gijeong Kim",
      "Min-Gyu Kim",
      "Hae-Won Park"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.24067v1",
    "title": "Balanced Collaborative Exploration via Distributed Topological Graph\n  Voronoi Partition",
    "summary": "This work addresses the collaborative multi-robot autonomous online\nexploration problem, particularly focusing on distributed exploration planning\nfor dynamically balanced exploration area partition and task allocation among a\nteam of mobile robots operating in obstacle-dense non-convex environments.\n  We present a novel topological map structure that simultaneously\ncharacterizes both spatial connectivity and global exploration completeness of\nthe environment. The topological map is updated incrementally to utilize known\nspatial information for updating reachable spaces, while exploration targets\nare planned in a receding horizon fashion under global coverage guidance.\n  A distributed weighted topological graph Voronoi algorithm is introduced\nimplementing balanced graph space partitions of the fused topological maps.\nTheoretical guarantees are provided for distributed consensus convergence and\nequitable graph space partitions with constant bounds.\n  A local planner optimizes the visitation sequence of exploration targets\nwithin the balanced partitioned graph space to minimize travel distance, while\ngenerating safe, smooth, and dynamically feasible motion trajectories.\n  Comprehensive benchmarking against state-of-the-art methods demonstrates\nsignificant improvements in exploration efficiency, completeness, and workload\nbalance across the robot team.",
    "published": "2025-10-28T05:01:04Z",
    "updated": "2025-10-28T05:01:04Z",
    "link": "http://arxiv.org/pdf/2510.24067v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Tianyi Ding",
      "Ronghao Zheng",
      "Senlin Zhang",
      "Meiqin Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.19804v2",
    "title": "DynaFlow: Dynamics-embedded Flow Matching for Physically Consistent\n  Motion Generation from State-only Demonstrations",
    "summary": "This paper introduces DynaFlow, a novel framework that embeds a\ndifferentiable simulator directly into a flow matching model. By generating\ntrajectories in the action space and mapping them to dynamically feasible state\ntrajectories via the simulator, DynaFlow ensures all outputs are physically\nconsistent by construction. This end-to-end differentiable architecture enables\ntraining on state-only demonstrations, allowing the model to simultaneously\ngenerate physically consistent state trajectories while inferring the\nunderlying action sequences required to produce them. We demonstrate the\neffectiveness of our approach through quantitative evaluations and showcase its\nreal-world applicability by deploying the generated actions onto a physical Go1\nquadruped robot. The robot successfully reproduces diverse gait present in the\ndataset, executes long-horizon motions in open-loop control and translates\ninfeasible kinematic demonstrations into dynamically executable, stylistic\nbehaviors. These hardware experiments validate that DynaFlow produces\ndeployable, highly effective motions on real-world hardware from state-only\ndemonstrations, effectively bridging the gap between kinematic data and\nreal-world execution.",
    "published": "2025-09-24T06:40:57Z",
    "updated": "2025-10-28T03:10:25Z",
    "link": "http://arxiv.org/pdf/2509.19804v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Sowoo Lee",
      "Dongyun Kang",
      "Jaehyun Park",
      "Hae-Won Park"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23997v1",
    "title": "VOCALoco: Viability-Optimized Cost-aware Adaptive Locomotion",
    "summary": "Recent advancements in legged robot locomotion have facilitated traversal\nover increasingly complex terrains. Despite this progress, many existing\napproaches rely on end-to-end deep reinforcement learning (DRL), which poses\nlimitations in terms of safety and interpretability, especially when\ngeneralizing to novel terrains. To overcome these challenges, we introduce\nVOCALoco, a modular skill-selection framework that dynamically adapts\nlocomotion strategies based on perceptual input. Given a set of pre-trained\nlocomotion policies, VOCALoco evaluates their viability and energy-consumption\nby predicting both the safety of execution and the anticipated cost of\ntransport over a fixed planning horizon. This joint assessment enables the\nselection of policies that are both safe and energy-efficient, given the\nobserved local terrain. We evaluate our approach on staircase locomotion tasks,\ndemonstrating its performance in both simulated and real-world scenarios using\na quadrupedal robot. Empirical results show that VOCALoco achieves improved\nrobustness and safety during stair ascent and descent compared to a\nconventional end-to-end DRL policy",
    "published": "2025-10-28T01:59:34Z",
    "updated": "2025-10-28T01:59:34Z",
    "link": "http://arxiv.org/pdf/2510.23997v1.pdf",
    "category": [
      "cs.RO",
      "I.2.9"
    ],
    "authors": [
      "Stanley Wu",
      "Mohamad H. Danesh",
      "Simon Li",
      "Hanna Yurchyk",
      "Amin Abyaneh",
      "Anas El Houssaini",
      "David Meger",
      "Hsiu-Chin Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23988v1",
    "title": "A Survey on Collaborative SLAM with 3D Gaussian Splatting",
    "summary": "This survey comprehensively reviews the evolving field of multi-robot\ncollaborative Simultaneous Localization and Mapping (SLAM) using 3D Gaussian\nSplatting (3DGS). As an explicit scene representation, 3DGS has enabled\nunprecedented real-time, high-fidelity render- ing, ideal for robotics.\nHowever, its use in multi-robot systems introduces significant challenges in\nmaintaining global consistency, managing communication, and fusing data from\nheterogeneous sources. We systematically categorize approaches by their\narchitecture-centralized, distributed- and analyze core components like\nmulti-agent consistency and alignment, communication- efficient, Gaussian\nrepresentation, semantic distillation, fusion and pose optimization, and real-\ntime scalability. In addition, a summary of critical datasets and evaluation\nmetrics is provided to contextualize performance. Finally, we identify key open\nchallenges and chart future research directions, including lifelong mapping,\nsemantic association and mapping, multi-model for robustness, and bridging the\nSim2Real gap.",
    "published": "2025-10-28T01:44:52Z",
    "updated": "2025-10-28T01:44:52Z",
    "link": "http://arxiv.org/pdf/2510.23988v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Phuc Nguyen Xuan",
      "Thanh Nguyen Canh",
      "Huu-Hung Nguyen",
      "Nak Young Chong",
      "Xiem HoangVan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23963v1",
    "title": "Adaptive-twist Soft Finger Mechanism for Grasping by Wrapping",
    "summary": "This paper presents a soft robot finger capable of adaptive-twist deformation\nto grasp objects by wrapping them. For a soft hand to grasp and pick-up one\nobject from densely contained multiple objects, a soft finger requires the\nadaptive-twist deformation function in both in-plane and out-of-plane\ndirections. The function allows the finger to be inserted deeply into a limited\ngap among objects. Once inserted, the soft finger requires appropriate control\nof grasping force normal to contact surface, thereby maintaining the twisted\ndeformation. In this paper, we refer to this type of grasping as grasping by\nwrapping. To achieve these two functions by a single actuation source, we\npropose a variable stiffness mechanism that can adaptively change the stiffness\nas the pressure is higher. We conduct a finite element analysis (FEA) on the\nproposed mechanism and determine its design parameter based on the FEA result.\nUsing the developed soft finger, we report basic experimental results and\ndemonstrations on grasping various objects.",
    "published": "2025-10-28T00:37:20Z",
    "updated": "2025-10-28T00:37:20Z",
    "link": "http://arxiv.org/pdf/2510.23963v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Hiroki Ishikawa",
      "Kyosuke Ishibashi",
      "Ko Yamamoto"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23954v1",
    "title": "A Comprehensive General Model of Tendon-Actuated Concentric Tube Robots\n  with Multiple Tubes and Tendons",
    "summary": "Tendon-actuated concentric tube mechanisms combine the advantages of\ntendon-driven continuum robots and concentric tube robots while addressing\ntheir respective limitations. They overcome the restricted degrees of freedom\noften seen in tendon-driven designs, and mitigate issues such as snapping\ninstability associated with concentric tube robots. However, a complete and\ngeneral mechanical model for these systems remains an open problem. In this\nwork, we propose a Cosserat rod-based framework for modeling the general case\nof $n$ concentric tubes, each actuated by $m_i$ tendons, where $i = \\{1,\n\\ldots, n\\}$. The model allows each tube to twist and elongate while enforcing\na shared centerline for bending. We validate the proposed framework through\nexperiments with two-tube and three tube assemblies under various tendon\nrouting configurations, achieving tip prediction errors $<4\\%$ of the robot's\ntotal length. We further demonstrate the model's generality by applying it to\nexisting robots in the field, where maximum tip deviations remain around $5\\%$\nof the total length. This model provides a foundation for accurate shape\nestimation and control of advanced tendon-actuated concentric tube robots.",
    "published": "2025-10-28T00:18:40Z",
    "updated": "2025-10-28T00:18:40Z",
    "link": "http://arxiv.org/pdf/2510.23954v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Pejman Kheradmand",
      "Behnam Moradkhani",
      "Raghavasimhan Sankaranarayanan",
      "Kent K. Yamamoto",
      "Tanner J. Zachem",
      "Patrick J. Codd",
      "Yash Chitalia",
      "Pierre E. Dupont"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23902v1",
    "title": "Stand, Walk, Navigate: Recovery-Aware Visual Navigation on a Low-Cost\n  Wheeled Quadruped",
    "summary": "Wheeled-legged robots combine the efficiency of wheels with the obstacle\nnegotiation of legs, yet many state-of-the-art systems rely on costly actuators\nand sensors, and fall-recovery is seldom integrated, especially for\nwheeled-legged morphologies. This work presents a recovery-aware\nvisual-inertial navigation system on a low-cost wheeled quadruped. The proposed\nsystem leverages vision-based perception from a depth camera and deep\nreinforcement learning policies for robust locomotion and autonomous recovery\nfrom falls across diverse terrains. Simulation experiments show agile mobility\nwith low-torque actuators over irregular terrain and reliably recover from\nexternal perturbations and self-induced failures. We further show goal directed\nnavigation in structured indoor spaces with low-cost perception. Overall, this\napproach lowers the barrier to deploying autonomous navigation and robust\nlocomotion policies in budget-constrained robotic platforms.",
    "published": "2025-10-27T22:19:35Z",
    "updated": "2025-10-27T22:19:35Z",
    "link": "http://arxiv.org/pdf/2510.23902v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Jans Solano",
      "Diego Quiroz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23899v1",
    "title": "Coordinated Autonomous Drones for Human-Centered Fire Evacuation in\n  Partially Observable Urban Environments",
    "summary": "Autonomous drone technology holds significant promise for enhancing search\nand rescue operations during evacuations by guiding humans toward safety and\nsupporting broader emergency response efforts. However, their application in\ndynamic, real-time evacuation support remains limited. Existing models often\noverlook the psychological and emotional complexity of human behavior under\nextreme stress. In real-world fire scenarios, evacuees frequently deviate from\ndesignated safe routes due to panic and uncertainty. To address these\nchallenges, this paper presents a multi-agent coordination framework in which\nautonomous Unmanned Aerial Vehicles (UAVs) assist human evacuees in real-time\nby locating, intercepting, and guiding them to safety under uncertain\nconditions. We model the problem as a Partially Observable Markov Decision\nProcess (POMDP), where two heterogeneous UAV agents, a high-level rescuer (HLR)\nand a low-level rescuer (LLR), coordinate through shared observations and\ncomplementary capabilities. Human behavior is captured using an agent-based\nmodel grounded in empirical psychology, where panic dynamically affects\ndecision-making and movement in response to environmental stimuli. The\nenvironment features stochastic fire spread, unknown evacuee locations, and\nlimited visibility, requiring UAVs to plan over long horizons to search for\nhumans and adapt in real-time. Our framework employs the Proximal Policy\nOptimization (PPO) algorithm with recurrent policies to enable robust\ndecision-making in partially observable settings. Simulation results\ndemonstrate that the UAV team can rapidly locate and intercept evacuees,\nsignificantly reducing the time required for them to reach safety compared to\nscenarios without UAV assistance.",
    "published": "2025-10-27T22:12:21Z",
    "updated": "2025-10-27T22:12:21Z",
    "link": "http://arxiv.org/pdf/2510.23899v1.pdf",
    "category": [
      "cs.MA",
      "cs.RO"
    ],
    "authors": [
      "Maria G. Mendoza",
      "Addison Kalanther",
      "Daniel Bostwick",
      "Emma Stephan",
      "Chinmay Maheshwari",
      "Shankar Sastry"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23895v1",
    "title": "Modeling and Scheduling of Fusion Patterns in Autonomous Driving Systems\n  (Extended Version)",
    "summary": "In Autonomous Driving Systems (ADS), Directed Acyclic Graphs (DAGs) are\nwidely used to model complex data dependencies and inter-task communication.\nHowever, existing DAG scheduling approaches oversimplify data fusion tasks by\nassuming fixed triggering mechanisms, failing to capture the diverse fusion\npatterns found in real-world ADS software stacks. In this paper, we propose a\nsystematic framework for analyzing various fusion patterns and their\nperformance implications in ADS. Our framework models three distinct fusion\ntask types: timer-triggered, wait-for-all, and immediate fusion, which\ncomprehensively represent real-world fusion behaviors. Our Integer Linear\nProgramming (ILP)-based approach enables an optimization of multiple real-time\nperformance metrics, including reaction time, time disparity, age of\ninformation, and response time, while generating deterministic offline\nschedules directly applicable to real platforms. Evaluation using real-world\nADS case studies, Raspberry Pi implementation, and randomly generated DAGs\ndemonstrates that our framework handles diverse fusion patterns beyond the\nscope of existing work, and achieves substantial performance improvements in\ncomparable scenarios.",
    "published": "2025-10-27T22:05:54Z",
    "updated": "2025-10-27T22:05:54Z",
    "link": "http://arxiv.org/pdf/2510.23895v1.pdf",
    "category": [
      "eess.SY",
      "cs.OS",
      "cs.RO",
      "cs.SY"
    ],
    "authors": [
      "Hoora Sobhani",
      "Hyoseung Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.16372v3",
    "title": "COMPASS: Cross-embodiment Mobility Policy via Residual RL and Skill\n  Synthesis",
    "summary": "As robots are increasingly deployed in diverse application domains, enabling\nrobust mobility across different embodiments has become a critical challenge.\nClassical mobility stacks, though effective on specific platforms, require\nextensive per-robot tuning and do not scale easily to new embodiments.\nLearning-based approaches, such as imitation learning (IL), offer alternatives,\nbut face significant limitations on the need for high-quality demonstrations\nfor each embodiment.\n  To address these challenges, we introduce COMPASS, a unified framework that\nenables scalable cross-embodiment mobility using expert demonstrations from\nonly a single embodiment. We first pre-train a mobility policy on a single\nrobot using IL, combining a world model with a policy model. We then apply\nresidual reinforcement learning (RL) to efficiently adapt this policy to\ndiverse embodiments through corrective refinements. Finally, we distill\nspecialist policies into a single generalist policy conditioned on an\nembodiment embedding vector. This design significantly reduces the burden of\ncollecting data while enabling robust generalization across a wide range of\nrobot designs. Our experiments demonstrate that COMPASS scales effectively\nacross diverse robot platforms while maintaining adaptability to various\nenvironment configurations, achieving a generalist policy with a success rate\napproximately 5X higher than the pre-trained IL policy on unseen embodiments,\nand further demonstrates zero-shot sim-to-real transfer.",
    "published": "2025-02-22T22:26:30Z",
    "updated": "2025-10-27T21:59:34Z",
    "link": "http://arxiv.org/pdf/2502.16372v3.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Wei Liu",
      "Huihua Zhao",
      "Chenran Li",
      "Yuchen Deng",
      "Joydeep Biswas",
      "Soha Pouya",
      "Yan Chang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.23860v1",
    "title": "Motivating Students' Self-study with Goal Reminder and Emotional Support",
    "summary": "While the efficacy of social robots in supporting people in learning tasks\nhas been extensively investigated, their potential impact in assisting students\nin self-studying contexts has not been investigated much. This study explores\nhow a social robot can act as a peer study companion for college students\nduring self-study tasks by delivering task-oriented goal reminder and positive\nemotional support. We conducted an exploratory Wizard-of-Oz study to explore\nhow these robotic support behaviors impacted students' perceived focus,\nproductivity, and engagement in comparison to a robot that only provided\nphysical presence (control). Our study results suggest that participants in the\ngoal reminder and the emotional support conditions reported greater ease of\nuse, with the goal reminder condition additionally showing a higher willingness\nto use the robot in future study sessions. Participants' satisfaction with the\nrobot was correlated with their perception of the robot as a social other, and\nthis perception was found to be a predictor for their level of goal achievement\nin the self-study task. These findings highlight the potential of socially\nassistive robots to support self-study through both functional and emotional\nengagement.",
    "published": "2025-10-27T21:07:17Z",
    "updated": "2025-10-27T21:07:17Z",
    "link": "http://arxiv.org/pdf/2510.23860v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Hyung Chan Cho",
      "Go-Eum Cha",
      "Yanfu Liu",
      "Sooyeon Jeong"
    ]
  }
]